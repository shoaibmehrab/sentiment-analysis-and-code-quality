id,original_comment,processed_comment,source,sentiment_VADER,sentiment_textblob,sentiment_pattern,sentiment_bert,sentiment_spacy,max_voted_sentiment
2040710292,"can you try installing after lowering the version of cython? 
for instance - `pip install cython==0.29.36`",try lowering version instance pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
2040568115,"Hey @Smartappli! Thanks for the PR! Many on the team are likely to be off for the weekend, but i've flagged your PR for review (good chance upgrading the transformers package passes all the tests and goes swimmingly in the mean time — shouldn't be long). 

Thanks for taking the time to submit a PR back to the codebase! Also if you're not already, feel free to join our slack (slack.openmined.org). ",hey thanks many team likely weekend review good chance package go swimmingly mean time long thanks taking time submit back also already feel free join slack,issue,positive,positive,positive,positive,positive,positive
2035884535,"Check out this pull request on&nbsp; <a href=""https://app.reviewnb.com/OpenMined/PySyft/pull/8662""><img align=""absmiddle""  alt=""ReviewNB"" height=""28"" class=""BotMessageButtonImage"" src=""https://raw.githubusercontent.com/ReviewNB/support/master/images/button_reviewnb.png""/></a> 

 See visual diffs & provide feedback on Jupyter Notebooks. 

---

 <i>Powered by <a href='https://www.reviewnb.com/?utm_source=gh'>ReviewNB</a></i>",check pull request see visual provide feedback powered,issue,negative,neutral,neutral,neutral,neutral,neutral
2034737778,"@kiendang this is a spike PR to see if we can use smartopen, but as you rightly pointed out it just doesn't fit in well. Additionally, smartopen doesn't support deleting files which renders it partially useful. Meanwhile, @tcp has been working on using fsspec which feels much more complete and in-line with our use-case. There still remains some gaps, specifically how to upload blob from client to bucket (through backend) without seaweed's `/blob` API. As we solve it we may actually end up doing some much needed rework/refactoring of our blob store APIs. 

Regardless, thank you for your insights!",spike see use rightly pointed fit well additionally support partially useful meanwhile working much complete still remains specifically blob client bucket without seaweed solve may actually end much blob store regardless thank,issue,positive,positive,positive,positive,positive,positive
2034086344,"This pull request sets up GitHub code scanning for this repository. Once the scans have completed and the checks have passed, the analysis results for this pull request branch will appear on [this overview](/OpenMined/PySyft/security/code-scanning?query=pr%3A8655+is%3Aopen). Once you merge this pull request, the 'Security' tab will show more code scanning analysis results (for example, for the default branch). Depending on your configuration and choice of analysis tool, future pull requests will be annotated with code scanning analysis results. For more information about GitHub code scanning, check out [the documentation](https://docs.github.com/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/about-code-scanning). ",pull request code scanning repository analysis pull request branch appear overview merge pull request tab show code scanning analysis example default branch depending configuration choice analysis tool future pull code scanning analysis information code scanning check documentation,issue,negative,neutral,neutral,neutral,neutral,neutral
2026642794,"@yashgorana while working on integration with different blob storage services, if you think of any tweaks to these abstractions that better fit our use cases please push them.",working integration different blob storage think better fit use please push,issue,positive,positive,positive,positive,positive,positive
2026637444,"Had a discussion with @tcp the other day around blob storage abstractions (client, connection, config). I do see now that the `BlobStorageConnection` interface does not really work here, at least not yet. The original intention behind `BlobStorageConnection` is that you can do 

```py
with blob_client.connect() as conn:
    conn.write(...)

with blob_client.connect() as conn:
    conn.read(...)
```

where `blob_client.connect()` returns a `BlobStorageConnection` via `BlobStorageConnection.__init__()`

I see that here we can't really do that yet since you need to pass different parameters to the connection to Smart Open depending on whether you write or read.

We could change the abstraction a bit to allow `client.connect()` and `BlobStorageConnection.__init__()` to accept extra parameters but that would leak abstraction. We probably needs a rework/rethinking around this.",discussion day around blob storage client connection see interface really work least yet original intention behind conn conn via see ca really yet since need pas different connection smart open depending whether write read could change abstraction bit allow accept extra would leak abstraction probably need around,issue,positive,positive,neutral,neutral,positive,positive
2017839880,@shubham3121 is this because we cleaned up the older versions of the classes and made the codebase stop being compatible with older versions after updated to pydantic v2,older class made stop compatible older,issue,negative,positive,positive,positive,positive,positive
2009933884,Haven't tested this rigorously so please don't merge,tested rigorously please merge,issue,negative,neutral,neutral,neutral,neutral,neutral
2009283078,"Stellar Work @itstauq  ⭐ 
It's great to Chunking working with great reliability
![test](https://github.com/OpenMined/PySyft/assets/43314053/b2e33150-6838-4a91-aa14-2bb77db9ea88)

",stellar work star great working great reliability test,issue,positive,positive,positive,positive,positive,positive
2003936820,"Propagating error when Input policy is not longer valid (e.g. running a function on a different dataset)

![Screenshot from 2024-03-18 19-08-43](https://github.com/OpenMined/PySyft/assets/11032835/f1dff3da-ca9f-4aa5-9f90-7852673ae2da)
",error input policy longer valid running function different,issue,negative,neutral,neutral,neutral,neutral,neutral
1999158044,"Progress: fix bugs in https://github.com/OpenMined/Heartbeat/issues/1140

![image](https://github.com/OpenMined/PySyft/assets/88959106/47a9266b-6b0c-4fb4-9865-20f231fdd7ca)
![image](https://github.com/OpenMined/PySyft/assets/88959106/b3982588-05fc-4381-9752-6298cf435837)

Note: now `DatasetService.search`'s roles is `GUEST_ROLE_LEVEL`",progress fix image image note,issue,negative,neutral,neutral,neutral,neutral,neutral
1998601633,"> there is one package: pycapnp.
> 
> use conda install manually and you will avoid this error.
> 
> conda install -c conda-forge pycapnp

This solved my problem. MacOS 11.7.10, MacBook Pro (Retina, 15-inch, Late 2013)",one package use install manually avoid error install problem pro retina late,issue,negative,negative,negative,negative,negative,negative
1997152421,"Error while trying to launch and login web-server gateway nodes

![image](https://github.com/OpenMined/PySyft/assets/88959106/9acbd31c-f6f4-4171-a3a4-9260a006bf4e)

![image](https://github.com/OpenMined/PySyft/assets/88959106/578ef711-d28b-4e1d-a820-11f77e6e95f1)

![image](https://github.com/OpenMined/PySyft/assets/88959106/1b68a436-f55f-48a1-8111-ec9d98a0717b)
",error trying launch login gateway image image image,issue,negative,neutral,neutral,neutral,neutral,neutral
1996748758,"After launching a gateway node and a domain node, connect the domain node to the gateway node, we have

![Screenshot from 2024-03-14 14-40-11](https://github.com/OpenMined/PySyft/assets/88959106/d279be6a-b9e6-44e1-9df6-7f9efcb53293)
",gateway node domain node connect domain node gateway node,issue,negative,neutral,neutral,neutral,neutral,neutral
1993818084,"Merging the PR, as the tests are highly flaky, due to which, I have been re-starting the tests from morning
",highly flaky due morning,issue,negative,positive,neutral,neutral,positive,positive
1993649374,"I'll be pushing some more fixes, please don't merge this PR at the moment",pushing please merge moment,issue,negative,neutral,neutral,neutral,neutral,neutral
1992831615,@iamtrask we have some paid testing accounts if you reach out to @IonesioJunior he can show you how to use them.,testing reach show use,issue,negative,neutral,neutral,neutral,neutral,neutral
1990237113,"Got this `TypeHintWarning` that needs to be fixed when login
![image](https://github.com/OpenMined/PySyft/assets/88959106/20d985b1-6186-414f-9c8d-3ea8671fbe0e)
 ",got need fixed login image,issue,negative,positive,neutral,neutral,positive,positive
1989919099,"Great question. On the email thing. I tried to setup an OpenMined-paid twilio or something but ran into mysterious issues around authenticating my account (sent an email to support — we'll see). If it wasn't crazy expensive, I'm not totally against taking the risk and putting a rate-limited private key in there (maybe 1000 emails a day?... we could increase its limits as people are using it until it gets unreasonable) and recommending it for use by first-time users. 

Longer term, it seems like people can setup a new email account for popular email providers (gmail, outlook, etc.), put in the credentails to PySyft, and have that email forward to their normal email account. This feels like the real solution long-term because it also means that if a user replies to the email they end up talking to the domain owner (And it means they can skip setting up twilio). (I think Ionesio might have had this kind of idea in mind in his video as well). Anyway, from a product perspective, it seems desirable for people to have a free option that just involves entering email credentails for a forwarding account. Feels accessible and secure. (note: strictly speaking I think this is a better security practice to setup a forwarder email than to use one's email directly — although that seems difficult for us to enforce. we could have the dummy/test email it sends upon Domain Setup specifically tell them to setup a forwarder i suppose.)

Anyway - main thing I'm hoping for here is a near-turn-key option for both dev and non-dev mode. I had such a big trouble setting up a twilio (or similar) platform, seems ideal if we can help users skip that step with good defaults, and an easy way to use their own email (by setting up a forwarder)",great question thing tried setup something ran mysterious around account sent support see crazy expensive totally taking risk private key maybe day could increase people unreasonable use longer term like people setup new account popular outlook put forward normal account like real solution also user end talking domain owner skip setting think might kind idea mind video well anyway product perspective desirable people free option entering forwarding account accessible secure note strictly speaking think better security practice setup forwarder use one directly although difficult u enforce could upon domain setup specifically tell setup forwarder suppose anyway main thing option dev mode big trouble setting similar platform ideal help skip step good easy way use setting forwarder,issue,positive,positive,positive,positive,positive,positive
1987686472,"This has been pretty high on my personal ""unsolveable annoying problems"" list! @kiendang and @khoaguin great work getting it fixed. 🙏",pretty high personal annoying list great work getting fixed,issue,positive,positive,neutral,neutral,positive,positive
1987619570,"@iamtrask nice work finally hiding the C++ bug.
```python
# from the library source
      capture = py.io.StdCaptureFD(out=out, in_=in_)
```

That explains why no other way we tried to catch those warnings worked.

Regarding the test email, thats a pretty handy way to do it, would this best be in `dev` mode only? Also we might want to check to see what happens if auth fails if that account gets blocked to make sure it doesnt stop people running notebook examples down the track.
",nice work finally bug python library source capture way tried catch worked regarding test thats pretty handy way would best dev mode also might want check see account blocked make sure doesnt stop people running notebook track,issue,positive,positive,positive,positive,positive,positive
1987085824,"@iamtrask @kiendang I worked on Kien's proposed solution in [this PR](https://github.com/OpenMined/PySyft/pull/8563), and seems like it's working 
![image](https://github.com/OpenMined/PySyft/assets/88959106/70aef922-2300-4205-bd96-107d9c6fa46d)
",worked solution like working image,issue,positive,neutral,neutral,neutral,neutral,neutral
1987058107,@kiendang thanks for taking all the time to investigate! I defer to the wisdom of the group on timing and prioritization. Thanks for finding the root security issue in there. I did notice the failing test and wasn't sure what that was all about. Sounds like you've got a workable plan forward! 🙏,thanks taking time investigate defer wisdom group timing thanks finding root security issue notice failing test sure like got workable plan forward,issue,positive,positive,positive,positive,positive,positive
1986832936,"Thanks @iamtrask this warning must have driven everyone crazy. After a bit of investigation I do agree this is the only solution that works. Some context for anyone else looking into this, since the warning is raised by a C/C++ library, changing `sys.stdout`, `sys.stderr` or using `contextlib.redirect_stdout`, `contextlib.redirect_stderr` doesn't work. I also tried using the [`importlib.resources.files`](https://setuptools.pypa.io/en/latest/userguide/datafiles.html#accessing-data-files-at-runtime) api to load the `capnp` files instead to bypass the issue but this also does not work due to `capnp.load` quirkiness.

However there is still an issue with this solution. The `hide-warnings` library depends on [`py`](https://py.readthedocs.io/en/latest/io.html), which has been deprecated for a while and raises a security alert as you can see in the CI. `py` is also a heavy dependency to add to `syft` just to suppress a warning (it used to be `pytest` backend).

Nevertheless suppressing this warning is definitely something we need to do. I think the right approach is just to port/copy `hide-warnings` and the `py` code it depends on here. This is not a lot of code (only 2 short files [1](https://github.com/Rainbow-Dreamer/hide_warnings/blob/main/hide_warnings.py) [2](https://github.com/pytest-dev/py/blob/master/py/_io/capture.py)).

If you think this makes sense I can try to resolve this during some down time in the 0.8.6 cycle.",thanks warning must driven everyone crazy bit investigation agree solution work context anyone else looking since warning raised library work also tried load instead bypass issue also work due quirkiness however still issue solution library security alert see also heavy dependency add suppress warning used nevertheless warning definitely something need think right approach code lot code short think sense try resolve time cycle,issue,positive,negative,neutral,neutral,negative,negative
1986736659,"I recognize 0.8.5 is about to go out the door. Not necessarily a hard requirement but given it's a small PR, cosmetically it feels like a win for UX. I defer to the judgement of the team.",recognize go door necessarily hard requirement given small cosmetically like win defer team,issue,positive,positive,neutral,neutral,positive,positive
1986711323,Oh `AZURE_BLOB_STORAGE_KEY` not being set is due to this PR being created in Madhava's fork. Let's switch to #8559.,oh set due fork let switch,issue,negative,negative,negative,negative,negative,negative
1985080798,"Thank you for the cleanup @yashgorana , the commands are even more simpler now",thank cleanup even simpler,issue,negative,neutral,neutral,neutral,neutral,neutral
1983469177,"I don't seem to encounter this error anymore, probably a mistake from my side. Thank you!",seem encounter error probably mistake side thank,issue,negative,neutral,neutral,neutral,neutral,neutral
1982897290,@AlexAronikov can you be a bit more specific about the blob storage issue? Can you give me the error message and how you got it so I can replicate it? If its unrelated you could always create a new issue.,bit specific blob storage issue give error message got replicate unrelated could always create new issue,issue,negative,positive,neutral,neutral,positive,positive
1982893307,@H4LL Adam did you get this to work? I will close this for now as I know that its related to quotes on my zsh.,get work close know related,issue,negative,neutral,neutral,neutral,neutral,neutral
1982757536,"@koenvanderveen, since we're not keeping compatibility for this release, I have deprecated SyftObjectRetrieval version 3 class and removed any migrations for the same.",since keeping compatibility release version class removed,issue,negative,neutral,neutral,neutral,neutral,neutral
1982167582,"Thanks @madhavajay ! The error mentioned before is fixed with your suggestions. The ""No blob storage entry exists"" error persists with my own data, though. Any suggestions on how to troubleshoot?",thanks error fixed blob storage entry error data though,issue,negative,positive,positive,positive,positive,positive
1982096531,"@yashgorana excellent.
@simba-axin I will close this for now but if you want to do remote debugging please checkout the guide above.",excellent close want remote please guide,issue,positive,positive,positive,positive,positive,positive
1982094724,"@AlexAronikov I have replicated this issue. It isn't a bug per se, whats happening is there is an exception which gets logged but is not visible to the user which says `no module named 'opendp'`
<img width=""828"" alt=""Screenshot 2024-03-07 at 10 14 47 am"" src=""https://github.com/OpenMined/PySyft/assets/2882739/9cba6e15-be7c-4d71-b309-d02b27546c27"">

In CI we install syft with all the data science extras:
```
$ pip install syft[data_science]
```

However if you just install syft and use this notebook you won't have opendp.

You should be able to verify and fix with:
```
!pip list | grep opendp
```

```
!pip install opendp==0.8.0
```

And then restart your notebook and try again.

What we can do here is make that error more obvious. @koenvanderveen I think in this case printing out the exception makes sense because for the local user its their private access anyway, for the remote server its printing on the server and we capture that context and make it part of the protected logs as well.
",replicated issue bug per se whats happening exception logged visible user module install data science pip install however install use notebook wo able verify fix pip list pip install restart notebook try make error obvious think case printing exception sense local user private access anyway remote server printing server capture context make part well,issue,negative,positive,neutral,neutral,positive,positive
1981070021,@madhavajay Thanks for your answer. It's Python 3.9.18. What version do you recommend?,thanks answer python version recommend,issue,positive,positive,positive,positive,positive,positive
1981067480,I resolved the conflicts. Protocol version's messed up again though due to the type annotation syntax change.,resolved protocol version though due type annotation syntax change,issue,negative,negative,negative,negative,negative,negative
1980859617,"@kiendang I see conflicts with recent dev, I will work on resolving it, first thing tomorrow. ",see recent dev work first thing tomorrow,issue,negative,positive,positive,positive,positive,positive
1980584316,"We probably should merge #8548 first since it updates type annotations, from `typing.List` to `list`, `Optional[X]` to `X | None`, ... I'm not sure if that affects protocol version. Tests are passing in #8548 except for some flakiness in `serde/numpy_function_test.py` in Python 3.12 unit tests.",probably merge first since type list optional none sure protocol version passing except flakiness python unit,issue,negative,positive,positive,positive,positive,positive
1980163394,"Discussed it with Madhava and I'm fixing it as a separate PR, since we will be breaking protocol anyways.",fixing separate since breaking protocol anyways,issue,negative,neutral,neutral,neutral,neutral,neutral
1980162140,@shubham3121 The migration/protocol version still needs taking care of though?,version still need taking care though,issue,negative,neutral,neutral,neutral,neutral,neutral
1980148178,@AlexAronikov are you able to tell us what version of python you are running also so I can try to replicate this.,able tell u version python running also try replicate,issue,negative,positive,positive,positive,positive,positive
1979691267,"Unfortunately, it does not work when importing opendp, still.
'Exception encountered while running sum_trade_value_mil, please contact the Node Admin for more info.'

![Screenshot 2024-03-05 at 22 46 28](https://github.com/OpenMined/PySyft/assets/60147284/f7a037ff-9497-4c0c-9fc6-44e1d030d541)
",unfortunately work still running please contact node,issue,negative,negative,negative,negative,negative,negative
1979621284,"What is the .message (pointer.message in this case) property of the SyftError you are getting? Just to be completely sure its not an environment issue, if you import opendp from within the notebook that works?",case property getting completely sure environment issue import within notebook work,issue,negative,positive,positive,positive,positive,positive
1979054307,"Hi @koenvanderveen, I just retested the recently updated notebooks. The issue is still the same as in #8530. Can confirm with both Notebook #1 and Notebook #3 run into issues for me (with opendp installed and imported). It's MacOS, if that matters. Attached both errors.

![Screenshot 2024-03-05 at 16 36 13](https://github.com/OpenMined/PySyft/assets/60147284/3f33b6cc-a457-42ca-beee-54fffddc926e)

![Screenshot 2024-03-05 at 16 32 26](https://github.com/OpenMined/PySyft/assets/60147284/ae8d352e-7ff2-4449-8b69-eff423115e63)


",hi recently issue still confirm notebook notebook run attached,issue,negative,neutral,neutral,neutral,neutral,neutral
1978574906,Thanks @koenvanderveen . I tried redownloading the notebooks and it seems to seitch between this issue with my own data and Issue #8530 with the data provided in the notebooks. Will further investigate abd let you know!,thanks tried issue data issue data provided investigate let know,issue,negative,positive,positive,positive,positive,positive
1978564033,Thanks @koenvanderveen ! I tried installing and importing opendp in all notebooks but the error persists. Is there something else which should be done? ![image](https://github.com/OpenMined/PySyft/assets/60147284/9685c2c8-45a8-4588-9825-03b653701e9f),thanks tried error something else done image,issue,negative,positive,positive,positive,positive,positive
1977739136,"Hi, thanks for raising this. I am not able to reproduce though. Which version of the notebooks are you running? Can you try it from the 0.8.4 branch and see if the problem persists?",hi thanks raising able reproduce though version running try branch see problem,issue,negative,positive,positive,positive,positive,positive
1977731011,"Hey folks, thanks for raising this. We forgot to mention in the notebook that we now need a manually install the dependency. Also, error handling should definitely be improved here. Please use 
```
pip install opendp
```
and it will work",hey thanks raising forgot mention notebook need manually install dependency also error handling definitely please use pip install work,issue,positive,positive,neutral,neutral,positive,positive
1976954407,"Hi @madhavajay @H4LL  I am running into the same issue in the same notebook. Syft_Version = 0.8.4. Is there a fix for this? Many thanks.


![Screenshot 2024-03-04 at 17 17 46](https://github.com/OpenMined/PySyft/assets/60147284/f6ff772a-7908-4d3a-8c3b-cf13bdf72561)
",hi running issue notebook fix many thanks,issue,negative,positive,positive,positive,positive,positive
1975673606,"I was running `0.8.3`, upgrading to to `0.8.4` resolves the issue.
Perhaps the `SYFT_VERSION` in the first cell of the notebook can also be updated?

Thanks! @madhavajay @H4LL ",running issue perhaps first cell notebook also thanks,issue,negative,positive,positive,positive,positive,positive
1975613622,"This now creates a pointer where as before it was returning the locally executed data, so I wonder if this is a mismatch between a version and the notebook.

Can you both please print `sy.__version__` to see what version is running and try the `0.8.4` in case you have one of the betas?",pointer locally executed data wonder mismatch version notebook please print see version running try case one,issue,negative,neutral,neutral,neutral,neutral,neutral
1975603057,@yzmninglang glad to hear you got it working! 👏,glad hear got working,issue,negative,positive,positive,positive,positive,positive
1975600038,"Hi @H4LL, I think the issue is `zsh`. I use it as well but the syntax for `[` extras requires `""` quotes.

```
$ pip install -U ""syft[data_science]""
```",hi think issue use well syntax pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
1975596683,"@rajaboja and @H4LL Interesting, seems like its having trouble creating the temporary worker. I will ask the team to investigate.

<img width=""648"" alt=""Screenshot 2024-03-04 at 1 13 33 pm"" src=""https://github.com/OpenMined/PySyft/assets/2882739/cad7c9a2-c94a-4f42-b53f-f2295491a0ba"">
",interesting like trouble temporary worker ask team investigate,issue,negative,positive,positive,positive,positive,positive
1975513739,"Closed as it's outdated and we need to also make it work with Kubernetes, so mostly will be an entirely rework",closed outdated need also make work mostly entirely rework,issue,negative,negative,negative,negative,negative,negative
1974172493,"I used this PR as inspiration, but I ended up solving it in a slightly different way",used inspiration ended slightly different way,issue,positive,neutral,neutral,neutral,neutral,neutral
1971882238,"+1 to 

> add some permission to allow users to add datasets in the future

yes please!",add permission allow add future yes please,issue,positive,neutral,neutral,neutral,neutral,neutral
1970958172,"Thank you very much for your reply. My raspberry pi is the latest version of raspberry pi 5. I also feel that the aarchpython dependency package you mentioned is not compatible. Because some packages only compile x86 architecture, I can't install the dependencies needed by pysyft here.Currently, my raspberry pie 5 is a 64-bit ubuntu system, when I follow your prompts to create an python3.9 environment in conda. Running pip install syft, everything seems to be fine now. Thank you very much for your guidance.",thank much reply raspberry pi latest version raspberry pi also feel dependency package compatible compile architecture ca install raspberry pie system follow create python environment running pip install everything fine thank much guidance,issue,positive,positive,positive,positive,positive,positive
1970082703,"Closing this, I dont want to spend time right now on merging it. It might reopen if we still need this in the future ",dont want spend time right might reopen still need future,issue,negative,positive,positive,positive,positive,positive
1970037955,"Fixed. In my case, it turned out conda was using the system-wide pip and not the pip from the conda environment. seems like a conda bug actually... regardless, locating the bin file for the conda pip and using that pip should solve the problem.",fixed case turned pip pip environment like bug actually regardless bin file pip pip solve problem,issue,negative,positive,neutral,neutral,positive,positive
1970016537,Facing same issue from conda. Is syft not runnable from conda (i see the working example is from pyenv)?,facing issue runnable see working example,issue,negative,neutral,neutral,neutral,neutral,neutral
1966879660,"I can confirm that I also get an error running the same code block:

syft version: 0.8.4
python version: 3.11.8

<img width=""942"" alt=""Screenshot 2024-02-27 at 3 51 19 PM"" src=""https://github.com/OpenMined/PySyft/assets/46713492/c0a521c1-44b1-4aea-a262-462ee2a72e4f"">
",confirm also get error running code block version python version,issue,negative,neutral,neutral,neutral,neutral,neutral
1964128490,"@yzmninglang We dropped support for python 3.8 a while back but you should be able to install Python 3.9.

The main thing that will prevent you install syft will be aarch packages for raspberry pi. 

If its a 32-bit raspberry pi it might be a bit harder.
Have you tried to install the current dependencies directly with pip to see which ones are supported currently?

Do you know which model of raspberry pi you have?

https://github.com/OpenMined/PySyft/blob/dev/packages/syft/setup.cfg

```
bcrypt==4.0.1
boto3==1.28.65
forbiddenfruit==0.1.4
gevent==23.9.1
loguru==0.7.2
networkx==2.8
packaging>=23.0
pyarrow==14.0.1
pycapnp==1.3.0
pydantic[email]==1.10.13
pymongo==4.6.1
pynacl==1.5.0
pyzmq>=23.2.1,<=25.1.1
redis==4.6.0
requests==2.31.0
RestrictedPython==7.0
result==0.10.0
tqdm==4.66.1
typeguard==2.13.3
typing_extensions==4.8.0
sherlock[redis,filelock]==0.4.1
uvicorn[standard]==0.24.0.post1
fastapi==0.103.2
psutil==5.9.6
hagrid>=0.3
itables==1.6.2
safetensors==0.4.1
argon2-cffi==23.1.0
matplotlib==3.8.0
jaxlib==0.4.20
jax==0.4.20
numpy>=1.23.5,<=1.24.4
pandas==1.5.3
docker==6.1.3
kr8s==0.13.1
PyYAML==6.0.1
azure-storage-blob==12.19
```

If you have any issues with these libs you can try to create a branch of PySyft in a fork and modify the setup.cfg to get it to use versions that are compatible with your raspberry pi.",support python back able install python main thing prevent install raspberry pi raspberry pi might bit harder tried install current directly pip see currently know model raspberry pi sherlock standard post try create branch fork modify get use compatible raspberry pi,issue,positive,positive,neutral,neutral,positive,positive
1953568004,"Closing this PR due to merge Conflicts, will recreate a new PR",due merge recreate new,issue,negative,positive,neutral,neutral,positive,positive
1946317579,"Hi @nameli0722 - If you mean homomorphic encryption, I believe the leading folks in the space are at https://www.zama.ai/. They have an open source library (concrete), but I believe their fastest one is closed-source/propriteary.",hi mean homomorphic encryption believe leading space open source library concrete believe one,issue,negative,negative,neutral,neutral,negative,negative
1946315046,"Hi @hwjnihao while there's no strict limit on the size of assets used in PySyft, we don't at present have a tutorial around them. I don't presently have a date for when such a tutorial might come together, but we are actively performing R&D in this area.",hi strict limit size asset used present tutorial around presently date tutorial might come together actively area,issue,positive,negative,neutral,neutral,negative,negative
1946312695,"Hi @yihong1120, I wholeheartedly agree with you on all of these needs, and we will seek to support them as quickly as possible. Should you be interested in collaborations in this area, please don't hesitate to reach out to me (@trask on OpenMined's slack: slack.openmined.org)",hi wholeheartedly agree need seek support quickly possible interested area please hesitate reach slack,issue,positive,positive,positive,positive,positive,positive
1945328165,"> But I am afraid that if we fix all in one PR it will make the PR very big
In this case it's fine. The changes are very similar, and I would need to go through the same amount of code to review any way. Having it all in one PR makes it more convenient.

> we also agreed previously that we will fix one folder in one PR, right?
Yup we still do that just with a bigger folder.",afraid fix one make big case fine similar would need go amount code review way one convenient also agreed previously fix one folder one right still bigger folder,issue,negative,negative,neutral,neutral,negative,negative
1945300472,"@HijaziNeveen You might be able to use TenSEAL to do HE encrypted computation.
https://github.com/OpenMined/TenSEAL",might able use computation,issue,negative,positive,positive,positive,positive,positive
1945298883,"@MyStarNight are you still having this issue it was probably related to Windows and UTF8 language. The above commands can help force windows to use UTF8. I would guess this has probably been fixed in Windows and Python in recent versions but we don't use Windows in asian languages to test it.

If its still a problem let me know.",still issue probably related language help force use would guess probably fixed python recent use test still problem let know,issue,negative,positive,neutral,neutral,positive,positive
1945296236,"@jack-chen2022 The UI mentions some roles which have not been implemented yet. We are focused on Data / Model Owner, Data Scientist work flows at the moment.",yet data model owner data scientist work moment,issue,negative,neutral,neutral,neutral,neutral,neutral
1945295171,"@FaisalAlshami To use Duet you need a version of from around syft 0.3 - 0.5.
There won't really be anything you can do with Duet you can't do in Syft 0.8.3 so I would suggest migrating to that.

https://github.com/OpenMined/PySyft/tree/dev/notebooks/api/0.8",use duet need version around wo really anything duet ca would suggest,issue,negative,positive,positive,positive,positive,positive
1945281751,"Yes sure @kiendang I think opening less PRs will save resources and mental efforts. But I am afraid that if we fix all in one PR it will make the PR very big, and we also agreed previously that we will fix one folder in one PR, right?
I am thinking about fixing multiple folders in `/service/` in one PR, but once it gets too large I will open another one. What do you think?",yes sure think opening le save mental afraid fix one make big also agreed previously fix one folder one right thinking fixing multiple one large open another one think,issue,positive,positive,neutral,neutral,positive,positive
1945271547,"Yay! Finally Mac Support , Great work @tcp  ",finally mac support great work,issue,positive,positive,positive,positive,positive,positive
1945268504,"Sorry for the delay , will review the PR by today evening",sorry delay review today evening,issue,negative,negative,negative,negative,negative,negative
1944019078,"> Should we ensure the stash update was successful/check for errors before returning Syft Success/Error?

Yup! Good catch! Fixed it in the last commit! :)",ensure stash update good catch fixed last commit,issue,positive,positive,positive,positive,positive,positive
1943466953,@khoaguin I think can fix the rest of `syft/service` in this PR? To shorten the regex file matcher line also.,think fix rest shorten file matcher line also,issue,negative,neutral,neutral,neutral,neutral,neutral
1943255414,"You can do federated learning by using the 00-04 tutorials here (https://github.com/OpenMined/PySyft/tree/dev/notebooks/api/0.8), but we haven't made an end-to-end example tutorial. We're currently interviewing candidates who would do so if/when they are hired.

Thank you for your patience in this area. For the last two years we've prioritized figuring out how to really nail access to data at one institution (in particular overcoming legal, security, privacy, ethics, PR, trust & safety and other issues which tend to block deployment of PETs). A solution to working with data at one institution does generalize to federated learning without too much fuss, but we haven't focused on that generalization in a while. However, I think we're getting to the point where access to data at one institution is getting easy enough that we could start thinking about FL. Join the slack (slack.openmined.org) to get a notification when we do (i.e. new tutorials).",learning made example tutorial currently would hired thank patience area last two really nail access data one institution particular legal security privacy ethic trust safety tend block deployment solution working data one institution generalize learning without much fuss generalization however think getting point access data one institution getting easy enough could start thinking join slack get notification new,issue,positive,positive,positive,positive,positive,positive
1943149051,"@avdvg you have to wait until the request is approved before you can run `.get`. Try going through these examples from start to finish:
https://github.com/OpenMined/PySyft/tree/dev/notebooks/api/0.8",wait request run try going start finish,issue,negative,neutral,neutral,neutral,neutral,neutral
1943148193,The DataSubject interface changed before the final release of 0.7. Thanks for the above solutions. I will close this for now.,interface final release thanks close,issue,negative,positive,neutral,neutral,positive,positive
1943147078,"@lokeaichirou that usually happens when theres a conflict with which jupyter gets launched, can you try to deactivate and reactivate your virtualenv?",usually there conflict try deactivate reactivate,issue,negative,negative,negative,negative,negative,negative
1943144973,We will be creating new tutorials to replace these but for now the Lessons which are tested in CI lessons 3 onwards do work.,new replace tested onwards work,issue,negative,positive,positive,positive,positive,positive
1943144204,@kennethbruskiewicz thank you. Yes @qxzhou1010 the kwarg name was changed at one point.,thank yes name one point,issue,positive,neutral,neutral,neutral,neutral,neutral
1943143514,"@nwadheralblihed this will be to do with upstream dependencies not us, we don't control what versions of other libraries are available for upstream dependencies.

If you force install an older torch then it should work or you could fork the `0.2.x` code and change the torch version there yourself. 

Unfortunately `0.2.x` is no longer supported by us.",upstream u control available upstream force install older torch work could fork code change torch version unfortunately longer u,issue,negative,positive,neutral,neutral,positive,positive
1943140978,This is usually due to a hidden error which you will see if you use `--verbose`. I will close this for now.,usually due hidden error see use verbose close,issue,negative,negative,negative,negative,negative,negative
1943140546,"I will close for now as there has been no response, this was fixed by updating the dependencies, please install the latest syft and that should correct the issue.",close response fixed please install latest correct issue,issue,negative,positive,positive,positive,positive,positive
1943138761,@liu-a111 thats a very old version of syft can you try the latest `0.8.3` or `0.8.4` which will be released in a few days (you can try beta's already).,thats old version try latest day try beta already,issue,negative,positive,positive,positive,positive,positive
1943137947,@X-Omil sorry can you be a little more explicit in what you are asking? It sounds like a Federated Learning use case?,sorry little explicit like learning use case,issue,negative,negative,negative,negative,negative,negative
1943136247,"@omerfaruktuna the code you have is for `0.2.x` so it won't work in other versions.
Adding FL primitives back is on our roadmap.",code wo work back,issue,negative,neutral,neutral,neutral,neutral,neutral
1943131498,"@xwang317 are you able to update hagrid with `pip install -U hagrid` and try again, then run `!hagrid debug` in a cell and copy out the output?",able update pip install try run cell copy output,issue,negative,positive,positive,positive,positive,positive
1943130261,@simba-axin you probably need to run the main python backend server with `pdb` inline. @yashgorana is actually adding this to our Kubernetes Dev environment this month. Ill make sure we add documentation on the main README.md.,probably need run main python server actually dev environment month ill make sure add documentation main,issue,negative,positive,neutral,neutral,positive,positive
1943129153,"@whsybzz sorry this was the fault of Google not compiling jaxlib for all OSes, we provided some links to alternative versions, good news is its not a problem any more.

We are now using `jaxlib==0.4.20` and google ships binaries for all OSes and CPU architectures to pypi.",sorry fault provided link alternative good news problem,issue,negative,positive,neutral,neutral,positive,positive
1943128185,"I think there seems to be some issue with `conda` and `pycapnp`, I will get the team to investigate this.",think issue get team investigate,issue,negative,neutral,neutral,neutral,neutral,neutral
1943127347,"@LoganZeien 
1. Is there a list of implemented PyTorch/TensorFlow functions that are compatible with the encrypting tensors?
We have a few different Tensor implementations in earlier versions and will be bringing this back in the near future. For now you can do what ever you like server side in a custom container / custom function.

2. Does the DP implemented in PySyft have a security proof?
We are in the process of doing a security audit.

3. Followup to 1, where is all the implemented functions/code?
If you want to see some older DP tensor stuff you can see this:
https://github.com/OpenMined/PySyft/tree/0.7.0/packages/syft/src/syft/core/tensor/autodp",list compatible different tensor back near future ever like server side custom container custom function security proof process security audit want see older tensor stuff see,issue,positive,positive,neutral,neutral,positive,positive
1943125603,"@jokikim we do have something that might satisfy your desire for dashboards on the roadmap.

As for doing things like Scikit learn that should be possible in the new `0.8.4` custom container workload APIs. The release will be in the next few days but the latest beta should be just as stable.

https://github.com/OpenMined/PySyft/blob/dev/notebooks/api/0.8/10-container-images.ipynb",something might satisfy desire like learn possible new custom container release next day latest beta stable,issue,positive,positive,positive,positive,positive,positive
1943124493,"You should be able to `pip install pycapnp` as it has a binary release:
https://pypi.org/project/pycapnp/

However if your OS cpu etc are not listed it will try to compile, on mac you need 
`brew install cmake`

We test MacOS (including silicon), Windows and Linux for a variety of python versions in CI.

@jokikim your os, cpu, python version should be covered, can you try installing it manually from pypi or via a wheel?

I have seen this issue occur when someone was using a version of python with a different ABI to those normal ones listed there in PYPI.

<img width=""644"" alt=""Screenshot 2024-02-14 at 3 48 32 pm"" src=""https://github.com/OpenMined/PySyft/assets/2882739/812a37f8-452d-4c61-95c3-01bb051819cc"">",able pip install binary release however o listed try compile mac need brew install test silicon variety python o python version covered try manually via wheel seen issue occur someone version python different normal listed,issue,negative,positive,positive,positive,positive,positive
1943122464,"@lokeaichirou did you provide a full publicly accessible url to the login command for each client. If one of the nodes needs to contact another you need to make sure they can reach those IPs as well, alternatively you can log in with a client and provide a new alternative `route` to one node for another node.",provide full publicly accessible login command client one need contact another need make sure reach well alternatively log client provide new alternative route one node another node,issue,positive,positive,positive,positive,positive,positive
1943120174,"@JieJieNiu sorry, this broke a few times but we just fixed it, can you try installing the latest `hagrid==0.3.108`.
`pip install -U hagrid`

https://pypi.org/project/hagrid/",sorry broke time fixed try latest pip install,issue,negative,positive,neutral,neutral,positive,positive
1943119436,"Hi @cherry-licongyi `VirtualWorker` was in `0.2.x` which is deprecated, however we will be adding GPU / CUDA support to `0.8.x` soon.",hi however support soon,issue,negative,neutral,neutral,neutral,neutral,neutral
1943118951,"@bluetail14 Tenseal was available in Syft 0.5 if you would prefer to use that.

Alternatively in the latest version of syft 0.8.4 you can install what ever python libraries inside a container and use that in your custom user functions.",available would prefer use alternatively latest version install ever python inside container use custom user,issue,negative,positive,positive,positive,positive,positive
1943118219,@Murat-U-Saglam that is correct thanks. Also @bluetail14 we will be adding some much more high quality tutorials soon.,correct thanks also much high quality soon,issue,negative,positive,positive,positive,positive,positive
1943117681,Hi @pxyfxun your message translated in google translate says something about Federated Learning. We will be adding Federated Learning primitives in the future.,hi message translate something learning learning future,issue,negative,neutral,neutral,neutral,neutral,neutral
1943116736,"Dataset upload is normally restricted to admins, however we are likely to add some permission to allow users to add datasets in the future.",normally restricted however likely add permission allow add future,issue,negative,positive,neutral,neutral,positive,positive
1943096525,@AlexAronikov Correct `TorchHook` was part of `0.2` and is no longer valid in Syft.,correct part longer valid,issue,negative,neutral,neutral,neutral,neutral,neutral
1938110834,"Scheduled cleanup working as expected
![image](https://github.com/OpenMined/PySyft/assets/11070218/5aa73215-8e07-4234-9074-4afe03f5ce54)
![image](https://github.com/OpenMined/PySyft/assets/11070218/4f824a20-374d-41fd-9e36-1a87e4e00264)
",cleanup working image image,issue,negative,neutral,neutral,neutral,neutral,neutral
1935559586,Please do not merge this change right now,please merge change right,issue,negative,positive,positive,positive,positive,positive
1931322309,I added a review as a paper trail for if I decide to force merge this to work around CI flapping issues.,added review paper trail decide force merge work around,issue,negative,neutral,neutral,neutral,neutral,neutral
1922843687,Great work @yashgorana @rasswanth-s with registry integration to requests 🎉🎉,great work registry integration,issue,positive,positive,positive,positive,positive,positive
1918301488,"Just so we know what `large_disk` is doing, it looks like its using an extra byte to allocate a larger volume increasing from 30 GB to 8000 GB (8 Terrabytes). I guess this is just an unfortunate side effect of having files > 30GB, but I think for now we can just stick to the larger one and not worry about this for the foreseeable future.

@koenvanderveen can you add a comment that maybe links to the source: https://github.dev/seaweedfs/seaweedfs/blob/d6e0cae6e7bf97534593842ba60fedf8b7f8b229/weed/command/update.go#L138-L139

Note to future self coming back here in 2034 (yes I know, we thought 8 TB files were too big). 😭

<img width=""1032"" alt=""Screenshot 2024-01-31 at 1 03 00 pm"" src=""https://github.com/OpenMined/PySyft/assets/2882739/519e81ab-44b2-4711-a157-9422902dbe32"">
",know like extra allocate volume increasing guess unfortunate side effect think stick one worry foreseeable future add comment maybe link source note future self coming back yes know thought big,issue,negative,negative,neutral,neutral,negative,negative
1918122488,"I just spoke with census and figured id try to fix this, looks like we can do something more general for future changes:
https://github.com/OpenMined/PySyft/pull/8435",spoke census figured id try fix like something general future,issue,negative,positive,neutral,neutral,positive,positive
1914726108,"@rasswanth-s @yashgorana Quick last thing, we need to add `container_workload` to `pytest-modules` in  `pr-tests-stack-k8s.yml` ",quick last thing need add,issue,negative,positive,positive,positive,positive,positive
1908753943,"Devs are expected to run the commands in the following order:

For starting the cluster & registry (once first time or after destroying)
- `tox -e dev.k8s.start` to start a local registry + cluster and patch hosts file

For deploying syft (every time after updating code/helm charts)
- `tox -e dev.k8s.deploy` to deploy syft on the cluster
- `tox -e dev.k8s.hotreload` to deploy syft on the cluster with hot reloading and port forwards

For cleaning up
- `tox -e dev.k8s.cleanup` only removes the syft deployment, images, etc but keep the cluster running
- `tox -e dev.k8s.destroy` deletes the deployment, cluster, but keeps the registry running
- `tox -e dev.k8s.destroyall` deletes deployment, cluster and registry
",run following order starting cluster registry first time tox start local registry cluster patch file every time tox deploy cluster tox deploy cluster hot port forward cleaning tox deployment keep cluster running tox deployment cluster registry running tox deployment cluster registry,issue,negative,positive,neutral,neutral,positive,positive
1907710129,"worker consumer state = detached? 
![image](https://github.com/OpenMined/PySyft/assets/88959106/e09c55ca-cb6c-437c-baac-4e5c17de7f6f)
",worker consumer state detached image,issue,negative,neutral,neutral,neutral,neutral,neutral
1902272936,"It is my understanding that using TorchHook explicitly is no longer necessary in the latest version of PySyst and that step can be skipped. I am still learning myself, so I cannot say for sure.",understanding explicitly longer necessary latest version step still learning say sure,issue,negative,positive,positive,positive,positive,positive
1898098717,Yes we can remove it from the worker pool service. ,yes remove worker pool service,issue,negative,neutral,neutral,neutral,neutral,neutral
1891232210,"Seems like there is a conflict in system packages when installing `htop` in `SYSTEM_PACKAGES` of `tox.ini`'s `backend.test.basecpu`, making the `pr-syft-image-test` failed.",like conflict system making,issue,negative,neutral,neutral,neutral,neutral,neutral
1886224042,"If I understand correctly, this

https://github.com/OpenMined/PySyft/blob/5563cbe6e1e38ddf8f87acba09ab5f36d497dcd2/packages/syft/src/syft/node/node.py#L1475-L1482

only prints the message for the first container that errors, even if there are multiple containers failing to build? Should it aggregate all the containers that fail to build and print out all the error messages instead? I understand that this logic exists prior to the PR.",understand correctly message first container even multiple failing build aggregate fail build print error instead understand logic prior,issue,negative,negative,neutral,neutral,negative,negative
1880679626,"this has been stale for too long, closing it for now. We can re-open it once we have capacity to work on it.  ",stale long capacity work,issue,negative,negative,negative,negative,negative,negative
1878952103,"Hey, was asked to review this. Can you let me know what problem this solves?",hey review let know problem,issue,negative,neutral,neutral,neutral,neutral,neutral
1878185575,Closing this for now. We have most notebooks already in 0.8 and project notebooks we will added later during a refactor.,already project added later,issue,negative,neutral,neutral,neutral,neutral,neutral
1877719921,"Given that this pull request has been open for nearly a year, I suggest closing it and reopening it on a more recent branch if we still intend to include its feature in our codebase. What are your thoughts on this approach, @IshanMi  and @jcardonnet ?",given pull request open nearly year suggest recent branch still intend include feature approach,issue,negative,positive,neutral,neutral,positive,positive
1876287739,"Very cool. I do think we can probably use something like passkeys now that they are generally available on all major browsers, phones, operating systems etc.

I will close this for now and we can revisit it in the future when it comes back up.",cool think probably use something like generally available major operating close revisit future come back,issue,positive,positive,positive,positive,positive,positive
1875076980,"This is great work and we will probably merge this at some point, but currently our focus is elsewhere. I will reopen this one we focus on improving UX again",great work probably merge point currently focus elsewhere reopen one focus improving,issue,positive,positive,positive,positive,positive,positive
1875075000,"closing because we dont have capacity to merge right now, will reopen when relevant again",dont capacity merge right reopen relevant,issue,negative,positive,positive,positive,positive,positive
1875074663,Closing bcs this has been open very long and we will reopen when relevant again,open long reopen relevant,issue,negative,positive,positive,positive,positive,positive
1875010341,"When using `os.environ[""ORCHESTRA_DEPLOYMENT_TYPE""] = ""container_stack""`, we get

![image](https://github.com/OpenMined/PySyft/assets/88959106/d41b87d1-acf8-4f39-bac2-aa3295897119)
![image](https://github.com/OpenMined/PySyft/assets/88959106/2412412c-d6c8-4991-8128-c2cabcc950b3)
![image](https://github.com/OpenMined/PySyft/assets/88959106/8a5460c2-90de-45cf-af8e-bd1cbe6911d7)
![image](https://github.com/OpenMined/PySyft/assets/88959106/a4408a79-4ad9-4891-91fd-4c88f5e4bfac)
![image](https://github.com/OpenMined/PySyft/assets/88959106/4fcf8d07-136c-4a35-8fef-6a069067253b)
",get image image image image image,issue,negative,neutral,neutral,neutral,neutral,neutral
1873877673,"Updated after having default worker pool in dev

![image](https://github.com/OpenMined/PySyft/assets/88959106/42ab5e81-158d-46a6-a8b9-ec160c3afdb2)
",default worker pool dev image,issue,negative,neutral,neutral,neutral,neutral,neutral
1868429471,"Close this. After discussing with @shubham3121 and team, we decide to modify `SyftClient.api.service.worker_image.push` to add a prompt on top, and there would be no difference between `SyftClient.images.push` and `SyftClient.api.service.worker_image.push`. After further investigation I decide the best way is to just modify `SyftWorkerImageService.push` to add the prompt directly rather than adding it inside `SyftClient.images` since if doing the latter we would modify `push` every time someone calls `SyftClient.images`.",close team decide modify add prompt top would difference investigation decide best way modify add prompt directly rather inside since latter would modify push every time someone,issue,positive,positive,positive,positive,positive,positive
1867638323,"Updated single worker pool repr
![image](https://github.com/OpenMined/PySyft/assets/88959106/1fe00b21-70ee-43f9-b9f1-470e7f7344b4)
Indexing with string using image repo and tag
![image](https://github.com/OpenMined/PySyft/assets/88959106/de989a8a-ee21-4613-8e0c-c2cb630edc3c)
",single worker pool image indexing string image tag image,issue,negative,negative,neutral,neutral,negative,negative
1867594254,"> @rasswanth-s @shubham3121 I need some inputs on this: Irina wants to have an empty list returned when the image is not built, but for now the way we build is to get the `image_id` first with
> 
> ```python
> dockerfile_list = domain_client.images
> workerimage = dockerfile_list[0]
> domain_client.api.services.worker_image.build(uid=workerimage.id, tag=docker_tag)
> ```
> 
> So I patched it currently with return a list of images with empty `image_hash` and `image_identifier` ![image](https://private-user-images.githubusercontent.com/88959106/292465324-4ff789b2-c669-4a37-b899-98625ae28169.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDMyNDU4NDYsIm5iZiI6MTcwMzI0NTU0NiwicGF0aCI6Ii84ODk1OTEwNi8yOTI0NjUzMjQtNGZmNzg5YjItYzY2OS00YTM3LWI4OTktOTg2MjVhZTI4MTY5LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFJV05KWUFYNENTVkVINTNBJTJGMjAyMzEyMjIlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjMxMjIyVDExNDU0NlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWE2MmY2ZWQwZmVjZTc2YTQ2ODM0NDFjZGI1ZDlhODJjM2MxYmQ5NmRmMDU0NGQwOTBkOTUyYzM0OWQzZTY3MDQmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.jk_aclJzQ4vKmZhhBFyksx7WRzLLBFkkyZJOv8QiVWA)

Yes that sounds good, in case the image_tag or image_hash is not available we should show them as None.",need empty list returned image built way build get first python currently return list empty image yes good case available show none,issue,negative,positive,positive,positive,positive,positive
1867514832,"@rasswanth-s @shubham3121 I need some inputs on this:  
Irina wants to have an empty list returned when the image is not built, but for now the way we build is to get the `image_id` first with 
```python
dockerfile_list = domain_client.images
workerimage = dockerfile_list[0]
domain_client.api.services.worker_image.build(uid=workerimage.id, tag=docker_tag)
```
So I patched it currently with return a list of images with empty `image_hash` and `image_identifier`
![image](https://github.com/OpenMined/PySyft/assets/88959106/4ff789b2-c669-4a37-b899-98625ae28169)
",need empty list returned image built way build get first python currently return list empty image,issue,negative,positive,neutral,neutral,positive,positive
1867343170,"We have a new convention for syft image tag, repo, name and registry (after reading the [Docker docs](https://docs.docker.com/engine/reference/commandline/tag/#tag-an-image-referenced-by-name-and-tag) and disscuss with Rasswanth and Kien) like below: 
For example if we have the image identifier as `docker.io/openmined/test-nginx:0.7.8` then
```
registry = docker.io
repo = openmined/test-nginx
tag = 0.7.8
repo_with_tag = openmined/test-nginx:0.7.8
full_name = docker.io/openmined/test-nginx
full_name_with_tag = docker.io/openmined/test-nginx:0.7.8
```
This will reflect the following changes in the codebase:
- refactor `SyftWorkerImageTag` into `SyftWorkerImageIdentifier` since tag only refers to the version (e.g. `0.7.8`) and cause confusions
- replace `SyftWorkerImage.full_tag` with `SyftWorkerImageIdentifier.repo_with_tag` everywhere
- add the following properties to `SyftWorkerImageIdentifier`: `repo_with_tag`, `full_name_with_tag`

",new convention image tag name registry reading docker like example image identifier registry tag reflect following since tag version cause replace everywhere add following,issue,negative,positive,neutral,neutral,positive,positive
1864798617,"> Closing for now as gipc has been removed.

okay :-) :sob: haha. Well. Time goes on!",removed sob well time go,issue,negative,neutral,neutral,neutral,neutral,neutral
1864041342,@khoaguin Just resolved conflicts with dev. Will take a look at the `DictTuple` thing.,resolved dev take look thing,issue,negative,neutral,neutral,neutral,neutral,neutral
1863956741,"Merging the PR, as the tests are blocked by the flaky mongo tests which are passing in other runners of different OS.",blocked flaky passing different o,issue,negative,neutral,neutral,neutral,neutral,neutral
1863936071,"Changes after mergingin with `dev`: we have a new column for `Job` in `WorkerPool`'s repr

![image](https://github.com/OpenMined/PySyft/assets/88959106/6f405f5d-6d07-47d0-9b4e-c843018cca22)
",dev new column job image,issue,negative,positive,positive,positive,positive,positive
1862524760,"![image](https://github.com/OpenMined/PySyft/assets/88959106/0436c783-bb01-4886-b182-855b31f8b255)
![image](https://github.com/OpenMined/PySyft/assets/88959106/6af598dd-b6b9-4639-a5b5-91a6ced68692)
![image](https://github.com/OpenMined/PySyft/assets/88959106/3015d13a-c136-46eb-a219-0f25bac494a5)
![image](https://github.com/OpenMined/PySyft/assets/88959106/e278edfb-cc34-4e29-aa22-b3ba26b80391)
",image image image image,issue,negative,neutral,neutral,neutral,neutral,neutral
1858049285,Did a little refactor to use the utility functions added in #8346. Also use `worker_pool_id: UID` instead of `pool_name: str` for the endpoints.,little use utility added also use instead,issue,negative,negative,negative,negative,negative,negative
1853586960,@khoaguin can you resolve merge conflict and merge with dev,resolve merge conflict merge dev,issue,negative,neutral,neutral,neutral,neutral,neutral
1852588488,"After some discussion, we've decided to discard the proposed solution. I'll be submitting a new pull request (PR) soon to address this issue more effectively.",discussion decided discard solution new pull request soon address issue effectively,issue,negative,positive,positive,positive,positive,positive
1849642992,"Before building image
![image](https://github.com/OpenMined/PySyft/assets/88959106/b04c3c7d-c430-4f14-a0a8-9e7032434a37)

SyftWorkerImage repr
![image](https://github.com/OpenMined/PySyft/assets/88959106/3e433c44-ea5a-4e57-b6dd-b328ac6bd0ce)

After building image
![image](https://github.com/OpenMined/PySyft/assets/88959106/24362446-11e1-446b-8369-6e1fd1ced2d1)
",building image image image building image image,issue,negative,neutral,neutral,neutral,neutral,neutral
1840061407,"Old changes in the current dev branch: 
![Screenshot 2023-12-05 at 11 25 22 AM](https://github.com/OpenMined/PySyft/assets/43314053/5d28f20e-240a-48fe-91fa-6c917c2047a7)
",old current dev branch,issue,negative,positive,neutral,neutral,positive,positive
1840000950,"@IonesioJunior , after I stored the kube config using `aks_credential_storage.sh`

I deleted context by

```sh
kubectl config delete-context <context-name>
```

Then when I executed
`retrieve_aks_credential.sh`

As the context was deleted it threw an error like
<img width=""645"" alt=""Screenshot 2023-12-05 at 10 14 32 AM"" src=""https://github.com/OpenMined/PySyft/assets/43314053/455ecd3e-d29f-43db-88d5-aab4a1deb5e0"">

",context sh executed context threw error like,issue,negative,neutral,neutral,neutral,neutral,neutral
1839916670,"Command: **High Side** 🔆 

```sh
helm install syft-domain ./syft --set node.settings.nodeType=""domain"" --set node.settings.nodeName=""canada"" --set node.settings.nodeSideType=""high""
```
![Screenshot 2023-12-05 at 8 28 26 AM](https://github.com/OpenMined/PySyft/assets/43314053/b14e4f4e-2527-43b8-a62c-b6321e41e58a)

",command high side sh helm install set domain set canada set high,issue,negative,positive,positive,positive,positive,positive
1839907269,"Command: **Low Side** 🔅 

```sh
helm install syft-gateway ./syft --set node.settings.nodeType=""gateway"" --set node.settings.nodeName=""un-petlab"" --set node.settings.nodeSideType=""low""
```

![Screenshot 2023-12-05 at 8 16 13 AM](https://github.com/OpenMined/PySyft/assets/43314053/b17dcb7c-e234-4cad-8c9a-4d5eaf732242)
",command low side sh helm install set gateway set set low,issue,negative,neutral,neutral,neutral,neutral,neutral
1838730281,Example: `helm install <node_name> <repo> --set nodeSideType=low/high`,example helm install set,issue,negative,neutral,neutral,neutral,neutral,neutral
1838217752,"@PeterChung241 Include in `helm` values.yaml template. Check `helm.py`, then test with `helm install --arg`",include helm template check test helm install,issue,negative,neutral,neutral,neutral,neutral,neutral
1838027996,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file.

If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",wo notify release get touch new version available rather skip next major minor version let know ignore major version ignore minor version also ignore major minor patch dependency ignore condition desired file change mind resolve,issue,negative,positive,neutral,neutral,positive,positive
1835361103,Closing this PR due to the challenges in updating it after a long period. This will help simplify our PR list and clarify our priorities.,due long period help simplify list clarify,issue,negative,negative,neutral,neutral,negative,negative
1835360208,I'm considering closing this PR due to the challenges in updating it after a long period. This will help simplify our PR list and clarify our priorities. What are your thoughts on this? @tcp @dhreb @madhavajay,considering due long period help simplify list clarify,issue,negative,negative,neutral,neutral,negative,negative
1835356038,I'm closing this PR for now to streamline our open PRs and better prioritize our tasks. We'll retain this branch for future reference.,streamline open better retain branch future reference,issue,negative,positive,positive,positive,positive,positive
1827529886,We decided to solve this in a different way. Closing,decided solve different way,issue,negative,neutral,neutral,neutral,neutral,neutral
1826195854,"Thank you for providing the Windows download address.
Can you provide a Linux version of jaxlib 0.3.14 for download
```
ERROR: Ignored the following yanked versions: 0.1.63, 0.4.0, 0.4.15
ERROR: Could not find a version that satisfies the requirement jaxlib==0.3.14 (from tensorflow-federated) (from versions: 0.4.1, 0.4.2, 0.4.3, 0.4.4, 0.4.6, 0.4.7, 0.4.9, 0.4.10, 0.4.11, 0.4.12, 0.4.13, 0.4.14, 0.4.16, 0.4.17, 0.4.18, 0.4.19, 0.4.20)
ERROR: No matching distribution found for jaxlib==0.3.14
```

when i execute pip install - U jaxlib=0.3.14- f https://storage.googleapis.com/jax-releases/jaxlib_releases.htmlPost error
```
Looking in links: https://storage.googleapis.com/jax-releases/jaxlib_releases.html

Error: Ignored the following yang versions: 0.1.63, 0.4.0, 0.4.15

Error: Could not find a version that satisfies the requirement jaxlib=0.3.14 (from versions: 0.4.1, 0.4.2, 0.4.3, 0.4.4, 0.4.6, 0.4.7, 0.4.9, 0.4.10, 0.4.11, 0.4.12, 0.4.13, 0.4.14, 0.4.16, 0.4.17, 0.4.18, 0.4.19, 0.4.20)

Error: No matching distribution found for jaxlib==0.3.14
```",thank providing address provide version error following error could find version requirement error matching distribution found execute pip install error looking link error following yang error could find version requirement error matching distribution found,issue,negative,neutral,neutral,neutral,neutral,neutral
1825069302,"> Great work @khoaguin and @kiendang !!! 🎉 💯

Thank you so much @shubham3121 and @kiendang for your great help on the PR! ",great work thank much great help,issue,positive,positive,positive,positive,positive,positive
1824180965,Yup adding a concurrent write lock [`sharing=locked`](https://docs.docker.com/engine/reference/builder/#run---mounttypecache) seems to solve it.,concurrent write lock solve,issue,negative,neutral,neutral,neutral,neutral,neutral
1824140040,"https://github.com/OpenMined/PySyft/actions/runs/6968364753/job/18962116916?pr=8273

Sometimes the `apk add` command fails with

```
#13 [backend backend 2/6] RUN --mount=type=cache,target=/var/cache/apk     apk update &&     apk add tzdata bash python-3.11 py3.11-pip &&     ln -snf /usr/share/zoneinfo/Etc/UTC /etc/localtime && echo Etc/UTC > /etc/timezone &&     mkdir -p /var/log/pygrid /root/data/creds /root/data/db /root/.cache /root/.local
#13 0.398 fetch https://packages.wolfi.dev/os/x86_64/APKINDEX.tar.gz
#13 0.722 WARNING: updating https://packages.wolfi.dev/os: No such file or directory
#13 0.742  [https://packages.wolfi.dev/os]
#13 0.742 0 unavailable, 1 stale; 28537 distinct packages available
#13 ERROR: process ""/bin/sh -c apk update &&     apk add tzdata bash python-$PYTHON_VERSION py$PYTHON_VERSION-pip &&     ln -snf /usr/share/zoneinfo/$TZ /etc/localtime && echo $TZ > /etc/timezone &&     mkdir -p /var/log/pygrid $HOME/data/creds $HOME/data/db $HOME/.cache $HOME/.local"" did not complete successfully: exit code: 1
```

but passes when rerun.",sometimes add command run update add bash echo fetch warning file directory unavailable stale distinct available error process update add bash echo complete successfully exit code rerun,issue,negative,positive,positive,positive,positive,positive
1824134052,"Sometimes the `apk add` in the backend build step fails, but passes when rerun. I reopened #8273 temporarily to investigate further.",sometimes add build step rerun temporarily investigate,issue,negative,neutral,neutral,neutral,neutral,neutral
1823767381,"```
(syft311) param@param-Legion-5-15IAH7H:~/projects/oss/PySyft/packages/grid$ kubectl describe secrets seaweedfsecret -n syft4
Name:         seaweedfsecret
Namespace:    syft4
Labels:       app.kubernetes.io/managed-by=Helm
Annotations:  meta.helm.sh/release-name: syft4
              meta.helm.sh/release-namespace: syft4

Type:  Opaque

Data
====
S3_ROOT_PWD_SECRET:   32 bytes
S3_ROOT_USER_SECRET:  32 bytes
```",param describe name type opaque data,issue,negative,neutral,neutral,neutral,neutral,neutral
1822231045,Thanks @kiendang. I am working on the test for the `syft_base_cpu.dockerfile` image. Let me integrate these changes into it,thanks working test image let integrate,issue,negative,positive,positive,positive,positive,positive
1812512763,"from local testing
```
(syft311) $ kubectl get secrets -n syft
NAME                          TYPE                 DATA   AGE
mongosecret                   Opaque               4      94s
syftsecret                    Opaque               2      94s
sh.helm.release.v1.syft3.v1   helm.sh/release.v1   1      94s
$ kubectl describe secret mongosecret -n syft
Name:         mongosecret
Namespace:    syft
Labels:       app.kubernetes.io/managed-by=Helm
Annotations:  meta.helm.sh/release-name: syft3
              meta.helm.sh/release-namespace: syft

Type:  Opaque

Data
====
mongo-password-secret:    32 bytes
mongo-username-secret:    32 bytes
mongoInitdbRootPassword:  32 bytes
mongoInitdbRootUsername:  32 bytes
$ kubectl describe secret syftsecret -n 
syft
Name:         syftsecret
Namespace:    syft
Labels:       app.kubernetes.io/managed-by=Helm
Annotations:  meta.helm.sh/release-name: syft3
              meta.helm.sh/release-namespace: syft

Type:  Opaque

Data
====
defaultRootPassword:  32 bytes
stackApiKey:          32 bytes
```",local testing get name type data age opaque opaque describe secret name type opaque data describe secret name type opaque data,issue,negative,negative,negative,negative,negative,negative
1811731739,"> I think another place where I have seen this break is when we return an ActionDataEmpty as result of the job. In that case it sometimes returns a None as the output of **str**() during repr. I am not sure if this is solved by that. Can we check that?

I  couldn't reproduce this scenario. Maybe we can sync and check if it's still a problem.",think another place seen break return result job case sometimes none output sure check could reproduce scenario maybe sync check still problem,issue,negative,positive,positive,positive,positive,positive
1803828820,"Hey. Yeah, things are a little bit in limbo. Meh. A few thoughts on the situation:

The gevent CVE-2023-41419 that seemingly motivates people to upgrade gevent is all about `gevent.pywsgi` which hopefully very few people use in serious deployments. Does PySyft use gevent.pywsgi?

I am not sure if ""forcing people"" into gevent 23.9.0.post1+greenlet2 is a responsible thing to do, because there are known problems in this combo. Maybe in superficial testing everything seems fine, but reading through https://github.com/gevent/gevent/issues/1985 I really think that cutting edge greenlet 3 is the most responsible way forward for gevent 23.9. Jason has really done important debugging+fixing work there:

> Require greenlet 3.0 on Python 3.11 and Python 3.12; greenlet 3.0 is recommended for all platforms. This fixes a number of obscure crashes on all versions of Python, as well as fixing a fairly common problem on Python 3.11+ that could manifest as either a crash or as a SystemError. See [issue #1985](https://github.com/gevent/gevent/issues/1985).

I am hopeful that very soon we have a fixed greenlet3 macOS binary/wheel release and then we can move forward with a solid combo greenlet3/gevent23.9.x/gipc1.6.0.

",hey yeah little bit limbo situation seemingly people upgrade hopefully people use serious use sure forcing people responsible thing known maybe superficial testing everything fine reading really think cutting edge greenlet responsible way forward really done important work require greenlet python python greenlet number obscure python well fixing fairly common problem python could manifest either crash see issue hopeful soon fixed greenlet release move forward solid,issue,positive,positive,neutral,neutral,positive,positive
1801476627,I think another place where I have seen this break is when we return an ActionDataEmpty as result of the job. In that case it sometimes returns a None as the output of __str__() during repr. I am not sure if this is solved by that. Can we check that?,think another place seen break return result job case sometimes none output sure check,issue,negative,positive,positive,positive,positive,positive
1801064829,"Below worked for me.
It is about torch and torchvison version compatibility

```
1. pip install syft
2. pip install torchvision===0.1.6 torchaudio===0.11.0 -f https://download.pytorch.org/whl/torch_stable.html
```",worked torch version compatibility pip install pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
1799140878,"it seems like the workers are not correctly connecting to the mongo store 
```

  File ""/usr/local/lib/python3.11/asyncio/runners.py"", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""uvloop/loop.pyx"", line 1517, in uvloop.loop.Loop.run_until_complete
  File ""/root/.local/lib/python3.11/site-packages/uvicorn/server.py"", line 68, in serve
    config.load()
  File ""/root/.local/lib/python3.11/site-packages/uvicorn/config.py"", line 473, in load
    self.loaded_app = import_from_string(self.app)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/root/.local/lib/python3.11/site-packages/uvicorn/importer.py"", line 21, in import_from_string
    module = importlib.import_module(module_str)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.11/importlib/__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""<frozen importlib._bootstrap>"", line 1204, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 1176, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 1147, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 690, in _load_unlocked
  File ""<frozen importlib._bootstrap_external>"", line 940, in exec_module
  File ""<frozen importlib._bootstrap>"", line 241, in _call_with_frames_removed
  File ""/app/grid/main.py"", line 13, in <module>
    from grid.api.router import api_router
  File ""/app/grid/api/router.py"", line 12, in <module>
    from grid.api.new.new import router as new_router
  File ""/app/grid/api/new/new.py"", line 5, in <module>
    from grid.core.node import worker
  File ""/app/grid/core/node.py"", line 71, in <module>
    worker = Domain(
             ^^^^^^^
  File ""/app/syft/src/syft/node/node.py"", line 318, in __init__
    self.init_stores(
  File ""/app/syft/src/syft/node/node.py"", line 693, in init_stores
    self.action_store = MongoActionStore(
                        ^^^^^^^^^^^^^^^^^
TypeError: __init__() should return None, not 'Err'
```",like correctly store file line run return task file line file line serve file line load file line module file line return name level package level file frozen line file frozen line file frozen line file frozen line file frozen line file frozen line file line module import file line module import router file line module import worker file line module worker domain file line file line return none,issue,negative,neutral,neutral,neutral,neutral,neutral
1783777123,"Thanks @gautam1858 for the PR. 

Linting issues can be fixed with 

```sh
pre-commit run --all-files
```
For tests those are failing, you could run following to run all tests manually on your machine

```
pytest packages/syft/tests -n auto
```


From github runners I see these tests failing 

```
tests/integration/network/client_test.py::test_client_type[node_metadata0] FAILED
tests/integration/network/client_test.py::test_client_type[node_metadata1] FAILED
tests/integration/network/client_test.py::test_client_name[node_metadata0] FAILED
tests/integration/network/client_test.py::test_client_name[node_metadata1] FAILED
```",thanks fixed sh run failing could run following run manually machine auto see failing,issue,negative,positive,positive,positive,positive,positive
1782148126,@shubham3121 and @jcardonnet excellent work. Yes please remove from the docs too but it can be a different PR.,excellent work yes please remove different,issue,positive,positive,positive,positive,positive,positive
1782147103,"If we do add back self hosted runners we should add the following:
1) a script which checks their uptime and aborts with an error if the runner has been up for longer than about a day or so
2) run the runners in duplicate with github actions for a while until we have confidence they aren't flakey",add back self add following script error runner longer day run duplicate confidence,issue,negative,neutral,neutral,neutral,neutral,neutral
1781078630,"@madhavajay Deleted all references of Headscale, Tailscale and VPN-IPTables. There are some reference in the docs of headscale and tailscale let me know if want to update that now.",reference let know want update,issue,negative,neutral,neutral,neutral,neutral,neutral
1780526071,@kiendang can you run the security tox task locally it was failing on the server in CI.,run security tox task locally failing server,issue,negative,neutral,neutral,neutral,neutral,neutral
1780389068,"Suggestions:
- change {{}} go templates to '{{}}' syntax in .yaml file
- remove /helm chart folder from pre-commit yaml
- add lookup syntax to secrets so that it keeps existing secrets",change go syntax file remove chart folder add syntax,issue,negative,neutral,neutral,neutral,neutral,neutral
1774601809,"This has been merged manually bcs there were so many things that required changing, great work! Closing this one",manually many great work one,issue,positive,positive,positive,positive,positive,positive
1774500048,"@madhavajay Yah keys should not be `int`. If you have a `d: DictTuple` with `int` keys, now `d[2]` is ambiguous since it means both ""getting the 3rd element"" and ""getting the element with key 2"". I'll just put in a check, raising an error on attempting to create a `DictTuple` with `int` key.

You would encounter similar error with the current `TupleDict` too.

```python
p = TupleDict({1: ""z"", 2: ""b""})
p[2]

File ""/Users/kien/pysyft/packages/syft/src/syft/types/tupledict.py"", line 14, in __getitem__
    return list(self.values())[key]
           ~~~~~~~~~~~~~~~~~~~^^^^^
IndexError: list index out of range
```

> the tests definitely help

I have a more comprehensive test suite for this but is currently blocked by #8188 (without #8188 it is very slow). Will push that once it is resolved.",yah ambiguous since getting element getting element key put check raising error create key would encounter similar error current python file line return list key list index range definitely help comprehensive test suite currently blocked without slow push resolved,issue,negative,negative,neutral,neutral,negative,negative
1774476674,"@kiendang great work, I had a play and found a possible bug.

It seems if the keys are ints and non 0 sequential it freaks out on casting to a dict.
<img width=""668"" alt=""Screenshot 2023-10-23 at 3 46 33 pm"" src=""https://github.com/OpenMined/PySyft/assets/2882739/3db2b19a-fce5-4220-8469-c9fbbf6f3a6c"">
",great work play found possible bug non sequential casting,issue,positive,positive,positive,positive,positive,positive
1772079419,@kiendang this is really great work! Thank you for your diligence in addressing all the tests as well. 👏 We are still figuring out how to hand off these kinds of API changes but I think it helps to have some code examples for @IrinaMBejan Pylot team.,really great work thank diligence well still hand think code team,issue,positive,positive,positive,positive,positive,positive
1771571626,"**Instruction to Test**

Preparation Steps:
1. Fetch branches:
- git fetch origin obj-version-data-migrate (Data migration code)
- gh pr checkout 8130 ( Branch: `nodemetadatajson_fix` and [PR](https://github.com/OpenMined/PySyft/pull/8130)) (NodeSettings change code)

2. Checkout to `obj-version-data-migrate` branch 
```bash git checkout obj-version-data-migrate```

3. Checkout a new branch from `obj-version-data-migrate`
```git checkout -b obj-version-test-1```

4. Creating a Merged branch. Merge `nodemetadatajson_fix` into `obj-version-test-1`.
```bash git merge nodemetadatajson_fix --strategy-option theirs```


Test:

1. ```bash git checkout obj-version-data-migrate```

2. Run the follow code in a Notebook
```python
import syft as sy
from syft.service.settings.settings_service import SettingsService

# Launch node
node = sy.orchestra.launch(""solaris-empress"", dev_mode=True, reset=True)

# Get the filename for sql store
node.python_node.action_store_config.client_config.filename

# List the metadata
node.python_node.metadata.dict()

# Login into the client
client = node.login(email=""info@openmined.org"", password=""changethis"")

# List the setting data
client.api.services.settings.get()

# List the node metadata
client.api.services.metadata.get_metadata()
```
3. Check out to the merge branch created: `obj-version-test-1`
```git checkout obj-version-test-1```

4. Run the below code again in the notebook. **Note**: here reset flag in orchestra.launch is False since we want to use the existing database.
```python
import syft as sy
from syft.service.settings.settings_service import SettingsService

# Launch node
node = sy.orchestra.launch(""solaris-empress"", dev_mode=True)

# Get the filename for sql store
node.python_node.action_store_config.client_config.filename

# List the metadata
node.python_node.metadata.dict()

# Login into the client
client = node.login(email=""info@openmined.org"", password=""changethis"")

# List the setting data
client.api.services.settings.get()

# List the node metadata
client.api.services.metadata.get_metadata()
```",instruction test preparation fetch git fetch origin data migration code branch change code branch bash git new branch git branch merge bash git merge test bash git run follow code notebook python import import launch node node get store list login client client list setting data list node check merge branch git run code notebook note reset flag false since want use python import import launch node node get store list login client client list setting data list node,issue,negative,negative,negative,negative,negative,negative
1770160861,@madhavajay I put the changelog examples in the description of the PR. 1 short concise example to highlight the change and 1 longer fully runnable one.,put description short concise example highlight change longer fully runnable one,issue,negative,positive,neutral,neutral,positive,positive
1769859406,"@kiendang Can we get a changelog example for the `Product Team`. For example:
```
# old code example
```

```
# new code example
```",get example product team example old code example new code example,issue,negative,positive,positive,positive,positive,positive
1769013421,"> @gautam1858 thanks for the PR, are you able to fix the tests before we review it?

Not able to fix the tests",thanks able fix review able fix,issue,negative,positive,positive,positive,positive,positive
1768219152,"Removed the description, we can handle the defaults in another PR :)",removed description handle another,issue,negative,neutral,neutral,neutral,neutral,neutral
1768196741,The `Text` part is the domain description. Should we erase it regardless or change the default to be empty?,text part domain description erase regardless change default empty,issue,negative,negative,neutral,neutral,negative,negative
1767501570,"@tcp great work.
I tested it and got this:
<img width=""663"" alt=""Screenshot 2023-10-18 at 12 11 45 pm"" src=""https://github.com/OpenMined/PySyft/assets/2882739/12010bb2-c2e7-4871-9378-d2598395b597"">

Maybe we can remove the `Text` part?
",great work tested got maybe remove text part,issue,positive,positive,positive,positive,positive,positive
1767495148,"@gautam1858 thanks for the PR, are you able to fix the tests before we review it?",thanks able fix review,issue,negative,positive,positive,positive,positive,positive
1764600552,"> @yashgorana the test `pr-tests-stack` looks like its saying:
> 
> ```
> 2023-10-13T05:05:59.5226266Z ##[error]No space left on device : '/home/runner/runners/2.309.0/_diag/blocks/f92775bc-6976-478a-9cee-6977f7b58277_8d2d333e-4dbd-5553-5489-587358cf17ab.1'
> ```
> 
> We previously did a work around to free up more space on the github runners. I think that it might be time to hunt down this problem.
> 
> I guess perhaps the images are being built on Docker and then pushed to k3d registry which means they are duplicate and possibly taking up too much space? But still thats a lot space, is there possibly too many copies of our DL libraries in layers being kept or some other large images during our tests which are causing this issue?

yes this is something @rasswanth-s and I will look at",test like saying error space left device previously work around free space think might time hunt problem guess perhaps built docker registry duplicate possibly taking much space still thats lot space possibly many kept large causing issue yes something look,issue,negative,positive,positive,positive,positive,positive
1764444769,"tested this manually

## Step 1. basic http setup

Command `helm install syft ./helm/syft --namespace syft --set node.settings.nodeType=gateway --create-namespace`

Deploys ingress with name `grid-stack-ingress`
<img width=""637"" alt=""image"" src=""https://github.com/OpenMined/PySyft/assets/11070218/e46c477b-0e95-4c47-ada5-65aa656558bf"">

YAML
<img width=""637"" alt=""image"" src=""https://github.com/OpenMined/PySyft/assets/11070218/ed02db47-9383-44bc-a89e-e637ef2c1d6e"">

## Step 2. Upgrade to use TLS with domain
Command: `helm upgrade syft ./helm/syft --set node.settings.nodeType=gateway --set node.settings.tls=true --set node.settings.hostname=localhost.openmined.org --namespace syft`

Ingress swapped to `grid-stack-ingress-tls`
<img width=""637"" alt=""image"" src=""https://github.com/OpenMined/PySyft/assets/11070218/97f9697a-c6dd-410b-ab60-90134bbca830"">

YAML
<img width=""637"" alt=""image"" src=""https://github.com/OpenMined/PySyft/assets/11070218/ecc413ba-9e65-4234-937b-806f11ea1ea6"">

Should be pretty straight forward now =)",tested manually step basic setup command helm install set ingres name image image step upgrade use domain command helm upgrade set set set ingres image image pretty straight forward,issue,positive,positive,positive,positive,positive,positive
1764195248,"Test:

1. Launch a docker node with `hagrid launch to docker:8081 --dev --tail`
2. Login to the node and upload a dataset
```python
import syft as sy
import pandas as pd
from syft import autocache
domain_client = sy.login(url='http://localhost:8081', email=""info@openmined.org"", password=""changethis"")

country = sy.DataSubject(name=""Country"", aliases=[""country_code""])

canada = sy.DataSubject(name=""Canada"", aliases=[""country_code:ca""])
germany = sy.DataSubject(name=""Germany"", aliases=[""country_code:de""])
country.add_member(canada)
country.add_member(germany)
response = domain_client.data_subject_registry.add_data_subject(country)
data_subjects = domain_client.data_subject_registry.get_all()

canada_dataset_url = ""https://github.com/OpenMined/datasets/blob/main/trade_flow/ca%20-%20feb%202021.csv?raw=True""
df = pd.read_csv(autocache(canada_dataset_url))
# private data samples
ca_data = df[0:10]
ca_data
# Mock data samples
mock_ca_data = df[10:20]
mock_ca_data

dataset = sy.Dataset(name=""Canada Trade Value"")
dataset.set_description(""Canada Trade Data"")
dataset.add_citation(""Person, place or thing"")
dataset.add_url(""https://github.com/OpenMined/datasets/tree/main/trade_flow"")

dataset.add_contributor(name=""Andrew Trask"", 
                        email=""andrew@openmined.org"",
                        note=""Andrew runs this domain and prepared the dataset metadata."")

dataset.add_contributor(name=""Madhava Jay"", 
                        email=""madhava@openmined.org"",
                        note=""Madhava tweaked the description to add the URL because Andrew forgot."")

ctf = sy.Asset(name=""canada_trade_flow"")
ctf.set_description(""Canada trade flow represents export & import of different commodities to other countries"")
ctf.add_contributor(name=""Andrew Trask"", 
                    email=""andrew@openmined.org"",
                    note=""Andrew runs this domain and prepared the asset."")
ctf.set_obj(ca_data)
ctf.set_shape(ca_data.shape)
ctf.add_data_subject(canada)
ctf.no_mock()
dataset.add_asset(ctf)
ctf.set_mock(mock_ca_data, mock_is_real=False)

domain_client.upload_dataset(dataset)
```
3. Connect to the Mongo server and observe that we have `Action_data` and `Action_permissions` collections
![image](https://github.com/OpenMined/PySyft/assets/88959106/ef2a4235-40d7-439e-895d-66be8edf95d3)

![image](https://github.com/OpenMined/PySyft/assets/88959106/6019e734-5a7a-4645-bb73-c3591e14fa72)
",test launch docker node launch docker dev tail login node python import import import country country canada canada ca de canada response country private data mock data canada trade value canada trade data person place thing domain prepared jay description add forgot canada trade flow export import different domain prepared asset canada connect server observe image image,issue,positive,neutral,neutral,neutral,neutral,neutral
1763689474,@kiendang interesting. Lets discuss in the Eng channel in slack.,interesting discus channel slack,issue,negative,positive,positive,positive,positive,positive
1763683817,"@yashgorana the test `pr-tests-stack` looks like its saying:
```
2023-10-13T05:05:59.5226266Z ##[error]No space left on device : '/home/runner/runners/2.309.0/_diag/blocks/f92775bc-6976-478a-9cee-6977f7b58277_8d2d333e-4dbd-5553-5489-587358cf17ab.1'
```

We previously did a work around to free up more space on the github runners. I think that it might be time to hunt down this problem.

I guess perhaps the images are being built on Docker and then pushed to k3d registry which means they are duplicate and possibly taking up too much space? But still thats a lot space, is there possibly too many copies of our DL libraries in layers being kept or some other large images during our tests which are causing this issue?

",test like saying error space left device previously work around free space think might time hunt problem guess perhaps built docker registry duplicate possibly taking much space still thats lot space possibly many kept large causing issue,issue,negative,positive,positive,positive,positive,positive
1763384101,"Pre-Merge check on staging server, where a gateway could connect to localhost domain, which is not reachable as a proxy client.
![Screenshot 2023-10-15 at 6 35 13 PM](https://github.com/OpenMined/PySyft/assets/43314053/b2895390-dc42-4177-9ae1-6b54b67207a5)

After the PR -merge, the staging server would be updated, by which , we could check this same test, where we should receive an error during connection itself, where the gateway rejects connection if it is not rechable
",check staging server gateway could connect domain reachable proxy client staging server would could check test receive error connection gateway connection,issue,negative,neutral,neutral,neutral,neutral,neutral
1760609198,"Hello @MyStarNight ,
I did manage to install PySyft successfully, although it's been a while, so I might not remember all the details. However, I stopped using it later on due to a lack of sufficient documentation to replicate existing tutorials.
If you're looking to install PySyft, I can suggest the following steps:

1. Install PySyft using the following command: `pip install syft -U -f https://whls.blob.core.windows.net/unstable/index.html`
2. Make sure you have the latest PyTorch installed. If you haven't already installed it, you can do so by running: `pip install torch`

I hope this helps you get started with PySyft. Good luck!",hello manage install successfully although might remember however stopped later due lack sufficient documentation replicate looking install suggest following install following command pip install make sure latest already running pip install torch hope get good luck,issue,positive,positive,positive,positive,positive,positive
1759110849,@shubham3121 Really Excellent work! Definitely PR of the week. ❤️,really excellent work definitely week,issue,positive,positive,positive,positive,positive,positive
1759022321,I met the same problem with you.Can you tell me whether you have solutions and what it si . Thank you.,met problem tell whether si thank,issue,negative,neutral,neutral,neutral,neutral,neutral
1757915663,"> syft==0.6.0 is compatible in colab? I installed this version. Import is ok, but when I try to create virtual worker using hook=sy.TorchHook(torch) then it shows TorchHook module error

Same happens with me.. anybody having solution to this ..will be great help for me ..",compatible version import try create virtual worker torch module error anybody solution great help,issue,positive,positive,positive,positive,positive,positive
1754453155,"Currently the stable beta is beta.35, the below screenshot deploys beta.34
![Screenshot 2023-10-10 at 11 35 13 AM](https://github.com/OpenMined/PySyft/assets/43314053/0123ad02-0de9-4f4f-ae5f-ae26775ebfd9)

Syft Version

![Screenshot 2023-10-10 at 11 36 19 AM](https://github.com/OpenMined/PySyft/assets/43314053/e00dc738-24b6-4070-b02d-ff2aa1e717ef)
",currently stable beta beta version,issue,negative,neutral,neutral,neutral,neutral,neutral
1754212318,@rasswanth-s works well for the beta tags I tried but it fails to deploy if a user chooses `latest`.,work well beta tried deploy user latest,issue,negative,positive,positive,positive,positive,positive
1750005649,"there is one package: pycapnp. 

use conda install manually and you will avoid this error. 

conda install -c conda-forge pycapnp",one package use install manually avoid error install,issue,negative,neutral,neutral,neutral,neutral,neutral
1747090135,"## Workflow tests:
### Normal manual run
https://github.com/OpenMined/PySyft/actions/runs/6407517403

<img width=""863"" alt=""image"" src=""https://github.com/OpenMined/PySyft/assets/11070218/8c2f764d-e217-4d3d-bf38-1055dea19098"">

### Scheduled run on cache miss
https://github.com/OpenMined/PySyft/actions/runs/6407817417

<img width=""1250"" alt=""image"" src=""https://github.com/OpenMined/PySyft/assets/11070218/548e1cc4-86e7-494d-be8c-76620f0819e4"">

<img width=""977"" alt=""image"" src=""https://github.com/OpenMined/PySyft/assets/11070218/a73b125c-73fa-41c2-b8dd-1e40a54de98a"">

### Scheduled run on cache hit
https://github.com/OpenMined/PySyft/actions/runs/6407860608

<img width=""941"" alt=""image"" src=""https://github.com/OpenMined/PySyft/assets/11070218/7b0b3fcd-7886-4e77-86fd-e51b54b494ae"">
<img width=""1066"" alt=""image"" src=""https://github.com/OpenMined/PySyft/assets/11070218/392f8d74-e060-442b-8f5b-0ecb15bb2196"">
<img width=""1092"" alt=""image"" src=""https://github.com/OpenMined/PySyft/assets/11070218/1c35538b-6162-4bec-9ec3-7b01c1dbf016"">
",normal manual run image run cache miss image image run cache hit image image image,issue,negative,positive,positive,positive,positive,positive
1746226652,"I think , we could merge this PR to keep the dev velocity, and add tests for vagrant in subsequent PR's due to our current upcoming milestones.

I have verified the initial vagrant setup in my ARM machine manually.",think could merge keep dev velocity add vagrant subsequent due current upcoming initial vagrant setup arm machine manually,issue,negative,negative,neutral,neutral,negative,negative
1746088984,Great work and thanks for the details on the tag code.,great work thanks tag code,issue,positive,positive,positive,positive,positive,positive
1742923352,"I will review this but, excellent work @yashgorana this is my favourite PR of the week! 🙌",review excellent work week,issue,positive,positive,positive,positive,positive,positive
1742878104,Thanks a lot for the kind words @shubham3121. We probably need a test or two for this?,thanks lot kind probably need test two,issue,positive,positive,positive,positive,positive,positive
1742772050,This old PR contains the github action example to run VirtualBox on GitHub MacOS Runners. https://github.com/OpenMined/PySyft/pull/7579,old action example run,issue,negative,positive,neutral,neutral,positive,positive
1742155002,"import syft as sy
sy.load_lib(""tenseal"")
duet = sy.launch_duet(loopback=True)
duet = sy.launch_duet()

Hi there. When I run this script I got an error;
AttributeError: module 'syft' has no attribute 'load_lib'

Which updated library requirements or do I need to work with it?

",import duet duet hi run script got error module attribute library need work,issue,negative,neutral,neutral,neutral,neutral,neutral
1739746065,"@madhavajay @rasswanth-s tested the kubernetes deployments. I had to tweak `tox.ini` & `helm.py` because the final helm yaml files were missing `apiVersion` key in some cases. Aditionally, the file names follow helm's convention & i've updated the component-chart to `0.9.1`.

Emply cluster on `dev`
<img width=""838"" alt=""empty-cluster"" src=""https://github.com/OpenMined/PySyft/assets/11070218/32ffe86a-4f44-4c6d-8bd5-bab67c51c174"">

Helm install on `dev`
<img width=""838"" alt=""deploy-tot"" src=""https://github.com/OpenMined/PySyft/assets/11070218/f561ed11-b041-4d98-9df1-37706722000f"">

Helm update on this branch (with seaweed-fs)
<img width=""838"" alt=""deploy-seaweed"" src=""https://github.com/OpenMined/PySyft/assets/11070218/391debda-3c4e-4075-bb3f-cad87f948278"">
",tested tweak final helm missing key file follow helm convention cluster dev helm install dev helm update branch,issue,negative,negative,neutral,neutral,negative,negative
1738426620,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`.

If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",wo notify release get touch new version available rather skip next major minor version let know ignore major version ignore minor version change mind resolve,issue,negative,positive,neutral,neutral,positive,positive
1730899095,"Yes, I'll get on it immediately today. Sorry about the delay I was out of
town.

On Fri, Sep 22, 2023, 7:49 AM Madhava Jay ***@***.***> wrote:

> @yash1993 <https://github.com/yash1993> can you add a test like @Param-29
> <https://github.com/Param-29> suggested so we don't regress on your fix?
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/pull/8074#issuecomment-1730836738>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ACEBIKVRX4USD7NJ2F65OELX3URFLANCNFSM6AAAAAA4OBZTTY>
> .
> You are receiving this because you were mentioned.Message ID:
> ***@***.***>
>
",yes get immediately today sorry delay town jay wrote add test like regress fix reply directly view id,issue,negative,negative,negative,negative,negative,negative
1730877068,"Yes I think we can merge this documentation.
FYR: Only provisioning and setup of machines to AWS via hagrid has been tested. The E2E setup still needs to be tested. ",yes think merge documentation setup via tested setup still need tested,issue,negative,neutral,neutral,neutral,neutral,neutral
1730836738,@yash1993 can you add a test like @Param-29 suggested so we don't regress on your fix?,add test like regress fix,issue,negative,neutral,neutral,neutral,neutral,neutral
1730835765,@teo-milea best branch name ever 😭,best branch name ever,issue,positive,positive,positive,positive,positive,positive
1730834076,I have closed the main bridge prototype PR for now and we will come back to these PRs and cherry pick when we implement this stuff later.,closed main bridge prototype come back cherry pick implement stuff later,issue,negative,positive,neutral,neutral,positive,positive
1730833554,I am closing this prototype branch until we revisit this functionality.,prototype branch revisit functionality,issue,negative,neutral,neutral,neutral,neutral,neutral
1730831676,"@tcp and @IonesioJunior lets discuss how much time we think there is to finish this off, id rather it in the code base than rotting on the PR vine.",discus much time think finish id rather code base rotting vine,issue,negative,negative,negative,negative,negative,negative
1730824262,@rasswanth-s and @yashgorana can we discuss this again in slack and get it merged if its working and tested?,discus slack get working tested,issue,negative,neutral,neutral,neutral,neutral,neutral
1730818180,"@vdasu great work on this PR, if you want to discuss the implementation in more detail reach out to our DP lead @IshanMi, ill close this for now.",great work want discus implementation detail reach lead ill close,issue,negative,positive,positive,positive,positive,positive
1730816285,@tcp is this working? Does it only fail due to linting? Should we fix and merge?,working fail due fix merge,issue,negative,negative,negative,negative,negative,negative
1730815534,@koenvanderveen what do you think? Should we close this for now and revisit it if we need to pull any HF parts out?,think close revisit need pull,issue,negative,neutral,neutral,neutral,neutral,neutral
1730813305,@tcp if this is a quick win to merge should we get it updated with `dev` and rename the endpoint to `/healthcheck`?,quick win merge get dev rename,issue,positive,positive,positive,positive,positive,positive
1730808123,@shubham3121 is this now covered by our new SeaweedFS implementation which allows credentials being set directly?,covered new implementation set directly,issue,negative,positive,positive,positive,positive,positive
1726829931,"[solved]

jax-lib in windows auto install ml_dtypes 0.3.0 which removed type float_e4m3b11

replace ml_dtypes  to 0.2.0 solved error",auto install removed type replace error,issue,negative,neutral,neutral,neutral,neutral,neutral
1725457829,"Currently, I am aware the dev branch is failing due to flaky tests, but this current PR is separate from the failing flaky tests, I have verified this PR working manually, hence merging the same.",currently aware dev branch failing due flaky current separate failing flaky working manually hence,issue,negative,positive,neutral,neutral,positive,positive
1725142582,"```
[vagrant@almalinux-9 ~]$ ls
rules.v4.new  rules.v4.old
[vagrant@almalinux-9 ~]$ cat rules.v4.new 
# Generated by iptables-save v1.8.8 (nf_tables) on Tue Sep 19 09:20:21 2023
*filter
:INPUT DROP [0:0]
:FORWARD DROP [0:0]
:OUTPUT ACCEPT [0:0]
-A INPUT -p tcp -m tcp --dport 22 -j ACCEPT
COMMIT
# Completed on Tue Sep 19 09:20:21 2023
[vagrant@almalinux-9 ~]$ curl www.google.com
curl: (6) Could not resolve host: www.google.com
[vagrant@almalinux-9 ~]$ curl https://github.com/OpenMined/PySyft
curl: (6) Could not resolve host: github.com
[vagrant@almalinux-9 ~]$ 

```",vagrant vagrant cat tue filter input drop forward drop output accept input accept commit tue vagrant curl curl could resolve host vagrant curl curl could resolve host vagrant,issue,positive,neutral,neutral,neutral,neutral,neutral
1722221501,"```sh
    # [vagrant@almalinux-9 ~]$ sudo iptables-save
    # Generated by iptables-save v1.8.8 (nf_tables) on Sat Sep 16 12:33:51 2023
    # *filter
    # :INPUT DROP [4:304]
    # :FORWARD DROP [0:0]
    # :OUTPUT ACCEPT [81:9418]
    # -A INPUT -p tcp -m tcp --dport 22 -j ACCEPT
    # COMMIT
    # # Completed on Sat Sep 16 12:33:51 2023
    
```

Settings output above",sh vagrant sat filter input drop forward drop output accept input accept commit sat output,issue,negative,neutral,neutral,neutral,neutral,neutral
1719223494,"TODO: if we delete an object from a partition, delete its corresponding entry in the permissions collection (in the `_delete` method in `kv_document_store` and `mongo_document_store`)",delete object partition delete corresponding entry collection method,issue,negative,neutral,neutral,neutral,neutral,neutral
1709501904,"@madhavajay @kiendang closing this PR for now as Purple team is rebuilding the Kubernetes pipeline.
@rasswanth-s for your reference, PR maybe helpful in your Kubernetes integration.",purple team pipeline reference maybe helpful integration,issue,negative,neutral,neutral,neutral,neutral,neutral
1709499495,"@madhavajay @khoaguin closing this PR for now, as it requires some more work to fix concurrency issues with the File based Graph Store. Moving the related to backlog for now.",work fix concurrency file based graph store moving related backlog,issue,negative,neutral,neutral,neutral,neutral,neutral
1709332001,"Great work; running below before pushing new commit should help with Linting issues;
```
pre-commit run --all-files
```

Also it would be nice to add tests in 

```
packages/syft/tests/syft/service/dataset/dataset_service_test.py
```",great work running pushing new commit help run also would nice add,issue,positive,positive,positive,positive,positive,positive
1707533359,"@madhavajay  jaxlib started building for me for 0.4.14 due to a recent commit of tensorflow two hours ago.
The build is about to finish shortly.",building due recent commit two ago build finish shortly,issue,negative,negative,neutral,neutral,negative,negative
1704900752,Recheck after this commit [a9d6290](https://github.com/OpenMined/PySyft/pull/8017/commits/a9d6290995a8273100a9267cfcb5725b7ab66749) and previous issues within [this comment](https://github.com/OpenMined/PySyft/pull/8017#issuecomment-1704720674) are fixed,recheck commit ad previous within comment fixed,issue,negative,negative,neutral,neutral,negative,negative
1704720674,"After the commit [a914c87](https://github.com/OpenMined/PySyft/pull/8017/commits/a914c87fe7ba2ddf0eb43463fc95baf4b20144df), we had a bug like in the picture below where we got error if we add things with `ignore_duplicates = True` in `_set()` of `MongoStorePartition`, for example when using `data_subject_registry.add_data_subject`

![image](https://github.com/OpenMined/PySyft/assets/88959106/a0f47488-b70a-4721-8596-9b4ed5d1d019)

I reverted back to the commit [6b5cc8e](https://github.com/OpenMined/PySyft/pull/8017/commits/6b5cc8e70c46e6564e53b2d988a774b2030b7f21) where we did not get this issue like below,
![image](https://github.com/OpenMined/PySyft/assets/88959106/96655cad-aa66-445a-ac88-84dc0ded6159),
however, we still got an issue: Although we only had 3 data subjects
![image](https://github.com/OpenMined/PySyft/assets/88959106/d4ab3ca7-68f2-4ddc-895a-c7588eec684b)
but in the `DataSubject_permissions` collection we have 4 entries like below
![image](https://github.com/OpenMined/PySyft/assets/88959106/b8b48626-7919-4b70-a876-b60fdd078e50)

Furthermore, if I tried to re-upload the same dataset to create duplicates, we will get an error when uploading the dataset
![image](https://github.com/OpenMined/PySyft/assets/88959106/6740ef39-d459-4327-964f-fbbf2a1de170)
and will still only have 1 dataset. However, we added 1 more permission to the `Dataset_permissions` collection
![image](https://github.com/OpenMined/PySyft/assets/88959106/da0f94a6-083a-4138-b583-63edb81b6df5)



",commit bug like picture got error add true example image back commit get issue like image however still got issue although data image collection like image furthermore tried create get error image still however added permission collection image,issue,positive,positive,positive,positive,positive,positive
1702536150,"> @kiendang notebook 6 is working fine. Can you take the latest pull ?

Yup it works now after clearing the db from previous runs.",notebook working fine take latest pull work clearing previous,issue,negative,positive,positive,positive,positive,positive
1702530053,"@koenvanderveen @khoaguin We're running testing the notebooks against mongo in the CI. Check pr-tests-notebook-stack which runs `tox -e stack.test.notebook` with `ORCHESTRA_DEPLOYMENT_TYPE: ""container_stack""`, which launches docker containers with Mongo. Task runner: `om-ci-16vcpu-ubuntu2204`",running testing check tox docker task runner,issue,negative,neutral,neutral,neutral,neutral,neutral
1702507497,@kiendang notebook 6 is working fine. Can you take the latest pull ?,notebook working fine take latest pull,issue,negative,positive,positive,positive,positive,positive
1702411692,"I have changed the example policy from notebook 5 as this feature is not really used and we could offer support to anyone trying it out. Given the changes from the last few months, we need to refactor and rethink the UX for custom policies, but it does not feel like a priority right now.",example policy notebook feature really used could offer support anyone trying given last need rethink custom feel like priority right,issue,positive,positive,positive,positive,positive,positive
1702348475,"Hmm I thought `outputs[output_arg]` raised the previous error which got fixed with `accept_by_depositing_result`?
The error from `domain_client.code.func(x=x_pointer)` looks like a separate issue.

```python
res_ptr = domain_client.code.func(x=x_pointer)
res_ptr

SyftError: Failed to run. 'NoneType' object has no attribute 'services'
```",thought raised previous error got fixed error like separate issue python run object attribute,issue,negative,negative,neutral,neutral,negative,negative
1702344120,"yes, getting the same error, that's weird the tests passed. The problem seems to be in `apply_output` in `RepeatedCallPolicy`: outputs[output_arg] is throwing the error.",yes getting error weird problem throwing error,issue,negative,negative,negative,negative,negative,negative
1702332895,"I got the same issue as @kiendang locally with the same fix, how did the tests pass?
",got issue locally fix pas,issue,negative,neutral,neutral,neutral,neutral,neutral
1702324139,"@shubham3121 I did the same `accept_by_depositing_result` fix but got another error in notebook 05 after that

```python
res_ptr = domain_client.code.func(x=x_pointer)
res = res_ptr.get()
res

AttributeError                            Traceback (most recent call last)
Cell In[21], line 2
      1 res_ptr = domain_client.code.func(x=x_pointer)
----> 2 res = res_ptr.get()
      3 res

AttributeError: 'SyftError' object has no attribute 'get'
```

Do you encounter the same thing locally?",fix got another error notebook python recent call last cell line object attribute encounter thing locally,issue,negative,neutral,neutral,neutral,neutral,neutral
1702098730,"Hi @shubham3121  @koenvanderveen, here is the notebook containing some code to test the feature
[mongodb-permission-model.zip](https://github.com/OpenMined/PySyft/files/12496379/mongodb-permission-model.zip)


",hi notebook code test feature,issue,negative,neutral,neutral,neutral,neutral,neutral
1701306816,"I tested the permissions on the [seaweed integration](https://github.com/OpenMined/PySyft/pull/7987) branch, and the problem was fixed, code for reference: 
```
import syft as sy
node = sy.orchestra.launch(""test-domain"", reset=True)

root_client = node.login(email=""info@openmined.org"",password=""changethis"")
data = sy.ActionObject.from_obj([1, 2,3])
data_ptr = data.send(root_client)
data_ptr
guest_client = node.client.guest()
guest_client
res = guest_client.api.services.action.get_pointer(data_ptr.id)
res.syft_action_data # guest does not have access to the data
res.get()
res = root_client.api.services.action.get_pointer(data_ptr.id)
res.syft_action_data # root has access to the data
```",tested seaweed integration branch problem fixed code reference import node data guest access data root access data,issue,negative,positive,neutral,neutral,positive,positive
1701295326,"Yes sure @koenvanderveen. Please start the ticket and assign it to me, I think I can and should start working on it right away since memory is still fresh. By the way, I am done with the notebook to test this feature. Where should I put it?
",yes sure please start ticket assign think start working right away since memory still fresh way done notebook test feature put,issue,positive,positive,positive,positive,positive,positive
1701225944,"Also I think the notebooks seem to prioritize returning the mock which is
what was confusing me a bit. Because when I change it to private first the
notebooks start breaking. API/0.8/00

On Fri, Sep 1, 2023, 01:02 Peter Chung ***@***.***> wrote:

> Sorry for the late reply, at work right now. Think I was trying to change
> a few things around to test the return results in the notebooks before I
> had to leave so I committed what I was doing at the time. I'll keep looking
> at it when I get home in the morning 🙂
>
> On Fri, Sep 1, 2023, 00:18 Koen van der Veen ***@***.***>
> wrote:
>
>> ***@***.**** commented on this pull request.
>> ------------------------------
>>
>> In packages/syft/src/syft/service/action/action_store.py
>> <https://github.com/OpenMined/PySyft/pull/8054#discussion_r1311708881>:
>>
>> >                  if isinstance(obj, TwinObject):
>> -                    obj = (
>> -                        obj.mock if not is_action_data_empty(obj.mock) else obj.private
>> -                    )
>> +                    if self.has_permission(read_permission):
>> +                        obj = (
>> +                            obj.mock
>> +                            if not is_action_data_empty(obj.mock)
>>
>> I think this should return private right?
>>
>> —
>> Reply to this email directly, view it on GitHub
>> <https://github.com/OpenMined/PySyft/pull/8054#pullrequestreview-1604876233>,
>> or unsubscribe
>> <https://github.com/notifications/unsubscribe-auth/AXCVACBW2PRKBHZVMVP2TZTXYCMKLANCNFSM6AAAAAA4FQ2P2Y>
>> .
>> You are receiving this because you authored the thread.Message ID:
>> ***@***.***>
>>
>
",also think seem mock bit change private first start breaking peter wrote sorry late reply work right think trying change around test return leave time keep looking get home morning van veen wrote pull request else think return private right reply directly view id,issue,negative,positive,neutral,neutral,positive,positive
1701220062,"Sorry for the late reply, at work right now. Think I was trying to change a
few things around to test the return results in the notebooks before I had
to leave so I committed what I was doing at the time. I'll keep looking at
it when I get home in the morning 🙂

On Fri, Sep 1, 2023, 00:18 Koen van der Veen ***@***.***>
wrote:

> ***@***.**** commented on this pull request.
> ------------------------------
>
> In packages/syft/src/syft/service/action/action_store.py
> <https://github.com/OpenMined/PySyft/pull/8054#discussion_r1311708881>:
>
> >                  if isinstance(obj, TwinObject):
> -                    obj = (
> -                        obj.mock if not is_action_data_empty(obj.mock) else obj.private
> -                    )
> +                    if self.has_permission(read_permission):
> +                        obj = (
> +                            obj.mock
> +                            if not is_action_data_empty(obj.mock)
>
> I think this should return private right?
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/pull/8054#pullrequestreview-1604876233>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AXCVACBW2PRKBHZVMVP2TZTXYCMKLANCNFSM6AAAAAA4FQ2P2Y>
> .
> You are receiving this because you authored the thread.Message ID:
> ***@***.***>
>
",sorry late reply work right think trying change around test return leave time keep looking get home morning van veen wrote pull request else think return private right reply directly view id,issue,negative,negative,neutral,neutral,negative,negative
1701147755,"> Thank you @koenvanderveen . From what I know we have the tests in `mongo_document_store_test.py` but they are more about the functionality of the methods like `set`, `update`..., rather than the permissions

Oke, I think its not necessary to do it now, but we can at least add a ticket for triaging",thank know functionality like set update rather think necessary least add ticket,issue,positive,negative,negative,negative,negative,negative
1701122847,"Thank you @koenvanderveen . From what I know we have the tests in `mongo_document_store_test.py` but they are more about the functionality of the methods like `set`, `update`..., rather than the permissions",thank know functionality like set update rather,issue,positive,neutral,neutral,neutral,neutral,neutral
1701012065,"Overall this PR looks very good to me, great work @khoaguin! I am not completely sure about the test coverage of the mongo store, do we have any visibility of on which tests use this? Also, it would be quite good to have a notebook that shows how you can easily start a node with a mongo store using orchestra (maybe for a later PR as well, but we can make a ticket now).",overall good great work completely sure test coverage store visibility use also would quite good notebook easily start node store orchestra maybe later well make ticket,issue,positive,positive,positive,positive,positive,positive
1700372108,"Excellent work @callezenwaka!
<img width=""748"" alt=""Screenshot 2023-08-31 at 3 02 17 pm"" src=""https://github.com/OpenMined/PySyft/assets/2882739/90618a3d-ec22-4c37-9ed1-e1f0a6684496"">
<img width=""685"" alt=""Screenshot 2023-08-31 at 3 02 28 pm"" src=""https://github.com/OpenMined/PySyft/assets/2882739/9bf675cb-cacc-4168-b811-4febe288a298"">

I fixed the linting issue by running the precommit scripts locally.
```
$ pip install pre-commit
$ pre-commit install
$ pre-commit run --all-files
```
",excellent work fixed issue running precommit locally pip install install run,issue,positive,positive,positive,positive,positive,positive
1700362974,I can confirm I was able to deploy to k3ds on my machine without issue!,confirm able deploy machine without issue,issue,negative,positive,positive,positive,positive,positive
1698607716,"It may be a compatibility issue between Syft and Hagrid versions. Could you try using Hagrid version 0.3.37 and check if this error is still triggered ?

**Disclaimer:** I'm not a maintainer of PySyft.
",may compatibility issue could try version check error still triggered disclaimer maintainer,issue,negative,neutral,neutral,neutral,neutral,neutral
1692829230,"I think this means we might need to go back to using our own repo on gh-pages, but for now we can do the above for 0.8.2 release and then do the custom repo gh-pages action later.",think might need go back release custom action later,issue,negative,positive,neutral,neutral,positive,positive
1687715073,"I got the same issue, i'm feeling helpless
",got issue feeling helpless,issue,negative,neutral,neutral,neutral,neutral,neutral
1687713331,"same question. When I use `device = torch.device(""cpu"") ` this error would disappear.  This could be because PySyft may have some compatibility issues with PyTorch’s CUDA functionality, and it may not allow you to move your tensors and models to the GPU device. ",question use device error would disappear could may compatibility functionality may allow move device,issue,negative,neutral,neutral,neutral,neutral,neutral
1682053406,"> Yeah @bitsofsteve , Testing is something , which we need to figure out optimally.
> 
> I was mainly , waiting for some initial mature code, to choose our testing strategy
> 
> We have plethora of testing options
> 
> 1. Testing python and  standalone binary options ( 2 options)
> 2. Testing Operating systems (windows, mac, linux) (3 options)
> 3. Testing python versions ( 3.9- 3.11)
> 
> We would need around 18 different runners, to test all the scenarios
> 
> I thought it would be best to do it in the `cool down period`, Since yash is also working on the bundle part of syft cli currently
> 
> We could get a good idea, in choosing a testing strategy that is optimal with number of runners by then.

Sounds good then.",yeah testing something need figure mainly waiting initial mature code choose testing strategy plethora testing testing python binary testing operating mac testing python would need around different test thought would best cool period since also working bundle part currently could get good idea choosing testing strategy optimal number good,issue,positive,positive,positive,positive,positive,positive
1682033202,"Yeah @bitsofsteve , Testing is something , which we need to figure out optimally.

I was mainly , waiting for some initial mature code, to choose our testing strategy

We have plethora of testing options
1. Testing python and  standalone binary options ( 2 options)
2. Testing Operating systems (windows, mac, linux) (3 options)
3. Testing python versions ( 3.9- 3.11)

We would need around 18 different runners, to test all the scenarios

I thought it would be best to do it in the `cool down period`,
Since yash is also working on the bundle part of syft cli currently

We could get a good idea, in choosing a testing strategy that is optimal with number of runners by then.
",yeah testing something need figure mainly waiting initial mature code choose testing strategy plethora testing testing python binary testing operating mac testing python would need around different test thought would best cool period since also working bundle part currently could get good idea choosing testing strategy optimal number,issue,positive,positive,positive,positive,positive,positive
1680421839,"To be able to test it , 
Create a virtual Environement for syft development

1. pip install pre-commit
2. pre-commit install
3. pre-commit run --all-files

This should run all the pre commit checks, 

Then iteratively add each file, and solve the errors
",able test create virtual development pip install install run run commit iteratively add file solve,issue,positive,positive,positive,positive,positive,positive
1680420101,"Since, there are lot of paths, to solve , this issue could be tackled in several PR's
Adding file paths iteratively",since lot solve issue could tackled several file iteratively,issue,negative,neutral,neutral,neutral,neutral,neutral
1678621326,"> Wonderful Work @yashgorana , left one minor comment with black, other than that, we could merge once the tests pass.

The regex `files: ^packages/syft(?!(.*_pb2\\.py$)).*\\.py` already picks up syft-cli. 
![image](https://github.com/OpenMined/PySyft/assets/11070218/d0dc4d34-5bb1-42a5-9747-2efc755ba802)",wonderful work left one minor comment black could merge pas already image,issue,positive,positive,positive,positive,positive,positive
1678436920,"Well Done @yashgorana , on the initial start.

I think once ,we address all the comments above.

I think, we should be good to merge the PR.
",well done initial start think address think good merge,issue,positive,positive,positive,positive,positive,positive
1673566610,"> @dhreb great work on the PR. Can you fix the linting issues. I would recommend running the pre-commit hooks.
> 
> ```
> $ pip install pre-commit
> $ pre-commit install
> ```
> 
> Then to manually run:
> 
> ```
> $ pre-commit run --all-files
> ```
> 
> If you run this before you commit it will tell you if you have any issues which will fail the linting check.

Certainly, I was going to ask about this 👍",great work fix would recommend running pip install install manually run run run commit tell fail check certainly going ask,issue,positive,positive,positive,positive,positive,positive
1672610199,@rasswanth-s this is just a linting PR and the tests all pass. However it hits some enclave code. Would appreciate if you could take a look on those files and check if the changes are ok. Only 2 files under `external/oblv`.,pas however enclave code would appreciate could take look check,issue,negative,neutral,neutral,neutral,neutral,neutral
1672342561,"@dhreb great work on the PR. Can you fix the linting issues. I would recommend running the pre-commit hooks.

```
$ pip install pre-commit
$ pre-commit install
```

Then to manually run:
```
$ pre-commit run --all-files
```

If you run this before you commit it will tell you if you have any issues which will fail the linting check.",great work fix would recommend running pip install install manually run run run commit tell fail check,issue,positive,positive,positive,positive,positive,positive
1669585833,"If we only put `Asset` class as an argument to the `unsafe_function`, we get the message telling it's PRIVATE data if the user has the permission, otherwise MOCK data
![image](https://github.com/OpenMined/PySyft/assets/88959106/833c32d0-8db8-4aa2-993c-233276b015f6)
 ",put asset class argument get message telling private data user permission otherwise mock data image,issue,negative,neutral,neutral,neutral,neutral,neutral
1665845417,"@khoaguin  @PeterChung241

Scope has changed since opening this PR (from @shubham3121)
- Policy has been re-scoped as a nice-to-have feature to be picked up later
- Using Action Object permissions instead of implementing blob storage's own permissions since blob storage is meant to mainly work with Action Objects. This is to be worked on together with Action Object proxy.

Next step would be SeaweedFS implementation.

Thus I'm discarding most of the changes in this PR, only keeping the change from `blob_storage_entry` to `blob_storage_entry_id` in `BlobDeposit` as well as other minor fixes/cleanup.

@shubham3121 This can be merged now. Will open another PR for SeaweedFS implementation when the team work on it.",scope since opening policy feature picked later action object instead blob storage since blob storage meant mainly work action worked together action object proxy next step would implementation thus keeping change well minor open another implementation team work,issue,negative,positive,neutral,neutral,positive,positive
1655436288,"Sorry for abusing force pushing, just to make the commits clean for easier review. If you want to synchronize your local repo with this PR do `git pull --rebase`.",sorry force pushing make clean easier review want synchronize local git pull rebase,issue,positive,negative,neutral,neutral,negative,negative
1655148544,"@shubham3121 @PeterChung241 @khoaguin I've finished renaming all the file stuff to blob storage as we discussed. Please review all the commits starting with `Rename ...`.

There are 2 changes I made that are different from what we discussed. One is renaming `SyftResource`  and `SyftWriteResource` to `BlobRetrieval` and `BlobDeposit` instead of `SyftReadResource`  and `SyftWriteResource`. Alr discussed with Shubham about this.

The second one is renaming `FileObject` to `BlobStorageEntry` instead of `BlobStorageInformation`. Reasons are:
- We have things like `CreateFileObject`, `get_file_object_by_uid`, `get_all_file_object`, ... Replacing `file_object` here with `blob_storage_entry` instead of `blob_storage_information` reads better grammatically
- The object works like an entry in the blob storage as well since it serves as a record to help allocate and keep track of the syft object in the blob storage.

Let me know what you think. Happy to make changes again.",finished file stuff blob storage please review starting rename made different one instead second one instead like instead better grammatically object work like entry blob storage well since record help allocate keep track object blob storage let know think happy make,issue,positive,positive,positive,positive,positive,positive
1653500167,"I think in general we need more consistency in the naming in the code_history_service, we have

code_history.get -> return CodeHistory
code_history.get_all -> returns [CodeHistory]
code_history.get_history -> returns CodeHistoryDict[CodeVersions]
code_history.get_history_for_user -> CodeHistoryDict[CodeVersions]
code_history.get_by_name_and_user_email -> returns [CodeHistory]
code_history.get_histories_group_by_user -> returns UserHistoryDict

there are a 2 main inconsistencies

1. CodeHistoryDict does not contain Codehistory object but CodeVersions
2. get_history give you versions instead of histories

the solution could be
CodeVersion and CodeHistory are almost the same object. Maybe we should call them CodeHistory and CodeHistoryView to communicate that they are similar. This would also make more sense for 2), because you would actually have the right type of object in your dict (view instead of real, but thats fine I suppose)",think general need consistency naming return main contain object give instead solution could almost object maybe call communicate similar would also make sense would actually right type object view instead real thats fine suppose,issue,negative,positive,positive,positive,positive,positive
1653385251,"Thought about the negative indexing thing and whether its necessary, I think its still something we dont want for the DO because we want to prevent
```
code = client.code_histories[""my_user""].my_func[-1]
func = code.unsafe_function
res = func()
request.accept_by_depositing_result(res)
```",thought negative indexing thing whether necessary think still something dont want want prevent code,issue,negative,negative,negative,negative,negative,negative
1653325274,"apart from all the comments, I want to mention again that this is an amazing PR :heart:",apart want mention amazing heart,issue,positive,positive,positive,positive,positive,positive
1653321082,"few notes on reprs that I communicated earlier:
- Would be nice with repr for a list of codeversion to see how many versions each CodeVersioon has (jane_client.code_history)
- Would be nice for a each version of a UserCode to see which version it is and when it was submitted time (jane_client.code_history.test_func)
- admin_client.code_histories, needs a repr",would nice list see many would nice version see version time need,issue,positive,positive,positive,positive,positive,positive
1643655885,"I am not completely understanding the problem this solves. If I remove the lines with the context, the tests are still passing",completely understanding problem remove context still passing,issue,negative,positive,neutral,neutral,positive,positive
1641305162,"The bug ""Role Permission not being propagated on query or get based calls"" is fixed like below

![image](https://github.com/OpenMined/PySyft/assets/88959106/572352a9-d47e-453c-be0f-242e118074b5)
",bug role permission query get based fixed like image,issue,negative,positive,neutral,neutral,positive,positive
1638143296,"Great Functionality in a short amount of time.
Kachow
![lightning-mcqueen-cars-movie](https://github.com/OpenMined/PySyft/assets/43314053/74e8a08c-4391-4f34-ade7-5ecdd2dd00bc)
",great functionality short amount time,issue,positive,positive,positive,positive,positive,positive
1637445839,"There is still an issue: In the test and notebook, we have different results when setting a role of a user to `admin` or `data_owner`. For example, if we have 3 users in the test function, the new admin can see all 3 of them. However, in the notebook, the new admin can only see 2 of them (not the original admin user) 
```
def test_user_view_set_role(worker, guest_client) -> None:
    admin_client = get_mock_client(worker.root_client, ServiceRole.ADMIN)
    assert admin_client.me.role == ServiceRole.ADMIN
    admin_client.register(
        name=""Sheldon Cooper"",
        email=""sheldon@caltech.edu"",
        password=""changethis"",
        institution=""Caltech"",
        website=""https://www.caltech.edu/"",
    )
    sheldon = admin_client.users[-1]
    sheldon.set_role(""admin"")
    ds_client = guest_client.login(email=""sheldon@caltech.edu"", password=""changethis"")
    assert len(ds_client.users.get_all()) == len(admin_client.users.get_all())
```
Then the `assert len(ds_client.users.get_all()) == len(admin_client.users.get_all())` will pass.

However, if we try to do the same thing in jupyter notebooks, we will have something different like below:
The original admin
![image](https://github.com/OpenMined/PySyft/assets/88959106/159a05f2-08a1-4dc9-bdf8-56fa0e4d8c6c)

The 2nd admin
![image](https://github.com/OpenMined/PySyft/assets/88959106/77acb75d-46d7-410d-ba9b-9456f5aec20f)

",still issue test notebook different setting role user example test function new see however notebook new see original user worker none assert cooper assert assert pas however try thing something different like original image image,issue,positive,positive,positive,positive,positive,positive
1635862152,"https://github.com/OpenMined/PySyft/pull/7916#issuecomment-1632757831
Flag is turned off for tests.

> would be good to also have a prompt for when user registration is enabled on the high side

Added to toggle registration api as well",flag turned would good also prompt user registration high side added toggle registration well,issue,positive,positive,positive,positive,positive,positive
1633002342,TODO: Unit tests for this change. Please don't merge until i have some unit tests added to this change.,unit change please merge unit added change,issue,negative,neutral,neutral,neutral,neutral,neutral
1632907544,"@rasswanth-s @koenvanderveen @shubham3121 Madhava asked me to have this reviewed by you folks, can you please take a look at this review? I've updated this change to be a more cleaner + robust in multi-threaded scenarios (syft running with threads through gunicorn)",please take look review change cleaner robust running,issue,positive,neutral,neutral,neutral,neutral,neutral
1632757831,"How does it work now with the notebooks that dont have a high side and low side. Bcs the default node type is high so by default you get prompts everywhere? Should be turned off for notebook testing I suppose. Should maybe also be turned off for the tutorials?
",work dont high side low side default node type high default get everywhere turned notebook testing suppose maybe also turned,issue,negative,positive,positive,positive,positive,positive
1632753581,would be good to also have a prompt for when user registration is enabled on the high side,would good also prompt user registration high side,issue,negative,positive,positive,positive,positive,positive
1632656968,"Apply to gateway (If node is a high side node):
![Screenshot from 2023-07-17 17-49-57](https://github.com/OpenMined/PySyft/assets/11032835/6978d828-f124-4d69-97db-ab7492c894df)

Only warning (low side node -> no confirmation)
![Screenshot from 2023-07-17 17-49-31](https://github.com/OpenMined/PySyft/assets/11032835/d7d5481c-852e-4feb-a519-1201000725f8)

Upload Dataset (Only High side):
High Side
![Screenshot from 2023-07-17 17-50-51](https://github.com/OpenMined/PySyft/assets/11032835/569556d5-ad09-4ad9-8f28-f8de9830d351)

User Registration (High Side Only) -> This is shown only if guest signup is disabled and node is High Side
![Screenshot from 2023-07-17 17-51-31](https://github.com/OpenMined/PySyft/assets/11032835/b6a7e752-7c7e-4f39-a5d8-6f0d07e23fc4)

Get Dataset (High and Low Side) -> Only Reminder
![Screenshot from 2023-07-17 17-55-56](https://github.com/OpenMined/PySyft/assets/11032835/a41377d4-6133-49c1-8342-4ea2e6b32ba7)

![Screenshot from 2023-07-14 18-46-58](https://github.com/OpenMined/PySyft/assets/11032835/4664f7ae-dd7a-4a78-87d0-33325ac6760b)

Toggle Registration (Only High Side):
![Screenshot from 2023-07-17 17-56-38](https://github.com/OpenMined/PySyft/assets/11032835/07a85c26-7b29-471b-b2ea-773a9e653263)


Login Screens:

On login by a user:
![Screenshot from 2023-07-12 18-48-09](https://github.com/OpenMined/PySyft/assets/11032835/b9db3041-b447-47be-a2f1-3a3f4f56cdf7)

![Screenshot from 2023-07-12 18-48-42](https://github.com/OpenMined/PySyft/assets/11032835/b27ef80c-d16c-4f1e-9e99-d68fbc1ef3af)

Client  Repr: Added Node Type and Node Side Type information 
- Gateway: 
![Screenshot from 2023-07-12 20-08-29](https://github.com/OpenMined/PySyft/assets/11032835/373ff140-cb55-4f17-b7f5-3dec48079b7e)

- Domain: 
![Screenshot from 2023-07-12 20-07-13](https://github.com/OpenMined/PySyft/assets/11032835/0cc28849-c66f-4d67-8701-e8f2cd94e4cf)
- Enclaves:
![Screenshot from 2023-07-12 20-06-29](https://github.com/OpenMined/PySyft/assets/11032835/45d35631-0b10-4fe8-8a70-cecedf2ac72f)






",apply gateway node high side node warning low side node confirmation high side high side user registration high side shown guest disabled node high side get high low side reminder toggle registration high side login login user client added node type node side type information gateway domain,issue,negative,positive,neutral,neutral,positive,positive
1630756663,"Hey @rasswanth-s I would like to explore this issue, can you please assign this to me?",hey would like explore issue please assign,issue,positive,neutral,neutral,neutral,neutral,neutral
1630617485,"OK, I found my error,
if i change my password to this not mine
```python
root_client = node.login(email=""info@openmined.org"", password=""changethis"")
```",found error change password mine python,issue,negative,neutral,neutral,neutral,neutral,neutral
1628666537,"Also, after resetting the password, shall the old `domain_client` be logged out?
![image](https://github.com/OpenMined/PySyft/assets/88959106/80d699c3-f509-4885-8a6a-41ff5e093ab9)
",also password shall old logged image,issue,negative,positive,neutral,neutral,positive,positive
1628660125,"Currently I am checking the default password like this (with ` if password == ""changethis"":`). Is there a better way to sync it with `defaultRootPassword = ""changethis""` as in `values.yaml`?
![image](https://github.com/OpenMined/PySyft/assets/88959106/66be7892-74ce-42aa-98dc-15c022986048)


Fixed using ` get_default_root_password()` from `node.py`",currently default password like password better way sync image fixed,issue,positive,positive,positive,positive,positive,positive
1623523516,Hey @shubham3121 for my visibility could you expand upon this README so I know what's up here.,hey visibility could expand upon know,issue,negative,neutral,neutral,neutral,neutral,neutral
1623338906,"Looks great :heart:, no comments. I will add the tutorial notebook so its in CI",great heart add tutorial notebook,issue,positive,positive,positive,positive,positive,positive
1621055656,"Currently closing the PR and moving to a new PR, as the latest commits are not being shown in the PR.",currently moving new latest shown,issue,negative,positive,positive,positive,positive,positive
1619623486,"Logged the techdebt associated with the PR in this issue
https://github.com/OpenMined/Heartbeat/issues/518
Proposing to merge the PR early, as it would unblock others and improvement PR's could be pointed at dev branch.",logged associated issue merge early would unblock improvement could pointed dev branch,issue,negative,positive,neutral,neutral,positive,positive
1614339443,"Hi @shubham3121 @kiendang I am running the notebook `07-queue.ipynb` but got the below error. I found out that this is because the `queue_item.syft_client_verify_key = None`, hence `api = APIRegistry.api_for` in `QueueItem.fetch` returns `None`. 
![image](https://github.com/OpenMined/PySyft/assets/88959106/43bea4ca-0d0d-4f08-9d20-c48085fd5b5b)

If I assign the `queue_item` a `verify_key` with `queue_item.syft_client_verify_key = client.credentials.verify_key`, the problem disappears

",hi running notebook got error found none hence none image assign problem,issue,negative,neutral,neutral,neutral,neutral,neutral
1612724980,"Hi @koenvanderveen I am working on the `06-eager-execution.ipynb` notebook for the current api and saw something a bit weird like in the picture. The value should be 28, right, but somehow it returns 29?

![temp](https://github.com/OpenMined/PySyft/assets/88959106/ddd0ac94-26c6-4f1c-aaf7-9595d4e9d291)
",hi working notebook current saw something bit weird like picture value right somehow temp,issue,negative,negative,neutral,neutral,negative,negative
1612305667,"Hi @madhavajay, thank you for your fast response!

You may be right that the decoding error is due to the Chinese (zh-CN) language setting on my computer's operating system. However, I have identified that the problem specifically originates from the ""autodp"" package (https://github.com/yuxiangw/autodp.git), as mentioned in this issue: https://github.com/yuxiangw/autodp/issues/37#issue-1380117212.

Initially, I believed that by installing the ""autodp"" package separately using the solution suggested in the aforementioned link (`pip install -e`), the ""syft"" package installation (`pip install -U syft`) would recognize that the requirement for ""autodp"" is already satisfied. However, even though the installation of ""autodp==0.2"" was successful, I encountered the same error when attempting to install ""syft.""

Is there a way to remove ""autodp==0.2"" as a dependency of ""syft"" since it is already installed on my computer?

Additionally, I tried the solution you suggested for forcing Python to load in UTF8 mode by running:
`python -X utf8 -m pip install -U syft`
Unfortunately, I encountered the same error mentioned earlier.

Please let me know if there are any other possible solutions or suggestions. Thank you!",hi thank fast response may right error due language setting computer operating system however problem specifically package issue initially package separately solution link pip install package installation pip install would recognize requirement already satisfied however even though installation successful error install way remove dependency since already computer additionally tried solution forcing python load mode running python pip install unfortunately error please let know possible thank,issue,positive,positive,positive,positive,positive,positive
1612201291,"Hi @makinno I am trying to figure out how we can debug this. I believe its related to your operating system's language / locale settings and its ability to decode the README.md file. We test this in Windows on GitHub CI but my guess is that the language and locale are EN / US.

It would help if we knew what characters are being misinterpreted in the readme.

This looks like the same problem here:
https://github.com/alibaba/web-editor/issues/105

I think the solution is to force Python to load in UTF8 mode.

https://stackoverflow.com/questions/50933194/how-do-i-set-the-pythonutf8-environment-variable-to-enable-utf-8-encoding-by-def

You might be able to do something like:
```bash
set PYTHONUTF8=1 
pip install -U syft
```
or 
```bash
python3  -X utf8 -m pip install -U syft 
```",hi trying figure believe related operating system language locale ability decode file test guess language locale en u would help knew like problem think solution force python load mode might able something like bash set pip install bash python pip install,issue,positive,positive,positive,positive,positive,positive
1611077423,"@khoaguin , I pushed a  small fix to this branch
https://github.com/OpenMined/PySyft/pull/7874
which prevented the notebooks tests from running and merged dev into yours

Now hopefully the tests would run, after including in TEST_NOTEBOOOK_PATHS",small fix branch running dev hopefully would run,issue,negative,negative,negative,negative,negative,negative
1611025282,"@khoaguin  we need to add it in `pr-tests-syft.yml`
you could add them to `pr-tests-syft-notebook-python`, we could eventually move them to containers.

We set the TEST_NOTEBOOK_PATHS in that yaml file.",need add could add could eventually move set file,issue,negative,neutral,neutral,neutral,neutral,neutral
1611022784,"Somehow I added `api/0.9` in `TEST_NOTEBOOK_PATHS = {env:TEST_NOTEBOOK_PATHS:api/0.8,api/0.9,tutorials}` in `tox.ini` for `testenv:stack.test.notebook` and expect the checks to fail but they are still succeeding",somehow added expect fail still succeeding,issue,negative,negative,negative,negative,negative,negative
1611007938,"@khoaguin great start on the PR, Could we also add back projects folder back in 0.9

Initial removal PR:
https://github.com/OpenMined/PySyft/pull/7807/files",great start could also add back folder back initial removal,issue,positive,positive,positive,positive,positive,positive
1606845278,"> Amazing work @bitsofsteve , Kudos for using github actions syxtax itself
> 
> Maybe after the PR merge, we could test this workflow also on the PR's from forked branches to see if it works.

@rasswanth-s I'm sure it will work, since the concurrency grouping we used makes it unique to the PR. Great work on switching to `github.event.pull_request.number`. ",amazing work kudos maybe merge could test also forked see work sure work since concurrency grouping used unique great work switching,issue,positive,positive,positive,positive,positive,positive
1606155732,@koenvanderveen @rasswanth-s Can you please have a look and leave some comments for improvement? Thanks,please look leave improvement thanks,issue,positive,positive,positive,positive,positive,positive
1601643516,I got the same error on google Colab. The same code run on my mac machine,got error code run mac machine,issue,negative,neutral,neutral,neutral,neutral,neutral
1600885719,@chen-z-j hagrid is probably checking api v2 but you might be deploying api v1. Api v2 is in the latest betas and we will release a stable 0.8.1 this week.,probably might latest release stable week,issue,negative,positive,positive,positive,positive,positive
1600833083,"@Dumplingz we have moved to `api/v2` sometimes that check will fail but that doesnt mean the system isnt running. Can you update hagrid with:
```
$ pip install -U hagrid
```

And try running with `--verbose` and see what the output says.",sometimes check fail doesnt mean system running update pip install try running verbose see output,issue,negative,negative,negative,negative,negative,negative
1600830366,"@KoSpades Can you try `pip install -U hagrid` and update it, or ensure its installed in a virtualenv so that it doesn't conflict with any other packages you have.",try pip install update ensure conflict,issue,negative,neutral,neutral,neutral,neutral,neutral
1600829014,"@gelliravi please update hagrid
```
$ pip install -U hagrid
```

And then run debug to see your system settings.
```
$ hagrid debug
```

And then run your command with: 
```
$ hagrid ... --verbose
```

If you still have an issue paste the output and the debug output here and ill help.

",please update pip install run see system run command verbose still issue paste output output ill help,issue,negative,negative,negative,negative,negative,negative
1600814700,@qxzhou1010 We support SMPC in several versions of Syft and now Secure Enclaves. If you are interested in discussing other PET capabilities please join our Slack channel and one of our Input or Output privacy experts will be happy to talk to you.,support several secure interested pet please join slack channel one input output privacy happy talk,issue,positive,positive,positive,positive,positive,positive
1600812599,We will be launching new 0.8+ servers with CD soon so there won't be these manually deployed out of date network servers. ,new soon wo manually date network,issue,negative,positive,positive,positive,positive,positive
1600808951,"@superjdz we now have notebooks which run through CI here:
https://github.com/OpenMined/PySyft/tree/dev/notebooks

New release coming shortly with more blog post tutorials.",run new release coming shortly post,issue,negative,positive,neutral,neutral,positive,positive
1600087283,"Must have gotten included elsewhere, closing for now?",must gotten included elsewhere,issue,negative,neutral,neutral,neutral,neutral,neutral
1598505551,"Awesome PR ❤️ 

There are a bunch of things we want to add in the future, which I will specify in tickets for 0.8.2 or later

- make sure widgets work with millions of rows
- check DataSubjectList repr
- make repr_html more uniform
- reduce the nr of option we have to specify style for a syftobject
- add urls
- dataset with empty asset list shows search field undefined
- we want both indentation (e.g. usercode) and bold (user **b** want to change object **y** to permission **z**)

https://github.com/orgs/OpenMined/projects/81/views/1?pane=issue&itemId=31261251
",awesome bunch want add future specify later make sure work million check make uniform reduce option specify style add empty asset list search field undefined want indentation bold user want change object permission,issue,positive,positive,positive,positive,positive,positive
1598170595,"@shubham3121 , should the PR be 0.8.1 or 0.8.2? , I have marked it 0.8.1 last week, in last meeting we had a discussion on the notifications flow and this PR contains really nice changes for the notifications part.",marked last week last meeting discussion flow really nice part,issue,negative,positive,positive,positive,positive,positive
1597191536,@koenvanderveen I see some changes were made by @akalliokoski in PR #7775 based on your feedback. Is there anything else that I can work on for this issue? Thanks!,see made based feedback anything else work issue thanks,issue,negative,positive,positive,positive,positive,positive
1597055444,"> As this will become quite a short tutorial if you include these changes. I think it would be good to reference other tutorials for more information

Data owner and data scientist tutorials are now referenced in the beginning of the notebook.",become quite short tutorial include think would good reference information data owner data scientist beginning notebook,issue,negative,positive,positive,positive,positive,positive
1596885678,As this will become quite a short tutorial if you include these changes. I think it would be good to reference other tutorials for more information ,become quite short tutorial include think would good reference information,issue,negative,positive,positive,positive,positive,positive
1596874173,"Imo, it would be good to make this as short as possible. It should feel more like `print(""hello world"")` and less like a tutorial. I will add a few suggestions on how to achieve this.",would good make short possible feel like print hello world le like tutorial add achieve,issue,positive,positive,positive,positive,positive,positive
1596589719,@madhavajay @rasswanth-s this is now fixed. Please see the description as to why the fix had to be done in this way,fixed please see description fix done way,issue,negative,positive,neutral,neutral,positive,positive
1594336987,"Thinking about this again I think we can repurpose this PR as a high side low side tutorial for level 0, and have a much shorter version as hello syft tutorial",thinking think repurpose high side low side tutorial level much shorter version hello tutorial,issue,negative,positive,positive,positive,positive,positive
1591130171,"DO denies a request. Request status is marked as Rejected.
![image](https://github.com/OpenMined/PySyft/assets/11032835/d309864f-0eb8-41ac-9d03-12c126a38b6c)

DS receives a notification for the same
![image](https://github.com/OpenMined/PySyft/assets/11032835/846b6b62-83c1-47bc-91af-67b44804bbac)

DS cannot execute code is request is denied
![image](https://github.com/OpenMined/PySyft/assets/11032835/14444ce4-47f2-45fc-8128-477d537c7f6e)

",request request status marked image notification image execute code request image,issue,negative,positive,neutral,neutral,positive,positive
1589413643,"Now we only show the name of the `CreateAsset List` like below since the `id` and `shape` will be `None` before uploading 
![image](https://github.com/OpenMined/PySyft/assets/88959106/33c6aca5-4f83-4f66-b54c-2a58aa8dc439)
",show name list like since id shape none image,issue,negative,neutral,neutral,neutral,neutral,neutral
1588877017,"I think the main purpose of this notebook is that people can run syft as quickly as possible. I really like the notebook and the explanations, but for this purpose it is a bit long. My proposal would be a to add a shorter version of this, kind of a TLDR. We could keep this longer version with explanations if people want to read more. We could split those up into 2 separate notebooks or have a tldr as first chapter.",think main purpose notebook people run quickly possible really like notebook purpose bit long proposal would add shorter version kind could keep longer version people want read could split separate first chapter,issue,positive,positive,positive,positive,positive,positive
1588645845,"Instead of showing the `id`, we will show the name and shape of `CreateAsset` since we only want to create the `id` for an asset on the server side when it's uploaded ",instead showing id show name shape since want create id asset server side,issue,positive,neutral,neutral,neutral,neutral,neutral
1583802521,"@teo-milea  I am marking the PR with 0.8.2  label with the ticket rescope(https://github.com/OpenMined/Heartbeat/issues/337).
We could have the UI changes related to usercode, in a new PR if you are interested.",marking label ticket could related new interested,issue,negative,positive,positive,positive,positive,positive
1583026655,"it is worth considering how the experience is for the DS: if they don't have access to the data, do we show the denied message or not repr the data? Also, what if the data inside an Assets has other than 2 dimensions? We can make a corner case for one dimensions arrays, but for more than 2 we should thing about how to allow DOs to customize the repr. (for the moment we could show only the shape of the data)",worth considering experience access data show message data also data inside asset make corner case one thing allow do moment could show shape data,issue,positive,positive,positive,positive,positive,positive
1581951552,"I think there was a test missing for get_by_uid, I think we could add it in the second PR.",think test missing think could add second,issue,negative,negative,neutral,neutral,negative,negative
1581020282,"> hmm, in that case we definitely need self hosted runners

Yep, Currently there are some errors in the ubuntu runners, I have added only windows self hosted runners.
But after 0.8.1 , we could definitely add more  linux runners ",case definitely need self yep currently added self could definitely add,issue,positive,neutral,neutral,neutral,neutral,neutral
1581017900,"hmm, in that case we definitely need self hosted runners",case definitely need self,issue,negative,neutral,neutral,neutral,neutral,neutral
1581014464,"> I think apart from making them parallel I believe it would also be useful to have a separate job for every folder. in #7708
> 
> I am using
> 
> ```
>         notebook-paths:
>           [
>             ""tutorials/data-engineer"",
>             ""tutorials/data-owner"",
>             ""tutorials/data-scientist"",
>             ""tutorials/hello-syft"",
>             ""tutorials/pandas-cookbook"",
>             ""tutorials/pandas-cookbook-level-2"",
>           ]
> ```

This is good idea.

I experimented a lot on this idea some time back
I used to do this a lot while in SyMPC Repo(https://github.com/OpenMined/SyMPC)

This has a diminishing return.
Currently github allocates only a specific number of runners for each organization/repo level.

Currently,when one particular PR has a large number of runners..

This would not allow any other parallel PR's to execute the github runners.

As the other PR's have to wait until the first PR's runners have finished.

In 0.7 , we had a mix of self hosted runners (in Azure) + using github own runners",think apart making parallel believe would also useful separate job every folder good idea experimented lot idea time back used lot return currently specific number level currently one particular large number would allow parallel execute wait first finished mix self azure,issue,positive,positive,positive,positive,positive,positive
1580987233,"Not saying that we should implement all of these in this PR, just food for thought",saying implement food thought,issue,negative,neutral,neutral,neutral,neutral,neutral
1580986811,"Lastly I think it would be good to slightly reduce the nr of tests we have. We are parameterizing very heavily in some test files such as action_object_test.py, resulting in over 200 tests that do a lot of similar things
",lastly think would good slightly reduce heavily test resulting lot similar,issue,negative,positive,neutral,neutral,positive,positive
1580983788,"It would also be very helpful if we could partition the unit tests among different runners with something like this
https://stackoverflow.com/questions/56698210/limit-the-number-of-test-cases-to-be-executed-in-pytest

",would also helpful could partition unit among different something like,issue,positive,neutral,neutral,neutral,neutral,neutral
1580980164,"I think apart from making them parallel I believe it would also be useful to have a separate job for every folder. in
https://github.com/OpenMined/PySyft/pull/7708

I am using

```
        notebook-paths:
          [
            ""tutorials/data-engineer"",
            ""tutorials/data-owner"",
            ""tutorials/data-scientist"",
            ""tutorials/hello-syft"",
            ""tutorials/pandas-cookbook"",
            ""tutorials/pandas-cookbook-level-2"",
          ]
```",think apart making parallel believe would also useful separate job every folder,issue,negative,positive,positive,positive,positive,positive
1580526238,"I hardcoded the ports in many of the notebook tests as it is a source of flakyness when running parallel notebook tests that all use port=auto. They can still end up using the same port


EDIT: fixed port=auto instead by making it try a random port as first option instead of the default port
",many notebook source running parallel notebook use still end port edit fixed instead making try random port first option instead default port,issue,negative,positive,neutral,neutral,positive,positive
1576705190,"Did you find any subsequent fixes on this? 
I'm still facing this issue
",find subsequent still facing issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1576247131,"After discussing with Madhava, this PR is being targeted for 0.8.2 and will be put on the back burner for this week.",targeted put back burner week,issue,negative,neutral,neutral,neutral,neutral,neutral
1573170110,"@IshanMi Looking good, just need to fix the error the linter found:
```
packages/syft/src/syft/service/code/user_code.py:399:47: B008 Do not perform function call `SingleExecutionExactOutput` in argument defaults
```

Otherwise every code object will have the same OutputPolicy instance.",looking good need fix error linter found perform function call argument otherwise every code object instance,issue,negative,positive,positive,positive,positive,positive
1572756376,"> Instantly detects a whole bunch of circular and incorrect imports - especially between client, node & service. I have a couple of ideas to resolve this, but need to discuss in detail.

Would be great if we can resolve this. Currently there are a bunch of places where we have to do lazy import inside function body to work around this, which also means we have to give up on typing.",instantly whole bunch circular incorrect especially client node service couple resolve need discus detail would great resolve currently bunch lazy import inside function body work around also give,issue,positive,positive,positive,positive,positive,positive
1572603798,"Instantly detects a whole bunch of circular and incorrect imports - especially between `client`, `node` & `service`. I have a couple of ideas to resolve this, but need to discuss in detail. Also a quick heads up - this PR will be big =)",instantly whole bunch circular incorrect especially client node service couple resolve need discus detail also quick big,issue,negative,positive,positive,positive,positive,positive
1572237810,Closing this for now- we can re-open it later when we're working on DP level abstractions again. It looks like the discrete guassian code was taken from the original paper's github repo without any modification so we can always revisit it when the time comes.  ,later working level like discrete code taken original paper without modification always revisit time come,issue,positive,positive,positive,positive,positive,positive
1572089163,"Great work @alejandrosame , closing the PR, as the aim of the PR was to get a understanding of the DP codebase.",great work aim get understanding,issue,positive,positive,positive,positive,positive,positive
1572039598,"@teo-milea  , could we close the PR, as it is related to 0.7, or do we have some changes in the PR, we would be using later ?",could close related would later,issue,negative,neutral,neutral,neutral,neutral,neutral
1572035586,"Currently Closing the current PR, with our upcoming release.This issue would rescoped in the next iteration.",currently current upcoming issue would next iteration,issue,negative,neutral,neutral,neutral,neutral,neutral
1572029878,"Sorry for responding late on the PR, 

We have diverged a lot from the 0.7 release.

Currently closing the PR , as we do not have DP Implemented yet in the code base in the current version..

Feel free to ping me, if you are interested in taking up any issues related to our upcoming releases.

Slack Handle : Rasswanth",sorry late lot release currently yet code base current version feel free ping interested taking related upcoming slack handle,issue,positive,negative,negative,negative,negative,negative
1568390845,"@iamtrask, sure, sounds good! I will get back on this on Thursday.",sure good get back,issue,positive,positive,positive,positive,positive,positive
1567766998,"Yup I actually also tried reenabling mypy but it's close to 1000 errors now. I think we can gradually resolve them by reenabling individual parts of the code base like you said.
> I think we just need to progressively open this up as we go.",actually also tried close think gradually resolve individual code base like said think need progressively open go,issue,positive,negative,negative,negative,negative,negative
1567687742,"Dear iamtrask and 
koenvanderveen:
I have seen the notebook about  [tutorials](https://github.com/OpenMined/PySyft/tree/dev/notebooks/tutorials)  jupyter. Are we developing JUPYTER based on the system’s original role assignment? like the image.
<img width=""856"" alt=""image"" src=""https://github.com/OpenMined/PySyft/assets/114645772/66d915ad-edb6-4a03-83d0-21ae417e07d6"">

 ",dear seen notebook based system original role assignment like image image,issue,positive,positive,positive,positive,positive,positive
1567528241,"@teo-milea thank you for your comment! 

I understood the oversight and, after further inspection from the source code, I went and took the general form of `__truediv__` instead of `__sum__`.

The code keeps compiling and, unless I'm misunderstanding the implementation of `__truediv__`, the sign should be properly managed now.",thank comment understood oversight inspection source code went took general form instead code unless misunderstanding implementation sign properly,issue,negative,positive,neutral,neutral,positive,positive
1567422115,@madhavajay I've re-added the flake8-bugbear checks and attempted to fix the failed checks. There are only a couple of places in the code where fixing the checks makes it stop working. Those will be followed up separately.,fix couple code fixing stop working separately,issue,negative,neutral,neutral,neutral,neutral,neutral
1567314822,"I noticed that the @syft_function methods do not have arguments. Might it be possible to change a few more of them to accept arguments (as opposed to putting/initializing all the variables * in * the method, could we initialize outside the method and then pass them in at runtime?). I'm hoping this isn't much work as it's mostly about moving where initialization happens, but I feel that it could inspire much stronger confidence in how our stack works with Jax (and possibly uncover bugs relating to variable inputs)",might possible change accept opposed method could initialize outside method pas much work mostly moving feel could inspire much confidence stack work possibly uncover variable,issue,positive,positive,positive,positive,positive,positive
1567128487,"@kiendang yes, great catch. We used to use bugbear which had a check for this but we switched to `ruff`: https://github.com/charliermarsh/ruff Can you see if we can add back the right bugbear check to ruff for this.

https://github.com/PyCQA/flake8-bugbear
```
B006: Do not use mutable data structures for argument defaults. They are created during function definition time. All calls to the function reuse this one instance of that data structure, persisting changes between them.
```",yes great catch used use bugbear check switched ruff see add back right bugbear check ruff use mutable data argument function definition time function reuse one instance data structure persisting,issue,positive,positive,positive,positive,positive,positive
1567097428,"Hi @alejandrosame  thanks for working on the trial! You are definitely going in the right direction, you might only need more attention to how your min and max values are computed. Think about negative numbers as well and see how your implementation might be affected by them. ",hi thanks working trial definitely going right direction might need attention min think negative well see implementation might affected,issue,negative,positive,neutral,neutral,positive,positive
1566781551,"> @Kariten can you run:
> 
> ```
> $ hagrid quickstart --reset
> ```

This works pretty well, thanks.",run reset work pretty well thanks,issue,positive,positive,positive,positive,positive,positive
1566768904,"Ah looks like pydantic handles this differently so things like
```python
class CreateAsset(SyftObject): 
    ...
    contributors: List[Contributor] = []
```

is valid.",ah like differently like python class list contributor valid,issue,positive,neutral,neutral,neutral,neutral,neutral
1566136007,I am closing long standing Github Issues related to older PySyft versions (<=0.7) or  are not aligned in the current roadmap.Kindly re-open the issue if the needs to be addressed or is still relevant.,long standing related older current issue need still relevant,issue,negative,positive,positive,positive,positive,positive
1566126824,I am closing long standing Github Issues which are not aligned in the current roadmap.Kindly re-open the issue if the needs to be addressed or is still relevant.,long standing current issue need still relevant,issue,negative,positive,positive,positive,positive,positive
1566120025,"Currently this is possible with the new Syft Orchestra Feature, hence closing the issue.Kindly Re-open the issue, if the issue is not fully addressed in the current version.",currently possible new orchestra feature hence issue issue fully current version,issue,negative,positive,neutral,neutral,positive,positive
1566119400,"I am closing long standing Github issues belonging to older PySyft versions(<=0.7). Kindly re-open the issue , if this issue needs to be addressed or is still relevant.",long standing belonging older kindly issue issue need still relevant,issue,negative,positive,positive,positive,positive,positive
1566118238,"I am closing long standing Github issues belonging to older PySyft versions(<=0.7). Kindly re-open the issue , if this issue needs to be addressed.",long standing belonging older kindly issue issue need,issue,negative,positive,positive,positive,positive,positive
1566110276,"The branches were pruned, two months back for a demo, 
Currently we have only the active branches.

Hence closing the issue",two back currently active hence issue,issue,negative,negative,neutral,neutral,negative,negative
1562617792,"Just discussed with @teo-milea , lets assume 1 datasubject here and address multi data subject use case in another tutorial",assume address data subject use case another tutorial,issue,negative,negative,negative,negative,negative,negative
1562312572,@KamalGalrani it looks like this got resolved but thanks for the PR and the other ones I already merged. ❤️,like got resolved thanks already,issue,positive,positive,positive,positive,positive,positive
1562309551,@YBCS ping me if you are still interested in resolving this otherwise I will close for the time being.,ping still interested otherwise close time,issue,negative,positive,positive,positive,positive,positive
1560739947,"Already I installed syft 0.8.0.post2, torch 2.0.1 and torchvision 0.15.2
and I got this problem :
AttributeError: module 'syft' has no attribute 'join_duet'

Please I need help
[image: image.png]



On Tue, May 23, 2023 at 8:54 PM Victor Obarafor ***@***.***>
wrote:

> Hello, I have been struggling to install pysyft on both my windows 10 and
> Mac OS Big Sur version 11.7.7 device since Thursday. I have followed
> different installation procedures found on your github repositories but it
> keeps failing with errors. Failure to build wheels for pycapnp error and
> subprocess errors. Can anyone help please. Do you have a newer version or
> something that I could use as I am trying to do some experiments on my PhD
> project. Any help please. Thanks
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/7624#issuecomment-1559265119>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AFP5QTU3KT4MSRAHAHB2NSTXHSXRZANCNFSM6AAAAAAX6AEO4Q>
> .
> You are receiving this because you authored the thread.Message ID:
> ***@***.***>
>
",already post torch got problem module attribute please need help image tue may victor wrote hello struggling install mac o big sur version device since different installation found failing failure build error anyone help please version something could use trying project help please thanks reply directly view id,issue,negative,negative,neutral,neutral,negative,negative
1559265119,"Hello, I have been struggling to install pysyft on both my windows 10 and Mac OS Big Sur version 11.7.7 device since Thursday. I have followed different installation procedures found on your github repositories but it keeps failing with errors. Failure to build wheels for pycapnp error and subprocess errors. Can anyone help please. Do you have a newer version or something that I could use as I am trying to do some experiments on my PhD project. Any help please. Thanks",hello struggling install mac o big sur version device since different installation found failing failure build error anyone help please version something could use trying project help please thanks,issue,negative,negative,neutral,neutral,negative,negative
1558375792,"@tcp  I have re-enabled the playwright tests and pushed a commit, I am not fully sure, why it is failing again",playwright commit fully sure failing,issue,negative,positive,positive,positive,positive,positive
1557674929,"Hi @HopeDevote,

We are hoping to roll in detailed documentation soon for 0.8. Currently, some code examples are provided here: https://github.com/OpenMined/PySyft/tree/dev/notebooks/api/0.8

and over the next few weeks, the API documentation will be available more extensively here: https://github.com/OpenMined/PySyft/tree/dev/notebooks/tutorials/

Thanks a lot for waiting!",hi roll detailed documentation soon currently code provided next documentation available extensively thanks lot waiting,issue,negative,positive,positive,positive,positive,positive
1550899338,"@koenvanderveen and @tthoraldson great work. I had a few issues with CI at the end there, still need to get things a little more stable with this many notebook tests.",great work end still need get little stable many notebook,issue,positive,positive,positive,positive,positive,positive
1545625725,"> What's this one about?

It is mainly on  adding a query functionality to the project interface


and adding a the notion of thread to ProjectMessages (like we have in slack)


and also a project poll
",one mainly query functionality project interface notion thread like slack also project poll,issue,negative,positive,positive,positive,positive,positive
1545014854,Hey @KamalGalrani - thanks for looking into the fix! Is this issue ready to close?,hey thanks looking fix issue ready close,issue,positive,positive,positive,positive,positive,positive
1545014240,Duet did not exist in PySyft before 0.6. I recommend upgrading to PySyft 0.6 and trying again.,duet exist recommend trying,issue,negative,neutral,neutral,neutral,neutral,neutral
1545010972,"The error you're getting is basically that the project already exists, and PySyft won't let you create two projects with the same name.",error getting basically project already wo let create two name,issue,negative,neutral,neutral,neutral,neutral,neutral
1545010357,"Hey @jack-chen2022 - i've added a new feature request to be able to delete projects from the Python API. (I'm sure we were planning this anyway but now there's a ticket so you can track its progress).

In the mean time if you don't mind clearing the whole domain you can use ""hagrid land all; hagrid clean volumes"" and it'll empty out everything from your docker container and give you a fresh place to start again. You'll need to run ""hagrid launch"".",hey added new feature request able delete python sure anyway ticket track progress mean time mind clearing whole domain use land clean empty everything docker container give fresh place start need run launch,issue,positive,positive,positive,positive,positive,positive
1545004817,"Hey @Terror-1 - can you post how to reproduce this bug? Please include your operating system and version of python, docker, syft, and hagrid.",hey post reproduce bug please include operating system version python docker,issue,negative,neutral,neutral,neutral,neutral,neutral
1537457160,"precommit passed offline
```
[WARNING] The 'files' field in hook 'nbstripout' is a regex, not a glob -- matching '/*' probably isn't what you want here
check python ast.........................................................Passed
trim trailing whitespace.................................................Passed
check docstring is first.................................................Passed
check json...............................................................Passed
check for added large files..............................................Passed
check yaml...............................................................Passed
check for merge conflicts................................................Passed
check that executables have shebangs.....................................Passed
debug statements (python)................................................Passed
python tests naming......................................................Passed
fix requirements.txt.....................................................Passed
mixed line ending........................................................Passed
absolufy-imports.........................................................Passed
isort....................................................................Passed
black....................................................................Passed
ruff.....................................................................Passed
mypy-hagrid..............................................................Passed
mypy-grid................................................................Passed
mypy-syft................................................................Passed
nbstripout...........................................(no files to check)Skipped

```",precommit warning field hook matching probably want check python ast trim trailing check first check check added large check check merge check python python naming fix mixed line ending black ruff check,issue,negative,positive,neutral,neutral,positive,positive
1535837629,"> ## Description
> Hi everyone, I am experiencing an issue withe **Lesson 2: Remote Data Science Demo**. When I execute:
> 
> ```
> from time import sleep
> total_cases = 0
> for result in results:
>     ptr = result.publish()
>     sleep(1)
>     total_cases += ptr.get()
> ```
> 
> I receive the error:
> 
> ```
> Unable to Get Object with ID <UID: 754c48210cbc4ec9931f4be5be4f3f58> from store. Possible dangling Pointer. 'Object not found! for UID: 754c4821-0cbc-4ec9-931f-4be5be4f3f58'
> ```
> 
> ## How to Reproduce
> 1. Run the notebook [Lesson 2: Remote Data Science Demo](https://github.com/OpenMined/courses/blob/introduction-to-remote-data-science-dev/L2_Demo.ipynb)
> 2. The error is thrown by the last code block
> 
> ## Expected Behavior
> After a long wait I receive the error:
> 
> ```
> Unable to Get Object with ID <UID: 754c48210cbc4ec9931f4be5be4f3f58> from store. Possible dangling Pointer. 'Object not found! for UID: 754c4821-0cbc-4ec9-931f-4be5be4f3f58'
> ```
> 
> ## System Information
> * Syft version 0.7.0
> 
> ## Additional Context
> The problem persists after running the commands `hagrid land all; hagrid clean volumes;` followed by running again the Jupyter Notebook [Lesson 2: Remote Data Science Demo](https://github.com/OpenMined/courses/blob/introduction-to-remote-data-science-dev/L2_Demo.ipynb)

DId you find a solution to this problem ?
",description hi everyone issue withe lesson remote data science execute time import sleep result sleep receive error unable get object id store possible dangling pointer found reproduce run notebook lesson remote data science error thrown last code block behavior long wait receive error unable get object id store possible dangling pointer found system information version additional context problem running land clean running notebook lesson remote data science find solution problem,issue,negative,negative,neutral,neutral,negative,negative
1533898742,Hi @tguerand sorry we had to redo the source branch for this task because we had a major change to the repo code structure can you rebase your changes over that new branch and also target the same branch for merge?,hi sorry redo source branch task major change code structure rebase new branch also target branch merge,issue,negative,negative,negative,negative,negative,negative
1533897595,"@KamalGalrani I guess the problem with this solution is the result being deserialized will be a `str`. 

Can you add something here:
https://github.com/OpenMined/PySyft/blob/dev/packages/syft/src/syft/serde/third_party.py

And a test to verify it does serialize and deserialize correctly on both sides?",guess problem solution result add something test verify serialize correctly side,issue,negative,neutral,neutral,neutral,neutral,neutral
1533895933,"@KamalGalrani great spot, we need some test coverage on this as it got missed before, can you add something quickly? We also need to deploy an updated server for this.",great spot need test coverage got add something quickly also need deploy server,issue,positive,positive,positive,positive,positive,positive
1532437622,"Hey @IonesioJunior, sure I would then close this PR.
",hey sure would close,issue,negative,positive,positive,positive,positive,positive
1530859649,Hi @alejandrosame looks like you got the old branch before we updated it can you rebase on the new branch head or create a new PR?,hi like got old branch rebase new branch head create new,issue,positive,positive,positive,positive,positive,positive
1530859420,Hi @factdroid looks like you got the old branch can you rebase on the updated branch or create a new PR?,hi like got old branch rebase branch create new,issue,positive,positive,positive,positive,positive,positive
1530859233,"Hi @tguerand looks like you might have gotten the old branch before we updated it, can you rebase on the updated commit of the target branch or create a new pr?",hi like might gotten old branch rebase commit target branch create new,issue,positive,positive,positive,positive,positive,positive
1530858660,Hi @dbckz bad timing you must have grabbed the old branch before we updated it. Can you rebase on the updated branch or just create a new one based on the updated branch?,hi bad timing must old branch rebase branch create new one based branch,issue,negative,negative,negative,negative,negative,negative
1530565972,"Hello @Neelaksh-Singh! Our `padawan_trial_1` branch was experiencing errors in the continuous integration tests due to last month's changes.

We have managed to fix it. However, due to the branch being significantly outdated, there were numerous conflicts that required manual resolution.

Could you create a new pull request using the updated branch state to ensure that the changes are properly reflected? 😃 

We apologize for the unexpected issue.",hello branch continuous integration due last month fix however due branch significantly outdated numerous manual resolution could create new pull request branch state ensure properly reflected apologize unexpected issue,issue,positive,negative,neutral,neutral,negative,negative
1528939292,"While importing syft==0.3.0 

getting error

NameError: name 'RequestMessage' is not defined
",getting error name defined,issue,negative,neutral,neutral,neutral,neutral,neutral
1528939185,"NameError                                 Traceback (most recent call last)
/tmp/ipykernel_16343/2086299665.py in <module>
----> 1 import syft

~/anaconda3/envs/FL/lib/python3.7/site-packages/syft/__init__.py in <module>
     61 from syft.core.node.device.device import Device  # noqa: F401
     62 from syft.core.node.device.device import DeviceClient  # noqa: F401
---> 63 from syft.core.node.domain.domain import Domain  # noqa: F401
     64 from syft.core.node.domain.domain import DomainClient  # noqa: F401
     65 from syft.core.node.network.network import Network  # noqa: F401

~/anaconda3/envs/FL/lib/python3.7/site-packages/syft/core/node/domain/__init__.py in <module>
      1 # syft relative
----> 2 from .client import DomainClient  # noqa: F401
      3 from .domain import Domain  # noqa: F401
      4 
      5 __all__ = [""DomainClient"", ""Domain""]

~/anaconda3/envs/FL/lib/python3.7/site-packages/syft/core/node/domain/client.py in <module>
     18 from ...io.route import Route
     19 from ..common.client import Client
---> 20 from .service import RequestMessage
     21 
     22 

~/anaconda3/envs/FL/lib/python3.7/site-packages/syft/core/node/domain/service/__init__.py in <module>
      1 # syft relative
----> 2 from .request_answer_message import RequestAnswerMessage  # noqa: F401
      3 from .request_answer_message import RequestAnswerMessageService  # noqa: F401
      4 from .request_answer_message import RequestAnswerResponse  # noqa: F401
      5 from .request_message import RequestMessage  # noqa: F401

~/anaconda3/envs/FL/lib/python3.7/site-packages/syft/core/node/domain/service/request_answer_message.py in <module>
     22 from ...abstract.node import AbstractNode
     23 from ...common.service.node_service import ImmediateNodeServiceWithReply
---> 24 from .request_message import RequestStatus
     25 
     26 

~/anaconda3/envs/FL/lib/python3.7/site-packages/syft/core/node/domain/service/request_message.py in <module>
     34 
     35 
---> 36 class RequestMessage(ImmediateSyftMessageWithoutReply):
     37 
     38     __slots__ = [""name"", ""request_description"", ""request_id""]

~/anaconda3/envs/FL/lib/python3.7/site-packages/syft/core/common/serde/serializable.py in __new__(cls, name, bases, dct)
     45         x = super().__new__(cls, name, bases, dct)
     46         try:
---> 47             protobuf_schema = dct[""get_protobuf_schema""].__get__("""")()
     48             protobuf_schema.schema2type = x
     49         except (KeyError, NotImplementedError):

~/anaconda3/envs/FL/lib/python3.7/site-packages/syft/decorators/syft_decorator_impl.py in wrapper(*args, **kwargs)
     29         def wrapper(*args: Tuple[Any], **kwargs: Dict[Any, Any]) -> Callable:
     30 
---> 31             return function(*args, **kwargs)
     32             # try:
     33             #     return function(*args, **kwargs)

~/anaconda3/envs/FL/lib/python3.7/site-packages/syft/decorators/typecheck.py in decorator(*args, **kwargs)
    108         if prohibit_args:
    109             check_args(*args, **kwargs)
--> 110         return typechecked(decorated)(*args, **kwargs)
    111 
    112     decorator.__annotations__ = decorated.__annotations__

~/anaconda3/envs/FL/lib/python3.7/site-packages/syft/core/node/domain/service/request_message.py in get_protobuf_schema()
    161         return request_msg
    162 
--> 163     @staticmethod
    164     @syft_decorator(typechecking=True)
    165     def get_protobuf_schema() -> GeneratedProtocolMessageType:

NameError: name 'RequestMessage' is not defined
",recent call last module import module import device import import domain import import network module relative import import domain domain module import route import client import module relative import import import import module import import import module class name name base super name base try except wrapper wrapper callable return function try return function decorator return decorated return name defined,issue,positive,negative,negative,negative,negative,negative
1516164253,"Todos

- [x] add function_signatures_registry to the CMPTree on the CMPTree node level
- [ ] allow children in CMPTree definition that skip modules (e.g. nump.ma.masked_array as child of numpy)
- [x] document signature extraction code
- [x] test permissions with SyftAPICall (you cannot call numpy.testing.something because we have NONE_EXECUTE for that branch of the tree). It should be a SyftAPICall as we can bypassing client.api.lib.numpy.something using SyftAPICalls
- [ ] implement TwinObject functionalities when calling action.execute with for instance numpy.add
- [ ] What do we do with None signatures
- [ ] add tests for Tree coverage. What are the edge cases, especially around signatures. Add tests for those
- [ ] add tests for function/class outputs. We are making some shortcuts with signatures, make sure we know how our outputs differ or what our limitations are
- [x] fix signature problems with some classes that were previously working
- [x] passing tests for execution of functions/classes
- [ ] test a bunch of popular methods
- [ ] manually test autocomplete
- [ ] try to add jax/pandas, split out numpy specific code
  - [ ] add tests
  - [ ] add analysis: what is working, what is not working
",add node level allow definition skip child document signature extraction code test call branch tree implement calling instance none add tree coverage edge especially around add add making make sure know differ fix signature class previously working passing execution test bunch popular manually test try add split specific code add add analysis working working,issue,positive,positive,positive,positive,positive,positive
1509302199,"@koenvanderveen, rebuild function for extracting the signature from docstrings. still wip",rebuild function signature still,issue,negative,neutral,neutral,neutral,neutral,neutral
1507936851,"> It seems that notebooks L3 and L5 (L5 being the one where `.publish()` and `.get()` are used) both work. I don't plan do debug further this issue at the moment, but I share below some observations.
> 
> It seems that when the DataSubject name is something like `""Country 0""` everything works fine, but when it is simply `""0""` you receive the error Exception: `Unable to Get Object with ID <UID: bbace75459dc4065a8c0b0ed9dbdf0d7> from store. Possible dangling Pointer. can only concatenate str (not ""Int"") to str`. Perhaps the `""0""` is converted into the integer `0` somewhere in one of the calls.

I've tried it with a string like ""person 0"" but still get the same error. Have you found a solution? ",one used work plan issue moment share name something like country everything work fine simply receive error exception unable get object id store possible dangling pointer concatenate perhaps converted integer somewhere one tried string like person still get error found solution,issue,positive,negative,neutral,neutral,negative,negative
1504984439,This looks great to me! The added test coverage is awesome and I really like the docs.,great added test coverage awesome really like,issue,positive,positive,positive,positive,positive,positive
1500967698,"Also getting exactly this. Out of interest, when you login to the domain node do you also find the name of it is 'default_domain_node' rather than 'test_domain'?",also getting exactly interest login domain node also find name rather,issue,negative,positive,positive,positive,positive,positive
1494956415,"@madhavajay 
open todo's 

- implement another collection in the mongo docstore that contains the permissions, similar to kv_dict_store
- implement mongostore.has_permission similar to kv_dict_store
- fix mongo store tests
- fix enclave tests (I believe @rasswanth-s is looking into this)


",open implement another collection similar implement similar fix store fix enclave believe looking,issue,negative,neutral,neutral,neutral,neutral,neutral
1488274325,"You're absolutely correct @khoaguin, there is a missing step for `request.getfixturevalue`. Good catch !! 🐛  I will create a fix for it in another PR.",absolutely correct missing step good catch bug create fix another,issue,negative,positive,positive,positive,positive,positive
1488248108,"While writing the test, I read the similar test in `packages/syft/tests/syft/users/user_serde_test.py`:
```python
@pytest.mark.parametrize(
    ""obj"",
    [
        ""guest_create_user"",
        ""guest_view_user"",
        ""guest_user"",
        ""guest_user_private_key"",
        ""update_user"",
        ""guest_user_search"",
        ""user_stash"",
        ""user_service"",
    ],
)
def test_user_serde(obj: Any) -> None:
    ser_data = sy.serialize(obj, to_bytes=True)
    assert isinstance(ser_data, bytes)
    deser_data = sy.deserialize(ser_data, from_bytes=True)

    assert isinstance(deser_data, type(obj))
    assert deser_data == obj
```

This function does not use `request.getfixturevalue` to get the real value of the fixture, hence the `obj` are just of type string. So we were just testing serializing and deserializing strings, which I think is not what we were trying to do",writing test read similar test python none assert assert type assert function use get real value fixture hence type string testing think trying,issue,negative,positive,neutral,neutral,positive,positive
1488149217,@shubham3121 this is ready for review now. Added 1 small fix in `document_store.py`,ready review added small fix,issue,negative,negative,neutral,neutral,negative,negative
1488033022,"Hey @shubham3121 @koenvanderveen  Can you please review the PR? 
Thanks",hey please review thanks,issue,positive,positive,positive,positive,positive,positive
1485982866,"@madhavajay @shubham3121 moving this out of WIP. Have added some tests to give an idea how the new `@serializable` works & the flexibility it offers. One key improvement is that working with pydantic objects like `SyftObject`/`SyftBaseObject` is a lot cleaner. I've captured and reviewed the differences between this PR & dev branch for all serializable classes here: https://docs.google.com/spreadsheets/d/1gwq3dgN8T3lUR8TL4EVBbLP3c27sBvMAvM5tz53tXF8/edit?usp=sharing

Please do take a look and let me know if you'd want to add/remove any change.",moving added give idea new work flexibility one key improvement working like lot cleaner dev branch class please take look let know want change,issue,positive,positive,neutral,neutral,positive,positive
1481053648,"@yashgorana, superb work with the PR. 🔥 🎉 
Below are the answers to your queries:
- The field `id` is currently optional in SyftObject and doesn't get defined until the Derived Class explicitly defines it (and therefore we don't serialize it there). Also, I think if a user explicitly defines some field to be serializable in its derived class (but that field is not serialized in the base class), then we should serialize it.
- SyftAPICall - We can even add `node_uid` to it -> [""node_uid"", ""path"", ""args"", ""kwargs""] 
- StorePartition, SQLiteStorePartition, DictStorePartition -> Attrs on these classes look good.


",superb work fire field id currently optional get defined derived class explicitly therefore serialize also think user explicitly field derived class field base class serialize even add path class look good,issue,positive,positive,positive,positive,positive,positive
1480483406,"Also in the latest version , following packages are not found:
from syft.core.plan.plan_builder import ROOT_CLIENT
from syft.core.plan.plan_builder import make_plan
from syft.federated.model_centric_fl_client import ModelCentricFLClient
from syft.lib.python.int import Int
from syft.lib.python.list import List
from syft.proto.core.plan.plan_pb2 import Plan as PlanPB
from syft.proto.lib.python.list_pb2 import List as ListPB",also latest version following found import import import import import list import plan import list,issue,negative,positive,positive,positive,positive,positive
1479839152,"> Hey @dhreb , I'm getting this error while trying to see the dataset list. Also, it's rendering it below the sidebar. Not sure why
> 
> ![error](https://user-images.githubusercontent.com/26658472/226881678-7d2155fb-254d-4d15-ab54-0d8dcc67620e.png)

@IonesioJunior Good finds. I fixed these issues. I had been developing without being logged in recently so I wasn't accounting for the Side/nav bar. Just pushed a couple fixes to these issues 👍 ",hey getting error trying see list also rendering sure error good fixed without logged recently accounting bar couple,issue,negative,positive,positive,positive,positive,positive
1479335002,"Hey @dhreb , I'm getting this error while trying to see the dataset list.
Also, it's rendering it below the sidebar. Not sure why

![error](https://user-images.githubusercontent.com/26658472/226881678-7d2155fb-254d-4d15-ab54-0d8dcc67620e.png)
",hey getting error trying see list also rendering sure error,issue,negative,positive,positive,positive,positive,positive
1479033443,"@madhavajay @shubham3121 here's a work-in-progress PR. I have done a parity check and most the attrs are being added to the serde map correctly. There are certain classes for which there seems to be some new additions/deletions which we can review:

| Class                  | attrs on `dev`              | attrs on `yash/serde`                                          | Reason                                               |
|------------------------|-----------------------------|----------------------------------------------------------------|------------------------------------------------------|
| **PythonNodeRoute**      | `['id', 'worker_settings']` | `['worker_settings']`                                          | ⚠️ Class is derived from `SyftObject` but `""id""` is not a seriazable attr of SyftObject; either we do this or let derived classes explicitly define ""id"" |
| **SyftAPICall**          |                             | `[""path"", ""args"", ""kwargs""]`                                   | ❗Rebase conflict. Need to fix. |
| **StorePartition**       | `None`                      | `['settings', 'searchable_cks', 'unique_cks', 'store_config']` | ⚠️ Had missing serializable attrs that I added manually. Please review. |
| **SQLiteStorePartition** | `None`                      | `['settings', 'searchable_cks', 'unique_cks', 'store_config']` | ✅ Inherited from `StorePartition`. Working as expected. |
| **DictStorePartition**   | `None`                      | `['settings', 'searchable_cks', 'unique_cks', 'store_config']` | ✅ Inherited from `StorePartition`. Working as expected. |
",done parity check added map correctly certain class new review class dev reason warning class derived id either let derived class explicitly define id path rebase conflict need fix none warning missing added manually please review none working none working,issue,negative,positive,neutral,neutral,positive,positive
1478653261,"Workaround: remove the reference to kwargs and just use the positional arguments.
```python
age_data = sy.Tensor(dataset[""Age""]).annotate_with_dp_metadata(
   0, 100, data_subjects
)
```",remove reference use positional python age,issue,negative,neutral,neutral,neutral,neutral,neutral
1477372969,"> @bcebere I couldn't push to this PR again for some reason, I fixed some issues in this commit here: [3566eb8](https://github.com/OpenMined/PySyft/commit/3566eb808bde824b1949a65c8c478df653d62af5)

OK, sure. But I didn't touch those files in this PR.
",could push reason fixed commit sure touch,issue,positive,positive,positive,positive,positive,positive
1477283450,"I was not able to solve.. Can you please share if something works for you.
And do you know if what was the syft version they used when they created the the tutorial in the below link?
https://github.com/OpenMined/PySyft/blob/c4cba6a47500db5d0d19393b8aa3ad2df6a55d99/examples/tutorials/advanced/Split%20Neural%20Network/Tutorial%201%20-%20SplitNN%20Introduction.ipynb",able solve please share something work know version used tutorial link,issue,positive,positive,positive,positive,positive,positive
1477274894,"Not yet.

On Mon, Mar 20, 2023 at 10:27 PM Shivani Kolanu ***@***.***>
wrote:

> Is this issue resolved as I'm also facing the same issue?
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/7431#issuecomment-1477264758>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AKO6USSM52JLNGRS33L4LUDW5EUZVANCNFSM6AAAAAAV64X6WY>
> .
> You are receiving this because you authored the thread.Message ID:
> ***@***.***>
>
",yet mon mar wrote issue resolved also facing issue reply directly view id,issue,negative,positive,neutral,neutral,positive,positive
1477274467,@ShivaniKolanu not yet. How did you solve? I'm focusing on duet without creating virtual workers.,yet solve duet without virtual,issue,negative,neutral,neutral,neutral,neutral,neutral
1477266406,"is this issue resolved? I'm also having the same issue. can you please tell me if you solved?
",issue resolved also issue please tell,issue,negative,neutral,neutral,neutral,neutral,neutral
1477264758,Is this issue resolved as I'm also facing the same issue?,issue resolved also facing issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1477224908,"@bcebere I couldn't push to this PR again for some reason, I fixed some issues in this commit here: https://github.com/OpenMined/PySyft/pull/7443/commits/3566eb808bde824b1949a65c8c478df653d62af5",could push reason fixed commit,issue,negative,positive,neutral,neutral,positive,positive
1475657648,"Great points @koenvanderveen. Auto-login post register is currently implemented, so this should work.
```
node = Worker()
ds_client = node.root_client.guest()
ds_client.register(""x@y.com"", ""mypw"")
```
I think we will definitely look at implementing a method like this `node.root_client.update_user_role`, it's just that the client-side UX for user profile-related views hasn't been designed yet.",great post register currently work node worker think definitely look method like user designed yet,issue,positive,positive,positive,positive,positive,positive
1474246581,"@madhavajay @shubham3121 with this PR some parts of the API become a bit more closed off. I expect that when writing tests something like this would be super common

```
node = Worker()
guest_client = node.root_client.guest()
guest_client.register(""x@y.com"", ""mypw"")
user_id = #get user id
guest_client.login(""x@y.com"", ""mypw"")
node.root_client.services.api.users.update(user_id, UserUpdate(role=ServiceRole.DATASCIENTIST))

# do stuff with guest client, accept stuff with root_client
```  

Earlier, we didnt need this because every endpoint was accessible to everyone. Now we do, but it feels like it would be nice to make this somehow a bit shorter. 

- we could give register a parameter `login` that does both in one step. Which also prevents retyping your credentials
- we could add a convenience method `node.root_client.update_user_role(""myaccount@openmined.org"", ServiceRole.DATASCIENTIST)`

```
node = Worker()
ds_client = node.root_client.guest()
ds_client.register(""x@y.com"", ""mypw"")
node.root_client.update_user_role(""x@y.com"", ServiceRole.DATASCIENTIST)
```

Something like a login code would be even better to build a reliable api, but also a bit more work.",become bit closed expect writing something like would super common node worker get user id stuff guest client accept stuff didnt need every accessible everyone like would nice make somehow bit shorter could give register parameter login one step also could add convenience method node worker something like login code would even better build reliable also bit work,issue,positive,positive,positive,positive,positive,positive
1471590481,"I have encountered exactly the same problem, please tell me **how to solve this problem.** I tried using `hagrid launch domain --build-src=0.7.0`, but it didn't work.",exactly problem please tell solve problem tried launch domain work,issue,negative,positive,positive,positive,positive,positive
1471254988,@teo-milea A change similar to #7399 would fix this.,change similar would fix,issue,negative,neutral,neutral,neutral,neutral,neutral
1470920289,"> $ pip install git+https://github.com/OpenMined/PySyft@dev#egg=syft

When I tried using ! pip install git+https://github.com/OpenMined/PySyft@dev#egg=syft in colab. 

The error: 
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting syft
  Cloning https://github.com/OpenMined/PySyft (to revision dev) to /tmp/pip-install-tjhwud16/syft_5391efd74ee248e785982ea2e00f5980
  Running command git clone --filter=blob:none --quiet https://github.com/OpenMined/PySyft /tmp/pip-install-tjhwud16/syft_5391efd74ee248e785982ea2e00f5980
  Resolved https://github.com/OpenMined/PySyft to commit f43cfe650f02944cc48dc784594274baa9e87b04
ERROR: syft from git+https://github.com/OpenMined/PySyft@dev#egg=syft does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found",pip install tried pip install error looking revision dev running command git clone none quiet resolved commit error appear python project neither found,issue,negative,neutral,neutral,neutral,neutral,neutral
1470814842,"syft==0.6.0 is compatible in colab? I installed this version. Import is ok, but when I try to create virtual worker using hook=sy.TorchHook(torch) then it shows TorchHook module error",compatible version import try create virtual worker torch module error,issue,negative,neutral,neutral,neutral,neutral,neutral
1470814448,"> Sadly - this is a known issue. The latest version of PySyft is not compatible with some of the ways Colab is locked down - pip install locally (using conda) and we'll address colab integration in a later version.
> 
> CC: @madhavajay to confirm.

syft==0.6.0 is compatible in colab? I installed this version. Import is ok, but when I try to create virtual worker using hook=sy.TorchHook(torch) then it shows TorchHook module error",sadly known issue latest version compatible way locked pip install locally address integration later version confirm compatible version import try create virtual worker torch module error,issue,negative,neutral,neutral,neutral,neutral,neutral
1465620538,@kiendang yes im pretty sure this just needs to be moved to `__attr_searchable__` since if it was unique then a user could only upload 1 UserCode object? @teo-milea is that the issue you were having?,yes pretty sure need since unique user could object issue,issue,positive,positive,positive,positive,positive,positive
1465594351,"@akalliokoski unfortunately we are reworking the code base so we can't merge this PR. If you are interested in contributing I can highly recommend signing up for the Padawan Program where we can mentor you and have you join the Dev Team.
https://blog.openmined.org/work-on-ais-most-exciting-frontier-no-phd-required/",unfortunately code base ca merge interested highly recommend program mentor join dev team,issue,positive,negative,negative,negative,negative,negative
1465110825,"@avinsit123 I am using syft 0.5.0 and what you recommended is working, but could you please tell me how can I send some different data to a client ?",working could please tell send different data client,issue,negative,neutral,neutral,neutral,neutral,neutral
1464895255,"Hagrid land command for worker container
![Screenshot 2023-03-11 at 5 25 11 PM](https://user-images.githubusercontent.com/43314053/224482893-ecf10a56-5638-4ee3-8034-f3e923a28ecd.png)
",land command worker container,issue,negative,neutral,neutral,neutral,neutral,neutral
1463776711,"Health Checks added for the Worker Container
![Screenshot 2023-03-10 at 6 34 26 PM](https://user-images.githubusercontent.com/43314053/224323147-0686bba0-2b26-4576-a472-369107ab250b.png)
",health added worker container,issue,negative,neutral,neutral,neutral,neutral,neutral
1463775811,"Launching  Hagrid through command line through Orchestra by python API
![Screenshot 2023-03-10 at 6 33 42 PM](https://user-images.githubusercontent.com/43314053/224323016-0e051f44-3d30-4d66-a85c-b994b37ca9f8.png)
",command line orchestra python,issue,negative,neutral,neutral,neutral,neutral,neutral
1461875029,"Yup currently `validate_partition_keys` checks that each of the key in `__attr_unique__` has to be unique.
There are 2 potential fixes here, either changing the behavior of `validate_partition_keys` to check that the combination of the keys in `__attr_unique__` is unique, or move `user_verify_key` out of `__attr_unique__`. @madhavajay what do you think?",currently key unique potential either behavior check combination unique move think,issue,negative,positive,positive,positive,positive,positive
1461131420,"Hi,
Please let me know if this issue is resolved or not. I am facing similar issue : 
federated_train_loader = syft.FederatedDataLoader(
    datasets.MNIST('../data', train=True, download=True,
                   transform=transforms.Compose([
                       transforms.ToTensor(),
                       transforms.Normalize((0.1307,), (0.3081,))
                   ]))
    .federate((CS1, CS2)),
    batch_size=args['batch_size'], shuffle=True)

This is the error I am seeing : 
AttributeError: module 'syft' has no attribute 'FederatedDataLoader'",hi please let know issue resolved facing similar issue error seeing module attribute,issue,negative,neutral,neutral,neutral,neutral,neutral
1461085111,"@dmpiergiacomo thanks for the bug report, the Data Subject system has changed a few times and this is no doubt the cause of the issue. Since L2 notebooks werent tested in CI it must have been missed. We have a more advanced Data Subject Registry in our new release which does not have this problem, it should be available at the end of Q1 along with tested notebooks on how to use it. :) Thanks for your patience.",thanks bug report data subject system time doubt cause issue since werent tested must advanced data subject registry new release problem available end along tested use thanks patience,issue,negative,positive,positive,positive,positive,positive
1459991939,"It seems that notebooks L3 and L5 (L5 being the one where `.publish()` and `.get()` are used) both work. I don't plan do debug further this issue at the moment, but I share below some observations.

It seems that when the DataSubject name is something like `""Country 0""` everything works fine, but when it is simply `""0""` you receive the error Exception: `Unable to Get Object with ID <UID: bbace75459dc4065a8c0b0ed9dbdf0d7> from store. Possible dangling Pointer. can only concatenate str (not ""Int"") to str`. Perhaps the `""0""` is converted into the integer `0` somewhere in one of the calls.",one used work plan issue moment share name something like country everything work fine simply receive error exception unable get object id store possible dangling pointer concatenate perhaps converted integer somewhere one,issue,negative,negative,neutral,neutral,negative,negative
1459986809,"Following the suggestion of @madhavajay on Slack I ran `docker logs -f yourdomain-celeryworker-1` to inspect the logs of the celeryworker container. Below te output:
```
[2023-03-06 18:36:32,171: INFO/MainProcess] Task grid.worker.msg_without_reply[a879cf0d-b805-430a-84e0-0fb3e34b1272] received
[2023-03-06 18:36:32,187: WARNING/MainProcess] Publish_id: 
[2023-03-06 18:36:32,187: WARNING/MainProcess]  
[2023-03-06 18:36:32,187: WARNING/MainProcess] <UID: bbace75459dc4065a8c0b0ed9dbdf0d7>
[2023-03-06 18:36:32,248: WARNING/MainProcess] Failed to get data from proxy object can only concatenate str (not ""Int"") to str.
[2023-03-06T18:36:32.248775+0000][CRITICAL][logger]][89] Unable to Get Object with ID <UID: bbace75459dc4065a8c0b0ed9dbdf0d7> from store. Possible dangling Pointer. can only concatenate str (not ""Int"") to str
[2023-03-06 18:36:32,277: ERROR/MainProcess] Task grid.worker.msg_without_reply[a879cf0d-b805-430a-84e0-0fb3e34b1272] raised unexpected: Exception('Unable to Get Object with ID <UID: bbace75459dc4065a8c0b0ed9dbdf0d7> from store. Possible dangling Pointer. can only concatenate str (not ""Int"") to str')
Traceback (most recent call last):
  File ""/app/syft/src/syft/core/node/common/node_service/publish/publish_service.py"", line 41, in process
    publish_object = retrieve_object(
  File ""/app/syft/src/syft/core/node/common/action/greenlets_switch.py"", line 20, in retrieve_object
    store_obj = node.store.get_or_none(key=id_at_location, proxy_only=proxy_only)
  File ""/app/syft/src/syft/core/node/common/node_manager/redis_store.py"", line 48, in get_or_none
    return self.get(key, proxy_only)
  File ""/app/syft/src/syft/core/node/common/node_manager/redis_store.py"", line 110, in get
    obj = self.resolve_proxy_object(obj=obj)
  File ""/app/syft/src/syft/core/node/common/node_manager/redis_store.py"", line 92, in resolve_proxy_object
    obj = obj.get_s3_data(settings=self.settings)
  File ""/app/syft/src/syft/core/store/proxy_dataset.py"", line 106, in get_s3_data
    raise e
  File ""/app/syft/src/syft/core/store/proxy_dataset.py"", line 99, in get_s3_data
    response = s3_client.get_object(Bucket=self.node_id.no_dash, Key=self.name)
  File ""/app/syft/src/syft/core/store/proxy_dataset.py"", line 87, in name
    return self.dataset_name + ""/"" + self.asset_name
TypeError: can only concatenate str (not ""Int"") to str

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/root/.local/lib/python3.10/site-packages/celery/app/trace.py"", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File ""/root/.local/lib/python3.10/site-packages/celery/app/trace.py"", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File ""/app/grid/worker.py"", line 32, in msg_without_reply
    raise e
  File ""/app/grid/worker.py"", line 30, in msg_without_reply
    node.recv_immediate_msg_without_reply(msg=obj_msg)
  File ""/app/syft/src/syft/core/node/common/node.py"", line 554, in recv_immediate_msg_without_reply
    self.process_message(msg=msg, router=self.immediate_msg_without_reply_router)
  File ""/app/syft/src/syft/core/node/common/node.py"", line 668, in process_message
    raise e
  File ""/app/syft/src/syft/core/node/common/node.py"", line 644, in process_message
    result = service.process(
  File ""/app/syft/src/syft/core/node/common/node_service/publish/publish_service.py"", line 76, in process
    traceback_and_raise(Exception(log))
  File ""/app/syft/src/syft/logger.py"", line 70, in traceback_and_raise
    raise e
Exception: Unable to Get Object with ID <UID: bbace75459dc4065a8c0b0ed9dbdf0d7> from store. Possible dangling Pointer. can only concatenate str (not ""Int"") to str
```

The interesting bit here is the following: `can only concatenate str (not ""Int"") to st`.",following suggestion slack ran docker inspect container te output task received get data proxy object concatenate critical logger unable get object id store possible dangling pointer concatenate task raised unexpected exception get object id store possible dangling pointer concatenate recent call last file line process file line file line return key file line get file line file line raise file line response file line name return concatenate handling exception another exception recent call last file line fun file line return file line raise file line file line file line raise file line result file line process exception log file line raise exception unable get object id store possible dangling pointer concatenate interesting bit following concatenate st,issue,positive,negative,neutral,neutral,negative,negative
1455307738,Dev frontend wont build at the moment so im merging this so we can get CI up and running again.,dev wont build moment get running,issue,negative,neutral,neutral,neutral,neutral,neutral
1453487088,"Hi,

Unfortunately when I code with syft version 0.7 I cannot use hook or torch hook, as I understood in the new version some ways of coding have been changed, but unfortunately I could not find any documentations helping me to understand how do I have to code.
I just saw that I must use only VirtualMachine but further I encounter again some problems because of changes.
Let me know please from where can I see how do I have to code in syft version 0.7

Thanks",hi unfortunately code version use hook torch hook understood new version way unfortunately could find helping understand code saw must use encounter let know please see code version thanks,issue,negative,negative,negative,negative,negative,negative
1452760456,"> When using pysyft version 0.7, I faced the same problem. I was excited when I first encountered the concept of federated learning, but every time I tried to run the code, I became frustrated with the disconnect between the tutorials and the code, as well as the outdated code version.

So sorry for the frustration. We've had to take several steps backwards to ultimately find the right path forward. I hope you'll find the wait was worth it but I suppose we won't know that until it's released. Thank you for your patience and we'll increase our vigilence w.r.t deleting old documentation.",version faced problem excited first concept learning every time tried run code disconnect code well outdated code version sorry frustration take several backwards ultimately find right path forward hope find wait worth suppose wo know thank patience increase old documentation,issue,positive,positive,neutral,neutral,positive,positive
1452759884,UPDATE: We've made some tweaks to final scope and it looks likely there'll be a FL example in 0.8. Please give us a couple weeks to work out the kinks.,update made final scope likely example please give u couple work,issue,negative,neutral,neutral,neutral,neutral,neutral
1451423710,"When using pysyft version 0.7, I faced the same problem. I was excited when I first encountered the concept of federated learning, but every time I tried to run the code, I became frustrated with the disconnect between the tutorials and the code, as well as the outdated code version. ",version faced problem excited first concept learning every time tried run code disconnect code well outdated code version,issue,negative,positive,neutral,neutral,positive,positive
1450859043,"Hi @bussfromspace - we're working very hard to bring FL back on the new foundation. It will be possible in 0.8 (close to dev complete, testing happening in march for a release at the end of the month) but a bit inconvenient. It's looking like 0.9 will have robust support for FL.",hi working hard bring back new foundation possible close dev complete testing happening march release end month bit inconvenient looking like robust support,issue,positive,negative,negative,negative,negative,negative
1449282726,Lets leave this off for now just because we dont want to make the library heavier. We should think about some kind of helper code in syft which can possibly load some of these optional libraries in a `try catch` and then use bytes for the serialization of images for now so that these libraries are needed just to send the data.,leave dont want make library think kind helper code possibly load optional try catch use serialization send data,issue,positive,positive,positive,positive,positive,positive
1447830336," this triggers the error:

AttributeError: 'DataLoader' object has no attribute 'federated'

how do you resolve it?",error object attribute resolve,issue,negative,neutral,neutral,neutral,neutral,neutral
1434383104,"@TwsThomas You can go to the folder where Syft is located (if you are using hagrid quickstart you should look for the .hagrid folder) and change the function that I mentioned. 

For example in Windows:

You should go to ```C:\Users\<your_username>\.hagrid\quickstart\.venv\Lib\site-packages\syft\core\adp\data_subject.py```

And modify that file.",go folder look folder change function example go modify file,issue,negative,neutral,neutral,neutral,neutral,neutral
1434365051,"Hello, 

I have the same issue when following the guide [https://openmined.github.io/PySyft/guides/data-owner/01-upload-data.html](https://github.com/OpenMined/PySyft/issues/url)

However, I don't understand how I could use the workaround. Should I need to re-build pysyft from source with this modification? And how could I do that?",hello issue following guide however understand could use need source modification could,issue,negative,neutral,neutral,neutral,neutral,neutral
1434141494,switch to `eval` works. anw I've applied all the changes here to #7330 as well so gonna just close this.,switch work applied well gon na close,issue,negative,neutral,neutral,neutral,neutral,neutral
1433637275,@kiendang if locals() works thats fine. I had trouble getting the result to evaluate so what ever works.,work thats fine trouble getting result evaluate ever work,issue,negative,positive,positive,positive,positive,positive
1431361236,"I have solved it by creating a new Conda environment!
Thanks anyway.",new environment thanks anyway,issue,negative,positive,positive,positive,positive,positive
1430286603,"> Hi @friendsAI the recent 0.3.x release is a complete rebuild of PySyft and as such there is no longer a torch hook. I apologise that this isn't 100% clear on the new documentation, and we have several tickets already created to address this. We are aware that the two releases are not identical in functionality however we have some very exciting things coming which are only possible with the new 0.3.x architecture so bear with us. Some of the new API is already documented on our Duet example README.md here: https://github.com/OpenMined/PySyft/tree/dev/examples/duet

what should be written in the code to fix this error",hi recent release complete rebuild longer torch hook clear new documentation several already address aware two identical functionality however exciting coming possible new architecture bear u new already duet example written code fix error,issue,negative,positive,positive,positive,positive,positive
1425181599,"@AndreMPCosta, yes the API changed slightly right before release and we haven't been able to update the docs. Sorry about this, i'm glad you were able to fix it. We have a small patch for `0.7` coming and will try to fix this up at the same time.",yes slightly right release able update sorry glad able fix small patch coming try fix time,issue,positive,positive,positive,positive,positive,positive
1424486980,"@madhavajay , any suggestions what would be the best way to fix the circular imports (pointer <-> tensor)?",would best way fix circular pointer tensor,issue,positive,positive,positive,positive,positive,positive
1424485426,"There is a draft PR at https://github.com/OpenMined/PySyft/pull/7300. I will continue work on that again next week, latest on Friday. 
TODO:
* fix circular imports
* fix my local dev env to be able to run the tests",draft continue work next week latest fix circular fix local dev able run,issue,negative,positive,positive,positive,positive,positive
1418090772,"Hi @madhavajay, I am unable to find the above code. is this still open?",hi unable find code still open,issue,negative,negative,negative,negative,negative,negative
1418001940,I would like to work on this issue on Thursday 2023-2-9. Discussed picking this issue with @madhavajay in Slack.,would like work issue issue slack,issue,negative,neutral,neutral,neutral,neutral,neutral
1413088298,"> Great work! 🙌🏽
> 
> I have enabled the new tests and fixed a few small issues which opened up some more code to the serde and quickly fixed that as well.
> 
> For the defaultdict that was a pretty solid start. I changed it to propagate the type as well and now i think it works for all cases.
> 
> Excellent work.

@madhavajay  Thanks. Your fix for defaultdicts is definitely much more robust. Amazing work.",great work new fixed small code quickly fixed well pretty solid start propagate type well think work excellent work thanks fix definitely much robust amazing work,issue,positive,positive,positive,positive,positive,positive
1412162993,"@madhavajay @shubham3121 Regarding the fixing of SerDe for defaultdict, please review it and let me know if this fix is alright. If there's a better way to do this, please do let me know and I will modify accordingly. Thanks.

I've also added a couple of TODOs regarding the potential pitfalls. Please do check them.",regarding fixing please review let know fix alright better way please let know modify accordingly thanks also added couple regarding potential please check,issue,positive,positive,positive,positive,positive,positive
1409582999,@the-elancier this looks great. Lets discuss the TODOs when you have a moment. I think if we can just adjust everything so that it works for the simplest case we can probably merge it for now.,great discus moment think adjust everything work case probably merge,issue,positive,positive,positive,positive,positive,positive
1409561600,"@YBCS thanks for the PR, and sorry about the review. I think that it would be better if this was configurable as the current functionality of getting the passwords quickly while deploying many nodes is being relied upon.",thanks sorry review think would better current functionality getting quickly many upon,issue,positive,positive,positive,positive,positive,positive
1409559784,"@pcsoni007 thats great you got it to work.
There is actually a class you can subclass to implement your own handlers here:
https://github.com/OpenMined/PySyft/blob/syft_0.5.0/packages/syft/src/syft/grid/duet/exchange_ids.py

You will notice that users manual input default version (OpenGridTokenManualInputExchanger) is actually a class which implements the same interface.

I will close this PR since this can be achieved using the parent class as needed.",thats great got work actually class subclass implement notice manual input default version actually class interface close since parent class,issue,positive,positive,positive,positive,positive,positive
1407035804,@kiendang great catch and interesting to learn more about the signature api.,great catch interesting learn signature,issue,positive,positive,positive,positive,positive,positive
1406191737,"Hi Madhava, I just updated the branch to point to the right one and resolved the merge conflict.",hi branch point right one resolved merge conflict,issue,negative,positive,positive,positive,positive,positive
1406087773,@madhavajay this is up for review - please take a look at it. Will push another commit to fix the linting issue,review please take look push another commit fix issue,issue,positive,neutral,neutral,neutral,neutral,neutral
1383142870,"> 



> @thormacy, we should import syft rather than import PySyft-master/syft.
> 
> There is something wrong with the original example, and we need some modifies.
> 
> Copy the websockets_mnist in your Desktop or other folder (make sure it is not included by PySyft-master)
> 
> And the folder files is:
> 
> ```
> run_websocket_client.py
> run_websocket_server.py
> start_websocket_servers.py
> ```
> 
> the run_websocket_server.py is copied from the PySyft-master/run_websocket_server.py.
> 
> The start_websocket_servers.py should also be modified as following:
> 
> ```
> import subprocess
> import sys
> from pathlib import Path
> 
> python = Path(sys.executable).name
> 
> FILE_PATH = './run_websocket_server.py'
> 
> call_alice = [python, FILE_PATH, ""--port"", ""8777"", ""--id"", ""alice""]
> 
> call_bob = [python, FILE_PATH, ""--port"", ""8778"", ""--id"", ""bob""]
> 
> call_charlie = [python, FILE_PATH, ""--port"", ""8779"", ""--id"", ""charlie""]
> 
> 
> print(""Starting server for Alice"")
> subprocess.Popen(call_alice)
> 
> print(""Starting server for Bob"")
> subprocess.Popen(call_bob)
> 
> print(""Starting server for Charlie"")
> subprocess.Popen(call_charlie)
> ```
> 
> Then, you can run:
> 
> ```
> python start_websocket_servers.py
> python run_websocket_client.py
> ```

hello, I can not find run_websocket_server.py， can you give me?",import rather import something wrong original example need copy folder make sure included folder copied also following import import import path python path python port id python port id bob python port id print starting server print starting server bob print starting server run python python hello find give,issue,negative,positive,neutral,neutral,positive,positive
1382634924,"@gmuraru The error might be due to a older commit ,Could you kindly try it on the latest commit",error might due older commit could kindly try latest commit,issue,positive,positive,positive,positive,positive,positive
1382145082,"In the Enclaves.ipynb there is at one point.
`sy.create_deploymnet` where one of the parameters is `client` and I think it should be `oblv_client`

Also, in the same notebook, I tried to run `bob_ds.oblv.check_connection(depl)` but they are throwing the following errors:
```
TypeError: SyftOblvClient.__init__() missing 2 required positional arguments: 'cookies' and 'headers'
```",one point one client think also notebook tried run throwing following missing positional,issue,negative,negative,neutral,neutral,negative,negative
1381514181,"> @bitsofsteve, found that the Click version on the azure machines is 7.0.0 which does not support `context_settings={""show_default"": True}` as arguments on the `click.command` method. Versions > 7.1.0 support this argument. Upgrading the version of click should fix this. ![Screenshot from 2023-01-13 14-18-55](https://user-images.githubusercontent.com/11032835/212277721-e54cd659-ba3c-4955-bf60-efe1ed7e36c4.png)

Yeah @shubham3121 , I tried pinning it, but it still wouldn't install a click version > 7.0.0",found click version azure support true method support argument version click fix yeah tried pinning still would install click version,issue,positive,positive,positive,positive,positive,positive
1381489157,"@bitsofsteve, found that the Click version on the azure machines is 7.0.0 which does not support `context_settings={""show_default"": True}` as arguments on the `click.command` method. Versions > 7.1.0 support this argument. Upgrading the version of click should fix this.
![Screenshot from 2023-01-13 14-18-55](https://user-images.githubusercontent.com/11032835/212277721-e54cd659-ba3c-4955-bf60-efe1ed7e36c4.png)
",found click version azure support true method support argument version click fix,issue,positive,positive,positive,positive,positive,positive
1376748828,"> Hello @avdvg , could you share the snippet of the code, which produced this error ? On the Error part, you would have to submit a request on the MPCTensor to view the result. assume `mpc_tensor` was the resultant variable We would have to call mpc_tensor.request(reason=""Input a valid reason to view the result of the computation"")
> 
> This request would then be approved by the Data Owner

I call mpc_tensor.request(reason=""Input a valid reason to view the result of the computation""). Then i logged in to the administrator, passed the request, and successfully printed the data. Thank you very much for your help.",hello could share snippet code produced error error part would submit request view result assume resultant variable would call input valid reason view result computation request would data owner call input valid reason view result computation logged administrator request successfully printed data thank much help,issue,positive,positive,positive,positive,positive,positive
1376741384,"> Hello @avdvg , could you share the snippet of the code, which produced this error ? On the Error part, you would have to submit a request on the MPCTensor to view the result. assume `mpc_tensor` was the resultant variable We would have to call mpc_tensor.request(reason=""Input a valid reason to view the result of the computation"")
> 
> This request would then be approved by the Data Owner

thanks @rasswanth-s, when i run ""print(f""Reconstruct\n{mpc_tensor.reconstruct()}"")"" producted that error:

the code is:

import syft as sy
import torch
import numpy as np
from syft.core.tensor.smpc.mpc_tensor import MPCTensor
sy.logger.remove()

ravenclaw = sy.login(email=""122@openmined.org"", password=""122"", port=8080)
(..... 4 domains)

parties = [gryffindor, slytherin, hufflepuff, ravenclaw]
value_secret = gryffindor.syft.core.tensor.tensor.Tensor(np.array([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]], dtype=np.int64))
mpc_tensor = MPCTensor(secret=value_secret, shape=(2,5), parties=parties)
print(f""Reconstruct\n{mpc_tensor.reconstruct()}"") 

i don't know how to read the mpc_tensor data for data scientist, we look forward to your reply!",hello could share snippet code produced error error part would submit request view result assume resultant variable would call input valid reason view result computation request would data owner thanks run print producted error code import import torch import import print know read data data scientist look forward reply,issue,negative,positive,positive,positive,positive,positive
1376678434,"Hello @avdvg , could you share the snippet of the code, which produced this error ?
On the Error part, you would have to submit a request on the MPCTensor to view the  result.
assume `mpc_tensor` was the resultant variable
We would have to call
mpc_tensor.request(reason=""Input a valid reason to view the result of the computation"")

This request would then be approved by the Data Owner 
",hello could share snippet code produced error error part would submit request view result assume resultant variable would call input valid reason view result computation request would data owner,issue,negative,neutral,neutral,neutral,neutral,neutral
1374656947,"Hi @iamtrask, I am new to open source contributions and would like to pick this issue. ",hi new open source would like pick issue,issue,negative,positive,neutral,neutral,positive,positive
1368808208,Your Syft version is 0.6.0. I'm not sure whether FederatedDataLoader is present in your version. Which tutorial are you following?,version sure whether present version tutorial following,issue,negative,positive,positive,positive,positive,positive
1367751317,"Hey @shubham3121 sorry for the delay, made the requested changes uniformly across the notebook as well as the rst doc page! PTAL

cc: @IrinaMBejan ",hey sorry delay made uniformly across notebook well doc page,issue,negative,negative,negative,negative,negative,negative
1366577260,"> 

Thanks for taking a look at my PR. Appreciate it.",thanks taking look appreciate,issue,positive,positive,positive,positive,positive,positive
1366506683,Good work @the-elancier! I know this is WIP but just dropped a small comment there.,good work know small comment,issue,negative,positive,positive,positive,positive,positive
1365173397,"The question/problem is still open. I would really appreciate if you can comment on how to fix this issue.

Best wishes,",still open would really appreciate comment fix issue best,issue,positive,positive,positive,positive,positive,positive
1359292163,"
Hello @shubham3121 @madhavajay ,
I need clarifications regarding some things (I have added TODO comments in the code as well regarding some of these):
1. Is it okay if we deploy the EC2 instance in the default VPC & subnet? Or should we ask for this information from the user as well? (Right now, we're deploying in the default VPC)
2. We're using the following AMI (Image): Amazon Linux 2 AMI (HVM) - Kernel 5.10, SSD Volume Type (ami-0b0dcb5067f052a63). Is this alright, or should we use some other AMI (perhaps Ubuntu?)?
3. Should we attach any tags to the EC2 instance?
4. When creating a key-pair, we're asking for a path to store the created one. Do you think we should check if the path ends with .pem, and if not, append '.pem' to the file path?

Also, please note:
I have added the code for provisioning the required resources on the deployed instance using Ansible. However, I haven't tested that portion yet as we would require costlier instances with more memory and storage. I am currently using t2.micro to test on the free-tier. @shubham3121 said I could get help from someone in the team for testing this portion of the code. 

Please feel free to comment/answer whenever you find time.

Thank you.  

",hello need regarding added code well regarding deploy instance default ask information user well right default following ami image ami kernel volume type alright use ami perhaps attach instance path store one think check path append file path also please note added code instance however tested portion yet would require memory storage currently test said could get help someone team testing portion code please feel free whenever find time thank,issue,positive,positive,positive,positive,positive,positive
1358424761,"@shubham3121 great work, I tested it locally and it seems to work. 🙌🏽",great work tested locally work,issue,positive,positive,positive,positive,positive,positive
1357707257,Oooff @shubham3121 good catch. I guess we need to add this to a test?,good catch guess need add test,issue,negative,positive,positive,positive,positive,positive
1354581602,"**Data Scientist Explore a dataset tutorial**
Added comments here:
https://app.reviewnb.com/OpenMined/PySyft/pull/7045/",data scientist explore tutorial added,issue,negative,neutral,neutral,neutral,neutral,neutral
1354424211,"Data Scientist Search for Datasets tutorial:
Left comments in the PR: https://github.com/OpenMined/PySyft/pull/6871
",data scientist search tutorial left,issue,negative,neutral,neutral,neutral,neutral,neutral
1354406704,"Data Scientist Connect to Domain tutorial:
Left comments in the PR:
https://github.com/OpenMined/PySyft/pull/7120

@Kiaka007, yes it is currently possible to register to a domain if the user has the URL to the domain. Although, they will have a zero privacy budget allocated to them.
",data scientist connect domain tutorial left yes currently possible register domain user domain although zero privacy budget,issue,negative,neutral,neutral,neutral,neutral,neutral
1352177735,"# Feedback on quickstart docs

## Data Scientist Explore a dataset tutorial:
**Image**
You can use: https://github.com/OpenMined/design/blob/assets/diagrams/exploring%20a%20dataset.png

## Step 8 Actually querying data
If you actually want to query data, you could do it by spending some of your privacy budget. This happens with the following 2 commands:

* .publish() uses your privacy budget limit approved by the data owner to query the actual data and produce a noised result that does not compromise the original dataset. The amount of accuracy and therefore the amount of privacy budget you spend here is determined by the sigma you define. Sigma in this case indicates the level of noise added to the final result; whether you want the range of your answer to be within an X estimated sigma of the true answer.
* get() to access the contents of the published_result pointer created above.
* **It is important to note that if you do not have enough privacy budget to receive a result with the specified sigma then you will instead receive a very noisy result. This is an indication that you need to request more privacy budget from the domain owner.**

## Step 10 View our final privacy budget
As you can see, your privacy budget got reduced. It is because we used the .publsh(sigma=x) and .get() methods to actually query the dataset. ~~Also, if you look deeply, your privacy budget used up is equal to the amount you used for the sigma!~~

**Note: I X'ed out the above because that statement is not true. The amount of sigma specified is not the same thing as the privacy budget used and in general the two values do not tend to equate to be the same value. Sigma is tied to the amount of noise added. I believe you can think of it in terms of standard statistics sigma as in sigma=1 indicates that I want my answer to be within 1 standard deviation of the true answer.
",feedback data scientist explore tutorial image use step actually querying data actually want query data could spending privacy budget following privacy budget limit data owner query actual data produce result compromise original amount accuracy therefore amount privacy budget spend determined sigma define sigma case level noise added final result whether want range answer within sigma true answer get access content pointer important note enough privacy budget receive result sigma instead receive noisy result indication need request privacy budget domain owner step view final privacy budget see privacy budget got reduced used actually query look deeply privacy budget used equal amount used sigma note statement true amount sigma thing privacy budget used general two tend equate value sigma tied amount noise added believe think standard statistic sigma want answer within standard deviation true answer,issue,positive,positive,positive,positive,positive,positive
1352141014,"# Feedback on quickstart docs

## Data Scientist Search for Datasets tutorial:
In the last tutorial, you learned as a Data Scientist [:doc:`How to Connect to a Domain Server <00-deploy-domain>`](https://github.com/OpenMined/PySyft/blob/8b049a5ed891f77016b1cac669a9f5be84175ee5/docs/source/guides/data-scientist/01-search-for-datasets.rst#id1) which allowed us to connect to our organization’s domain server.

Once connected to the domain, the first thing that we would want to do as a data scientist, is look for available datasets listed on the domain. Today's tutorial will be going over how we go about doing that.

### Step 2 Login to the Domain
* Let's login to our Domain with the credentials provided to us by the domain owner. If there is no domain or specific domain owner for you to try these steps out on then, you can create a domain node locally for yourself and act as a domain owner by following the tutorials starting here: [data-owner/00-deploy-domain](https://github.com/OpenMined/PySyft/blob/8b049a5ed891f77016b1cac669a9f5be84175ee5/docs/source/guides/data-owner/00-deploy-domain.html).

### Step 3 Search for datasets on the domain
**Note:**
Might want to add some descriptions as to what the different columns in the dataset list table mean. Like shape and assets etc.",feedback data scientist search tutorial last tutorial learned data scientist doc connect domain server u connect organization domain server connected domain first thing would want data scientist look available listed domain today tutorial going go step login domain let login domain provided u domain owner domain specific domain owner try create domain node locally act domain owner following starting step search domain note might want add different list table mean like shape asset,issue,positive,positive,neutral,neutral,positive,positive
1352124831,"# Feedback on quickstart docs

## Data Scientist  Connect to Domain tutorial:
* Data Scientists are end users who want to perform computations or answer specific questions using the dataset(s) of one or more data owners. The very first thing Data Scientists have to do in order to submit their requests is login and connect to the Domain Server that hosts the data they would like to make requests off of or to connect to a network by which they can search for different datasets. Today's tutorial will show you how you as a Data Scientist can connect to an organization's domain server using PySyft.
* For connecting to a Domain Server, we will use the login credentials assigned to us by the Domain Owner. By default, we as Data Scientists have the lowest level of permission to access the data (which means data is highly private) and will be assigned a Privacy Budget of 0.
* Overview of this tutorial:

- Obtain the Login Credentials
- Login to your Server
- Explore some useful starting commands (we could show how some useful starting commands work like listing datasets on the domain etc.)

**Note:
PyGrid Admin (the UI) is only meant to be used by domain or data owners so a data scientist would never login to the domain node via the UI.**


### Step 1 Obtain Login Credentials
* To utilize the privacy-enhancing features and play around with your privacy budget, as a Data Scientist you must first get your login credentials from the domain owner. What you will need to login to the domain server is the following information:
* **email**
* **password**
* **URL of the domain**
* **port of the domain**

**Note:
I am not sure if the commands in the cell of the current notebook are possible for a data scientist to use in syft. I need input from @shubham3121  As far as I know Data Scientists cannot just auto register themselves to a domain node.**

### Step 2 Login to the Domain as a Data Scientist
* Once you have the above information you can open a Jupyter Notebook and begin logging into the domain server.
* To start you will need to install syft 
* ``` import syft as sy ```
* Then you can provide your login credentials by typing:
* ``` domain = sy.login(email=""____"", password=""____"", url=""____"",port=8081) ```

### Step 3 Exploring a Domain Server
**Note:
It would be a good opportunity here to show some useful beginning commands for a data scientist like listing the datasets on this domain. @shubham3121 will have good ideas on what some starter ones could be.**

**Note:
Adjusting permissions and setting roles is not something a data scientist user does. It is something a domain owner does to create and manage users of the domain. So we should delete any steps here that point to the UI and that point to adjusting permissions.**
",feedback data scientist connect domain tutorial data end want perform answer specific one data first thing data order submit login connect domain server data would like make connect network search different today tutorial show data scientist connect organization domain server domain server use login assigned u domain owner default data level permission access data data highly private assigned privacy budget overview tutorial obtain login login server explore useful starting could show useful starting work like listing domain note meant used domain data data scientist would never login domain node via step obtain login utilize play around privacy budget data scientist must first get login domain owner need login domain server following information password domain port domain note sure cell current notebook possible data scientist use need input far know data auto register domain node step login domain data scientist information open notebook begin logging domain server start need install import provide login domain step exploring domain server note would good opportunity show useful beginning data scientist like listing domain good starter could note setting something data scientist user something domain owner create manage domain delete point point,issue,positive,positive,positive,positive,positive,positive
1349076732,"Hi Shubham,

This is amazing work! Feel free to assign ownership to trask@openmined.org.

Merging it :).
",hi amazing work feel free assign ownership,issue,positive,positive,positive,positive,positive,positive
1345836527,Sadly I'm not aware of any frameworks which are as of yet capable of doing this. :),sadly aware yet capable,issue,negative,positive,positive,positive,positive,positive
1345371246,I noticed you also even improved the docs for the previous change where we set --tail=False by default. Fantastic.,also even previous change set default fantastic,issue,positive,positive,positive,positive,positive,positive
1345371100,Love these improvements and fantastic job digging into the various places where this would make our documentation out of date. Really well done.,love fantastic job digging various would make documentation date really well done,issue,positive,positive,positive,positive,positive,positive
1340496143,"Hi @madhavajay,
I would like to work on this issue.",hi would like work issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1340405201,"@tcp is this hard to fix, seems unrelated to the actual backend.",hard fix unrelated actual,issue,negative,negative,negative,negative,negative,negative
1340402276,"The react error is actually unrelated and happens when we refresh but we can address it separately if we want to keep using react. I have moved that to a seperate issue:
https://github.com/OpenMined/PySyft/issues/7155",react error actually unrelated refresh address separately want keep react issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1338903049,Thanks @letv3! Looks like we needed a specific version of `tensorflow-federated` due to dependency conflicts and that module not existing in some versions. I hope this one works for you.,thanks like specific version due dependency module hope one work,issue,positive,positive,neutral,neutral,positive,positive
1338142289,"Hey @teo-milea and @madhavajay I figured out the problem and created new PR here https://github.com/OpenMined/PySyft/pull/7146 
 
Seems like project maintainers can not be allowed edit  the forks created inside organisation. So I created a new fork and pushed my commit there. Strange problem indeed.

So I am closing this PR, please review the new one.
Thanks for understanding.",hey figured problem new like project edit inside new fork commit strange problem indeed please review new one thanks understanding,issue,negative,positive,positive,positive,positive,positive
1336784608,"Totally agree. I think its worth doing some planning around rebuilding hagrid from scratch so that its much cleaner and more consistent and modular.

I think a new python cli code base could be started and the functionality we want ported over pretty quickly once we include the desired capabilities.

Lets discuss this post 0.7.",totally agree think worth around scratch much cleaner consistent modular think new python code base could functionality want ported pretty quickly include desired discus post,issue,positive,positive,neutral,neutral,positive,positive
1334663363,"@IonesioJunior I tweaked this a bit to use an nginx static config for the network node so we have no code now but can re-use the same frontend build and container as domains for future.

The tricky part was getting it to respond to the `NODE_TYPE` env variable but it seems as though nginx now supports this automatically on startup if you use their `.template` files.

Until we have a frontend for the network, network dev mode will simply use the production container which itself has an nginx network config.",bit use static network node code build container future tricky part getting respond variable though automatically use network network dev mode simply use production container network,issue,negative,positive,positive,positive,positive,positive
1333998669,Really nice work - also @IonesioJunior i love that design decision you mentioned about calling the exception immediately if the pointer isn't there. Well done!,really nice work also love design decision calling exception immediately pointer well done,issue,positive,positive,positive,positive,positive,positive
1333935673,"I added a check inside the `compute_min_max` function of the lazyrepeatarrays which will help us detect NaN and Infs on the data scientist's side and raise Exceptions early, on the TensorPointers themselves :+1: 

This will also help #6950 ",added check inside function help u detect nan data scientist side raise early also help,issue,positive,positive,neutral,neutral,positive,positive
1333476846,"As discussed, on publishing bool type results (e.g. mask = values > 100) we will convert the booleans to ints, add noise, and publish normally (so that flow is not broken). Also, we will warn the client that publishing bool values maybe provide inconsistent results. cc @IshanMi ",bool type mask convert add noise publish normally flow broken also warn client bool maybe provide inconsistent,issue,negative,negative,negative,negative,negative,negative
1333269847,@kirkdemeroukas the PR I just merged should mean that .get will auto retry for 60 seconds by default. We will be doing more to provide information to the users on top of this soon.,mean auto retry default provide information top soon,issue,negative,positive,neutral,neutral,positive,positive
1333247427,"Are we sure this is not an issue. If you follow the output from the function backwards it appears that the value never gets mutated.

Here is where `value` gets set at the start of `publish`.
line 78: 
```python
if isinstance(tensor.child, FixedPrecisionTensor):
    # Incase SMPC is involved, there will be an FPT in the chain to account for
    value = tensor.child.decode()
else:
    value = tensor.child

while isinstance(value, PassthroughTensor):
    # TODO: Ask Rasswanth why this check is necessary
    # ATTENTION: we do the same unboxing below with root_child
    # is this still needed to be done twice?
    value = value.child
```

After that the variable never changes.
But inside `line 227: if has_budget:`

`line 228: original_output = value`
`line 268: return original_output + noise`

The part which mutates the filtered value is:
`line 370: tensor = tensor.swap_state(filtered_sourcetree)`

In the old code it used to have:
```
original_output = tensor.child
```

But since the final output is now from `value` not `tensor.child` it doesn't change.

Do we need to set `value = tensor.child` after `tensor = tensor.swap_state(filtered_sourcetree)`?

And, even if the mutation is happening somehow implicitly internally with `jax` could this be problematic for reading the code and future refactors?

",sure issue follow output function backwards value never value set start publish line python incase involved chain account value else value value ask check necessary attention still done twice value variable never inside line line value line return noise part value line tensor old code used since final output value change need set value tensor even mutation happening somehow implicitly internally could problematic reading code future,issue,positive,positive,neutral,neutral,positive,positive
1333217719,"> > Launching a domain node using `hagrid launch --tag=latest` launched a domain node with Syft 0.6.0- could this be the cause of the issue? ![image](https://user-images.githubusercontent.com/32711264/203352984-c91846a3-4f91-421c-b260-ed7a60c61874.png)
> 
> @IshanMi I believe we've confirmed that this was not the issue. I was planning to reproduce on dev today but dev isn't building. However, running with --tag=latest still produces the same issue.

@iamtrask  Now that `dev` is working on your machine can you see if this can be replicated?",domain node launch domain node could cause issue image believe confirmed issue reproduce dev today dev building however running still issue dev working machine see replicated,issue,negative,positive,positive,positive,positive,positive
1332918967,Recloning fixed the issue - looks like I had some untracked changes in my files. ,fixed issue like untracked,issue,negative,positive,neutral,neutral,positive,positive
1332915262,"Recloning now i've got
```
Launching a PyGrid Domain node on port 8081!

  - NAME: magical_larochelle
  - RELEASE: development
  - TYPE: domain
  - DOCKER_TAG: 0.7.0-beta.59-dev
  - GIT_HASH: c30667ea78e29a0f026b779e95d8f8c2f5222970
  - HAGRID_VERSION: 0.2.113-dev
  - HAGRID_REPO_SHA: c30667ea78e29a0f026b779e95d8f8c2f5222970
  - PORT: 8081
  - DOCKER COMPOSE: v2.12.2
```",got domain node port name release development type domain port docker compose,issue,negative,neutral,neutral,neutral,neutral,neutral
1332900539,"Here's a clue - when my dev builds syft it installs this versoin of PySyft ""syft-0.7.0b59"" 
```
✅ Docker service is running
✅ Git 2.38.1
✅ Docker 20.10.21
✅ Docker Compose 2.12.2

Launching a PyGrid Domain node on port 8082!

  - NAME: dreamy_ng
  - RELEASE: development
  - TYPE: domain
  - DOCKER_TAG: 0.7.0-beta.59-dev
  - GIT_HASH: c30667ea78e29a0f026b779e95d8f8c2f5222970
  - HAGRID_VERSION: 0.2.113-dev
  - HAGRID_REPO_SHA: c30667ea78e29a0f026b779e95d8f8c2f5222970
  - PORT: 8082
  - DOCKER COMPOSE: v2.12.2
 ```

```

quirky_gardner-celeryworker-1    | Successfully installed GitPython-3.1.29 asttokens-2.2.0 backcall-0.2.0 bandit-1.7.4 beautifulsoup4-4.11.1 black-22.6.0 black-nb-0.7 bleach-5.0.1 cfgv-3.3.1 coverage-6.5.0 defusedxml-0.7.1 distlib-0.3.6 doc8-0.11.2 docutils-0.19 dparse-0.6.2 entrypoints-0.4 exceptiongroup-1.0.4 execnet-1.9.0 executing-1.2.0 faker-13.15.1 fastjsonschema-2.16.2 filelock-3.8.0 flake8-3.8.4 gitdb-4.0.10 identify-2.5.9 importlib-metadata-4.13.0 iniconfig-1.1.1 ipython-8.7.0 isort-5.10.1 jedi-0.18.2 jinja2-3.1.2 jsonschema-4.17.3 jupyter-client-7.4.7 jupyter-core-5.1.0 jupyterlab-pygments-0.2.2 lxml-4.9.1 matplotlib-inline-0.1.6 mccabe-0.6.1 mistune-0.8.4 mypy-0.971 mypy-extensions-0.4.3 nbclient-0.7.2 nbconvert-6.5.4 nbformat-5.4.0 nest-asyncio-1.5.6 nodeenv-1.7.0 opentelemetry-api-1.11.1 opentelemetry-exporter-jaeger-1.11.1 opentelemetry-exporter-jaeger-proto-grpc-1.11.1 opentelemetry-exporter-jaeger-thrift-1.11.1 opentelemetry-sdk-1.11.1 opentelemetry-semantic-conventions-0.30b1 pandocfilters-1.5.0 parso-0.8.3 pathspec-0.10.2 pbr-5.11.0 pexpect-4.8.0 pickleshare-0.7.5 platformdirs-2.5.4 pluggy-1.0.0 pre-commit-2.20.0 ptyprocess-0.7.0 pure-eval-0.2.2 py-cpuinfo-9.0.0 pycodestyle-2.6.0 pyflakes-2.2.0 pyrsistent-0.19.2 pytest-7.2.0 pytest-asyncio-0.20.2 pytest-benchmark-4.0.0 pytest-cov-4.0.0 pytest-custom-exit-code-0.3.0 pytest-randomly-3.12.0 pytest-sugar-0.9.6 pytest-xdist-3.0.2 restructuredtext-lint-1.4.0 ruamel.yaml-0.17.21 ruamel.yaml.clib-0.2.7 safety-2.1.1 smmap-5.0.0 soupsieve-2.3.2.post1 stack-data-0.6.2 stevedore-4.1.1 syft-0.7.0b59 thrift-0.16.0 tinycss2-1.2.1 tokenize-rt-5.0.0 tomli-2.0.1 tornado-6.2 traitlets-5.6.0 virtualenv-20.17.0 webencodings-0.5.1
```

Note - removing ~/.hagrid did not help",clue dev docker service running git docker docker compose domain node port name release development type domain port docker compose successfully post note removing help,issue,positive,positive,positive,positive,positive,positive
1332514002,">  I noticed some of the network tests take longer because they rely on the .get failing and getting caught in a try-catch which doesn't happen as fast now so we might need to change those tests.

Actually, this shouldn't happen since we just skip the entire thing and raise the `Exception` instantly in case the pointer isn't there.

**UPDATE**: One thing that I found that might be related was the fact that we moved `is_processing_pointer = False` to the outside of the `while` loop. This made the `is_processing_pointer` always `True`, making the `while` stop only when timeout is achieved. This forced us to wait for the entire timeout even if we retrieved the pointer successfully.

Moving it back to the inside of the while made it back to normal.",network take longer rely failing getting caught happen fast might need change actually happen since skip entire thing raise exception instantly case pointer update one thing found might related fact false outside loop made always true making stop forced u wait entire even pointer successfully moving back inside made back normal,issue,negative,positive,neutral,neutral,positive,positive
1332506623,">The other thing we could do is have some concept of retry=True/False but right now the code is already getting a little overloaded so I think we should circle back to this later rather than have it hold up our existing bugs in 0.7.

+100",thing could concept right code already getting little think circle back later rather hold,issue,negative,positive,neutral,neutral,positive,positive
1331747832,"@IonesioJunior Great work. I had a play and made some small changes and added a test.

Since there was already a default timeout in the http code this now flows through and does the while loop if its in the pointer registry as well but there is no concept of No timeout because 0 timeout is not allowed in the http code.

I think this means currently in my changes the default retry is the GET_OBJECT_TIMEOUT.
The code is becoming a little busy because we had a timeout function in `get` already which was relating to request block.

The other thing we could do is have some concept of retry=True/False but right now the code is already getting a little overloaded so i think we should circle back to this later rather than have it hold up our existing bugs in 0.7.

As long as this doesn't break anything for now I think we can merge it but we should keep an eye on it because .get is used everywhere and there could be unexpected side effects of changing the default behavior. I noticed some of the network tests take longer because they rely on the .get failing and getting caught in a try catch which doesnt happen as fast now so we might need to change those tests.


",great work play made small added test since already default code loop pointer registry well concept code think currently default retry code becoming little busy function get already request block thing could concept right code already getting little think circle back later rather hold long break anything think merge keep eye used everywhere could unexpected side effect default behavior network take longer rely failing getting caught try catch doesnt happen fast might need change,issue,negative,positive,neutral,neutral,positive,positive
1331724981,Closing this PR. Merged the commits to @teo-milea 's [publish refactor branch](https://github.com/OpenMined/PySyft/tree/fix_publish_loop) as that fixes filtering. All the changes can now be seen in this PR: #7103 ,publish branch filtering seen,issue,negative,neutral,neutral,neutral,neutral,neutral
1331682441,"Captain Scope Creep here just chiming in to say, I think we should move this to 0.8 and address it with workers and memory pinning.",captain scope creep say think move address memory pinning,issue,negative,neutral,neutral,neutral,neutral,neutral
1331665081,I think re-enabling GC even in a partial state is a good idea. ,think even partial state good idea,issue,negative,positive,positive,positive,positive,positive
1331615506,"@letv3 thanks, this is great. It looks like you unchecked the the tick box which allows us to make changes to the PR.
![image](https://user-images.githubusercontent.com/2882739/204704719-d903ac57-4bf1-4c87-beab-e0bab2a0d170.png)
Are you able to change the permission otherwise you need to merge `dev` in as there were some changes to CI which happened after this PR was opened which will prevent it from passing some tests.",thanks great like unchecked tick box u make image able change permission otherwise need merge dev prevent passing,issue,positive,positive,positive,positive,positive,positive
1331281098,"@iamtrask working great for me. Are you able to share more info about your hagrid?

This is mine right now:

```
 hagrid launch --dev --tail=True
✅ Docker service is running
✅ Git 2.38.1
✅ Docker 20.10.21
✅ Docker Compose 2.12.2

Launching a PyGrid Domain node on port 8081!

  - NAME: determined_altman
  - RELEASE: development
  - TYPE: domain
  - DOCKER_TAG: 0.7.0-beta.59-dev
  - GIT_HASH: 1042480ca16aaba31b36b33efc1e1c52d59ebf8e
  - HAGRID_VERSION: 0.2.113-dev
  - HAGRID_REPO_SHA: 1042480ca16aaba31b36b33efc1e1c52d59ebf8e
  - PORT: 8081
  - DOCKER COMPOSE: v2.12.2
```",working great able share mine right launch dev docker service running git docker docker compose domain node port name release development type domain port docker compose,issue,positive,positive,positive,positive,positive,positive
1331022203,Relying on a syft.helper_messages = True flag seems like a reasonable middle ground. Default it to False and set it to True in all our tutorials.,true flag like reasonable middle ground default false set true,issue,positive,positive,neutral,neutral,positive,positive
1330996060,I'm running the latest Docker Desktop on OSX and I ran Clean / Purge immediately before.,running latest docker ran clean purge immediately,issue,negative,positive,positive,positive,positive,positive
1330969804,"> Launching a domain node using `hagrid launch --tag=latest` launched a domain node with Syft 0.6.0- could this be the cause of the issue? ![image](https://user-images.githubusercontent.com/32711264/203352984-c91846a3-4f91-421c-b260-ed7a60c61874.png)

@IshanMi I believe we've confirmed that this was not the issue. I was planning to reproduce on dev today but dev isn't building. However, running with --tag=latest still produces the same issue.",domain node launch domain node could cause issue image believe confirmed issue reproduce dev today dev building however running still issue,issue,negative,positive,positive,positive,positive,positive
1330962341,"> Unable to reproduce this issue- when I ran the code posted I got the same RDP constants and epsilon spend both times FWIW this also suffers from #6949 since sigma=1 made the RDP constant = 0.03966208 for me
> 
> I'll circle back to this once that issue is fixed

@IshanMi - the measurements you describe are subtley unrelated to this issue. Both queries should create the same RDP constants and epsilon spend.

However, because they're doing so against different data subjects the amount of remaining privacy budget for the domain node (which is a max across all data subjects) should not change between the first and second query. The second query is just bringing more data subjects to the same level of epsilon spend as the first query. 

The expected behavior is for bob.privacy_budget to change after the first query is run, but for bob.privacy_budget to remain the same when the second query is run.",unable reproduce ran code posted got epsilon spend time also since made constant circle back issue fixed describe unrelated issue create epsilon spend however different data amount privacy budget domain node across data change first second query second query data level epsilon spend first query behavior change first query run remain second query run,issue,negative,positive,neutral,neutral,positive,positive
1330898509,I fixed this issue by running Clean / Purge data from Docker. I suspect that this behavior was the result of Docker running out of disk space. I'll create a separate issue to check this in the future.,fixed issue running clean purge data docker suspect behavior result docker running disk space create separate issue check future,issue,negative,positive,positive,positive,positive,positive
1330660468,"@IonesioJunior yes, I will add the fix for the filtering system here as well (by tomorrow it should be fixed)
",yes add fix filtering system well tomorrow fixed,issue,positive,positive,neutral,neutral,positive,positive
1330439201,"@tcp @madhavajay I have found the issue, it was a minor fix on the backend API itself. Created a fix here:
https://github.com/OpenMined/PySyft/pull/7127",found issue minor fix fix,issue,negative,negative,neutral,neutral,negative,negative
1330101187,@superjdz We haven't released it yet. We are currently finishing off all bugs relating to the 0.7 release. There are a number of notebooks being worked on by the docs team and course3 notebooks are tested against 0.7 in CI.,yet currently finishing release number worked team course tested,issue,negative,neutral,neutral,neutral,neutral,neutral
1330097744,"Yes, I agree, but lets circle back after 0.7.",yes agree circle back,issue,positive,neutral,neutral,neutral,neutral,neutral
1330096577,@tcp do you know if this will be difficult or is it related to a common problem with PyGrid UI in 0.7?,know difficult related common problem,issue,negative,negative,negative,negative,negative,negative
1330054977,"@IonesioJunior Is the PR ready for review, I tried the script again, and I am able to replicate the error logs, 
maybe there is some pending work still in the PR?",ready review tried script able replicate error maybe pending work still,issue,negative,positive,positive,positive,positive,positive
1330016724,"I see, I think we could run black on continuous-delivery.yml after we bump2version in the CI.",see think could run black,issue,negative,negative,negative,negative,negative,negative
1328490080,Looks like recently the bump version thing has been adding trailing white spaces. Do you know where this is configured?,like recently bump version thing trailing white know,issue,negative,neutral,neutral,neutral,neutral,neutral
1328207615,"Disable support for `__array_ufunc__` for tensors for now at least until we can implement them properly.

Implementing `__array_ufunc__` requires supporting different call `method`s: `__call__`, `reduce`, `reduceat`, `accumulate`, `outer`, `inner`. Otherwise if users call things like `np.multiply.reduce(tensor)` they're gonna get the same results as `np.multiply(tensor)` which is wrong.

https://numpy.org/doc/stable/reference/ufuncs.html",disable support least implement properly supporting different call method reduce accumulate outer inner otherwise call like tensor gon na get tensor wrong,issue,positive,negative,negative,negative,negative,negative
1327451771,"@kiendang , it would be constant also in the future , 
This constant fixing would be same like us fixing the return types of each operation in the AST.
In this case, since the DP pointers are custom subclasses, we fix the return type in the class itself.",would constant also future constant fixing would like u fixing return operation ast case since custom fix return type class,issue,negative,neutral,neutral,neutral,neutral,neutral
1327417411,"I will create a ticket to explore the removal of serialization when we check for immutability, I think that making our objects hashable would helps us in plenty of places.",create ticket explore removal serialization check immutability think making would u plenty,issue,negative,neutral,neutral,neutral,neutral,neutral
1327359172,"To catch this reliably we might have to add serde bytes check to all our custom classes, but it depends explicitly on the custom class if they tend to have random UID, like the one with Py Primitives.

I have wanted for a long time to remove the double serde in RunClassMethodAction, totally sede happens `four` times for a single operation 😅. Yep totally, we could definitely explore  that, for 0.8",catch reliably might add check custom class explicitly custom class tend random like one long time remove double totally four time single operation yep totally could definitely explore,issue,positive,negative,neutral,neutral,negative,negative
1327346149,"Great work @rasswanth-s ! I think this is a nice solution until we merge 0.8.0. You killed plenty of dead code. One remark - do you think there is any way to catch this behaviour reliably? I am pretty sure it only happened in the context of upcast.

Another line of work that would significantly improve this yet again would be to drop the double serialization to check for mutability. I think that at some point, all the serializable objects should be hashable (this feature would be cool for plenty of reasons + we can derive this quite easily I believe - we know the fields we care about, we just add a `__hash__` function that recursively hashes the underlying selected objects) - one would be to check for mutability without the time/performance hit. I am sure we should definitely explore that for 0.8.0. What do you think?",great work think nice solution merge plenty dead code one remark think way catch behaviour reliably pretty sure context upcast another line work would significantly improve yet would drop double serialization check mutability think point feature would cool plenty derive quite easily believe know care add function underlying selected one would check mutability without hit sure definitely explore think,issue,positive,positive,positive,positive,positive,positive
1326997540,"I have had to disable this for now because every time a tensor gets created with internal code it prints. For SMPC this can result in hundreds of the same message getting printed.

https://github.com/OpenMined/PySyft/pull/7086

Let's create a new PR which enables this but does not trigger. Perhaps we could have a global timeout or something similar to prevent it from flooding prints?",disable every time tensor internal code result message getting printed let create new trigger perhaps could global something similar prevent flooding,issue,negative,positive,neutral,neutral,positive,positive
1326996550,@rasswanth-s can we get an estimate on the number of person-days to fix?,get estimate number fix,issue,negative,neutral,neutral,neutral,neutral,neutral
1326612758,"## Gevent
🟠[PENDING] MAYBE: Explain libev and eventloop?

SMPC in Action
🟠[PENDING] MAYBE: The output when creating a Tensor looks a little bit unaligned:
Tensor created! You can activate Differential Privacy protection by calling .private() or .annotate_with_dp_metadata(). (Probably a fix is required in the SyftTensor?)
🟠[PENDING] MAYBE: When starting hagrid some of the ascii art table does not seem properly aligned?
🟠[PENDING] MAYBE: I would skip the ""Request for Budget"" and introduce it at the end -- how to combine SMPC And DP.
✅ Q: You wanted to call get? modified to show result

## MPCTensor
✅ MAYBE: Shares name
✅ Q: Strange that this code does not show ""PointerTensor"" Currently it shows
✅ OUGHTTO: ""Let's get the actual data of the TensorPointer of alice.""
✅ NITPICK: ShareTensor explanation modified

## ShareTensor

✅ NITPICK: explanation changed and fixed

MAYBE: In the image ""SharedTensor"" -> ""ShareTensor""
MAYBE: The rectangle from the MPCTensor needs some alignment.
NITPICK: There are some spaces before/after commas that need to be removed/added.
OUGHTTO: Remove the ""They know to compute the Turing Complete operations"" --> There is introduced a new term ""Turing Complete"" and it should be defined. I think it is better to use a simpler language

## Pseudo Random Generators (PRGs)

NITPICK: ""revealed(or are predictable)"" space between ""revealed"" and ""(""
MAYBE: Try to build a little bit on this ""If the random bits are revealed(or are predictable) the entire structure collapses"". I was thinking at rephrasing it as the following.
""Consider a two party scenario from above. If one of the parties know what random number the other party would use or even predict with a good chance what that number might be then the entire structure collapses""
NITPICK: ""Obtaining, true randomness is expensive"" --> no comma here.
MAYBE: That PRG image could be smaller I think?
Q: It is expected that they know what a seed is?
MAYBE: ""Let's use the secrets library for generating random numbers, as it is cryptographically secure"" --> ""We will use the secrets library"" (The phrase ""Let's"" is also on the previous row).
MAYBE: ""Let's generate a small seed to be used to by the generator"" (I would remove that ""small"")
",pending maybe explain action pending maybe output tensor little bit unaligned tensor activate differential privacy protection calling probably fix pending maybe starting ascii art table seem properly pending maybe would skip request budget introduce end combine call get show result maybe name strange code show currently let get actual data explanation explanation fixed maybe image maybe rectangle need alignment need remove know compute complete new term complete defined think better use simpler language pseudo random revealed predictable space revealed maybe try build little bit random revealed predictable entire structure thinking following consider two party scenario one know random number party would use even predict good chance number might entire structure true randomness expensive comma maybe image could smaller think know seed maybe let use library generating random cryptographically secure use library phrase let also previous row maybe let generate small seed used generator would remove small,issue,positive,negative,neutral,neutral,negative,negative
1326292758,Changed the title coz currently this is the issue with both tensors and pointers because they both subclass `PassthroughTensor` but the issue with pointers is being tracked at #6922.,title coz currently issue subclass issue tracked,issue,negative,neutral,neutral,neutral,neutral,neutral
1324876479,"Oops.., my bad then. Then its no longer an issue. I will close it.",bad longer issue close,issue,negative,negative,negative,negative,negative,negative
1324624551,"I have verified the same after the merging the PR https://github.com/OpenMined/PySyft/pull/7002
![Screenshot 2022-11-23 at 12 23 03 PM](https://user-images.githubusercontent.com/43314053/203487438-f9cfaa29-ee9e-48bc-b898-7ecd2376dae4.png)

with 0.01 sigma --> 14 (budget spent)
with 1  sigma  --> 0.07 (budget spent)
",sigma budget spent sigma budget spent,issue,negative,negative,neutral,neutral,negative,negative
1324474910,"It's not ideal for Pointer to implement ops as multiple ops because it means we're sending more messages than necessary. It's a fine way to get to a lot of functionality fast but the ideal state is ti have that all on server side.

Given that ideal state, it seems like a good decision for us to remove passthrough from pointer. Since SMPC functionality is so limited there's a part of me that wonders if leaving some of the methods that work by calling a series of other method on self would be worth it. But if we do a push on SMPC we can cross that bridge then. ",ideal pointer implement multiple sending necessary fine way get lot functionality fast ideal state ti server side given ideal state like good decision u remove pointer since functionality limited part leaving work calling series method self would worth push cross bridge,issue,positive,positive,positive,positive,positive,positive
1324467185,@shubham3121 but `keep_dims` is not the named argument it's `keepdims` as you can see with my example and numpy docs above? Is there something im missing?,argument see example something missing,issue,negative,negative,negative,negative,negative,negative
1324465403,"@mathews since were going to release 0.7 soon im going to close this, please open it again if you want to discuss it further.",since going release soon going close please open want discus,issue,negative,neutral,neutral,neutral,neutral,neutral
1324397335,"Great find that deleted users can still do things issue.

Please file a seperate issue and keep this PR in scope for this issue: https://github.com/OpenMined/PySyft/issues/6990",great find still issue please file issue keep scope issue,issue,positive,positive,positive,positive,positive,positive
1324098803,"> I think that even after we delete the root domain user, we are able to do operations with the already created syft client ![Screenshot 2022-11-22 at 12 57 31 PM](https://user-images.githubusercontent.com/43314053/203251518-bf2d0c29-52d5-443a-86a0-924c6fa29ad2.png) Maybe we should prevent that scenario. Code to reproduce in the screenshot

@rasswanth-s , @tcp This issue was solved in the last commits, and now we're returning an unauthorized exception.
<img width=""826"" alt=""session_finish_error"" src=""https://user-images.githubusercontent.com/26658472/203397808-661324ff-71b2-4f5a-b052-85d1a7f0e1c7.png"">

",think even delete root domain user able already client maybe prevent scenario code reproduce issue last unauthorized exception,issue,negative,positive,positive,positive,positive,positive
1324097938,"I have discussed this with @IshanMi at it seems like the filtering is working as ""intended"". We will review the budget computation for `0.8` and optimize the filtering with the new DSA. I have opened a PR that is adding just noise when the filtering fails, and I have also refactored that part of the code. It might not be compatible with full Jax execution as I am doing in-place filtering. but whenever we will be working on that I will make sure to fix it. I have also added a basic publish test, but I have no idea how to check execution on the worker container.",like filtering working intended review budget computation optimize filtering new noise filtering also part code might compatible full execution filtering whenever working make sure fix also added basic publish test idea check execution worker container,issue,positive,positive,positive,positive,positive,positive
1323957361,"I modified all the occurrences of `value` but it does not solve the problem. To me, it seems that during the filtering, the epsilon computed for each leaf tensor is lower than the available budget so no filtering is happening. My initial guess is that maybe changing the code from recursive to iterative broke the filtering, but maybe there was a change in the way we compute the RDP parameters/privacy budget spent. Tomorrow I will delve deeper into the paper to debug that but if you have any insights let me know.",value solve problem filtering epsilon leaf tensor lower available budget filtering happening initial guess maybe code recursive iterative broke filtering maybe change way compute budget spent tomorrow delve paper let know,issue,negative,positive,positive,positive,positive,positive
1323848915,"Launching a domain node using `hagrid launch --tag=latest` launched a domain node with Syft 0.6.0- could this be the cause of the issue?
![image](https://user-images.githubusercontent.com/32711264/203352984-c91846a3-4f91-421c-b260-ed7a60c61874.png)
",domain node launch domain node could cause issue image,issue,negative,neutral,neutral,neutral,neutral,neutral
1323677585,"Yep, it would imply to keep that list with the implemented methods.
There might be some other workarounds for this problem.

We could also check `func` - it is implemented - but I think you would still need to have a list of implemented methods.",yep would imply keep list might problem could also check think would still need list,issue,negative,neutral,neutral,neutral,neutral,neutral
1323637187,"> I think that even after the we delete the root domain user,we are able to do operations with the already created syft client

I suggest we open a new issue for handling that bug, so we keep this small :)",think even delete root domain user able already client suggest open new issue handling bug keep small,issue,negative,positive,neutral,neutral,positive,positive
1323620023," Placeholder for the second set of comments:

🟠[PENDING]Some sentences are ending with a period and some are not (they do not have any marks at the end).

## AND Gate
✅ TYPO
✅ MAYBE
✅ TYPO
✅ TYPO: ""Since Alice and Bob have the shares required to reconstruct "" the second reconstruction should use x_b and y_b.
✅ MAYBE: constant term
✅  OUGHTTO: image synchronization
🟠[PENDING] Q: Why not use all the row to write ""Alice and Bob either send each of their shares to the stakeholder for them to reconstruct individually or they send it between themselves and make it a public output."" (it seems like there is added a character limit per row)
✅ MAYBE: ""Similar to xor gate, 

## Explanation 1
✅ MAYBE: I would stick to using ""they""/""them"" both for Bob and/or Alice

✅ ###  Explanation 2 (there is a typo in the title) : removed this currently

## Solving the Original Circuit Example
✅ MAYBE: We already have two wires from the circuit, maybe I am missing something?

## Security Models
MAYBE: ""Semi-honest"" I feel like the ""language""/words could be simplified. For example ""However, they try to learn information from the transcript of the messages communicated in the protocol."" --> something around the lines ""they could look at intermediary values computed by the protocol, but they should not be able to find stuff about the secret from those""

## SMPC in PySyft
✅ MAYBE: Crypten repo link

## Async Execution Model
Q: ""The server side doesn't need to execute async messages , asynchronously, but by doing so, we could have a lot more functionality"" -- async messages + asynchronously does not sound too good (I am thinking about the formulation).
MAYBE: Explain that there are tradeoffs ^^ doing stuff async does not come without negative parts.
MAYBE: "" by a resource or an output"" after that it is ""have a pending I/O request,' -- I would rather leave only one of the two sentences (probably only the I/O part -- it feels like both sentences are saying the same thing - that we switch in case we are doing I/O)
✅ MAYBE: Add links to RabbitMQ and Celery
MAYBE: ""Syft uses , RabbitMQ as the messaging queue"" -- maybe it is better to talk about the concepts in the SMPC in PySyft Chapter or another section with ""Remote execution in PYSyft"". And in this part present ""RabbitMQ"", ""Celery worker"".
✅ OUGHTTO: @madhavajay included explanation for the above terms in the notebook
",second set pending ending period end gate typo maybe typo typo since bob reconstruct second reconstruction use maybe constant term image synchronization pending use row write bob either send stakeholder reconstruct individually send make public output like added character limit per row maybe similar gate explanation maybe would stick bob explanation typo title removed currently original circuit example maybe already two circuit maybe missing something security maybe feel like language could simplified example however try learn information transcript protocol something around could look intermediary protocol able find stuff secret maybe link execution model server side need execute could lot functionality sound good thinking formulation maybe explain stuff come without negative maybe resource output pending request would rather leave one two probably part like saying thing switch case maybe add link celery maybe queue maybe better talk chapter another section remote execution part present celery worker included explanation notebook,issue,positive,positive,neutral,neutral,positive,positive
1323330467,"@gmuraru this would require us to maintain a separate `VISIBLE_ATTRS`? The issue here is just a non terminating recursion, would detecting non implementation and throw NotImplemented early instead of continuing descending into `self.__class__(func(*args, **kwargs))` a cleaner solution?",would require u maintain separate issue non recursion would non implementation throw early instead descending cleaner solution,issue,negative,positive,neutral,neutral,positive,positive
1323236339,"> For example, when people, tend to use hagrid logs for `not` launched domain, should we raise an intimation that the domain is not launched yet? ![Screenshot 2022-11-22 at 12 33 53 PM](https://user-images.githubusercontent.com/43314053/203247199-adb4f9b9-be21-48ca-a79e-18e13c66c250.png)

@rasswanth-s I wonder if, for sake of scope, we can move this improvement to a new ticket so we can limit the ""ifs"" and work on it as a separate issue? 
",example people tend use domain raise intimation domain yet wonder sake scope move improvement new ticket limit work separate issue,issue,negative,positive,positive,positive,positive,positive
1323226778,"> @X-Omil , this currently uses SyMPC respository, which was supported in `0.5.0`, most of the SMPC functionality have changed. We have an upcoming SMPC introduction notebook which would be released next week, which has the code context for our current architecture.

Thanks for letting me know what went wrong.  I'm looking forward to the upcoming notebook.",currently functionality upcoming introduction notebook would next week code context current architecture thanks know went wrong looking forward upcoming notebook,issue,negative,negative,neutral,neutral,negative,negative
1323225755,"I think that even after the we delete the root domain user,we are able to do operations with the already created syft client
![Screenshot 2022-11-22 at 12 57 31 PM](https://user-images.githubusercontent.com/43314053/203251518-bf2d0c29-52d5-443a-86a0-924c6fa29ad2.png)
Maybe we should prevent that scenario.
Code to reproduce in the screenshot",think even delete root domain user able already client maybe prevent scenario code reproduce,issue,negative,positive,positive,positive,positive,positive
1323207259,"For example, when people, tend to use hagrid logs for  `not` launched domain, should we raise an intimation that the domain is not launched yet?
![Screenshot 2022-11-22 at 12 33 53 PM](https://user-images.githubusercontent.com/43314053/203247199-adb4f9b9-be21-48ca-a79e-18e13c66c250.png)
",example people tend use domain raise intimation domain yet,issue,negative,neutral,neutral,neutral,neutral,neutral
1323191123,"We get this error after deleting a domain and submitting the response
![Screenshot 2022-11-22 at 12 16 48 PM](https://user-images.githubusercontent.com/43314053/203243996-d2e6dd8d-0d76-45db-a1e6-4a1117a7ab80.png)
",get error domain response,issue,negative,neutral,neutral,neutral,neutral,neutral
1322574304,"Maybe something like the following:

```
def __getattribute__(self, attr_name: str) -> Any:
     if attr in VISIBLE_ATTRS:
        return object.__getattribute__(self, attr_name)
     raise ValueError(f""Attribute {attr_name} not found!"") # Or Not Implemented
```

`VISIBLE_ATTRS` would have to be of string with all the `methods/attributes` we support",maybe something like following self return self raise attribute found would string support,issue,positive,neutral,neutral,neutral,neutral,neutral
1322530653,"We actually do this already- we replace values with 0 using `GammaTensor.filtered()` instead of doing any in-place replacing (since that can be difficult with JAX)

This issue has more to do with the fact that when using the new tensor, it's trying to call tensor.flatten() instead of tensor.flatten(order=""F"") because of an oversight on our end.",actually replace instead since difficult issue fact new tensor trying call instead oversight end,issue,negative,negative,negative,negative,negative,negative
1322441940,"We have a cache that stores epsilon spends. That cache stores epsilon spends corresponding from RDP constant=[0, 50, step=0.0001]. These are the first ~500,000 values in our cache. For RDP_constants in [51, 700,050], the cache has 1 epsilon spend corresponding to each integer between 51 and 700,050.

![](https://user-images.githubusercontent.com/32711264/202245354-2b3f8476-17f9-4a60-b7f8-5dca65372a7e.png)

The indexing function that  converts an RDP constant to the cache index involves a -1. When our RDP constant is < 1, this results in the index being a negative number. (This is the error.) 
When we use this negative number as the index into our cache, the epsilon spend is gigantic because it corresponds to a RDP constant of ~700,000.

Hope that makes sense! And sorry for not being more explicit before.",cache epsilon cache epsilon corresponding first cache cache epsilon spend corresponding integer indexing function constant cache index constant index negative number error use negative number index cache epsilon spend gigantic constant hope sense sorry explicit,issue,negative,negative,negative,negative,negative,negative
1322430236,"We actually do this already- we handle RDP constants between 0 and 50 at increments of(1/10,000) and another which handles 50-700,000+ at integer increments
This is just a simple indexing bug that's been solved in #7002 and is just waiting for tests to pass",actually handle another integer simple indexing bug waiting pas,issue,negative,neutral,neutral,neutral,neutral,neutral
1321943067,"@gmuraru we have tests for datasets, seems like they were not added to tox and CI. I have added them now, should be reflected in the CI.",like added tox added reflected,issue,negative,neutral,neutral,neutral,neutral,neutral
1321750697,Hi @Boluwatifeh I have unassigned this for now as there has been no progress in a month.,hi unassigned progress month,issue,negative,neutral,neutral,neutral,neutral,neutral
1321684109,"I think, this just means moving `def publish` to the `GammaTensorPointer` and returning a `numpy` pointer type.",think moving publish pointer type,issue,negative,neutral,neutral,neutral,neutral,neutral
1321484794,"Oops! Now, should I wait for it to get resolved or is there something I should do from my side?",wait get resolved something side,issue,negative,neutral,neutral,neutral,neutral,neutral
1321483823,"Keeping this a placeholder for answering the review comments

Motivations
TO Answer


### Introduction to SMPC
✅ NITPICK: spelling SMPC fixed
✅MAYBE : DO names fix 
🟠[PENDING] MAYBE: Does it make sense in the ""Motivations"" section to add a clarification that ""Data Owner"" means ""data"" (actual dataset) or ""model"" (weights) owner? -- I am not sure if people would think that DO means only a person that has a dataset.
✅  Q: Privacy : Since we mention any whatever information apart from the public output, it would encompass the intermediate, but we solidify this intuition in the later part of the notebook

### Secret Sharing
🟠 [PENDING] OUGHTTO: To create a new image for nuclear example
✅ MAYBE
✅ MAYBE: I thought maybe in the initial protocol, it might be abstract if parties themselves share their private data , I included an explanation, at the end of XOR gate,on the scenario in which the parties hold private input to the wires.

SMPC Boolean Circuit Example
✅ MAYBE: The values a,a' & b,b' are the actual private input to their wire (computed in normally), sharing of the  private bits, I have described in each gate computation

✅  Here you could also introduce that ""+"" in ring size two is actually the ""^"" (xor) or it might be too much?
`A` : I thought we could include the section on arithmetic secret sharing at the end of Circuit Example

✅ TYPO?: ""Let's break down the problem see how we could compute the basic gates."" --> ""Let's break down the problem and see how we could compute the basic gates.'""

### XOR Gate

✅ TYPO
MAYBE: I am not sure why we add the stakeholders S1 and S2 - can't we simply say that Alice and Bob have the data (they are the DOs) and DS could find something by doing private computation on their data, but without revealing their data?
✅ NITPICK: 
✅ NITPICK:
✅ OUGHTTO: Sharholders name change
✅ NITPICK
✅ Q: modified random bit naming
✅ MAYBE: share order
✅ TYPO: bob --> Bob
✅ MAYBE: In the picture Ana should have α and α' to be in sync with ""The stakeholders give the shares α,α' to Alice and β,β' to Bob"" (even if α == a ^ r1)
✅ MAYBE: Modified to consistent stakeholder naming
✅ NITPICK: ""γ(gamma)"" 
✅ NITPICK: Associativity 
🟠[PENDING]MAYBE: Also the equations could use less/more spaces in some places.
✅ NITPICK: ""Let's take look at the XOR table"" --> ""at the XOR table""
🟠[STRETCH]MAYBE: There are more places in the text with the ""space"" problem before/after commas (I will skip those) - also there are some punctuation marks missing in some phrases.
 ✅  TYPO: ""its's""
✅ MAYBE: ""Does the former protocol described above does not compute the xor function securely?"" Rephrase this.
✅ Q: I do not understand this. Reveals the private input of the other party if the output is revealed.`Yep, crct I modified the explanation for the same`
✅ OUGHTTO: Secure Function Evaluation described this term in the introduction to smpc section.
✅ TYPO: ""exchaning"" -- ""exchanging""

### AND Gate
✅ MAYBE: Beaver triple
..[STRETCH]MAYBE: Add the ""&"" sign for AND -- ab will become a & b
✅  MAYBE: The code is mainly to view in python setting.
🟠[PENDING] MAYBE: The sharing x, y and z could be added together -- same rows and different columns -- this also for some others before this. I feel like there is a lot of ""empty space"" in the notebook.
✅ MAYBE: Remove the pre-processing phase since it is not explained. I think maybe we should focus on the concepts of SMPC and not how we should ""improve"" the process.
✅ MAYBE: ""Alice computes"", ""Bob Computes"" -- change ""Computes"" to ""computes"" - it is good to have consistency.
🟠[PENDING]: Simplify Beaver triple equation

### Dating problem
✅ Q: ""a date with other."" --> ""date with each other""? Simplification

In this part, one of the sections would be removed `Explanation 1` or `Explanation 2`
",keeping review answer introduction spelling fixed maybe fix pending maybe make sense section add clarification data owner data actual model owner sure people would think person privacy since mention whatever information apart public output would encompass intermediate solidify intuition later part notebook secret pending create new image nuclear example maybe maybe thought maybe initial protocol might abstract share private data included explanation end gate scenario hold private input circuit example maybe actual private input wire normally private gate computation could also introduce ring size two actually might much thought could include section arithmetic secret end circuit example typo let break problem see could compute basic let break problem see could compute basic gate typo maybe sure add ca simply say bob data do could find something private computation data without revealing data name change random bit naming maybe share order typo bob bob maybe picture ana sync give bob even maybe consistent stakeholder naming gamma pending maybe also could use let take look table table stretch maybe text space problem skip also punctuation missing typo maybe former protocol compute function securely rephrase understand private input party output yep explanation secure function evaluation term introduction section typo gate maybe beaver triple stretch maybe add sign become maybe code mainly view python setting pending maybe could added together different also feel like lot empty space notebook maybe remove phase since think maybe focus improve process maybe bob change good consistency pending simplify beaver triple equation dating problem date date simplification part one would removed explanation explanation,issue,positive,positive,neutral,neutral,positive,positive
1321478715,Hmm I haven't checked that. Also I think we could think about whether we should refactor this check out of `private` coz it might be useful elsewhere.,checked also think could think whether check private coz might useful elsewhere,issue,negative,positive,positive,positive,positive,positive
1321476174,"Could be related. What I understand is `ufunc` support for `np.ones_like` was supposed to work but broken? #7042 is discussing whether we support `ufunc` at all? So yes, these 2 issues are closely related.",could related understand support supposed work broken whether support yes closely related,issue,positive,negative,negative,negative,negative,negative
1321392154,Looks like you might have hit some unlucky timing on a dependency security issue.,like might hit unlucky timing dependency security issue,issue,positive,neutral,neutral,neutral,neutral,neutral
1321383656,"@tudorcebere we want the quickest solution for 0.7 since its fixed in 0.8.

So right now, users still need to have the correct permission to save on mutation but the code will always compare and find the equality false therefore saving the self back to Redis. So this just means like 2 saves instead of one. If you agree that there is no security issues with this just some performance penalty perhaps we leave it?",want solution since fixed right still need correct permission save mutation code always compare find equality false therefore saving self back like instead one agree security performance penalty perhaps leave,issue,positive,negative,neutral,neutral,negative,negative
1321376792,"> Ah - so I suppose PassthroughTensor is doing two things when it should really only do one.
> 
> 1. if an op can be framed as merely a series of other tensor ops, implement it
> 2. if an op cannot be framed as a series of other ops, call self.child.op
> 
> The main value of passthrough tensor is (1). That's the bit I'd like for us to keep. We can delete the parts of the api for (2). (I don't know if those deletions will break things... they might)

Does it make sense for a Pointer to implement its client side logic with calls to multiple actions as composition? All that does is send 3 sub actions and chain the results, rather than sending 1 action and having the server side do the composition. I think Pointers should have 0 knowledge of anything except ""send this action"", which is why they used to be derived directly.

As I understand the goal of subclassing is to provide default behavior, but what is the default behavior for an unimplemented method?

Looking at the code I think whats happening is because we have public data such as bounds and data subjects, its desirable that the generated local pointer from an operation mirrors the same behavior that would happen remotely.

If this was implemented as a DP Pointer parent class then it could do something like:
```python
def op(self, *args, *kwargs) -> Any:
  self.send_action(self.op.__name__, args, kwargs)
  min_vals = apply_op(op, self.min_vals, args, kwargs)
  max_vals = apply_op(op, self.max_vals, args, kwargs)
  data_subjects = apply_op(op, self.data_subjects, args, kwargs)
  return DPPointer.create(data_subjects.is_gamma, min_vals, max_vals, data_subjects)
```

Since the DP Tensor Pointer knows about its internal public bounds and datasubject attributes which require mutation and since DSA and bounds should be a `numpy`-like type ready to be called directly with the op.

If min_vals, max_vals, or data_subject happen to inherit from PassthroughTensor then they can get all the free composition locally as well, but the Pointer shouldnt know about this stuff.

Then the default behavior for any `op` on DPTensorPointer would be to send that op to the server and run it against its local public attributes, if we wanted to.

Looking at `MPCTensor` it looks like that uses a seperate `TensorPointer` which does not inherit from `PassthroughTensor`.

Without digging into it I guess theres probably some coupling and overlap particularly around the need for multiple return type signatures from methods which could result in either a DP or SMPC TensorPointer. 

I suggest we do two things here:
1) remove the bug by not subclassing from PassthroughTensor
2) separately look at our Pointer design and unify it around a set of constraints which allow for local public and remote private data to be executed of different types",ah suppose two really one framed merely series tensor implement framed series call main value tensor bit like u keep delete know break might make sense pointer implement client side logic multiple composition send sub chain rather sending action server side composition think knowledge anything except send action used derived directly understand goal provide default behavior default behavior method looking code think whats happening public data data desirable local pointer operation behavior would happen remotely pointer parent class could something like python self return since tensor pointer internal public require mutation since type ready directly happen inherit get free composition locally well pointer shouldnt know stuff default behavior would send server run local public looking like inherit without digging guess there probably coupling overlap particularly around need multiple return type could result either suggest two remove bug separately look pointer design unify around set allow local public remote private data executed different,issue,positive,positive,neutral,neutral,positive,positive
1321358705,"Just for clarity I will link the comment from the other ticket here: https://github.com/OpenMined/PySyft/issues/6950#issuecomment-1321004067

I believe @iamtrask is suggesting this ticket should also use the same ""I'm sorry, but our privacy accountant can't yet divide by a number which might be zero..."" message.",clarity link comment ticket believe suggesting ticket also use sorry privacy accountant ca yet divide number might zero message,issue,negative,negative,negative,negative,negative,negative
1321356819,"Lets not do ""stretch"" anything, its either in or out and for this lets say its out:
https://github.com/OpenMined/Heartbeat/issues/1038

Any ambiguity should always be `Modulo` sliced off and put into another ticket.",stretch anything either say ambiguity always modulo sliced put another ticket,issue,negative,neutral,neutral,neutral,neutral,neutral
1321348336,"@kiendang Great work, I think that is a big improvement over what we have now. Do you know what happens if DataSubjects get filtered in a root Tensor? I guess a Gamma can become a Phi technically? Not sure if that matters though.",great work think big improvement know get root tensor guess gamma become phi technically sure though,issue,positive,positive,positive,positive,positive,positive
1321214736,"In order to be more general, during the publishing system I raised an exception when we find any `NaN` or `Inf` in the L2 norms in this PR: https://github.com/OpenMined/PySyft/pull/7008. Indeed, I created an exploit that allowed a DS to publish entire arrays while only consuming the default budget for publishing noise. It seems like these checks were enough. On the overflow issue, however, I could reverse the min and max values, but couldn't abuse this in any way. I will add some warnings on the DS side for this issue https://github.com/OpenMined/PySyft/issues/6952, but at the moment in doesn't seem we need any check on the server. Let me know if you have any recommendations! ",order general system raised exception find nan indeed exploit publish entire consuming default budget noise like enough overflow issue however could reverse min could abuse way add side issue moment seem need check server let know,issue,negative,positive,neutral,neutral,positive,positive
1321153170,"My call is that all of this is generated from the usage of python primitives & associated IDs. Every time we serialize a primitive object like `str`, `int`, etc we upcast to sy.String, sy.Int. When upcasting, we need to have an associated unique id. This unique id is generated randomly, and it's added to the serialized format of the object . Right now, it cannot be made the same across multiple consecutive serializations.

Good news:
* in `0.8.0`, we don't have primitives anymore in the serialization stack and as far as I've tested, this does not reproduce.
* This feature never worked via immutability; we should see a performance improvement, congrats @rasswanth-s for pointing this out.

Possible fixes:
* (more involved) - pass an optional random seed when serializing/deserializing, but this would mean changing many logic/function signatures, and we should roll back this when we merge with 0.8.
*  We can save the current random state, then serialize, then reset the random seed used by the uuid library to the previous, we should be able to get away with this, but it's so hacky it makes me cry
* remove the usage of uuids in our primitives - I think they were never useful in the first place, but it's slightly involved. I think this would kinda make sense, making us question if we ever needed sy.primitives in the first place.
* rely on sy.primitives in tensor - I think it would add more complexity, instead of solving the issue.
* change the logic to verify immutability (we will still have the fundamental problem) - even tho I think double serialization to verify immutability might be a bit too much, this should be a separated issue by itself.

This is unrelated to the serialization protocol we are using - protobuf/captainproto/pickle would behave the same, as the objects are actually different.

```python3
import syft

test = """"

def assert_equal_bytes(obj):
    object1 = syft.serialize(obj, to_bytes=True)
    object2 = syft.serialize(obj, to_bytes=True)

    assert object1 == object2

assert_equal_bytes(test)
```

",call usage python associated every time serialize primitive object like upcast need associated unique id unique id randomly added format object right made across multiple consecutive good news serialization stack far tested reproduce feature never worked via immutability see performance improvement pointing possible involved pas optional random seed would mean many roll back merge save current random state serialize reset random seed used library previous able get away hacky cry remove usage think never useful first place slightly involved think would make sense making u question ever first place rely tensor think would add complexity instead issue change logic verify immutability still fundamental problem even tho think double serialization verify immutability might bit much issue unrelated serialization protocol would behave actually different python import test object object assert object object test,issue,positive,positive,neutral,neutral,positive,positive
1321120532,"@teo-milea  Hey, created the PR, can you review it? messed up with labels a bit, sorry 😄 ",hey review bit sorry,issue,negative,negative,negative,negative,negative,negative
1321012636,"I have solved it for both scenario's , I have it in the branch
https://github.com/OpenMined/PySyft/tree/padawan_smpc, 
will create a PR for it soon.",scenario branch create soon,issue,negative,neutral,neutral,neutral,neutral,neutral
1321012196,Flagging for 0.7 because other issues necessitate a refactor of DataSubjectArray and so we should take this issue into account during that process.,flagging necessitate take issue account process,issue,negative,neutral,neutral,neutral,neutral,neutral
1321011568,Totally agree that what you've described is the right way to get past this issue - but for 0.7 let's at least print .exists in __repr__,totally agree right way get past issue let least print,issue,negative,negative,neutral,neutral,negative,negative
1321011422,@kirkdemeroukas - sorry this was giving you trouble as well.,sorry giving trouble well,issue,negative,negative,negative,negative,negative,negative
1321011388,Let's at least update this text to describe possible issues for the 0.7 release.,let least update text describe possible release,issue,negative,negative,negative,negative,negative,negative
1321010904,"syft.lazyrepeatarray([[[""Person 1"", ""Person 2""]]], shape=(50, 50, 2)

Once lazyrepeatarray is done and DataSubjectArray is int based with the last dimension holding data subjects for that value then something like this could work.",person person done based last dimension holding data value something like could work,issue,positive,neutral,neutral,neutral,neutral,neutral
1321009601,"Ah - so I suppose PassthroughTensor is doing two things when it should really only do one. 

1) if an op can be framed as merely a series of other tensor ops, implement it
2) if an op cannot be framed as a series of other ops, call self.child.op

The main value of passthrough tensor is (1). That's the bit I'd like for us to keep. We can delete the parts of the api for (2). (I don't know if those deletions will break things... they might)",ah suppose two really framed merely series tensor implement framed series call main value tensor bit like u keep delete know break might,issue,positive,negative,neutral,neutral,negative,negative
1321007015,"Quick fix: instead of removing values entirely, replace them with 0s so that all ops work as designed for the full computation.",quick fix instead removing entirely replace work designed full computation,issue,negative,positive,positive,positive,positive,positive
1321004400,"See https://github.com/OpenMined/PySyft/issues/6950#issuecomment-1321004067 for a related exception.

Adding 1 to both members of the fraction is not enough to ensure that the privacy budget is preserved. I'm confident I could use this to attack the system and leak more information than the accountant was keeping track of. Please see the other comment above for how to deal with this issue for now. ",see related exception fraction enough ensure privacy budget confident could use attack system leak information accountant keeping track please see comment deal issue,issue,negative,positive,positive,positive,positive,positive
1321004067,"As a bug this is more complex than a simple overflow issue. It is genuinely an infinite privacy spend risk WRT the public privacy API. If the denominator has a min_val of -1 and a max_val of 1, then it's possible that the private value is indeed zero and the computation is invalid. The permutation of min_min, min_mmax, etc. is correctly capturing this. That is to say - it's correct to determine that it's possible this is an invalid computation.

We will need to spend more time thinking on this. For 0.7 - please fix by raising an exception on the pointer when a denominator could be zero (isn't positive-definite or negative-definite). The exception should read something like, ""I'm sorry, but our privacy accountant can't yet divide by a number which might be zero. Please find a way to approximate your computation without dividing by a private value which might be zero. This can usually be done by computing the function piecewise - by performing three computations which are merged through masking and summing: one which addresses what happens if the denominator is positive-definite, another which addresses what happens if the denominator is negative-definite, and another which addresses what happens if the denominator is 0 exactly. Use comparison operators, masking, and summing to accomplish this (not if statements - which don't work on private values). """,bug complex simple overflow issue genuinely infinite privacy spend risk public privacy denominator possible private value indeed zero computation invalid permutation correctly say correct determine possible invalid computation need spend time thinking please fix raising exception pointer denominator could zero exception read something like sorry privacy accountant ca yet divide number might zero please find way approximate computation without dividing private value might zero usually done function piecewise three one denominator another denominator another denominator exactly use comparison accomplish work private,issue,positive,negative,neutral,neutral,negative,negative
1321002726,"> We could also persist this `syft settings` to their `~` home directory the same way we do with `hagrid`.

Let's make this bit stretch for 0.7",could also persist home directory way let make bit stretch,issue,negative,neutral,neutral,neutral,neutral,neutral
1321002623,"The quick fix here is to delete the mean() code that is DP specific (and likely incorrect) and add a mean() op to the PassthroughTensor which calls (roughly) self.sum(dim) / self.public_shape[dim]. As an added bonus, we'll get mean() for SMPC too.",quick fix delete mean code specific likely incorrect add mean roughly dim dim added bonus get mean,issue,positive,negative,neutral,neutral,negative,negative
1321001138,"If I understand the problem, this should be an easy fix. Create two RDP constant tables. One which handles RDP constants between 0 and 10 (at 0.01 increments) and another which handles RDP constants >10 at integer increments.

(note - actually building two datastructures and saving both to disk might not be the fastest way to build this feature. These don't actually have to be two separate tables if you know that the first 1000 values map from 0 to 10 and the remaining values from 10 onward. Just make sure you get the key creation logic right for mapping into the RDP array.)",understand problem easy fix create two constant table one another integer note actually building two saving disk might way build feature actually two separate table know first map onward make sure get key creation logic right array,issue,positive,positive,positive,positive,positive,positive
1321000108,"I still don't understand how this error is caused - can you explain a bit more? Taking a guess, it sounds like if RDP < 1 that it gets rounded down to zero (when instead we should be rounding up in all cases... releasing more privacy budget than necessary instead of less).",still understand error explain bit taking guess like rounded zero instead rounding privacy budget necessary instead le,issue,negative,neutral,neutral,neutral,neutral,neutral
1320991743,Note: this is a timing-based side-channel attack we'll need to revisit in the upcoming security push.,note attack need revisit upcoming security push,issue,negative,neutral,neutral,neutral,neutral,neutral
1320991691,Madhava's solution is the best one. Great thinking sir.,solution best one great thinking sir,issue,positive,positive,positive,positive,positive,positive
1320991589,"@rasswanth-s what can we do to split this into two tasks.
1) prevent theft of data using this code path for non SMPC situations
2) fix this in SMPC itself

The goal would be to ship the first in 0.7 and discuss the second for later prioritization",split two prevent theft data code path non fix goal would ship first discus second later,issue,negative,positive,neutral,neutral,positive,positive
1320991394,"Yes I think that's the solution here, at least until we have our own tensor API doc.",yes think solution least tensor doc,issue,positive,negative,negative,negative,negative,negative
1320991107,@iamtrask As I understand it PassthroughTensor is for the server side. Pointers are for the client side. Client side Pointers will never have a .child hence the issue.,understand server side client side client side never hence issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1320991026,Yikes. Do we know how big of a fix this would be?,know big fix would,issue,negative,neutral,neutral,neutral,neutral,neutral
1320990580,"There may need to be some cleanup here involving PassthroughTensor but it's as of yet unclear to me. The idea of PassthroughTensor was to be able to reduce the number of ops we had to implement by implementing some ops by using simpler ops. For example, sum() could be implemented as a series of __add__ operations at the pointer level. This should have alleviated the need for us to implement a sum() method for SMPC or DP as long as SMPC/DP had __add__ implemented. It'd probably be a bit slower, but would bring us to full API functionality faster.

If, however,. there are ops which PassthroughTensor defines but doesn't have functionality for, we should comment them out. However, I think PassthroughTensor is still a good idea, particularly for giving us lots of functionality quickly.",may need cleanup yet unclear idea able reduce number implement simpler example sum could series pointer level need u implement sum method long probably bit would bring u full functionality faster however functionality comment however think still good idea particularly giving u lot functionality quickly,issue,positive,positive,positive,positive,positive,positive
1320990114,"This has been remedied - because we don't have any tensor ops which return a different set of rows based on the private data values - this is a non-issue.

When we eventually add methods which return a different amount of data based on the private data values (a kind of filter method), we will need to revisit this.",tensor return different set based private data eventually add return different amount data based private data kind filter method need revisit,issue,positive,positive,positive,positive,positive,positive
1320989684,"Hi @kkech - this does have a lot in common with PySyft's roadmap. One specific difference, the ""need to agree a common data model"" is something we think we've gotten past through the use of pointers and RPC. With PySyft, in theory you don't need to convince a bunch of data holders to agree to format their data in similar ways. We assume data scientists will do that remotely using the PySyft API.

Additionally - I feel it's too early for a marketplace (I assume you're implying $ changing hands) to exist as various serious aspects like security and legal interpretation of PETs are still uncertain.

Closing for now but I appreciate the vision you're bringing to the community!",hi lot common one specific difference need agree common data model something think gotten past use theory need convince bunch data agree format data similar way assume data remotely additionally feel early assume exist various serious like security legal interpretation still uncertain appreciate vision community,issue,positive,negative,neutral,neutral,negative,negative
1320950831,@teo-milea  Can you please assign me to solve this error? I will create the PR to dev with fixing. Thanks,please assign solve error create dev fixing thanks,issue,positive,positive,positive,positive,positive,positive
1319842552,I don't think so. `ones_like` was implemented but doesn't work. Maybe @rasswanth-s can confirm?,think work maybe confirm,issue,negative,neutral,neutral,neutral,neutral,neutral
1319644513,"That is a good question, but given that all these checks happen in `phi_tensor.py` on the server side, that shouldn't be an issue as we don't support GPU yet (or at least that is what I thought). If that is not the case, we can change it to something that prevents this, but my suspicion is that this will not be the only problem when adding GPU support.",good question given happen server side issue support yet least thought case change something suspicion problem support,issue,negative,positive,positive,positive,positive,positive
1319621808,Cool! I will start my work on this :rocket: ,cool start work rocket,issue,negative,positive,positive,positive,positive,positive
1319619196,"Hi @shashankc28

If you want to try to fix this yourself you can checkout the branch here:
https://github.com/OpenMined/pysyft/tree/syft_0.5.0

Then just take a look at the `torch` code and enable any additional methods you might need.

Unfortunately we can't support 0.5 anymore.",hi want try fix branch take look torch code enable additional might need unfortunately ca support,issue,negative,negative,negative,negative,negative,negative
1319617959,"@X-Omil , this currently uses SyMPC respository, which was supported in `0.5.0`, most of the SMPC functionality have changed.
We have an upcoming SMPC introduction notebook which would be released next week, which has the code context for our current architecture.",currently functionality upcoming introduction notebook would next week code context current architecture,issue,negative,neutral,neutral,neutral,neutral,neutral
1319616482,@teo-milea won't this incur a copy to the CPU with numpy if it happens to be in jax or another tensor library on GPU? ,wo incur copy another tensor library,issue,negative,neutral,neutral,neutral,neutral,neutral
1319614870,@chinmaydas96 yeah the VirtualMachine doesn't have the service try a `Domain`. I would highly recommend updating to `syft` 0.7. Install `hagrid` from the main README and use `hagrid quickstart` and follow the install wizard and tutorials.,yeah service try domain would highly recommend install main use follow install wizard,issue,positive,positive,positive,positive,positive,positive
1319612157,"> @kangxiangping I am glad you got this working. The Docs team are working on more notebooks and when they are merged in they will be linked from the README and available in this notebook. 🙂
> 
> I will close this issue for now.

OK! Thank you and your team for your hard work.",glad got working team working linked available notebook close issue thank team hard work,issue,positive,positive,positive,positive,positive,positive
1319608366,"@kangxiangping I am glad you got this working. The Docs team are working on more notebooks and when they are merged in they will be linked from the README and available in this notebook. 🙂

I will close this issue for now.",glad got working team working linked available notebook close issue,issue,negative,positive,positive,positive,positive,positive
1319595143,"@teo-milea this looks related https://github.com/OpenMined/PySyft/issues/6876
I suspect the solution might also be similar. Detect the NotImplemented and dispatch the `r` op?",related suspect solution might also similar detect dispatch,issue,negative,neutral,neutral,neutral,neutral,neutral
1319587438,@tudorcebere since this forces a mutation do you think this is an issue? Or does it not matter since the user who has permission can anyway and as you said the bytes representation is stable in `0.8`?,since mutation think issue matter since user permission anyway said representation stable,issue,negative,neutral,neutral,neutral,neutral,neutral
1319586125,"@bipinKrishnan Thanks. I have assigned you, let me know if you have any questions. 🙂",thanks assigned let know,issue,negative,positive,positive,positive,positive,positive
1319582683,"@bitsofsteve great work.
I tested it and it works. I think there are some small changes that we want to do before merge.

It seems like it shows the health check twice?
<img width=""611"" alt=""Screen Shot 2022-11-18 at 3 52 15 pm"" src=""https://user-images.githubusercontent.com/2882739/202630865-bd43d41f-759e-40d2-954e-43bc9a4c4b10.png"">

The description on logging doesnt wrap properly.
<img width=""667"" alt=""Screen Shot 2022-11-18 at 3 53 06 pm"" src=""https://user-images.githubusercontent.com/2882739/202630905-a6cf8871-291e-4d5b-aa6b-a0a925b1eeb9.png"">
I think what you want to do here is remove the line breaks from the actual quoted text and instead break up the string like this to format it:

```python
long_string = (
+ ""a really long line here""
+ ""more long line continued here\n"" # \n for explicit line breaks
)
```

That might fix it.
<img width=""764"" alt=""Screen Shot 2022-11-18 at 3 52 59 pm"" src=""https://user-images.githubusercontent.com/2882739/202630888-b48ac71a-73e2-4258-8584-a6fb3536e05d.png"">


",great work tested work think small want merge like health check twice screen shot description logging doesnt wrap properly screen shot think want remove line actual text instead break string like format python really long line long line continued explicit line might fix screen shot,issue,positive,positive,neutral,neutral,positive,positive
1319571706,"I think rather than extending the cache, anything which is outside the cache range should just be passed to `find_alpha_and_eps` sure its going to be slow but its predictably slow where as if you jump really high you generate everything from 1.2 million RDP constants to where ever you jumped inclusive when often you will only want a few values. We can then also introduce a timeout so that if it fails to solve all the RDP Constants for a query by a certain time we raise an Exception. Then at least we arent crashing the server.

Thoughts?

Then for a future task:
- Making that run in parallel in the background will then be easier.
- We can also later change the cache structure so the ranges <50 >50 etc can be seperate arrays. If a user jumps into the distance we can just create a new array at that position, solve the answer and then optionally kick off a multithreaded cache building search around that value range to close the gaps.",think rather extending cache anything outside cache range sure going slow predictably slow jump really high generate everything million ever inclusive often want also introduce solve query certain time raise exception least arent server future task making run parallel background easier also later change cache structure user distance create new array position solve answer optionally kick multithreaded cache building search around value range close,issue,positive,positive,neutral,neutral,positive,positive
1319544886,"Ah I think I see now you're saying. I think that since we need to re-think the data structure for DSA so that it can handle dynamic updates we should add this to the requirements so what ever we build can identify if the tree of DSA data is `homogenous` or not. Although perhaps it's not needed at that stage. We could not convert `PhiTensor` to `GammaTensor` when its a root tensor and then it would be implied that its DSA would be singular, then allow composition from that point on.

https://github.com/OpenMined/Heartbeat/issues/1027",ah think see saying think since need data structure handle dynamic add ever build identify tree data homogenous although perhaps stage could convert root tensor would would singular allow composition point,issue,positive,neutral,neutral,neutral,neutral,neutral
1319522219,"@the-elancier great spot.

I have verified this occurs and that its related to the internal implementation of `int` `__add__` which returns `NotImplemented` and normally triggers an `__radd__` on `float`.

If you reverse the pointer addition everything works as expected.
To solve this we could use some simple `heuristics` to detect the `NotImplementedError` and check if the `self.path` contains `__dunder__` method and if that `__dunder__` method has a corresponding `__rdunder__` version, swap the arg order and execute it.

@tudorcebere I think we might have discussed this last year but never fixed it.

For anyone interested in working on this its likely to only be:
```python
# packages/syft/src/syft/core/node/common/action/run_class_method_action.py

# try catch here and implement swapping logic
result = method(*upcasted_args, **upcasted_kwargs)
```",great spot related internal implementation normally float reverse pointer addition everything work solve could use simple detect check method method corresponding version swap order execute think might last year never fixed anyone interested working likely python try catch implement swapping logic result method,issue,positive,positive,positive,positive,positive,positive
1319506345,Docs and README can be based off this notebook session 5 notebook.,based notebook session notebook,issue,negative,neutral,neutral,neutral,neutral,neutral
1319498543,"We could do two things:
1) hash the files and if they are the same just skip asking for that file
2) provide the opposite of `a` all as `s` skip all or something similar

If some one in the community wants to do it they are welcome, however since this is low priority I will triage it as so for now. ",could two hash skip file provide opposite skip something similar one community welcome however since low priority triage,issue,negative,positive,positive,positive,positive,positive
1319491260,"@Boluwatifeh Are you able to submit a PR with progress? If you are too busy, I can unassign the ticket so that the task can be taken by someone else.",able submit progress busy ticket task taken someone else,issue,negative,positive,positive,positive,positive,positive
1319490479,Hi @Sukanya-rs I suspect there's no easy way to know if a server which waits for incoming requests should be safely automatically shutdown. In theory we could do some kind of loadbalancing and detect no traffic and shut down containers but I suspect that is out of the scope of local dev mode deployments anyway. I will close this for now.,hi suspect easy way know server incoming safely automatically shutdown theory could kind detect traffic shut suspect scope local dev mode anyway close,issue,positive,positive,positive,positive,positive,positive
1319469624,Oh apologies. Looks like that has always been the plan. I only just now saw the empty `proxy_dataset.py` file.,oh like always plan saw empty file,issue,negative,negative,neutral,neutral,negative,negative
1319467185,"Thanks @ivyclare.

We could merge this but as @madhavajay said `ProxyDataset` was originally only meant for tensors/arrays. This PR makes it work with other things with `__len__` but also open to all kind of variables and might cause other issues down the line?

Should we merge this and create an issue to remind us to implement `ProxyObject` for things other than tensors/arrays?",thanks could merge said originally meant work also open kind might cause line merge create issue remind u implement,issue,positive,positive,positive,positive,positive,positive
1319448555,Agree. Gonna close this as duplicated.,agree gon na close,issue,negative,neutral,neutral,neutral,neutral,neutral
1319448030,@ShubhamPalriwala great working finding that. I will get this ticket triaged so lets not work on it yet but this will be something we can do soon.,great working finding get ticket work yet something soon,issue,positive,positive,positive,positive,positive,positive
1319447239,"I think we can create something similar to this:
https://github.com/OpenMined/Heartbeat/issues/1009

Check for a few basic pre-reqs that `hagrid` needs and then attempt to install them and hagrid.",think create something similar check basic need attempt install,issue,negative,neutral,neutral,neutral,neutral,neutral
1319425331,@rAlexandre00 I think docker engine has switched to a `year.month` style versioning. I think anything from 20.04 or 20.10 onwards is fine and anything older is going to be ancient. However this is not a high priority so I wont schedule this in to be worked on just yet.,think docker engine switched style think anything onwards fine anything older going ancient however high priority wont schedule worked yet,issue,negative,positive,positive,positive,positive,positive
1319419938,"I think the simplest fix here is that by having the error message in this issue people can find it, and that in future we should create a common errors list somewhere in the docs.",think fix error message issue people find future create common list somewhere,issue,negative,negative,negative,negative,negative,negative
1319337704,"This feels like a combo of both these issues:

1) calling passthrough tensor methods on a pointer
https://github.com/OpenMined/PySyft/issues/7043

2) triggering ufunc by passing pointers / tensor types to np.functional calls
https://github.com/OpenMined/PySyft/issues/7042",like calling tensor pointer passing tensor,issue,negative,neutral,neutral,neutral,neutral,neutral
1319335189,"Yeah doesnt supporting the `np` functional style require us to provide `__array_ufunc__` support?

I believe we started this in `PassthroughTensor` but its probably incomplete and it was super confusing.

Perhaps the easiest thing here is to raise `NotImplementedError` for now?

```python
    def __array_function__(
        self,
        func: Callable,
        types: List[Type],  # what this means =  List of Type(Type())
        args: List[Any],
        kwargs: Dict[str, Any],
    ) -> PassthroughTensor:
        # Note: this allows subclasses that don't override
        # __array_function__ to handle PassthroughTensor objects.
        if not all(issubclass(t, self.__class__) for t in types):
            return NotImplemented

        implementation = query_implementation(self.__class__, func)
        if implementation:
            return implementation(*args, **kwargs)
        return self.__class__(func(*args, **kwargs))

    def __array_ufunc__(self, ufunc, method, *inputs, **kwargs):
        implementation = query_implementation(self.__class__, ufunc)
        if implementation:
            return implementation(*inputs, **kwargs)
        return self.__class__(ufunc(*inputs, **kwargs))
```",yeah doesnt supporting functional style require u provide support believe probably incomplete super perhaps easiest thing raise python self callable list type list type type list note override handle return implementation implementation return implementation return self method implementation implementation return implementation return,issue,positive,positive,positive,positive,positive,positive
1319331801,"I think this is a duplicate of this:
https://github.com/OpenMined/PySyft/issues/6922

The problem is that the `Pointer` class inherits from `PassthroughTensor` I dont think thats correct because Pointers arent tensors and dont have a .child.",think duplicate problem pointer class dont think thats correct arent dont,issue,negative,neutral,neutral,neutral,neutral,neutral
1318529519,Before fixing this we need to decide whether we're actually going to try to modify the numpy API or whether we should just make an imitation syft.numpy module where we define our own methods (like zeroes_like()) with no connection to actual numpy. If unsure we should do the latter for now because it's easier to build and easier to change later (and less likely to be buggy),fixing need decide whether actually going try modify whether make imitation module define like connection actual unsure latter easier build easier change later le likely buggy,issue,positive,negative,neutral,neutral,negative,negative
1318516462,"Hello @chinmaydas96.

Thank you for opening the issue.
Are you using the latest version of PySyft?

Looking at the code, the VirtualWorker it is something that I am not aware that we use anymore.",hello thank opening issue latest version looking code something aware use,issue,negative,positive,positive,positive,positive,positive
1318195552,@madhavajay there's something wrong with `shell: bash` on windows. They're currently all throwing `Error: Process completed with exit code -1073740791.`,something wrong shell bash currently throwing error process exit code,issue,negative,negative,negative,negative,negative,negative
1318186664,"Updated the form as per Kyoko's feedback: https://forms.gle/mL5HJrh96FnpvU8p6

@IrinaMBejan @Kiaka007:
- Let me know to what email should I transfer the ownership
- And do you want me to remove the form from the page right now and add something like coming soon or just our email ID?",form per feedback let know transfer ownership want remove form page right add something like coming soon id,issue,negative,positive,positive,positive,positive,positive
1318177400,"Also got

```
Run echo ""::set-output name=date::$(date +'%Y-%m-%d')""
Get-Date : Cannot bind parameter 'Date'. Cannot convert value ""+%Y-%m-%d"" to type ""System.DateTime"". Error: ""String
was not recognized as a valid DateTime.""
At C:\Users\azureuser\actions-runner\_work\_temp\d7527863-397d-4a3e-81be-adf7150401f2.ps1:2 char:38
+ echo ""::set-output name=date::$(date +'%Y-%m-%d')""
+                                      ~~~~~~~~~~~
    + CategoryInfo          : InvalidArgument: (:) [Get-Date], ParentContainsErrorRecordException
    + FullyQualifiedErrorId : CannotConvertArgumentNoMessage,Microsoft.PowerShell.Commands.GetDateCommand

Error: Process completed with exit code 1.
```

Just pushed a commit to fix this.",also got run echo date bind parameter convert value type error string valid char echo date error process exit code commit fix,issue,negative,neutral,neutral,neutral,neutral,neutral
1318152728,"Awesome work @yashgorana. This works great!
<img width=""675"" alt=""Screen Shot 2022-11-17 at 4 29 57 pm"" src=""https://user-images.githubusercontent.com/2882739/202372929-2006c835-d5c1-44e1-9c73-05674851ced7.png"">

I removed the two unused ports for seaweedfs and rabbitmq (s3 and amqp) so that users dont try to open them with the dev tools and get nothing useful.
",awesome work work great screen shot removed two unused dont try open dev get nothing useful,issue,positive,positive,positive,positive,positive,positive
1317742405,The `search` method for the domain was removed to avoid misunderstanding and unexpected behavior since it had no purpose for the domain nodes. Now we only have the `search`  method at NetworkClient API.,search method domain removed avoid misunderstanding unexpected behavior since purpose domain search method,issue,negative,positive,neutral,neutral,positive,positive
1317484609,"Unable to reproduce this issue- when I ran the code posted I got the same RDP constants and epsilon spend both times
FWIW this also suffers from #6949 since sigma=1 made the RDP constant = 0.03966208 for me 

I'll circle back to this once that issue is fixed",unable reproduce ran code posted got epsilon spend time also since made constant circle back issue fixed,issue,negative,negative,neutral,neutral,negative,negative
1317434568,"This issue is synonymous with #6949 
This is because setting sigma = 1 results in an RDP constant that is less than 1, which causes this error to kick in",issue synonymous setting sigma constant le error kick,issue,negative,neutral,neutral,neutral,neutral,neutral
1317161877,I think this should have been fixed by #7024. TLDR: just wrap the check everywhere in the codebase with a NumPy array. Can we close this?,think fixed wrap check everywhere array close,issue,negative,positive,neutral,neutral,positive,positive
1316503619,"Closing this PR, since it looks like we won't be swinging the way of Docker swarm anyways.",since like wo swinging way docker swarm anyways,issue,negative,neutral,neutral,neutral,neutral,neutral
1316459752,"@IonesioJunior given you fixed this issue recently: https://github.com/OpenMined/PySyft/pull/7004

Can you take a look at this and figure out if its still an issue and resolve it. There's also an included test I wrote so its worth seeing that passes or not.",given fixed issue recently take look figure still issue resolve also included test wrote worth seeing,issue,positive,positive,positive,positive,positive,positive
1314691527,"I found absolute syft imports in file:
`packages/syft/src/syft/util.py`
`packages/syft/src/syft/ast/klass.py`
`packages/syft/src/syft/core/common/serde/serializable.py`
`packages/syft/src/syft/core/common/serde/serialize.py`
`packages/syft/src/syft/core/node/common/node_manager/redis_store.py`
maybe we could replace them also, in rest I think we are good for merge.

",found absolute file maybe could replace also rest think good merge,issue,negative,positive,positive,positive,positive,positive
1313443267,+1 for this PR and the circular import one. One problem with `syft` right now is slow import OpenMined/Heartbeat#1008. One solution is lazy import and for that to work we need to get rid of circular imports.,circular import one one problem right slow import one solution lazy import work need get rid circular,issue,negative,negative,neutral,neutral,negative,negative
1313149886,"> @kangxiangping did you run the cells? The `quickstart` command in the notebook gives you a list of other tutorials to download.

Yes! I've learned all these tutorials and run all the cells. This benefits me a lot, so I want to learn a tutorial on data-scientist, such as how to have domain nodes jointly train a model with federated learning.",run command notebook list yes learned run lot want learn tutorial domain jointly train model learning,issue,negative,neutral,neutral,neutral,neutral,neutral
1313087452,@bitsofsteve great work but please stick to the scope of the ticket for now. This ticket only needs `--tail=fase` and a list of the docker commands.,great work please stick scope ticket ticket need list docker,issue,positive,positive,positive,positive,positive,positive
1313085065,"@IshanMi could this just be because the Pointer classes subclass from `PassthroughTensor`?

```python
class TensorWrappedPhiTensorPointer(Pointer, PassthroughTensor):

class TensorWrappedGammaTensorPointer(Pointer, PassthroughTensor):
```",could pointer class subclass python class pointer class pointer,issue,negative,neutral,neutral,neutral,neutral,neutral
1313083435,"Yes as per @hadjipantelis suggestion 0.6 is a bit dated now we have the `course3` code here which is compatible with `dev` / `0.7.0 betas`:
https://github.com/OpenMined/courses/tree/introduction-to-remote-data-science-dev",yes per suggestion bit course code compatible dev,issue,negative,neutral,neutral,neutral,neutral,neutral
1313075818,@kangxiangping did you run the cells? The `quickstart` command in the notebook gives you a list of other tutorials to download.,run command notebook list,issue,negative,neutral,neutral,neutral,neutral,neutral
1312652735,"### Proposed solution
Move `downcast_args_and_kwargs` and `upcast_args_and_kwargs` to an independent module where both `ast` and `lib` modules can import without creating a circular import issue.

<img width=""692"" alt=""circular_import_callable_lib_solution"" src=""https://user-images.githubusercontent.com/26658472/201509509-09dc4b72-21a8-48f6-8a4e-2d763b05ef4f.png"">
",solution move independent module ast import without circular import issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1312608580,Context for the Node -> node commit https://github.com/OpenMined/PySyft/pull/7022#issuecomment-1310737272,context node node commit,issue,negative,neutral,neutral,neutral,neutral,neutral
1312549137,"@madhavajay  I would like to work on this issue if no one else has already started. 

Replacing [this](https://github.com/OpenMined/PySyft/blob/d2bc2290b545c37bb0b6f0a0ad888530ae284405/packages/hagrid/hagrid/cli.py#L2981) print statement with the below one should solve the issue, right?
```python3
print(""Video Explanation: https://youtu.be/BJhlCxerQP4\n"")
```",would like work issue one else already print statement one solve issue right python print video explanation,issue,positive,positive,positive,positive,positive,positive
1312249456,"@shubham3121 @madhavajay can you please take a look at this.

I can also directly print out `http://localhost:[port]` for ease-of-use, but trying to keep parity with the previous script's output.",please take look also directly print trying keep parity previous script output,issue,negative,negative,neutral,neutral,negative,negative
1311587514,"I added a quick fix in #7024 but no `equality` check function, maybe we can add it in `0.8`",added quick fix equality check function maybe add,issue,negative,positive,positive,positive,positive,positive
1311458669,@madhavajay @rasswanth-s  I think the `k8` tests are failing here. Should I continue to restart them until they pass?,think failing continue restart pas,issue,negative,neutral,neutral,neutral,neutral,neutral
1311298491,"I also noticed, some issues with the CI log collector action, give me some time and I'll push a commit. ",also log collector action give time push commit,issue,negative,positive,neutral,neutral,positive,positive
1310737272,Should we change `Checking Node API` to `Checking node API`? Kinda silly but the first time I saw it my first thought was NodeJS.,change node node silly first time saw first thought,issue,negative,neutral,neutral,neutral,neutral,neutral
1310530186,So looks like the problem was due to the container name returned from the shell command being quoted in windows (*e.g* `'test_container_name'`) and that's an illegal filename. The `Remove single quotes` commit fixes this.,like problem due container name returned shell command illegal remove single commit,issue,negative,negative,negative,negative,negative,negative
1309883379,"I couldn't reproduce the numpy warning and the overflows happen on the server too, but given the new checks from #7008 and #7002 we should be safe for now, maybe keep it in a backlog somewhere for when we do another red teaming effort?
",could reproduce warning happen server given new safe maybe keep backlog somewhere another red teaming effort,issue,negative,positive,positive,positive,positive,positive
1309744510,"Maybe we could remove the id_at_location_override argument in .send method
https://github.com/OpenMined/PySyft/blob/795805b8355b04836c138e8c5dc0e38893523063/packages/syft/src/syft/ast/klass.py#L685

in klass.py
since it is a more public facing API, which might make users (or Data Scientist) think they could override particular UID.
For the case , in which a malicious user, creates a save object action manually I think the server side error would be perfect.",maybe could remove argument method since public facing might make data scientist think could override particular case malicious user save object action manually think server side error would perfect,issue,negative,positive,positive,positive,positive,positive
1309687943,"@teo-milea and @IshanMi Considering that we shouldnt change precision for users unless they want it, and this happens locally the same as it would with any overflows and there is a numpy warning already, would you say that this can be closed for now?",considering shouldnt change precision unless want locally would warning already would say closed,issue,negative,negative,neutral,neutral,negative,negative
1309647464,"@madhavajay I am also thinking for the hagrid logs command we should have an option for log file dump to a directory.. something like `hagrid logs {{DOMAIN_NAME}} --dump_file=true` or something. I'd assume, this can be helpful, maybe? ",also thinking command option log file dump directory something like something assume helpful maybe,issue,negative,neutral,neutral,neutral,neutral,neutral
1309645677,"@madhavajay @iamtrask for this improvement, I have a PR open for this and have built the first working version of `hagrid logs`. 
 See PR [Here](https://github.com/OpenMined/PySyft/pull/7011) 

Please take a look here to leave a comment, if there's how we can make more improvements especially related to the wording of the output etc. 

I also assumed it will be best to default `--tail=false` even in dev mode, except explicitly set to `true.`
",improvement open built first working version see please take look leave comment make especially related wording output also assumed best default even dev mode except explicitly set,issue,positive,positive,positive,positive,positive,positive
1308965051,"I dont seem to reproduce this on the twitter notebook, but I was able to overflow `max_vals` so `min_vals > max_vals` but I cant find any exploit with them, if any of you can let me know so I can test it",dont seem reproduce twitter notebook able overflow cant find exploit let know test,issue,negative,positive,positive,positive,positive,positive
1308212089,"yep, I think at this point is mostly and UX issues, as we are adding guards against NaN/Inf values in publish. The way we solved this for the demo is to add `1` to both members of the fraction, which is a pretty common thing to do in data science, so the practice should be kept for remote data science
",yep think point mostly publish way add fraction pretty common thing data science practice kept remote data science,issue,positive,positive,neutral,neutral,positive,positive
1308210527,"My guess is that in was on the `bounds` so it should be both locally and on the server as well, but I can investigate today.",guess locally server well investigate today,issue,negative,neutral,neutral,neutral,neutral,neutral
1308011007,"Okay so essentially were just saying, hey what ever op you used to get here, the ability to add noise to the result is undefined and therefore we can't let you publish it. Seems reasonable to me.",essentially saying hey ever used get ability add noise result undefined therefore ca let publish reasonable,issue,negative,positive,neutral,neutral,positive,positive
1308007573,I wouldn't say the first option is a quick enough fix to ship before the end of the week. Is the second option easy?,would say first option quick enough fix ship end week second option easy,issue,negative,positive,positive,positive,positive,positive
1308006175,"@teo-milea Correct me if i'm wrong but this is happening locally right, we don't automatically return any warnings or errors to the user from the server of private data, so its not on the data but something else, like the `data_subjects` or the `bounds`?",correct wrong happening locally right automatically return user server private data data something else like,issue,negative,negative,neutral,neutral,negative,negative
1307573027,"There are two quick fixes for this:
1) pre-generate a larger RDP cache (possibly in a thread)
2) the client can deny a .publish() event if it's likely to generate a privacy budget spend higher than the upper bound that the client already knows about.",two quick cache possibly thread client deny event likely generate privacy budget spend higher upper bound client already,issue,negative,positive,positive,positive,positive,positive
1307441810,"Perhaps we can fall back on `private=False`, and throw an exception if `min_vals.data` or `max_vals.data` is a NaN or Inf",perhaps fall back throw exception nan,issue,negative,neutral,neutral,neutral,neutral,neutral
1307440309,"If there's a NaN or Inf value in our array, my gut feeling says there's a good chance the min_val or max_val might also be NaN or Inf so private=False might also fail",nan value array gut feeling good chance might also nan might also fail,issue,positive,positive,neutral,neutral,positive,positive
1307294725,"I tested this and indeed the RDP constants become `NaN` and you can leak a whole array with a single `NaN` value. I inspected the code for `compute_rdp_constant` in `data_subject_ledger.py` and I was thinking that maybe when we detect `NaN` values (or `Inf` values) we can call computer_rdp_constant with private=False to use the bonds when computing the budget spent. @IshanMi what do you think about this solution?
",tested indeed become nan leak whole array single nan value code thinking maybe detect nan call use budget spent think solution,issue,negative,positive,neutral,neutral,positive,positive
1307247582,"> Looks better way now! Maybe in the future, we can change this table to change its size dynamically according to the size of the output ![datasets_vis](https://user-images.githubusercontent.com/26658472/200556637-36db6de0-a054-41fd-91db-4d611fa89a3f.png)

Could we create a subsequent issue for this (the dynamic size for the table)? 😄 ",better way maybe future change table change size dynamically according size output could create subsequent issue dynamic size table,issue,positive,positive,positive,positive,positive,positive
1307187078,"Let me see if I can get this working as expected -- if we need to do many backend changes, we drop this part.",let see get working need many drop part,issue,negative,positive,positive,positive,positive,positive
1307185268,Yes :) Let's get it done.,yes let get done,issue,negative,neutral,neutral,neutral,neutral,neutral
1307084824,"Looks better way now! Maybe in the future, we can change this table to change its size dynamically according to the size of the output
![datasets_vis](https://user-images.githubusercontent.com/26658472/200556637-36db6de0-a054-41fd-91db-4d611fa89a3f.png)
",better way maybe future change table change size dynamically according size output,issue,positive,positive,positive,positive,positive,positive
1307054898,"@IonesioJunior ,I think when module name is too large , it overlaps with ID , when we view the datasets, 
Maybe we could print just the class Name without the path or reformat the pandas table?
![Screenshot 2022-11-08 at 4 51 58 PM](https://user-images.githubusercontent.com/43314053/200551570-e55ef65e-f513-4215-8aba-2b774591ac34.png)
",think module name large id view maybe could print class name without path table,issue,negative,positive,positive,positive,positive,positive
1307038971,"hmm the k8s integration test just stuck forever at `
Waiting for service backend --context k3d-test-domain-2 --namespace test-domain-2...`. alr rerun the job 3 times... ",integration test stuck forever waiting service context rerun job time,issue,negative,neutral,neutral,neutral,neutral,neutral
1306764422,"But this also happened for me, I was doing a mean query over a dataset of 13k rows with a max value of 150.",also mean query value,issue,negative,negative,negative,negative,negative,negative
1306717635,"> @bitsofsteve Looks like a conflict, can you fix it and make the requested changes so we can get this into production?

@rasswanth-s @madhavajay this is ready for merge. ",like conflict fix make get production ready merge,issue,negative,positive,positive,positive,positive,positive
1306678724,"That's a good point. It probably is, as we were summing 10k values with a max_val of 700_000. The real question is whether this overflow creates a privacy problem when publishing, so I guess it is pretty urgent.",good point probably real question whether overflow privacy problem guess pretty urgent,issue,positive,positive,positive,positive,positive,positive
1306675518,"That should not be the case, as min and max are public values, the problem is that publishing fails and we feel like the problem should be raised here rather than on publishing. The problem you are describing is more related to #6956 if we raise an error instead of returning an array of Nans or maybe just noise. ",case min public problem feel like problem raised rather problem related raise error instead array maybe noise,issue,negative,neutral,neutral,neutral,neutral,neutral
1306664227,"Cool, thanks for the quick review and feedback everyone :heart:.",cool thanks quick review feedback everyone heart,issue,positive,positive,positive,positive,positive,positive
1306622637,"@IonesioJunior I'd prefer we merge this now to unblock other related issues. For the integration test I created OpenMined/Heartbeat#1018.
@rasswanth-s This does not actually fix the underlying issue in OpenMined/PySyft#6940, only the exception handling part so I just removed the link.",prefer merge unblock related integration test actually fix underlying issue exception handling part removed link,issue,negative,neutral,neutral,neutral,neutral,neutral
1306605348,"Nice Find @kiendang , great  work for the extensive description of the Problem.",nice find great work extensive description problem,issue,positive,positive,positive,positive,positive,positive
1306595818,"@iamtrask , @IshanMi  One small question, Accurate shape as in the public shape of TensoWrappedPhiTensorPointer/TensorWrappedGammaTensorPointer?",one small question accurate shape public shape,issue,negative,positive,neutral,neutral,positive,positive
1306553924,"In discussion with @rasswanth-s I agree the solution here for now is to raise an Exception since there should never be more than 1 `SaveObjectAction` to the same UID. Anything else that is true mutation should be a different operation anyway. Can we add code to check the write_permissions as well so that later any code which just raises the exception isnt removed re-opening this problem. So perhaps, two different exceptions. 
1) you do not have write permission to this UID
2) you have already executed SaveObjectAction against this UID",discussion agree solution raise exception since never anything else true mutation different operation anyway add code check well later code exception removed problem perhaps two different write permission already executed,issue,negative,positive,neutral,neutral,positive,positive
1306545745,"@madhavajay , this issue is for the override of the Data itself, using the .send method which contains the id_at_location_override , the later is for the deletion of data.",issue override data method later deletion data,issue,negative,neutral,neutral,neutral,neutral,neutral
1306524856,@tcp we can just remove this from the HTML unless you think it should work or theres a better way?,remove unless think work there better way,issue,negative,positive,positive,positive,positive,positive
1306517549,@tcp any chance you can take a look at this? Or if you think its a non issue or there is a better way to solve let me know.,chance take look think non issue better way solve let know,issue,positive,positive,positive,positive,positive,positive
1306515677,I agree that we shouldn't have a lot of manually constructed Pointer classes but we might want to address during `Derived Services`.,agree lot manually pointer class might want address derived,issue,negative,neutral,neutral,neutral,neutral,neutral
1306513903,"If you publish something don't you just change its ""accuracy"". Shouldn't the `Pointer` that you call publish on know its type and therefore the resultant Published Pointer would also have the correct type?

It just looks like Any is hardcoded.

```
def publish(self, sigma: float = 1.5, private: bool = True) -> Any:

        # relative
        from ..node.common.node_service.publish.publish_service import (
            PublishScalarsAction,
        )

        id_at_location = UID()

        obj_msg = PublishScalarsAction(
            id_at_location=id_at_location,
            address=self.client.address,
            publish_ids_at_location=[self.id_at_location],
            sigma=sigma,
            private=private,
        )

        self.client.send_immediate_msg_without_reply(msg=obj_msg)
        # create pointer which will point to float result

        ptr = self.client.lib_ast.query(""syft.lib.python.Any"").pointer_type(
            client=self.client
        )
```",publish something change accuracy pointer call publish know type therefore resultant pointer would also correct type like publish self sigma float private bool true relative import create pointer point float result,issue,positive,positive,positive,positive,positive,positive
1306508724,"The code is supposed to exit the while loop where it tries to reduce the accuracy and remain within budget if it has not successfully reduced the budget spend from the previous iteration to prevent infinite looping. In the fail case it should return noise.

That exception should be caught and the end of the functions generate noise in the shape of the tensor code should still return.",code supposed exit loop reduce accuracy remain within budget successfully reduced budget spend previous iteration prevent infinite looping fail case return noise exception caught end generate noise shape tensor code still return,issue,negative,positive,neutral,neutral,positive,positive
1306506142,"This is a duplicate of this right?
https://github.com/OpenMined/PySyft/issues/6978

Users can always create manual messages, the issue is that `ObjectDeleteMessage` has no check to see if the owner of the data `verify_key in result_write_permissions` is true.",duplicate right always create manual issue check see owner data true,issue,positive,positive,positive,positive,positive,positive
1306501371,Is this because of the underlying data type? E.g. Int32? The error is coming from `numpy` so unless we change the precision to higher how can we avoid this issue?,underlying data type error coming unless change precision higher avoid issue,issue,negative,positive,positive,positive,positive,positive
1306499758,"This doesn't seem like something we can quickly fix for 0.7. My suggestion is we revisit this as part of the work to provide the  User access to the Action Graph in 0.8. In the mean time I guess we have to raise an Exception. Forcing a cache rebuild and there by overloading the domain is not really a solution. Also, do we need to extend the entire cache just to solve for a value which is out of range? Can't we just force calculate things outside of the cache but not cache the results?",seem like something quickly fix suggestion revisit part work provide user access action graph mean time guess raise exception forcing cache rebuild domain really solution also need extend entire cache solve value range ca force calculate outside cache cache,issue,positive,positive,neutral,neutral,positive,positive
1306497471,Would this allow someone to detect 0's by dividing and publishing without spending?,would allow someone detect dividing without spending,issue,negative,neutral,neutral,neutral,neutral,neutral
1306496170,@shubham3121 The code seems fine if the type is `np.ndarray` which is what a lazyrepeatarray is supposed to represent right? So maybe we just need a `NumpyLike` type which can also be `lazyrepeatarray`?,code fine type supposed represent right maybe need type also,issue,negative,positive,positive,positive,positive,positive
1305969514,"> Hi @ShubhamPalriwala ,
> 
> It seems this reversed the changes added last time by Mrinal. This is the latest version of the notebook which got broken by the merge: https://github.com/abhiwalia15/PySyft/blob/7b493eb48bb19b4f829604c12f950002d0a721cf/notebooks/quickstart/data-owner/01-upload-data.ipynb
> 
> Let me know when it is updated, thanks for the help!

This is the latest commit in which I have included the gif image for changing the admin credentials from UI. ",hi reversed added last time latest version notebook got broken merge let know thanks help latest commit included gif image,issue,positive,positive,positive,positive,positive,positive
1305961044,"Hi @ShubhamPalriwala ,

It seems this reversed the changes added last time by Mrinal. This is the latest version of the notebook which got broken by the merge:
https://github.com/abhiwalia15/PySyft/blob/7b493eb48bb19b4f829604c12f950002d0a721cf/notebooks/quickstart/data-owner/01-upload-data.ipynb

Let me know when it is updated, thanks for the help!",hi reversed added last time latest version notebook got broken merge let know thanks help,issue,negative,positive,neutral,neutral,positive,positive
1305557065,"@madhavajay @IshanMi what do we want the return type to be here for min_vals and max_vals, Tensor or lazyrepeatarray: 

![Screenshot from 2022-11-07 18-12-32](https://user-images.githubusercontent.com/11032835/200313395-f3fd70e1-b773-4cd4-8e0c-d666d7b820bd.png)

Currently, in the code, we are trying to convert the min_vals and max_vals to Tensor (or the class the variable `data` represents). Let me know the requirements and I can make the change accordingly.",want return type tensor currently code trying convert tensor class variable data let know make change accordingly,issue,negative,neutral,neutral,neutral,neutral,neutral
1305528809,"@madhavajay seems like the domain client is re-using the `NetworkSearchMessage` (defined for networks) and there is no service class defined to handle this type of message in the case of the domain client. 
Therefore the search method in the domain_client.py is of no use. Do we want to have a `.search` feature on the domain and if so should we prioritise it in 0.8 and remove the search method now altogether for now ?? 
Also, I feel this should be more like `domain_client.store.search` instead",like domain client defined service class defined handle type message case domain client therefore search method use want feature domain remove search method altogether also feel like instead,issue,positive,neutral,neutral,neutral,neutral,neutral
1305357510,"Placeholder: Also calling 
domain.settings retrieves the setup values and the private key.",also calling setup private key,issue,negative,neutral,neutral,neutral,neutral,neutral
1305298357,@abhiwalia15 Please confirm that I have not missed anything while solving the issue that might have been initially caused due to a git merge or something.,please confirm anything issue might initially due git merge something,issue,negative,negative,negative,negative,negative,negative
1305202665,"Yes, I think we should take the url and create a `GridURL` object, if there is no passed in url the default is `localhost` and then any `optional` supplied port, if its a valid `int` can be added to the `GridURL`. After that all the validation and convenience methods are available already to extract anything we want back out, so then we can raise an exception if the final resultant GridURL isnt valid.",yes think take create object default optional port valid added validation convenience available already extract anything want back raise exception final resultant valid,issue,positive,positive,positive,positive,positive,positive
1305200166,"Also, this command is broken, as it runs health checks post printing the docker commands.
hagrid launch canada to docker:8082 --tag=latest --tail=false --dev --cmd=true
![Screenshot from 2022-11-07 13-09-45](https://user-images.githubusercontent.com/11032835/200252818-bee1f5a7-7e3c-4f54-a0c1-7159ef172de3.png)
",also command broken health post printing docker launch canada docker dev,issue,negative,negative,negative,negative,negative,negative
1305196002,I would add that it would be great to make sure this also works inside the `Jupyter` notebook interface as that currently freezes between updates and can look blocked for a long time before it suddenly completes.,would add would great make sure also work inside notebook interface currently look blocked long time suddenly,issue,positive,positive,positive,positive,positive,positive
1305193873,Is there a way to demonstrate / replicate this? From I see `ObjectDeleteMessage` only gets sent on `.get` so there should be no other way to delete stuff from the store. Perhaps the issue is just that the server side error is preventing future `publish` calls from working? Or the same one will result in the same error?,way demonstrate replicate see sent way delete stuff store perhaps issue server side error future publish working one result error,issue,negative,neutral,neutral,neutral,neutral,neutral
1305191658,"I guess It's not broken, it's just not implemented. This error occurs because the code was written to send a GarbageCollection message but the Domain has no service to handle it. The only implementation I can find was for Worker / VM. In `0.8` this has been commented out already but the fix wasn't back ported to dev. I think we might want to do that to cut down on incorrect bug reports.",guess broken error code written send message domain service handle implementation find worker already fix back ported dev think might want cut incorrect bug,issue,negative,negative,negative,negative,negative,negative
1305177367,What is the suggestion here? Should we include a link to the official numpy docs as a worst case backup?,suggestion include link official worst case backup,issue,negative,negative,negative,negative,negative,negative
1305176158,"I agree, thanks for filing the bug here so that future google searches end up here and help users to solve their problem! 🙂",agree thanks filing bug future end help solve problem,issue,positive,positive,neutral,neutral,positive,positive
1305173602,"We could, but rather than create a request for every single `repr` perhaps it's best to flow this information back to the client as part of the action graph information so that a user can opt to `.cancel()` certain operations which are taking too long.

That way when you run `repr` we can output what we know about the Pointers result, was it queued, started, finished, cancelled etc?",could rather create request every single perhaps best flow information back client part action graph information user opt certain taking long way run output know result finished,issue,positive,positive,positive,positive,positive,positive
1305169811,"Is this something which would act locally to just check the Pointer type?

Is this to allow a user to avoid running expensive operations on their Tensors if they are `gamma` because doing so causes its own issues of broken or slow / unresponsive Domain where you can't cancel actions in the queue? Or does it have another utility?",something would act locally check pointer type allow user avoid running expensive gamma broken slow unresponsive domain ca cancel queue another utility,issue,negative,negative,negative,negative,negative,negative
1305162399,Agreed. Since we are trying to support Tensors and Scalars in the same data types we should be more careful and perhaps introduce an `equality` check function we can call which checks the sizes and does the correct comparison in the event of a Scalar.,agreed since trying support data careful perhaps introduce equality check function call size correct comparison event scalar,issue,positive,negative,neutral,neutral,negative,negative
1305154968,"I guess the first one is just showing the default method signature as fallback. The question is can we annotate all these methods with the same strict method signatures as numpy. If so that would be great. If not, perhaps it needs to be added via the docstring, but unfortunately docstrings dont execute so they can quickly become invalid, so if we can change the actual signature first, I think that would be optimal.",guess first one showing default method signature fallback question annotate strict method would great perhaps need added via unfortunately dont execute quickly become invalid change actual signature first think would optimal,issue,positive,positive,positive,positive,positive,positive
1305149564,"<img width=""430"" alt=""Screen Shot 2022-11-07 at 4 34 55 pm"" src=""https://user-images.githubusercontent.com/2882739/200241226-6ade13df-364b-44d7-825b-71dca89d802c.png"">

<img width=""801"" alt=""Screen Shot 2022-11-07 at 4 34 46 pm"" src=""https://user-images.githubusercontent.com/2882739/200241208-b652617d-4727-412e-9b86-b1eee1f37650.png"">

So, `keep_dims` is actually incorrect.
It might be worth adding a `try` `catch` around passing args blindly down to the `data_subjects` in case there are some different handling depending on data types... mostly to just give the user better error messages, but im not sure if that matters.",screen shot screen shot actually incorrect might worth try catch around passing blindly case different handling depending data mostly give user better error sure,issue,positive,positive,positive,positive,positive,positive
1305141567,Could you do `Person1` first and then multiply by 1 with `Person2`?,could person first multiply person,issue,negative,positive,positive,positive,positive,positive
1305140492,Anything that doesn't reliably work should be `commented` out for the 0.7 release.,anything reliably work release,issue,negative,neutral,neutral,neutral,neutral,neutral
1305134552,We could also persist this `syft settings` to their `~` home directory the same way we do with `hagrid`.,could also persist home directory way,issue,negative,neutral,neutral,neutral,neutral,neutral
1305132382,Given the issues that `NaN` causes im inclined to mark this as a `bug` even though its more pre-emptive.,given nan mark bug even though,issue,negative,neutral,neutral,neutral,neutral,neutral
1305129331,Yes if we have known incorrect / incomplete methods lets comment them out so they don't get shipped! This might break some tests but we can just disable them the functionality is not valid anyway.,yes known incorrect incomplete comment get shipped might break disable functionality valid anyway,issue,negative,neutral,neutral,neutral,neutral,neutral
1305126787,"Agree, lets remove most of that unimportant information like the `tag` (this is unrelated to the docker tag its totally useless info for the user which isolates the containers between stacks with the proxy) and add something about the `docker tag` or `local dev build` version and the `hagrid` version.",agree remove unimportant information like tag unrelated docker tag totally useless user proxy add something docker tag local dev build version version,issue,negative,negative,negative,negative,negative,negative
1305124452,"I agree we should default to `tail=false`. To provide more access to information we should build `hagrid status` which will show all the known nodes and allow a user to explore them further, either by checking logs or running commands like, land, update, backup, etc. A small step in that direction would be a `hagrid logs` command which could provide a quick way to access the logs of different containers.

In the meantime some helpful print statements is likely the best short term solution.",agree default provide access information build status show known allow user explore either running like land update backup small step direction would command could provide quick way access different helpful print likely best short term solution,issue,positive,positive,positive,positive,positive,positive
1305117536,"Interestingly this works for me, but I do have to press and hold `command` button first which is normal for highlighting links in my terminal. It might be a good idea to just output the raw link though for maximum compatibility.
<img width=""391"" alt=""Screen Shot 2022-11-07 at 3 50 35 pm"" src=""https://user-images.githubusercontent.com/2882739/200235594-c5842073-6141-4f13-9041-5a2b788324c3.png"">
",interestingly work press hold command button first normal link terminal might good idea output raw link though maximum compatibility screen shot,issue,positive,positive,positive,positive,positive,positive
1305114527,"Great find. I can replicate this and it appears that the part of the `bytes` which varies are the `Int` values, assuming the data is after the type.


![Image](https://user-images.githubusercontent.com/2882739/200234820-5b9e7a35-7ddc-4be5-b2c2-bcf0cf607f5e.png)


![Image](https://user-images.githubusercontent.com/2882739/200234851-5719d75a-0749-4827-bd46-21564097b6d5.png)

Most comparisons seem to pass so this is definitely weird, but we should add the `bytes` equality to our tests.",great find replicate part assuming data type image image seem pas definitely weird add equality,issue,positive,positive,positive,positive,positive,positive
1305110701,This looks like its trying to `init` a Tensor that matches the type of the parent but in this case the `Scalar` values for `min_vals` the `init` function rejects it.,like trying tensor type parent case scalar function,issue,negative,neutral,neutral,neutral,neutral,neutral
1305102204,"I tried the running the updated code, the progress bar is not visible, maybe it would good to also have the progress bar visible also with spinner animation.
![Screenshot 2022-11-07 at 10 56 15 AM](https://user-images.githubusercontent.com/43314053/200232747-7962aed1-d01f-4f88-9231-9bfe46341b9f.png)
",tried running code progress bar visible maybe would good also progress bar visible also spinner animation,issue,positive,positive,positive,positive,positive,positive
1305095957,"@rasswanth-s excellent find, this one is critically bad. It seems like this might be left over from when we were going to allow the `frontend` to setup a domain from scratch. I suspect we can just completely delete the `get_setup` methods in settings.py and domain_client.py.",excellent find one critically bad like might left going allow setup domain scratch suspect completely delete,issue,negative,positive,positive,positive,positive,positive
1305085449,"Great find. I assume because it's the result of an object which got sent to the `blob` storage it also gets put in `blob` storage. I think the correct solution is to make `ProxyDataset` more generic and basically just be `ProxyObject` without all the extra meta-data. Datasets can have metadata but objects are just objects of any kind. In the mean time we can probably just defensively attempt to get the .shape and fallback to length if thats available and None if it's not. The signature is non Optional, so maybe 0 for None? Feels a bit hacky and we will probably create a problem elsewhere with this shortcut solution.",great find assume result object got sent blob storage also put blob storage think correct solution make generic basically without extra kind mean time probably defensively attempt get fallback length thats available none signature non optional maybe none bit hacky probably create problem elsewhere solution,issue,positive,positive,positive,positive,positive,positive
1305074961,@iamtrask we are discussing providing more robust feedback during 0.8 specifically relating to all of the `async` actions that have been queued which would allow us to provide information about this since we would know that it was submitted but not completed as opposed to something which never existed or was deleted. I think the correct solution here is to expose better feedback about the state of the action graph to users.,providing robust feedback specifically would allow u provide information since would know opposed something never think correct solution expose better feedback state action graph,issue,positive,positive,positive,positive,positive,positive
1305073569,"Great find @rasswanth-s! Fortunately, we don't need `RBAC` to fix this bug, we just need to check if the owner can mutate the object the same way we check for mutation in `RunClassMethodAction`.",great find fortunately need fix bug need check owner mutate object way check mutation,issue,positive,positive,positive,positive,positive,positive
1304695718,"We mainly need the spinner animation instead of clock gif when doing hagrid launch
You could follow the pysyft main readme, to install hagrid and launch quickstart which inturn would help to launch a domain, which would show if the spinner animation works.
Comment on the thread , if there were any blockers.",mainly need spinner animation instead clock gif launch could follow main install launch inturn would help launch domain would show spinner animation work comment thread,issue,negative,positive,positive,positive,positive,positive
1304613649,"Hi @rasswanth-s, I'm new to the PySyft codebase but I have some familiarity with using rich progress bars. I would like to work on this issue to get started here.

To add the spinner, I should change the code below:
https://github.com/OpenMined/PySyft/blob/5de360b9fc4cff81dda76bd0a35af7c0167554c4/packages/hagrid/hagrid/cli.py#L613

to this:
```python3
with Progress(
    SpinnerColumn(), 
    TextColumn(""[progress.description]{task.description}""), 
    console=console, 
    auto_refresh=False,
  ) as progress:
```
Is this correct or am I missing something?",hi new familiarity rich progress would like work issue get add spinner change code python progress progress correct missing something,issue,positive,positive,positive,positive,positive,positive
1303798787,"Closing this PR- I had copied your implementation of the mean op into the working branch we were using to round out the 0.7 DS API since it was easier than having to solve all of these merge conflicts- some of which involve older implementations of operations which were insecure.

Terrific work @curt-mitch !!",copied implementation mean working branch round since easier solve merge involve older insecure terrific work,issue,positive,negative,negative,negative,negative,negative
1303024447,"@tudorcebere Weird that `docker ps -q | xargs -L 1 docker logs` is complaining about `2022-10-06T10:06:36.7253565Z ""docker logs"" requires exactly 1 argument.` It runs fine locally on my machine.",weird docker docker docker exactly fine locally machine,issue,negative,negative,neutral,neutral,negative,negative
1303021835,"> @bitsofsteve Looks like a conflict, can you fix it and make the requested changes so we can get this into production?

Sure @madhavajay !",like conflict fix make get production sure,issue,negative,positive,positive,positive,positive,positive
1303019309,"@bitsofsteve Looks like a conflict, can you fix it and make the requested changes so we can get this into production?",like conflict fix make get production,issue,negative,neutral,neutral,neutral,neutral,neutral
1302251170,"I had timed it for values in the range 12e6 it was taking like 2.5 hours 😂 for the whole process. I was thinking of solving this in a few ways:
- increase the size of the cache file
- multithreaded the `_get_optimal_alpha_for_constant` computations, as each computation is independent of the other.
- have a background task (via celery) running that increases cache size every few intervals in a separate thread. Although, this may cause memory overload at some time.",timed range taking like whole process thinking way increase size cache file multithreaded computation independent background task via celery running cache size every separate thread although may cause memory overload time,issue,negative,positive,neutral,neutral,positive,positive
1302221960,"sigma was set at 0.001 and this created an RDP constant of 41M which would take a LONG time to generate

![Image](https://user-images.githubusercontent.com/32711264/199752273-f16bfef2-4d31-42b8-971a-115d42f90f14.png)

",sigma set constant would take long time generate image,issue,negative,negative,neutral,neutral,negative,negative
1302208098,"co-authored by: @teo-milea 
Division by zero for instance would cause min/vals and max_vals to be NaN



![Image](https://user-images.githubusercontent.com/32711264/199749766-003eab9e-6e56-4a3f-89a6-7cd1ed7c02b0.png)

",division zero instance would cause nan image,issue,negative,neutral,neutral,neutral,neutral,neutral
1301902789,"That's a good catch @teo-milea, I just noticed that today. 

Code to reproduce:
Launch domain:  `hagrid launch test_domain domain to docker:8081 --tag=latest --tail=false --dev`


```
domain_client = sy.login(email=""info@openmined.org"", password=""changethis"", port=8081)

domain_client.create_user(name=""Joker"", email=""joker@test.com"", password=""test"", budget=99999)

data1 = np.random.randint(1, 1000, (10000))

data1_ptr = dataset1.send(domain_client)

data1_ptr.id_at_location

ds_client = sy.login(email=""joker@test.com"", password=""test"", port=8081)

data1_ptr_ds = ds_client.store[data1_ptr.id_at_location]

data_val_gt_100 = data1_ptr_ds > 100

data_val_gt_100_pub = data_val_gt_100.publish(sigma=10)

data_val_gt_100_pub.exists
```

Check error log on celerworker container:
![Screenshot from 2022-11-03 16-05-27](https://user-images.githubusercontent.com/11032835/199699700-9d776644-5397-456c-b6b8-d86dda1f536a.png)


",good catch today code reproduce launch domain launch domain docker dev joker joker test data joker test check error log container,issue,negative,positive,positive,positive,positive,positive
1301571781,"The same thing happens with `var` as well

```python
d_ptr.var(keep_dims=True)
```

```
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
Cell In [10], line 1
----> 1 d_ptr.var(keep_dims=True)

File ~/pysyft/packages/syft/src/syft/core/tensor/autodp/phi_tensor.py:1002, in TensorWrappedPhiTensorPointer.var(self, *args, **kwargs)
    975 def var(self, *args: Any, **kwargs: Any) -> TensorWrappedPhiTensorPointer:
    976     """"""
    977     Compute the variance along the specified axis of the array elements, a measure of the spread of a distribution.
    978     The variance is computed for the flattened array by default, otherwise over the specified axis.
   (...)
   1000             Elements to include in the variance. See reduce for details.
   1001     """"""
-> 1002     return self._apply_self_tensor_op(""var"", *args, **kwargs)

File ~/pysyft/packages/syft/src/syft/core/tensor/autodp/phi_tensor.py:260, in TensorWrappedPhiTensorPointer._apply_self_tensor_op(self, op_str, *args, **kwargs)
    251 def _apply_self_tensor_op(self, op_str: str, *args: Any, **kwargs: Any) -> Any:
    252     # we want to get the return type which matches the attr_path_and_name
    253     # so we ask lib_ast for the return type name that matches out
   (...)
    256 
    257     # We always maintain a Tensor hierarchy Tensor ---> PT--> Actual Data
    258     attr_path_and_name = f""syft.core.tensor.tensor.Tensor.{op_str}""
--> 260     min_vals, max_vals = compute_min_max(
    261         self.min_vals, self.max_vals, None, op_str, *args, **kwargs
    262     )
    264     if hasattr(self.data_subjects, op_str):
    265         if op_str == ""choose"":

File ~/pysyft/packages/syft/src/syft/core/tensor/lazy_repeat_array.py:597, in compute_min_max(x_min_vals, x_max_vals, other, op_str, *args, **kwargs)
    592     max_vals = lazyrepeatarray(
    593         data=x_max_vals.data ** (np.prod(x_max_vals.shape) / dummy_res.size),
    594         shape=dummy_res.shape,
    595     )
    596 elif op_str == ""var"":
--> 597     dummy_res = np.empty(x_min_vals.shape).var(*args, **kwargs)
    598     min_vals = lazyrepeatarray(data=0, shape=dummy_res.shape)
    599     max_vals = lazyrepeatarray(
    600         data=0.25 * (x_max_vals.data - x_min_vals.data) ** 2,
    601         shape=dummy_res.shape,
    602     )

TypeError: _var() got an unexpected keyword argument 'keep_dims'
```",thing well python recent call last cell line file self self compute variance along axis array measure spread distribution variance array default otherwise axis include variance see reduce return file self self want get return type ask return type name always maintain tensor hierarchy tensor actual data none choose file got unexpected argument,issue,negative,positive,neutral,neutral,positive,positive
1300867713,"> @abhiwalia15 , we are in the process of renaming `min_val` and `max_val` to `lower_bound` and `upper_bound` in this PR: #6912 . Can you also update the documentation accordingly?

I have made the changes, please check it 😊",process also update documentation accordingly made please check,issue,negative,neutral,neutral,neutral,neutral,neutral
1299694037,"@marcalph What to do to overcome this issue? 
Here is the error I am getting -

UnknownPrivateException                   Traceback (most recent call last)
Input In [25], in <cell line: 6>()
      7     ptr = result.publish() 
      8     sleep(1) 
----> 9     total_cases += ptr.get()",overcome issue error getting recent call last input cell line sleep,issue,negative,neutral,neutral,neutral,neutral,neutral
1299380976,@OSobky did you figure out that error? According to this SO its likely to be running out of disk space? https://stackoverflow.com/questions/16996125/no-usable-temporary-directory-found,figure error according likely running disk space,issue,negative,neutral,neutral,neutral,neutral,neutral
1299079392,"Similar problems exist for other ops, such as concatenate:



![Image](https://user-images.githubusercontent.com/32711264/199331355-a6be2672-a150-44b9-80c3-0eb459c43c1c.png)

",similar exist concatenate image,issue,negative,neutral,neutral,neutral,neutral,neutral
1298705209,Shouldn't the data_subjects in this case be a set composed of the two different data subjects?,case set composed two different data,issue,negative,neutral,neutral,neutral,neutral,neutral
1298357688,"The problem with jupyter notebook printing random characters, It happened also for the `hagrid check` command when we executed it in shell in notebook: `!hagrid check localhost:8081`, when using python API , `hagrid.check(""localhost:8083"")`
we get it printed correctly.

This mainly because the rich console has an auto-detection of jupyter environment
https://rich.readthedocs.io/en/stable/reference/console.html during console creation.

I think this would be solved , when modify hagrid launch command to python API.
https://github.com/OpenMined/PySyft/issues/6734
 ",problem notebook printing random also check command executed shell notebook check python get printed correctly mainly rich console environment console creation think would modify launch command python,issue,negative,negative,neutral,neutral,negative,negative
1297590849,I like this idea. I think this and other queries might be best turned on/off by a syft.helper=True flag (which could default to True),like idea think might best turned flag could default true,issue,positive,positive,positive,positive,positive,positive
1297305934,Was having exactly the same issue and I was wondering why. Sometimes it worked but others it didn't even while changing absolutely nothing. I also tried calling .block.get() and while this doesn't throw an error anymore it just keeps loading forever.,exactly issue wondering sometimes worked even absolutely nothing also tried calling throw error loading forever,issue,negative,positive,positive,positive,positive,positive
1297160265,"Great work on catching even all the errors by docker itself.
![Screenshot 2022-10-31 at 7 46 38 PM](https://user-images.githubusercontent.com/43314053/199029460-8c1ee7ac-68a6-4337-a69c-ab8c19071c5b.png)
",great work catching even docker,issue,positive,positive,positive,positive,positive,positive
1297023838,"Deprecation Warnings for:
.private
![Screenshot from 2022-10-31 17-57-23](https://user-images.githubusercontent.com/11032835/199009205-093e7b72-c649-419e-bcc2-f51990b5a4b6.png)

.annotated_with_dp_metadata
![Screenshot from 2022-10-31 18-01-48](https://user-images.githubusercontent.com/11032835/199009258-6e29f543-19fc-4bbe-9c33-169911a63941.png)

Data Subject List class
![Screenshot from 2022-10-31 17-56-49](https://user-images.githubusercontent.com/11032835/199009339-47ad6fa6-00df-4cdd-b129-36155d348e6b.png)",deprecation data subject list class,issue,negative,negative,negative,negative,negative,negative
1296857933,Added checks in PR #6912 but should we also add server-side checks to prevent malicious uploads?,added also add prevent malicious,issue,negative,neutral,neutral,neutral,neutral,neutral
1296712500,"@abhiwalia15 , we are in the process of renaming `min_val` and `max_val` to `lower_bound` and `upper_bound` in this PR: https://github.com/OpenMined/PySyft/pull/6912 . Can you also update the documentation accordingly?",process also update documentation accordingly,issue,negative,neutral,neutral,neutral,neutral,neutral
1296672555,While solving this we could also add a warning when min_val = min(x) and max_val = min(x),could also add warning min min,issue,negative,neutral,neutral,neutral,neutral,neutral
1296604358,"Could we also fix #6915 with this PR or should we first close this and then work on that? It would be a bad idea to work on both in parallel
",could also fix first close work would bad idea work parallel,issue,negative,negative,negative,negative,negative,negative
1295637033,Ideally it triggers an error if you try to pass in min_val or max_val ranges on a tensor which holds data that lies outside of those ranges.,ideally error try pas tensor data outside,issue,negative,positive,positive,positive,positive,positive
1295619859,"Because I know how PySyft works - I know that this is because the user called .get() before the object existed and so the user needs to call .block.get() in order to be able to run this code without triggering a trace. 

However, even though I know this it's still painful from a UX experience. In a perfect world we'd be able to say ""Hey - it looks like you're asking for an object that won't exist for another 4 seconds""... or at maybe .get() should be a blocking function by default?

In any rate - the error of ""object with id can't be found"" is a really opaque way to fail and is quite misleading. Would love to hear better ideas for how this UX could be.",know work know user object user need call order able run code without trace however even though know still painful experience perfect world able say hey like object wo exist another maybe blocking function default rate error object id ca found really opaque way fail quite misleading would love hear better could,issue,negative,positive,positive,positive,positive,positive
1294436228,"**Tracking and throwing docker errors to the user in --silent mode.**
![ezgif com-gif-maker (2)](https://user-images.githubusercontent.com/26658472/198501570-55f09d65-34fe-44ad-81d2-4b0fddefcfce.gif)",throwing docker user silent mode,issue,negative,neutral,neutral,neutral,neutral,neutral
1294435019,"**Launching PRODUCTION mode in notebook** _(production mode skips the building step since we're downloading the images)_
![ezgif com-gif-maker (1)](https://user-images.githubusercontent.com/26658472/198501799-527d9619-c75f-4649-894c-e5a2bb6acb88.gif)

PS: rich packages is a bit buggy in notebooks, I couldn't get rid of these weird characters after completing the progress bar.",production mode notebook production mode building step since rich bit buggy could get rid weird progress bar,issue,positive,negative,neutral,neutral,negative,negative
1293912389,"Hi !
Sorry but I will have to cancel the meeting

On Tue, 25 Oct 2022 at 14:21 Ionésio Junior ***@***.***>
wrote:

> Description
>
> Data Scientists can not retrieve the result of their computations even
> after having their data access request approved by the Data Owner.
> How to Reproduce
>
> import syft as sy
>
> do_client = sy.login(
>     ***@***.***"",
>     password=""changethis"",
>     port=8081
> )
>
> # Create a new Data Scientist User
> do_client.users.create(name='DataScientist',
>     ***@***.***',
>     password = 'DataScientist',
>     budget=0,
>     role = ""Data Scientist""
> )
>
> # login as a Data Scientist User
> ds_client = sy.login(
>     ***@***.***"",
>     password=""DataScientist"",
>     port=8081
> )
>
>
> # Send a tensor using the Data Owner Session
> x_s = x.send(do_client, tags=[""#X"", ""#diabetes""], description=""My diabetes y label"")
>
> # Get a pointer to the data using the Data Scientist Session
> ds_x_pointer = ds_client.store[0]
>
> # Perform Arbitrary computation
> result = ds_x_pointer + ds_x_pointer
>
> # Submit Data Access request as a Data Scientist
> result.request(reason=""I'd like to see my result ..."")
>
> # Approve Data Access Request as a Data Owner
> do_client.requests[0].approve()
>
>
> # Try to retrieve your result as a Data Scientist
> result.get_copy()
>
> Expected Behavior
>
> We should be able to retrieve the values of our result if the data access
> request was approved.
> Additional Comments
>
>    - This workflow is important for the not fully automated use cases
>    where we don't use Differential Privacy and the Data Owner still needs to
>    inspect data access requests.
>    - It's important to add some tests to keep tracking this workflow in
>    future changes as well.
>    - Special thanks to @mikaelapisani <https://github.com/mikaelapisani>
>    for discovering and reporting it.
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/6899>, or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ABI2AG27TXGP6MYO6NJXH4LWFAJKDANCNFSM6AAAAAAROF63AI>
> .
> You are receiving this because you were mentioned.Message ID:
> ***@***.***>
>
-- 

Mikaela Pisani

Head of Data Science

www.rootstrap.com
",hi sorry cancel meeting tue junior wrote description data retrieve result even data access request data owner reproduce import create new data scientist user password role data scientist login data scientist user send tensor data owner session diabetes diabetes label get pointer data data scientist session perform arbitrary computation result submit data access request data scientist like see result approve data access request data owner try retrieve result data scientist behavior able retrieve result data access request additional important fully use use differential privacy data owner still need inspect data access important add keep future well special thanks reply directly view id head data science,issue,positive,positive,positive,positive,positive,positive
1293860106,"@teo-milea , It is due to a great P2p with you, Teamwork makes the Dreamwork, Go TEAM 🚀 ",due great teamwork go team rocket,issue,positive,positive,positive,positive,positive,positive
1293855680,Great catch from @rasswanth-s and even better debugging skills with that nasty SQLAlchemy bug!! ,great catch even better nasty bug,issue,positive,positive,positive,positive,positive,positive
1293700764,It seems to me more like the acceptordeny request message is getting routed to different service altogther.,like request message getting different service,issue,negative,neutral,neutral,neutral,neutral,neutral
1293699890,"@teo-milea  , I tested it locally on my machine, I am still getting the request error.",tested locally machine still getting request error,issue,negative,neutral,neutral,neutral,neutral,neutral
1293693306,"Thank you, @IonesioJunior!! Should I add here some new tests for requests or should we merge this and do it in a new PR?
",thank add new merge new,issue,negative,positive,positive,positive,positive,positive
1293529275,"This is caused because of how we use multiprocessing (and happens specifically on MacOS) during printing dynamic logs when we call apply_to_network
Bug details: https://bugs.python.org/issue28965
Possible solutions: https://superfastpython.com/filenotfounderror-multiprocessing-python/
Will create a fix for it. ",use specifically printing dynamic call bug possible create fix,issue,positive,neutral,neutral,neutral,neutral,neutral
1293196875,"Do we have a sense of how difficult it is to fix? My guess from this stack trace is that it's just missing a method called ""reply_to"" which is usually a no-op method. Garbage collection is a pretty important feature to have working - so if it's a quick fix it'd be better to fix than to disable.

That is to say - perhaps this issue should say ""Fix Garbage Collector"" instead of ""Disable""",sense difficult fix guess stack trace missing method usually method garbage collection pretty important feature working quick fix better fix disable say perhaps issue say fix garbage collector instead disable,issue,negative,positive,neutral,neutral,positive,positive
1292811204,"Sorry everyone- I was preoccupied with the Data Science API and forgot about this. I've made the changes requested and added tests to make sure calling `.private` does indeed return the correct things when receiving a string, list, tuple, array, etc.  ",sorry preoccupied data science forgot made added make sure calling indeed return correct string list array,issue,negative,neutral,neutral,neutral,neutral,neutral
1292108344,"Thank you @Kariten for the quick fix 🙌🏾 . 
Can you fix the lining errors?",thank quick fix fix lining,issue,negative,positive,positive,positive,positive,positive
1292014801,"Closing this for now, but will keep an eye on this for the next few days.",keep eye next day,issue,negative,neutral,neutral,neutral,neutral,neutral
1292000009,"It seems like the tail scale issue with Networks was temporary.
I tested it with a fresh Network and Domain running in non-dev mode with the latest images and it seems to be working correctly now.

![Screenshot from 2022-10-26 18-31-16](https://user-images.githubusercontent.com/11032835/198032612-12776cf9-502a-450a-9b68-3c7f20d785ea.png)
",like tail scale issue temporary tested fresh network domain running mode latest working correctly,issue,positive,positive,positive,positive,positive,positive
1291904273,Fix for removing silent but allowing for some really basic output is covered in Issue: https://github.com/OpenMined/PySyft/issues/6727,fix removing silent really basic output covered issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1291091174,"> @Kariten - it would be amazing if the wizard automatically detected the wrong version of docker/docker compose and prompted you to manually install. Any chance that's something you might be interested in helping to add to the interface?

I've created a pull request which fixed this problem, you can check out #6901.",would amazing wizard automatically wrong version compose manually install chance something might interested helping add interface pull request fixed problem check,issue,positive,positive,positive,positive,positive,positive
1290568993,@Kariten - it would be amazing if the wizard automatically detected the wrong version of docker/docker compose and prompted you to manually install. Any chance that's something you might be interested in helping to add to the interface?,would amazing wizard automatically wrong version compose manually install chance something might interested helping add interface,issue,positive,positive,positive,positive,positive,positive
1290543162,I solved this problem by manually install docker compose from https://github.com/docker/compose,problem manually install docker compose,issue,negative,neutral,neutral,neutral,neutral,neutral
1290394799,"> @IshanMi , would this PR functionality be part of the 0.7 release or for future releases?

Let's plan to include it in 0.7 if possible. It's a significant improvement in UX for noobs which will likely be the primary users of 0.7.",would functionality part release future let plan include possible significant improvement likely primary,issue,positive,positive,positive,positive,positive,positive
1289356157,"


> @factdroid can we up-prioritize this one? Looks like it's been chillin for a month or so.

@iamtrask yeah it's a priority for me this week, I'll try to push through it. ",one like month yeah priority week try push,issue,positive,neutral,neutral,neutral,neutral,neutral
1289351673,Very much looking forward to this one!,much looking forward one,issue,negative,positive,positive,positive,positive,positive
1289343327,"Also - hagrid.check() should accept a string url or a list of strings. Requiring a list of strings (and only a list of strings) in a user-facing API is bad python API design given that most people are only ever going to pass in a list with one thing in it. It's one of those ""Well that's kindof annoying"" types of bugs noobs will run into.",also accept string list list list bad python design given people ever going pas list one thing one well annoying run,issue,negative,negative,negative,negative,negative,negative
1289265713,"
<img width=""846"" alt=""Error"" src=""https://user-images.githubusercontent.com/29546622/197576461-c6c017c4-1a76-45f8-86c6-248e27102bef.PNG"">
Hi @rasswanth-s,
I just ran into this issue. How should I resolve it?
Sys. spec:
`Docker version 20.10.12, build 20.10.12-0ubuntu2~20.04.1`
`Python 3.8.10`

Thanks",error hi ran issue resolve spec docker version build python thanks,issue,negative,positive,positive,positive,positive,positive
1287994627," Adding a Placeholder
The following tests were disabled in the past week for fast merging of PR's as they were flaky:

- def test_benchmark_datasets (spicy_swan_performance_test.py)
- def test_large_blob_upload (large_message_test.py)

",following disabled past week fast flaky,issue,negative,negative,neutral,neutral,negative,negative
1287991790,"@IshanMi , would this PR functionality be part of the 0.7 release or for future releases?",would functionality part release future,issue,negative,neutral,neutral,neutral,neutral,neutral
1287991291,"@IshanMi , would this PR functionality be part of the 0.7 release or for future release ?",would functionality part release future release,issue,negative,neutral,neutral,neutral,neutral,neutral
1287990805,@bitsofsteve  will the PR functionality be a part of 0.7 release or it is for the future release?,functionality part release future release,issue,negative,neutral,neutral,neutral,neutral,neutral
1287872315,@rasswanth-s That's awesome. Thank you for all the help along the way. ,awesome thank help along way,issue,positive,positive,positive,positive,positive,positive
1287754750,@rasswanth-s I have resolved the conflicts. Could you approve the review to merge it?,resolved could approve review merge,issue,negative,neutral,neutral,neutral,neutral,neutral
1285268387,great work @rAlexandre00 and congrats on your first contribution!! ,great work first contribution,issue,positive,positive,positive,positive,positive,positive
1284932810,"I think one idea would be to make the user creation run only at the backend container, we could separate the user creation at pre-start.sh (initial_data.py) and put in a separate shell script and we could make that script run in backend container only as an entry point . Since we plan on switching to MongoDB in 0.8 which has the locking feature.Thoughts?",think one idea would make user creation run container could separate user creation put separate shell script could make script run container entry point since plan switching locking,issue,negative,neutral,neutral,neutral,neutral,neutral
1284929736,"I just do a normal hagrid launch on my machine, 

![Screenshot 2022-10-20 at 10 32 46 AM](https://user-images.githubusercontent.com/43314053/196860596-5d6b5fab-0a81-4696-958f-2f66b5c4b45a.png)
They are created with a millisecond different in the created_at column.",normal launch machine millisecond different column,issue,negative,positive,neutral,neutral,positive,positive
1284819725,"@mihirdcoder  could you revert the protobuf changes in this PR, `path: packages/syft/src/syft/proto/*` , I think you must have formatted it with a new version, we currently use 3.19.4",could revert path think must new version currently use,issue,negative,positive,neutral,neutral,positive,positive
1284598781,"@rasswanth-s  Can you help me to reproduce and test it out? For some reason in my environment, It just creates a unique account now. 

Maybe it is something related to the amount of concurrency we choose.",help reproduce test reason environment unique account maybe something related amount concurrency choose,issue,negative,positive,positive,positive,positive,positive
1284595281,"Ohh, thank you for testing it and catching it out @rasswanth!

Yeah, `lock` seems a good way to solve it. I'll take a look at Madhava's solution and try to adapt it to this use case.",thank testing catching yeah lock good way solve take look solution try adapt use case,issue,positive,positive,positive,positive,positive,positive
1284103469,"@IonesioJunior , I think we should use some locks like madhava did in mongo db part, (Shylock)
I tried logging in , I got  three users in the dashboard
![Screenshot 2022-10-19 at 7 54 10 PM](https://user-images.githubusercontent.com/43314053/196718787-7642b3da-2366-4233-aa17-a61f7ee1d2bf.png)
",think use like part tried logging got three dashboard,issue,negative,neutral,neutral,neutral,neutral,neutral
1282648489,"Hello @ShubhamPalriwala 

I am not really sure how HAGrid works if we did not pass `--reset=True`. However, if this is the case having the overwrite question/pop-up,` Overwrite 00-welcome.ipynb?(a/y/N)` does not really matter in this case. 

Moreover, I can see it being more user-friendly if the user can pass `--no` while running the command instead of having to pass `N` for every existing notebook. In my case, it was 4 times as you can see in the following log:

> You have 4 existing notebooks matching: padawan
> padawan/00-welcome.ipynb
> padawan/01-pets-and-syft.ipynb
> padawan/02-dev-setup.ipynb
> padawan/03-architecture.ipynb
>   0%|                                                     | 0/5 [00:00<?, ?it/s]
> Overwrite 00-welcome.ipynb?(a/y/N) N
> Skipping 00-welcome.ipynb
>  20%|█████████                                    | 1/5 [00:02<00:08,  2.12s/it]
> Overwrite 01-pets-and-syft.ipynb?(a/y/N) N
> Skipping 01-pets-and-syft.ipynb
>  40%|██████████████████                           | 2/5 [00:03<00:04,  1.41s/it]
> Overwrite 02-dev-setup.ipynb?(a/y/N) N
> Skipping 02-dev-setup.ipynb
>  60%|███████████████████████████                  | 3/5 [00:04<00:02,  1.39s/it]
> Overwrite 03-architecture.ipynb?(a/y/N) N
> Skipping 03-architecture.ipynb
>  80%|████████████████████████████████████         | 4/5 [00:05<00:01,  1.42s/it]Downloading notebook: 04-rpc-and-pointers.ipynb
> 100%|█████████████████████████████████████████████| 5/5 [00:06<00:00,  1.27s/it]
> ",hello really sure work pas however case overwrite overwrite really matter case moreover see user pas running command instead pas every notebook case time see following log matching overwrite skipping overwrite skipping overwrite skipping overwrite skipping notebook,issue,negative,positive,positive,positive,positive,positive
1282371953,"Hey, as far as I know, HAgrid does not overwrite your existing notebooks until you pass `--reset=True` even after which it asks for confirmation before overwriting the notebooks.

Could you please help with some more information here if possible?",hey far know overwrite pas even confirmation could please help information possible,issue,positive,positive,neutral,neutral,positive,positive
1281429380,Love where this is going! Especially love the GIFS!,love going especially love,issue,positive,positive,positive,positive,positive,positive
1281384962,"Ignore mismatch and keep applying to the network
![mismatch_version_y](https://user-images.githubusercontent.com/26658472/196267566-f3300a1a-b6af-413a-a1af-dc813df9eb5f.gif)
",ignore mismatch keep network,issue,negative,neutral,neutral,neutral,neutral,neutral
1281384349,"Cancel option due to a mismatch during connection
![mismatch_version_n](https://user-images.githubusercontent.com/26658472/196267387-af71a8f8-9f59-4ecd-99e5-5561e66dacb3.gif)
",cancel option due mismatch connection,issue,negative,negative,negative,negative,negative,negative
1280097982,"Yes, that solved my issue, but looking forward to know the fix for the issue for `syft==0.5.1` or `0.6.0` version.",yes issue looking forward know fix issue version,issue,negative,neutral,neutral,neutral,neutral,neutral
1279968737,@majauhar  could you try resolving the conflicts with dev branch?,could try dev branch,issue,negative,neutral,neutral,neutral,neutral,neutral
1278298575,@shubham3121 please assign this task to me. Thanks 😊 ,please assign task thanks,issue,positive,positive,positive,positive,positive,positive
1277891784,@shubham3121 I have corrected the link in the install wizard. Sorry for the delay 👍🏻,corrected link install wizard sorry delay,issue,negative,negative,negative,negative,negative,negative
1277678171,"> Can we add a test for this?

We can add a test for this to the granular publish PR #6790 ",add test add test granular publish,issue,negative,neutral,neutral,neutral,neutral,neutral
1277621512,"@iamtrask we can currently do something like this: 
`hagrid quickstart petlab_sessions/TradeDemoE2E`, but if you feel this seems inconvenient we can switch to something like `hagrid quickstart petlab`",currently something like feel inconvenient switch something like,issue,negative,negative,negative,negative,negative,negative
1277443656,"Hey @IrinaMBejan Now that all the PRs are open for this, can you reference them in the issue title itself so that it gets easier to track them?",hey open reference issue title easier track,issue,negative,neutral,neutral,neutral,neutral,neutral
1277370461,Small thought (and forgive me if this is already happening) - shall we create a section in the hagrid quickstart for petlab for this notebook?,small thought forgive already happening shall create section notebook,issue,negative,negative,negative,negative,negative,negative
1277247981,@amdjedbens can you install syft 0.7 beta version: `pip install -U syft --pre`.,install beta version pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
1277165887,@shubham3121 I just resolved the conflicts please check it out and let me know if there is more I can/need to do  ,resolved please check let know,issue,negative,neutral,neutral,neutral,neutral,neutral
1276554961,"> Small thing - any chance we can also add the ability to pass in a single string? (which would be interpreted as passing in a list of length 1)

I believe that exists already: https://github.com/OpenMined/PySyft/blob/6f381d92514e71108d48fa0db4dd03c4a54c6590/packages/syft/src/syft/core/tensor/ancestors.py#L416",small thing chance also add ability pas single string would passing list length believe already,issue,positive,negative,negative,negative,negative,negative
1276057664,"There's an easier way to do this private budget modification- on [this line](https://github.com/OpenMined/PySyft/blob/45827b78b517b1a0072c02355b829e152592a764/packages/syft/src/syft/core/adp/vectorized_publish.py#L159) of vectorized_publish, simply replace `private=True` with `private=False`
",easier way private budget line simply replace,issue,negative,neutral,neutral,neutral,neutral,neutral
1276048204,Small thing - any chance we can also add the ability to pass in a single string? (which would be interpreted as passing in a list of length 1),small thing chance also add ability pas single string would passing list length,issue,positive,negative,negative,negative,negative,negative
1275317030,"Okay, great!  A similar issue #6841 was opened  by @iamtrask  can you check it out and let me know so i can put that into consideration @shubham3121 ",great similar issue check let know put consideration,issue,positive,positive,positive,positive,positive,positive
1275027805,Looks good to me!  Great work @amdjedbens 🚀,good great work rocket,issue,positive,positive,positive,positive,positive,positive
1274462690,@abhiwalia15 can you also fix the link to `Install Wizard` in Step 1 of `00-deploy-domain.ipynb`,also fix link install wizard step,issue,negative,neutral,neutral,neutral,neutral,neutral
1274459936,This looks great !! Thanks for the quick fix @abhiwalia15 🎉 ,great thanks quick fix,issue,positive,positive,positive,positive,positive,positive
1274242016,"I see，many many thanks!

发自我的iPhone

在 2022年6月29日，10:33，Madhava Jay ***@***.***> 写道：

﻿

@lepangdan<https://github.com/lepangdan> in Duet there are two nodes, one is the Data Owner side with a store, and the other is the Data Scientist. All data that is send with .send goes to the Data Owner side. None of that traffic goes through any other servers.

—
Reply to this email directly, view it on GitHub<https://github.com/OpenMined/PySyft/issues/6614#issuecomment-1169467647>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AF3DX5T53ECQY3ALMKA6EK3VROYWFANCNFSM5Z5OKYXQ>.
You are receiving this because you were mentioned.Message ID: ***@***.***>
",many thanks jay duet two one data owner side store data scientist data send go data owner side none traffic go reply directly view id,issue,negative,positive,positive,positive,positive,positive
1273879273,"Hey @shubham3121 and @IrinaMBejan, the changes have been made and are in PR #6837. 

Please merge when checked ✅",hey made please merge checked,issue,negative,neutral,neutral,neutral,neutral,neutral
1272631018,"**Error message when docker binary is not found**
![docker_uninstalled](https://user-images.githubusercontent.com/26658472/194780019-5e1ffa47-a798-44fb-afea-bf3e2c5ce8ca.png)


**Error message when docker binary is found but the current user is not allowed to execute docker commands (Linux)**
![user_permission_error](https://user-images.githubusercontent.com/26658472/194780071-a57c7647-cc6f-4ffb-aa49-143783dbbf1f.png)
",error message docker binary found error message docker binary found current user execute docker,issue,negative,neutral,neutral,neutral,neutral,neutral
1272281668,"Hey @madhavajay, I just looked up to get some more alternatives/enhancements and the only other action that made sense to me was this: https://github.com/marketplace/actions/workflow-telemetry

This shows us a good metric about the machine but does not compare to our main branch's runs.

I think we can start by adding the timer workflow. Would like to take this up if possible!",hey get action made sense u good metric machine compare main branch think start timer would like take possible,issue,positive,positive,positive,positive,positive,positive
1268903498,"After studying documents and examples for a while, I came to a conclusion, that at this point PySyft is not suitable for described scenario. For other, that might be looking for suitable framework for model-centric FL (with IoT support), have a look at FedMl.",came conclusion point suitable scenario might looking suitable framework support look,issue,negative,positive,positive,positive,positive,positive
1267923894,"@faustyang , could you try resolving the conflict with dev branch.",could try conflict dev branch,issue,negative,neutral,neutral,neutral,neutral,neutral
1267921859,"@vinalb-oblivious , could you try resolving the conflicts with dev branch,once they are resolved we could merge the PR.",could try dev branch resolved could merge,issue,negative,neutral,neutral,neutral,neutral,neutral
1264506094,"@ktobah these are the course notebooks which we test in CI on every PR:
https://github.com/OpenMined/courses/tree/introduction-to-remote-data-science-dev

We will be adding some better tooling to help trace issues when they occur but unfortunately we can't just send back a normal exception to the client user because that would allow them to figure out why their query failed and learn information about the dataset.

There are some stability changes happening as we speak in the `dev` branch which should make the usage of AutoDP more robust, once we release 0.7 officially the example notebooks with some presupplied datasets we are building should work.

I can highly recommend you tail the logs of your `celeryworker` container when you publish. If there is an error it will appear there.",course test every better tooling help trace occur unfortunately ca send back normal exception client user would allow figure query learn information stability happening speak dev branch make usage robust release officially example building work highly recommend tail container publish error appear,issue,positive,positive,neutral,neutral,positive,positive
1261495647,"`test_any()` and `test_all()` in `PhiTensor` and `GammaTensor` were flopping intermittently because once in a blue moon, `condition = np.random.choice(a=[False, True], size=(reference_data.shape[0])` would return a list of only `False` and this would fail the assertion check. I added a fix for this, which was to manually replace the last value in the list with a `True` so that there's always at least 1 element being tested.",intermittently blue moon condition false true would return list false would fail assertion check added fix manually replace last value list true always least element tested,issue,positive,negative,negative,negative,negative,negative
1261185588,Very excited about this PR - well framed and timely. Also great job for creating a WIP ahead of time with a great description. This greatly helps with visibility on what features/changes are coming.,excited well framed timely also great job ahead time great description greatly visibility coming,issue,positive,positive,positive,positive,positive,positive
1257960187,"Hrm, I wonder if this happens when installs are done with an Admin shell? Also I think that needs a UTF-16 decode on Windows.",wonder done shell also think need decode,issue,negative,neutral,neutral,neutral,neutral,neutral
1257480162,"@madhavajay , closing this issue,as  I noticed that ,as we already have this feature integrated in dev branch.
![Screenshot 2022-09-26 at 10 22 38 AM](https://user-images.githubusercontent.com/43314053/192196369-d7e71a20-5b2d-4c93-a2b1-7ad6eed5b2e3.png)
",issue already feature dev branch,issue,negative,neutral,neutral,neutral,neutral,neutral
1257369359,"I changed the dataset selected, and somehow it worked now. So, if you think this has to do with the dataset uploaded having an issue, please close the issue.",selected somehow worked think issue please close issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1256877509,"After installing ```syft==0.2.9``` with
```console
pip install syft==0.2.9
```

Then import like this
```python
import syft.frameworks.torch.dp.pate as pate
```

This is how I resolved it.",console pip install import like python import pate resolved,issue,negative,neutral,neutral,neutral,neutral,neutral
1253683464,"![Screenshot 2022-09-21 at 6 34 28 PM](https://user-images.githubusercontent.com/43314053/191511351-2af831b4-4234-4c16-a834-ebd72dee8ad6.png)

Love the new hagrid quickstart display on gitpod , great work , shubham, the link works perfectly...",love new display great work link work perfectly,issue,positive,positive,positive,positive,positive,positive
1250799223,"We don't have access to the user env, but I think you're right, git seems to be the issue.",access user think right git issue,issue,negative,positive,positive,positive,positive,positive
1250043482,"TODO: discuss with Ishan how to reduce the number of data subjects on certain operations.
",discus reduce number data certain,issue,negative,positive,positive,positive,positive,positive
1248921979, @madhavajay The Upload tutorial link used in the session was broken because the tutorial wasn't merged in dev. Now the corresponding PR has been merged and the Tester guide updated with correct tutorial notebooks.,tutorial link used session broken tutorial dev corresponding tester guide correct tutorial,issue,negative,negative,negative,negative,negative,negative
1248796396,Unfortunately since the prompt from the command line doesnt work in Jupyter we will have to handle that in another task which is already specced to introduce a Python API for hagrid land.,unfortunately since prompt command line doesnt work handle another task already introduce python land,issue,negative,negative,negative,negative,negative,negative
1248790414,"Final fix, to make the url not wrap. 🙌🏽",final fix make wrap,issue,negative,neutral,neutral,neutral,neutral,neutral
1248744133,@shubham3121 was this PR merged already but just not used in that previous session?,already used previous session,issue,negative,negative,negative,negative,negative,negative
1248196709,"Alright, thanks @madhavajay i'll do that right away. See you on Slack!",alright thanks right away see slack,issue,positive,positive,positive,positive,positive,positive
1247663248,"@bitsofsteve I have updated the PR to use gitpod url only for display at hagrid check, for checking we can still continue to use localhost.",use display check still continue use,issue,negative,neutral,neutral,neutral,neutral,neutral
1247514464,@bitsofsteve Great start. This needs a few fixes and testing on gitpod.,great start need testing,issue,positive,positive,positive,positive,positive,positive
1247497066,"@Boluwatifeh Thanks for the PR, there were a few more changes required so I merged Stephens PR. If you want to help out we can use your help with some user testing. Come to Slack and ping myself or Stephen and we can point you at the private signup form.",thanks want help use help user testing come slack ping point private form,issue,positive,positive,neutral,neutral,positive,positive
1246623254,"@abhiwalia15 merging the first two DO notebooks, we can create a new PR for `03-create-account-and-manage-budget [WIP]`.",first two create new,issue,negative,positive,positive,positive,positive,positive
1246618150,"> I'm not sure it's a requirement but conventionally I believe the ""-U"" goes after the end of the command (so after the word ""hagrid"")

@iamtrask oh good to know, but looking at the documentation from pip here: https://pip.pypa.io/en/stable/installation/#upgrading-pip and how it's used it seems `pip install -U SomePackage` is also pretty standard. ",sure requirement conventionally believe go end command word oh good know looking documentation pip used pip install also pretty standard,issue,positive,positive,positive,positive,positive,positive
1246275868,I am closing this due to no response. arm64 linux builds have been available for a while now and are tested in CI.,due response arm available tested,issue,negative,positive,positive,positive,positive,positive
1246265906,Looks like its complaining about git not being installed. But it could be another issue. Do we have access to this users test environment?,like git could another issue access test environment,issue,negative,neutral,neutral,neutral,neutral,neutral
1246262156,"Related to this:
https://github.com/OpenMined/PySyft/issues/6714

This is caused by the requirement to compile pycapnp which is no longer required.",related requirement compile longer,issue,negative,neutral,neutral,neutral,neutral,neutral
1246258890,"![image](https://user-images.githubusercontent.com/2882739/190067745-1319b7f9-7dbc-45bf-b866-8699455bb84f.png)

I just tested it and it seems to work fine. We do intentionally test Python 3.7 in CI because Google Colab refuses to get with the modern Python times.

<img width=""293"" alt=""Screen Shot 2022-09-14 at 3 35 07 pm"" src=""https://user-images.githubusercontent.com/2882739/190068046-d0737826-1fa7-461d-9004-25593f2708c8.png"">
",image tested work fine intentionally test python get modern python time screen shot,issue,negative,positive,positive,positive,positive,positive
1246251916,"This should be resolved now that we have fixed the M1 build here:
https://github.com/capnproto/pycapnp/pull/297

And updated syft to use pycapnp==1.2.1",resolved fixed build use,issue,negative,positive,neutral,neutral,positive,positive
1246251393,"Unfortunately in my commit message for the change its not clear if I upgraded it due to functionality requirements or a security issue. If we can down grade thats one solution but unfortunately if a user trys to install and it fails due to pip dependencies there isnt really any way we can hook in with a message to tell them to do anything else.

If this happens in the quickstart environment it will be a virtualenv so this shouldnt happen.

I think long term moving hagrid to a non python library will help prevent install issues in the global space.

If we do the 1 liner bash script we ""could"" try to resolve this by installing hagrid in a self contained env and linking it to /usr/local/bin but it all gets a bit complicated.",unfortunately commit message change clear due functionality security issue grade thats one solution unfortunately user install due pip really way hook message tell anything else environment shouldnt happen think long term moving non python library help prevent install global space liner bash script could try resolve self linking bit complicated,issue,positive,negative,negative,negative,negative,negative
1246246876,Can we try to use a different format for our data than pickle?,try use different format data pickle,issue,negative,neutral,neutral,neutral,neutral,neutral
1246194779,I think this could extend to hagrid check where we could decide if should check for an external IP based off the same heuristic.,think could extend check could decide check external based heuristic,issue,negative,neutral,neutral,neutral,neutral,neutral
1243033956,I appreciate how clear and organized you are in your commit messages,appreciate clear organized commit,issue,positive,positive,positive,positive,positive,positive
1241317105,"@shubham3121 following our conversation, I just added a script that will set up a docker swarm cluster on Azure. 

It does the following. 

- Creates a resource group
- Creates 5 VMs in this resource group
- Sets up docker in these machines
- Makes one machine the Service discovery Backend for the cluster registry, using  consul 
- Makes two machine Managers, one primary, one replica
- Makes the other two machine worker nodes. 

I bet next steps will be to run the services across this cluster.",following conversation added script set docker swarm cluster azure following resource group resource group docker one machine service discovery cluster registry consul two machine one primary one replica two machine worker bet next run across cluster,issue,negative,positive,neutral,neutral,positive,positive
1239571212,"@ricardocarvalhods In Slack it has been suggested to try `pip install syft —pre` and `hagrid launch domain —tag=latest`.
",slack try pip install launch domain,issue,negative,neutral,neutral,neutral,neutral,neutral
1237604141,"Hello, I was having the same error in L2C6.
Here's the exception showed in the celery worker:
![image](https://user-images.githubusercontent.com/7207015/188538042-8fa1885a-ba37-47e1-a6d4-a34307b5849f.png)

The problem went away after restarting the celeryworker container:
- In Docker, go to the ""Container / Apps"" menu on the upper left
- Expand ""local_node""
- In ""local_node-celeryworker-1"" on the bottom right, click on restart

**See image below.**

![image](https://user-images.githubusercontent.com/7207015/188537305-1bef612c-3ab4-4d1a-b79e-37cc5b7a8776.png)

After doing this, the code from L2C6 worked without changing anything.",hello error exception celery worker image problem went away container docker go container menu upper left expand bottom right click restart see image image code worked without anything,issue,negative,positive,neutral,neutral,positive,positive
1236072920,Seems like the windows error might be unrelated so closing.,like error might unrelated,issue,negative,neutral,neutral,neutral,neutral,neutral
1233105417,"Hi Mrinal,

I will close this one since there are other issues to cover every batch of notebooks we work on ([first one](https://github.com/OpenMined/PySyft/issues/6677), [second one](https://github.com/OpenMined/PySyft/issues/6688))",hi close one since cover every batch work first one second one,issue,negative,positive,positive,positive,positive,positive
1229946975,"This PR is ready for review and has covered all the features/fixes needed and suggested by peers.
The recent most commit: https://github.com/OpenMined/PySyft/pull/6686/commits/0f1f44db55346d7932bfbf78a7499d24912a3016 introduces the option to overwrite all notebooks at once instead of pinging the user each time when there's a conflicting notebook!",ready review covered recent commit option overwrite instead user time conflicting notebook,issue,negative,positive,neutral,neutral,positive,positive
1229228508,@IrinaMBejan @abhiwalia15 Please review whenever you get time!,please review whenever get time,issue,negative,neutral,neutral,neutral,neutral,neutral
1229198189,"@IrinaMBejan Hey, can you assign this issue to me? Thanks",hey assign issue thanks,issue,negative,positive,positive,positive,positive,positive
1227338700,I am trying to follow the tutorial in `L2C6 - Remote Data Science` and I get the same error.,trying follow tutorial remote data science get error,issue,negative,negative,neutral,neutral,negative,negative
1221969392,This pull request has been linked to [Shortcut Story #6786: [Tech Debt] - HAGrid Templating](https://app.shortcut.com/openmined/story/6786/tech-debt-hagrid-templating).,pull request linked story tech debt,issue,negative,neutral,neutral,neutral,neutral,neutral
1221868898,"```python
# Calculate the total number of COVID cases 
results = [dataset[f'{i}'] for i in range(10)]

from time import sleep
total_cases = 0

for result in results:
    ptr = result.publish()
#  print(ptr.get())
    sleep(1)
    total_cases += ptr.get()

print('The total number of COVID19 cases are: {}'.format(total_cases))
```",python calculate total number covid range time import sleep result print sleep print total number covid,issue,negative,neutral,neutral,neutral,neutral,neutral
1221868225,"Hi @madhavajay and @Crazynovatech, I have faced the same issue when I try to run this example [DEPLOYING A SINGLE DOMAIN NODE](https://blog.openmined.org/remote-data-science-part-3-deploying-a-single-domain-node/) at the final step to calculate *the total number of Covid cases*. 

I'm using PySyft version 0.6.0, Python 3.9

Hope you can give me some clues to fix this. Thank you so much
",hi faced issue try run example single domain node final step calculate total number covid version python hope give fix thank much,issue,positive,positive,neutral,neutral,positive,positive
1218996019,"> Hey @madhavajay, I would like to start with the Notebooks. Please assign this task to me; thanks!!

Hello @madhavajay, can you please assign this to me so I can tickmark the tasks I am completing?",hey would like start please assign task thanks hello please assign,issue,positive,positive,positive,positive,positive,positive
1216099953,"Hey @madhavajay, I would like to start with the Notebooks. Please assign this task to me; thanks!!",hey would like start please assign task thanks,issue,positive,positive,positive,positive,positive,positive
1208739405,"@iamtrask great spot, iv also pulled out `forbiddenfruit` since i don't think we use it anymore.",great spot also since think use,issue,positive,positive,positive,positive,positive,positive
1203237861,"@IonesioJunior awesome work. Lets add a domain reconnection test in this file just like the network reconnection test:
https://github.com/OpenMined/PySyft/blob/dev/tests/integration/network/connect_nodes_test.py",awesome work add domain reconnection test file like network reconnection test,issue,positive,positive,positive,positive,positive,positive
1203141643,This pull request has been linked to [Shortcut Story #6516: [Feature] - Add First Span](https://app.shortcut.com/openmined/story/6516/feature-add-first-span).,pull request linked story feature add first span,issue,negative,positive,positive,positive,positive,positive
1201869604,"> Hey, I was wondering that changing the ""Copying Data"" to ""Accessing data"" in the pilot image might make more sense? ![Screenshot_2022-08-01-14-55-17_1920x1080](https://user-images.githubusercontent.com/55556994/182118213-3e8fe30b-ea7a-4b34-a02f-6ad01c566ce2.png)

You are accessing it though.... you're just not copying it. This is a surprisingly complicated thing to describe because we actually lack words in the English language to describe ""utilizing"" something without ""seeing"", ""viewing"", ""accessing"", ""inspecting"", ""examining"", ""observing"".

I think that `access` implies too much capability for the individual to both `enter` and `locate` data: https://en.wiktionary.org/wiki/access 

Having said that this is by no means final, so ill bing up your suggestion when we go for a copy review before merging.",hey wondering data data pilot image might make sense though surprisingly complicated thing describe actually lack language describe something without seeing examining observing think access much capability individual enter locate data said final ill bing suggestion go copy review,issue,negative,negative,negative,negative,negative,negative
1200952468,"Hey, I was wondering that changing the ""Copying Data"" to ""Accessing data"" in the pilot image might make more sense?
![Screenshot_2022-08-01-14-55-17_1920x1080](https://user-images.githubusercontent.com/55556994/182118213-3e8fe30b-ea7a-4b34-a02f-6ad01c566ce2.png)

",hey wondering data data pilot image might make sense,issue,negative,neutral,neutral,neutral,neutral,neutral
1198837648,Outstanding work. @IshanMi @shubham3121 @rasswanth-s @IonesioJunior  This PR contains some significantly impressive work combining DL + DP that likely doesn't exist anywhere else. Im sure Copilot will be learning to reproduce this in no time. 😂,outstanding work significantly impressive work combining likely exist anywhere else sure copilot learning reproduce time,issue,positive,positive,positive,positive,positive,positive
1195486479,Apparently we can install syft[tff] with --use-deprecated=legacy-resolver. We can use that for an integration test.,apparently install use integration test,issue,negative,positive,neutral,neutral,positive,positive
1194856613,"If my understanding is correct then this is already covered by this code:
https://github.com/OpenMined/PySyft/blob/a591dea8bbdc53a3df8b8022f7a9341e75c907c5/packages/grid/backend/grid/worker.py#L60

And this test:
https://github.com/OpenMined/PySyft/blob/a591dea8bbdc53a3df8b8022f7a9341e75c907c5/tests/integration/network/connect_nodes_test.py#L162

But please let me know if I am mis-understanding something.

We do really appreciate the PR however, so if you are interested in contributing, I can highly recommend signing up for our Padawan program on our blog where we mentor people 1:1 to understand the code base and contribute. Feel free to DM me on Slack to discuss further.",understanding correct already covered code test please let know something really appreciate however interested highly recommend program mentor people understand code base contribute feel free slack discus,issue,positive,positive,neutral,neutral,positive,positive
1194853856,"Hi @jabelman the Network already joins itself automatically on startup. I would highly recommend not treating anything in `Experimental` as up to date, those notebooks can live for years with old experimental and out of date code.",hi network already automatically would highly recommend treating anything experimental date live old experimental date code,issue,negative,positive,positive,positive,positive,positive
1193573675,"@madhavajay no, the goal was just to make it possible for a network to join itself and defer to whatever logic already existed in the VPNJoinSelfMessageWithReply, but I didn't fully read through it. I was thinking the join self message would handle the error checking for a network trying to join another network instead of itself. I was following this notebook as a guide for setting up a network with multiple domains, but could not get it to work without this change to the code: 

https://github.com/OpenMined/PySyft/blob/2e58833bcfb5e7d9b697633383ca42995899d1c5/notebooks/Experimental/Shubham/Joining%20a%20Network%20Node.ipynb",goal make possible network join defer whatever logic already fully read thinking join self message would handle error network trying join another network instead following notebook guide setting network multiple could get work without change code,issue,negative,neutral,neutral,neutral,neutral,neutral
1193548156,Hi @jabelman is the goal of this to allow Networks to connect to other Network VPNs?,hi goal allow connect network,issue,negative,neutral,neutral,neutral,neutral,neutral
1193153038,"Updated `hagrid quickstart`:

## Command:
```
hagrid quickstart
```
### What it does:
- Downloads deps and sample notebook and opens it in a jupyter notebook
- If the `quickstart/` dir already exists, will skip downloading deps and open up the dir
- If a notebook already exists in the directory, will directly open the same up 

## Command:
```
hagrid quickstart <url-to-notebook>
```
### What it does:
- Downloads and opens the notebook if it doesn't exist
- If it already exists, prompt the user if they are sure they want to overwrite it with a y/N

## Command:
```
hagrid quickstart --reset
```
### What it does:
- Prompts the user for confirmation of what they are about to do
- Deletes the existing virtual envs and notebooks in the same dir and create an entirely new setup, ie fresh deps and a sample notebook, unless URL is provided


PS: The code has also been modularised now with the main division into two parts ie setup and run, and further micro functions to perform checks and independent commands.
",command sample notebook notebook already skip open notebook already directory directly open command notebook exist already prompt user sure want overwrite command reset user confirmation virtual create entirely new setup ie fresh sample notebook unless provided code also main division two ie setup run micro perform independent,issue,positive,positive,positive,positive,positive,positive
1192173360,"@kiendang @madhavajay , Just the launched the stacks with is PR merged in dev, the stacks start very fast now, parallely , amazing work guys, The speedup is lightning fast.",dev start fast amazing work lightning fast,issue,positive,positive,positive,positive,positive,positive
1191760434,"@madhavajay yep good to go, we will discuss at a later day how to improve it further",yep good go discus later day improve,issue,positive,positive,positive,positive,positive,positive
1191428516,This pull request has been linked to [Shortcut Story #6512: [Feature] - Add Open Telemetry](https://app.shortcut.com/openmined/story/6512/feature-add-open-telemetry).,pull request linked story feature add open telemetry,issue,negative,neutral,neutral,neutral,neutral,neutral
1189940763,"@kiendang awesome work. Our stack will start so much faster with this PR!

I fixed some issue where the worker was not getting the UID set on the first startup due to the same race condition so I changed it so that the worker also respects the `postgresql` lock and now everything is good. I will merge this when the tests pass.",awesome work stack start much faster fixed issue worker getting set first due race condition worker also lock everything good merge pas,issue,positive,positive,positive,positive,positive,positive
1189771207,Closing as this seems to be caused by `safety` which is being installed in the `backend` container even without `dev` mode.,safety container even without dev mode,issue,negative,neutral,neutral,neutral,neutral,neutral
1188784913,"Thanks for the PR @ShubhamPalriwala, the new getting started section looks great!",thanks new getting section great,issue,positive,positive,positive,positive,positive,positive
1184529318,"https://github.com/OpenMined/PySyft/pull/6608#pullrequestreview-1033405428 Upon further consideration and disussion - it seems more important that 0.7 be able to fully execute the MFLP demo. So we should lean towards merging in all of the new functionality once its ready (and tests are passing), likely as one large PR (this one). 0.8 is a significant refactor push during which we can dig into the next/deeper architectural conversations, and it seems like there's a smooth upgrade path from the functionality here (0.7) and functionality we have discussed supporting in 0.8.

Please forgive my message before which now feels pre-mature and not fully considered. I was not at my best.",upon consideration important able fully execute lean towards new functionality ready passing likely one large one significant push dig architectural like smooth upgrade path functionality functionality supporting please forgive message fully considered best,issue,positive,positive,positive,positive,positive,positive
1184526314,Impressive pace of progress in this PR. Also great job breaking things into lots of intuitive commits.,impressive pace progress also great job breaking lot intuitive,issue,positive,positive,positive,positive,positive,positive
1183822953,"Great work getting it ready for merge. Unfortunately it looks like we renamed the class and implemented it here: https://github.com/OpenMined/PySyft/blob/dev/packages/syft/src/syft/core/tensor/autodp/phi_tensor.py#L1424

I'll close this PR for now.",great work getting ready merge unfortunately like class close,issue,positive,positive,positive,positive,positive,positive
1183446050,Closing this PR since we implemented dot during model training ,since dot model training,issue,negative,neutral,neutral,neutral,neutral,neutral
1183445288,"This likely won't make it to 0.7, so postponing this PR for now- will require changes to almost all Phi and Gamma Tensor operations.",likely wo make require almost phi gamma tensor,issue,negative,neutral,neutral,neutral,neutral,neutral
1183440810,Closing since I believe all of these are already in dev ,since believe already dev,issue,negative,neutral,neutral,neutral,neutral,neutral
1179824230,"Hi @Adsensess the guide you referenced is for `0.2.x`, it won't work in any other version of syft.",hi guide wo work version,issue,negative,neutral,neutral,neutral,neutral,neutral
1179523343,"ModuleNotFoundError: No module named 'syft.frameworks' 

I've tried 0.5.0 and 0.5.1, but they didn't work. The error still exists.",module tried work error still,issue,negative,neutral,neutral,neutral,neutral,neutral
1178543870,"Hi @Dragon-Tab use `hagrid` to deploy rather than directly with docker compose. Alternatively if you run `hagrid` with `--cmd=true` it will output the command you can use to manually run with `docker compose`.

Also you will need `docker compose` v2 which is no longer called `docker-compose`. It ships with all the new docker desktop versions or you can get it for linux here: https://github.com/docker/compose/

TLDR:
```
$ pip install hagrid
$ hagrid launch domain to docker:8081 --tag=latest
```

Optionally to do a dry run to see what `hagrid` is doing:
```
$ hagrid launch domain to docker:8081 --tag=latest --cmd=true
```",hi use deploy rather directly docker compose alternatively run output command use manually run docker compose also need docker compose longer new docker get pip install launch domain docker optionally dry run see launch domain docker,issue,negative,positive,neutral,neutral,positive,positive
1175470921,Hi @Adsensess can you elaborate on your issue? This issue was opened years ago relating to `0.2.x`?,hi elaborate issue issue ago,issue,negative,positive,positive,positive,positive,positive
1173183541,"Hi @kiristern it's not ready yet, but we do have a docs team working on new documentation and the PyTorch training code is being worked on. Thanks for your patience.",hi ready yet team working new documentation training code worked thanks patience,issue,positive,positive,positive,positive,positive,positive
1172719029,"Hi @madhavajay I noticed this issue has been closed but unsure where to find the (new) examples of using PySyft for training PyTorch FL models, as described in the original comment. Would you please be able to direct me to the tutorial? Thank you for your work !",hi issue closed unsure find new training original comment would please able direct tutorial thank work,issue,positive,positive,positive,positive,positive,positive
1171409348,"Amazing work @ShubhamPalriwala, thanks for your contribution! ",amazing work thanks contribution,issue,positive,positive,positive,positive,positive,positive
1169467647,"@lepangdan in Duet there are two nodes, one is the Data Owner side with a store, and the other is the Data Scientist. All data that is send with `.send` goes to the Data Owner side. None of that traffic goes through any other servers.",duet two one data owner side store data scientist data send go data owner side none traffic go,issue,negative,neutral,neutral,neutral,neutral,neutral
1168273961,"@madhavajay  so you mean the data owner did upload the actual data (encrypted version) to duet,  not duet just knowing an address pointer? ",mean data owner actual data version duet duet knowing address pointer,issue,negative,negative,negative,negative,negative,negative
1168255346,"@lepangdan In the version you refer to syft `0.5` with Duet, there are two nodes and they communicate peer to peer. There is a signalling server used to establish the p2p connection through a firewall but after that the traffic is purely peer to peer and uses this library:
https://github.com/aiortc/aiortc

I believe it has some kind of encryption of the UDP packets but you would need to check their documentation. Regardless, Syft 0.5 is not intended for production use.",version refer duet two communicate peer peer server used establish connection traffic purely peer peer library believe kind encryption would need check documentation regardless intended production use,issue,positive,positive,positive,positive,positive,positive
1168163259,"Hi, @madhavajay  Thanks for your reply. And I have 4 confusing problems which need to be clarified with your help.  
1. **Whether Duet or GridNode or OpenMined could see the data uploaded by the data owner** because the following code shows data owner needs to send their data to duet `age_data_pointer = age_data.send(duet, pointable=True)` [see here](https://github.com/OpenMined/courses/blob/foundations-of-private-computation/federated-learning/duet_basics/Duet_Basics_Data_Owner.ipynb).  
2. **Or the data owner doesn't send actual data to the duet, which only creates a data address pointer**, and makes the duet know where the data is stored, and sent the address of the dataset if the data owner allows, then the duet sent to address to the data scientist?
3. The speaker says GridNode exit and does not participate in connection anymore after the data owner and data scientist create a connection [see here](https://courses.openmined.org/courses/foundations-of-private-computation/5b4beea5-9e95-42a5-9b8e-c5222386314a/7ed3019d-3d1f-4cc1-9231-b61143bda983),  however, we can see in code, duet still do much work,  is the two things conflict?
4.  The computation shown follow  [see here](https://github.com/OpenMined/courses/blob/foundations-of-private-computation/federated-learning/duet_basics/Duet_Basics_Data_Scientist.ipynb) is performed in the server of data owner or Duet/GridNode?  
      ```
      average_age = data_ptr.float().mean()
      # Now the Data Scientist wants to download the result.
      try:
          average_age.get()
      except Exception as e:
          print(e)
      ```",hi thanks reply need help whether duet could see data data owner following code data owner need send data duet duet see data owner send actual data duet data address pointer duet know data sent address data owner duet sent address data scientist speaker exit participate connection data owner data scientist create connection see however see code duet still much work two conflict computation shown follow see server data owner data scientist result try except exception print,issue,positive,positive,neutral,neutral,positive,positive
1168127997,"Hi @lepangdan, data sent to a Domain is visible by the person who sent it there, and anyone who owns the domain since they have control of the physical database and the data is not stored encrypted at rest by default. Typically this means that private data is only added by Data Owners to their Domains.

Does that answer your question?",hi data sent domain visible person sent anyone domain since control physical data rest default typically private data added data answer question,issue,negative,neutral,neutral,neutral,neutral,neutral
1168126954,"Hi @lepangdan the nodes can talk to each other directly, or via a network using something we call a ProxyClient.
If you look at our SMPC Integration tests you can see that they have 3 party communication going on.

https://github.com/OpenMined/PySyft/blob/f62ba29ff944b456e62ad03ee1fad9baa87974dd/tox.ini#L334
https://github.com/OpenMined/PySyft/tree/dev/tests/integration/smpc",hi talk directly via network something call look integration see party communication going,issue,negative,positive,neutral,neutral,positive,positive
1167330273,"Thanks for getting back, @madhavajay! Looking forward to working with the examples! I'll keep this issue open for any updates until then. ",thanks getting back looking forward working keep issue open,issue,negative,positive,neutral,neutral,positive,positive
1167299544,"Hi @naga-karthik Thanks for asking, we actually recently changed the previous PyTorch integration to make it (much) more flexible, and its going to be pretty exciting to show.

We'll have some examples for you soon.",hi thanks actually recently previous integration make much flexible going pretty exciting show soon,issue,positive,positive,positive,positive,positive,positive
1164356348,I will make this mergeable and break the features into different PRs as well as tasks in our planning.,make break different well,issue,negative,neutral,neutral,neutral,neutral,neutral
1160081080,"As discussed today, the Getting Started will focus primarily on the setup and we will be having something like ""What's next guides"" after the setup that will have micro-notebooks such as ""Adding a data scientist"", and ""Increasing the Privacy Budget"".",today getting focus primarily setup something like next setup data scientist increasing privacy budget,issue,negative,positive,positive,positive,positive,positive
1160005990,@curt-mitch awesome work. I changed the port because the filer is probably more useful during dev since there is only 1 node.,awesome work port filer probably useful dev since node,issue,positive,positive,positive,positive,positive,positive
1159976979,This pull request has been linked to [Shortcut Story #5882: [Feature] - Refactor Network Pairing to include callback URL](https://app.shortcut.com/openmined/story/5882/feature-refactor-network-pairing-to-include-callback-url).,pull request linked story feature network include,issue,negative,neutral,neutral,neutral,neutral,neutral
1159974869,"@madhavajay I had an idea to revamp the current Getting started section in more of a _story format_ heavily inspired from our ""Remote Data Science in 15 minutes"" from the ""Introduction to Remote Data Science course"".
This would involve **gamifying** their experience with a storyline such as ""predicting the number of heads in a coin toss"" and introducing characters such as:
- Alice: One who tosses the coin aka Data Owner
- Bob: Who says he can predict the outcome without actually knowing the original result aka Remote Data Scientist
- Macy: Node where Alice keeps her record of the flips aka Domain node
- etc as the story progresses if needed

As the story progresses, they would be guided for the setup accordingly and whenever a setup is required, the page will split into 3 options:
- Linux OS
- Mac
- Windows


This will be very friendly as well as involving in nature for first-timers, **but** I doubt if the audience that just directly wants to get started with the local setup ASAP will not like this.

@IrinaMBejan @Kiaka007 @abhiwalia15 Would like to know your thoughts as well on the same!",idea revamp current getting section heavily inspired remote data science introduction remote data science course would involve experience number coin toss one coin aka data owner bob predict outcome without actually knowing original result aka remote data scientist node record aka domain node story story would setup accordingly whenever setup page split o mac friendly well nature doubt audience directly get local setup like would like know well,issue,positive,positive,neutral,neutral,positive,positive
1159330229,@lepangdan We are doing something in this vein currently but it has not been released as a tutorial. If you look at the SMPC examples you will see that operations can be done against multiple nodes via SMPC. The communication is handled via the client class which is the same one that you get when logging into a node.,something vein currently tutorial look see done multiple via communication handled via client class one get logging node,issue,negative,neutral,neutral,neutral,neutral,neutral
1158541684,"> 
@madhavajay  I don't really get that multiple distributed workers for a single action graph?  could you explain it in more detail? In fact, what I want to know is if I have multiple machines that have their own data, could I train a model using federated learning.  I really care if these machines can communicate with each other and, if possible, how to communicate in PySyft. Is there any tutorial for the case?",really get multiple distributed single action graph could explain detail fact want know multiple data could train model learning really care communicate possible communicate tutorial case,issue,positive,positive,neutral,neutral,positive,positive
1158468697,"@lepangdan if you create a Domain on each machine and split your data up, then you can connect to them via a `client` and do data parallel, however we currently don't support multiple distributed workers for a single action graph, but this is something we will build down the track.",create domain machine split data connect via client data parallel however currently support multiple distributed single action graph something build track,issue,positive,positive,neutral,neutral,positive,positive
1154793319,"

> > > Hi @caiyuanqin, it looks like you are trying to use the old 0.2.x method of `TorchHook` in 0.3.0 which is no longer needed.
> > > This raises a very good issue which is we need to add a 0.2.x upgrade explanation to our README.md so thanks, I will get this in the pipeline asap.
> > 
> > 
> > Can you please show how should we write the following in syft 0.3.0:
> > import torch as th
> > import syft as sy
> > hook = sy.TorchHook(th)
> 
> Someone have a solution for this ? I use torch 1.6 and syft 0.3.0 How can I write this lines of codes in 0.3.0 if sy.TorchHook() is not anymore available ?

We don't need hook and the example are as follows:
alice = sy.VirtualMachine(name=""alice"")
bob = sy.VirtualMachine(name= 'bob')",hi like trying use old method longer good issue need add upgrade explanation thanks get pipeline please show write following import torch th import hook th someone solution use torch write available need hook example bob,issue,positive,positive,positive,positive,positive,positive
1154790923,"> Someone have a solution for this that how we can execute code with torchhook in syft 0.3.x? please reply
such as: 
alice = sy.VirtualMachine(name=""alice"")",someone solution execute code please reply,issue,positive,neutral,neutral,neutral,neutral,neutral
1153861282,"Hi @Irfan1001 I don't believe `syft.frameworks` is part of `0.5` is there a reason you are using `syft==0.5.0rc1`, can you try the final `0.5.0`?
https://pypi.org/project/syft/0.5.0/

Or the 0.5.1 hotfix?
https://pypi.org/project/syft/0.5.1/",hi believe part reason try final,issue,negative,neutral,neutral,neutral,neutral,neutral
1153859605,"Hi @JacksonSung sorry we don't support `0.2.x` any more, the old branch is here:
https://github.com/OpenMined/PySyft/tree/syft_0.2.x

The deprecation FAQ is here:
https://github.com/OpenMined/PySyft/blob/main/packages/syft/docs/FAQ_0.2.x.md",hi sorry support old branch deprecation,issue,negative,negative,negative,negative,negative,negative
1153743676,"I'm not 100% sure that this can be done without causing privacy leakage. Can you explain a bit more about why FPT ""increases the range of the input tensor"". Why should it increase the range? Do you mean it reduces the precision? If so, then unfortunately it's doing exactly what it's supposed to.

It's actually quite important that we don't use floating point precision for differential privacy. Let's not merge this change until we are sure we understand it. https://www.microsoft.com/en-us/research/wp-content/uploads/2012/10/lsbs.pdf",sure done without causing privacy leakage explain bit range input tensor increase range mean precision unfortunately exactly supposed actually quite important use floating point precision differential privacy let merge change sure understand,issue,positive,positive,positive,positive,positive,positive
1153605463,This pull request has been linked to [Shortcut Story #6320: [Bug] - User Register API does not update University and Website](https://app.shortcut.com/openmined/story/6320/bug-user-register-api-does-not-update-university-and-website).,pull request linked story bug user register update university,issue,negative,neutral,neutral,neutral,neutral,neutral
1153589414,"@tuduweb @tcp currently, the frontend is sending requests with content-type `multipart-form data` in headers to the register API `http://localhost:8081/api/v1/register`. But the register API accepts data as `application/json`.

This works currently.
```
curl --location --request POST 'http://localhost:8081/api/v1/register' \
--header 'Content-Type: application/json' \
--data-raw '{
    ""name"": ""Jane Doe"",
    ""email"": ""myemail@email.com"",
    ""password"": ""password""
}'
```",currently sending data register register data work currently curl location request post header name jane doe password password,issue,negative,neutral,neutral,neutral,neutral,neutral
1152994584,"ModuleNotFoundError: No module named 'syft.frameworks'

can anybody help me on this issue , please ?",module anybody help issue please,issue,positive,neutral,neutral,neutral,neutral,neutral
1152935302,"@madhavajay I elaborate on pysyft-0.2.3a3，and my purpose is extracting  original torch.nn.Module or torchscript including original torch.nn.Module  from RecursiveScriptModule which derives from  train_config.TrainConfig().get_model().obj. 
Thank you for your quick reply.",elaborate purpose original original thank quick reply,issue,positive,positive,positive,positive,positive,positive
1152017886,"I am closing this issue, as this was for the old notebooks,
For any question feel free to DM me on OM slack
My handle `Rasswanth`
Joining LInk : [OM Slack](https://slack.openmined.org)",issue old question feel free om slack handle joining link om slack,issue,positive,positive,positive,positive,positive,positive
1152012455,"Hi @yuanbw,
The Old Notebook was one of our Nice to have features, 

It was not fully completed, There are some example smpc examples in https://github.com/OpenMined/PySyft/tree/dev/notebooks/smpc/Training%20Demo
For the initial Training,

To work with the example you would need to launch Domain Nodes through **hagrid**,
Our current syft documentation would help you in the same 
https://openmined.github.io/PySyft/

Creating new examples notebooks for our current architecture is at the top of my `TODO` list, within one or two week , I will create good Starting notebooks for SMPC.

I am closing this issue, as the feature was not implement.
Feel to reach out to me for any questions on OM slack,
Joining link: [OM Slack](https://slack.openmined.org)
My Slack handle: `@Rasswanth`

",hi old notebook one nice fully example initial training work example would need launch domain current documentation would help new current architecture top list within one two week create good starting issue feature implement feel reach om slack joining link om slack slack handle,issue,positive,positive,positive,positive,positive,positive
1152007494,"To work with examples, you would need to launch Domain Nodes through hagrid , 
The syft documentation,would help you with the initial setup and deployment
https://openmined.github.io/PySyft/",work would need launch domain documentation would help initial setup deployment,issue,negative,neutral,neutral,neutral,neutral,neutral
1152003809,"Hi @jiyanxin , 
At that time  we had SyMPC  in another repo, https://github.com/OpenMined/SyMPC , PySyft did not have full fledged SyMPC
Currently we have some example notebooks in https://github.com/OpenMined/PySyft/tree/dev/notebooks/smpc/Training%20Demo
For Initial Training Part, 

Creating Good SMPC Example notebook is at top of my TODO list, Within maybe one or two weeks, I will create good SMPC notebook example.",hi time another full currently example initial training part good example notebook top list within maybe one two create good notebook example,issue,positive,positive,positive,positive,positive,positive
1150829112,"@madhavajay
1. `hagrid debug`

```
WARNING: No swap limit support


When reporting bugs, please copy everything between the lines.
==================================================================

{""datetime"": ""09/06/2022 16:26:10 CST"", ""python_binary"": ""/home/n504/anaconda3/envs/ob-fed/bin/python"", ""dependencies"": {""docker"": ""/usr/bin/docker"", ""git"": ""/usr/bin/git"", ""ansible-playbook"": ""/home/n504/anaconda3/envs/ob-fed/bin/ansible-playbook""}, ""environment"": {""uname"": [""Linux"", ""n504-3090"", ""5.4.0-110-generic"", ""#124~18.04.1-Ubuntu SMP Fri Apr 22 12:01:21 UTC 2022"", ""x86_64"", ""x86_64""], ""platform"": ""linux"", ""os_version"": ""5.4.0-110-generic"", ""python_version"": ""3.9.12""}, ""hagrid"": ""0.2.50"", ""hagrid_dev"": false, ""hagrid_path"": ""/home/n504/anaconda3/envs/ob-fed/lib/python3.9/site-packages"", ""hagrid_repo_sha"": ""156cf93489b16dd0205b0058d4d23d56b3a91ab8"", ""docker"": ""Client:\n Context:    default\n Debug Mode: false\n Plugins:\n  app: Docker App (Docker Inc., v0.9.1-beta3)\n  buildx: Docker Buildx (Docker Inc., v0.8.2-docker)\n  compose: Docker Compose (Docker Inc., v2.5.0)\n  scan: Docker Scan (Docker Inc., v0.17.0)\n\nServer:\n Containers: 67\n  Running: 32\n  Paused: 0\n  Stopped: 35\n Images: 25\n Server Version: 20.10.16\n Storage Driver: overlay2\n  Backing Filesystem: extfs\n  Supports d_type: true\n  Native Overlay Diff: true\n  userxattr: false\n Logging Driver: json-file\n Cgroup Driver: cgroupfs\n Cgroup Version: 1\n Plugins:\n  Volume: local\n  Network: bridge host ipvlan macvlan null overlay\n  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog\n Swarm: inactive\n Runtimes: io.containerd.runc.v2 io.containerd.runtime.v1.linux runc\n Default Runtime: runc\n Init Binary: docker-init\n containerd version: 212e8b6fa2f44b9c21b2798135fc6fb7c53efc16\n runc version: v1.1.1-0-g52de29d\n init version: de40ad0\n Security Options:\n  apparmor\n  seccomp\n   Profile: default\n Kernel Version: 5.4.0-110-generic\n Operating System: Ubuntu 18.04.5 LTS\n OSType: linux\n Architecture: x86_64\n CPUs: 20\n Total Memory: 62.5GiB\n Name: n504-3090\n ID: ELD6:IDFL:EFGZ:SZD3:3SR3:3YEX:ME6I:DT2I:3V4C:TI2U:5L4F:GJ7W\n Docker Root Dir: /home/n504/docker\n Debug Mode: false\n Registry: https://index.docker.io/v1/\n Labels:\n Experimental: false\n Insecure Registries:\n  127.0.0.0/8\n Registry Mirrors:\n  https://y0qd3iq.mirror.aliyuncs.com/\n Live Restore Enabled: false\n\n""}
```
2. import & print 
```
Python 3.9.12 (main, Apr  5 2022, 06:56:58)
[GCC 7.5.0] :: Anaconda, Inc. on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import syft as sy
>>> print(sy.__version__)
0.6.0
```

3. `pip3 list`
```
hagrid               0.2.50
syft                 0.6.0
```",warning swap limit support please copy everything docker git environment generic platform generic false docker client context mode docker docker docker docker compose docker compose docker scan docker scan docker running stopped server version storage driver backing native overlay logging driver driver version volume network bridge host null log local swarm default binary version version version security profile kernel version operating system architecture total memory name id eld yex docker root mode registry experimental insecure registry live restore import print python main anaconda type help copyright license information import print pip list,issue,positive,negative,neutral,neutral,negative,negative
1149532434,"Hi @rish2410 there is a lot of HE content in our older branch here:
https://github.com/OpenMined/pysyft/tree/syft_0.5.0
https://github.com/OpenMined/PySyft/tree/syft_0.5.0/packages/syft/examples/homomorphic-encryption

I can highly recommend you checkout the Course 2 content:
https://courses.openmined.org/

For our latest version `dev` (0.7.0 release coming soon), we have gone for `SMPC` instead of `HE` because it executes faster.",hi lot content older branch highly recommend course content latest version dev release coming soon gone instead faster,issue,negative,positive,positive,positive,positive,positive
1149531281,"@tuduweb are you able to tell us what version of syft / hagrid you are using?
```
$ hagrid debug
```

```
import syft as sy
print(sy.__version__)
```",able tell u version import print,issue,negative,positive,positive,positive,positive,positive
1149529250,@JacksonSung Can you please elaborate on what version you are running and what code you are running?,please elaborate version running code running,issue,negative,positive,positive,positive,positive,positive
1149528779,"Hi @NightOnDark we are about to release `0.7.0` from `dev` with a examples of NN training and FL as well as other great things. `0.6.0` was a big change from previous versions that introduced our containerized server for PyGrid, however during 0.6.0 our internal Tensor type was still being implemented. Please checkout `dev` to see our latest code which can handle a variety of operations with both DP and SMPC.",hi release dev training well great big change previous server however internal tensor type still please dev see latest code handle variety,issue,positive,positive,positive,positive,positive,positive
1149527400,We have upgraded packaging to `21.3` in `dev` and the API in `0.6` and `dev` (0.7.0) is nearly identical.,dev dev nearly identical,issue,negative,positive,neutral,neutral,positive,positive
1149525778,"We understand peoples frustration but the changes between versions have been necessary and based on discoveries we have made over the iterations while implementing the latest research. We were unable to triage all of the github issues while working to deliver the latest version for the community. That time is very close and `dev` which will soon be `0.7.0` is about to be released. We already have stable beta releases weekly on PyPI and dockerhub all of which are tested against our integration test suite.

Recently we were accepted to GSOD so we have two great docs team members who will be working with us to update all the documentation to our biggest release.

Thank you for your patience. You will see in the commit logs we have been working constantly since the last release to completely overhaul the tech stack to support our user friendly Automatic Differential Privacy and Secure Multi-Party Compute solution which can be deployed to a variety of platforms using our cli tool hagrid.

We are looking forwards to sharing the 0.7.0 release with everyone shortly.",understand frustration necessary based made latest research unable triage working deliver latest version community time close dev soon already stable beta weekly tested integration test suite recently accepted two great team working u update documentation biggest release thank patience see commit working constantly since last release completely overhaul tech stack support user friendly automatic differential privacy secure compute solution variety tool looking forward release everyone shortly,issue,positive,positive,positive,positive,positive,positive
1149522108,@kovkev we have 2 people from GSOD working on docs and tutorials. We are also working on something related to CNNs and will be demonstrating it soon.,people working also working something related soon,issue,negative,neutral,neutral,neutral,neutral,neutral
1149521180,"@yuanbw 0.6 and 0.7 (dev) do not use SyMPC, instead they use a built in SMPC implementation from the same authors @gmuraru and @rasswanth-s.

@rasswanth-s what is the equivalent of `merge` in 0.7?",dev use instead use built implementation equivalent merge,issue,negative,neutral,neutral,neutral,neutral,neutral
1149519745,"@mathews this could be fixed in `dev`, I will see what @tcp says.",could fixed dev see,issue,negative,positive,neutral,neutral,positive,positive
1149518992,"@adamFinastra any reason you want the client ID after the fact? We no longer support 0.5 but we did have a custom class you could implement to control the connection flow.

Checkout the `DuetCredentialExchanger`:

https://github.com/OpenMined/PySyft/blob/f07116ffc4bd6ed6f262ddacf9e77ece988ddad0/packages/syft/src/syft/grid/duet/exchange_ids.py#L1
",reason want client id fact longer support custom class could implement control connection flow,issue,negative,neutral,neutral,neutral,neutral,neutral
1149517089,"@Crazynovatech we temporarily had an int32 limitation which as been changed now to int64. The underlying implementations of our DP, SMPC and FixedPrecision tensors require different things under the hood. You should be able to load in a normal numpy array in the latest version and it will take care of it. Can you try this with the latests code on `dev`?",temporarily limitation underlying require different hood able load normal array latest version take care try code dev,issue,negative,positive,positive,positive,positive,positive
1149515812,"Hi @Whiplashcandobear we are no longer supporting 0.5. We have Automatic DP and SMPC built into `0.7.0` which is about to be released from `dev`.

I can highly recommend you checkout our latest version with:
```
$ pip install hagrid
$ hagrid launch domain to docker:8081 --tag=latest
$ pip install --pre syft
```

Then checkout some of our integration tests or notebooks for examples on how to use. More docs coming shortly.",hi longer supporting automatic built dev highly recommend latest version pip install launch domain docker pip install integration use coming shortly,issue,positive,positive,positive,positive,positive,positive
1149515086,"@yigedage We no longer support these old websocket versions of Grid. I believe the libraries have changed causing issues with how these old versions run now. I can highly recommend you checkout our latest version with:
```
$ pip install hagrid
$ hagrid launch domain to docker:8081 --tag=latest
$ pip install --pre syft
```

Then checkout some of our integration tests or notebooks for examples on how to use. More docs coming shortly.",longer support old grid believe causing old run highly recommend latest version pip install launch domain docker pip install integration use coming shortly,issue,positive,positive,positive,positive,positive,positive
1149513613,"@MissiontoMars these versions are no longer supported. Please checkout `dev` and our `0.7.0` release.

We will be updating our docs shortly but you can get started with:
```
$ pip install hagrid
$ hagrid launch domain to docker:8081 --tag=latest
```",longer please dev release shortly get pip install launch domain docker,issue,negative,neutral,neutral,neutral,neutral,neutral
1149512688,"@bentay85 theres nothing stopping you from modifying the worker code to do this, however we are about to release 0.7.0 and no longer support <0.5 including 0.2.",there nothing stopping worker code however release longer support,issue,negative,neutral,neutral,neutral,neutral,neutral
1149511502,"@AmitDavidi we are working on our docs as we speak, however in the mean time the best resource is https://courses.openmined.org/",working speak however mean time best resource,issue,positive,positive,positive,positive,positive,positive
1149510511,"@MissiontoMars My guess is that your docker version is out of date.
Please install the latest version of `docker desktop` and enable `docker compose v2` in the settings.",guess docker version date please install latest version docker enable docker compose,issue,negative,positive,positive,positive,positive,positive
1149509822,"@zhaowei-laster Those notebooks are all experimental, if you want something which is stable, checkout our integration tests.

https://github.com/OpenMined/PySyft/tree/dev/tests/integration

This one is particularly good for seeing a good end to end smpc + dp example:
https://github.com/OpenMined/PySyft/blob/dev/tests/integration/e2e/trade_demo_smpc_adp_test.py",experimental want something stable integration one particularly good seeing good end end example,issue,positive,positive,positive,positive,positive,positive
1149508234,"@Sihan-Song you need to run `pip install -e .[dev]` to make sure that the pytest packages also get installed.

You can see how all of this is done in our `tox` tasks or github CI.
We run all our main tests on Windows on every PR and nightlies.

What are you trying to do?",need run pip install dev make sure also get see done tox run main every trying,issue,negative,positive,positive,positive,positive,positive
1149507593,"@Crazynovatech HAGrid can deploy to local docker or a remote VM so it depends on where you deployed it. Where ever you did, there will be a redis store and a seaweed blob store and any data sent will go into either of those depending on what type or size it is.

In local dev mode you can run:
```
$ hagrid launch domain to docker:8081 --dev
```

Then you can use the dev tools to see the different data stores.
```
$ ./scripts/dev_tools.sh 
```",deploy local docker remote ever store seaweed blob store data sent go either depending type size local dev mode run launch domain docker dev use dev see different data,issue,negative,negative,neutral,neutral,negative,negative
1149506246,@Crazynovatech are you able to provide more example code and the version of Grid / Syft you are using?,able provide example code version grid,issue,negative,positive,positive,positive,positive,positive
1149505298,"@deepquantum88 are you able to show the error? If you call `tolist` you would then just get a ListPointer instead of a TensorPointer, is there a reason you need to?",able show error call would get instead reason need,issue,negative,positive,positive,positive,positive,positive
1149502947,We had some small issue and the Signalling server was rebooted and it is now working again. There is also a maintenance release of syft 0.5 which allows newer Torch which should fix issues with Apple Silicon.,small issue server working also maintenance release torch fix apple silicon,issue,negative,negative,negative,negative,negative,negative
1149502367,"That container is deprecated and has been removed.
If you want to use a jupyter environment with syft easily do this:
```
$ git clone https://github.com/OpenMined/PySyft.git
$ cd PySyft
$ pip install tox
$ tox -e syft.jupyter
```",container removed want use environment easily git clone pip install tox tox,issue,negative,positive,positive,positive,positive,positive
1149501148,Not all object types are serializable. In 0.5 we have a local proxy object called SyNet which holds the functionality locally but refers to remote data Module pointers. Since 0.7 includes our own Tensor type this is no longer required.,object local proxy object functionality locally remote data module since tensor type longer,issue,negative,negative,neutral,neutral,negative,negative
1149499542,"Hi @Rene36 we have actually added support for arm64 linux just recently and it runs in CI on our nightlies. HAGrid now supports an extra command `--platform linux/arm64` which will get passed to docker. Can you confirm if this works on Raspberry Pi?

Also please make sure to update to the latest 0.7.0 beta releases.
```
$ pip install hagrid
$ hagrid launch domain to docker:8081 --tag=latest --platform=linux/arm64
```",hi actually added support arm recently extra command platform get docker confirm work raspberry pi also please make sure update latest beta pip install launch domain docker,issue,positive,positive,positive,positive,positive,positive
1149495905,Unfortunately PyVertical does not support any newer versions of Syft. I believe the authors were interested but we haven't spoken since ICLR 2021.,unfortunately support believe interested spoken since,issue,negative,negative,negative,negative,negative,negative
1149495086,"I updated 0.5 today and tested the latest version of torchvision, this doesnt add new functionality but just lets you import syft. However the fix was for Apple Silicon not other 0.5 bugs as 0.5 is now considered deprecated.",today tested latest version doesnt add new functionality import however fix apple silicon considered,issue,negative,positive,positive,positive,positive,positive
1149491781,@szczepanTopolski I believe this is an issue with PyDP. Check the latest versions here: https://github.com/OpenMined/PyDP/,believe issue check latest,issue,negative,positive,positive,positive,positive,positive
1149488336,0.5 is deprecated. I did release a new version today but only to fix issues with installing syft on Apple Silicon.,release new version today fix apple silicon,issue,negative,positive,positive,positive,positive,positive
1149487355,Both PyGrid and SyMPC are now part of the monorepo and we have working implementations of SMPC inside the core. Our docs are undergoing an update.,part working inside core undergoing update,issue,negative,neutral,neutral,neutral,neutral,neutral
1149486701,@fu1001hao syft 0.2x was deprecated in 2020 and syft 0.5 was deprecated in 2021. We will be providing lots of new tutorials on FL in 0.7.0 shortly.,providing lot new shortly,issue,negative,positive,neutral,neutral,positive,positive
1149485398,@spnzig We have a new code architecture in dev which will be released as `0.7.0` soon with a much better working SMPC implementation built into the core.,new code architecture dev soon much better working implementation built core,issue,negative,positive,positive,positive,positive,positive
1149484807,@fu1001hao we are getting close to releasing `0.7.0` and there is a completely new architecture and smpc implementation there. You can see it in dev.,getting close completely new architecture implementation see dev,issue,negative,positive,positive,positive,positive,positive
1149432923,"@leriomaggio awesome work thank you.
In the end I just stripped a bunch of stuff out and managed to get some of the tests to still pass. The core of Syft is probably fine but some of the lib support or grid might be flakey.",awesome work thank end stripped bunch stuff get still pas core probably fine support grid might,issue,positive,positive,positive,positive,positive,positive
1145457285,This pull request has been linked to [Shortcut Story #5770: [Bug] - Dataset Deletion Issues](https://app.shortcut.com/openmined/story/5770/bug-dataset-deletion-issues).,pull request linked story bug deletion,issue,negative,neutral,neutral,neutral,neutral,neutral
1143809544,This pull request has been linked to [Shortcut Story #6297: [Bug] - Network nodes getting stuck on timeouts with domains which are down](https://app.shortcut.com/openmined/story/6297/bug-network-nodes-getting-stuck-on-timeouts-with-domains-which-are-down).,pull request linked story bug network getting stuck,issue,negative,neutral,neutral,neutral,neutral,neutral
1140227329,Wow! Seriously a 7->1 change? That... sounds very significant!,wow seriously change significant,issue,positive,positive,neutral,neutral,positive,positive
1137474981,"@rasswanth-s I think there are issues with the `gamma_tensor_serde` test- I tried running it in the dev and got the same error there: 
![Screenshot from 2022-05-25 12-00-16](https://user-images.githubusercontent.com/32711264/170306454-5fbd3225-10fb-4c4b-a3bc-1dee98ebcfaa.png)
 ",think tried running dev got error,issue,negative,neutral,neutral,neutral,neutral,neutral
1137148986,"Yes, i dont change anything. I just pull down it and run this with hagrid.",yes dont change anything pull run,issue,negative,neutral,neutral,neutral,neutral,neutral
1137146302,"request headers

```
POST /api/v1/register HTTP/1.1
Accept: */*
Accept-Encoding: gzip, deflate
Accept-Language: zh
Cache-Control: no-cache
Connection: keep-alive
Content-Length: 274
Content-Type: multipart/form-data; boundary=----WebKitFormBoundaryHECfdt5nzI95oBYg
Host: 172.20.144.74:8081
Origin: http://172.20.144.74:8081
Pragma: no-cache
Referer: http://172.20.144.74:8081/signup
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.0.0 Safari/537.36
```

payload -> Form Data

```
------WebKitFormBoundaryHECfdt5nzI95oBYg
Content-Disposition: form-data; name=""new_user""

{""name"":""username"",""institution"":"""",""email"":""username@gmail.com"",""password"":""123456"",""confirm_password"":""123456"",""website"":"""",""role"":1}
------WebKitFormBoundaryHECfdt5nzI95oBYg--
```",request post accept deflate connection host origin mac o like gecko form data name institution password role,issue,positive,neutral,neutral,neutral,neutral,neutral
1136625977,"Yes, sure looks like it. No other changes were made?

If you have more details -- like the request body (exclude the pw) -- that would be helpful.",yes sure like made like request body exclude would helpful,issue,positive,positive,positive,positive,positive,positive
1135250147,"I'll just ""throw"" this here:
- Provide ""Show"" option on password fields",throw provide show option password,issue,negative,neutral,neutral,neutral,neutral,neutral
1134278480,This pull request has been linked to [Shortcut Story #6206: [Feature] - HAGrid - rename login to ui beta](https://app.shortcut.com/openmined/story/6206/feature-hagrid-rename-login-to-ui-beta).,pull request linked story feature rename login beta,issue,negative,neutral,neutral,neutral,neutral,neutral
1133537174,This pull request has been linked to [Shortcut Story #5926: [Bug] - Frontend container broken in dev mode](https://app.shortcut.com/openmined/story/5926/bug-frontend-container-broken-in-dev-mode).,pull request linked story bug container broken dev mode,issue,negative,negative,negative,negative,negative,negative
1130269319,This pull request has been linked to [Shortcut Story #6172: [Feature] - Add admin email and password to HAGrid](https://app.shortcut.com/openmined/story/6172/feature-add-admin-email-and-password-to-hagrid).,pull request linked story feature add password,issue,negative,neutral,neutral,neutral,neutral,neutral
1130093819,"It seems it works and the linting passed so we can merge, After the AdAstra demos, I will expand on this to use Kibana for visualization.",work merge demo expand use visualization,issue,negative,neutral,neutral,neutral,neutral,neutral
1129143000,Yes its' only about parametrization and usage of tests. I will check it once more and push a final version so we can close. ,yes usage check push final version close,issue,negative,neutral,neutral,neutral,neutral,neutral
1129114879,"> 

@madhavajay this PR is @teo-milea 's effort to improve benchmarking, mostly the code structure e.g parametrization, it was totally separate from the original benchmarking work which is already merged, so this doesn't impact the way we do benchmarking now, they're progressive improvements. @teo-milea ???",effort improve mostly code structure totally separate original work already impact way progressive,issue,positive,positive,positive,positive,positive,positive
1128501484,"I have installed syft '0.5.0rc1' version using
pip install syft==0.5.0rc1

but still, I'm getting this error.

ModuleNotFoundError: No module named 'syft.frameworks'

can anybody help me with that?
thanks
",version pip install still getting error module anybody help thanks,issue,negative,positive,positive,positive,positive,positive
1128376195,@chinmayshah99 this PR breaks hagrid which is why none of the tests are passing. I can recommend running HAGrid locally and some of the tests before committing to catch these issues before CI.,none passing recommend running locally catch,issue,negative,neutral,neutral,neutral,neutral,neutral
1128349259,"@teo-milea and @bitsofsteve can I get a sanity check on this, I am a bit out of the loop on the benchmarking code, but I got it running locally on my machine so I assume that means its working. Also I think the readme needs updating but I don't know if there are any replacement args for all the changes to removing REPT and SEPT?",get sanity check bit loop code got running locally machine assume working also think need know replacement removing sept,issue,negative,neutral,neutral,neutral,neutral,neutral
1128335357,"Hey, you can use Tensor flow Federated. It's very well documented !!! I ended up using that.. ",hey use tensor flow well ended,issue,negative,neutral,neutral,neutral,neutral,neutral
1128331113,"Man, when I clicked this issue I was expecting to see the maintainer's replies on example links (there were some examples in 0.3.0 but removed in the latest, wtf!), but no replies are seen after four weeks. 
I have to say pysyft is one of the most ridiculous python libraries that every api is f**king no longer supported in the next minor version and the demos and docs are as perfunctory as an 8-star high school homework repo rather than 8k-star it has. lol",man issue see maintainer example link removed latest seen four say one ridiculous python every king longer next minor version demo perfunctory high school homework rather,issue,negative,positive,neutral,neutral,positive,positive
1127383425,@madhavajay it can go either way :) close if you're cleaning up. We can open a new one in a couple of weeks.,go either way close cleaning open new one couple,issue,negative,positive,neutral,neutral,positive,positive
1125414208,This pull request has been linked to [Shortcut Story #5940: [Feature] - HAGrid Check New Features](https://app.shortcut.com/openmined/story/5940/feature-hagrid-check-new-features).,pull request linked story feature check new,issue,negative,positive,positive,positive,positive,positive
1124844992,This pull request has been linked to [Shortcut Story #6015: [Bug] - Misc AA Demo Notebook Improvements](https://app.shortcut.com/openmined/story/6015/bug-misc-aa-demo-notebook-improvements).,pull request linked story bug aa notebook,issue,negative,neutral,neutral,neutral,neutral,neutral
1124605048,This pull request has been linked to [Shortcut Story #6044: [Bug] - Fix broken Course 3 Stack Integration Tests](https://app.shortcut.com/openmined/story/6044/bug-fix-broken-course-3-stack-integration-tests).,pull request linked story bug fix broken course stack integration,issue,negative,negative,negative,negative,negative,negative
1121841910,"Hi 
I am struggling with torch, cuda and syft!

for using cuda I need torch> 1.11, but syft is noy=t compatible with that!

pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113
Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113
Requirement already satisfied: torch in c:\users\hizadi\fl\fl_avg_cae\env\lib\site-packages (1.10.0)
Requirement already satisfied: torchvision in c:\users\hizadi\fl\fl_avg_cae\env\lib\site-packages (0.12.0+cu113)
Requirement already satisfied: torchaudio in c:\users\hizadi\fl\fl_avg_cae\env\lib\site-packages (0.11.0+cu113)
Requirement already satisfied: typing-extensions in c:\users\hizadi\fl\fl_avg_cae\env\lib\site-packages (from torch) (4.0.0)
Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\users\hizadi\fl\fl_avg_cae\env\lib\site-packages (from torchvision) (9.0.1)
Requirement already satisfied: numpy in c:\users\hizadi\fl\fl_avg_cae\env\lib\site-packages (from torchvision) (1.21.4)
Collecting torch
  Using cached https://download.pytorch.org/whl/cu113/torch-1.11.0%2Bcu113-cp38-cp38-win_amd64.whl (2186.1 MB)
Requirement already satisfied: requests in c:\users\hizadi\fl\fl_avg_cae\env\lib\site-packages (from torchvision) (2.26.0)
Requirement already satisfied: idna<4,>=2.5 in c:\users\hizadi\fl\fl_avg_cae\env\lib\site-packages (from requests->torchvision) (3.3)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\users\hizadi\fl\fl_avg_cae\env\lib\site-packages (from requests->torchvision) (1.26.9)
Requirement already satisfied: charset-normalizer~=2.0.0 in c:\users\hizadi\fl\fl_avg_cae\env\lib\site-packages (from requests->torchvision) (2.0.12)
Requirement already satisfied: certifi>=2017.4.17 in c:\users\hizadi\fl\fl_avg_cae\env\lib\site-packages (from requests->torchvision) (2021.10.8)
Installing collected packages: torch
  Attempting uninstall: torch
    Found existing installation: torch 1.10.0
    Uninstalling torch-1.10.0:
      Successfully uninstalled torch-1.10.0
_ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
syft 0.6.0 requires torch<=1.10.0,>=1.8.1, but you have torch 1.11.0+cu113 which is incompatible._
Successfully installed torch-1.11.0+cu113
",hi struggling torch need torch compatible pip install torch looking requirement already satisfied torch requirement already satisfied requirement already satisfied requirement already satisfied torch requirement already satisfied pillow requirement already satisfied torch requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied collected torch torch found installation torch successfully uninstalled pip dependency resolver currently take account behaviour source following dependency torch torch successfully,issue,positive,positive,positive,positive,positive,positive
1120651363,This pull request has been linked to [Shortcut Story #5754: [Feature] - Store VPN URL and Key and Auto Reconnect](https://app.shortcut.com/openmined/story/5754/feature-store-vpn-url-and-key-and-auto-reconnect).,pull request linked story feature store key auto reconnect,issue,negative,neutral,neutral,neutral,neutral,neutral
1120564987,@gigaray thanks for the PR. We need to actually update those docs because on you can now install HAGrid into windows python and use it there for docker deployments without any wsl2. However due to `ansible` not being available on windows if you want to do deployments to the cloud you either need to use the hagrid docker container or wsl2.,thanks need actually update install python use docker without however due available want cloud either need use docker container,issue,negative,positive,positive,positive,positive,positive
1118423693,This pull request has been linked to [Shortcut Story #5916: [Feature] - Optionally Output JSON when deploying with HAGrid](https://app.shortcut.com/openmined/story/5916/feature-optionally-output-json-when-deploying-with-hagrid).,pull request linked story feature optionally output,issue,negative,neutral,neutral,neutral,neutral,neutral
1118153470,Please check out this repository (https://github.com/MMorafah/Sub-FedAvg). It provides an official implementation for Sub-FedAvg which is Federated Learning Pruning benchmark. ,please check repository official implementation learning pruning,issue,negative,neutral,neutral,neutral,neutral,neutral
1118109512,"@madhavajay  , I planned to port some ideas from this PR to the current MPCTensor , it delayed a bit, I will close this as soon as I finish it",port current bit close soon finish,issue,negative,neutral,neutral,neutral,neutral,neutral
1117581554,Hi @madhavajay - I think we should close this. Thank you!,hi think close thank,issue,negative,neutral,neutral,neutral,neutral,neutral
1117351147,This pull request has been linked to [Shortcut Story #5187: [Bug] - Not able to register users from notebook using `sy.register`](https://app.shortcut.com/openmined/story/5187/bug-not-able-to-register-users-from-notebook-using-syregister).,pull request linked story bug able register notebook,issue,negative,positive,positive,positive,positive,positive
1117348883,@madhavajay yes I think it's good! I will be expanding it as the project goes on - is that okay with the workflow or should I wait until it's *complete*?,yes think good expanding project go wait complete,issue,positive,positive,positive,positive,positive,positive
1116930271,"@ivyclare I fixed the issues with this PR since we renamed some of the classes. However it looks like python doesnt like `+var` for pos, so I changed it to `__pos__()` assuming thats what this test is for.

But it says:
```
E       AttributeError: 'GammaTensor' object has no attribute '__pos__'
```

Sorry if iv made it worse.",fixed since class however like python doesnt like assuming thats test object attribute sorry made worse,issue,negative,negative,negative,negative,negative,negative
1116924686,"@teo-milea owch, sorry about all the noise on the dev branch. Let me know if you need help rebasing this.",sorry noise dev branch let know need help,issue,negative,negative,negative,negative,negative,negative
1116923342,@factdroid can you please rebase this on dev since we have renamed ndim and removed lots of old DP code. Also it looks like the lint checks need to pass.,please rebase dev since removed lot old code also like lint need pas,issue,positive,positive,neutral,neutral,positive,positive
1116922828,Probably the worlds most expensive string line fix PR. 😂,probably expensive string line fix,issue,negative,negative,negative,negative,negative,negative
1116900560,@shubham3121 i think this just needs a check to make sure the nested metadata deserialization isnt broken.,think need check make sure broken,issue,negative,positive,neutral,neutral,positive,positive
1116895260,@teo-milea can you rebase this on the latest dev if its still needed?,rebase latest dev still,issue,negative,positive,positive,positive,positive,positive
1116895007,"@shubham3121 wow long PR conversation, what is needed to get this merged?",wow long conversation get,issue,positive,positive,neutral,neutral,positive,positive
1116894472,@tcp are we still going to use this branch or should we close this PR?,still going use branch close,issue,negative,neutral,neutral,neutral,neutral,neutral
1115967565,This pull request has been linked to [Shortcut Story #5717: [Tech Debt] - Change CD to run tests first then deploy atomically](https://app.shortcut.com/openmined/story/5717/tech-debt-change-cd-to-run-tests-first-then-deploy-atomically).,pull request linked story tech debt change run first deploy atomically,issue,negative,positive,positive,positive,positive,positive
1114563901,This pull request has been linked to [Shortcut Story #4565: Create the notebook for domain owners to upload a dataset](https://app.shortcut.com/openmined/story/4565/create-the-notebook-for-domain-owners-to-upload-a-dataset).,pull request linked story create notebook domain,issue,negative,neutral,neutral,neutral,neutral,neutral
1113870694,"Hi @pgupta07 those notebooks are pretty old and are mock notebooks, please see the more up to date docs here: https://openmined.github.io/PySyft/",hi pretty old mock please see date,issue,negative,positive,positive,positive,positive,positive
1110410502,@bitsofsteve can you resolve this conflict and ill hit merge.,resolve conflict ill hit merge,issue,negative,negative,negative,negative,negative,negative
1107746860,"> Hello, @Williance!
> 
> We are working on getting all of them + many more. Stay tuned, more will show up in the next few weeks.

Hello, is there any LSTM examples except Sine waves now?",hello working getting many stay tuned show next hello except sine,issue,negative,positive,positive,positive,positive,positive
1103996117,This pull request has been linked to [Shortcut Story #5688: [Feature] - HAGrid can deploy multiple machines in one command](https://app.shortcut.com/openmined/story/5688/feature-hagrid-can-deploy-multiple-machines-in-one-command).,pull request linked story feature deploy multiple one command,issue,negative,neutral,neutral,neutral,neutral,neutral
1102073003,This pull request has been linked to [Shortcut Story #5605: [Bug] - Joining Network doesnt appear on network.domains](https://app.shortcut.com/openmined/story/5605/bug-joining-network-doesnt-appear-on-networkdomains).,pull request linked story bug joining network doesnt appear,issue,negative,neutral,neutral,neutral,neutral,neutral
1101716785,"Is there any improvement with the documentation part? I am a student and want to use the library for projects but there is not way of getting started. 

If there is no documentation can someone please suggest any other library to do a Federated Learning-based project. ",improvement documentation part student want use library way getting documentation someone please suggest library project,issue,positive,neutral,neutral,neutral,neutral,neutral
1099865384,@kovkev  Can I work on this.I will take part in Gsod this year,work take part year,issue,negative,neutral,neutral,neutral,neutral,neutral
1095897382,"Since the Gamma Tensor PR is merged https://github.com/OpenMined/PySyft/pull/6353 ,Merging this PR to fixed precision branch to modify it to NDEPT,to get it ready for merge.",since gamma tensor fixed precision branch modify get ready merge,issue,negative,positive,positive,positive,positive,positive
1093119833,"I am also getting the same error on python 3.7.9 when i run precommit

```
error: ""bool"" has no attribute ""as_integer_ratio""
```",also getting error python run precommit error bool attribute,issue,negative,neutral,neutral,neutral,neutral,neutral
1080465080,"Thanks! Actually, I tried one day later the same code and the error was gone lol...",thanks actually tried one day later code error gone,issue,negative,positive,neutral,neutral,positive,positive
1080339508,Unfortunately not. It works running the same code on colab though (just removing loopback=True).,unfortunately work running code though removing,issue,negative,negative,negative,negative,negative,negative
1079127864,Hi! Have you figured out how to solve this? I also met this problem.,hi figured solve also met problem,issue,negative,neutral,neutral,neutral,neutral,neutral
1069643162,"Hi I can't seem to find the notebook in any of the branches anymore. Does anyone have the solution? I noticed an older version of PySyft (before Duet) had the `BaseDataset` class:

`base=sy.BaseDataset(torch.from_numpy(X_train),torch.from_numpy(y_train))`

But I would love to find the Duet version equivalent. My non-federated model uses a pretty simple dataset which I'd like to replicate in PySyft (currently using `0.5.0`):

```
class RegressionDataset(Dataset):
    
    def __init__(self, X_data, y_data):
        self.X_data = X_data
        self.y_data = y_data
        
    def __getitem__(self, index):
        return self.X_data[index], self.y_data[index]
        
    def __len__ (self):
        return len(self.X_data)
```",hi ca seem find notebook anyone solution older version duet class would love find duet version equivalent model pretty simple like replicate currently class self self index return index index self return,issue,positive,positive,positive,positive,positive,positive
1063877867,@rasswanth-s sure let's do it. Should we update the version to 0.7.0 beta ,sure let update version beta,issue,negative,positive,positive,positive,positive,positive
1063827838,"@shubham3121 , should I do for both (dev and 0.6.0) as dev Readme.md is in the front page of the repo",dev dev front page,issue,negative,neutral,neutral,neutral,neutral,neutral
1063815689,@rasswanth-s I guess we need to raise the pull request against `0.6.0` branch instead of dev. ,guess need raise pull request branch instead dev,issue,negative,neutral,neutral,neutral,neutral,neutral
1063657983,"No worries @arturomf94 , we are working on mostly porting SMPC to PySyft,you could ping me on slack, if you would like to take up SMPC issues in PySyft :slightly_smiling_face: ",working mostly could ping slack would like take,issue,negative,positive,positive,positive,positive,positive
1063230590,"> @gmuraru Should we continue development in SyMPC, as we are mostly moving all our functionality to PySyft, or shall we work on it as proof of concept.

Hey folks! :) @gmuraru @rasswanth-s - yeah, sorry. I just left this because I thought there were going to be some considerable changes to how we interact with PySyft so feel free to pick it up in whichever way you think is best or close this PR.",continue development mostly moving functionality shall work proof concept hey yeah sorry left thought going considerable interact feel free pick whichever way think best close,issue,positive,positive,positive,positive,positive,positive
1062602202,"Closing the PR , as we had decided to modify public divide to x/y ==> x*(y)-1",decided modify public divide,issue,negative,neutral,neutral,neutral,neutral,neutral
1062565038,"@gmuraru  Should we continue development in SyMPC, as we are mostly moving all our functionality to PySyft, or shall we work on it as proof of concept.",continue development mostly moving functionality shall work proof concept,issue,negative,positive,positive,positive,positive,positive
1046846087,"Hey @RoyRin and @Chris-george-anil, thanks for adding this issue - we are working on better docs for PySyft.

You can find here a few tutorials on using and deploying PySyft + PyGrid and the API documentation. It's still work in progress, but happy to hear your feedback: https://openmined.github.io/PySyft/index.html#

We will work on adding tutorials similar to the outdated ones and I'll try to add updates on this current thread. If you want to contribute, let me know!


",hey thanks issue working better find documentation still work progress happy hear feedback work similar outdated try add current thread want contribute let know,issue,positive,positive,positive,positive,positive,positive
1043554515,"@IgorDavidyuk thanks for the PR, great job. I just worked with @tcp to streamline this screen even more and fixed a few issues.

Looking forwads to more PRs from yourself! 🙂",thanks great job worked streamline screen even fixed looking,issue,positive,positive,positive,positive,positive,positive
1042645939,Building a local Duet server can help you. #5991 ,building local duet server help,issue,negative,neutral,neutral,neutral,neutral,neutral
1042613505,"If you launch version 0.5.0, the code below can play the same function as `syft-network` to start a Flask,
```
import syft.grid.example_nodes.network as network
network.signaling_server()
```",launch version code play function start flask import network,issue,negative,neutral,neutral,neutral,neutral,neutral
1040105681,"Thank you for your comment. Yes, it is working fine with Ubuntu 20.04",thank comment yes working fine,issue,positive,positive,positive,positive,positive,positive
1039726350,"@Crazynovatech HAGrid currently only supports Ubuntu 20.04, the only difference I can imagine is that the docker version or docker compose install isn't functioning properly. `docker-compose` is deprecated and should be removed, all of the new docker compose versions act as a plugin to docker engine. This should give you an indication of what ansible is doing:
https://github.com/OpenMined/PySyft/blob/dev/packages/grid/ansible/roles/node/tasks/docker.yml",currently difference imagine docker version docker compose install properly removed new docker compose act docker engine give indication,issue,negative,positive,neutral,neutral,positive,positive
1032700019,"I'm able to curl the address and receive the three alternative addresses, but the same error persist.
I also tried @zhengjiawei001 solution: it tries to connect but stops after some time not getting any response.
I'd like to use it on the loopback too, but it doesn't work neither :/.

`
#import syft as sy
#duet = sy.duet(loopback=True)
`

I'm with pysyft version 0.5.0.",able curl address receive three alternative error persist also tried solution connect time getting response like use work neither import duet version,issue,negative,positive,positive,positive,positive,positive
1032234435,"> 

I was also getting the same error as @mkeshav  and @phenomenal-manish . I tried installing an earlier version using pip and it worked for me.

`pip install syft==0.5.0`

https://pypi.org/project/syft/0.6.0/#history
",also getting error tried version pip worked pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
1031631513,"Same error for me.
I use pyenv with a python version 3.7.4 end pysyft 0.5.0.
I'm not sure, but I think it happened when I updated the pyOpenSSL lib to the 22.0.0 version.",error use python version end sure think version,issue,negative,positive,positive,positive,positive,positive
1031603446,but the problem is that version 0.3.x does not support torchhook. If it's supported please share an example. ,problem version support please share example,issue,positive,neutral,neutral,neutral,neutral,neutral
1027347774,"Benchmarked using `spicy_bird.ipynb` and confirmed this speeds up uploading significantly. Great job, Rasswanth!",confirmed significantly great job,issue,positive,positive,positive,positive,positive,positive
1022787924,"As of `Jan 2022`, this error still remains , 
![image](https://user-images.githubusercontent.com/52364337/151281193-3eda6fad-de71-451b-a965-382fd9b236ef.png)


",error still remains image,issue,negative,neutral,neutral,neutral,neutral,neutral
1018371406,"I dig a bit deeper into the source code and I am trying to understand better how PySyft works. The following information do fix max problem, but maybe they help others:

When importing syft, the ` lib/__init__.py` is called and runs `lib_ast = create_lib_ast(None)` all the way at the end. I haven't figured this part out yet, but for each data type three functions are assigned (send, tag, describe).

Checkout out `util.py`, where you can find the obj, name and attr (send, tag, describe) I printed below. The attr/functions are defined in `ast/klaas.py`. For example for the Python Bytes data type,
```
<class 'syft.lib.python.Bytes'> send <function Class.create_send_method.<locals>.send at 0x7fb8287b7280>
<class 'syft.lib.python.Bytes'> tag <function Class.create_storable_object_attr_convenience_methods.<locals>.tag at 0x7fb8287b7310>
<class 'syft.lib.python.Bytes'> describe <function Class.create_storable_object_attr_convenience_methods.<locals>.describe at 0x7fb8287b73a0>
```

So, this approach is also done for all kinds of torch data types.
```
<class 'torch.nn.parameter.Parameter'> send <function Class.create_send_method.<locals>.send at 0x7fb8286341f0>
<class 'torch.nn.parameter.Parameter'> tag <function Class.create_storable_object_attr_convenience_methods.<locals>.tag at 0x7fb8285b9820>
<class 'torch.nn.parameter.Parameter'> describe <function Class.create_storable_object_attr_convenience_methods.<locals>.describe at 0x7fb8285b98b0>
<class 'torch.nn.modules.module.Module'> send <function Class.create_send_method.<locals>.send at 0x7fb8285b9940>
<class 'torch.nn.modules.module.Module'> tag <function Class.create_storable_object_attr_convenience_methods.<locals>.tag at 0x7fb8285bc040>
<class 'torch.nn.modules.module.Module'> describe <function Class.create_storable_object_attr_convenience_methods.<locals>.describe at 0x7fb8285bc0d0>
<class 'torch.nn.modules.conv.Conv2d'> send <function Class.create_send_method.<locals>.send at 0x7fb8285bc160>
<class 'torch.nn.modules.conv.Conv2d'> tag <function Class.create_storable_object_attr_convenience_methods.<locals>.tag at 0x7fb8285bc700>
<class 'torch.nn.modules.conv.Conv2d'> describe <function Class.create_storable_object_attr_convenience_methods.<locals>.describe at 0x7fb8285bc790>
<class 'torch.nn.modules.dropout.Dropout2d'> send <function Class.create_send_method.<locals>.send at 0x7fb8285bc820>
<class 'torch.nn.modules.dropout.Dropout2d'> tag <function Class.create_storable_object_attr_convenience_methods.<locals>.tag at 0x7fb8285bcdc0>
<class 'torch.nn.modules.dropout.Dropout2d'> describe <function Class.create_storable_object_attr_convenience_methods.<locals>.describe at 0x7fb8285bce50>
```

You can find a dictionary of all supported torch operations in `lib/torch/allowlist.py`.

**Question: How do I use them for my CNN which I want to send to a VirtualMachine and eventually to a remote host?** ",dig bit source code trying understand better work following information fix problem maybe help none way end figured part yet data type three assigned send tag describe find name send tag describe printed defined example python data type class send function class tag function class describe function approach also done torch data class send function class tag function class describe function class send function class tag function class describe function class send function class tag function class describe function class send function class tag function class describe function find dictionary torch question use want send eventually remote host,issue,negative,positive,positive,positive,positive,positive
1013958895,Closing this as it seems we might need to rethink some of the logic with ```TensorPointer``` and ```Shares```,might need rethink logic,issue,negative,neutral,neutral,neutral,neutral,neutral
1013631565,I am also getting the same bug while following Adam's video Multi-Limb SplitNN on MNIST,also getting bug following video,issue,negative,neutral,neutral,neutral,neutral,neutral
1013631325,"HI Team and @StrangeTcy , 

Any update on this bug ? ",hi team update bug,issue,negative,neutral,neutral,neutral,neutral,neutral
1013154207,"With some workarounds I fixed the issue for a fresh Ubuntu 20.04 install, PySyft v0.6.0 and hagrid v0.2.0. I fixed the CPU architecture issue by changing two dockerfiles. I tried the setup with two jupyter notebooks and I can connect to the domain node on the Raspberry Pi. However, I did not improve for efficiency.

1. Find the path of the installed `hagrid` package.
2. Open `lib.py` and comment out `update_repo(repo=GIT_REPO, branch=repo_branch)` to avoid that our changes to the dockerfiles are over written.

The used tailscale image ([shaynesweeney/tailscale:latest](https://hub.docker.com/r/shaynesweeney/tailscale/tags)) in `/hagrid/PySyft/packages/grid/vpn/tailscale.dockerfile` and the [waitforit](https://github.com/maxcnunes/waitforit/releases/) function in `hagrid/PySyft/packages/grid/backend/backend.dockerfile` do not support ARM 64 bit (aarch64). Therefore, I replaced it with the original [tailscale image](https://hub.docker.com/r/tailscale/tailscale/tags) and built the `waitforit` function from source. 
The resulting dockerfiles are at the bottom of this post.

The last release from `waitforit` is almost 4 years old. Therefore, I recommend to replace it with something more current.

I logged into the remote Raspberry Pi domain via
```
domain = sy.login(email=""info@openmined.org"",
                              password=""changethis"",
                              url=<ip_address>,
                              port=8081)
```


`hagrid/PySyft/packages/grid/backend/backend.dockerfile`
```
#FROM python:3.9.9-slim as build
FROM ubuntu:latest as build

RUN apt-get update && apt-get upgrade -y

# Download and build waitforit from source
RUN DEBIAN_FRONTEND=noninteractive apt-get install git golang -y
RUN git clone https://github.com/maxcnunes/waitforit
WORKDIR waitforit
RUN go build

RUN cp waitforit /usr/local/bin/waitforit

RUN --mount=type=cache,target=/var/cache/apt
RUN apt-get install -y --no-install-recommends curl python3-dev gcc make

WORKDIR /app
COPY grid/backend/requirements.txt /app

RUN apt-get install -y python3-pip
RUN apt-get install -y python3-dev libpq-dev  # pscopg2 requirement
# Allow installing dev dependencies to run tests
RUN --mount=type=cache,target=/root/.cache
RUN pip install --user ""uvicorn[standard]"" gunicorn

RUN if [ $(uname -m) = ""x86_64"" ]; then \
  pip install --user torch==1.10.0+cpu -f https://download.pytorch.org/whl/torch_stable.html; \
  fi

# apple m1 build PyNaCl for aarch64
RUN if [ $(uname -m) != ""x86_64"" ]; then \
  pip install --user PyNaCl; \
  pip install --user torch==1.10.0 -f https://download.pytorch.org/whl/torch_stable.html; \
  fi

RUN --mount=type=cache,target=/root/.cache
RUN pip install --user -r requirements.txt

# allow container to wait for other services
#ENV WAITFORIT_VERSION=""v2.4.1""
#COPY grid/backend/waitforit /usr/local/bin/waitforit
#RUN curl -o /usr/local/bin/waitforit -sSL https://github.com/maxcnunes/waitforit/releases/download/>
#  chmod +x /usr/local/bin/waitforit

# Backend
FROM python:3.9.9-slim as backend
ENV PYTHONPATH=/app
ENV PATH=/root/.local/bin:$PATH

# copy start scripts and gunicorn conf
COPY grid/backend/docker-scripts/start.sh /start.sh
COPY grid/backend/docker-scripts/gunicorn_conf.py /gunicorn_conf.py
COPY grid/backend/docker-scripts/start-reload.sh /start-reload.sh
COPY grid/backend/worker-start.sh /worker-start.sh
COPY grid/backend/worker-start-reload.sh /worker-start-reload.sh

RUN chmod +x /start.sh
RUN chmod +x /start-reload.sh
RUN chmod +x /worker-start.sh
RUN chmod +x /worker-start-reload.sh

COPY --from=build /root/.local /root/.local
COPY --from=build /usr/local/bin/waitforit /usr/local/bin/waitforit

#RUN --mount=type=cache,target=/root/.cache
# ---------------------------------------------------------
RUN apt-get update
RUN apt-get install -y python3-dev libpq-dev  # pscopg2 requirement
RUN apt-get update && apt-get install -y libpython3-dev build-essential
WORKDIR /app
COPY grid/backend/requirements.txt .
RUN pip install --user -r requirements.txt

RUN pip install --user tenacity configparser  # ModuleNotFoundError for psycopg2
RUN pip install --user watchdog pyyaml argh psycopg2
# ---------------------------------------------------------

# copy grid
COPY grid/backend /app/

# copy syft
# until we have stable releases make sure to install syft
COPY syft/setup.py /app/syft/setup.py
COPY syft/setup.cfg /app/syft/setup.cfg
COPY syft/src /app/syft/src

# install syft
RUN --mount=type=cache,target=/root/.cache
RUN pip install --user -e /app/syft

# change to worker-start.sh or start-reload.sh as needed
CMD [""bash"", ""start.sh""]
```

`hagrid/PySyft/packages/grid/vpn/tailscale.dockerfile`
```
# FROM shaynesweeney/tailscale:latest
FROM tailscale/tailscale:latest

RUN --mount=type=cache,target=/var/cache/apk

# see https://github.com/alpine-docker/git/issues/35
RUN apk update && apk upgrade
RUN apk fix
RUN apk add --no-cache python3 py3-pip ca-certificates

WORKDIR /tailscale
COPY ./requirements.txt /tailscale/requirements.txt
RUN --mount=type=cache,target=/root/.cache
RUN pip install --user -r requirements.txt

COPY ./tailscale.sh /tailscale/tailscale.sh
COPY ./tailscale.py /tailscale/tailscale.py

ENV HOSTNAME=""node""

CMD [""sh"", ""-c"", ""/tailscale/tailscale.sh ${HOSTNAME}""]
```",fixed issue fresh install fixed architecture issue two tried setup two connect domain node raspberry pi however improve efficiency find path package open comment avoid written used image latest function support arm bit therefore original image built function source resulting bottom post last release almost old therefore recommend replace something current logged remote raspberry pi domain via domain python build latest build run update upgrade build source run install git run git clone run go build run run run install curl make copy run install run install requirement allow dev run run run pip install user standard run pip install user fi apple build run pip install user pip install user fi run run pip install user allow container wait copy run curl python path copy start copy copy copy copy copy run run run run copy copy run run update run install requirement run update install copy run pip install user run pip install user tenacity run pip install user watchdog copy grid copy copy stable make sure install copy copy copy install run run pip install user change bash latest latest run see run update upgrade run fix run add python copy run run pip install user copy copy node sh,issue,positive,positive,positive,positive,positive,positive
1012388772,"Closing the PR, as the windows was fixed due to an orthogonal problem.",fixed due orthogonal problem,issue,negative,negative,neutral,neutral,negative,negative
1012203130,"Hi @IgorDavidyuk, you need to install syft and hagrid in the editable mode for your dev changes to be reflected.
`cd PySyft/packages/syft` and `pip install -e .`
`cd PySyft/packages/hagrid` and `pip install -e .`",hi need install mode dev reflected pip install pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
1012081622,@madhavajay @tudorcebere Could you guys please check if the deleted methods in the last commits aren't being used? I didn't find any other mention in PySyft's codebase but they seems pretty important for the AST.,could please check last used find mention pretty important ast,issue,positive,positive,positive,positive,positive,positive
1008690449,"Hi @Rene36 , could you try with the latest 0.6.0 branch and post regarding the status of the error.",hi could try latest branch post regarding status error,issue,negative,positive,positive,positive,positive,positive
1008576988,"True , the blogposts and tutorials does not point to the exact version for which it was created, some are pretty old.It might be hard to work with them. 

In the future blog posts we would  pin the exact version for which it was created.

Currently at this point, the best starting point to learn more about syft ecosystem , would  be start at our new course.
**Remote Data Science** : https://courses.openmined.org/courses/introduction-to-remote-data-science.
which covers most of the new API,
Feel  free to post any questions.

Closing the issue for now, reopen if necessary.
",true point exact version pretty might hard work future would pin exact version currently point best starting point learn ecosystem would start new course remote data science new feel free post issue reopen necessary,issue,positive,positive,positive,positive,positive,positive
990538462,I'm not sure what would be the correct way to avoid this - https://github.com/OpenMined/PySyft/runs/4478730784?check_suite_focus=true#step:7:30,sure would correct way avoid,issue,negative,positive,positive,positive,positive,positive
987832060,"I am seeing the same issue still with the openmined/pysyft-notebook image. I am also using the code ""syft.frameworks.torch.federated""
",seeing issue still image also code,issue,negative,neutral,neutral,neutral,neutral,neutral
985668430,`hagrid==0.1.9` seems to have fixed the issue. Even though it is not yet working on ARM architectures.,fixed issue even though yet working arm,issue,negative,positive,neutral,neutral,positive,positive
985315043,"> > Then current stable release is 0.5.0 and the private AI series on https://courses.openmined.com uses this version to implement the course
> 
> However, this course website is down.

This is the correct link:
https://courses.openmined.org/",current stable release private ai series version implement course however course correct link,issue,negative,neutral,neutral,neutral,neutral,neutral
983808786,"> Then current stable release is 0.5.0 and the private AI series on https://courses.openmined.com uses this version to implement the course

However, this course website is down.",current stable release private ai series version implement course however course,issue,negative,neutral,neutral,neutral,neutral,neutral
983576161,"I guess `from syft.frameworks.crypten.context import run_multiworkers` might work with `syft==0.2.9`. However, the general structure changed significantly to version 0.5.0. I cannot help you with your question directly, but I suppose you search for your `run_multiworkers` in the latest [documentation](https://pysyft.readthedocs.io/en/latest/). which unfortunately is for v0.3.0.

The `from syft.` only gives for me core, lib, grid, federated, ast and proto. So for example `from syft.core.node.common.action.exception_action import UnknownPrivateException` works.",guess import might work however general structure significantly version help question directly suppose search latest documentation unfortunately core grid ast proto example import work,issue,negative,positive,positive,positive,positive,positive
983567104,"With `syft==0.6.0a0` I get a similar error after running `syft-network` in a terminal with the respective virtual environment active:

```
Traceback (most recent call last):
  File ""/home/karsten/Dokumente/venvs/fl60/bin/syft-network"", line 5, in <module>
    from syft.grid.example_nodes.network import run
ModuleNotFoundError: No module named 'syft.grid.example_nodes'
```

## System Information
 - OS: Ubuntu
 - OS Version: 20.04.3 LTS
 - Language Version: Python 3.8.10
 - Package Manager Version: Virtual Environment, Pip 20.0.2",get similar error running terminal respective virtual environment active recent call last file line module import run module system information o o version language version python package manager version virtual environment pip,issue,negative,negative,neutral,neutral,negative,negative
983564450,"From what I've read and heard is v0.2.x not supported anymore and it went through a huge overhaul resulting in v0.5.0. Therefore, I suggest you move forward as well to the newest version. Even though it probably means that most of your code base is waste now.",read went huge overhaul resulting therefore suggest move forward well version even though probably code base waste,issue,negative,negative,negative,negative,negative,negative
983380116,"Closing in favour of this: https://github.com/OpenMined/PySyft/pull/6213 because its not possible to push to this PR since it was not opened by the repo author and so this couldnt be enabled:
<img width=""321"" alt=""Screen Shot 2021-12-01 at 5 55 06 pm"" src=""https://user-images.githubusercontent.com/2882739/144194014-7951a390-6f8f-4483-8a0a-f00cd89ef67b.png"">",possible push since author screen shot,issue,negative,neutral,neutral,neutral,neutral,neutral
982693325,This pull request has been linked to [Shortcut Story #3973: [BUG] Fix problem with data access requests](https://app.shortcut.com/openmined/story/3973/bug-fix-problem-with-data-access-requests).,pull request linked story bug fix problem data access,issue,negative,neutral,neutral,neutral,neutral,neutral
981301984,"@fiza11  Shall we close this, as we had discussed for single tensor pointer for all DP operations",shall close single tensor pointer,issue,negative,negative,neutral,neutral,negative,negative
981227423,I don't think we should disable these tests - we need comparison to keep working,think disable need comparison keep working,issue,negative,neutral,neutral,neutral,neutral,neutral
980828050,interesting integration test failure,interesting integration test failure,issue,negative,positive,neutral,neutral,positive,positive
980827996,Why do we want to disable these tests? I'm very inclined to keep them given tests are what prevent us from regressing on functionality.,want disable keep given prevent u functionality,issue,negative,neutral,neutral,neutral,neutral,neutral
980812773,I had no idea this went in and was trying to figure out why a version I built last week isn't working with my VPN setup on k8s... 😪 ,idea went trying figure version built last week working setup,issue,negative,neutral,neutral,neutral,neutral,neutral
979733436,This pull request has been linked to [Shortcut Story #4094: [Core & Product] - Confusion around what gets shown by .privacy_budget](https://app.shortcut.com/openmined/story/4094/core-product-confusion-around-what-gets-shown-by-privacy_budget).,pull request linked story core product confusion around shown,issue,negative,neutral,neutral,neutral,neutral,neutral
978921644,"@LaplaceZhang i have met the same problem about

`[2021-11-25 07:43:19]: 8 DEBUG WebSocket request accepted, switching protocols`
`[2021-11-25 07:43:19]: 8 DEBUG Closed WebSocket`
`[2021-11-25 07:43:19]: 8 DEBUG Failed to write closing frame -> closing socket`
`[2021-11-25 07:43:19]: 8 DEBUG Closed WebSocket`

and then

`BrokenPipeError: [Errno 32] Broken pipe`

do you know how to fix that now ?really appreciate.",met problem request accepted switching closed write frame socket closed broken pipe know fix really appreciate,issue,negative,negative,negative,negative,negative,negative
978914108,"hah, at first, i met the same problem.
then, you would find that you miss the step starting the pygrid domain.
when you try to start a domain no matter using the docker or manual
you will find some other problems like ""missing environment varibles"",""ConnectionRefusedError: [Errno 111] Connection refused"",""BrokenPipeError: [Errno 32] Broken pipe"" and so on.
i still dont know how to fix some of them.

using syft0.5.0",hah first met problem would find miss step starting domain try start domain matter docker manual find like missing environment connection broken pipe still dont know fix,issue,negative,negative,neutral,neutral,negative,negative
975134200,"Yes, seconded!

I've even tried generating the docs using Sphinx, and I only found documentation on Hagrid - since most of the tutorials are pre 0.3.0 (https://blog.openmined.org/federated-learning-additive-secret-sharing-pysyft/) it's unclear what the expected flow is.

Documentation can be a lot and can slow down development speed, but even just some updated tutorials would be really helpful!
",yes even tried generating sphinx found documentation since unclear flow documentation lot slow development speed even would really helpful,issue,positive,negative,neutral,neutral,negative,negative
975116377,"Please provide a small script to recreate the issue, but I suspect you are either not sending the model to the device
(`model.send(device)`) or not pulling the data from device to the central server (`x= x.get()`).

However, this is a guess, and if you could provide more information, I could provide a better answer.",please provide small script recreate issue suspect either sending model device device data device central server however guess could provide information could provide better answer,issue,negative,positive,neutral,neutral,positive,positive
974760617,"> I am also running into this issue - `from syft.frameworks.torch.dp import pate` returns: `ModuleNotFoundError: No module named 'syft.frameworks'`
> 
> Directly running code from https://blog.openmined.org/maintaining-privacy-in-medical-data-with-differential-privacy/

As told by @madhavajay, 0.3 version of pysyft is a completely new rebuild. Hence I would suggest you to download previous version of pysyft, maybe 0.1x or 0.2x",also running issue import pate module directly running code told version completely new rebuild hence would suggest previous version maybe,issue,negative,positive,neutral,neutral,positive,positive
974394457,"I am also running into this issue - 
`from syft.frameworks.torch.dp import pate`
returns:
`ModuleNotFoundError: No module named 'syft.frameworks'`

Directly running code from https://blog.openmined.org/maintaining-privacy-in-medical-data-with-differential-privacy/",also running issue import pate module directly running code,issue,negative,positive,neutral,neutral,positive,positive
972862459,Hey! I would love to work on this issue!,hey would love work issue,issue,positive,positive,positive,positive,positive,positive
972719100,"@cereallarceny sorry to repeat the question above, but does such an API exists (in 0.3.x and later)? If not, could this be reopened?

thanks",sorry repeat question later could thanks,issue,negative,negative,neutral,neutral,negative,negative
968741055,"Hey @madhavajay, just pushed my progress so far on the TLS story.

On the docker compose side of things, you said that it's ok to break things from the main `docker-compose.yml` file as it's only ever used with the override file and never on its own. Just to confirm, since the main file is the one with options for running with Docker Swarm, does it therefore mean Docker Swarm is never used as a deployment option? If so, I guess I'll remove all mentions of it and further simplify things.

When it comes to `hagrid`, I feel like things are starting to get a lot messier in there than I'd like to work with but I also don't feel comfortable refactoring everything because it's changing pretty quickly without me. What options do you think I should expose and what should happend automagically? For example, for switching the security features on and off, a flag such as `--insecure` (note that deployment would become secure by default). Then, should it ask the user to generate self-signed certificates for them, should it just auto-generate with no prompt, should it tell the user to generate the certs manually and re-run? If users will provide their own certificates, should there be new flags `--tls-certificate`, `--tls-key` with paths to their files or should it tell the user to put their files in the expected location with the expected names? If generating certificates, should it automatically import them to a store, should it prompt the user for options and import, should it tell the user about different ways to import? Should two ports be exposed or only the secure one? Should there be options to turn redirection on and off?",hey progress far story docker compose side said break main file ever used override file never confirm since main file one running docker swarm therefore mean docker swarm never used deployment option guess remove simplify come feel like starting get lot like work also feel comfortable everything pretty quickly without think expose example switching security flag insecure note deployment would become secure default ask user generate prompt tell user generate manually provide new tell user put location generating automatically import store prompt user import tell user different way import two exposed secure one turn redirection,issue,positive,positive,positive,positive,positive,positive
967560965,Has this notebook/the mnist training demo been removed entirely? Is it no longer supported?,training removed entirely longer,issue,negative,neutral,neutral,neutral,neutral,neutral
966437682,"@iamtrask ping, shall we close this as the bug is resolved?",ping shall close bug resolved,issue,negative,neutral,neutral,neutral,neutral,neutral
966046926,"Hey @madhavajay, after I pulled this PR, commands to `vm` seem broken (e.g. `hagrid launch eu to vm`) because they check for dependencies which are no longer included in the list of dependencies to check for. What's the intended way to launch on VM now?",hey seem broken launch eu check longer included list check intended way launch,issue,negative,negative,negative,negative,negative,negative
964507896,Love this added detail! Keep it coming! This really adds a lot of clarity.,love added detail keep coming really lot clarity,issue,positive,positive,positive,positive,positive,positive
963338037,Hi @iamtrask is this issue still available? If so I am interested to take it up and will create the PR for it.,hi issue still available interested take create,issue,positive,positive,positive,positive,positive,positive
961632324,"This pull request has been linked to [Shortcut Story #3754: Missing value in New Budget. Should say the budget increased from 210 to 229 (It did in fact increase this part of the UI just doesn't show it, but the other part does)](https://app.shortcut.com/openmined/story/3754/missing-value-in-new-budget-should-say-the-budget-increased-from-210-to-229-it-did-in-fact-increase-this-part-of-the-ui-just).",pull request linked story missing value new budget say budget fact increase part show part,issue,negative,negative,neutral,neutral,negative,negative
961628299,"This pull request has been linked to:

- [Shortcut Story #3747: Typing in the privacy budget when creating a user in the UI is a bit finnicky](https://app.shortcut.com/openmined/story/3747/typing-in-the-privacy-budget-when-creating-a-user-in-the-ui-is-a-bit-finnicky)
- [Shortcut Story #3749: When creating a new user in the UI the privacy budget doesn't update](https://app.shortcut.com/openmined/story/3749/when-creating-a-new-user-in-the-ui-the-privacy-budget-doesnt-update)
- [Shortcut Story #3750: ""Update budget"" doesn't close window](https://app.shortcut.com/openmined/story/3750/update-budget-doesnt-close-window)
- [Shortcut Story #3752: In Upgrade Requests the ""Current Balance"" accidentally shows ""Current Budget"" instead of the actual current balance.](https://app.shortcut.com/openmined/story/3752/in-upgrade-requests-the-current-balance-accidentally-shows-current-budget-instead-of-the-actual-current-balance)
- [Shortcut Story #3759: Logout doesn't work for admin panel](https://app.shortcut.com/openmined/story/3759/logout-doesnt-work-for-admin-panel)
",pull request linked story privacy budget user bit story new user privacy budget update story update budget close window story upgrade current balance accidentally current budget instead actual current balance story work panel,issue,negative,positive,neutral,neutral,positive,positive
961602314,Tested locally and working great!,tested locally working great,issue,positive,positive,positive,positive,positive,positive
961509339,This pull request has been linked to [Shortcut Story #3659: 3. Lesson 2 - Eliminate the need for .publish().sleep and replace it with a .block method](https://app.shortcut.com/openmined/story/3659/3-lesson-2-eliminate-the-need-for-publishsleep-and-replace-it-with-a-block-method).,pull request linked story lesson eliminate need replace method,issue,negative,neutral,neutral,neutral,neutral,neutral
959351065,This pull request has been linked to [Shortcut Story #3641: Dataset uploading gets crazy slow if you have a lot of datasets you're uploading](https://app.shortcut.com/openmined/story/3641/dataset-uploading-gets-crazy-slow-if-you-have-a-lot-of-datasets-youre-uploading).,pull request linked story crazy slow lot,issue,negative,negative,negative,negative,negative,negative
959262938,This pull request has been linked to [Shortcut Story #3661: HAGrid warn if low ram](https://app.shortcut.com/openmined/story/3661/hagrid-warn-if-low-ram).,pull request linked story warn low ram,issue,negative,neutral,neutral,neutral,neutral,neutral
959061374,This pull request has been linked to [Shortcut Story #3660: Lesson 5 - domain.datasets is pretty ugly if we have a lot of assets.](https://app.shortcut.com/openmined/story/3660/lesson-5-domaindatasets-is-pretty-ugly-if-we-have-a-lot-of-assets).,pull request linked story lesson pretty ugly lot asset,issue,negative,negative,negative,negative,negative,negative
958842104,"Hello,
Extending @Madelon-Molhoek question, it would be nice if in this example Alice has half of the features, Bob the other half + labels.",hello extending question would nice example half bob half,issue,negative,positive,neutral,neutral,positive,positive
958673448,This pull request has been linked to [Shortcut Story #3699: Support Domain Configuration in `dev` as of Nov 1](https://app.shortcut.com/openmined/story/3699/support-domain-configuration-in-dev-as-of-nov-1).,pull request linked story support domain configuration dev,issue,negative,neutral,neutral,neutral,neutral,neutral
958671115,This pull request has been linked to [Shortcut Story #3695: Support Account Settings features in `dev` as of Nov 1](https://app.shortcut.com/openmined/story/3695/support-account-settings-features-in-dev-as-of-nov-1).,pull request linked story support account dev,issue,negative,neutral,neutral,neutral,neutral,neutral
958664203,This pull request has been linked to [Shortcut Story #3688: Support Permissions features in `dev` as of Nov 1](https://app.shortcut.com/openmined/story/3688/support-permissions-features-in-dev-as-of-nov-1).,pull request linked story support dev,issue,negative,neutral,neutral,neutral,neutral,neutral
958505257,"@danielorihuela thanks for the PR, unfortunately we have removed Duet from the `0.6.0` release so I will close this for now.",thanks unfortunately removed duet release close,issue,negative,negative,negative,negative,negative,negative
958202547,This pull request has been linked to [Shortcut Story #3658: Lesson 2 - Confirm that uploading anything other than np.int32 dataset throws an error](https://app.shortcut.com/openmined/story/3658/lesson-2-confirm-that-uploading-anything-other-than-npint32-dataset-throws-an-error).,pull request linked story lesson confirm anything error,issue,negative,neutral,neutral,neutral,neutral,neutral
958185139,@rasswanth-s you're pushing out updates at an incredible pace! well done!,pushing incredible pace well done,issue,negative,positive,positive,positive,positive,positive
957402203,@gmuraru - i'll leave this merge conflict to you as I'm not sure about it.,leave merge conflict sure,issue,negative,positive,positive,positive,positive,positive
957398761,Well done @IshanMi - hope it's ok if we keep rolling in the merges even though it's marked WIP.,well done hope keep rolling even though marked,issue,positive,positive,neutral,neutral,positive,positive
956828892,"> Feel free to revert everything I just did if I caused more damage than help.

No worries. I think I fixed it!",feel free revert everything damage help think fixed,issue,negative,positive,positive,positive,positive,positive
956510942,Feel free to revert everything I just did if I caused more damage than help. ,feel free revert everything damage help,issue,negative,positive,positive,positive,positive,positive
956508232,I'm also really not sure about this merge (https://github.com/OpenMined/PySyft/pull/6112/commits/cb8ac538854b9fc69db4160da3a57c6f619eed71). It's starting to feel like it added back code that was intentionally removed.,also really sure merge starting feel like added back code intentionally removed,issue,positive,positive,positive,positive,positive,positive
956504701,"@gmuraru or @rasswanth-s  - please take a look at my attempt at fixing flake errors. I am not familiar enough with the code to be confident about my fixes.

https://github.com/OpenMined/PySyft/pull/6112/commits/a9332f09bb41e9bdcb5708d87a34b2df0bf17713",please take look attempt fixing flake familiar enough code confident,issue,positive,positive,positive,positive,positive,positive
956485452,Hi Shivam. It doesn't appear that this is translating our existing text but is instead creating a file which translates a toy string. Closing for now?,hi appear text instead file toy string,issue,negative,neutral,neutral,neutral,neutral,neutral
956483436,Brilliant - looking forward to merging as soon as the tests pass!,brilliant looking forward soon pas,issue,positive,positive,positive,positive,positive,positive
956205119,"@iamtrask 
When a user approves a data request, the following operation happens:
`node.store[UID.from_string(_req.object_id)] = tmp_obj` , refer to [line](https://github.com/OpenMined/PySyft/blob/45abdda928cacf5f80657dc0b01c77f5f6944d69/packages/syft/src/syft/core/node/common/node_service/object_request/object_request_service.py#L607)

During this set operation, the BinObject is deleted (Refer to line 170 in this PR). As a result, any BinObjDataset referencing the BinObjet is also deleted due to cascading effect. So if the BinObject being requested is the asset itself, then since the BinObjDataset is deleted, it is no longer visible as part of the Dataset object.",user data request following operation refer line set operation refer line result also due effect asset since longer visible part object,issue,negative,negative,neutral,neutral,negative,negative
955970754,This pull request has been linked to [Shortcut Story #3579: [Notebook] UX Bug fixes](https://app.shortcut.com/openmined/story/3579/notebook-ux-bug-fixes).,pull request linked story notebook bug,issue,negative,neutral,neutral,neutral,neutral,neutral
952637298,"@pculliton totally agree that it seems backwards that you lose your data the moment you call get, but thats how it has been historically. We did create a remote print I think on pointer. It returns self as well so you can chain it.

Try:
```
x_ptr.print()
```",totally agree backwards lose data moment call get thats historically create remote print think pointer self well chain try,issue,negative,negative,neutral,neutral,negative,negative
952498477,"Andrew gave me pointers to where this could be fixed less broadly / more appropriately, so I'm closing this!",gave could fixed le broadly appropriately,issue,negative,positive,positive,positive,positive,positive
952439829,"If you're a data owner and you're calling get() to check your dataset, you probably do *not* expect it to be deleted by that call, so I think it's more a side effect of being able to access those assets with get() than an intended function. In Slack you suggested restricting the delete_obj=False default to Dataset objects / dataset assets. I think that's an excellent idea.",data owner calling get check probably expect call think side effect able access asset get intended function slack default asset think excellent idea,issue,positive,positive,positive,positive,positive,positive
952421358,"The key question is probably, ""Why do you need to call .get() again on something you've already downloaded?""",key question probably need call something already,issue,negative,neutral,neutral,neutral,neutral,neutral
952378897,"It's on the principle: If you don't remember that you need it in the store, then it will break, otherwise, is doing cleanup for you. We assume you are not going to use this twice, unless you tell us you are going to use it twice.",principle remember need store break otherwise cleanup assume going use twice unless tell u going use twice,issue,negative,neutral,neutral,neutral,neutral,neutral
952375529,"Hey @pculliton! Actually, as far as I remember, this is the desired behaviour (as far as I remember). Correct me if I'm wrong @iamtrask @madhavajay, but by default we want to delete after get (there is a flag that allows you to keep the object in store after get).",hey actually far remember desired behaviour far remember correct wrong default want delete get flag keep object store get,issue,negative,negative,neutral,neutral,negative,negative
952331177,Commit history indicates this PR is functional and could be merged with the right approvals. I've also addressed the flake and mypyp errors.,commit history functional could right also flake,issue,negative,positive,positive,positive,positive,positive
952051997,Heads up - if the tests pass I'd like to merge this large PR because it has some fixes which are affecting a separate PR I'm working on. Performance still needs to improve and I understand we don't yet have an integration test for now because it would make CI prohibitively slow. ,pas like merge large affecting separate working performance still need improve understand yet integration test would make prohibitively slow,issue,positive,negative,neutral,neutral,negative,negative
951407946,@IshanMi can you double check the merge with `dev` didn't kill any code and fix the Linting issues so we can get this badboy merged.,double check merge dev kill code fix get,issue,negative,neutral,neutral,neutral,neutral,neutral
951027700,Merged - let's keep notebook edits coming though! (in additional incremental PRs.) Smaller the PR the better.,let keep notebook coming though additional incremental smaller better,issue,negative,positive,positive,positive,positive,positive
950550866,This pull request has been linked to [Shortcut Story #1545: [Back-End] - Adjust permissions so a Data Scientist (or any user?) can update their own information](https://app.shortcut.com/openmined/story/1545/backend-adjust-permissions-so-a-data-scientist-or-any-user-can-update-their-own-information).,pull request linked story adjust data scientist user update information,issue,negative,neutral,neutral,neutral,neutral,neutral
950527030," The update asset functionality for assets is not implemented and has been skipped. This is because the process of updating the value of an asset is similar to adding the asset, therefore, it's better for the user to delete the asset and then add a new one.",update asset functionality asset process value asset similar asset therefore better user delete asset add new one,issue,positive,positive,positive,positive,positive,positive
949917357,@pculliton I don't think that's required as the datasets used are already part of the dev branch. @iamtrask I think we're good to merge these notebooks.,think used already part dev branch think good merge,issue,negative,positive,positive,positive,positive,positive
949874175,"Do we need to remove references to the national datasets used for demos? (e.g. the mock notebooks contain views of trade info, etc.) Do we want information about those shared?",need remove national used demo mock contain trade want information,issue,negative,neutral,neutral,neutral,neutral,neutral
948876517,Can we merge this? Seems like merging notebook changes into dev directly is a low-risk move and makes it even easier for a wider group of folks to be seeing/testing them on the regular.,merge like notebook dev directly move even easier group regular,issue,positive,positive,neutral,neutral,positive,positive
944906062,@rasswanth-s I will close this since we decided to keep the `SMPCExecutor` since the `celeryworker` gives us that nice property to  retry with round-robin,close since decided keep since u nice property retry,issue,negative,positive,positive,positive,positive,positive
943130718,Will revisit later after `0.6.0` alpha release,revisit later alpha release,issue,negative,neutral,neutral,neutral,neutral,neutral
940887706,@gmuraru  Could we  revisit the PR later and close it now for `0.6` release? ,could revisit later close release,issue,negative,neutral,neutral,neutral,neutral,neutral
940693011,"We can revisit this when it comes back up, for now to focus on the `0.6.0 alpha` I will close this.",revisit come back focus alpha close,issue,negative,neutral,neutral,neutral,neutral,neutral
940690303,"I think this needs to be cherry picked anyway, but we can revisit this when it comes back up, for now to focus on the `0.6.0 alpha` I will close this.",think need cherry picked anyway revisit come back focus alpha close,issue,negative,neutral,neutral,neutral,neutral,neutral
939861612,"Sadly, this didn't seem to fix the issue, but I did fix the broken tests due to the tailscale log output changing.",sadly seem fix issue fix broken due log output,issue,negative,negative,negative,negative,negative,negative
939487970,"Hi @IshanMi @pculliton!

Here is the proposal of how I would extend the notebook for deploying the node to make it easier to follow by the course students.

Please let me know what you think - if this is what we want and if we should do it for other ones next too.

Thank you!",hi proposal would extend notebook node make easier follow course please let know think want next thank,issue,positive,neutral,neutral,neutral,neutral,neutral
939447615,"I am getting this error please help me thanks "" module syft has no attribute 'TorchHook'.
I am creating virtual environment with conda and then install this but again error. Please help me ",getting error please help thanks module attribute virtual environment install error please help,issue,positive,positive,positive,positive,positive,positive
938898619,"Hi @madhavajay. I am interested on working on that. I have one question. In the description you say: 

> We are now only supporting Linux

However, once of the acceptance criteria is: Testing all three platforms against 1 version of Python and Torch. It seems a bit contradictory to me. Can I remove the testing on windows and mac for the PR tests? Or we should leave them?

Thanks!",hi interested working one question description say supporting however acceptance criterion testing three version python torch bit contradictory remove testing mac leave thanks,issue,positive,positive,positive,positive,positive,positive
937995419,"Hi, I am facing same error  `bytes is not a 16-char string` in `return deserialize(pb)` line of `get_model(...)` function. Has anyone been able to solve it?",hi facing error string return line function anyone able solve,issue,negative,positive,positive,positive,positive,positive
934513728,This pull request has been linked to [Shortcut Story #340: SMPC: Users should be able to multiplication on MPCTensors](https://app.shortcut.com/openmined/story/340/smpc-users-should-be-able-to-multiplication-on-mpctensors).,pull request linked story able multiplication,issue,negative,positive,positive,positive,positive,positive
931578557,"> @IshanMi - May I leave it to you to resolve conflicts on this one? If it's still here after a day or two I'll be able to get to it.

Resolved! The conflicts weren't major :+1:",may leave resolve one still day two able get resolved major,issue,negative,positive,positive,positive,positive,positive
931571654,@IshanMi - May I leave it to you to resolve conflicts on this one? If it's still here after a day or two I'll be able to get to it.,may leave resolve one still day two able get,issue,negative,positive,positive,positive,positive,positive
931571038,This flapping has been very persnickety. Great work! I know this was non-trivial to find.,persnickety great work know find,issue,positive,positive,positive,positive,positive,positive
930111102,"> Q: Could you also open a Good First Issue regarding typing the information from different files? like we have a lot of `Any` and we should fix that

Great reviewing @gmuraru!",could also open good first issue regarding information different like lot fix great,issue,positive,positive,positive,positive,positive,positive
929927918,Q: Could you also open a Good First Issue regarding typing the information from different files? like we have a lot of `Any` and we should fix that,could also open good first issue regarding information different like lot fix,issue,positive,positive,positive,positive,positive,positive
929862526,"hi , I am getting same error . tried with different python versions and os.
`ImportError: cannot import name 'run' from 'syft.grid.example_nodes.network' (....\anaconda3\envs\syft\lib\site-packages\syft\grid\example_nodes\network.py)   `",hi getting error tried different python o import name,issue,negative,neutral,neutral,neutral,neutral,neutral
929380417,"I have one follow up question to this
There is a major change in PySyft 0.5.0 (current stable version) compared to 0.2.x series. So where I can understand about the changes done to PySyft modules?
Can I still use  PySyft 0.2.x for my coding or should I make a shift to 0.5.0?
What is the replacement for syft.frameworks module in 0.5.0?
It is quite confusing to understand the changes that has happened from 0.2.x series to 0.5.0. If any documentation is available to understand these changes then kindly help.",one follow question major change current stable version series understand done still use make shift replacement module quite understand series documentation available understand kindly help,issue,positive,positive,positive,positive,positive,positive
927645270,"No george, after the pointer bug, this would work george,",pointer bug would work,issue,negative,neutral,neutral,neutral,neutral,neutral
925524781,"I have also tried this, same error am i getting.",also tried error getting,issue,negative,neutral,neutral,neutral,neutral,neutral
924711549,This pull request has been linked to [Shortcut Story #2508: Basic Network and Domain VPN](https://app.shortcut.com/openmined/story/2508/basic-network-and-domain-vpn).,pull request linked story basic network domain,issue,negative,neutral,neutral,neutral,neutral,neutral
924609941,This pull request has been linked to [Shortcut Story #3013: SMPC: Generation of Beaver Triples](https://app.shortcut.com/openmined/story/3013/smpc-generation-of-beaver-triples).,pull request linked story generation beaver,issue,negative,neutral,neutral,neutral,neutral,neutral
924492518,Sounds good - just be sure to add it to the spreadsheet somehow so we don't forget it.,good sure add somehow forget,issue,positive,positive,positive,positive,positive,positive
924471546,"@iamtrask ,since we had the reconstruct issue, we have to create test with ``pytest.mark.xfail``, I thought that maybe we could do it after fixing,I could also do now .Shall we do after fixing or we will add now itself?",since reconstruct issue create test thought maybe could fixing could also fixing add,issue,negative,neutral,neutral,neutral,neutral,neutral
924443594,Can we get an integration test for this before we merge? Perhaps including the functionality from the notebook included in the PR?,get integration test merge perhaps functionality notebook included,issue,negative,neutral,neutral,neutral,neutral,neutral
924148550,Closing the PR as checkout is an essential file for file changes notification.,essential file file notification,issue,negative,neutral,neutral,neutral,neutral,neutral
923498051,"@rasswanth-s Awesome work, if you can revert the package install for the security check step then we can merge! :)",awesome work revert package install security check step merge,issue,positive,positive,positive,positive,positive,positive
922908674,"Hi Bolu, below is the screenshots for different scenario i tried.

**Scenario 1**

Data Scientist(google colab)
Connection established but am unable to access data pointer after sending from data owner end(local machine). It keeps running ""duet.store.pandas"".
![image](https://user-images.githubusercontent.com/43243814/134004324-d213d573-1315-4c51-a267-9f3f6cff6948.png)



**Scenario 2**

Dataowner(local machine)
![image](https://user-images.githubusercontent.com/43243814/134006524-ef42939a-2a63-4b27-bced-62fbdd7f8699.png)

Data Scientist(google colab)
![image](https://user-images.githubusercontent.com/43243814/134005303-0a70d8ca-ef5b-4632-b0c3-28d5730cd21d.png)



**Scenerio 3**

Dataowner(local machine)
![image](https://user-images.githubusercontent.com/43243814/134005838-802a4eba-3dae-4e7c-a03a-16636a783a1f.png)

Data Scientist(google colab)
![image](https://user-images.githubusercontent.com/43243814/134005885-180e0cf0-fd82-4824-ab53-06665454638c.png)

",hi different scenario tried scenario data scientist connection established unable access data pointer sending data owner end local machine running image scenario local machine image data scientist image local machine image data scientist image,issue,negative,negative,neutral,neutral,negative,negative
922720480,This pull request has been linked to [Shortcut Story #3056: SMPC - Numpy Ops(Week 1)](https://app.shortcut.com/openmined/story/3056/smpc-numpy-opsweek-1).,pull request linked story week,issue,negative,neutral,neutral,neutral,neutral,neutral
922244730,"Hi there @Pem14604 i guess this is an event loop issue, did you add loopback=True argument when creating your duet object ? In context
```duet = sy.join_duet(loopback=True)``` 


Also adding a screenshot would go a long way ",hi guess event loop issue add argument duet object context duet also would go long way,issue,negative,negative,neutral,neutral,negative,negative
920960186,Then current stable release is 0.5.0 and the private AI series on  https://courses.openmined.com uses this version to implement the course,current stable release private ai series version implement course,issue,negative,neutral,neutral,neutral,neutral,neutral
920913686,"Thank you for your answer @Boluwatifeh ! 
Are there any similar tutorials for the latest stable version (if I am not mistaken it's 0.5.x)?",thank answer similar latest stable version mistaken,issue,negative,positive,positive,positive,positive,positive
920910861,"hi there @iliasbibas the screenshot you added above is specific to the pysyft 0.2.x version on the branch Pysyft/syft_0.2.x branch which can be found [here](https://github.com/OpenMined/PySyft/tree/PySyft/syft_0.2.x/examples/tutorials). 

those tutorials on the openmined blog are mostly based on the syft 0.2.x version which can be found in the link i shared. I hope this answers your question",hi added specific version branch branch found mostly based version found link hope question,issue,negative,positive,positive,positive,positive,positive
920506235,"Added a hot fix to disable pydp in CI to fix broken CI.
https://github.com/OpenMined/PyDP/issues/393",added hot fix disable fix broken,issue,negative,negative,neutral,neutral,negative,negative
918105395,This pull request has been linked to [Clubhouse Story #2858: SMPC: Tensor pointers must abstract MPCTensor for arbitrary number of parties.](https://app.clubhouse.io/openmined/story/2858/smpc-tensor-pointers-must-abstract-mpctensor-for-arbitrary-number-of-parties).,pull request linked clubhouse story tensor must abstract arbitrary number,issue,negative,negative,neutral,neutral,negative,negative
916776678,This pull request has been linked to [Clubhouse Story #1842: [Engineering] - DO configures domain](https://app.clubhouse.io/openmined/story/1842/engineering-do-configures-domain).,pull request linked clubhouse story engineering domain,issue,negative,neutral,neutral,neutral,neutral,neutral
916232713,Well done @rasswanth-s! You made fast work of that! ,well done made fast work,issue,negative,positive,positive,positive,positive,positive
915400818,This pull request has been linked to [Clubhouse Story #2824: SMPC: Hook Numpy Methods.](https://app.clubhouse.io/openmined/story/2824/smpc-hook-numpy-methods).,pull request linked clubhouse story hook,issue,negative,neutral,neutral,neutral,neutral,neutral
913844708,@avinsit123  could you please share me the link for syft updated documentation?,could please share link documentation,issue,positive,neutral,neutral,neutral,neutral,neutral
913820414,This pull request has been linked to [Clubhouse Story #971: [PyGrid UI] Fork Domain and Network UI](https://app.clubhouse.io/openmined/story/971/pygrid-ui-fork-domain-and-network-ui).,pull request linked clubhouse story fork domain network,issue,negative,neutral,neutral,neutral,neutral,neutral
913418852,Integration test is broken in `dev`.,integration test broken dev,issue,negative,negative,negative,negative,negative,negative
913078969,"Yes @gmuraru , I am not sure completely , why it is not working , I will take a additional look into it.",yes sure completely working take additional look,issue,positive,positive,positive,positive,positive,positive
913060212,Merging as failing test is not a regression - merely inheriting the fail from dev.,failing test regression merely fail dev,issue,negative,negative,negative,negative,negative,negative
913054340,"What is the issue with doing `get`, @rasswanth-s ?
The idea from using `get` here was to fetch the shares locally and then to add them.
If the process of `fetching` the shares would  fail (because maybe one of the parties did not approve the request for `get`) - then we will `resend` the shares we fetch until that point.",issue get idea get fetch locally add process fetching would fail maybe one approve request get resend fetch point,issue,negative,negative,negative,negative,negative,negative
913042848,Yeah it strikes me these would get stuck in the store forever. We need to do .get() instead but handle when subsets fail.,yeah would get stuck store forever need instead handle fail,issue,negative,negative,negative,negative,negative,negative
913042784,Ah the issue in this one is fixed in a different PR apparently?,ah issue one fixed different apparently,issue,negative,positive,neutral,neutral,positive,positive
913042712,I'm merging this now because even though one of hte integration tests fails I'm confident this is fixing more than it's breaking (at present the users page doesn't work),even though one integration confident fixing breaking present page work,issue,negative,positive,positive,positive,positive,positive
913042547,One of the Syft + Grid Stack Integration Tests are failing and it's non-obvious why. I don't think anything I changed should have affected it.,one grid stack integration failing think anything affected,issue,negative,neutral,neutral,neutral,neutral,neutral
912907347,"> Is it okay to do this? Will the objects be stuck in the store forever?
Yes @madhavajay ,that's a caveat, @iamtrask  and @gmuraru  suggested ideas like using blocking `get` until object appears, If we incorporate it , I think it would solve.
",stuck store forever yes caveat like blocking get object incorporate think would solve,issue,negative,neutral,neutral,neutral,neutral,neutral
912379923,"Closing this for now as it will require basing and multiple patches, but the work should stay in an open branch, as it is valuable.",require multiple work stay open branch valuable,issue,negative,neutral,neutral,neutral,neutral,neutral
912360781,"Dependabot tried to update this pull request, but something went wrong. We're looking into it, but in the meantime you can retry the update by commenting `@dependabot rebase`.",tried update pull request something went wrong looking retry update rebase,issue,negative,negative,negative,negative,negative,negative
912160150,False alarm - I just needed to clear out my docker volumes and rebuild.,false alarm clear docker rebuild,issue,negative,negative,negative,negative,negative,negative
912149485,"Not sure what's broken at present - current error when launching with hagrid:

```
 => [openmined/grid-backend:0.6.0-alpha.0 backend  8/10] COPY --from=build /root/.local /root/.local                                                             22.5s
 => ERROR [openmined/grid-backend:0.6.0-alpha.0 backend  9/10] COPY --from=build /usr/local/bin/waitforit /usr/local/bin/waitforit                                0.2s
------
 > [openmined/grid-backend:0.6.0-alpha.0 backend  9/10] COPY --from=build /usr/local/bin/waitforit /usr/local/bin/waitforit:
------
failed to solve: rpc error: code = Unknown desc = failed to add snapshot lilmhs3ftrssddu76ed3deggm to lease: input/output error
```",sure broken present current error copy error copy copy solve error code unknown add snapshot lease error,issue,negative,negative,neutral,neutral,negative,negative
912135053,Closing because I'm trying to sort out merge conflicts in another branch. See https://github.com/OpenMined/PySyft/pull/5949,trying sort merge another branch see,issue,negative,neutral,neutral,neutral,neutral,neutral
909086313,This pull request has been linked to [Clubhouse Story #1121: Get Users PR merged](https://app.clubhouse.io/openmined/story/1121/get-users-pr-merged).,pull request linked clubhouse story get,issue,negative,neutral,neutral,neutral,neutral,neutral
908332419,"This pull request has been linked to [Clubhouse Story #977: [PyGrid] (Alembic) Migration for ""budget""](https://app.clubhouse.io/openmined/story/977/pygrid-alembic-migration-for-budget).",pull request linked clubhouse story alembic migration budget,issue,negative,neutral,neutral,neutral,neutral,neutral
908296198,This pull request has been linked to [Clubhouse Story #897: Set up end-to-end tests in PyGrid UI](https://app.clubhouse.io/openmined/story/897/set-up-endtoend-tests-in-pygrid-ui).,pull request linked clubhouse story set,issue,negative,neutral,neutral,neutral,neutral,neutral
906753588,Since ADPTensor will sit on top of ShareTensor I don't think ShareTensor would have .publish() called on it. We do however need publish on MPCTensor.,since sit top think would however need publish,issue,negative,positive,positive,positive,positive,positive
903103395,"HI @IonesioJunior,
Were you able to find a solution to this issue?",hi able find solution issue,issue,negative,positive,positive,positive,positive,positive
901321183,Yep! I will assign both of you to the issue and you can sync on how to split the work :+1: ,yep assign issue sync split work,issue,negative,neutral,neutral,neutral,neutral,neutral
900504496,"I am having this same issue, but I am able to visit this url https://raw.githubusercontent.com/OpenMined/OpenGridNodes/master/network_address

If this issue has been resolved, please post the solution here as this is extremely frustrating..",issue able visit issue resolved please post solution extremely,issue,positive,positive,positive,positive,positive,positive
899369490,"Hello. Yes, I am trying to install PySyft on my Anaconda prompt. Tried the
link that you have mentioned. Got the following error:
ERROR: Cannot install syft[udacity]==0.2.3, syft[udacity]==0.2.4,
syft[udacity]==0.2.5, syft[udacity]==0.2.6, syft[udacity]==0.2.7,
syft[udacity]==0.2.8, syft[udacity]==0.2.9, syft[udacity]==0.3.0 and
syft[udacity]==0.5.0 because these package versions have conflicting
dependencies.

The conflict is caused by:
    syft[udacity] 0.5.0 depends on torchvision<=0.9.1 and >=0.5
    syft[udacity] 0.3.0 depends on torch>=1.5
    syft[udacity] 0.2.9 depends on torch~=1.4.0
    syft[udacity] 0.2.8 depends on torch~=1.4.0
    syft[udacity] 0.2.7 depends on torch~=1.4.0
    syft[udacity] 0.2.6 depends on torchvision~=0.5.0
    syft[udacity] 0.2.5 depends on torch~=1.4.0
    syft[udacity] 0.2.4 depends on torch~=1.4.0
    syft[udacity] 0.2.3 depends on torch~=1.4.0

To fix this you could try to:
1. loosen the range of package versions you've specified
2. remove package versions to allow pip attempt to solve the dependency
conflict

ERROR: ResolutionImpossible: for help visit
https://pip.pypa.io/en/latest/user_guide/#fixing-conflicting-dependencies

On Sat, Aug 14, 2021 at 4:21 PM Ogundeyi Boluwatife <
***@***.***> wrote:

> Hi there @anaghasimha <https://github.com/anaghasimha> are you trying to
> run tutorials from the private AI series? if yes, try following the guide
> here <https://github.com/OpenMined/pysyft/tree/syft_0.5.0> and if it's
> for pysyft 0.2.x you can reference this branch here
> <https://github.com/OpenMined/PySyft/tree/syft_0.2.x>
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/5909#issuecomment-898878678>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ATE2FYSWCDIM2BD3DUT3SM3T4ZDDLANCNFSM5CE5MVQQ>
> .
> Triage notifications on the go with GitHub Mobile for iOS
> <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>
> or Android
> <https://play.google.com/store/apps/details?id=com.github.android&utm_campaign=notification-email>
> .
>
",hello yes trying install anaconda prompt tried link got following error error install package conflicting conflict torch fix could try loosen range package remove package allow pip attempt solve dependency conflict error help visit sat wrote hi trying run private ai series yes try following guide reference branch reply directly view triage go mobile android,issue,negative,positive,neutral,neutral,positive,positive
899217114,"Hi @next-fernandocerezal I appreciate the PR however I am not able to replicate the issue.

```
$ git checkout syft_0.5.0
$ docker build -f docker/syft.Dockerfile --build-arg GPU=false -t openmined/syft:latest -t openmined/syft:`python VERSION` .
$ docker run -it openmined/syft /bin/bash
$ pip list | grep petlib
petlib                            0.0.45
```

Since this image and container are no longer being used in `dev` anyway my machine had to do a completely fresh uncached build, and there is no issue with installing petlib on the docker linux image.

In either case we won't be supporting this container and early versions of `0.6.0` are already in `dev`.",hi appreciate however able replicate issue git docker build latest python version docker run pip list since image container longer used dev anyway machine completely fresh build issue docker image either case wo supporting container early already dev,issue,positive,positive,positive,positive,positive,positive
898878678,"Hi there @anaghasimha are you trying to run tutorials from the private AI series? if yes, try following the guide [here](https://github.com/OpenMined/pysyft/tree/syft_0.5.0)  and if it's for pysyft 0.2.x you can reference this branch [here](https://github.com/OpenMined/PySyft/tree/syft_0.2.x)",hi trying run private ai series yes try following guide reference branch,issue,negative,neutral,neutral,neutral,neutral,neutral
895955758,He @tudorcebere I would like to work on this issue. May I know where these operations need to be added? I'm a bit new to PySyft but know PyTorch well.,would like work issue may know need added bit new know well,issue,positive,positive,positive,positive,positive,positive
894738130,This pull request has been linked to [Clubhouse Story #21: SMPC: Users should be able to perform basic operations on MPCTensors](https://app.clubhouse.io/openmined/story/21/smpc-users-should-be-able-to-perform-basic-operations-on-mpctensors).,pull request linked clubhouse story able perform basic,issue,negative,positive,positive,positive,positive,positive
894296255,"pip install git+https://github.com/OpenMined/PySyft@dev#egg=syft

ERROR: File ""setup.py"" not found for legacy project syft from git+https://github.com/OpenMined/PySyft@dev#egg=syft.",pip install error file found legacy project,issue,negative,neutral,neutral,neutral,neutral,neutral
893962167,"@arpitvaghela awesome work.

I think the only suggestion I can make is to change `skip_windows` to maybe just use the existing vendor requirements spec:

```
def vendor_requirements_available(vendor_requirements: TypeDict[str, TypeAny]) -> bool:
```
So for petlib you could change this:
```
LIB_NAME = ""petlib""
PACKAGE_SUPPORT = {
    ""lib"": LIB_NAME,
    ""python"": {""max_version"": (3, 9, 99)},
}
```

to this:
```
LIB_NAME = ""petlib""
PACKAGE_SUPPORT = {
    ""lib"": LIB_NAME,
    ""python"": {""max_version"": (3, 9, 99)},
    ""os"": [""macos"", ""linux""]
}
```

Then add some code which will check the os with something like sys.platform.
I believe windows reports windows and linux reports linux but mac will report `Darwin` so perhaps normalise this to macos. I would set them all to lowercase as well.",awesome work think suggestion make change maybe use vendor spec bool could change python python o add code check o something like believe mac report perhaps would set well,issue,positive,positive,positive,positive,positive,positive
893280390,I think it might haven gotten a bit out of date (assumption).  I probably I will have time this month to have a look again,think might gotten bit date assumption probably time month look,issue,negative,neutral,neutral,neutral,neutral,neutral
893265668,@sanggusti the dev branch got changed pretty heavily so I will close this PR and if you want to open a new one with any Windows bootstrapping work let me know.,dev branch got pretty heavily close want open new one work let know,issue,positive,positive,neutral,neutral,positive,positive
893263943,Closing as I think this was a clubhouse story place holder.,think clubhouse story place holder,issue,negative,neutral,neutral,neutral,neutral,neutral
893262887,@stoic-signs can you please push the changes we worked on together to this branch and fix any conflicts?,please push worked together branch fix,issue,negative,neutral,neutral,neutral,neutral,neutral
893262492,@jmaunon lets discuss this and look at getting stuff like this handled in the lint Github Action within the precommit file.,discus look getting stuff like handled lint action within precommit file,issue,negative,positive,neutral,neutral,positive,positive
893261688,@tudorcebere Let's come back to this once we have cloud credits.,let come back cloud,issue,negative,neutral,neutral,neutral,neutral,neutral
893261296,@koenvanderveen is this still relevant or should we close and tackle as part of the future Plan Usage Policy work?,still relevant close tackle part future plan usage policy work,issue,negative,positive,positive,positive,positive,positive
893259953,@stoic-signs Unfortunately the duet tests are currently disabled so we can't test this. If you can get the conflicts fixed I will re-run this when the tests are enabled again.,unfortunately duet currently disabled ca test get fixed,issue,negative,negative,negative,negative,negative,negative
893258797,@tudorcebere I definitely still want to see this PR. Lets discuss when you have cycles again.,definitely still want see discus,issue,negative,neutral,neutral,neutral,neutral,neutral
893257572,"@vsquareg any chance we can get this updated with the latest changes in `dev`.

",chance get latest dev,issue,negative,positive,positive,positive,positive,positive
893256484,Closing because this is stale. We will revisit this when we understand how we want to handle Plans in the `0.6.0` branch.,stale revisit understand want handle branch,issue,negative,negative,negative,negative,negative,negative
893255994,Closing as the old grid code has been removed.,old grid code removed,issue,negative,positive,neutral,neutral,positive,positive
893020799,This pull request has been linked to [Clubhouse Story #80: Add & edit user API](https://app.clubhouse.io/openmined/story/80/add-edit-user-api).,pull request linked clubhouse story add edit user,issue,negative,neutral,neutral,neutral,neutral,neutral
892647054,Sorted out the last few linting issues and merge conflicts hre https://github.com/OpenMined/PySyft/pull/5875 and merged in its current state,sorted last merge current state,issue,negative,neutral,neutral,neutral,neutral,neutral
891096129,"Hi, 
I've got the same problem. Did anybody manage to solve this ?",hi got problem anybody manage solve,issue,negative,neutral,neutral,neutral,neutral,neutral
890839744,"George , there are some error logs at notebook examples(after updation), could you resolve it before merge ",error notebook could resolve merge,issue,negative,neutral,neutral,neutral,neutral,neutral
890316445,This pull request has been linked to [Clubhouse Story #292: Flynt](https://app.clubhouse.io/openmined/story/292/flynt).,pull request linked clubhouse story,issue,negative,neutral,neutral,neutral,neutral,neutral
889830312,This pull request has been linked to [Clubhouse Story #588: Duet ADP Demo works on PyGrid](https://app.clubhouse.io/openmined/story/588/duet-adp-demo-works-on-pygrid).,pull request linked clubhouse story duet work,issue,negative,neutral,neutral,neutral,neutral,neutral
888682248,"> @gmuraru Awesome work. I have read the code, made a few small lint fixes and comments above. As soon as CI is passing we can do a final review and approve.

Some of the stuff -- like the ```smpc_action``` generator should be done better --- but I want to get in something and continue from there.

I pushed some tests - it seems the VMs tests pass",awesome work read code made small lint soon passing final review approve stuff like generator done better want get something continue pas,issue,positive,positive,positive,positive,positive,positive
887984903,"@gmuraru Awesome work. I have read the code, made a few small lint fixes and comments above. As soon as CI is passing we can do a final review and approve. ",awesome work read code made small lint soon passing final review approve,issue,positive,positive,positive,positive,positive,positive
887979626,"@gmuraru Lint checks and tests have now been enabled. I see this test is failing:
```
# tests/syft/core/tensor/autodp/single_entity_phi_test.py
E       AttributeError: 'Tensor' object has no attribute 'private'
```

I also see that the PR disabled this property in the ast but I don't know if that was intentional, should we then remove or modify these tests?",lint see test failing object attribute also see disabled property ast know intentional remove modify,issue,negative,negative,negative,negative,negative,negative
887945641,I tested and updated the previous PR which fixes the use of tox on linux.,tested previous use tox,issue,negative,negative,negative,negative,negative,negative
887944994,"Great work! I will close this and merge this other PR where I made some fixes here: https://github.com/OpenMined/PySyft/pull/5846

I was unable to merge in the existing `demo_strike_team_branch_4` and push back to your PR because the branch name wasn't unique. In future don't forget to create a branch when you make a change.",great work close merge made unable merge push back branch name unique future forget create branch make change,issue,positive,positive,positive,positive,positive,positive
887939928,"This PR just gets the linting and tests to work and pass again, and removes a bunch of old `pytorch` examples which are just flagging up false positives in snyk and linting tools.",work pas bunch old flagging false,issue,negative,negative,negative,negative,negative,negative
886475402,Hey @madhavajay ! Yes let's close this pr and delete the branch ,hey yes let close delete branch,issue,negative,neutral,neutral,neutral,neutral,neutral
886342764,"@willclarktech I am just trying to fix the CI issues but I can't push to your PR so I have created a new one here:
https://github.com/OpenMined/PySyft/pull/5610

In future, if you leave the checkmark when you create the PR, then we can push directly to the PR.
<img width=""413"" alt=""Screen Shot 2021-07-26 at 1 21 48 pm"" src=""https://user-images.githubusercontent.com/2882739/126928801-ca5ac52c-a8de-454d-bb64-9312169fdca8.png"">
",trying fix ca push new one future leave create push directly screen shot,issue,negative,positive,neutral,neutral,positive,positive
886300635,"False positive, but these external examples will be removed in this PR: https://github.com/OpenMined/PySyft/pull/5835/files",false positive external removed,issue,positive,negative,neutral,neutral,negative,negative
886294137,"Hi @victorperezc I guess this is for the old grid, so maybe we should close this since the `demo_strike_team_branch_4` changes the grid code?",hi guess old grid maybe close since grid code,issue,negative,positive,neutral,neutral,positive,positive
886293798,"Thanks, this was a great idea, but I have started putting the datasets in a github repo so they are easy to manage but quick to install on CI. I think the cache action has a limit to how much we can cache and we sometimes go over the limit so perhaps we should keep datasets separate. I will close this for now and we can revisit it later if we need it.",thanks great idea easy manage quick install think cache action limit much cache sometimes go limit perhaps keep separate close revisit later need,issue,positive,positive,positive,positive,positive,positive
885240484,This pull request has been linked to [Clubhouse Story #19: Part 1: Setup Experiment and Load Data](https://app.clubhouse.io/openmined/story/19/part-1-setup-experiment-and-load-data).,pull request linked clubhouse story part setup experiment load data,issue,negative,neutral,neutral,neutral,neutral,neutral
885239762,This pull request has been linked to [Clubhouse Story #93: Part 3: Select and ETL data into proper format](https://app.clubhouse.io/openmined/story/93/part-3-select-and-etl-data-into-proper-format).,pull request linked clubhouse story part select data proper format,issue,negative,neutral,neutral,neutral,neutral,neutral
884706512,This pull request has been linked to [Clubhouse Story #488: implement initial hagrid grammer system](https://app.clubhouse.io/openmined/story/488/implement-initial-hagrid-grammer-system).,pull request linked clubhouse story implement initial system,issue,negative,neutral,neutral,neutral,neutral,neutral
884575565,This pull request has been linked to [Clubhouse Story #167: Store DP Tensor in object-store](https://app.clubhouse.io/openmined/story/167/store-dp-tensor-in-objectstore).,pull request linked clubhouse story store tensor,issue,negative,neutral,neutral,neutral,neutral,neutral
883723281,This pull request has been linked to [Clubhouse Story #92: Part 2: Search for relevant data across a network](https://app.clubhouse.io/openmined/story/92/part-2-search-for-relevant-data-across-a-network).,pull request linked clubhouse story part search relevant data across network,issue,negative,positive,positive,positive,positive,positive
883351655,This pull request has been linked to [Clubhouse Story #290: Flake8](https://app.clubhouse.io/openmined/story/290/flake8).,pull request linked clubhouse story flake,issue,negative,neutral,neutral,neutral,neutral,neutral
883292612,This pull request has been linked to [Clubhouse Story #65: pip install hagrid (and it's deps automagically)](https://app.clubhouse.io/openmined/story/65/pip-install-hagrid-and-its-deps-automagically).,pull request linked clubhouse story pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
883150430,"Yeah, I'll remove the comments and make another commit. Then I'll remove WIP",yeah remove make another commit remove,issue,positive,neutral,neutral,neutral,neutral,neutral
882603775,"@iamtrask got it. 
Then I think I will first take up issue #5780 to get familiarize myself with the basic structure and if meanwhile the issue still remains unassigned, I will try to take up the issue. ",got think first take issue get familiarize basic structure meanwhile issue still remains unassigned try take issue,issue,negative,positive,positive,positive,positive,positive
882598330,"HI @divyanshsinghvi - i'm afraid that I shouldn't have marked this one as a good first issue. Per your comment, I don't have clear instructions on how we should make the binary smaller and would need someone to dig in and help the team figure that out. :) That said, if the project is still interesting to you given that additional challenge, let us know!",hi afraid marked one good first issue per comment clear make binary smaller would need someone dig help team figure said project still interesting given additional challenge let u know,issue,positive,positive,positive,positive,positive,positive
882514889,This pull request has been linked to [Clubhouse Story #274: some story regarding hagrid](https://app.clubhouse.io/openmined/story/274/some-story-regarding-hagrid).,pull request linked clubhouse story story regarding,issue,negative,neutral,neutral,neutral,neutral,neutral
881884993,"Hi @iamtrask , 
I was interested to solve this `good first issue`. How should I go about reducing the size of the binary? If you could point me where I should begin with that would be indeed helpful. 
Also, while sending the pull request do I have to merge changes from the branch `demo_strike_team_branch_4` to the hagrid tool? 
",hi interested solve good first issue go reducing size binary could point begin would indeed helpful also sending pull request merge branch tool,issue,positive,positive,positive,positive,positive,positive
880763098,"The issue `BrokenPipeError: [Errno 32] Broken pipe` comes from the fact that the notebook mcfl_create_plan does not completely describe the initialisation required for the grid (the Step 4.1 section in the notebook).

What is currently worked for me (version 0.5.0) is: 
- use PyGrid from PySyft repo (at https://github.com/OpenMined/PySyft/tree/dev/packages/grid/apps/domain) 
- start using: ""APP_ENV=dev LOCAL_DATABASE=True PORT=7000 ./run.sh""
- invoke once the code below (to setup the domain, inspired from https://github.com/OpenMined/PySyft/blob/dev/packages/syft/examples/pygrid/tutorials/Getting%20Started.ipynb)
- if you want to run completely mcfl_create_plan check also https://github.com/OpenMined/PySyft/pull/5520 there are some fixes there that are not yet merged

```
from syft.grid.client.client import connect
from syft.grid.client.grid_connection import (GridHTTPConnection,) 
domain = connect(
    url=""http://localhost:7000"", 
    conn_type=GridHTTPConnection,
)

domain.setup(
    email=""owner@openmined.org"",
    password=""owerpwd"",
    domain_name=""OpenMined Node"",
    token=""9G9MJ06OQH"",
)
```",issue broken pipe come fact notebook completely describe grid step section notebook currently worked version use start invoke code setup domain inspired want run completely check also yet import connect import domain connect owner node,issue,negative,negative,neutral,neutral,negative,negative
880753225,Please reopen as this is not yet fixed in 0.5.0 (latest release) or dev branch. The changes in #5520 still work if applied manually but currently that branch can't be merged to dev due to conflicts.,please reopen yet fixed latest release dev branch still work applied manually currently branch ca dev due,issue,negative,positive,positive,positive,positive,positive
880660251,This pull request has been linked to [Clubhouse Story #178: Accountant allows downloads of published data](https://app.clubhouse.io/openmined/story/178/accountant-allows-downloads-of-published-data).,pull request linked clubhouse story accountant data,issue,negative,neutral,neutral,neutral,neutral,neutral
880254628,This pull request has been linked to [Clubhouse Story #135: sample story](https://app.clubhouse.io/openmined/story/135/sample-story).,pull request linked clubhouse story sample story,issue,negative,neutral,neutral,neutral,neutral,neutral
880216852,"This pull request has been linked to:

- [Clubhouse Story #65: pip install hagrid (and it's deps automagically)](https://app.clubhouse.io/openmined/story/65/pip-install-hagrid-and-its-deps-automagically)
- [Clubhouse Story #67: hagrid create and destroy local vm](https://app.clubhouse.io/openmined/story/67/hagrid-create-and-destroy-local-vm)
",pull request linked clubhouse story pip install clubhouse story create destroy local,issue,negative,negative,neutral,neutral,negative,negative
880184475,"This pull request has been linked to:

- [Clubhouse Story #65: pip install hagrid (and it's deps automagically)](https://app.clubhouse.io/openmined/story/65/pip-install-hagrid-and-its-deps-automagically)
- [Clubhouse Story #108: hagrid create and terminate VMs on AWS/Azure/GCP](https://app.clubhouse.io/openmined/story/108/hagrid-create-and-terminate-vms-on-awsazuregcp)
",pull request linked clubhouse story pip install clubhouse story create terminate,issue,negative,neutral,neutral,neutral,neutral,neutral
878624917,"I close this issue, `PyGrid` is under a refactorization and seems this funcionality will be included by default",close issue included default,issue,negative,neutral,neutral,neutral,neutral,neutral
877841073,I've updated the link but it may take a few hours to propagate - for now use this: https://communityinviter.com/apps/openmined/openmined,link may take propagate use,issue,negative,neutral,neutral,neutral,neutral,neutral
877648847,"@tcp Same issue, yes. I just tried it on Android and it says that something went wrong. I'm using a gmail.com address. ",issue yes tried android something went wrong address,issue,negative,negative,negative,negative,negative,negative
877614552,"Hi @ngagesmu! That is very strange. What link in particular is requiring that?

All Slack links appear to be working — slack.openmined.org

Are you having the same issue @ganzuul?",hi strange link particular slack link appear working issue,issue,negative,positive,neutral,neutral,positive,positive
877561962,"> The link seems to be fixed on the main website as of now.

Unfortunately, you need a @canada.ca email address to sign up. So, the links are still broken.",link fixed main unfortunately need address sign link still broken,issue,negative,negative,negative,negative,negative,negative
876159919,"@rasswanth-s any suggestion on how to go ahead with the MPC examples? I still seem to be stuck with an Unknown private exception when I try basic operations (sum, subtract, multiply) on tensors.
![image](https://user-images.githubusercontent.com/30037676/124871533-c7f09300-dfe1-11eb-91f7-451d5b9779b1.png)
",suggestion go ahead still seem stuck unknown private exception try basic sum subtract multiply image,issue,negative,negative,neutral,neutral,negative,negative
874801360,"Hello @gkaissis, glad to see you! :smiley: 

Initially, the idea of ​​returning rest codes in PyGrid messages was something in our development plan. Over time, due to planning changes and the possibility of the Syft library working with different protocols, this lost some of its semantic meaning. Currently, `status_code=200` is returned by default on all messages (unless an internal error has occurred) just to not break things.

We intend to remove this field in the next versions in order to delegate the responsibility to the frameworks of an external layer (without creating a dependency between the Syft library and the communication protocol used).

In the future, services will be developed following [this pattern](https://github.com/OpenMined/PySyft/blob/785fd8a29e6f8db20ac7b3b159b5842b4c1a8509/packages/syft/src/syft/core/node/common/node_service/dataset_manager/dataset_manager_service.py#L95)

In case of an HTTP request, the code returned will be managed by an external layer, responsible exclusively for handling messages using this protocol.

My apologies for the mistake created.",hello glad see initially idea rest something development plan time due possibility library working different lost semantic meaning currently returned default unless internal error break intend remove field next order delegate responsibility external layer without dependency library communication protocol used future following pattern case request code returned external layer responsible exclusively handling protocol mistake,issue,negative,positive,neutral,neutral,positive,positive
874751085,"The same behavior happens for `create` and `update` routes.

I can have a go.

@IonesioJunior",behavior create update go,issue,negative,neutral,neutral,neutral,neutral,neutral
873420225,I would like to discuss bioethics for a project proposal involving PySyft. I hope this open issue can get some attention.,would like discus project proposal hope open issue get attention,issue,positive,neutral,neutral,neutral,neutral,neutral
872028740,"Hi @saichandrapandraju , I use docker image for pygrid, using pysyft 0.5.0, open port + create firewall rules for the port (7000) and it works without error. ",hi use docker image open port create port work without error,issue,positive,neutral,neutral,neutral,neutral,neutral
872020012,"Hi @intrivil ,
Were you able to resolve this error? I'm facing same problem.",hi able resolve error facing problem,issue,negative,positive,positive,positive,positive,positive
871909020,"We are still following an allowlist policy, but since we are planning on moving the lib support out, we are added a denylist in syft itself that looks into allowlist of libs (which may or may not be created by us) and deny methods that may cause issues.",still following policy since moving support added may may u deny may cause,issue,negative,neutral,neutral,neutral,neutral,neutral
871776680,"Would love to learn more about the decision to enforce a policy using a denylist instead of (or perhap sin addition to) an allowlist. For example, if numpy introduced a new method ""read_json_v2"" and we didn't notice, would that create a vulnerability by which someone could access the file system?",would love learn decision enforce policy instead sin addition example new method notice would create vulnerability someone could access file system,issue,negative,positive,positive,positive,positive,positive
871622871,"Hi @madhavajay I am the creator of Cirun.io, ""GPU support"" and ""CI Runner on AWS"" caught my eye.

FWIW I'll share my two cents. I created a service for problems like these, which is basically running custom machines (including GPUs) in GitHub Actions: https://cirun.io/

It is used in multiple open source projects needing GPU support like the following:

- https://github.com/pystatgen/sgkit/
- https://github.com/qutip/qutip-cupy

It is fairly simple to setup, all you need is a cloud account (AWS or GCP) and a simple yaml file describing what kind of machines you need and Cirun will spin up ephemeral machines on your cloud for GitHub Actions to run. It's native to GitHub ecosystem, which mean you can see logs/trigger in the Github's interface itself, just like any Github Action run.

Also, note that Cirun is free for Open source projects. (You only pay to your cloud provider for machine usage)",hi creator support runner caught eye share two service like basically running custom used multiple open source needing support like following fairly simple setup need cloud account simple file kind need spin ephemeral cloud run native ecosystem mean see interface like action run also note free open source pay cloud provider machine usage,issue,positive,positive,neutral,neutral,positive,positive
871280266,"This works for the connect part only,
```
from syft.grid.client.client import connect  # Method used to connect with the node.
from syft.grid.client.grid_connection import GridHTTPConnection

domain = connect(
     url=""http://localhost:5000"",  # Domain Address
     conn_type=GridHTTPConnection,
 )  # HTTP Connection Protocol
 print(domain)
```
Result:
<GridClient: <UID: 66bc7c48b36044e285a3448d43fcff20>>
Process finished with exit code 0

===============================================================================================

However, old code does result in a 404 Handshake Error, which does not seem right as said and relates to not finding the server of the app in the server. 
```
grid_address = ""localhost:5000""
grid = ModelCentricFLClient(address=grid_address, secure=False)
grid.connect()
```
Result:
```
Traceback (most recent call last):
  File ""/home/algarecu/Documents/github/PySyft/packages/syft/examples/federated-learning/model-centric/mcfl_create_plan_mobile.py"", line 285, in <module>
    grid.connect()
  File ""/home/algarecu/anaconda3/envs/pysyft/lib/python3.9/site-packages/syft/federated/model_centric_fl_base.py"", line 52, in connect
    self.ws = websocket.create_connection(**args_)
  File ""/home/algarecu/anaconda3/envs/pysyft/lib/python3.9/site-packages/websocket/_core.py"", line 595, in create_connection
    websock.connect(url, **options)
  File ""/home/algarecu/anaconda3/envs/pysyft/lib/python3.9/site-packages/websocket/_core.py"", line 252, in connect
    self.handshake_response = handshake(self.sock, *addrs, **options)
  File ""/home/algarecu/anaconda3/envs/pysyft/lib/python3.9/site-packages/websocket/_handshake.py"", line 59, in handshake
    status, resp = _get_resp_headers(sock)
  File ""/home/algarecu/anaconda3/envs/pysyft/lib/python3.9/site-packages/websocket/_handshake.py"", line 145, in _get_resp_headers
    raise WebSocketBadStatusException(""Handshake status %d %s"", status, status_message, resp_headers)
websocket._exceptions.WebSocketBadStatusException: Handshake status 404 NOT FOUND

Process finished with exit code 1
```
===============================================================================================
Server itself runs in development mode as follows, as well as database which I see it is created using also the next command correctly.

```
./run.sh --name bob --port 5000 --start_local_db 'postgresql+psycopg2://postgres:@localhost:5432/localdb'
[2021-06-30 11:40:48]: 22009 INFO domain version: 0.5.0 in Dev is Ready
```
===============================================================================================

Does any of this ring any bells @madhavajay ?  I also want to try the same in the dockerized env rather than local, but these results make me think it is not a matter of local environment setup but a network problem with websockets or the pygrid api itself.",work connect part import connect method used connect node import domain connect domain address connection protocol print domain result process finished exit code however old code result handshake error seem right said finding server server grid result recent call last file line module file line connect file line file line connect handshake file line handshake status resp sock file line raise handshake status status handshake status found process finished exit code server development mode well see also next command correctly name bob port domain version dev ready ring also want try rather local make think matter local environment setup network problem,issue,negative,positive,neutral,neutral,positive,positive
871193294,"Already using package syft 0.5.0, however using branch `main` (e.g., as the file version seems equal there), which seemingly had integrated latest stable commits I see coming up yes. However, I still see not all integration tests were passed in that file I mention above over the branch `main`, yet it was committed 1 month ago approx. Will check back a conda deployment on 0.5.0 to see if anything changes but I suspect it won't if they model centric example contains any deprecated methods for hosting the training plan on a grid domain of pygrid as it gets stucked just at the end there.",already package however branch main file version equal seemingly latest stable see coming yes however still see integration file mention branch main yet month ago check back deployment see anything suspect wo model centric example hosting training plan grid domain end,issue,negative,positive,positive,positive,positive,positive
871045014,"@algarecu the MCFL tests are still passing in the `0.5.0` branch here: https://github.com/OpenMined/PySyft/blob/syft_0.5.0/packages/syft/tests/syft/core/fl/model-centric/mcfl_create_execute_plan_test.py

All code from `0.5.0` is public on PyPI, dockerhub and available in the `syft_0.5.0` branch.
The PyGrid repo is `deprecated` and the latest stable version is in the branch above.

`dev` is undergoing lots of changes at the moment so please use the above branch for `0.5.0` stability.",still passing branch code public available branch latest stable version branch dev undergoing lot moment please use branch stability,issue,positive,positive,positive,positive,positive,positive
870802970,Broken. New API changes have broken the ModelCentricFLClient in the FL examples of model centric and possibly others. Please advise or fix.,broken new broken model centric possibly please advise fix,issue,negative,negative,negative,negative,negative,negative
870222557,That's probably because I use an M1 mac. I close this issue because it's not an issue of pysyft.,probably use mac close issue issue,issue,negative,neutral,neutral,neutral,neutral,neutral
870100871,@tudorcebere can we update this with the mono repo and get it merged before there are too many new post `0.5.0` changes.,update mono get many new post,issue,negative,positive,positive,positive,positive,positive
869143621,Solved by installing `syft==0.5.0rc1` which I think uses a different version of PyTorch. I will leave this open because the recommended installation procedure does not work.,think different version leave open installation procedure work,issue,negative,neutral,neutral,neutral,neutral,neutral
869094397,"In forcing PySyft to serialize all objects it checks into the store, I've discovered a large number of objects which currently aren't serializable or wherein serialization is broken. I've marked the respective tests with the @pytest.mark.skip in most places (with some commenting out). In particular Iterator needs work as well as serialization for several syft.libs.",forcing serialize store discovered large number currently wherein serialization broken marked respective particular need work well serialization several,issue,negative,positive,neutral,neutral,positive,positive
869066842,@madhavajay and @tudorcebere - check out https://github.com/OpenMined/PySyft/pull/5735/commits/34dba1fbdb76698be78fb66a657f49e02493d1e0 The idea of the recursive serde class is that it can be subclassed and make it so that we don't have to create custom protobufs for all our custom classes as long as its attributes eventually are composed of simple types we do know how to serialize,check idea recursive class make create custom custom class long eventually composed simple know serialize,issue,negative,negative,neutral,neutral,negative,negative
869041166,@madhavajay at https://github.com/OpenMined/PySyft/pull/5735/commits/46fe370117c41ba495f520ee54cfbd122eaf8111 I couldn't figure out how to import sqlalchemy into tox correctly. Please help.,could figure import tox correctly please help,issue,positive,neutral,neutral,neutral,neutral,neutral
868902212,Not merging - going to redo this code and merge in smaller increments.,going redo code merge smaller,issue,negative,neutral,neutral,neutral,neutral,neutral
868389475,@tudorcebere Can KotlinSyft be used server side? Does it utilise the GPU to train?,used server side train,issue,negative,neutral,neutral,neutral,neutral,neutral
868321114,"Hey @AdrianGlauben!

Could you install the latest from the dev branch to see if you can replicate the error anymore? Thank you!",hey could install latest dev branch see replicate error thank,issue,negative,positive,positive,positive,positive,positive
868320236,"Hey @rhobro,

We are working on this, but I can't give you an estimated timeline or roadmap for performance improvement on pygrid.

In terms of rust, we don't know exactly how it's going to look like, but we would like at some point to have our networking backbone in it for our workers (swift, js, kotling, python, etc). Long road ahead tho, don't expect to see this too soon 😆 ",hey working ca give performance improvement rust know exactly going look like would like point backbone swift python long road ahead tho expect see soon,issue,positive,positive,neutral,neutral,positive,positive
867783362,"Duplicate to [Issue # 5671](https://github.com/OpenMined/PySyft/issues/5671).

However, here a quick summary of how I set it up. Note that it was all messy with an already existing virtual environment which had syft, torch and torchvision installed. So I started with a fresh virtual environment:

```
python -m venv fl05
. fl05/bin/activate
pip install git+https://github.com/OpenMined/SyMPC@main  # SyMPC
pip install syft==0.5.0rc2
```",duplicate issue however quick summary set note messy already virtual environment torch fresh virtual environment python pip install pip install,issue,negative,positive,positive,positive,positive,positive
867725098,"This is a dupe because im trying to get CI to work :(
",dupe trying get work,issue,negative,neutral,neutral,neutral,neutral,neutral
867695679,"Hey @daler3 !

Using the latest release of syft and python 3.9 with a fresh install I couldn't replicate this issue. Could you try again (if it still replicates, could you give me OS info)",hey daler latest release python fresh install could replicate issue could try still could give o,issue,negative,positive,positive,positive,positive,positive
867226563,"> The division works for the moment with a number of two parties (we are working towards adding support for more)

I uninstalled pysyft and sympc, then reinstalled. It shows the same error. From my test,  only the MPCTensor that are processed by neural network will become NoneType by division (which is weird). If I just simply divide an MPCTensor by a constant, it works well (I have checked that). So I think it is from the sy.Module or MPC version of the network that causes the issue.",division work moment number two working towards support uninstalled error test neural network become division weird simply divide constant work well checked think version network issue,issue,negative,negative,negative,negative,negative,negative
867221823,The division works for the moment with a number of two parties (we are working towards adding support for more),division work moment number two working towards support,issue,negative,neutral,neutral,neutral,neutral,neutral
866385582,"> @jmaunon status for this?

I have already fixed the conflicts. @tudorcebere , could you merge it?",status already fixed could merge,issue,negative,positive,neutral,neutral,positive,positive
866045336,"BTW, the new pysyft version does not support 3 parties, either.

When I do

<img width=""497"" alt=""image"" src=""https://user-images.githubusercontent.com/57201660/122945244-72ac5480-d346-11eb-9c3b-4d3d918f7098.png"">

I have 

<img width=""989"" alt=""image"" src=""https://user-images.githubusercontent.com/57201660/122945321-822b9d80-d346-11eb-87de-035ba7a30a32.png"">

When will the 3 or more parties' computation be supported?",new version support either image image computation,issue,negative,positive,positive,positive,positive,positive
866039817,"The latest version , supports division, @gmuraru  is it because of spdz issue with division(2 parties),?",latest version division issue division,issue,negative,positive,positive,positive,positive,positive
866033940,"I did, but the problem was not solved.

The error is:
<img width=""672"" alt=""image"" src=""https://user-images.githubusercontent.com/57201660/122942535-47c10100-d344-11eb-8a04-fd261aa6e041.png"">
because I did division in my code:
<img width=""563"" alt=""image"" src=""https://user-images.githubusercontent.com/57201660/122942648-5e675800-d344-11eb-83b7-6f05c093f985.png"">

If I remove the division, it has no error. So overall, even the latest version does not support division.
",problem error image division code image remove division error overall even latest version support division,issue,negative,positive,positive,positive,positive,positive
866014151,"> Yeah,I answered the issue for a similar error ,could you follow these issues #5701 and #5671

Not work for me. I run

pip uninstall syft
pip uninstall sympc

then run

pip install -e ""git+https://github.com/OpenMined/PySyft@dev#egg=syft&subdirectory=packages/syft""
pip install git+https://github.com/OpenMined/SyMPC@main

And it shows successful install but still when I run the code I got the same error.",yeah issue similar error could follow work run pip pip run pip install pip install successful install still run code got error,issue,negative,positive,positive,positive,positive,positive
865703067,"> @jmaunon status for this?

Hi @tudorcebere . Excuse me, I though you resolved the conflicts and was already merged.
Can you do it? (Or I can do it later)",status hi excuse though resolved already later,issue,negative,negative,neutral,neutral,negative,negative
865635724,"Closing this due to inactivity. Please open a new PR with the new monorepo structure/updates.

",due inactivity please open new new,issue,negative,positive,neutral,neutral,positive,positive
865634408,"Closing this due to inactivity. Please open a new PR with the updated solution.

",due inactivity please open new solution,issue,positive,positive,neutral,neutral,positive,positive
865631231,Closing this due to inactivity. We will make GPU testing a bit different soon.,due inactivity make testing bit different soon,issue,negative,negative,neutral,neutral,negative,negative
865630248,"Closing this due to inactivity. Please open a new PR with the new monorepo structure/updates. Thanks for the work, we will design a new implementation in the backlog.",due inactivity please open new new thanks work design new implementation backlog,issue,positive,positive,neutral,neutral,positive,positive
865488269,"Yeah,I answered the issue for a similar error ,could you follow these issues https://github.com/OpenMined/PySyft/issues/5701 and https://github.com/OpenMined/PySyft/issues/5671",yeah issue similar error could follow,issue,negative,neutral,neutral,neutral,neutral,neutral
865259811,"> Sorry ,I interchanged in pysyft we `dev` for SyMPC we use `main` , this would work `pip install git+https://github.com/OpenMined/SyMPC@main`

I got a totally different error. Before update I could at least run the code by not using dividing, now I can't even run the code.

<img width=""920"" alt=""image"" src=""https://user-images.githubusercontent.com/57201660/122811106-12fa6e80-d29e-11eb-939c-00ce0f17a742.png"">

I even ran the 'introduction.ipynb' on your SyMPC GitHub. It gave me the same error.
",sorry dev use main would work pip install got totally different error update could least run code dividing ca even run code image even ran gave error,issue,negative,negative,negative,negative,negative,negative
865034442,"root@ip-172-31-26-203:~# pip3 install syft==0.5.0rc2
ERROR: Could not find a version that satisfies the requirement syft==0.5.0rc2 (from versions: 0.1.0a1, 0.1.1a2, 0.1.2a1, 0.1.3a1, 0.1.4a1, 0.1.4a2, 0.1.5a1, 0.1.6a1, 0.1.7a1, 0.1.8a1, 0.1.9a1, 0.1.10a1, 0.1.10a2, 0.1.10a4, 0.1.11a1, 0.1.12a1, 0.1.13a1, 0.1.14a1, 0.1.15a1, 0.1.16a1, 0.1.19a1, 0.1.20a1, 0.1.21a1, 0.1.22a1, 0.1.23a1, 0.1.24a1, 0.1.25a1, 0.1.26a1, 0.1.27a1, 0.1.28a1, 0.1.29a1, 0.2.0a1, 0.2.0a2, 0.2.1a1, 0.2.2a1, 0.2.3a1, 0.2.3a2, 0.2.3a3, 0.2.3, 0.2.4, 0.2.5, 0.2.6, 0.2.7, 0.2.8, 0.2.9, 0.3.0, 0.5.0rc1)
ERROR: No matching distribution found for syft==0.5.0rc2


I tried with version ""0.5.0rc1"" but it has thrown another error as below:
ERROR: syft-proto 0.5.3 has requirement protobuf>=3.12.2, but you'll have protobuf 3.12.0 which is incompatible.

Then I tried updating probut. It results in further error:
root@ip-172-31-26-203:~# pip3 install protobuf==3.12.2
Collecting protobuf==3.12.2
Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf==3.12.2) (51.3.3)
Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf==3.12.2) (1.15.0)
ERROR: tensorflow 1.15.5 has requirement numpy<1.19.0,>=1.16.0, but you'll have numpy 1.19.5 which is incompatible.
ERROR: coremltools 2.0 has requirement six==1.10.0, but you'll have six 1.15.0 which is incompatible.
ERROR: autokeras 1.0.11 has requirement tensorflow>=2.3.0, but you'll have tensorflow 1.15.5 which is incompatible.
Installing collected packages: protobuf
  Attempting uninstall: protobuf
    Found existing installation: protobuf 3.12.0
    Uninstalling protobuf-3.12.0:
      Successfully uninstalled protobuf-3.12.0
Successfully installed protobuf-3.12.2

",root pip install error could find version requirement error matching distribution found tried version thrown another error error requirement incompatible tried error root pip install requirement already satisfied requirement already satisfied six error requirement incompatible error requirement six incompatible error requirement incompatible collected found installation successfully uninstalled successfully,issue,negative,positive,positive,positive,positive,positive
864945957,"That is great to know @tudorcebere . My use case requires high performance for production deployment.

In the meantime, is there any other way to speed up PyGrid server side?

I've seen the rust experimental repo you are referring to. Will it be able to run grid on the server side or will it be an alternative for KotlinSyft on client side?",great know use case high performance production deployment way speed server side seen rust experimental able run grid server side alternative client side,issue,positive,positive,positive,positive,positive,positive
864935693,"> > Can we add a test which runs this and asserts that they all pass and then we can run that in CI and get a canary alert that our Signalling server has gone down and be sure the code coverage is running?
> > Also perhaps change the loopback=True branch to still check the live urls are reachable.
> 
> Should I add an explicit test in the CI for this? Or just let it run as it would normally with the blanket pytest action?

Normal sounds good!",add test pas run get canary alert server gone sure code coverage running also perhaps change branch still check live reachable add explicit test let run would normally blanket action normal good,issue,positive,positive,positive,positive,positive,positive
864906074,"Hi @rhobro!

We have a few use cases for sure! Currently, we are exploring this option, porting down stuff to Rust, creating bindings, etc. We did not settle for something yet, but we are interested for sure in this! :) ",hi use sure currently exploring option stuff rust settle something yet interested sure,issue,positive,positive,positive,positive,positive,positive
864890706,@rasswanth-s Thanks for your time. That would be really helpful.,thanks time would really helpful,issue,positive,positive,positive,positive,positive,positive
864889514,"I think we did not update the examples to the current sympc framework in pysyft, I would look at it and get back to you regarding this.",think update current framework would look get back regarding,issue,negative,neutral,neutral,neutral,neutral,neutral
864878185,"Thanks @rasswanth-s . That worked. But I am not sure if the library is fully functional. I get errors when I try out the code.
![image](https://user-images.githubusercontent.com/30037676/122738589-c0ba4d00-d29f-11eb-9c21-e81cff60b2b4.png)

The error is below
```
`[2021-06-21T14:49:49.943489+0530][CRITICAL][logger]][10676] UnknownPrivateException has been triggered.
---------------------------------------------------------------------------
UnknownPrivateException                   Traceback (most recent call last)
<ipython-input-13-b434b26d9c89> in <module>
----> 1 print(""X + Y ="", (x + y).reconstruct())

E:\SMC\lib\site-packages\sympc\tensor\mpc_tensor.py in reconstruct(self, decode, get_shares)
    375             self.share_ptrs,
    376             get_shares=get_shares,
--> 377             security_type=self.session.protocol.security_type,
    378         )
    379 

E:\SMC\lib\site-packages\sympc\tensor\share_tensor.py in reconstruct(share_ptrs, get_shares, security_type)
    525 
    526         args = [[share] for share in share_ptrs]
--> 527         local_shares = request_wrap(args)
    528 
    529         shares = [share.tensor for share in local_shares]

E:\SMC\lib\site-packages\sympc\utils\utils.py in wrapper(args, kwargs)
    122                 futures.append(executor.submit(funcs[i], *_args, **_kwargs))
    123 
--> 124         local_shares = [f.result() for f in futures]
    125 
    126         return local_shares

E:\SMC\lib\site-packages\sympc\utils\utils.py in <listcomp>(.0)
    122                 futures.append(executor.submit(funcs[i], *_args, **_kwargs))
    123 
--> 124         local_shares = [f.result() for f in futures]
    125 
    126         return local_shares

C:\ProgramData\Anaconda3\lib\concurrent\futures\_base.py in result(self, timeout)
    423                 raise CancelledError()
    424             elif self._state == FINISHED:
--> 425                 return self.__get_result()
    426 
    427             self._condition.wait(timeout)

C:\ProgramData\Anaconda3\lib\concurrent\futures\_base.py in __get_result(self)
    382     def __get_result(self):
    383         if self._exception:
--> 384             raise self._exception
    385         else:
    386             return self._result

C:\ProgramData\Anaconda3\lib\concurrent\futures\thread.py in run(self)
     55 
     56         try:
---> 57             result = self.fn(*self.args, **self.kwargs)
     58         except BaseException as exc:
     59             self.future.set_exception(exc)

E:\SMC\lib\site-packages\sympc\tensor\share_tensor.py in _request_and_get(share_ptr)
    518             if not islocal(share_ptr):
    519                 share_ptr.request(block=True)
--> 520             res = share_ptr.get_copy()
    521             return res
    522 

e:\smc\src\syft\packages\syft\src\syft\core\pointer\pointer.py in get_copy(self, request_block, timeout_secs, reason, verbose)
    202             reason=reason,
    203             delete_obj=False,
--> 204             verbose=verbose,
    205         )
    206 

e:\smc\src\syft\packages\syft\src\syft\core\pointer\pointer.py in get(self, request_block, timeout_secs, reason, delete_obj, verbose)
    267 
    268         if not request_block:
--> 269             result = self._get(delete_obj=delete_obj, verbose=verbose)
    270         else:
    271             response_status = self.request(

e:\smc\src\syft\packages\syft\src\syft\core\pointer\pointer.py in _get(self, delete_obj, verbose)
    177         )
    178 
--> 179         obj = self.client.send_immediate_msg_with_reply(msg=obj_msg).data
    180         if self.is_enum:
    181             enum_class = self.client.lib_ast.query(self.path_and_name).object_ref

e:\smc\src\syft\packages\syft\src\syft\core\node\common\client.py in send_immediate_msg_with_reply(self, msg, route_index)
    234                 exception = exception_msg.exception_type(exception_msg.exception_msg)
    235                 error(str(exception))
--> 236                 traceback_and_raise(exception)
    237             else:
    238                 return response.message

e:\smc\src\syft\packages\syft\src\syft\logger.py in traceback_and_raise(e, verbose)
     59     if not issubclass(type(e), Exception):
     60         e = Exception(e)
---> 61     raise e
     62 
     63 

UnknownPrivateException: UnknownPrivateException has been triggered.`
```",thanks worked sure library fully functional get try code image error critical logger triggered recent call last module print reconstruct self decode reconstruct share share share wrapper return return result self raise finished return self self raise else return run self try result except return self reason verbose get self reason verbose result else self verbose self exception error exception exception else return verbose type exception exception raise,issue,negative,positive,positive,positive,positive,positive
864852933,"ok , I made a typo this would work `pip install -e  ""git+https://github.com/OpenMined/PySyft@dev#egg=syft&subdirectory=packages/syft""`",made typo would work pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
864830465,"Tried it in a new virtual env `pip install git+https://github.com/OpenMined/PySyft@dev#egg=syft&subdirectory=packages/syft`.

But getting the below error. 
![image](https://user-images.githubusercontent.com/30037676/122729893-44237080-d297-11eb-84e8-2f7d9885006a.png)

Are there any dependencies?",tried new virtual pip install getting error image,issue,negative,positive,positive,positive,positive,positive
864797535,"We modified the functionalities, the error is due to the old version of PySyft , you could remove the current version and install the latest one.`pip uninstall syft`.
`pip install git+https://github.com/OpenMined/PySyft@dev#egg=syft&subdirectory=packages/syft`",error due old version could remove current version install latest pip pip install,issue,negative,positive,positive,positive,positive,positive
864724562,"It is due to the PyPI problem, now it should work. I think there  wont be any dependency issue with other libraries ,you could open a issue , if there are any.",due problem work think wont dependency issue could open issue,issue,negative,negative,neutral,neutral,negative,negative
864722004,"Thank you. I will try that out. 
I have installed PySyft with this command ` pip install syft==0.5.0rc2` and haven't installed any other package explicitly to try out the examples for SMC with PySyft.
Would this have any dependency issues for running other examples under Homomorphic encryption or differential privacy? ",thank try command pip install package explicitly try would dependency running homomorphic encryption differential privacy,issue,negative,neutral,neutral,neutral,neutral,neutral
864719721,"Yeah , that is due to gpu build issue,I think you must have installed `torchcsprng==0.2.1`.
Firtst  you  could uninstall it `pip uninstall torchcsprng`.
Then install the cpu build from torch repo `pip install torchcsprng==0.2.1+cpu -f https://download.pytorch.org/whl/torch_stable.html`
Then you could import sympc and check.",yeah due build issue think must could pip install build torch pip install could import check,issue,negative,negative,negative,negative,negative,negative
864715736,"Oh, I see.
@rasswanth-s that doesn't seem to work for me either . 
![image](https://user-images.githubusercontent.com/30037676/122706601-f0545f80-d275-11eb-8b0f-50154a7eb127.png)

Are there any updated document with details about the installation steps and examples? 
I am trying out the examples for SyMPC under PySyft. 
![image](https://user-images.githubusercontent.com/30037676/122706822-5c36c800-d276-11eb-9e87-153e9cf7cd44.png)
",oh see seem work either image document installation trying image,issue,negative,neutral,neutral,neutral,neutral,neutral
864713014,"I think `sy.load`  is deprecated now,remove `sy.load` could you try `import sympc` in a separate cell,that should work.",think remove could try import separate cell work,issue,negative,neutral,neutral,neutral,neutral,neutral
864706038,"Sorry ,I interchanged in pysyft we `dev` for SyMPC we use `main` , this would work `pip install git+https://github.com/OpenMined/SyMPC@main`",sorry dev use main would work pip install,issue,negative,negative,negative,negative,negative,negative
864705533,"@rasswanth-s yes I tried that. It still didn't work. 
![image](https://user-images.githubusercontent.com/30037676/122707524-cbf98280-d277-11eb-8f1e-70bdb636c037.png)
",yes tried still work image,issue,negative,neutral,neutral,neutral,neutral,neutral
864594695,"> You could install the latest version by `pip install git+https://github.com/OpenMined/SyMPC@dev` , it would install latest one.

<img width=""762"" alt=""image"" src=""https://user-images.githubusercontent.com/57201660/122684666-b97a3d00-d1d4-11eb-85e2-1f9d75858ce7.png"">

It doesn't work.",could install latest version pip install would install latest one image work,issue,negative,positive,positive,positive,positive,positive
864517121,"I am using pysft version 0.3.0. I am running it on ubuntu machine python version 3.6.9. 
>>> import syft
>>> syft.__version__
'0.3.0'



",version running machine python version import,issue,negative,neutral,neutral,neutral,neutral,neutral
864500866,"You could install the latest version by `pip install git+https://github.com/OpenMined/SyMPC@dev` , it would install latest one.",could install latest version pip install would install latest one,issue,negative,positive,positive,positive,positive,positive
864466556,"> If you take the latest version of SyMPC - from the dev branch - do you have the same problem?
> It might be that at the point of releasing there was no support for division?

 I downloaded via this link: https://github.com/OpenMined/SyMPC/tree/main/src/sympc. Is this the latest one?",take latest version dev branch problem might point support division via link latest one,issue,negative,positive,positive,positive,positive,positive
864465947,"If you take the latest version of SyMPC - from the dev branch - do you have the same problem?
It might be that at the point of releasing there was no support for division?",take latest version dev branch problem might point support division,issue,negative,positive,positive,positive,positive,positive
864456905,"@tudorcebere , I think this PR does what we discussed about check documentation but only in the difference, I mean, only checks new lines of code",think check documentation difference mean new code,issue,negative,negative,neutral,neutral,negative,negative
864436755,"> @fu1001hao I will take a look at it. could you also post the whole code, where you get None value from MPCTensor, when doing operations with constant.

<img width=""438"" alt=""image"" src=""https://user-images.githubusercontent.com/57201660/122649823-cd06a480-d0fd-11eb-8d38-28348dfcc621.png"">

You set ""batchs"" to be any constant number, you get None type. I also attach the whole code.

import syft as sy
import torch
import torch.optim as optim
from sympc.session import Session
from sympc.session import SessionManager
from sympc.module import nn
from sympc.optim import SGD
from sympc.tensor import MPCTensor
import time

start = time.time()
sy.load(""sympc"")
sy.logger.add(sink=""./example.log"")

alice = sy.VirtualMachine(name=""alice"")
bob = sy.VirtualMachine(name=""bob"")

alice_client = alice.get_client()
bob_client = bob.get_client()

session = Session(parties=[alice_client, bob_client])
session.autograd_active = True
SessionManager.setup_mpc(session)

x, y = torch.load('data/train.pt')
xt, yt = torch.load('data/test.pt')

def one_hot(y):

    tmp = torch.zeros((len(y),10))
    for i in range(len(y)):
        tmp[i, y[i]] = 1
    return tmp

def split(x, y):

    party0, party1 = [], []
    for i in range(10):
        indices = (y==i).nonzero()[:,0]
        l = len(indices) // 2
        party0.append(indices[:l])
        party1.append(indices[l:])
    party0, party1 = torch.cat(party0, 0), torch.cat(party1, 0)
    return (x[party0], y[party0]), (x[party1], y[party1])

party0, party1 = split(x, y)

class Net(sy.Module):

    def __init__(self, torch_ref):
        super(Net, self).__init__(torch_ref = torch_ref)
        self.fc1 = torch_ref.nn.Linear(28*28, 128)
        self.fc2 = torch_ref.nn.Linear(128, 64)
        self.fc3 = torch_ref.nn.Linear(64, 10)

    def forward(self, x):
        x = self.torch_ref.nn.functional.relu(self.fc1(x))
        x = self.torch_ref.nn.functional.relu(self.fc2(x))
        x = self.fc3(x)
        
        return x

def share(party, pct = 0.01):

    x, y = party
    shared = []
    for i in range(10):
        indices = (y==i).nonzero()[:,0]
        l = int(len(indices)*pct)
        shared.append(indices[:l])
    shared = torch.cat(shared, 0)
    return x[shared], y[shared]


model = Net(torch_ref = torch)
private = True

x0, y0 = party0
xs, ys = share(party1)
x0, xs = x0.reshape(-1, 28*28), xs.reshape(-1, 28*28)
print(x0.shape, xs.shape)

ys = one_hot(ys)
y0 = one_hot(y0)
lr = 1e-2
epoch = 500
device = 'cpu'

batch0, batchs = y0.shape[0], ys.shape[0]
x0, y0 = x0.to(device), y0.to(device)
xs, ys = xs.to(device), ys.to(device)

shapexs, shapeys = xs.shape, ys.shape

if private:

    xs = xs.share(session = session)
    ys = ys.share(session = session)

for i in range(epoch):

    print(i)
    for j in range(2):

        if (j==0):

            if i!=0 and private:

                model = model.reconstruct()

            optimizer = optim.SGD(model.parameters(), lr = lr)
            optimizer.zero_grad()
            output = model(x0)
            loss = ((output - y0)**2).mean()
            loss.backward()
            optimizer.step()
            print(loss.item())

        elif (j==1):

            if private:

                model = model.share(session)
                optimizer = SGD(model.parameters(), lr = lr)
            else:

                optimizer = optim.SGD(model.parameters(), lr = lr)
                
            optimizer.zero_grad()
            output = model(xs)
            loss = ((output - ys)**2).sum()/batchs
            loss.backward()
            optimizer.step()
            if private:

                print(loss.reconstruct())

            else:

                print(loss.item())

xt = xt.reshape(-1, 28*28)
xt, yt = xt.to(device), yt.to(device)
if private:

    model = model.reconstruct()
output = model(xt)
pred = output.argmax(dim=1)
total = pred.eq(yt).sum().item()
print(total*1.0/len(pred), total, len(pred))

print(time.time() - start)",take look could also post whole code get none value constant image set constant number get none type also attach whole code import import torch import import session import import import import import time start bob bob session session true session range return split party party range index index index index party party party party return party party party party party party split class net self super net self forward self return share party party range index index index return model net torch private true party share party print epoch device batch device device device device private session session session session range epoch print range private model output model loss output print private model session else output model loss output private print else print device device private model output model total print total total print start,issue,positive,positive,neutral,neutral,positive,positive
864435449,"@fu1001hao I will take a look at it. could you also post the whole code, where you get None value from MPCTensor, when doing operations with constant.",take look could also post whole code get none value constant,issue,negative,positive,neutral,neutral,positive,positive
864428967,"> @fu1001hao ,maybe could you post a screenshot of the error , when you do operations of MPCTensor with a constant,also syft version

<img width=""817"" alt=""image"" src=""https://user-images.githubusercontent.com/57201660/122649242-f2de7a00-d0fa-11eb-89b3-ed2fae625d11.png"">

The version is ""0.5.0rc2.post1.dev25+ge7fa7629f.d20210520""

There are other issues. For example, if a network structure (model) contains two subnetworks (model1, model2), the MPC will return an empty list of parameters, when calling model.parameters(). You have to use model1.parameters()+model2.paramters() to call the parameters. Also, the MPCTensor cannot be divided by constant, it will return None type data.",maybe could post error constant also version image version example network structure model two model model return empty list calling use call also divided constant return none type data,issue,negative,negative,neutral,neutral,negative,negative
864426491,"@fu1001hao  ,maybe could you post a screenshot of the error , when you do operations of  MPCTensor with a constant,also syft version",maybe could post error constant also version,issue,negative,neutral,neutral,neutral,neutral,neutral
864390494,"I close this PR. I think that I have found the good way to do it, but I will open another PR with a cleaner history.",close think found good way open another cleaner history,issue,positive,positive,positive,positive,positive,positive
864380781,Thanks @divyadixit . What is needed is to review and update the links that appear in the notebooks from PyGrid example folder. Some of them are broken due to the monorepo recent structure,thanks review update link appear example folder broken due recent structure,issue,negative,negative,neutral,neutral,negative,negative
864329358,"Hi @jmaunon, I wanna work on this. Can you please assign this issue to me!! And give me some guidance to so I can solve this issue as soon as I can.",hi wan na work please assign issue give guidance solve issue soon,issue,negative,negative,negative,negative,negative,negative
863751606,I was initially facing a similar issue. Which version of PySyft are you using? Could you share in some environment details too.,initially facing similar issue version could share environment,issue,negative,neutral,neutral,neutral,neutral,neutral
862834957,"`File ""setup.py"" or ""setup.cfg"" not found for legacy project syft from git+https://github.com/OpenMined/PySyft@dev#egg=syft`

I get above error when i try to install using `pip install git+https://github.com/OpenMined/PySyft@dev#egg=syft`",file found legacy project get error try install pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
860354276,"> Can we add a test which runs this and asserts that they all pass and then we can run that in CI and get a canary alert that our Signalling server has gone down and be sure the code coverage is running?
> 
> Also perhaps change the loopback=True branch to still check the live urls are reachable.

Should I add an explicit test in the CI for this? Or just let it run as it would normally with the blanket pytest action? ",add test pas run get canary alert server gone sure code coverage running also perhaps change branch still check live reachable add explicit test let run would normally blanket action,issue,positive,positive,positive,positive,positive,positive
859336070,"hello，have u solved this problem？i want to define my own fitting algorithm, but ""async def async_fit"" can't find the ""fit"" function. ",want define fitting algorithm ca find fit function,issue,negative,positive,positive,positive,positive,positive
857188570,"Hello @madhavajay !

I have the same problem with this function, but when I tried to install PySyft from the dev branch, an error raised. How can this can be fixed?

Thank you!


![image](https://user-images.githubusercontent.com/2991063/121261791-8f965180-c889-11eb-905d-112cc944d4af.png)
",hello problem function tried install dev branch error raised fixed thank image,issue,negative,positive,neutral,neutral,positive,positive
856913663,"I didn't. I ended up using Socket + Pickle to build one manually. Also, I followed this [demo](https://heartbeat.fritz.ai/federated-learning-demo-in-python-part-1-client-server-application-cebdcfb96b9) to learn how to use Socket to host virtual network services. I hope this helps you. 😃",ended socket pickle build one manually also learn use socket host virtual network hope,issue,negative,neutral,neutral,neutral,neutral,neutral
856552505,"The problem is in the `tensor_util.py` because we do not take into account all the fields (like ""device""). But this is not an urgent matter.",problem take account like device urgent matter,issue,negative,neutral,neutral,neutral,neutral,neutral
856542518,"Hi
I have the exact same error with the WebSocket, Did you manage to solve this problem?",hi exact error manage solve problem,issue,negative,positive,positive,positive,positive,positive
856369704,"@madhavajay No fields need to be added. Right now methods exist only for serialization/deserialization of TensorData and not TensorProto. 

It's not an immediate requirement like @gmuraru mentioned. But, in the future. ",need added right exist immediate requirement like future,issue,negative,positive,positive,positive,positive,positive
855886747,"Hello @LuanJia!  

Yeah, we need to use different prompt-toolkit versions due to some dependencies (hopefully we'll be fixing it in the next weeks).

Regarding the branches/tags/version, we're actually in the middle of a huge task that will merge PySyft/PyGrid at the same repository in order to sync their development/issues. This will probably solve all this confusion and make the development process clean and easy for both repositories.",hello yeah need use different due hopefully fixing next regarding actually middle huge task merge repository order sync probably solve confusion make development process clean easy,issue,positive,positive,positive,positive,positive,positive
855586252,"We currently have the following:
```
message TensorProto {
    TensorData tensor = 1;
    bool requires_grad = 2;
    TensorData grad = 3;
    syft.lib.torch.Device device = 4;
}
```

@kamathhrishi Can you explain what fields specifically need to be added?",currently following message tensor bool grad device explain specifically need added,issue,negative,neutral,neutral,neutral,neutral,neutral
855584779,"@rasswanth-s Since `--experimental_allow_proto3_optional` is not needed anymore and we are in control of the version of `protoc` that we use to compile our protobufs, we should just remove this flag and force everyone to upgrade their `protoc`. Can you provide a PR for this?",since control version use compile remove flag force everyone upgrade provide,issue,negative,neutral,neutral,neutral,neutral,neutral
855583447,"Two issues, one your version is likely very out of date, we will be doing an official release as soon as we merge the monorepo until then the latest release candidate is available here:
```
$ pip install syft==0.5.0rc2
```

Second issue, sy.load takes a string:
```
import syft as sy
import tenseal as ts
import pytest 
sy.load(""tenseal"")
```",two one version likely date official release soon merge latest release candidate available pip install second issue string import import import,issue,negative,positive,positive,positive,positive,positive
855383609,@Macha2021 Thanks. Unfortunately I have to stick with this library for it's multiplatform support. ,thanks unfortunately stick library support,issue,negative,negative,negative,negative,negative,negative
855373090,Arf no I didn’t succeed in resolving this error. I just decided to change for IBM library (very easier to use and their examples work with no problem for me) ,succeed error decided change library easier use work problem,issue,negative,neutral,neutral,neutral,neutral,neutral
855360330,"Hi
Did you manage to solve this problem? I have the exact same error",hi manage solve problem exact error,issue,negative,positive,positive,positive,positive,positive
854800524,"@tudorcebere 

Ok, so far the results have revealed the following: the problem persists if I try to install `syft==0.5.0rc1` from pip, and it doesn't arise if I `pip install syft==0.3.0`, but in the latter case syft.util has no `get_root_data_path`

ETA: in a fresh install of syft from source (cloning and `pip install -e .`) the problem seemingly persists.",far revealed following problem try install pip arise pip install latter case eta fresh install source pip install problem seemingly,issue,negative,positive,neutral,neutral,positive,positive
853797878,"Tests, linting, cleaning up are todo. Early feedback would be great",cleaning early feedback would great,issue,positive,positive,positive,positive,positive,positive
853581160,"Elaborating this issue a bit for #5634. A script that measures what happens to proto size when nesting SyModules:
```
from torch import nn
from syft import  SySequential, SyModule, serialize
import matplotlib.pyplot as plt
from syft import logger
logger.remove()

class Wrapper(SyModule):
    def __init__(self, module, input_size=(1, 10)):
        super().__init__(input_size=input_size)
        self.module = module
        
    def forward(self, x):
        return self.module(x=x)[0]

bytesizes = []
for n in range(10):
    model = SySequential(nn.Linear(10, 10), input_size=(1, 10))
    # Nest model in an empty SyModule n times
    for _ in range(n):
        model = Wrapper(model)
    proto = serialize(model)
    bytesizes.append(proto.ByteSize())
    
plt.plot(bytesizes)
plt.show()
```


Which shows that the protobuf size doubles every time you nest:

![14147894](https://user-images.githubusercontent.com/7243409/120592688-8e56c600-c43e-11eb-8a22-4b3d980636f0.png)",issue bit script proto size torch import import serialize import import logger class wrapper self module super module forward self return range model nest model empty time range model wrapper model proto serialize model size every time nest,issue,negative,positive,positive,positive,positive,positive
853538019,"Hi @LSnyd and @arnewitt , 
Thank you very much for your reply.
I have been able to solve this by either install the latest version (0.5.0rc2) of syft OR downgrading torch to 1.7.1 and use syft 0.3.0.
Just to note, the command pip install git+https://github.com/OpenMined/PySyft@dev#egg=syft as suggested in some thread is not working as of the time of this comment. 
Again thank you.
Best regards,
",hi thank much reply able solve either install latest version torch use note command pip install thread working time comment thank best,issue,positive,positive,positive,positive,positive,positive
853401382,"Hi @intrivil and @nrakurniawan!
As @LSnyd kindly suggested, your problem is with incompatible versions. I would personally recommend downgrading syft to 0.3.0 and torch to 1.7.1, since syft 0.3.0 is incompatible with torch 1.8.1. 

This setup proved to be most reliable on my machine. Keep in mind that syft 0.5.0 is still only a release candidate. 

`
pip install syft==0.3.0 torch==1.7.1
` 

Hope that helps! Have a great day!",hi kindly problem incompatible would personally recommend torch since incompatible torch setup proved reliable machine keep mind still release candidate pip install hope great day,issue,positive,positive,positive,positive,positive,positive
852938201,"@koenvanderveen, thanks for your PR! I have just seen and I have some comments for this PR, could you ping me via slack? (@jmaunon)",thanks seen could ping via slack,issue,negative,positive,positive,positive,positive,positive
852827690,"@jmaunon  No worries! :p
I've removed logs from notebook! Does it look good?
It seems the other conflicts are desirable",removed notebook look good desirable,issue,positive,positive,positive,positive,positive,positive
852668771,"I've already solved this problem by creating 2 env:
`conda create -n env1` and install  `syft-0.5.0rc1` /run jupyter notebook
`conda create -n env2` and run `pygrid_0.4.0`

by the way ,there are too many branches/tags/version in PyGrid/PySfyt, It would be even better if there was a recommended matching version of PyGrid and PySyft 

thanks！
",already problem create install notebook create run way many would even better matching version,issue,positive,positive,positive,positive,positive,positive
852204021,"Hi @intrivil and @nrakurniawan, 
it worked for me when I installed PySyft in a newer version:

`pip install syft==0.5.0rc1`",hi worked version pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
852052277,"Getting error when using 'from syft.frameworks.torch.federated import utils'

ModuleNotFoundError: No module named 'syft.frameworks'  

Installed syft '0.5.0rc1' version using 
pip install syft==0.5.0rc1",getting error import module version pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
852033529,"Hi! `0.2.x` hit EOL 2 months ago, we are no longer support it.

Thank you and take a look maybe syft `0.5.0` suits your needs already!",hi hit ago longer support thank take look maybe need already,issue,positive,neutral,neutral,neutral,neutral,neutral
852031188,"I have the same error:
`---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-1-fde8a91b7813> in <module>
----> 1 import syft
      2 print(syft. __version__)

~\anaconda3\envs\pysyft\lib\site-packages\syft\__init__.py in <module>
     59 from syft.core.common.serde.serialize import _serialize as serialize  # noqa: F401
     60 from syft.core.node.common.service.repr_service import ReprMessage  # noqa: F401
---> 61 from syft.core.node.device.device import Device  # noqa: F401
     62 from syft.core.node.device.device import DeviceClient  # noqa: F401
     63 from syft.core.node.domain.domain import Domain  # noqa: F401

~\anaconda3\envs\pysyft\lib\site-packages\syft\core\node\device\__init__.py in <module>
      1 # syft relative
----> 2 from .client import DeviceClient
      3 from .device import Device
      4 
      5 __all__ = [""DeviceClient"", ""Device""]

~\anaconda3\envs\pysyft\lib\site-packages\syft\core\node\device\client.py in <module>
     14 from ...io.location import SpecificLocation
     15 from ...io.route import Route
---> 16 from ..common.client import Client
     17 
     18 

~\anaconda3\envs\pysyft\lib\site-packages\syft\core\node\common\client.py in <module>
     18 from ....core.pointer.pointer import Pointer
     19 from ....decorators import syft_decorator
---> 20 from ....lib import lib_ast
     21 from ....proto.core.node.common.client_pb2 import Client as Client_PB
     22 from ....proto.core.node.common.metadata_pb2 import Metadata as Metadata_PB

~\anaconda3\envs\pysyft\lib\site-packages\syft\lib\__init__.py in <module>
     24 
     25 # constructor: copyType = create_lib_ast
---> 26 lib_ast = create_lib_ast()
     27 lib_ast._copy = create_lib_ast

~\anaconda3\envs\pysyft\lib\site-packages\syft\lib\__init__.py in create_lib_ast()
     10 
     11     python_ast = create_python_ast()
---> 12     torch_ast = create_torch_ast()
     13     torchvision_ast = create_torchvision_ast()
     14     # numpy_ast = create_numpy_ast()

~\anaconda3\envs\pysyft\lib\site-packages\syft\lib\torch\__init__.py in create_torch_ast()
     51                 # this allows us to import them for testing
     52                 continue
---> 53             ast.add_path(
     54                 path=method, framework_reference=torch, return_type_name=return_type
     55             )

~\anaconda3\envs\pysyft\lib\site-packages\syft\ast\globals.py in add_path(self, path, index, return_type_name, framework_reference)
     63         attr = self.attrs[framework_name]
     64         if hasattr(attr, ""add_path""):
---> 65             attr.add_path(  # type: ignore
     66                 path=path, index=1, return_type_name=return_type_name
     67             )

~\anaconda3\envs\pysyft\lib\site-packages\syft\ast\module.py in add_path(self, path, index, return_type_name, framework_reference)
    118             self.lookup_cache[attr_ref] = path
    119         if hasattr(attr, ""add_path""):
--> 120             attr.add_path(  # type: ignore
    121                 path=path, index=index + 1, return_type_name=return_type_name
    122             )

~\anaconda3\envs\pysyft\lib\site-packages\syft\ast\callable.py in add_path(self, path, index, return_type_name)
     80             if path[index] not in self.attrs:
     81 
---> 82                 attr_ref = getattr(self.ref, path[index])
     83 
     84                 if isinstance(attr_ref, module_type):

AttributeError: type object 'Tensor' has no attribute 'fft' `",error recent call last module import print module import serialize import import device import import domain module relative import import device device module import import route import client module import pointer import import import client import module constructor u import testing continue self path index type ignore self path index path type ignore self path index path index path index type object attribute,issue,negative,neutral,neutral,neutral,neutral,neutral
852018395,Ignore flapping duet test and merging anyway!,ignore duet test anyway,issue,negative,neutral,neutral,neutral,neutral,neutral
851957742,"To add, I've also tried to install syft with this command:
pip install git+https://github.com/OpenMined/PySyft@dev#egg=syft
But I encountered the problem: 
ERROR: File ""setup.py"" or ""setup.cfg"" not found for legacy project syft from git+https://github.com/OpenMined/PySyft@dev#egg=syft.
I truely don't get it, so many people are using this why I can't even install it?",add also tried install command pip install problem error file found legacy project get many people ca even install,issue,negative,positive,positive,positive,positive,positive
851905638,"I changed the description because, for the moment, this is not something we require. It would be good to have all the tensor info (that it is in the proto file) at the serialization time, but this is not a blocker for us",description moment something require would good tensor proto file serialization time blocker u,issue,negative,positive,positive,positive,positive,positive
851882521,"@arpitvaghela good call, although I think we should still check the object contains the same elements or when sorted matches so the test should be updated.",good call although think still check object sorted test,issue,negative,positive,positive,positive,positive,positive
851875428,"Hi @nooralahzadeh 

The blogpost is not quite up to date with PySyft (it's related to the versions prior to 0.3.0). Currently, this is possible in Syft (everything lower than 0.3.0 hit EOL in April :))

Thanks for your interest in Syft! 
",hi quite date related prior currently possible everything lower hit thanks interest,issue,positive,positive,neutral,neutral,positive,positive
851828733,"Hey @willclarktech 

I will hold out this PR until I figure out a few bugs on the gym/numpy interaction. I hope it won't be long (and you won't have too many conflicts to solve 🤣 )

",hey hold figure interaction hope wo long wo many solve,issue,positive,positive,positive,positive,positive,positive
851756415,"I had to update the MNIST notebooks because they had some merge conflicts in them and there were some old files left over from the old folder structure which got accidentally re-added but now its all good.
I also fixed a mistake in the README.md.

Tests are passing here: https://github.com/OpenMined/PySyft/runs/2714651491?check_suite_focus=true
For some reason the README.md triggered another action which it shouldnt but i skipped it.
",update merge old left old folder structure got accidentally good also fixed mistake passing reason triggered another action shouldnt,issue,negative,positive,positive,positive,positive,positive
851616890,"> Hi @Dat-Boi-Arjun,
> 
> 
> 
> What's the status of this PR?

I still have a few commits to make that I will finish soon.",hi status still make finish soon,issue,negative,neutral,neutral,neutral,neutral,neutral
851415453,"Hi @wip-abramson,

Looks like the pre-commit hook is failing. Would you mind taking care of that before we review?",hi like hook failing would mind taking care review,issue,negative,neutral,neutral,neutral,neutral,neutral
851306258,"Hi @marcalph . Thanks for your PR and sorry for the late response, I am not as reviewer and it was out of my radar, xd.

Please, resolve conflicts. I have also included a couple of comments/questions ",hi thanks sorry late response reviewer radar please resolve also included couple,issue,positive,negative,negative,negative,negative,negative
851297063,"Hello. 

@tudorcebere , as far as I can recall, I'm using torch 1.8, which might be one of the reason for the error.

Anyway, test results on the latest dev are to follow.",hello far recall torch might one reason error anyway test latest dev follow,issue,negative,positive,positive,positive,positive,positive
851263031,"Hi @StrangeTcy,

With the latest release/dev branch, I can't reproduce the error (python 3.8, torch 1.7.1, Ubuntu OS).

Could you give me more info/could you test with the latest branch of dev to see if you can still reproduce it?

Thank you!",hi latest branch ca reproduce error python torch o could give test latest branch dev see still reproduce thank,issue,negative,positive,positive,positive,positive,positive
851232342,"@vsquareg great work, just need a few small tweaks before merge. 😊",great work need small merge,issue,positive,positive,positive,positive,positive,positive
850380609,"`Syft` team is quite interested in this idea, however we have to think the best approach.
After a conversation with @tudorcebere , we have decided to close this one for the moment, and we have to think the best way to apply these checks ONLY to differences, that is, if I write a new class/function/method, I have to include the documentation (but I do not have to care about the rest of the file)

",team quite interested idea however think best approach conversation decided close one moment think best way apply write new include documentation care rest file,issue,positive,positive,positive,positive,positive,positive
850287850,Hi @tudorcebere! You mean refactoring all messages having `SetUp` to `setup`?,hi mean setup setup,issue,negative,negative,negative,negative,negative,negative
850287278,"Hi @napoay !

Thank you for your interest in Syft! Sadly, everything that is lower than `0.3.0` hit EOL and it's no longer supported. Checkout the latest releases, maybe it will suit your needs!",hi thank interest sadly everything lower hit longer latest maybe suit need,issue,negative,neutral,neutral,neutral,neutral,neutral
850285638,"Hi @harikrishnankh !

I hope @rasswanth-s managed yo answer your question! I will be closing this for now.",hi hope yo answer question,issue,negative,neutral,neutral,neutral,neutral,neutral
850279785,"Hey @SamiurRahman1!

Currently, we are working on a benchmarking suite internally, but we are not close to over. This is an interesting idea to have as a metric, we will add it to our benchmarking suite.

Thank you for your interest in Syft!",hey currently working suite internally close interesting idea metric add suite thank interest,issue,positive,positive,positive,positive,positive,positive
850261001,"Hi @victorperezc !

Nice to meet you. Could you refactor everything  to setup then this is ready to merge?",hi nice meet could everything setup ready merge,issue,positive,positive,positive,positive,positive,positive
848621473,"I think this library can be used for virtual set-up, i.e., place worker and host in one device and use socket to connect the different pipes in localhost. ",think library used virtual place worker host one device use socket connect different,issue,negative,neutral,neutral,neutral,neutral,neutral
848618468,"Syft got totally re-written after version 0.3.0 and functions in v0.2.x are no longer supported, see source code for v0.2.x [here](https://github.com/OpenMined/PySyft/blob/syft_0.2.x/syft/frameworks/torch/mpc/cuda/tensor.py). The new way to use is just like Pytorch, see source code [here](https://github.com/OpenMined/PySyft/blob/dev/packages/syft/src/syft/lib/torch/module.py#L196)",got totally version longer see source code new way use like see source code,issue,negative,positive,neutral,neutral,positive,positive
847721991,"> > Yes we have a first integration of Opacus!
> > Check out: https://blog.openmined.org/pysyft-opacus-federated-learning-with-differential-privacy/
> 
> hi @LaRiffle , i tried to run the code in this blog just recently with pysyft 0.2.9, but there is an error with parameter has no `grad_sample` attribute.
> I have seen similiar issues asked but unsolved #4917 , so could u please share were there versions of Opacus and Pysyft that can run together at the time of the blog?

Have u known versions of Opacus and Pysyft that can run together at this blog",yes first integration check hi tried run code recently error parameter attribute seen unsolved could please share run together time known run together,issue,positive,positive,positive,positive,positive,positive
847630515,@madhavajay could you give me a ping on slack when this is ready for review,could give ping slack ready review,issue,negative,positive,positive,positive,positive,positive
846515443,"> I don't think I can request a review since I am not a maintainer.
> 
> @gmuraru, @LaRiffle, @aanurraj, and @madhavajay have a look at the PR and let me know if I am going about the right way. If I have missed out on anything.

I am sorry, I realized there are some changes I need to make before a proper review. ",think request review since maintainer look let know going right way anything sorry need make proper review,issue,negative,negative,neutral,neutral,negative,negative
846514912,"I don't think I can request a review since I am not a maintainer. 

@gmuraru, @LaRiffle, @aanurraj, and @madhavajay have a look at the PR and let me know if I am going about the right way. If I have missed out on anything. ",think request review since maintainer look let know going right way anything,issue,negative,positive,positive,positive,positive,positive
845188720,"> 
> 
> It is mos
> 
> > Hello, I had the same issue and your proposition worked @madhavajay, thanks!
> > But why do we have to that and why `pip install syft` alone does not work?
> 
> It is mostly because of the torch version!
> We need torch version <=1.7.0 & >=1.4.0 and torchvision<=0.9 & >=0.5 .


I also had to deal with this problem.
My system information as follows:

OS: windows 10
Language Version:Python 3.7
Package Manager Version: syft 0.3, torch1.8.1


I tried to downgrade **torch==1.7.0 and  torchvision==0.8.1**

an installation with CUDA
`pip install torch===1.7.0 torchvision===0.8.1 torchaudio===0.7.0 -f https://download.pytorch.org/whl/torch_stable.html`

an installation without CUDA
`pip install torch==1.7.0+cpu torchvision==0.8.1+cpu torchaudio===0.7.0 -f https://download.pytorch.org/whl/torch_stable.html`

And it works.",hello issue proposition worked thanks pip install alone work mostly torch version need torch version also deal problem system information o language version python package manager version torch tried downgrade installation pip install installation without pip install work,issue,negative,positive,positive,positive,positive,positive
843931900,"@gmuraru if you are sending it using Syft, we'll add an experimental module for this. There are a few caveats on this:
* they have support only for cpp and python on it (js/java is on the roadmap, but they are not ready)

On the other side, they have amazing support for:
* compression
* zero-copy operations
* pandas
* GPU

",sending add experimental module support python ready side amazing support compression,issue,positive,positive,positive,positive,positive,positive
843922279,"Benchmark results:
```
[----------------------- Serde of Numpy arrays ------------------------]
                                               |   Arrow    |    Proto  
------------------------------------------------------------------------
      dtype: float16, shape: (100, 100)        |      95.0  |     1303.8
      dtype: float16, shape: (500, 500)        |     338.7  |    35422.9
      dtype: float16, shape: (1000, 1000)      |    2787.2  |   147132.2
      dtype: float16, shape: (100, 100, 100)   |    2600.5  |   146360.7
      dtype: float16, shape: (50, 50, 50, 50)  |   53542.8  |   997589.8
      dtype: float32, shape: (100, 100)        |      88.7  |     1316.0
      dtype: float32, shape: (500, 500)        |    1077.7  |    34173.3
      dtype: float32, shape: (1000, 1000)      |    7812.5  |   143600.6
      dtype: float32, shape: (100, 100, 100)   |    8136.6  |   163172.3
      dtype: float32, shape: (50, 50, 50, 50)  |  110270.2  |   988503.6
      dtype: float64, shape: (100, 100)        |     106.4  |     1190.4
      dtype: float64, shape: (500, 500)        |    3261.2  |    36200.6
      dtype: float64, shape: (1000, 1000)      |   15796.9  |   156819.3
      dtype: float64, shape: (100, 100, 100)   |   16477.2  |   159666.3
      dtype: float64, shape: (50, 50, 50, 50)  |  312778.1  |  1280666.5
```



```
from torch.utils import benchmark
import numpy as np
from syft import serialize, deserialize, load
from syft.experimental_flags import flags
load(""numpy"")

def serde(obj):
    bytes_repr = serialize(obj, to_bytes=True)
    obj_back = deserialize(bytes_repr, from_bytes=True)


results = []

for backend in [""Arrow"", ""Proto""]:
    if backend == ""Arrow"":
        flags.APACHE_ARROW_TENSOR_SERDE = True
    else:
        flags.APACHE_ARROW_TENSOR_SERDE = False

    for dtype in [np.float16, np.float32, np.float64]:
        for sizes in [(100, 100), (500, 500), (1000, 1000), (100, 100, 100), (50, 50, 50, 50)]:
            obj = np.random.randn(*sizes).astype(dtype)
            t = benchmark.Timer(
                stmt='serde(obj)',
                setup='from __main__ import serde',
                label=f'Serde of Numpy arrays',
                globals={'obj': obj},
                sub_label=f'dtype: {dtype.__name__}, shape: {sizes}',
                description=backend
            ).timeit(500)
            results.append(t)
            print(f""Finished {backend} - {dtype} - {sizes} on 1 thread"")

compare = benchmark.Compare(results)
compare.print()
```",arrow proto float shape float shape float shape float shape float shape float shape float shape float shape float shape float shape float shape float shape float shape float shape float shape import import import serialize load import load serialize arrow proto arrow true else false size size import shape size print finished size thread compare,issue,negative,negative,neutral,neutral,negative,negative
842753908,sorry，so long to see this. can you post some output information here?,long see post output information,issue,negative,negative,neutral,neutral,negative,negative
842643234,"> Hello @tudorcebere!
> As you mentioned, there were three sleeps in the code of the program apart from the examples and tests. I was unable to remove in `src/syft/grid/duet/__init__.py` due to hinderance in tests.

I think this one is not crucial! Thanks a lot for the PR :) 
Apparently you still have some conflicts @cgoxo ",hello three code program apart unable remove due hinderance think one crucial thanks lot apparently still,issue,negative,negative,neutral,neutral,negative,negative
842556911,"Looking forward to this! This means that if we want to send a tensor, it would make more sense to convert it to numpy --> use arrow --> convert back to tensor?",looking forward want send tensor would make sense convert use arrow convert back tensor,issue,negative,neutral,neutral,neutral,neutral,neutral
842378422,Don't you think it is due to the fact that we launch the server and the client on the same computer ?,think due fact launch server client computer,issue,negative,negative,negative,negative,negative,negative
841727669,"Not exactly, I still stuck here, and I don't know which part went wrong. I assume it may be caused by PyGrid does not start a service properly, and the socket went to sleep mode, but I'm confident about this. I actually got a similar error traceback in issue [#5521](https://github.com/OpenMined/PySyft/issues/5521) but this problem is not resolved yet.",exactly still stuck know part went wrong assume may start service properly socket went sleep mode confident actually got similar error issue problem resolved yet,issue,negative,positive,neutral,neutral,positive,positive
841640293,"Okay so what I figured out was, the course on Private and Secure AI on Udacity has old pysyft implementations, and therefore while installing you will have to install lower versions of Pysyft and torch version. I feel it's better to pursue the course on Openmined website as it has more recent pysyft implementations.
Although I still don't understand that If the developers change so much in one update, why did they not add this as a caution in the documentation or on udacity's course.",figured course private secure ai old therefore install lower torch version feel better pursue course recent although still understand change much one update add caution documentation course,issue,negative,positive,positive,positive,positive,positive
841605259,"@harikrishnankh To answer your question on additive secret sharing.

**Secure Multiparty Computation (MPC)**: It is one of the privacy advocates. It allows multiple parties to compute a joint function without revealing their private inputs beyond what is revealed by the output of the function.

**Secret Sharing** is one of the primitives of MPC.

Secret sharing allows you to split the secret into shares such that no party or a subset can determine the secret.

Additive Secret Sharing: The secret is split into shares and addition of the all the shares would reveal the secret.

Ex: Consider the integer  7 and 3 parties, it can be split as 4,2,1
Each of the three parties holds a share, all three parties have to combine the shares to reveal the secret. It is an **n-out-of-n secret sharing**, where n parties have to combine the shares to reveal the secret.
4+2+1=7(Reconstructed Secret)

Generally, sharing is done over finite fields.

Consider the MPC functionality with three parties, where we want to multiply two numbers a,b. The number a,b are shared between the parties by secret sharing. Each party holds shares of a,b. We apply a custom protocol for multiplication and maintain the **invariant** that output  (a*b) is also secret shared. Each party has only the shares at each computation revealing nothing about the private input.

Considering the ML scenario of private inference, the model (weights and biases) are secret shared between parties after training. The user wanting to do inference shares his data as shares to the parties and the output shares are sent to the user. The invariant is maintained at each step.


There are also various secret sharing schemes such as Threshold Secret Sharing, Verifiable Secret Sharing.

I have abstracted many technical details.
Here are resources that would be helpful :
[Crypto Notes](https://www.cs.cornell.edu/courses/cs4830/2010fa/lecnotes.pdf)
[Crypto Notes -SM](https://cseweb.ucsd.edu/~mihir/papers/gb.pdf)


",answer question additive secret secure computation one privacy multiple compute joint function without revealing private beyond revealed output function secret one secret split secret party subset determine secret additive secret secret split addition would reveal secret ex consider integer split three share three combine reveal secret secret combine reveal secret reconstructed secret generally done finite consider functionality three want multiply two number secret party apply custom protocol multiplication maintain invariant output also secret party computation revealing nothing private input considering scenario private inference model secret training user wanting inference data output sent user invariant step also various secret threshold secret verifiable secret abstracted many technical would helpful,issue,positive,negative,negative,negative,negative,negative
841591922,"> Hi,
> Try this
> pip uninstall syft
> pip install git+https://github.com/OpenMined/PySyft@dev#egg=syft

@mojtaba732 

I tried on my mac and get  the error :
```
 ✘ 👍  ~  sudo pip3 install git+https://github.com/OpenMined/PySyft@dev#egg=syft
WARNING: The directory '/Users/pan/Library/Caches/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.
WARNING: The directory '/Users/pan/Library/Caches/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.
Collecting syft
  Cloning https://github.com/OpenMined/PySyft (to revision dev) to /private/tmp/pip-install-289tqzaz/syft
  Running command git clone -q https://github.com/OpenMined/PySyft /private/tmp/pip-install-289tqzaz/syft
  fatal: unable to access 'https://github.com/OpenMined/PySyft/': Failed to connect to github.com port 443: Operation timed out
ERROR: Command errored out with exit status 128: git clone -q https://github.com/OpenMined/PySyft /private/tmp/pip-install-289tqzaz/syft Check the logs for full command output.
```",hi try pip pip install tried mac get error pip install warning directory parent directory current user cache disabled please check owner directory pip may want flag warning directory parent directory current user disabled check owner directory pip may want flag revision dev running command git clone fatal unable access connect port operation timed error command exit status git clone check full command output,issue,negative,negative,neutral,neutral,negative,negative
841588787,"Hi,
Try this
pip uninstall syft
pip install git+https://github.com/OpenMined/PySyft@dev#egg=syft",hi try pip pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
841548323,"Hello @tudorcebere!
As you mentioned, there were three sleeps in the code of the program apart from the examples and tests. I was unable to remove in `src/syft/grid/duet/__init__.py` due to hinderance in tests.",hello three code program apart unable remove due hinderance,issue,negative,negative,negative,negative,negative,negative
841105643,"I have to support torchnlp to complete this notebook, but the syft team tries to implement a new way to support lib now. Thus, I close this PR and come back when the new supporting method is ready. ",support complete notebook team implement new way support thus close come back new supporting method ready,issue,positive,positive,positive,positive,positive,positive
840439495,Hi @madhavajay I was trying to follow the same schema as other messages do like [CreateInitialSetUp](https://github.com/OpenMined/PySyft/blob/c3528907b1af156d2e84cc3dd6d0fbdb7f4c0f3a/proto/grid/messages/setup_messages.proto#L8). Shall I refactor everything? ,hi trying follow schema like shall everything,issue,negative,neutral,neutral,neutral,neutral,neutral
840397497,"I'm fine with mono repo first, then this change.",fine mono first change,issue,negative,positive,positive,positive,positive,positive
840375989,"> I have some views about your serialization and de-serialization techniques. I'll add my views on slack.

Happy to hear that.",serialization add slack happy hear,issue,positive,positive,positive,positive,positive,positive
840342469,"> Great thinking. Let's discuss how we can approach this more programmatically for future lib support changes.

Yeah, what I was thing was some kind of `SklearnModelWrapper` for modular code, lets discuss it sometime soon. Thanks for the help! :) ",great thinking let discus approach programmatically future support yeah thing kind modular code discus sometime soon thanks help,issue,positive,positive,positive,positive,positive,positive
840305960,"> e lack a few features yet to do FL

Have you done with tutorial for FL with pysyft 0.3.x?",lack yet done tutorial,issue,negative,neutral,neutral,neutral,neutral,neutral
840262479,Hi @victorperezc any reason why you renamed Setup to SetUp. The first version `Setup` is correct.,hi reason setup setup first version setup correct,issue,negative,positive,positive,positive,positive,positive
840260870,"@tudorcebere This looks like it breaks the Grid unit tests. We could hold this one off until we go monorepo, or you could checkout the PyGrid repo into the root syft dir and then run the tests the same way CI does and make a PR for Grid that brings them together.",like grid unit could hold one go could root run way make grid together,issue,negative,neutral,neutral,neutral,neutral,neutral
840254584,"Hi @cgoxo Great work so far. Lets discuss how we can approach the addition of whole libraries in a more programmatic way, including the answers to some of your questions above.

> * Do we need to add methods for `np.tolist` , `np.astype` ?

Lets discuss a more programmatic approach to these on Slack.

> * The attribute `dtype` does not support while applying method `send` and it refers the error

`dtype` has to be supported. The Type is a type itself, which is different to the instance of said type.

>   `AttributeError: type object 'numpy.int16' has no attribute 'send'`
> * How to make tests for non mutable methods as the pointer variable does not take the value?

Do you have an example of a method that makes no changes and gives no return value?

> * Some methods do have a return type that are not present under `src/lib/python` such as `np.data` , `np.__array_struct__`. > Do these methods are required or need to make serde for these classes ?

Lets discuss.

",hi great work far discus approach addition whole programmatic way need add discus programmatic approach slack attribute support method send error type type different instance said type type object attribute make non mutable pointer variable take value example method return value return type present need make class discus,issue,positive,positive,positive,positive,positive,positive
840250006,"@cgoxo Great work so far, but can we discuss this before any more work is done. I would like to take a more programmatic approach to lib support rather than manually adding ops, tests, serde and return types.",great work far discus work done would like take programmatic approach support rather manually return,issue,positive,positive,positive,positive,positive,positive
840241701,"I agree with this in principal, but we will probably still need some kind of controls on the Syft library to both block ops and override which ones are available at some point. I think it would be a good idea to talk about what we expect out of a third party library API so that we can implement that for situations like this.",agree principal probably still need kind library block override available point think would good idea talk expect third party library implement like,issue,positive,positive,positive,positive,positive,positive
840240390,"@uid42 Sorry for the wait on reviewing this. I booted a K80 GPU to test this and im a little confused.
On my CPU only Laptop this fails to run because the new rules seem to cause some confusion.
On the K80 the same happens. I am running the `autofix_allowlist_test.py` on the K80 now, but it seems to be failing with nearly all the ops. I was under the impression it should be the opposite and that the GPU system should be capable of practically all ops?

Were you able to run the `pytest -m torch -n auto` tests on both CPU and GPU systems with this PR?",sorry wait booted test little confused run new seem cause confusion running failing nearly impression opposite system capable practically able run torch auto,issue,negative,negative,neutral,neutral,negative,negative
839849260,"Since I still have issues on windows, I have tried this script on ubuntu docker container and I found the same error as your. Did you found a solution to this problem?",since still tried script docker container found error found solution problem,issue,negative,neutral,neutral,neutral,neutral,neutral
839561626,"Sure!

If you have time and you know the workflow I think that would be great! You can open an issue and send it to me -- I will assign you to it.
",sure time know think would great open issue send assign,issue,positive,positive,positive,positive,positive,positive
839541931,"@gmuraru  Yeah, these were suggested by the security team 
Feature request details can be found here: https://github.com/OpenMined/PySyft/issues/5448 
I'd love to integrate these in SyMPC repos as well if you'd like that xD",yeah security team feature request found love integrate well like,issue,positive,positive,positive,positive,positive,positive
839532031,Do you know if this would also benefit SyMPC? :D - thinking of opening an issue there,know would also benefit thinking opening issue,issue,negative,neutral,neutral,neutral,neutral,neutral
836169558,"@madhavajay 

>add synk and safety scanning to our CI

That's correct. I see from https://github.com/OpenMined/PySyft/pull/5542/files we've added `safety`, do we plan on adding Snyk too?

>pin cryptography>=3.4.7

I'd say upgrade to whichever latest version `cryptography` which fixes the vuln that is mentioned. Not sure if by 3.4.7 they would've fixed that vuln yet. But yea, whichever version is vuln-free, we could pin to next IMO.",add safety scanning correct see added safety plan pin cryptography say upgrade whichever latest version cryptography vuln sure would fixed vuln yet yea whichever version could pin next,issue,positive,positive,positive,positive,positive,positive
836061526,"Hello Sir! I have a couple of doubts regarding this issue
1. Do we need to add methods for `np.tolist` , `np.astype` ?
2. The attribute `dtype` does not support while applying method `send` and it refers the error 
`AttributeError: type object 'numpy.int16' has no attribute 'send'`
3. How to make tests for non mutable methods as the pointer variable does not take the value?  
4. Some methods do have a return type that are not present under `src/lib/python` such as `np.data` , `np.__array_struct__`. Do these methods are required or need to make serde for these classes ?

Sorry for asking so many questions at once",hello sir couple regarding issue need add attribute support method send error type object attribute make non mutable pointer variable take value return type present need make class sorry many,issue,negative,neutral,neutral,neutral,neutral,neutral
835710337,"> @ArtistBanda for your flake8 and black conflict, Id suggest adding `# noqa: E203` as I think there is nothing that we can do about this formatting conflict.
> Documentation: [Ignoring flake8 errors](https://flake8.pycqa.org/en/3.1.1/user/ignoring-errors.html)
> 
> A couple of things:
> 
> 1. If you have not noticed, your mypy is also failing
> 
> ```
> src/syft/lib/python/range.py:65: error: ""range"" has no attribute ""__bool__""
> Found 1 error in 1 file (checked 379 source files)
> ```
> 
> 1. Please re-base your branch as it makes reviewing a lot simpler. (Note: After this, you will also have to make changes in the code such as adding documentation based on newer changes we have added in pre-commit)
> 
> I hope this helps!

I noticed the `mypy` failing, I am a bit stuck with that, could you help me?",flake black conflict id suggest think nothing conflict documentation flake couple also failing error range attribute found error file checked source please branch lot simpler note also make code documentation based added hope failing bit stuck could help,issue,negative,negative,negative,negative,negative,negative
835398315,"Hi, @vvmnnnkv

Yes, the first problem got fixed and as for the second one is because I didn't start a PyGrid service before trying to connect it. 

However, after I managed to launch a domain via PyGrid manually (use this command `sh run.sh --port 7000 --name bob --start_local_db`), the function in [federated created plan](https://github.com/OpenMined/PySyft/blob/dev/examples/federated-learning/model-centric/mcfl_create_plan.ipynb)

     response = grid.host_federated_training(
         model=local_model,
         client_plans={""training_plan"": train},
         client_protocols={},
         server_averaging_plan=avg_plan,
         client_config=client_config,
         server_config=server_config,
     )

returns error `BrokenPipeError: [Errno 32] Broken pipe`, which I think is because the web socket services is closed. The terminal looks like this:

![2021-05-08 15-37-58 的屏幕截图](https://user-images.githubusercontent.com/25606364/117543627-89f0e600-b015-11eb-9f24-7f4291c51eea.png)

Debug records:

     [2021-05-08 15:37:11]: 134214 DEBUG Initializing WebSocket
     [2021-05-08 15:37:11]: 134214 DEBUG Validating WebSocket request
     [2021-05-08 15:37:11]: 134214 DEBUG Attempting to upgrade connection
     [2021-05-08 15:37:11]: 134214 DEBUG WebSocket request accepted, switching protocols
     [2021-05-08 15:37:11]: 134214 DEBUG Closed WebSocket
     [2021-05-08 15:37:11]: 134214 DEBUG Failed to write closing frame -> closing socket
     [2021-05-08 15:37:11]: 134214 DEBUG Closed WebSocket

And if I connected this address in a browser, it says  `{""error"": ""This app is in sleep mode. Please undergo the initial setup first""}`. I tried to search this error online but not much useful information I got. Seems `BrokenPipeError: [Errno 32] Broken pipe` is usually due to pytorch, but I think this may be related to pygrid when starting a web socket service. I'm not familiar with web socket or socket, so I'm not quite sure where it went wrong. ",hi yes first problem got fixed second one start service trying connect however launch domain via manually use command sh port name bob function plan response train error broken pipe think web socket closed terminal like request upgrade connection request accepted switching closed write frame socket closed connected address browser error sleep mode please undergo initial setup first tried search error much useful information got broken pipe usually due think may related starting web socket service familiar web socket socket quite sure went wrong,issue,negative,positive,neutral,neutral,positive,positive
833351932,I would like to work in this one,would like work one,issue,negative,neutral,neutral,neutral,neutral,neutral
833305992,"Closing this due to inactivity, please open a new PR if you still want to fix the issue.",due inactivity please open new still want fix issue,issue,negative,positive,neutral,neutral,positive,positive
833221597,@jmaunon okay lets continue this conversation on Slack because I think the path forward with our own flake8 plugins is going to be better. I will close this for now since I think we already have this covered.,continue conversation slack think path forward flake going better close since think already covered,issue,negative,positive,positive,positive,positive,positive
833215531,@tudorcebere @AlanAboudib lets rebase this over `dev` since `0.4` is no longer in existance.,rebase dev since longer,issue,negative,neutral,neutral,neutral,neutral,neutral
833208611,"@arpitvaghela Awesome work! ❤️ I have moved the remaining issue here: https://github.com/OpenMined/PySyft/issues/5543

We are currently working on a few stability releases so if you are interested in getting involved, please join us on the Slack #engineering channel and come to one of the two weekly Syft meetings and we can discuss what we are working on and see what you might be interested in helping with. ",awesome work issue currently working stability interested getting involved please join u slack engineering channel come one two weekly discus working see might interested helping,issue,positive,positive,positive,positive,positive,positive
833147619,"@arpitvaghela CI was broken due to a seperate issue which made its way into `dev`. I have fixed it and updated this PR. In future if you see that CI is broken and you don't understand the issue please ask for help. Often PRs sit a long time because the core team sees they are broken, and the developer doesn't fix it because they don't understand the issue when its often a simple fix.",broken due issue made way dev fixed future see broken understand issue please ask help often sit long time core team broken developer fix understand issue often simple fix,issue,negative,negative,negative,negative,negative,negative
833134677,"> @jmaunon I 100% agree except our lint checks already catch these so we don't need to auto remove them. Over on the Grid side im doing this right now and its hard because theres no lint checks and there are lots of imports used for export without noqa and you have to run all the tests and hope for coverage before removing them.
> 
> In addition this could actually be bad. If a user does not add test coverage, forgets to annotate with noqa: 401 and then this check removes the line, the next time they run the lint check wont find the noqa: 401 unused import and will just assume all is well.

Yes, in PyGrid is a bit a more tricky. Actually is there where I have seen some unused imports, but I agree with you that in some cases can be bad",agree except lint already catch need auto remove grid side right hard there lint lot used export without run hope coverage removing addition could actually bad user add test coverage annotate check line next time run lint check wont find unused import assume well yes bit tricky actually seen unused agree bad,issue,negative,negative,negative,negative,negative,negative
833123994,"@jmaunon I 100% agree except our lint checks already catch these so we don't need to auto remove them. Over on the Grid side im doing this right now and its hard because theres no lint checks and there are lots of imports used for export without noqa and you have to run all the tests and hope for coverage before removing them.

In addition this could actually be bad. If a user does not add test coverage, forgets to annotate with noqa: 401 and then this check removes the line, the next time they run the lint check wont find the noqa: 401 unused import and will just assume all is well.",agree except lint already catch need auto remove grid side right hard there lint lot used export without run hope coverage removing addition could actually bad user add test coverage annotate check line next time run lint check wont find unused import assume well,issue,negative,negative,negative,negative,negative,negative
833077047,"> @jmaunon Do you think theres a downside in doing this? The existing lint checks will already fail for these conditions which gives the user an opportunity to fix them, rather than simply removing them. If someone forgets to put say # noqa: 401 after an import, this will remove it and their code will break but perhaps they won't notice?

I do not identify at this moment an important downside. The idea is that @gmuraru comments, sometime as developer we import something that is not used. The code will not fail but it is not a good practice",think there downside lint already fail user opportunity fix rather simply removing someone put say import remove code break perhaps wo notice identify moment important downside idea sometime developer import something used code fail good practice,issue,negative,positive,neutral,neutral,positive,positive
832648566,"how to I use from syft.frameworks.torch.dp import pate?
As it shows ModuleNotFoundError: No module named 'syft.frameworks",use import pate module,issue,negative,neutral,neutral,neutral,neutral,neutral
832629600,"It is mos

> 
> 
> Hello, I had the same issue and your proposition worked @madhavajay, thanks!
> But why do we have to that and why `pip install syft` alone does not work?

It is mostly because of the torch version!
We need torch version <=1.7.0 & >=1.4.0 and torchvision<=0.9 & >=0.5 .
",hello issue proposition worked thanks pip install alone work mostly torch version need torch version,issue,negative,positive,positive,positive,positive,positive
832567653,"Hi @LaplaceZhang 
Let's start with your first problem, which is `@make_plan`.
I couldn't reproduce it using fresh Ubuntu 20 + conda + py3.8 environment.

For the sake of reproducibility, I've made following Dockerfile that installs pysyft 0.5.0rc1 in conda py3.8 environment:

```
FROM ubuntu:20.04

RUN apt-get update && apt-get install -y git curl build-essential

RUN curl -O https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
RUN bash ./Miniconda3-latest-Linux-x86_64.sh -b
ENV PATH=$PATH:/root/miniconda3/bin
RUN conda create -n syft -y python=3.8

WORKDIR /openmined/pysyft
RUN git clone https://github.com/openmined/pysyft .
RUN git checkout 0.5.0rc1

SHELL [""conda"", ""run"", ""-n"", ""syft"", ""/bin/sh"", ""-c""]
RUN pip install jupyter notebook
RUN pip install -Ur requirements.txt
RUN pip install -e .
``` 

Now if I build this image (`docker build -t bug .`) and then execute the notebook in it:
`docker run --rm bug conda run -n syft jupyter nbconvert --to notebook --execute examples/federated-learning/model-centric/mcfl_create_plan.ipynb` I see that it successfully passes the cell where the plan is built and fails on grid connect.

So perhaps there's a problem with your environment?
Could you post `pip freeze`?

",hi let start first problem could reproduce fresh environment sake reproducibility made following environment run update install git curl run curl run bash path run create run git clone run git shell run run pip install notebook run pip install run pip install build image docker build bug execute notebook docker run bug run notebook execute see successfully cell plan built grid connect perhaps problem environment could post pip freeze,issue,negative,positive,positive,positive,positive,positive
832442537,"I'd like to take up this issue. 

Q: @security-team As report generated is highly dependent on versions of the packages, I think it would be a good idea to run these commands with minimum versions of the packages we support? 
I see following as the output of `safety check`

```
+==============================================================================+
| REPORT                                                                       |
| checked 178 packages, using free DB (updated once a month)                   |
+============================+===========+==========================+==========+
| package                    | installed | affected                 | ID       |
+============================+===========+==========================+==========+
| urllib3                    | 1.26.3    | >=1.26.0,<1.26.4         | 40014    |
| pyyaml                     | 5.3.1     | <5.4                     | 39611    |
| pip                        | 21.0.1    | <21.1                    | 40291    |
| pillow                     | 7.2.0     | <8.0.1                   | 40264    |
| pillow                     | 7.2.0     | <8.1.0                   | 40265    |
| pillow                     | 7.2.0     | <8.1.0                   | 40270    |
| pillow                     | 7.2.0     | <8.1.0                   | 40271    |
| pillow                     | 7.2.0     | <8.1.1                   | 40266    |
| pillow                     | 7.2.0     | <8.1.1                   | 40272    |
| pillow                     | 7.2.0     | <8.1.1                   | 40273    |
| pillow                     | 7.2.0     | <8.1.1                   | 40274    |
| pillow                     | 7.2.0     | <8.1.1                   | 40275    |
| pillow                     | 7.2.0     | <8.1.2                   | 40263    |
| pillow                     | 7.2.0     | <8.1.2                   | 40267    |
| pillow                     | 7.2.0     | <8.1.2                   | 40268    |
| pillow                     | 7.2.0     | <8.1.2                   | 40269    |
+==============================================================================+

```",like take issue report highly dependent think would good idea run minimum support see following output safety check report checked free month package affected id pip pillow pillow pillow pillow pillow pillow pillow pillow pillow pillow pillow pillow pillow,issue,positive,positive,positive,positive,positive,positive
832390563,"The original PR actually never ran the tests on MacOS:
https://pipelines.actions.githubusercontent.com/tPFNPqeRbvWdN0L3FU84cUvH4mGjAPQ3yYz8CFZWN08ePzUDwG/_apis/pipelines/1/runs/11244/signedlogcontent/30?urlExpires=2021-05-05T03%3A32%3A49.3947978Z&urlSigningMethod=HMACV1&urlSignature=gtsKxvjjm%2FUo6ouATDjvfN20dsfg6M3RGaO%2FUaFPw8M%3D

```
2021-04-20T08:50:44.4358540Z Failed to load xgboost. XGBoost Library (libxgboost.dylib) could not be loaded.
2021-04-20T08:50:44.4359540Z Likely causes:
2021-04-20T08:50:44.4362060Z   * OpenMP runtime is not installed (vcomp140.dll or libgomp-1.dll for Windows, libomp.dylib for Mac OSX, libgomp.so for Linux and other UNIX-like OSes). Mac OSX users: Run `brew install libomp` to install OpenMP runtime.
2021-04-20T08:50:44.4365050Z   * You are running 32-bit Python on a 64-bit OS
2021-04-20T08:50:44.4367390Z Error message(s): ['dlopen(/Users/runner/hostedtoolcache/Python/3.6.13/x64/lib/python3.6/site-packages/xgboost/lib/libxgboost.dylib, 6): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n  Referenced from: /Users/runner/hostedtoolcache/Python/3.6.13/x64/lib/python3.6/site-packages/xgboost/lib/libxgboost.dylib\n  Reason: image not found']
```

The reason why these tests skip is for instances where there are mismatches or issues installing especially across different python versions etc so its important to actually check they ran.

",original actually never ran load library could loaded likely mac mac run brew install install running python o error message library loaded reason image found reason skip especially across different python important actually check ran,issue,negative,positive,positive,positive,positive,positive
831820463,"Hey @madhavajay! Just wanted to confirm, is it the case that this issue is no longer open to new contributors?",hey confirm case issue longer open new,issue,negative,positive,neutral,neutral,positive,positive
831783088,"@madhavajay do you need any extra features in this PR? Imo this is ready to be merged, and we can make issues for additional features (auto inferring shapes, performance, local execution, `model.to_symodule()`, etc.) ",need extra ready make additional auto performance local execution,issue,negative,positive,neutral,neutral,positive,positive
831749111,"@ArtistBanda for your flake8 and black conflict, Id suggest adding `# noqa: E203` as I think there is nothing that we can do about this formatting conflict. 
Documentation: [Ignoring flake8 errors](https://flake8.pycqa.org/en/3.1.1/user/ignoring-errors.html)

A couple of things: 
1. If you have not noticed, your mypy is also failing 
```
src/syft/lib/python/range.py:65: error: ""range"" has no attribute ""__bool__""
Found 1 error in 1 file (checked 379 source files)
```

2. Please re-base your branch as it makes reviewing a lot simpler. (Note: After this, you will also have to make changes in the code such as adding documentation based on newer changes we have added in pre-commit)

I hope this helps!",flake black conflict id suggest think nothing conflict documentation flake couple also failing error range attribute found error file checked source please branch lot simpler note also make code documentation based added hope,issue,negative,negative,negative,negative,negative,negative
831717123,"Hi @Lone-Survivor2020 we are working on Multi-worker functionality and examples for PyGrid, and yes it will be runnable without Jupyter Notebooks. We recently published an updated video of PyGrid 0.5 here: https://www.youtube.com/watch?v=IW4Tt4qBpHo",hi working functionality yes runnable without recently video,issue,negative,neutral,neutral,neutral,neutral,neutral
831706747,"@hwrdtm Just to understand you would like us to?
- pin cryptography>=3.4.7
- add synk and safety scanning to our CI",understand would like u pin cryptography add safety scanning,issue,positive,neutral,neutral,neutral,neutral,neutral
831701843,"> @jmaunon Do you think theres a downside in doing this? The existing lint checks will already fail for these conditions which gives the user an opportunity to fix them, rather than simply removing them. If someone forgets to put say # noqa: 401 after an import, this will remove it and their code will break but perhaps they won't notice?

This tool will automatically remove all the unused imports (maybe some IDEs already do this) and all the unused variables. I think the downside is that it takes some time to run?",think there downside lint already fail user opportunity fix rather simply removing someone put say import remove code break perhaps wo notice tool automatically remove unused maybe ides already unused think downside time run,issue,negative,negative,negative,negative,negative,negative
831652149,"@jmaunon Do you think theres a downside in doing this? The existing lint checks will already fail for these conditions which gives the user an opportunity to fix them, rather than simply removing them. If someone forgets to put say # noqa: 401 after an import, this will remove it and their code will break but perhaps they won't notice?",think there downside lint already fail user opportunity fix rather simply removing someone put say import remove code break perhaps wo notice,issue,negative,negative,negative,negative,negative,negative
831026094,Please also let me know how to handle the `flake8` and `black` conflict.,please also let know handle flake black conflict,issue,negative,negative,negative,negative,negative,negative
831025498,I have tested some of the CPython tests after serialization and deserialization to check the validity of the code and it works fine. @tudorcebere. ,tested serialization check validity code work fine,issue,negative,positive,positive,positive,positive,positive
831024807,The PR is complete from my side @tudorcebere @madhavajay . If there is anything more required please let me know.,complete side anything please let know,issue,negative,positive,neutral,neutral,positive,positive
830928092,"Hi @madhavajay, I'm new to the community and I'd like to be assigned to this issue if possible :)",hi new community like assigned issue possible,issue,negative,positive,neutral,neutral,positive,positive
830843550,"Hi, have you solved this issue? I met the same problem here, but it returns `BrokenPipeError: [Errno 32] Broken pipe`. The full screenshot is like this:

![2021-05-02 18-15-13 的屏幕截图](https://user-images.githubusercontent.com/25606364/116821598-74da0a00-ab72-11eb-8307-1bec67688ba8.png)

I googled this error online, but this error usually caused by torch.DataLoader which is not related to my issue. I think this may be caused by socket service closed, but I don't know why the PyGrid socket is disconnected. The screenshot of the terminal is like this:

![2021-05-02 18-32-17 的屏幕截图](https://user-images.githubusercontent.com/25606364/116822094-d3a08300-ab74-11eb-8b41-f0ebc07e82e9.png)


Appreciate if you know how to fix this.
 
***

And as for this error you met, this may because the `json.loads(self.ws.recv())`, you can try to add this argument `json.loads(self.ws.recv(), strict=False)` to see if your problem resolved. Hope this can help you.
",hi issue met problem broken pipe full like error error usually related issue think may socket service closed know socket disconnected terminal like appreciate know fix error met may try add argument see problem resolved hope help,issue,negative,negative,neutral,neutral,negative,negative
830808572,"I will use torch, thanks for help",use torch thanks help,issue,positive,positive,positive,positive,positive,positive
830782344,"Hello, is this still of interest? Can I try to take a stab at it?",hello still interest try take stab,issue,negative,neutral,neutral,neutral,neutral,neutral
829268100,"a few thoughts:
- Do we we want to get rid of the old Sy.Module?
- It would be really cool to have a `sy_module = my_torch_module.to_symodule()` API
- as mentioned by Andrew it would be great if we could infer `input_size`
- We should refactor plan.execute_locally and make it such that it does need to serialize and deserialize the plan, as execution of SyModule is very slow for larger models right now
",want get rid old would really cool would great could infer make need serialize plan execution slow right,issue,positive,positive,positive,positive,positive,positive
829125958,@marcalph  Is this bug resolved? I am facing the same issue.,bug resolved facing issue,issue,negative,neutral,neutral,neutral,neutral,neutral
828798860,"## Add another question about how to host the grid network

I met the `ConnectionRefusedError: [Errno 111] Connection refused` error when I attempt to use `ModelCentricFLClient` to set client and host a network via `syft.grid.client.client.connect()`. The screenshot looks like this:
![2021-04-28 22-14-29 的屏幕截图](https://user-images.githubusercontent.com/25606364/116473807-92a42800-a86f-11eb-90d1-025a51d42ba0.png)
I tried to set the client manually following a tutorial in the `./PySyft/examples/pygrid/homomorphic-encryption/` but it also returns 

      ConnectionError: HTTPConnectionPool(host='localhost', port=7000): Max retries exceeded with url: /users/login (Caused by 
      NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fd48657af40>: Failed to establish a new connection: 
      [Errno 111] Connection refused'))

I'm not sure if I need to run Pygrid in a docker container to host the network, or I can simply run it in the notebook. ",add another question host grid network met connection error attempt use set client host network via like tried set client manually following tutorial also object establish new connection connection sure need run docker container host network simply run notebook,issue,negative,positive,positive,positive,positive,positive
828623194,"i think that can help 
``
!pip install syft==0.2.9 
``
![image](https://user-images.githubusercontent.com/54450458/116443903-7f379380-a854-11eb-96e5-09317b1144b3.png)
",think help pip install image,issue,negative,neutral,neutral,neutral,neutral,neutral
828426204,"Dear madhavajay:
There is a problem after I connected.  The Error is: `Task <Task pending name='Task-20' coro=<WebRTCConnection.send_sync_message() running at /opt/anaconda3/lib/python3.8/site-packages/typeguard/__init__.py:944>> got Future <Future pending> attached to a different loop`

Owner have uploaded data by  `data_features_pointer = data_features.send(duet, searchable=True)`, but Server can't get the data which Owner has been sent. 

The owner code is here:
```
import torch

import syft as sy

sy.VERBOSE = False

duet = sy.launch_duet(network_url=""http://ec2-18-216-8-163.us-east-2.compute.amazonaws.com:5000"")

data_features = torch.tensor([1, 2, 3, 4, 5])

data_features.tag('#tag_data')

data_features.describe(""This is a test of features' data."")

data_features_pointer = data_features.send(duet, searchable=True)
```
The server code:

```
import syft as sy

sy.VERBOSE = False

duet = sy.join_duet(target_id='626aed2eca9c1aa9b73e4fd02ad874dc', network_url=""http://ec2-18-216-8-163.us-east-2.compute.amazonaws.com:5000"")

duet.store

# Error Appear Here
```

The server and owner have appeared 'connected' when connecting each other. My coding environment is one laptop with two Jupyter files generated by Anaconda, is that the event loop conflict causes this problem?",dear problem connected error task task pending running got future future pending attached different loop owner data duet server ca get data owner sent owner code import torch import false duet test data duet server code import false duet error appear server owner environment one two anaconda event loop conflict problem,issue,negative,negative,negative,negative,negative,negative
828245328,@vvmnnnkv Can we get these changes added to the `tests/syft/core/fl/model-centric/mcfl_create_execute_plan_test.py` since its a combination of both notebooks?,get added since combination,issue,negative,neutral,neutral,neutral,neutral,neutral
827616292,"Fixed in https://github.com/OpenMined/PySyft/pull/5520
Note: this error doesn't affect FL model from being hosted or later execution of training plan (in execute plan notenook).
It's just the part of notebook that demonstrates low-level interaction with pygrid and it had outdated code of how model is serialized.",fixed note error affect model later execution training plan execute plan part notebook interaction outdated code model,issue,negative,negative,negative,negative,negative,negative
827409628,"Oh I see. wish I had known earlier coz I spent quite some time working on this. Anyways, thanks for informing @madhavajay ",oh see wish known coz spent quite time working anyways thanks,issue,positive,positive,neutral,neutral,positive,positive
827350831,"@Koukyosyumei awesome work, I love the benchmarks! Looks like `arrow` for the win!",awesome work love like arrow win,issue,positive,positive,positive,positive,positive,positive
827348573,"Hi @vsquareg!

Really nice work! As far as I've understood, you are solving the remote type to see if it's a not implemented after executing. This is nice, but it basically requires you to have permission on doing that all the time.

We can diverge from how python behaves and maybe call the add operation for example if `__add__` is called and solve the state machine that python uses for addition. Ping me for a small call in slack to figure it out, just to be sure we are on the same page. 
",hi really nice work far understood remote type see nice basically permission time diverge python maybe call add operation example solve state machine python addition ping small call slack figure sure page,issue,positive,positive,positive,positive,positive,positive
827343305,"Hi @avinsit123 This issue has been assigned to @tudorcebere because theres a few issues we want to double check with the implementation and how it fits into our existing AST code.

Sorry, about that.
",hi issue assigned there want double check implementation ast code sorry,issue,negative,negative,negative,negative,negative,negative
827339591,"Hi @dnabanita7, sadly, the problem is quite deep in our AST architecture right now. Namely, we can't have an object reference in our AST to support this kind of ops. We are working on this, but it's blocked right now. I'll close this for now and we can open it back when we have obj references in the AST. ",hi sadly problem quite deep ast architecture right namely ca object reference ast support kind working blocked right close open back ast,issue,negative,positive,neutral,neutral,positive,positive
827336463,"Hi @cgoxo!

We got other plans in terms of refactoring klass.py. Thank you for your help, but we are not 100% on how to proceed, but when we'll do it, we'll add you as a contributor. 👍🏼 

Thank you for your interest, ping me on slack if you want help on picking up new issues (holidays are over) 💯 ",hi got thank help proceed add contributor thank interest ping slack want help new,issue,positive,positive,positive,positive,positive,positive
827332528,"Hi @RishabhDahale this issue is that the current code works, and your code change breaks the remote model using pointers.

```diff
- if ""torch.nn"" in full_name_with_qualname(klass=type(value)):
+ if isinstance(value, torch.nn.Module):
```


What we probably need, is to have two checks:
`if is normal torch module` or `if is syft pointer klass`.

The reason why this ticket exists is because checking some strings in the class name is not a very safe way to code.
But its needed for these two examples:

```
assert ""torch.nn"" in ""torch.nn.Conv2""
assert ""torch.nn"" in ""syft.proxy.torch.nn.Conv2Pointer""
```

As you can see both need to work and they both have `torch.nn` in them.",hi issue current code work code change remote model value value probably need two normal torch module pointer reason ticket class name safe way code two assert assert see need work,issue,positive,positive,positive,positive,positive,positive
827014197,"Awesome work! Before jumping and implementing this, we might want to discuss how to add custom serde methods to certain types in a scalable way before coding it. Can't wait to see this one live!",awesome work might want discus add custom certain scalable way ca wait see one live,issue,positive,positive,positive,positive,positive,positive
827001516,"Hi! 0.2.x hit EOL, closing this as we no longer support it. ",hi hit longer support,issue,negative,neutral,neutral,neutral,neutral,neutral
826991043,"Have you tried the same with an alternate version of PySyft?

like 0.3.0dev etc..?

@YasirArfat32",tried alternate version like dev,issue,negative,neutral,neutral,neutral,neutral,neutral
826969680,"Having a similar issue at the same point in the notebook

Any solutions yet ? @YasirArfat32",similar issue point notebook yet,issue,negative,neutral,neutral,neutral,neutral,neutral
826311447,"@JozefKondas seems like you are running the wrong code for this version. Support for hooks is deprecated in `0.3.0` .  Try running the below code to create a vm and have a root user. 
```python
import syft as sy
bob_vm = sy.VirtualMachine(name=""bob"")
bob_root = bob_vm.get_root_client()
ptr = bob_root.torch.Tensor([1,2,3])
ptr = ptr.get()
print(ptr)
```
Also, syft no longer supports Tensorflow.",like running wrong code version support try running code create root user python import bob print also longer,issue,negative,negative,negative,negative,negative,negative
826281364,"Which version of Syft are you using? If it is 0.2.x, switch to 0.5. PySyft has been completed revamped after 0.2 and there is no use of hooks anymore. Also, support for tensorflow was discontinued.",version switch use also support,issue,negative,neutral,neutral,neutral,neutral,neutral
826249683,"> I think #5265 could be used as a good reference. 
> Is this already been worked or can I create a PR?

It's slightly different than #5265, anyway it's already assigned so I'd suggest you to either talk to Tudor or take up some other issue. ",think could used good reference already worked create slightly different anyway already assigned suggest either talk take issue,issue,positive,positive,positive,positive,positive,positive
826126592,"I think #5265 could be used as a good reference. 
Is this already been worked or can I create a PR?",think could used good reference already worked create,issue,positive,positive,positive,positive,positive,positive
826112004,I'd suggest changing label to GSoC to remove confusion.,suggest label remove confusion,issue,negative,neutral,neutral,neutral,neutral,neutral
826061741,"Hello @tudorcebere !
If there is any other method to shift let me know",hello method shift let know,issue,negative,neutral,neutral,neutral,neutral,neutral
824593118,"We already do support `numpy.ndarray` and all the methods you have added in are for that so I believe serialization and de-serialization are not required, If there is another data type which you want to add support for, then you need to work on serializing and de-serializing it. 

The next step would be to write unit tests to check if all the methods you have added support for run as expected on the virtual machine. Check out `PySyft/tests/syft/lib/` for more. 

Here in `xgboost` you can see how we have tested `.predict()` method. I believe you will have to do something similar, just try creating some kind of `.json` to keep the code clean (like `torchvision`) 


Also, I'll suggest you to **bring your branch up to date** using git efficiency, I am not sure what is wrong but I see unrelated files as different as well, dm me on slack if you are still facing this issue!",already support added believe serialization another data type want add support need work next step would write unit check added support run virtual machine check see tested method believe something similar try kind keep code clean like also suggest bring branch date git efficiency sure wrong see unrelated different well slack still facing issue,issue,positive,positive,positive,positive,positive,positive
824578593,"Hello @Param-29 I have commented the methods which hinder privacy. 
Just want to know as of now do I have to make changes under `array.py` for serialize/deserialize methods?",hello hinder privacy want know make,issue,negative,neutral,neutral,neutral,neutral,neutral
823916160,"Hi! 0.2 hit EOL with the release of 0.5.0rc1, no issues/PRs are going to target this specific version anymore, but checkout 0.5.0rc1, as it's close to feature parity with 0.2.x.",hi hit release going target specific version close feature parity,issue,negative,neutral,neutral,neutral,neutral,neutral
823888142,@jmaunon I spoke to @cereallarceny and I believe we will be deleting the readthedocs.io profile so we can close this.,spoke believe profile close,issue,negative,neutral,neutral,neutral,neutral,neutral
823887016,"@Jasopaum hey man, long time no speak, I didn't see this while I was on break. Do you want to join the syft Slack channel and discuss, just ping @tudorcebere.",hey man long time speak see break want join slack channel discus ping,issue,negative,negative,neutral,neutral,negative,negative
823886271,During discussion with @koenvanderveen we thought maybe an `Alias` type for all of the Torch Shaped types would be a good way to go.,discussion thought maybe alias type torch shaped would good way go,issue,negative,positive,positive,positive,positive,positive
823861989,"We will be removing readthedocs, so ill close this issue.",removing ill close issue,issue,negative,negative,negative,negative,negative,negative
823480298,"I was able to sort this one out.  This is because I was using a URL for the `url` parameter that does not refer to any service using port `5000` in my local machine. Note that the value for `url` has to be a URL that is used by a PyGrid Domain service, which if anybody wants to know how to set up can refer to the [PyGird repo](https://github.com/OpenMined/PyGrid).

I ended up hosting a PyGrid Domain service on a remote server and then passing the URL of that service as the `url` parameter, and now it's working just fine.",able sort one parameter refer service port local machine note value used domain service anybody know set refer ended hosting domain service remote server passing service parameter working fine,issue,negative,positive,positive,positive,positive,positive
823329766,"Hi, I did create a PR for the same issue a few months ago but it was closed due to some reason. I would like to work on this PR and try out the method that you have suggested. Also, you can refer to the conversation we had previously in this PR #5117 . ",hi create issue ago closed due reason would like work try method also refer conversation previously,issue,positive,negative,negative,negative,negative,negative
823309483,"Do it, I agree. We'll be using Gitbook or something else. Definitely not
RTD.

On Tue, Apr 20, 2021 at 8:37 AM Madhava Jay ***@***.***>
wrote:

> @cereallarceny <https://github.com/cereallarceny> Says we will not be
> using https://pysyft.readthedocs.io anymore, so we should delete it.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/4995#issuecomment-823050836>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AAJ44CUA2CAZSBE7QDQ7SBDTJUVLVANCNFSM4V2BUNEA>
> .
>
",agree something else definitely tue jay wrote delete reply directly view,issue,positive,positive,neutral,neutral,positive,positive
822930943,"@tudorcebere
I fixed a bug in the actor-critic notebook and solved most of the errors.  
The notebooks seem to work in my local environment. 
Could you find other issues within RL notebooks?",fixed bug notebook seem work local environment could find within,issue,negative,positive,neutral,neutral,positive,positive
822614968,"Hey @madhavajay I would like to work on this and help you guys create Integration Tests for Duet. However had 2 doubts before I would create a PR. 

1.  Should we also create Tests like the ones created by Koen in `basic_plans.ipynb` or `Plan API.ipynb`?
2. Also, what would we compare in case of the MLP Integration Test - the local and remote model parameters or the actual and predicted image values.

Thanks",hey would like work help create integration duet however would create also create like plan also would compare case integration test local remote model actual image thanks,issue,positive,positive,neutral,neutral,positive,positive
822397092,"No, you could just comment the line which you do not want to add, but do keep them so that we could know which methods were commented for security reasons",could comment line want add keep could know security,issue,negative,neutral,neutral,neutral,neutral,neutral
822396746,"Hi, I decided not to pursue it further due to shortage of time. Feel free to continue on working with these changes.",hi decided pursue due shortage time feel free continue working,issue,negative,positive,positive,positive,positive,positive
822354775,"Thank you for the response.
So, should I make a seperate `allowlist.py` for numpy library and comment out the methods which hinders data privacy?",thank response make library comment data privacy,issue,negative,neutral,neutral,neutral,neutral,neutral
822319509,"Awesome work @Koukyosyumei!

One small comment, try (at least from now on) to make meaningful commits/commit messages. (I can teach you how to use rebase on rewriting history if you don't want to keep everything tidy)",awesome work one small comment try least make meaningful teach use rebase history want keep everything tidy,issue,positive,positive,positive,positive,positive,positive
822285305,"I played a bit with the solution and I think there is a bug in it. I wasn't aware that you can't test the existence of subfields in proto when they are basic types like int/bool. Everyday we learn something new. The nice solutions would be to rollback to the optional field trick or to leave it as it is.

Currently, this implementation fails for a number of use cases:

```
import syft as sy

value = sy.lib.python.Slice(start=1, stop=5)
value_proto = sy.serialize(obj=value, to_proto=True)
print(value_proto.start)
print(value_proto.step)
print(value_proto.stop)

slice = sy.lib.python.Slice._proto2object(value_proto)

print([1,2,3,4][slice.upcast()])
```

I'll close this until we update the version of protoc to officially support `optional`, solving this problem.",bit solution think bug aware ca test existence proto basic like everyday learn something new nice would rollback optional field trick leave currently implementation number use import value print print print slice print close update version officially support optional problem,issue,positive,positive,positive,positive,positive,positive
822247105,"PATE analysis still works with 0.2.9 but the module doesn't seem to be incorporated in 0.3 anymore. The entire folder structure is missing and there is no dp folder anywhere else.

Was that intentionally be removed?",pate analysis still work module seem incorporated entire folder structure missing folder anywhere else intentionally removed,issue,negative,negative,neutral,neutral,negative,negative
822229407,"Hi @cgoxo, great job. 

Some of the methods you have added should not be allowed to keep the data private, so I'd suggest giving this a good thought before adding a method/class to `ast`. 

Example (dtype): 

File: `PySyft/src/syft/lib/torch/allowlist.py`
```
# allowlist[""torch.Tensor.dtype""] = SECURITY WARNING: DO NOT ADD TO ALLOW LIST YET - talk to TRASK
```

Hope this helps you get a better insight!",hi great job added keep data private suggest giving good thought ast example file security warning add allow list yet talk hope get better insight,issue,positive,positive,positive,positive,positive,positive
821604180,"Thanks a lot!
Your feedback is very very useful. I share your opinion and this is part of the work that must be done!

I close this issue because this was the goal

",thanks lot feedback useful share opinion part work must done close issue goal,issue,positive,positive,positive,positive,positive,positive
821076384,"
Hey Team, I recently found PySyft/PyGrid and (upon request) wanted to share some of my feelings and findings and the things I came across. This is mostly a log of my steps, so see it as a first-time-user-report. I'm a user that is skilled in full stack and data science and conceptual (not hands-on) federated learning.

### Progress log
* In order of appearance, it looks like the latest PySyft install is broken. I'm assuming this is known, but as a newbie it set me back a bit.
* I loved the titles of the course sessions (courses.openmined.org) and wanted to check some of them out. I was disappointed to see that you can follow the course linearly only (at least I didn't manage to skip anything), because I'm familiar with the basics already. It was a lot of clicking and waiting to get to the good part. IMO, the courses are weak as courses, but _incredible_ as the backbone of documentation.
* Then: which tutorial to start with? PySyft tutorials seemed like the best option. 
  * Starting with: `examples/api/start.ipynb`. It's alphabetically the first with `api` and his has `start` in there, so maybe it's number one? It worked out of the box so that was very nice. It was also a bit complicated and dry and after running it's only a couple of days later that I understand what happened :) It would be really cool if the flow of this notebook is documented in a diagram!
  * Next, I found the `private-ai-series/duet_basics` Owner-Scientist dual example. This one is *AMAZING*. I loved how it worked out of the box and solves the problem why I landed with PySyft in the first place. This is my personal interest, so this should have been my first tutorials, but maybe others feel differently. 
    * Minor details on the tutorial: The very first commands `duet = sy.launch_duet(loopback=True)` would be improved with a comment on how to change it for a collaborative duet. I believe something like `duet = sy.launch_duet(""SOME_SECRET"", loopback=True)` would do the trick
  * For my use case, I'm really interested in a use case beyond peer-to-peer and for multiple clients in the network. I realised that's what PyGrid is for. So I went to check out the `examples/pygrid` tutorials.
    * This is where things got hairy. I first went to the `PyGrid` repository, but those examples were out of date and rather minimal. 
      * The imports were specific for `syft==0.3.0` and I had to update them by looking through the code (see Slack). 
      * The tutorial starts with authentication, but there's no documentation on how to create that first user. I used a manual curl request and to my surprise it worked `curl --request POST http://localhost:7000/users --header 'Content-Type: application/json' --data-raw '{""email"": ""admin@email.com"", ""password"": ""pwd123”}’`.
      * There are 3 different ports used (5000, 5001, 7000) in the scientist/owner notebook. I can see how different users might be on different ports, but explanation would be nice :)
      * The `Create a new users` block failed. My hunch was that the permissions to create users with certain roles are updated because the first user is created but not the second. I stopped here, because I didn't feel like going more into the depths of the code. 
    * I moved to PySyft tutorials in the PyGrid folder. I wanted to start with the basics. 
      * I started with the `user` folder, but I got the same problem as above, so quit this pretty quickly. And my Hackathon was over.
  * In the Duet basic example I quickly replaced the sample age data for fake patient data that is produced by our internal application. I showed the example to others and people were very enthusiastic. So I definitely got a go signal to continue exploring if we can use PySyft and collaborate. Will keep you posted :) 

### General thoughts about dependencies
I am in general a little confused about the relationship between PyGrid and PySyft. PyGrid seems to be a server that handles PySyft requests, full fledged with user and permission management. It has a dependency on PySyft but I'm not sure if that's necessary, i.e. if it's doing syfty things, or if it's just delegating generic peer-to-peer connections. Conversely, I'm not quite sure to what extend PySyft is modelled towards PyGrid or if PyGrid could easily be exchanged for 'some other access management tool'. 


### Concluding remarks
So, these are my thoughts. Please feel free to move this report elsewhere, because it might be cluttering the ticket. Don't feel obliged to answer the questions I have here, I'm just pointing out that these are the questions a first time user might have. Thanks for your work on this, I'm going to continue diving into the OpenMined libraries :) ",hey team recently found upon request share came across mostly log see user skilled full stack data science conceptual learning progress log order appearance like latest install broken assuming known set back bit course session check disappointed see follow course linearly least manage skip anything familiar already lot waiting get good part weak backbone documentation tutorial start like best option starting alphabetically first start maybe number one worked box nice also bit complicated dry running couple day later understand would really cool flow notebook diagram next found dual example one amazing worked box problem landed first place personal interest first maybe feel differently minor tutorial first duet would comment change collaborative duet believe something like duet would trick use case really interested use case beyond multiple network went check got hairy first went repository date rather minimal specific update looking code see slack tutorial authentication documentation create first user used manual curl request surprise worked curl request post header password different used notebook see different might different explanation would nice create new block hunch create certain first user second stopped feel like going code folder start user folder got problem quit pretty quickly duet basic example quickly sample age data fake patient data produced internal application example people enthusiastic definitely got go signal continue exploring use collaborate keep posted general general little confused relationship server full user permission management dependency sure necessary generic conversely quite sure extend towards could easily access management tool concluding please feel free move report elsewhere might ticket feel obliged answer pointing first time user might thanks work going continue diving,issue,positive,positive,positive,positive,positive,positive
820622149,"@marcalph , yes please, open as many PR as you need.

Many of you have contributed to audit tutorials. I will try open the associated issues in order to fix them.

Thanks a lot for your effort!",yes please open many need many audit try open associated order fix thanks lot effort,issue,positive,positive,positive,positive,positive,positive
820572989,"> @jmaunon An update. I've updated the Audit doc as well.
> 
> ## NOTE: This list also includes notebooks present in the courses repo.
> * [x]  federated_learning
>   
>   * duet_basics: Good
>   * duet_fl: Good
>   * duet_iris: Good
>   * (courses) duet_mnist: Bad (throws error while training). (covered in #5429 )
> * [x]  (courses) split-nn
>   
>   * splitnn/basic: Good
>   * splitnn/advanced: Good
>   * multilimb-splitnn/basic: Good
>   * multilimb-splitnn/advanced: Decent (throws error while training).
>   
>   ```
>   [2021-04-09T18:56:15.964802+0530][CRITICAL][logger]][18795] Request to access data length rejected.
>   [2021-04-09T18:56:15.965163+0530][CRITICAL][logger]][18795] Request to access data length rejected.
>   
>   ---------------------------------------------------------------------------
>   Exception                                 Traceback (most recent call last)
>   ~/miniconda2/envs/pysyft/lib/python3.9/site-packages/syft/ast/klass.py in __len__(self)
>     249                 if data_len is None:
>   --> 250                     raise Exception
>     251 
>   
>   Exception: 
>   
>   During handling of the above exception, another exception occurred:
>   
>   ValueError                                Traceback (most recent call last)
>   ~/miniconda2/envs/pysyft/lib/python3.9/site-packages/syft/ast/klass.py in __iter__(self)
>     222             try:
>   --> 223                 data_len = self.__len__()
>     224             except Exception:
>   
>   ~/miniconda2/envs/pysyft/lib/python3.9/site-packages/syft/ast/klass.py in __len__(self)
>     253             except Exception:
>   --> 254                 traceback_and_raise(
>     255                     ValueError(""Request to access data length rejected."")
>   
>   ~/miniconda2/envs/pysyft/lib/python3.9/site-packages/syft/logger.py in traceback_and_raise(e, verbose)
>      60         e = Exception(e)
>   ---> 61     raise e
>      62 
>   
>   ValueError: Request to access data length rejected.
>   
>   During handling of the above exception, another exception occurred:
>   
>   ValueError                                Traceback (most recent call last)
>   <ipython-input-15-230656f1092f> in <module>
>       3     train_total = 0
>       4 
>   ----> 5     for in1, in2, label in zip(dl_1, dl_2, dl_local):
>       6         opt1.zero_grad()
>       7         opt2.zero_grad()
>   
>   ~/miniconda2/envs/pysyft/lib/python3.9/site-packages/syft/ast/klass.py in __iter__(self)
>     223                 data_len = self.__len__()
>     224             except Exception:
>   --> 225                 traceback_and_raise(
>     226                     ValueError(""Request to access data length rejected."")
>     227                 )
>   
>   ~/miniconda2/envs/pysyft/lib/python3.9/site-packages/syft/logger.py in traceback_and_raise(e, verbose)
>      59     if not issubclass(type(e), Exception):
>      60         e = Exception(e)
>   ---> 61     raise e
>      62 
>      63 
>   
>   ValueError: Request to access data length rejected.
>   ```
>   
>   
>   
>   * concepts-definition-code: Good
>   * attack-on-splitnn: Good
> * [ ]  (course) cryptography
>   
>   * ciphers: Good

Thanks a lot!!",update audit doc well note list also present good good good bad error training covered good good good decent error training critical logger request access data length critical logger request access data length exception recent call last self none raise exception exception handling exception another exception recent call last self try except exception self except exception request access data length verbose exception raise request access data length handling exception another exception recent call last module label zip self except exception request access data length verbose type exception exception raise request access data length good good course cryptography good thanks lot,issue,positive,positive,positive,positive,positive,positive
820540970,Just my 2 cents - we absolutely want to get there. I'd say biggest blocker (Among several) is encrypted autograd,absolutely want get say biggest blocker among several,issue,negative,positive,neutral,neutral,positive,positive
820413977,The error still is ``Attribute error: type object Normalize has no attribute mean`` which is true,error still attribute error type object normalize attribute mean true,issue,negative,positive,neutral,neutral,positive,positive
819663026,"Note: suggested fix is to add new table for FLProcess-Worker authorization.
When worker successfully authenticates for given FL process, we add record to this table.
Then in cycle request, we should check if worker_id is authorized for requested FL process.",note fix add new table authorization worker successfully given process add record table cycle request check authorized process,issue,negative,positive,positive,positive,positive,positive
819615526,"@jmaunon you are right, it had to do with the use of GPU as a default, I've fixed things accordingly...
Would you recommend I open a separate PR for each tutorial?",right use default fixed accordingly would recommend open separate tutorial,issue,negative,positive,positive,positive,positive,positive
819450065,"`black` and `flake8` are in conflict here 
```python
flake8...................................................................Failed
- hook id: flake8
- exit code: 1

tests/syft/lib/python/range/range_test.py:201:31: E203 whitespace before ':'
        self.assertEqual(x[idx : idx + 1][0], a + idx)
                              ^
tests/syft/lib/python/range/range_test.py:219:31: E203 whitespace before ':'
        self.assertEqual(x[idx : idx + 1][0], a + idx)
                              ^
tests/syft/lib/python/range/range_test.py:238:31: E203 whitespace before ':'
        self.assertEqual(x[idx : idx + 1][0], a + (idx * c))
                              ^
tests/syft/lib/python/range/range_test.py:257:31: E203 whitespace before ':'
        self.assertEqual(x[idx : idx + 1][0], a + (idx * c))
                              ^
4     E203 whitespace before ':'
4
```

If this is fixed, it is changed back by `black`",black flake conflict python flake hook id flake exit code fixed back black,issue,negative,negative,neutral,neutral,negative,negative
818721928,"
@arpitvaghela This error usually means you have some issue in your `__init__` of the library you are trying to work with. I have made a set of changes and the tests pass now. I have also attached `.txt` version of it below

[__init__.txt](https://github.com/OpenMined/PySyft/files/6303946/__init__.txt)

**PS: if you get an error in `root_client.pandas`, its always a bug hiding in `__init__`** :)

```
(py387) param@param:~/git-projects/PySyft/tests/syft/lib/pandas$ pytest pandas_test.py 
========================== test session starts ===========================
platform linux -- Python 3.8.6, pytest-6.2.2, py-1.10.0, pluggy-0.13.1 -- /home/param/anaconda3/envs/py387/bin/python
cachedir: .pytest_cache
rootdir: /home/param/git-projects/PySyft, configfile: setup.cfg
plugins: typeguard-2.11.1, cov-2.11.1
collected 5 items                                                        

pandas_test.py::test_pandas PASSED                                 [ 20%]
pandas_test.py::test_pd_categoriesdtype PASSED                     [ 40%]
pandas_test.py::test_pd_categories PASSED                          [ 60%]
pandas_test.py::test_slice_dataframe PASSED                        [ 80%]
pandas_test.py::test_pandas_json_normalize PASSED                  [100%]

=========================== 5 passed in 1.47s ============================

```

Let me know if that helped!
",error usually issue library trying work made set pas also attached version get error always bug param param test session platform python collected let know,issue,negative,negative,negative,negative,negative,negative
818170745,I am getting `AttributeError: 'Globals' object has no attribute 'pandas'` when running the tests. Can someone help me out with this error?,getting object attribute running someone help error,issue,negative,neutral,neutral,neutral,neutral,neutral
817886562,"1. pydp
    - PyDP_Syft_Data_Owner.ipynb: Bad

        PyDP_Syft_Data_Scientist.ipynb : Bad

        - *duet.requests.add_handler()*
            - It has a TypeError for the argument '*name*'.
            - I tried to comment out the *name* argument, and it worked well.

        ```python
        duet.requests.add_handler(
            name=""private_mean"",
            action=""accept"",
            print_local=True
        )
        duet.requests.handlers
        ---------------------------------------------------------------------------
        TypeError                                 Traceback (most recent call last)
        <ipython-input-24-e5c48006c244> in <module>
        ----> 1 duet.requests.add_handler(
              2     name=""private_mean"",
              3     action=""accept"",
              4     print_local=True
              5 )

        TypeError: add_handler() got an unexpected keyword argument 'name'
        ```

        - I found that the *name* argument was deleted as it had an overlapped usage with the *tag* (See the issue: [https://github.com/OpenMined/PySyft/issues/5102](https://github.com/OpenMined/PySyft/issues/5102)).

            So, now the *name* argument does not exist anymore in the method. 

            ```python
            syft.core.node.domain.client.add_handler()
            def add_handler(
                    self,
                    action: str,
                    print_local: bool = False,
                    log_local: bool = False,
                    tags: Optional[List[str]] = None,
                    timeout_secs: int = -1,
                    element_quota: Optional[int] = None,
                ) -> None:
                    handler_opts = self._validate_options(
                        id=UID(),
                        action=action,
                        print_local=print_local,
                        log_local=log_local,
                        tags=tags,
                        timeout_secs=timeout_secs,
                        element_quota=element_quota,
                    )

                    self._update_handler(handler_opts, keep=True)
            ```

        - I may delete the *name* argument from the tutorials or include the *name* argument in *add_handler()*.
        - In my PR, I'll take the second option since the argument seems to be needed.

2. opacus
    - Opacus_Syft_Data_Owner.ipynb: Good
    - Opacus_Syft_Data_Scientist.ipynb: Good",bad bad argument name tried comment name argument worked well python accept recent call last module accept got unexpected argument found name argument usage tag see issue name argument exist method python self action bool false bool false optional list none optional none none may delete name argument include name argument take second option since argument good good,issue,negative,negative,neutral,neutral,negative,negative
817379125,"@mistryishan25 , the idea is just to know if tutorials are working and are fully understandable",idea know working fully understandable,issue,negative,neutral,neutral,neutral,neutral,neutral
817262344,"> Hello, I had the same issue and your proposition worked @madhavajay, thanks!
> But why do we have to that and why `pip install syft` alone does not work?

Maybe it is because the packge installed by pip is an old version which is different from https://github.com/OpenMined/PySyft@dev#egg=syft",hello issue proposition worked thanks pip install alone work maybe pip old version different,issue,negative,positive,positive,positive,positive,positive
817199863,Hey @tudorcebere  I was looking into this and noticed that there are quite a few used in the benchmark tests. I assume that those are run via the GH Actions. Quite confused about what to do with them. Should I just leave them there?,hey looking quite used assume run via quite confused leave,issue,negative,negative,negative,negative,negative,negative
817173124,"Could I get a little more info about the issue?

",could get little issue,issue,negative,negative,negative,negative,negative,negative
817159929,I would like work on pandas tutorial documentation. ,would like work tutorial documentation,issue,negative,neutral,neutral,neutral,neutral,neutral
817102777,"I think supporting gym is better, and I guess it makes the integration test work because we don't need asyncio sleeping.
I created a new PR #5457  ",think supporting gym better guess integration test work need sleeping new,issue,positive,positive,positive,positive,positive,positive
817096734,"Hello, I had the same issue and your proposition worked @madhavajay, thanks!
But why do we have to that and why `pip install syft` alone does not work?",hello issue proposition worked thanks pip install alone work,issue,negative,positive,positive,positive,positive,positive
816799897,"@jmaunon An update. I've updated the Audit doc as well.

NOTE: This list also includes notebooks present in the courses repo.
---

- [x] federated_learning
    - duet_basics: Good
    - duet_fl: Good
    - duet_iris: Good
    - (courses) duet_mnist: Bad (throws error while training). (covered in #5429 )
- [x] (courses) split-nn
    - splitnn/basic: Good
    - splitnn/advanced: Good
    - multilimb-splitnn/basic: Good
    - multilimb-splitnn/advanced: Decent (throws error while training).
    ```
  [2021-04-09T18:56:15.964802+0530][CRITICAL][logger]][18795] Request to access data length rejected.
  [2021-04-09T18:56:15.965163+0530][CRITICAL][logger]][18795] Request to access data length rejected.

  ---------------------------------------------------------------------------
  Exception                                 Traceback (most recent call last)
  ~/miniconda2/envs/pysyft/lib/python3.9/site-packages/syft/ast/klass.py in __len__(self)
      249                 if data_len is None:
  --> 250                     raise Exception
      251 

  Exception: 

  During handling of the above exception, another exception occurred:

  ValueError                                Traceback (most recent call last)
  ~/miniconda2/envs/pysyft/lib/python3.9/site-packages/syft/ast/klass.py in __iter__(self)
      222             try:
  --> 223                 data_len = self.__len__()
      224             except Exception:

  ~/miniconda2/envs/pysyft/lib/python3.9/site-packages/syft/ast/klass.py in __len__(self)
      253             except Exception:
  --> 254                 traceback_and_raise(
      255                     ValueError(""Request to access data length rejected."")

  ~/miniconda2/envs/pysyft/lib/python3.9/site-packages/syft/logger.py in traceback_and_raise(e, verbose)
       60         e = Exception(e)
  ---> 61     raise e
       62 

  ValueError: Request to access data length rejected.

  During handling of the above exception, another exception occurred:

  ValueError                                Traceback (most recent call last)
  <ipython-input-15-230656f1092f> in <module>
        3     train_total = 0
        4 
  ----> 5     for in1, in2, label in zip(dl_1, dl_2, dl_local):
        6         opt1.zero_grad()
        7         opt2.zero_grad()

  ~/miniconda2/envs/pysyft/lib/python3.9/site-packages/syft/ast/klass.py in __iter__(self)
      223                 data_len = self.__len__()
      224             except Exception:
  --> 225                 traceback_and_raise(
      226                     ValueError(""Request to access data length rejected."")
      227                 )

  ~/miniconda2/envs/pysyft/lib/python3.9/site-packages/syft/logger.py in traceback_and_raise(e, verbose)
       59     if not issubclass(type(e), Exception):
       60         e = Exception(e)
  ---> 61     raise e
       62 
       63 

  ValueError: Request to access data length rejected.
  ```


    - concepts-definition-code: Good
    - attack-on-splitnn: Good
   
- [ ] (course) cryptography
    - ciphers: Good",update audit doc well note list also present good good good bad error training covered good good good decent error training critical logger request access data length critical logger request access data length exception recent call last self none raise exception exception handling exception another exception recent call last self try except exception self except exception request access data length verbose exception raise request access data length handling exception another exception recent call last module label zip self except exception request access data length verbose type exception exception raise request access data length good good course cryptography good,issue,positive,positive,positive,positive,positive,positive
816657237,"Hi @arpitvaghela, the team is on their 2-week off, they should be back by (15 April). 
I cannot see the complete error stack, it would be helpful if you could send that. Also as I see you have added in the new `.proto3`, I'd suggest quickly sending and getting these types to and from the virtual machine, **also called as serde tests** to quickly check if thats working right, initially that is what causes issues. 

Hope this helps!",hi team back see complete error stack would helpful could send also see added new suggest quickly sending getting virtual machine also quickly check thats working right initially hope,issue,negative,positive,positive,positive,positive,positive
816582826,"> @IMVector did you solve this?

Thanks，I got the release code,and I successfully ran it.",solve got release code successfully ran,issue,positive,positive,positive,positive,positive,positive
816491336,"The issue said to add another job and that threw me off. I agree having a single job with extra steps makes more sense. All tests pass now, performance benchmarks included.",issue said add another job threw agree single job extra sense pas performance included,issue,negative,negative,neutral,neutral,negative,negative
816362868,"https://blog.openmined.org/upgrade-to-federated-learning-in-10-lines/
I refered to this blog, but the author doesn't seem to realize parallel training and model aggregation.Is there any API in pysyft  can help us to realize it?",author seem realize parallel training model help u realize,issue,negative,neutral,neutral,neutral,neutral,neutral
815916153,"Yes, I would say that `MNIST` had priority. I will try open new issues related to this.
I though that some of these tutorials were integrated in our CI system. Could you check it please? ",yes would say priority try open new related though system could check please,issue,positive,positive,neutral,neutral,positive,positive
815869632,"@vsquareg merged your branch, will pick up work from there. Thank you!",branch pick work thank,issue,negative,neutral,neutral,neutral,neutral,neutral
815847859,"> > Hey @ArtistBanda!
> > I did some work on this earlier (but never got to create a PR): [vsquareg/range-support1 ](https://github.com/vsquareg/PySyft/tree/range-support1). Range support is added, just the tests are pending.
> > You can take a look, if that's useful.
> 
> This looks great, you can add changes to this PR if you want.

I'm not sure I have the permission to do that. If you want to incorporate those changes, you can merge the branch into yours.",hey work never got create range support added pending take look useful great add want sure permission want incorporate merge branch,issue,positive,positive,positive,positive,positive,positive
815829146,"> Hey @ArtistBanda!
> 
> I did some work on this earlier (but never got to create a PR): [vsquareg/range-support1 ](https://github.com/vsquareg/PySyft/tree/range-support1). Range support is added, just the tests are pending.
> 
> You can take a look, if that's useful.

This looks great, you can add changes to this PR if you want.",hey work never got create range support added pending take look useful great add want,issue,positive,positive,positive,positive,positive,positive
815493655,"Hey @ArtistBanda!

I did some work on this earlier (but never got to create a PR): [vsquareg/range-support1 ](https://github.com/vsquareg/PySyft/tree/range-support1). Range support is added, just the tests are pending.

You can take a look, if that's useful.",hey work never got create range support added pending take look useful,issue,positive,positive,positive,positive,positive,positive
815393821,I'm unable to reproduce this on the current dev branch. Could you confirm if this still requires any attention?,unable reproduce current dev branch could confirm still attention,issue,negative,negative,negative,negative,negative,negative
815161479,"@tudorcebere I have added 24 `pd.Categorical` methods which didn't require additional types and doesn't result in an `Exception`. However the tests are failing when calling `__len__`, can u please take a look. 
The tests are in `test/syft/lib/pandas/categorical_test.py` 

![Screenshot from 2021-04-08 00-33-13](https://user-images.githubusercontent.com/50636734/113921077-323b4100-9803-11eb-85bc-019d5280d8d1.png)
",added require additional result exception however failing calling please take look,issue,negative,neutral,neutral,neutral,neutral,neutral
815031123,"Long time no see 👋 
I can try to do that! The only problem I see for the moment is that if I try to do
```
data_ptr = data.send(duet)
duet.store[""my_fav_plan""].fix_inputs({""data"": data_ptr})
```
the `{""data"": data_ptr}` arg will be serialized with a `syft.proxy.torch.TensorPointer` inside of it, which we don't know how to serde, right?",long time see try problem see moment try duet data data inside know right,issue,negative,positive,positive,positive,positive,positive
814973454,"@tudorcebere I will create a WIP PR, would like to have in-progress feedback.",create would like feedback,issue,positive,neutral,neutral,neutral,neutral,neutral
814712118,"All tutorials work as expected after installing TenSEAL.

Since TenSEAL is not a PySyft dependency, it's likely that it won't be in the user's env. For this reason, I believe it should be made explicit that installing the package is necessary and explain how to do it, e.g. `pip install tenseal`.",work since dependency likely wo user reason believe made explicit package necessary explain pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
814663026,Hi! I can start working on this issue today. Should I just post the results on this thread or is there a better place to submit them?,hi start working issue today post thread better place submit,issue,negative,positive,positive,positive,positive,positive
814623632,Hi! I'd like to work on this issue as a part of applying to GSoC!,hi like work issue part,issue,negative,neutral,neutral,neutral,neutral,neutral
814404028,"@jmaunon  sry for the delay, finished and duplicated/updated the google doc accordingly
I'd like to continue working on this as I feel comfortable resolving ""issues"" (apart from the lightning version of mnist where I must confess I'm at loss). 
Am I correct assuming mnist has priority?",delay finished doc accordingly like continue working feel comfortable apart lightning version must confess loss correct assuming priority,issue,negative,positive,positive,positive,positive,positive
813874323,"Duet:I found when I ran the example that it stopped in the second DUET connection creation process. Console print 'Connecting...' or '..waiting for partner to connect...' and didn't go on.
",duet found ran example stopped second duet connection creation process console print waiting partner connect go,issue,negative,neutral,neutral,neutral,neutral,neutral
813592918,"@tudorcebere could you recheck this PR?
The benchmark should be added in another PR - only to keep each PR at a decent level such that people would review it!",could recheck added another keep decent level people would review,issue,negative,positive,positive,positive,positive,positive
813544385,"Hey Can I work on this issue as a part of gsoc application process?
",hey work issue part application process,issue,negative,neutral,neutral,neutral,neutral,neutral
813422426,@tudorcebere I think this resolves the issue. About the test cases could you guide me a bit more?,think issue test could guide bit,issue,negative,neutral,neutral,neutral,neutral,neutral
813416353,"Hi @jmaunon , can I work on this? I'm going through the Private AI Series right now as well, so it should be fairly quick. I'll ~~open a PR~~ the doc soon and keep updating the progress here!",hi work going private ai series right well fairly quick doc soon keep progress,issue,positive,positive,positive,positive,positive,positive
813342397,@tudorcebere please give me a brief of what should be moved. That would be a great help,please give brief would great help,issue,positive,positive,positive,positive,positive,positive
813236537,"Hello @jmaunon.

For the VM I think that if we use ```get_root_client``` - not the ```get_client``` it should work.
For the other one, I need to look into it.",hello think use work one need look,issue,negative,neutral,neutral,neutral,neutral,neutral
813117611,"@dimasquest , thanks a lot for your feedback! 
I have tried to reproduce the tutorial because I colaborated  in this one  and I was familiar. I do not get your errors, I have been capable of installing `pysyft` and `sympc` (separately, if I try to install just `syft` I get your 2nd error)

In any case, I am not capable of running any of tutorials for the following:
* VMs: I get `Request to access data length rejected.`
* Duet: (After some  minor but required modifications) I get `UnknownPrivateException`


@gmuraru , are you aware of this? we could open an issue for fixing but I do not know where the erros come from.

I attach the corresponding errors.

![VMs](https://user-images.githubusercontent.com/16245436/113524567-d9c03580-95af-11eb-90e1-8c7d55926baf.png)

-----
![Duet-error](https://user-images.githubusercontent.com/16245436/113524566-d9279f00-95af-11eb-9ff9-d04a85912d80.png)

",thanks lot feedback tried reproduce tutorial one familiar get capable separately try install get error case capable running following get request access data length duet minor get aware could open issue fixing know come attach corresponding,issue,positive,positive,positive,positive,positive,positive
812872130,"all tutorials for smpc fail with exactly 2 types of issues:

1.  `AttributeError: type object 'Tensor' has no attribute 'fft' ` when using the latest version of syft
2. `ModuleNotFoundError: No module named 'sympc'` when using syft 0.3.0.post0.dev1280+gce2510e65 (as suggested in https://openmined.slack.com/archives/C6EEFN3A8/p1616892669121500)

the latter is explained by 
```
sy.load(""sympc"")

[2021-04-03T15:22:08.608322+0100][CRITICAL][logger]][1168755] Unable to load package support for: sympc. No module named 'sympc'

```

So looks Red to me unfortunately at this moment ",fail exactly type object attribute latest version module latter critical logger unable load package support module red unfortunately moment,issue,negative,negative,neutral,neutral,negative,negative
812868655,"From a quick round of importing and running the notebooks, VM notebook does not seem to be compatible with the most recent version of syft

pip install git+https://github.com/OpenMined/PySyft@dev#egg=syft allows to import syft without fft error (which has been brought up in slack multiple times), however, it just ends up failing to import sympc

checking the others ones as well",quick round running notebook seem compatible recent version pip install import without error brought slack multiple time however failing import well,issue,negative,positive,neutral,neutral,positive,positive
812458528,"Hey @arpitvaghela, I think you should be able to send a PR to the repo. I can create a new branch and merge the two once the maintainers have had a chance to look at it.",hey think able send create new branch merge two chance look,issue,negative,positive,positive,positive,positive,positive
812452779,"@tudorcebere could you take a look to see if this pattern for gc strategies seems better,",could take look see pattern better,issue,negative,positive,positive,positive,positive,positive
812434930,"Really nice work, congrats! :rocket: ",really nice work rocket,issue,negative,positive,positive,positive,positive,positive
812343413,"I'd like to work on this as I've already started to look into it, I'll open a PR later ~~today!~~ in the meantime, I'll be updating progress here
- [x] cli
Good : need adding a readme
- [x] dcgan 
decent : typos,  works fine but broken on gpu
```
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-46-802e9ff2bad1> in <module>
     71             created_img = netG(fixed_noise).get(request_block=True)
     72             vutils.save_image(
---> 73                             created_img.detach(),
     74                             f""{config['outf']}/fake_samples_{epoch}_{batch_idx}.png"",
     75                             normalize=True,

AttributeError: 'NoneType' object has no attribute 'detach'
```  

- [x] fast_neural_style
Bad : notebooks are empty, also needs a readme
- [x] information_flow_demo_split_nn 
Good
- [x] mnist
Decent : broken!! (on gpu)
```---------------------------------------------------------------------------
UnknownPrivateException                   Traceback (most recent call last)
<ipython-input-22-653de4faaab9> in <module>
      7     print(f""Epoch: {epoch}"")
      8     # remote training on model with remote_torch
----> 9     train(model, remote_torch, train_loader_ptr, optimizer, epoch, args, train_data_length)
     10     # local testing on model with local torch
     11     test_local(model, torch, test_loader, test_data_length)

<ipython-input-18-c6153a198b5b> in train(model, torch_ref, train_loader, optimizer, epoch, args, train_data_length)
     17         optimizer.step()
     18         loss_item = loss.item()
---> 19         train_loss = loss_item.resolve_pointer_type()
     20         if batch_idx % args[""log_interval""] == 0:
     21             local_loss = None

~/projects/PySyft/src/syft/ast/klass.py in _resolve_pointer_type(self)
     64 
     65     # the path to the underlying type. It has to live in the AST
---> 66     real_type_path = self.client.send_immediate_msg_with_reply(msg=cmd).type_path
     67     new_pointer = self.client.lib_ast.query(real_type_path).pointer_type(
     68         client=self.client, id_at_location=id_at_location

~/projects/PySyft/src/syft/core/node/common/client.py in send_immediate_msg_with_reply(self, msg, route_index)
    229                 exception = exception_msg.exception_type(exception_msg.exception_msg)
    230                 error(str(exception))
--> 231                 traceback_and_raise(exception)
    232             else:
    233                 return response.message

~/projects/PySyft/src/syft/logger.py in traceback_and_raise(e, verbose)
     59     if not issubclass(type(e), Exception):
     60         e = Exception(e)
---> 61     raise e
     62 
     63 

UnknownPrivateException: UnknownPrivateException has been triggered.
```
- [x] mnist_lightning 
Bad : broken!
```---------------------------------------------------------------------------
ModuleNotFoundError                       Traceback (most recent call last)
<ipython-input-2-74f22e0c7363> in <module>
      5 from torch import nn
      6 from pytorch_lightning import Trainer
----> 7 from pytorch_lightning.experimental.plugins.secure.pysyft import SyLightningModule
      8 from pytorch_lightning.utilities.imports import is_syft_initialized
      9 from pytorch_lightning.metrics import Accuracy

ModuleNotFoundError: No module named 'pytorch_lightning.experimental'
```
- [x] reinforcement_learning
Bad : empty
- [x] snli
Bad : empty
- [x] super_resolution
Good  
- [x] time_seq_prediction
Bad: empty
- [x] vae
Good 
- [x] word_language_model
Bad: empty",like work already look open later progress good need decent work fine broken recent call last module epoch object attribute bad empty also need good decent broken recent call last module print epoch epoch remote training model train model epoch local testing model local torch model torch train model epoch none self path underlying type live ast self exception error exception exception else return verbose type exception exception raise triggered bad broken recent call last module torch import import trainer import import import accuracy module bad empty bad empty good bad empty good bad empty,issue,negative,negative,neutral,neutral,negative,negative
812330470,"Hey @stoic-signs, can u add me as a collaborator ? I have certain ideas to merge the test together ",hey add collaborator certain merge test together,issue,negative,positive,positive,positive,positive,positive
812218242,"@felixfaisal @ashkan-pirmani @marcalph I have created an issue per folder in PySyft, in that way you and rest of community can work more efficient. 
I close this issue, but please, continue with your work!, just asign to yourself any of the new issues.

Your feedback is very very useful for us",issue per folder way rest community work efficient close issue please continue work new feedback useful u,issue,positive,positive,positive,positive,positive,positive
811790607,"This should be ready, I was not sure what should be the type of a message so I just added sy.Serializable as sy.serialize is the only function used in the auxiliary function for the message integrity check.",ready sure type message added function used auxiliary function message integrity check,issue,positive,positive,positive,positive,positive,positive
811775014,"@Param-29 I went ahead and finished this off for now, its all working. Thanks for your help. 👍🏼 ",went ahead finished working thanks help,issue,positive,positive,positive,positive,positive,positive
811748831,"This is close to ready! :fire: :fire: 

Please run `pre-commit run --all-files` and address the changes requested there. This is looking pretty solid.",close ready fire fire please run run address looking pretty solid,issue,positive,positive,positive,positive,positive,positive
811642196,"@madhavajay  Yup! It's [this one](https://github.com/OpenMined/PySyft/blob/3551725d6749309bb2ffb60ec6b5566318a7361b/src/syft/grid/client/grid_connection.py#L17). We set it [here](https://github.com/OpenMined/PySyft/blob/d358e191874c4f5e331ebaa1150b4c9c6e3d64b8/src/syft/grid/client/client.py#L60). It's expected by the user to set the proper connection type _(choosing the proper communication protocol they want to use to connect with PyGrid. eg: HTTP, Websocket, WebRTC, etc.)_

The problem is: when it was developed, we still had that concept of the node types in mind, so it was designed to be created dynamically, extending the proper node client (Network, Domain, Device, and VirtualMachine) and using the proper Connection (HTTP, Websocket, WebRTC ... ) in order to give support to all client types and node connections using a single function: `connect`. 

_PS : Since we'll be removing the node types architecture from the next versions, we'll probably refactor this client as well ._",one set user set proper connection type choosing proper communication protocol want use connect problem still concept node mind designed dynamically extending proper node client network domain device proper connection order give support client node single function connect since removing node architecture next probably client well,issue,positive,negative,neutral,neutral,negative,negative
811565587,"@IonesioJunior this one is weird, somehow the code is already in there but now it doesnt like it!?
I can't find any reference to this DomainClient type with its `.conn` attribute though so for now iv just disabled the warning by setting the type to `Any` but it would be nice to fix this properly. Do you know where that type with `.conn` exists?",one weird somehow code already doesnt like ca find reference type attribute though disabled warning setting type would nice fix properly know type,issue,negative,negative,neutral,neutral,negative,negative
811554969,@IonesioJunior it would be good to get your feedback on this and if its going in the right direction.,would good get feedback going right direction,issue,negative,positive,positive,positive,positive,positive
811554635,@apzl if it checks for existence before allowing it to be set then how will it get set the first time?,existence set get set first time,issue,negative,positive,positive,positive,positive,positive
811442278,"Hi all,

I'd be glad to contribute alongside. Let's start with the obvious for syft, according to the google doc we have : 
- [ ] cli/
- [ ] dcgan/
- [ ] fast_neural_style/
- [ ] information_flow_demo_splitnn_tenseal
- [ ] mnist/
- [ ] reinforcement_learning/
- [ ] snli/
- [ ] super_resolution/
- [ ] time_sequence_prediction/
- [ ] vae/
- [ ] word_language_model/



@felixfaisal @ashkan-pirmani 
Can you indicate which tutorials you guys have been dealing with so far (DM me over the openmined slack maybe?) I'll update the task list accordingly and it will then be used to keep track of the tutorials audit, also we could link easily related issues/PR.
 
EDIT : formatting",hi glad contribute alongside let start obvious according doc indicate dealing far slack maybe update task list accordingly used keep track audit also could link easily related edit,issue,positive,positive,positive,positive,positive,positive
811114846,"Hey, about this:

> Allows to build a more user-readable source code (#5359 (comment))

Can you explain me how you would like to improve that with the current (or future?) changes?",hey build source code comment explain would like improve current future,issue,positive,neutral,neutral,neutral,neutral,neutral
811076482,"@jmaunon That's a great idea, Actually I was finding it hard to collaborate, If we could bring this up in Slack or other in communication medium, that'd be pretty useful. I've only listed out the notebooks inside duet examples, And reviewed all the readmes under that. I've not reviewed the notebooks itself. ",great idea actually finding hard collaborate could bring slack communication medium pretty useful listed inside duet,issue,positive,positive,positive,positive,positive,positive
811055317,"Would really appreciate some thoughts and discussions on this before proceeding to other Action types. 

Regarding whether or not this is even required, and if there's a better approach for implementation. ",would really appreciate proceeding action regarding whether even better approach implementation,issue,positive,positive,positive,positive,positive,positive
810969999,"@felixfaisal @ashkan-pirmani , which is the status of your tasks? More people want to contribute. 
It might be more efficient if we split this issue in more specific ones (maybe one per folder...) but we did not have time",status people want contribute might efficient split issue specific maybe one per folder time,issue,negative,neutral,neutral,neutral,neutral,neutral
810848959,"Yeah, maybe it would be worth making an Alias like: Generic Syft Type or something like that?",yeah maybe would worth making alias like generic type something like,issue,positive,positive,positive,positive,positive,positive
810816458,"I would like to work on this issue
",would like work issue,issue,negative,neutral,neutral,neutral,neutral,neutral
810555973,Is someone actively working on this? I would like to work on that,someone actively working would like work,issue,positive,negative,negative,negative,negative,negative
810451087,"Looks pretty solid!

Before merging/jumping into doing a bit more complicated stuff, would you mind benchmarking this? Like, create 2-3 GC-intensive functions and then profile a client (would love to see even a duet test) with our new GC heuristics, including our current one. ",pretty solid bit complicated stuff would mind like create profile client would love see even duet test new current one,issue,positive,positive,neutral,neutral,positive,positive
810360515,"Hey, I noticed there hasn't been much progress here and that the other PRs were closed. Could I work on it?",hey much progress closed could work,issue,negative,positive,neutral,neutral,positive,positive
810341860,Hey! I did this because I figured out it would speed CI. We will post a new issue in a few days on separating in a fancier way our dependencies based on what libs you are using. :) ,hey figured would speed post new issue day separating fancier way based,issue,negative,positive,positive,positive,positive,positive
810152527,"> Hi @ArtistBanda!
> 
> For all the changes that are made, please add a test on them and double-check that wrapping iterators is not pointless (double wrapping might occur). Down below in the AST I am wrapping the iterator so it might not be useful. Keep going, you are on the right track.

Well for resolving `syft.lib.python.Any` in the `create_python_ast` for methods like `__getitem__()` and `pop()`, what should it be replaced with?
Should `syft.lib.python.Any` be replaced with 
```
UnionGenerator[
    ""syft.lib.python.Int"",
    ""syft.lib.python.Float"",
    ""syft.lib.python.String"",
    ""torch.nn.Parameter"",
    ""torch.Tensor"",
],
```",hi made please add test wrapping pointless double wrapping might occur ast wrapping might useful keep going right track well like pop,issue,positive,positive,neutral,neutral,positive,positive
810133066,"@LaRiffle I know, it was actually implemented by you if I remember correctly, I liked the idea and I think that we can do a more customizable version of this for our next release. :) ",know actually remember correctly idea think version next release,issue,negative,neutral,neutral,neutral,neutral,neutral
810129174,"I'll merge this as it is so we won't stack open PRs that are good to go. Indeed, it's quite hard to demonstrate the behaviour without wrapping something internally in our codebase to trace the call. I'll think about this and post and issue if I find something good enough.",merge wo stack open good go indeed quite hard demonstrate behaviour without wrapping something internally trace call think post issue find something good enough,issue,positive,positive,positive,positive,positive,positive
810038468,"Hi @razvanmatisan :wave:,

Please open a PR before actually starting to work on it (be sure to check `allow edits from maintainers`) so we can give continuous feedback on your work. :book:

Thanks for your interest in Syft! :raised_hands: ",hi wave please open actually starting work sure check allow give continuous feedback work book thanks interest,issue,positive,positive,positive,positive,positive,positive
810022224,"Hi @teo-milea! :wave: 

Please open a PR before starting to work on this so we can give feedback as you go. :1st_place_medal: 

Thanks for your interest in Syft! :100: ",hi wave please open starting work give feedback go thanks interest,issue,positive,positive,neutral,neutral,positive,positive
809990622,"Due to inactivity, I'll close this PR. If you are interested in working on this, please open a fresh PR @karynaur.

Thank you!",due inactivity close interested working please open fresh thank,issue,positive,positive,positive,positive,positive,positive
809977619,"Hi @ArtistBanda!

For all the changes that are made, please add a test on them and double-check that wrapping iterators is not pointless (double wrapping might occur). Down below in the AST I am wrapping the iterator so it might not be useful. Keep going, you are on the right track. :smile: 


",hi made please add test wrapping pointless double wrapping might occur ast wrapping might useful keep going right track smile,issue,positive,positive,positive,positive,positive,positive
809963978,I have added docstrings and inline comments wherever required in the `src/syft/ast` module except for `klass.py`. I am thinking of creating an another PR for it. All other methods of `syft/ast` have dosctrings. Some still fail the pydocstyle and darglint. ,added wherever module except thinking another still fail,issue,negative,negative,negative,negative,negative,negative
809918445,"`test_load_errors` is testing the `sy.load` for errors raised within the logger for invalid calls.

This requires #5397 to be merged first. ",testing raised within logger invalid first,issue,negative,positive,positive,positive,positive,positive
809842863,"duet_examples are extremely flaky, most of the times tests fail is due to `ds_proc` being hanged. Should be covered within the PR for this.",extremely flaky time fail due covered within,issue,negative,negative,negative,negative,negative,negative
809842011,"@tudorcebere All data structures with more than one iterator return type were rewrapping it (Dict, List, ...). Since `wrap_iterator(.)` was a common fn call, this should fix them all.

Working on a test to verify this behaviour, but those don't seem very elegant. Do you have anything in mind?",data one return type list since common call fix working test verify behaviour seem elegant anything mind,issue,negative,positive,neutral,neutral,positive,positive
809177475,"Awesome work @vsquareg!

As @madhavajay said, could you introduce a PR that checks this behaviour? Could you double-check any other existing data structures for this behaviour as well? (you can make a separate PR for other structures so we won't keep this opened for too long)",awesome work said could introduce behaviour could data behaviour well make separate wo keep long,issue,positive,positive,positive,positive,positive,positive
809162176,@vsquareg is it possible to show this in a test so that we don't regress this behaviour again later?,possible show test regress behaviour later,issue,negative,neutral,neutral,neutral,neutral,neutral
809159777,"@cgoxo Can I suggest you update your `protoc`. If you have a recent version you won't get the generated output diff because they stabilised the output back around 3.14 i think. Also 3.15 introduced optionals. We currently install and compile the protobufs in CI with the latest build and since we are in control of compiling and shipping them we will likely be doing that with our PyPI releases.

https://github.com/protocolbuffers/protobuf/releases",suggest update recent version wo get output output back around think also currently install compile latest build since control shipping likely,issue,negative,positive,neutral,neutral,positive,positive
809109002,"> I have made the changes you suggested, for running hello-world notebooks, I am facing 2 issues
> You can find the code and the issue in jupyter-notebook `Issue 4850`
> 
> Errors:
> 
> ```
> TypeError: 'Expression' object is not iterable
> ```
> 
> Expression object is not expected to be iterable
> 
The issue here is that you are trying to construct 2 x `petlib.ec.EcPt` but the allowlist return type is set to a single one.

```python
allowlist[""zksk.utils.make_generators""] = ""petlib.ec.EcPt""
```

It seems that the return type of `make_generators` is actually a list even if you only ask for one.
```
>>> x = zksk.utils.make_generators(num=1, seed=42)
>>> type(x)
<class 'list'>
```

I have also noticed that the protobuf hasn't been regenerated which is causing issues with the `serde` of the EcPt type. I would highly suggest writing a few light tests which just create, send and get all of these types you are supporting to make sure that all works first.",made running facing find code issue issue object iterable expression object iterable issue trying construct return type set single one python return type actually list even ask one type class also causing type would highly suggest writing light create send get supporting make sure work first,issue,positive,positive,positive,positive,positive,positive
809091386,"I see, so non-optional libraries follow one kind of template and optional ones another kind. ",see follow one kind template optional another kind,issue,positive,positive,positive,positive,positive,positive
809089880,@vsquareg some libraries are not optional dependencies yet like `torch` while others are. What exactly is the issue here?,optional yet like torch exactly issue,issue,negative,positive,positive,positive,positive,positive
809072910,"I think you need to rebase to have the latest ```dev``` changes. If you look in the modified files (the tab from the PR) there is a large number of modified files - which should not be touched by the ```build_proto.sh```.
Also, after running ```build_proto.sh```, add only the one specific for the session - not all the files.",think need rebase latest dev look tab large number touched also running add one specific session,issue,negative,positive,positive,positive,positive,positive
808956033,Hmm...I think you changed more files than required (you could add only the protocol file for session and not the other files),think could add protocol file session,issue,negative,neutral,neutral,neutral,neutral,neutral
808939966,"Do we want to perform the same change with the messages themselves or just protobuffers representing them? I am currently working on unifying the messages, but I am not sure how, for example approach the constructor of `AssociationRequestAPI` which looks like this:
```
    def __init__(self, send: Callable):
        super().__init__(
            create_msg=SendAssociationRequestMessage,
            get_msg=GetAssociationRequestMessage,
            get_all_msg=GetAssociationRequestsMessage,
            delete_msg=DeleteAssociationRequestMessage,
            send=send,
            response_key=AssociationRequestAPI.response_key,
           )
```
        
if they are to be unified, how would this be reflected in this constructor?",want perform change currently working sure example approach constructor like self send callable super unified would reflected constructor,issue,positive,positive,positive,positive,positive,positive
808928191,"To support older versions of torchvision (methods with only `PIL.Image.Image` as argument type), I believe we need to load the PIL library by default. This is required for both, to modify the tests to pass and during runtime (since `PIL.Image.Image` would have to be used anyway). 

Or are there any other workarounds I could look at?",support older argument type believe need load library default modify pas since would used anyway could look,issue,negative,positive,positive,positive,positive,positive
808909125,"I have resolved most of the issues in the file ``enum.py`` and  ``globals.py``. The report on ``enum.py`` is as follows:
```
(nabanita07) (base) nabanita07@nabanita07:~/PySyft/src/syft/ast$ interrogate -P -ignore-private enum.py
RESULT: PASSED (minimum: 80.0%, actual: 83.3%)
Generated badge to /home/nabanita07/PySyft/src/syft/ast/nore-private
(nabanita07) (base) nabanita07@nabanita07:~/PySyft/src/syft/ast$ pydocstyle --convention=google enum.py
enum.py:1 at module level:
        D100: Missing docstring in public module
(nabanita07) (base) nabanita07@nabanita07:~/PySyft/src/syft/ast$ darglint enum.py
enum.py:__call__:91: DAR101: - **kwargs
enum.py:__call__:91: DAR101: - *args
enum.py:add_path:101: DAR101: - **kwargs
enum.py:add_path:101: DAR101: - *args
```
The report on ``globals.py`` are as follows:
```
(nabanita07) (base) nabanita07@nabanita07:~/PySyft/src/syft/ast$ interrogate -P -ignore-private globals.py
RESULT: FAILED (minimum: 80.0%, actual: 66.7%)
Generated badge to /home/nabanita07/PySyft/src/syft/ast/nore-private
(nabanita07) (base) nabanita07@nabanita07:~/PySyft/src/syft/ast$ pydocstyle --convention=google globals.py
globals.py:1 at module level:
        D100: Missing docstring in public module
globals.py:132 in public method `apply_node_changes`:
        D102: Missing docstring in public method
(nabanita07) (base) nabanita07@nabanita07:~/PySyft/src/syft/ast$ darglint globals.py
```
``nore-private`` is added to notify you the changes and errors. I will delete that later.",resolved file report base interrogate result minimum actual badge base module level missing public module base dar dar dar dar report base interrogate result minimum actual badge base module level missing public module public method missing public method base added notify delete later,issue,negative,negative,negative,negative,negative,negative
808872992,"I think you should also run the script to generate the protocol buffers.
It can be found in the folder ```scripts``` (simply run ```pre_commit.sh``` and it should be auto-generated)",think also run script generate protocol found folder simply run,issue,negative,neutral,neutral,neutral,neutral,neutral
808868819,"> Hi @dnabanita7
> Thanks for your effort!! I think you have started for one of the most complex modules, great job!
> 
> The quality of the docstring is measured in the following way:
> 
> * `interrogate -P -ignore-private src/syft/ast: Returns the percentage of docstring coverage: `RESULT: FAILED (minimum: 80.0%, actual: 29.3%)`
> * `pydocstyle --convention=google  src/syft/ast`: Raises errors according to Google convention (see [this link](https://sphinxcontrib-napoleon.readthedocs.io/en/latest/example_google.html) for examples)
> * `darglint  src/syft/ast`: Raises errors according to docstring consistency
> 
> They can be installed simply by copy-paste the following command: `pip install interrogate pydocstyle darglint flake8`
> 
> This can be a bit a annoying, but following this criteria the QA will be improved a lot! Do not hesitate to write me if you have any question. We plan to new issues for the rest of modules.

Let me run these and get back to you. Thank you! ",hi thanks effort think one complex great job quality measured following way interrogate percentage coverage result minimum actual according convention see link according consistency simply following command pip install interrogate flake bit annoying following criterion lot hesitate write question plan new rest let run get back thank,issue,positive,positive,neutral,neutral,positive,positive
808827655,"@madhavajay 
Thank you for your work! I tested the notebook you modified, and it worked! The checkpoints seem fine to me. ",thank work tested notebook worked seem fine,issue,positive,positive,positive,positive,positive,positive
808824698,"We have defined the following [template](https://jbt.github.io/markdown-editor/#lVXbbtw2EH3frxjACGAv7JWdm51FEqCp3SBAgDiOUyAICosrUhJrilR42bX+vmeovTlNH/q2Kw6HZ86cOXNAX3spoqJLV4XotW3I1fQ6DHUsGq/lW3rdOZmMKnpR3YtGvZ1MDg7o01L5pVarCa6lTtkoonaWdKDK66grYUhbEnag3ru/VRVn9KGmlaKVsJGio6AUueTJ6IUXXqtAKShJi4FcbJXnfz4cE34PZBVOcCdZiY9RWEk6Ho+BKx3UGLXSxpDUIYheCT+bTEqJku6iEl3JwKIfuDrk6VNoKbhOUeOcBEJRATIgiIVLkeSjkg61Ndoq/jryA1ApOq+FAT71ILre8FWAulFCdioczWgy+YQrIBLIKIpwjwDjcTxQJTzKlcQvMSpHIkkdc2TlpDrO1MQWZ99Dz3dCq1T867CNsQ/zomAgMwBvjJpVriv2gkIhi7Orh8uzq88fPsePD6fPxF17bt5dm6UIf4Zu8eziy+nTd/XqhTj//PLpt0Lh5YNGyzdnZy9evTq/eH7+Euhv+fERVSsCeaG5NWA2odCVjm0G+5gm1JoZ7YfY4u9aLKEYxQOmrOiUGeaT6Ri3pZOEV9QhOX7Pfn0qdV3rKpn4WAT/Ea1t5WzQIQJbYV2klAUuCz7wHlpEWJOhg/6h//W70qFWvl07Y9yKypHxEj2yS1xFzZDYLRSoxgpY6+VYfbktP8tiS0FwY18zk9x8r/i1Ko7yFlIWI9ZCdxibpaLptNwbxfJfs0g7ce56MZ3yiB7Q7wnV2rhXFGiLKTBq+pGE0XHYaHQXA1idEiF5brnNhyMFfLgS6CDIKrWNynvXsHOcXNOJbqzz6qT3esmfMui35RwjEZO3Iafpla8YY5MnY/dihUo9vs6pvLn68vXj7Zz++O3Dx6tLOuy01V3q5nRxOjt9ckwYVOCe07PT2dmTo5KR9EPONBgAOdk1583Yrz0n2zQlw2JJB+ISPJpUQRhybQ7vx3u7THTIA/k9dw5k3+8mMfSttg+IRB2LEyt6ZxRkweOIevOcalcoWxhwEmKxNou79fC2sTNHINdvXeSIC5JQJ96JGXrzf6DvU7qegGrIImXbsbTg4YAGjEFvAzRmBjbcyvXDSS8Q/lO34S6QtURfet1vrtJ+6/fI38KujbhXF+WowfcOm4CH4FLV6OXGKi6dVZPplIXYCais4bDRDTfS31MkVKh8F/jiRraccucEiJpO2XXHlPLRWxJvTaec/UfSwDwWnlcLiRBcpdkd6Dqhthv1Ax4XKbQuGUlVq6p7BIqIJaGW2qWwISUgb/aH7I550yWrHnqVpzl3Z0aPl2MnBm4BT/z9WEGeCu96x/663YRFdM6E7Cr8AMamRtZsHxCJCFgRub+ofvQTeLSgJuEDmwHzwE3PRoMDDNcwLrpag66N+9Q0uLRdx43CgV06s8xjjy8LPJQX0oy+IRAwF2Jh1mt2Om1F7lFaxAByF6oS2Ng55ZqXGnwOuUdhvbNXzKPYbIiyMmC/JMi/rJOtmKIy2+6MrnOZeGWdq1VBR9YbcPG4wQZoqQUFg7ngDD/38gZymPwD)

New issues will be created soon.",defined following template new soon,issue,negative,positive,neutral,neutral,positive,positive
808791848,@tudorcebere added `_exhausted` field and added test for that and updated an existing test.,added field added test test,issue,negative,neutral,neutral,neutral,neutral,neutral
808702664,There is a flake8 error. If you look at the python linting job you can see the errors,flake error look python job see,issue,negative,neutral,neutral,neutral,neutral,neutral
808687227,"This is caused due to the `__iter__` being wrapped multiple times by:

https://github.com/OpenMined/PySyft/blob/261869e50852a24b2d76f3b44a5819050acd9eb8/src/syft/ast/klass.py#L338-L342

For `OrderedDict`: (`items`, `values`, `keys`) return an `Iterator`, hence the  `__iter__` gets wrapped thrice.

I believe the wrapping was done in this manner to account for types that can't be iterated directly (no `__iter__`) but have inbuilt functions that can return an `Iterator`.

To avoid the wrapping multiple times, either a flag can be added within this `for` loop.
Or`wrap_iterator` function can check if `__iter__` has already been wrapped, and skip re-wrapping it (current PR).

@tudorcebere if this seems fine, I'll create a PR.",due wrapped multiple time return hence wrapped thrice believe wrapping done manner account ca directly inbuilt return avoid wrapping multiple time either flag added within loop function check already wrapped skip current fine create,issue,negative,positive,neutral,neutral,positive,positive
808686147,black is wroking fine but I have not included the files except `session_pb2.py` because minor changes occured which does not hinder the codebase. In `session_pb2.py` protocol has been introduced with the help of `session.proto`.,black fine included except minor hinder protocol help,issue,positive,positive,neutral,neutral,positive,positive
808680562,"Hi @riccardo94p 

Our awesome writing team is helping us to create some nice docs for our next release! In the meantime, the `examples` folder is where you can understand syft in the best way.",hi awesome writing team helping u create nice next release folder understand best way,issue,positive,positive,positive,positive,positive,positive
808676876,"Hi @karynaur!

Please take a look at the other benchmarks in that folder. We don't have docs yet on how to make a benchmark, but after you get it (it's not hard), you could write a tutorial on it! :) 

Thank you!",hi please take look folder yet make get hard could write tutorial thank,issue,positive,negative,negative,negative,negative,negative
808675214,"@cgoxo the changes look good.

Could you run black to make sure the code is formatted correctly",look good could run black make sure code correctly,issue,positive,positive,positive,positive,positive,positive
808660996,"Hi @ArtistBanda,

`self.gc_enabled` is not a good marker to check if the pointer has been exhausted. You might want to add a `_exhausted` field on the pointer?",hi good marker check pointer exhausted might want add field pointer,issue,negative,positive,positive,positive,positive,positive
808605558,"The lib tests are getting really slow, I will investigate and see if we can trim some time before we merge this otherwise its going to be a really long wait to merge PRs.",getting really slow investigate see trim time merge otherwise going really long wait merge,issue,negative,negative,negative,negative,negative,negative
808031783,"> Did you install syft with?
> 
> ```
> $ pip install git+https://github.com/OpenMined/PySyft@dev#egg=syft
> ```

thank u soooooooooooooooooooooo much!!!",install pip install thank much,issue,negative,positive,positive,positive,positive,positive
808019580,"So, once the `get` function is called by the `pointer` with the flag `delete_obj=True` it should raise an error like `ReferenceError` for the next call?
Will this solution work?

Edit: If `gc_enable` is True then should we raise the Error?",get function pointer flag raise error like next call solution work edit true raise error,issue,negative,positive,positive,positive,positive,positive
807915461,@Param-29 okay no problem I will take a look as soon as I get a chance. 👍🏼 ,problem take look soon get chance,issue,negative,neutral,neutral,neutral,neutral,neutral
807726213,"@koenvanderveen I personally was thinking it would be cool to re-construct the code from our actions and assign variables, and perhaps we might look at some kind of Plan decompilation step later but I think the goal right now is to do `inspect.getsource` so that its verbatim the same code you used to create it. If it worked on the DS side it should work on the DO side, so later we can optionally do the compilation on the DO side to provide some level of confidence in the Plan being untampered.",personally thinking would cool code assign perhaps might look kind plan step later think goal right verbatim code used create worked side work side later optionally compilation side provide level confidence plan untampered,issue,positive,positive,positive,positive,positive,positive
806526302,"I have made the changes you suggested, for running hello-world notebooks, I am facing 2 issues 
You can find the code and the issue in jupyter-notebook `Issue 4850`

Errors:
```
TypeError: 'Expression' object is not iterable
```

Expression object is not expected to be iterable 

```
TypeError: cannot unpack non-iterable EcPtPointer object
```

I couldn't find iterator for `EcPt`",made running facing find code issue issue object iterable expression object iterable unpack object could find,issue,negative,neutral,neutral,neutral,neutral,neutral
806354833,"@ashkan-pirmani Hey, I've sort of written down all the files in duet examples, you could do that with other examples, as there are a number of notebooks to cover ",hey sort written duet could number cover,issue,negative,neutral,neutral,neutral,neutral,neutral
806330629,"Awesome spot! I have created a related ticket because of this find. https://github.com/OpenMined/Heartbeat/issues/1000

We might have more completed functionality which isn't completely turned on.",awesome spot related ticket find might functionality completely turned,issue,positive,positive,positive,positive,positive,positive
806320846,"@Param-29 this is excellent work! I have fixed the conflict with `src/syft/lib/__init__.py` since these are optional libraries we won't load them on startup but make it a separate `sy.load` call.

Theres a few naming changes to make and then it I would love to see the `Peggy` and `Victor` example from the README https://github.com/spring-epfl/zksk in a test file and that should be ready for merge! 🙌",excellent work fixed conflict since optional wo load make separate call there naming make would love see peggy victor example test file ready merge,issue,positive,positive,positive,positive,positive,positive
806310412,"@Koukyosyumei Nice!
I also went a step further and refactored some more so that we can only support what we know we support, and make sure the `max` and `min` values of all types are tested. The naming conventions in Python usually reserve 🐫 `CamelCase` for class names, and GLOBAL_STATIC type variables as all 🐍 `UPPER_SNAKE_CASE`.",nice also went step support know support make sure min tested naming python usually reserve class type snake,issue,positive,positive,positive,positive,positive,positive
806306775,"@madhavajay 
Thank you! I didn't know that. I fixed the process of dtype and added a dtype check to test. ",thank know fixed process added check test,issue,negative,positive,neutral,neutral,positive,positive
806290231,"Looks like we need to check the `dtype` as well just in case since different data types still match the == condition.
```python
>>> import numpy as np
>>> x = np.array([1, 2, 3])
>>> y = np.array([1, 2, 3], dtype=np.int32)
>>> x
array([1, 2, 3])
>>> y
array([1, 2, 3], dtype=int32)
>>> x == y
array([ True,  True,  True])
>>> x.dtype == y.dtype
False
```

```python
assert test_array.dtype == received_array.dtype

E           AssertionError: assert dtype('uint16') == dtype('int16')
E             +dtype('uint16')
E             -dtype('int16')
```

Interesting. Let me investigate.",like need check well case since different data still match condition python import array array array true true true false python assert assert interesting let investigate,issue,positive,positive,positive,positive,positive,positive
806288048,"@Param-29 Great suggestion, lets address that as a separate PR:
https://github.com/OpenMined/PySyft/issues/5368",great suggestion address separate,issue,positive,positive,positive,positive,positive,positive
806281105,"Hi @withshubh you missed a bunch of my requested changes and didn't fix CI. I have fixed these issues and reverted a major cause of breaking tests which was the false positive change to the `Dict` init function which has a whole comment block above it explaining why it needs to be special.

Overall I would say that this experience with `deepsource.io` has been disappointing. There were far more false positives than true positives and the fixes themselves were often questionable, lacking ""deep"" enough understanding of the class hierarchy. Analyzing such a dynamic language as Python is no doubt quite hard, however I am skeptical of the value of this tool right now, over our existing tooling which seems to be providing very high quality true positive checks, and so im going to remove the `.deepsource.toml` file for now.

I would love to be convinced otherwise in future if the tool improves and PRs to include it in our code base, pass the CI test suite without our team having to fix all the mistakes that false positives introduce to our code base.

",hi bunch fix fixed major cause breaking false positive change function whole comment block explaining need special overall would say experience disappointing far false true often questionable deep enough understanding class hierarchy dynamic language python doubt quite hard however skeptical value tool right tooling providing high quality true positive going remove file would love convinced otherwise future tool include code base pas test suite without team fix false introduce code base,issue,positive,negative,neutral,neutral,negative,negative
806197614,Is there any room still available to contribute to this issue?,room still available contribute issue,issue,negative,positive,positive,positive,positive,positive
805979800,"@Koukyosyumei  I believe there are 2 small change that we can do 

1. 
In `tests/syft/lib/torchvision` there is a file I had added, `imageTensor.pt`, this can then be deleted and in the following function, **you could convert PySyft's logo to tensor and use that tensor for tests** 

File name: _allowlist_test.py_
```
@pytest.fixture(scope=""function"")
def tens() -> torch.Tensor:
    if path.isfile(""imageTensor.pt""):
        return torch.load(""imageTensor.pt"")
    else:
        cwd = os.getcwd()
        path_file = cwd + ""/tests/syft/lib/torchvision/"" + fileName
        return torch.load(path_file)
```
2. 

We had added in `min_version` for a lot of methods because old versions of torchvision didn't support `tensor.Tensor` as input

Look for this comment in `torchvision\allowlist.py`

> Torch 1.6 expects input to be PIL image, so minimum version as 0.7 (Torch 1.7.0)

**I believe even this (i.e min_version) can be changed now, and PIL Image can be passed to tests instead of `torch.Tensor`**

I think these changes are not a big set of changes but would go a long way in maintaining the library 

Reviews could take a pool if this should be done,  and if so where, in this PR or a new issue!

I hope my expectations were clear enough, if not we could talk over slack. 

Cheers!",believe small change file added following function could convert tensor use tensor file name function return else return added lot old support input look comment torch input image minimum version torch believe even image instead think big set would go long way library could take pool done new issue hope clear enough could talk slack,issue,positive,positive,neutral,neutral,positive,positive
805890869,"Tested on these python versions:
- [x] Python 3.6
- [x] Python 3.7
- [x] Python 3.8
- [x] Python 3.9

Fixed version dependency issues.",tested python python python python python fixed version dependency,issue,negative,positive,neutral,neutral,positive,positive
805878854,"or do we just use something like `inspect.getsource(func)`, that would be pretty easy, but not very secure if we rely on this representation for approving execution",use something like would pretty easy secure rely representation execution,issue,positive,positive,positive,positive,positive,positive
805870029,"@madhavajay 
Thank you for your review and fix! Please merge it. ",thank review fix please merge,issue,positive,neutral,neutral,neutral,neutral,neutral
805774885,"When we do:
`y = data+data`
Do we store the name ""y"" in the `StoreObjectAction`? Probably not right? Do we want (and is it feasible) to do this? Otherwise we would get something like:
```
var1 = data+data
var2 = var1*var1 + arg2
```

Also, I dont think we can infer whether multiple operations were chained on one line, so I think we cannot infer whether it was

`z = y * y + arg2`

or

```
z1 = y * y
z = z1 + arg2
```

it would make a bit of difference though, because if we don't have these things we might choose to improve the representation for individual actions, and just make the plan add some boilerplate (`@makeplan`, def ...), and replace e.g. ""UID123"" -> ""var1""
",store name probably right want feasible otherwise would get something like also dont think infer whether multiple chained one line think infer whether would make bit difference though might choose improve representation individual make plan add replace,issue,positive,positive,neutral,neutral,positive,positive
805768726,"Conceptually I always compared plans to python functions, they have args (in our case they are not allowed) and kwargs, execute some operations, and return a tuple of outputs. This would move away from that abstraction, but I don't completely understand why yet. Could you elaborate about the permission part?",conceptually always python case execute return would move away abstraction completely understand yet could elaborate permission part,issue,negative,positive,positive,positive,positive,positive
805762690,"I agree that the API is currently not as intuitive as it could be. I wonder if introducing PlaceHolders would make it less confusing, because it is another abstraction to understand. What would be the conceptual benefit of Placeholders? For the current use case I believe that we are only using local objects and pointers to objects when creating plans. Another approach to make the API less confusing to consider could be to make the sending part more explicit, but maybe with a shorter notation by overloading `@` to `.send`
```
@make_plan
def add_plan(inp=th.zeros(3)@plan_vm, inp2=th.zeros(5)@plan_vm) -> th.Tensor:  # type: ignore
    return inp + inp
```

(we would need some logic to check whether the object itself already overloaded `@` and whether the passed arg is a Node to implement this)",agree currently intuitive could wonder would make le another abstraction understand would conceptual benefit current use case believe local another approach make le consider could make sending part explicit maybe shorter notation type ignore return would need logic check whether object already whether node implement,issue,negative,neutral,neutral,neutral,neutral,neutral
805544624,"@ArtistBanda nice! I can highly recommend testing the tests on each version of Python in a virtualenv locally first, because the new tests will likely break on older versions of python. If you see in side the tests we have a few places where we handle this already.

```python
#complex_test.py
self.assertEqual(Complex(complex0(1j)), 42j)
if sys.version_info >= (3, 7):
    # Only deprecated from python 3.7
    with self.assertWarns(DeprecationWarning):
        self.assertEqual(Complex(complex1(1j)), 2j)
self.assertRaises(TypeError, Complex, complex2(1j))
```",nice highly recommend testing version python locally first new likely break older python see side handle already python complex complex python complex complex complex complex,issue,positive,negative,neutral,neutral,negative,negative
805471869,Thank you for the review Param! Ill read about pre-commit. @madhavajay Could you advice me on what to put into the benchmark_send_tensor.py test. A link to a documentation explaining the same would be fine too!,thank review param ill read could advice put test link documentation explaining would fine,issue,negative,negative,neutral,neutral,negative,negative
805448673,@karynaur are you still able to fix this properly?,still able fix properly,issue,negative,positive,positive,positive,positive,positive
805443068,"Thank you @madhavajay and @tudorcebere for helping out. Now, I understand the codebase better and syft is so cool!",thank helping understand better cool,issue,positive,positive,positive,positive,positive,positive
805436467,"> > @dnabanita7 Thanks for the serde tests. I added another test to check for the last field `step` which is optional and found that it wasn't working because the proto only had ints and the default int in proto is 0. I have added some code to allow for a boolean to determine if the value is set and should be used and defaulted the slice attribute as None if the boolean is false.
> > I also added some tests to see if it works with Tensor and Pandas DataFrame which it does, and because of the primitive_factory we can just use the normal python syntax:
> > ```python
> > t = th.Tensor([1, 2, 3])
> > t_ptr = t.send(alice_client)
> > 
> > res_ptr2 = t_ptr[0:1]
> > res2 = res_ptr2.get()
> > assert t[0:1] == res2
> > ```
> > 
> > 
> > Pretty cool!
> > Thanks for your help, and ill get this merged ASAP.
> 
> Yes, I checked that Tensor and Pandas DataFrame didn't work for step because proto takes ints only.

Okay, next time let us know so we can help you fix it. 😊",thanks added another test check last field step optional found working proto default proto added code allow determine value set used slice attribute none false also added see work tensor use normal python syntax python assert pretty cool thanks help ill get yes checked tensor work step proto next time let u know help fix,issue,positive,positive,neutral,neutral,positive,positive
805414917,"> @dnabanita7 Thanks for the serde tests. I added another test to check for the last field `step` which is optional and found that it wasn't working because the proto only had ints and the default int in proto is 0. I have added some code to allow for a boolean to determine if the value is set and should be used and defaulted the slice attribute as None if the boolean is false.
> 
> I also added some tests to see if it works with Tensor and Pandas DataFrame which it does, and because of the primitive_factory we can just use the normal python syntax:
> 
> ```python
> t = th.Tensor([1, 2, 3])
> t_ptr = t.send(alice_client)
> 
> res_ptr2 = t_ptr[0:1]
> res2 = res_ptr2.get()
> assert t[0:1] == res2
> ```
> 
> Pretty cool!
> Thanks for your help, and ill get this merged ASAP.

Yes, I checked that Tensor and Pandas DataFrame didn't work for step because proto takes ints only.",thanks added another test check last field step optional found working proto default proto added code allow determine value set used slice attribute none false also added see work tensor use normal python syntax python assert pretty cool thanks help ill get yes checked tensor work step proto,issue,positive,positive,neutral,neutral,positive,positive
805398749,"@dnabanita7 Thanks for the serde tests. I added another test to check for the last field `step` which is optional and found that it wasn't working because the proto only had ints and the default int in proto is 0. I have added some code to allow for a boolean to determine if the value is set and should be used and defaulted the slice attribute as None if the boolean is false.

I also added some tests to see if it works with Tensor and Pandas DataFrame which it does, and because of the primitive_factory we can just use the normal python syntax:
```python
t = th.Tensor([1, 2, 3])
t_ptr = t.send(alice_client)

res_ptr2 = t_ptr[0:1]
res2 = res_ptr2.get()
assert t[0:1] == res2
```

Pretty cool!
Thanks for your help, and ill get this merged ASAP.
",thanks added another test check last field step optional found working proto default proto added code allow determine value set used slice attribute none false also added see work tensor use normal python syntax python assert pretty cool thanks help ill get,issue,positive,positive,neutral,neutral,positive,positive
805261646,"> ## Description
> MCFL attempt 2, previous code was deleted by revert in Plans PR.

So weird, going to see how this happened. Sorry.",description attempt previous code revert weird going see sorry,issue,negative,negative,negative,negative,negative,negative
804840564,"I wonder whether we really need to serialize the forward method as a plan here. Alternatively, we could just serialize the state of the module, call the .forward method on the module pointer, and trace the actions that originate from that call. So a module in a plan instead of a plan in a module.",wonder whether really need serialize forward method plan alternatively could serialize state module call method module pointer trace originate call module plan instead plan module,issue,negative,positive,positive,positive,positive,positive
804789697,"@madhavajay 
I am not sure if I have enough time to implement this, but I'll search for this. ",sure enough time implement search,issue,negative,positive,positive,positive,positive,positive
804787390,"@madhavajay 
Thanks for your review and comments! I have one question. Please correct me if I'm wrong, could I also ignore uint and raise exceptions or should I make a custom proto which supports uint now?",thanks review one question please correct wrong could also ignore raise make custom proto,issue,negative,negative,negative,negative,negative,negative
804759041,"@madhavajay Awkward, I remember solving this at some point. @xutongye fixed and added tests to be sure to not have a regression again.",awkward remember point fixed added sure regression,issue,negative,neutral,neutral,neutral,neutral,neutral
804673831,"Additional use case is `grad` and `data` for Tensors which are used in the `UnionGenerator` for `Plans`.
```
torch.Tensor.grad
torch.Tensor.data
```",additional use case grad data used,issue,negative,neutral,neutral,neutral,neutral,neutral
804641429,Feel free to use an existing image like the syft or duet logo from the existing repo in `/docs/img`.,feel free use image like duet,issue,positive,positive,positive,positive,positive,positive
804641126,@Koukyosyumei let's add its own set of tests and it should be added to the `requirements.libs.txt` file as well.,let add set added file well,issue,negative,neutral,neutral,neutral,neutral,neutral
804638544,"@Koukyosyumei this is awesome, and a much needed bit of functionality to unblock many different library integrations which return `numpy.ndarray` types.

One final change, can you add `numpy` to `requirements.libs.txt` its not explicitly included anywhere and it would be good to add it to be specific.",awesome much bit functionality unblock many different library return one final change add explicitly included anywhere would good add specific,issue,positive,positive,positive,positive,positive,positive
804622908,"@Koukyosyumei I have updated the ticket with some of the remaining tasks and pushed the CDC Dataset to the web and updated the notebooks to download them automatically.

I would vote on trying feather / apache arrow format first for the serde.

The ultimate goal is getting the notebooks fully functioning.
The things which might be a little trickier are:
- `df.attr`
- `iloc`
- alternative serde method for Pandas DF using say `feather` , `hdf5` or `msgpack`",ticket web automatically would vote trying feather apache arrow format first ultimate goal getting fully might little alternative method say feather,issue,negative,positive,neutral,neutral,positive,positive
804592298,"@madhavajay 
Should I edit tests/syft/lib/torchvision/allowlist_test.py or add a new test file?",edit add new test file,issue,negative,positive,positive,positive,positive,positive
804583408,"@madhavajay 

Since there are some differences between dtypes of torch.Tensor and numpy.array, I cannot make np.uint16, np.uint32, np.uint64, np.str_, np.object_ work. Also, because syft currently doesn't support complex numbers, np.complex64 and np.complex128 are not available.

Thus, the available dtypes are as follows.

        np.int8
        np.int16
        np.int32
        np.int64
        np.uint8
        np.float16
        np.float32
        np.float64
        np.bool_",since make work also currently support complex available thus available,issue,negative,positive,positive,positive,positive,positive
804561290,@tudorcebere Did we end up supporting Dicts in the `Iterator`? Seems like you can get `.len()` on the `dptr` but not on the `itemsptr` interestingly.,end supporting like get interestingly,issue,positive,positive,positive,positive,positive,positive
804531393,"@Koukyosyumei this is super awesome, the only thing else I would recommend is that we run `black-nb` to auto format the notebook cells.
```bash
$ black-nb /examples/duet/vae
```",super awesome thing else would recommend run auto format notebook bash,issue,positive,positive,positive,positive,positive,positive
804522643,@dnabanita7 As soon as the `serde tests` are in I think we should merge this PR and then start each of the remaining tasks as a few separate PRs so that they can be smaller and quicker to parallelize.,soon think merge start separate smaller parallelize,issue,negative,neutral,neutral,neutral,neutral,neutral
804522017,@dnabanita7 No worries. I hope your exams went well! 😊 Take a look at the changes I made so you can get a feel for the way we are handling Python types. Also I think @tudorcebere is probably the best person to check this PR since he did many of the other types. Something which comes to mind is the `primitive_factory` we probably need to add `Slice` in there as well. I will update the issue / todos.,hope went well take look made get feel way handling python also think probably best person check since many something come mind probably need add slice well update issue,issue,positive,positive,positive,positive,positive,positive
804191757,"> Hi @dnabanita7, thanks for your PR. I have refactored the code a little bit.
> I think the remaining things to be done are:
> 
>     * [ ]  Add some serde tests
>       The proto only takes ints so you might need to change that to support None as well.
> 
>     * [ ]  Add the tests from CPython: https://github.com/python/cpython/blob/3.9/Lib/ctypes/test/test_slicing.py
> 
>     * [ ]  Add the CPython test filename to the LICENSE.txt file
> 
>     * [ ]  Make sure Slice works on other types like Tensor or Pandas
>       If there are issues we might need to override the Pointer with a wrapped **getitem**
> 
>     * [ ]  Make sure that **setitem** also works: https://stackoverflow.com/questions/32772755/how-do-getitem-setitem-work-with-slices
> 
> 
> Theres a bit of work here so it might make sense if we split it up. Could you start by writing some tests for the `serde` and fixing up the proto?

Yes yes sure thing! this looks great now! I am sorry not to be have responded earlier as I had my final exams going on. I will try to add tests asap! Thanks for summarizing this up.",hi thanks code little bit think done add proto might need change support none well add add test file make sure slice work like tensor might need override pointer wrapped make sure also work there bit work might make sense split could start writing fixing proto yes yes sure thing great sorry final going try add thanks,issue,positive,positive,positive,positive,positive,positive
804004086,"Hey @madhavajay 

Apology for late response. I skipped the previous notification.

Yes, you can add the `skipcq` to ignore the issue. Read more [here](https://deepsource.io/docs/how-to/silence-issues.html)",hey apology late response previous notification yes add ignore issue read,issue,negative,negative,negative,negative,negative,negative
804000274,"@Koukyosyumei Last thing would be some tests just to show it works, so just create a test with a virtualmachine and load an image, send it to the client and retrieve it back and assert it matches. Then use the remote API to create the PIL image remotely if you can. That might require creating one with torchvision via a tensor first and then passing the PIL in the store into the PIL constructor.",last thing would show work create test load image send client retrieve back assert use remote create image remotely might require one via tensor first passing store constructor,issue,negative,positive,neutral,neutral,positive,positive
803998052,"Hi @dnabanita7, thanks for your PR. I have refactored the code a little bit.
I think the remaining things to be done are:
- [ ] Add some serde tests
       The proto only takes ints so you might need to change that to support None as well.
- [ ] Add the tests from CPython: https://github.com/python/cpython/blob/3.9/Lib/ctypes/test/test_slicing.py
- [ ] Add the CPython test filename to the LICENSE.txt file
- [ ] Make sure Slice works on other types like Tensor or Pandas
        If there are issues we might need to override the Pointer with a wrapped __getitem__
- [ ] Make sure that __setitem__ also works: https://stackoverflow.com/questions/32772755/how-do-getitem-setitem-work-with-slices

Theres a bit of work here so it might make sense if we split it up. Could you start by writing some tests for the `serde` and fixing up the proto?",hi thanks code little bit think done add proto might need change support none well add add test file make sure slice work like tensor might need override pointer wrapped make sure also work there bit work might make sense split could start writing fixing proto,issue,positive,positive,positive,positive,positive,positive
803988288,"@madhavajay Yes, definitely. I'm currently working on OpenMined/PySyft#5306 . Would like to work on the plugin after it. ",yes definitely currently working would like work,issue,positive,neutral,neutral,neutral,neutral,neutral
803853113,@madhavajay I would like to work on this issue. Could you elaborate a little more on what `attach_tags()` is doing here. Does this mean that in case of pandas DataFrame or Series we need to ignore value of tags and description and store it as None?,would like work issue could elaborate little mean case series need ignore value description store none,issue,negative,neutral,neutral,neutral,neutral,neutral
803845873,"@Koukyosyumei Great work, interesting solution. I tried adding this to an integration test but it seems to hang or fail, possibly due to the additional async code. If you could give it another shot now that the code is in place that would be nice, otherwise we can merge without a test and come back and re-implement this with Plans.

The code I added does a find and replace of the notebooks to change the `epoch` and `steps` to make the test faster, but I might have gotten something wrong with the checkpoints, or its just hanging on the first one?",great work interesting solution tried integration test fail possibly due additional code could give another shot code place would nice otherwise merge without test come back code added find replace change epoch make test faster might gotten something wrong hanging first one,issue,positive,positive,positive,positive,positive,positive
803840493,This is currently still an issue for fqn string -> Class or Pointer without reference to the `obj`,currently still issue string class pointer without reference,issue,negative,neutral,neutral,neutral,neutral,neutral
803824374,"@Koukyosyumei awesome work.
Could we add a few unit tests to make sure it works and possibly iterate through the available data types and make sure they also go to their destination and come back as the same type without issue?

The test can just use a `VirtualMachine`:
```python
>>> import syft as sy
>>> vm = sy.VirtualMachine()
>>> client = vm.get_root_client()
>>> import numpy as np
>>> a = np.array([1, 2, 3])
>>> a
array([1, 2, 3])
>>> sy.load(""numpy"")
>>> x = a.send(client)
>>> y = x.get()
>>> y
array([1., 2., 3.], dtype=float32)
>>> type(y)
<class 'numpy.ndarray'>
>>> assert a == y
```",awesome work could add unit make sure work possibly iterate available data make sure also go destination come back type without issue test use python import client import array client array type class assert,issue,positive,positive,positive,positive,positive,positive
803820969,@gmuraru Thanks for the review. I made most of the changes relating to the code and formatted the notebooks and added some more comments. ❤️,thanks review made code added,issue,negative,positive,positive,positive,positive,positive
803797289,"@meijiu That seems like the case mostly, except it would be good if we don't rely on a simple `""torch.nn"" in ` check, and possibly also make sure were not missing something from the original source code:
```python
# torch/nn/modules/module.py
def __setattr__(self, name: str, value: Union[Tensor, 'Module']) -> None:
    def remove_from(*dicts_or_sets):
        for d in dicts_or_sets:
            if name in d:
                if isinstance(d, dict):
                    del d[name]
                else:
                    d.discard(name)

    params = self.__dict__.get('_parameters')
    if isinstance(value, Parameter):
        if params is None:
            raise AttributeError(
                ""cannot assign parameters before Module.__init__() call"")
        remove_from(self.__dict__, self._buffers, self._modules, self._non_persistent_buffers_set)
        self.register_parameter(name, value)
    elif params is not None and name in params:
        if value is not None:
            raise TypeError(""cannot assign '{}' as parameter '{}' ""
                            ""(torch.nn.Parameter or None expected)""
                            .format(torch.typename(value), name))
        self.register_parameter(name, value)
    else:
        modules = self.__dict__.get('_modules')
        if isinstance(value, Module):
            if modules is None:
                raise AttributeError(
                    ""cannot assign module before Module.__init__() call"")
            remove_from(self.__dict__, self._parameters, self._buffers, self._non_persistent_buffers_set)
            modules[name] = value
        elif modules is not None and name in modules:
            if value is not None:
                raise TypeError(""cannot assign '{}' as child module '{}' ""
                                ""(torch.nn.Module or None expected)""
                                .format(torch.typename(value), name))
            modules[name] = value
        else:
            buffers = self.__dict__.get('_buffers')
            if buffers is not None and name in buffers:
                if value is not None and not isinstance(value, torch.Tensor):
                    raise TypeError(""cannot assign '{}' as buffer '{}' ""
                                    ""(torch.Tensor or None expected)""
                                    .format(torch.typename(value), name))
                buffers[name] = value
            else:
                object.__setattr__(self, name, value)
```",like case mostly except would good rely simple check possibly also make sure missing something original source code python self name value union tensor none name name else name value parameter none raise assign call name value none name value none raise assign parameter none value name name value else value module none raise assign module call name value none name value none raise assign child module none value name name value else none name value none value raise assign buffer none value name name value else self name value,issue,positive,positive,positive,positive,positive,positive
803792837,"@avinsit123 Its okay, there are other issues to, but if you are interested then it would be a great addition.",interested would great addition,issue,positive,positive,positive,positive,positive,positive
803792524,"@densechen I think you have the wrong version installed.
See this issue: https://github.com/OpenMined/PySyft/issues/5334",think wrong version see issue,issue,negative,negative,negative,negative,negative,negative
803754118,@Koukyosyumei  thats awesome work. Any chance you could also quickly throw in a PR with `numpy.ndarray` which also uses Torch to transport it across the serde? That would mean a lot of other code which returns ndarrays like `sklearn` could also be worked on. ❤️ ,thats awesome work chance could also quickly throw also torch transport across would mean lot code like could also worked,issue,positive,positive,positive,positive,positive,positive
803722429,"@divinit7 awesome job thank you so much!! ❤️
We have also moved the flake8-kwarger plugin here for further development as an OpenMined library.
https://github.com/OpenMined/trasterisk

Are you interested in helping finish some tasks on it?
https://github.com/OpenMined/Heartbeat/issues/994",awesome job thank much also development library interested helping finish,issue,positive,positive,positive,positive,positive,positive
803715348,"Hi @yashmaurya01 since many of the notebooks, including this one in particular are run in our integration tests in CI, your error probably means you don't have the right version of Syft installed.

Until the next release it's advised to install directly from the `dev` branch.
```
$  pip install git+https://github.com/OpenMined/PySyft@dev#egg=syft
```",hi since many one particular run integration error probably right version next release advised install directly dev branch pip install,issue,negative,positive,positive,positive,positive,positive
803507445,"Will work on the required changes.
The above link is broken, working link for Lib tests: https://github.com/python/cpython/tree/3.9/Lib/test",work link broken working link,issue,negative,negative,negative,negative,negative,negative
803503120,"Great work. I pulled this PR and added a notebook to demo a use case with Opacus+Plan, #5333 . From the process I create the notebook using the Plan API, I feel it very necessary to support `for` loop in Plan. Without supporting to `for` loop, the Plan object created is very very large when I define a full training process as a Plan.",great work added notebook use case process create notebook plan feel necessary support loop plan without supporting loop plan object large define full training process plan,issue,positive,positive,positive,positive,positive,positive
803241627,"A couple of small reviews
1. You could install `pre-commit` to run **Python-Linting** tests before you commit (You can read more about it [here](https://github.com/OpenMined/PySyft/blob/dev/CONTRIBUTING.md#pre-commit))
2. Lookout for merge conflict, when (#5152) gets merged. 

Hope this helps!",couple small could install run commit read lookout merge conflict hope,issue,negative,negative,negative,negative,negative,negative
802945565,"What is the 'subclass init bug' being referenced in the TODO? ie.

        # this is how we catch the modules being set during subclass init
        # bug where torch.nn.modules isn't the full name on some imports

Based on what I'm understanding so far, __set_attr__ checks whether the attribute being set is a torch.nn module. If it is, it adds it to its dict of modules and also adds it to the dict of 'real_modules', which is holds the underlying torch Module. If it is not, it uses the canonical 'set attribute'.

Forgive me if this is a dumb question, but in what case would the attribute being added not be in the torch.nn package? I was looking through the notebooks in 'examples/duet' and it seems like in these examples __set_attr__ is only used to add a neural network layer from torch.nn.",bug ie catch set subclass bug full name based understanding far whether attribute set module also underlying torch module canonical attribute forgive dumb question case would attribute added package looking like used add neural network layer,issue,negative,positive,neutral,neutral,positive,positive
802814530,"> > @madhavajay what do you need from me to wrap this up?
> 
> Its high on the list sorry, just getting swamped.

np",need wrap high list sorry getting,issue,negative,negative,negative,negative,negative,negative
802790631,"> I have moved two small remaining issues into new issues to deal with later as they arent a big deal and it would be great to get this into the pending release.


@madhavajay Sounds great!, I'll try and take up the issues opened in some time because currently working on another issue.

Thanks for the clean-up.  

Cheers!!",two small new deal later arent big deal would great get pending release great try take time currently working another issue thanks,issue,positive,positive,positive,positive,positive,positive
802686242,Would close this for now and when more people would need this custom tensor there should be adapter from here: https://github.com/OpenMined/SyMPC/pull/89,would close people would need custom tensor adapter,issue,negative,neutral,neutral,neutral,neutral,neutral
802663188,Yes @madhavajay I am willing to look into it. Tudor's comment above has given me a small idea on what we are aiming for,yes willing look comment given small idea aiming,issue,negative,neutral,neutral,neutral,neutral,neutral
802659256,@avinsit123 thanks for the PR. Are you interested in investigating the post import hook?,thanks interested investigating post import hook,issue,positive,positive,positive,positive,positive,positive
802630103,"> @gmuraru why don't we just add the code to turn size into a tuple and then back again on the other side?
> 
> ```python
> >>> a = torch.Tensor([1, 2, 3])
> >>> torch.stack((a, a, a))
> tensor([[1., 2., 3.],
>         [1., 2., 3.],
>         [1., 2., 3.]])
> >>> tuple(b.size())
> (3, 3)
> >>> c = tuple(b.size())
> >>> torch.Size(c)
> torch.Size([3, 3])
> >>> x = torch.Size(c)
> >>> x == b.size()
> True
> ```

I tried this! but I got an error because I did not have access to ```len``` (from a VirtualClient) - it throws my an exception because i do not have the permissions.

Shouldn't all VirtualClients have access to ```len``` an ```iterator``` without having to request access? (because we can call ```get``` without explicitly specifying the permissions - I was expecting the same behavior)",add code turn size back side python tensor true tried got error access exception access without request access call get without explicitly behavior,issue,negative,positive,positive,positive,positive,positive
802622527,"@rishkum the `syft-server` should work you just need to make sure that you are connecting on the right IP and port from the other machine, if your on a home network it will likely be something like: `192.x.x.x`.

Since its set to `0.0.0.0` it should bind on all interfaces. If you can't connect it could be a firewall issue.

```python
HOST = ""0.0.0.0"" if IP_MODE == ""IPV4"" else ""::""  # nosec
PORT = os.getenv(""PORT"", 5000)
```",work need make sure right port machine home network likely something like since set bind ca connect could issue python host else port port,issue,positive,positive,positive,positive,positive,positive
802616345,"@ArtistBanda well, there was a bug with notebook 5.x where it wouldnt work, but I think its unrelated to colab, so in this instance we could allow the `Exception: Your Jupyter Notebook is too old` check to pass if the code is running in colab for now, which is detected by doing this:
```python
if ""google.colab"" in sys.modules:
```",well bug notebook wouldnt work think unrelated instance could allow exception notebook old check pas code running python,issue,negative,positive,neutral,neutral,positive,positive
802615009,"@divinit7 yeah this is a little weird, since `def traceback_and_raise(e: Any, verbose: bool = False) -> NoReturn:` technically never returns because it always raises. I think ignore is fine if its complaining that the abstract methods dont have an explicit return.",yeah little weird since verbose bool false technically never always think ignore fine abstract dont explicit return,issue,positive,negative,negative,negative,negative,negative
802594172,"@gmuraru why don't we just add the code to turn size into a tuple and then back again on the other side?

```python
>>> a = torch.Tensor([1, 2, 3])
>>> torch.stack((a, a, a))
tensor([[1., 2., 3.],
        [1., 2., 3.],
        [1., 2., 3.]])
>>> tuple(b.size())
(3, 3)
>>> c = tuple(b.size())
>>> torch.Size(c)
torch.Size([3, 3])
>>> x = torch.Size(c)
>>> x == b.size()
True
```",add code turn size back side python tensor true,issue,negative,positive,positive,positive,positive,positive
802553245,"@gmuraru This looks great, whats left to do? Serialization? Or should we break into a separate task?",great whats left serialization break separate task,issue,positive,positive,positive,positive,positive,positive
802479492,"Thanks for the fix.
Oh man those nested Parens feel like an English Grammer code smell! Wheres our English Language linter!!!! 😛",thanks fix oh man feel like code smell language linter,issue,positive,positive,positive,positive,positive,positive
802177877,"@karynaur I believe what is required is to write benchmark tests similar to `send_tensor.py`. So you could create a test named `benchmark_send_tensor.py ` to get the expected functionality. 

Also to make sure that python-linting tests pass, you could install `pre-commit`.  
You can read more about it [here](https://github.com/OpenMined/PySyft/blob/dev/CONTRIBUTING.md#pre-commit) ",believe write similar could create test get functionality also make sure pas could install read,issue,positive,positive,positive,positive,positive,positive
802009450,@tudorcebere @madhavajay could u review this work PR so that I can continue with autoloading and making appropriate changes in SyMPC.,could review work continue autoloading making appropriate,issue,negative,positive,positive,positive,positive,positive
801823051,"As mentioned above, **we no longer need to Hook libraries like torch**, so for versions 0.3+, I believe you could remove the line and the code would work fine.

You can also see examples present in the repo ([example](https://github.com/OpenMined/PySyft/blob/dev/examples/secure-multi-party-computation/Duet/1-DS-1-DO/POC-MPCTensor-Duet-Party1-DS.ipynb))

**Notice you no longer need to hook torch**

I hope this will help to resolve the confusion.!",longer need hook like torch believe could remove line code would work fine also see present example notice longer need hook torch hope help resolve confusion,issue,positive,positive,positive,positive,positive,positive
801783089,"Hi @sgaseretto I have the same issue here, did you find any solution? thansk",hi issue find solution,issue,negative,neutral,neutral,neutral,neutral,neutral
801740711,"@madhavajay I am trying to fix warnings in `src/syft/core/store`
but I'm getting `7     DAR202 Excess ""Returns"" in Docstring: + return`
`2     DAR402 Excess exception(s) in Raises section: +r ValueError`
in `src/syft/core/store/store_interface.py`. Should they be ignored with `#noqa`?",trying fix getting dar excess return dar excess exception section,issue,negative,neutral,neutral,neutral,neutral,neutral
801688450,"`import syft as fy` shows this exception 
```
Exception: Your Jupyter Notebook is too old. Please upgrade to version 6 or higher.
```

and running `pip install --upgrade notebook` shows this error 

```
ERROR: google-colab 1.0.0 has requirement notebook~=5.3.0; python_version >= ""3.0"", but you'll have notebook 6.2.0 which is incompatible.
ERROR: google-colab 1.0.0 has requirement tornado~=5.1.0; python_version >= ""3.0"", but you'll have tornado 6.1 which is incompatible.
```

alongside this warning 
```
WARNING: Upgrading ipython, ipykernel, tornado, prompt-toolkit or pyzmq can
cause your runtime to repeatedly crash or behave in unexpected ways and is not
recommended. If your runtime won't connect or execute code, you can reset it
with ""Factory reset runtime"" from the ""Runtime"" menu.
```

although the exception goes away after restarting runtime as the notebook is updated.

So, what exactly is the definition of the fix?",import exception exception notebook old please upgrade version higher running pip install upgrade notebook error error requirement notebook incompatible error requirement tornado incompatible alongside warning warning tornado cause repeatedly crash behave unexpected way wo connect execute code reset factory reset menu although exception go away notebook exactly definition fix,issue,negative,positive,positive,positive,positive,positive
801638708,"@gmuraru If we add dataset in the repo for testing purposes, we would have to add all the datasets which torchvision supports, so as suggested above, I am working on monkey patching the `__init__` for all the classes in Dataset. ",add testing would add working monkey class,issue,negative,negative,neutral,neutral,negative,negative
800766923,I'm interested in this issue. How is the current situation?,interested issue current situation,issue,negative,positive,positive,positive,positive,positive
800661480,"We can install in Colab, but there are issues running in Colab after the connection is established which relates to networking between Colab and another system which we are investigating.

To install in colab do this:
```python
%%capture
# This only runs in colab and clones the code sets it up and fixes a few issues, 
# you can skip this if you are running Jupyter Notebooks
import sys
if ""google.colab"" in sys.modules:
    branch = ""dev""    # change to the branch you want
    ! git clone --single-branch --branch $branch https://github.com/OpenMined/PySyft.git
    ! cd PySyft && ./scripts/colab.sh      # fixes some colab python issues
    sys.path.append(""/content/PySyft/src"") # prevents needing restart
```

You can see more about whats going on in the script `scripts/colab.sh`.

Additionally if you are reading this ticket because you are trying to use Syft for the Privacy Course on your local Jupyter until the next PyPI release you will need to install via git:
```
pip install git+https://github.com/OpenMined/PySyft@dev#egg=syft
```",install running connection established another system investigating install python capture code skip running import branch dev change branch want git clone branch branch python needing restart see whats going script additionally reading ticket trying use privacy course local next release need install via git pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
800646975,"Sadly - this is a known issue. The latest version of PySyft is not compatible with some of the ways Colab is locked down - pip install locally (using conda) and we'll address colab integration in a later version.

CC: @madhavajay to confirm.",sadly known issue latest version compatible way locked pip install locally address integration later version confirm,issue,negative,neutral,neutral,neutral,neutral,neutral
800641922,Looks like this is still on 0.2.x. Have you tried on the latest version? I think you'll find that this error doesn't occur on 0.3 and up.,like still tried latest version think find error occur,issue,negative,positive,positive,positive,positive,positive
800440831,@gmuraru I tried this out the other day but to no avail. You still get the same error!,tried day avail still get error,issue,negative,neutral,neutral,neutral,neutral,neutral
800437883,"> @madhavajay I have added in the tests the way we discussed above. Also, any suggestions on testing the `Datasets` without downloading the dataset would be really helpful.

Maybe it might be worth having a dataset in our repo? (and use ```download=False``` when loading the dataset)",added way also testing without would really helpful maybe might worth use loading,issue,negative,positive,positive,positive,positive,positive
800435219,"@abhi1nandy2 could you try to install ```torch == 1.7.1``` after installing syft.
The issue might be because ```torch1.8``` is out and syft was not released (YET!) with torch1.8 support.",could try install torch issue might yet torch support,issue,negative,neutral,neutral,neutral,neutral,neutral
800229260,"> I would like to take up this issue

Could you please  help with colab? It shows an error `AttributeError: type object 'Tensor' has no attribute 'fft'`",would like take issue could please help error type object attribute,issue,positive,neutral,neutral,neutral,neutral,neutral
800218165,Ok fine pls review this PR and I will try to open a seperate one to solve the autoloading issue. Thanks,fine review try open one solve autoloading issue thanks,issue,positive,positive,positive,positive,positive,positive
800203368,"LGTM!

I think we should merge this as it is so we won't keep a PR open for too long and then you can work on autoloading?

Autoloading requires 2 steps:
* when importing a targeted library, we have an internal hook that knows about this and automatically calls load(library) so we install our stuff.
* when a party does some remote execution on another party and uses a library, auto load it if it's present, if not, return an error.

Autoloading is basically integrating somewhere the sy.load call so we don't need to call it by hand, but it's an open question on how to do that.",think merge wo keep open long work autoloading autoloading targeted library internal hook automatically load library install stuff party remote execution another party library auto load present return error autoloading basically somewhere call need call hand open question,issue,positive,negative,neutral,neutral,negative,negative
800187240,"So instead of creating a directory as `../pysft/data` use a universal directory `~/.syft/data` or `~/.pysyft/data`.
I am new to this repository and a GSOC aspirant. I will create a PR to resolve this issue.",instead directory use universal directory new repository aspirant create resolve issue,issue,positive,positive,neutral,neutral,positive,positive
800104397,hey @madhavajay !! Made a PR #5309 that should solve the issue. Please let me know if anything has to be done. Ill look into it asap.,hey made solve issue please let know anything done ill look,issue,negative,negative,negative,negative,negative,negative
800084680,Don't forget to also make a PR in [SyMPC](https://github.com/OpenMined/SyMPC) with ```load_lib``` -> ```load``` ,forget also make load,issue,negative,neutral,neutral,neutral,neutral,neutral
799956147,"@dnabanita7 
`src/syft/lib/__init__.py`
Here there is an exception class: 
```
class VendorLibraryImportException(Exception):
```

You could edit this class to get a clear message about the exception. ([Link](https://stackoverflow.com/questions/1319615/proper-way-to-declare-custom-exceptions-in-modern-python))

Hope this helps!",exception class class exception could edit class get clear message exception link hope,issue,positive,positive,positive,positive,positive,positive
799927328,"> > > @madhavajay can somebody else add the tests for the object?
> > 
> > 
> > Its usually preferred if the original author of the code creates the tests as they know the code best.
> 
> Alright! Let me try. Another thing is I can't use `pytest` for testing as I get the ` couldn't import VendorLibrary error`.

As all code is fully tested on Mac, Linux and Windows in CI, its likely this is an issue with the way you are trying to run the tests. Please provide the exact command you are running and we can try to figure out what is going wrong.",somebody else add object usually preferred original author code know code best alright let try another thing ca use testing get could import error code fully tested mac likely issue way trying run please provide exact command running try figure going wrong,issue,positive,positive,positive,positive,positive,positive
799466075,"@madhavajay I have added in the tests the way we discussed above. Also, any suggestions on testing the `Datasets` without downloading the dataset would be really helpful. ",added way also testing without would really helpful,issue,negative,positive,positive,positive,positive,positive
799415439,"> > @madhavajay can somebody else add the tests for the object?
> 
> Its usually preferred if the original author of the code creates the tests as they know the code best.

Alright! Let me try. Another thing is I can't use ``pytest`` for testing as I get the `` couldn't import VendorLibrary error``.",somebody else add object usually preferred original author code know code best alright let try another thing ca use testing get could import error,issue,positive,positive,positive,positive,positive,positive
799409522,"> @dnabanita7 , the idea is to include docstring to make the code understable for new developers. Docstring of `klass.py` may be complex (I do not understand the full logic of this module but the new docstring should help to this) so could be useful start with smaller sections/modules or ask to `syft team` via slack

Sure thing! Thank you. I have asked on slack.",idea include make code new may complex understand full logic module new help could useful start smaller ask team via slack sure thing thank slack,issue,positive,positive,positive,positive,positive,positive
799409034,"> Hi @dnabanita7, this PR does not properly document the `klass.py` section of the codebase. You might want to understand the full `syft/ast` section and afterwards try to document it or to start writing about smaller sections of the codebase.
> 
> Thank you for your interest in Syft! If you need help on this, write on Slack to me, @jmaunon or @IrinaMBejan and you'll be guided.

Yes, I would want to learn codebase of ``ast/klass.py``. I will say to keep this pr open for now and i will make changes to it later.",hi properly document section might want understand full section afterwards try document start writing smaller thank interest need help write slack yes would want learn say keep open make later,issue,positive,positive,neutral,neutral,positive,positive
799139432,"Hi @prodigy803 go for it. As far as CI, I think if you just check the logs:

<img width=""832"" alt=""Screen Shot 2021-03-15 at 4 04 28 pm"" src=""https://user-images.githubusercontent.com/2882739/111110369-2368c200-85a8-11eb-8982-cc6880e9656a.png"">
```
2021-02-19T04:57:27.9371418Z ##[error]      raise RuntimeError('Event loop is closed')
```

So it looks like you should be able to just replicate the error on Windows and try to get it to not happen.
",hi prodigy go far think check screen shot error raise loop closed like able replicate error try get happen,issue,negative,positive,positive,positive,positive,positive
799135608,"> Hello @xutongye !
> Great job!
> 
> Could you also add in the `requirements.torch.txt` and `setup.cfg` to take `torch 1.8` into consideration now.
> Also, could you add the latest version of `opacus` (in the `supported_libs.txt` file) -- because it was needing `torch 1.8`

I think all of the torch==1.8.0 and python 3.9 requirements were taken care of in the linked PR which was merged, so this is just adding new functionality that 1.8.0 provides. ",hello great job could also add take torch consideration also could add latest version file needing torch think python taken care linked new functionality,issue,positive,positive,positive,positive,positive,positive
799077143,"> Is there a way I could push some code to this PR? I tried a couple of commands, made the changes but during push it says failed because permission denied.

Unfortunately pushing directly to another branch requires permission from the author which is usually only set on creating the PR and given to the maintainers of the destination repo which in this case is the Syft Core team.

So the other way to do this currently is either, create a PR to this original branch: `dnabanita7:slice`.

If you go to the PR section in GitHub it usually only lets you select your `repo:branch` to compare with the main `PySyft:branch` but if you edit the browser url to change the destination to be another `user:branch` then it works.

Or alternatively, since the most important thing is that the contributions of others are preserved, the easiest way is just to open a new PR against the main repo with the shared history of the branch you branched off.

Either is fine by me.",way could push code tried couple made push permission unfortunately pushing directly another branch permission author usually set given destination case core team way currently either create original branch slice go section usually select branch compare main branch edit browser change destination another user branch work alternatively since important thing easiest way open new main history branch branched either fine,issue,positive,positive,neutral,neutral,positive,positive
799076033,"> @madhavajay can somebody else add the tests for the object?

Its usually preferred if the original author of the code creates the tests as they know the code best.
",somebody else add object usually preferred original author code know code best,issue,positive,positive,positive,positive,positive,positive
799019173,"@dnabanita7 , the idea is to include docstring to make the code understable for new developers. Docstring of `klass.py`  may be complex (I do not understand the full logic of this module but the new docstring should help to this) so could be useful start with smaller sections/modules or ask to `syft team` via slack",idea include make code new may complex understand full logic module new help could useful start smaller ask team via slack,issue,positive,positive,positive,positive,positive,positive
798942916,"Hi, I wanted to get started on this problem but I have no idea about CI/CD. Is it okay if I am assigned this and I take some time to figure out the problem?",hi get problem idea assigned take time figure problem,issue,negative,neutral,neutral,neutral,neutral,neutral
798936261,"Hi @dnabanita7, this PR does not properly document the `klass.py` section of the codebase. You might want to understand the full `syft/ast` section and afterwards try to document it or to start writing about smaller sections of the codebase.

Thank you for your interest in Syft! If you need help on this, write on Slack to me, @jmaunon or @IrinaMBejan and you'll be guided. ",hi properly document section might want understand full section afterwards try document start writing smaller thank interest need help write slack,issue,positive,positive,positive,positive,positive,positive
798926092,@tudorcebere @madhavajay Could u give an idea of where to use pre-import hooks here? I have read the tutorials mentioned in #5273 ,could give idea use read,issue,negative,neutral,neutral,neutral,neutral,neutral
797898810,"Is there a way I could push some code to this PR? I tried a couple of commands, made the changes but during push it says failed because permission denied.",way could push code tried couple made push permission,issue,negative,neutral,neutral,neutral,neutral,neutral
797875204,"@jmaunon Awesome, I'll create a dummy PR, Also mentioning which parts I worked on. ",awesome create dummy also worked,issue,positive,positive,positive,positive,positive,positive
797542513,"@dnabanita7 and @bug-debug-done  , please, open a new PR making reference to this issue. In this way is easier to keep trace and more people can help",please open new making reference issue way easier keep trace people help,issue,positive,positive,neutral,neutral,positive,positive
797539960,"Thanks @felixfaisal  and @animesh-007 for your collaboration. Please, update the spreadsheet with your feedback. To keep trace, if you want you can open a dummy PR referencing this issue, or please, address here your updates (or even via slack).",thanks collaboration please update feedback keep trace want open dummy issue please address even via slack,issue,positive,positive,neutral,neutral,positive,positive
797420283,@madhavajay can somebody else add the tests for the object?,somebody else add object,issue,negative,neutral,neutral,neutral,neutral,neutral
797337420,"Hello @xutongye !
Great job!

Could you also add in the ```requirements.torch.txt``` and ```setup.cfg``` to take ```torch 1.8``` into consideration now.
Also, could you add the latest version of ```opacus``` (in the ```supported_libs.txt``` file) -- because it was needing ```torch 1.8```",hello great job could also add take torch consideration also could add latest version file needing torch,issue,positive,positive,positive,positive,positive,positive
797291867,@LaRiffle yes we should keep an eye on it and benchmark to see if theres something going on we can improve.,yes keep eye see there something going improve,issue,positive,neutral,neutral,neutral,neutral,neutral
797291011,"Hmmm interesting indeed! In my memory serialisation was marginally slower with torch than numpy (independently of the conversion), but this can addressed in time :)",interesting indeed memory marginally torch independently conversion time,issue,negative,positive,positive,positive,positive,positive
797286568,The API is under flux and all the working examples in CI are off `dev`. Its possible you are using `0.3.0` from PyPI. Try installing the `dev` branch directly and play with the examples which are in the examples folder as most of them are tested with CI against the `dev` directly.,flux working dev possible try dev branch directly play folder tested dev directly,issue,negative,positive,neutral,neutral,positive,positive
797285179,"@JTunis that looks perfect, any idea on ETA, or if we can get into a private beta?",perfect idea eta get private beta,issue,positive,positive,positive,positive,positive,positive
797283937,"@TTitcombe MNIST broke again, the latest fix is in `dev`.",broke latest fix dev,issue,negative,positive,positive,positive,positive,positive
797282827,"@LaRiffle I believe that the in memory reference is actually the same so there should be minimal performance impact. https://stackoverflow.com/questions/61526297/pytorch-memory-model-how-does-torch-from-numpy-work

Our plan was to use `torch` to serde `numpy` until such time as we decided if supporting it directly was necessary and to decouple it. For now this would be great, so I totally approve! 👍🏼 ",believe memory reference actually minimal performance impact plan use torch time decided supporting directly necessary would great totally approve,issue,positive,positive,positive,positive,positive,positive
797277302,"@bigmoumou and @cherrytora 
The current example is here:
https://github.com/OpenMined/PySyft/tree/dev/examples/differential-privacy/opacus

Its still a work in progress but you can remotely train MNIST with opacus.",current example still work progress remotely train,issue,negative,negative,neutral,neutral,negative,negative
797224755,"*shakes head* Well that took some time.

@Param-29 thanks for your help.
I have created a seperate issue for adding the new functionality which is in `torch==1.8.0` here: https://github.com/OpenMined/PySyft/issues/5295",head well took time thanks help issue new functionality,issue,positive,positive,positive,positive,positive,positive
797142334,"Hey @felixfaisal and @animesh-007! To clarify a bit, we have been auditing the source code so far in this spreadsheet: https://docs.google.com/spreadsheets/d/1ExD1EQIQtLx03a_h7lBPlvasVsmb38S02Bfw5a7Q62Y/edit#gid=1159978476

The plan is to go through each tutorial/example/readme file in the PySyft/Pygrid repo and assign each a status (as explained above), together with some short explanation in the document. Feel free to start with any that has not been yet documented. ",hey clarify bit source code far plan go file assign status together short explanation document feel free start yet,issue,positive,positive,positive,positive,positive,positive
797001251,"I am interested in writing the notebook. Let's discuss how to start, what to include.",interested writing notebook let discus start include,issue,negative,positive,positive,positive,positive,positive
796938744,"For a lot of functional transformers, they expect a `PIL` image as an input for torch version 1.6. They added in support for `torch.Tensor` for version `1.7`. So I suggest adding a minimum version for all these functional transformers (as I belive, we don't support PIL images currently) 

I would like suggestions on testing the `Datasets` as many of these do not download the dataset (or if they do, its time consuming and would make the tests slow) 

*PS: really sorry about the number of commits above, tried testing on the local machine for the local machine but couldn't*",lot functional expect image input torch version added support version suggest minimum version functional belive support currently would like testing many time consuming would make slow really sorry number tried testing local machine local machine could,issue,positive,negative,neutral,neutral,negative,negative
796748424,"@madhavajay I don't think that this issue is relevant
Let me provide a more clear example
`type(upcast(downcast([1,2,3]))[0])` gives `syft.lib.python.Int` while it should be just `int`
I got the idea that `upcast` should be inverse of `downcast`

Here is the example with pytorch optimizer, that can use the list param_groups as an argument

This code runs successfully
```
class SyNet(sy.Module):
    def __init__(self, torch_ref):
        super(SyNet, self).__init__(torch_ref=torch_ref)
        self.lin = nn.Linear(1,1)

    def forward(self, x):
        return self.lin(x)
    
model = SyNet(torch)

parameters = [{'params': model.parameters()[0], 'lr':0.1},
        {'params': model.parameters()[1], 'lr' : 0.01 }]

optimizer = torch.optim.Adadelta(parameters)
```

This one returns error 
```
class SyNet(sy.Module):
    def __init__(self, torch_ref):
        super(SyNet, self).__init__(torch_ref=torch_ref)
        self.lin = nn.Linear(1,1)

    def forward(self, x):
        return self.lin(x)
    
model = SyNet(torch)
model.send(client)

parameters = [{'params': model.parameters()[0], 'lr':0.1},
        {'params': model.parameters()[1], 'lr' : 0.01 }]

optimizer = client.torch.optim.Adadelta(parameters)
```
Stacktrace:
```
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-187-6514aa276e26> in <module>
     13         {'params': model.parameters()[1], 'lr' : 0.01 }]
     14 
---> 15 optimizer = client.torch.optim.Adadelta(parameters)
     16 
     17 

/opt/conda/lib/python3.8/site-packages/syft/ast/callable.py in __call__(self, *args, **kwargs)
     96                 )
     97 
---> 98                 self.client.send_immediate_msg_without_reply(msg=msg)
     99 
    100                 inherit_tags(

/opt/conda/lib/python3.8/site-packages/syft/core/node/common/client.py in send_immediate_msg_without_reply(self, msg, route_index)
    256             msg = msg.sign(signing_key=self.signing_key)
    257         debug(f""> Sending {msg.pprint} {self.pprint} ➡️  {msg.address.pprint}"")
--> 258         self.routes[route_index].send_immediate_msg_without_reply(msg=msg)
    259 
    260     def send_eventual_msg_without_reply(

/opt/conda/lib/python3.8/site-packages/syft/core/io/route.py in send_immediate_msg_without_reply(self, msg)
    165     ) -> None:
    166         debug(f""> Routing {msg.pprint} via {self.pprint}"")
--> 167         self.connection.send_immediate_msg_without_reply(msg=msg)
    168 
    169     def send_eventual_msg_without_reply(

/opt/conda/lib/python3.8/site-packages/syft/core/io/virtual.py in send_immediate_msg_without_reply(self, msg)
     68         self, msg: SignedImmediateSyftMessageWithoutReply
     69     ) -> None:
---> 70         self.server.recv_immediate_msg_without_reply(msg=msg)
     71 
     72     def send_immediate_msg_with_reply(

/opt/conda/lib/python3.8/site-packages/syft/core/io/virtual.py in recv_immediate_msg_without_reply(self, msg)
     38         self, msg: SignedImmediateSyftMessageWithoutReply
     39     ) -> None:
---> 40         self.node.recv_immediate_msg_without_reply(msg=msg)
     41 
     42     def recv_eventual_msg_without_reply(

/opt/conda/lib/python3.8/site-packages/syft/core/node/common/node.py in recv_immediate_msg_without_reply(self, msg)
    395         )
    396 
--> 397         self.process_message(msg=msg, router=self.immediate_msg_without_reply_router)
    398         try:
    399             pass

/opt/conda/lib/python3.8/site-packages/syft/core/node/common/node.py in process_message(self, msg, router)
    477                 traceback_and_raise(KeyError(log))
    478 
--> 479             result = service.process(
    480                 node=self,
    481                 msg=msg.message,

/opt/conda/lib/python3.8/site-packages/syft/core/node/common/service/obj_action_service.py in process(node, msg, verify_key)
     25         verify_key: Optional[VerifyKey] = None,
     26     ) -> None:
---> 27         msg.execute_action(node=node, verify_key=verify_key)
     28 
     29     @staticmethod

/opt/conda/lib/python3.8/site-packages/syft/core/node/common/action/function_or_constructor_action.py in execute_action(self, node, verify_key)
    124 
    125         # execute the method with the newly upcasted args and kwargs
--> 126         result = method(*upcasted_args, **upcasted_kwargs)
    127 
    128         # to avoid circular imports

/opt/conda/lib/python3.8/site-packages/torch/optim/adadelta.py in __init__(self, params, lr, rho, eps, weight_decay)
     34 
     35         defaults = dict(lr=lr, rho=rho, eps=eps, weight_decay=weight_decay)
---> 36         super(Adadelta, self).__init__(params, defaults)
     37 
     38     @torch.no_grad()

/opt/conda/lib/python3.8/site-packages/torch/optim/optimizer.py in __init__(self, params, defaults)
     50 
     51         for param_group in param_groups:
---> 52             self.add_param_group(param_group)
     53 
     54     def __getstate__(self):

/opt/conda/lib/python3.8/site-packages/torch/optim/optimizer.py in add_param_group(self, param_group)
    228         for param in param_group['params']:
    229             if not isinstance(param, torch.Tensor):
--> 230                 raise TypeError(""optimizer can only optimize Tensors, ""
    231                                 ""but one of the params is "" + torch.typename(param))
    232             if not param.is_leaf:

TypeError: optimizer can only optimize Tensors, but one of the params is syft.lib.python.Dict
```

This happens because in
https://github.com/pytorch/pytorch/blob/95d2318510371523b3406ae1d4818f8f0607bbc6/torch/optim/optimizer.py#L50
param_groups[0] is `syft.lib.python.Dict` instead of `dict`

`param_groups = [{'params': param_groups}]` makes optimizer crash later with given stacktrace",think issue relevant let provide clear example type upcast downcast got idea upcast inverse downcast example use list argument code successfully class self super self forward self return model torch one error class self super self forward self return model torch client recent call last module self self sending self none routing via self self none self self none self try pas self router log result process node optional none none self node execute method newly result method avoid circular self rho super self self self self param param raise optimize one param optimize one instead crash later given,issue,positive,positive,positive,positive,positive,positive
796657866,@tudorcebere added Documentations in Google style. I hope this one's fine.,added style hope one fine,issue,positive,positive,positive,positive,positive,positive
796556876,"Hey! I would like to fix this one. 
A small clarification: Do the images have to be from the organization's/OpenMined's website or can it be from other sources as well? I could not find an image with a white background from the official website/GitHub.",hey would like fix one small clarification well could find image white background official,issue,positive,negative,negative,negative,negative,negative
796016885,"Hi @avinsit123 !

We introduced a few new CI tests and one of them is to document all new code. Do you think you could provide documentation for the written code in a Google style format?

Thank you!",hi new one document new code think could provide documentation written code style format thank,issue,negative,positive,positive,positive,positive,positive
795948758,"I would like to contribute to this issue.
",would like contribute issue,issue,negative,neutral,neutral,neutral,neutral,neutral
795797373,"Same issue with Torch 1.7, syft 0.3.0 and 0.2.9

Does someone have a notebook that works end to end? Also do I need to use Duet as shown [here](https://github.com/OpenMined/PySyft/blob/dev/examples/secure-multi-party-computation/Duet/1-DS-1-DO/POC-MPCTensor-Duet-Party1-DS.ipynb). What I really want to do is run [this tutorial](https://blog.openmined.org/encrypted-training-on-mnist/) but it uses the same TorchHook that fails
 ",issue torch someone notebook work end end also need use duet shown really want run tutorial,issue,negative,positive,positive,positive,positive,positive
795684179,"Run the above scenarios again.
For the first one (with ```transpose```):
```
OrderedDict([(<UID: a6fdd4e889ad4adfbf082c6185d1b868>, <Storable: tensor([[1., 2., 3.],    [4., 5., 6.]])>)])
OrderedDict([(<UID: a6fdd4e889ad4adfbf082c6185d1b868>, <Storable: tensor([[1., 2., 3.],    [4., 5., 6.]])>), (<UID: aefb129edd1145fd8ccab202c71a7626>, <Storable: 0>), (<UID: e0160cb7bbf44916a5a6bf1b03afc8e6>, <Storable: 1>), (<UID: ac5cbe2ee2724a5499a1f16464abc6ad>, <Storable: tensor([[1., 4.],    [2., 5.],    [3., 6.]])>)])
```

For the second one with ```transpose_```
```
OrderedDict([(<UID: b79d0dd7b061472db623544d931e151f>, <Storable: tensor([[1., 2., 3.],    [4., 5., 6.]])>)])
OrderedDict([(<UID: b79d0dd7b061472db623544d931e151f>, <Storable: tensor([[1., 4.],    [2., 5.],    [3., 6.]])>), (<UID: 2eb4a17386b444cbb22629b721af2831>, <Storable: 0>), (<UID: 32b7ad97cc9b40a9a681eee9a4b34319>, <Storable: 1>), (<UID: 741e4fb891414c0fab010f2c62226c11>, <Storable: tensor([[1., 4.],    [2., 5.],    [3., 6.]])>)])
```
From my understanding for the second case (with ```transpose_```) the inplace method creates a new tensor and we also get back a new pointer ```x_ptr2``` to it.
I think this behavior is ok for us. If we had only one underlying object then when ```x_ptr2``` or ```x_ptr``` would get deleted/out of scope then we would send the delete message and we would remove the object from the store --> Now the other pointer (that did not get deleted/out of the scope) would point to a UUID that is no longer there.

The other objects from the store (1 and 0) are the parameters from the transpose?",run first one transpose storable tensor storable tensor storable storable storable tensor second one storable tensor storable tensor storable storable storable tensor understanding second case method new tensor also get back new pointer think behavior u one underlying object would get scope would send delete message would remove object store pointer get scope would point longer store transpose,issue,negative,positive,neutral,neutral,positive,positive
795590684,"@madhavajay I know it seems a little unconventional but I was thinking something like this for tests 

*allowlist.py*
```
allowlist[""torchvision.transforms.GaussianBlur""] = {
    ""return_type"": ""torchvision.transforms.GaussianBlur"",
    ""min_version"": ""0.8.0"",
    ""test_parameters"": ""(3, sigma=(0.1, 2.0)""
}
```
*allowlist_test.py*
```
if (allowlist[""torchvision.transforms.GaussianBlur""].version > SYS_VERSION){
exec(""torchvision.transforms.GaussianBlur"" + allowlist[""torchvision.transforms.GaussianBlur""].test_parameters)
}
```

This would solve the minimum version problem and would make the testing code a lot simpler. 

Also, I am still not sure how to test the **Datasets** without downloading them",know little unconventional thinking something like would solve minimum version problem would make testing code lot simpler also still sure test without,issue,negative,positive,positive,positive,positive,positive
795277096,"@bug-debug-done Welcome to OpenMined! It is very likely this issue will require multiple PRs, so many people can get involved. If you are interested to contribute, open a PR mentioning what file/module you are fixing when you start, to avoid conflicts. 

Hopefully this way we can make progress iteratively and faster. Also, feel free to ask questions on the openminded Slack (http://openmined.slack.com/)",welcome likely issue require multiple many people get involved interested contribute open fixing start avoid hopefully way make progress iteratively faster also feel free ask slack,issue,positive,positive,positive,positive,positive,positive
795140419,"I am new to open source can please assign this to me. 
",new open source please assign,issue,negative,positive,neutral,neutral,positive,positive
795114247,"Hey @jmaunon , So I wanted to know the tutorials in the readme folder, takes me to the examples using Duet, Do we have to try that out or find all existing tutorials on the web and do this. ",hey know folder duet try find web,issue,negative,neutral,neutral,neutral,neutral,neutral
795055363,"Hello @avinsit123 !

Open a PR and lets talk directly on that. :100:",hello open talk directly,issue,negative,positive,neutral,neutral,positive,positive
794982852,"@tudorcebere Okay I totally agree, since its working lets hold this off till after `0.5` but we should definitely revisit this as I believe at a minimum we can refactor a lot of this common code away and then remove it later if possible.",totally agree since working hold till definitely revisit believe minimum lot common code away remove later possible,issue,positive,negative,neutral,neutral,negative,negative
794849254,"@tudorcebere This is really awesome, its going to be so popular to use during development and debugging. I made some changes to fix the permission checks. I guess we need to add more tests to be sure this isn't going to accidentally leak any sensitive data.",really awesome going popular use development made fix permission guess need add sure going accidentally leak sensitive data,issue,positive,positive,positive,positive,positive,positive
794821901,"@TTitcombe I have added the workaround for MNIST and torchvision to the notebook.
Also it would be great, once this is finished, if we added this as a test using the notebook testing infrastructure we have. The normal notebook one probably needs some modification now if we want to run it on different paths but that should be easy to fix.

```
# this one does normal notebooks
# just add a bunch of asserts to the notebook to know its working
- name: Run notebook API examples
  if: ${{ matrix.os == 'ubuntu-latest' }}
  run: |
    ./scripts/nb_test.sh
    pytest examples/api -n auto


# this one does pairs of Duet notebooks where you require a Duet connection
- name: Run notebook Duet examples
  run: |
    python ./scripts/nb_duet_test.py
    cd tests/syft/notebooks/ && pytest . -n 1

```",added notebook also would great finished added test notebook testing infrastructure normal notebook one probably need modification want run different easy fix one normal add bunch notebook know working name run notebook run auto one duet require duet connection name run notebook duet run python,issue,positive,positive,positive,positive,positive,positive
794811219,"> > @Param-29 How did you run the tests? I don't see any test files?
> 
> @madhavajay
> 
> I checked by running a custom jupyter-notebook with code like this:
> `tens_client = torchvision.transforms.functional.adjust_contrast(tens,0.2).get(alice)`
> 
> I tried finding tests for `/tensor/allowlist.py` and `/tensorvision/allowlist.py` to get an idea of what is expected, but couldn't find any. Can you guide me to the location where these tests can be found?

`/tests/syft/lib/allowlist_test.py` tests all the torch ops but you will probably not want to re-use that since its very targetted at sending and retrieving stuff to test the torch ops.

I think what would be good is a test file inside `/tests/syft/lib/torchvision/` which basically just creates a `vm` like you did in your notebook and then runs through all these APIs and constructs them and makes sure they don't create errors.

For the dataset downloading if you use a new util class I created we can share the same data dir.
```python
# inside syft/util.py
def get_root_data_path() -> Path:
    # get the PySyft / data directory to share datasets between notebooks
    ...
```

That function should give you the `/PySyft/data` dir from anywhere inside the project.
Also I think we need to change it to this, since I had an issue on Linux with case sensitivity.
```python
-    while os.path.basename(here) != ""PySyft"" and here != here.parent:
+    while os.path.basename(here).lower() != ""pysyft"" and here != here.parent:
```

If this test is taking a long time to run due to the downloads of datasets we could try to monkey patch the method, turn off download=True or make sure that the code somehow runs without downloading the datasets in the test environment.",run see test checked running custom code like tried finding get idea could find guide location found torch probably want since sending stuff test torch think would good test file inside basically like notebook sure create use new class share data python inside path get data directory share function give anywhere inside project also think need change since issue case sensitivity python test taking long time run due could try monkey patch method turn make sure code somehow without test environment,issue,positive,positive,positive,positive,positive,positive
794802362,"@withshubh thanks for the PR, this is certainly interesting. I think if we can add some `# ignore rules` to the areas where deepsource has false positives and make sure that CI is passing then we can look at adding this. How do we actually consume these checks, is it via deepsource or can we get a CI check added to report on these? I would opt for a non failing test initially so that we can evaluate how this goes and if there is any value.",thanks certainly interesting think add ignore false make sure passing look actually consume via get check added report would opt non failing test initially evaluate go value,issue,positive,positive,positive,positive,positive,positive
794537984,"> @jmaunon Did we evaluate this against the existing `darglint` flake8 check?
> 
> I turned it off the other day because we were ignoring the results anyway and wanted to speed up CI, but if you run that locally you should see errors for every function and its google style docstring.
> 
> @nahuakang ?
> 
> ```
> # - name: Run darglint via flake8 - Ignore Errors
>   #   continue-on-error: true
>   #   run: |
>   #     pip install darglint flake8
>   #     flake8 src tests
> ```

@madhavajay . I have evaluated `darglint` flake 8 running the command `flake8 src tests` (in fact quite slow, xd) and it is not the same. `darglint` will fail if a docstring's description does not match the actual function/method implementation.

`docstr-coverage -p src` just returns a number, in this case the value of docstring coverage is 27.82%, then, this workflow compares `dev` branch with the current PR. If this value is lower means that the developer did not write any docstring, therefore the PR will be denied.

",evaluate flake check turned day anyway speed run locally see every function style name run via flake ignore true run pip install flake flake flake running command flake fact quite slow fail description match actual implementation number case value coverage dev branch current value lower developer write therefore,issue,negative,negative,neutral,neutral,negative,negative
793745122,@avinsit123 could you also open a PR in [SyMPC](https://github.com/OpenMined/SyMPC/blob/main/src/sympc/__init__.py#L23) for changing the name?,could also open name,issue,negative,neutral,neutral,neutral,neutral,neutral
793441447,"I have the same problem. I tried pysyft 0.2.8 + opacus 0.9.x and  pysyft 0.2.9 + opacus 0.9.x , but it still doesn't work.",problem tried still work,issue,negative,neutral,neutral,neutral,neutral,neutral
793201222,"@jmaunon Did we evaluate this against the existing `darglint` flake8 check?

I turned it off the other day because we were ignoring the results anyway and wanted to speed up CI, but if you run that locally you should see errors for every function and its google style docstring.

@nahuakang ?

```
# - name: Run darglint via flake8 - Ignore Errors
  #   continue-on-error: true
  #   run: |
  #     pip install darglint flake8
  #     flake8 src tests
```",evaluate flake check turned day anyway speed run locally see every function style name run via flake ignore true run pip install flake flake,issue,negative,positive,positive,positive,positive,positive
793137331,"Thanks for your feedback @IrinaMBejan. Actually I was not sure to place in `pr_test.yml` or separately

> That's a really great suggestion!
> Optionally - I think it would be better to have it inside the PR Tests yml file since it is designed to contain all jobs that run on pull request.
> 
> Also, the python-linting job has a flake8 command to validate the docstrings added are compliant with the Google style, which was recently commented out to speed up the development. It would be good to enable it back as soon as the docs team starts fixing the inline docs to avoid regressions, maybe module by module. Let me know if this sounds good to you @madhavajay.
> Together with the docstr-coverage, this should keep the documentation in great shape.

I agree with you, a new `.yml` is not needed. I have moved the funcionality in the existing `pr_test.yml` file",thanks feedback actually sure place separately really great suggestion optionally think would better inside file since designed contain run pull request also job flake command validate added compliant style recently speed development would good enable back soon team fixing avoid maybe module module let know good together keep documentation great shape agree new file,issue,positive,positive,positive,positive,positive,positive
793029571,"Is this implementation still a thing? I see all issues in the milestone marked as ""stale"".",implementation still thing see milestone marked stale,issue,negative,negative,negative,negative,negative,negative
792964952,Same issue here. Any tutorial for 0.2.x or 0.3.x to work with privacy engine in Opacus is really helpful. I have been waiting for 2 months so far.,issue tutorial work privacy engine really helpful waiting far,issue,negative,positive,positive,positive,positive,positive
792854039,"> Yes we have a first integration of Opacus!
> Check out: https://blog.openmined.org/pysyft-opacus-federated-learning-with-differential-privacy/

hi @LaRiffle , i tried to run the code in this blog just recently with pysyft 0.2.9, but there is an error with parameter has no `grad_sample` attribute. 
I have seen similiar issues asked but unsolved #4917  , so could u please share were there versions of Opacus and Pysyft that can run together at the time of the blog?",yes first integration check hi tried run code recently error parameter attribute seen unsolved could please share run together time,issue,positive,positive,positive,positive,positive,positive
792849967,"That's a really great suggestion!
Optionally - I think it would be better to have it inside the PR Tests yml file since it is designed to contain all jobs that run on pull request.

Also, the python-linting job has a flake8 command to validate the docstrings added are compliant with the Google style, which was recently commented out to speed up the development. It would be good to enable it back as soon as the docs team starts fixing the inline docs to avoid regressions, maybe module by module. Let me know if this sounds good to you @madhavajay.
Together with the docstr-coverage, this should keep the documentation in great shape. ",really great suggestion optionally think would better inside file since designed contain run pull request also job flake command validate added compliant style recently speed development would good enable back soon team fixing avoid maybe module module let know good together keep documentation great shape,issue,positive,positive,positive,positive,positive,positive
792848180,"> Hi @wlnancy please refer this blog
> https://blog.openmined.org/pysyft-opacus-federated-learning-with-differential-privacy/
hi @aanurraj, i have same issue with wlnancy. Have u tried to run the code in this blog? Any ideas on what versions are able to run together? Thanks.
",hi please refer hi issue tried run code able run together thanks,issue,positive,positive,positive,positive,positive,positive
792845810,"This still does not work, when i try to run https://blog.openmined.org/pysyft-opacus-federated-learning-with-differential-privacy/
How were they able to run both together at that time? i tried pysyft 0.2.8 + opacus 0.9.x also can not.
Any ideas on what versions of both library can work together?
@madhavajay 
",still work try run able run together time tried also library work together,issue,negative,positive,positive,positive,positive,positive
792412839,"I updated the compatibility report script and ran it.
It looks like a lot of the time you are just ignoring the tests rather than running them.

This rule on a pretty important op like `dot` is effectively saying that op is not supported on `1.7.1` for any data types so don't test it.


```json
{
  ""dot"": {
    ""profile"": ""default"",
    ""data_types"": [""common""],
    ""tensors"": [""tensor1""],
    ""not_available"": [
      {
        ""inputs"": [false, true, 0, 1, [0], [1]],
        ""lte_version"": ""1.7.0""
      },
      {
        ""data_types"": [""bool"", ""bfloat16""],
        ""lte_version"": ""1.7.0""
      },
      {
        ""data_types"": [""float16""],
        ""lte_version"": ""1.5.1""
      },
      {
        ""data_types"": [
          ""bool"",
          ""uint8"",
          ""int8"",
          ""int16"",
          ""int32"",
          ""int64"",
          ""float32"",
          ""float64"",
          ""float16"",
          ""bfloat16""
        ],
        ""lte_version"": ""1.7.1"",
        ""gte_version"": ""1.7.1""
      }
    ]
  }
}
```

<img width=""1391"" alt=""Screen Shot 2021-03-08 at 12 00 08 pm"" src=""https://user-images.githubusercontent.com/2882739/110265551-84702300-8007-11eb-9995-348a574baa6a.png"">

There are many other examples like this in the compatibility report where 1.7.1 has been set to just ignore the tests.
This isn't really the solution we were looking for.

Also it seems that `pin_memory` is broken?
<img width=""1549"" alt=""Screen Shot 2021-03-08 at 12 02 23 pm"" src=""https://user-images.githubusercontent.com/2882739/110265621-b71a1b80-8007-11eb-8c84-e5ce33b39167.png"">

",compatibility report script ran like lot time rather running rule pretty important like dot effectively saying data test dot profile default common tensor false true bool float bool float float float screen shot many like compatibility report set ignore really solution looking also broken screen shot,issue,positive,positive,positive,positive,positive,positive
792324142,"> @withshubh yeah, the protobuf fix should be reverted and there are a few fixes that should be added to the linting, then this should be good to go.

@tudorcebere 
- Reverted the fix in protobuf file
- Fixed linting issues using pre-commit (mypy in pre-commit is still failing)
- Added exclude pattern for protobuf files in .deepsource.toml file",yeah fix added good go fix file fixed still failing added exclude pattern file,issue,negative,positive,positive,positive,positive,positive
792280914,I believe CI seems to be failing for unassociated reasons. Any take on this??,believe failing unassociated take,issue,negative,neutral,neutral,neutral,neutral,neutral
792273107,"@withshubh yeah, the protobuf fix should be reverted and there are a few fixes that should be added to the linting, then this should be good to go. :+1: ",yeah fix added good go,issue,positive,positive,positive,positive,positive,positive
792240264,"A few notes on this @madhavajay :
* removal of `Int`, `Float` and other primitives that are non-iterable is possible 100%, there is no actual need of them if we don't need an `id` set on them.
* removal of `List`, `Dict` and other primitives that are iterable is possible, but we won't be able to use templating/actually type them. Here a metaclass would be really handy (the testing should remain tho)
* removal of `Iterator` I would say it's not possible.

If we implement the `client.send(obj)` or `syft.send(obj, client)` we might be able to remove a ton of code, but first we need to be sure that's the desired API (I am totally into it). Are we sure we want to make this refactor for `0.5`? I would say it would be nice to release the new API with `0.5` and then take our time to clean the codebase at our own peace to be sure we get it right this time.",removal float possible actual need need id set removal list iterable possible wo able use type would really handy testing remain tho removal would say possible implement client might able remove ton code first need sure desired totally sure want make would say would nice release new take time clean peace sure get right time,issue,positive,positive,positive,positive,positive,positive
791980474,"Hi @tudorcebere :wave: 

Thank You for your review! :sparkling_heart: 

Shall I revert the fix from protobuf file? :thinking: 

Also, Just to let you know all these fixes are made using the DeepSource auto-fix feature. :grin: ",hi wave thank review shall revert fix file thinking also let know made feature grin,issue,positive,neutral,neutral,neutral,neutral,neutral
791933952,"Hi @withshubh, thanks for your interest in Syft!

Nice fixes here! One comment:
* don't touch the protobuf files, as they are automatically generated

@madhavajay, is a thing of interest to keep a CI integration test with DeepSource or we should remove the .toml file? The issues found by the tool are super awesome and it might be a nice thing to have.

",hi thanks interest nice one comment touch automatically thing interest keep integration test remove file found tool super awesome might nice thing,issue,positive,positive,positive,positive,positive,positive
791507048,"@madhavajay  **PR ready to be merged**, do let me know if you think anything else needs to be added.  


**Functional transformers**

- [x] adjust_brightness 
- [x] adjust_contrast
- [x] adjust_gamma
- [x] adjust_hue
- [x] adjust_saturation
- [x] adjust_sharpness
- [x] affine 
- [x] autocontrast
- [x] center_crop
- [x] crop
- [x] equalize
- [x] erase
- [x] five_crop
- [x] gaussian_blur
- [x] hflip
- [x] invert
- [x] normalize
- [x] pad
- [x] perspective
- [x] pil_to_tensor
- [x] to_grayscale
",ready let know think anything else need added functional affine crop equalize erase invert normalize pad perspective,issue,negative,positive,positive,positive,positive,positive
791484629,#5258: I have also added in some features which are available in the latest torchvision (in torch 1.8) ,also added available latest torch,issue,negative,positive,positive,positive,positive,positive
791416929,"@madhavajay We will also have to make changes in the allowlist(for torch) because as torch removed support for a lot of things (in Torch 1.8)
Example: 
`torch.fft`

I'd like to work on the issue after merging torchvision api. ",also make torch torch removed support lot torch example like work issue,issue,positive,neutral,neutral,neutral,neutral,neutral
791395165,"@madhavajay 
Finally! The **duet_test** was hitting the wrong route... 
Seems a bit late though... ",finally wrong route bit late though,issue,negative,negative,negative,negative,negative,negative
791318917,"@madhavajay I have re-prioritized this as we need simple np.array forwarding over the network for SyMPC (for the moment I just convert np array to th tensors, but it will have an impact on performance)",need simple forwarding network moment convert array th impact performance,issue,negative,neutral,neutral,neutral,neutral,neutral
790781253,"Following are the list of tests 

**Transforms** 
- [x] ToPILImage 
- [x] RandomErasing
- [x] Normalize
- [x] RandomOrder
- [x] RandomChoice
- [x] GaussianBlur
- [x] TenCrop
- [x] Scale **warning, depricated**
- [x] Resize
- [x] RandomVerticalFlip
- [x] RandomSizedCrop **warning, depricated**
- [x] RandomRotation
- [x] RandomResizedCrop
- [x] RandomPerspective
- [x] RandomHorizontalFlip
- [x] RandomGrayscale
- [x] RandomCrop
- [x] RandomApply
- [x] RandomAffine
- [x] Pad
- [x] Grayscale
- [x] CenterCrop
- [x] ColorJitter
- [x] FiveCrop

**Datasets**

I couldn't test many datasets as they are dependent on huge data-sets which need to be downloaded, following are the classes I tested

- [x] EMNIST
- [x] CIFAR10
- [x] CIFAR100
- [x] FakeData
- [x] FashionMNIST
- [x] Flickr8k
",following list normalize scale warning resize warning pad could test many dependent huge need following class tested,issue,negative,positive,positive,positive,positive,positive
790758492,"I'm excited for [LambCI](https://github.com/lambci/serverless-actions) to be released. Not a solution right now, but good to keep an eye on!",excited solution right good keep eye,issue,positive,positive,positive,positive,positive,positive
790606983,"> @madhavajay I am working on tests for these now, I didn't really understand these
> 
> > we need to start thinking about introducing a special way to provide these from the DO side easily to load into the store, or from the DS side without passing in a remote path (maybe by only using an approved path from the DO side.

Great news on the tests! :)

DM me on Slack and I can speak more about the remote path stuff. It doesn't need to be done in this PR but its something that we should think about adding soon.",working really understand need start thinking special way provide side easily load store side without passing remote path maybe path side great news slack speak remote path stuff need done something think soon,issue,positive,positive,positive,positive,positive,positive
790554030,"@madhavajay I am working on tests for these now, I didn't really understand these 
> we need to start thinking about introducing a special way to provide these from the DO side easily to load into the store, or from the DS side without passing in a remote path (maybe by only using an approved path from the DO side.",working really understand need start thinking special way provide side easily load store side without passing remote path maybe path side,issue,positive,positive,positive,positive,positive,positive
790494747,"@Param-29 this is awesome work!! Can we work on a test for all of these just to make sure they work as expected.
I also think we need to start thinking about introducing a special way to provide these from the DO side easily to load into the store, or from the DS side without passing in a remote path (maybe by only using an approved path from the DO side.",awesome work work test make sure work also think need start thinking special way provide side easily load store side without passing remote path maybe path side,issue,positive,positive,positive,positive,positive,positive
790354415,"> @xutongye this is an awesome job! ❤️
> My only thought is that is it now no longer possible to remotely construct one of these types?
> 
> ```
> eigenvalues_ptr = duet.python.ValuesIndices.eigenvalues()
> ```
> 
> I don't know if thats hugely important but it would be nice if this functionality was somehow still possible.

We can partially do that. Look at `returntypes_test.py`.",awesome job thought longer possible remotely construct one know thats hugely important would nice functionality somehow still possible partially look,issue,positive,positive,positive,positive,positive,positive
790322367,"yes, sure! this PR looks messy. I will do that next time.",yes sure messy next time,issue,negative,positive,neutral,neutral,positive,positive
790131625,"@madhavajay 
I must have done something wrong the first time... Cannot figure out what, so I've restarted with a fresh install just in case. 
The `allowlist_test.json` was missing some ""not_available"" rules, I've updated it.
Things should be better : 
![pytest_torch_mark](https://user-images.githubusercontent.com/29433028/109882090-9eada800-7c79-11eb-8070-00eb32503efe.png)

About the duet_test that is failing in slow, I'll try something tomorrow.

",must done something wrong first time figure fresh install case missing better failing slow try something tomorrow,issue,negative,positive,neutral,neutral,positive,positive
789375697,"@xutongye this is an awesome job! ❤️
My only thought is that is it now no longer possible to remotely construct one of these types?
```
eigenvalues_ptr = duet.python.ValuesIndices.eigenvalues()
```

I don't know if thats hugely important but it would be nice if this functionality was somehow still possible.",awesome job thought longer possible remotely construct one know thats hugely important would nice functionality somehow still possible,issue,positive,positive,positive,positive,positive,positive
789353314,"@dnabanita7 if you run the `pre-commit` checks locally you can see the errors which are failing in CI.

Install: https://pre-commit.com/

And then run:
```
$ pre-commit run --all-files
```",run locally see failing install run run,issue,negative,neutral,neutral,neutral,neutral,neutral
789337720,"@marcalph The torch tests are failing (they don't run in the pr_tests.yml in CI only on merge).
I ran them on Python 3.8 and Torch 1.7.1 and there are hundreds of ops which have not been updated.
My guess is there are some issues with `scripts/autofix_allowlist_test.py`. The other thing which needs to be done is to confirm that there is no new functionality we need to add.

https://github.com/pytorch/pytorch/releases

I read the notes and diffed both `dir(torch)` and `dir(torch.Tensor)` and they are identical.

If you can fix the script so it generates a working .json file to pass the tests for `1.7.1` that would be greatly appreciated. ",torch failing run merge ran python torch guess thing need done confirm new functionality need add read torch identical fix script working file pas would greatly,issue,negative,positive,positive,positive,positive,positive
788921862,Hi @tudorcebere could you refer me to the PR as I really wanted to know the solution to this issue. I am not able to find the PR. Thanks,hi could refer really know solution issue able find thanks,issue,positive,positive,positive,positive,positive,positive
788910990,"My bad! it works fine now.
What is a circular import?",bad work fine circular import,issue,negative,negative,negative,negative,negative,negative
788814981,"Hello @apzl,

Your approach does not suite our needs, the right approach would be to target the requests part of the API and clean that, your approach hit all of our codebase. :smile: 

I will close this PR for now, thanks for your interest in Syft!",hello approach suite need right approach would target part clean approach hit smile close thanks interest,issue,positive,positive,positive,positive,positive,positive
788813815,"Hello,

This issue has been addressed by a previous PR. Thanks for your interest in Syft! :+1: ",hello issue previous thanks interest,issue,positive,positive,neutral,neutral,positive,positive
788715490,"@madhavajay Thank you so much for your input!

I've updated the matrices now, so apart from duet things look fine.
As for the failing duet test, I am on linux so I'll keep looking. it looks weird to me an exception is raised because an uuid seems empty post, so I'm guessing it comes from serde ?
I'm new to protobuf so I am slow
",thank much input matrix apart duet look fine failing duet test keep looking weird exception raised empty post guessing come new slow,issue,negative,negative,neutral,neutral,negative,negative
788653870,"@dnabanita7 we use those commands in CI, so it's possible this is related to your current branch.
Are you in a particular branch you can share to test this?
Do you have a circular import or other issue in your branch?",use possible related current branch particular branch share test circular import issue branch,issue,negative,positive,neutral,neutral,positive,positive
787986008,"I'd like to work on the issue, I am still not sure about the testing methodology. ",like work issue still sure testing methodology,issue,positive,positive,positive,positive,positive,positive
787881428,"@marcalph Great work and good questions.

Regarding the `allowlist_test.json` file, it used to be handled manually but now the script `autofix_allow_list_test.py` automatically updates it. That is why you will see a rule like:
```json
{
    ""data_types"": [
        ""bool"",
        ""float16""
    ],
    ""lte_version"": ""1.7.1"", << REMOVE THIS?
    ""gte_version"": ""1.7.1"" 
}
```

This is fine, since this rule is just for `1.7.1` and the other existing rule takes care of older versions. Theres minimal advantage in merging these into one rule by hand since the result is the same.

For the tests if you check the `pr_tests.yml` file you can see how they run. The `libs` tests installs the packages inside `requirements/supported_libs.txt`. For the failing `test_duet` in `slow` are you on macOS? There is a situation where that tests sometimes stalls on mac.

As far as torch version matrix, yes, I have removed older torch versions from `dev` so your PR should add `1.7.1` to the existing `1.6.0` and `1.7.0`.",great work good regarding file used handled manually script automatically see rule like bool float remove fine since rule rule care older there minimal advantage one rule hand since result check file see run inside failing slow situation sometimes mac far torch version matrix yes removed older torch dev add,issue,positive,positive,positive,positive,positive,positive
787877705,@Koukyosyumei Awesome work! I see your PR and i'll take a look shortly. 😊,awesome work see take look shortly,issue,positive,positive,positive,positive,positive,positive
787686790,"@madhavajay @uid42 
Since there has been no activity for a while, I created a new PR based on @uid42. I solved the problem of getting a remote model, the issue of sending listpointer has not been solved yet, though it works well in 0.4.  ",since activity new based problem getting remote model issue sending yet though work well,issue,negative,positive,neutral,neutral,positive,positive
786693113,"Looks good! it would be good to have tests that check if this now actually works remotely, but I suppose we need `.send()` to be working first.",good would good check actually work remotely suppose need working first,issue,positive,positive,positive,positive,positive,positive
786527256,"Hi, 

`torch==1.7.1` does look good thanks  to `autofix_allow_list_test.py` but I have a couple more questions (sorry):
- If I got this right, in the autofix process ""skip rules"" are added to `allowlist_test.json`,  is this file maintained manually? do I need to refine some of these rules e.g.:

```
 ""__ifloordiv__"": {
        ""profile"": ""tensor_float_division_method_v150"",
        ""not_available"": [
          {
            ""data_types"": [
              ""bool"",
              ""float16""
            ],
            ""lte_version"": ""1.7.0""
          },
          {
            ""data_types"": [
              ""bool"",
              ""float16""
            ],
            ""lte_version"": ""1.7.1"", << REMOVE THIS?
            ""gte_version"": ""1.7.1"" 
          }
        ]
      }
```
- Other markers in the test suite are almost fine : 
   * marker `fast` runs OK
   * for the `libs` one, where I had to install a couple dependencies should these be added to `requirements.dev.txt`? (namely `opacus`, `openmined_psi`, `python-dp`) 
   * for the `slow` one , I'm still looking into an error with `test_duet`

- On the CI side, to get this straights is it just about changing the *torch-version* var in the matrices for the `pr_tests.yml` and `merge_test.yml` workflows?

Thanks!
  ",hi look good thanks couple sorry got right process skip added file manually need refine profile bool float bool float remove test suite almost fine marker fast one install couple added namely slow one still looking error side get matrix thanks,issue,positive,positive,positive,positive,positive,positive
786476804,"Searching through the code it seems that the `msg_history` only contains received messages. Setting `verbose=True` helps in getting a clearer image. I am still puzzled though how this corresponds to actual communication between workers. See this example:
```python
alice = sy.VirtualWorker(hook, id='alice', verbose=True)
x = th.Tensor([1,2,3])
x_p = x.send(alice)
x = x_p.get()
```
Which prints:
```
worker <VirtualWorker id:alice #objects:0> received ObjectMessage
worker <VirtualWorker id:alice #objects:1> received ObjectRequestMessage
```
After receiving the ObjectRequestMessage Alice must have sent the tensor back to the central orchestrator (me), but I don't see her sending anything? ",searching code received setting getting clearer image still puzzled though actual communication see example python hook worker id received worker id received must sent tensor back central orchestrator see sending anything,issue,negative,neutral,neutral,neutral,neutral,neutral
785804974,"For the moment there is an issue when we want to call a method that is ""native"" to the ```torch.tensor``` and the custom tensor is remote.

Currently, I am trying to come with a fix for this using metaclasses (the hard part might be to catch the differences between properties and methods).",moment issue want call method native custom tensor remote currently trying come fix hard part might catch,issue,negative,negative,negative,negative,negative,negative
785532378,@IonesioJunior we can ignore that failing MacOS integration test for now.,ignore failing integration test,issue,negative,neutral,neutral,neutral,neutral,neutral
784847908,Ingoring MacOS TenSEAL Duet Integration test fail,duet integration test fail,issue,negative,negative,negative,negative,negative,negative
784713949,"@AlanAboudib I fixed the issue that was preventing the Loss from going down.
I made sure that the results of the `output`, `hidden` were the right types after getting them from the LSTM return tuple. This is something we are working on but for now the easiest way is to just re-create them by passing them to their remote constructors.

I wonder what is left on this notebook now that this is fixed?

<img width=""752"" alt=""Screen Shot 2021-02-24 at 12 57 37 pm"" src=""https://user-images.githubusercontent.com/2882739/108941141-489c9b80-76a0-11eb-8749-2db8bbcc3ca9.png"">
",fixed issue loss going made sure output hidden right getting return something working easiest way passing remote wonder left notebook fixed screen shot,issue,negative,positive,positive,positive,positive,positive
784674621,"I believe this is blocked by the ability to obtain a pointer to a remote model, which is something we are currently looking at for some other PRs, so I will circle back here when its fixed.",believe blocked ability obtain pointer remote model something currently looking circle back fixed,issue,negative,neutral,neutral,neutral,neutral,neutral
783981978,@madhavajay would you be also interested in replacing the extra list in setup.cfg by requirements.txt  so you would maintain only one location and do not think twice where else the requirements shall be updated if needed...? ,would also interested extra list would maintain one location think twice else shall,issue,negative,positive,positive,positive,positive,positive
783876113,@socd06 You could report a bug with Kali saying their packages are vulnerable. Who's watching the watchers? 😂,could report bug kali saying vulnerable watching,issue,negative,negative,negative,negative,negative,negative
783874753,"@bcebere Totally open to suggestions for improvement. I assume we will need to hash it at least once, and surely at the time of signing to make sure it isn't changed? We could use something else to hash the message, perhaps an interface allowing a custom hash implementation on any given message and a fallback to the hash of the bytes after serialization?",totally open improvement assume need hash least surely time make sure could use something else hash message perhaps interface custom hash implementation given message fallback hash serialization,issue,negative,positive,positive,positive,positive,positive
783304711,Hello! For the moment this issue is not available since it is targeting a previous version (0.2.x). Thank you for pointing this out!,hello moment issue available since previous version thank pointing,issue,negative,positive,positive,positive,positive,positive
783180274,Hello @gmuraru I am a newbie to openmined and would love to make my hands dirty with this project. Can you please make me the assignee? Thanks!:),hello would love make dirty project please make assignee thanks,issue,positive,positive,neutral,neutral,positive,positive
783129985,"Since we have completely overhauled the `StorableObject` code im going to assume this isn't an issue anymore.
There ",since completely code going assume issue,issue,negative,positive,neutral,neutral,positive,positive
783129057,I will close this for now since the cause is a bad build of `torch` and not our library. If this comes back we can re-investigate.,close since cause bad build torch library come back,issue,negative,negative,negative,negative,negative,negative
783126290,@uid42 are you able to create a PR against the `dev` branch then we can discuss the issues and how to help get it fixed? 😊,able create dev branch discus help get fixed,issue,positive,positive,positive,positive,positive,positive
783111058,@H4LL Glad to hear its working. I think we might need to replay these over `dev` since it diverged from `0.4` when I accidentally rebased it and rewrote the old `0.4` history.... Since this is just notebook changes it shouldn't be too hard to just cherry pick all the changes.,glad hear working think might need replay dev since accidentally old history since notebook hard cherry pick,issue,negative,positive,positive,positive,positive,positive
783095064,"[I've got something here which works: ](https://github.com/H4LL/PySyft/blob/0.4/examples/duet/vertical_learning/advanced/MNIST/DS.ipynb)

PR is [here](https://github.com/OpenMined/PySyft/pull/5205#issuecomment-783098356)

It took an hour++ to run though",got something work took run though,issue,negative,neutral,neutral,neutral,neutral,neutral
782950254,@avinash463 We are working on some tooling which will make this much quicker and easier but if you wish to start I would look at the existing library support inside the `dev` branch to help understand how it works.,working tooling make much easier wish start would look library support inside dev branch help understand work,issue,positive,positive,positive,positive,positive,positive
782950098,"@avinash463 Theres an active PR and we are working on it: https://github.com/OpenMined/PySyft/pull/5152

Contributions are always welcome. 😊",there active working always welcome,issue,positive,positive,positive,positive,positive,positive
782583020,"> os.linesep fails because requirements.txt uses \n only

quite curious, I would expect that this shall work since we want to run it on all OS",quite curious would expect shall work since want run o,issue,negative,negative,neutral,neutral,negative,negative
782479855,I would like to take this issue,would like take issue,issue,negative,neutral,neutral,neutral,neutral,neutral
782479268,"Correct me if I'm wrong, but with this PR from @animesh-007, it's just necessary to update the CI",correct wrong necessary update,issue,negative,negative,negative,negative,negative,negative
782228067,"@madhavajay Yes, that should be fine if you have add a sentence along the line of ""Unless otherwise specified in a file header, all code is licensed: ..."" to your LICENSE file.

You can see why that is a bit annoying, because the reader then has to scan the whole code base for such exceptions.  The alternative is what I proposed above, that you add a section to the license file. What you suggest is a valid option, though.",yes fine add sentence along line unless otherwise file header code licensed license file see bit annoying reader scan whole code base alternative add section license file suggest valid option though,issue,negative,negative,negative,negative,negative,negative
781894531,"@animesh-007 to answer your question about doing similar fixes, replacing random is fine, its only being used for printing a number to match in logging so actually we could remove it but for now its fine. As for removing `asserts` if they cause exceptions if they fail then we should replace them with another `raise` so that the code fails in a similar way.",answer question similar random fine used printing number match logging actually could remove fine removing cause fail replace another raise code similar way,issue,negative,negative,neutral,neutral,negative,negative
781887710,@stefanv Can this PSF license statement just be added to the top of any file that was copied and modified from the CPython repo tests?,license statement added top file copied,issue,negative,positive,positive,positive,positive,positive
781886282,"@animesh-007 Thanks, I got a weird mypy issue when I pulled down this PR and I fixed it so im just going to merge this and you can open a new one. 👍🏼 ",thanks got weird issue fixed going merge open new one,issue,negative,negative,neutral,neutral,negative,negative
781884517,@public hahahah lol... welcome. Syft is a very cool library.,public welcome cool library,issue,positive,positive,positive,positive,positive,positive
781874371,Hi @curt-mitch we should probably just ignore these as they are in the test files that are copied directly from the cpython repo: https://github.com/python/cpython,hi probably ignore test copied directly,issue,negative,positive,neutral,neutral,positive,positive
781842889,"@madhavajay As of now, I am continuing with a different version but would definitely like to explore the problem. 
Please run the following commands so that we could investigate if it is an OS issue (ubuntu) or a python version issue
```sh
conda create -n bug_5019 python=3.7.9
conda activate bug_5019
pip install pre-commit
pip install -e . 
pre-commit run --all-files 
```

This does give me the issue I mentioned above. ",different version would definitely like explore problem please run following could investigate o issue python version issue sh create activate pip install pip install run give issue,issue,positive,neutral,neutral,neutral,neutral,neutral
781815510,@xutongye This is a really awesome job cleaning up the whole ugly Wrapper system.,really awesome job cleaning whole ugly wrapper system,issue,negative,positive,positive,positive,positive,positive
781797650,"Yes, that helps.

Still, the big impact comes from the signing logic.
So, 
 1. Do we need to sign the already encrypted data too?
 2. If yes, do we need to re-serialize the deserialized object for that? if storable object can keep a hash for the signing logic directly, that could speed-up things.",yes still big impact come logic need sign already data yes need object storable object keep hash logic directly could,issue,positive,positive,neutral,neutral,positive,positive
781720778,@bcebere We also need something similar for Opacus so we can remotely attach the PrivacyEngine to the model. The way the SyModule currently works is its a thin veneer over the submodule layers. Perhaps we can simply create a real torch module on either side inside the SyModule to help attach all of the layers to thus providing a very real normal model to get a pointer to. The main issue is that `send` requires serialization so if we want to send the whole model we need to support sending everything the model supports where as currently we just invoke the creation of the same modules remotely. I would love some input on the best way to tackle this one.,also need something similar remotely attach model way currently work thin veneer perhaps simply create real torch module either side inside help attach thus providing real normal model get pointer main issue send serialization want send whole model need support sending everything model currently invoke creation remotely would love input best way tackle one,issue,positive,positive,positive,positive,positive,positive
781718587,"@bcebere The typecheck is gone and we have an idea about building a client side cache, do you think that would help improve this scenario?",gone idea building client side cache think would help improve scenario,issue,positive,neutral,neutral,neutral,neutral,neutral
781717084,Can we get a Numeric type which is used in most cases for Collections seeing as there should be a lot of instances where that will be the case.,get type used seeing lot case,issue,negative,neutral,neutral,neutral,neutral,neutral
781714058,I think we should be able to fix this with a client side registry which tracks duplicates and introduce the unique shared network `var_name`. See notion: https://www.notion.so/openmined/2021-02-10-0-5-API-Refactor-f636ae0ff25f4921a84505ac7bd97ac7,think able fix client side registry introduce unique network see notion,issue,negative,positive,positive,positive,positive,positive
781711842,@Param-29 that is strange. I have installed Python 3.7.9 on macOS and I don't see that issue on your branch. If this is related to that specific version of Python and / or Ubuntu 20 we might see it when Ubuntu 20 is the default in GitHub CI. Until then perhaps continue with a different version or try to fix the issue that Mypy complains about and see if it passes in CI as well.,strange python see issue branch related specific version python might see default perhaps continue different version try fix issue see well,issue,negative,negative,neutral,neutral,negative,negative
781345221,It can be closed - we would deal with it in SyMPC when the time would come,closed would deal time would come,issue,negative,negative,neutral,neutral,negative,negative
781315880,"I also noticed a similar issue. For both versions, `0.800` and `0.782`, I am getting the following error
Command: 
`pre-commit run --all-files`
Output 
```
Check python ast.........................................................Passed
Trim Trailing Whitespace.................................................Passed
Check docstring is first.................................................Passed
Check JSON...............................................................Passed
Check for added large files..............................................Passed
Check Yaml...............................................................Passed
Check for merge conflicts................................................Passed
Check that executables have shebangs.....................................Passed
Debug Statements (Python)................................................Passed
Tests should end in _test.py.............................................Passed
Fix requirements.txt.....................................................Passed
flake8...................................................................Passed
black....................................................................Passed
mypy.....................................................................Failed
- hook id: mypy
- exit code: 1

src/syft/lib/python/bool.py:276: error: ""bool"" has no attribute ""as_integer_ratio""
src/syft/lib/python/int.py:336: error: ""as_integer_ratio"" undefined in superclass
Found 2 errors in 2 files (checked 264 source files)

flynt....................................................................Passed
isort (python)...........................................................Passed

```

python3 version: `3.7.9`
PR that I am working on: #5131 
My OS: `ubuntu-20.04`

Note: CI uses python `3.8.7`
https://github.com/OpenMined/PySyft/pull/5157/checks?check_run_id=1911426541#step:7:83

**Updating to python `3.8.6` does solve the issue for me.** 
```
(py387) param@param:~/git-projects/PySyft$ pre-commit run --all-files
[INFO] Installing environment for https://github.com/pre-commit/pre-commit-hooks.
[INFO] Once installed this environment will be reused.
[INFO] This may take a few minutes...
[INFO] Installing environment for https://gitlab.com/pycqa/flake8.
[INFO] Once installed this environment will be reused.
[INFO] This may take a few minutes...
[INFO] Installing environment for https://github.com/pre-commit/mirrors-mypy.
[INFO] Once installed this environment will be reused.
[INFO] This may take a few minutes...
[INFO] Installing environment for local.
[INFO] Once installed this environment will be reused.
[INFO] This may take a few minutes...
Check python ast.........................................................Passed
Trim Trailing Whitespace.................................................Passed
Check docstring is first.................................................Passed
Check JSON...............................................................Passed
Check for added large files..............................................Passed
Check Yaml...............................................................Passed
Check for merge conflicts................................................Passed
Check that executables have shebangs.....................................Passed
Debug Statements (Python)................................................Passed
Tests should end in _test.py.............................................Passed
Fix requirements.txt.....................................................Passed
flake8...................................................................Passed
black....................................................................Passed
mypy.....................................................................Passed
flynt....................................................................Passed
isort (python)...........................................................Passed
(py387) param@param:~/git-projects/PySyft$ python --version
Python 3.8.6
```",also similar issue getting following error command run output check python ast trim trailing check first check check added large check check merge check python end fix flake black hook id exit code error bool attribute error undefined superclass found checked source python python version working o note python python solve issue param param run environment environment may take environment environment may take environment environment may take environment local environment may take check python ast trim trailing check first check check added large check check merge check python end fix flake black python param param python version python,issue,negative,positive,neutral,neutral,positive,positive
781197612,We also need the top level to work properly.,also need top level work properly,issue,negative,positive,positive,positive,positive,positive
781195889,I am closing this since A) the statement is incorrect and B) the mypy checks have been fixed and upgraded in another PR.,since statement incorrect fixed another,issue,negative,positive,neutral,neutral,positive,positive
781195441,"Also try installing tf_encrypted:
```
$ pip install tf_encrypted
```
https://github.com/OpenMined/PySyft/issues/4875",also try pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
781194819,@harikrishnankh what python version are you using? Python 3.9 is not supported by syft==0.2.9 or any version of syft currently.,python version python version currently,issue,negative,neutral,neutral,neutral,neutral,neutral
781192599,"@prajotsl123  An end-to-end example with PyGrid and Workers is coming soon, stay tuned.",example coming soon stay tuned,issue,negative,neutral,neutral,neutral,neutral,neutral
781191265,@sbasu26 Did you get a chance to run my commands or get this working?,get chance run get working,issue,negative,neutral,neutral,neutral,neutral,neutral
781187820,"I believe this is related to the scenario in which the request is made:
https://github.com/OpenMined/PySyft/issues/5170

This does need to be fixed.",believe related scenario request made need fixed,issue,negative,positive,neutral,neutral,positive,positive
781150610,We have decided to offer a separate pathway without `setattr` so this can be closed.,decided offer separate pathway without closed,issue,negative,negative,neutral,neutral,negative,negative
781144364,"Last check worked, so we can close this until the GPU CI tests.",last check worked close,issue,negative,neutral,neutral,neutral,neutral,neutral
781135602,This will be handled when we build the client side registry to track pointers.,handled build client side registry track,issue,negative,neutral,neutral,neutral,neutral,neutral
781131006,@LaRiffle some of these orgs have been added recently. Do you know where we can get a final definitive list of orgs so they can added in one go?,added recently know get final definitive list added one go,issue,negative,neutral,neutral,neutral,neutral,neutral
781128095,"Most of this is completed, other libraries will be approached once we are ready to plan more third party support.",ready plan third party support,issue,positive,positive,neutral,neutral,positive,positive
781124186,I will close this for now since we support `torch==1.4.0` so the main thing preventing Arm usage is finding an up to date Python wheel of PyTorch which is a little out of our scope. We have a separate issue to track testing on Arm64 CI and once Apple's M1s are readily available on CI we can add more Arm tests.,close since support main thing arm usage finding date python wheel little scope separate issue track testing arm apple readily available add arm,issue,negative,positive,positive,positive,positive,positive
781122949,"@pepper-jk We have some examples here for Opacus and PyDP: https://github.com/OpenMined/PySyft/tree/dev/examples/differential-privacy

Things are in flux a little bit but we have some big stuff coming and better examples specifically for DP.
I will close this issue for now as DP is being actively worked on and when we have more to share we will announce and update the docs and examples. Thanks for your patience.",flux little bit big stuff coming better specifically close issue actively worked share announce update thanks patience,issue,positive,positive,neutral,neutral,positive,positive
780945204,"@AbhishekPokala any chance you can test out the nightlies and see if they install on your hardware?
https://github.com/OpenMined/PySyft/issues/4826",chance test see install hardware,issue,negative,neutral,neutral,neutral,neutral,neutral
780540812,"Roger that. In order to avoid us having to sweep every file in our codebase, do you have a readymade list of the offending files? We'd be happy to patch them with the appropriate inline documentation at the top of each file. 😄 ",roger order avoid u sweep every file list happy patch appropriate documentation top file,issue,positive,positive,positive,positive,positive,positive
780336254,"PyTorch will provide standard binary packages for arm64 starting in PyTorch 1.8 (first half of March). In the meantime, you can try the nightlies and let us know if you run into any issues:

pip install --pre torch torchvision  -f https://download.pytorch.org/whl/nightly/cpu/torch_nightly.html
",provide standard binary arm starting first half march try let u know run pip install torch,issue,negative,positive,neutral,neutral,positive,positive
780333273,"@sek22 We now have CLI based Integration tests between Duet running as Python code, in this case actually converting a notebook to python code first but the result is the same:
https://github.com/OpenMined/PySyft/blob/c7018768e9a7d78da8c93cbf39d564713bca7968/.github/workflows/pr_tests.yml#L222
```
      - name: Run notebook Duet examples
```

Does that solve your issue?",based integration duet running python code case actually converting notebook python code first result name run notebook duet solve issue,issue,negative,positive,positive,positive,positive,positive
780296710,"The epsilon is fixed, this was related to a change in Lists vs Tuples and also the return of numpy types on the Opacus side.",epsilon fixed related change also return side,issue,negative,positive,neutral,neutral,positive,positive
780228257,"@madhavajay 
Thank you for your support! Please merge first. I'll survey the integration test and dm you later! ",thank support please merge first survey integration test later,issue,positive,positive,positive,positive,positive,positive
780034342,"OK just did the same thing on Ubuntu + Conda and got the same result as you. 
Steps:
1. `$ conda create -n pysyft python=3.8`
2. `$ conda activate pysyft`
3. `$ conda install jupyter notebook`
4. `$ pip install syft`
5. `$ pip install safety`
6. `$ safety check`

Closing since it's not clear if Jupyter is vulnerable. My original report probably had to do with Kali + Virtualenv or just a mistake on my end. ",thing got result create activate install notebook pip install pip install safety safety check since clear vulnerable original report probably kali mistake end,issue,positive,negative,neutral,neutral,negative,negative
779922357,"Yes it seems I wrote the issue poorly. Just edited the steps to reproduce. Let me double check on Ubuntu 18.04 LTS and anaconda, might have to do with it being on kali and virtualenv",yes wrote issue poorly reproduce let double check anaconda might kali,issue,negative,negative,negative,negative,negative,negative
779623267,@avinsit123 I have merged this for now. If you want to correct more open a new PR. 👍🏼 ,want correct open new,issue,negative,positive,neutral,neutral,positive,positive
779587519,Oh ok sorry. Also should all the warnings be fixed in one PR or multiple PR's,oh sorry also fixed one multiple,issue,negative,negative,negative,negative,negative,negative
779586544,"@avinsit123 This takes the number down to `406` but it doesn't close the issue, please update the description so that merging this PR doesn't close the original issue.",number close issue please update description close original issue,issue,positive,positive,positive,positive,positive,positive
779563268,@xutongye I fixed this by cherry picking it over the top of `dev`: https://github.com/OpenMined/PySyft/pull/5159,fixed cherry top dev,issue,negative,positive,positive,positive,positive,positive
779537908,@Koukyosyumei Also if you DM me on Slack I can help explain the Integration Test stuff.,also slack help explain integration test stuff,issue,negative,neutral,neutral,neutral,neutral,neutral
779537456,"@Koukyosyumei thank you, I was mid-review on these and got interrupted by some other tasks. Both notebooks worked and I was able to see output:
![fake_samples_0_936](https://user-images.githubusercontent.com/2882739/108010328-558e0f00-7050-11eb-8938-10e0b34066ca.png)
![output2](https://user-images.githubusercontent.com/2882739/108010334-5c1c8680-7050-11eb-8b32-2c3d30711385.jpg)

Let me get these merged first and then we can discuss how to turn them into an integration test.
Sorry for the wait, I really appreciate your patience.
",thank got interrupted worked able see output output let get first discus turn integration test sorry wait really appreciate patience,issue,negative,positive,positive,positive,positive,positive
779536656,"@socd06 are you sure you are scanning syft?

None of these packages are in our requirements or installed in my virtualenv? Perhaps you are running `safety check` with your main system site-packages in the path.


If I run the same safety check I get the following:
```
safety report
checked 160 packages, using free DB (updated once a month)
---
-> tornado, installed 6.1, affected <=6.1, id 39462
```

Additionally looking into this:
```
$ pip install pipdeptree
$ pipdeptree -r -p tornado
tornado==6.1
  - jupyter-client==6.1.11 [requires: tornado>=4.1]
    - nbclient==0.5.2 [requires: jupyter-client>=6.1.5]
      - nbconvert==6.0.7 [requires: nbclient>=0.5.0,<0.6.0]
```

It appears tornado is only being used by Jupyter.

Looking at the CVE:
```json
""tornado"": [
    {
        ""advisory"": ""All versions of package tornado are vulnerable to Web Cache Poisoning by using a vector called parameter cloaking. When the attacker can separate query parameters using a semicolon (;), they can cause a difference in the interpretation of the request between the proxy (running with default configuration) and the server. This can result in malicious requests being cached as completely safe ones, as the proxy would usually not see the semicolon as a separator, and therefore would not include it in a cache key of an unkeyed parameter. See CVE-2020-28476."",
        ""cve"": null,
        ""id"": ""pyup.io-39462"",
        ""specs"": [
            ""<=6.1""
        ],
        ""v"": ""<=6.1""
    }
],
```

https://vuldb.com/?id.168074
https://snyk.io/vuln/SNYK-PYTHON-TORNADO-1017109

Based on that it's not clear that Jupyter itself would be vulnerable but the Jupyter server would need to be accessible to the attacker. Syft does not use Jupyter for communication itself, instead it operates over a WebRTC connection established in Python, so I would imagine this likely does not apply.

What are your thoughts on this?
",sure scanning none perhaps running safety check main system path run safety check get following safety report checked free month tornado affected id additionally looking pip install tornado tornado tornado used looking tornado advisory package tornado vulnerable web cache poisoning vector parameter cloaking attacker separate query semicolon cause difference interpretation request proxy running default configuration server result malicious completely safe proxy would usually see semicolon separator therefore would include cache key unkeyed parameter see null id spec based clear would vulnerable server would need accessible attacker use communication instead connection established python would imagine likely apply,issue,negative,positive,neutral,neutral,positive,positive
779491445,"I tried to retest this against dev and on the DO side I see a lot of stuff like:

```
02-15T22:11:26.317734+0000][DEBUG][logger]][387] Serializing syft.grid.services.signaling_service.AnswerPullRequestMessage
[2021-02-15T22:11:26.319933+0000][DEBUG][logger]][387] > Creating Signed ✉️ 🔏 (SignedImmediateSyftMessageWithReply) <UID:🙘🛫>
[2021-02-15T22:11:26.320430+0000][DEBUG][logger]][387] Serializing syft.core.common.message.SignedImmediateSyftMessageWithReply
[2021-02-15T22:11:26.320757+0000][DEBUG][logger]][387] > ✉️ 🔏 -> Proto 🔢 <UID: fe3d401ea0ff4526b65f76099efe0769>
[2021-02-15T22:11:26.398639+0000][DEBUG][logger]][387] > Creating ✉️  (SignalingAnswerMessage) <UID:🚻🚴>
[2021-02-15T22:11:26.399692+0000][DEBUG][logger]][387] > Creating Signed ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply) <UID:🚻🚴>
[2021-02-15T22:11:26.399931+0000][DEBUG][logger]][387] > ✉️ 🔏 <- 🔢 Proto
[2021-02-15T22:11:26.403205+0000][DEBUG][logger]][387] > Creating ✉️  (SignalingAnswerMessage) <UID:🚻🚴>
[2021-02-15T22:11:27.167427+0000][DEBUG][logger]][387] > Creating 📡 [🏰] Joiner Client (Duet)@<UID:🚄🚂>
[2021-02-15T22:11:27.168745+0000][DEBUG][logger]][387] failed to log exception
[2021-02-15T22:11:27.169070+0000][INFO][logger]][387] ♫♫♫ > CONNECTED!
[2021-02-15T22:11:27.546997+0000][DEBUG][logger]][387] > Creating 📡 [🏰] Launcher Client (DomainClient)@<UID:🚅🚆>
[2021-02-15T22:11:27.547997+0000][DEBUG][logger]][387] failed to log exception
[2021-02-15T22:11:27.552995+0000][ERROR][logger]][387] Got an exception in Duet push. 
[2021-02-15T22:11:27.648700+0000][DEBUG][logger]][387] failed to log exception
[2021-02-15T22:11:27.751409+0000][DEBUG][logger]][387] failed to log exception
[2021-02-15T22:11:27.853312+0000][DEBUG][logger]][387] failed to log exception
[2021-02-15T22:11:27.955377+0000][DEBUG][logger]][387] failed to log exception
[2021-02-15T22:11:28.057515+0000][DEBUG][logger]][387] failed to log exception
[2021-02-15T22:11:28.159987+0000][DEBUG][logger]][387] failed to log exception
[2021-02-15T22:11:28.262311+0000][DEBUG][logger]][387] failed to log exception
[2021-02-15T22:11:28.364578+0000][DEBUG][logger]][387] failed to log exception
```

On the DS side I see this:
```
[2021-02-15T22:11:26.652335+0000][DEBUG][logger]][369] > Creating 📡 [🏰] Launcher Client (Duet)@<UID:🚅🚆>
[2021-02-15T22:11:26.653845+0000][DEBUG][logger]][369] failed to log exception
[2021-02-15T22:11:26.654422+0000][INFO][logger]][369] ♫♫♫ > CONNECTED!
[2021-02-15T22:11:26.659252+0000][ERROR][logger]][369] Got an exception in Duet pull. 
```

I tried to test this operation:
```
# lets ask to see if our Data Owner has CUDA
has_cuda = False
has_cuda_ptr = remote_torch.cuda.is_available()
has_cuda = bool(has_cuda_ptr.get(
    request_block=True,
    reason=""To run test and inference locally"",
    timeout_secs=5,  # change to something slower
))
print(has_cuda)
```

And it seems it works if I do this IMMEDIATELY after on the DS side (I get back a boolean).
If I try to run:
```model = local_model.send(duet)```
and after the exact code with ```has_cuda...``` then it remains blocked...

I am not sure if the ```local_model.send``` does something weird (I also removed the GarbageCollectionMessage being sent in the ```__del__``` function from pointer).

If anyone has any idea it would be of much help, if not I can continue digging into this.",tried retest dev side see lot stuff like logger logger envelope logger logger envelope proto logger envelope logger envelope logger envelope proto logger envelope logger castle joiner client duet logger log exception logger connected logger castle launcher client logger log exception error logger got exception duet push logger log exception logger log exception logger log exception logger log exception logger log exception logger log exception logger log exception logger log exception side see logger castle launcher client duet logger log exception logger connected error logger got exception duet pull tried test operation ask see data owner false bool run test inference locally change something print work immediately side get back try run model duet exact code remains blocked sure something weird also removed sent function pointer anyone idea would much help continue digging,issue,negative,positive,neutral,neutral,positive,positive
779443926,"You should add a line that states that files under '/path/to/python/code' are licensed under the PSF license.
",add line licensed license,issue,negative,neutral,neutral,neutral,neutral,neutral
779428548,"Could you be more specific about what you’d like for us to do in PySyft? I
think we’re all highly interested in offering credit where credit is due,
but I’m not sure I correctly understand what you’d like for us to do to
resolve the situation.

On Mon, Feb 15, 2021 at 5:50 PM Stefan van der Walt <
notifications@github.com> wrote:

> Here's an example from scikit-image, of the form that is used by the
> Debian project:
>
> https://github.com/scikit-image/scikit-image/blob/master/LICENSE.txt
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/5146#issuecomment-779372677>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AAJ44CXPLKJ2OKYQ2H5VNBLS7FNFLANCNFSM4XODQGWQ>
> .
>
",could specific like u think highly interested offering credit credit due sure correctly understand like u resolve situation mon van walt wrote example form used project reply directly view,issue,positive,positive,positive,positive,positive,positive
779372677,"Here's an example from scikit-image, of the form that is used by the Debian project:

https://github.com/scikit-image/scikit-image/blob/master/LICENSE.txt",example form used project,issue,negative,neutral,neutral,neutral,neutral,neutral
779099197,Do you have a proposal for what should be added in order to comply @stefanv?,proposal added order comply,issue,negative,neutral,neutral,neutral,neutral,neutral
779006374,@madhavajay I have opened a PR to fix darglint warnings for `src/syft/utils.py` . What I wish to know is whether you want a seperate PR for each file or just for `src/syft` or `tests/syft`,fix wish know whether want file,issue,negative,neutral,neutral,neutral,neutral,neutral
778576479,"@madhavajay 
Hi,
I replaced ""name"" with ""tag"", and all of my notebooks worked. I also implemented ""dry_run"", so every notebook runs only one batch! How can I try the integration test?",hi name tag worked also every notebook one batch try integration test,issue,negative,neutral,neutral,neutral,neutral,neutral
777491171,@madhavajay Thank you! This is exactly what I was looking for. Appreciate you sharing!,thank exactly looking appreciate,issue,positive,positive,positive,positive,positive,positive
777291573,"@apzl I haven't started yet, 
If you are interested to work on please go ahead ",yet interested work please go ahead,issue,positive,positive,positive,positive,positive,positive
777185350,"Hey,

Reposting from Slack so we can attempt to get more views. 

I'm currently working on introducing a doc linter to `PySyft` so that we conform to the Google docstring format. I was just looking through the codebase and I realized that the existing docstrings are formatted according to Sphinx Style so that PySyft can generate docs. This would mean that I can't remove the Sphinx Style comments at they would affect doc generation.

I was thinking of introducing a Sphinx extension like [Napoleon](https://www.sphinx-doc.org/en/master/usage/extensions/napoleon.html) and subsequently replacing the Sphinx docstrings with Google Style docstrings. Just wanted to get your thoughts on this and check if there are alternative workarounds and if you forsee any potential portions of the docs breaking because of the introduction of this new extension.",hey slack attempt get currently working doc linter conform format looking according sphinx style generate would mean ca remove sphinx style would affect doc generation thinking sphinx extension like napoleon subsequently sphinx style get check alternative potential breaking introduction new extension,issue,negative,negative,neutral,neutral,negative,negative
777185112,"Sure, sounds good. Will get to it in a bit.",sure good get bit,issue,positive,positive,positive,positive,positive,positive
777182745,"Thanks, that sounds good!  Feel free to close this as you see fit.",thanks good feel free close see fit,issue,positive,positive,positive,positive,positive,positive
777181660,"Hi @stefanv right, I guess I was trying to say we know the Docs are broken and we will be going over them with a closer eye soon. Thanks for pointing out the rendering issue. We haven't decided yet on if we will keep using `sphinx` or switch to another docs tool, but either way we will keep an eye on the formatting. 🙂",hi right guess trying say know broken going closer eye soon thanks pointing rendering issue decided yet keep sphinx switch another tool either way keep eye,issue,negative,positive,neutral,neutral,positive,positive
777180160,"Thanks, @madhavajay.  This seems like a different issue than the two you referred to, but I'm glad to hear that it will be fixed in the next release.",thanks like different issue two glad hear fixed next release,issue,positive,positive,positive,positive,positive,positive
777179231,"@J0 Looks like we need to configure it a little bit first:
https://github.com/terrencepreilly/darglint#configuration

Can you add some configuration to `setup.cfg` which:
- sets the `docstring_style` to google
- ignores the comments that we have added to import sections for `isort`
- ignores anything inside the `src/syft/proto` folder since thats autogenerated

Then we probably need to turn off failing and make it just a warning for now so we can progressively fix these.
If you can't turn that off in pre-commit, just comment it out and add `darglint` itself to `requirements.txt` and the `pr_tests.yml` linting step so that we can manually ignore the return code with something like:
```
$ darglint || true
```",like need configure little bit first add configuration added import anything inside folder since thats probably need turn failing make warning progressively fix ca turn comment add step manually ignore return code something like true,issue,negative,positive,positive,positive,positive,positive
777177309,"@LasTAD and @geoffkip There is an example of using a different dataset in one of the SuperResolution notebooks which is close to being merged. https://github.com/OpenMined/PySyft/pull/5122

We will be creating more examples and documentation for the next release.",example different one close documentation next release,issue,negative,neutral,neutral,neutral,neutral,neutral
777176185,"@stefanv yes, the docs have not been properly rebuilt yet.
We have several PRs and issues to:
- implement a docstring checker: https://github.com/OpenMined/PySyft/pull/5123
- fix the documentation build warnings: https://github.com/OpenMined/PySyft/issues/4518

We are aiming to fix this for the next release.",yes properly rebuilt yet several implement checker fix documentation build aiming fix next release,issue,negative,neutral,neutral,neutral,neutral,neutral
776896988,"Hello @madhavajay and @tudorcebere, I check again running ` $ pytest -m 'fast or slow' --no-cov -n auto ` and was raised 4117 warnings. I did some changes that is on the PR #5125 and decrease to 24 warnings.

Then I opened issues for the warnings there are left, the issues are #5137, #5138, #5139, #5140, #5141, #5142, #5143.",hello check running slow auto raised decrease left,issue,negative,negative,negative,negative,negative,negative
776499402,"@iamtrask I have detailed the remaining work on the lint checker here:
https://github.com/OpenMined/Heartbeat/issues/994

Since its a static check that will always run in CI, I see no harm in merging this PR while its hot and prevent it going stale and being harder to merge.

Can you mark your ""Change request"" as approved so we can merge?",detailed work lint checker since static check always run see harm hot prevent going stale harder merge mark change request merge,issue,negative,positive,positive,positive,positive,positive
776448305,Thanks @madhavajay ! I have the same issue but 0.2.9 doesn't help either.,thanks issue help either,issue,positive,positive,positive,positive,positive,positive
775989581,@madhavajay pushed one more change to interchange two lines.,one change interchange two,issue,negative,neutral,neutral,neutral,neutral,neutral
775825311,"I am into the solution from @madhavajay, it's the best tradeoff in terms of speed and functionality + we can extend it to do whatever we want in the future. ",solution best speed functionality extend whatever want future,issue,positive,positive,positive,positive,positive,positive
775768639,"@syumeikoukyo this is awesome work! ❤️
I am running both notebooks and will be discussing how we can fix the issue of securely fetching the result data of some operations without using the old `handler` `name` param now that we have removed it. As soon as this works I think we will also look at turning this into an Integration Test possibly with only a few batches in dry run.",awesome work running fix issue securely fetching result data without old handler name param removed soon work think also look turning integration test possibly dry run,issue,positive,positive,positive,positive,positive,positive
775703130,I will close this PR since theres more progress over here: https://github.com/OpenMined/PySyft/pull/5089,close since there progress,issue,negative,neutral,neutral,neutral,neutral,neutral
775702622,@avinsit123 make sure to merge this into `dev` as the AST got a big rewrite and all that code has been merged into `dev` now.,make sure merge dev ast got big rewrite code dev,issue,negative,positive,positive,positive,positive,positive
775664145,"I have added our custom flake8-kwarger linter plugin to resolve these requirements.

**- requires type hints in every method in the codebase**
✅ this is already covered by mypy
**- requires that kwargs be used for all methods - especially the end-user API**
✅ see the new flake8-kwarger https://github.com/madhavajay/flake8-kwarger
**- enforces that arguments passed into methods are correct at runtime by the end user**
❎ python * and PEP 3102 checks the kwarg names at runtime but not the types.
We are trying to avoid the runtime type checking since its expensive and Python doesn't normally do this.
For all our internal code we have mypy static checking and I think this is the right trade-off.

This first commit https://github.com/OpenMined/PySyft/pull/5105/commits/ed133f711632202fe7a38577ab4b70d6b3530aba shows an example of how it works.

With * included in the VirtualMachine init for example the following happens.
```python
>>> import syft as sy
>>> sy.VirtualMachine(""Bob"")
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
TypeError: __init__() takes 1 positional argument but 2 were given
>>> sy.VirtualMachine(name=""Bob"")
VirtualMachine: Bob: <UID: 51ade0963f28484b8d22284bc421b295>
```",added custom linter resolve type every method already covered used especially see new correct end user python pep trying avoid type since expensive python normally internal code static think right first commit example work included example following python import bob recent call last file line module positional argument given bob bob,issue,negative,positive,neutral,neutral,positive,positive
775444805,I am having this exact same issue. Is there any way in Pysyft to create a Custom Dataset pointer using remote tensor pointers? Ultimately I need to use this in a remote torch dataloader etc.,exact issue way create custom pointer remote tensor ultimately need use remote torch,issue,negative,positive,neutral,neutral,positive,positive
775255206,"Hi, I see what might be happening before. It seems that attributes of Normalize like `mean` , `std` and `inplace`  are not getting added to the torchvision ast.

```python
>>> from syft.lib.torchvision import create_torchvision_ast
>>> create_torchvision_ast()
Module:
	.torchvision -> Module:
		.transforms -> Module:
			.Compose -> <syft.ast.klass.Class object at 0x7fac6130ed08>
			.ToTensor -> <syft.ast.klass.Class object at 0x7fac6130ed68>
			.Normalize -> <syft.ast.klass.Class object at 0x7fac6130edc8>

		.datasets -> Module:
			.MNIST -> <syft.ast.klass.Class object at 0x7fac61366048>
			.VisionDataset -> <syft.ast.klass.Class object at 0x7fac61366108>
```
This seems to happen with  `torchvision.datasets.MNIST.__len__` and  `torchvision.datasets.VisionDataset.__len__` both which were already present in allowlist before these changes. It seems that attributes of modules are not getting added to AST . I will try to fix this ASAP and write tests.

```python
>>> import syft as sy
>>> bob = sy.VirtualMachine(name=""Bob"")
>>> root_client = bob.get_root_client()
>>> ptr = root_client.torchvision.datasets.MNIST
>>> ptr.__len__
<syft.ast.callable.Callable object at 0x7ffeadbf2348>
[2021-02-08T21:34:12.205178+0530][CRITICAL][logger] __getattribute__ failed. If you are trying to access an EnumAttribute or a StaticAttribute, be sure they have been added to the AST. Falling back on__getattr__ to search in self.attrs for the requested field.
[2021-02-08T21:34:12.206367+0530][CRITICAL][logger] 'Class' object has no attribute '__len__'
>>> ptr.__len__
<syft.ast.callable.Callable object at 0x7ffeadbf2468>
[2021-02-08T21:34:56.009231+0530][CRITICAL][logger] __getattribute__ failed. If you are trying to access an EnumAttribute or a StaticAttribute, be sure they have been added to the AST. Falling back on__getattr__ to search in self.attrs for the requested field.
[2021-02-08T21:34:56.009740+0530][CRITICAL][logger] 'Class' object has no attribute '__len__'
```
",hi see might happening normalize like mean getting added ast python import module module module object object object module object object happen already present getting added ast try fix write python import bob bob object critical logger trying access sure added ast falling back search field critical logger object attribute object critical logger trying access sure added ast falling back search field critical logger object attribute,issue,negative,positive,neutral,neutral,positive,positive
775222730,"Please document why syft_decorator is being removed and how we will enforce types in the end user API at runtime (as well as internal API) moving forward.

Also - if this PR does not include enforcement of end user API features - I would vote to hold this PR until that is added. I fear that we will never return to it if we remove it now.

Background: syft_decorator was not put in for performance - it was put in as a safety guardrail against developers of PySyft creating technical debt (syft_decorator has caught hundreds if not thousands of bugs already), forcing us to write readable code (with type hints and kwargs), and forcing **users of PySyft** to always pass in kwargs instead of args. This last feature is so that everyone (both developers and  **users of PySyft**) is forced to write readable code.

My assumption is that this is being removed because syft_decorator is either annoying or causes the codebase to be slow. If this is the case - that's sortof its purpose (not the slow part - but it is supposed to be annoying). I'd be more inclined to create a script which strips out syft_decorator for PyPI builds (and only in non-user API facing methods) than to remove it entirely. But of course - down to chat it here and I'm sure discussion has happened.",please document removed enforce end user well internal moving forward also include enforcement end user would vote hold added fear never return remove background put performance put safety guardrail technical debt caught already forcing u write readable code type forcing always pas instead last feature everyone forced write readable code assumption removed either annoying slow case purpose slow part supposed annoying create script facing remove entirely course chat sure discussion,issue,negative,negative,negative,negative,negative,negative
775163611,"Oh thanks @madhavajay , I was just running:

`$ pytest -m fast -n auto`

that was the one I saw on the CONTRIBUTING.md.
Sorry, I'll be looking up again.",oh thanks running fast auto one saw sorry looking,issue,negative,negative,neutral,neutral,negative,negative
775060027,"Some conclusions from slack:

Changing the `DC_MAX_CHUNK_SIZE` var from `2 ** 14` to `2 ** 18` in src/syft/grid/connections/webrtc.py
reduces the third notebook test duration(the encrypted images one) from 227sec to 65sec on Ubuntu. 

It looks like the fix works on MacOS as well, since all tests take 116 seconds with the changed chunk size.",slack third notebook test duration one sec sec like fix work well since take chunk size,issue,positive,negative,neutral,neutral,negative,negative
774996337,@rahul-art Is this PR still active? The existing commits don't currently add anything.,still active currently add anything,issue,negative,negative,neutral,neutral,negative,negative
774953572,"Ok I see, yes then we should add support for all types",see yes add support,issue,positive,neutral,neutral,neutral,neutral,neutral
774948366,"Yes, although the types ultimately mean nothing, all that matters is it gets passed to `torch.as_tensor()` so I think we should allow anything which can get passed into that which so far seems like, int, float, Tuple and List, and probably Tensor and Numpy's ndarray.

```python
>>> import torch
>>> torch.as_tensor(1)
tensor(1)
>>> torch.as_tensor(1.1)
tensor(1.1000)
>>> torch.as_tensor([1])
tensor([1])
>>> torch.as_tensor((1, 2))
tensor([1, 2])
>>> import numpy
>>> a = numpy.array([1, 2, 3])
>>> torch.as_tensor(a)
tensor([1, 2, 3])
>>> torch.as_tensor({1, 2})
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
RuntimeError: Could not infer dtype of set
>>> torch.as_tensor({1.1, 2.1})
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
RuntimeError: Could not infer dtype of set
>>> torch.as_tensor({1.1, 2.1})
KeyboardInterrupt
>>> torch.as_tensor({""a"": 2.1})
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
RuntimeError: Could not infer dtype of dict
```",yes although ultimately mean nothing think allow anything get far like float list probably tensor python import torch tensor tensor tensor tensor import tensor recent call last file line module could infer set recent call last file line module could infer set recent call last file line module could infer,issue,positive,negative,neutral,neutral,negative,negative
774946648,"Hi @avinsit123 Thanks for your PR. Sorry for the wait, I just went through this and I think I understand whats going on. In the event of p_args for a module_pargs key being defined, when the attribute is fetched an object is instantiated first and the attribute is fetched from the object instead of the class.

However, I created a simple test case and I can't seem to see any of the methods on the Pointer class.

```python
def test_object_properties() -> None:
    bob = sy.VirtualMachine(name=""Bob"")
    root_client = bob.get_root_client()

    ptr = root_client.torchvision.transforms.Normalize(1, 1)
    print(type(ptr))
    print(""ptr inplace"", getattr(ptr, ""inplace"", None))
    print(""ptr mean"", getattr(ptr, ""mean"", None))
    print(""ptr std"", getattr(ptr, ""std"", None))
    print(dir(ptr))
    assert hasattr(ptr, ""inplace"")
    assert hasattr(ptr, ""mean"")
    assert hasattr(ptr, ""std"")
```

Are you able to figure out why the Pointer is not getting these methods and perhaps add some tests for all the different scenarios that you have added code for so we can be sure they pass?",hi thanks sorry wait went think understand whats going event key defined attribute fetched object first attribute fetched object instead class however simple test case ca seem see pointer class python none bob bob print type print none print mean mean none print none print assert assert mean assert able figure pointer getting perhaps add different added code sure pas,issue,positive,positive,neutral,neutral,positive,positive
774928067,"Ok, I see but if u have a look at the parameters for `normalize` we can see that in the function `mean` and `std `both are `List[Float]` type so shouldn't we just allow `syft.python.lib.List `

https://github.com/pytorch/vision/blob/ced96a0ca66e35ae61b64267e083fc3e3a62172a/torchvision/transforms/functional.py#L297 - have a look at this",see look normalize see function mean list float type allow look,issue,negative,negative,negative,negative,negative,negative
774906439,"Cool, will file a PR shortly. Thanks!",cool file shortly thanks,issue,positive,positive,positive,positive,positive,positive
774904924,"Looks like it ends up as this:
```
mean = torch.as_tensor(mean, dtype=dtype, device=tensor.device)
std = torch.as_tensor(std, dtype=dtype, device=tensor.device)
```

So we should support any `Sequence` which works with torch.as_tensor.",like mean mean support sequence work,issue,positive,negative,negative,negative,negative,negative
774901215,"So it turns it out mean and std aren't tuples, Normalize is the tuple, so its mean and std are what ever you want them to be... 😬

```
>>> a = torchvision.transforms.Normalize(1, 1)
>>> a
Normalize(mean=1, std=1)
>>> type(a.mean)
<class 'int'>

>>> b = torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
>>> b
Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))
>>> type(b.std)
<class 'tuple'>

😱
>>> c = torchvision.transforms.Normalize([0.5, 0.5, 0.5], (0.5, 0.5, 0.5))
>>> c
Normalize(mean=[0.5, 0.5, 0.5], std=(0.5, 0.5, 0.5))
>>> type(c.mean)
<class 'list'>

>>> d = torchvision.transforms.Normalize(torch.Tensor([0.5, 0.5, 0.5]), (0.5, 0.5, 0.5))
>>> d
Normalize(mean=tensor([0.5000, 0.5000, 0.5000]), std=(0.5, 0.5, 0.5))
>>> type(d.mean)
<class 'torch.Tensor'>

😱😱😱
>>> e = torchvision.transforms.Normalize(""test"", (0.5, 0.5, 0.5))
>>> e
Normalize(mean=test, std=(0.5, 0.5, 0.5))
>>> e.mean
'test'

```",turn mean normalize mean ever want normalize type class normalize type class normalize type class normalize type class test normalize,issue,negative,negative,negative,negative,negative,negative
774893586,"@xutongye I am not sure what happened but when ever I run the examples the tags are empty.
I also tried adding a test:
```python
def test_tag_heritance() -> None:
    bob = sy.VirtualMachine(name=""Bob"")
    root_client = bob.get_root_client()

    ten = th.tensor([1, 2])

    ptr = ten.send(root_client, tags=[""a""])
    assert ptr.tags == [""a""]

    result_ptr = ptr.T
    assert result_ptr.tags == [""a"", ""T""]
```

Do you also have the problem of empty `tags`?",sure ever run empty also tried test python none bob bob ten assert assert also problem empty,issue,negative,positive,neutral,neutral,positive,positive
774873212,"@shujaat81 Can you please let us know what version of Windows and Python you are using, what the version of Syft you are using is (or commit hash, if you run pip freeze you can see what version) and the commands you ran to cause the issue?",please let u know version python version commit hash run pip freeze see version ran cause issue,issue,positive,neutral,neutral,neutral,neutral,neutral
774871459,"@J0 it also looks like they support `pre-commit` so adding it to that makes sense since it gets run in the `pr_tests.yml` linting step above.
```
repos:
-   repo: https://github.com/terrencepreilly/darglint
    rev: master
    hooks:
    - id: darglint
```",also like support sense since run step rev master id,issue,positive,neutral,neutral,neutral,neutral,neutral
774870812,@J0 Spot on! If you can open a PR with darglint added to the `pr_tests.yml` in the `python-linting` step that would be awesome. We should make it not fail for now but progressively make it harder so that we are forced to refactor these docs.,spot open added step would awesome make fail progressively make harder forced,issue,negative,positive,neutral,neutral,positive,positive
774868907,"We should make sure to run:
```
$ pytest -m 'fast or slow' --no-cov -n auto
```

There are a number of warnings that come from the slow tests and we can check the `torch` tests as well but since its a single test with parameterization I wouldn't expect many.

Right now on `dev` im getting:
```
= 2120 passed, 1 skipped, 4 xfailed, 4171 warnings in 64.62s (0:01:04) ==
```",make sure run slow auto number come slow check torch well since single test would expect many right dev getting,issue,positive,positive,positive,positive,positive,positive
774862363,"@gmuraru I haven't checked on Colab since we added the `event_loop.py` code, but doesn't it usually show an exception for that?",checked since added code usually show exception,issue,negative,negative,negative,negative,negative,negative
774861983,"@bhadreshpsavani Sure, but make sure to push a PR while you are working on it so that if we need to help get it ready for merging your commits will be included.",sure make sure push working need help get ready included,issue,positive,positive,positive,positive,positive,positive
774860673,"@bcebere This is super awesome. Everything works except when I run the last test or the 3rd notebook it seems to hang on: `ctx = ctx_ptr.get(delete_obj=False)` on my MacOS and Python 3.8.6.

In the tests i guess it timesout eventually with:
```
    raise ConnectionError(""Cannot send encrypted data, not connected"")
ConnectionError: Cannot send encrypted data, not connected
----------------------- Captured stdout teardown ------------------------
stop signaling server
```

Maybe its too big for the slow connection?",super awesome everything work except run last test notebook python guess eventually raise send data connected send data connected teardown stop server maybe big slow connection,issue,positive,positive,positive,positive,positive,positive
774837132,It seems like I have to rebase to dev branch. I'll create new PR for dev. ,like rebase dev branch create new dev,issue,positive,positive,positive,positive,positive,positive
774816187,"I see this error sometimes on quitting. I think its unrelated to the change, because this error is now showing when we connect two syft instances as well.

<img width=""596"" alt=""Screen Shot 2021-02-08 at 11 49 46 am"" src=""https://user-images.githubusercontent.com/2882739/107167132-c192c680-6a03-11eb-8fca-421aad15664b.png"">
",see error sometimes think unrelated change error showing connect two well screen shot,issue,negative,neutral,neutral,neutral,neutral,neutral
774667800,"> @gmuraru Awesome. So you think that its really just some kind of timeout due to too slow performance between two far apart network nodes?
> Also, great idea with the `send_tensor.py`, i'm going to investigate this.

I might be that, another idea might be that...is there any chance that there is created another event loop?",awesome think really kind due slow performance two far apart network also great idea going investigate might another idea might chance another event loop,issue,positive,positive,positive,positive,positive,positive
774657644,Hi. I would love to work on this.,hi would love work,issue,positive,positive,positive,positive,positive,positive
774627315,"I can work on this one, please assign it to me.",work one please assign,issue,negative,neutral,neutral,neutral,neutral,neutral
774561324,"@madhavajay can I work on this?

**Implementation Plan**
1.  Install  docstring linter like [darglint](https://github.com/terrencepreilly/darglint)
2.  Progressively correct all docstrings

Not sure if there's more to it",work implementation plan install linter like progressively correct sure,issue,positive,positive,positive,positive,positive,positive
774401134,"@madhavajay 
Hi, I am working on this issue, and I have almost done it. But, I already have a PR (#5071 ) to fix #4798. So, should I wait for #5071 to be finished, or may I create another PR for this issue?  Also, one possible plan is committing the notebooks for this issue within #5071 which I made for the DCGAN issue. I would like to hear your opinion because I'm not familiar with contriution to open source project. Thank you in advance. ",hi working issue almost done already fix wait finished may create another issue also one possible plan issue within made issue would like hear opinion familiar open source project thank advance,issue,positive,positive,positive,positive,positive,positive
774387145,@madhavajay Have a look at PR #5117 I have cherry-picked commits and rebased it with dev branch. Also could u help me out in how to write allowlist tests. Thanks.,look dev branch also could help write thanks,issue,positive,positive,positive,positive,positive,positive
773878412,"@madhavajay As I can see I have the latest one:
`
>>> import torchvision
>>> torchvision.__version__
'0.8.2'
>>> torchvision.datasets.VisionDataset
<class 'torchvision.datasets.vision.VisionDataset'>
>>> 

`",see latest one import class,issue,negative,positive,positive,positive,positive,positive
773812855,"@IonesioJunior if you run the `scripts/pre_commit.sh` script it will fix most of these issues.
You can also run: `pre-commit run --all-files` to just get a quick lint check or `pre-commit install` so that it happens automatically when you commit.",run script fix also run run get quick lint check install automatically commit,issue,negative,positive,positive,positive,positive,positive
773806161,"Ohh. My bad, I got it wrong, closing this PR. Will submit another one with correct code. Thanks for guiding 👍",bad got wrong submit another one correct code thanks,issue,negative,negative,negative,negative,negative,negative
773801744,"@rajatrc1705 The goal is to change our code so that it passes these tests not changing the tests so that our code passes.
These tests are from the official CPython repository:
https://github.com/python/cpython/blob/3.8/Lib/test/test_dict.py

So if our code doesn't pass these checks there could be issues. 

As you can see even though the original test references `dict` if you substitute `UserDict` into the test it passes:
```python
@pytest.mark.slow
def test_free_after_iterating(self):
    from collections import UserDict

    # this seems like a bit of a puzzle
    support.check_free_after_iterating(self, iter, UserDict)
    support.check_free_after_iterating(self, lambda d: iter(d.keys()), UserDict)
    support.check_free_after_iterating(self, lambda d: iter(d.values()), UserDict)
    support.check_free_after_iterating(self, lambda d: iter(d.items()), UserDict)
```

```
tests/syft/lib/python/dict/dict_test.py::DictTest::test_free_after_iterating PASSED [100%]
```

Since we subclass from UserDict we should be able to pass this test too.",goal change code code official repository code pas could see even though original test substitute test python self import like bit puzzle self iter self lambda iter self lambda iter self lambda iter since subclass able pas test,issue,positive,positive,positive,positive,positive,positive
773791472,"@mfarre we are no longer using these example notebooks and they will be shortly removed. We are going to use GitHub for code and documentation of existing features only and not for planning and ideas. If you are interested in contributing to Syft, I would highly recommend joining the ` #lib_pysyft` channel and discuss these ideas there.",longer example shortly removed going use code documentation interested would highly recommend joining channel discus,issue,positive,positive,positive,positive,positive,positive
773782354,"Yes, and I need to get some Apple Silicon soon anyway so this issue will raise it head again soon I have no doubt.",yes need get apple silicon soon anyway issue raise head soon doubt,issue,negative,neutral,neutral,neutral,neutral,neutral
773781543,"@lucastliu Awesome, great catch! ❤️ The `.gitmodules` file must have been deleted a long time ago but not properly removed from git itself.

I ran this to confirm that it still thought there should be some kind of submodule:
```
$ git submodule status
```

Then to remove it:
```
$ git rm docs/_themes/sphinx-theme-graphite
```

Let's see if this fixes the issue.",awesome great catch file must long time ago properly removed git ran confirm still thought kind git status remove git let see issue,issue,positive,positive,positive,positive,positive,positive
773739269,"Here's an example:
https://github.com/OpenMined/PySyft/runs/1834413505?check_suite_focus=true
Look under ""Post Run actions/checkout@v2""

I peeked at a couple of builds. The warnings all spit from the same issue ""fatal: No url found for submodule path 'docs/_themes/sphinx-theme-graphite' in .gitmodules""

Looks like your documentation tool theme (sphinx-theme-graphite) submodule is not being recognized. Is your theme file even supposed to be a submodule? Why not just have a regular file to define the theme?

In any case, this does not seem like a critical part of the codebase. 
",example look post run couple spit issue fatal found path like documentation tool theme theme file even supposed regular file define theme case seem like critical part,issue,negative,neutral,neutral,neutral,neutral,neutral
773731814,"Hey!
I notice the same issue on my end, and was wondering if you found any solution to this? 
I am currently using PySyft 0.2.9 (the same as you mentioned in the post). ",hey notice issue end wondering found solution currently post,issue,negative,neutral,neutral,neutral,neutral,neutral
773649106,"Apologies for my ignorance, I still couldn't locate it. Would it be possible for you to share a link to the exact line where this occurs, for example? Or the step?

a simple search doesn't yield much, I looked at a few steps but to no avail, unfortunately.",ignorance still could locate would possible share link exact line example step simple search yield much avail unfortunately,issue,negative,negative,neutral,neutral,negative,negative
773063110,"@NiWaRe No worries, thank you for the PR anyway. I hope the exams are going well. 😊",thank anyway hope going well,issue,positive,neutral,neutral,neutral,neutral,neutral
773062471,"@gmuraru Awesome. So you think that its really just some kind of timeout due to too slow performance between two far apart network nodes?
Also, great idea with the `send_tensor.py`, i'm going to investigate this.",awesome think really kind due slow performance two far apart network also great idea going investigate,issue,positive,positive,positive,positive,positive,positive
773060907,"The background asyncio tasks require a Thread to run in. In Jupyter this is provided, in the python interpreter in REPL mode we create one, but when running .py scripts we do not because we are looking for a solution that will allow us to not use the thread for certain implementations of Python which have threads disabled.

In the mean time you can just edit the `event_loop.py`:
```
# REPL requires us to create the Thread and Exit handler
# if not is_jupyter and is_interactive and SYFT_USE_EVENT_LOOP_THREAD:
if True:
    event_loop_thread = EventLoopThread(loop=loop)

    def exit_handler() -> None:
        info(""Shutting Down Syft"")
        if event_loop_thread is not None:
            event_loop_thread.shutdown()

    atexit.register(exit_handler)

__all__ = [""loop"", ""event_loop_thread""]
```

Once that is done then you can run two separate processes and they should work however there appears to be some multiprocessing issues so it depends on how you launch them.

We are working on some deeper integration tests which will iron this out soon.",background require thread run provided python interpreter mode create one running looking solution allow u use thread certain python disabled mean time edit u create thread exit handler true none shutting none loop done run two separate work however launch working integration iron soon,issue,positive,positive,neutral,neutral,positive,positive
773059429,@zhengjiawei001 This is not a problem with Syft its a problem with not being able to access `githubusercontent.com` through certain firewalls. You can manually set the `network_url` like above to one of the three listed above.,problem problem able access certain manually set like one three listed,issue,negative,positive,positive,positive,positive,positive
773057077,"@Rene36 If you want to update the code to accept both a list and the varadic args that would be great.
I'm getting `TypeError: unhashable type: 'list'` for your example though, not a nested list.",want update code accept list would great getting type example though list,issue,positive,positive,positive,positive,positive,positive
773056113,"I had closed my previous PR solving the same issue as @tudorcebere had asked me to rebase it with 0.4 : ) That's fine. It would be great if u could do it if u have time, otherwise I will do it. No issues.",closed previous issue rebase fine would great could time otherwise,issue,positive,positive,positive,positive,positive,positive
773051774,"@avinsit123 Looks like its going to be best to cherry pick these back off the updated `dev` branch. Sorry about this we had a really long standing branch with `0.4` and now its rebased onto `dev`.

I can do this if you would prefer when I get a moment.",like going best cherry pick back dev branch sorry really long standing branch onto dev would prefer get moment,issue,positive,positive,positive,positive,positive,positive
772991265,"rebase to 0.4, too many meaningless commits, ugly",rebase many meaningless ugly,issue,negative,negative,negative,negative,negative,negative
772946952,"@shujaat81 this is strange, `torchvision.datasets.VisionDataset` is available in torch>=0.5 at least. Can you confirm what version of torchvision you have and that if you go to a python console and type and show what your output is:
```
import torchvision
torchvision.__version__
torchvision.datasets.VisionDataset
```

For me with torchvision 0.5 I get:
```
>>> import torchvision
>>> torchvision.__version__
'0.5.0'
>>> torchvision.datasets.VisionDataset
<class 'torchvision.datasets.vision.VisionDataset'>
```

",strange available torch least confirm version go python console type show output import get import class,issue,negative,positive,neutral,neutral,positive,positive
772360026,@madhavajay Thanks. Hopefully your recent commit https://github.com/OpenMined/PySyft/pull/5100 should solve this issue. I leave it open till your test on Big Sur. ,thanks hopefully recent commit solve issue leave open till test big sur,issue,positive,positive,neutral,neutral,positive,positive
771720212,I have rebased as you asked to. Now maybe you could review it and tell me if I am going in the right direction with the PR...,maybe could review tell going right direction,issue,negative,positive,positive,positive,positive,positive
771715441,"Hmm, thinking about it again, if we would use ""tensor"" as name, we would be using it as tensor.tensor, which is a bit confusing.",thinking would use tensor name would bit,issue,negative,neutral,neutral,neutral,neutral,neutral
771686508,"1) yes I agree that might be a better name
2) yes both could be possible, I don't have a good enough overview of the rest of the code and constraints to assess that currently ",yes agree might better name yes could possible good enough overview rest code ass currently,issue,positive,positive,positive,positive,positive,positive
771677854,"Hey - it looks good!

Some nitpicking stuff:

- self.child - I would change this to self.tensor (or self._tensor)
- I am not sure if we want to have the relation ""SyftTensor has a FloatTensor"" or ""FloatTensor is a SyftTensor"" (in this case I think we might want to implement SyftTensor like an abstract class)",hey good stuff would change sure want relation case think might want implement like abstract class,issue,positive,positive,positive,positive,positive,positive
771640178,"So for a FloatTensor that would look something like this, is that the direction you were thinking of.

```
from syft.decorators import syft_decorator

import syft
import torch
from typing import Union

class DataTensor():
    
    @syft_decorator(typechecking=True)
    def __init__(self, child: Union[torch.FloatTensor, torch.IntTensor]):
        self.child=child
    
    def __add__(self, other):
        return DataTensor(child=self.child + other.child)

class FloatTensor():
    
    @syft_decorator(typechecking=True)
    def __init__(self, child: DataTensor):
        self.child=child
        
    def __add__(self, other):
        return FloatTensor(child=self.child + other.child)
    
class IntegerTensor():
    
    @syft_decorator(typechecking=True)
    def __init__(self, child: DataTensor):
        self.child=child
        
    def __add__(self, other):
        return FloatTensor(child=self.child + other.child)

class SyftTensor():
    def __init__(self, child: Union[FloatTensor, IntegerTensor]):
        self.child = child

    def __add__(self, other):
        return SyftTensor(child=self.child + other.child)
    
    @classmethod
    def FloatTensor(cls, data):
        if isinstance(data, list):
            return cls(child=FloatTensor(child=DataTensor(child=torch.FloatTensor(data))))
    

# test
def get_children_types(t, l=None):
    l = [] if l is None else l
    if hasattr(t, ""child""): return l + [type(t)] + get_children_types(t.child, l)
    else: return l + [type(t)]

t = SyftTensor.FloatTensor([1,2,3])
assert get_children_types(t) == [SyftTensor, FloatTensor, DataTensor, torch.Tensor]

t2 = SyftTensor.FloatTensor([4,5,6])
t3 = t + t2
assert all(t3.child.child.child.numpy() == [5.0, 7.0, 9.0])
```",would look something like direction thinking import import import torch import union class self child union self return class self child self return class self child self return class self child union child self return data data list return data test none else child return type else return type assert assert,issue,negative,neutral,neutral,neutral,neutral,neutral
771533512,"Few questions before I want to dive in

- Can we specify the ops we want to begin with, maybe something like this?
    - __add__, __sub__,  __mul__, __truediv__, __matmul__
- How do we wrap these tensors? Lets say I am creating a tensor for federated learning, which should compute on a PyTorch FloatTensor under the hood. How is this wrapped? Is this the idea?: ```SyftTensor(FloatTensor(DataTensor(torch.FloatTensor([1,2,3]))))```
I think it makes sense to write this down for all tensor types before implementing.
- For the SyftTensor, what kind of logic is it responsible for other than passing the function calls it gets to its children?
- For the AutogradTensor, Apart from type checking, is there fundamentally anything different from a FloatTensor?
",want dive specify want begin maybe something like wrap say tensor learning compute hood wrapped idea think sense write tensor kind logic responsible passing function apart type fundamentally anything different,issue,positive,positive,positive,positive,positive,positive
771469797,@xutongye also perhaps rather than rely on ID we could look at a hash since we use that already for signing.,also perhaps rather rely id could look hash since use already,issue,negative,neutral,neutral,neutral,neutral,neutral
771454229,"Some lessons:
 - Duet should have the concept of session. The TenSEAL context needs to sent only once. That reduces the running time of the above script from 80sec to 15 sec. This is still 13 sec slower than the native version.
 - It looks like some crypto signing operations and typeguarding are taking a lot of time.

The top calls in the profiler are
```
         15783679 function calls (15178813 primitive calls) in 15.337 seconds

   Ordered by: internal time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      200    1.290    0.006    1.293    0.006 /home/bcebere/anaconda3/envs/pysyft/lib/python3.8/site-packages/tenseal/tensors/ckkstensor.py:10(__init__)
      550    1.201    0.002    1.201    0.002 {built-in method _sodium.crypto_sign}
      150    1.085    0.007    1.085    0.007 /home/bcebere/anaconda3/envs/pysyft/lib/python3.8/site-packages/tenseal/tensors/abstract_tensor.py:72(serialize)
      550    0.659    0.001    0.659    0.001 {built-in method _sodium.crypto_sign_open}
75506/72986    0.626    0.000    1.122    0.000 /home/bcebere/anaconda3/envs/pysyft/lib/python3.8/inspect.py:2889(_bind)
245244/145684    0.603    0.000    1.767    0.000 /home/bcebere/anaconda3/envs/pysyft/lib/python3.8/site-packages/typeguard/__init__.py:601(check_type)
       50    0.549    0.011    0.689    0.014 /home/bcebere/anaconda3/envs/pysyft/lib/python3.8/site-packages/tenseal/tensors/ckkstensor.py:65(mul)
    75506    0.537    0.000    1.330    0.000 /home/bcebere/anaconda3/envs/pysyft/lib/python3.8/inspect.py:2112(_signature_from_function)
        1    0.418    0.418    0.418    0.418 /home/bcebere/anaconda3/envs/pysyft/lib/python3.8/site-packages/tenseal/enc_context.py:172(serialize)
1423757/1419919    0.345    0.000    0.353    0.000 {built-in method builtins.getattr}
    75506    0.344    0.000    1.171    0.000 /home/bcebere/anaconda3/envs/pysyft/lib/python3.8/site-packages/typeguard/__init__.py:842(typechecked)
75506/72902    0.330    0.000    3.844    0.000 /home/bcebere/anaconda3/envs/pysyft/lib/python3.8/site-packages/typeguard/__init__.py:100(__init__)
2744871/2740634    0.318    0.000    0.320    0.000 {built-in method builtins.isinstance}
75506/2432    0.310    0.000   13.694    0.006 /home/bcebere/anaconda3/envs/pysyft/lib/python3.8/site-packages/typeguard/__init__.py:888(wrapper)
75506/75422    0.295    0.000    1.824    0.000 /home/bcebere/anaconda3/envs/pysyft/lib/python3.8/inspect.py:2206(_signature_from_callable)
      100    0.264    0.003    0.264    0.003 /home/bcebere/anaconda3/envs/pysyft/lib/python3.8/site-packages/tenseal/tensors/abstract_tensor.py:31(link_context)
   167319    0.236    0.000    0.412    0.000 /home/bcebere/anaconda3/envs/pysyft/lib/python3.8/inspect.py:2477(__init__)
        1    0.235    0.235    0.235    0.235 {built-in method _tenseal_cpp.deserialize}
        1    0.216    0.216    0.216    0.216 /home/bcebere/anaconda3/envs/pysyft/lib/python3.8/site-packages/tenseal/enc_context.py:227(generate_galois_keys)
    75506    0.200    0.000    0.357    0.000 /home/bcebere/anaconda3/envs/pysyft/lib/python3.8/functools.py:34(update_wrapper)
   151012    0.197    0.000    0.361    0.000 /home/bcebere/anaconda3/envs/pysyft/lib/python3.8/inspect.py:171(_has_code_flag)
```",duet concept session context need sent running time script sec sec still sec native version like taking lot time top profiler function primitive ordered internal time function method serialize method serialize method method wrapper method,issue,positive,positive,neutral,neutral,positive,positive
771452647,"Full profiling script

```
import os
import pytest
from time import time
import tenseal as ts

import syft as sy
from typing import Any

import pstats
import cProfile

profile = cProfile.Profile()

sy.logger.remove()
LOOPS = 50


def duet_ctx() -> Any:
    return sy.VirtualMachine().get_root_client()


def context():
    context = ts.context(
        ts.SCHEME_TYPE.CKKS, 8192, coeff_mod_bit_sizes=[60, 40, 40, 60]
    )
    context.global_scale = pow(2, 40)
    context.generate_galois_keys()
    return context


def test_stress_imul_duet() -> None:
    sy.load_lib(""tenseal"")

    v1 = [0, 1, 2, 3, 4]
    v2 = [4, 3, 2, 1, 0]
    expected = [v1 * v2 for v1, v2 in zip(v1, v2)]

    duet = duet_ctx()
    ctx = context()

    ctx_ptr = ctx.send(duet, searchable=True)

    for i in range(LOOPS):
        enc_v1 = ts.ckks_tensor(ctx, v1)
        enc_v1_ptr = enc_v1.send(duet, searchable=True)
        enc_v1_ptr.link_context(ctx_ptr)
        enc_v1_ptr.link_context(ctx_ptr)

        result_enc_ptr = enc_v1_ptr * v2
        result_enc = result_enc_ptr.get()


start = time()

profile.runcall(test_stress_imul_duet)

total = time() - start
op_results = total / LOOPS
print(f""AVG Duet imul duration: {op_results} sec. total {total} sec"")

ps = pstats.Stats(profile)
ps.sort_stats(""tottime"")

ps.print_stats()
```",full script import o import time import time import import import import import profile return context context pow return context none zip duet context duet range duet start time total time start total print duet duration sec total total sec profile,issue,negative,positive,neutral,neutral,positive,positive
771418344,"@dylanamiller Python 3.6 is correctly listed and supported. I wonder if there is an issue with your local environment and running the pre-commit hook checks?

The version for mypy listed in the `.pre-commit-config.yml` is:
```
- repo: https://github.com/pre-commit/mirrors-mypy
    rev: v0.782
```

Interestingly if I upgrade it to mypy 0.800 which is the latest those errors still don't appear.
If you can upgrade `.pre-commit-config.yml` to use mypy 0.800 and fix the pre-commit warnings in a PR that would be greatly appreciated.",python correctly listed wonder issue local environment running hook version listed rev interestingly upgrade latest still appear upgrade use fix would greatly,issue,negative,positive,positive,positive,positive,positive
771409852,@harikrishnankh the Torch Vision API hasn't been completely added yet. This would probably be a pretty easy fix. If you would like to open a PR that would be greatly appreciated. See `src/syft/lib/torchvision/allowlist.py`,torch vision completely added yet would probably pretty easy fix would like open would greatly see,issue,positive,positive,positive,positive,positive,positive
771407113,"@Koukyosyumei you should be able to do:
```
$ git checkout 0.4
$ git pull
$ git checkout feature_4798
$ get merge 0.4
```

At this point it's going to tell you there are conflicts.
You need to carefully edit the conflicted files and merge the code in places where it doesn't match.

Check out guides like this one:
https://www.atlassian.com/git/tutorials/using-branches/merge-conflicts

Alternatively, if all you have changed are Notebooks then it might be easier to just copy the notebooks out and create a fresh branch from the latest 0.4 and commit them as a single commit.",able git git pull git get merge point going tell need carefully edit merge code match check like one alternatively might easier copy create fresh branch latest commit single commit,issue,positive,positive,positive,positive,positive,positive
771400446,"@madhavajay 
Thanks for your reply! Actually, I'm not familiar with git. Could you show me how to resolve the conflict?",thanks reply actually familiar git could show resolve conflict,issue,negative,positive,positive,positive,positive,positive
771398865,@Koukyosyumei this looks great! Thank you so much for your PR. I will be reviewing this tomorrow. As @tudorcebere says are you able to fix the conflicts?,great thank much tomorrow able fix,issue,positive,positive,positive,positive,positive,positive
771084936,"Hi, I think there is a bigger bug in the functionality provided here,

When we execute the following statement from the DS side:

```
torch_ptr = duet.torch.Tensor([1, 2, 3])
```

It adds the data in the store of the Data Owner beforehand (even before administering the request itself). The Data Scientist can flood the data store of the data owner via this, an example

```
>>> duet.store.pandas
                                        ID Tags Description             object_type
0  <UID: cd63b75dfa55405eaabe28546e7b9717>  [x]      xasdad  <class 'torch.Tensor'>
1  <UID: e50520210b4244ca87eb274c4659f997>   []              <class 'torch.Tensor'>
2  <UID: 4ca9b63f45534f7a8e53bee1bec5bb96>   []              <class 'torch.Tensor'>
3  <UID: 01a56e5218884d90b0b396869959001b>   []              <class 'torch.Tensor'>
4  <UID: 38560424aacf44af834daf73b6236927>   []              <class 'torch.Tensor'>

>>> duet.store[1].get()
tensor([1., 2., 3.])
```",hi think bigger bug functionality provided execute following statement side data store data owner beforehand even request data scientist flood data store data owner via example id description class class class class class tensor,issue,negative,neutral,neutral,neutral,neutral,neutral
770986844,"Hello @Koukyosyumei !

Your work looks really nice! A few things before starting to review it:
* can you solve conflicts to have 0.4 as a base branch? We have a ton of new functionality/ideas there that might be worth having.

Ping me on Slack if you require help on changing anything or if you need help with the rebase/conflict solving on 0.4.

Thanks for your interest in syft!",hello work really nice starting review solve base branch ton new might worth ping slack require help anything need help thanks interest,issue,positive,positive,neutral,neutral,positive,positive
770682549,"I have some thoughts about this issue.
1. The problem is not that ""duet.store has multiple elements with same tags"". I think it's okay and reasonable.
2. And ""we can't call `duet.store['context']` when there are multiple elements with tags=['context']"" is also not the real problem. Because it's natural that syft can't figure out  which one to return when there are mutiple ones match. The right way in this case is to use `duet.store[""5061f0db8a824e4f90c8295cc745cd0d""]# use id` or `duet.store[0] # use index`.
3. But it is truly a problem that ""multiple ptrs in duet.store pointing to the same object, if we send a same object multiple times."" This is a bug we want to fix. And I have one optional solution in mind:
    1. The method `SaveObjectAction.execute_action` is where we put an object into `node.store`.
    2. In this method, before we do anything, we should first check if there already exists an object with the same id.
    3. If so, we just do nothing. Becuase the object we want to put into store is already there.
    4. Else, we do what should be done normally.",issue problem multiple think reasonable ca call multiple also real problem natural ca figure one return match right way case use use id use index truly problem multiple pointing object send object multiple time bug want fix one optional solution mind method put object method anything first check already object id nothing object want put store already else done normally,issue,negative,positive,positive,positive,positive,positive
770471323,"Hi, @madhavajay ! Could I ask you to review this PR ?",hi could ask review,issue,negative,neutral,neutral,neutral,neutral,neutral
770179238,"Full cProfile dump.

Decompress first. Can be visualized with 
```
pyprof2calltree -i profile -k
```

[profile.tar.gz](https://github.com/OpenMined/PySyft/files/5897630/profile.tar.gz)
",full dump decompress first profile,issue,negative,positive,positive,positive,positive,positive
770146904,"Hi, @madhavajay I'm working on this issue, and I almost finished the implementation for MNIST (PR #5071 ). I tested my notebook on both my local laptop and Google Colab, and both of them worked. Then, I have a few questions. 

1. Should I support other datasets like the original example? It seems that remote_torchvision.datasets currently supports only MNIST. 
2. I had to change the structure of the model a bit because pysyft doesn't support transform.resize. Is it OK?",hi working issue almost finished implementation tested notebook local worked support like original example currently change structure model bit support,issue,positive,positive,positive,positive,positive,positive
769739365,"This issue should be reopened, I had the exact same problem because of the hook:
![image](https://user-images.githubusercontent.com/26694607/106267656-a28d7b00-6232-11eb-8e28-64bdc4ae7063.png)
If I comment out the hook part (hook = sy.TorchHook(torch)) it works
Also worked when I moved into numpy to do the operations and back to torch. ",issue exact problem hook image comment hook part hook torch work also worked back torch,issue,negative,positive,positive,positive,positive,positive
769382678,"> > Hi @caiyuanqin, it looks like you are trying to use the old 0.2.x method of `TorchHook` in 0.3.0 which is no longer needed.
> > This raises a very good issue which is we need to add a 0.2.x upgrade explanation to our README.md so thanks, I will get this in the pipeline asap.
> 
> Can you please show how should we write the following in syft 0.3.0:
> import torch as th
> import syft as sy
> hook = sy.TorchHook(th)

Someone have a solution for this ? I use torch 1.6 and syft 0.3.0  How can I write this lines of codes in 0.3.0 if sy.TorchHook() is not anymore available ? ",hi like trying use old method longer good issue need add upgrade explanation thanks get pipeline please show write following import torch th import hook th someone solution use torch write available,issue,positive,positive,positive,positive,positive,positive
768119546,"```
>>> torchvision.transforms.Compose.transforms
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
AttributeError: type object 'Compose' has no attribute 'transforms'
>>> import torchvision.transforms as transform
>>> torchvision.transforms.Compose([transform.CenterCrop(10),transform.ToTensor()])
Compose(
    CenterCrop(size=(10, 10))
    ToTensor()
)
>>> torchvision.transforms.Compose([transform.CenterCrop(10),transform.ToTensor()]).transforms
[CenterCrop(size=(10, 10)), ToTensor()]
>>> 
```
same thing in my case while solving #5033 it is working only when we passing value inside otherwise not @avinsit123 and @Koukyosyumei ",recent call last file line module type object attribute import transform compose thing case working passing value inside otherwise,issue,negative,neutral,neutral,neutral,neutral,neutral
768028872,"@Koukyosyumei Not really. The trick is to pass mean and std as parameters, but currently `module.py` do not support any such functionality.",really trick pas mean currently support functionality,issue,negative,negative,neutral,neutral,negative,negative
767822333,Could you also help me with the CI build where this occurs please? ,could also help build please,issue,positive,neutral,neutral,neutral,neutral,neutral
767795774,"What I managed to find until now on the ```dev``` branch.

It seems that sending a big model and then trying to run whatever cell - it remains ""stuck"" running the cell (eventually it runs it...).

I tried to reduce the number of output neurons from the Linear layer (in the example there are 9216 x 128) -- I tried to use 9216 x 1 and I have not seen this problem.

Also, tried the script Vova from ```examples/duet/mnist/send_tensor.py``` but I did not have this problem (tested it locally) - maybe it is because the DO and DS reside on the same machine.

A good next step would be to test it on the colab machine (using the method Madhava suggested to connect to those machines)",find dev branch sending big model trying run whatever cell remains stuck running cell eventually tried reduce number output linear layer example tried use seen problem also tried script problem tested locally maybe reside machine good next step would test machine method connect,issue,negative,positive,positive,positive,positive,positive
767577695,"@avinsit123

Thanks for your comment! 
Did you come up with any solution?",thanks comment come solution,issue,positive,positive,positive,positive,positive,positive
767548298,"> did we have to add this above type of test into some file??

There is a folder with tests (named ```tests``` :D). You should be able to find there also a folder for ```torchvision```",add type test file folder able find also folder,issue,negative,positive,positive,positive,positive,positive
767545524,did we have to add this above type of test into some file??,add type test file,issue,negative,neutral,neutral,neutral,neutral,neutral
767536831,i created PR #5064 try to solve this issue give some guidance to create test case for this,try solve issue give guidance create test case,issue,negative,neutral,neutral,neutral,neutral,neutral
767492549,"@Koukyosyumei I am working on Issue #5031 which is similar to this. I see that u have interpreted the issue and line `# TODO: Normalize properties only exists on the object not on the class?` in a different manner. If you will try to access any attribute of `torchvision.transforms.Normalize` like `inplace` you will get a no such attribute error(See Screenshot below). 

![Screenshot 2021-01-26 at 5 19 17 PM](https://user-images.githubusercontent.com/33565881/105841499-b77fc980-5ffa-11eb-9aae-c387903632d8.png)

It can be only accessed if you input `mean` and `std` (See below). It would involve modifying allowlist in a manner such that u can pass `mean `and `std` during checks.

![Screenshot 2021-01-26 at 5 19 46 PM](https://user-images.githubusercontent.com/33565881/105841531-c49cb880-5ffa-11eb-8c95-d6d63e97f070.png)

If u are able to fix this issue do tell me as this would help me a lot.


",working issue similar see issue line normalize object class different manner try access attribute like get attribute error see input mean see would involve manner pas mean able fix issue tell would help lot,issue,negative,negative,neutral,neutral,negative,negative
767485536,Could you also write some tests and also uncomment the other ```Normalize``` methods to check if they work?,could also write also normalize check work,issue,negative,neutral,neutral,neutral,neutral,neutral
766920467,"> Hi @caiyuanqin, it looks like you are trying to use the old 0.2.x method of `TorchHook` in 0.3.0 which is no longer needed.
> 
> This raises a very good issue which is we need to add a 0.2.x upgrade explanation to our README.md so thanks, I will get this in the pipeline asap.

Can you please show how should we write the following in syft 0.3.0:
import torch as th
import syft as sy
hook = sy.TorchHook(th)",hi like trying use old method longer good issue need add upgrade explanation thanks get pipeline please show write following import torch th import hook th,issue,positive,positive,positive,positive,positive,positive
766312306,Hi! One mention for this PR before I start reviewing is that it should have a base from 0.4. Do you mind cherry picking those commits and rebasing with 0.4? I can help you with that if you are not so familiar with git. Drop me a message on slack and we can have call to fix that.,hi one mention start base mind cherry help familiar git drop message slack call fix,issue,negative,negative,negative,negative,negative,negative
766276084,"> Hey @xutongye,
> Nice work! This should also close #4899 :)

Hi @NiWaRe , thanks. I saw your PR and gain some inspiration from it. I thought about merging your commits in, but they are behind 0.4 too much, there would be a lot of conflicts, so I did not do that. But thanks for your previous work.",hey nice work also close hi thanks saw gain inspiration thought behind much would lot thanks previous work,issue,positive,positive,positive,positive,positive,positive
766157443,"Benchmarking currently is not supported in KotlinSyft. If you want, you can explicitly write tests/timestamp evaluations for benchmarking in kotlin. Also, you don't need to run multiple devices, you can set the number of workers to 1 in pygrid server config.",currently want explicitly write also need run multiple set number server,issue,negative,neutral,neutral,neutral,neutral,neutral
766095198,Interesting question - I feel that @vkkhare might be your best bet for help on this. I'll assign this ticket to him @phoenix-meadowlark.,interesting question feel might best bet help assign ticket,issue,positive,positive,positive,positive,positive,positive
765897034,"Hey @xutongye, 
Nice work! This should also close #4899 :) 
",hey nice work also close,issue,negative,positive,positive,positive,positive,positive
765657081,"I didn't test GCE, only AWS.
In my case, I have the following behavior:
 - data owner AWS <-> data scientist local network: doesn't work (there's no timeout either, it just sits there indefinitely).
 - data owner AWS <-> data scientist AWS: works fine
 
Note that the VM on AWS is behind a proxy",test case following behavior data owner data scientist local network work either indefinitely data owner data scientist work fine note behind proxy,issue,negative,positive,neutral,neutral,positive,positive
765652629,"@madhavajay thanks for the answers! 
Sorry for not progressing much lately (exams coming up at university ^^), I saw that @xutongye also did a PR to resolve #4898, that means this isn't useful anymore right? ",thanks sorry much lately coming university saw also resolve useful right,issue,positive,negative,neutral,neutral,negative,negative
765201903,"Sure, I can add filters too, I will investigate that.

Also, the current exceptions logging might be a bit aggressive, I will have to review that. I disabled the full traceback for now, not sure if we needed somewhere.",sure add investigate also current logging might bit aggressive review disabled full sure somewhere,issue,negative,positive,positive,positive,positive,positive
765154520,"@bcebere awesome work. What do you think would be the best way to achieve some kind of code area grepping? So for example if all the logging / print in WebRTC was tagged with network and the user could disable it so they don't see any of those messages while keeping say, the store event log? Maybe an optional ""TAG"" prefix to the line?",awesome work think would best way achieve kind code area example logging print tagged network user could disable see keeping say store event log maybe optional tag prefix line,issue,positive,positive,positive,positive,positive,positive
765152630,@JMLourier the best place is to message in the #lib_pysyft channel on Slack so that anyone of the team can respond. 😊,best place message channel slack anyone team respond,issue,positive,positive,positive,positive,positive,positive
765151483,I haven't seen this issue since the https://github.com/OpenMined/PySyft/pull/5006 fix so lets consider it resolved.,seen issue since fix consider resolved,issue,negative,neutral,neutral,neutral,neutral,neutral
765150306,Currently the github url we use to resolve these is blocked in some countries.,currently use resolve blocked,issue,negative,neutral,neutral,neutral,neutral,neutral
765142014,"Most of this is done in the AST Refactor but we might still need some of the shortcut properties to jump between Class, Pointer and FQN.",done ast might still need jump class pointer,issue,negative,neutral,neutral,neutral,neutral,neutral
765135727,"If anyone has any ideas how to go about this, I would be grateful for any help.",anyone go would grateful help,issue,positive,neutral,neutral,neutral,neutral,neutral
765135173,"I am not able to figure out how to go about this. No matter what I do, the iterator for UserDict and Dict fails the pytest.
![image](https://user-images.githubusercontent.com/52173002/105450724-1cf15480-5ca1-11eb-84b9-b3d51058b006.png)
The same code works on a Jupyter Notebook, 
![image](https://user-images.githubusercontent.com/52173002/105450767-31355180-5ca1-11eb-90e3-fd28d58925f5.png)
",able figure go matter image code work notebook image,issue,negative,positive,positive,positive,positive,positive
765055436,"@bcebere this is super awesome. I removed the unused Union. Also I noticed that there is no serde for the Enum types. We have support for this now, so I wonder if it's worth adding. It would mean that they can be sent back and forth or remotely created in a store which isn't a Memory Store like the SQLite store which would be handy.

For example:
```
st_ckks = ts.SCHEME_TYPE.CKKS
st_ckks.send(duet, searchable=True)
```",super awesome removed unused union also support wonder worth would mean sent back forth remotely store memory store like store would handy example duet,issue,positive,positive,positive,positive,positive,positive
764801380,"@madhavajay, perfect, thanks! I'd continue to work on the issue but I need some support. Many of the remaining warnings are caused by exposing public interfaces, as fas as I see it. I would need to discuss this with someone how knows the code a bit. Would that be you? :)",perfect thanks continue work issue need support many public see would need discus someone code bit would,issue,positive,positive,positive,positive,positive,positive
764377098,"I tried installing syft 0.2.9 but I got the error:"" Could not find a version that satisfies the requirement torch~=1.4.0 (from syft)""
I tried installing pytorch 1.4,0 manually, but got the same error",tried got error could find version requirement tried manually got error,issue,negative,neutral,neutral,neutral,neutral,neutral
763054430,"Hi all!

An issue will be assigned after a PR is opened to tackle the progress/give feedback.

Open a PR and ping me where you get stuck, thank you for your interest in syft!",hi issue assigned tackle feedback open ping get stuck thank interest,issue,positive,neutral,neutral,neutral,neutral,neutral
762848354,"Hi there, has anyone found a fix for this issue yet? 

Syft 0.2.9 still has this issue and it's causing me to use huge amounts of RAM. Using tracemalloc I've found that the ID's referring to Syft objects generated while iterating over a federated data loader are stored indefinitely. The more Epochs you iter over, the higher the ID count. It can only be removed from memory by resetting the kernel.

Tracemalloc report:
`\syft\generic\id_provider.py:41: size=32.0 MiB (+28.0 MiB), count=1 (+0), average=32.0 MiB`
`\syft\generic\id_provider.py:7: size=20.4 MiB (+16.3 MiB), count=669505 (+535602), average=32 B`",hi anyone found fix issue yet still issue causing use huge ram found id data loader indefinitely iter higher id count removed memory kernel report mib mib mib mib mib,issue,negative,positive,positive,positive,positive,positive
762794050,"
> check notebooks in this github https://github.com/udacity/private-ai

this notebook is not working with the new version of syft 0.3
",check notebook working new version,issue,negative,positive,positive,positive,positive,positive
762647699,"Hi,
I have been working on this for some days and got some code.
This works fine in 0.4(via setup.py), but fails in 0.3(pip install syft=0.3.0). 
I think some bugs need to be fixed to make it work.

After the training is complete, the model can not be retrieved because ""'Linear' object has no attribute 'serializable_wrapper_type'"", Do I have to put it in a class MyLinear(sy.Module)?

```

import syft as sy
import sklearn
import torch
from sklearn.datasets import load_boston

alice = sy.VirtualMachine()
alice_client = alice.get_root_client()

dataset = load_boston()
boston_data = torch.tensor(dataset[""data""]).float()
boston_target = torch.tensor(dataset[""target""]).float()

#tensors below appear in alice_client.store
boston_data.send(alice_client, searchable =True)
boston_target.send(alice_client, searchable =True)

#torch.utils.data.TensorDataset is not wrapped, generate the dataset manually.
ds = [t for t in zip(boston_data, boston_target)]
ds = sy.lib.python.List(ds)
ds.send(alice_client, searchable=True)

#in 0.3, error occurs, 'ds' is invisible
#print(len(alice_client.stroe)) ==> 2
#when trying to read alice.store, error occurs at obj_search_service.py:process()
#--> 211                     ptr_type = obj2pointer_type(obj=obj.data)
#UnboundLocalError(""local variable 'ref' referenced before assignment"")
#so ""ds"" is invisible in alice_client

remote_torch = alice_client.torch
#torch.nn.Linear is not wrapped, can not be sent
remote_model = remote_torch.nn.Linear(13, 1)

remote_dl = remote_torch.utils.data.DataLoader(
    alice_client.store[2], batch_size=32, shuffle=True
 )

#make the request to be approved automatically(#5015), or exception ""Request to access data length not granted""
remote_dl.set_request_config({})

loss_accum = 0
for i, t in enumerate(remote_dl):
    optimizer = remote_torch.optim.Adam(params=remote_model.parameters(),lr=1e-2)
    optimizer.zero_grad()    
    data, target = t[0], t[1]
    pred = remote_model(data)    
    loss = ((pred.view(-1) - target)**2).mean()
    loss.backward()
    optimizer.step()    
    gotloss = loss.get()
    loss_accum += float(gotloss)
    print(i, gotloss)
    
print(loss_accum)   

```",hi working day got code work fine via pip install think need fixed make work training complete model object attribute put class import import import torch import data target appear searchable searchable wrapped generate manually zip error invisible print trying read error process local variable assignment invisible wrapped sent make request automatically exception request access data length enumerate data target data loss target float print print,issue,negative,positive,positive,positive,positive,positive
762642788,"@tudorcebere I am getting the following error(in screenshot) when I run your code snippet. I am not able to understand the purpose of `request_block = True` as when I use a normal `Tensor([1,2,3]).get()` I am able to retrieve the tensor from alice_client . Do you want the .get() function to still return if the `request_block` is set to `True` .
![Screenshot 2021-01-19 at 12 22 20 PM](https://user-images.githubusercontent.com/33565881/104998712-af031e00-5a51-11eb-8809-c2123344fc62.png)
",getting following error run code snippet able understand purpose true use normal tensor able retrieve tensor want function still return set true,issue,negative,positive,positive,positive,positive,positive
762519020,"> @jmaunon this looks great. I just fixed a broken cell on the end of the DS notebook but they all ran as expected.
> If you don't want to use the credential exchanger you can probably remove that from the imports.
> 
> Also what is the relation to this PR? #5013 Should we merge #5013 first?
> @gmuraru ?

Removed credential exchanger import",great fixed broken cell end notebook ran want use credential exchanger probably remove also relation merge first removed credential exchanger import,issue,negative,positive,positive,positive,positive,positive
762493016,Great Work!! Only minor stuff - but the rest looks great!,great work minor stuff rest great,issue,positive,positive,positive,positive,positive,positive
762491222,"> @jmaunon this looks great. I just fixed a broken cell on the end of the DS notebook but they all ran as expected.
> If you don't want to use the credential exchanger you can probably remove that from the imports.
> 
> Also what is the relation to this PR? #5013 Should we merge #5013 first?
> @gmuraru ?

Yep, but this should work without that PR :D",great fixed broken cell end notebook ran want use credential exchanger probably remove also relation merge first yep work without,issue,positive,positive,positive,positive,positive,positive
762490486,"Could you remove the ""POC - MPC Tensor - Duet.ipynb"" (I think it is not used anywhere).",could remove tensor think used anywhere,issue,negative,neutral,neutral,neutral,neutral,neutral
762377107,"I would strongly advocate for exploring DIDComm as a potential solution to this - https://identity.foundation/didcomm-messaging/spec/

It may be a future improvement to this one, but certainly something we should keep in mind.",would strongly advocate exploring potential solution may future improvement one certainly something keep mind,issue,positive,positive,positive,positive,positive,positive
762183569,"> @jmaunon this looks great. I just fixed a broken cell on the end of the DS notebook but they all ran as expected.
> If you don't want to use the credential exchanger you can probably remove that from the imports.
> 
> Also what is the relation to this PR? #5013 Should we merge #5013 first?
> @gmuraru ?

Yep - we should merge #5013 (which is ready). I can look over this PR in 4-5 hours.",great fixed broken cell end notebook ran want use credential exchanger probably remove also relation merge first yep merge ready look,issue,positive,positive,positive,positive,positive,positive
761998062,"@bcebere this is looking great.
I just noticed that the timeout can be really short sometimes to run both cells in the notebooks on loopback. What do you think about maybe having a `KeyboardInterrupt`?

```
while True:
    try:
        with open(self.file_path, ""r"") as f:
            loopback_config = json.loads(f.read())

            if ""client_id"" in loopback_config:
                client_id = str(loopback_config[""client_id""])
                break
            time.sleep(0.5)

    except KeyboardInterrupt:
        try_print(""Cancelling connection"")
        break
    except Exception as e:
        try_print(""server config load failed"", self.file_path, e)
```

I tried to keep the original:
```
if ""client_id"" not in loopback_config:
    raise Exception(""Client not ready"")

```
but it seems to mean that the except KeyboardInterrupt doesn't run.
Then I guess an optional timeout could be passed in as an arg to launch / join?",looking great really short sometimes run think maybe true try open break except connection break except exception server load tried keep original raise exception client ready mean except run guess optional could launch join,issue,positive,positive,positive,positive,positive,positive
761981751,"@jmaunon this looks great. I just fixed a broken cell on the end of the DS notebook but they all ran as expected.
If you don't want to use the credential exchanger you can probably remove that from the imports.

Also what is the relation to this PR? https://github.com/OpenMined/PySyft/pull/5013 Should we merge #5013 first?
@gmuraru ?",great fixed broken cell end notebook ran want use credential exchanger probably remove also relation merge first,issue,negative,positive,positive,positive,positive,positive
761840172,"Thanks, I'll check it out.

On Sun, 17 Jan, 2021, 7:58 pm RAHUL Danu, <notifications@github.com> wrote:

> in requirements.txt you can see clearly that it is installing torch>=1.5
> and the version of torch vision which is compatible with that
> if you want stable pysyft i say go with pi install syft=0.=2.9
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/5010#issuecomment-761821288>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ADRITK2DQ6VEL6VPUMCIH6TS2LX2PANCNFSM4WAHRZ5Q>
> .
>
",thanks check sun wrote see clearly torch version torch vision compatible want stable say go pi install thread reply directly view,issue,positive,positive,positive,positive,positive,positive
761821288,"in requirements.txt you can see clearly that it is installing torch>=1.5 and the version of torch vision which is compatible with that 
if you want stable pysyft i say go with pi install syft=0.=2.9",see clearly torch version torch vision compatible want stable say go pi install,issue,positive,positive,positive,positive,positive,positive
761709434,I will make this quick update to the documentation if that is alright.,make quick update documentation alright,issue,negative,positive,positive,positive,positive,positive
761607125,"will torch vision package automatically add with syft?

On Sat, Jan 16, 2021 at 9:46 PM Harikrishnan K H <
harikrishnankh1996@gmail.com> wrote:

> can you please mention a stable version of torchvision
>
>
> On Thu, Jan 14, 2021 at 5:56 PM Leo3967 <notifications@github.com> wrote:
>
>> install torchvision or update torchvision
>>
>> —
>> You are receiving this because you authored the thread.
>> Reply to this email directly, view it on GitHub
>> <https://github.com/OpenMined/PySyft/issues/5010#issuecomment-760164796>,
>> or unsubscribe
>> <https://github.com/notifications/unsubscribe-auth/ADRITK3IADUT4MU55IIDVCLSZ3PH7ANCNFSM4WAHRZ5Q>
>> .
>>
>
",torch vision package automatically add sat wrote please mention stable version wrote install update thread reply directly view,issue,positive,positive,neutral,neutral,positive,positive
761589812,"can you please mention a stable version of torchvision


On Thu, Jan 14, 2021 at 5:56 PM Leo3967 <notifications@github.com> wrote:

> install torchvision or update torchvision
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/5010#issuecomment-760164796>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ADRITK3IADUT4MU55IIDVCLSZ3PH7ANCNFSM4WAHRZ5Q>
> .
>
",please mention stable version wrote install update thread reply directly view,issue,positive,positive,neutral,neutral,positive,positive
760682934,"Hey, I want to work on this issue, can you help from where to get started?",hey want work issue help get,issue,negative,neutral,neutral,neutral,neutral,neutral
760559643,"Hi @libratiger, Thanks for the PR, however I have thought about this change and decided that we won't merge it because changing the priority of information in the REAME.md to focus on running a local signalling server is less important than the information which precedes it. I hope you can understand.",hi thanks however thought change decided wo merge priority information focus running local server le important information hope understand,issue,positive,positive,positive,positive,positive,positive
760366385,"I can work on this work, please assign it to me.",work work please assign,issue,negative,neutral,neutral,neutral,neutral,neutral
760161059,"The create_sandbox function does not exist in 0.3. To make the dataloader work we need that function. 

https://github.com/OpenMined/PySyft/issues/3728

This needs to be fixed. Credits to Kishan Sairam Adapa for this. 

Link to Slack post: https://openmined.slack.com/archives/C6EEFN3A8/p1609763826164500",function exist make work need function need fixed link slack post,issue,negative,positive,neutral,neutral,positive,positive
760122387,"I would like to work on this and I'm trying to understand the notebook. I'm not asking to get assigned in this, but please don't close this issue. ",would like work trying understand notebook get assigned please close issue,issue,positive,neutral,neutral,neutral,neutral,neutral
760096635,"I won't get it, Can you tell in brief?",wo get tell brief,issue,negative,neutral,neutral,neutral,neutral,neutral
759457793,Closing this and adding all the changes directly in the ```sympc-dev``` branch because I should had cut the 0.4 branch when I created the ```sympc-dev```,directly branch cut branch,issue,negative,positive,neutral,neutral,positive,positive
759291340,Yes! I will try to fix it and merge in 5 minutes. Will ping you! ,yes try fix merge ping,issue,negative,neutral,neutral,neutral,neutral,neutral
759290337,"@gmuraru Looks good, but I guess we need this PR first? https://github.com/OpenMined/SyMPC/pull/42/",good guess need first,issue,negative,positive,positive,positive,positive,positive
759223297,"@madhavajay 
Successfully installed syft  after changing python version to 3.8.0
Thank you for your help!

But a new issue raised. An Attribute error while importing syft. torchvision.datasets has no attribute visiondataset. Please check the attachment for more details

I tried importing syft module alone, but the issue still persists.

## Screenshots
![e1](https://user-images.githubusercontent.com/14846379/104411930-5df6b400-5591-11eb-8f13-a116292b0264.PNG)
![e2](https://user-images.githubusercontent.com/14846379/104411936-5f27e100-5591-11eb-8790-cb6581b069d3.PNG)

",successfully python version thank help new issue raised attribute error attribute please check attachment tried module alone issue still,issue,positive,positive,positive,positive,positive,positive
759190899,"@madhavajay  I am using windows 10. I am running this on anaconda. My python version is 3.9.1. I will try to install python 3.8, Can you please recommend an exact version of python.",running anaconda python version try install python please recommend exact version python,issue,positive,positive,positive,positive,positive,positive
759181574,"@harikrishnankh I can see mention of 3.9 in the output above, are you using Python 3.9? It's still not supported yet, so I would suggest using something lower like 3.8 if you can. Can you confirm the output of this command:
```
where python3
python3 --version
```",see mention output python still yet would suggest something lower like confirm output command python python version,issue,negative,neutral,neutral,neutral,neutral,neutral
759110787,"Hi @devkumar24 if you run the `python -m torch` tests inside the `0.4` branch and monitor your memory usage you will see that it gets pretty high. You can see in `allowlist_test.py` that the test is heavily parameterized:
```
@pytest.mark.torch
@pytest.mark.parametrize(
    ""tensor_type, op_name, self_tensor, _args, is_property, return_type, deterministic"",
    TEST_DATA,
)
def test_all_allowlisted_tensor_methods(
```

pytest is holding on to all these variables until the entire test method is finished all possible combinations, we need to find a way to reduce the amount of memory it uses by cleaning up in between or splitting up the parameterization into multiple tested functions to reduce the memory watermark.",hi run python torch inside branch monitor memory usage see pretty high see test heavily deterministic holding entire test method finished possible need find way reduce amount memory cleaning splitting multiple tested reduce memory watermark,issue,negative,positive,neutral,neutral,positive,positive
759098340,"@harikrishnankh Please provide all of the relevant details required to debug such an error.
- OS version
- Python version
- Instructions followed
- Command ran
- Errors Outputted",please provide relevant error o version python version command ran,issue,negative,positive,positive,positive,positive,positive
758802445,"it doesnt have it,,,,
i want in real world case...not virtual",doesnt want real world case virtual,issue,negative,positive,positive,positive,positive,positive
758614561,"Hey @madhavajay, I want to work on this issue, could you help me to where to start from?
",hey want work issue could help start,issue,negative,neutral,neutral,neutral,neutral,neutral
758541592,"PyTorch's load_state_dict breaks the computational graph, so on get(), there won't be any gradients to retrieve.

The gradients will have to be retrieved via the model_ptr.parameters().get() call.",computational graph get wo retrieve via call,issue,negative,neutral,neutral,neutral,neutral,neutral
758362712,Hey @madhavajay been keeping busy with work lately. Feel free to assign this one to someone else.,hey keeping busy work lately feel free assign one someone else,issue,positive,positive,neutral,neutral,positive,positive
758263585,@hershd23 how did you go? Are you able to push a Draft PR? If not I might need to delegate this task to someone else.,go able push draft might need delegate task someone else,issue,negative,positive,positive,positive,positive,positive
757864676,"Hello @libratiger!

Currently, this has been solved in a PR, thanks for your interest!

Keep an eye out for the `Good first issue` tag!",hello currently thanks interest keep eye good first issue tag,issue,positive,positive,positive,positive,positive,positive
757705313,"We did not release anything else yet, we offer support only for duet right now.",release anything else yet offer support duet right,issue,negative,positive,positive,positive,positive,positive
757611900,"
After trying the following code:

```
import syft as sy
duet = sy.launch_duet(network_url=""http://ec2-18-216-8-163.us-east-2.compute.amazonaws.com:5000"")
import syft as sy
duet = sy.join_duet(target_id=""xxxxx"", network_url=""http://ec2-18-216-8-163.us-east-2.compute.amazonaws.com:5000"")
```

it works.

So my problem is with the GitHub URL not loading. It is that 
` curl https://raw.githubusercontent.com/OpenMined/OpenGridNodes/master/network_address`
does not work. So it is not a pysyft problem. ",trying following code import duet import duet work problem loading curl work problem,issue,negative,neutral,neutral,neutral,neutral,neutral
757570668,"@NiWaRe your implementation looks correct! 👍🏼 
Good questions:

> why is the file called 'uppercase' ? ^^
> the purpose of the file: creating a wrapperclass for serialization and deserialization and setting that as an attribute of a normal tensor?

It's called uppercase because its the torch.Tensor class not the torch.tensor function.

> Why do we do that and how is that then applied to every torch tensor that is created? Is it because somewhere else we call e.g. the _data_object2proto function on a tensor before sending it?

The `aggressive_set_attr` is modifying the class to have an attribute `serializable_wrapper_type` which points to the Wrapper class. When syft finds a foreign object and wants to serialize it checks if this attribute exists and if it does it uses that class and its methods to do the serde.

> concerning this DeviceWrapper Class - given that I didn't misunderstand you completely ^^ - why couldn't we just define an field int index = 4? And how will be the Wrapper be used as an attribute? (about same questions as the previous one)

The advantage of separating the Device from the Tensor as its own type means that users can construct a `Device` and then re-use that same pointer / variable as input on other Tensors or methods which take a device as input. If Device ever changes we can update it separately from Tensor itself. As we want to cover as much of the Torch API as possible it makes sense for us to support `device` so adding it now would be really appreciated. 😊

Let me know if you have any more questions.",implementation correct good file purpose file serialization setting attribute normal tensor class function applied every torch tensor somewhere else call function tensor sending class attribute wrapper class foreign object serialize attribute class concerning class given misunderstand completely could define field index wrapper used attribute previous one advantage separating device tensor type construct device pointer variable input take device input device ever update separately tensor want cover much torch possible sense u support device would really let know,issue,positive,positive,positive,positive,positive,positive
757569372,The goal here would be to allow some kind of ENVIRONMENT VAR to be set before import which would allow a version of torch compiled with missing ops to still load.,goal would allow kind environment set import would allow version torch missing still load,issue,positive,positive,positive,positive,positive,positive
757569194,As discussed this isn't a bug with Syft but we can look to work around this.,bug look work around,issue,negative,neutral,neutral,neutral,neutral,neutral
757524195,"Hello @devkumar24,

This has been already addressed in a PR that will be merged soon.

Thank you for your interest in the syft! I would recommend searching for the issues tagged with `Good first issue` and grab one of those as your first issue in 0.3.X!
",hello already soon thank interest would recommend searching tagged good first issue grab one first issue,issue,positive,positive,positive,positive,positive,positive
757522486,"Hello @lk1983823,

This is the goal for us on the next few months, to reach feature parity with 0.2.x. We lack a few features yet to do FL, but as soon as we get them done, a similar tutorial to the one in 0.2.x will be released.",hello goal u next reach feature parity lack yet soon get done similar tutorial one,issue,negative,neutral,neutral,neutral,neutral,neutral
757522217,"Hello @uid42!

You are right, this is a bug we've found and almost fixed it in the new release!

If you want to understand why this is happening, let's look a bit on some python internals:

```
example_list = [1, 2, 3]

for elem in example_list:
   pass

```

Here, python gets an iterator from `example_list`, when the iterator is exhausted (when the last element gets iterated), an error is being thrown that is being caught by the python interpreter, namely `StopIteration`. At this point, the for loop is exited.

Now, in the context of syft, we are iterating through a remote list, while the remote iterator gets exhausted and it throws an error on the owner side, the other side (data scientist) of the duet has no mechanism yet to know that the error has been thrown, so it's still looping and waiting for `StopIteration` to be thrown.

In the next patch we have a few fixes for this problem. :)
",hello right bug found almost fixed new release want understand happening let look bit python internals pas python exhausted last element error thrown caught python interpreter namely point loop context remote list remote exhausted error owner side side data scientist duet mechanism yet know error thrown still looping waiting thrown next patch problem,issue,negative,negative,neutral,neutral,negative,negative
757521150,"Hello, @Williance!

We are working on getting all of them + many more. Stay tuned, more will show up in the next few weeks.",hello working getting many stay tuned show next,issue,negative,positive,positive,positive,positive,positive
757520647,"Hello!

Thank you @rajatrc1705 for the help, your answer is correct! :100: 

@prajotsl123 yet we support only duet: only 2 entities can communicate over duet, upcoming work will introduce 2+ parties. Stay tuned!",hello thank help answer correct yet support duet communicate duet upcoming work introduce stay tuned,issue,positive,neutral,neutral,neutral,neutral,neutral
757519577,"Thanks, @madhavajay! 
Sry for the late response I was pretty busy with exam prep lately. 
Your suggestion sounds like a great idea! I have to admit that I'm just getting started with the protobuf serialization.
So to add the device type directly into the serialization do you mean to create a file device.py that looks similar to the current uppercase_tensor.py? Smt like that: 

```
# device.py
import [...]

device_type = torch.device(1)

class DeviceWrapper(StorableObject): 
    def __init__(self, device : object): 
        super().__init__(
           [...]
        )
        self.device = device
    def _data_object2proto(self) -> Tensor_PB:
       proto = Tensor_PB()
       # leave as bool to be more efficient than a string? 
       proto.on_cuda = getattr(self.device, ""type"", ""cpu"") == ""cuda""
       # new int in tensor.proto
       proto.index = getattr(self.device, ""index"", 0)
    
   [...]

    @staticmethod
    def _data_proto2object(proto: Tensor_PB) -> th.device:
        tensor = protobuf_tensor_deserializer(proto.tensor)
        [...]

        if proto.on_cuda is True and th.cuda.is_available():
            type = ""cuda""
        else:
            type = ""cpu"" 
        index = proto.index

        device = torch.device(type, index)

        return device

aggressive_set_attr(
    obj=device_type, name=""serializable_wrapper_type"", attr=DeviceWrapper
)
```

Tbh I don't quite understand what's going on in the original uppercase_tensor.py would you mind clarifying some things? :) 

- why is the file called 'uppercase' ? ^^
- the purpose of the file: creating a wrapperclass for serialization and deserialization and setting that as an attribute of a normal tensor? Why do we do that and how is that then applied to every torch tensor that is created? Is it because somewhere else we call e.g. the `_data_object2proto` function on a tensor before sending it? 
- concerning this DeviceWrapper Class - given that I didn't misunderstand you completely ^^ - why couldn't we just define an field `int index = 4`? And how will be the Wrapper be used as an attribute? (about same questions as the previous one)

Still struggling a bit with the bigger picture, thanks for your help :)",thanks late response pretty busy exam prep lately suggestion like great idea admit getting serialization add device type directly serialization mean create file similar current like import class self device object super device self proto leave bool efficient string type new index proto tensor true type else type index device type index return device quite understand going original would mind file purpose file serialization setting attribute normal tensor applied every torch tensor somewhere else call function tensor sending concerning class given misunderstand completely could define field index wrapper used attribute previous one still struggling bit bigger picture thanks help,issue,positive,positive,positive,positive,positive,positive
757093320,"ya thanks @rajatrc1705 
it worked ......
is there any way where i can connect multiple clients PC?
",ya thanks worked way connect multiple,issue,negative,positive,neutral,neutral,positive,positive
756834612,"Yes you can, open two jupyter notebooks, name one Data Scientist and the other Data Owner.
The Data Scientist notebook should contain the code for Data Scientist, and same goes for Data Owner.
Launch the Flask server using following command in the terminal:
`syft-network`
![image](https://user-images.githubusercontent.com/52173002/104036410-5d5cc700-51f9-11eb-8627-68ebc4c66410.png)
Now run the respective codes of both the Scientist and the Owner as given in the manual, I have given the link below.
https://github.com/OpenMined/PySyft/blob/dev/examples/duet/README.md

Let us know if you got it working.",yes open two name one data scientist data owner data scientist notebook contain code data scientist go data owner launch flask server following command terminal image run respective scientist owner given manual given link let u know got working,issue,positive,neutral,neutral,neutral,neutral,neutral
756625326,"Now the PR seems complete, the code is working all right on my machine.
![image](https://user-images.githubusercontent.com/52173002/103992800-a93c4b80-51ba-11eb-93b1-d3897d0d0a2a.png)
",complete code working right machine image,issue,negative,positive,positive,positive,positive,positive
756595862,"Hi @prajotsl123 Yes the docs need generating and theres an open ticket for this in the mean time the contribution guide is fairly big already: https://github.com/OpenMined/PySyft/blob/dev/CONTRIBUTING.md

Also checkout the Duet README.md:
https://github.com/OpenMined/PySyft/tree/master/examples/duet/",hi yes need generating there open ticket mean time contribution guide fairly big already also duet,issue,negative,negative,negative,negative,negative,negative
756569974,"@lk1983823 Are you able to DM me on Slack? I can give you some commands to do some pinging and trace-routing but the output would reveal your approximate location in the world and you might not want to post your ISP or IP addresses on the public internet. Also what operating system are you using and what kind of network? Is it at home, work, office, university all that info will help as these issues are usually caused by complex Corporate or University networks.",able slack give output would reveal approximate location world might want post public also operating system kind network home work office university help usually complex corporate university,issue,positive,positive,neutral,neutral,positive,positive
756486632,"> Hi @lk1983823, are you interested in helping us debug the issue. As you can imagine its important that our connection system works with zero configuration so it would be great to get to the bottom of the issue.

Yes, I am willing to offer help.  So what should I do now?",hi interested helping u issue imagine important connection system work zero configuration would great get bottom issue yes willing offer help,issue,positive,positive,positive,positive,positive,positive
756470826,"@sbasu26 Thanks. Thats interesting, you have a few issues there that I can see.
1) The path to your python3 is the system but not a virtualenv.
You can see here on my output when I use a virtualenv the first location found for python is in the virtualenv.
```
C:\dev\pysyft>pipenv shell
Warning: Your Pipfile requires python_version 3.8, but you are using 3.7.9 (C:\Users\me\.\p\S\python.exe).
  $ pipenv --rm and rebuilding the virtual environment may resolve the issue.
  $ pipenv check will surely fail.
Launching subshell in virtual environment…
Microsoft Windows [Version 10.0.19042.685]
(c) 2020 Microsoft Corporation. All rights reserved.

(pysyft-8bj21zgT) C:\dev\pysyft>where python
C:\Users\me\.virtualenvs\pysyft-8bj21zgT\Scripts\python.exe
C:\Users\me\AppData\Local\Programs\Python\Python36\python.exe
C:\Users\me\AppData\Local\Programs\Python\Python37\python.exe
C:\Users\me\AppData\Local\Programs\Python\Python38\python.exe
C:\Users\me\AppData\Local\Microsoft\WindowsApps\python.exe

(pysyft-8bj21zgT) C:\dev\pysyft>
```

Always use a virtualenv when creating python projects on a Desktop OS. The only time you don't need them is inside containers since thats already a kind of virtual environment with its own PATH, Python version and site-packages.

2) The syft version is totally wrong, it says its using a cache.
Maybe try installing with a more forceful command like:
```
$ pip install --upgrade syft
Collecting syft
  Downloading syft-0.3.0-py2.py3-none-any.whl (289 kB)
     |████████████████████████████████| 289 kB 6.4 MB/s
Collecting websockets
  Using cached websockets-8.1-cp36-cp36m-win_amd64.whl (66 kB)
Collecting aiortc
  Using cached aiortc-1.0.0-cp36-cp36m-win_amd64.whl (975 kB)
```

It should get version 0.3.0 right now.

The fact that you aren't getting an up to date version leads me to believe that perhaps your systems architecture isn't supported.

Can you run these two commands and how me what you get where the * * stars are, e.g. whats the OS Name and OS Version and what is the OSArchitecture?
```
$ systeminfo
...
Host Name:                 DESKTOP-JLSLBKO
*OS Name:                   Microsoft Windows 10 Pro*
*OS Version:                10.0.19042 N/A Build 19042*
```

```
$ wmic OS get OSArchitecture
OSArchitecture
*64-bit*
...
```
",thanks thats interesting path python system see output use first location found python shell warning virtual environment may resolve issue check surely fail virtual version corporation reserved python always use python o time need inside since thats already kind virtual environment path python version version totally wrong cache maybe try forceful command like pip install upgrade get version right fact getting date version believe perhaps architecture run two get whats o name o version host name o name pro o version build o get,issue,positive,positive,positive,positive,positive,positive
756320320,"Per discussion with Madhava, next up I'll try do some work on `syft/grid/connections/webrtc.py`:
```
src/syft/grid/connections/webrtc.py                                     278    219    21%   136-184, 196-246, 260-289, 296-331, 338-388, 391-402, 405-411, 415-455, 468-481, 490-502, 511-516, 528-533, 542-549, 558-564, 576-610, 616-628
```",per discussion next try work,issue,negative,neutral,neutral,neutral,neutral,neutral
756254092,I checked PyPi and it gives a 404 for the relative link. Thanks for pointing this out. I'll change them to absolute links.,checked relative link thanks pointing change absolute link,issue,negative,positive,positive,positive,positive,positive
756069630,"@madhavajay Below is the output of the command ""where python3""

(pysyft3) C:\Users\dell>where python3
C:\Users\dell\AppData\Local\Microsoft\WindowsApps\python3.exe

And executing the line import syft as sy fives me the below error:
AttributeError: module 'torchvision.datasets' has no attribute 'VisionDataset'

Somehow when I install pysyft using pip, the torchvision version which gets installed is 0.2.2.

And if I uninstall 0.2.2 and try to install torchvision 0.8.0, I get the below error screen!
<img width=""960"" alt=""torchvisionError"" src=""https://user-images.githubusercontent.com/26589431/103889520-923f2000-510c-11eb-8050-c4eafa547280.png"">
",output command python python line import five error module attribute somehow install pip version try install get error screen,issue,negative,neutral,neutral,neutral,neutral,neutral
756057527,"Hi @rajatrc1705 you need to run it from the main dir:
```
$ scripts/pre_commit.sh
```

It also looks like you don't have some of the dependencies like bandit so you will need to run:
```
$ pip install -r requirements.txt
```

To build the protos you will also need an up to date version of `protoc`.
There are some instructions in the CONTRIBUTING guide: https://github.com/OpenMined/PySyft/blob/dev/CONTRIBUTING.md 

However updated instructions for other platforms are needed so if you want to add Ubuntu or Linux that would be greatly appreciated.",hi need run main also like like bandit need run pip install build also need date version guide however want add would greatly,issue,positive,positive,positive,positive,positive,positive
756050638,"Hi @sbasu26 thats unfortunate, i'm sorry to hear about your laptop crash. I still see no PR's for this Issue. People regularly ask to have issues assigned to them and then disappear so I am no longer assigning issues to people unless they can at least lodge a PR showing some progress so we can help them. Not having a PR opened means that at any moment all your work could be completely wasted when our team decides we need that issue fixed fast and just do it ourselves. This has happened before so to prevent wasting contributors time, I am asking that people start on the issue, open a draft PR and we can discuss if it is going in the right direction and provide help.",hi thats unfortunate sorry hear crash still see issue people regularly ask assigned disappear longer people unless least lodge showing progress help moment work could completely wasted team need issue fixed fast prevent wasting time people start issue open draft discus going right direction provide help,issue,negative,negative,negative,negative,negative,negative
756047319,"> @madhavajay I would like to point out, that I am installing PySyft 0.3 after freshly installing Anaconda (after a laptop crash).
> Am I missing something apart from the installation steps mentioned in the Guide.
> 
> I have installed Ananconda and run the below commands only to install Pysyft, and I am getting the ModuleNotFound error for importing PySyft.
> 
> How to Reproduce
> $ conda create -n pysyft python=3.8
> $ conda activate pysyft
> $ conda install jupyter notebook
> $ pip install syft
> $ jupyter notebook

Can you please run these commands and report back the output where the `...` are:
```
$ conda create -n pysyft python=3.8
$ conda activate pysyft
$ conda install jupyter notebook
$ where jupyter
...
$ pip install syft
$ where python3
...
$ python3
>>> import syft as sy
>>> sy.__version__
...
```",would like point freshly anaconda crash missing something apart installation guide run install getting error reproduce create activate install notebook pip install notebook please run report back output create activate install notebook pip install python python import,issue,negative,positive,neutral,neutral,positive,positive
756043381,"Hi @lk1983823, are you interested in helping us debug the issue. As you can imagine its important that our connection system works with zero configuration so it would be great to get to the bottom of the issue.",hi interested helping u issue imagine important connection system work zero configuration would great get bottom issue,issue,positive,positive,positive,positive,positive,positive
756042633,"@gleec14 Looks good but I just remembered that I think the reason why we have absolute links is due to the PyPI README.md.
https://pypi.org/project/syft/
Are you able to find out if thats the case?",good think reason absolute link due able find thats case,issue,negative,positive,positive,positive,positive,positive
755243382,"`1.4.0` support is here: https://github.com/OpenMined/PySyft/tree/0.4

As we need this for the moment for some internal use cases we will keep `1.4.0` in CI for Ubuntu and Python 3.7. The other OSes and Python versions should mostly work. Hopefully we can deprecate this in the coming months.",support need moment internal use keep python python mostly work hopefully deprecate coming,issue,positive,positive,positive,positive,positive,positive
755097769,"@madhavajay I would like to point out, that I am installing PySyft 0.3 after freshly installing Anaconda (after a laptop crash).
Am I missing something apart from the installation steps mentioned in the Guide.

I have installed Ananconda and run the below commands only to install Pysyft, and I am getting the ModuleNotFound error for importing PySyft.

How to Reproduce
$ conda create -n pysyft python=3.8
$ conda activate pysyft
$ conda install jupyter notebook
$ pip install syft
$ jupyter notebook",would like point freshly anaconda crash missing something apart installation guide run install getting error reproduce create activate install notebook pip install notebook,issue,negative,positive,neutral,neutral,positive,positive
755096510,"@madhavajay I had assigned this issue to myself as I was working on Federated Learning and Split Learning using PySyft 0.2 from Nov onwards. I was just completing my training of a Split Learning network on VGG19 using PySyft, when my Laptop had crashed. After getting my Laptop fixed, when I freshly tried to install PySyft 0.3 on my laptop from scratch I got the error that I raised in issue https://github.com/OpenMined/PySyft/issues/4986.

I would request to be given some more time so that I can complete the installation successfully and raise a PR for this issue as soon as possible.",assigned issue working learning split learning onwards training split learning network getting fixed freshly tried install scratch got error raised issue would request given time complete installation successfully raise issue soon possible,issue,negative,positive,positive,positive,positive,positive
755061167,"hey @tudorcebere, can you help me to get started with this issue?
",hey help get issue,issue,negative,neutral,neutral,neutral,neutral,neutral
754431731,"This is getting annoying. Windows CI will fail randomly every now and then because of this issue probably due to a race condition.

<img width=""712"" alt=""Screen Shot 2021-01-05 at 4 31 31 pm"" src=""https://user-images.githubusercontent.com/2882739/103614105-94ba4200-4f73-11eb-9691-2ef6deaefeb4.png"">
",getting annoying fail randomly every issue probably due race condition screen shot,issue,negative,negative,negative,negative,negative,negative
754415505,"> @kishansairam9 Please find attached
> [PySyftEnv.txt](https://github.com/OpenMined/PySyft/files/5765981/PySyftEnv.txt)

Also, doesn't this file imply that conda has not installed pysyft. Don't you need to tell conda to install it not pip? I don't use conda so I can't comment.

```
(pysyft4) C:\Users\dell>conda env export
name: pysyft4
channels:
  - defaults
dependencies:
  - ca-certificates=2020.12.8=haa95532_0
  - certifi=2020.12.5=py38haa95532_0
  - openssl=1.1.1i=h2bbff1b_0
  - pip=20.3.3=py38haa95532_0
  - python=3.8.5=h5fd99cc_1
  - setuptools=51.0.0=py38haa95532_2
  - sqlite=3.33.0=h2a8f88b_0
  - vc=14.2=h21ff451_1
  - vs2015_runtime=14.27.29016=h5e58377_2
  - wheel=0.36.2=pyhd3eb1b0_0
  - wincertstore=0.2=py38_0
  - zlib=1.2.11=h62dcd97_4
prefix: C:\Users\dell\AppData\Local\conda\conda\envs\pysyft4
```",please find attached also file imply need tell install pip use ca comment export name prefix,issue,negative,neutral,neutral,neutral,neutral,neutral
754414785,"@AbhishekPokala Thanks for the PR. Sorry about the duplicate work but we had to start because there this PR was not available to work from when we had to make the decision to re-add `1.4.0`. However part of the reason why I prioritised this work was that you had shown interest in 1.4.0 support so the effort was not wasted. I think we will go with this one for now because it has a few more changes: https://github.com/OpenMined/PySyft/pull/4982

I will let you know as soon as its merged in so you can test it on Arm.

",thanks sorry duplicate work start available work make decision however part reason work shown interest support effort wasted think go one let know soon test arm,issue,positive,negative,neutral,neutral,negative,negative
754412752,@rajatrc1705 what is the issue with `pre_commit.sh`? It would be great to know so we can fix it.,issue would great know fix,issue,positive,positive,positive,positive,positive,positive
754411660,@rajatrc1705 Please make sure to post some PR progress otherwise the task might be taken by someone else.,please make sure post progress otherwise task might taken someone else,issue,positive,positive,positive,positive,positive,positive
754409393,"That should probably be a relative path to CONTRIBUTING.md, opening a PR would be appreciated.",probably relative path opening would,issue,negative,neutral,neutral,neutral,neutral,neutral
754407280,"It could be that the jupyter instance you are running is not mapped to the same virtualenv environment site packages that you are installing pysyft to. Can you try this:
```
$ conda create -n pysyft python=3.8
$ conda activate pysyft
$ pip install syft
$ which python3
$ python3
>>> import syft as sy
>>> sy.__version__
```",could instance running environment site try create activate pip install python python import,issue,negative,neutral,neutral,neutral,neutral,neutral
754184165,You might be interested in checking my latest bit: https://github.com/toshas/torch-householder,might interested latest bit,issue,negative,positive,positive,positive,positive,positive
754170260,"@kishansairam9 Neither of the commands have been able to fix the error.
I had suspected the same that pysyft had not been installed, hence I had tried uninstalling and installing it multiple times.

On Uninstalling (pip uninstall pysyft), I get the bellow confirmation of uninstallation:

(pysyft4) C:\Users\dell>pip uninstall syft
Found existing installation: syft 0.3.0
Uninstalling syft-0.3.0:
  Would remove:
    c:\users\dell\appdata\local\conda\conda\envs\pysyft4\lib\site-packages\syft-0.3.0.dist-info\*
    c:\users\dell\appdata\local\conda\conda\envs\pysyft4\lib\site-packages\syft\*
    c:\users\dell\appdata\local\conda\conda\envs\pysyft4\scripts\syft-device.exe
    c:\users\dell\appdata\local\conda\conda\envs\pysyft4\scripts\syft-domain.exe
    c:\users\dell\appdata\local\conda\conda\envs\pysyft4\scripts\syft-network.exe
    c:\users\dell\appdata\local\conda\conda\envs\pysyft4\scripts\syft-proto.exe
Proceed (y/n)?

And again on installing with the command _python3 -m pip install syft_ and importing syft in Jupyter notebook, i get the same Module Not found Error!

Also executing the command !pip install syft in Jupyter Notebook has Not helped!",neither able fix error suspected hence tried multiple time pip get bellow confirmation pip found installation would remove proceed command pip install notebook get module found error also command pip install notebook,issue,negative,positive,positive,positive,positive,positive
754124544,"I am unable to run pre_commit.sh on my machine, so there might be some linting problems.
Also, I would like to know how I can edit the 'syft-network' binary file, this is how my 'syft-network' binary file looks after editing in my local machine:
![image](https://user-images.githubusercontent.com/52173002/103564522-ae607880-4ee4-11eb-816b-057a7d8b96c9.png)
Once these changes are implemented, then the PR is complete. ",unable run machine might also would like know edit binary file binary file local machine image complete,issue,negative,negative,negative,negative,negative,negative
754111021,"@sbasu26 As you can observe from the output, pysyft hasn't been installed in this environment
This might have occurred due to ""pip"" referring to different executable on Windows when you ran install command.
Please try running `python3 -m pip install syft`, this might fix your issue

Alternatively, you can run this `!pip install syft` in the jupyter notebook where you faced an error. This should fix it. ",observe output environment might due pip different executable ran install command please try running python pip install might fix issue alternatively run pip install notebook faced error fix,issue,negative,negative,neutral,neutral,negative,negative
753991398,"Hi @sbasu26 @Abhishek-1Bhatt ,
I tried to reproduce the issue, but was unable to. There seems to be no error.
Can you attach the output of `conda env export` run in your environment?
",hi tried reproduce issue unable error attach output export run environment,issue,negative,negative,negative,negative,negative,negative
753953235,"@gmuraru 
If this code is going to be removed, it doesn't seem necessary to merge. I will close this PR. 😄 ",code going removed seem necessary merge close,issue,negative,neutral,neutral,neutral,neutral,neutral
753517410,"Got an initial implementation here
https://github.com/OpenMined/PySyft/pull/4911/commits

On Sat, 2 Jan 2021, 19:03 Adam J Hall, <notifications@github.com> wrote:

> @wip-abramson <https://github.com/wip-abramson> you've got the solution
> now right?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/4844#issuecomment-753516271>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AEJX7SFKZRBJTLNDCDVB5HLSX5UYNANCNFSM4UAPXG7Q>
> .
>
",got initial implementation sat hall wrote got solution right reply directly view,issue,negative,positive,positive,positive,positive,positive
752832388,This is awesome work @ViveK-PothinA thank you so much. ❤️,awesome work thank much,issue,positive,positive,positive,positive,positive,positive
752828002,@NProkoptsev we have a related issue which might make more sense: https://github.com/OpenMined/PySyft/issues/4854,related issue might make sense,issue,negative,neutral,neutral,neutral,neutral,neutral
752826637,@sbasu26 I haven't seen any PR's so i'm clearing the assignment and will leave it until someone can submit a PR. Please note we have our own internal roadmaps so if something needs doing and there is no PR we reserve the right to just do it ourselves. In the interest of making sure your work is not wasted effort `ALWAYS` provide a `Draft PR` ASAP so that we can see if the solution is heading in the right direction and even help collaborate with you to get it merged. If you wait too long to push and open a PR the issue may be done by someone else first.,seen clearing assignment leave someone submit please note internal something need reserve right interest making sure work wasted effort always provide draft see solution heading right direction even help collaborate get wait long push open issue may done someone else first,issue,positive,positive,positive,positive,positive,positive
752826144,"@NProkoptsev totally understand, we battled with that for a while but since the `is` comparison relates to the actual memory address and `None` is a singleton it's impossible to provide `SyNone is None`. The recursive `upcasting` and `downcasting` on both sides can be done but we will need to go through the code and just double check we aren't relying on the current functionality. If you have already had this issue with a particular bit of code, I would be interested in seeing an example.",totally understand battled since comparison actual memory address none singleton impossible provide none recursive side done need go code double check current functionality already issue particular bit code would interested seeing example,issue,negative,negative,neutral,neutral,negative,negative
752825593,"@beichen777 no worries, we are working on `1.7.1` so as soon as it passes CI we will merge it in and you can upgrade. 👍🏼 ",working soon merge upgrade,issue,negative,neutral,neutral,neutral,neutral,neutral
752825227,"> @lk1983823 The error says it can't load github to resolve the OpenGrid URLS, are you able to visit this URL: https://raw.githubusercontent.com/OpenMined/OpenGridNodes/master/network_address

Yes. It shows: 
[""http://ec2-18-216-8-163.us-east-2.compute.amazonaws.com:5000"",
 ""http://ec2-3-22-236-160.us-east-2.compute.amazonaws.com:5000"",
 ""http://ec2-18-221-100-52.us-east-2.compute.amazonaws.com:5000""]",error ca load resolve able visit yes,issue,negative,positive,positive,positive,positive,positive
752824247,"@lk1983823 The error says it can't load github to resolve the OpenGrid URLS, are you able to visit this URL: https://raw.githubusercontent.com/OpenMined/OpenGridNodes/master/network_address",error ca load resolve able visit,issue,negative,positive,positive,positive,positive,positive
752799721,"This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",issue marked stale open day activity leave comment remove stale label otherwise closed day,issue,negative,negative,negative,negative,negative,negative
752799684,"This pull request has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.",pull request marked stale open day activity leave comment remove stale label otherwise closed day,issue,negative,negative,negative,negative,negative,negative
752633775,"Thank you very much, I will change the torch version and try again.  keep in touch! @madhavajay ^_^",thank much change torch version try keep touch,issue,negative,positive,positive,positive,positive,positive
752404219,"The main problem is that
`lib.python.util.downcast(None) is None` returns `False`, so some functions may not work correctly",main problem none none false may work correctly,issue,negative,negative,negative,negative,negative,negative
752331748,"@agnim25 awesome work, I couldn't push to your fork because the PR wasn't from a new branch, so I made some changes here and its now merged: https://github.com/OpenMined/PySyft/pull/4966/",awesome work could push fork new branch made,issue,positive,positive,positive,positive,positive,positive
752290655,@NProkoptsev There is some asymmetry in upcasting and downcasting at the moment because `generate_primitive` doesn't pass through anything non primitives but instead terminates in a SyNone. Do you have an example of this actually causing an issue yet?,asymmetry moment pas anything non instead example actually causing issue yet,issue,negative,neutral,neutral,neutral,neutral,neutral
751952694,"@agnim25 Awesome work. It looks like theres just a few small issues.
```
-        run: |   
-	  &""/scripts/pytorch_install.ps1 ${{ matrix.torch-version }}""
+        run: |
+          &""/scripts/pytorch_install.ps1 ${{ matrix.torch-version }}""
-        run: |   
-	  ./scripts/pytorch_install.sh ${{ matrix.torch-version }}
+        run: |
+          ./scripts/pytorch_install.sh ${{ matrix.torch-version }}
```

And in the bash script and extra `fi`
```
- fi;
```

I can't push to your PR because you didn't create a branch off dev. If you can make these changes or move this PR to a branch and make sure to tick ""allow maintainers to make changes"" then I can fix it for you.",awesome work like there small run run run run bash script extra fi fi ca push create branch dev make move branch make sure tick allow make fix,issue,positive,positive,positive,positive,positive,positive
751933732,"@NiWaRe This is awesome! 👍🏼 

Do you think this would be even better if we supported `torch.device` properly then just added that to the tensor protobuf as well?
```
>>> torch.randn((2,3), device=torch.device('cuda:1'))
>>> torch.device(1)
device(type='cuda', index=1)
```

That way we can support the optional ordinal of the cuda device as well, and easily expand to other device types if they get added in future.

All we need is to add a protobuf wrapper and then set it onto the real torch.device class like so:
```
# syft/lib/torch/__init__.py
from . import parameter  # noqa: 401
from . import uppercase_tensor  # noqa: 401
from . import device  # noqa: 401  < ---- add this
```

```
# hypothetical device.py
aggressive_set_attr(
    obj=device_type, name=""serializable_wrapper_type"", attr=DeviceWrapper
)

```",awesome think would even better properly added tensor well device way support optional ordinal device well easily expand device get added future need add wrapper set onto real class like import parameter import import device add hypothetical,issue,positive,positive,positive,positive,positive,positive
751906286,"Some ops are simply not added or tested yet across all torch versions, however we can still add any of the new ones for `1.7.1`. ",simply added tested yet across torch however still add new,issue,negative,positive,neutral,neutral,positive,positive
751903821,"@beichen777 `torch.1.7.1` is not supported yet, but we will be adding it very shortly. My guess is that some of the rules we have set to explicitly run certain tests on certain torch versions is passing through which is intended behavior to prevent us from accidentally thinking that a new torch version is fully supported without explicitly checking and testing all op changes etc.",torch yet shortly guess set explicitly run certain certain torch passing intended behavior prevent u accidentally thinking new torch version fully without explicitly testing,issue,negative,positive,positive,positive,positive,positive
751903285,"@rondey No worries, I am sure we will get to very soon, but we just have a few priorities of our own as well. 😊 Good luck with the paper and thanks for using PySyft in the implementation. ❤️",sure get soon well good luck paper thanks implementation,issue,positive,positive,positive,positive,positive,positive
751632872,"@madhavajay, as I have seen `torch.imag`, is missing in  1.7.0 so can I add this in 1.7.1
I am asking because I am a little bit confused and how to write the test in allowlist_test.json",seen missing add little bit confused write test,issue,negative,negative,negative,negative,negative,negative
751538240,"@naveenggmu Hi Naveen, I could not test on 0.3.x as you know the releases 0.3.x do not support all the privacy-preserving techniques that 0.2.x used to support, for me I am using PySyft for Federated Learning. ",hi could test know support used support learning,issue,positive,neutral,neutral,neutral,neutral,neutral
751494778,is this issue fixed in 0.3.x? @Hjeljeli. Currently stuck with this bug in 0.2.9 :(.,issue fixed currently stuck bug,issue,negative,positive,neutral,neutral,positive,positive
751379854,"@madhavajay made pull request #4954, hoping you could take a look?",made pull request could take look,issue,negative,neutral,neutral,neutral,neutral,neutral
751194055,"I want to work on this, can you assignee me to this issue?",want work assignee issue,issue,negative,neutral,neutral,neutral,neutral,neutral
751149555,"> 
> 
> @beichen777 are you able to report what version of torch you are using since those are torch tests?

torch 1.7.1",able report version torch since torch torch,issue,negative,positive,positive,positive,positive,positive
750921647,"I like the idea, but actually I have a paper to complete (I'm using PySyft for the implementation).",like idea actually paper complete implementation,issue,negative,positive,neutral,neutral,positive,positive
750710972,"ok thanks

On Thu, Dec 24, 2020 at 7:55 AM Madhava Jay <notifications@github.com>
wrote:

> The lint checker failed, I have pushed a fix.
> Please read the section in the CONTRIBUTING.md on code quality:
> https://github.com/OpenMined/PySyft/blob/dev/CONTRIBUTING.md#code-quality
>
> I highly recommend you run the scripts/pre_commit.sh before committing
> and pushing and to install the pre-commit hooks.
>
> Also regarding the allowlist changes:
> Those methods are already in 1.7.0.
>
> [image: Screen Shot 2020-12-24 at 12 22 10 pm]
> <https://user-images.githubusercontent.com/2882739/103051595-f62cf900-45e2-11eb-8f5f-3f3c092ea17e.png>
>
> [image: Screen Shot 2020-12-24 at 12 22 15 pm]
> <https://user-images.githubusercontent.com/2882739/103051591-f3ca9f00-45e2-11eb-9927-f3a0247a4ae4.png>
>
> We only want the new 1.7.1 methods since 1.7.0 to be included (if there
> are any, there might not be), plus any tests to be added in
> allowlist_test.json.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/pull/4940#issuecomment-750708856>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AMPIV6SRJNG5W76DM5HCBMDSWKRCDANCNFSM4VHCWHKQ>
> .
>
",thanks jay wrote lint checker fix please read section code quality highly recommend run pushing install also regarding already image screen shot image screen shot want new since included might plus added thread reply directly view,issue,positive,positive,positive,positive,positive,positive
750708856,"The lint checker failed, I have pushed a fix.
Please read the section in the CONTRIBUTING.md on code quality: https://github.com/OpenMined/PySyft/blob/dev/CONTRIBUTING.md#code-quality

I highly recommend you run the `scripts/pre_commit.sh` before committing and pushing and to install the pre-commit hooks.

Also regarding the allowlist changes:
Those methods are already in 1.7.0.

<img width=""338"" alt=""Screen Shot 2020-12-24 at 12 22 10 pm"" src=""https://user-images.githubusercontent.com/2882739/103051595-f62cf900-45e2-11eb-8f5f-3f3c092ea17e.png"">

<img width=""333"" alt=""Screen Shot 2020-12-24 at 12 22 15 pm"" src=""https://user-images.githubusercontent.com/2882739/103051591-f3ca9f00-45e2-11eb-9927-f3a0247a4ae4.png"">

We only want the new 1.7.1 methods since 1.7.0 to be included (if there are any, there might not be), plus any tests to be added in `allowlist_test.json`.",lint checker fix please read section code quality highly recommend run pushing install also regarding already screen shot screen shot want new since included might plus added,issue,positive,positive,positive,positive,positive,positive
750525265,I'll keep working in the `core/io` directory and make the overall coverage to be around 90% at least (but in other PRs if that's ok) :smile: ,keep working directory make overall coverage around least smile,issue,negative,neutral,neutral,neutral,neutral,neutral
750504858,"This is excellent work @nahuakang the code looks nice and clean, the coverage is improved and it passes all the lint checks! ❤️",excellent work code nice clean coverage lint,issue,positive,positive,positive,positive,positive,positive
750095285,"Possible changes: 

- In serialization by default shift on CPU and in deserialization only check for CUDA. 
- In serialization, an extra feature could be implemented which allows the sender to specify CUDA even if he/she doesn't have CUDA him/herself. 

Also, I still have to think about testing. ",possible serialization default shift check serialization extra feature could sender specify even also still think testing,issue,negative,neutral,neutral,neutral,neutral,neutral
749867932,"Ok, I will do that.

On Wed, Dec 23, 2020, 5:10 AM Madhava Jay <notifications@github.com> wrote:

> @devil-cyber <https://github.com/devil-cyber> That is correct. If you can
> submit a PR with your progress I can give you feedback. 👍🏼
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/4906#issuecomment-749837595>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AMPIV6T5JYXUPYW2HW6VIRLSWEU67ANCNFSM4UZDRHNA>
> .
>
",wed jay wrote correct submit progress give feedback reply directly view,issue,negative,positive,neutral,neutral,positive,positive
749838296,@beichen777 are you able to report what version of torch you are using since those are torch tests?,able report version torch since torch,issue,negative,positive,positive,positive,positive,positive
749837595,@devil-cyber That is correct. If you can submit a PR with your progress I can give you feedback. 👍🏼 ,correct submit progress give feedback,issue,negative,neutral,neutral,neutral,neutral,neutral
749251771,"> @simcof Please use this: https://allcontributors.org/
> @madhavajay Please remove the stale issue labeler.

Thats really awesome @cereallarceny I rekon we should add that for sure, but does it also cover things like Organisational contribution / sponsorship credits? I think for this ticket we just need to know what other orgs to give shout-outs 📣 to since the last version README.md.",please use please remove stale issue labeler thats really awesome add sure also cover like contribution sponsorship think ticket need know give megaphone since last version,issue,positive,positive,positive,positive,positive,positive
749250891,"@Nilanshrajput this ticket stands to remind us that when we do a refactor of the whole AST we need to include this functionality. Currently its working with a workaround you can see here:
https://github.com/OpenMined/PySyft/blob/e956be84e277babe26e10c0d683227e853d7dccd/src/syft/util.py#L143
https://github.com/OpenMined/PySyft/blob/7af672148afc4476e3344c4bce7225ed484c2d18/src/syft/ast/module.py#L37

I would say this task isn't actionable right now and is blocked by some other larger refactors.",ticket remind u whole ast need include functionality currently working see would say task actionable right blocked,issue,negative,positive,positive,positive,positive,positive
749250073,"Hi @JMLourier thats great! Any chance you can open a PR? That's our preferred way to collaborate as you can imagine copying and pasting code around Slack which is just overwhelmed with continual new posts isn't the best way to track a discussion about specific code. If you want some private DM conversation thats fine, but without some code to look it's going to be a lot harder to understand your questions.

https://github.com/OpenMined/PySyft/blob/dev/CONTRIBUTING.md",hi thats great chance open preferred way collaborate imagine pasting code around slack continual new best way track discussion specific code want private conversation thats fine without code look going lot harder understand,issue,positive,positive,positive,positive,positive,positive
749078899,"Hi @madhavajay, I fixed quite some simple issues around wrong docstring formating. For the remaining issues I would need some support. Shall I post the questions to the Slack channel or is there any other way of getting support? Many thanks!",hi fixed quite simple around wrong would need support shall post slack channel way getting support many thanks,issue,positive,positive,neutral,neutral,positive,positive
748995666,"@madhavajay  I would like to help, can you direct me to the location where I can see how current AST mapping works/created.",would like help direct location see current ast,issue,positive,positive,neutral,neutral,positive,positive
748918198,"@simcof Please use this: https://allcontributors.org/
@madhavajay Please remove the stale issue labeler.",please use please remove stale issue labeler,issue,positive,negative,negative,negative,negative,negative
748771401,"Thank you. Yes, I will make sure to keep you informed about my progress on this issue. ",thank yes make sure keep informed progress issue,issue,positive,positive,positive,positive,positive,positive
748748969,"@rajatrc1705 Your help would be greatly appreciated. I would do the following:
- Run the local network signaling server with:
```
$ syft-network
```
- Start jupyter notebooks and load up any example like MNIST or even a basic connection
- Connect via your local network server using the instructions here: https://github.com/OpenMined/PySyft/tree/master/examples/duet/#host-a-network
```
duet = sy.launch_duet(network_url=""http://127.0.0.1:5000"")
```

Then once its working, modify the script and the code to get it working over IPV6.

Please note however, people often offer to help with issues but never get around to submitting a PR, as such if there is no Draft PR showing some initial attempt after a week, then if someone else wants to take this issue I will have to reassign it. I hope you can understand. If you have any questions feel free to ping me on Slack.",help would greatly would following run local network server start load example like even basic connection connect via local network server duet working modify script code get working please note however people often offer help never get around draft showing initial attempt week someone else take issue reassign hope understand feel free ping slack,issue,positive,positive,positive,positive,positive,positive
748677144,"# [Codecov](https://codecov.io/gh/OpenMined/PySyft/pull/4815?src=pr&el=h1) Report
> Merging [#4815](https://codecov.io/gh/OpenMined/PySyft/pull/4815?src=pr&el=desc) (c57d9cc) into [syft_0.2.x](https://codecov.io/gh/OpenMined/PySyft/commit/7327653e824bcd362bfd8dfe561cc10f4ce6be4e?el=desc) (7327653) will **not change** coverage.
> The diff coverage is `100.00%`.

[![Impacted file tree graph](https://codecov.io/gh/OpenMined/PySyft/pull/4815/graphs/tree.svg?width=650&height=150&src=pr&token=W0kQS1vaXB)](https://codecov.io/gh/OpenMined/PySyft/pull/4815?src=pr&el=tree)

```diff
@@             Coverage Diff             @@
##           syft_0.2.x    #4815   +/-   ##
===========================================
  Coverage       94.98%   94.98%           
===========================================
  Files             206      206           
  Lines           21546    21546           
===========================================
  Hits            20466    20466           
  Misses           1080     1080           
```


| [Impacted Files](https://codecov.io/gh/OpenMined/PySyft/pull/4815?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [syft/frameworks/torch/mpc/fss.py](https://codecov.io/gh/OpenMined/PySyft/pull/4815/diff?src=pr&el=tree#diff-c3lmdC9mcmFtZXdvcmtzL3RvcmNoL21wYy9mc3MucHk=) | `89.16% <100.00%> (ø)` | |
| [syft/frameworks/torch/mpc/primitives.py](https://codecov.io/gh/OpenMined/PySyft/pull/4815/diff?src=pr&el=tree#diff-c3lmdC9mcmFtZXdvcmtzL3RvcmNoL21wYy9wcmltaXRpdmVzLnB5) | `85.91% <100.00%> (ø)` | |
| [test/torch/mpc/test\_crypto\_store.py](https://codecov.io/gh/OpenMined/PySyft/pull/4815/diff?src=pr&el=tree#diff-dGVzdC90b3JjaC9tcGMvdGVzdF9jcnlwdG9fc3RvcmUucHk=) | `100.00% <100.00%> (ø)` | |
| [test/torch/mpc/test\_fss.py](https://codecov.io/gh/OpenMined/PySyft/pull/4815/diff?src=pr&el=tree#diff-dGVzdC90b3JjaC9tcGMvdGVzdF9mc3MucHk=) | `100.00% <100.00%> (ø)` | |
",report change coverage coverage impacted file tree graph coverage coverage impacted coverage,issue,negative,neutral,neutral,neutral,neutral,neutral
748626215,"I would like to work on this issue. I have only recently started exploring PySyft so I may need some hint or help to get started.
Could you assign this to me?",would like work issue recently exploring may need hint help get could assign,issue,positive,neutral,neutral,neutral,neutral,neutral
748551106,We will need to get this updated prior to course launch. I'll work to resolve ASAP,need get prior course launch work resolve,issue,negative,neutral,neutral,neutral,neutral,neutral
748549083,"@replomancer Are you able to provide a reliable way to reproduce this so we can create a ticket and get it fixed?
My guess is that in some code paths the loop is being started and in others it's not (or a race condition). So perhaps the solution is just to explicitly start one at the top level of the syft library on first import so theres always one available?",able provide reliable way reproduce create ticket get fixed guess code loop race condition perhaps solution explicitly start one top level library first import there always one available,issue,positive,positive,positive,positive,positive,positive
748548333,"> @jph00 I'll consider that officially sanctioned 👍🏼 

@rondey I am a big FastAI fan myself but we don't have the bandwidth to start this right now while we are building support for all the other libraries needed to provide the PPML functionality you mentioned in the FastAI forum post. 😂. However if you are interested in opening an initial PR on this I can walk you through the process. ❤️",consider officially big fan start right building support provide functionality forum post however interested opening initial walk process,issue,positive,positive,positive,positive,positive,positive
748489967,"I am getting the `RunTimeError: Task got Future attached to a different loop` exception on Ubuntu.

I see this:
> ♫♫♫ > ...error getting a running event Loop... no running event loop
♫♫♫ > ...creating a new event loop...

on both sides (data owner and data scientist). I can also see ""CONNECTED"" on both sides. The data owner can later do stuff with duet e.g. send a tensor without errors, but the data scientist gets RunTimeErrors as above when evaluating `duet.store.pandas`


My system is Ubuntu 20.04. I'm building a virtual environment with python 3.8.5

edit: I do not see have this issue when I use jupyter notebooks.",getting task got future attached different loop exception see error getting running event loop running event loop new event loop side data owner data scientist also see connected side data owner later stuff duet send tensor without data scientist system building virtual environment python edit see issue use,issue,negative,positive,neutral,neutral,positive,positive
748420368,"@madhavajay Based on discussions on slack, we decided to display the  solicitation message on import of library as pip natively doesn't support this feature yet (see https://github.com/pypa/pip/issues/5970 )

I made a PR here: https://github.com/OpenMined/PySyft/pull/4930",based slack decided display solicitation message import library pip natively support feature yet see made,issue,negative,neutral,neutral,neutral,neutral,neutral
748404213,"Looking forward to seeing how you get along with this! :D
",looking forward seeing get along,issue,negative,neutral,neutral,neutral,neutral,neutral
748008501,"@madhavajay Thank you so much, I have created [a new post](https://forums.fast.ai/t/fast-ai-support-for-ml-privacy-preserving-using-pysyft/83607) on the FastAI forum.",thank much new post forum,issue,negative,positive,positive,positive,positive,positive
747863934,@rondey I would also highly recommend posting this on the FastAI Discord / Forums as well and see if @jph00 is potentially interested in giving it some official sanctioning.,would also highly recommend posting discord well see potentially interested giving official,issue,positive,positive,positive,positive,positive,positive
747862691,It totally could be possible. I know a few people from the FastAI Audio group who might be interested in helping. @rbracco ?,totally could possible know people audio group might interested helping,issue,positive,positive,neutral,neutral,positive,positive
747861364,"I would do something like `conv2d` first:
```
allowlist[""torch.nn.Conv2d""] = ""torch.nn.Conv2d""
allowlist[""torch.nn.Conv2d.__call__""] = ""torch.Tensor""
allowlist[""torch.nn.Conv2d.parameters""] = ""syft.lib.python.List""
allowlist[""torch.nn.Conv2d.train""] = ""torch.nn.Conv2d""
allowlist[""torch.nn.Conv2d.cuda""] = ""torch.nn.Conv2d""
allowlist[""torch.nn.Conv2d.cpu""] = ""torch.nn.Conv2d""
allowlist[""torch.nn.Conv2d.state_dict""] = ""syft.lib.python.collections.OrderedDict""
allowlist[
    ""torch.nn.Conv2d.load_state_dict""
] = ""syft.lib.python._SyNone""  # torch.nn.modules.module._IncompatibleKeys
allowlist[""torch.nn.Conv2d.extra_repr""] = ""syft.lib.python.String""
```

If those are tested then we can easily update that code to do nearly all the same for all the other layer modules.
Also we arent trying to prove correctness, we are just trying to make sure that when you call the functions with a a variety of valid input types (mostly tensors of all the different dtypes) that it works and the result is of the expected type and that the result on the remote version is the same as the result we get running it locally. Check the `allowlist_tests.py` to see what i mean. Also it will probably be easier to make a new allowlist_tests file like say `allowlist_module_tests.py` since allowlist_tests is very geared towards the tensors.",would something like first tested easily update code nearly layer also arent trying prove correctness trying make sure call variety valid input mostly different work result type result remote version result get running locally check see mean also probably easier make new file like say since geared towards,issue,positive,positive,positive,positive,positive,positive
747641002,I'll make the Draft PR and let you know. I got the sense of what is to be done. Just the question of where do I start as `allowlist.py` contains a pretty long dict. ,make draft let know got sense done question start pretty long,issue,negative,positive,neutral,neutral,positive,positive
747612955,"# [Codecov](https://codecov.io/gh/OpenMined/PySyft/pull/4926?src=pr&el=h1) Report
> :exclamation: No coverage uploaded for pull request base (`syft_0.2.x@2dc64e6`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/OpenMined/PySyft/pull/4926/graphs/tree.svg?width=650&height=150&src=pr&token=W0kQS1vaXB)](https://codecov.io/gh/OpenMined/PySyft/pull/4926?src=pr&el=tree)

```diff
@@              Coverage Diff              @@
##             syft_0.2.x    #4926   +/-   ##
=============================================
  Coverage              ?   94.98%           
=============================================
  Files                 ?      206           
  Lines                 ?    21546           
  Branches              ?        0           
=============================================
  Hits                  ?    20466           
  Misses                ?     1080           
  Partials              ?        0           
```


",report exclamation coverage pull request base click learn coverage impacted file tree graph coverage coverage,issue,negative,negative,negative,negative,negative,negative
747599310,"There are these three other issues that also exist, I could take a look or, given that I already have another task, leave it for now. What do you think @LaRiffle @gmuraru? 

* Further possible tasks 
  1. add 'locations' property to additiveSharedModels (same as 'location' for normal remote models)
  2. suppress 'location' property in normal tensors 
  3. FixedPrecisionTensor.child has a location property (should only have if AdditiveSharedTensor as child)
",three also exist could take look given already another task leave think possible add property normal remote suppress property normal location property child,issue,negative,positive,neutral,neutral,positive,positive
747330830,"We can add some additional checks in this PR to make sure all these connection permutations are tested.
https://github.com/OpenMined/PySyft/pull/4889/files",add additional make sure connection tested,issue,negative,positive,positive,positive,positive,positive
747168941,"> I think it would be great if we went one step further and refactored the manual and loopback functions into a nice interface like this:
> 
> ```python
> import os
> from typing import Any as TypeAny
> from typing import Union as TypeUnion
> 
> class DuetCredentialExchanger:
>     def __init__(self, credential: TypeAny) -> None:
>         self.credential = credential
> 
>     def run(self) -> TypeAny:
>         raise NotImplementedError
> 
> 
> class OpenGridTokenManualInputExchanger(DuetCredentialExchanger):
>     # join=True is the Client and join=False is the Server
>     def __init__(self, credential: str, join: bool = False) -> None:
>         self.credential = credential
> 
>     def run(self) -> str:
>         ...
>     
> class OpenGridTokenFileExchanger(DuetCredentialExchanger)
>     def __init__(self, credential: str, join: bool = False, file_path: Union[str, os.PathLike]) -> None:
>         self.credential = credential
>         self.file_path = file_path
> 
>     def run(self) -> str:
>         ...
> ```

done in a new commit @madhavajay",think would great went one step manual nice interface like python import o import import union class self credential none credential run self raise class client server self credential join bool false none credential run self class self credential join bool false union none credential run self done new commit,issue,positive,positive,positive,positive,positive,positive
747093133,"I think it would be great if we went one step further and refactored the manual and loopback functions into a nice interface like this:
```python
import os
from typing import Any as TypeAny
from typing import Union as TypeUnion

class DuetCredentialExchanger:
    def __init__(self, credential: TypeAny) -> None:
        self.credential = credential

    def run(self) -> TypeAny:
        raise NotImplementedError


class OpenGridTokenManualInputExchanger(DuetCredentialExchanger):
    # join=True is the Client and join=False is the Server
    def __init__(self, credential: str, join: bool = False) -> None:
        self.credential = credential

    def run(self) -> str:
        ...
    
class OpenGridTokenFileExchanger(DuetCredentialExchanger)
    def __init__(self, credential: str, join: bool = False, file_path: Union[str, os.PathLike]) -> None:
        self.credential = credential
        self.file_path = file_path

    def run(self) -> str:
        ...


```",think would great went one step manual nice interface like python import o import import union class self credential none credential run self raise class client server self credential join bool false none credential run self class self credential join bool false union none credential run self,issue,positive,positive,positive,positive,positive,positive
747074381,"Hi @hershd23 that would be hugely appreciated.
Currently, this test file here:
https://github.com/OpenMined/PySyft/blob/dev/tests/syft/lib/allowlist_test.py

Tests all of the torch.Tensor ops listed in here:
https://github.com/OpenMined/PySyft/blob/dev/src/syft/lib/torch/allowlist.py

These ones:
```
allowlist[""torch.Tensor""] = ""torch.Tensor""
allowlist[""torch.Tensor.xxxxxx""] = ""torch.Tensor""
...
```

What this ticket is about, is adding a similar testing suite for all of the other entries in that file, like say conv2d:
```
allowlist[""torch.nn.Conv2d""] = ""torch.nn.Conv2d""
allowlist[""torch.nn.Conv2d.__call__""] = ""torch.Tensor""
allowlist[""torch.nn.Conv2d.parameters""] = ""syft.lib.python.List""
allowlist[""torch.nn.Conv2d.train""] = ""torch.nn.Conv2d""
allowlist[""torch.nn.Conv2d.cuda""] = ""torch.nn.Conv2d""
allowlist[""torch.nn.Conv2d.cpu""] = ""torch.nn.Conv2d""
allowlist[""torch.nn.Conv2d.state_dict""] = ""syft.lib.python.collections.OrderedDict""
allowlist[
    ""torch.nn.Conv2d.load_state_dict""
] = ""syft.lib.python._SyNone""  # torch.nn.modules.module._IncompatibleKeys
allowlist[""torch.nn.Conv2d.extra_repr""] = ""syft.lib.python.String""
```

Since the layers and modules nearly always have the exact same methods and return types we should be able to write code a bit like the allowlist_tests for Tensors which can loop through all of these and test them. There will be some unexpected issues for example the inputs to some types vary, like LSTMs and therefore so does their return types for .__call__ forward pass and thats exactly why we want to test them and make sure the return types are labelled correctly. If the return type is wrong the user can't use it properly because the synthetic pointer won't match.

If you create a Draft PR and get started I can keep an eye on it and show you how to keep going. 👍🏼 ",hi would hugely currently test file listed ticket similar testing suite file like say since nearly always exact return able write code bit like loop test unexpected example vary like therefore return forward pas thats exactly want test make sure return correctly return type wrong user ca use properly synthetic pointer wo match create draft get keep eye show keep going,issue,positive,positive,positive,positive,positive,positive
746936454,@madhavajay is any help needed on the issue? If so let me know how to get started,help issue let know get,issue,negative,neutral,neutral,neutral,neutral,neutral
745910402,"I am new to this repo, I want to begin the contribution from this issue, is there any adivces?",new want begin contribution issue,issue,negative,positive,positive,positive,positive,positive
745452283,"Ok apparently this is because we have an old version of jupyter notebook!
`pip install --upgrade notebook`  should fix this!",apparently old version notebook pip install upgrade notebook fix,issue,negative,positive,neutral,neutral,positive,positive
745442452,"Same problem for me when running https://github.com/OpenMined/PySyft/tree/dev/examples/duet/mnist
- mac OS 11.0.1
- Python 3.7",problem running mac o python,issue,negative,neutral,neutral,neutral,neutral,neutral
745044425,@chinmayshah99 Excellent work! 🙌❤️ I just quickly ported in the Carrots Demo and cleaned up a few things and I would say this has met the goals of the initial deadline date so 🎉.,excellent work quickly ported would say met initial deadline date,issue,positive,positive,positive,positive,positive,positive
744555934,"Hi,
    Just in case for anyone in the same situation, this is fixed with PyGrid workers.(not supporting PySyft-0.3.0 for now)
    You can check [this slack posting](https://openmined.slack.com/archives/C6EEFN3A8/p1596720041221900?thread_ts=1596661549.217900&cid=C6EEFN3A8) for an example to setup PyGrid workers and then move() should work.

Thanks,",hi case anyone situation fixed supporting check slack posting example setup move work thanks,issue,positive,positive,positive,positive,positive,positive
744378749,"Hi there -- I ended up using a different framework (https://github.com/adap/flower) to implement this, so I won't be working on this issue. Feel free to close this issue, but also feel free to keep it open for other contributors.",hi ended different framework implement wo working issue feel free close issue also feel free keep open,issue,positive,positive,positive,positive,positive,positive
744217687,"Hey @madhavajay for PyTorch 1.7.1 we have to add all API functionality 
as well as we have to update the respective torch vision in the YML file.
 Am I in the right direction?
",hey add functionality well update respective torch vision file right direction,issue,positive,positive,positive,positive,positive,positive
744155607,"Ok thanks i will start my work

On Mon, Dec 14, 2020, 6:04 AM Madhava Jay <notifications@github.com> wrote:

> @devil-cyber <https://github.com/devil-cyber>, take a look at the merge
> and pr tests.yml files for GitHub Actions.
> Then go see the src/syft/lib/torch/allowlist.py:
>
> allowlist[""torch.Tensor.amax""] = {
>     ""return_type"": ""torch.Tensor"",
>     ""min_version"": ""1.7.0"",
> }
>
> What you need to do is import torch 1.7.1 and dir(torch) and dump the
> entire API or check the changelog and see if there are any new OPS we need
> to support, if there are you need to add them to the allowlist.py and
> then also add tests to the allowlist_test.json.
>
> If you can create a PR which shows some progress I will assign this to you.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/4906#issuecomment-744099616>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AMPIV6QKCHPMV2TOHA76QTDSUVMS5ANCNFSM4UZDRHNA>
> .
>
",thanks start work mon jay wrote take look merge go see need import torch torch dump entire check see new need support need add also add create progress assign reply directly view,issue,positive,positive,positive,positive,positive,positive
744099616,"@devil-cyber, take a look at the merge and pr tests.yml files for GitHub Actions.
Then go see the `src/syft/lib/torch/allowlist.py`:

```
allowlist[""torch.Tensor.amax""] = {
    ""return_type"": ""torch.Tensor"",
    ""min_version"": ""1.7.0"",
}
```

What you need to do is import torch 1.7.1 and `dir(torch)` and dump the entire API or check the changelog and see if there are any new OPS we need to support, if there are you need to add them to the `allowlist.py` and then also add tests to the `allowlist_test.json`.

If you can create a PR which shows some progress I will assign this to you.",take look merge go see need import torch torch dump entire check see new need support need add also add create progress assign,issue,positive,positive,neutral,neutral,positive,positive
744098597,"@jaintj95, this looks like its converting UTF-8 into cp1252 on windows and failing. Are you able to find the exact char sequence which fails and dump it do we can turn this into a test for all platforms and fix the issue?",like converting failing able find exact char sequence dump turn test fix issue,issue,negative,positive,positive,positive,positive,positive
744097828,"@jaintj95. Good spot, this is most likely in the dev branch which is not 100% stable. We recently added a new __len__ getter mechanism for iterators, so this code will need to change but the API hasn't been fully worked out yet.

You can see in these cells that there is an automatically generated request in the background.
<img width=""1083"" alt=""Screen Shot 2020-12-14 at 10 25 41 am"" src=""https://user-images.githubusercontent.com/2882739/102028621-e4836e80-3df6-11eb-98c1-210e33f1d46d.png"">


<img width=""793"" alt=""Screen Shot 2020-12-14 at 10 26 00 am"" src=""https://user-images.githubusercontent.com/2882739/102028619-e0efe780-3df6-11eb-81b2-bd2397f9f2b2.png"">

I will make sure we get this example updated once we get the Iterators / Len stuff sorted.
",good spot likely dev branch stable recently added new getter mechanism code need change fully worked yet see automatically request background screen shot screen shot make sure get example get stuff sorted,issue,positive,positive,positive,positive,positive,positive
744091190,"@sbasu26 Sure, as you asked first I will assign it to you, but if you cannot work on it please report back quickly so that someone else can take it.",sure first assign work please report back quickly someone else take,issue,positive,positive,positive,positive,positive,positive
743952626,Forcing the merge due to possible issue with this code executing outside of the repo in a PR.,forcing merge due possible issue code outside,issue,negative,negative,neutral,neutral,negative,negative
743727061,"For Vanilla FL remote shifting to and from CUDA is supported (which has to be done before and after calling the secure aggregation function, a showcase should be added to the current secure aggregation tutorial), remaining problems will be fixed through #4899 #4898. 
Complete encrypted training will be locally possible with Sycret.",vanilla remote shifting done calling secure aggregation function showcase added current secure aggregation tutorial fixed complete training locally possible,issue,positive,positive,positive,positive,positive,positive
743709761,Can I also try and work on this issue.. I am just getting started but would like to work on this issue too.,also try work issue getting would like work issue,issue,negative,neutral,neutral,neutral,neutral,neutral
743246518,"Hi,

Please assign this issue to me.
I would like to work on this.

",hi please assign issue would like work,issue,positive,neutral,neutral,neutral,neutral,neutral
742925771,@jaintj95 We can add some Conda tests to our CI to see whats happening and make sure this isnt an issue. ,add see whats happening make sure issue,issue,negative,positive,positive,positive,positive,positive
742358210,"Torch 1.4.0 is installed in Conda base package but I created a separated conda environment for syft.

Steps:
```
$ conda create -n pysyft python=3.8
$ conda activate pysyft
$ conda install jupyter notebook
$ pip install syft
```
",torch base package environment create activate install notebook pip install,issue,negative,negative,negative,negative,negative,negative
742357943,"The issue arises due to conflicting dependencies of different versions for syft. 
As, @madhavajay suggested, you should consider using `virtualenvs` if you seek to work with multiple versions. Or consider uninstalling previous versions, if you currently don't have dependendents off them.
On a side note, we recent brought major changes in recent releases for pysyft(v0.3.x), and it is recommended to switch to current versions to recieve all the cool new changes. 🚀",issue due conflicting different consider seek work multiple consider previous currently side note recent brought major recent switch current cool new rocket,issue,negative,positive,neutral,neutral,positive,positive
742354162,"Hi @jaintj95, Do you have an existing installation of torch? Are you able to show some steps to re-produce your 3.8.x error?",hi installation torch able show error,issue,negative,positive,positive,positive,positive,positive
742347568,@ydennisy there are some other blockers preventing @AlanAboudib  from finishing this notebook. As soon as they are resolved we will get this notebook merged.,finishing notebook soon resolved get notebook,issue,negative,neutral,neutral,neutral,neutral,neutral
742340956,"Hey, I want to work on this issue, Can you assign me on this issue?",hey want work issue assign issue,issue,negative,neutral,neutral,neutral,neutral,neutral
742337825,"Hey, I am new to the open-source community and would to start contributing and Think of starting
 with this issue, can I start off this issue?
",hey new community would start think starting issue start issue,issue,negative,positive,neutral,neutral,positive,positive
742307050,"Unfortunately, PyTorch does not support Python 3.9 yet so we are unable to support it either.
I would suggest using a tool like pyenv so you can install multiple versions of Python 3 on MacOS now that brew is upgrading the current python 3 to 3.9.0.",unfortunately support python yet unable support either would suggest tool like install multiple python brew current python,issue,positive,negative,negative,negative,negative,negative
741916653,@jaintj95 Worked perfectly - thanks a lot! ,worked perfectly thanks lot,issue,positive,positive,positive,positive,positive,positive
741742894,"Facing the exact same issue on Windows 10.

@Wilann As a temporary resolution, you can try these steps.
1) pip install syft==0.3.0
2) If 1 fails, install pytorch
3) Try 1 again",facing exact issue temporary resolution try pip install install try,issue,negative,positive,positive,positive,positive,positive
739816132,"Well, at the end I did not know what was the problem. However, running the script un ubuntu has no problems, so I will doing in ubuntu",well end know problem however running script un,issue,negative,neutral,neutral,neutral,neutral,neutral
738504971,"Okay I try to find some other issues to work.

On Fri, 4 Dec 2020, 04:30 Madhava Jay, <notifications@github.com> wrote:

> Hi @sparkingdark <https://github.com/sparkingdark> the Slack is Public.
> Unfortunately I have no assigned this to @JMLourier
> <https://github.com/JMLourier> so if you want to help see if theres some
> way you can sub divide the work otherwise there are other tickets available.
> [image: Screen Shot 2020-12-04 at 8 58 33 am]
> <https://user-images.githubusercontent.com/2882739/101098585-e6874980-360e-11eb-84b4-d65b41a6bfd0.png>
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/4518#issuecomment-738422242>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AL7XHCDNTILKU27EQ35QEXDSTAKCLANCNFSM4QSE7POQ>
> .
>
",try find work jay wrote hi slack public unfortunately assigned want help see there way sub divide work otherwise available image screen shot reply directly view,issue,negative,positive,neutral,neutral,positive,positive
738452173,"> This is for static classes? or static methods?

We need both but they are different problems I guess, in this instance we need to enable the path to the static class without a constructor, so the issue is, allowing static functions on any level of the module / class hierarchy.

Here you can see an example of how the code in this PR fails:
<img width=""641"" alt=""Screen Shot 2020-12-04 at 9 34 17 am"" src=""https://user-images.githubusercontent.com/2882739/101101266-ed648b00-3613-11eb-9d39-05075b25c83c.png"">

We create a None and send back a correct Pointer which is fine, but if any other triggers the store to regenerate the pointer such as searching the store we will get a SyNone.

<img width=""664"" alt=""Screen Shot 2020-12-04 at 9 27 45 am"" src=""https://user-images.githubusercontent.com/2882739/101101167-b9896580-3613-11eb-9452-3d33bb244a93.png"">

<img width=""573"" alt=""Screen Shot 2020-12-04 at 9 28 12 am"" src=""https://user-images.githubusercontent.com/2882739/101101161-b5f5de80-3613-11eb-873d-775a88b99260.png"">
",static class static need different guess instance need enable path static class without constructor issue static level module class hierarchy see example code screen shot create none send back correct pointer fine store regenerate pointer searching store get screen shot screen shot,issue,negative,positive,positive,positive,positive,positive
738429928,@ElsaBroso1 Perhaps you can investigate and see if you can figure it out? We believe its something to do with the main process not having an asyncio event loop started under some scenarios so perhaps see if theres a way to ensure that the main event loop gets started when syft starts up?,perhaps investigate see figure believe something main process event loop perhaps see there way ensure main event loop,issue,negative,positive,positive,positive,positive,positive
738422242,"Hi @sparkingdark the Slack is Public. Unfortunately I have no assigned this to @JMLourier so if you want to help see if theres some way you can sub divide the work otherwise there are other tickets available.
<img width=""629"" alt=""Screen Shot 2020-12-04 at 8 58 33 am"" src=""https://user-images.githubusercontent.com/2882739/101098585-e6874980-360e-11eb-84b4-d65b41a6bfd0.png"">
",hi slack public unfortunately assigned want help see there way sub divide work otherwise available screen shot,issue,negative,negative,neutral,neutral,negative,negative
737767048,"@madhavajay can you send me the slack invite? 

Actually I got messed up and as well my college started so can't reply you but now I got some free time so can work.",send slack invite actually got well college ca reply got free time work,issue,positive,positive,positive,positive,positive,positive
737760539,@JMLourier Yes if you could I can assign it to you for now. @sparkingdark I didn't hear from you so ill just assign it to @JMLourier for now if thats okay.,yes could assign hear ill assign thats,issue,negative,negative,negative,negative,negative,negative
737753613,"Hi @madhavajay and @sparkingdark, do you need support on this issue? I'd like to contribute here.",hi need support issue like contribute,issue,positive,neutral,neutral,neutral,neutral,neutral
737345590,"Hi, when I start duet I have the message 
...waiting for partner to connect...
♫♫♫ > ...error getting a running event Loop... no running event loop
♫♫♫ > ...creating a new event loop...

And then, when with the data owner send the data, as soon as I make duet.store.pandas I have theRunTimeError: Task got Future <Future pending> attached to a different loop. How can I solve it?",hi start duet message waiting partner connect error getting running event loop running event loop new event loop data owner send data soon make task got future future pending attached different loop solve,issue,negative,positive,neutral,neutral,positive,positive
736574202,@madhavajay thanks for the reply and I was pretty busy with my college and assignments but now I am start working again the assigned issues.,thanks reply pretty busy college start working assigned,issue,positive,positive,positive,positive,positive,positive
736569971,"Okay I will inform you soon... @cereallarceny and btw I am not on slack,can you send me a invite",inform soon slack send invite,issue,negative,neutral,neutral,neutral,neutral,neutral
736551548,"I really like the idea of using Arrow in our store/serde. I'll add the 0.3.X tag and create an issue, I'd be really interested in working on this, mostly because I am curious about how Arrow works.

@madhavajay :eyes: ",really like idea arrow add tag create issue really interested working mostly curious arrow work,issue,positive,positive,positive,positive,positive,positive
736539601,"it's also valid for 0.3.X!
We could use pyarrow, which is dedicated to sending big object and comes together with a kind of network protocol called arrow flight
We have done a PoC of this for crypto purpose (in branches ryffel/ariaNN of Pysyft & PyGrid), it provides great speed-ups
",also valid could use sending big object come together kind network protocol arrow flight done purpose great,issue,positive,positive,positive,positive,positive,positive
736523574,"Hello @LaRiffle,

Is this related to 0.2.X or 0.3.X? We are rethinking a bit a part of the serde in the current 0.3.X. Do you have any example from such channel in other projects?",hello related bit part current example channel,issue,negative,neutral,neutral,neutral,neutral,neutral
735635724,@Harkirat155 Looks like you might still need to run black. I would suggest running the `scripts/pre_commit.sh`.,like might still need run black would suggest running,issue,negative,negative,negative,negative,negative,negative
735549036,Remaining tasks on this issue should be converted into new tickets for the future backlog.,issue converted new future backlog,issue,negative,positive,neutral,neutral,positive,positive
735013608,"@TryFL . The new 0.3.0 release no longer uses sy.TorchHook. Some updated documentation is here: https://github.com/OpenMined/PySyft/tree/dev/examples/duet
More to come shortly.

If you need to use 0.2.x it is still available on PyPI.",new release longer documentation come shortly need use still available,issue,negative,positive,positive,positive,positive,positive
734118956,"# [Codecov](https://codecov.io/gh/OpenMined/PySyft/pull/4859?src=pr&el=h1) Report
> :exclamation: No coverage uploaded for pull request base (`syft_0.2.x@1d865a8`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/OpenMined/PySyft/pull/4859/graphs/tree.svg?width=650&height=150&src=pr&token=W0kQS1vaXB)](https://codecov.io/gh/OpenMined/PySyft/pull/4859?src=pr&el=tree)

```diff
@@              Coverage Diff              @@
##             syft_0.2.x    #4859   +/-   ##
=============================================
  Coverage              ?   94.59%           
=============================================
  Files                 ?      209           
  Lines                 ?    22088           
  Branches              ?        0           
=============================================
  Hits                  ?    20895           
  Misses                ?     1193           
  Partials              ?        0           
```


",report exclamation coverage pull request base da click learn coverage impacted file tree graph coverage coverage,issue,negative,negative,negative,negative,negative,negative
734015175,"Hi @xutongye, the issue is due to the missing pytest-xdist package, which provides the `-n auto` option.
The package is in requirements.txt but is not in setup.cfg as an install_requires= dependency.

While it probably should be added to the testing= section of the setup.cfg from my understanding that won't install it using `pip install -e .` and we are using pytest directly to give a bit more control over how we run our tests.

Currently this is covered in the CONTRIBUTING during the `### Install Python Packages` step with both `pip` and `pipenv` instructions, but it should be made more clear that this is necessary for development dependencies in the `requirements.txt`. It's a pity there is no good standard here since both `poetry` and `pipenv` allow for dev dependencies but do not share a format. 😕

I will add it to setup.cfg testing= now just to make things a little more robust.",hi issue due missing package auto option package dependency probably added section understanding wo install pip install directly give bit control run currently covered install python step pip made clear necessary development pity good standard since poetry allow dev share format add make little robust,issue,positive,positive,neutral,neutral,positive,positive
734005720,"Hi @ayush12gupta Yes, sorry the Duet stuff is in the code but only referenced from the Duet README currently.
https://github.com/OpenMined/PySyft/tree/dev/examples/duet

This task is to create 2 notebooks for DCGAN the same way we have for MNIST.
You will see the MNIST notebooks in the README.md above and the DCGAN folder already created in examples.
However please be aware that it's entirely possible that all the functionality required to complete the DCGAN notebooks might not exist yet, but an initial attempt is a great way to figure out whats missing and all contributions are greatly appreciated.

If you have any questions feel free to jump into the Slack Channel. 😊",hi yes sorry duet stuff code duet currently task create way see folder already however please aware entirely possible functionality complete might exist yet initial attempt great way figure whats missing greatly feel free jump slack channel,issue,positive,positive,positive,positive,positive,positive
733910401,@madhavajay  I am new to this project I have gone through tutorials but didn't come across what are duets as I would like to contribute to this issue ,new project gone come across would like contribute issue,issue,negative,positive,positive,positive,positive,positive
733538501,"> LGTM, we'll be working on refactoring the Store API soon, but this brings a quality of life fix until then. One small linting error and you are good to go.

Sure, thanks.",working store soon quality life fix one small error good go sure thanks,issue,positive,positive,positive,positive,positive,positive
733538020,"> Hi @xutongye thank you so much for the quick fix and contribution. I apologise for the delay in responding we have been a little busy with the switch over. As @tudorcebere mentioned we have some refactors coming for this part of the code as it stands I don't think our code actually initialises StorableObject without it being from a subclass using the `construct_new_object` `staticmethod`. But this itself is not how we want it to be so we fully acknowledge this is confusing and ugly.
> 
> Regarding your patch. The only thing left to update is the linting errors.
> You can see them here:
> https://github.com/OpenMined/PySyft/pull/4827/checks?check_run_id=1441012237
> 
> ```
> mypy.....................................................................Failed
> - hook id: mypy
> - exit code: 1
> 
> src/syft/core/store/storeable_object.py:106: error: unused 'type: ignore' comment
> src/syft/core/store/storeable_object.py:111: error: unused 'type: ignore' comment
> src/syft/core/store/storeable_object.py:150: error: Left operand of 'and' is always true
> src/syft/core/store/storeable_object.py:157: error: Statement is unreachable
> Found 4 errors in 1 file (checked 204 source files)
> ```
> 
> We highly recommend contributors run the local checks before pushing so they know their code will pass the lint checks on CI.
> 
> I have an open PR which aims to fix the contribution guide to make this clearer:
> #4837
> 
> In this case the fix to mypy's complaints are a little more complex so I have provided what might be a workable solution via a .patch file:
> https://pastebin.com/THaT2zv0

Hi @madhavajay , thinks for pointing me to the new contributing guide, it helps a lot. 
I did not run pytest and pre-commit checks to my previous commits, so a lot of tests failed when I push new commits to PRs. So, according to your new contributing guide,  I reinstalled all these things. Feels good to pass all the checks. 
But there is one thing, I can run `pytest -m fast` well, but when I run `pytest -m fast -n auto`, error happened:
```python
ERROR: usage: pytest [options] [file_or_dir] [file_or_dir] [...]
pytest: error: unrecognized arguments: -n
  inifile: /mnt/d/github/PySyft/setup.cfg
  rootdir: /mnt/d/github/PySyft
```
Should I worry about this? Or can you please give some hints how to fix this?",hi thank much quick fix contribution delay little busy switch coming part code think code actually without subclass want fully acknowledge ugly regarding patch thing left update see hook id exit code error unused ignore comment error unused ignore comment error left operand always true error statement unreachable found file checked source highly recommend run local pushing know code pas lint open fix contribution guide make clearer case fix little complex provided might workable solution via file hi pointing new guide lot run previous lot push new according new guide good pas one thing run fast well run fast auto error python error usage error unrecognized worry please give fix,issue,negative,positive,neutral,neutral,positive,positive
733161109,"Hey all,

I think this PR made a bug that I noticed when using `some_tensor.send(client, searchable=True)`.  


`SaveObjectAction` instantiates VerifyAll, while this new method returns the class.   This new line will return false with a VerifyAll object, rather than class:

> `               contains_all_in_permissions = any(
>                     key is VerifyAll for key in obj.search_permissions.keys()
>                 )` 
",hey think made bug client new method class new line return false object rather class key key,issue,negative,negative,neutral,neutral,negative,negative
732702285,I think as soon as we have this in place with the new GitHub Benchmark system we should create a benchmark test for Serde / transport of tensors between Duet nodes and then rebase this PR and see what the difference is: https://github.com/OpenMined/PySyft/pull/4807,think soon place new system create test transport duet rebase see difference,issue,negative,positive,positive,positive,positive,positive
732683113,"@tudorcebere Awesome work!! I tested it by changing all the state_dict to OrderedDict and removed the previous hack and it all works.

Can you merge this PR in?: https://github.com/OpenMined/PySyft/tree/madhava/fix-4836",awesome work tested removed previous hack work merge,issue,positive,positive,positive,positive,positive,positive
732641827,"@tudorcebere this is really awesome work!! 👍 
I have added a PR here to your PR which enables this for multiple ops in the allowlist and fixes a small bug with the name cache which only revealed itself after adding more than 1 identical Union type.
https://github.com/OpenMined/PySyft/tree/madhava/4812-fix

I think this is ready to merge once that fix and the tests from my PR are added.",really awesome work added multiple small bug name cache revealed identical union type think ready merge fix added,issue,positive,positive,positive,positive,positive,positive
732516342,"Hi @xutongye thank you so much for the quick fix and contribution. I apologise for the delay in responding we have been a little busy with the switch over. As @tudorcebere mentioned we have some refactors coming for this part of the code as it stands I don't think our code actually initialises StorableObject without it being from a subclass using the `construct_new_object` `staticmethod`. But this itself is not how we want it to be so we fully acknowledge this is confusing and ugly.

Regarding your patch. The only thing left to update is the linting errors.
You can see them here:
https://github.com/OpenMined/PySyft/pull/4827/checks?check_run_id=1441012237
```
mypy.....................................................................Failed
- hook id: mypy
- exit code: 1

src/syft/core/store/storeable_object.py:106: error: unused 'type: ignore' comment
src/syft/core/store/storeable_object.py:111: error: unused 'type: ignore' comment
src/syft/core/store/storeable_object.py:150: error: Left operand of 'and' is always true
src/syft/core/store/storeable_object.py:157: error: Statement is unreachable
Found 4 errors in 1 file (checked 204 source files)
```

We highly recommend contributors run the local checks before pushing so they know their code will pass the lint checks on CI.

I have an open PR which aims to fix the contribution guide to make this clearer:
https://github.com/OpenMined/PySyft/pull/4837

In this case the fix to mypy's complaints are a little more complex so I have provided what might be a workable solution via a .patch file:
https://pastebin.com/THaT2zv0",hi thank much quick fix contribution delay little busy switch coming part code think code actually without subclass want fully acknowledge ugly regarding patch thing left update see hook id exit code error unused ignore comment error unused ignore comment error left operand always true error statement unreachable found file checked source highly recommend run local pushing know code pas lint open fix contribution guide make clearer case fix little complex provided might workable solution via file,issue,negative,negative,neutral,neutral,negative,negative
732508990,Hi @Zongshun96 unfortunately the code bases are completely unrelated and Syft 0.3.0 is a completely rewrite so that isn't really possible. We are working to bring full parity of functionality between 0.2.x to 0.3.x ASAP.,hi unfortunately code base completely unrelated completely rewrite really possible working bring full parity functionality,issue,negative,negative,negative,negative,negative,negative
732342084,"Hi,
The problem is that my code is based on v0.2.9 and I would Iike to take advantage of the view() and sum() from v0.3.0 while not modifying anything else.
So, is it possible to share which commit I can check for reference? So I can try to add them in the PySyft I am running on.

Thanks,
Zongshun",hi problem code based would take advantage view sum anything else possible share commit check reference try add running thanks,issue,positive,positive,neutral,neutral,positive,positive
732315293,"LGTM, we'll be working on refactoring the Store API soon, but this brings a quality of life fix until then. One small linting error and you are good to go.",working store soon quality life fix one small error good go,issue,negative,positive,positive,positive,positive,positive
732055433,"> @xutongye are you still working on this? :D

No, because you said we should throw an exception. But I can work on it if you like me to.",still working said throw exception work like,issue,negative,neutral,neutral,neutral,neutral,neutral
732031840,The tests are failing :( - I think you can try to rebase and see if it works.,failing think try rebase see work,issue,negative,neutral,neutral,neutral,neutral,neutral
732030953,@abogaziah could we close this since @PlamenHristov is taking up the private compare?,could close since taking private compare,issue,negative,neutral,neutral,neutral,neutral,neutral
732006783,"@tudorcebere im not sure what the status of this is, but I have updated it and added the new torch.return_types.* and the tests pass here: https://github.com/OpenMined/PySyft/tree/tudor/storable_fix",sure status added new pas,issue,negative,positive,positive,positive,positive,positive
731998355,"@madhavajay Cool, let me make the same change in the duet README as well.",cool let make change duet well,issue,positive,positive,positive,positive,positive,positive
731917523,"Hi @friendsAI the recent 0.3.x release is a complete rebuild of PySyft and as such there is no longer a torch hook. I apologise that this isn't 100% clear on the new documentation, and we have several tickets already created to address this. We are aware that the two releases are not identical in functionality however we have some very exciting things coming which are only possible with the new 0.3.x architecture so bear with us. Some of the new API is already documented on our Duet example README.md here: https://github.com/OpenMined/PySyft/tree/dev/examples/duet",hi recent release complete rebuild longer torch hook clear new documentation several already address aware two identical functionality however exciting coming possible new architecture bear u new already duet example,issue,positive,positive,positive,positive,positive,positive
731916387,"Hi @Zongshun96 the view method should be available in the master and dev branches and on the 0.3.0 release on PyPI. Here is a link to the line which enables the view method on Tensor.
https://github.com/OpenMined/PySyft/blob/65ba3ebe83eecc26528f1b451746ede7f6a43fc0/src/syft/lib/torch/allowlist.py#L481",hi view method available master dev release link line view method tensor,issue,negative,positive,positive,positive,positive,positive
731868741,"Hi,
    Can you mention how you add the view() method? Which commit should I check for reference?
Thanks,
Zongshun",hi mention add view method commit check reference thanks,issue,positive,positive,positive,positive,positive,positive
731511264,"Added the complete URL to README, should look good now.",added complete look good,issue,negative,positive,positive,positive,positive,positive
731009953,"> Closing! Unable to get output from the author.

 Hi @aanurraj, sorry that I didn't answer. I wasn't available the last weeks.  Closing this PR makes absolutely sense, since #4595 implements it even better.

Best regards,
~dymat
",unable get output author hi sorry answer available last absolutely sense since even better best,issue,positive,positive,positive,positive,positive,positive
730383438,"Hello! Just letting you know that we are no longer planning on supporting anything on the 0.2.x product line and that all work should be ported over to 0.3.x, which is considered a complete rebuild of PySyft. Because of that, I’ll be closing this issue. If you feel this is a mistake, or if the issue actually applies to 0.3.x as well, please feel free to ping me on Slack and I’ll reopen the issue.",hello know longer supporting anything product line work ported considered complete rebuild issue feel mistake issue actually well please feel free ping slack reopen issue,issue,positive,positive,positive,positive,positive,positive
729876925,"Check this issue if the RunTime error persists. https://github.com/pytorch/pytorch/issues/20006
This error is related to PyTorch.",check issue error error related,issue,negative,neutral,neutral,neutral,neutral,neutral
729725352,I read the about the implementation of snn through its paper and not trying to understand the code structure,read implementation paper trying understand code structure,issue,negative,neutral,neutral,neutral,neutral,neutral
729676432,"@NProkoptsev thanks, I do so. But it seems saving and loading would break the object pointer so once you use the `get` command to retrieve your model from one of the workers it retrieves the old one (the same model before saving and not the updated one).
```Python
torch.jit.save(model,'model.pt')
model = torch.jit.load('model.pt',map_location='cpu')
```",thanks saving loading would break object pointer use get command retrieve model one old one model saving one python model model,issue,negative,positive,positive,positive,positive,positive
729547591,"Thanks for the reply.

Actually I have two machines and try to implement my own federated learning structure.

All i need is just to define the dataloader in the client's code and tell client's while iterating over the batches do something for each one of them.

For more insight

Client:
![image](https://user-images.githubusercontent.com/26565713/99510288-e3545280-29ac-11eb-90e1-5a3fd06b6e63.png)

Server:
![image](https://user-images.githubusercontent.com/26565713/99510383-067f0200-29ad-11eb-8ce7-85427d266791.png)

As it is federated learning, I should be able to pull out the data from client and not like send the data from server to the client.

Please guide me to achieve this.

",thanks reply actually two try implement learning structure need define client code tell client something one insight client image server image learning able pull data client like send data server client please guide achieve,issue,positive,positive,positive,positive,positive,positive
729521698,"There are some outstanding issues with operating Duet in CLI mode and the event loop, possibly on Windows which we should test for and ensure we have fixed.
See https://github.com/OpenMined/PySyft/issues/4766",outstanding operating duet mode event loop possibly test ensure fixed see,issue,positive,positive,positive,positive,positive,positive
729443394,"@gmuraru Are we confident its a copy? After all the python code should only be returning a pointer to the inplace operator which in this case might just be a view. Perhaps PyTorch is simply not GCing the underlying data until both views of the data are freed.

Perhaps we can try this with another inplace operator that is destructive like sub_, add_ etc?
",confident copy python code pointer operator case might view perhaps simply underlying data data freed perhaps try another operator destructive like,issue,positive,negative,neutral,neutral,negative,negative
729397383,"I have checked this in 0.3.0 and it seems while the Flask server runs in IPV6 the sy.duet() joining function fails to connect.
We will investigate further.",checked flask server joining function connect investigate,issue,negative,neutral,neutral,neutral,neutral,neutral
729340595,"@AbhishekPokala is this now working? I imagine the same issues will happen with the new 0.3.0 release and Torch on arm linux, perhaps you could try this with 0.3.0 and document the process so we can add it to our docs? I have a TinkerBoard in the cupboard I can grab to do some testing as well on Raspbian.",working imagine happen new release torch arm perhaps could try document process add cupboard grab testing well,issue,negative,positive,positive,positive,positive,positive
729318663,"@mothukuriv thats great news! I was hopeful that pip would be enough I guess the updated pip knows how to fetch and build the dependencies but just incase i thought I would include the missing ffmpeg stuff as it looked like that was the downstream issue.

The error you see now is a normal error when you install torchvision with a different version of torch. Just uninstall torch or torchvision and pick a compatible version. If you install torchvision it will match the version of torch for you.

We support:
```
torch==1.5.0
torch==1.5.1
torch==1.6.0
torch==1.7.0
```

The torchvision versions which match the above are:
```
torchvision==0.6.0
torchvision==0.6.1
torchvision==0.7.0
torchvision==0.8.1 (0.8.0 was patched quickly after release)
```

You can read more here:
https://pypi.org/project/torchvision/",thats great news hopeful pip would enough guess pip fetch build incase thought would include missing stuff like downstream issue error see normal error install different version torch torch pick compatible version install match version torch support match quickly release read,issue,positive,positive,positive,positive,positive,positive
729294379,"Thank you , Just with the update of pip3 I was able to install syft.
`(env) user@lambda-quad:~/3.0/PySyft$ pip3 freeze|grep syft
syft==0.3.0
(env) user@lambda-quad:~/3.0/PySyft$ python3 -m pip --version
pip 20.2.4 from /home/user/3.0/PySyft/env/lib/python3.6/site-packages/pip (python 3.6)`

Installation have only one error in log, 

`ERROR: 
torchvision 0.8.1 requires torch==1.7.0, but you'll have torch 1.6.0 which is incompatible.`

",thank update pip able install user pip user python pip version pip python installation one error log error torch,issue,negative,positive,positive,positive,positive,positive
729237515,"Hi @caiyuanqin, it looks like you are trying to use the old 0.2.x method of `TorchHook` in 0.3.0 which is no longer needed.

This raises a very good issue which is we need to add a 0.2.x upgrade explanation to our README.md so thanks, I will get this in the pipeline asap.",hi like trying use old method longer good issue need add upgrade explanation thanks get pipeline,issue,positive,positive,positive,positive,positive,positive
729236380,"@mothukuriv Thanks for the command outputs. 😊
My first thought is that the pip version looks very old. It also looks like it is unable to build PyAV due to some missing AV libraries.

Firstly for pip your version is:
```
pip 9.0.1
```

My current version with python 3.6.9 is:
```
pip 20.2.4
```

Can you try the following:
```
$ python3 -m pip install --upgrade pip
$ python3 -m pip --version
```

Then secondly since we are using aiortc for our WebRTC library which seems to have a dependency on PyAV for its Video functionality (which we are not using), my guess is this ticket relates to your issue: https://github.com/PyAV-Org/PyAV/issues/697

I think the solution will be:
```
$ apt-get install ffmpeg-dev
```

After that try installing syft again.
```
$ python3 -m pip install syft
```

Then please include the output here again.",thanks command first thought pip version old also like unable build due missing firstly pip version pip current version python pip try following python pip install upgrade pip python pip version secondly since library dependency video functionality guess ticket issue think solution install try python pip install please include output,issue,positive,negative,neutral,neutral,negative,negative
729216508,"Have this/similar problem too.
After hooking torch, the following code will fail every time:
`pickle.load(pickle_file)`

I also used the workaround of first importing torchvision and then hooking.",problem torch following code fail every time also used first,issue,negative,negative,neutral,neutral,negative,negative
729089956,"I have exactly the same issue 
![issue1](https://user-images.githubusercontent.com/33352454/99426583-f283c380-290c-11eb-8366-43c176b16894.JPG)
![issue2](https://user-images.githubusercontent.com/33352454/99426584-f31c5a00-290c-11eb-9bc6-a1e5f48bb93b.JPG)
",exactly issue issue issue,issue,negative,positive,positive,positive,positive,positive
729071212,"`(env) user@lambda-quad:~/3.0/PySyft$ which python3
/home/user/3.0/PySyft/env/bin/python3
(env) user@lambda-quad:~/3.0/PySyft$ python3 --version
Python 3.6.9
(env) user@lambda-quad105535:~/3.0/PySyft$ python3 -m pip --version
pip 9.0.1 from /home/user/3.0/PySyft/env/lib/python3.6/site-packages (python 3.6)
(env) user@lambda-quad105535:~/3.0/PySyft$ python3 -m pip install syft`

`Building wheels for collected packages: av, pylibsrtp
  Running setup.py bdist_wheel for av ... error
  Complete output from command /home/vmothuku/3.0/PySyft/env/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-ffqu4usp/av/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" bdist_wheel -d /tmp/tmp3iqgcqjxpip-wheel- --python-tag cp36:
  usage: -c [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]
     or: -c --help [cmd1 cmd2 ...]
     or: -c --help-commands
     or: -c cmd --help

  error: invalid command 'bdist_wheel'

  ----------------------------------------
  Failed building wheel for av
  Running setup.py clean for av
  Running setup.py bdist_wheel for pylibsrtp ... error
  Complete output from command /home/vmothuku/3.0/PySyft/env/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-ffqu4usp/pylibsrtp/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" bdist_wheel -d /tmp/tmpjvcay0ogpip-wheel- --python-tag cp36:
  usage: -c [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]
     or: -c --help [cmd1 cmd2 ...]
     or: -c --help-commands
     or: -c cmd --help

  error: invalid command 'bdist_wheel'

  ----------------------------------------
  Failed building wheel for pylibsrtp
  Running setup.py clean for pylibsrtp
Failed to build av pylibsrtp
Installing collected packages: av, pylibsrtp, aiortc, typing-extensions, websockets, python-dateutil, pytz, pandas, chardet, urllib3, idna, certifi, requests, pillow, torchvision, nest-asyncio, forbiddenfruit, pyparsing, packaging, immutables, contextvars, aiocontextvars, loguru, typeguard, protobuf, dpcontracts, syft
  Running setup.py install for av ... error
    Complete output from command /home/vmothuku/3.0/PySyft/env/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-ffqu4usp/av/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/pip-tv71fji3-record/install-record.txt --single-version-externally-managed --compile --install-headers /home/vmothuku/3.0/PySyft/env/include/site/python3.6/av:
    running install
    running build
    running build_py
    creating build
    creating build/lib.linux-x86_64-3.6
    creating build/lib.linux-x86_64-3.6/av
    copying av/__main__.py -> build/lib.linux-x86_64-3.6/av
    copying av/__init__.py -> build/lib.linux-x86_64-3.6/av
    copying av/deprecation.py -> build/lib.linux-x86_64-3.6/av
    copying av/datasets.py -> build/lib.linux-x86_64-3.6/av
    creating build/lib.linux-x86_64-3.6/av/video
    copying av/video/__init__.py -> build/lib.linux-x86_64-3.6/av/video
    creating build/lib.linux-x86_64-3.6/av/filter
    copying av/filter/__init__.py -> build/lib.linux-x86_64-3.6/av/filter
    creating build/lib.linux-x86_64-3.6/av/audio
    copying av/audio/__init__.py -> build/lib.linux-x86_64-3.6/av/audio
    creating build/lib.linux-x86_64-3.6/av/codec
    copying av/codec/__init__.py -> build/lib.linux-x86_64-3.6/av/codec
    creating build/lib.linux-x86_64-3.6/av/sidedata
    copying av/sidedata/__init__.py -> build/lib.linux-x86_64-3.6/av/sidedata
    creating build/lib.linux-x86_64-3.6/av/subtitles
    copying av/subtitles/__init__.py -> build/lib.linux-x86_64-3.6/av/subtitles
    creating build/lib.linux-x86_64-3.6/av/data
    copying av/data/__init__.py -> build/lib.linux-x86_64-3.6/av/data
    creating build/lib.linux-x86_64-3.6/av/container
    copying av/container/__init__.py -> build/lib.linux-x86_64-3.6/av/container
    running build_ext
    running config
    PyAV: 8.0.2 (unknown commit)
    Python: 3.6.9 (default, Oct  8 2020, 12:12:24) \n[GCC 8.4.0]
    platform: Linux-5.4.0-52-generic-x86_64-with-Ubuntu-18.04-bionic
    extension_extra:
        include_dirs: [b'include']
        libraries: []
        library_dirs: []
        define_macros: []
        runtime_library_dirs: []
    config_macros:
        PYAV_COMMIT_STR=""unknown-commit""
        PYAV_VERSION=8.0.2
        PYAV_VERSION_STR=""8.0.2""
    Could not find libavformat with pkg-config.
    Could not find libavcodec with pkg-config.
    Could not find libavdevice with pkg-config.
    Could not find libavutil with pkg-config.
    Could not find libavfilter with pkg-config.
    Could not find libswscale with pkg-config.
    Could not find libswresample with pkg-config.

    ----------------------------------------
Command ""/home/vmothuku/3.0/PySyft/env/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-ffqu4usp/av/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/pip-tv71fji3-record/install-record.txt --single-version-externally-managed --compile --install-headers /home/vmothuku/3.0/PySyft/env/include/site/python3.6/av"" failed with error code 1 in /tmp/pip-build-ffqu4usp/av/`
",user python user python version python user python pip version pip python user python pip install building collected running error complete output command import open compile code usage help help error invalid command building wheel running clean running error complete output command import open compile code usage help help error invalid command building wheel running clean build collected pillow running install error complete output command import open compile code install record compile running install running build running build running running unknown commit python default platform could find could find could find could find could find could find could find command import open compile code install record compile error code,issue,negative,positive,neutral,neutral,positive,positive
728727536,"Hi @NavyaSreeY all `Pointer` classes have a `.get()` method to allow you retrieve the real result. If the user has insufficient permission you will get an Authorization error and you may request with the blocking request API and allow the Data Owner to approve the request.

If the data was created by the client and sent it is usually not made ""searchable"". However we have a method for this in an open PR which should be merged shortly. If you check the `duet.store.pandas` on the server / Data Owner side you might see the entry in there and you could attempt to retrieve it that way.

The documentation on the Duet README.md is here: https://github.com/OpenMined/PySyft/blob/master/examples/duet/README.md is more comprehensive right now so I would recommend taking a look there and follow the examples and the MNIST notebook. We will be updating the main docs and root README.md very shortly.

I hope that helps answer your question.",hi pointer class method allow retrieve real result user insufficient permission get authorization error may request blocking request allow data owner approve request data client sent usually made searchable however method open shortly check server data owner side might see entry could attempt retrieve way documentation duet comprehensive right would recommend taking look follow notebook main root shortly hope answer question,issue,positive,positive,neutral,neutral,positive,positive
728723380,"Hi @zizi96, Unfortunately due to the rebuild, 0.3.0 isn't at 100% parity with 0.2.x as yet, however this will be addressed very shortly. In the mean time if you need that specific functionality, you can still install 0.2.x like so:
```
$ pip install syft==0.2.9
```",hi unfortunately due rebuild parity yet however shortly mean time need specific functionality still install like pip install,issue,negative,negative,negative,negative,negative,negative
728721214,"@mothukuriv Can you please run the following and then paste the output for this commands here.
```
$ which python3
$ python3 --version
$ python3 -m pip --version
$ python3 -m pip install syft
```

Syft 0.3 supports python 3.6 on Ubuntu and we have it in our CI: https://github.com/OpenMined/PySyft/blob/master/.github/workflows/tests.yml

Usually these kinds of issues relate to an issue with python paths, not using an virtualenv or some Ubuntu system packages needed to compile dependencies. ",please run following paste output python python version python pip version python pip install python usually relate issue python system compile,issue,negative,negative,negative,negative,negative,negative
728207928,"Do you have two versions of python installed? You said you have Python 3.7 but the log you posted references 3.6

> --compile --install-headers /home/user/env/include/site/python3.6/av
",two python said python log posted compile,issue,negative,neutral,neutral,neutral,neutral,neutral
727311254,"@gmuraru It installs websockets version 8.1

I am sorry for the late reply.",version sorry late reply,issue,negative,negative,negative,negative,negative,negative
726426200,"> This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the `stale` label to unmark it. Otherwise, this will be closed in 7 days.

Updating so this issue is active.",issue marked stale open day activity leave comment remove stale label otherwise closed day issue active,issue,negative,negative,negative,negative,negative,negative
726260120,Closing! Unable to get output from the author. ,unable get output author,issue,negative,negative,negative,negative,negative,negative
726257999,"Damn it, Patrick! You always say that you'll try to make them smaller!",damn always say try make smaller,issue,negative,neutral,neutral,neutral,neutral,neutral
725541966,"# [Codecov](https://codecov.io/gh/OpenMined/PySyft/pull/4644?src=pr&el=h1) Report
> Merging [#4644](https://codecov.io/gh/OpenMined/PySyft/pull/4644?src=pr&el=desc) (1a913fd) into [master](https://codecov.io/gh/OpenMined/PySyft/commit/a61f2e71a72e6da6926232079122bef60d51ceb8?el=desc) (a61f2e7) will **increase** coverage by `0.01%`.
> The diff coverage is `98.55%`.

[![Impacted file tree graph](https://codecov.io/gh/OpenMined/PySyft/pull/4644/graphs/tree.svg?width=650&height=150&src=pr&token=W0kQS1vaXB)](https://codecov.io/gh/OpenMined/PySyft/pull/4644?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master    #4644      +/-   ##
==========================================
+ Coverage   94.60%   94.61%   +0.01%     
==========================================
  Files         209      211       +2     
  Lines       22071    22116      +45     
==========================================
+ Hits        20880    20926      +46     
+ Misses       1191     1190       -1     
```


| [Impacted Files](https://codecov.io/gh/OpenMined/PySyft/pull/4644?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [syft/frameworks/torch/mpc/aby3/aby3\_helper.py](https://codecov.io/gh/OpenMined/PySyft/pull/4644/diff?src=pr&el=tree#diff-c3lmdC9mcmFtZXdvcmtzL3RvcmNoL21wYy9hYnkzL2FieTNfaGVscGVyLnB5) | `94.11% <94.11%> (ø)` | |
| [syft/frameworks/torch/mpc/falcon/falcon\_helper.py](https://codecov.io/gh/OpenMined/PySyft/pull/4644/diff?src=pr&el=tree#diff-c3lmdC9mcmFtZXdvcmtzL3RvcmNoL21wYy9mYWxjb24vZmFsY29uX2hlbHBlci5weQ==) | `98.55% <100.00%> (+4.21%)` | :arrow_up: |
| [syft/frameworks/torch/mpc/przs.py](https://codecov.io/gh/OpenMined/PySyft/pull/4644/diff?src=pr&el=tree#diff-c3lmdC9mcmFtZXdvcmtzL3RvcmNoL21wYy9wcnpzLnB5) | `93.25% <100.00%> (ø)` | |
| [...ks/torch/tensors/interpreters/replicated\_shared.py](https://codecov.io/gh/OpenMined/PySyft/pull/4644/diff?src=pr&el=tree#diff-c3lmdC9mcmFtZXdvcmtzL3RvcmNoL3RlbnNvcnMvaW50ZXJwcmV0ZXJzL3JlcGxpY2F0ZWRfc2hhcmVkLnB5) | `93.75% <100.00%> (+0.10%)` | :arrow_up: |
| [test/torch/mpc/aby3/test\_aby3\_helper.py](https://codecov.io/gh/OpenMined/PySyft/pull/4644/diff?src=pr&el=tree#diff-dGVzdC90b3JjaC9tcGMvYWJ5My90ZXN0X2FieTNfaGVscGVyLnB5) | `100.00% <100.00%> (ø)` | |
| [test/torch/mpc/falcon/test\_falcon\_helper.py](https://codecov.io/gh/OpenMined/PySyft/pull/4644/diff?src=pr&el=tree#diff-dGVzdC90b3JjaC9tcGMvZmFsY29uL3Rlc3RfZmFsY29uX2hlbHBlci5weQ==) | `100.00% <100.00%> (ø)` | |
",report master increase coverage coverage impacted file tree graph coverage master coverage impacted coverage,issue,negative,neutral,neutral,neutral,neutral,neutral
725429161,"Tested with with MNIST notebook!
Downloading the model is ~40% faster for me (11 sec vs 6 sec).
The difference is not very noticeable for a small model, but the weird thing about aiortc is that if that the bigger message you send the slower (exponentially) it gets. E.g. sending monolith 4mb blob takes ~5 sec. 8mb ~15 sec. 16mb ~60 sec.",tested notebook model faster sec sec difference noticeable small model weird thing bigger message send exponentially sending monolith blob sec sec sec,issue,negative,negative,negative,negative,negative,negative
725361086,"> sorry i accidentally closed :P

No worries :D - I have to add one more thing to this",sorry accidentally closed add one thing,issue,negative,negative,negative,negative,negative,negative
725317063,"# [Codecov](https://codecov.io/gh/OpenMined/PySyft/pull/4801?src=pr&el=h1) Report
> Merging [#4801](https://codecov.io/gh/OpenMined/PySyft/pull/4801?src=pr&el=desc) (6885208) into [master](https://codecov.io/gh/OpenMined/PySyft/commit/35ea7282f484091070e0e2af6754902ec0cf34b1?el=desc) (35ea728) will **increase** coverage by `0.00%`.
> The diff coverage is `100.00%`.

[![Impacted file tree graph](https://codecov.io/gh/OpenMined/PySyft/pull/4801/graphs/tree.svg?width=650&height=150&src=pr&token=W0kQS1vaXB)](https://codecov.io/gh/OpenMined/PySyft/pull/4801?src=pr&el=tree)

```diff
@@           Coverage Diff           @@
##           master    #4801   +/-   ##
=======================================
  Coverage   94.59%   94.59%           
=======================================
  Files         209      209           
  Lines       21983    21994   +11     
=======================================
+ Hits        20794    20805   +11     
  Misses       1189     1189           
```


| [Impacted Files](https://codecov.io/gh/OpenMined/PySyft/pull/4801?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [syft/generic/object\_storage.py](https://codecov.io/gh/OpenMined/PySyft/pull/4801/diff?src=pr&el=tree#diff-c3lmdC9nZW5lcmljL29iamVjdF9zdG9yYWdlLnB5) | `97.50% <100.00%> (+0.06%)` | :arrow_up: |
| [test/generic/pointers/test\_pointer\_tensor.py](https://codecov.io/gh/OpenMined/PySyft/pull/4801/diff?src=pr&el=tree#diff-dGVzdC9nZW5lcmljL3BvaW50ZXJzL3Rlc3RfcG9pbnRlcl90ZW5zb3IucHk=) | `100.00% <100.00%> (ø)` | |
",report master ea increase coverage coverage impacted file tree graph coverage master coverage impacted coverage,issue,negative,neutral,neutral,neutral,neutral,neutral
725059429,I think for now lets use the temporary lookup_cache solution and then do this in the refactor here: https://github.com/OpenMined/PySyft/issues/4806,think use temporary solution,issue,negative,neutral,neutral,neutral,neutral,neutral
724965932,You should rebase - there was a fix that got into the master branch,rebase fix got master branch,issue,negative,neutral,neutral,neutral,neutral,neutral
724656554,I can confirm this is broken on CLI and is fixed by this change. 👍,confirm broken fixed change,issue,negative,negative,negative,negative,negative,negative
724565901,"Ahh...I do not know how this got out of my notification bar from GitHub.
Could you reopen it, please? - I can check it out.",know got notification bar could reopen please check,issue,negative,neutral,neutral,neutral,neutral,neutral
724480201,"The following links can be used to test the MNIST notebooks on Colab:
```
https://colab.research.google.com/github/OpenMined/PySyft/blob/demo/examples/duet/mnist/MNIST_Syft_Data_Owner.ipynb
https://colab.research.google.com/github/OpenMined/PySyft/blob/demo/examples/duet/mnist/MNIST_Syft_Data_Scientist.ipynb
```

There appears to be some bug where Colab kind of disconnects or times out.",following link used test bug kind time,issue,positive,positive,positive,positive,positive,positive
724336556,"hi,
wher you able to fix this error message
",hi able fix error message,issue,negative,positive,positive,positive,positive,positive
724264591,"Yes thank you for your feedback.

<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
Bez
virů. www.avast.com
<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
<#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

pi 6. 11. 2020 o 18:55 George-Cristian Muraru <notifications@github.com>
napísal(a):

> hey @Martiniann <https://github.com/Martiniann>.
>
> Can this issue be closed?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/4652#issuecomment-723216710>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AQGQNQ2WLOBLIEC6GV2AUPDSOQ2AXANCNFSM4SREGRPQ>
> .
>
",yes thank feedback pi hey issue closed reply directly view,issue,positive,neutral,neutral,neutral,neutral,neutral
724182513,"> Yayy! One step closer to FALCON!! <3

I also have the Bit Injection (malicious setup)",one step closer falcon also bit injection malicious setup,issue,negative,neutral,neutral,neutral,neutral,neutral
724150726,"# [Codecov](https://codecov.io/gh/OpenMined/PySyft/pull/4793?src=pr&el=h1) Report
> Merging [#4793](https://codecov.io/gh/OpenMined/PySyft/pull/4793?src=pr&el=desc) (e575a35) into [master](https://codecov.io/gh/OpenMined/PySyft/commit/4575a50f38b78728dafe2615aad9145dae17b085?el=desc) (4575a50) will **increase** coverage by `0.00%`.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/OpenMined/PySyft/pull/4793/graphs/tree.svg?width=650&height=150&src=pr&token=W0kQS1vaXB)](https://codecov.io/gh/OpenMined/PySyft/pull/4793?src=pr&el=tree)

```diff
@@           Coverage Diff           @@
##           master    #4793   +/-   ##
=======================================
  Coverage   94.57%   94.57%           
=======================================
  Files         209      209           
  Lines       21958    21958           
=======================================
+ Hits        20766    20767    +1     
+ Misses       1192     1191    -1     
```


| [Impacted Files](https://codecov.io/gh/OpenMined/PySyft/pull/4793?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [...ft/frameworks/torch/tensors/interpreters/native.py](https://codecov.io/gh/OpenMined/PySyft/pull/4793/diff?src=pr&el=tree#diff-c3lmdC9mcmFtZXdvcmtzL3RvcmNoL3RlbnNvcnMvaW50ZXJwcmV0ZXJzL25hdGl2ZS5weQ==) | `87.75% <0.00%> (-0.19%)` | :arrow_down: |
| [syft/execution/plan.py](https://codecov.io/gh/OpenMined/PySyft/pull/4793/diff?src=pr&el=tree#diff-c3lmdC9leGVjdXRpb24vcGxhbi5weQ==) | `94.90% <0.00%> (+0.56%)` | :arrow_up: |
",report ea master increase coverage coverage impacted file tree graph coverage master coverage impacted coverage,issue,negative,neutral,neutral,neutral,neutral,neutral
724126852,"Yes we have a first integration of Opacus!
Check out: https://blog.openmined.org/pysyft-opacus-federated-learning-with-differential-privacy/",yes first integration check,issue,negative,positive,positive,positive,positive,positive
724090804,"_Btw for anyone reviewing, feedback is very much appreciated! Pls keep in mind it's still work in progress._",anyone feedback much keep mind still work,issue,negative,positive,positive,positive,positive,positive
723803878,@gmuraru I have to check. Please give a day! ,check please give day,issue,negative,neutral,neutral,neutral,neutral,neutral
723453769,I am new to this project and wish to contribute to it I have gone through all the tutorials. Can give a try to this issue,new project wish contribute gone give try issue,issue,negative,positive,positive,positive,positive,positive
723426465,"Thanks!
I added new test!",thanks added new test,issue,negative,positive,positive,positive,positive,positive
723356791,"Hi @Jagoul , wer you able to solve the issue with the recommended fix ?? I m facing same error.. initially size(-1) is 0 after adding size method (expected to be in range of [-1, 0], but got 1)
if I use rnn instead of nn then ' got 1D, 2D tensors at '",hi wer able solve issue fix facing error initially size size method range got use instead got,issue,negative,positive,positive,positive,positive,positive
723069912,"As @boris-vasilev explained, the use of ckks isn't yet fully supported in PySyft. We are working hard on TenSEAL to make the integration as soon as possible.",use yet fully working hard make integration soon possible,issue,negative,negative,negative,negative,negative,negative
723038966,"Looking at https://github.com/OpenMined/TenSEAL/issues/19 it seems like if you want to use syft.frameworks.tenseal you have to use the [tenseal/ckksvector](https://github.com/OpenMined/PySyft/tree/tenseal/ckksvector) branch. But it seems like adding CKKSTensor won't be merged into master anytime soon due to the technical challenges faced.

I also tried running the tutorial but after using [tenseal/ckksvector](https://github.com/OpenMined/PySyft/tree/tenseal/ckksvector)  I got the following error even though the import succeeded:

![image](https://user-images.githubusercontent.com/12242041/98362780-ba83a300-2025-11eb-8635-1c515eb774a8.png)
",looking like want use use branch like wo master soon due technical faced also tried running tutorial got following error even though import image,issue,negative,negative,neutral,neutral,negative,negative
722941726,Hi @Nilanshrajput I just tried this on my machine and its working and as discussed with you we can close this issue :) ,hi tried machine working close issue,issue,negative,neutral,neutral,neutral,neutral,neutral
722782586,The last commit is I rebase the previous one to the lastest master branch.,last commit rebase previous one master branch,issue,negative,negative,neutral,neutral,negative,negative
722580533,"Hey @dymat we appreciate your work and thank-you soo much for making a PR but since the above mentioned PR solves the and is merged, can you please close this PR ?",hey appreciate work much making since please close,issue,positive,positive,positive,positive,positive,positive
722532236,"Yeah, I haven't been able to work on it, I got really busy.
I will sure have another go at this.",yeah able work got really busy sure another go,issue,positive,positive,positive,positive,positive,positive
722414994,"Currently, the tests are failling here:
```
 def test_serde_coverage():
        """"""Checks all types in serde are tested""""""
        for cls, _ in msgpack.serde.msgpack_global_state.simplifiers.items():
            # currently involves running grid node instance might create overhead
            # To do add method for running pygrid node instance to cover this testing
            if cls == syft.grid.clients.data_centric_fl_client.DataCentricFLClient:
                continue
            has_sample = cls in samples
>           assert has_sample, f""Serde for {cls} is not tested""
E           AssertionError: Serde for <class 'syft.frameworks.torch.tensors.interpreters.bfv.BFVTensor'> is not tested
E           assert False
```

You need to also add serialization/deserialize tests.",currently tested currently running grid node instance might create overhead add method running node instance cover testing continue assert tested class tested assert false need also add,issue,negative,negative,negative,negative,negative,negative
722375572,"# [Codecov](https://codecov.io/gh/OpenMined/PySyft/pull/4773?src=pr&el=h1) Report
> Merging [#4773](https://codecov.io/gh/OpenMined/PySyft/pull/4773?src=pr&el=desc) into [master](https://codecov.io/gh/OpenMined/PySyft/commit/eb4d348e19ee0356343a841e19f8df978cf9170f?el=desc) will **decrease** coverage by `0.00%`.
> The diff coverage is `92.85%`.

[![Impacted file tree graph](https://codecov.io/gh/OpenMined/PySyft/pull/4773/graphs/tree.svg?width=650&height=150&src=pr&token=W0kQS1vaXB)](https://codecov.io/gh/OpenMined/PySyft/pull/4773?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master    #4773      +/-   ##
==========================================
- Coverage   94.57%   94.56%   -0.01%     
==========================================
  Files         209      209              
  Lines       21886    21958      +72     
==========================================
+ Hits        20699    20765      +66     
- Misses       1187     1193       +6     
```


| [Impacted Files](https://codecov.io/gh/OpenMined/PySyft/pull/4773?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [syft/frameworks/torch/hook/hook.py](https://codecov.io/gh/OpenMined/PySyft/pull/4773/diff?src=pr&el=tree#diff-c3lmdC9mcmFtZXdvcmtzL3RvcmNoL2hvb2svaG9vay5weQ==) | `89.38% <0.00%> (-0.48%)` | :arrow_down: |
| [...ft/frameworks/torch/tensors/interpreters/native.py](https://codecov.io/gh/OpenMined/PySyft/pull/4773/diff?src=pr&el=tree#diff-c3lmdC9mcmFtZXdvcmtzL3RvcmNoL3RlbnNvcnMvaW50ZXJwcmV0ZXJzL25hdGl2ZS5weQ==) | `87.75% <87.50%> (-0.20%)` | :arrow_down: |
| [...frameworks/torch/tensors/interpreters/precision.py](https://codecov.io/gh/OpenMined/PySyft/pull/4773/diff?src=pr&el=tree#diff-c3lmdC9mcmFtZXdvcmtzL3RvcmNoL3RlbnNvcnMvaW50ZXJwcmV0ZXJzL3ByZWNpc2lvbi5weQ==) | `95.03% <100.00%> (+0.04%)` | :arrow_up: |
| [syft/generic/pointers/pointer\_tensor.py](https://codecov.io/gh/OpenMined/PySyft/pull/4773/diff?src=pr&el=tree#diff-c3lmdC9nZW5lcmljL3BvaW50ZXJzL3BvaW50ZXJfdGVuc29yLnB5) | `92.50% <100.00%> (+0.15%)` | :arrow_up: |
| [test/generic/pointers/test\_pointer\_tensor.py](https://codecov.io/gh/OpenMined/PySyft/pull/4773/diff?src=pr&el=tree#diff-dGVzdC9nZW5lcmljL3BvaW50ZXJzL3Rlc3RfcG9pbnRlcl90ZW5zb3IucHk=) | `100.00% <100.00%> (ø)` | |
| [test/torch/tensors/test\_precision.py](https://codecov.io/gh/OpenMined/PySyft/pull/4773/diff?src=pr&el=tree#diff-dGVzdC90b3JjaC90ZW5zb3JzL3Rlc3RfcHJlY2lzaW9uLnB5) | `100.00% <100.00%> (ø)` | |
| [syft/execution/plan.py](https://codecov.io/gh/OpenMined/PySyft/pull/4773/diff?src=pr&el=tree#diff-c3lmdC9leGVjdXRpb24vcGxhbi5weQ==) | `94.33% <0.00%> (-0.57%)` | :arrow_down: |
| [test/torch/tensors/test\_additive\_shared.py](https://codecov.io/gh/OpenMined/PySyft/pull/4773/diff?src=pr&el=tree#diff-dGVzdC90b3JjaC90ZW5zb3JzL3Rlc3RfYWRkaXRpdmVfc2hhcmVkLnB5) | `100.00% <0.00%> (ø)` | |
",report master decrease coverage coverage impacted file tree graph coverage master coverage impacted coverage,issue,negative,neutral,neutral,neutral,neutral,neutral
722278902,"Hi @Bhuvan-21 just checked this notebook, runs perfectly on my machine. Please upgrade to the latest syft master, I am sure it will no longer throw this error. ",hi checked notebook perfectly machine please upgrade latest master sure longer throw error,issue,positive,positive,positive,positive,positive,positive
721889833,"I am new to this library and have gone through all the tutorial I aim to contribute to this library. Can I try this issue and can you please clarify what you mean by  ""which reflect the VAE example split into DO (Data Owner) and DS (Data Scientist)"" ",new library gone tutorial aim contribute library try issue please clarify mean reflect example split data owner data scientist,issue,negative,negative,neutral,neutral,negative,negative
721804650,"Thanks for the update @gmuraru, I'll use what's in this PR and then switch to your bit injectection once merged. Otherwise, yeah I can add the OT stuff later.

Thanks @abogaziah.",thanks update use switch bit otherwise yeah add stuff later thanks,issue,positive,positive,positive,positive,positive,positive
721591843,"It looks, it could have been done very easily. I just could not think of this while raising the issue.
**client = FLClient(url=gridAddress, auth_token=None, verbose=True)**

I believe this issue can be closed without a change required. Now, the concern is whether we want auth_token as an optional parameter or go like this way only. @vvmnnnkv your thoughts?",could done easily could think raising issue client believe issue closed without change concern whether want optional parameter go like way,issue,positive,positive,positive,positive,positive,positive
721426179,"Only a headsup that there is also a PR that adds the bit injection - from ABY3, but for the malicious settings here: https://github.com/OpenMined/PySyft/pull/4644 - I should finish the PR and make it ready for review this week

Falcon has two scenarios for semi-honest and malicious - I think, for the moment, we might be able to use the malicious setup (and use the implementation from the above PR for Private Compare).

For the semi-honest setting, there is needed an Oblivious Transfer-like component - but we can do that in another PR.",also bit injection aby malicious finish make ready review week falcon two malicious think moment might able use malicious setup use implementation private compare setting oblivious component another,issue,negative,positive,positive,positive,positive,positive
721420517,"Hey @abogaziah ,
I can see you started implementing the private compare, but haven't made much progress, since September.
Would it be ok if I continue where you left off and open a PR ?  
",hey see private compare made much progress since would continue left open,issue,negative,positive,neutral,neutral,positive,positive
721160042,"Looked into this issue!

Run the following code:
```
alice = sy.VirtualMachine(name=""alice"")
alice_client = alice.get_client()
    
x_ptr = x.send(alice_client)
print(alice.store)
   
x_ptr2 = x_ptr.transpose(0, 1)
print(alice.store)
```
How the store looks:

1.
```
{<UID:0ba289de-72a8-415f-ad5f-fa322e104367>: <Storable:tensor([[1, 2, 3],    [4, 5, 6]])>}
```
makes sense to be only one object since we sent one tensor

2.
```
{<UID:0ba289de-72a8-415f-ad5f-fa322e104367>: <Storable:tensor([[1, 2, 3],    [4, 5, 6]])>, <UID:0d01b581-fcde-46ff-b0de-e72cc161d6d6>: <Storable:tensor([[1, 4],    [2, 5],    [3, 6]])>}
``` 
makes sense to be 2 objects since we called ```transponse``` on the tensor (and one is the transpose of the other)

With inplace methods/ops:
```
alice = sy.VirtualMachine(name=""alice"")
alice_client = alice.get_client()
        
x = th.tensor([[1,2,3], [4,5,6]])
x_ptr = x.send(alice_client)
print(alice.store)

x_ptr2 = x_ptr.transpose_(0, 1)
print(alice.store)
```
How the store looks:
1. ```{<UID:dbf20faa-d36e-446d-87cf-39b2d09368bd>: <Storable:tensor([[1, 2, 3],    [4, 5, 6]])>}```
2. ```{<UID:dbf20faa-d36e-446d-87cf-39b2d09368bd>: <Storable:tensor([[1, 4],    [2, 5],    [3, 6]])>, <UID:d9acfb0f-b215-4068-b32c-90142d68453a>: <Storable:tensor([[1, 4],    [2, 5],    [3, 6]])>}```

since we used ```transpose_``` (does the inplace transpose + returns the same transposed tensor -- in our case pointer to tensor)
This might be an acceptable behavior depending on what we want.

1. ```transpose_``` creates another tensor with how the data should look after transposing + changes the underlying data for the value we called ```transpose``` on.

If a user calls ```x_ptr2.get()``` it would get one value and the value pointed by ```x_ptr``` still remains in the store.

Other behaviors might be:
1. Return a **new pointer** which points **to the same data** in the store:
  - calling get on a pointer would fetch and delete that data, the other pointer remains invalidated (a user calling get on it would get an exception because there is no data on the store).
   - deleting the **new** or **original** pointer would send a delete message to the store which would delete the underlying data -- the other pointer would point to invalid data.

2. Return the **same pointer** as the pointer we called the inplace operation on (we do not create a copy on the data on the store side)
- We would basically have *x_ptr2* and *x_ptr* but they are the same object (```id(x_ptr2) == id(x_ptr)```)
- The same downside is - doing *x_ptr.get()* or *x_ptr2.get()* would make the other point to invalid data (data that was removed)

What we are doing now I consider to be the safest behavior - create a copy of the data (in the store) - modify the copy + the original.

What I consider the most correct behavior would be ```2.``` when we return the same pointer and there is only one instance of data in store, which would also be mutated -- I consider that is the responsibility of the user to be dealing with the pointers. We basically do the inplace operation and return the same object (in our case is the pointer on which we apply the inplace operator). If the user does a ```get``` on one of the pointers then they should know that the other pointer is invalidated.
",issue run following code print print store storable tensor sense one object since sent one tensor storable tensor storable tensor sense since tensor one transpose print print store storable tensor storable tensor storable tensor since used transpose tensor case pointer tensor might acceptable behavior depending want another tensor data look underlying data value transpose user would get one value value pointed still remains store might return new pointer data store calling get pointer would fetch delete data pointer remains user calling get would get exception data store new original pointer would send delete message store would delete underlying data pointer would point invalid data return pointer pointer operation create copy data store side would basically object id id downside would make point invalid data data removed consider behavior create copy data store modify copy original consider correct behavior would return pointer one instance data store would also consider responsibility user dealing basically operation return object case pointer apply operator user get one know pointer,issue,positive,positive,positive,positive,positive,positive
721100193,"@gmuraru @LaRiffle 
Thank you for your review!
Can you check a new commit?",thank review check new commit,issue,positive,positive,positive,positive,positive,positive
720798188,"This also happens inside the new sy.module:
```
# module.py
def __setattr__(self, name: str, value: Union[Any, ""Module""]) -> None:
        # bug where torch.nn.modules isnt the full name on some imports
        # TODO: fix this properly
        if ""torch.nn"" in full_name_with_qualname(klass=type(value)):
            modules = self.__dict__.get(""_modules"")
            if modules is not None:
                modules[name] = value
        else:
            object.__setattr__(self, name, value)

```",also inside new self name value union module none bug full name fix properly value none name value else self name value,issue,positive,positive,positive,positive,positive,positive
720740137,"Hi @sparkingdark if you have any specific issues post them here, but if you want real time help join public slack https://openmined.slack.com/ where there are many other contributors who can potentially answer your questions.",hi specific post want real time help join public slack many potentially answer,issue,positive,positive,positive,positive,positive,positive
720516269,"> Yep - I am ok with both cases, I think it is that tradeoff game :D -
> 
> * Throwing an exception would be more frustrating for the developer (because it would have to always do an FPT)
> * Having Syft doing this automatically would be easier for the developer, but it might introduce some bugs.

Yeah exactly, it will hide bugs, but also now the code is more robust than 6 months ago, that's why I've changed my mind ;) ",yep think game throwing exception would developer would always automatically would easier developer might introduce yeah exactly hide also code robust ago mind,issue,positive,negative,neutral,neutral,negative,negative
720514547,"Yep - I am ok with both cases, I think it is that tradeoff game :D - 
* Throwing an exception would be more frustrating for the developer (because it would have to always do an FPT)
* Having Syft doing this automatically would be easier for the developer, but it might introduce some bugs.

",yep think game throwing exception would developer would always automatically would easier developer might introduce,issue,positive,negative,negative,negative,negative,negative
720512611,"Hey!
That's right, but because of the several cases we have faced where you try to monkey patch other libs, operating internal float tensors with our FPT inputs, I think we actually need this, even if technically from a mathematic viewpoint it doesn't make sense.
I would also add @marload support for operating real python floats with FPT, what do you think about this?",hey right several faced try monkey patch operating internal float think actually need even technically mathematic viewpoint make sense would also add support operating real python think,issue,negative,positive,neutral,neutral,positive,positive
720462207,"> > @marload had a talk with @LaRiffle and I think the best solution for this is to throw an exception in case we try to multiply/divide `fix_precision` with a ""normal tensor"" such that anyone who tries to multiply/divide would have to explicitly convert to `fix_precision`
> 
> Are you saying that we should raise the exception when `torch.tensor(...).fix_precision() / torch.tensor(...)`?

Yep - but let's see what @LaRiffle has to say about this.",talk think best solution throw exception case try normal tensor anyone would explicitly convert saying raise exception yep let see say,issue,positive,positive,positive,positive,positive,positive
720440420,"> @marload had a talk with @LaRiffle and I think the best solution for this is to throw an exception in case we try to multiply/divide `fix_precision` with a ""normal tensor"" such that anyone who tries to multiply/divide would have to explicitly convert to `fix_precision`

Are you saying that we should raise the exception when `torch.tensor(...).fix_precision() / torch.tensor(...)`?",talk think best solution throw exception case try normal tensor anyone would explicitly convert saying raise exception,issue,positive,positive,positive,positive,positive,positive
720260943,"@PlamenHristov Yes, I totally agree that there are instances where it seems obvious that a particular data type doesn't make sense, but there are over 400 functions so rather than deciding on a case by case basis its a lot easier if we just keep upper limits on all the not_available rules so we don't accidentally forget to test certain data type support in future versions. I have been meaning to add a ""description"" field, for this exact purpose so that we can leave notes on why functionality is or isn't available which would be the perfect in this instance. For now it can stay as it is. 👍 ",yes totally agree obvious particular data type make sense rather case case basis lot easier keep upper accidentally forget test certain data type support future meaning add description field exact purpose leave functionality available would perfect instance stay,issue,positive,positive,positive,positive,positive,positive
720255678,"Okay send me the slack invite my email is debomastet335@gmail.com

On Mon, 2 Nov 2020, 11:26 Madhava Jay, <notifications@github.com> wrote:

> @sparkingdark <https://github.com/sparkingdark>, okay no problems. If you
> want to come onto slack and message me if you have any issues maybe I can
> help.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/4518#issuecomment-720254032>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AL7XHCAD4VM3K6NAQEFJDZLSNZC2FANCNFSM4QSE7POQ>
> .
>
",send slack invite mon jay wrote want come onto slack message maybe help reply directly view,issue,positive,positive,neutral,neutral,positive,positive
720254032,"@sparkingdark, okay no problems. If you want to come onto slack and message me if you have any issues maybe I can help.",want come onto slack message maybe help,issue,negative,neutral,neutral,neutral,neutral,neutral
719925254,"@marload had a talk with @LaRiffle and I think the best solution for this is to throw an exception in case we try to multiply/divide ```fix_precision``` with a ""normal tensor"" such that anyone who tries to multiply/divide would have to explicitly convert to ```fix_precision```",talk think best solution throw exception case try normal tensor anyone would explicitly convert,issue,positive,positive,positive,positive,positive,positive
719895546,"I found that this issue is not a lonely case, and most of the builtin_properties of Tensor dont work on wrapped tensors, including wrapped PointerTensor, FixedPrecisionTensor, and so on. 
Here are some examples:
```python
t = torch.randint(high=10,size=(2,3)).cuda()
fix_t = t.fix_prec()

print(t)
# tensor([[8, 2, 7],
#         [8, 7, 3]], device='cuda:0')
print(fix_t)
# (Wrapper)>FixedPrecisionTensor>tensor([[8000, 2000, 7000],
#                                        [8000, 7000, 3000]], device='cuda:0')

print(t.dtype)
# torch.int64
print(fix_t.dtype)
# torch.float32

print(t.device)
# cuda:0
print(fix_t.device)
# cpu

print(t.ndim)
# 2
print(fix_t.ndim)
# 1

print(t.T)
# tensor([[8, 8],
#         [2, 7],
#         [7, 3]], device='cuda:0')
print(fix_t.T)
# tensor([])

```",found issue lonely case tensor dont work wrapped wrapped python print tensor print wrapper tensor print print print print print print print tensor print tensor,issue,negative,negative,neutral,neutral,negative,negative
719553092,"Still happens on classes like:
```
>>> torch.nn.modules.Sequential
<class 'torch.nn.modules.container.Sequential'>
>>> torch.nn.Sequential
<class 'torch.nn.modules.container.Sequential'>
```",still class like class class,issue,negative,neutral,neutral,neutral,neutral,neutral
719539789,"Hello @madhavajay

I would like to work on this issue if it is still open. 

Also, I would like a bit of further clarity on this issue so I would ping you up on Slack for the purpose.",hello would like work issue still open also would like bit clarity issue would ping slack purpose,issue,positive,neutral,neutral,neutral,neutral,neutral
719526430,"Hello @madhavajay 

I would like to work on this issue if it is still open. This would be my first contribution towards OpenMined, and I would like to take it up and complete it as soon as possible for me.",hello would like work issue still open would first contribution towards would like take complete soon possible,issue,positive,positive,neutral,neutral,positive,positive
719416724,"Hey @madhavajay,

Thank you so much for the lovely feedback! I'm super excited to work on other stuff as well.

Regarding the testing on torch 1.7.0. that's where I did my testing and I think everything was passing normally,
The reason I added the bool as ignored, is because I don't think it makes sense (as in mathematically) to ask for the angle of a boolean.

As for the GPU testing, I'll check out how it can be GPU tested and can try it out myself, since I'm a bit of a PyTorch noob. 

Let me know your thoughts. Again super excited to work on some other stuff with all you guys!",hey thank much lovely feedback super excited work stuff well regarding testing torch testing think everything passing normally reason added bool think sense mathematically ask angle testing check tested try since bit let know super excited work stuff,issue,positive,positive,positive,positive,positive,positive
719403484,"@LaRiffle I know we discussed yesterday about this behavior.

We throw an exception if:
- float_tensor (+|-|*|/) fix_prec_tensor
- fix_prec_tensor (+|-|*|/) float_tensor

This was the conclusion, right?",know yesterday behavior throw exception conclusion right,issue,negative,positive,positive,positive,positive,positive
719030865,"This is happening with any and all classes where the fqn changes depending on import context, so we need something more permanently corrective.",happening class depending import context need something permanently corrective,issue,negative,neutral,neutral,neutral,neutral,neutral
719024130,"@PlamenHristov awesome! 👍 ❤️ Thanks so much for the PR.
We have added torch==1.7.0 to the syft_0.3.0 branch CI so its worth keeping that in mind now.
What I like to do is test it for the latest version and then check some of the older versions locally or in CI.

If you have the project setup in a virtualenv you can use the scripts/compatibility_report.sh to automatically test every single torch version.

Its configured for pipenv, but if you know another way to detect virtualenvs an update would be cool. Otherwise you can disable the check while using it.

I usually disable all the allowlist entries im not testing so that its faster and then do about 10-20 at a time and look at the results.

At the moment i'm thinking its a good idea to include an lte_version upper bound on any not_available rules so that if a future version of torch supports something we will test it automatically.

I actually need to go through the existing lte_version 1.6.0 not available rules and re-run them on 1.7.0. Currently I just bumped the 1.6.0 string to 1.7.0 so that it skips those tests on 1.7.0 torch as well because I wanted to quickly make sure nothing obvious breaks with 1.7.0, but my guess is some of the previously not supported op / dtype combos will be added and weirdly occasionally sometimes it seems they also get dropped.

Also note, this is all for CPU, so we really need a separate GPU datatype test but thats something I will look into in a few weeks.

For now, I think if you can add the lte_version ""1.6.0"" to the bool not_available rule that should do it.
Then it might fail on 1.7.0 and we can fix it if thats the case, or feel free to install 1.7.0 and test it now.

Thank you again for the PR and I look forwards to seeing more allowlist fixes from you. 😊",awesome thanks much added branch worth keeping mind like test latest version check older locally project setup use automatically test every single torch version know another way detect update would cool otherwise disable check usually disable testing faster time look moment thinking good idea include upper bound future version torch something test automatically actually need go available currently string torch well quickly make sure nothing obvious guess previously added weirdly occasionally sometimes also get also note really need separate test thats something look think add bool rule might fail fix thats case feel free install test thank look forward seeing,issue,positive,positive,positive,positive,positive,positive
718595257,"> @gmuraru
> 
> ```
> self = (Wrapper)>AutogradTensor>[PointerTensor | me:61309067411 -> alice:45981611550]
> inplace = False, user = None, reason = '', args = ()
> kwargs = {'get_copy': True}
> 
>     def get(self, *args, inplace: bool = False, user=None, reason: str = """", **kwargs):
>         """"""Requests the tensor/chain being pointed to, be serialized and return
>         Args:
>             args: args to forward to worker
>             inplace: if true, return the same object instance, else a new wrapper
>             kwargs: kwargs to forward to worker
>         Raises:
>             GetNotPermittedError: Raised if get is not permitted on this tensor
>         """"""
>     
>         # If it is a local tensor/chain, we don't need to verify permissions
>         if not isinstance(self.child, syft.PointerTensor):
> >           tensor = self.child.get(*args, **kwargs)
> E           TypeError: get() got an unexpected keyword argument 'get_copy'
> ```
> 
> `tensor = self.child.get(*args, **kwargs)
> E TypeError: get() got an unexpected keyword argument 'get_copy'
> 
> `
> is child here not a pysyft tensor? seems like this get function is different!

You should add an ```import pdb; pdb.set_trace()``` and check what that tensor is.
What I think is happening is that we did not update all the ""get"" methods",self wrapper false user none reason true get self bool false reason pointed return forward worker true return object instance else new wrapper forward worker raised get permitted tensor local need verify tensor get got unexpected argument tensor get got unexpected argument child tensor like get function different add import check tensor think happening update get,issue,negative,positive,neutral,neutral,positive,positive
718593989,"One of the errors is this:
```
File ""/home/runner/work/PySyft/PySyft/syft/workers/message_handler.py"", line 212, in handle_force_delete_object_msg
    for object_id in msg.object_ids:
TypeError: 'int' object is not iterable
```

You should check why the ```msg.object_ids``` becomes and integer, it should be a list or set probably",one file line object iterable check becomes integer list set probably,issue,negative,neutral,neutral,neutral,neutral,neutral
718586180,"Hi @xutongye , I've started to work on this now. Will need a few days. I'll let you know if I cannot finish it.",hi work need day let know finish,issue,negative,neutral,neutral,neutral,neutral,neutral
718551254, I would like to fix this if still available,would like fix still available,issue,negative,positive,positive,positive,positive,positive
718291819,"@ViveK-PothinA, sorry I needed this done because of some errors we are trying to track down so I went ahead and implemented it.

https://github.com/OpenMined/PySyft/pull/4748",sorry done trying track went ahead,issue,negative,negative,negative,negative,negative,negative
718237700,"Another similar one:
```
Task exception was never retrieved
future: <Task finished name='Task-47763' coro=<RTCSctpTransport._transmit() done, defined at /Users/madhavajay/.local/share/virtualenvs/PySyft-lHlz_cKe/lib/python3.8/site-packages/aiortc/rtcsctptransport.py:1505> exception=ConnectionError('Cannot send encrypted data, not connected')>
Traceback (most recent call last):
  File ""/usr/local/opt/python@3.8/Frameworks/Python.framework/Versions/3.8/lib/python3.8/asyncio/tasks.py"", line 280, in __step
    result = coro.send(None)
  File ""/Users/madhavajay/.local/share/virtualenvs/PySyft-lHlz_cKe/lib/python3.8/site-packages/aiortc/rtcsctptransport.py"", line 1539, in _transmit
    await self._send_chunk(chunk)
  File ""/Users/madhavajay/.local/share/virtualenvs/PySyft-lHlz_cKe/lib/python3.8/site-packages/aiortc/rtcsctptransport.py"", line 1339, in _send_chunk
    await self.__transport._send_data(
  File ""/Users/madhavajay/.local/share/virtualenvs/PySyft-lHlz_cKe/lib/python3.8/site-packages/aiortc/rtcdtlstransport.py"", line 655, in _send_data
    raise ConnectionError(""Cannot send encrypted data, not connected"")
ConnectionError: Cannot send encrypted data, not connected
```",another similar one task exception never future task finished done defined send data connected recent call last file line result none file line await chunk file line await file line raise send data connected send data connected,issue,negative,neutral,neutral,neutral,neutral,neutral
717203572,It's going slowly I tried to fix it using warning library but not worked.Now I am trying to solve it @madhavajay ,going slowly tried fix warning library trying solve,issue,negative,negative,negative,negative,negative,negative
717146316,"@aanurraj I made some changes here: https://github.com/OpenMined/PySyft/pull/4722

If you want you can merge / cherry pick or we can continue to iterate on it via that shared branch.",made want merge cherry pick continue iterate via branch,issue,negative,neutral,neutral,neutral,neutral,neutral
716466314,"Once PR #4697 gets approved and merged, could you please try and see if the issue got resolved for websockets as well? ",could please try see issue got resolved well,issue,positive,neutral,neutral,neutral,neutral,neutral
716257134,"@vvmnnnkv I think you are correct here, we definitely don't want the tests to be 2x slower, and the fact that its passing the whole version matrix is a good sign that we can probably leave this off for now. Previously we had separate tests that shared mostly the same code but by having a single test this allows us to be much more confident they perform identically as expected.",think correct definitely want fact passing whole version matrix good sign probably leave previously separate mostly code single test u much confident perform identically,issue,positive,positive,positive,positive,positive,positive
716228251,"Sorry @AkashM398, I forgot to label this 0.3 in the original issue. Can you please branch from syft_0.3.0 and update the contribution guide for that branch? It probably needs to be a combination of the original master guide with some updates and new bits for the 0.3.0 branch.",sorry forgot label original issue please branch update contribution guide branch probably need combination original master guide new branch,issue,positive,positive,neutral,neutral,positive,positive
716228052,"Sorry, I think I forgot the 0.3 label on this task... 😬",sorry think forgot label task,issue,negative,negative,negative,negative,negative,negative
716175959,"Hmm, do you mean something like in #4707?
(The ""self"" tensor is made Parameter)
I'm not sure it makes a lot of sense to test every method (and make unit tests slower) because Parameter is pretty much same thing as Tensor",mean something like self tensor made parameter sure lot sense test every method make unit parameter pretty much thing tensor,issue,positive,positive,positive,positive,positive,positive
716036069,"> I suppose the problem you mentioned may arise when working with distributed machines instead of local ones?

Yeah, I believe so as well. With virtual workers things are working pretty much as expected.",suppose problem may arise working distributed instead local yeah believe well virtual working pretty much,issue,positive,positive,positive,positive,positive,positive
715877852,Is there any other way to bypass the problem by using some alternative method than **move()**,way bypass problem alternative method move,issue,negative,neutral,neutral,neutral,neutral,neutral
715507040,"I m facing this issue in version 0.2.4 ... is it fixed now
",facing issue version fixed,issue,negative,positive,neutral,neutral,positive,positive
715440434,"Hey @LaRiffle @gmuraru @omershlo @Nilanshrajput, 
I incorporated your feedback and added the code, the first version should be completed now. 
For now, I've decided to compare the training of different simple models on the Cifar10 dataset and compare performance in terms of accuracy and speed on a very small test-set. (otherwise, it takes to long on my laptop)
I created it to also serve as a sort of sandbox to create try out different models, computations, loss functions, optimizers for different developers. One final thing I planned to add is the local training to have a certain benchmark against which to compare. 

Would be nice if you could give me some feedback on the approach, structure, comprehensibility, and correctness. Also, feel free to suggest or request some features you'd like to have in the notebook. 👍 ",hey incorporated feedback added code first version decided compare training different simple compare performance accuracy speed small otherwise long also serve sort sandbox create try different loss different one final thing add local training certain compare would nice could give feedback approach structure comprehensibility correctness also feel free suggest request like notebook,issue,positive,positive,neutral,neutral,positive,positive
715393486,"@madhavajay Anyone is working on this currently? 
I see it has a critical status, should it be completed before November 11th?",anyone working currently see critical status th,issue,negative,neutral,neutral,neutral,neutral,neutral
715351418,You can both work on it - maybe coordinate such that one takes some files and the other person takes some other files (you can always use the OpenMined slack for that :D ),work maybe one person always use slack,issue,negative,neutral,neutral,neutral,neutral,neutral
714828097,"@madhavajay I was not able to make progress on this, we can assign it somone.",able make progress assign,issue,negative,positive,positive,positive,positive,positive
714709767,"@madhavajay could we merge this? (this might impose security issues because it bypasses the ""request"" --> ""approve"" formula)",could merge might impose security request approve formula,issue,negative,neutral,neutral,neutral,neutral,neutral
714528791,"The GC is already in the syft_0.3.0 branch.

This ticket addresses the problem when we do
```
ptr = x.send(alice)
ptr = x.send(alice)
```",already branch ticket problem,issue,negative,neutral,neutral,neutral,neutral,neutral
714449537,"> @aanurraj wasn't this done (also in syft_0.3.0)?

No Tudor said he will come up with a plan, I am waiting for it.",done also said come plan waiting,issue,negative,neutral,neutral,neutral,neutral,neutral
714423513,@arturomf94 I think this is done. Could we close this?,think done could close,issue,negative,neutral,neutral,neutral,neutral,neutral
714352723,"Sure! Please ping me on slack @Théo Ryffel whenever the PRs are ready :) 
@aksh-02 @Bhuvan-21 ",sure please ping slack whenever ready,issue,positive,positive,positive,positive,positive,positive
714330512,This was blocked by the broken allowlist slow tests so it should be good to merge now.,blocked broken slow good merge,issue,negative,negative,neutral,neutral,negative,negative
714330243,This is already covered by another commit so we can close or merge either way.,already covered another commit close merge either way,issue,negative,neutral,neutral,neutral,neutral,neutral
714328068,I'm going to open a Pull Request with the new changes shortly,going open pull request new shortly,issue,negative,positive,neutral,neutral,positive,positive
714311042,"This is essentially done, the remaining related tasks are being triaged through the GitHub Kanban board.",essentially done related board,issue,negative,neutral,neutral,neutral,neutral,neutral
714281666,"So, I just cloned the latest version of PySyft and ran it all locally on an Ubuntu Virtual Machine from my local Windows. I then proceeded to start the websockets locally, and ran the example ""Federated Recurrent Neural Network"".

The only thing I changed was removed any reference to ""device"", which in my case led to a lot of problems, as I don't have CUDA installed. So I made the following changes:

```
#device = torch.device(""cuda"" if args.use_cuda else ""cpu"")
model = RNN(n_letters, n_hidden, n_categories)#.to(device)
```

And from:
```
    line_reshaped, category_single = line_reshaped.to(device), category_single.to(device)
```

to:

```
line_reshaped, category_single = line_reshaped, category_single
```

Then, everything went well, and the training went just fine. I suppose the problem you mentioned may arise when working with distributed machines instead of local ones? That's kinda weird though: from my experience, if something worked on local websockets, it worked on remote websockets just as well. 



![image](https://user-images.githubusercontent.com/4907418/96837052-1b1bb900-1446-11eb-941d-16480933e3d7.png)
",latest version ran locally virtual machine local start locally ran example recurrent neural network thing removed reference device case led lot made following device else model device device device everything went well training went fine suppose problem may arise working distributed instead local weird though experience something worked local worked remote well image,issue,negative,positive,neutral,neutral,positive,positive
713671419,"@madhavajay , cool I would like to give it a try for next couple of days, if I do not make progress we can handover it to someone, does that work ?",cool would like give try next couple day make progress someone work,issue,positive,positive,positive,positive,positive,positive
713502940,"Can confirm this bug exists. I am not using any tutorial. Just created a hook and then tried to import datasets from torchvision and I got the same error.

The hack I am using right now is to do torchvision stuff first and then create a hook.",confirm bug tutorial hook tried import got error hack right stuff first create hook,issue,negative,positive,positive,positive,positive,positive
713501328,"Ah okay, I dont think I tried that version. I will try and see if it works. But I guess folks over at slack are recommending to use grid now.",ah dont think tried version try see work guess slack use grid,issue,negative,neutral,neutral,neutral,neutral,neutral
713471742,"Yeah, between August 2019 and 2017 there  don't seem to be any versions tracked. The most similar version could be: 0.1.23a though https://github.com/OpenMined/PySyft/releases/tag/0.1.23a dating back to August 2019. From what I remember, this version was working with my example",yeah august seem tracked similar version could though dating back august remember version working example,issue,negative,neutral,neutral,neutral,neutral,neutral
713467450,"> Yeah, that's indeed the problem I noticed as well... I will try to see if I managed replicate the problem on my end with this example. Are you sure you're using exactly the same PySyft build version on both web workers? Did you try not to use conda, and building PySyft from source instead?

I am not using v1.19a1 or rather I can't. When I search for tagged releases, I get results from hydrogen and onwards, there is no v1.19a1. I did use hydrogen release though and made sure that all my systems were using the same version but that did not help either. I did not try to build it from source. I might give that a shot!",yeah indeed problem well try see replicate problem end example sure exactly build version web try use building source instead rather ca search tagged get hydrogen onwards use hydrogen release though made sure version help either try build source might give shot,issue,positive,positive,positive,positive,positive,positive
713423785,"@gmuraru 
```
self = (Wrapper)>AutogradTensor>[PointerTensor | me:61309067411 -> alice:45981611550]
inplace = False, user = None, reason = '', args = ()
kwargs = {'get_copy': True}

    def get(self, *args, inplace: bool = False, user=None, reason: str = """", **kwargs):
        """"""Requests the tensor/chain being pointed to, be serialized and return
        Args:
            args: args to forward to worker
            inplace: if true, return the same object instance, else a new wrapper
            kwargs: kwargs to forward to worker
        Raises:
            GetNotPermittedError: Raised if get is not permitted on this tensor
        """"""
    
        # If it is a local tensor/chain, we don't need to verify permissions
        if not isinstance(self.child, syft.PointerTensor):
>           tensor = self.child.get(*args, **kwargs)
E           TypeError: get() got an unexpected keyword argument 'get_copy'
```

`tensor = self.child.get(*args, **kwargs)
E           TypeError: get() got an unexpected keyword argument 'get_copy'

`
is child here not a pysyft tensor? seems like this get function is different!",self wrapper false user none reason true get self bool false reason pointed return forward worker true return object instance else new wrapper forward worker raised get permitted tensor local need verify tensor get got unexpected argument tensor get got unexpected argument child tensor like get function different,issue,negative,positive,neutral,neutral,positive,positive
713288448,"If this is open, I would like to work on it. I'll try to integrate with loguru.",open would like work try integrate,issue,negative,neutral,neutral,neutral,neutral,neutral
713037329,Good point - progress could start before MNIST is done.,good point progress could start done,issue,positive,positive,positive,positive,positive,positive
712984071,@ViveK-PothinA  I'm actively working on it. I would let you know if unable to proceed.,actively working would let know unable proceed,issue,negative,negative,negative,negative,negative,negative
712958924,"Hello, @AnshuTrivedi @gmuraru , if this issue is available, can I pick it up?",hello issue available pick,issue,negative,positive,positive,positive,positive,positive
712847110,"After this PR merge, there should be no assert statements in master branch. Maybe we can add the `bandit` flag on `assert` and close this issue.",merge assert master branch maybe add bandit flag assert close issue,issue,negative,neutral,neutral,neutral,neutral,neutral
712642940,"> Hi @DanyEle, no, with virtualworkers most of the stuff runs as expected. The problem starts to occur when PySyft is being used in a pseudo realistic/realistic setup.

Yeah, that's indeed the problem I noticed as well... I will try to see if I managed replicate the problem on my end with this example. Are you sure you're using exactly the same PySyft build version on both web workers? Did you try not to use conda, and building PySyft from source instead?",hi stuff problem occur used pseudo setup yeah indeed problem well try see replicate problem end example sure exactly build version web try use building source instead,issue,negative,positive,positive,positive,positive,positive
712641867,"Uhm, I was trying to merge the OpenMined HEAD on my local fork. I guess something must have gone wrong haha. Yes, let's close it. ",trying merge head local fork guess something must gone wrong yes let close,issue,negative,negative,negative,negative,negative,negative
712524017,"Part of this PR will be to trim down the target support for complex, qint and 1.4.0 to be discussed as separate tickets and features at a later date.",part trim target support complex separate later date,issue,negative,negative,negative,negative,negative,negative
712495910,"@rajathpatel23 Yes, this is for 0.3 but contributions are welcome. If you checkout syft_0.3.0 and then branch from there and make this change that would be amazing. Just a note, the ""slow"" tests are currently failing on the 0.3.0 branch which i am fixing now in another PR, so don't be surprised if that happens. This task only applies to the fast tests.

Also this might not be the easiest task for starting on the 0.3 code base, so sorry if I labelled it that way, its hard to know if the work has been done yet or it's just still left off. Feel free to try or if you don't want to thats also okay. 😊

If you have any questions just write them here or ping me on slack and I can try to help.",yes welcome branch make change would amazing note slow currently failing branch fixing another task fast also might easiest task starting code base sorry way hard know work done yet still left feel free try want thats also write ping slack try help,issue,positive,positive,neutral,neutral,positive,positive
712108815,"Hi @DanyEle, no, with virtualworkers most of the stuff runs as expected. The problem starts to occur when PySyft is being used in a pseudo realistic/realistic setup.",hi stuff problem occur used pseudo setup,issue,negative,neutral,neutral,neutral,neutral,neutral
711439800,"@gmuraru @LaRiffle For instance, here is my setup running Pygrid.  Model is on machine A, it's acting as grid node, node id 'alice' and also as grid network. Data is already present on machine B, acting as grid node, node id 'bob'. The data on machine B has been tagged. Now, if I leave it as it is and then search on the network, I don't get any results. However, if I send the data to bob, node id for the same machine where the data resides, then I get results! Am I missing something here?",instance setup running model machine acting grid node node id also grid network data already present machine acting grid node node id data machine tagged leave search network get however send data bob node id machine data get missing something,issue,negative,negative,neutral,neutral,negative,negative
711419770,"Got it to work, I was using Network instead of Node app from PyGrid. Thanks @gmuraru anyway! ",got work network instead node thanks anyway,issue,negative,positive,positive,positive,positive,positive
711357036,"Any help still needed on this @gmuraru @tudorcebere @madhavajay ?

Is support to `String` and `StringPointer` done @gmuraru ?",help still support string done,issue,positive,neutral,neutral,neutral,neutral,neutral
711149206,if you try to install websockets with pip install what version it installs?,try install pip install version,issue,negative,neutral,neutral,neutral,neutral,neutral
711131890,"Hi, just wondering: do you get this error also when replacing the Web Workers with local ""dummy"" Virtual Workers? 


FYI: The PySyft version I was using in the tutorial linked https://blog.openmined.org/federated-learning-of-a-rnn-on-raspberry-pis/, was v0.1.19A1",hi wondering get error also web local dummy virtual version tutorial linked,issue,negative,neutral,neutral,neutral,neutral,neutral
711053465,"@Boluwatifeh 
python setup.py install

`error: Could not find suitable distribution for Requirement.parse('websockets~=8.1.0')`",python install error could find suitable distribution,issue,negative,positive,positive,positive,positive,positive
711047351,"work is done! thanks, @ramesht007 closing the issue ",work done thanks issue,issue,negative,positive,positive,positive,positive,positive
711041061,"> Really love this, looking forward to see it merged! Congrats for your first PR @ PySyft!

Thanks @tudorcebere , my first PR in open source world 😬 , hopefully will do more going forward.",really love looking forward see first thanks first open source world hopefully going forward,issue,positive,positive,positive,positive,positive,positive
711040242,"> `pip install syft==0.2.0a2` worked for me.
> 
> see [OpenMined/PySyft-TensorFlow#43 (comment)](https://github.com/OpenMined/PySyft-TensorFlow/issues/43#issuecomment-631465354)

This kinda works for me, but I still get the warning below:

WARNING:tensorflow:From /usr/local/anaconda3/envs/pysyft/lib/python3.7/site-packages/tf_encrypted/session.py:24: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

At least kernel does not die after importing syft",pip install worked see comment work still get warning warning name please use instead least kernel die,issue,negative,negative,negative,negative,negative,negative
710770199,"Really love this, looking forward to see it merged! Congrats for your first PR @ PySyft! ",really love looking forward see first,issue,positive,positive,positive,positive,positive,positive
710763412,"@gmuraru i am facing difficulty in setting environment where stuck with two versions of pip. 
Thank you , i will ask problem in slack community.",facing difficulty setting environment stuck two pip thank ask problem slack community,issue,negative,neutral,neutral,neutral,neutral,neutral
710756192,@LaRiffle I would like to give it a try too.,would like give try,issue,negative,neutral,neutral,neutral,neutral,neutral
710679428,"Sure! Sorry :(, I do not know how I missed this notification. You can also ping me on the slack channel.",sure sorry know notification also ping slack channel,issue,negative,neutral,neutral,neutral,neutral,neutral
710310458,"Hello @aanurraj, @LaRiffle, I ran the code mentioned in the blog on Google Colab and ran into the following issue
```
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-10-c04e515dbba4> in <module>()
     40 print(""$%%@*E^*@#^@&(#^@*@"")
     41 for epoch in range(5):
---> 42     train(epoch, delta=1e-5)

6 frames
/usr/local/lib/python3.6/dist-packages/opacus/per_sample_gradient_clip.py in <genexpr>(.0)
    260             (n, p.grad_sample)  # pyre-ignore[16]
    261             for n, p in self.module.named_parameters()
--> 262             if p.requires_grad
    263         )
    264 

AttributeError: 'Parameter' object has no attribute 'grad_sample'
```

On the first glance, it seems like this is because privacy related attributes are not available to the `local_model` as the privacy engine is not attached to that model.

Could you please verify if the code on the blog still works? If yes, step are we missing?

Thanks.",hello ran code ran following issue recent call last module print epoch range train epoch object attribute first glance like privacy related available privacy engine attached model could please verify code still work yes step missing thanks,issue,positive,positive,neutral,neutral,positive,positive
710230265,"Hi, Is this issue still being worked on?

Thanks",hi issue still worked thanks,issue,negative,positive,positive,positive,positive,positive
710219115,Re-opened this. Will try to look into it. @ProfXGiter do you run using the latest pysyft version?,try look run latest version,issue,negative,positive,positive,positive,positive,positive
710215148,Did you get any solution to this problem? I am also facing similar problem and it looks like all reported issues similar to this one have gone stale!,get solution problem also facing similar problem like similar one gone stale,issue,negative,negative,negative,negative,negative,negative
710212336,This bug is still present unfortunately.,bug still present unfortunately,issue,negative,negative,negative,negative,negative,negative
709850700,"will love to see if this should be solved inside pygrid or pysyft... or if a fix should be applied to both sides... just wondering what is the correct way to handle this.

Also 

> list_objects_remote() should throw an error if allowed user/key is not provided.

I was wondering what this means... @xanderwallace85 could you provide an example on how to pass that ""allowed user key""?

Anyway, waiting for the extra feedback to make a proposal.",love see inside fix applied side wondering correct way handle also throw error provided wondering could provide example pas user key anyway waiting extra feedback make proposal,issue,negative,positive,positive,positive,positive,positive
709384821,@AnshuTrivedi hey! How is the work going on this issue? If you need any help you can ping me in the OpenMined slack channel :100: ,hey work going issue need help ping slack channel,issue,negative,neutral,neutral,neutral,neutral,neutral
708448950,The issue I think is that CrypTen is not supported on Windows. You might get away with it by removing crypten from the requirements file.,issue think might get away removing file,issue,negative,neutral,neutral,neutral,neutral,neutral
708428842,"Hey ! this is a crypten error
Maybe related to https://github.com/SsnL/dataset-distillation/issues/12
please check the crypten repo for more details :) 
https://github.com/facebookresearch/CrypTen",hey error maybe related please check,issue,negative,neutral,neutral,neutral,neutral,neutral
708376744,"not necessarily, there might be stuff to adapt, but give it a try! :) ",necessarily might stuff adapt give try,issue,negative,neutral,neutral,neutral,neutral,neutral
708306130,"Hi, i have done the changes 
Please have a look
",hi done please look,issue,negative,neutral,neutral,neutral,neutral,neutral
708299599,yeah I am taking a look will get back to you @Bhuvan-21 ,yeah taking look get back,issue,negative,neutral,neutral,neutral,neutral,neutral
708288061,"Hey, can any reviewer check the test results and let me know what is wrong now?
I fixed the lint issues using black",hey reviewer check test let know wrong fixed lint black,issue,negative,negative,negative,negative,negative,negative
708207966,"Hey, you should run `black` and `flake8` to fix the lint issues

Here is what the test suite does:
https://github.com/OpenMined/PySyft/blob/master/.github/workflows/tests.yml#L56",hey run black flake fix lint test suite,issue,negative,negative,negative,negative,negative,negative
708174897,"Hi @ViveK-PothinA , have you started working on this? I will need a few days before I can begin",hi working need day begin,issue,negative,neutral,neutral,neutral,neutral,neutral
708008570,Hey - This is available. Maybe @duggalsu you can sync with @ViveK-PothinA to work on it? :100: ,hey available maybe sync work,issue,negative,positive,positive,positive,positive,positive
707956811,"Yeah, I saw the details of the failed test.
It's because I used spaces in get_copy = True which should have been get_copy=True.
I will fix them and make a new PR once the Tutorials test is done.
",yeah saw test used true fix make new test done,issue,positive,positive,positive,positive,positive,positive
707790099,"Can I work on this?
Is the code you provided the only thing to be changed?
",work code provided thing,issue,negative,neutral,neutral,neutral,neutral,neutral
707720018,"Thank you for your help. My current Pysyft is 0.2.8 and 0.2.7(in two different computers). I run the codes in examples/tutorials/Part 06 for 100 epoch. There is no phenomenon that the epoch time keeps increasing(about 100s one epoch). Probably, there are some bugs in my own codes. I'll try to figure out it.",thank help current two different run epoch phenomenon epoch time increasing one epoch probably try figure,issue,positive,neutral,neutral,neutral,neutral,neutral
707713384,"Ah ok! 
Have you monitored memory usage to check if the RAM gets filled? We had in the past issues with memory leakage, it might be linked maybe
",ah memory usage check ram filled past memory leakage might linked maybe,issue,negative,positive,neutral,neutral,positive,positive
707653572,"It's not the demo in Pysyft example. It's my own codes and I write my own dataloader and training process. I train AlexNet in Cifar10 with 10 workers, but with other model and dataset there are also similar situation. Computer metrics: GPU: 2080Ti,  CPU: 16  Intel(R) Xeon(R) CPU E5-2620 v4 @ 2.10GHz, RAM: 32GB.
Is there any suggestion to solve or find out the problem in my codes?",example write training process train model also similar situation computer metric ti ram suggestion solve find problem,issue,negative,neutral,neutral,neutral,neutral,neutral
707609557,"@Bhuvan-21  go for it!! 
replace from every place in tutorials also. (tip: do a global search through your editor in PySyft)",go replace every place also tip global search editor,issue,negative,neutral,neutral,neutral,neutral,neutral
707572263,Took a quick look over it and left some comments! Need to read more and will come back with more feedback :D,took quick look left need read come back feedback,issue,negative,positive,positive,positive,positive,positive
707532275,"Hey, on which code demo?
what does your computer metrics say? (RAM, cpu, etc?)
You probably have a RAM issue?",hey code computer metric say ram probably ram issue,issue,negative,neutral,neutral,neutral,neutral,neutral
707436981,Yes I changed branch to swaft-0.3 and it's done to replicate in my local system.,yes branch done replicate local system,issue,negative,neutral,neutral,neutral,neutral,neutral
707412851,"@sparkingdark on the latest syft_0.3.0 branch I did the following:
```
$ pip install sphinx_rtd_theme
$ python setup.py docs
```

Two issues:
- 1 the doc generation is paused as the code crawling accidentally launches a flask server
We should stop this happening, in the mean time hit Control + C to quit it
- 2 after running there are a lot of errors and warnings:
```bash
copying extra files... done
dumping search index in English (code: en)... done
dumping object inventory... done
build succeeded, 116 warnings.
```

Are you able to replicate these issues on your end?",latest branch following pip install python two doc generation code crawling accidentally flask server stop happening mean time hit control quit running lot bash extra done dumping search index code en done dumping object inventory done build able replicate end,issue,negative,positive,positive,positive,positive,positive
707205040,Hey @madhavajay can you give me the instruction to produce the problem scenario I run the `python setup.py docs` but get no option.,hey give instruction produce problem scenario run python get option,issue,negative,neutral,neutral,neutral,neutral,neutral
706985214,"> Any update @Doodlera?

By the way,I used to find the same problem in 0.2.7. I change the release to 0.2.6 and avoid it.",update way used find problem change release avoid,issue,negative,neutral,neutral,neutral,neutral,neutral
706940351,"I have added some default permissions in a previous PR (I forgot about request) and this PR removes them.

python_remote.random() <-- I had access to this - but the proper way (I think) is to use ```request```",added default previous forgot request access proper way think use request,issue,negative,negative,neutral,neutral,negative,negative
706841154,I am on but I need some time as I have some other issues to solve as well.,need time solve well,issue,negative,neutral,neutral,neutral,neutral,neutral
706835260,@LaRiffle Could you please give a demo? Thank you very much!,could please give thank much,issue,positive,positive,positive,positive,positive,positive
706834951,The trainconfig seed to be removed in pysyft 0.2.6. I am not sure whether there is a replace method in pysyft 0.2.9.,seed removed sure whether replace method,issue,negative,positive,positive,positive,positive,positive
706831972,The contents of this PR has already been merged under a separate branch.,content already separate branch,issue,negative,neutral,neutral,neutral,neutral,neutral
706831644,I will close this PR for the time being as the majority of the changes are either integrated already or not required.,close time majority either already,issue,negative,neutral,neutral,neutral,neutral,neutral
706824691,The generic CWrapper / ShadowWrapper approach is no longer being used so this PR can be closed for now.,generic approach longer used closed,issue,negative,negative,neutral,neutral,negative,negative
706824114,"@imskr and @sparkingdark if either of you are able to do this task that would be amazing! ❤️ Please let me know who still wants it first and i'll assign it. As @iamtrask is super busy, I will be helping with the 0.3 task management and going through the remaining backlog of tasks needed for the 0.3 release.

There will be a lot more issues like this and I would love any help on offer.",either able task would amazing please let know still first assign super busy helping task management going backlog release lot like would love help offer,issue,positive,positive,positive,positive,positive,positive
706822486,"@shubham3121 I have updated this and created a new PR here, just because I can't push to your fork:
https://github.com/OpenMined/PySyft/pull/4638",new ca push fork,issue,negative,positive,positive,positive,positive,positive
706819653,"@gmuraru I think maybe we can do this type of thing as discussed on Slack:
https://github.com/OpenMined/PySyft/pull/4637

Then maybe we can just close this for now and re-discuss in future if theres a desire to go down this path again?",think maybe type thing slack maybe close future there desire go path,issue,negative,neutral,neutral,neutral,neutral,neutral
706817452,@gmuraru Do you remember what this PR was about? I'm just getting my brain back online after the break.,remember getting brain back break,issue,negative,neutral,neutral,neutral,neutral,neutral
706721136,@sssilvar if open wanna work,open wan na work,issue,negative,negative,neutral,neutral,negative,negative
706720687,"@iamtrask I want to work on it to fix all the warnings,assign it to me.",want work fix assign,issue,negative,neutral,neutral,neutral,neutral,neutral
706720488,Is it open to fix then I want to give a try,open fix want give try,issue,negative,neutral,neutral,neutral,neutral,neutral
706626287,"Hi there @LaRiffle, Im a little stuck, so I ask here:

* Should I modify the handler route on PyGrid? because I think it is an error on PyGrid (its just return the text description of the search)?.

**Because**  `.get()` is an added method over torch tensor because it is implemented in `TorchTensor(AbstractTensor)` so it check if it is a .child and raises the error... but I think the printed tensor is a string... which is the results directly from PyGrid, so I think the problem is with PyGrid not checking this and returning the __str__ of all tensors even the private ones... I dont mind checking PyGrid, at less it seems that it is handled with `@data_centric_routes.route(""/search"", methods=[""POST""])` on https://github.com/OpenMined/PyGrid/blob/1e9512e2801c3756cf0ceeebdaceaa8395b76d1b/apps/node/src/app/main/routes/data_centric/routes.py#L253 (but dont know how do change code inside docker-up thing... wonder if you people have some hints?/tutorials)


**I have found that**

This clients connect to a PyGrid via `DataCentricFLClient(WebsocketClientWorker) and they send the request with `_send_msg_and_deserialize`.  But the search for mytag is done inside `PublicGridNetwork(AbstractGrid)#search` then for each found federated worker/client it calls its ""search""... so yeah the answer already have a string containing at less the size of the private tensor (still is not a real tensor).

![image](https://user-images.githubusercontent.com/506234/95666840-65866700-0b23-11eb-87db-0a29bbb7b8c9.png)
",hi little stuck ask modify handler route think error return text description search added method torch tensor check error think printed tensor string directly think problem even private dont mind le handled post dont know change code inside thing wonder people found connect via send request search done inside search found search yeah answer already string le size private tensor still real tensor image,issue,negative,positive,neutral,neutral,positive,positive
706542881,"Hey @LaRiffle @gmuraru @somiljain7,
I started with creating a notebook outline and a first version of high level explanations of the different protocols. 
The idea was that even people who don't understand how exactly the SMPC-encryption works can still get a high level grasp of what it does and especially what kind of models they can train and infer on using the different encryption. 

As mentioned in my PR it would be nice if you could quickly give quick feedback on whether the outline makes sense (does what I did so far correspond with what you had in mind?) and whether the content is correct and understandable. I marked parts of the content where I'm not 100% sure red (I'm also new to the protocols) so those are especially important.  

Next steps would be do to the implementations and incorporate feedback/improve understandability, etc. 👍 ",hey notebook outline first version high level different idea even people understand exactly work still get high level grasp especially kind train infer different encryption would nice could quickly give quick feedback whether outline sense far correspond mind whether content correct understandable marked content sure red also new especially important next would incorporate understandability,issue,positive,positive,positive,positive,positive,positive
706525706,"> @gmuraru I will remove `copy().get()` in other PR (I will create an issue for that now) this one's little urgent for syfertext

Yep - there was also a stale PR that was opened before - but I think there was no review for it :\",remove copy create issue one little urgent yep also stale think review,issue,positive,negative,negative,negative,negative,negative
706524287,@gmuraru  I will remove `copy().get()` in other PR (I will create an issue for that now) this one's little urgent for syfertext,remove copy create issue one little urgent,issue,negative,negative,negative,negative,negative,negative
706523099,"I solved one of the test failings but for this `test_serde_roundtrip_protobuf` i will have to update syft-proto 
```
@staticmethod
    def bufferize(worker, msg):
        """"""
        This method serializes a ObjectRequestMessage using ObjectRequestMessagePB.

        Args:
            msg (ObjectRequestMessage): input ObjectRequestMessage to be serialized.

        Returns:
            proto_msg (ObjectRequestMessagePB): serialized ObjectRequestMessage.
        """"""
        proto_msg = ObjectRequestMessagePB()
        sy.serde.protobuf.proto.set_protobuf_id(proto_msg.object_id, msg.object_id)
        proto_msg.reason = msg.reason
        return proto_msg

````
And `ObjectRequestMessagePB() t`his is very complex I cant understand how its working, 
One solution is to pass default` False `here in return (`user` is also passed as default I think)
```
@staticmethod
    def unbufferize(worker, proto_msg):
        """"""
        This method deserializes ObjectRequestMessagePB into ObjectRequestMessage.

        Args:
            protobuf_msg (ObjectRequestMessagePB): input serialized ObjectRequestMessagePB.

        Returns:
           ObjectRequestMessage: deserialized ObjectRequestMessagePB.
        """"""
        obj_id = sy.serde.protobuf.proto.get_protobuf_id(proto_msg.object_id)
        # add worker support when it will be available
        return ObjectRequestMessage(obj_id=obj_id, user=None, reason=proto_msg.reason, get_copy=False)

```",one test update worker method input return complex cant understand working one solution pas default false return user also default think worker method input add worker support available return,issue,positive,negative,negative,negative,negative,negative
706321256,"LGTM! The TOKEN is from github actions app :D (it is not anymore a personal token).

Waiting for @LaRiffle to take a look, but I think we are good with the merge for this PR",token personal token waiting take look think good merge,issue,negative,positive,positive,positive,positive,positive
706312215,"> As suggested by @gmuraru, I made a change to the workflow so that:
> 
> 1. It uses the `GITHUB_TOKEN`.
> 2. It saves the benchmark results under `benchmarks/frameworks/torch/mpc/pytestbenchmark/`.
> 
> @aanurraj what do you think?

Everything looks good thanks :)",made change think everything good thanks,issue,positive,positive,positive,positive,positive,positive
706305668,"> Hi there again @xanderwallace85, I have setup this https://gist.github.com/tyoc213/a41db571f12a983812fa55ecdb93b951
> 
> In there, I call each node from 5000 to 5003 and assigned a tensor of size 1 is [1], 2 is [2,3], 3 is [4,5,6] and 4 is [7,8,9,10].
> 
> As you can see here
> ![image](https://user-images.githubusercontent.com/506234/95549332-b172c800-09cc-11eb-82fa-468fb439e0b6.png)
> 
> each node did receive the correct ""size"" for each one, then printed the `list_objects_remote` which for alice is
> 
> ![image](https://user-images.githubusercontent.com/506234/95549542-19c1a980-09cd-11eb-8ec3-1dbc79996f03.png)
> 
> And for dan is
> ![image](https://user-images.githubusercontent.com/506234/95549566-26460200-09cd-11eb-9f0a-28e46c77a81a.png)
> 
> Which I think is correct?
> 
> Inded with that code if I do `bob[0].get()`, `dan[0].get()`, `alice[0].get()`, `charlie[0].get()` I get exception error ` GetNotPermittedError:`, but I think the list_objects_remote are listening only what is on the node?
> 
> or to reproduce error..... where should I send the different data with which user permissions? I mean even changing
> 
> ![image](https://user-images.githubusercontent.com/506234/95550407-740f3a00-09ce-11eb-8322-dfc7267b96e5.png)
> 
> Seem to print same output as before
> 
> ![image](https://user-images.githubusercontent.com/506234/95550440-87220a00-09ce-11eb-9423-850e27b43ab6.png)
> 
> What Im missing to reproduce the error?

Hi @tyoc213 I think the point of private tensors is that you are not supposed to get/see the their content without authorisation (as for the get function).",hi setup call node assigned tensor size see image node receive correct size one printed image dan image think correct code bob dan get exception error think listening node reproduce error send different data user mean even image seem print output image missing reproduce error hi think point private supposed content without get function,issue,negative,negative,negative,negative,negative,negative
706043085,"Is this issue still available?
If not, you may wanna remove Status Available from this.
If available, I want to work on this.",issue still available may wan na remove status available available want work,issue,negative,positive,positive,positive,positive,positive
705995702,"Hi there again @xanderwallace85, I have setup this https://gist.github.com/tyoc213/a41db571f12a983812fa55ecdb93b951

In there, I call each node from 5000 to 5003 and assigned a tensor of size 1 is [1], 2 is [2,3], 3 is [4,5,6] and 4 is [7,8,9,10]. 

As you can see here 
![image](https://user-images.githubusercontent.com/506234/95549332-b172c800-09cc-11eb-82fa-468fb439e0b6.png)

each node did receive the correct ""size"" for each one, then printed the `list_objects_remote` which for alice is

![image](https://user-images.githubusercontent.com/506234/95549542-19c1a980-09cd-11eb-8ec3-1dbc79996f03.png)

And for dan is 
![image](https://user-images.githubusercontent.com/506234/95549566-26460200-09cd-11eb-9f0a-28e46c77a81a.png)

Which I think is correct?

Inded with that code if I do `bob[0].get()`, `dan[0].get()`, `alice[0].get()`, `charlie[0].get()` I get exception error `
GetNotPermittedError:`, but I think the list_objects_remote are listening only what is on the node?

or to reproduce error..... where should I send the different data with which user permissions? I mean even changing

![image](https://user-images.githubusercontent.com/506234/95550407-740f3a00-09ce-11eb-8322-dfc7267b96e5.png)

Seem to print same output as before

![image](https://user-images.githubusercontent.com/506234/95550440-87220a00-09ce-11eb-9423-850e27b43ab6.png)


What Im missing to reproduce the error?",hi setup call node assigned tensor size see image node receive correct size one printed image dan image think correct code bob dan get exception error think listening node reproduce error send different data user mean even image seem print output image missing reproduce error,issue,negative,negative,negative,negative,negative,negative
705943465,"Hi, I have used torch 1.6,but when I use pip install opacus, it occurred error that:
ERROR: Could not find a version that satisfies the requirement torch==1.6.0 (from opacus) (from versions: 0.1.2, 0.1.2.post1, 0.1.2.post2)
ERROR: No matching distribution found for torch==1.6.0 (from opacus)
I want to know how can I solve the problem?",hi used torch use pip install error error could find version requirement post post error matching distribution found want know solve problem,issue,negative,neutral,neutral,neutral,neutral,neutral
705921268,"here is my error:
ERROR: Could not find a version that satisfies the requirement torch==1.6.0 (from opacus) (from versions: 0.1.2, 0.1.2.post1, 0.1.2.post2)
ERROR: No matching distribution found for torch==1.6.0 (from opacus)",error error could find version requirement post post error matching distribution found,issue,negative,neutral,neutral,neutral,neutral,neutral
705917434,"Hi @aanurraj when I try to download the package opacus, it occurs some troubles. It showed  that no opacus version can satisfied my torch 1.6.0, how can I solve the problem?",hi try package version satisfied torch solve problem,issue,negative,positive,positive,positive,positive,positive
705908322,"> Any update @Doodlera?

It didn't work.
I install manually by _pip install openmined.threepio==0.2.0_.It have been installed as follow:
![image](https://user-images.githubusercontent.com/32300708/95530037-57472680-0a0f-11eb-9ef6-269e44ba239a.png)
But I still have the problem:
    _ModuleNotFoundError: No module named 'pythreepio.threepio'_
",update work install manually install follow image still problem module,issue,negative,neutral,neutral,neutral,neutral,neutral
705541469,"Hi @eric-vader ! Unfortunately, this changes won't be merged soon due to a lot of technical challenges we faced. You can still look into [TenSEAL](https://github.com/OpenMined/TenSEAL) if you need to perform ML with HE. TenSEAL currently doesn't have a general purpose tensor type, which is expected on the PySyft side, so we preferred to make the integration once it's ready.",hi unfortunately wo soon due lot technical faced still look need perform currently general purpose tensor type side preferred make integration ready,issue,negative,negative,neutral,neutral,negative,negative
705350252,"Going to take a while before I complete it. I will like to complete it, but if someone else is interested to do it before me please go ahead. ",going take complete like complete someone else interested please go ahead,issue,positive,positive,positive,positive,positive,positive
705312645,"> a yeah, I got that about accessing a unknow key...
> 
> I was wondering why the returned dictionary only cointains data for Bob. Im running the default `docker-compuse up` PyGrid https://github.com/OpenMined/PyGrid#1-setting-the-your-hostfile
> 
> And was wondering why I get Bob as default for the name, indeed if I printi `node` I get `<Federated Worker id:Bob>`
> 
> so yeah, changing to `res_alice = results['Bob'][0]` works... but let me see if I can get your same example to run as spected... sorry for the random questions and blocks, figuring this out 👍.

I personalised my underlying network :) Now that you have res_bob you could try to run ,get() -which should return an error- and .location.list_objetcts_remote() - which should wrongly return the data in Bob.",yeah got unknow key wondering returned dictionary data bob running default wondering get bob default name indeed node get worker id bob yeah work let see get example run sorry random underlying network could try run get return wrongly return data bob,issue,negative,negative,negative,negative,negative,negative
705282664,"a yeah, I got that about accessing a unknow key...

I was wondering why the returned dictionary only cointains data for Bob. Im running the default `docker-compuse up` PyGrid https://github.com/OpenMined/PyGrid#1-setting-the-your-hostfile

 And was wondering why I get Bob as default for the name, indeed if I printi `node` I get `<Federated Worker id:Bob>`

so yeah, changing to `res_alice = results['Bob'][0]` works... but let me see if I can get your same example to run as spected... sorry for the random questions and blocks, figuring this out :+1:.",yeah got unknow key wondering returned dictionary data bob running default wondering get bob default name indeed node get worker id bob yeah work let see get example run sorry random,issue,negative,negative,negative,negative,negative,negative
705260003,"> Hi there, sorry, jusst take a look today, but with the provided code I get this...
> 
> ![image](https://user-images.githubusercontent.com/506234/95393572-74b9aa80-08c0-11eb-83ca-dd6992624bc7.png)
> 
> Is this the correct setup or what Im missing to reproduce the bug @xanderwallace85 ?
> 
> Also I will be updating more the issue with what I find, if I got stuck is this the correct place to ask for hints?

Hi @tyoc213 , I think the error you get is due to ""results['alice']"". ""results"" seems to contain only data for ""Bob"". See ""Out[4]"".
Probably when you start the node on port 5001 you label it ""Bob"".",hi sorry take look today provided code get image correct setup missing reproduce bug also issue find got stuck correct place ask hi think error get due contain data bob see probably start node port label bob,issue,negative,negative,negative,negative,negative,negative
705244461,"Run this command instead

 python setup.py install
",run command instead python install,issue,negative,neutral,neutral,neutral,neutral,neutral
705242621,"@Boluwatifeh I have installed a new version of PyTorch. It gives an error after running this code:
`python setup.py install udacity`

Error is:
```
usage: setup.py [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]
   or: setup.py --help [cmd1 cmd2 ...]
   or: setup.py --help-commands
   or: setup.py cmd --help

error: invalid command 'udacity
```

",new version error running code python install error usage help help error invalid command,issue,negative,positive,positive,positive,positive,positive
705222049,"Hi  there, sorry, jusst take a look today, but with the provided code I get this...

![image](https://user-images.githubusercontent.com/506234/95393572-74b9aa80-08c0-11eb-83ca-dd6992624bc7.png)


Is this the correct setup or what Im missing to reproduce the bug @xanderwallace85 ?

Also I will be updating more  the issue with what I find, if I got stuck is this the correct place to ask for hints?",hi sorry take look today provided code get image correct setup missing reproduce bug also issue find got stuck correct place ask,issue,negative,negative,negative,negative,negative,negative
704909932,@madhavajay have added test for send alias method and fixed the failing test.,added test send alias method fixed failing test,issue,negative,positive,neutral,neutral,positive,positive
704839911,"Thanks ,I would try to experiment with the content of the blog",thanks would try experiment content,issue,negative,positive,positive,positive,positive,positive
704633970,"Yeah, I would close the issue,thanks.",yeah would close issue thanks,issue,positive,positive,positive,positive,positive,positive
704487348,"~~`pip install syft==0.2.0a2` worked for me.~~

see https://github.com/OpenMined/PySyft-TensorFlow/issues/43#issuecomment-631465354

EDIT: Still run into an error: `WARNING:tensorflow:From /usr/local/anaconda3/envs/pysyft/lib/python3.7/site-packages/tf_encrypted/session.py:24: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.`",pip install worked see edit still run error warning name please use,issue,negative,neutral,neutral,neutral,neutral,neutral
704427899,"@catdogpandas do you mean Tensorflow Federated? I thought they had their own DP implementation out of the box.
Has been a while since I tried TFF, but it is kind of a mess. Our biggest problem was tensorflow/federated/issues/832 and in regards to DP the location of clipping and noise application was hard coded.

As a result we disregarded it for our research now and switched to pytorch with [pytorch/opacus](https://github.com/pytorch/opacus) for differential privacy. As we only do research experiments we have not yet implemented a real hierarchy with PySyft yet, but in theory it should be possible. Would be nice to have this confirmed though.

Hope this helps you.",mean thought implementation box since tried kind mess biggest problem location clipping noise application hard result research switched differential privacy research yet real hierarchy yet theory possible would nice confirmed though hope,issue,positive,positive,positive,positive,positive,positive
704415968,"Yes. I face the same issue. I tried to use https://github.com/tensorflow/privacy for **TFF**, but failed. It seems I have to make a fresh start ? : ) 😭 ",yes face issue tried use make fresh start,issue,positive,positive,positive,positive,positive,positive
704384160,Does this solve your problem @wlnancy ? Could we close this issue?,solve problem could close issue,issue,negative,neutral,neutral,neutral,neutral,neutral
704191811,@LaRiffle what other organisations do we need to add apart from the current four(udacity & co) ? Would love to work on this,need add apart current four would love work,issue,positive,positive,positive,positive,positive,positive
704181382,"You can set the id like id=f""i"" (the index from the loop).
For the second question: you can search for a tag, get a pointer and then call shape on that object",set id like index loop second question search tag get pointer call shape object,issue,negative,neutral,neutral,neutral,neutral,neutral
704117763,"But how can I set id?By the way,do you know how to check the data size of each worker owns?",set id way know check data size worker,issue,negative,neutral,neutral,neutral,neutral,neutral
704111161,I think you can do a for loop and create the workers? (and keep them in a list),think loop create keep list,issue,negative,neutral,neutral,neutral,neutral,neutral
703911032,@Boluwatifeh Can you help me in upgrading the PyTorch by sharing a valuable article or video?,help valuable article video,issue,positive,neutral,neutral,neutral,neutral,neutral
703910247,Or probably your pytorch version is lower than 1.4 . Try upgrading pytorch if that's the case,probably version lower try case,issue,negative,neutral,neutral,neutral,neutral,neutral
703908928,"@dA505819 Are you sure you have pytorch installed on your machine? The error indicates you haven't installed pytorch yet. 

Head over here https://github.com/OpenMined/PySyft/blob/dev/INSTALLATION.md and follow the instructions and you should be good to go",da sure machine error yet head follow good go,issue,negative,positive,positive,positive,positive,positive
703430006,"The duration of sy.create_sandbox(globals(), download_data=False) is about a second and for sy.create_sandbox(globals(), download_data=True) is about 17 sec.
@LaRiffle , @gmuraru what do you think?",duration second sec think,issue,negative,negative,neutral,neutral,negative,negative
703413367,"You can check in the ""files"" tab the changes that your PR provide, it might not be what you expected (ie a simple line change)!",check tab provide might ie simple line change,issue,negative,neutral,neutral,neutral,neutral,neutral
703412066,"Yeah totally agree, if the download time on the CI is not too much we can add it!",yeah totally agree time much add,issue,positive,positive,neutral,neutral,positive,positive
703230345,"> Indeed it couldn't find the Boston dataset. It is because in the test_sandbox.py the flag download_data=False.
> Can I change it to true?

hmm..we can do that, I am thinking in the case we have bad connectivity and we might download with 5kbps? (although this should be a rare case). Also, how much does it takes to download the datasets? (if is a small period of time < 5s, I think we should go and add it and if not...maybe remove the datasets from the tests?) What do you think @LaRiffle ",indeed could find boston flag change true thinking case bad connectivity might although rare case also much small period time think go add maybe remove think,issue,negative,negative,neutral,neutral,negative,negative
703156550,"Indeed it couldn't find the Boston dataset. It is because in the test_sandbox.py the flag download_data=False.
Can I change it to true?",indeed could find boston flag change true,issue,negative,positive,positive,positive,positive,positive
703103856,"> test on sand box failed :/

It can't find the Boston dataset.",test sand box ca find boston,issue,negative,neutral,neutral,neutral,neutral,neutral
703103588,"Thinking more on it, I think the good first issue label is a sub-evaluation of the issue because someone will have to do the following changes:
* Add field with plan tag in the communication object <-- this will require changes in syft-proto repo.
* When decomposing the message search for that message tag in the object store and run it.
",thinking think good first issue label issue someone following add field plan tag communication object require message search message tag object store run,issue,negative,positive,positive,positive,positive,positive
702890636,"Are you taking part in Hacktoberfest, by any chance? I see that this is your first PR - I recommend checking out OpenMined's contributing guide https://github.com/OpenMined/.github/blob/master/CONTRIBUTING.md for information on how to make the best impact on our projects.

This PR doesn't add anything as the comment is just a duplication of the code. Generally, although documentation changes are vital to ensure a project remains useful, PRs with small changes to documentation / comments don't add much but do take up quite a bit of the maintainers' time. Wanting to contribute to Open Source is great, and I encourage you to continue doing so, but PRs like this aren't helpful.


",taking part chance see first recommend guide information make best impact add anything comment duplication code generally although documentation vital ensure project remains useful small documentation add much take quite bit time wanting contribute open source great encourage continue like helpful,issue,positive,positive,positive,positive,positive,positive
702845796,"How much knowledge of pysyft do I need to work on this? 
I am trying to get started and saw this as a stale Good First Issue.",much knowledge need work trying get saw stale good first issue,issue,negative,positive,positive,positive,positive,positive
702845032,"Yes I just wanted to make it easier to understand for any other person who
wants to go through it

On Fri, Oct 2, 2020, 8:22 AM George-Cristian Muraru <
notifications@github.com> wrote:

> Hmm...there is only a commented line with an import
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/pull/4625#issuecomment-702571487>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AOTGQORPS2W53PF2ZFA4PHTSIV5TTANCNFSM4SBC7XAA>
> .
>
",yes make easier understand person go wrote line import thread reply directly view,issue,positive,positive,neutral,neutral,positive,positive
702621147,Hi! I think that #4595 also solves this + has added extra support for buffers and GPU,hi think also added extra support,issue,negative,neutral,neutral,neutral,neutral,neutral
702616631,"Opacus is on torch 1.6, and upgrades are always a bit annoyins, so I would say let's update as high as possible! ",torch always bit would say let update high possible,issue,negative,positive,neutral,neutral,positive,positive
702575913,"the crypten master is on torch1.5 maybe we can bump to 1.5 first
",master torch maybe bump first,issue,negative,positive,positive,positive,positive,positive
702572033,Could you try with the latest ```crypten``` master?,could try latest master,issue,negative,positive,positive,positive,positive,positive
702232419,"this is pretty weird I run this code in debug mode, stepped into every function, the things seemed correct while computing the response (3 tensors were returned),  and in the end got this error : (which shows things were correct 3 tensor returned as expected)
```
Exception has occurred: ValueError
not enough values to unpack (expected 4, got 3)
  File ""/home/nilansh/Anton/OpenMined/PySyft/debug.py"", line 8, in <module>
    U, s, _, V = x.svd()

```

but returns 4 values when run as normal python code.

@LaRiffle  ",pretty weird run code mode stepped every function correct response returned end got error correct tensor returned exception enough unpack got file line module run normal python code,issue,negative,negative,neutral,neutral,negative,negative
702174007,"Nope, I think it is fine because the parameter name ```allowed_users``` allude to a list/tuple of user names",nope think fine parameter name allude user,issue,negative,positive,positive,positive,positive,positive
702172767,"@gmuraru  should i add a method to convert string to list explicitly?
so you can pass a string also, and passing string for single user looks better",add method convert string list explicitly pas string also passing string single user better,issue,negative,positive,positive,positive,positive,positive
702172302,Thank you for looking into this. I think we can close it!,thank looking think close,issue,negative,neutral,neutral,neutral,neutral,neutral
702166324,"actually this not a bug, private tensor expects a list of users, `private_tensor(allowed_users = (""Alice"")) ` and here you are passing a string basically which converts to 5 users ['A', 'l' ....], 

either pass a list or tuple. for tuple with single element you need to use this format `(""Alice"",)` ,   `(""Alice"")` this is just a string
`private_tensor(allowed_users = (""Alice"",)) ` this will work
or better `private_tensor(allowed_users = [""Alice""]) `",actually bug private tensor list passing string basically either pas list single element need use format string work better,issue,negative,positive,positive,positive,positive,positive
702108256,"I trust that it'll work, but I didn't upgrade my MacOS.  I just decided to use PySyft on Unix.",trust work upgrade decided use,issue,positive,neutral,neutral,neutral,neutral,neutral
702098908,Could you include a stack trace? :D,could include stack trace,issue,negative,neutral,neutral,neutral,neutral,neutral
702098157,"Hey @AnshuTrivedi. 
As a first Proof of Concept and check if it works I think it is best to look at the ```VirtualWorker``` class <-- there should be a send/recv methods.",hey first proof concept check work think best look class,issue,positive,positive,positive,positive,positive,positive
702024930,"Yep, you can both work on this. Currently, FALCON milestone is still ongoing but there are methods (like the ones from RST) that need documentation.",yep work currently falcon milestone still ongoing like need documentation,issue,positive,neutral,neutral,neutral,neutral,neutral
701990070,"> hey @gmuraru !
> can i take this issue

I am very sorry that I did not see this reply :(.

Sure, it would be GREAT!",hey take issue sorry see reply sure would great,issue,positive,positive,positive,positive,positive,positive
701985820,"Hey, I'll start to work on this issue from now on, as discussed with @somiljain7 and @LaRiffle 👍 ",hey start work issue,issue,negative,neutral,neutral,neutral,neutral,neutral
701983126,Thank you for reporting it! It might be a problem that the tensors should be sent to the ```device``` (in this case GPU) before using ```set_```,thank might problem sent device case,issue,negative,neutral,neutral,neutral,neutral,neutral
701955724,"Yeah sure, give it a try @tyoc213 :)",yeah sure give try,issue,positive,positive,positive,positive,positive,positive
701554688,"+1, I also run into this issue with very similar code to the above, except using mobilenet instead of resnet. RuntimeError message is the same. The issue disappears when I use a neural net I specify for myself, so I think it could be interop with the torch model zoo models?

(for reference I had this same issue back in ~May on syft ~0.2.4 but didn't report- unfortunately some other projects pulled me away from this one)",also run issue similar code except instead message issue use neural net specify think could torch model zoo reference issue back unfortunately away one,issue,negative,negative,negative,negative,negative,negative
701520388,"hi @iamtrask, I would like to work on this one. ",hi would like work one,issue,negative,neutral,neutral,neutral,neutral,neutral
701349853,"Great! @sssilvar if you want to take a stab at it it can be a nice good first issue! :)
(basically adding a `def T` property to the pointer tensor that call self.t())",great want take stab nice good first issue basically property pointer tensor call,issue,positive,positive,positive,positive,positive,positive
701346839,"Hi!
Very strange that it didn't install `pythreepio`...
You can install manually
`pip install openmined.threepio==0.2.0`
Please let me know if this fixes the pb",hi strange install install manually pip install please let know,issue,negative,negative,neutral,neutral,negative,negative
701140631,"> Could you please verify the result is the same? I have tried in three different environments and I get empty tensors when performing the operation `x.T`. Additionally, it does not create a pointer as it should (raising an error when try to `.get()` the tensor from the worker.
> 
> ```python
> x = torch.rand(250,84).send(bob)  # Creates a pointer
> torch.eq(x.T, x.transpose(1,0)).get()  # Raises Error
> ```
> 
> Because I get the following:
> 
> ```python
> ---------------------------------------------------------------------------
> AttributeError                            Traceback (most recent call last)
> <ipython-input-27-b6d586366917> in <module>()
> ----> 1 torch.eq(x.T, x.transpose(1,0)).get().min()
> 
> /usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/tensors/interpreters/native.py in get(self, inplace, user, reason, *args, **kwargs)
>     643 
>     644         # If it is a local tensor/chain, we don't need to verify permissions
> --> 645         if not isinstance(self.child, syft.PointerTensor):
>     646             tensor = self.child.get(*args, **kwargs)
>     647         else:  # Remote tensor/chain
> 
> AttributeError: 'Tensor' object has no attribute 'child'
> ```

Yes , i have verified the results for x.T and x.transpose(1,0) are the same.",could please verify result tried three different get empty operation additionally create pointer raising error try tensor worker python bob pointer error get following python recent call last module get self user reason local need verify tensor else remote object attribute yes,issue,negative,negative,neutral,neutral,negative,negative
701139825,"```python3

import torch
import syft as sy

hook = sy.TorchHook(torch)
bob = sy.VirtualWorker(hook, id='bob')

x = torch.rand(250, 84) # Synthetic tensor
transpose_x = x.T

transpose_x.send(bob)

#output : (Wrapper)>[PointerTensor | me:76058087319 -> bob:43056241225]
```
@sssilvar
here, this yields pointer.",python import torch import hook torch bob hook synthetic tensor bob output wrapper bob pointer,issue,negative,neutral,neutral,neutral,neutral,neutral
700674610,"> Hey! Can you use `x.t()` instead?

It works too, yeah. Thanks @LaRiffle 
Although, would be nice to have the behavior fixed for the next minor releases. :+1: ",hey use instead work yeah thanks although would nice behavior fixed next minor,issue,positive,positive,positive,positive,positive,positive
700535732,"I am interested in the changes, @youben11
Any plans to still merge the branch since its approved?",interested still merge branch since,issue,negative,positive,positive,positive,positive,positive
700524232,"> ```python
> import torch
> import syft as sy
> 
> hook = sy.TorchHook(torch)
> bob = sy.VirtualWorker(hook, id='bob')
> 
> x = torch.rand(250, 84) # Synthetic tensor
> x.send(bob)
> x.T
> 
> #Output : ""transpose of x""
> ```
> 
> This code works.
> But i don't understand what is your objective here @sssilvar?

Plus, there is an error in what you're doing. You are not capturing the pointer after sending:
```python
x.send(bob)  # Does not capture the pointer (incorrect)
x = x.send(bob)  # Does capture the pointer by replacing x for the pointer (correct)
```",python import torch import hook torch bob hook synthetic tensor bob output transpose code work understand objective plus error pointer sending python bob capture pointer incorrect bob capture pointer pointer correct,issue,negative,neutral,neutral,neutral,neutral,neutral
700480647,"Could you please verify the result is the same? I have tried in three different environments and I get empty tensors when performing the operation `x.T`. Additionally, it does not create a pointer as it should (raising an error when try to `.get()` the tensor from the worker.

```python
x = torch.rand(250,84).send(bob)  # Creates a pointer
torch.eq(x.T, x.transpose(1,0)).get()  # Raises Error
```
Because I get the following:

```python
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-27-b6d586366917> in <module>()
----> 1 torch.eq(x.T, x.transpose(1,0)).get().min()

/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/tensors/interpreters/native.py in get(self, inplace, user, reason, *args, **kwargs)
    643 
    644         # If it is a local tensor/chain, we don't need to verify permissions
--> 645         if not isinstance(self.child, syft.PointerTensor):
    646             tensor = self.child.get(*args, **kwargs)
    647         else:  # Remote tensor/chain

AttributeError: 'Tensor' object has no attribute 'child'
```",could please verify result tried three different get empty operation additionally create pointer raising error try tensor worker python bob pointer error get following python recent call last module get self user reason local need verify tensor else remote object attribute,issue,negative,negative,neutral,neutral,negative,negative
700435101,"```python3
import torch
import syft as sy

hook = sy.TorchHook(torch)
bob = sy.VirtualWorker(hook, id='bob')

x = torch.rand(250, 84) # Synthetic tensor
x.send(bob)
x.T

#Output : ""transpose of x""
```
This code works.
But i don't understand what is your objective here @sssilvar?",python import torch import hook torch bob hook synthetic tensor bob output transpose code work understand objective,issue,negative,neutral,neutral,neutral,neutral,neutral
700337218,Just quickly fixing this before I forget and someone tries to use it on an old branch which will get deleted eventually.,quickly fixing forget someone use old branch get eventually,issue,negative,positive,positive,positive,positive,positive
699611822,"@gmuraru i want ot work on this issue.Can you assign me?
Also which code file are you referring to include feature?",want work assign also code file include feature,issue,negative,neutral,neutral,neutral,neutral,neutral
699582120,I wonder if I can fix this :)... so Im new to this library and probably will need some help.,wonder fix new library probably need help,issue,negative,positive,positive,positive,positive,positive
698852939,Close due to lint issue,close due lint issue,issue,negative,negative,negative,negative,negative,negative
698582005,"Hi @aanurraj,

yes, this PR resolves the averaging bug. The second issue described in #3863 is not resolved, since it is due to models living on different devices.",hi yes bug second issue resolved since due living different,issue,positive,negative,neutral,neutral,negative,negative
698503854,"> Hey @xanderwallace85!
> This issue won't be solved shortly I think... why exactly do you need size and shape won't do the job?

Hi @LaRiffle ! Apparently, even simple CNN models do not work when using private tensors. I believe this is due to the size function :(  For instance, a model like the one below won't work as the function size is required (by the nn.Linear?).
```
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5, 1)
        self.conv2 = nn.Conv2d(20, 50, 5, 1)
        self.fc1 = nn.Linear(4*4*50, 500)
        self.fc2 = nn.Linear(500, 10)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = F.max_pool2d(x, 2, 2)
        x = F.relu(self.conv2(x))
        x = F.max_pool2d(x, 2, 2)
        x = x.view(-1, 4*4*50)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return F.log_softmax(x, dim=1)
```

Is there an alternative to private tensors? As I am looking for a solution to hide the data in the nodes (so not allowing the .get(), for example). 
Would be a pity to not be able to fully exploit private tensors though :( ",hey issue wo shortly think exactly need size shape wo job hi apparently even simple work private believe due size function instance model like one wo work function size class net self super net self forward self return alternative private looking solution hide data example would pity able fully exploit private though,issue,positive,positive,neutral,neutral,positive,positive
698430465,"Hey @xanderwallace85!
This issue won't be solved shortly I think... why exactly do you need size and shape won't do the job?",hey issue wo shortly think exactly need size shape wo job,issue,negative,positive,positive,positive,positive,positive
698393641,"> Sure will do (I still have problem with the Lint phase, so I am struggling with it)

You can run 
`$ black .`

To check the lint
",sure still problem lint phase struggling run black check lint,issue,negative,positive,positive,positive,positive,positive
698305487,"Hi @LaRiffle, any news about this issue?
The (big) problem related to this is that models cannot be executed on private tensors :( ",hi news issue big problem related executed private,issue,negative,neutral,neutral,neutral,neutral,neutral
697311828,This looks really nice and promising! Keep up the good work!,really nice promising keep good work,issue,positive,positive,positive,positive,positive,positive
697165183,"> @aanurraj Thanks for starting this, I have added a PR here: #4589 to this PR. You can merge this into your branch or merge my PR and close this, either way.

thankyou :) closing this PR",thanks starting added merge branch merge close either way,issue,negative,positive,neutral,neutral,positive,positive
697047500,"Thanks for the PR. ❤️

It looks like you hit the jackpot on the CI tests. 😂
The coverage test is just the quickest so it often fails first but the error is nothing to do with coverage.
I have had this problem myself, its not a real issue its just that by adding additional methods our wrapped types have higher ""lengths"" in terms of the number of attributes so this fixed test fails.
```
____________________________ test_api_sanity_check _____________________________

    def test_api_sanity_check():
        sy_int = Int(42)
        py_int = 42
        sy_int_API = set(dir(sy_int))
        py_int_API = set(dir(py_int))
    
        assert len(py_int_API - sy_int_API) == 0
        # immutable opeartors on the ID
>       assert len(sy_int_API - py_int_API) == 28
E       assert 29 == 28
E         +29
E         -28
```

A recent commit of mine updated the comments already to make this clearer.
```
def test_api_sanity_check():
    sy_int = Int(42)
    py_int = 42
    sy_int_API = set(dir(sy_int))
    py_int_API = set(dir(py_int))
    sy_int_method_count = 29  # warning this changes when we add methods

    assert len(py_int_API - sy_int_API) == 0
    # immutable opeartors on the ID
    # warning this changes when we add methods
    assert len(sy_int_API - py_int_API) == sy_int_method_count
```

We should probably fix this properly, since its not helpful if it breaks any time we add functionality.
@tudorcebere Do you have any thoughts on what we should do here?

Speaking of tests, is it possible to add a test that checks ""send_to"".
Maybe a new test function inside: tensor_remote_serde_test.py or something similar?",thanks like hit coverage test often first error nothing coverage problem real issue additional wrapped higher number fixed test set set assert immutable id assert assert recent commit mine already make clearer set set warning add assert immutable id warning add assert probably fix properly since helpful time add functionality speaking possible add test maybe new test function inside something similar,issue,positive,positive,positive,positive,positive,positive
696709507,"Sure will do (I still have problem with the Lint phase, so I am struggling with it)",sure still problem lint phase struggling,issue,negative,positive,positive,positive,positive,positive
696708429,Can you please add a description about the PR and a valid Title ? Thanks 😉,please add description valid title thanks,issue,positive,positive,positive,positive,positive,positive
696600131,"If there are technical reasons for why it is not possible, it would be nice to at least have a function which removes the hook from torch. That way one could arbitrarily switch between some standard (local) torch operations not supported by PySyft and some private operations on secretly shared data.",technical possible would nice least function hook torch way one could arbitrarily switch standard local torch private secretly data,issue,negative,negative,neutral,neutral,negative,negative
696596787,"I encountered the same issue when using facenet-pytorch (https://github.com/timesler/facenet-pytorch), using Python version 3.7.9, PySyft version 0.2.9 and PyTorch version 1.4. My code:
```python
from facenet_pytorch import MTCNN
from PIL import Image
import torch
import syft as sy

im = Image.open(""example.jpg"")
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

mtcnn = MTCNN(
    image_size=160, margin=0, min_face_size=20,
    thresholds=[0.6,0.7,0.7], factor=0.709, post_process=True,
    device=device, keep_all=True
)

# Calling this works fine
x_aligned = mtcnn(im)
hook = sy.TorchHook(torch)

# This call fails with an IndexError
x_aligned = mtcnn(im)
```
The error is
```
---------------------------------------------------------------------------
IndexError                                Traceback (most recent call last)
<ipython-input-5-44b80875f4ab> in <module>
----> 1 x_aligned = mtcnn(im)

~/miniconda3/envs/pysyft/lib/python3.7/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    530             result = self._slow_forward(*input, **kwargs)
    531         else:
--> 532             result = self.forward(*input, **kwargs)
    533         for hook in self._forward_hooks.values():
    534             hook_result = hook(self, input, result)

~/miniconda3/envs/pysyft/lib/python3.7/site-packages/facenet_pytorch/models/mtcnn.py in forward(self, img, save_path, return_prob)
    245         # Detect faces
    246         with torch.no_grad():
--> 247             batch_boxes, batch_probs = self.detect(img)
    248 
    249         # Determine if a batch or single image was passed

~/miniconda3/envs/pysyft/lib/python3.7/site-packages/facenet_pytorch/models/mtcnn.py in detect(self, img, landmarks)
    352                 self.pnet, self.rnet, self.onet,
    353                 self.thresholds, self.factor,
--> 354                 self.device
    355             )
    356 

~/miniconda3/envs/pysyft/lib/python3.7/site-packages/facenet_pytorch/models/utils/detect_face.py in detect_face(imgs, minsize, pnet, rnet, onet, threshold, factor, device)
     73         reg, probs = pnet(im_data)
     74 
---> 75         boxes_scale, image_inds_scale = generateBoundingBox(reg, probs[:, 1], scale, threshold[0])
     76         boxes.append(boxes_scale)
     77         image_inds.append(image_inds_scale)

~/miniconda3/envs/pysyft/lib/python3.7/site-packages/facenet_pytorch/models/utils/detect_face.py in generateBoundingBox(reg, probs, scale, thresh)
    210     mask_inds = mask.nonzero()
    211     image_inds = mask_inds[:, 0]
--> 212     score = probs[mask]
    213     reg = reg[:, mask].permute(1, 0)
    214     bb = mask_inds[:, 1:].type(reg.dtype).flip(1)

~/miniconda3/envs/pysyft/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
    167                 except BaseException as e:
    168                     # we can make some errors more descriptive with this method
--> 169                     raise route_method_exception(e, self, args, kwargs)
    170 
    171             else:  # means that there is a wrapper to remove

~/miniconda3/envs/pysyft/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
    163 
    164                 try:
--> 165                     response = method(*args, **kwargs)
    166 
    167                 except BaseException as e:

IndexError: The shape of the mask [111, 226] at index 0 does not match the shape of the indexed tensor [1, 111, 226] at index 0
```
and appears to be caused by the line `score = probs[mask]`, so I presume it is the same indexing issue.",issue python version version version code python import import image import torch import device else calling work fine hook torch call error recent call last module self input result input else result input hook hook self input result forward self detect determine batch single image detect self threshold factor device reg reg scale threshold reg scale thresh score mask reg reg mask self except make descriptive method raise self else wrapper remove self try response method except shape mask index match shape indexed tensor index line score mask presume indexing issue,issue,negative,positive,neutral,neutral,positive,positive
696541385,"I solved this problem by wrapping FILE_PATH with str() like below.
`FILE_PATH = str(Path(__file__).resolve().parent.joinpath(""run_websocket_server.py""))`

I think it's not that elaborate way, but anyway it works for my case. 
",problem wrapping like path think elaborate way anyway work case,issue,negative,positive,positive,positive,positive,positive
695997613,"> Could you check in the falcon helper for `xor` if is wrapper?

no both are [ReplicatedSharingTensor]",could check falcon helper wrapper,issue,negative,neutral,neutral,neutral,neutral,neutral
695990878,"> Wow, awesome work. ❤️ I pulled down the PR to see why its failing and ran the pre_commit script we use to locally check everything that also runs in CI. The main difference with CI is there are some slow tests we don't run in pre_commit.sh so that its easy to get quick feedback that your code lint checks and the basic tests pass. This definitely needs to be documented better so sorry about that.
> 
> ```shell
> $ scripts/pre_commit.sh
> ```
> 
> > src/syft/lib/python/dict.py:93: error: Argument 4 of ""construct_new_object"" is incompatible with supertype ""StorableObject""; supertype defines the argument type as ""Optional[List[str]]""
> > src/syft/lib/python/dict.py:93: note: This violates the Liskov substitution principle
> 
> Fixing this and the required imports, seemed to get the checks to pass locally.
> 
> ```diff
> # dict.py
> -        tags: Optional[TypeDict[str, str]],
> +        tags: Optional[List[str]],
> ```
> 
> For these Primitive Wrapping types we have been copying the official python tests for the parent type and using that to ensure our subclass works as expected.
> 
> You can see an example for List in `/tests/syft/lib/python/list/list_test.py`.
> 
> My guess is this is the correct one for Mapping / Dicts:
> https://github.com/python/cpython/blob/3.8/Lib/test/mapping_tests.py
> 
> If the tests fail on one of the earlier versions of Python, such as python 3.7 or python 3.6 which are in our Test Matrix, it could be that there was a change added to the tests to prevent regression, so you can check the history and figure out which test was added for which version.
> https://github.com/python/cpython/commits/3.8/Lib/test/mapping_tests.py
> 
> You can see an example of that in our copy of `float_test.py`:
> 
> ```python
> # using __index__ in init was added in python 3.8
> # https://github.com/python/cpython/commit/bdbad71b9def0b86433de12cecca022eee91bd9f
> if sys.version_info >= (3, 8):
> 
>     class MyIndex:
>         def __init__(self, value):
>             self.value = value
> 
>         def __index__(self):
>             return self.value
> 
>     assert Float(MyIndex(42)) == 42.0
>     with pytest.raises(OverflowError):
>         Float(MyIndex(2 ** 2000))
> ```

done thanks :)",wow awesome work see failing ran script use locally check everything also main difference slow run easy get quick feedback code lint basic pas definitely need better sorry shell error argument incompatible argument type optional list note substitution principle fixing get pas locally optional optional list primitive wrapping official python parent type ensure subclass work see example list guess correct one fail one python python python test matrix could change added prevent regression check history figure test added version see example copy python added python class self value value self return assert float float done thanks,issue,positive,positive,positive,positive,positive,positive
695896463,"Wow, awesome work. ❤️ I pulled down the PR to see why its failing and ran the pre_commit script we use to locally check everything that also runs in CI. The main difference with CI is there are some slow tests we don't run in pre_commit.sh so that its easy to get quick feedback that your code lint checks and the basic tests pass. This definitely needs to be documented better so sorry about that.
```sh
$ scripts/pre_commit.sh
```

> src/syft/lib/python/dict.py:93: error: Argument 4 of ""construct_new_object"" is incompatible with supertype ""StorableObject""; supertype defines the argument type as ""Optional[List[str]]""
src/syft/lib/python/dict.py:93: note: This violates the Liskov substitution principle

Fixing this and the required imports, seemed to get the checks to pass locally.
```diff
# dict.py
-        tags: Optional[TypeDict[str, str]],
+        tags: Optional[List[str]],
```

For these Primitive Wrapping types we have been copying the official python tests for the parent type and using that to ensure our subclass works as expected.

You can see an example for List in `/tests/syft/lib/python/list/list_test.py`.

My guess is this is the correct one for Mapping / Dicts:
https://github.com/python/cpython/blob/3.8/Lib/test/mapping_tests.py

If the tests fail on one of the earlier versions of Python, such as python 3.7 or python 3.6 which are in our Test Matrix, it could be that there was a change added to the tests to prevent regression, so you can check the history and figure out which test was added for which version.
https://github.com/python/cpython/commits/3.8/Lib/test/mapping_tests.py

You can see an example of that in our copy of `float_test.py`:
```python
# using __index__ in init was added in python 3.8
# https://github.com/python/cpython/commit/bdbad71b9def0b86433de12cecca022eee91bd9f
if sys.version_info >= (3, 8):

    class MyIndex:
        def __init__(self, value):
            self.value = value

        def __index__(self):
            return self.value

    assert Float(MyIndex(42)) == 42.0
    with pytest.raises(OverflowError):
        Float(MyIndex(2 ** 2000))
```
",wow awesome work see failing ran script use locally check everything also main difference slow run easy get quick feedback code lint basic pas definitely need better sorry sh error argument incompatible argument type optional list note substitution principle fixing get pas locally optional optional list primitive wrapping official python parent type ensure subclass work see example list guess correct one fail one python python python test matrix could change added prevent regression check history figure test added version see example copy python added python class self value value self return assert float float,issue,positive,positive,neutral,neutral,positive,positive
695877647,"This PR is awesome work. ❤️

In the interest of getting this merged ASAP 🚀, I have read through all of the comments and requested changes and tried my best to action them where possible ambiguity remains.

The result is a PR here to this PR:
https://github.com/OpenMined/PySyft/pull/4578

I also managed to get the notebooks working with network.py, and update the instructions on how to use the example_node scripts, and in doing so made a few more small cleanups like imports etc.

Apologies, if I understood something wrong or missed something.
",awesome work interest getting rocket read tried best action possible ambiguity remains result also get working update use made small like understood something wrong something,issue,positive,positive,positive,positive,positive,positive
695877581,"Note, I changed `__send_msg` to `_send_msg` because I previously had issues with `__id` and name mangaling preventing me from being able to catch the property when overwriting `__getattribute__`.

According to sources, _ single underscore is still correct in signalling private usage without changing the actual internal naming of the attribute in python.

https://stackoverflow.com/questions/1301346/what-is-the-meaning-of-single-and-double-underscore-before-an-object-name

Happy to change it back if its a problem.",note previously name able catch property according single underscore still correct private usage without actual internal naming attribute python happy change back problem,issue,negative,positive,positive,positive,positive,positive
695867833,"> Since we can't save messages in the object store yet, i've recommended a slightly different temporary workaround which we're more likely to fix later.

This is resolved with the addition of signaling_msgs dict to AbstractNode.",since ca save object store yet slightly different temporary likely fix later resolved addition,issue,positive,neutral,neutral,neutral,neutral,neutral
695860985,"@LaRiffle 
Hi Theo, please find my stack trace. Merci pour ton aide!

```
<ipython-input-16-1a450dc3c5d4> in <module>
      3 logging.basicConfig(format=FORMAT, level=LOG_LEVEL)
      4 
----> 5 main()

<ipython-input-15-443eb06bbc7c> in main()
    208     for epoch in range(1, epochs + 1):
    209         logger.warning(""Starting epoch %s/%s"", epoch, epochs)
--> 210         model = train(model, device, federated_train_loader, test_loader, lr, federate_after_n_batches)
    211         test(model, device, test_loader)

<ipython-input-15-443eb06bbc7c> in train(model, device, federated_train_loader, test_loader, lr, federate_after_n_batches, abort_after_one)
    112             curr_batches = batches[worker]
    113             if curr_batches:
--> 114                 local_models[worker] = train_on_batches(worker, curr_batches, model, device, test_loader, lr)
    115 
    116             else:

<ipython-input-15-443eb06bbc7c> in train_on_batches(worker, batches, model_in, device, test_loader, lr)
     42             t1 = time.time()
     43             # We measure accurancy of worker's model
---> 44             model.get()
     45             accuracy = test(model, device, test_loader)
     46             accuracies[worker].append(accuracy)

/usr/local/lib/python3.7/dist-packages/syft-0.2.7-py3.7.egg/syft/frameworks/torch/hook/hook.py in module_get_(nn_self)
    669             for element_iter in tensor_iterator(nn_self):
    670                 for p in element_iter():
--> 671                     p.get_()
    672 
    673             if isinstance(nn_self.forward, Plan):

/usr/local/lib/python3.7/dist-packages/syft-0.2.7-py3.7.egg/syft/frameworks/torch/tensors/interpreters/native.py in get_(self, *args, **kwargs)
    685         Calls get() with inplace option set to True
    686         """"""
--> 687         return self.get(*args, inplace=True, **kwargs)
    688 
    689     def allow(self, user=None) -> bool:

/usr/local/lib/python3.7/dist-packages/syft-0.2.7-py3.7.egg/syft/frameworks/torch/tensors/interpreters/native.py in get(self, inplace, user, reason, *args, **kwargs)
    672 
    673         if inplace:
--> 674             self.set_(tensor)
    675             if hasattr(tensor, ""child""):
    676                 self.child = tensor.child

RuntimeError: Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _th_set_
```",hi please find stack trace pour ton aide module main main epoch range starting epoch epoch model train model device test model device train model device worker worker worker model device else worker device measure worker model accuracy test model device worker accuracy plan self get option set true return allow self bool get self user reason tensor tensor child object device type got device type argument call,issue,positive,positive,positive,positive,positive,positive
695823416,Issue would be resolved by pull request #4576 ,issue would resolved pull request,issue,negative,neutral,neutral,neutral,neutral,neutral
695800648,"> # Description & reproduce
> I met a similar problem on windows,
> when I type in my command, `from syft.frameworks.torch.dp import pate`, the error msg is as follows:
> 
> Traceback (most recent call last):
>   File """", line 1, in 
>   File ""D:\Anaconda\envs\torch\lib\site-packages\syft-0.2.9-py3.7.egg\syft\__init__.py"", line 14, in 
>     import syft.frameworks.torch.hook.hook_args
>   File ""D:\Anaconda\envs\torch\lib\site-packages\syft-0.2.9-py3.7.egg\syft\frameworks\torch\hook\hook_args.py"", line 4, in 
>     from syft.frameworks.torch.tensors.interpreters.native import TorchTensor
>   File ""D:\Anaconda\envs\torch\lib\site-packages\syft-0.2.9-py3.7.egg\syft\frameworks\torch\tensors\interpreters\native.py"", line 16, in 
>     from syft.generic.utils import memorize
>   File ""D:\Anaconda\envs\torch\lib\site-packages\syft-0.2.9-py3.7.egg\syft\generic\utils.py"", line 1, in 
>     from syft.generic.frameworks.attributes import allowed_commands
>   File ""D:\Anaconda\envs\torch\lib\site-packages\syft-0.2.9-py3.7.egg\syft\generic\frameworks\attributes.py"", line 8, in 
>     from syft.generic.frameworks.hook.hook import FrameworkHook
>   File ""D:\Anaconda\envs\torch\lib\site-packages\syft-0.2.9-py3.7.egg\syft\generic\frameworks\hook\hook.py"", line 11, in 
>     from syft.generic.frameworks.hook.pointers import PointerHook
>   File ""D:\Anaconda\envs\torch\lib\site-packages\syft-0.2.9-py3.7.egg\syft\generic\frameworks\hook\pointers.py"", line 8, in 
>     from syft.generic.pointers.multi_pointer import MultiPointerTensor
>   File ""D:\Anaconda\envs\torch\lib\site-packages\syft-0.2.9-py3.7.egg\syft\generic\pointers\multi_pointer.py"", line 11, in 
>     from syft.workers.base import BaseWorker
>   File ""D:\Anaconda\envs\torch\lib\site-packages\syft-0.2.9-py3.7.egg\syft\workers\base.py"", line 12, in 
>     from syft.execution.plan import Plan
>   File ""D:\Anaconda\envs\torch\lib\site-packages\syft-0.2.9-py3.7.egg\syft\execution\plan.py"", line 21, in 
>     from syft.execution.translation.threepio import PlanTranslatorTfjs
>   File ""D:\Anaconda\envs\torch\lib\site-packages\syft-0.2.9-py3.7.egg\syft\execution\translation\threepio.py"", line 2, in 
>     import pythreepio
> ModuleNotFoundError: No module named 'pythreepio'
> How can I solve the problem?
> 
> # System Information
> python version: 3.7.6
> os: windows 10
> torch: 1.4.0 GPU
> syft: 0.2.9

I solved it by myself. 

1) First, uninstall the original pysyft--`pip uninstall syft`. 

2) And then to use this command `pip install syft -f https://download.pytorch.org/whl/torch_stable.html` from this [link](https://stackoverflow.com/questions/61850455/could-not-find-a-version-that-satisfies-the-requirement-torch-1-4-0-from-syft)

3) maybe you will meet this problem, `ModuleNotFoundError: No module named 'syft.frameworks.torch.differential_privacy'`, please change it into `ModuleNotFoundError: No module named 'syft.frameworks.torch.dp` according to this [link](https://stackoverflow.com/questions/58367187/modulenotfounderror-no-module-named-syft-pysyft)",description reproduce met similar problem type command import pate error recent call last file line file line import file line import file line import memorize file line import file line import file line import file line import file line import file line import plan file line import file line import module solve problem system information python version o torch first original pip use command pip install link maybe meet problem module please change module according link,issue,negative,positive,positive,positive,positive,positive
695798590,"# Description & reproduce
I met a similar problem on windows,
when I type in my command, `from syft.frameworks.torch.dp import pate`, the error msg is as follows:
<pre>
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""D:\Anaconda\envs\torch\lib\site-packages\syft-0.2.9-py3.7.egg\syft\__init__.py"", line 14, in <module>
    import syft.frameworks.torch.hook.hook_args
  File ""D:\Anaconda\envs\torch\lib\site-packages\syft-0.2.9-py3.7.egg\syft\frameworks\torch\hook\hook_args.py"", line 4, in <module>
    from syft.frameworks.torch.tensors.interpreters.native import TorchTensor
  File ""D:\Anaconda\envs\torch\lib\site-packages\syft-0.2.9-py3.7.egg\syft\frameworks\torch\tensors\interpreters\native.py"", line 16, in <module>
    from syft.generic.utils import memorize
  File ""D:\Anaconda\envs\torch\lib\site-packages\syft-0.2.9-py3.7.egg\syft\generic\utils.py"", line 1, in <module>
    from syft.generic.frameworks.attributes import allowed_commands
  File ""D:\Anaconda\envs\torch\lib\site-packages\syft-0.2.9-py3.7.egg\syft\generic\frameworks\attributes.py"", line 8, in <module>
    from syft.generic.frameworks.hook.hook import FrameworkHook
  File ""D:\Anaconda\envs\torch\lib\site-packages\syft-0.2.9-py3.7.egg\syft\generic\frameworks\hook\hook.py"", line 11, in <module>
    from syft.generic.frameworks.hook.pointers import PointerHook
  File ""D:\Anaconda\envs\torch\lib\site-packages\syft-0.2.9-py3.7.egg\syft\generic\frameworks\hook\pointers.py"", line 8, in <module>
    from syft.generic.pointers.multi_pointer import MultiPointerTensor
  File ""D:\Anaconda\envs\torch\lib\site-packages\syft-0.2.9-py3.7.egg\syft\generic\pointers\multi_pointer.py"", line 11, in <module>
    from syft.workers.base import BaseWorker
  File ""D:\Anaconda\envs\torch\lib\site-packages\syft-0.2.9-py3.7.egg\syft\workers\base.py"", line 12, in <module>
    from syft.execution.plan import Plan
  File ""D:\Anaconda\envs\torch\lib\site-packages\syft-0.2.9-py3.7.egg\syft\execution\plan.py"", line 21, in <module>
    from syft.execution.translation.threepio import PlanTranslatorTfjs
  File ""D:\Anaconda\envs\torch\lib\site-packages\syft-0.2.9-py3.7.egg\syft\execution\translation\threepio.py"", line 2, in <module>
    import pythreepio
ModuleNotFoundError: No module named 'pythreepio'
</pre>
How can I solve the problem? 

# System Information
python version: 3.7.6
os: windows 10
torch: 1.4.0 GPU
syft: 0.2.9",description reproduce met similar problem type command import pate error recent call last file line module file line module import file line module import file line module import memorize file line module import file line module import file line module import file line module import file line module import file line module import plan file line module import file line module import module solve problem system information python version o torch,issue,negative,neutral,neutral,neutral,neutral,neutral
695200449,"Hi @Hjeljeli @LaRiffle, I encountered the same problem a few months ago, please refer to the comments in #3848 for further explanation.",hi problem ago please refer explanation,issue,negative,neutral,neutral,neutral,neutral,neutral
695000649,"I pushed an empty commit, and the test fail is due to 94% test coverage but in the last commit it was passing and I haven't made any changes since so not sure what to do :/",empty commit test fail due test coverage last commit passing made since sure,issue,negative,negative,neutral,neutral,negative,negative
694940427,Hmm..Could you push an empty commit?,could push empty commit,issue,negative,negative,neutral,neutral,negative,negative
694836983,"Hey, thanks for reporting!
can you alors provide your stack trace please? :) ",hey thanks provide stack trace please,issue,positive,positive,positive,positive,positive,positive
694711018,"## Question on this Changes

Hi, I'm one of the developers who wants to use view() function in the syft library, thus I referred to this pull request to implement the view() function.

However, when I'm trying this with the ```Create Plan.ipynb``` file, I'm getting an error as shown below.
![image](https://user-images.githubusercontent.com/61619970/93570100-77b23100-f9cd-11ea-840b-e1366be2eb16.png)

Could anyone help me to identify which part is causing this error?
Or does anyone know why am I getting this error?",question hi one use view function library thus pull request implement view function however trying create file getting error shown image could anyone help identify part causing error anyone know getting error,issue,negative,neutral,neutral,neutral,neutral,neutral
694427890,"Hi @gmuraru , sorry, got tied up in some other work. Let me have a look at this again over the weekend.

> I think you will also need to change some things in tests at the serialization level + update the syft-proto repository with a new message type.

The update to syft-proto repository needs to happen before this pull request can be merged right?",hi sorry got tied work let look weekend think also need change serialization level update repository new message type update repository need happen pull request right,issue,negative,negative,neutral,neutral,negative,negative
694088058,"So yeah I guess it solves your note: `# Note: this would fail with an ObjectNotFoundError(obj_id, self) although we called clone on the pointer. With copy() it works as expected`  because with clone remote copy wasn't duplicated
For the other part:
```
print(p.grad.data.copy().get()) # this returns tensor([[0.0000, 0.7492]])
                print(p.grad.data.clone().get()) # this returns tensor([[0.3831, 0.2120]], requires_grad=True)
                # print(p.clone().get().grad.data) # this would return the correct/expected value: tensor([[0.0000, 0.7492]])
                
```
The .grad.data on pointers might not be 100% stable, if you can copy().get() or clone().get() directly on the pointer it would solve your issue I guess! Alternatively, if you build a minimal example of this error we can try investigating it, although this kind of bugs will disappear in 0.3.
I hope this helps :) ",yeah guess note note would fail self although clone pointer copy work clone remote copy part print tensor print tensor print would return value tensor might stable copy clone directly pointer would solve issue guess alternatively build minimal example error try investigating although kind disappear hope,issue,positive,neutral,neutral,neutral,neutral,neutral
693995452,"It'd be great to have GPU support, or at least an example, for this tutorial.

https://github.com/OpenMined/PySyft/blob/44dd09d944ab4f927a1e35a6a1e623265cd6cb11/examples/experimental/CrypTen/CrypTen%20-%20Training%20an%20Encrypted%20Neural%20Network%20across%20Workers%20using%20Jails.ipynb",great support least example tutorial,issue,positive,positive,positive,positive,positive,positive
693747172,"I tried to figure out why that lint error is happening:
https://github.com/OpenMined/PySyft/pull/4564

Feel free to cherry pick or merge from this PR.",tried figure lint error happening feel free cherry pick merge,issue,negative,positive,positive,positive,positive,positive
693745354,"Not sure what I did to fix the docs lint issue.
I was unable to replicate it on my machine, and then I tried to add doc8 and add some max-line-length configuration but it wouldnt pass in CI, so i removed it for now.

Issue is here:
https://github.com/PyCQA/doc8/issues/48",sure fix lint issue unable replicate machine tried add doc add configuration wouldnt pas removed issue,issue,negative,neutral,neutral,neutral,neutral,neutral
693691666,Is this to help automatically boxing python primitives into SyPrimitive?,help automatically boxing python,issue,negative,neutral,neutral,neutral,neutral,neutral
693656118,"Thanks for the clarification @LaRiffle, however, it is not clear to me why the two statements in my example yield different results. Even if I clone the pointer and later call `.get()` it should return the same value, especially if nothing should have happened in the meantime.",thanks clarification however clear two example yield different even clone pointer later call return value especially nothing,issue,positive,positive,neutral,neutral,positive,positive
693599098,"```python
x = th.tensor([1, 2])
p = x.send(alice)
print(p)
print(p.clone())
print(p.copy())
```
prints
```
(Wrapper)>[PointerTensor | me:34294736491 -> alice:26236999679]
(Wrapper)>[PointerTensor | me:34294736491 -> alice:26236999679]
(Wrapper)>[PointerTensor | me:17174615997 -> alice:9847375338]
``` 
Hi!
`clone`clones the pointer while `copy` copies the remote value, so return a new poitner",python print print print wrapper wrapper wrapper hi clone pointer copy remote value return new,issue,negative,positive,neutral,neutral,positive,positive
693473845,Have some difficulties with the Lint step. Still working on this ,lint step still working,issue,negative,neutral,neutral,neutral,neutral,neutral
693313865,"For the operation I mentioned, with my current optimization (working with cuda), the global runtime is 2.0s for 0.34 is 17%. For the resnet18 blogpost, it's 6% of the overall runtime :O

",operation current optimization working global overall,issue,negative,neutral,neutral,neutral,neutral,neutral
693297300,@LaRiffle Do you know what percent of that time is lost in ```_compress``` and ```_decompress``` (in each function)?,know percent time lost function,issue,negative,neutral,neutral,neutral,neutral,neutral
693218751,"You could search for this data! We have a `search` functionality available! Your worker should only tag its data, and the you search for it and get a pointer (just like if you had send this data but you have not), and then the procedure is unchanged",could search data search functionality available worker tag data search get pointer like send data procedure unchanged,issue,negative,positive,positive,positive,positive,positive
693217412,Ok that's great! Get in touch with the team whenever you're ready to start :) ,great get touch team whenever ready start,issue,positive,positive,positive,positive,positive,positive
692725368,"@addy369 Hi, I also meet the same error as you mentioned about the ""cannot import name 'onnx_converter' from crypten.nn. So have you solved it?",hi also meet error import name,issue,negative,neutral,neutral,neutral,neutral,neutral
692665593,"Hey there @LaRiffle i was reading through the contribution.md page and under the deploying workers section, the example link on how to deploy workers returns a 404 page. Here's the link https://github.com/OpenMined/PySyft/blob/master/examples/deploy_workers/deploy-and-connect.ipynb",hey reading page section example link deploy page link,issue,negative,neutral,neutral,neutral,neutral,neutral
692661149,Thanks for the feedback! It's probably gonna be a couple more weeks before I've fully fledged out my project. I'll keep this issue updated with any relevant developments.,thanks feedback probably gon na couple fully project keep issue relevant,issue,negative,positive,positive,positive,positive,positive
692550742,"Hey can you please precise what the bug is? Thanks 😄 
",hey please precise bug thanks,issue,positive,positive,positive,positive,positive,positive
692550030,"Yeah that would be really great! :) 
I would strongly recommend to apply the Federated Learning team if you want to commit to such a project and be in touch with the rest of the team: https://placements.openmined.org/#h.mhok1srmapq4",yeah would really great would strongly recommend apply learning team want commit project touch rest team,issue,positive,positive,positive,positive,positive,positive
692542893,"Hi!
I guess it must be linked to https://github.com/huggingface/tokenizers/issues/321#issuecomment-659969197
You're using macOS El Capitan from 2016, if you can upgrade to a newer version it will be fixed.
We should update `MACOSX_DEPLOYMENT_TARGET` as they suggest, but I don't know how to do this, contribution welcome  :) ",hi guess must linked el capitan upgrade version fixed update suggest know contribution welcome,issue,negative,positive,positive,positive,positive,positive
692023793,"note that a new version of the Falcon paper is available as they promised. 
Besides line 7 there are few other changes to the protocol (which is now at subsection 3.2)
<img width=""644"" alt=""Screen Shot 2020-09-14 at 15 34 21"" src=""https://user-images.githubusercontent.com/2446179/93086599-08bc9b80-f6a0-11ea-9a64-c3375789d34b.png"">

https://arxiv.org/pdf/2004.02229.pdf ",note new version falcon paper available besides line protocol subsection screen shot,issue,negative,positive,positive,positive,positive,positive
691982453,"Check out this pull request on&nbsp; <a href=""https://app.reviewnb.com/OpenMined/PySyft/pull/4554""><img align=""absmiddle""  alt=""ReviewNB"" height=""28"" class=""BotMessageButtonImage"" src=""https://raw.githubusercontent.com/ReviewNB/support/master/images/button_reviewnb.png""/></a> 

 Review Jupyter notebook visual diffs & provide feedback on notebooks. 

---

 <i>Powered by <a href='https://www.reviewnb.com/?utm_source=gh'>ReviewNB</a></i>",check pull request review notebook visual provide feedback powered,issue,negative,neutral,neutral,neutral,neutral,neutral
691668778,"# [Codecov](https://codecov.io/gh/OpenMined/PySyft/pull/4552?src=pr&el=h1) Report
> Merging [#4552](https://codecov.io/gh/OpenMined/PySyft/pull/4552?src=pr&el=desc) into [master](https://codecov.io/gh/OpenMined/PySyft/commit/88c2606b36244923c214ee40be069f896bf6342a?el=desc) will **not change** coverage.
> The diff coverage is `100.00%`.

[![Impacted file tree graph](https://codecov.io/gh/OpenMined/PySyft/pull/4552/graphs/tree.svg?width=650&height=150&src=pr&token=W0kQS1vaXB)](https://codecov.io/gh/OpenMined/PySyft/pull/4552?src=pr&el=tree)

```diff
@@           Coverage Diff           @@
##           master    #4552   +/-   ##
=======================================
  Coverage   94.75%   94.75%           
=======================================
  Files         209      209           
  Lines       21464    21464           
=======================================
  Hits        20339    20339           
  Misses       1125     1125           
```


| [Impacted Files](https://codecov.io/gh/OpenMined/PySyft/pull/4552?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [syft/version.py](https://codecov.io/gh/OpenMined/PySyft/pull/4552/diff?src=pr&el=tree#diff-c3lmdC92ZXJzaW9uLnB5) | `100.00% <100.00%> (ø)` | |
",report master change coverage coverage impacted file tree graph coverage master coverage impacted coverage,issue,negative,neutral,neutral,neutral,neutral,neutral
691642599,@mccorby there are integration tests in pygrid already and here the changes were done only in the notebook for compatibility,integration already done notebook compatibility,issue,negative,neutral,neutral,neutral,neutral,neutral
691630736,You might need to rerun the linter for this (there is a new black version),might need rerun linter new black version,issue,negative,negative,neutral,neutral,negative,negative
691630093,You want to say that the worker that orchestrates the training/inference has a part of the data/model on their side?,want say worker part side,issue,negative,neutral,neutral,neutral,neutral,neutral
691629889,"Hey @roberthoenig!

I think this is a good idea ^_^ and we will accept PRs that adds functionalities on top of PySyft. What do you think @LaRiffle ?",hey think good idea accept top think,issue,positive,positive,positive,positive,positive,positive
691579019,Excellent! Thank you so much for helping buffer our the documentation! This is super important (and timely) work!,excellent thank much helping buffer documentation super important timely work,issue,positive,positive,positive,positive,positive,positive
691138634,"Hi @gmuraru, WIP check hasn't still completed, so what should I do? Or is there anything else I need to change?",hi check still anything else need change,issue,negative,neutral,neutral,neutral,neutral,neutral
690996106,"@LaRiffle I am getting this error:
```
f""You tried to run a crypto protocol on worker {crypto_store._owner.id} ""
AttributeError: 'str' object has no attribute '_owner'
```",getting error tried run protocol worker object attribute,issue,negative,neutral,neutral,neutral,neutral,neutral
690981634,"> LGTM! I did not run it yet :( I can try to run it tomorrow and provide more input - if something goes haywire

Oh yeah that would be awesome :D ",run yet try run tomorrow provide input something go haywire oh yeah would awesome,issue,positive,positive,positive,positive,positive,positive
690879358,Hi @abogaziah I would like to attempt this if still available,hi would like attempt still available,issue,negative,positive,positive,positive,positive,positive
690877149,"@gmuraru hi, I can work on this if still available",hi work still available,issue,negative,positive,positive,positive,positive,positive
690876618,"@gmuraru Hi, I can take this if still available",hi take still available,issue,negative,positive,positive,positive,positive,positive
690344908,"hey, @iamtrask, if this issue is still not taken I would like to work on this",hey issue still taken would like work,issue,negative,neutral,neutral,neutral,neutral,neutral
690325990,"We merged one of the String PRs.
I think we still need to work on/test if they work:
- test unary operators
- test binary operators against all our types (for the moment we made sure that some of the strings methods like ```len``` returns an ```Int``` from Syft, rather than an ```int``` from Python) -- We need to do this when we add full support for all the other types",one string think still need work work test unary test binary moment made sure like rather python need add full support,issue,positive,positive,positive,positive,positive,positive
690084402,Looks pretty solid to me. I guess once we merge we will need to update all the other SyPrimitives with the new SyPrimitiveRet type?,pretty solid guess merge need update new type,issue,positive,positive,positive,positive,positive,positive
689651878,"Hey, I would like to work on this issue. Can you suggest me some ways to get started?",hey would like work issue suggest way get,issue,negative,neutral,neutral,neutral,neutral,neutral
689449311,This experiment was with metaclass for the PyPrimitives instead of pure subclass with possible merits. We can look back at this later if we decide to investigate further.,experiment instead pure subclass possible look back later decide investigate,issue,negative,positive,neutral,neutral,positive,positive
689352592,I think we can also add tests to catch the exception :D,think also add catch exception,issue,negative,neutral,neutral,neutral,neutral,neutral
688915534,"@vkkhare will we use this ticket to brainstorm worker-level auth?
If so, could you update summary, please?",use ticket could update summary please,issue,negative,neutral,neutral,neutral,neutral,neutral
688855477,quick fix: just reinstall chardet module,quick fix reinstall module,issue,negative,positive,positive,positive,positive,positive
688560113,Could you please see to the failing tests and perhaps @cereallarceny or @gmuraru have a look? This was a subject of discussion recently owing to the issues we had with websocket training,could please see failing perhaps look subject discussion recently owing training,issue,negative,negative,neutral,neutral,negative,negative
688396421,"I went through multiple articles suggesting that we should use .close() first followed by .join()
the official Python documentation stats the following:
![Screenshot 2020-09-07 at 9 01 03 PM](https://user-images.githubusercontent.com/28955148/92402480-4031c200-f14d-11ea-89fa-c3fa0312e606.png)
though at many places including the official examples have not used .close().

![Screenshot 2020-09-07 at 9 02 50 PM](https://user-images.githubusercontent.com/28955148/92402631-7f601300-f14d-11ea-9284-fb9dce4b12af.png)

so here I am in the dilemma of replacing it or not. :) ",went multiple suggesting use first official python documentation following though many official used dilemma,issue,negative,positive,positive,positive,positive,positive
688329526,Looking great so far! Should we merge this as an incremental fix?,looking great far merge incremental fix,issue,positive,positive,positive,positive,positive,positive
688286272,"I tested PySyft versions 0.2.2 to 0.2.6 with the code above. Up to version 0.2.5 the `add_dataset()` method is working. In 0.2.6 it is broken.

Best regards!
d

ps: thanks for this great library",tested code version method working broken best thanks great library,issue,positive,positive,positive,positive,positive,positive
688276799,"Same here using PySyft 0.2.8


```
import pandas as pd
import numpy as np
import torch
import syft as sy

[...]

if __name__ == ""__main__"":
    
    # init PySyft
    hook = sy.TorchHook(torch)
        
    # load data
    data = pd.read_csv(""worker-train.csv"")

    # split data into sequences by using sliding window technique
    X, y = get_train_data_and_labels(data)
    
    # create syft dataset 
    dataset = sy.BaseDataset(data=X, targets=y)
    
    # setup server
    websocket_server = sy.WebsocketServerWorker(hook=hook, id=""worker-0"", host=""0.0.0.0"", port=""9999"")
    websocket_server.add_dataset(dataset, key=""some-key"")
```

```
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-80-c62cd3dd5cb7> in <module>
     18     # setup server
     19     websocket_server = WebsocketServerWorker(hook=hook, id=""worker-0"", host=""0.0.0.0"", port=""9999"")
---> 20     websocket_server.add_dataset(dataset)
     21 
     22 

AttributeError: 'WebsocketServerWorker' object has no attribute 'add_dataset'
```",import import import torch import hook torch load data data split data sliding window technique data create setup server recent call last module setup server object attribute,issue,negative,neutral,neutral,neutral,neutral,neutral
688110933,"> Great work. I played around with this locally and it works great. It's cool that Python gives us UserList to do this in such a clean way.
> 
> I fixed a few mypy / linting issues I saw after running scripts/pre_commit.sh here if you want to merge those in:
> https://github.com/OpenMined/PySyft/tree/python-lists-linting
> 
> The only thing I started thinking was, will there be any naming clash issues with the existing:
> 
> ```
> from typing import List
> ```
> 
> Perhaps we should prefix our Collections and Primitives so they are immediately clear rather than causing possible confusion about where they come from. I do prefer the shorter written version without a prefix but I can also see how easily someone could get mixed up with the native types if they see these:
> 
> ```python
> Int()
> List()
> Bool()
> 
> vs 
> 
> SyInt()
> SyList()
> SyBool()
> ```

Thanks, I'll take your commit 🙂 

As for the naming, I myself had this syft.List / typing.List clash... So I do agree that we could prefix our types with ""Sy"". Maybe after all the current PRs on primitive types are merged?",great work around locally work great cool python u clean way fixed saw running want merge thing thinking naming clash import list perhaps prefix immediately clear rather causing possible confusion come prefer shorter written version without prefix also see easily someone could get mixed native see python list bool thanks take commit naming clash agree could prefix maybe current primitive,issue,positive,positive,positive,positive,positive,positive
688010432,"@radusqrt thank you, your solution works!  
And I think, just as mentioned by @addy369 , this issue should be fixed as soon as possible.",thank solution work think issue fixed soon possible,issue,positive,positive,neutral,neutral,positive,positive
687947845,"Great work. I played around with this locally and it works great. It's cool that Python gives us UserList to do this in such a clean way.

I fixed a few mypy / linting issues I saw after running scripts/pre_commit.sh here if you want to merge those in:
https://github.com/OpenMined/PySyft/tree/python-lists-linting

The only thing I started thinking was, will there be any naming clash issues with the existing:
```
from typing import List
```

Perhaps we should prefix our Collections and Primitives so they are immediately clear rather than causing possible confusion about where they come from. I do prefer the shorter written version without a prefix but I can also see how easily someone could get mixed up with the native types if they see these:

```python
Int()
List()
Bool()

vs 

SyInt()
SyList()
SyBool()
```",great work around locally work great cool python u clean way fixed saw running want merge thing thinking naming clash import list perhaps prefix immediately clear rather causing possible confusion come prefer shorter written version without prefix also see easily someone could get mixed native see python list bool,issue,positive,positive,positive,positive,positive,positive
687628377,If you try to update the ```Pillow``` version from ```pip-dep/requirements.txt``` does everything works correctly?,try update pillow version everything work correctly,issue,negative,neutral,neutral,neutral,neutral,neutral
687613319,@iamtrask could you assign anyone to review this pull request please?,could assign anyone review pull request please,issue,negative,neutral,neutral,neutral,neutral,neutral
687590300,Another subtask of this epic to wrap this SMPC  in a class @LaRiffle @gmuraru ,another epic wrap class,issue,negative,positive,neutral,neutral,positive,positive
686803751,I feel this is a good one to start with. Can i work on this @iamtrask ,feel good one start work,issue,negative,positive,positive,positive,positive,positive
686266358,"> ## Description
> When I send the tensor X from python notebook to bob worker that running by using WebsockerServer instead of the virtual machine in another instance (IP address: A). I also create another instance Alice worker by using WebsocketServer (IP address: B). I cannot run this command ""x.share(Alice, bob)"" They said cannot serialize the WebsocketClientWorker.
> `
> 
> ## How to Reproduce
> ```
> from torchvision.models.resnet import ResNet, BasicBlock
> import syft as sy
> from torchvision.datasets import MNIST
> import torch.nn.functional as F
> from tqdm.autonotebook import tqdm
> from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score
> import inspect
> import time
> from torch import nn, optim
> import torch
> from torchvision.transforms import Compose, ToTensor, Normalize, Resize
> from torch.utils.data import TensorDataset, DataLoader
> from torchvision import datasets, transforms
> from syft.workers.websocket_client import WebsocketClientWorker                                                                                                                                                                                   hook = sy.TorchHook(torch)
> # verbose mode
> kwargs_websocket_worker_alice = {""host"": ""xx.xx.xx.xx"", ""hook"": hook,""verbose"":False}
> kwargs_websocket_worker_bob = {""host"": ""x.xx.xxx.xxx"", ""hook"": hook,""verbose"":False}
> alice = WebsocketClientWorker(id=""alice"", port=8777, **kwargs_websocket_worker_alice)
> bob = WebsocketClientWorker(id=""bob"", port=8778, **kwargs_websocket_worker_bob)
> test = torch.tensor([25]).send(bob)
> check = test.share(bob,alice)
> ```
> 
> The error that I got.
> 
> ```
> ---------------------------------------------------------------------------
> TypeError                                 Traceback (most recent call last)
> <ipython-input-7-4ac801f8f830> in <module>
>       1 test = torch.tensor([25]).send(bob)
> ----> 2 check = test.share(bob,alice)
> ~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in share(self, protocol, field, dtype, crypto_provider, requires_grad, no_wrap, *owners)
>     907                 dtype=dtype,
>     908                 crypto_provider=crypto_provider,
> --> 909                 **kwargs_,
>     910             )
>     911         else:
> ~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/generic/pointers/pointer_tensor.py in share(self, *args, **kwargs)
>     380             raise RuntimeError(""Error, share must have > 1 arguments all of type syft.workers"")
>     381 
> --> 382         response = self.owner.send_command(self.location, ""share"", self, args, kwargs)
>     383         return response
>     384 
> ~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/base.py in send_command(self, recipient, cmd_name, target, args_, kwargs_, return_ids, return_value)
>     624                 cmd_name, target, args_, kwargs_, return_ids, return_value
>     625             )
> --> 626             ret_val = self.send_msg(message, location=recipient)
>     627         except ResponseSignatureError as e:
>     628             ret_val = None
> ~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/base.py in send_msg(self, message, location)
>     269 
>     270         # Step 1: serialize the message to a binary
> --> 271         bin_message = sy.serde.serialize(message, worker=self)
>     272 
>     273         # Step 2: send the message and wait for a response
> ~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/serde/serde.py in serialize(obj, worker, simplified, force_full_simplification, strategy)
>      43         strategy = serialize
>      44 
> ---> 45     return strategy(obj, worker, simplified, force_full_simplification)
>      46 
>      47 
> ~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/serde/msgpack/serde.py in serialize(obj, worker, simplified, force_full_simplification)
>     335 
>     336     simple_objects = _serialize_msgpack_simple(obj, worker, simplified, force_full_simplification)
> --> 337     return _serialize_msgpack_binary(simple_objects)
>     338 
>     339 
> ~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/serde/msgpack/serde.py in _serialize_msgpack_binary(simple_objects, worker, simplified, force_full_simplification)
>     289     # 2) Serialize
>     290     # serialize into a binary
> --> 291     binary = msgpack_lib.dumps(simple_objects)
>     292 
>     293     # 3) Compress
> ~/anaconda3/envs/pysyft/lib/python3.7/site-packages/msgpack/__init__.py in packb(o, **kwargs)
>      33     See :class:`Packer` for options.
>      34     """"""
> ---> 35     return Packer(**kwargs).pack(o)
>      36 
>      37 
> msgpack/_packer.pyx in msgpack._cmsgpack.Packer.pack()
> msgpack/_packer.pyx in msgpack._cmsgpack.Packer.pack()
> msgpack/_packer.pyx in msgpack._cmsgpack.Packer.pack()
> msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()
> msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()
> msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()
> msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()
> msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()
> msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()
> msgpack/_packer.pyx in msgpack._cmsgpack.Packer._pack()
> TypeError: can not serialize 'WebsocketClientWorker' object
> ```

I had the same problem. Did you solve it?",description send tensor python notebook bob worker running instead virtual machine another instance address also create another instance worker address run command bob said serialize reproduce import import import import import import import inspect import time torch import import torch import compose normalize resize import import import hook torch verbose mode host hook hook verbose false host hook hook verbose false bob bob test bob check bob error got recent call last module test bob check bob share self protocol field else share self raise error share must type response share self return response self recipient target target message except none self message location step serialize message binary message step send message wait response serialize worker simplified strategy strategy serialize return strategy worker simplified serialize worker simplified worker simplified return worker simplified serialize serialize binary binary compress see class packer return packer serialize object problem solve,issue,negative,negative,negative,negative,negative,negative
686170584,"@iamtrask , @madhavajay It's still in **WIP** status due to the need of develop unit tests (I'm trying to implement some integration tests as well). But any thoughts / suggestions would be very welcome.",still status due need develop unit trying implement integration well would welcome,issue,positive,positive,positive,positive,positive,positive
685668091,"update black and run it on your fork, or sync it with upstream/master, changed files currently 69, it should be around 5 when you do that successfully ",update black run fork sync currently around successfully,issue,negative,positive,positive,positive,positive,positive
685514581,"Hey, @gmuraru yup I'm still working on this, but will not be able to give any update as I have my exams till 10th September. After that I will start working on it with full force.🙂",hey still working able give update till th start working full force,issue,negative,positive,positive,positive,positive,positive
685244661,"My apologies for the late response, I must've missed your message. 

I've actually succeeded in installing the latest version of PySyft (v0.2.8) in a Raspberry Pi 4 (armv7l architecture).
I was successful in building torch from source but couldn't do it for torchvision so I had to use the wheel file from [HERE](https://github.com/sungjuGit/PyTorch-and-Vision-for-Raspberry-Pi-4B) to install it.
I did run into issues with aiortc and shaloop dependencies of PySyft but I eventually figured it out.

Thanks a lot for your help! ",late response must message actually latest version raspberry pi architecture successful building torch source could use wheel file install run eventually figured thanks lot help,issue,positive,positive,positive,positive,positive,positive
685110601,I would like to work on this issue (as part of my boot camp project),would like work issue part boot camp project,issue,negative,neutral,neutral,neutral,neutral,neutral
685053791,"Hey @abogaziah  @gmuraru 

I think it might be better for me to unassign myself. I'm really not sure how to fix the issue or where to put the fixes so it might be better for someone else to try and take it on. I'll close out the PR but leave a reference to it",hey think might better really sure fix issue put might better someone else try take close leave reference,issue,positive,positive,positive,positive,positive,positive
684969809,"I think your IDE/environment is betraying you by allowing you to import ""tests.syft.<rest of the import>"". This consistently breaks in OpenCI",think import rest import consistently,issue,negative,positive,positive,positive,positive,positive
684941275,I'm excited about this one! Let's include some autograd tests if we can?,excited one let include,issue,negative,positive,positive,positive,positive,positive
684816952,"> Awesome!! thank you for the PR and the changes

We make a good team! :+1: ",awesome thank make good team,issue,positive,positive,positive,positive,positive,positive
684691132,"Thanks, I will comeback later on for the first bug to see whether it appears on linux or not.",thanks comeback later first bug see whether,issue,negative,positive,positive,positive,positive,positive
684645594,@gmuraru the issue doesn't get resolved by following those steps.,issue get resolved following,issue,negative,neutral,neutral,neutral,neutral,neutral
684566591,"In the current version of syft we create a chain of tensors - and a wrapper around them. Basically, if you have something like an ```AdditiveSharingTensor``` you will have:
```
shared_tensor = torch.tensor([1,2,3], dtype=torch.long).share(alice, bob, crypto_provider=charlie, protocol=""securenn"")
print(shared_tensor)
> (Wrapper)>AST[list of shares]
```
(this^ is written from memory, but you should have something like this :D)
in this case --> ```shared_tensor.child``` represents the ```AST```",current version create chain wrapper around basically something like bob print wrapper ast list written memory something like case ast,issue,positive,neutral,neutral,neutral,neutral,neutral
684547323,"> Hi, have you find a solution?

Not yet, I have given up PySyft",hi find solution yet given,issue,negative,neutral,neutral,neutral,neutral,neutral
684530801,"I may need some time to fix other errors regarding to tensor flow on Linux.

Meanwhile,in tutorial two, I followed the example code but comes out with 
![Untitled](https://user-images.githubusercontent.com/63416489/91823544-f25c1c00-ec6b-11ea-9250-85b13c85950e.png)

ImportError: cannot import name 'ReduceOp' from 'torch.distributed' (C:\Users\user\anaconda3\envs\pysyft\lib\site-packages\torch\distributed\__init__.py)

I have do some search and found that the distributed processing seems not to support windows yet,but I can ran the code in serveral weeks ago before I install with other package or libray.How can I fix this?",may need time fix regarding tensor flow meanwhile tutorial two example code come untitled import name search found distributed support yet ran code ago install package fix,issue,negative,neutral,neutral,neutral,neutral,neutral
684439644,Could you try to run on Linux and check if the issue is still there?,could try run check issue still,issue,negative,neutral,neutral,neutral,neutral,neutral
684438627,"Yes, I was like running on Windows first before I run on Azure",yes like running first run azure,issue,positive,positive,positive,positive,positive,positive
684401776,"The sources are updating (I think) at least once in every 3-4 days
https://github.com/OpenMined/PySyft/issues/4473 <-- could you run the steps posted by @teo-milea ",think least every day could run posted,issue,negative,negative,negative,negative,negative,negative
683997269,Looks like a small linting error. rerun black?,like small error rerun black,issue,negative,negative,negative,negative,negative,negative
683948573,"Resolved. The solution turned out to be simple. Just reconstruct the model and convert it back to floating point using model.get().float_precision(). Then use torch.save(model, PATH).",resolved solution turned simple reconstruct model convert back floating point use model path,issue,negative,neutral,neutral,neutral,neutral,neutral
683682888,@IonesioJunior failing on code formatting. Please get this to pass and I'll merge it.,failing code please get pas merge,issue,negative,neutral,neutral,neutral,neutral,neutral
683591604,@steph-en-m Sure. I added a code snippet to the description. ,sure added code snippet description,issue,negative,positive,positive,positive,positive,positive
683329207,"Hello @steph-en-m!

Thanks for the PR, one mention is that we are updating our `black` version for linting. After the update, please rerun linting and commit your changes. Otherwise, LGTM! :+1: ",hello thanks one mention black version update please rerun commit otherwise,issue,positive,positive,neutral,neutral,positive,positive
683130420,"@Hjeljeli  Could you also provide a code snippet to reproduce the error. Thanks
",could also provide code snippet reproduce error thanks,issue,negative,positive,positive,positive,positive,positive
682582214,This PR is *really* coming together! I really like where this is going.,really coming together really like going,issue,negative,positive,positive,positive,positive,positive
682525112,"Hello, have you tried building from sources? This error might have been solved in the latest version that is not released yet.",hello tried building error might latest version yet,issue,negative,positive,positive,positive,positive,positive
681931435,@gkaissis ..I would like to give this a shot..how would you like me to approach this bug?,would like give shot would like approach bug,issue,positive,neutral,neutral,neutral,neutral,neutral
681140086,Hey. It might not be that easy. You can start doing that and then check out what/how breaks.,hey might easy start check,issue,negative,positive,positive,positive,positive,positive
680955321,I could do it. Is it sufficient to just call the wrap() method on the returned PointerTensor?,could sufficient call wrap method returned,issue,negative,neutral,neutral,neutral,neutral,neutral
680872456,(I cancelled your tests owing to a github Actions config experiment. If you needed these tests to merge promptly please do re-run and my apologies for the delay),owing experiment merge promptly please delay,issue,negative,neutral,neutral,neutral,neutral,neutral
680767360,"> this will break some tests, I don't know why they didn't run.
> if you can fix the broken tests that would be cool, if not, I'll wrap the pointers after calling it temporarily until you make this change and fix what it broke :)

I will create an issue around this and close this PR - seems like a good issue to get along our codebase",break know run fix broken would cool wrap calling temporarily make change fix broke create issue around close like good issue get along,issue,negative,positive,positive,positive,positive,positive
680766937,"LGTM! After you merge it, could you give me a ping to refactor [this](https://github.com/OpenMined/PySyft/pull/4474)",merge could give ping,issue,negative,neutral,neutral,neutral,neutral,neutral
680611234,"Good catch! I looked at the failing test and realised that its because its python 3.6 so I did some debugging locally and figured out that the Errors are slightly different in python 3.6. It seems like:

Python 3.7+ errors:
```
TypeError()
```

Python 3.6 errors:
```
TypeError:
```
So we need to relax the string matching a little bit.
I have created a branch off this and a PR to test the changes (which have all passed 🎉), but feel free to merge mine into your branch first and then merge this PR or the other one either is fine.

https://github.com/OpenMined/PySyft/pull/4482",good catch failing test python locally figured slightly different python like python python need relax string matching little bit branch test feel free merge mine branch first merge one either fine,issue,positive,positive,positive,positive,positive,positive
680401629,"It solved thanks!!! But It appeared another error with the program

Is that something i missed to install?
![Untitled](https://user-images.githubusercontent.com/63416489/91243206-ff64a100-e77b-11ea-833e-c0484b6e099c.png)
",thanks another error program something install untitled,issue,negative,positive,positive,positive,positive,positive
680193995,"> @aanurraj that's not going to be easy :D let me share my progress in this issue so far:
> a.fix_perc().share(bob, alice, james, protocol = ""falcon"")
> this line calls the share function of the native tensor instead of the FPT, they both have a ""share"" method, you want to call the one that belongs to FPT, so you'll probably want to edit the share function of the native tensor to do that, once you do that you'll be able to build the chain and unbuild it
> to be able to do arithmetic, that's the hard part, you will want to edit the arithmetic functions of the FPT class (add/sub) we don't support decision yet so you won't be able to support multiplication or division
> FPT class is messy and tightly coupled so making it more tightly coupled is a nightmare, so you should leave the class cleaner than you found it
> good luck! ✊

Thanks, I literally got a headache in trying to figure out, where to start from :P, Also, will ping you on slack if I have any issues. ",going easy let share progress issue far bob protocol falcon line share function native tensor instead share method want call one probably want edit share function native tensor able build chain unbuild able arithmetic hard part want edit arithmetic class support decision yet wo able support multiplication division class messy tightly coupled making tightly coupled nightmare leave class cleaner found good luck thanks literally got headache trying figure start also ping slack,issue,positive,positive,positive,positive,positive,positive
680191089,"@aanurraj  that's not going to be easy :D let me share my progress in this issue so far:
a.fix_perc().share(bob, alice, james, protocol = ""falcon"")
this line calls the share function of the native tensor instead of the FPT, they both have a ""share"" method, you want to call the one that belongs to FPT, so you'll probably want to edit the share function of the native tensor to do that, once you do that you'll be able to build the chain and unbuild it
to be able to do arithmetic, that's the hard part, you will want to edit the arithmetic functions of the FPT class (add/sub) we don't support division yet so you won't be able to support multiplication or division
FPT class is messy and tightly coupled so making it more tightly coupled is a nightmare, so you should leave the class cleaner than you found it
good luck! ✊",going easy let share progress issue far bob protocol falcon line share function native tensor instead share method want call one probably want edit share function native tensor able build chain unbuild able arithmetic hard part want edit arithmetic class support division yet wo able support multiplication division class messy tightly coupled making tightly coupled nightmare leave class cleaner found good luck,issue,positive,positive,positive,positive,positive,positive
679954686,"You need to build from repo with these steps:
-  `git clone https://github.com/OpenMined/PySyft.git`
-  `cd PySyft`
-  `pip install -r pip-dep/requirements.txt` (and possibly other files from pip-dep or other dependencies to ensure the compatibility of your venv with syft)
-  `pip install -e .`  

There will be another issue to update the version from pip to the latest release.
If there is any other problem let me know!
",need build git clone pip install possibly ensure compatibility pip install another issue update version pip latest release problem let know,issue,negative,positive,positive,positive,positive,positive
679921369,Can you please provide more info on how you want the split to be done ?,please provide want split done,issue,negative,neutral,neutral,neutral,neutral,neutral
679883956,"Hi,thank you for your help.Actually, I don't know how i made this bug.Maybe I provide the code with you first and to see whether is there a bug on your side.


[Federated learning with MNIST.zip](https://github.com/OpenMined/PySyft/files/5122356/Federated.learning.with.MNIST.zip)
",hi thank know made provide code first see whether bug side learning,issue,negative,positive,positive,positive,positive,positive
679868082,"Hello, could you provide a method to reproduce this bug? At a first glance it seems the computation command didn't find a worker, but I need a snippet to recreate the bug and help you further.",hello could provide method reproduce bug first glance computation command find worker need snippet recreate bug help,issue,negative,positive,positive,positive,positive,positive
679427200,Going to merge and continue on my branch.,going merge continue branch,issue,negative,neutral,neutral,neutral,neutral,neutral
679360768,"> This is a very nice contribution!

Thanks, it really feels amazing to get this from you!",nice contribution thanks really amazing get,issue,positive,positive,positive,positive,positive,positive
679198078,Could have been a slighlty more informative error - but this is definitely still an improvement!,could informative error definitely still improvement,issue,negative,neutral,neutral,neutral,neutral,neutral
679115442,@teo-milea you can go ahead i am currently not working on this issue.,go ahead currently working issue,issue,negative,neutral,neutral,neutral,neutral,neutral
679092845,"> Could you resolve conflict?

done :)",could resolve conflict done,issue,negative,neutral,neutral,neutral,neutral,neutral
679013642,Closing this issue since [this] (https://github.com/OpenMined/PySyft/pull/4467) PR should solve the problem,issue since solve problem,issue,negative,neutral,neutral,neutral,neutral,neutral
678999452,"> Use Python 3.6-3.7 and see if the error persists!

Hi @addy369, with 3.7 it worked! :)
Thank you so much for the precious help!",use python see error hi worked thank much precious help,issue,positive,positive,positive,positive,positive,positive
678956385,"> > LGTM
> > I recommend you create a new issue to eliminate this duplication because it duplicate a lot with `benchmark_sigmoid.py`.
> 
> Yep, I think this is a great idea! Could you create an issue? :D

Okay, I will create new issue. 😄 ",recommend create new issue eliminate duplication duplicate lot yep think great idea could create issue create new issue,issue,positive,positive,positive,positive,positive,positive
678941094,"> LGTM 
> I recommend you create a new issue to eliminate this duplication because it duplicate a lot with `benchmark_sigmoid.py`.

Yep, I think this is a great idea! Could you create an issue? :D",recommend create new issue eliminate duplication duplicate lot yep think great idea could create issue,issue,positive,positive,positive,positive,positive,positive
678809720,"> @aanurraj how does this look to you? Essentially, I recycled your code for the tanh func. Let me know if you notice anything worth changing... 😃

Looks good 👍🏻 ",look essentially code tanh let know notice anything worth good,issue,positive,positive,positive,positive,positive,positive
678796707,"@aanurraj how does this look to you? Essentially, I recycled your code for the tanh func. Let me know if you notice anything worth changing... :smiley: ",look essentially code tanh let know notice anything worth,issue,negative,positive,positive,positive,positive,positive
678783631,Use Python 3.6-3.7 and see if the error persists!,use python see error,issue,negative,neutral,neutral,neutral,neutral,neutral
678739164,"Sorry for misunderstanding at first, I added `test/crypten/*` and `test/serde/*` to omit coverage in `setup.cfg`.",sorry misunderstanding first added omit coverage,issue,negative,negative,negative,negative,negative,negative
678735202,@marload it showing that I still need a review from openmined/cryptography! So that means anyone from that team can review right?,showing still need review anyone team review right,issue,negative,positive,positive,positive,positive,positive
678713361,"Definitely! 

I'll look for the right area to put the code into. This was sloppy as I wanted to see if you and whomever else would review it thought that this was a viable solution to the problem. I didn't want to put too much work into making it look pretty until I was ready to merge (hence why I didn't even lint it) ",definitely look right area put code sloppy see whomever else would review thought viable solution problem want put much work making look pretty ready merge hence even lint,issue,positive,positive,neutral,neutral,positive,positive
678689309,Can you have a look again @marload ? I have added a modulus and signum function instead,look added modulus signum function instead,issue,negative,neutral,neutral,neutral,neutral,neutral
678657560,"> Just a suggestion: Could you remove unnecessary line-breaks 🙈

Sure :)",suggestion could remove unnecessary sure,issue,negative,positive,neutral,neutral,positive,positive
678651279,"Hi @gmuraru, I am new to OpenMined.
Can I work on this issue? If so, could you please provide some advice on how I can get started on this?
Thank you",hi new work issue could please provide advice get thank,issue,positive,positive,positive,positive,positive,positive
678623129,"> Nicely done in the test - to be clear I think we eventually also want to test all operations over all types of tensors and this sets us up for thiat. Great job.

Yep. Currently, I am looking at adding ```div```, it seems that simply adding it would throw an error",nicely done test clear think eventually also want test u great job yep currently looking div simply would throw error,issue,positive,positive,positive,positive,positive,positive
678598296,"> > There is also a coverage issue - You might need to ignore the crypten related files for coverage if windows is detected
> 
> Looked into it, couldn't find any such issues in the tests

I think @gmuraru means that the pytest functions that were excluded from pytest must also be excluded from the coverage tests.",also coverage issue might need ignore related coverage could find think must also coverage,issue,negative,neutral,neutral,neutral,neutral,neutral
678543182,Nicely done in the test - to be clear I think we eventually also want to test all operations over all types of tensors and this sets us up for thiat. Great job.,nicely done test clear think eventually also want test u great job,issue,positive,positive,positive,positive,positive,positive
678542127,Re-run black linter and it's ready to merge,black linter ready merge,issue,negative,positive,neutral,neutral,positive,positive
678262774,@IanQS let's review and merge the first fix and make the second one in a separate PR,let review merge first fix make second one separate,issue,negative,positive,positive,positive,positive,positive
677940473,Got it! I'll look into `syft.frameworks.torch.tensor.interpreters.Tensor` specifically the `add`! I'll get to it this weekend and will try my best to have something up by Monday. ,got look specifically add get weekend try best something,issue,positive,positive,positive,positive,positive,positive
677725815,"
okay let me give a try to explain
This is from pointer_tensor https://github.com/OpenMined/PySyft/blob/9e32521888192390e99363a0da2ed4b46a39a9e1/syft/generic/pointers/pointer_tensor.py#L374
```
def share(self, *args, **kwargs):
        """"""
        Send a command to remote worker to additively share a tensor

        Returns:
            A pointer to an AdditiveSharingTensor
        """"""
        if len(args) < 2:
            raise RuntimeError(""Error, share must have > 1 arguments all of type syft.workers"")

        response = self.owner.send_command(self.location, ""share"", self, args, kwargs)
        return response
```



So when you want to share a tensor from it's a pointer, we need to send a command to the owner of the tensor to connect to the  target worker with whom the tensor is going to be shared, and for that to happen we need to send the address and id of target node, for which we serialise  the`DataCentricFLCLient` and send it over to tensor owner, so it could connect to the target node,

and regarding  this

> we should serialize only the tensors (shares in this case)

we don't have shares on our machine we only have a pointer, and to share we need the target to be actually connected to the owner.(so the owner could send shares over to target node)",let give try explain share self send command remote worker additively share tensor pointer raise error share must type response share self return response want share tensor pointer need send command owner tensor connect target worker tensor going happen need send address id target node send tensor owner could connect target node regarding serialize case machine pointer share need target actually connected owner owner could send target node,issue,positive,negative,neutral,neutral,negative,negative
677718359,"For me, it is not (yet) clear why we need to serialize ```DataCentricFL``` - we should serialize only the tensors (shares in this case). Give me a second to try something",yet clear need serialize serialize case give second try something,issue,negative,positive,neutral,neutral,positive,positive
677707874,"@gmuraru for tests to run successfully, we need to start a Pygrid node instance, I made a separate workflow for it, but I am not sure in what order each workflow will run. is there a better method to initialise a grid node and keep it running while tests run.",run successfully need start node instance made separate sure order run better method grid node keep running run,issue,positive,positive,positive,positive,positive,positive
677694205,"Apologie - one more nit-picky thing. 

https://www.sphinx-doc.org/en/1.7/markup/code.html

Let's do the code example using a code block like this. This will make it print nicely when we run ""python setup.py docs""",one thing let code example code block like make print nicely run python,issue,negative,positive,positive,positive,positive,positive
677662360,"@IanQS you'd wanna look at the operations of the native tensor, since torch.Tensor+FPT calls the __add__ method of the native tensor (torch.Tensor)",wan na look native tensor since method native tensor,issue,negative,negative,negative,negative,negative,negative
677577897,"Hi, I'm currently having the same problem. Does this really work?",hi currently problem really work,issue,negative,positive,neutral,neutral,positive,positive
677528760,"> I guess the Log and NR method are a problem. Division works fine.. Will look into the issue

Also, there might be worth checking out how [CrypTen](https://github.com/facebookresearch/CrypTen) is doing - if they take into consideration negative values.

If not, one idea (it might not be the greatest) is to use symmetry.",guess log method problem division work fine look issue also might worth take consideration negative one idea might use symmetry,issue,negative,positive,positive,positive,positive,positive
677453436,I guess the Log and NR method are a problem. Division works fine.. Will look into the issue,guess log method problem division work fine look issue,issue,negative,positive,positive,positive,positive,positive
677448628,"**Please Note:** I have renamed ""location"" to ""client"" in Pointer because the code currently uses a client to dispatch messages but serializes to an ""Address"" which is going to bite us at some point so we should figure out what we want to do here. This then opens a can of circular import worms with Client being used in lots of its own super() classes to dispatch messages. Perhaps we need an interface which promises to have ""dispatch"" methods but doesnt itself inherit from Client.",please note location client pointer code currently client dispatch address going bite u point figure want circular import client used lot super class dispatch perhaps need interface dispatch doesnt inherit client,issue,positive,positive,positive,positive,positive,positive
677254252,"I merged yesterday a PR for [this](https://github.com/OpenMined/PySyft/pull/4044).
Yep - you are correct. The tests are passing, but there is a scenario that we do not take care of. Opened a new issue for this - [here](https://github.com/OpenMined/PySyft/issues/4048)",yesterday yep correct passing scenario take care new issue,issue,positive,positive,positive,positive,positive,positive
677237406,"> There is also a coverage issue - You might need to ignore the crypten related files for coverage if windows is detected

Looked into it, couldn't find any such issues in the tests",also coverage issue might need ignore related coverage could find,issue,negative,neutral,neutral,neutral,neutral,neutral
677003378,There is also a coverage issue - You might need to ignore the crypten related files for coverage if windows is detected,also coverage issue might need ignore related coverage,issue,negative,neutral,neutral,neutral,neutral,neutral
676848520,"@gmuraru 

I've linked my PR to this. Let me know if you think I'm going down the wrong path. I'd love to get feedback as I go along. I'm still trying to figure out how to address the `PureFrameworkTensorFoundError`",linked let know think going wrong path love get feedback go along still trying figure address,issue,negative,neutral,neutral,neutral,neutral,neutral
676847107,"> Woah! @madhavajay I don't know what exactly you did, but it solved the major part of my issues. Thank you so much!
> 
> Also, I'd like to ask you a couple of questions that maybe you can help me to understand.
> **First**: In your PR, you deleted the `obj2pointer_type` method, but in the current stage of `syft_0.3.0` branch we're still using it during `Search` service. Should I keep this method there, or should I delete it?
> 
You are 100% correct, this is a mistake and im glad you spotted it.

> **Second**: I'm finally able to build new SignalingMessage schemas and serialize them, but during the deserialization process, I'm getting an error about the lack of `schema2type` attribute. It happens when I try to deserialize one of my message attributes (string type) during proto2obj execution. Am I missing something?
> Again, thank you so much for your help! :)

I created a test and the fixed a few issues, and it works. I think the issue was you were not saving the data so when it tried to create a new object without the data on the deserialization side it failed.
Take a look at the changes and you will see what I did. Also its a good idea to make a serde test for any new messages or services and then you can be sure they are working.

I rebased your branch onto syft_0.3.0 so that it can be merged immediately. Unfortunately theres no easy way to PR to a PR, so for now we can just do it over here:
https://github.com/OpenMined/PySyft/pull/4046

Or if you prefer you can merge this into your branch, but because of the rebase the commits have been re-written.
Your commit history and ""authorship"" of the code is retained so there isnt really any downside to the rebase.

I will message you on slack a link to the new API Example notebook which might help explain a bit of the Serde / SignedMessage stuff. I think we should merge this ASAP and then continue to work on it branching back off syft_0.3.0 keeping the PR's to shorter 1 day cycles so that the require less rebasing. Since the Websocket stuff is fairly independent there shouldnt be much conflict anyway.



",know exactly major part thank much also like ask couple maybe help understand first method current stage branch still search service keep method delete correct mistake glad spotted second finally able build new serialize process getting error lack attribute try one message string type execution missing something thank much help test fixed work think issue saving data tried create new object without data side take look see also good idea make test new sure working branch onto immediately unfortunately there easy way prefer merge branch rebase commit history authorship code really downside rebase message slack link new example notebook might help explain bit stuff think merge continue work branching back keeping shorter day require le since stuff fairly independent shouldnt much conflict anyway,issue,positive,positive,positive,positive,positive,positive
676556029,"> Could you move them to a separate dir. as we have decided. We can have it merged right after that 🎉

done! I was waiting for you both to reply. Thanks :)",could move separate decided right done waiting reply thanks,issue,negative,positive,positive,positive,positive,positive
676551864,"> should I skip them as files them too or let them be? Currently they are marked as expected to fail

I guess having it as an xfail is sufficient. ",skip let currently marked fail guess sufficient,issue,negative,negative,negative,negative,negative,negative
676522963,"@gmuraru so the installation instructions are a bit outdated...I have also confirmed @radusqrt is right. Pip install crypten has a different structure than when cloning from the repo https://github.com/facebookresearch/CrypTen/tree/master/crypten. I can update the installation readme
",installation bit outdated also confirmed right pip install different structure update installation,issue,negative,positive,neutral,neutral,positive,positive
676518189,"this will break some tests, I don't know why they didn't run.
if you can fix the broken tests that would be cool, if not, I'll wrap the pointers after calling it temporarily until you make this change and fix what it broke :)",break know run fix broken would cool wrap calling temporarily make change fix broke,issue,negative,negative,neutral,neutral,negative,negative
676508028,"So multiple things. Firstly, should'nt we get a value >1 and not <1 as the assert suggests! Also the reciprocal method is tested.Passing method=""division  is just a default parameter and anyway tests with all methods(divison,log,nr) are getting passed. Tell me if I am missing something",multiple firstly get value assert also reciprocal method division default parameter anyway log getting tell missing something,issue,negative,positive,neutral,neutral,positive,positive
676506064,"I'm aware this is a stale & closed issue, but it seems like a strange decision to force a pinned dependency on those using the library for the sake of a specific use case (Udacity course). 

As an aside, including `notebook` as a dependency for a specific use-case, when someone is using IPython on GCloud seems a little over the top, it seems like that would make more sense as an `extra`.",aware stale closed issue like strange decision force pinned dependency library sake specific use case course aside notebook dependency specific someone little top like would make sense extra,issue,positive,negative,neutral,neutral,negative,negative
676504998,"Heya @gmuraru ! 

I've started working on it but I'm running into roadblocks. I've solved the 

`torch.tensor(5) + torch.tensor(5).fix_prec()).float_prec() = tensor(5.0050)` but admittedly my solution isn't pretty and I've not run tests to make sure that my changes don't break anything. 

I'm not too sure about how to solve the first issue (`PureFrameworkTensorFoundError`) I'd love some guidance if you've got any insight into it",working running tensor admittedly solution pretty run make sure break anything sure solve first issue love guidance got insight,issue,positive,positive,positive,positive,positive,positive
676175596,@IanQS how it goes with this issue. Did you start work on it?,go issue start work,issue,negative,neutral,neutral,neutral,neutral,neutral
676028383,"Woah!  @madhavajay I don't know what exactly you did, but it solved the major part of my issues. Thank you so much!

Also, I'd like to ask you a couple of questions that maybe you can help me to understand.
**First**: In your PR, you deleted the `obj2pointer_type` method, but in the current stage of `syft_0.3.0` branch we're still using it during `Search` service. Should I keep this method there, or should I delete it?

**Second**: I'm finally able to build new SignalingMessage schemas and serialize them, but during the deserialization process, I'm getting an error about the lack of `schema2type`  attribute. It happens when I try to deserialize one of my message attributes (string type) during proto2obj execution. Am I missing something?

Again, thank you so much for your help!  :)",know exactly major part thank much also like ask couple maybe help understand first method current stage branch still search service keep method delete second finally able build new serialize process getting error lack attribute try one message string type execution missing something thank much help,issue,positive,positive,positive,positive,positive,positive
676024855,"Yeah that worked thanks! So now I'm checking if its a Windows system and ignoring all test in `test\crypten`, but still using individual checks for the other two files because only a small part of their checks depend on crypten, should I skip them as files them too or let them be? Currently they are marked as expected to fail",yeah worked thanks system test still individual two small part depend skip let currently marked fail,issue,negative,negative,neutral,neutral,negative,negative
676021168,"I got the same error on Linux with Python 3.7.7.

**Problem:** Apparently, when you install **crypten** using ""python -m pip install crypten"" it doesn't create the same structure as here: https://github.com/facebookresearch/CrypTen/tree/master/crypten/nn

The only release is from Feb 5, before the commit (https://github.com/facebookresearch/CrypTen/commit/1aa8cedced113806e3b35f653bcd03f2cf364d6b#diff-901387c8cb64f231ab7b5bb4cad43497) which creates the file causing the error (onnx_converter.py): https://pypi.org/project/crypten/#history

**Solution:** I just hacked it by copying everything from here [1] to [2]. It works now, but we should modify the documentation, I guess.
[1]: https://github.com/facebookresearch/CrypTen/tree/master/crypten
[2]: ~/anaconda3/envs/pysyft/lib/python3.7/site-packages/crypten/

Let me know if you have any idea on how to automatically fix this issue instead of hacking it like I did above.",got error python problem apparently install python pip install create structure release commit file causing error solution hacked everything work modify documentation guess let know idea automatically fix issue instead hacking like,issue,negative,positive,neutral,neutral,positive,positive
675994374,"I have added an Example API notebook with asserts that is also run as a CI job.
The purpose of this notebook is to provide Dev Documentation with working examples that are verified on every PR.",added example notebook also run job purpose notebook provide dev documentation working every,issue,negative,neutral,neutral,neutral,neutral,neutral
675928333," I keep getting this error ""cannot import name 'onnx_converter'  from crypten.nn and that makes sense because there is no onnx_converter defined there",keep getting error import name sense defined,issue,negative,neutral,neutral,neutral,neutral,neutral
675927569,"Actually it isn't working with python 3.7 too
Can you please follow these steps
Create a virtual environment with Python 3.7
Install torch 1.4 and vison 0.5.0
Clone pysyft
Cd into directory
Run python setup.py
Run python setup.py test",actually working python please follow create virtual environment python install torch vison clone directory run python run python test,issue,positive,neutral,neutral,neutral,neutral,neutral
675880294,"The issue is related to the method we use for ```sigmoid``` when computing ```reciprocal```.
Could you make a PR where you can simply add ```method=""division""``` to the reciprocal.",issue related method use sigmoid reciprocal could make simply add division reciprocal,issue,negative,neutral,neutral,neutral,neutral,neutral
675863560,"> Not any way I know of, if they were all in a class or module we could have with pytest.mark.skipif(), to skip entire file only pytest.mark.skip is available but this unconditionally skips all tests, so the tests wouldn't run on Linux and Mac too

It seems that we can skip a file using the ```conftest.py```. There are more details [here](https://docs.pytest.org/en/latest/example/pythoncollection.html#customizing-test-collection) - did not test it, but looks promising",way know class module could skip entire file available unconditionally would run mac skip file test promising,issue,negative,positive,positive,positive,positive,positive
675862632,Assigned it to you! But I think this will require more research since it seems that the value is pretty high and probably we do something behind the scenes which brokes the ```exp```. A simple increase in the tolerance would not do the job.,assigned think require research since value pretty high probably something behind simple increase tolerance would job,issue,positive,positive,neutral,neutral,positive,positive
675859617,"In the PyGrid case, you will simply have to change the ```VirtualWorker``` with a different component.
Maybe also [this repo](https://github.com/OpenMined/PyGrid) will help",case simply change different component maybe also help,issue,negative,neutral,neutral,neutral,neutral,neutral
675823610,"> Are the tutorials helping (they can be found in this repository)?

Those are using Pysfyt and use the local virtual worker, I'd like to use the pygrid and to do the encrypted deep learning",helping found repository use local virtual worker like use deep learning,issue,positive,neutral,neutral,neutral,neutral,neutral
675687121,Hey @gmuraru would want to work on this!,hey would want work,issue,negative,neutral,neutral,neutral,neutral,neutral
675614747,"Not any way I know of, if they were all in a class or module we could have with pytest.mark.skipif(), to skip entire file only pytest.mark.skip is available but this unconditionally skips all tests, so the tests wouldn't run on Linux and Mac too",way know class module could skip entire file available unconditionally would run mac,issue,negative,positive,positive,positive,positive,positive
675571586,"Yep.
I think it would be a good idea to move those to another folder (I thought initially that it would be a good place in the ```mpc``` folder).

Thinking now again, maybe it is worth to create a new directory (at the root) named ```benchmarks``` and there have ```frameworks/torch/mpc``` <-- and here to have the scripts+graphs (everything related to benchmarking)

What do you guys think?",yep think would good idea move another folder thought initially would good place folder thinking maybe worth create new directory root everything related think,issue,positive,positive,positive,positive,positive,positive
675568895,Can't we have a skip method for the entire file (rather than marking each individual test?),ca skip method entire file rather marking individual test,issue,negative,neutral,neutral,neutral,neutral,neutral
675565640,"@H4LL @LaRiffle  can you review this,  its causing a security issue error in CI tests.",review causing security issue error,issue,negative,neutral,neutral,neutral,neutral,neutral
675562781,"The fail shows `FAILED test/torch/tensors/test_precision.py::test_torch_sigmoid_approx[exp-3-0.065]` and I didn't touch the function and neither is it dependent on anything I changes/added, so do I need to worry about it?",fail touch function neither dependent anything need worry,issue,negative,negative,negative,negative,negative,negative
675543348,"@cereallarceny  I could add these updates to `ModelCentricFLClient` and `FLClient` we might need serialization of these two also, let me know",could add might need serialization two also let know,issue,negative,neutral,neutral,neutral,neutral,neutral
675538226,"Hey, I figured out a way to bypass cyclic import issue using pickle for simplifying `DataCentricFLClient`, It's working :), sharing tensor(on grid nodes) from its pointer is now functional. @IonesioJunior @gmuraru can you review this.",hey figured way bypass cyclic import issue pickle working tensor grid pointer functional review,issue,negative,neutral,neutral,neutral,neutral,neutral
675524217,"I agree on both points @Syzygianinfern0. I think we should keep the benchmarks along with the tests... As for the matplotlib dependency: I could swear that it was included somewhere, but I've just checked and it's only in the `requirements_notebooks.txt` so it might be worth adding to the dev requirements.

Apart from that, it looks good to me too 🚀 

Let's wait on @gmuraru and if he agrees maybe we could merge with that change in mind.",agree think keep along dependency could swear included somewhere checked might worth dev apart good rocket let wait maybe could merge change mind,issue,positive,positive,positive,positive,positive,positive
675340921,"> Hi @Syzygianinfern0 I don't think the current version of requirements.txt has 'matplotlib'.

Yeah... I just had a look too. As we don't intend this to be used as a Syft API by the user at any point explicitly (just like tests), we could have something similar to how tests do it maybe? ie. by putting it under here: https://github.com/OpenMined/PySyft/blob/master/pip-dep/requirements_dev.txt

Thoughts @gmuraru :thinking: ",hi think current version yeah look intend used user point explicitly like could something similar maybe ie thinking,issue,positive,neutral,neutral,neutral,neutral,neutral
675336439,"> Secondly, @aanurraj you have mentioned `matplotlib` under ""Affected Dependencies""
> 
> Is the current version from requirements.txt not complying with the code?

Hi @Syzygianinfern0 I don't think the current version of requirements.txt has 'matplotlib'.",secondly affected current version code hi think current version,issue,negative,neutral,neutral,neutral,neutral,neutral
675327837,"Secondly, @aanurraj you have mentioned `matplotlib` under ""Affected Dependencies""

Is the current version from requirements.txt not complying with the code? ",secondly affected current version code,issue,negative,neutral,neutral,neutral,neutral,neutral
675322409,"@marload 
A couple of things to consider for future PRs :smile: 
- Squashing basic commits to hold a good commit structure before a push
- Working on a branch different from the master on your fork (makes it easier for you)

Thank you again for your contributions!",couple consider future smile basic hold good commit structure push working branch different master fork easier thank,issue,positive,positive,positive,positive,positive,positive
675310367,"Also @iamtrask  and @IonesioJunior, I found one possible issue I wanted to check:
`src/syft/core/node/common/service/child_node_lifecycle_service.py`
<img width=""906"" alt=""Screen Shot 2020-08-18 at 5 27 57 pm"" src=""https://user-images.githubusercontent.com/2882739/90483522-2cabc080-e178-11ea-9997-de7199f5c008.png"">

Since we needed to change the storage to use serialized versions of the client addresses (the whole client wasn't available in the method to get its id and other properties), I added a field for the key / look up, and since in the case of Client it is usually the ""address"" you want to dispatch to, I had it set to:
`lookup_id=client.id`

But there could be other times where the storage key is something like a msg.id, so I hope I haven't broken anything, just double checking this is correct. Also speaking of, the ""msg_id"" is now persisted across the serialization barrier in and out of signing a message, which makes it super easy to track a message in the debug output, however... I don't know if there is an expectation that msg_id's are unique between node routing hops or between the non-signed and signed version of a message?


",also found one possible issue check screen shot since change storage use client whole client available method get id added field key look since case client usually address want dispatch set could time storage key something like hope broken anything double correct also speaking across serialization barrier message super easy track message output however know expectation unique node routing version message,issue,positive,positive,neutral,neutral,positive,positive
675307015,"Hi @IonesioJunior awesome work!

I made a branch off this PR and fixed a few issues:
https://github.com/OpenMined/PySyft/tree/bidirectional_connection_fixes

You should be able to merge or rebase this into your branch and then push again.
I didn't get time for WS Duet tests, but that would be a good idea.
The WSDuet needs something to ""serve"" so it can ""connect"", thats as far as I got after all the little fixes and clean ups.

I also added some enhanced debugging by allowing naming to persist across serialization and within client and address creation. Also the ability to see whats in the store easily. I also added a random_name generator just like Docker, so we should always have something to see and match in Client / Node / Address both with the emoji Visual IDs / UUIDs and the Unique Names (if we don't set one).

Check out the Early Dev notebook:
<img width=""1064"" alt=""Screen Shot 2020-08-18 at 3 09 43 pm"" src=""https://user-images.githubusercontent.com/2882739/90482887-40a2f280-e177-11ea-870e-6ba6d07a8bf0.png"">

Also, I think we are trying to upgrade our `protoc` to a newer version so that the git commits don't always conflict.
The newer version creates this line in all the pb2 files:
<img width=""760"" alt=""Screen Shot 2020-08-18 at 3 12 17 pm"" src=""https://user-images.githubusercontent.com/2882739/90482966-5fa18480-e177-11ea-8753-a6f90636ced8.png"">

Can you check your version and try upgrading?
```
$ protoc --version
libprotoc 3.12.4
```

One last thing, it would be great if you could also use the pre_commit script during development, it helps catch flake8 and mypy issues early.

Just run it like this:
```
$ scripts/pre_commit.sh
```

I find its awesome to run before PR so that I know the linter and tests will all pass in CI.



",hi awesome work made branch fixed able merge rebase branch push get time duet would good idea need something serve connect thats far got little clean also added enhanced naming persist across serialization within client address creation also ability see whats store easily also added generator like docker always something see match client node address visual unique set one check early dev notebook screen shot also think trying upgrade version git always conflict version line screen shot check version try version one last thing would great could also use script development catch flake early run like find awesome run know linter pas,issue,positive,positive,positive,positive,positive,positive
675289983,I think we can go with ```chebyshev``` as the default one,think go default one,issue,negative,neutral,neutral,neutral,neutral,neutral
675283951,"> Is this feature added? I want to use a Python library on a remote worker. How can I do that?
> Thanks!!

Currently, there is a decorator that might allow you to do that ```@allow_command``` (this is for single function use).
The new version of pySyft 0.3 might have what you are looking for",feature added want use python library remote worker thanks currently decorator might allow single function use new version might looking,issue,positive,positive,neutral,neutral,positive,positive
675283131,"If we change such that ```sigmoid``` uses ```chebyshev``` by default, does it work?",change sigmoid default work,issue,negative,neutral,neutral,neutral,neutral,neutral
675274450,"`method='NR'` uses the Approx Exp, so there is a little more error than `method='division'`. I think this problem is caused by the error because `tanh` uses `_sigmoid_exp`.",little error think problem error tanh,issue,negative,negative,negative,negative,negative,negative
675253962,"Is the NR scheme buggy? Why did it fail for that?

> @Syzygianinfern0 @gmuraru
> 
> The error appears to be caused by a small error in the NR. We solved this problem by setting the default value of reciprocal to division.

But how does an error tolerance of about `1e-2` (as seen from the test cases you've written) propagate to something like `assert 20 < 1` ?",scheme buggy fail error small error problem setting default value reciprocal division error tolerance seen test written propagate something like assert,issue,negative,negative,negative,negative,negative,negative
675250723,"@Syzygianinfern0 @gmuraru 

The error appears to be caused by a small error in the NR. We solved this problem by setting the default value of reciprocal to division. :smile:",error small error problem setting default value reciprocal division smile,issue,negative,positive,neutral,neutral,positive,positive
675184216,"@AbhishekPokala I found the base ISO that I generated back then. In case it is of any use for you, you can get it from the link referenced in [this repo](https://github.com/brahman-ai/RPiSyft). Just remember that the syft and grid installed there are the pulled from the custom fork I mentioned before, which are outdated compared to current PySyft codebase. 

Maybe that is good enough for you right now, or maybe it is you succeed updating the code from the dependencies already installed in the ISO :crossed_fingers: ",found base iso back case use get link remember grid custom fork outdated current maybe good enough right maybe succeed code already iso,issue,positive,negative,neutral,neutral,negative,negative
675174064,"@AbhishekPokala Then I would try again by installing Torch through that wheel but now installing the official OpenMined fork. Back in January I made a custom repo because there were cross references and I merged two different forks to align them, but the codebase has moved a lot!

I'm not working with Pis and AI right now, but I could also try to replicate the installation on the weekend to try to see what has changed, in case you don't succeed by then :)",would try torch wheel official fork back made custom cross two different align lot working ai right could also try replicate installation weekend try see case succeed,issue,negative,positive,neutral,neutral,positive,positive
675172201,"@alejandrosame:
Yep.

> Defaulting to user installation because normal site-packages is not writeable
> Requirement already satisfied: syft-proto in /home/abhishek/.local/lib/python3.7/site-packages (0.5.1)
> Requirement already satisfied: protobuf>=3.12.2 in /home/abhishek/.local/lib/python3.7/site-packages (from syft-proto) (3.13.0)
> Requirement already satisfied: six>=1.9 in /home/abhishek/.local/lib/python3.7/site-packages (from protobuf>=3.12.2->syft-proto) (1.15.0)
> Requirement already satisfied: setuptools in /usr/local/lib/python3.7/site-packages (from protobuf>=3.12.2->syft-proto) (39.0.1)",yep user installation normal writeable requirement already satisfied requirement already satisfied requirement already satisfied six requirement already satisfied,issue,positive,positive,positive,positive,positive,positive
675171369,@AbhishekPokala did you also install syft-proto via `pip3 install syft-proto`?,also install via pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
675166226,"@alejandrosame:
I've installed torch and torchvision from the above wheels. 
But when I manually build syft, I get the following error: https://github.com/OpenMined/PySyft/issues/4033

And when I try to import syft after installing it from the your fork, 
I get the following error.

`import syft`

>Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/abhishek/PySyftBuildFolder/PySyft/PyGrid/src/syft/syft/__init__.py"", line 15, in <module>
    import syft.frameworks.torch.hook.hook_args
  File ""/home/abhishek/PySyftBuildFolder/PySyft/PyGrid/src/syft/syft/frameworks/torch/hook/hook_args.py"", line 6, in <module>
    from syft.frameworks.torch.tensors.interpreters.native import TorchTensor
  File ""/home/abhishek/PySyftBuildFolder/PySyft/PyGrid/src/syft/syft/frameworks/torch/tensors/interpreters/native.py"", line 13, in <module>
    from syft.frameworks.torch.tensors.interpreters.crt_precision import _moduli_for_fields
  File ""/home/abhishek/PySyftBuildFolder/PySyft/PyGrid/src/syft/syft/frameworks/torch/tensors/interpreters/crt_precision.py"", line 7, in <module>
    from syft.frameworks.torch.tensors.interpreters.precision import FixedPrecisionTensor
  File ""/home/abhishek/PySyftBuildFolder/PySyft/PyGrid/src/syft/syft/frameworks/torch/tensors/interpreters/precision.py"", line 7, in <module>
    from syft.generic.pointers.multi_pointer import MultiPointerTensor
  File ""/home/abhishek/PySyftBuildFolder/PySyft/PyGrid/src/syft/syft/generic/pointers/multi_pointer.py"", line 11, in <module>
    from syft.workers.base import BaseWorker
  File ""/home/abhishek/PySyftBuildFolder/PySyft/PyGrid/src/syft/syft/workers/base.py"", line 21, in <module>
    from syft.generic.pointers.object_pointer import ObjectPointer
  File ""/home/abhishek/PySyftBuildFolder/PySyft/PyGrid/src/syft/syft/generic/pointers/object_pointer.py"", line 15, in <module>
    from syft.messaging.message import ForceObjectDeleteMessage
  File ""/home/abhishek/PySyftBuildFolder/PySyft/PyGrid/src/syft/syft/messaging/message.py"", line 14, in <module>
    from syft_proto.messaging.v1.message_pb2 import OperationMessage as OperationMessagePB
ImportError: cannot import name 'OperationMessage' from 'syft_proto.messaging.v1.message_pb2' (/home/abhishek/.local/lib/python3.7/site-packages/syft_proto/messaging/v1/message_pb2.py)


@gmuraru:
The wheel files helped and I could install torch and torchvision without any additional problems.
But I've ran into a few more issues (listed above). 

Any suggestions appreciated!
Thanks! ",torch manually build get following error try import fork get following error import recent call last file line module file line module import file line module import file line module import file line module import file line module import file line module import file line module import file line module import file line module import import name wheel could install torch without additional ran listed thanks,issue,negative,positive,neutral,neutral,positive,positive
675080635,"Hello @XiaotianJia! ;)
Answering the first question:  We have some limitations due to the use of dependencies that don't optimize the transfer rate of large files. We are working on possible solutions for this and searching by optimized libraries. One of those limitations was solved and explained in this [PR ](https://github.com/OpenMined/PyGrid/pull/689) and was merged in PyGrid's dev branch.

Answering the second question: Yep, In the next PySyft version (0.3.0). I'll probably adopt async coroutines as a default approach to send/receive messages using WebSockets. You can learn about it by checking this [PR](https://github.com/OpenMined/PySyft/pull/4009/files#).


If you have any other questions/issues/suggestions feel free to create new issues or ask us in our slack channel #lib_pygrid.",hello first question due use optimize transfer rate large working possible searching one dev branch second question yep next version probably adopt default approach learn feel free create new ask u slack channel,issue,positive,positive,positive,positive,positive,positive
674883667,This issue is a reopned version of https://github.com/OpenMined/PySyft/issues/3469 checked with @LaRiffle  before opening it. :),issue version checked opening,issue,negative,neutral,neutral,neutral,neutral,neutral
674763335,"Hi, it's Sagnik from Slack, may I handle this issue?",hi slack may handle issue,issue,negative,neutral,neutral,neutral,neutral,neutral
674735389,"> Re-run the tests. It might be a problem regarding the `seed` - we might need to increase the tolerance (this issue was seen before :)

It ran 3 times and failed all of them :rofl: ",might problem regarding seed might need increase tolerance issue seen ran time,issue,negative,neutral,neutral,neutral,neutral,neutral
674729734,Re-run the tests. It might be a problem regarding the ```seed``` - we might need to increase the tolerance (this issue was seen before :\),might problem regarding seed might need increase tolerance issue seen,issue,negative,neutral,neutral,neutral,neutral,neutral
674668085,"@ege-erdogan sorry for the late reply.
Did you manage to solve the issues with the tests?",sorry late reply manage solve,issue,negative,negative,negative,negative,negative,negative
674535897,"@wicky1234444 sorry for the late reply. If you are still interested in this, yes it is up for take :+1: ",wicky sorry late reply still interested yes take,issue,positive,negative,negative,negative,negative,negative
674519462,"Yes. If `index2` is a numpy array, it works. Will the issue be resolved?",yes index array work issue resolved,issue,positive,neutral,neutral,neutral,neutral,neutral
674517960,"Yep - there is an issue. If you try to directly use ```index2``` without converting it to a tensor it works.
Thank you for signaling it :D",yep issue try directly use index without converting tensor work thank,issue,positive,positive,neutral,neutral,positive,positive
674512264,"Hi!

At the beginning of the year I successfully installed PySyft on Raspberry Pi 4s. You could check [here](https://github.com/brahman-ai/bb-aaa#setting-up-raspberry-pi-for-pysyft-and-pygrid) for inspiration, but beware that the PySyft fork used in that project is now outdated and I haven't been supporting it lately.

To install Torch and TorchVision, I used [this wheel](https://github.com/sungjuGit/PyTorch-and-Vision-for-Raspberry-Pi-4B).

I hope those pointers can help you!
Cheers.",hi beginning year successfully raspberry pi could check inspiration beware fork used project outdated supporting lately install torch used wheel hope help,issue,positive,positive,neutral,neutral,positive,positive
674423475,Hi @gmuraru I would like to work in this!,hi would like work,issue,negative,neutral,neutral,neutral,neutral,neutral
674397440,I think you will also need to change some things in ```tests``` at the serialization level + update the ```syft-proto``` repository with a new message type.,think also need change serialization level update repository new message type,issue,negative,positive,positive,positive,positive,positive
674396851,Phenominal contributions! I've also found this very frustrating! Thank you for making the experience better for you and for all of us :),also found thank making experience better u,issue,positive,positive,positive,positive,positive,positive
674390208,"Okay, so the tests pass but the code coverage is a little behind, I will fix it up later but just wanted to at least get the tests / PR stable. 😴",pas code coverage little behind fix later least get stable,issue,negative,negative,negative,negative,negative,negative
674389010,"I fixed the node tests, but I need to stop for the night.

<img width=""592"" alt=""Screen Shot 2020-08-15 at 10 08 37 pm"" src=""https://user-images.githubusercontent.com/2882739/90311965-e110d100-df43-11ea-9a3b-dc2ed0442afe.png"">
",fixed node need stop night screen shot,issue,negative,positive,neutral,neutral,positive,positive
674372393,"But currently, there is a circular import error I cannot import `DataCentricFLClient` in `syft.serde.msgpack.serde` module, as `DataCentricFLClient` uses `serde.serialize` to serialize the `model`.

cc @IonesioJunior  @iamtrask  @LaRiffle  @cereallarceny 
any suggestion, some file structure change will be required",currently circular import error import module serialize model suggestion file structure change,issue,negative,neutral,neutral,neutral,neutral,neutral
674346674,"I am finding it really hard to follow everything going on when debugging which results in lots of print messages to cave man debug. I honestly think it's slowing me down and giving me a physical headache. 😂 So I decided to make this less painful so I can see whats going on and follow it through.

I haven't added this everywhere yet just what was needed in tracing the node test through to see why one of them was failing.

The idea behind the Visual ID for addresses is to take the last 8 hex chars and turn them into 2 emojis. That way at a glance it's really easy to match UIDs visually.

I'm finding it really helpful but I understand if you think this is too intrusive. Still it might be good if we had a logging layer we could use and have this as a toggle.

<img width=""599"" alt=""Screen Shot 2020-08-15 at 2 17 22 pm"" src=""https://user-images.githubusercontent.com/2882739/90305115-56f44880-df02-11ea-9cc6-7cfff0cc2d11.png"">
",finding really hard follow everything going lot print cave man honestly think giving physical headache decided make le painful see whats going follow added everywhere yet tracing node test see one failing idea behind visual id take last hex turn way glance really easy match visually finding really helpful understand think intrusive still might good logging layer could use toggle screen shot,issue,positive,positive,neutral,neutral,positive,positive
674175288,"Hi @beatrizsmg, I see you're building from source, is there any reason for doing this rather than going the [more conventional route](https://github.com/OpenMined/PySyft#installation) of running 

```
pip install 'syft[udacity]'
```
?

---

Other than that, from reading the install instructions you linked, I think you're missing the `udacity` argument from the install command, i.e., you should be running 

```
python setup.py install udacity
```

instead of 

```
python setup.py install
```

From looking at the error trace, it seems to be related to tensorflow, which the udacity argument installs for you, so that may be the issue.

---

It might also be worth checking whether your default `python` points to Python 3. Try running 
```
python -V
```
to check.
In some systems the default Python version is still 2.7, which won't work afaik. ",hi see building source reason rather going conventional route running pip install reading install linked think missing argument install command running python install instead python install looking error trace related argument may issue might also worth whether default python python try running python check default python version still wo work,issue,negative,negative,neutral,neutral,negative,negative
674169760,"You could remove the lines  
https://github.com/OpenMined/PySyft/blob/1f36fbf0034bcaf2f8afe7ac9ccf85bcd425383e/pip-dep/requirements.txt#L21
and 
https://github.com/OpenMined/PySyft/blob/1f36fbf0034bcaf2f8afe7ac9ccf85bcd425383e/pip-dep/requirements.txt#L22

and install using a ```pip install -r pip-dep/requirements.txt```",could remove install pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
673375457,"> > > > @junrong1 For me it worked with the latest docker images using the development tag. The production one isn't working currently as it seems to be the case.
> > > > So, consider the following:
> > > > ```
> > > > docker pull openmined/grid-network:development
> > > > docker pull openmined/grid-node:development
> > > > ```
> > > > 
> > > > 
> > > > and then run the mnist federated learning example again.
> > > 
> > > 
> > > I tried to use
> > > `docker pull openmined/pysyft-notebook`
> > > but I cannaot find the link they give me.
> > 
> > 
> > Is there any tutorials for using network and node on docker?
> 
> Hi @junrong1 and @thiessl . The docker images were updated recently (a couple of day ago), actually the images are automatically udpated when a commit to develop or master is pushed.
> 
> @junrong1 , is https://hub.docker.com/r/openmined/grid-node the image you are looking for?
> 
> Please confirm this is solved in order to close the issue.
> For trazability reasons, we reccomend to open this issues directly on PyGr

> No. I run this yesterday from the docker compose from the repo without erros

",worked latest docker development tag production one working currently case consider following docker pull development docker pull development run learning example tried use docker pull find link give network node docker hi docker recently couple day ago actually automatically commit develop master image looking please confirm order close issue open directly run yesterday docker compose without,issue,positive,positive,neutral,neutral,positive,positive
673313938,I was thinking that we can have the training in the notebook and an image (or more) directly into the ```benchmark``` folder such that we might access it in an easy way.,thinking training notebook image directly folder might access easy way,issue,negative,positive,positive,positive,positive,positive
673308551,No. I run this yesterday from the docker compose from the repo without erros,run yesterday docker compose without,issue,negative,neutral,neutral,neutral,neutral,neutral
673307353,"> > > > @junrong1 For me it worked with the latest docker images using the development tag. The production one isn't working currently as it seems to be the case.
> > > > So, consider the following:
> > > > ```
> > > > docker pull openmined/grid-network:development
> > > > docker pull openmined/grid-node:development
> > > > ```
> > > > 
> > > > 
> > > > and then run the mnist federated learning example again.
> > > 
> > > 
> > > I tried to use
> > > `docker pull openmined/pysyft-notebook`
> > > but I cannaot find the link they give me.
> > 
> > 
> > Is there any tutorials for using network and node on docker?
> 
> Create a docker-compose.yml file with the following content:
> 
> ```
> version: '3'
> services:
>   network:
>     image: openmined/grid-network:development
>     environment:
>       - PORT=5000
>       - SECRET_KEY=ineedtoputasecrethere
>       - DATABASE_URL=sqlite:///databasenetwork.db
>     ports:
>       - 5000:5000
>   bob:
>     image: openmined/grid-node:development
>     environment:
>       - NODE_ID=Bob
>       - ADDRESS=http://bob:3000/
>       - PORT=3000
>       - NETWORK=http://network:5000
>       - DATABASE_URL=sqlite:///databasenode.db
> 
>     depends_on:
>       - 'network'
>     ports:
>       - 3000:3000
>   alice:
>     image: openmined/grid-node:development
>     environment:
>       - NODE_ID=Alice
>       - ADDRESS=http://alice:3001/
>       - PORT=3001
>       - NETWORK=http://network:5000
>       - DATABASE_URL=sqlite:///databasenode.db
>     depends_on:
>       - 'network'
>     ports:
>       - 3001:3001
> ```
> 
> and execute
> 
> `docker-compose up`
> 
> this ensures that alice and bob (grid-nodes) and the grid-network run based on the respective docker image (development tag, as this works with the current commit).
> 
> After that you can execute your notebook and connect to your grid-nodes properly.

I have an error with worker failed to boot. Do you know how can I fix this?",worked latest docker development tag production one working currently case consider following docker pull development docker pull development run learning example tried use docker pull find link give network node docker create file following content version network image development environment bob image development environment image development environment execute bob run based respective docker image development tag work current commit execute notebook connect properly error worker boot know fix,issue,positive,positive,neutral,neutral,positive,positive
673183030,"Hi, 
is size() included in master now?",hi size included master,issue,negative,neutral,neutral,neutral,neutral,neutral
673177211,I would like to take this up. So the results should be in a notebook right ? ,would like take notebook right,issue,negative,positive,positive,positive,positive,positive
672968295,"Hi @gmuraru, yes, I was trying to ramp up on the repo. I'll have a Pull Request soon. Apologies for the delay.",hi yes trying ramp pull request soon delay,issue,negative,neutral,neutral,neutral,neutral,neutral
672872713,The test passed! Thank you for your review :smile: ,test thank review smile,issue,positive,positive,positive,positive,positive,positive
672843663,@marload Feel free to ping any of us on Slack if you want to have to tests re-run due to a flaky failure.,feel free ping u slack want due flaky failure,issue,negative,negative,neutral,neutral,negative,negative
672823381,"> > > @junrong1 For me it worked with the latest docker images using the development tag. The production one isn't working currently as it seems to be the case.
> > > So, consider the following:
> > > ```
> > > docker pull openmined/grid-network:development
> > > docker pull openmined/grid-node:development
> > > ```
> > > 
> > > 
> > > and then run the mnist federated learning example again.
> > 
> > 
> > I tried to use
> > `docker pull openmined/pysyft-notebook`
> > but I cannaot find the link they give me.
> 
> Is there any tutorials for using network and node on docker?

Create a docker-compose.yml file with the following content:

```
version: '3'
services:
  network:
    image: openmined/grid-network:development
    environment:
      - PORT=5000
      - SECRET_KEY=ineedtoputasecrethere
      - DATABASE_URL=sqlite:///databasenetwork.db
    ports:
      - 5000:5000
  bob:
    image: openmined/grid-node:development
    environment:
      - NODE_ID=Bob
      - ADDRESS=http://bob:3000/
      - PORT=3000
      - NETWORK=http://network:5000
      - DATABASE_URL=sqlite:///databasenode.db

    depends_on:
      - 'network'
    ports:
      - 3000:3000
  alice:
    image: openmined/grid-node:development
    environment:
      - NODE_ID=Alice
      - ADDRESS=http://alice:3001/
      - PORT=3001
      - NETWORK=http://network:5000
      - DATABASE_URL=sqlite:///databasenode.db
    depends_on:
      - 'network'
    ports:
      - 3001:3001
```

and execute

`docker-compose up`

this ensures that alice and bob (grid-nodes) and the grid-network run based on the respective docker image (development tag, as this works with the current commit).

After that you can execute your notebook and connect to your grid-nodes properly.",worked latest docker development tag production one working currently case consider following docker pull development docker pull development run learning example tried use docker pull find link give network node docker create file following content version network image development environment bob image development environment image development environment execute bob run based respective docker image development tag work current commit execute notebook connect properly,issue,positive,positive,neutral,neutral,positive,positive
672811611,"> > > @junrong1 For me it worked with the latest docker images using the development tag. The production one isn't working currently as it seems to be the case.
> > > So, consider the following:
> > > ```
> > > docker pull openmined/grid-network:development
> > > docker pull openmined/grid-node:development
> > > ```
> > > 
> > > 
> > > and then run the mnist federated learning example again.
> > 
> > 
> > I tried to use
> > `docker pull openmined/pysyft-notebook`
> > but I cannaot find the link they give me.
> 
> Is there any tutorials for using network and node on docker?

Hi @junrong1 and @thiessl . The docker images were updated recently (a couple of day ago), actually the images are automatically udpated when a commit to develop or master is pushed.

@junrong1 , is https://hub.docker.com/r/openmined/grid-node the image you are looking for?

Please confirm this is solved in order to close the issue.
For trazability reasons, we reccomend to open this issues directly on PyGrid repo",worked latest docker development tag production one working currently case consider following docker pull development docker pull development run learning example tried use docker pull find link give network node docker hi docker recently couple day ago actually automatically commit develop master image looking please confirm order close issue open directly,issue,positive,positive,neutral,neutral,positive,positive
672789668,"> > @junrong1 For me it worked with the latest docker images using the development tag. The production one isn't working currently as it seems to be the case.
> > So, consider the following:
> > ```
> > docker pull openmined/grid-network:development
> > docker pull openmined/grid-node:development
> > ```
> > 
> > 
> > and then run the mnist federated learning example again.
> 
> I tried to use
> `docker pull openmined/pysyft-notebook`
> but I cannaot find the link they give me.

Is there any tutorials for using network and node on docker?",worked latest docker development tag production one working currently case consider following docker pull development docker pull development run learning example tried use docker pull find link give network node docker,issue,negative,positive,positive,positive,positive,positive
672770095,"> @junrong1 For me it worked with the latest docker images using the development tag. The production one isn't working currently as it seems to be the case.
> 
> So, consider the following:
> 
> ```
> docker pull openmined/grid-network:development
> docker pull openmined/grid-node:development
> ```
> 
> and then run the mnist federated learning example again.

I tried to use
`docker pull openmined/pysyft-notebook`
but I cannaot find the link they give me.",worked latest docker development tag production one working currently case consider following docker pull development docker pull development run learning example tried use docker pull find link give,issue,negative,positive,positive,positive,positive,positive
672748910,"@junrong1 For me it worked with the latest docker images using the development tag. The production one isn't working currently as it seems to be the case.

So, consider the following:

```
docker pull openmined/grid-network:development
docker pull openmined/grid-node:development
```

and then run the mnist federated learning example again.",worked latest docker development tag production one working currently case consider following docker pull development docker pull development run learning example,issue,negative,positive,positive,positive,positive,positive
672480034,"> @IonesioJunior @junrong1 I have the same problem of not finding the pointer via the grid search.
> Is there a workaround or a solution meanwhile?
> 
> Thx in advance!

Ohhhhhh, sorry for late respond, I haven't found the solution, could u tell me ur solution to fix this?",problem finding pointer via grid search solution meanwhile advance sorry late respond found solution could tell ur solution fix,issue,negative,negative,negative,negative,negative,negative
672326581,"Apologies - I forgot to run ""git add ."" again. I know that makes for a messy commit history. Please forgive.",forgot run git add know messy commit history please forgive,issue,negative,negative,negative,negative,negative,negative
672284139,"I have the same problem but with a convolutional network, mainly with a Conv2d layer. I think that the problem is related to issue #3509 and this one  #3550. I want to contribute for solve the problem and make .grad of this layer different from None. I tried to use the Conv2d from syft/frameworks/torch/nn/conv, but I'm still without success. The same occurs when a modified the autograd.py to support conv2d on backward pass. Based on the related issues I think, if available, that @iamtrask @karlhigley  and @vvmnnnkv can give us a start guide or tips to make these layers work in this example. I really want to contribute guys :+1: .",problem convolutional network mainly layer think problem related issue one want contribute solve problem make layer different none tried use still without success support backward pas based related think available give u start guide make work example really want contribute,issue,negative,positive,positive,positive,positive,positive
672201862,I am also interested in this project. I am currently graduate student of computer science and I have required skills and background to work on this project.,also interested project currently graduate student computer science background work project,issue,negative,positive,positive,positive,positive,positive
671846030,"Okay, I've found an docker image with a working pygrid! (development tag)",found docker image working development tag,issue,negative,neutral,neutral,neutral,neutral,neutral
671815528,"This is rebased off https://github.com/OpenMined/PySyft/pull/3983 which is in turn rebased off syft_0.3.0.
You can probably just look at the last 2 commits since the previous ones are part of the fix-mypy and syft_0.3.0 branch already.",turn probably look last since previous part branch already,issue,negative,negative,neutral,neutral,negative,negative
671814302,"Sorry, I tried to rebase and I think I made the commit graph... confusing.",sorry tried rebase think made commit graph,issue,negative,negative,negative,negative,negative,negative
671602208,"I'd like to take this on :) 

---

Formatting the exit condition and setup for easier checking

```
torch.tensor(5) + 5 = tensor(10)
torch.tensor(5) - 5 = tensor(0)
```

this should be the correct behavior of FPT:

```
(torch.tensor(5).fix_prec() - torch.tensor(5)).float_prec() = tensor(0)
(torch.tensor(5) + torch.tensor(5).fix_prec()).float_prec() = tensor(10)
```

but instead we get:

```
(torch.tensor(5).fix_prec() - torch.tensor(5)).float_prec() = PureFrameworkTensorFoundError
(torch.tensor(5) + torch.tensor(5).fix_prec()).float_prec() = tensor(5.0050)
```",like take exit condition setup easier tensor tensor correct behavior tensor tensor instead get tensor,issue,positive,neutral,neutral,neutral,neutral,neutral
671370623,"@IonesioJunior  @junrong1  I have the same problem of not finding the pointer via the grid search. 
Is there a workaround or a solution meanwhile?

Thx in advance!",problem finding pointer via grid search solution meanwhile advance,issue,negative,neutral,neutral,neutral,neutral,neutral
671336900,Good looking PR description - thank you for that!,good looking description thank,issue,positive,positive,positive,positive,positive,positive
671183993,"Please follow the command below. :smile: 

`pip install --upgrade syft-proto`",please follow command smile pip install upgrade,issue,positive,positive,positive,positive,positive,positive
671032802,"> Hey @samuxiii - i just finished this one in another place as it became a dependency for a project - can i help you find another project?

Hello, 
I am facing a problem when I try to use this functionality. Is there anything that I need to know or something.. I would appreciate the help ",hey finished one another place dependency project help find another project hello facing problem try use functionality anything need know something would appreciate help,issue,positive,neutral,neutral,neutral,neutral,neutral
670996386,This PR is too big as it is - so instead of finishing the checklist I'm going to merge where it's at now and finish the rest of the checklist in one or more followon PRs.,big instead finishing going merge finish rest one,issue,negative,neutral,neutral,neutral,neutral,neutral
670974726,"Hi @IanQS ! I updated the epic, we have split it into 2 milestones where you can know what's done and what's not:  
https://github.com/OpenMined/PySyft/milestone/15
https://github.com/OpenMined/PySyft/milestone/14
Falcon milestone isn't complete yet  ",hi epic split know done falcon milestone complete yet,issue,negative,positive,neutral,neutral,positive,positive
670959562,I can't merge in code with pickle yet because it causes security checks to fail - i think this is probably for the best for now.,ca merge code pickle yet security fail think probably best,issue,negative,positive,positive,positive,positive,positive
670958368,"Hey @abogaziah ! 

Sorry, but would it be possible to add a checkbox in front of each of those tickets so that we can see which ones are in progress or finished without needing to open each ticket? Sorry, it's been a while since I've used Github to track epics and milestones so I'm a little confused",hey sorry would possible add front see progress finished without needing open ticket sorry since used track little confused,issue,negative,negative,negative,negative,negative,negative
670933059,"> Getting the same error as @Naif18
I found the right solution that could solve this issue:
- Reinstall pytorch from here [https://pytorch.org/get-started/locally/#mac-package-manager](url)

- Make sure the **torch** version is 1.4.0 if it's not run the following command:
pip install syft -f https://download.pytorch.org/whl/torch_stable.html

- Now, you can download **syft** successfully:
pip install syft

to check the version of packages:
conda list",getting error naif found right solution could solve issue reinstall make sure torch version run following command pip install successfully pip install check version list,issue,positive,positive,positive,positive,positive,positive
670480576,"# [Codecov](https://codecov.io/gh/OpenMined/PySyft/pull/3959?src=pr&el=h1) Report
> Merging [#3959](https://codecov.io/gh/OpenMined/PySyft/pull/3959?src=pr&el=desc) into [master](https://codecov.io/gh/OpenMined/PySyft/commit/7e61474c436565a7d7453af7a7964b73a84feda0&el=desc) will **not change** coverage.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/OpenMined/PySyft/pull/3959/graphs/tree.svg?width=650&height=150&src=pr&token=W0kQS1vaXB)](https://codecov.io/gh/OpenMined/PySyft/pull/3959?src=pr&el=tree)

```diff
@@           Coverage Diff           @@
##           master    #3959   +/-   ##
=======================================
  Coverage   94.85%   94.85%           
=======================================
  Files         202      202           
  Lines       20702    20702           
=======================================
  Hits        19637    19637           
  Misses       1065     1065           
```


",report master change coverage coverage impacted file tree graph coverage master coverage,issue,negative,neutral,neutral,neutral,neutral,neutral
669741533,@LaRiffle could you take a look at this? (I think it can be merged),could take look think,issue,negative,neutral,neutral,neutral,neutral,neutral
669664804,Can anyone advise on where to make the change the correct this?,anyone advise make change correct,issue,negative,neutral,neutral,neutral,neutral,neutral
669298993,"> @LaRiffle @abogaziah
> 
> I applied the requested changes as much as possible. However, I am still learning the codebase of pysyft, so there may be some awkward or incorrect abstraction. If you have anything else to change, I would appreciate it if you could tell me everything!
> 
> Thank You! 😄

Keep going you're doing a nice job! ",applied much possible however still learning may awkward incorrect abstraction anything else change would appreciate could tell everything thank keep going nice job,issue,positive,neutral,neutral,neutral,neutral,neutral
669257959,"@LaRiffle @abogaziah 

I applied the requested changes as much as possible. However, I am still learning the codebase of pysyft, so there may be some awkward or incorrect abstraction. If you have anything else to change, I would appreciate it if you could tell me everything!

Thank You! 😄 ",applied much possible however still learning may awkward incorrect abstraction anything else change would appreciate could tell everything thank,issue,positive,negative,negative,negative,negative,negative
669081403,Thanks @LaRiffle for removing the `stale` label.,thanks removing stale label,issue,negative,negative,negative,negative,negative,negative
668546152,"> I am a little confused why I needed to add this:
> 
> ```
> - name: Run tests with coverage
>       run: |
> +            pip install typing-extensions dataclasses
>             python setup.py test
> ```
> 
> I would have thought that listing these packages in both the testing and install_requires inside setup.cfg would be sufficient?
> On my local machine these needed to be installed with pip before the tests would work.
> 
> Here it kind of suggests that you have to still install them manually?
> https://pyscaffold.org/en/latest/dependencies.html
> 
> _If run py.test runner, you will have to install those dependencies manually, or do a editable install of your package with pip install -e .[testing]._
> 
> Would be great if someone can clarify whats going on here.

I can't explain why it works this way but I have come to this understanding as well.",little confused add name run coverage run pip install python test would thought listing testing inside would sufficient local machine pip would work kind still install manually run runner install manually install package pip install testing would great someone clarify whats going ca explain work way come understanding well,issue,positive,positive,positive,positive,positive,positive
668509315,"I think it looks great as a first PR that enables us to use RSS.
What I think we should implement more is - have the possibility to do operations using ""+"", ""-"", etc (I do not know if that is possible for the moment) - There might be needed some ```@overloaded``` work",think great first u use think implement possibility know possible moment might work,issue,positive,positive,positive,positive,positive,positive
668418368,"> Why do we need those changes in the new PySyft Version?

It was an open 0.3.0 issue:
https://github.com/OpenMined/PySyft/issues/3826

It seems that perhaps support for 3.6 and 3.7 isn't actually incompatible with the usage of new Python typing constructs.",need new version open issue perhaps support actually incompatible usage new python,issue,negative,positive,neutral,neutral,positive,positive
668417349,"The reasoning for this change is that operating systems like Ubuntu LTS come with quite old python versions, so supporting 3.6 means Ubuntu 18.04+ should be covered out of the box.

I looked at going to python 3.5, but as Black is not supported (although its not actually needed for the library) and f"""" strings are not supported either this seems like too much of a disruption at this stage, however its possible this may work without significant changes and provide support for Ubuntu 16.04 LTS and many other platforms stuck on python 3.5.

To achieve this the following changes were made:

## Python 3.7
- Imports referring to final and Final were changed to:
```
from typing_extensions import final, Final
```
See more here:
https://github.com/python/typing/tree/master/typing_extensions

## Python 3.6
- The dataclasses backport library was added without any changes to the code.
- `from __future__ import annotations` were removed:

From what I can see they are not being used as removal has not caused any issues.
The ""annotations"" future is only to delay parsing of types until after load, to prevent issues with referencing custom types in their own definitions. The workaround is to simply define them as strings ""CustomType"" when referring with in a type definition, however if this becomes cumbersome to support, python 3.6 could be dropped.

See more here:
https://www.python.org/dev/peps/pep-0563/#dropping-annotations-with-o

I would say both of these changes are extremely minor at this stage, but we could choose to only support Python 3.7.

I am happy to incorporate any feedback in this PR, or close without merging if these changes are unacceptable.
",reasoning change operating like come quite old python supporting covered box going python black although actually library either like much disruption stage however possible may work without significant provide support many stuck python achieve following made python final final import final final see python library added without code import removed see used removal future delay load prevent custom simply define type definition however becomes cumbersome support python could see would say extremely minor stage could choose support python happy incorporate feedback close without unacceptable,issue,negative,positive,positive,positive,positive,positive
668411411,"I am a little confused why I needed to add this:
```
- name: Run tests with coverage
      run: |
+            pip install typing-extensions dataclasses
            python setup.py test

```

I would have thought that listing these packages in both the testing and install_requires inside setup.cfg would be sufficient?
On my local machine these needed to be installed with pip before the tests would work.

Here it kind of suggests that you have to still install them manually?
https://pyscaffold.org/en/latest/dependencies.html

*If run py.test runner, you will have to install those dependencies manually, or do a editable install of your package with pip install -e .[testing].*

Would be great if someone can clarify whats going on here.",little confused add name run coverage run pip install python test would thought listing testing inside would sufficient local machine pip would work kind still install manually run runner install manually install package pip install testing would great someone clarify whats going,issue,positive,positive,positive,positive,positive,positive
668186293,"Hi @marload :) thank you for taking this issue, we made this issue to enhance the readability of this class, this should be your primary goal to make it more readable, I'll share some tips with you :)
- the function is readable if you're able to know what it's doing without having to look in the detailed implementation. you should read it like you read a newspaper.
- to read a function replace ""def"" with ""to""
for example, this function reads like ""to share a secret, you get the number of shares then you arrange the workers then you generate the shares then you distribute the shares then you save a map to them as the tensor child""
![image](https://user-images.githubusercontent.com/33666625/89215120-58e80e80-d5c8-11ea-9453-65e9cee2823c.png)
- you should pick a good (expressive) name for every function, parameter or variable, use verbs for functions and nouns for vars
- a function must have a single responsibility that is expressed by its name, only one, that's so important. many of the functions in this class has more than one and they need to be broken down into smaller functions.
- functions should be small, like 5 lines long, the shorter the better
- abstract concepts should come first in the file then more details are reviled down the lines
- utility functions should be near the functions that use them 
- avoid encoding, write the whole thing instead, (e.x. library not lib nor librry)
- use naming convention from CS (hash map, list ..etc) or business domain or scientific paper
this is more of an art than engineering, I'll be seeing your art :) good luck ",hi thank taking issue made issue enhance readability class primary goal make readable share function readable able know without look detailed implementation read like read newspaper read function replace example function like share secret get number arrange generate distribute save map tensor child image pick good expressive name every function parameter variable use function must single responsibility expressed name one important many class one need broken smaller small like long shorter better abstract come first file utility near use avoid write whole thing instead library use naming convention hash map list business domain scientific paper art engineering seeing art good luck,issue,positive,positive,positive,positive,positive,positive
667876804,"Tests are passing! 🚀

Can I please get a PR?
I have kept all of the noisy black and flake8 changes to their own commits.

- There are three ""pickle.loads"" which are being ignored currently to allow 🏴‍☠️ bandit to pass.
- I have added isort and sqlitedict as required
- I have added a pre_commit.sh script file which runs isort and black, and then runs most of the actions from tests.yml
- my MacOS compatible build_proto changes need double checking on linux

",passing rocket please get kept noisy black flake three currently allow bandit pas added added script file black compatible need double,issue,negative,negative,neutral,neutral,negative,negative
667853184,"There is a further bug in the averaging method: If two nets living on the GPU are averaged, one gets an exception because the new model for the sum is initiated on the CPU.

![average cuda bug](https://user-images.githubusercontent.com/68423474/89156140-7b4b3f00-d56a-11ea-9519-3a3ea362f0ad.png)
",bug method two living one exception new model sum average bug,issue,negative,negative,neutral,neutral,negative,negative
667799407,Sure! It might involve more refactoring than it is written in the description.,sure might involve written description,issue,negative,positive,positive,positive,positive,positive
667600462,"I'm trying to implement a Plan for an LSTM model built from scratch but I'm getting the following error at line 71 in my code: `TypeError: addmm(): argument 'mat1' (position 2) must be Tensor, not AutogradTensor`. If I remove the `trace_autograd=True` parameter on the `@sy.func2plan` decorator, a `PureFrameworkTensorFoundError` is being raised when trying to execute a `F.linear(input, self.weight, self.bias)`. Here's the source code of my implementation:

```python
class LSTMCell(nn.Module):
    """"""
    Python implementation of LSTMCell for MPC
    This class overrides the torch.nn.LSTMCell
    """"""
​
    def __init__(self, input_size, hidden_size, bias=True, nonlinearity=None):
        super(LSTMCell, self).__init__()
    
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.bias = bias
        self.nonlinearity = nonlinearity
​
​
        # Input Gate
        self.fc_xi = nn.Linear(input_size, hidden_size, bias=bias)
        self.fc_hi = nn.Linear(hidden_size, hidden_size, bias=bias)
        
        # Forget Gate
        self.fc_xf = nn.Linear(input_size, hidden_size, bias=bias)
        self.fc_hf = nn.Linear(hidden_size, hidden_size, bias=bias)
​
        # Cell Gate
        self.fc_xc = nn.Linear(input_size, hidden_size, bias=bias)
        self.fc_hc = nn.Linear(hidden_size, hidden_size, bias=bias)
​
        # Output Gate
        self.fc_xo = nn.Linear(input_size, hidden_size, bias=bias)
        self.fc_ho = nn.Linear(hidden_size, hidden_size, bias=bias)
        
        self.init_parameters()
        
    def init_parameters(self):
        std = 1.0 / np.sqrt(self.hidden_size)
        for w in self.parameters():
            w.data.uniform_(-std, std)
        ​
    def init_hidden(self, batch_size):
        return torch.zeros(batch_size, self.hidden_size)
​
    def forward(self, x, hc=None):
​
        if hc is None:
            batch_size = x.shape[1]
            hc = (self.init_hidden(batch_size), self.init_hidden(batch_size))
        h, c = hc
        
        print('LSTMCell', type(x), x.shape)
        print('Hidden', h, h.shape)
        print('C t-1', c, c.shape) 
        x_i = self.fc_xi(x)
        h_i = self.fc_hi(h)
        x_f = self.fc_xf(x)
        h_f = self.fc_hf(h)
        x_c = self.fc_xc(x)
        h_c = self.fc_hc(h)
        x_o = self.fc_xo(x)
        h_o = self.fc_ho(h)
        
        inputgate = (x_i + h_i).sigmoid()
        forgetgate = (x_f + h_f).sigmoid()
        cellgate = (x_c + h_c).tanh()
        outputgate = (x_o + h_o).sigmoid()
​
#         c_ = torch.mul(forgetgate, c) + torch.mul(inputgate, cellgate)
        c_ = (forgetgate * c) + (inputgate * cellgate)
​
#         h_ = torch.mul(outputgate, torch.tanh(c_))
        h_ = outputgate * c_.tanh()
​
        return h_, c_
​
​
class LSTM(nn.Module):
    """"""
    V2
    Python implementation of LSTM for MPC
    This class overrides the torch.nn.LSTM
    """"""
​
    def __init__(
        self,
        input_size,
        hidden_size,
        num_layers=1,
        bias=True,
        batch_first=False,
        dropout=0,
        bidirectional=False,
        nonlinearity=None,
    ):
        super(LSTM, self).__init__()
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.bias = bias
        self.batch_first = batch_first
        self.dropout = float(dropout)
        self.bidirectional = bidirectional
#         self.num_directions = 2 if bidirectional else 1
#         self.is_lstm = base_cell is LSTMCell
        self.nonlinearity = nonlinearity
    
        # Dropout layers
        # TODO: implement a nn.Dropout class for PySyft
        # Link to issue: https://github.com/OpenMined/PySyft/issues/2500
​
        # Build RNN forward layers
        sizes = [input_size, *(hidden_size for _ in range(self.num_layers - 1))]
        self.rnn_forward = nn.ModuleList(
            (LSTMCell(sz, hidden_size, bias, nonlinearity) for sz in sizes)
        )
        
        self.lstm_cell = LSTMCell(self.input_size, self.hidden_size, self.bias, self.nonlinearity)
​
#         # Build RNN backward layers, if needed
#         if self.bidirectional:
#             self.rnn_backward = nn.ModuleList(
#                 (base_cell(sz, hidden_size, bias, nonlinearity) for sz in sizes)
#             )
​
    def init_hidden(self, batch_size):
        return torch.zeros(batch_size, self.hidden_size)
​
    def forward(self, x, hc=None):
        
        batch_size = x.shape[1]
        seq_len = x.shape[0]
        
        if hc is None:
            print('Init hc...')
            hc = (self.init_hidden(batch_size), self.init_hidden(batch_size))
            
        # Run through rnn in the forward direction
        for t in range(seq_len):
            input_ = x.select(0, t).view(1, -1)
            hc = self.lstm_cell(input_, hc)
                
        return hc
​
    
class WesadLSTM(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim=3, lstm_layers=1, dropout=0.2):
        # super(WesadLSTM, self).__init__(id=""encrypted-model"")
        super(WesadLSTM, self).__init__()
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        self.classes = output_dim
        self.lstm = LSTM(input_size=input_dim, hidden_size=input_dim, num_layers=lstm_layers, dropout=dropout)
        self.fc = nn.Linear(hidden_dim, output_dim)
        self.dropout = nn.Dropout(dropout)
​
    def forward(self, x, h):
        lstm_out, _ = self.lstm(x, h)
        out = self.fc(lstm_out.view(-1, self.hidden_dim))
        out = F.softmax(out.view(-1, self.classes), dim=1)
        return out
​
​
train_batch_size = 25
val_batch_size = 5
input_dim = 77
output_dim = 3
lstm_layers = 5
dropout = 0.5
lr = 1e-4
model = WesadLSTM(input_dim=input_dim, hidden_dim=input_dim, output_dim=output_dim, lstm_layers=lstm_layers,
                  dropout=dropout)
​
@sy.func2plan(args_shape=[(25, 77), (25, 3), (25, 77), (25, 77)], trace_autograd=True)
def try_batch(data, target, h, c):
    out = model(data, (h, c))
    
    batch_size = out.shape[0]
    loss = ((out - target)**2).sum().refresh()/batch_size
    loss.backward()
        
    return loss
```",trying implement plan model built scratch getting following error line code argument position must tensor remove parameter decorator raised trying execute input source code implementation python class python implementation class self super self bias input gate forget gate cell gate output gate self self return forward self none print type print print return class python implementation class self super self bias float dropout bidirectional bidirectional else dropout implement class link issue build forward size range bias size build backward bias size self return forward self none print run forward direction range return class self super self super self dropout forward self return dropout model data target model data loss target return loss,issue,positive,positive,positive,positive,positive,positive
667007614,"I find it is not a question.
But I find a new question that model_str.get() is slow.
It takes 60 seconds to get a model of resnet34.",find question find new question slow get model,issue,negative,negative,neutral,neutral,negative,negative
666988044,Kindly reopen this issue as the team is working on this,kindly reopen issue team working,issue,negative,positive,positive,positive,positive,positive
666517244,"correct, but I did try out=out.view(-1, 512 )  and I got huge negative losses which is why I went back to the default in the resnet code... not sure what's happening ",correct try got huge negative went back default code sure happening,issue,negative,positive,positive,positive,positive,positive
666338407,"> @fermat97 I am not sure what do you mean by ""there are still huge amount of communication between ..."". How do you know that there is still communication? Actually, after sent the model and config file to remote machine, the models would also be send from the remote machines to server, which would be used to calculate a average model.

Thank you. Yes I know they have to send back the model to the server, but during the training on the remote machines there shouldn't be any communication between server and remote workers. I am using some networking tools and it shows there still are. In other words it shows server container starts receiving data while the client containers are still receiving packages from server. ",sure mean still huge amount communication know still communication actually sent model file remote machine would also send remote server would used calculate average model thank yes know send back model server training remote communication server remote still server container data client still server,issue,positive,positive,neutral,neutral,positive,positive
666307205,"@LaRiffle the error pops up when you doing something like this
```
bob = DynamicFLClient(hook, ""ws://localhost:3001/"")
alice = DynamicFLClient(hook, ""ws://localhost:3002"")
bill = DynamicFLClient(hook, ""ws://localhost:3003"")
my_grid = sy.PrivateGridNetwork(bob,alice, bill)
t = th.Tensor([4,6]).send(alice)
t_shared = t.fix_prec().share(bob, alice, crypto_provider=bill)
t_shared.get() 
```
I don't think we directly send client worker but when you do operations like above this error pops up(for NodeClient and now DynamicFLClient)
",error something like bob hook hook bill hook bob bill bob think directly send client worker like error,issue,negative,positive,neutral,neutral,positive,positive
666039352,"out = out.view(out.size(0), -1)  
That is wrong in pysyft.  Cause the out.size() return a 0 . 
You need to change it like this :
        out=out.view(-1, 512 ) ###!!!!!!!!",wrong cause return need change like,issue,negative,negative,negative,negative,negative,negative
665001450,Ok let's keep clone for a separate PR :) ,let keep clone separate,issue,negative,neutral,neutral,neutral,neutral,neutral
664998849,"@LaRiffle please check. 
The test will not work for clone as specified above - there is another bug with cloning a model pointer. I can address it as well but I think it is better to do it as part of another PR. ",please check test work clone another bug model pointer address well think better part another,issue,positive,positive,positive,positive,positive,positive
664075221,"Sorry for the delay! It looks like a problem that we [solved ](https://github.com/OpenMined/PyGridNode/pull/7) before. But both PySyft and PyGrid have gone through several refactoring since then, probably something has changed during the process. I will check it when I get some time.
",sorry delay like problem gone several since probably something process check get time,issue,negative,negative,negative,negative,negative,negative
664040521,"@abogaziah I removed some points from this task and created other issues for each one individually.
They can be seen in the [FALCON Milestone](https://github.com/OpenMined/PySyft/milestone/13)",removed task one individually seen falcon milestone,issue,negative,neutral,neutral,neutral,neutral,neutral
664039906,"@youben11 @bcebere PR is ready for review, the operation is working now 🥳",ready review operation working,issue,negative,positive,positive,positive,positive,positive
664002387,@usamazf if you are planning to do federated learning with multiple people/users/data providers/parties then SMPC is the best way to go (PySyft has done an incredible work in that area),learning multiple best way go done incredible work area,issue,positive,positive,positive,positive,positive,positive
663958535,"@NicoSerranoP Excellent. Now I just need to figure out where I can serialize it when sending encrypted tensors to workers. Thanks you for sharing!

P.S. I have just started exploring privacy and communication efficiency in FL systems.",excellent need figure serialize sending thanks exploring privacy communication efficiency,issue,positive,positive,positive,positive,positive,positive
663935717,"Hi Usamazf! I was not able to solve it (It did not passed the testings) but I am using this function to serialize Paillier tensors:
```python
from syft.frameworks.torch.tensors.interpreters.paillier import PaillierTensor
from syft.serde.serde import deserialize
from phe.paillier import EncryptedNumber
from phe.paillier import PaillierPublicKey
from numpy import ndarray
from numpy import array


def serialize_paillier(element):
  # Case 1: tensor recursion
  if isinstance(element, torch.Tensor):
    paillier = element.child
    if isinstance(paillier, PaillierTensor):
      child = [serialize_paillier(subchild) for subchild in paillier.child]
      return {'n': paillier.pubkey.n, 'values': child} # in PaillierPublicKey g = n + 1
    else:
      raise TypeError(type(paillier))

  # Case 2: ndarray recursion
  elif isinstance(element, ndarray):
    return [serialize_paillier(subelement) for subelement in element]

  # Case 3: EncryptedNumber serialization
  elif isinstance(element, EncryptedNumber):
    return (str(element.ciphertext()), str(element.exponent))

  # Case 4: Unknown type
  else:
    raise TypeError(type(element))
def deserialize_paillier(struct, pub=None):
  # Case 1: dict recursion
  if isinstance(struct, dict):
    pub = PaillierPublicKey(n=int(struct['n']))
    child = [deserialize_paillier(substruct, pub) for substruct in struct['values']]
    # Building Paillier Tensor
    tensor = PaillierTensor()
    tensor.child = array(child)
    tensor.pubkey = pub
    return tensor.wrap()

  # Case 2: list recursion
  elif isinstance(struct, list):
    return [deserialize_paillier(substruct, pub) for substruct in struct]

  # Case 3: Tuple deserialization
  elif isinstance(struct, tuple):
    return EncryptedNumber(pub, int(struct[0]), int(struct[1]))

  # Case 4: Unknown type
  else:
    raise TypeError(type(struct))
```
In case you need a Encrypted Number Object to transform it to Paillier (for serialization) use:
```python
def to_paillier(element, public_key):
    if isinstance(element, torch.Tensor) and isinstance(element.child, PaillierTensor):
        element.child.pubkey = public_key
        child = element.child.child
        if isinstance(child, ndarray):
          return element
        elif isinstance(child, EncryptedNumber):
          element.child.child = array([child])
          return element
        else:
          raise Exception(""The tensor does not have an EncryptedNumber or a np.ndarray as child"")
    elif isinstance(element, PaillierTensor):
        element.pubkey = public_key
        return element.wrap()
    elif isinstance(element, ndarray):
        tensor = PaillierTensor()
        tensor.child = element
        tensor.pubkey = public_key
        return tensor.wrap()
    elif isinstance(element, list):
        tensor = PaillierTensor()
        tensor.child = array(element)
        tensor.pubkey = public_key
        return tensor.wrap()
    elif isinstance(element, EncryptedNumber):
        tensor = PaillierTensor()
        tensor.child = array([element])
        tensor.pubkey = public_key
        return tensor.wrap()
    else:
        raise TypeError(type(element))
```

I am actively working with Paillier tensors for my thesis and I would love to know what are you working on, maybe we can collaborate in something.",hi able solve function serialize python import import import import import import array element case tensor recursion element child return child else raise type case recursion element return subelement subelement element case serialization element return case unknown type else raise type element case recursion pub child substruct pub substruct building tensor tensor array child pub return case list recursion list return substruct pub substruct case return pub case unknown type else raise type case need number object transform serialization use python element element child child return element child array child return element else raise exception tensor child element return element tensor element return element list tensor array element return element tensor array element return else raise type element actively working thesis would love know working maybe collaborate something,issue,positive,positive,positive,positive,positive,positive
663905414,"I have a related question about send() method actually. 
Can anyone point me out where it is implemented? I didn't see it in torch.tensor and sequential module but it seems their instances do have this method. 
And it seems to be the similar question here. The AutogradTensor class don't have this method. So why there is the difference and how to debug this issue?

Thanks,",related question send method actually anyone point see sequential module method similar question class method difference issue thanks,issue,negative,positive,neutral,neutral,positive,positive
663876721,"I tried most of the solution that I read but no one is useful 
this is the error

ERROR: Could not find a version that satisfies the requirement torch~=1.4.0 (from syft) (from versions: 0.1.2, 0.1.2.post1, 0.1.2.post2)
ERROR: No matching distribution found for torch~=1.4.0 (from syft)

",tried solution read one useful error error could find version requirement post post error matching distribution found,issue,negative,positive,positive,positive,positive,positive
663797249,This issue still exists no? Any update? I am trying to do the same but get the same error on serialization.,issue still update trying get error serialization,issue,negative,neutral,neutral,neutral,neutral,neutral
663208709,"Hi, 
how is the move() handled now?

I was trying to move some intermediate output parameters from one `WebSocketServer` to a local `VirtualWorker` with move() but I got error saying `""Worker alice1 couldn't recognize worker bob""`.

Thanks.",hi move handled trying move intermediate output one local move got error saying worker could recognize worker bob thanks,issue,negative,positive,neutral,neutral,positive,positive
663137348,Tests should pass now. An unreleased version of 3p0 with my translations for `select` and `__rsub__` is required to translate the Plan to Tensorflow.js. The example is lenient and will not fail if these translations are missing.,pas unreleased version select translate plan example lenient fail missing,issue,negative,negative,neutral,neutral,negative,negative
663110990,"Hi Thanks for the reply, I tried that and it seems to be working but it's painfully slow to get a variable back from remote worker. Any suggestions for that?
",hi thanks reply tried working painfully slow get variable back remote worker,issue,negative,negative,neutral,neutral,negative,negative
663039006,Thanks @iamtrask ! The main issue is that translating the Plan to Tensorflow.js doesn't work yet but I'm making PRs to Threepio to get it working.,thanks main issue plan work yet making get working,issue,negative,positive,positive,positive,positive,positive
663026234,"Hey!
You can simply call `model.get()` if you want to get a local version of your model that's probably the best option.
Alternatively you can spot a parameter like `model.weight` if `model = nn.Linear(...)`, this should be a Pointer. You can then call `.copy().get()` on it to get a version back without deleting the remote version of the parameter (contrary to the .get() on the model)",hey simply call want get local version model probably best option alternatively spot parameter like model pointer call get version back without remote version parameter contrary model,issue,positive,positive,positive,positive,positive,positive
662902114,I have completed the required code for the operation but the result is not correct yet😭. I have added some deepcopy's till debugging. so will remove the redundant deepcopy's after everything starts working properly...,code operation result correct yet added till remove redundant everything working properly,issue,negative,negative,neutral,neutral,negative,negative
662803284,"The point here is the latest version use a Module 'pythreepio' which is not included in the building process. Somehow I make it work for my task. Since I needs websocket works properly, I downgrade the version.

For reference:
websocket-client 0.54.0
syft             0.2.0a2

Hope they can make the latest working soon!",point latest version use module included building process somehow make work task since need work properly downgrade version reference hope make latest working soon,issue,negative,positive,positive,positive,positive,positive
662718603,"# [Codecov](https://codecov.io/gh/OpenMined/PySyft/pull/3884?src=pr&el=h1) Report
> Merging [#3884](https://codecov.io/gh/OpenMined/PySyft/pull/3884?src=pr&el=desc) into [crypten](https://codecov.io/gh/OpenMined/PySyft/commit/2989989854c8879278ab1ba2eb0e1fce80170a58&el=desc) will **increase** coverage by `0.21%`.
> The diff coverage is `93.36%`.

[![Impacted file tree graph](https://codecov.io/gh/OpenMined/PySyft/pull/3884/graphs/tree.svg?width=650&height=150&src=pr&token=W0kQS1vaXB)](https://codecov.io/gh/OpenMined/PySyft/pull/3884?src=pr&el=tree)

```diff
@@             Coverage Diff             @@
##           crypten    #3884      +/-   ##
===========================================
+ Coverage    94.72%   94.94%   +0.21%     
===========================================
  Files          152      197      +45     
  Lines        16051    19897    +3846     
===========================================
+ Hits         15205    18891    +3686     
- Misses         846     1006     +160     
```


| [Impacted Files](https://codecov.io/gh/OpenMined/PySyft/pull/3884?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [syft/common/util.py](https://codecov.io/gh/OpenMined/PySyft/pull/3884/diff?src=pr&el=tree#diff-c3lmdC9jb21tb24vdXRpbC5weQ==) | `95.00% <ø> (ø)` | |
| [syft/execution/placeholder.py](https://codecov.io/gh/OpenMined/PySyft/pull/3884/diff?src=pr&el=tree#diff-c3lmdC9leGVjdXRpb24vcGxhY2Vob2xkZXIucHk=) | `95.10% <ø> (+0.82%)` | :arrow_up: |
| [syft/execution/placeholder\_id.py](https://codecov.io/gh/OpenMined/PySyft/pull/3884/diff?src=pr&el=tree#diff-c3lmdC9leGVjdXRpb24vcGxhY2Vob2xkZXJfaWQucHk=) | `96.87% <ø> (+0.44%)` | :arrow_up: |
| [syft/execution/plan.py](https://codecov.io/gh/OpenMined/PySyft/pull/3884/diff?src=pr&el=tree#diff-c3lmdC9leGVjdXRpb24vcGxhbi5weQ==) | `94.82% <ø> (+0.11%)` | :arrow_up: |
| [syft/execution/protocol.py](https://codecov.io/gh/OpenMined/PySyft/pull/3884/diff?src=pr&el=tree#diff-c3lmdC9leGVjdXRpb24vcHJvdG9jb2wucHk=) | `93.38% <ø> (+5.36%)` | :arrow_up: |
| [syft/execution/role.py](https://codecov.io/gh/OpenMined/PySyft/pull/3884/diff?src=pr&el=tree#diff-c3lmdC9leGVjdXRpb24vcm9sZS5weQ==) | `97.82% <ø> (-1.65%)` | :arrow_down: |
| [syft/execution/role\_assignments.py](https://codecov.io/gh/OpenMined/PySyft/pull/3884/diff?src=pr&el=tree#diff-c3lmdC9leGVjdXRpb24vcm9sZV9hc3NpZ25tZW50cy5weQ==) | `82.75% <ø> (ø)` | |
| [syft/execution/state.py](https://codecov.io/gh/OpenMined/PySyft/pull/3884/diff?src=pr&el=tree#diff-c3lmdC9leGVjdXRpb24vc3RhdGUucHk=) | `87.50% <ø> (-1.05%)` | :arrow_down: |
| [syft/execution/tracing.py](https://codecov.io/gh/OpenMined/PySyft/pull/3884/diff?src=pr&el=tree#diff-c3lmdC9leGVjdXRpb24vdHJhY2luZy5weQ==) | `93.10% <ø> (+3.62%)` | :arrow_up: |
| [syft/execution/translation/abstract.py](https://codecov.io/gh/OpenMined/PySyft/pull/3884/diff?src=pr&el=tree#diff-c3lmdC9leGVjdXRpb24vdHJhbnNsYXRpb24vYWJzdHJhY3QucHk=) | `75.00% <ø> (ø)` | |
| ... and [310 more](https://codecov.io/gh/OpenMined/PySyft/pull/3884/diff?src=pr&el=tree-more) | |
",report increase coverage coverage impacted file tree graph coverage coverage impacted coverage,issue,negative,neutral,neutral,neutral,neutral,neutral
662200735,UPDATE: This error seems to occur only when I try to create plan using the tutorials at: [Creating Plans](https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/static-fl/Part%2001%20-%20Create%20Plan.ipynb). After removing any calls to @sy.func2plan() the code seems to work fine. Is this a bug or not? I am confused now even more!,update error occur try create plan removing code work fine bug confused even,issue,negative,positive,neutral,neutral,positive,positive
661297560,@vvmnnnkv I can't tell why those tests fail. Some of those pass on my machine. Others fail but I think it's because I don't have Tensorflow set up.,ca tell fail pas machine fail think set,issue,negative,negative,negative,negative,negative,negative
661164876,"Hey sure yes!
But some elements are required before addressing this issue: I need to merge stuff related to function secret sharing to have it behave in the exact same way than secureNN.
I will let you know when this issue is unblocked!",hey sure yes issue need merge stuff related function secret behave exact way let know issue unblocked,issue,positive,positive,neutral,neutral,positive,positive
661162458,"Hey, @iamtrask I have contributed to threepio and I want to work on this issue.",hey want work issue,issue,negative,neutral,neutral,neutral,neutral,neutral
661022622,CC: @IonesioJunior - thoughts on this? Could use your help since it's in the syft.grid package.,could use help since package,issue,negative,neutral,neutral,neutral,neutral,neutral
660841211,"AdditiveSharingTensors can be multiplied with long tensors and fixedPrecisionTensors
Don't directly multiply floats with AdditiveSharingTensor  as an error will come when you multiply an AdditiveSharingTensors with a FloatTensor.
But sharing with fixed_precision we will be able to handle float values like parameters in an encrypted way. 

1)if decrypt z
```
import syft as sy
import torch as th
hook = sy.TorchHook(th)
bob = sy.VirtualWorker(hook, id=""bob"")
alice = sy.VirtualWorker(hook, id=""alice"")
x = th.tensor([1,2,3,4])
x = x.share(bob, alice, crypto_provider=bob)
z = x[0].get() #z got decrypted 
for i in range(1, len(x)):
    z *= x[i]
z.get()  # <-- returns tensor(24)
```

2) if we use fixed_Precision
```
import syft as sy
import torch as th
hook = sy.TorchHook(th)
bob = sy.VirtualWorker(hook, id=""bob"")
alice = sy.VirtualWorker(hook, id=""alice"")
x = th.tensor([1.,2,3,4])
x = x.fix_prec().share(bob, alice, crypto_provider=bob)
z = x[0] # <--- z is encrypted
for i in range(1, len(x)):
    z *= x[i] # <-- inplace mul
z.get().float_prec()  # <-- returns tensor(24)
```
",long directly multiply error come multiply able handle float like way import import torch th hook th bob hook bob hook bob got range tensor use import import torch th hook th bob hook bob hook bob range tensor,issue,negative,positive,positive,positive,positive,positive
660836694,"```
import syft as sy
import torch as th
hook = sy.TorchHook(th)
bob = sy.VirtualWorker(hook, id=""bob"")
alice = sy.VirtualWorker(hook, id=""alice"")
x = th.tensor([1,2,3,4])
print(x.prod())  # <- tensor(24)
x.fix_prec().share(bob, alice, crypto_provider=bob)
x.prod() # <- tensor(24)
```

AST can be multiplied with long tensors and fixedPrecisionTensors
Don't directly multiply floats with AdditiveSharingTensor (AST) as an error will come when you multiply an AST with a FloatTensor.
",import import torch th hook th bob hook bob hook print tensor bob tensor ast long directly multiply ast error come multiply ast,issue,negative,negative,neutral,neutral,negative,negative
659837797,"From my point, If you run the following code, it will get the same error as @shashigharti .
I implement bob and Alice with DynamicFLClient.

`x = torch.tensor([x]) `
`x = x.send(bob)`
`x = x.share(bob,alice)`
I would like to implement a secure model aggregation that means I need to share the local model (bob) without seeing the actual value. That is the reason why I need to use .share() with the pointertensor instead of the plaint parameter.
",point run following code get error implement bob bob bob would like implement secure model aggregation need share local model bob without seeing actual value reason need use instead plaint parameter,issue,negative,positive,neutral,neutral,positive,positive
659330481,"Hello Coldfire93,

Sorry, I am still unable to resolve the issue.

On Thu, Jul 16, 2020 at 2:11 PM Coldfire93 <notifications@github.com> wrote:

> I met the same problem. Have you solved it?
>
> In my conda environment, I have installed PyTorch (version-1.4.0),
> TensorFlow (version - 1.15.3) and then Syft through pip. Upto now
> everything is fine.
>
> But when I install tf-encrypted (0.5.9) using pip or source, I got this
> error.
>
> ** Falling back to insecure randomness since the required custom op could
> not be found for the installed version of TensorFlow. Fix this by compiling
> custom ops. Missing file was
> '/home/vtanwar/anaconda3/envs/pysyft_tfe/lib/python3.6/site-packages/tf_encrypted/operations/secure_random/
> secure_random_module_tf_1.15.3.so'
> WARNING:tensorflow:From
> /home/vtanwar/anaconda3/envs/pysyft_tfe/lib/python3.6/site-packages/tf_encrypted/session.py:24:
> The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.
> **
>
> Due to this, I am unable to proceed in Tutorials 13 b and 13 c.
>
> Please help me.
>
> Next, I am providing the output of my pip list -
>
> Package Version
>
> absl-py 0.9.0
> aioice 0.6.18
> aiortc 0.9.28
> astor 0.8.1
> astunparse 1.6.3
> attrs 19.3.0
> av 8.0.1
> backcall 0.1.0
> bleach 3.1.4
> blinker 1.4
> cachetools 3.1.1
> certifi 2020.4.5.1
> cffi 1.14.0
> chardet 3.0.4
> click 7.1.2
> crc32c 2.0
> cryptography 2.9.2
> dataclasses 0.7
> decorator 4.4.2
> defusedxml 0.6.0
> entrypoints 0.3
> Flask 1.1.2
> Flask-SocketIO 4.2.1
> gast 0.2.2
> google-auth 1.14.1
> google-auth-oauthlib 0.4.1
> google-pasta 0.2.0
> grpcio 1.27.2
> h5py 2.10.0
> idna 2.8
> importlib-metadata 1.6.0
> ipykernel 5.1.4
> ipython 7.13.0
> ipython-genutils 0.2.0
> itsdangerous 1.1.0
> jedi 0.17.0
> Jinja2 2.11.2
> jsonschema 3.2.0
> jupyter-client 6.1.3
> jupyter-core 4.6.3
> Keras-Applications 1.0.8
> Keras-Preprocessing 1.1.0
> lz4 3.0.2
> Markdown 3.1.1
> MarkupSafe 1.1.1
> mistune 0.8.4
> mkl-fft 1.0.15
> mkl-random 1.1.1
> mkl-service 2.3.0
> msgpack 1.0.0
> nbconvert 5.6.1
> nbformat 5.0.6
> netifaces 0.10.9
> notebook 5.7.8
> numpy 1.18.1
> oauthlib 3.1.0
> olefile 0.46
> opt-einsum 3.1.0
> pandocfilters 1.4.2
> parso 0.7.0
> pexpect 4.8.0
> phe 1.4.0
> pickleshare 0.7.5
> Pillow 6.2.2
> pip 20.0.2
> prometheus-client 0.7.1
> prompt-toolkit 3.0.4
> protobuf 3.12.2
> psutil 5.7.0
> ptyprocess 0.6.0
> pyasn1 0.4.8
> pyasn1-modules 0.2.7
> pycparser 2.20
> pyee 7.0.2
> Pygments 2.6.1
> PyJWT 1.7.1
> pylibsrtp 0.6.6
> pyOpenSSL 19.1.0
> pyrsistent 0.16.0
> PySocks 1.7.1
> python-dateutil 2.8.1
> python-engineio 3.13.0
> python-socketio 4.6.0
> PyYAML 5.3.1
> pyzmq 18.1.1
> requests 2.22.0
> requests-oauthlib 1.3.0
> rsa 4.0
> scipy 1.4.1
> Send2Trash 1.5.0
> setuptools 46.4.0.post20200518
> six 1.14.0
> syft 0.2.6
> syft-proto 0.4.6
> tblib 1.6.0
> tensorboard 1.15.0
> tensorboard-plugin-wit 1.6.0
> tensorflow 1.15.3
> tensorflow-estimator 1.15.1
> termcolor 1.1.0
> terminado 0.8.3
> testpath 0.4.4
> tf-encrypted 0.5.9
> torch 1.4.0
> torchvision 0.5.0
> tornado 4.5.3
> traitlets 4.3.3
> urllib3 1.25.9
> wcwidth 0.1.9
> webencodings 0.5.1
> websocket-client 0.57.0
> websockets 8.1
> Werkzeug 1.0.1
> wheel 0.34.2
> wrapt 1.12.1
> zipp 3.1.0
>
> I met the same problem. Have you solved it?
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/3640#issuecomment-659254116>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/APU3REMTKG3SBJJHA7GXTGDR324LJANCNFSM4NOUHOOQ>
> .
>


-- 
Thanks & Regards

Vishesh Kumar Tanwar
Research Scholar
Dept. of  Mathematics
Indian Institute of Technology Roorkee
INDIA
",hello sorry still unable resolve issue wrote met problem environment version pip everything fine install pip source got error falling back insecure randomness since custom could found version fix custom missing file warning name please use instead due unable proceed please help next providing output pip list package version astor bleach blinker click cryptography decorator flask gast jinja markdown notebook pillow pip post six torch tornado wheel met problem thread reply directly view thanks research scholar mathematics institute technology,issue,negative,negative,negative,negative,negative,negative
659274652,Using pysyft 0.2.5 is probably the only solution for now. Super weird though to remove the only thing that actually simulated a real federated environment.,probably solution super weird though remove thing actually real environment,issue,positive,positive,neutral,neutral,positive,positive
659254116,"I met the same problem. Have you solved it?

> In my conda environment, I have installed PyTorch (version-1.4.0), TensorFlow (version - 1.15.3) and then Syft through pip. Upto now everything is fine.
> 
> But when I install tf-encrypted (0.5.9) using pip or source, I got this error.
> 
> ** Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/home/vtanwar/anaconda3/envs/pysyft_tfe/lib/python3.6/site-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.15.3.so'
> WARNING:tensorflow:From /home/vtanwar/anaconda3/envs/pysyft_tfe/lib/python3.6/site-packages/tf_encrypted/session.py:24: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead. **
> 
> Due to this, I am unable to proceed in Tutorials 13 b and 13 c.
> 
> Please help me.
> 
> Next, I am providing the output of my pip list -
> 
> Package Version
> 
> absl-py 0.9.0
> aioice 0.6.18
> aiortc 0.9.28
> astor 0.8.1
> astunparse 1.6.3
> attrs 19.3.0
> av 8.0.1
> backcall 0.1.0
> bleach 3.1.4
> blinker 1.4
> cachetools 3.1.1
> certifi 2020.4.5.1
> cffi 1.14.0
> chardet 3.0.4
> click 7.1.2
> crc32c 2.0
> cryptography 2.9.2
> dataclasses 0.7
> decorator 4.4.2
> defusedxml 0.6.0
> entrypoints 0.3
> Flask 1.1.2
> Flask-SocketIO 4.2.1
> gast 0.2.2
> google-auth 1.14.1
> google-auth-oauthlib 0.4.1
> google-pasta 0.2.0
> grpcio 1.27.2
> h5py 2.10.0
> idna 2.8
> importlib-metadata 1.6.0
> ipykernel 5.1.4
> ipython 7.13.0
> ipython-genutils 0.2.0
> itsdangerous 1.1.0
> jedi 0.17.0
> Jinja2 2.11.2
> jsonschema 3.2.0
> jupyter-client 6.1.3
> jupyter-core 4.6.3
> Keras-Applications 1.0.8
> Keras-Preprocessing 1.1.0
> lz4 3.0.2
> Markdown 3.1.1
> MarkupSafe 1.1.1
> mistune 0.8.4
> mkl-fft 1.0.15
> mkl-random 1.1.1
> mkl-service 2.3.0
> msgpack 1.0.0
> nbconvert 5.6.1
> nbformat 5.0.6
> netifaces 0.10.9
> notebook 5.7.8
> numpy 1.18.1
> oauthlib 3.1.0
> olefile 0.46
> opt-einsum 3.1.0
> pandocfilters 1.4.2
> parso 0.7.0
> pexpect 4.8.0
> phe 1.4.0
> pickleshare 0.7.5
> Pillow 6.2.2
> pip 20.0.2
> prometheus-client 0.7.1
> prompt-toolkit 3.0.4
> protobuf 3.12.2
> psutil 5.7.0
> ptyprocess 0.6.0
> pyasn1 0.4.8
> pyasn1-modules 0.2.7
> pycparser 2.20
> pyee 7.0.2
> Pygments 2.6.1
> PyJWT 1.7.1
> pylibsrtp 0.6.6
> pyOpenSSL 19.1.0
> pyrsistent 0.16.0
> PySocks 1.7.1
> python-dateutil 2.8.1
> python-engineio 3.13.0
> python-socketio 4.6.0
> PyYAML 5.3.1
> pyzmq 18.1.1
> requests 2.22.0
> requests-oauthlib 1.3.0
> rsa 4.0
> scipy 1.4.1
> Send2Trash 1.5.0
> setuptools 46.4.0.post20200518
> six 1.14.0
> syft 0.2.6
> syft-proto 0.4.6
> tblib 1.6.0
> tensorboard 1.15.0
> tensorboard-plugin-wit 1.6.0
> tensorflow 1.15.3
> tensorflow-estimator 1.15.1
> termcolor 1.1.0
> terminado 0.8.3
> testpath 0.4.4
> tf-encrypted 0.5.9
> torch 1.4.0
> torchvision 0.5.0
> tornado 4.5.3
> traitlets 4.3.3
> urllib3 1.25.9
> wcwidth 0.1.9
> webencodings 0.5.1
> websocket-client 0.57.0
> websockets 8.1
> Werkzeug 1.0.1
> wheel 0.34.2
> wrapt 1.12.1
> zipp 3.1.0

I met the same problem. Have you solved it?",met problem environment version pip everything fine install pip source got error falling back insecure randomness since custom could found version fix custom missing file warning name please use instead due unable proceed please help next providing output pip list package version astor bleach blinker click cryptography decorator flask gast jinja markdown notebook pillow pip post six torch tornado wheel met problem,issue,negative,negative,negative,negative,negative,negative
659247003,"@hericlesme . You have been working with the clients, your opinion would bery helpful",working opinion would helpful,issue,negative,neutral,neutral,neutral,neutral,neutral
659218741,@usamazf No idea why it is removed. The only solution is to install pysyft 0.2.5 so that we can use this module.,idea removed solution install use module,issue,negative,neutral,neutral,neutral,neutral,neutral
658979564,I meet the same problem. The key is to call get for the weight of the model instead of the model itself. ,meet problem key call get weight model instead model,issue,negative,neutral,neutral,neutral,neutral,neutral
658806287,"> LGTM! But I'm wondering, do we have to always get a remote tensor to compare with zero? Can't we do that remotely without fetching it

Yeah indeed that could be a security issue. We could have a remote is_zero ? Like we have a is_none I think",wondering always get remote tensor compare zero ca remotely without fetching yeah indeed could security issue could remote like think,issue,negative,negative,negative,negative,negative,negative
658727750,"@LaRiffle Thank you very much. I also had the same feeling that  the way I was fixing is strange and not the right way and was looking for the feedback, so I created the PR. I had posted a question in slack (#lib_pygrid) to confirm if my understanding about the code and the solution was right.
https://openmined.slack.com/archives/C8PNKSDRU/p1594416474090900

The root cause of this error is:

The code wouldn't find any **_simplifiers_** for **_NodeClient_** (Function: _simplify, file serde.py line no 393).

for inheritance_type in **_classes_inheritance_**:
   if inheritance_type in **_msgpack_global_state.simplifiers:_**

It is because **_classes_inheritance_** is populated using this function:
inspect.getmro(type(obj))[1:]

and we get this list: 
(  <class 'syft.workers.websocket_client.WebsocketClientWorker'>, 
    **_<class 'syft.workers.base.BaseWorker'>_**, 
    ..., 
    <class 'object'>)

But **_msgpack_global_state.simplifiers_** has this :OrderedDict([
    (<class 'dict'>, (0, <function _simplify_dictionary at 0x7fb45058be50>)), 
    (<class 'list'>, (1, <function _simplify_collection at 0x7fb45058bb80>)), 
    .... 
    (**_<class 'syft.workers.virtual.VirtualWorker'>, (63, <function VirtualWorker.simplify at 0x7fb3e3df18b0>_**))
    ....])

Another option that I could think of is checking if any of the class in  msgpack_global_state.simplifiers is a subclass of class being searched for. But again I am not sure if this is the right way, I need your suggestion and hint.",thank much also feeling way fixing strange right way looking feedback posted question slack confirm understanding code solution right root cause error code would find function file line function type get list class class class class function class function class function another option could think class subclass class sure right way need suggestion hint,issue,negative,positive,positive,positive,positive,positive
658705385,Does any one know why the module was removed in the first place? And if any alternative was provided?,one know module removed first place alternative provided,issue,negative,positive,positive,positive,positive,positive
658703848,"It won't work because of the known GIL issue of the python. I tried similar approach for distributed training using PyTorch, and soon figured out that only one thread can take hold of GIL at any given time. When you set a thread to listen mode, it blocks all other threads from taking hold of GIL and in turn stops them from running.

You might wanna read about GIL here: https://realpython.com/python-gil/ and here: http://jessenoller.com/blog/2009/02/01/python-threads-and-the-global-interpreter-lock

Consider porting your code to sub-processes instead.",wo work known issue python tried similar approach distributed training soon figured one thread take hold given time set thread listen mode taking hold turn running might wan na read consider code instead,issue,negative,negative,neutral,neutral,negative,negative
657920766,"@fermat97 I am not sure what do you mean by ""there are still huge amount of communication between ..."". How do you know that there is still communication? Actually, after sent the model and config file to remote machine, the models would also be send from the remote machines to server, which would be used to calculate a average model. ",sure mean still huge amount communication know still communication actually sent model file remote machine would also send remote server would used calculate average model,issue,positive,positive,neutral,neutral,positive,positive
657687884,"Hi, I am not so much up-to-date with the latest PySyft version either, but I believe the only change you would need to make in the code base woud be adding a hooked .size() method in the hook.py file in the path `syft/frameworks/torch/hook/hook.py  `https://github.com/OpenMined/PySyft/blob/master/syft/frameworks/torch/hook/hook.py, analogously to the code from hook.py I posted here https://github.com/OpenMined/PySyft/pull/2343/files. 

The idea is that you override (i.e., hook) the basic PyTorch method with this custom version. However, doing this would probably break a few functionalities not required for LSTM training. 

To sum up, you could try adding code like:

```
 def size(self, dim=None):
            if dim is None:
                return self.shape
            return self.shape[dim]

hook_self.torch.tensor.size = size
```

to this file: `syft/frameworks/torch/hook/hook.py `, eventually applying modifications to make it possible to have the .size() method be hooked in PySyft. One thing also needed would be unncommenting the 'size' method name from https://github.com/OpenMined/PySyft/blob/master/syft/frameworks/torch/torch_attributes.py underneath the following comment:
#Add special functions to exclude from the hook **in alphabetical order**





",hi much latest version either believe change would need make code base hooked method file path analogously code posted idea override hook basic method custom version however would probably break training sum could try code like size self dim none return return dim size file eventually make possible method hooked one thing also would method name underneath following comment add special exclude hook alphabetical order,issue,positive,positive,neutral,neutral,positive,positive
657614930,"> FAILED test/torch/tensors/test_precision.py::test_torch_sigmoid_approx[exp-3-0.065]
@cereallarceny @IonesioJunior should we re-run the tests, or go ahead and merge it. Cause I believe the above test failed due to precision error, unrelated to this PR.",go ahead merge cause believe test due precision error unrelated,issue,negative,negative,negative,negative,negative,negative
657554381,"@DanyEle Hey! I want to use LSTMs to and running into errors due to the missing size() method. Your workaround code seems to be deprecated, as some of the files have been moved or renamed. I don't know enough about the pysyft workings, could you give a small guide where to add the changes in the current master code?

I am getting the following error although I tried setting the size method in various files inspired by your MR.
```
AttributeError: 'AutogradTensor' object has no attribute 'size'
```",hey want use running due missing size method code know enough could give small guide add current master code getting following error although tried setting size method various inspired object attribute,issue,negative,negative,neutral,neutral,negative,negative
657551513,"Recently I ran into the same issue while training a ResNet18 model with PySyft on GPU.

In my case, I found the error was caused by `torch.nn.BatchNorm2d`, which would generate `num_batches_tracked` tensors in Buffers and push them to CPU while `forward()`.

A quick solution is to set `track_running_stats=False` when using `torch.nn.BatchNorm2d`. However, this results in `torch.nn.BatchNorm2d` using batch statistics instead of running estimates while training ([[1](https://pytorch.org/docs/master/generated/torch.nn.BatchNorm2d.html)], [[2](https://discuss.pytorch.org/t/what-num-batches-tracked-in-the-new-bn-is-for/27097)]).",recently ran issue training model case found error would generate push forward quick solution set however batch statistic instead running training,issue,negative,positive,positive,positive,positive,positive
657513312,"Hi guys @NeuZhangQiang @MetaT1an I am using async federated training with `TrainConfig` , my understanding is once the model and config file are sent to the remote machine there shouldn't be any other communication in between. But it seems even during the training on the remote machines (clients), there are still huge amount of communication between the server and each of the clients. Isn't it? Could you understand what are those communications for?",hi training understanding model file sent remote machine communication even training remote still huge amount communication server could understand,issue,negative,positive,neutral,neutral,positive,positive
657505049,"ok, Thanks~

> Hi @xexiyong ! If you mean the crypten branch, it integrates [CrypTen](https://github.com/facebookresearch/CrypTen) into PySyft, so that you can do training and evaluation using private data/models across different PySyft workers, all that using SMPC protocols from CrypTen

",hi mean branch training evaluation private across different,issue,negative,negative,negative,negative,negative,negative
657421833,The new version does not support websocket. It seems that they can not solve it at this moment...,new version support solve moment,issue,positive,positive,positive,positive,positive,positive
657355150,"Hi, what's the major change between this branch compare to the master?",hi major change branch compare master,issue,negative,positive,neutral,neutral,positive,positive
657337035,"Hi @LaRiffle, I'm trying to reproduce, but I don't quite understand how.

```
import torch
import torch.nn as nn
import syft as sy

hook = sy.TorchHook(torch)
bob = sy.VirtualWorker(hook, id=""bob"")
```

I've tested 3 cases.

#### Case 1

```
model = nn.Linear(2, 1)
model_ptr = model.send(bob)
model_copy_ptr = model_ptr.clone()
```

#### Case 2
```
model = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 1))
model_ptr = model.send(bob)
model_copy_ptr = model_ptr.clone()
```

#### Case 3
```
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.fc = nn.Linear(2, 1)
    def forward(self, x):
        return nn.functional.relu(self.fc(x))

model = Net()
model_ptr = model.send(bob)
model_copy_ptr = model_ptr.clone()
```

All the cases fail but with a different error like:
```
...
AttributeError: 'Linear' object has no attribute 'clone'
```

How is this clone supposed to be made?

I also ended up noticing that I can do things like these ones, 

```
model_weights_copy = model_ptr.weight.clone()
model_bias_copy = model_ptr.bias.clone()
```
which works!
",hi trying reproduce quite understand import torch import import hook torch bob hook bob tested case model bob case model bob case class net self super net self forward self return model net bob fail different error like object attribute clone supposed made also ended like work,issue,negative,negative,neutral,neutral,negative,negative
657087207,There are still some docs warnings which need to be fixed but this is good enough for now. @tudorcebere - please help me continue to polish the codebase (more docs and cleanup) before pressing ahead into new functionality. It's starting to get ahead of us.,still need fixed good enough please help continue polish cleanup pressing ahead new functionality starting get ahead u,issue,positive,positive,positive,positive,positive,positive
656956303,"@gmuraru Thanks for chiming in. After some research, i figured that this issue is related to this: https://github.com/OpenMined/PySyft/issues/3349

The default Adam optimizer work but the wrapped version will. This is due to having multiple different workers. Closing now. ",thanks research figured issue related default work wrapped version due multiple different,issue,negative,positive,neutral,neutral,positive,positive
656941942,"> Following @youben11 comment, I think we can close this PR, right @wmlba?

Yes, please. Thanks!",following comment think close right yes please thanks,issue,positive,positive,positive,positive,positive,positive
656869712,Hi @shubham3121 I am using `PySyft` `0.2.4` and `torch` `1.4`. I have added your proposed dropout in your PR #3669.  But I am not sure how it works with the hooking process. How the syft nn module is called. Any idea? Thank you.,hi torch added dropout sure work process module idea thank,issue,positive,positive,positive,positive,positive,positive
656821216,"Following @youben11 comment, I think we can close this PR, right @wmlba?",following comment think close right,issue,negative,positive,positive,positive,positive,positive
656815943,"Hey @wmlba, could you share a notebook/script with all the code (that throws this error)? This is also happening for virtual workers, right?",hey could share code error also happening virtual right,issue,negative,positive,positive,positive,positive,positive
656809704,Hey @punitkoura. Sure - I updated the description - I think the most important part is that this code is on the ```crypten``` branch.,hey sure description think important part code branch,issue,negative,positive,positive,positive,positive,positive
656808540,They're in a different location now @Nilanshrajput - check the `examples/tutorials/static-fl` folder.,different location check folder,issue,negative,neutral,neutral,neutral,neutral,neutral
656688059,"@vvmnnnkv  are these notebooks hidden, I can't see them repo using this location https://github.com/OpenMined/PySyft/tree/master/examples/experimental/FL%20Training%20Plan/Host%20Plan.ipynb ",hidden ca see location,issue,negative,negative,negative,negative,negative,negative
655911012,"@NeuZhangQiang Yeah, it is exactly the missing part in PySyft 0.2.6",yeah exactly missing part,issue,negative,negative,negative,negative,negative,negative
655849396,"@MetaT1an You may want this [tutorial](https://github.com/OpenMined/PySyft/tree/v0.2.5/examples/tutorials/advanced/websockets_mnist_parallel), in which the clients work in parallel. ",may want tutorial work parallel,issue,negative,neutral,neutral,neutral,neutral,neutral
655691832,"Hi @gmuraru , I'd like to work on this issue. However, I'm fairly new to the code base. Could you elaborate a bit more about CryptenInitPlan and CryptenInitJail, and maybe point me to some code sections. Thanks a lot!",hi like work issue however fairly new code base could elaborate bit maybe point code thanks lot,issue,positive,positive,neutral,neutral,positive,positive
655512340,I'm wondering why would a NodeClient need to be sent?,wondering would need sent,issue,negative,neutral,neutral,neutral,neutral,neutral
655506141,"@NeuZhangQiang Hi, see you again here. >_<

I noticed that in [this tutorial](https://nbviewer.jupyter.org/github/OpenMined/PySyft/blob/master/examples/tutorials/Part%2006%20-%20Federated%20Learning%20on%20MNIST%20using%20a%20CNN.ipynb), the clients seem to not work in parallel.  Instead, the client updates the global model one after another.  Well, the training process is sort of different from the description in the original paper.  Despite the effectivenees of that model training process in PySyft, it acts in a weird way deviating from the reald world scenario/ correct FL paradigm.

By the way, I deeply agree with your requirement for asynchronous training.  Because It will make the trainning process more closer to the reality. ",hi see tutorial seem work parallel instead client global model one another well training process sort different description original paper despite model training process weird way world correct paradigm way deeply agree requirement asynchronous training make process closer reality,issue,positive,negative,neutral,neutral,negative,negative
655495789,"> @typhoon1104 You need to have a look at this [tutorial](https://github.com/OpenMined/PySyft/tree/v0.2.5/examples/tutorials/advanced/websockets_mnist_parallel). Please note that only pysyft 0.2.5 support this tutorial, while the pysyft 0.2.6 do not support. And I do not know why pysyft 0.2.6 remove this function.

I use dataset and dataloader of pytorch 1.5.0, it not in PySyft. ",typhoon need look tutorial please note support tutorial support know remove function use,issue,positive,neutral,neutral,neutral,neutral,neutral
655423032,"Hi, I found a solution for this, take a look here https://github.com/kuronosec/PySyft/commit/bd69d25c22aa106bbbeb13764e09a938bb617858 and here https://github.com/kuronosec/syft-proto/commit/e63901e5ffb003fec2c6bf98fe5b10b863c3e6db. But I don't know if that's the right solution or just a workaround. ",hi found solution take look know right solution,issue,positive,positive,positive,positive,positive,positive
655407608,"@typhoon1104 You need to have a look at this [tutorial](https://github.com/OpenMined/PySyft/tree/v0.2.5/examples/tutorials/advanced/websockets_mnist_parallel). Please note that only pysyft 0.2.5 support this tutorial, while the pysyft 0.2.6 do not support. And I do not know why pysyft 0.2.6 remove this function. ",typhoon need look tutorial please note support tutorial support know remove function,issue,positive,neutral,neutral,neutral,neutral,neutral
655406560,"Yes, you can. You only need to make sure the id is unique. ",yes need make sure id unique,issue,positive,positive,positive,positive,positive,positive
655370646,"@NeuZhangQiang Thanks for your kind reply.  Suppose I need 100 clients for a certain experiment, is it a good idea to create these clients with consecutive numbers(1~100) being their **id** property , and to put them into a list for future training?",thanks kind reply suppose need certain experiment good idea create consecutive id property put list future training,issue,positive,positive,positive,positive,positive,positive
655333383,"@Nolski 
Looks like we need this fix: https://github.com/OpenMined/Threepio/pull/109 in threepio.
I've used branch directly in requirements.txt to pass unit test in PySyft.
If threepio is published under new version, requirements.txt needs to be updated.",like need fix used branch directly pas unit test new version need,issue,negative,positive,positive,positive,positive,positive
655329950,hello，I have the question too.I use dataLoader and dataset.But I have a new question that can not get model.,question use new question get model,issue,negative,positive,positive,positive,positive,positive
655310330,"@MetaT1an Yes, PySyft can be used for large-scaled federated learning scenario. There is a [tutorial ](https://github.com/OpenMined/PySyft/tree/v0.2.5/examples/tutorials/advanced/websockets_mnist_parallel)that is helpful for your question. However, for some unclear reason, the pysyft 0.2.6 do not support the above tutorial. 

In addition, I can not find the similar tutorial for keras or tensorflow. ",yes used learning scenario tutorial helpful question however unclear reason support tutorial addition find similar tutorial,issue,positive,neutral,neutral,neutral,neutral,neutral
655045680,"> Q: Could you add a test for this?

I've updated the code once more maybe it's clearer now. It's hard to add tests for this, but it's needed for batchnorm that I wanted to put in a separate PR and which is tested. Sounds good?
(and the main function at stakes here, torch.roll, is tested)",could add test code maybe clearer hard add put separate tested good main function tested,issue,negative,positive,positive,positive,positive,positive
654877524,"Hi guys, nice to meet you. I think that these features are very important for the framework, so I'm very interested in it. I saw this implementation of FEDAVG is a little bit different from that presented on (McMahan at all 2016) https://arxiv.org/abs/1602.05629. Maybe i can be wrong, and the implementation can have some motivation to be like the way it is. However, it is something that I notice, and I want to share it with you.

I saw that in current implementation the first worker to be agregated is multiplied by the number of samples two times and when the model is scaled, this multiplication is not take in consideration, on the division/scale of the model. So the first worker receive more relevance than the second in some cases:

if models == []:
        return None
    if data_amount == None:
        data_amount = [1] * len(models)
    model = add_model(None, models[0], 0, data_amount[0])
    **total_num_data = data_amount[0]**
    for i in range(1, len(models)):
        model = add_model(**model**, models[i], **total_num_data**, data_amount[i])
        model = scale_model(model, 1.0 / (**total_num_data + data_amount[i]**))
        total_num_data += data_amount[i]
    return model

Using the same code base from @codergan i tried to implement the version of macmahan cited on paper:

def federated_avg(models, data_amount = None) :

    if models == []:
        return None
    total_data = sum(data_amount)
    data_scale = [num_samples/total_data for num_samples in data_amount]
    model = add_model_corrected(models[0], models[1] ,  data_scale[0], data_scale[1])
    for i in range(2, len(models)):
        model = add_model_corrected(model, models[i], 1.0, data_scale[i])
    return model

The total number of samples of all workers in a round is calculated before and the data_scale factor of each model is also calculated by the division (num_samples/total_data) to scale each model while executing the model addition process.

I think that the results are different between the two implementations. 

Thank you for your attention.
Best regards.


",hi nice meet think important framework interested saw implementation little bit different maybe wrong implementation motivation like way however something notice want share saw current implementation first worker number two time model scaled multiplication take consideration model first worker receive relevance second return none none model none range model model model model return model code base tried implement version paper none return none sum model range model model return model total number round calculated factor model also calculated division scale model model addition process think different two thank attention best,issue,positive,positive,neutral,neutral,positive,positive
654760696,"If it's not a blocker to other libraries, I am totally into 3.8. We can those features when syft 0.3 is done if we want backwards compatibility.",blocker totally done want backwards compatibility,issue,negative,neutral,neutral,neutral,neutral,neutral
654609042,"As long as we do not have any framework related dependency (Torch, Tensorflow, CrypTen, etc.) that we need to support, I think we should try to support the latest version.

Using the type annotations will help us maintain a cleaner codebase by enforcing more specific restrictions that exist only in Python 3.8",long framework related dependency torch need support think try support latest version type help u maintain cleaner specific exist python,issue,positive,positive,positive,positive,positive,positive
654601929,@youben11 the problem is that it needs a rebase - after the rebase it should work,problem need rebase rebase work,issue,negative,neutral,neutral,neutral,neutral,neutral
654498536,"Sorry. I think I press the ""close"" button by error",sorry think press close button error,issue,negative,negative,negative,negative,negative,negative
654278459,"> So this has been tested on the last commit of CrypTen? wasn't it working before and the update made it work?

Currently, on the CrypTen branch we target their master.",tested last commit working update made work currently branch target master,issue,negative,neutral,neutral,neutral,neutral,neutral
654026622,@gmuraru Great feature! Would love to see how this comes up. ,great feature would love see come,issue,positive,positive,positive,positive,positive,positive
654015774,So this has been tested on the last commit of CrypTen? wasn't it working before and the update made it work?,tested last commit working update made work,issue,negative,neutral,neutral,neutral,neutral,neutral
653975194,Hopefully the timeout can be specified as an argument when creating the websocket client later.,hopefully argument client later,issue,negative,neutral,neutral,neutral,neutral,neutral
653970302,@sunilsu how do you implement the lazy loading by add_dataset? Could you please provide an example?,implement lazy loading could please provide example,issue,negative,negative,negative,negative,negative,negative
653938869,The tests are failing because the branch needs rebasing using the new CrypTen changes from the branch,failing branch need new branch,issue,negative,positive,positive,positive,positive,positive
653920416,"@karlhigley  should i convert all asserts in syft/ directory into if/raise or only that have data validation? for example should i convert `assert len(workers) > 0, ""Please provide workers to receive the data"" ` these also into if/raise.",convert directory data validation example convert assert please provide receive data also,issue,negative,neutral,neutral,neutral,neutral,neutral
653894194,"First of all, the websocketServerWorker class is totally broken in present version(0.2.6), since those developers removed train_config and cause too many bug to fix. So if you want to imply multi-machined FL, an easy way is to use PySyft-0.2.5.
Base on PySyft-0.2.5, here is my understanding. Each client run a websocketServerWorker(""Server"" means hold the data), and server run a websocketclient to remote access the correspond websocketserverworker using the url that provided.
Each turn, server send the complied compute graph of the model(complied by torch.jit.trace) and its weight to client, client do the training and send back to the server. Finally server uses FedAvg algorithm to combine them.
the most accurate tutorial you should read is https://github.com/OpenMined/PySyft/tree/v0.2.5/examples/tutorials/advanced/websockets_mnist_parallel.",first class totally broken present version since removed cause many bug fix want imply easy way use base understanding client run server hold data server run remote access correspond provided turn server send compute graph model weight client client training send back server finally server algorithm combine accurate tutorial read,issue,negative,positive,neutral,neutral,positive,positive
653863620,"Good point @hericlesme. Yes, I should think we need to merge docs changes with this PR. Go ahead and do that first and submit any of those PR’s to me for merging.",good point yes think need merge go ahead first submit,issue,positive,positive,positive,positive,positive,positive
653831098,**Question:** Should documentation updates be mandatory for this pull request to be merged? That way we avoid conflicts or confusion for those who try to use the grid module or node client from the master branch.,question documentation mandatory pull request way avoid confusion try use grid module node client master branch,issue,negative,neutral,neutral,neutral,neutral,neutral
653723062,"> @gmuraru sir, I tried to solve the mentioned problem
> 
> ```
> 2020-04-29T13:13:32.5920184Z ./syft/exceptions.py:359:1: C901 'route_method_exception' is too complex (14)
> 2020-04-29T13:13:32.5920476Z def route_method_exception(exception, self, args_, kwargs_):
> 2020-04-29T13:13:32.5920733Z ^
> ```
> 
> But, instead of converting `route_method_exception` to two separate methods I just reduced the `if...elif` statements.
> And it seems to work properly, it shows positive results in both Flake8 test(after removing C901) and pytest.
> 
> Will this change work instead of separating the method?

Sure!",sir tried solve problem complex exception self instead converting two separate reduced work properly positive flake test removing change work instead separating method sure,issue,positive,positive,positive,positive,positive,positive
653394258,"@wmlba @ThorShockU I have one question. How do you load data in training? I think the data is very large to train VGG model. Am I right? In the tutorial of PySyft, it use data.send(work) to share data. However, if the data is very large (>10g), it is impossible to load it into memory. How can we share it?
One possible solution is FederatedDataLoader, but I have no idea how to convert DataLoader (torch) to FederatedDataset. Could you please give me some suggestion? Thank you very much in advance! ",one question load data training think data large train model right tutorial use work share data however data large impossible load memory share one possible solution idea convert torch could please give suggestion thank much advance,issue,positive,positive,neutral,neutral,positive,positive
653203695,"@gmuraru sir, I tried to solve the mentioned problem
```
2020-04-29T13:13:32.5920184Z ./syft/exceptions.py:359:1: C901 'route_method_exception' is too complex (14)
2020-04-29T13:13:32.5920476Z def route_method_exception(exception, self, args_, kwargs_):
2020-04-29T13:13:32.5920733Z ^
```
But, instead of converting ```route_method_exception``` to two separate methods I just reduced the ```if...elif``` statements.
And it seems to work properly, it shows positive results in both Flake8 test(after removing C901) and pytest.

Will this change work instead of separating the method?",sir tried solve problem complex exception self instead converting two separate reduced work properly positive flake test removing change work instead separating method,issue,negative,negative,neutral,neutral,negative,negative
652889042,"@HongdaWu1226 Thank you very much for the suggestion.

Currently, I meet a problem. PySyft use data.send(worker) to share the data. But, how can we deal with big data by PySyft? PyTorch use DataLoader, and Keras use generator for dataset lazy loading. Is it possible to share DataLoader or generator?

Any suggestion is appreciated! ",thank much suggestion currently meet problem use worker share data deal big data use use generator lazy loading possible share generator suggestion,issue,negative,negative,neutral,neutral,negative,negative
652862019,Will you be working on this tomorrow? I am keen to get more familiar with Syft and learn from the documentation approach so we can replicate something similar as we start to build out the identity repo.,working tomorrow keen get familiar learn documentation approach replicate something similar start build identity,issue,negative,positive,positive,positive,positive,positive
652708609,"@NeuZhangQiang 
If we downgrade the syft version to 0.2.5. It should work if you following the tutorial on ""websockets_mnist_parallel"". Also, you may still face some minor problems, but it is not a big deal and easy to handle.
If you have problem on this tutorial, just contact me via e-mail.",downgrade version work following tutorial also may still face minor big deal easy handle problem tutorial contact via,issue,negative,positive,neutral,neutral,positive,positive
652580550,I'm currently working on this - but anyone is welcome to jump in and get the codebase up to minimum documentation standards.,currently working anyone welcome jump get minimum documentation,issue,negative,positive,positive,positive,positive,positive
652387860,I'd forgotten about this PR but it looks like these changes must have been merged in from somewhere else. Closing.,forgotten like must somewhere else,issue,negative,neutral,neutral,neutral,neutral,neutral
652239709,"> This looks like a nice feature to have! And so, the functions that can be allowed should reside under the `syft` package, right?

Exactly!!
More to come on FSS to see how this can be intensively used :) ",like nice feature reside package right exactly come see intensively used,issue,positive,positive,positive,positive,positive,positive
652101555,Need to make the tests coverage 100% percent.,need make coverage percent,issue,negative,neutral,neutral,neutral,neutral,neutral
651678717,"> > @jmaunon The PyGrid may be a solution. However, I can not run the demo of pygrid, and [#3974](https://github.com/OpenMined/PySyft/issues/3794) describe the bug I have met.
> > @StuLiu Have you implement the clientworker and server workder data loading and model training in real federate learning scenario? Could you please provide me a demo?
> > > > Hi @StuLiu , i will try to help you.
> > > > 
> > > > 1. I am not sure about if there is a tutorial for a more realistic scenario. In any case, I would recommend you to take a look to PyGrid. Here you a find a blog: https://blog.openmined.org/what-is-pygrid-demo/
> > > > 2. Yes, it is possible!. Actually that is the functionality of PrivateTensors. Take a look (again) to the blog I recommend you
> > > 
> > > 
> > > Thank you sincerely for your help! It will help me a lot.
> 
> 您好！ @NeuZhangQiang
> 我也看了一下github上pygrid的项目，暂时没有一个完整的demo。正如你的问题[#3974]所说，需要先开启节点，具体怎么弄的我也不清楚。我用pysyft的serverworker和clientworker实现了数据指针获取与模型传输，能实现远程训练，但是没有保证数据隐私，感兴趣可以看一下这篇博客：https://blog.csdn.net/qq_26623993/article/details/106867566

@StuLiu 另外，这个帖子中，是先收集所有的数据，然后顺序执行。在真实的场景中，能不能让不同的客户端（比如不同的医院）同时计算模型，然后在另一台电脑把所有的模型收集起来做平均？这种并行操作，pysyft可以实现吗？
另外，这里在载入数据的时候，是先把所有整体读入内存。假如我数据特别大，比如100G，没法一次性载入内存，怎么办？
感谢！！",may solution however run describe bug met implement server data loading model training real federate learning scenario could please provide hi try help sure tutorial realistic scenario case would recommend take look find yes possible actually functionality take look recommend thank sincerely help help lot,issue,positive,positive,positive,positive,positive,positive
651672484,"I am getting similar issue in 

https://github.com/OpenMined/PySyft/blob/master/examples/experimental/FL%20Training%20Plan/Host%20Plan.ipynb in 

auth_response = await sendWsMessage(auth_request)
and
cycle_response = await sendWsMessage(cycle_request)

I am running it in Python, haven't checked it in IPython",getting similar issue await await running python checked,issue,negative,neutral,neutral,neutral,neutral,neutral
651633700,"@HongdaWu1226 Sorry, I don't know why there is no ""websockets_mnist_parallel"" tutorial. If you can find one, please tell me. ",sorry know tutorial find one please tell,issue,negative,negative,negative,negative,negative,negative
651598737,"Hey @Nike682631. Sorry for the late reply. Sure, you can work on it!",hey sorry late reply sure work,issue,negative,negative,negative,negative,negative,negative
651503916,"This works! @NeuZhangQiang 
Thanks for the information
Do you have any idea that why this up to date version doen't have the tutorial on ""websockets_mnist_parallel"", which is about asynchronous federated learning and have shown in some other branch.",work thanks information idea date version doe tutorial asynchronous learning shown branch,issue,negative,positive,positive,positive,positive,positive
651467207,"> > @jmaunon The PyGrid may be a solution. However, I can not run the demo of pygrid, and [#3974](https://github.com/OpenMined/PySyft/issues/3794) describe the bug I have met.
> > @StuLiu Have you implement the clientworker and server workder data loading and model training in real federate learning scenario? Could you please provide me a demo?
> > > > Hi @StuLiu , i will try to help you.
> > > > 
> > > > 1. I am not sure about if there is a tutorial for a more realistic scenario. In any case, I would recommend you to take a look to PyGrid. Here you a find a blog: https://blog.openmined.org/what-is-pygrid-demo/
> > > > 2. Yes, it is possible!. Actually that is the functionality of PrivateTensors. Take a look (again) to the blog I recommend you
> > > 
> > > 
> > > Thank you sincerely for your help! It will help me a lot.
> 
> 您好！ @NeuZhangQiang
> 我也看了一下github上pygrid的项目，暂时没有一个完整的demo。正如你的问题[#3974]所说，需要先开启节点，具体怎么弄的我也不清楚。我用pysyft的serverworker和clientworker实现了数据指针获取与模型传输，能实现远程训练，但是没有保证数据隐私，感兴趣可以看一下这篇博客：https://blog.csdn.net/qq_26623993/article/details/106867566

@StuLiu Thank you very much! It help me a lot.",may solution however run describe bug met implement server data loading model training real federate learning scenario could please provide hi try help sure tutorial realistic scenario case would recommend take look find yes possible actually functionality take look recommend thank sincerely help help lot thank much help lot,issue,positive,positive,positive,positive,positive,positive
651417493,"@Williamongh I would like to try the asynchronous websocket-based scenario on GPU. I was wandering how one can provide the information to use the GPU on a remote worker. Is that enough to just use `Net.to(device)`, since there is no option on the `sy.TrainConfig`. Thank you.",would like try asynchronous scenario wandering one provide information use remote worker enough use device since option thank,issue,positive,negative,neutral,neutral,negative,negative
651313622,"Hi @gmuraru sir. I just wanted to ask, can I still contribute to this one? I mean, was this only the part of GSoC?",hi sir ask still contribute one mean part,issue,negative,negative,negative,negative,negative,negative
650751962,I'll start tackling stuff around this one.,start tackling stuff around one,issue,negative,neutral,neutral,neutral,neutral,neutral
650715301,"@thormacy, we should import syft rather than import PySyft-master/syft. 

There is something wrong with the original example, and we need some modifies. 

Copy the websockets_mnist in your Desktop or other folder (make sure it is not included by PySyft-master)

And the folder files is:
```
run_websocket_client.py
run_websocket_server.py
start_websocket_servers.py
```
the run_websocket_server.py is copied from the PySyft-master/run_websocket_server.py.

The start_websocket_servers.py should also be modified as following:
```
import subprocess
import sys
from pathlib import Path

python = Path(sys.executable).name

FILE_PATH = './run_websocket_server.py'

call_alice = [python, FILE_PATH, ""--port"", ""8777"", ""--id"", ""alice""]

call_bob = [python, FILE_PATH, ""--port"", ""8778"", ""--id"", ""bob""]

call_charlie = [python, FILE_PATH, ""--port"", ""8779"", ""--id"", ""charlie""]


print(""Starting server for Alice"")
subprocess.Popen(call_alice)

print(""Starting server for Bob"")
subprocess.Popen(call_bob)

print(""Starting server for Charlie"")
subprocess.Popen(call_charlie)

```

Then, you can run:
```
python start_websocket_servers.py
python run_websocket_client.py
```",import rather import something wrong original example need copy folder make sure included folder copied also following import import import path python path python port id python port id bob python port id print starting server print starting server bob print starting server run python python,issue,negative,positive,neutral,neutral,positive,positive
650634376,I know it was marked WIP - but I was starting to diverge from where you were at so I went ahead and merged it. Moving fast and breaking things :),know marked starting diverge went ahead moving fast breaking,issue,negative,positive,positive,positive,positive,positive
650036173,@iamtrask can we stop marking issues like this as stale?,stop marking like stale,issue,negative,negative,negative,negative,negative,negative
649421353,"# [Codecov](https://codecov.io/gh/OpenMined/PySyft/pull/3782?src=pr&el=h1) Report
> Merging [#3782](https://codecov.io/gh/OpenMined/PySyft/pull/3782?src=pr&el=desc) into [differential-privacy](https://codecov.io/gh/OpenMined/PySyft/commit/3dac9dda90deae86406dba97d3186d08a4c0f753&el=desc) will **not change** coverage.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/OpenMined/PySyft/pull/3782/graphs/tree.svg?width=650&height=150&src=pr&token=W0kQS1vaXB)](https://codecov.io/gh/OpenMined/PySyft/pull/3782?src=pr&el=tree)

```diff
@@                  Coverage Diff                  @@
##           differential-privacy    #3782   +/-   ##
=====================================================
  Coverage                 94.75%   94.75%           
=====================================================
  Files                       186      186           
  Lines                     18459    18459           
=====================================================
  Hits                      17491    17491           
  Misses                      968      968           
```


",report change coverage coverage impacted file tree graph coverage coverage,issue,negative,neutral,neutral,neutral,neutral,neutral
648880461,I'm not sure why the tutorial tests are failing here. The error log doesn't seem to point to any of the parts I've changed either.,sure tutorial failing error log seem point either,issue,negative,positive,positive,positive,positive,positive
648763888,"@punitkoura Hey there, you might want to look at the new refactor issues, as we decided that there is some technical debt around, we are going to refactor syft. This version of pointers/workers/etc. won't be around for too much.",hey might want look new decided technical debt around going version wo around much,issue,negative,positive,positive,positive,positive,positive
648548802,"Finally, I find the solution. 

Using socket, we must create the server firstly, and then create the client. Those, the following code should be run firstly:

```
import syft as sy
import os
import sys
import logging
import torch
hook = sy.TorchHook(torch)

from syft.workers.websocket_server import WebsocketServerWorker

server_worker  = WebsocketServerWorker(
                            host=""localhost"",
                            hook=hook,
                            id=0,
                            port=8182)

server_worker.start()  # Might need to interrupt with `CTRL-C` or some other means

```
Then, do not close it, and run the following code:

```
import torch
import syft
import socket
hook = syft.TorchHook(torch)

from syft.workers.websocket_client import WebsocketClientWorker

remote_client = WebsocketClientWorker(
                            host='localhost',
                            hook=hook,
                            id=2,
                            port=8182)
```
Then, it is OK. ",finally find solution socket must create server firstly create client following code run firstly import import o import import logging import torch hook torch import might need interrupt close run following code import torch import import socket hook torch import,issue,negative,positive,neutral,neutral,positive,positive
648171622,"> Why does ""websockets_mnist_parallel"" be removed?
> Does pysyft support Asynchronous federated learning now?
> 
> When I am trying to run run_websocket_server.py with _--notebook mnist-parallel_ option, it reported an error says _"" AttributeError: 'WebsocketServerWorker' object has no attribute 'add_dataset' ""_.

They updated the PySyft version, where the attribute 'add_dataset' is remove for 'WebsocketServerWorker'. Down your PySyft version to 0.2.5, it will work.",removed support asynchronous learning trying run notebook option error object attribute version attribute remove version work,issue,negative,neutral,neutral,neutral,neutral,neutral
647934045,@tudorcebere Could you please remove the stale label? I don't have access to do this I think.,could please remove stale label access think,issue,negative,negative,negative,negative,negative,negative
647933563,Issue not stale... I'm in the process of sorting out a few issues before I can contribute. Apologies for the delay.,issue stale process contribute delay,issue,negative,negative,negative,negative,negative,negative
647546338,"Got a few questions around syft/ast/*
* What is the type of the variable `path`. As far as I can see, it should be a string?
* What is the type of the variable `path_and_name`. In some places, it is a list, in some places its a string.
* Can we say anything about the return type of `__call__`?
* `framework_reference` is always a ModuleType?
Linked some initial work, I'll clean it up after We get the types right in `syft/ast`.
",got around type variable path far see string type variable list string say anything return type always linked initial work clean get right,issue,negative,positive,positive,positive,positive,positive
647179160,Hi @KunlinY did you manage to solve this? I am getting the same error when I use torch.autograd.grad,hi manage solve getting error use,issue,negative,neutral,neutral,neutral,neutral,neutral
647153403,"Is this feature added? I want to use a Python library on a remote worker. How can I do that?
Thanks!!",feature added want use python library remote worker thanks,issue,negative,positive,neutral,neutral,positive,positive
647040538,"Do you want it like this? 
https://github.com/preactjs/preact/pull/588/commits/36b02704413a79eefc28be133c8acc02a50d77e6

Which uses this: 
https://github.com/opencollective/opencollective-postinstall

Or more simply like this:
https://github.com/preactjs/preact/pull/661/files/319639084c6b83346facfc0e5141910aa559b9ca

If so, I would like to try!",want like simply like would like try,issue,positive,neutral,neutral,neutral,neutral,neutral
646688624,"Things to watch out for:
- I never tested whether it affected runtime performance (when it should be turned off). I hope it shouldn't but it might.
- I didn't check whether it impacted testing performance.",watch never tested whether affected performance turned hope might check whether impacted testing performance,issue,positive,neutral,neutral,neutral,neutral,neutral
646595368,"I'll close this PR since @Nolski has fix the pb with #3725.

Thanks @joaolcaas for reporting and helping us to fix this!",close since fix thanks helping u fix,issue,positive,positive,positive,positive,positive,positive
646557626,#3725 Updates to the latest version of Threepio and fixes the current breaking change between versions.,latest version current breaking change,issue,negative,positive,positive,positive,positive,positive
646460413,"Apologies! 0.0.9 was a breaking change with multi command transition. I have a PR in progress to update pysyft to work with 0.0.9.

For now, let's keep a hard requirement on 0.0.8",breaking change command transition progress update work let keep hard requirement,issue,negative,negative,negative,negative,negative,negative
646456926,"I think the better fix for import issue would be strict version requirement for 3p0 package:
`==0.0.8` instead of `~= 0.0.8`
Until @Nolski finishes multi-command translation in PySyft.

With fix in this PR, multi-command translation will probably not work since you use only the first command from translation.
",think better fix import issue would strict version requirement package instead translation fix translation probably work since use first command translation,issue,negative,positive,positive,positive,positive,positive
646291203,I believe this issue to be complete in the initial commit of syft_0.3.0 branch.,believe issue complete initial commit branch,issue,negative,positive,neutral,neutral,positive,positive
645036798,"Why does ""websockets_mnist_parallel"" be removed? 
Does pysyft support Asynchronous federated learning now?

When I am trying to run run_websocket_server.py with _--notebook mnist-parallel_ option, it reported an error says _"" AttributeError: 'WebsocketServerWorker' object has no attribute 'add_dataset' ""_. ",removed support asynchronous learning trying run notebook option error object attribute,issue,negative,neutral,neutral,neutral,neutral,neutral
644460260,"> Hi @StuLiu , i will try to help you.
> 
> 1. I am not sure about if there is a tutorial for a more realistic scenario. In any case, I would recommend you to take a look to PyGrid. Here you a find a blog: https://blog.openmined.org/what-is-pygrid-demo/
> 2. Yes, it is possible!. Actually that is the functionality of PrivateTensors. Take a look (again) to the blog I recommend you

Thank you sincerely for your help! It will help me a lot.",hi try help sure tutorial realistic scenario case would recommend take look find yes possible actually functionality take look recommend thank sincerely help help lot,issue,positive,positive,positive,positive,positive,positive
644460106,@jmaunon Thank you sincerely for your help! It will help me a lot.,thank sincerely help help lot,issue,positive,positive,positive,positive,positive,positive
644339238,"Hi @StuLiu , i will try to help you.

1. I am not sure about if there is a tutorial for a more realistic scenario. In any case, I would recommend you to take a look to PyGrid. Here you a find a blog: https://blog.openmined.org/what-is-pygrid-demo/

2. Yes, it is possible!. Actually that is the functionality of PrivateTensors. Take a look (again) to the blog I recommend you

",hi try help sure tutorial realistic scenario case would recommend take look find yes possible actually functionality take look recommend,issue,positive,positive,positive,positive,positive,positive
644026326,"# [Codecov](https://codecov.io/gh/OpenMined/PySyft/pull/3708?src=pr&el=h1) Report
> Merging [#3708](https://codecov.io/gh/OpenMined/PySyft/pull/3708?src=pr&el=desc) into [crypten](https://codecov.io/gh/OpenMined/PySyft/commit/2989989854c8879278ab1ba2eb0e1fce80170a58&el=desc) will **decrease** coverage by `0.02%`.
> The diff coverage is `95.34%`.

[![Impacted file tree graph](https://codecov.io/gh/OpenMined/PySyft/pull/3708/graphs/tree.svg?width=650&height=150&src=pr&token=W0kQS1vaXB)](https://codecov.io/gh/OpenMined/PySyft/pull/3708?src=pr&el=tree)

```diff
@@             Coverage Diff             @@
##           crypten    #3708      +/-   ##
===========================================
- Coverage    94.72%   94.70%   -0.03%     
===========================================
  Files          152      193      +41     
  Lines        16051    18846    +2795     
===========================================
+ Hits         15205    17848    +2643     
- Misses         846      998     +152     
```


| [Impacted Files](https://codecov.io/gh/OpenMined/PySyft/pull/3708?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [syft/common/util.py](https://codecov.io/gh/OpenMined/PySyft/pull/3708/diff?src=pr&el=tree#diff-c3lmdC9jb21tb24vdXRpbC5weQ==) | `95.00% <ø> (ø)` | |
| [syft/execution/translation/abstract.py](https://codecov.io/gh/OpenMined/PySyft/pull/3708/diff?src=pr&el=tree#diff-c3lmdC9leGVjdXRpb24vdHJhbnNsYXRpb24vYWJzdHJhY3QucHk=) | `75.00% <ø> (ø)` | |
| [syft/frameworks/crypten/context.py](https://codecov.io/gh/OpenMined/PySyft/pull/3708/diff?src=pr&el=tree#diff-c3lmdC9mcmFtZXdvcmtzL2NyeXB0ZW4vY29udGV4dC5weQ==) | `97.05% <ø> (ø)` | |
| [syft/frameworks/crypten/hook/hook.py](https://codecov.io/gh/OpenMined/PySyft/pull/3708/diff?src=pr&el=tree#diff-c3lmdC9mcmFtZXdvcmtzL2NyeXB0ZW4vaG9vay9ob29rLnB5) | `95.28% <ø> (ø)` | |
| [syft/frameworks/crypten/jail.py](https://codecov.io/gh/OpenMined/PySyft/pull/3708/diff?src=pr&el=tree#diff-c3lmdC9mcmFtZXdvcmtzL2NyeXB0ZW4vamFpbC5weQ==) | `96.20% <ø> (ø)` | |
| [syft/frameworks/crypten/message\_handler.py](https://codecov.io/gh/OpenMined/PySyft/pull/3708/diff?src=pr&el=tree#diff-c3lmdC9mcmFtZXdvcmtzL2NyeXB0ZW4vbWVzc2FnZV9oYW5kbGVyLnB5) | `38.29% <ø> (ø)` | |
| [syft/frameworks/crypten/utils.py](https://codecov.io/gh/OpenMined/PySyft/pull/3708/diff?src=pr&el=tree#diff-c3lmdC9mcmFtZXdvcmtzL2NyeXB0ZW4vdXRpbHMucHk=) | `92.30% <ø> (ø)` | |
| [syft/frameworks/keras/model/sequential.py](https://codecov.io/gh/OpenMined/PySyft/pull/3708/diff?src=pr&el=tree#diff-c3lmdC9mcmFtZXdvcmtzL2tlcmFzL21vZGVsL3NlcXVlbnRpYWwucHk=) | `96.25% <ø> (-0.05%)` | :arrow_down: |
| [syft/frameworks/torch/dp/pate.py](https://codecov.io/gh/OpenMined/PySyft/pull/3708/diff?src=pr&el=tree#diff-c3lmdC9mcmFtZXdvcmtzL3RvcmNoL2RwL3BhdGUucHk=) | `89.94% <ø> (-0.06%)` | :arrow_down: |
| [syft/frameworks/torch/fl/dataloader.py](https://codecov.io/gh/OpenMined/PySyft/pull/3708/diff?src=pr&el=tree#diff-c3lmdC9mcmFtZXdvcmtzL3RvcmNoL2ZsL2RhdGFsb2FkZXIucHk=) | `91.45% <ø> (ø)` | |
| ... and [305 more](https://codecov.io/gh/OpenMined/PySyft/pull/3708/diff?src=pr&el=tree-more) | |
",report decrease coverage coverage impacted file tree graph coverage coverage impacted coverage,issue,negative,neutral,neutral,neutral,neutral,neutral
643579156,"@gmuraru I think coverage got merged as part of other PRs, right? ",think coverage got part right,issue,negative,positive,positive,positive,positive,positive
642534391,"> > Looks okay to me, but I know nothing about conda. @systemshift, is this the simplest way to do this?
> 
> It looks fine to me, but I don't know if it is worth it to add this to our readme, shouldn't we try to fix the issue rather than change the readme to solve edge cases?
> 
> I think this should be mentioned in the issue for those who use conda until we figure it out. We have a messy environment already with pipenv, conda, and docker.

Looking at the comments [issue](https://github.com/jupyter/notebook/issues/3397) it seems like there is no bulletproof solution (maybe I missed something in the comments?)",know nothing way fine know worth add try fix issue rather change solve edge think issue use figure messy environment already docker looking issue like bulletproof solution maybe something,issue,positive,positive,positive,positive,positive,positive
642439612,@karlhigley @tudorcebere I think I solved this issue. I am just running the tests and will do a pull request tomorrow :) ,think issue running pull request tomorrow,issue,negative,neutral,neutral,neutral,neutral,neutral
641847808,"**update:**
This has been dependency whack a mole. Once I thought we just got all of our dependency tree on conda merged a few hours ago, turns out last month `aiortc` has been added, which is not on conda, so now we have to get _that_ on conda-forge.",update dependency whack mole thought got dependency tree ago turn last month added get,issue,negative,neutral,neutral,neutral,neutral,neutral
641142358,"Hello @erksch!
I believe that a vague explanation of the meaning of each parameter can be even more confusing. Therefore, I'm linking this [document](https://github.com/OpenMined/Roadmap/blob/master/web_and_mobile_team/projects/federated_learning.md) for a better understanding.

If any questions still persist, feel free to create another issue, or ask in our slack.
",hello believe vague explanation meaning parameter even therefore linking document better understanding still persist feel free create another issue ask slack,issue,positive,positive,positive,positive,positive,positive
640214919,"yeah, but it is kind of decoupled from the message handler itself. I was thinking more like the message handler checking that in a static function, and workers using some handlers if their deps are okay.",yeah kind message handler thinking like message handler static function,issue,positive,positive,positive,positive,positive,positive
640208463,"one thing we can do for upload speed is to have multiple iterations of uploads, incrementing filesize just like download one",one thing speed multiple like one,issue,negative,neutral,neutral,neutral,neutral,neutral
640169696,"> yeah, that's what I meant, like every message_handler have a function for checking if the deps are okay, and every worker implements the message handlers he need (if the deps are okay for that specific message handler).

Isn't that happening in ```syft/__init__.py```? There I check if we have the framework installed and I add that framework to a variable ```framework_message_handlers```",yeah meant like every function every worker message need specific message handler happening check framework add framework variable,issue,positive,neutral,neutral,neutral,neutral,neutral
640169336,"yeah, that's what I meant, like every message_handler have a function for checking if the deps are okay, and every worker implements the message handlers he need (if the deps are okay for that specific message handler).",yeah meant like every function every worker message need specific message handler,issue,positive,neutral,neutral,neutral,neutral,neutral
640168816,"> Wasn't the initial design to leave every worker choose the message handlers to use, instead of adding all registered message handler in `syft.framework_message_handler`?

The initial design (like we had before) was like that (by using ```add_support``` from the ```BaseWorker```).

Now we automatically add the support if we detect a framework (currently is only for ```CrypTen```).

I tried to follow those steps from the discussion between us and @karlhigley:
```
And when adding a new messageHandler we do:
* Extend AbstractMessageHandler
* in the init_routing_table add our methods (routers) for the specific framework
* append a new instance of that class to our self.message_handlers
```

Or shouldn't we add the handlers automatically?",initial design leave every worker choose message use instead registered message handler initial design like like automatically add support detect framework currently tried follow discussion u new extend add specific framework append new instance class add automatically,issue,positive,positive,neutral,neutral,positive,positive
639669056,This issue was not caught by earlier tests because for every test of encryption-decryption process new parameters were generated and every ciphertext was tested for correct values only ones,issue caught every test process new every tested correct,issue,negative,positive,positive,positive,positive,positive
639274111,"@imskr right now we have to wait for the dependency maintainer to solve the license issue, but what I would like to know if someone could explain what is the exact license problem the maintainer is facing. 
I would just go and fix it upstream if I understood what is the problem.",right wait dependency maintainer solve license issue would like know someone could explain exact license problem maintainer facing would go fix upstream understood problem,issue,negative,positive,positive,positive,positive,positive
639223833,"> I'm working on this!

So I currently have a branch on this https://github.com/conda-forge/staged-recipes/pull/10602
One package dependency is missing from the conda-forge repo. I have opened a new issue for the maintainer to include his package, and now have been waiting for it. https://github.com/data61/python-paillier/issues/81
The other missing package used to be syft-proto but I have included it to conda-forge.",working currently branch one package dependency missing new issue maintainer include package waiting missing package used included,issue,negative,negative,neutral,neutral,negative,negative
638745037,This can be closed since we added other changes. Will reopen it if needed,closed since added reopen,issue,negative,negative,neutral,neutral,negative,negative
638334142,"@karlhigley I agree, `send` has that functionality for tensors that does not make sense in our case in SyferText. I will close this issue since you addressed it in  #3663 ",agree send functionality make sense case close issue since,issue,negative,neutral,neutral,neutral,neutral,neutral
638181377,@gmuraru got started on [an `AbstractPointer` class](https://github.com/OpenMined/PySyft/pull/3629/commits/017a9dd9a83360b12b560ed5e3a16e9ee576460f) recently. I’m working on `create_pointer()` in #3663.,got class recently working,issue,negative,neutral,neutral,neutral,neutral,neutral
637806411,"@gmuraru 
```
(pysyft) ➜  PySyft git:(master) pip freeze | grep tornado
tornado==4.5.3
```

I'll do you one better: here's my [my pip freeze output](https://github.com/OpenMined/PySyft/files/4719701/my_pip.txt)
",git master pip freeze tornado one better pip freeze output,issue,positive,positive,positive,positive,positive,positive
637636824,"@gmuraru's PR has been merged, so this functionality is available in the latest code on the `master` branch and will be included in the next release.",functionality available latest code master branch included next release,issue,negative,positive,positive,positive,positive,positive
637589965,@stephenjfox could you point to me what version of tornado are you using?,could point version tornado,issue,negative,neutral,neutral,neutral,neutral,neutral
637453717,"Dear team,
For your assistance, I have produced a file called ""results - failures and skips.txt"" which contains all those sections which have skipped and failed under the running of `pytest test`.

I hope this helps everyone,

Thank you, merci, gracias, gracie
[results - failures and skips.txt](https://github.com/OpenMined/PySyft/files/4716571/results.-.failures.and.skips.txt)

Anthony of Sydney",dear team assistance produced file running test hope everyone thank,issue,positive,neutral,neutral,neutral,neutral,neutral
637085416,"Even this intermediate step is apparently not something we can aim directly at. There's more fundamental refactoring required, so closing this and will revisit later.",even intermediate step apparently something aim directly fundamental revisit later,issue,negative,positive,neutral,neutral,positive,positive
636986894,"@gmuraru Thank you for your reply.

yupp.. It is true that tfencrypted needs a tensorflow of version < 2 and Syft-Tensorflow installs a version >= 2.

But I am still unable to catch the possible solution for above issue. What should I do to resolve it?

",thank reply true need version version still unable catch possible solution issue resolve,issue,positive,negative,neutral,neutral,negative,negative
636891467,"This works okay for the tensor types, but looks like it fails with other sendable objects like `Plans`. Going to take this one back to the drawing board and try to separate the comms methods that apply to any objects vs the ones that only apply to tensors.",work tensor like sendable like going take one back drawing board try separate apply apply,issue,positive,neutral,neutral,neutral,neutral,neutral
636868617,"Yes, I'm working on it, @cereallarceny. Waiting for OpenMined/PyGrid#577 to be reviewed and merged to open a new one here with the `get_model` function.",yes working waiting open new one function,issue,negative,positive,neutral,neutral,positive,positive
636844958,@tudorcebere is working on that issue. He is coming up with an idea: separaate properties for external detailers and simplifiers that are not updated.,working issue coming idea external,issue,negative,neutral,neutral,neutral,neutral,neutral
636843544,"Ah, that error has to do with the type codes listed in `proto.json` (which confusingly is for msgpack and not Protobuf.) We might be able to provide a way to augment that list, but it’ll be a bit tricky since the codes need to be both stable and unique.",ah error type listed confusingly might able provide way augment list bit tricky since need stable unique,issue,negative,positive,positive,positive,positive,positive
636836938,"I’d love to see it fixed, but I’m not opposed to a temporary change in the README. I have no idea what a fix would look like though.",love see fixed opposed temporary change idea fix would look like though,issue,positive,positive,positive,positive,positive,positive
636816690,"@LaRiffle @Syzygianinfern0  , I guess you have been working in multiplication of AST . I remember a bug related with this #3496 and maybe is related...",guess working multiplication ast remember bug related maybe related,issue,negative,neutral,neutral,neutral,neutral,neutral
636808249,"
Here is the current way I am doing it. (After some help from @tudorcebere ). I am actually having issues there. 


```
def register_to_serde(class_type: type):
    """"""Adds a class `class_type` to the `serde` module of PySyft.

    This is important to enable SyferText types to be sent to remote workers.

    Args:
        class_type (type): The class to register to PySyfts' serde module.
            This enables serde to serialize and deserialize objects of that class.

    Returns:
        (int): The proto ID it is registered with
    """"""

    # Get the maximum integer index of detailers and add 1 to it
    # to create a new index that does not exist yet
    proto_id = max(list(msgpack_global_state.detailers.keys())) + 1

    # Add the simplifier
    msgpack_global_state.detailers[proto_id] = class_type.detail

    # Add the simplifier
    msgpack_global_state.simplifiers[class_type] = (proto_id, class_type.simplify)

    return proto_id

```

However, I am getting an error message when I call this function. (Still trying to understand what it is about, but just posting it here in case you have a rough idea already about what it means):

```---------------------------------------------------------------------------

UndefinedProtocolTypeError                Traceback (most recent call last)
<ipython-input-1-ca47074b52e6> in <module>
      1 import syft as sy
      2 import torch
----> 3 import syfertext
      4 from syfertext.tokenizer import Tokenizer
      5 from syfertext.vocab import Vocab

~/deeplearning/openmined/SyferText/syfertext/__init__.py in <module>
    108 
    109 # Register some types to serde
--> 110 SubPipeline.proto_id = register_to_serde(SubPipeline)
    111 Tokenizer.proto_id = register_to_serde(Tokenizer)
    112 SimpleTagger.proto_id = register_to_serde(SimpleTagger)

~/deeplearning/openmined/SyferText/syfertext/__init__.py in register_to_serde(class_type)
     96     # Get the maximum integer index of detailers and add 1 to it
     97     # to create a new index that does not exist yet
---> 98     proto_id = max(list(msgpack_global_state.detailers.keys())) + 1
     99 
    100     # Add the simplifier

~/deeplearning/openmined/PySyft/syft/serde/msgpack/serde.py in wrapper(self)
     67         @property
     68         def wrapper(self):
---> 69             self = self.update()
     70             return wrapped_func.__get__(self, type(self))
     71 

~/deeplearning/openmined/PySyft/syft/serde/msgpack/serde.py in update(self)
    182         ):
    183             simplifier, detailer = syft_type.simplify, syft_type.detail
--> 184             _add_simplifier_and_detailer(syft_type, simplifier, detailer)
    185         #
    186         # # Register syft objects with custom force_simplify and force_detail methods

~/deeplearning/openmined/PySyft/syft/serde/msgpack/serde.py in _add_simplifier_and_detailer(curr_type, simplifier, detailer, forced)
    165 
    166         def _add_simplifier_and_detailer(curr_type, simplifier, detailer, forced=False):
--> 167             type_info = proto_type_info(curr_type)
    168             if forced:
    169                 self._forced_full_simplifiers[curr_type] = (type_info.forced_code, simplifier)

~/deeplearning/openmined/PySyft/syft/serde/msgpack/proto.py in proto_type_info(cls)
     72         return TypeInfo(name=type_name, obj=proto_info[""TYPES""][type_name])
     73     else:
---> 74         raise UndefinedProtocolTypeError(f""{type_name} is not defined in the protocol file"")

UndefinedProtocolTypeError: syfertext.pointers.state_pointer.StatePointer is not defined in the protocol file

```

By the way, `StatePointer` that you see in the error message is a SyferText object that inherits `ObjectPointer`. What is weird is that this error is raised before even registering it. It is raised while registering another object.",current way help actually type class module important enable sent remote type class register module serialize class proto id registered get maximum integer index add create new index exist yet list add simplifier add simplifier return however getting error message call function still trying understand posting case rough idea already recent call last module import import torch import import import module register get maximum integer index add create new index exist yet list add simplifier wrapper self property wrapper self self return self type self update self simplifier detailer simplifier detailer register custom simplifier detailer forced simplifier detailer forced simplifier return else raise defined protocol file defined protocol file way see error message object weird error raised even raised another object,issue,negative,negative,neutral,neutral,negative,negative
636805720,"I am ok with migrating to protobuf completely. But yeah, in the meantime, it would be good to have msgpack to work.

",completely yeah would good work,issue,positive,positive,positive,positive,positive,positive
636675409,"> Thanks @bobsonlin26 , could you include the label `grid`?

I don't know how to add a new label....
(I've tried to edit this issue, but no option for me to apply a new label)
Maybe it's because I'm not a contributor/member (?",thanks could include label grid know add new label tried edit issue option apply new label maybe,issue,negative,positive,positive,positive,positive,positive
636654011,"I am currently working on this, the natural ordering would be:
1. full protobuf support (protobuf can achieve this easier and better)
2. remove msgpack
3. add a new message in syft for non-syft objects (this might create security issues, this needs some thinking)

Currently, `SyftSerializable` is aware of non-syft objects, if they implement SyftSerializable, they are the same for the serde API, the only problem being the actual messaging system.

We could hack a way around for this to work with msgpack, but if we are going to deprecate it at a moment in time, I would focus on doing 1 and 2 first, 3 should be easy (without further bugs).",currently working natural would full support achieve easier better remove add new message might create security need thinking currently aware implement problem actual system could hack way around work going deprecate moment time would focus first easy without,issue,positive,positive,positive,positive,positive,positive
636639195,"Hello, @NicoSerranoP 

Unfortunately, not yet. You can set it to available if you want to.",hello unfortunately yet set available want,issue,negative,negative,neutral,neutral,negative,negative
636604972,"Dear Karl,
Thank you for the reply.

For yours and the Syft Core team additional information, the other observation I make is when I tried the ""experimental tutorials"", using jupyter notebook there were errors produced. 

Question please: I'm patient and will wait. When Syft is developed for v1.5.0 Pytorch: Do I do this in the following ordered sequence?
* Do I uninstall Syft for Pytorch v1.4.0?
* Do I erase the Syft package for Pytorch v1.4.0? 
* Do I re-git Syft for Pytorch v1.5.0? - Alternatively, in other words, does re-gitting a package mean that I don't have to erase the Syft package for Pytorch v1.4.0?

Thank you, merci, gracias, gracie,
Anthony of Sydney
",dear thank reply core team additional information observation make tried experimental notebook produced question please patient wait following ordered sequence erase package alternatively package mean erase package thank,issue,positive,negative,neutral,neutral,negative,negative
636580495,"> Looks okay to me, but I know nothing about conda. @systemshift, is this the simplest way to do this?

It looks fine to me, but I don't know if it is worth it to add this to our readme, shouldn't we try to fix the issue rather than change the readme to solve edge cases?

I think this should be mentioned in the issue for those who use conda until we figure it out. We have a messy environment already with pipenv, conda, and docker.",know nothing way fine know worth add try fix issue rather change solve edge think issue use figure messy environment already docker,issue,negative,positive,positive,positive,positive,positive
636527162,"Thanks @bobsonlin26 , could you include the label `grid`?",thanks could include label grid,issue,negative,positive,positive,positive,positive,positive
636503797,"The 33 failed tests represent parts of PySyft that don’t work properly with PyTorch 1.5 yet. The Syft Core team plans to work on this is the near future, but hasn’t gotten there yet.",represent work properly yet core team work near future gotten yet,issue,negative,positive,neutral,neutral,positive,positive
636487543,"Dear Karl,
Thank you for your reply.
After running `pytest test`, I had to install the following by pipping:

- papermill
- openssl
- nbformat
- pyopenssl (in order to import OpenSSL as ssl alternatively from OpenSSL import SSL)

In addition:
- Then I re-ran `pytest test`:
   * it was testing a lot of codes with a progress of the test expressed as a percentage. Then a summary...
   * 33 failed, 751 passed, 42 skipped, 163 warnings, 1 error in 2314.10 seconds - **What is the significance of this?**
   * then on two occasions displayed EOFError 

- **I also** I ran the jupyter notebook 'tutorial' in `C:\Python36\PySyft\examples\tutorials` running Part01 and Part02. They seem to work.
 
Thank you,
Anthony of Sydney",dear thank reply running test install following order import alternatively import addition test testing lot progress test expressed percentage summary error significance two displayed also ran notebook running part part seem work thank,issue,positive,neutral,neutral,neutral,neutral,neutral
636477637,"@AnthonyTheKoala 🎉 

I'd try running the test suite with `pytest test/` or `make test` to see what other issues crop up.",try running test suite make test see crop,issue,negative,neutral,neutral,neutral,neutral,neutral
636477461,"Cool, will reopen if I see it happen.",cool reopen see happen,issue,negative,positive,positive,positive,positive,positive
636477379,Could we implement the iterable interface on `PointerTensor` to build that behavior in?,could implement iterable interface build behavior,issue,negative,neutral,neutral,neutral,neutral,neutral
636461804,@tudorcebere this class can be used by libraries like Syfer text to register classes that needs to be serailized. Refer to this issue #3626 ,class used like text register class need refer issue,issue,negative,neutral,neutral,neutral,neutral,neutral
636448738,"@shubham3121 We might be able to achieve this with existing work, could you describe what is the end goal of this class? (Where/why is it needed?)",might able achieve work could describe end goal class,issue,negative,positive,positive,positive,positive,positive
636421779,"Dear Karl,
Thank you for your reply. Summary - it seems to work. 
The details:
Since then, I have changed the requirements file's entry of pytorch 1.4.0 to pytorch 1.5.
In addition it also required me to pip additional packages:
av, crc32c, pyb, pylibsrtp, dataclasses, pyee, tblib, pydot, aioice 
I reinstalled pysyft using: python setup.py install  OK

Now in python I did the following:
import syft as sy    ;#so far so good
sy.__spec__ ;# the underscores don't appear. Should be sy.underscoreunderscorespecunderscoreunderscore
ModuleSpec(name='syft', loader=<_frozen_importlib_external.SourceFileLoader object at 0x000000000364FA58>, origin='C:\\Python36\\lib\\site-packages\\syft-0.2.6-py3.6.egg\\syft\\__init__.py', submodule_search_locations=['C:\\Python36\\lib\\site-packages\\syft-0.2.6-py3.6.egg\\syft'])
sy.__package__ ; #the underscores don't appear should be sy.underscoreunderscorepackageunderscoreunderscore
'syft'

It appears to work, BUT there is no sy.__version__ - the underscores don't appear. 
It appears to work, BUT there is no sy.underscoreunderscoreversionunderscoreunderscore

In sum, it appears to work,  
However I would like to be directed to a simple example to test installation.

Thank you, merci, gracias, gracie,
Anthony of Sydney",dear thank reply summary work since file entry addition also pip additional python install python following import far good appear object appear work appear work sum work however would like directed simple example test installation thank,issue,positive,positive,positive,positive,positive,positive
636415431,"Each time I have seen this failing was because there were the same values. Maybe we need to keep an eye open for this issue and if we see it again, re-open this? ",time seen failing maybe need keep eye open issue see,issue,negative,neutral,neutral,neutral,neutral,neutral
636415261,"I think we should not have those ```ERRORS```. Those appear because of our dependencies. ```Syft``` has ```requests``` as dependency, with version 2.22.
We need to check if we increase/install the correct dependencies we break our functionalities.",think appear dependency version need check correct break,issue,negative,neutral,neutral,neutral,neutral,neutral
636414164,"> Hmm, looks like this happens because our tensor types like `PointerTensor` don't implement the iterable interface for Python classes. That might be a missing feature, but if we implemented it, I don't think it would have the behavior you're expecting, since the resulting tensors would still be on the worker `bob` and not local.
> 
> As written, it would probably print something like:
> 
> ```
> [PointerTensor | me:12345 -> bob:23456]
> [PointerTensor | me:34567 -> bob:45678]
> [PointerTensor | me:56789 -> bob:67890]
> [PointerTensor | me:78901 -> bob:89012]
> ```
> 
> To get the output you expect above, you'd need to fetch the results from `bob` to your local worker with something like:
> 
> ```
> for i in bob_data:
>     print(i.get())
> ```
> 
> @gmuraru, what do you think about this? Is this something we can do with the current implementation of `PointerTensor`? Are there things I'm not thinking of that would make this difficult?

Currently, we allow indexing. We can do a ```bob_data[0]``` and it will create a ```PointerTensor``` on our machine that will point to the data on ```bob```'s machine. (like you specified @karlhigley).

What we can do, to implement the for: simply get the ```shape``` of the ```PointerTensor``` and then use the functionality we have for indexing.

To get a fast implementation:
```
shape = tensor_ptr.shape
for i in range(shape[0]):
    print(bob_data[i].get()) #
```

What can be a use-case for doing an iteration on a ```PointerTensor```? (you can replace the behavior with a ```get``` and then iterate over it)",like tensor like implement iterable interface python class might missing feature think would behavior since resulting would still worker bob local written would probably print something like bob bob bob bob get output expect need fetch bob local worker something like print think something current implementation thinking would make difficult currently allow indexing create machine point data bob machine like implement simply get shape use functionality indexing get fast implementation shape range shape print iteration replace behavior get iterate,issue,positive,negative,neutral,neutral,negative,negative
636413728,"There isn’t a specific line that detects the PyTorch version. You could update the requirements file and give that a try, but the work to make PySyft compatible with PyTorch 1.5 hasn’t happened yet. I would expect errors along that path, but we’d love to have help addressing them.",specific line version could update file give try work make compatible yet would expect along path love help,issue,positive,positive,positive,positive,positive,positive
636413516,"Does it still fail though? (I think it does, but could be wrong.)",still fail though think could wrong,issue,negative,negative,negative,negative,negative,negative
636412748,"Hey @stephenjfox.
Thank you for opening the issue.
It seems the problem is related to ```notebook```, ```tornado``` versions. More details can be seen in this [issue](https://github.com/jupyter/notebook/issues/3397).

The solution (for the moment) is to pin the ```notebook``` and the ```tornado``` versions like:
```
pip install jupyter notebook==5.7.8 tornado==4.5.3
```

Also, made a PR to update the description.
",hey thank opening issue problem related notebook tornado seen issue solution moment pin notebook tornado like pip install also made update description,issue,positive,neutral,neutral,neutral,neutral,neutral
636412620,"Dear gmurau,
Thank you. I had no problem installing pytorch according to https://pytorch.org/ , in the section. ""QUICK START LOCALLY"", I used the pip version for Win without cuda to be:
pip install torch===1.5.0 torchvision===0.6.0 -f https://download.pytorch.org/whl/torch_stable.html

So problem installing pytorch:

BUT the first question has not been answered because pysyft could not be installed because it required pytorch v 1.4.0. I have the **higher version** at 1.5.

My question again please:
I have the source code of pysyft. I want to know which file in the source code that detects v1.4.0 of pytorch such that I can modify the line to pass through v.1.5.0+cpu of pytorch such that I can compile and install. 

Again, which file in the pysyft package detects v1.4.0 of pytorch such that **I can modify the source code and replace v1.4.0. with v.1.5.0+cpu of pytorch?**

Thank you, merci, gracias, gracie 
Anthony of Sydney
",dear thank problem according section quick start locally used pip version win without pip install problem first question could higher version question please source code want know file source code modify line pas compile install file package modify source code replace thank,issue,positive,positive,positive,positive,positive,positive
636410818,"I had a discussion with @karlhigley about this and we were thinking about something like this:
* Have different workflows for each supported framework:
   Eg: torch, tensorflow, crypten, etc..
* Each workflow should have a specific dependency file which will get installed
* Each workflow can have multiple ```sub-flows``` which trigger the tests for that specific framework with the specific python version.

The idea is to have another top level workflow which is specific for each supported framework.",discussion thinking something like different framework torch specific dependency file get multiple trigger specific framework specific python version idea another top level specific framework,issue,positive,positive,neutral,neutral,positive,positive
636409893,"For the first question:
* I think you can simply install torch 1.5 by using the pip command in your environment:
```pip install torch==1.5```
Second question:
* There is already an opened [issue](https://github.com/OpenMined/PySyft/issues/3395) regarding this, but I do not know if there is a concrete timeline when this will get in (@karlhigley @iamtrask)",first question think simply install torch pip command environment pip install second question already issue regarding know concrete get,issue,negative,positive,neutral,neutral,positive,positive
636408520,"For this issue we also need to update the ```PySyft-Tensorflow``` repository to take into consideration the new folder structure.
One of the import errors.
```
~/contrib/ttt/PySyft-TensorFlow/syft_tensorflow/syft_types/keras_layer.py in <module>
      5 import syft
      6 from syft.generic.frameworks.hook import hook_args
----> 7 from syft.generic.object import AbstractObject
      8 from syft.generic.pointers.object_pointer import ObjectPointer
      9 from syft.workers.base import BaseWorker

ModuleNotFoundError: No module named 'syft.generic.object'
```
This is because, the ```object``` is now in ```syft.generic.abstract```

**LE**: Another thing is that it seems we install ```tf_encrypted``` from ```udacity_requirements``` (which needs a ```tensorflow``` version < 2), but in our ```Syft-Tensorflow``` we have as requirement ```tensorflow a version >= 2.0.0```

**Q**: I solved the above dependencies, but seems we have a conflict because tfencrypted needs a version of tensorlfow that is lower than 2 and ```Syft-Tensorflow``` installs a version bigger than 2.",issue also need update repository take consideration new folder structure one import module import import import import import module object another thing install need version requirement version conflict need version lower version bigger,issue,negative,positive,neutral,neutral,positive,positive
636382520,This overlaps a little bit with some of the existing work on `SyftSerializable`. Might want to confer with @tudorcebere on this one.,little bit work might want one,issue,negative,negative,negative,negative,negative,negative
636292648,I don’t believe this actually is stale. @hericlesme can we get an update?,believe actually stale get update,issue,negative,negative,negative,negative,negative,negative
636244936,"> Hello!
> I would like to work on this.

Hi @doringeman ! Where you able to create the tests? I found out that ``` simplify ``` and ``` detail ``` in the [PaillierTensor class](https://github.com/OpenMined/PySyft/blob/master/syft/frameworks/torch/tensors/interpreters/paillier.py#L258-L295) do not work when the tensor has elements inside. Therefore I have not been able to create the proper tests. Check this code:

``` python

from syft.frameworks.torch.tensors.interpreters.paillier import PaillierTensor
import syft as sy
hook = sy.TorchHook(torch)
bob = sy.VirtualWorker(hook, id=""bob"")

array0 = np.array([]) # 0 dimension array
array1 = np.array([1,4]) # 1 dimension array
array2 = np.array([[5,2,3],[1,4,4],[2,4,4],[2,4,4]]) # 3 or n dimension array

x_tensor0 = torch.Tensor(array0)
x_tensor1 = torch.Tensor(array1)
x_tensor2 = torch.Tensor(array2)

pub, pri = sy.keygen()
x_encrypted0 = x_tensor0.encrypt(protocol=""paillier"", public_key=pub)
x_encrypted1 = x_tensor1.encrypt(protocol=""paillier"", public_key=pub)
x_encrypted2 = x_tensor2.encrypt(protocol=""paillier"", public_key=pub)

simplified0 = PaillierTensor.simplify(worker=bob, tensor=x_encrypted0)
simplified1 = PaillierTensor.simplify(worker=bob, tensor=x_encrypted1)
simplified2 = PaillierTensor.simplify(worker=bob, tensor=x_encrypted2)

detailed0 = PaillierTensor.detail(worker=bob, tensor_tuple=simplified0)
# error here: ValueError: cannot create an OBJECT array from memory buffer
detailed1 = PaillierTensor.detail(worker=bob, tensor_tuple=simplified1)
detailed2 = PaillierTensor.detail(worker=bob, tensor_tuple=simplified2)

```
Let me know if you were able to solve it. You can contact me in slack as well :)
",hello would like work hi able create found simplify detail class work tensor inside therefore able create proper check code python import import hook torch bob hook bob array dimension array array dimension array array dimension array array array array pub simplified simplified simplified detailed error create object array memory buffer detailed detailed let know able solve contact slack well,issue,positive,positive,positive,positive,positive,positive
636243193,"Hello,

Yes it should be ready to merge.

Thanks
Zarreen Reza

On Thu, May 28, 2020 at 8:35 PM Andrew Trask <notifications@github.com>
wrote:

> Is this ready to merge? Can we mark it not as draft?
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/pull/3444#issuecomment-635689765>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AHFKLC3H3H5IIKUOKV7P6JLRT37OJANCNFSM4MYKTROQ>
> .
>
",hello yes ready merge thanks may wrote ready merge mark draft thread reply directly view,issue,positive,positive,positive,positive,positive,positive
636154160,Let's ship it! Great work!,let ship great work,issue,positive,positive,positive,positive,positive,positive
636070213,"Here are some examples of the kinds of code I'm trying to remove:
* `TorchTensor.send()` [checks permissions](https://github.com/OpenMined/PySyft/blob/50031be862df886b5f565aad6d5f598fe7b3dbdf/syft/frameworks/torch/tensors/interpreters/native.py#L675-L702) on the whole tensor chain [before sending a tensor](https://github.com/OpenMined/PySyft/blob/50031be862df886b5f565aad6d5f598fe7b3dbdf/syft/frameworks/torch/tensors/interpreters/native.py#L456-L457), which means it has to know about functionality that properly belongs in `PrivateTensor`.
* `TorchTensor.send()` [checks child types](https://github.com/OpenMined/PySyft/blob/50031be862df886b5f565aad6d5f598fe7b3dbdf/syft/frameworks/torch/tensors/interpreters/native.py#L469-L472) in order to determine whether or not to reset the garbage collection flag.
* `TorchTensor.send()` [checks several flags](https://github.com/OpenMined/PySyft/blob/50031be862df886b5f565aad6d5f598fe7b3dbdf/syft/frameworks/torch/tensors/interpreters/native.py#L523-L531) to determine how to handle gradients, in order to make `AutogradTensor` compatible with `MultiPointerTensor`.

With `_before_send()` and `_after_send()` hooks that get called on each tensor in the chain, we should be able to move that kind of code into the relevant classes and avoid creating loops in the dependencies of the abstract and custom tensor types.",code trying remove whole tensor chain sending tensor know functionality properly child order determine whether reset garbage collection flag several determine handle order make compatible get tensor chain able move kind code relevant class avoid abstract custom tensor,issue,negative,positive,positive,positive,positive,positive
636009003,"(As context for anyone else reading this PR, the other communication methods don't quite work for execution yet because they need love and attention separately from `Protocols`, and there's relevant refactoring happening in #3611 and #3629.)",context anyone else reading communication quite work execution yet need love attention separately relevant happening,issue,positive,positive,positive,positive,positive,positive
636004305,"Oh, one more thing: I'm normally in favor of removing code instead of commenting it, but in this case I'd suggest commenting out the other communication methods instead of removing them. @Prtfw just did a bunch of work to add those and I think they work as intended for tracing. Also, I want us to have a concrete reminder to come back and sort them out once some of the deep refactoring concludes. 😄 ",oh one thing normally favor removing code instead case suggest communication instead removing bunch work add think work intended tracing also want u concrete reminder come back sort deep,issue,negative,positive,neutral,neutral,positive,positive
635971817,"Hmm, reading the stack trace, it looks like the optimizer passes the same grad to `addcmul_` twice, which looks right [according to the Torch docs](https://pytorch.org/docs/master/generated/torch.addcmul.html#torch-addcmul).
```
  File ""C:\Anaconda3\envs\pysyft\lib\site-packages\torch\optim\adadelta.py"", line 72, in step
    square_avg.mul_(rho).addcmul_(1 - rho, grad, grad)
```
I wonder if it has something to do with the way the operation is de/serialized and reconstructed on the remote `Worker`? Might have to try to try to replicate and dig into it with a debugger.",reading stack trace like grad twice right according torch file line step rho rho grad grad wonder something way operation reconstructed remote worker might try try replicate dig,issue,negative,positive,neutral,neutral,positive,positive
635963765,"Ah, sorry, I rushed to open this PR in order to share it with @gmuraru and @imskr, but I left out some context and should have marked it as a draft.

Behind the linting error, there's an issue with circular dependencies, because moving the communications methods to `AbstractSendable` means that it depends on `PointerTensor`, which is an `AbstractSendable`. Our current plan for what to try next is to add an `AbstractPointer` class (which might be just be a rename of `ObjectPointer`) and rewrite the general case versions of these methods to use that instead of `PointerTensor`. I think that means that `AbstractPointer` will need not to be an `AbstractSendable` though, so the concrete `Pointer` types will probably have to inherit from both. 🤷 ",ah sorry rushed open order share left context marked draft behind error issue circular moving current plan try next add class might rename rewrite general case use instead think need though concrete pointer probably inherit,issue,negative,negative,neutral,neutral,negative,negative
635961516,Labeled `protocols` and added to a new `Asynchronous Workers` milestone.,added new asynchronous milestone,issue,negative,positive,positive,positive,positive,positive
635961183,No worries! (The Syft Core team is just trying to do a better job of keeping up with open issues and PRs.),core team trying better job keeping open,issue,negative,positive,positive,positive,positive,positive
635960718,"Since the result may reveal information about the inputs, it should default to having the most restrictive permissions found among the inputs. There may be certain cases/operations where it's safe to reveal the output, but we should err on the side of privacy by default.",since result may reveal information default restrictive found among may certain safe reveal output err side privacy default,issue,positive,positive,positive,positive,positive,positive
635959740,I will test this quickly. I think you are right. the argument is redundant.,test quickly think right argument redundant,issue,negative,positive,positive,positive,positive,positive
635959021,"I think I get the general idea, but perhaps it's the subtleties I've been missing. We have so many examples that demonstrate secret sharing with very small tensors that it was a bit of a mental leap to think about encrypted embedding layers (for example.)",think get general idea perhaps missing many demonstrate secret small bit mental leap think example,issue,negative,negative,neutral,neutral,negative,negative
635957116,"I'm good with that, and I think we have some `ObjectPointer` refactoring to do anyway, so let's close this one and call it done. 👍 ",good think anyway let close one call done,issue,negative,positive,positive,positive,positive,positive
635953758,"The current GC behavior does send a delete message, but since our comms methods are currently synchronous and blocking, that means that garbage collection is a blocking operation. 🙁 ",current behavior send delete message since currently synchronous blocking garbage collection blocking operation,issue,negative,neutral,neutral,neutral,neutral,neutral
635940180,@mari-linhares happy to work on this together as well ,happy work together well,issue,positive,positive,positive,positive,positive,positive
635939799,Is there a way to mark this as a part of the protocols project?,way mark part project,issue,negative,neutral,neutral,neutral,neutral,neutral
635925647,"> Status on this?

Let me finish it !
I was just busy with other things few weeks ago
Now I have time deal with it",status let finish busy ago time deal,issue,negative,positive,neutral,neutral,positive,positive
635918330,"> There are (at least) two possible approaches here:
> 
> * Add `share` and other MPC methods to `PrivateTensor` (easier and will totally work for now)
> * Consolidate the tensor privacy and permissions functionality from `PrivateTensor` into one of the base classes for tensors (probably `AbstractTensor`), so that all tensors have both permissioning and MPC (harder but more robust in the long term)
> 
> Either way is fine for resolving this issue. If we end up doing the first one for now, then we can create a separate issue to do the second refactor later.

I agree with these two approaches. What I have been thinking is what happens with the permissions of the result, I mean if we are capable of sum 2 Private Tensor (via MPC), where each tensor has different permission, the result would include both permissions? Is an open comment :)
",least two possible add share easier totally work consolidate tensor privacy functionality one base class probably harder robust long term either way fine issue end first one create separate issue second later agree two thinking result mean capable sum private tensor via tensor different permission result would include open comment,issue,positive,negative,neutral,neutral,negative,negative
635900091,"So acceleration comes from accelerating the forward pass and the backward pass to in 'loss.backward()'.

So for the model, it could look something like

```
# SMPC
model.share(bob, alice, crypto_provider = crypto_provider)
model = sy.DataParallel(model, max_devices = 'all'/<max allowed GPUs>)
model = model.to(""cuda"", allow_revert = True/False) 

# FL
model.send(bob)
model = sy.DataParallel(model, max_devices = 'all'/<max allowed GPUs>)
model = model.to(""cuda"", allow_revert = True/False) 
```

It should be something like that. But of course more subtlities will pop up.

Is that clear @karlhigley ? ",acceleration come forward pas backward pas model could look something like bob model model model bob model model model something like course pop clear,issue,positive,positive,positive,positive,positive,positive
635898750,"Make whatever issue labels you want, but at the minimum you should assign a
type, status, priority, and severity issue label.
",make whatever issue want minimum assign type status priority severity issue label,issue,negative,neutral,neutral,neutral,neutral,neutral
635889146,"I think `PointerTensor` is one of the cases where I'd be kind of in favor of the multiple inheritance.
Maybe some of the methods on `PointerTensor` should be moved to `ObjectPointer` though.
Then `PointerTensor` would have a very simple implementation with almost no method of its own.
But I'm aware that multiple inheritance complexifies some things so...",think one kind favor multiple inheritance maybe though would simple implementation almost method aware multiple inheritance,issue,positive,positive,positive,positive,positive,positive
635833278,"@karlhigley I think this might be an awesome idea, workers really need some love, I like the idea of making send and receive on separate threads (could this help async workers as well?). This could be a step forward the actor model as well and the stack forwarding project. (maybe we would like to stick with some custom actor model?). I am not familiar with the GC behavior, but in my mind, the idea of adding a del message when an object goes out of scope could work really nice, (should make everything more transparent as well). ",think might awesome idea really need love like idea making send receive separate could help well could step forward actor model well stack forwarding project maybe would like stick custom actor model familiar behavior mind idea message object go scope could work really nice make everything transparent well,issue,positive,positive,positive,positive,positive,positive
635823235,"Hello @ChedidJM , thank you for reporting this bug,

Could you please provide:
1. full script to reproduce the bug.
2. stack tracke/logging if you have any.
3. OS and syft version.

Thank you!",hello thank bug could please provide full script reproduce bug stack o version thank,issue,positive,positive,positive,positive,positive,positive
635820206,"Hello! Thank you for reporting this, could you provide:

1. the full script to reproduce the error.
2. the stack trace/logging if you have.
3. syft and OS version.

Thank you!",hello thank could provide full script reproduce error stack o version thank,issue,negative,positive,positive,positive,positive,positive
635817581,"> @Avi-000-Avi all you - this is a great first issue if its your first.

Yeah working on it🙃",great first issue first yeah working,issue,positive,positive,positive,positive,positive,positive
635793521,"Much to do lately, working again on it starting next week. ",much lately working starting next week,issue,negative,negative,neutral,neutral,negative,negative
635766326,"Can't reproduce with fresh py36 or py37 conda environments on Win10.
@vikas-ratan Please post output of your `pip debug --verbose`.",ca reproduce fresh win please post output pip verbose,issue,positive,positive,positive,positive,positive,positive
635721945,"There are (at least) two possible approaches here:
* Add `share` and other MPC methods to `PrivateTensor` (easier and will totally work for now)
* Consolidate the tensor privacy and permissions functionality from `PrivateTensor` into one of the base classes for tensors (probably `AbstractTensor`), so that all tensors have both permissioning and MPC (harder but more robust in the long term)

Either way is fine for resolving this issue. If we end up doing the first one for now, then we can create a separate issue to do the second refactor later.",least two possible add share easier totally work consolidate tensor privacy functionality one base class probably harder robust long term either way fine issue end first one create separate issue second later,issue,positive,negative,neutral,neutral,negative,negative
635719708,"We’re burning this candle from several ends now, since the `AbstractSendable` work is also aimed at this goal. 👍",burning candle several since work also goal,issue,negative,neutral,neutral,neutral,neutral,neutral
635719339,"Yeah, let’s close this. `BaseWorker` can probably remain synchronous, but we’re going to want asynchronous sub-classes for testing and real usage.",yeah let close probably remain synchronous going want asynchronous testing real usage,issue,negative,positive,positive,positive,positive,positive
635718262,"I think @iamtrask will be working on building out a few tensor types with next-gen framework hooking, so let’s revisit after that. 👍",think working building tensor framework let revisit,issue,negative,neutral,neutral,neutral,neutral,neutral
635716697,"I think `Plans` and `Protocols` require a solution to this issue, but I don’t think they are the solution themselves. We’ll still need a way to handle this for execution outside `Plans/Protocols`.

If we rework `Workers` to have multiple threads for processing messages and executing actions, we’re going to need queues for passing incoming actions (from messages) in to the execution thread and outgoing messages back out to the communication thread. If we do that, then GC will mostly happen on the execution thread, so it will enqueue a lot of delete messages. My hunch is that having a queue that may contain multiple deletes would make batching easier—when you send a delete message, you iterate through the queue and pull _all_ the delete messages, then send them as a single message.

Our garbage collection probably needs bigger tweaks than this though. (Distributed system life is hard. 😅)",think require solution issue think solution still need way handle execution outside rework multiple going need passing incoming execution thread outgoing back communication thread mostly happen execution thread lot delete hunch queue may contain multiple would make send delete message iterate queue pull delete send single message garbage collection probably need bigger though distributed system life hard,issue,positive,positive,neutral,neutral,positive,positive
635711080,"> Status on this?

This PR can encrypt and decrypt integers using the FV scheme. In crypto-team, we have decided to merge this PR first and then start working on further part of the algorithm. I am waiting for some reviews.
Your review would be great!😃😄",status encrypt scheme decided merge first start working part algorithm waiting review would great,issue,positive,positive,positive,positive,positive,positive
635689765,Is this ready to merge? Can we mark it not as draft?,ready merge mark draft,issue,negative,positive,positive,positive,positive,positive
635688902,"Shouldn’t the object have an id at all times already? This seems like it might slow the api with an extra arg. Is there an exception here? 

If anything maybe we should remove the id option from the object store api. ",object id time already like might slow extra exception anything maybe remove id option object store,issue,negative,negative,negative,negative,negative,negative
635688095,"No need for this to be a blocking op is there.

I think the correct answer here is already in play via protocols and asynchronous comms.

We could work on sophisticated batching but not a high priority and increases the chance of leaks if comms get disconnected. Also torch re uses tensors intelligently so GC less might have perf issues elsewhere. 

The solution is plans and protocols - closing. ",need blocking think correct answer already play via asynchronous could work sophisticated high priority chance get disconnected also torch intelligently le might elsewhere solution,issue,positive,positive,positive,positive,positive,positive
635686919,@Avi-000-Avi all you - this is a great first issue if its your first.,great first issue first,issue,positive,positive,positive,positive,positive,positive
635686675,Hi @KunlinY - I’m afraid this is a known issue which will be fixed in the upcoming refactor. Look for the release of syft 0.3. ,hi afraid known issue fixed upcoming look release,issue,negative,negative,negative,negative,negative,negative
635686300,@cereallarceny whats the new policy on new GitHub tags?,whats new policy new,issue,negative,positive,positive,positive,positive,positive
635685371,Hey George - let’s sync on this. I think there’s a cleaner approach to this refactor. Book a meeting with me using calendly,hey let sync think cleaner approach book meeting,issue,negative,neutral,neutral,neutral,neutral,neutral
635684911,Safe to close this given today’s convo?,safe close given today,issue,negative,positive,positive,positive,positive,positive
635683084,Ready to merge one conflicts are resolved! 🙂,ready merge one resolved,issue,negative,positive,positive,positive,positive,positive
635682479,Looks like an additive sharing test is failing,like additive test failing,issue,negative,neutral,neutral,neutral,neutral,neutral
635633652,"Thanks for being on top of this Karl!

> Seems like it may depend on getting the new style of tensor hooking set up, so not sure if there's much to do that's directly Tensorflow-related right now. Thoughts?

Yes! I think this is right. Probably the next steps are not super TensorFlow related but should be highly influenced by what is needed to have TensorFlow working (if that makes sense).",thanks top like may depend getting new style tensor set sure much directly right yes think right probably next super related highly working sense,issue,positive,positive,positive,positive,positive,positive
635608766,"At this point, I think a series of recent refactors have addressed all of the listed classes except `PointerTensor`. I don't have a clear idea of how to make `PointerTensor` singly inheriting—I think it needs to have the `AbstractTensor` API, so maybe the better option is to make it be an `AbstactTensor` and have an `ObjectPointer`. What do you think, @Jasopaum?",point think series recent listed class except clear idea make singly think need maybe better option make think,issue,positive,positive,positive,positive,positive,positive
635606782,"@mari-linhares @iamtrask Since this didn't turn into a GSOC project, what are our next steps with this? Seems like it may depend on getting the new style of tensor hooking set up, so not sure if there's much to do that's directly Tensorflow-related right now. Thoughts?",since turn project next like may depend getting new style tensor set sure much directly right,issue,positive,positive,positive,positive,positive,positive
635606207,"@gmuraru Is this a case where we should increase the tolerance on this test? I've hesitated to fix it that way, because I don't know how much that weakens the test assertion, but think I remember seeing similar tests adjusted that way in the past.",case increase tolerance test fix way know much test assertion think remember seeing similar way past,issue,positive,negative,neutral,neutral,negative,negative
635605633,"@ZhechunZhou I have some guesses where this might come from, but it's a little bit difficult to pin down. Could you post a stack trace for this error?",might come little bit difficult pin could post stack trace error,issue,negative,negative,negative,negative,negative,negative
635600818,"Hmm, looks like this happens because our tensor types like `PointerTensor` don't implement the iterable interface for Python classes. That might be a missing feature, but if we implemented it, I don't think it would have the behavior you're expecting, since the resulting tensors would still be on the worker `bob` and not local.

As written, it would probably print something like:
```
[PointerTensor | me:12345 -> bob:23456]
[PointerTensor | me:34567 -> bob:45678]
[PointerTensor | me:56789 -> bob:67890]
[PointerTensor | me:78901 -> bob:89012]
```
To get the output you expect above, you'd need to fetch the results from `bob` to your local worker with something like:
```
for i in bob_data:
    print(i.get())
```

@gmuraru, what do you think about this? Is this something we can do with the current implementation of `PointerTensor`? Are there things I'm not thinking of that would make this difficult?",like tensor like implement iterable interface python class might missing feature think would behavior since resulting would still worker bob local written would probably print something like bob bob bob bob get output expect need fetch bob local worker something like print think something current implementation thinking would make difficult,issue,positive,negative,negative,negative,negative,negative
635595551,"Hmm, I'm not able to reproduce on a fresh Windows 10 install with Python 3.7.7. I get an error installing Torch:
```
C:\Users\karl\AppData\Local\Programs\Python\Python37>pip install syft[udacity]
Collecting syft[udacity]
  Downloading syft-0.2.6-py3-none-any.whl (377 kB)
     |████████████████████████████████| 377 kB 1.6 MB/s
Collecting syft-proto~=0.4.5
  Downloading syft_proto-0.4.6-py3-none-any.whl (57 kB)
     |████████████████████████████████| 57 kB 2.3 MB/s
Collecting phe~=1.4.0
  Downloading phe-1.4.0.tar.gz (35 kB)
Collecting scipy~=1.4.1
  Downloading scipy-1.4.1-cp37-cp37m-win_amd64.whl (30.9 MB)
     |████████████████████████████████| 30.9 MB 6.4 MB/s
Collecting flask-socketio~=4.2.1
  Downloading Flask_SocketIO-4.2.1-py2.py3-none-any.whl (16 kB)
Collecting Pillow~=6.2.2
  Downloading Pillow-6.2.2-cp37-cp37m-win_amd64.whl (2.0 MB)
     |████████████████████████████████| 2.0 MB 6.4 MB/s
ERROR: Could not find a version that satisfies the requirement torch~=1.4.0 (from syft[udacity]) (from versions: 0.1.2, 0.1.2.post1, 0.1.2.post2)
ERROR: No matching distribution found for torch~=1.4.0 (from syft[udacity])
```
But then if I follow the Torch instructions for a Windows install, I get:
```
C:\Users\karl\AppData\Local\Programs\Python\Python37>pip install torch==1.4.0+cpu torchvision==0.5.0+cpu -f https://download.pytorch.org/whl/torch_stable.html
Looking in links: https://download.pytorch.org/whl/torch_stable.html
Collecting torch==1.4.0+cpu
  Downloading https://download.pytorch.org/whl/cpu/torch-1.4.0%2Bcpu-cp37-cp37m-win_amd64.whl (77.4 MB)
     |████████████████████████████████| 77.4 MB 6.4 MB/s
Collecting torchvision==0.5.0+cpu
  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.5.0%2Bcpu-cp37-cp37m-win_amd64.whl (485 kB)
     |████████████████████████████████| 485 kB 3.3 MB/s
Collecting six
  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)
Collecting pillow>=4.1.1
  Downloading Pillow-7.1.2-cp37-cp37m-win_amd64.whl (2.0 MB)
     |████████████████████████████████| 2.0 MB 6.8 MB/s
Collecting numpy
  Downloading numpy-1.18.4-cp37-cp37m-win_amd64.whl (12.8 MB)
     |████████████████████████████████| 12.8 MB ...
Installing collected packages: torch, six, pillow, numpy, torchvision
Successfully installed numpy-1.18.4 pillow-7.1.2 six-1.15.0 torch-1.4.0+cpu torchvision-0.5.0+cpu
```
Which then allows me to try installing PySyft again, which gives this (emphasis mine):
```
C:\Users\karl\AppData\Local\Programs\Python\Python37>pip install syft[udacity]
Collecting syft[udacity]
  Using cached syft-0.2.6-py3-none-any.whl (377 kB)
Collecting requests~=2.22.0
  Downloading requests-2.22.0-py2.py3-none-any.whl (57 kB)
     |████████████████████████████████| 57 kB 1.1 MB/s
Requirement already satisfied: torchvision~=0.5.0 in c:\users\karl\appdata\local\programs\python\python37\lib\site-packages (from syft[udacity]) (0.5.0+cpu)
Collecting syft-proto~=0.4.5
  Using cached syft_proto-0.4.6-py3-none-any.whl (57 kB)
Collecting tblib~=1.6.0
  Downloading tblib-1.6.0-py2.py3-none-any.whl (12 kB)
Collecting lz4~=3.0.2
  Downloading lz4-3.0.2-cp37-cp37m-win_amd64.whl (162 kB)
     |████████████████████████████████| 162 kB 6.8 MB/s
Collecting msgpack~=1.0.0
  Downloading msgpack-1.0.0-cp37-cp37m-win_amd64.whl (72 kB)
     |████████████████████████████████| 72 kB 5.1 MB/s  
>>> Collecting websockets~=8.1.0
>>> Downloading websockets-8.1-cp37-cp37m-win_amd64.whl (66 kB)
     |████████████████████████████████| 66 kB ...
[...]
```
And then the install goes on to succeed. Syft currently only supports Python 3.6-3.7, so it could be a Python version thing?",able reproduce fresh install python get error torch pip install error could find version requirement post post error matching distribution found follow torch install get pip install looking link six pillow collected torch six pillow successfully try emphasis mine pip install requirement already satisfied install go succeed currently python could python version thing,issue,positive,positive,positive,positive,positive,positive
635561673,"In that case, could you post the full output from `pip install`? Also, what's your Python version?",case could post full output pip install also python version,issue,negative,positive,positive,positive,positive,positive
635535674,I tried removing cache but same error occurred.,tried removing cache error,issue,negative,neutral,neutral,neutral,neutral,neutral
635495086,"@AlanAboudib Those are good suggestions how the API might look. 👍 

Could you share an example of what it might look like on the model end? Want to make sure I'm following where the parallelism that GPUs can accelerate comes from.",good might look could share example might look like model end want make sure following parallelism accelerate come,issue,positive,positive,positive,positive,positive,positive
635491322,"Hmm, I'm not sure why that would happen, since it does look like there are [wheels available for `websockets 8.1` for Windows](https://pypi.org/project/websockets/#files).

Could it be a `pip cache` issue? Maybe try clearing it `pip cache purge` and then try re-installing from the requirements file again?",sure would happen since look like available could pip cache issue maybe try clearing pip cache purge try file,issue,positive,positive,positive,positive,positive,positive
635489377,@AlanAboudib Is this still a thing y'all would like to have? How are you handling this now? Is there example code we could look at to see where it would simplify things in SyferText?,still thing would like handling example code could look see would simplify,issue,negative,neutral,neutral,neutral,neutral,neutral
635488666,"Thinking maybe we should create a milestone for async/multi-threaded workers and assign this issue to that milestone. Anyone else have thoughts on that? I can't see a good way to address this without some form of concurrency, but that doesn't mean there isn't one. 🤔 ",thinking maybe create milestone assign issue milestone anyone else ca see good way address without form concurrency mean one,issue,positive,positive,positive,positive,positive,positive
635487042,"@tudorcebere I've been thinking a lot about refactoring workers in order to make `Protocols` work, and I think we might want to consider having separate threads for message sending/receiving, message processing, and `Plan/Protocol` execution. If we did that, we'd need to be able to pass messages between threads, so we'd probably use thread-safe queues.

And if we had _that_, then maybe the `__del__` hook that gets called for garbage collection when objects go out of scope could add a delete message to the queue instead of directly trying to serialize and send it. That would turn this issue into ""Do we want to make sure outgoing delete messages are processed when Python shuts down? If so, how?""

Instead of sending outgoing delete messages when we shut down, it might make more sense for workers to GC remaining objects that came from workers they're no longer in contact with? Not sure, but seems possible.",thinking lot order make work think might want consider separate message message execution need able pas probably use maybe hook garbage collection go scope could add delete message queue instead directly trying serialize send would turn issue want make sure outgoing delete python instead sending outgoing delete shut might make sense came longer contact sure possible,issue,positive,positive,positive,positive,positive,positive
635451282,"Got it!
```
[%] Starting computation
[+] run_encrypted_training() took 32s
Epoch 0 in progress:
	Batch 1 of 10 Loss 0.4638
	Batch 2 of 10 Loss 0.4666
	Batch 3 of 10 Loss 0.4065
	Batch 4 of 10 Loss 0.3488
	Batch 5 of 10 Loss 0.3314
	Batch 6 of 10 Loss 0.2796
	Batch 7 of 10 Loss 0.2767
	Batch 8 of 10 Loss 0.2432
	Batch 9 of 10 Loss 0.2456
	Batch 10 of 10 Loss 0.2003
Epoch 1 in progress:
	Batch 1 of 10 Loss 0.1625
	Batch 2 of 10 Loss 0.1515
	Batch 3 of 10 Loss 0.1549
	Batch 4 of 10 Loss 0.1922
	Batch 5 of 10 Loss 0.1319
	Batch 6 of 10 Loss 0.1635
	Batch 7 of 10 Loss 0.2243
	Batch 8 of 10 Loss 0.1453
	Batch 9 of 10 Loss 0.1717
	Batch 10 of 10 Loss 0.1335
```",got starting computation took epoch progress batch loss batch loss batch loss batch loss batch loss batch loss batch loss batch loss batch loss batch loss epoch progress batch loss batch loss batch loss batch loss batch loss batch loss batch loss batch loss batch loss batch loss,issue,negative,neutral,neutral,neutral,neutral,neutral
635434040,"@shubham3121 Thanks, didn't catch that! Looks like it might have been a temporary issue, but if it persists, we can open an issue. 👍 ",thanks catch like might temporary issue open issue,issue,positive,positive,neutral,neutral,positive,positive
635157583,"Tried to run the notebook but got this error:
```
---------------------------------------------------------------------------
ModuleNotFoundError                       Traceback (most recent call last)
<ipython-input-1-b5df2d527789> in <module>
      6 from time import time
      7 from syft import WebsocketClientWorker
----> 8 from syft.frameworks.crypten.context import run_multiworkers
      9 
     10 

ModuleNotFoundError: No module named 'syft.frameworks.crypten.context'
```

Is there something special that I need to change?",tried run notebook got error recent call last module time import time import import module something special need change,issue,negative,positive,positive,positive,positive,positive
635149965,"Hey. If the issue is still present, you can grab it :D",hey issue still present grab,issue,negative,neutral,neutral,neutral,neutral,neutral
635090484,Is the issue still open?I would like to work on it? @gmuraru ,issue still open would like work,issue,negative,neutral,neutral,neutral,neutral,neutral
634632314,"hey, @karlhigley. I have added some tests but I had to delete the dictionary copy part. Apparently, the model is a totally different object (something like avg_model != net1) but the weights are modified. The way that is now, this does not happen.",hey added delete dictionary copy part apparently model totally different object something like net way happen,issue,negative,positive,neutral,neutral,positive,positive
634056288,What do you mean? I think this part of the notebook is working fine. Maybe a version problem?,mean think part notebook working fine maybe version problem,issue,negative,positive,neutral,neutral,positive,positive
633969364,Done! Keep us updated on your progress @krharsh17 !,done keep u progress,issue,negative,neutral,neutral,neutral,neutral,neutral
633936951,"Hi, I'd like to work on this issue. Could you please assign it to me?",hi like work issue could please assign,issue,positive,neutral,neutral,neutral,neutral,neutral
633917048,"> analyzing it :)

Nice! I have been analyzing as well! One you have some conclusions, we could use this issue in order to exchange our impressions",nice well one could use issue order exchange,issue,positive,positive,positive,positive,positive,positive
633700157,Looks like the tests are failing early due to formatting issues. Try running `black .` to apply automatic formatting and then fixing any issues listed in the output of `flake8 --config=.flake8 .`,like failing early due try running black apply automatic fixing listed output flake,issue,negative,negative,neutral,neutral,negative,negative
633559745,closing this PR due to git mix up will open new [PR-3306 ](https://github.com/OpenMined/PySyft/pull/3606)with the required change only.,due git mix open new change,issue,negative,positive,neutral,neutral,positive,positive
633533411,"@rajathpatel23 The change to `pip-dep/requirements.txt` looks good! It seems like there's been a bit of a git mix-up though, because this PR changes hundreds of other files too. 😅 

Could you amend this commit to include only the requirements change or rebase this PR on the latest `master`? Thanks!",change good like bit git though could amend commit include change rebase latest master thanks,issue,positive,positive,positive,positive,positive,positive
633292813,"(Closing, but feel free to re-open if this doesn't address your issue.)",feel free address issue,issue,positive,positive,positive,positive,positive,positive
633292658,"I can replicate this behavior on `zsh`. This command is structured to be run as part of the automated test suite (where packages are built with a `venv`), so you'll need a slightly different format to run it locally. Try:
```
coverage run --omit=setup.py setup.py test
```",replicate behavior command structured run part test suite built need slightly different format run locally try coverage run test,issue,negative,neutral,neutral,neutral,neutral,neutral
633166282,"Yes - brain fart - my apologies. 

That being said - given that it's been a year and we have big changes on the horizon - I think I'd rather have a pip install which worked with the latest jupyter by default and we just tell Udacity folks to use a specific version.",yes brain said given year big horizon think rather pip install worked latest default tell use specific version,issue,negative,positive,positive,positive,positive,positive
633089742,I would like to take up this issue. Seems like a good way to get familiar with the code base :),would like take issue like good way get familiar code base,issue,positive,positive,neutral,neutral,positive,positive
633089563,"Hello, I think I can help with that in the next few days.",hello think help next day,issue,negative,neutral,neutral,neutral,neutral,neutral
633084398,"Looks good! The method is simple, but could you add a test or two to make sure it doesn't get removed in the future?",good method simple could add test two make sure get removed future,issue,positive,positive,positive,positive,positive,positive
633071288,"> **Note:**
> Some methods used to convert tensor types ( such as `private_tensor` and `fix_precision`) makes the new tensors unable to be searched by its tags (these tags aren't forwarded during the process).
> 
> Since the new tensor does not have the tags set up, it's not added to the list of searchable tensors, making them invisible to other workers.
> 
> https://github.com/OpenMined/PySyft/blob/eb0b87da9747e921643366491f5f8e0aa2cbc4ce/syft/generic/object_storage.py#L93-L99
> 
> **Proposed solution:**
> I just explicitly forward the tags during the object instantiation process.

This seems like a good workaround for now. We should capture this as an issue.",note used convert tensor new unable process since new tensor set added list searchable making invisible solution explicitly forward object process like good capture issue,issue,positive,positive,positive,positive,positive,positive
633068482,Currently making the first part building classic FL aggregation task where on MNIST data where data is unbalanced.,currently making first part building classic aggregation task data data unbalanced,issue,negative,positive,positive,positive,positive,positive
632989537,"**Note:**
Some methods used to convert tensor types ( such as `private_tensor`  and `fix_precision`) makes the new tensors unable to be searched by its tags (these tags aren't forwarded during the process).

Since the new tensor does not have the tags set up, it's not added to the list of searchable  tensors, making them invisible to other workers.https://github.com/OpenMined/PySyft/blob/eb0b87da9747e921643366491f5f8e0aa2cbc4ce/syft/generic/object_storage.py#L93-L99

**Proposed solution:**
I just explicitly forward the tags during the object instantiation process.


",note used convert tensor new unable process since new tensor set added list searchable making invisible solution explicitly forward object process,issue,negative,negative,neutral,neutral,negative,negative
632865930,"Is this still being a problem? Since `register` does not get an ID manually anymore since #3588, the event above is a tricky one to reproduce.",still problem since register get id manually since event tricky one reproduce,issue,negative,neutral,neutral,neutral,neutral,neutral
632285634,It apparently may cause issues due to changing the order of imports and/or hook application. Waiting to see how the tests turn out.,apparently may cause due order hook application waiting see turn,issue,negative,negative,neutral,neutral,negative,negative
632130252,"It would also be great if this information included a ""want to join development? Apply to join the PyGrid team!"" and there's a link.",would also great information included want join development apply join team link,issue,positive,positive,positive,positive,positive,positive
632102473,"Sadly, this is a known issue that we don't currently have a way to fix. See previous discussions in #2201, #2527, #3163, #3382, and #3554.",sadly known issue currently way fix see previous,issue,negative,negative,negative,negative,negative,negative
632095146,"Can you make sure it fails with an explicit message for common operations?
This would solve things like: https://github.com/OpenMined/PySyft/issues/3540
You can use decorator like `@crypto_provider_required` if it helps to factorize code (not 100% sure)",make sure explicit message common would solve like use decorator like factorize code sure,issue,positive,positive,positive,positive,positive,positive
632093788,May I suggest something like `me.peers[“another_node”]` to make explicit what’s happening? ,may suggest something like make explicit happening,issue,negative,neutral,neutral,neutral,neutral,neutral
632089352,"I'm sorry my title was misleading, the exception is only raised when operations that requires the crypto_provider are called, like multiplication.",sorry title misleading exception raised like multiplication,issue,negative,negative,negative,negative,negative,negative
632071108,"Hey! I had a thought about this: this should not raise an exception as long as the parties don't need to do mltiplcation or operations which require a crypto provider. 
So I would suggest: set the crypto_provide to None is it's not provided and raise an error if people try to do multiplications.

The idea behind is that for secure aggregatin we're just doing a mean so we don't need to have a crypto provider",hey thought raise exception long need require provider would suggest set none provided raise error people try idea behind secure mean need provider,issue,positive,negative,neutral,neutral,negative,negative
631866632,"If `disconnect` involves sending messages, the proposed solution with `__del__` may be problematic. The Pythonic way to do this would be a `contextmanager`.

***ducks***",disconnect sending solution may problematic pythonic way would,issue,negative,neutral,neutral,neutral,neutral,neutral
631860599,"What do you mean “about master”? The `master` branch still has to maintain compatibility with the Udacity course, right?",mean master master branch still maintain compatibility course right,issue,negative,negative,neutral,neutral,negative,negative
631860253,"@mari-linhares This PR sat dormant/abandoned for a long time, but a lot of it is now in #3559 (which I just opened today.)",sat long time lot today,issue,negative,negative,neutral,neutral,negative,negative
631782379,"Not technically a duplicate - in the other issue we wont' change versions because we want to maintain compatibility with the build for the Udacity course.

However, this bug is about master instead (which I failed to specify)",technically duplicate issue wont change want maintain compatibility build course however bug master instead specify,issue,negative,neutral,neutral,neutral,neutral,neutral
631781985,"What is the reason it should be cast to a tuple? immutable? I tend to use sets whenever I need to use the `in` operator. like:

```
if user in allowed_users:
```",reason cast immutable tend use whenever need use operator like user,issue,negative,neutral,neutral,neutral,neutral,neutral
631738085,Should we use the README template from the .github repo? ie. [this one](https://github.com/OpenMined/.github/blob/master/README-TEMPLATE.md),use template ie one,issue,negative,neutral,neutral,neutral,neutral,neutral
631679830,I'll close this one as I think #3472 solved the issue,close one think issue,issue,negative,neutral,neutral,neutral,neutral,neutral
631606072,"The query has been resolved , therefore I am closing this issue.",query resolved therefore issue,issue,negative,neutral,neutral,neutral,neutral,neutral
631605780,"@karlhigley Thanks for your reply..

I tried ""ob.object_store._tensors"" but this is not working showing same error..

VirtualWorker' object has no attribute 'object_store

However, I reinstalled the complete Syft and other dependencies in a new Conda environment. It's working great.

",thanks reply tried working showing error object attribute however complete new environment working great,issue,positive,positive,positive,positive,positive,positive
631471772,@vtanwar-iitr I think this was broken by a recent change. Try `bob.object_store._tensors`? ,think broken recent change try,issue,negative,negative,negative,negative,negative,negative
631159655,"Stack overflow moment: Marked as duplicate. 
#3556 covers this one.",stack overflow moment marked duplicate one,issue,negative,positive,neutral,neutral,positive,positive
630833356,"For SyferText, we also need to keep the same 'id' in the new copy",also need keep new copy,issue,negative,positive,positive,positive,positive,positive
630820808,"This issue looks like more generic version of https://github.com/OpenMined/PySyft/issues/3509?

Note that #3509 was postponed because there's no clearance if Autograd tensor should be used for autograd tracing in Plans. Autograd tensor is only used together with FixedPrecision and AdditiveSharing tensors and at least wasn't intended for tracing.
",issue like generic version note clearance tensor used tracing tensor used together least intended tracing,issue,negative,negative,negative,negative,negative,negative
630706570,Does `==` work if you set `requires_grad = False` in the `share` method?,work set false share method,issue,negative,negative,negative,negative,negative,negative
630400966,"Thanks for replying @karlhigley 
Any or both solutions look great. You could also add the `jupyter<6` version requirement to the readme  Jupyter install or `tornado>5` to [pip-dep requirements](https://github.com/OpenMined/PySyft/blob/master/pip-dep/requirements.txt)

I saw that it's listed in [requirements_notebook.txt](https://github.com/OpenMined/PySyft/blob/master/pip-dep/requirements_notebooks.txt#L2) but you won't install those requirements if you follow the readme. Maybe installing with `python setup.py install` won't yield this bug but I was not able to do so due to an `access denied` error, which could be another issue by the way.",thanks look great could also add version requirement install tornado saw listed wo install follow maybe python install wo yield bug able due access error could another issue way,issue,positive,positive,positive,positive,positive,positive
630391392,"Alternately, maybe it would be cleaner to add the notebook requirements to the `udacity` extras in [`setup.py`](https://github.com/OpenMined/PySyft/blob/master/setup.py#L53)?",alternately maybe would cleaner add notebook,issue,negative,neutral,neutral,neutral,neutral,neutral
630388534,"Hmm, a compatible notebook version is listed in [`requirements_notebook.txt`](https://github.com/OpenMined/PySyft/blob/master/pip-dep/requirements_notebooks.txt#L2). Should it also be in `requirements_udacity.txt`?",compatible notebook version listed also,issue,negative,neutral,neutral,neutral,neutral,neutral
630190999,"> I also had this equality issue, even with a crypto provider, only when `requires_grad = False`
Can you try again with pulling the master?
It works now when provided with crypto provider. Maybe changed in @LaRiffle's  FSS PR.",also equality issue even provider false try master work provided provider maybe,issue,negative,negative,negative,negative,negative,negative
630180710,"> Thanks @sukhadj, I figured it was something like that. A few beginner questions:
> 
>     1. What is AST?
AdditiveSharingTensor
>     2. Why does `x + y` work without a crypto provider and not `x * y`?
So addition is just basically adding alice's share of x with alice's share of y and then module it. You can see implementation of addition [here](https://github.com/OpenMined/PySyft/blob/6b55ba01e411537e5c43f44235d24c33bdbaadf0/syft/frameworks/torch/tensors/interpreters/additive_shared.py#L413).
>     3. Can I read more about this in the documentation somewhere?
PySyft currently don't have extensive documentation right now. But you can find more about SPDZ and triplets [here](https://mortendahl.github.io/2017/09/03/the-spdz-protocol-part1/) (Not an expert of the subject so maybe others can suggest better resources maybe :smile: )
>     4. If `crypto_provider` is not always required for `.share()`, as an alternative to @karlhigley's suggestion, can the error message be more specific? e.g. `crypto_provider required for * operation on AdditiveSharingTensors` rather than an `ObjectNotFoundError`.
That's correct we should definitely raise a warning during the sharing and exception when multiplying rather than object not found error. 
",thanks figured something like beginner ast work without provider addition basically share share module see implementation addition read documentation somewhere currently extensive documentation right find expert subject maybe suggest better maybe smile always alternative suggestion error message specific operation rather correct definitely raise warning exception multiplying rather object found error,issue,positive,positive,positive,positive,positive,positive
630174409,"I also had this equality issue, even with a crypto provider, only when `requires_grad = False`",also equality issue even provider false,issue,negative,negative,negative,negative,negative,negative
630165959,"Thanks @sukhadj, I figured it was something like that. A few beginner questions:

1. What is AST?
2. Why does `x + y` work without a crypto provider and not `x * y`?
3. Can I read more about this in the documentation somewhere?
4. If `crypto_provider` is not always required for `.share()`, as an alternative to @karlhigley's suggestion, can the error message be more specific? e.g. `crypto_provider required for * operation on AdditiveSharingTensors` rather than an `ObjectNotFoundError`.",thanks figured something like beginner ast work without provider read documentation somewhere always alternative suggestion error message specific operation rather,issue,negative,positive,neutral,neutral,positive,positive
630154423,"It seems like `share()` is overly permissive then. Until recently (when @Prtfw added an exception), `share()` could be called with no arguments. Something similar should probably happen here: a required argument that's missing should immediately raise an exception rather than allowing incorrect behavior.",like share overly permissive recently added exception share could something similar probably happen argument missing immediately raise exception rather incorrect behavior,issue,negative,negative,neutral,neutral,negative,negative
630149716,"> Same problem for multiplication!
> 
> ```python
> import syft as sy
> import torch as th
> hook = sy.TorchHook(th)
> 
> bob = sy.VirtualWorker(hook, id=""bob"")
> alice = sy.VirtualWorker(hook, id=""alice"")
> 
> x = th.tensor([1,2,3,4])
> y = th.tensor([2,-1,1,0])
> x = x.share(bob, alice)
> y = y.share(bob, alice)
> 
> z = x * y  # <-- ObjectNotFoundError
> z.get()
> ```
> 
> Only addition (`x + y`) works without specifying a `crypto_provider`.

Hey, so AST uses secure multiparty communication (SMPC) to perform the operations like multiplication, division. It uses `crypto provider` to generate the triplets which are necessary to perform this operations. So crypto provider is kind of necessary 🙂",problem multiplication python import import torch th hook th bob hook bob hook bob bob addition work without hey ast secure communication perform like multiplication division provider generate necessary perform provider kind necessary,issue,negative,positive,positive,positive,positive,positive
630034818,"The tests are passing for the pointer tensor, but fail for the others :( -- need to look into that",passing pointer tensor fail need look,issue,negative,negative,negative,negative,negative,negative
629950705,"Same problem for multiplication!

```python
import syft as sy
import torch as th
hook = sy.TorchHook(th)

bob = sy.VirtualWorker(hook, id=""bob"")
alice = sy.VirtualWorker(hook, id=""alice"")

x = th.tensor([1,2,3,4])
y = th.tensor([2,-1,1,0])
x = x.share(bob, alice)
y = y.share(bob, alice)

z = x * y  # <-- ObjectNotFoundError
z.get()
```

Only addition (`x + y`) works without specifying a `crypto_provider`.",problem multiplication python import import torch th hook th bob hook bob hook bob bob addition work without,issue,negative,neutral,neutral,neutral,neutral,neutral
629938371,"Can you try to send a tensor then get it and see if you get a NaN? 
if not, can you try to regenerate the error with simpler code than that? I do not have the pickle file(s) so I can't really test if it works :)",try send tensor get see get nan try regenerate error simpler code pickle file ca really test work,issue,negative,positive,positive,positive,positive,positive
629847406,"It's because `ObjectStorage` is renamed to `ObjectStore` so that GridNode can't be launched
I've fixed this error in my branch and created a [PR](https://github.com/OpenMined/GridNode/pull/11) to GridNode",ca fixed error branch,issue,negative,positive,neutral,neutral,positive,positive
629812355,"try to create async function and use inside the await i think it will work
",try create function use inside await think work,issue,negative,neutral,neutral,neutral,neutral,neutral
629751031,"@karlhigley 
Hey bauss... so this PR is kind of shaping up... was wondering if we 100% need a new action type workerAction? 

I think the pro is that it's conceptually cleaner... but the potential con is more code to maintain... or maybe I am missing some key reason / other pros entirely... wanted to get your / Jason's thoughts 

Thanks 🙏 ",hey kind shaping wondering need new action type think pro conceptually cleaner potential con code maintain maybe missing key reason entirely get thanks,issue,positive,positive,positive,positive,positive,positive
629677774,"@thiessl , did you find the solution?. I have found (maybe) the same error. Could you paste the error from node_server? (not only the client)",find solution found maybe error could paste error client,issue,negative,neutral,neutral,neutral,neutral,neutral
629393213,@karlhigley Is any one working on this ? I can take this task for my outside GSoC contribution ,one working take task outside contribution,issue,negative,neutral,neutral,neutral,neutral,neutral
629340669,"@karlhigley hmm, sounds we have some work to do on our end if we would like to  support pysyft > 0.2.5 :D

",work end would like support,issue,positive,neutral,neutral,neutral,neutral,neutral
629215382,"@AlanAboudib One of the key differences between msgpack and Protobuf is that Protobuf requires message schemas, so while we may implement some version of that functionality that allows external libraries to register classes for serialization, using it will require some work on the library end that we can't automate or abstract away.",one key message may implement version functionality external register class serialization require work library end ca abstract away,issue,negative,neutral,neutral,neutral,neutral,neutral
629213717,"Current state is that everything that depends on `WebsocketWorker` is broken, for reasons I haven't been able to determine. They're pretty hard to debug. 🙁 ",current state everything broken able determine pretty hard,issue,negative,positive,neutral,neutral,positive,positive
629172572,"Hey @LaRiffle really sorry for the late reply. I haven't had the time to work on this lately, if someone else would like to take this up, then please go ahead.
I am sorry for holding onto this for so long.",hey really sorry late reply time work lately someone else would like take please go ahead sorry holding onto long,issue,negative,negative,negative,negative,negative,negative
629171413,"Seen this again, here:
```
2020-05-15T10:08:51.0720029Z =================================== FAILURES ===================================
2020-05-15T10:08:51.0721859Z ____________________ test_torch_tanh_approx[sigmoid-3-0.1] _____________________
2020-05-15T10:08:51.0722192Z 
2020-05-15T10:08:51.0722841Z method = 'sigmoid', prec_frac = 3, tolerance = 0.1
2020-05-15T10:08:51.0723543Z workers = {'alice': <VirtualWorker id:alice #objects:1>, 'bob': <VirtualWorker id:bob #objects:1>, 'charlie': <VirtualWorker id:charlie #objects:0>, 'james': <VirtualWorker id:james #objects:0>, ...}
2020-05-15T10:08:51.0723844Z 
2020-05-15T10:08:51.0724137Z     @pytest.mark.parametrize(
2020-05-15T10:08:51.0724423Z         ""method, prec_frac, tolerance"",
2020-05-15T10:08:51.0724702Z         [
2020-05-15T10:08:51.0724982Z             (""chebyshev"", 3, 3 / 100),
2020-05-15T10:08:51.0725298Z             (""chebyshev"", 4, 2 / 100),
2020-05-15T10:08:51.0725575Z             (""sigmoid"", 3, 10 / 100),
2020-05-15T10:08:51.0725839Z             (""sigmoid"", 4, 5 / 100),
2020-05-15T10:08:51.0726117Z         ],
2020-05-15T10:08:51.0726385Z     )
2020-05-15T10:08:51.0726666Z     def test_torch_tanh_approx(method, prec_frac, tolerance, workers):
2020-05-15T10:08:51.0726956Z         """"""
2020-05-15T10:08:51.0727241Z         Test the approximate tanh with different tolerance depending on
2020-05-15T10:08:51.0727539Z         the precision_fractional considered
2020-05-15T10:08:51.0727820Z         """"""
2020-05-15T10:08:51.0728136Z         alice, bob, james = workers[""alice""], workers[""bob""], workers[""james""]
2020-05-15T10:08:51.0728430Z     
2020-05-15T10:08:51.0728923Z         t = torch.tensor(range(-10, 10)) * 0.5
2020-05-15T10:08:51.0729246Z         t_sh = t.fix_precision(precision_fractional=prec_frac).share(alice, bob, crypto_provider=james)
2020-05-15T10:08:51.0729547Z         r_sh = t_sh.tanh(method)
2020-05-15T10:08:51.0729828Z         r = r_sh.get().float_prec()
2020-05-15T10:08:51.0730108Z         t = t.tanh()
2020-05-15T10:08:51.0730596Z         diff = (r - t).abs().max()
2020-05-15T10:08:51.0730890Z         norm = (r + t).abs().max() / 2
2020-05-15T10:08:51.0731163Z     
2020-05-15T10:08:51.0731433Z >       assert (diff / (tolerance * norm)) < 1
2020-05-15T10:08:51.0731714Z E       assert (tensor(0.1021) / (0.1 * tensor(1.0000))) < 1
2020-05-15T10:08:51.0731925Z 
```
[Link](https://pipelines.actions.githubusercontent.com/tPFNPqeRbvWdN0L3FU84cUvH4mGjAPQ3yYz8CFZWN08ePzUDwG/_apis/pipelines/1/runs/4726/signedlogcontent/4?urlExpires=2020-05-15T10%3A58%3A25.7158601Z&urlSigningMethod=HMACV1&urlSignature=LC4XWEEH8D9P7UbpZMTe1olEd4B3XTD2qrq7Frc81oU%3D)",seen sigmoid method tolerance id id bob id id method tolerance sigmoid sigmoid method tolerance test approximate tanh different tolerance depending considered bob bob range bob method norm assert tolerance norm assert tensor tensor link,issue,positive,negative,negative,negative,negative,negative
629119405,"@karlhigley that's good to know. However, if PySyft implements its own version of my function, I suppose I would just use it out of the box",good know however version function suppose would use box,issue,negative,positive,positive,positive,positive,positive
628971636,"I have seen this happen before, though it may not be consistent. I think the cause is `PointerTensors` or `ObjectPointers` going out of scope, having their `__del__` method called (which attempts to send a message to the owner of the referenced object), and having that collide with Python shut down activities. There's not likely to be a quick fix for this though, because our GC implementation fundamentally relies on Python's GC, which offers no guarantees for when or whether the `__del__` method will be executed.

Long term, the solution is probably to come up with a better way to do distributed GC.",seen happen though may consistent think cause going scope method send message owner object collide python shut likely quick fix though implementation fundamentally python whether method executed long term solution probably come better way distributed,issue,positive,positive,positive,positive,positive,positive
628953228,Heads up that this is nowhere near functional. This is just me sharing my first attempt to sort through the implications of transitioning to async/await-style worker code.,nowhere near functional first attempt sort worker code,issue,negative,positive,positive,positive,positive,positive
628882223,"@karlhigley not able to replicate the error, both in google colab and in local terminal.",able replicate error local terminal,issue,negative,positive,positive,positive,positive,positive
628841883,"@LaRiffle 
![image](https://user-images.githubusercontent.com/16415585/81976943-45e02680-95f7-11ea-948f-6d919d58ee7b.png)

If I am not mistaken now we are getting the size of the (empty) torch tensor, How does this happen differently when it comes to Size method only?
",image mistaken getting size empty torch tensor happen differently come size method,issue,negative,negative,neutral,neutral,negative,negative
628752294,"@AlanAboudib Worth mentioning that msgpack serialization will eventually be replaced by Protobuf, so something to be aware of that's on the horizon and getting closer.",worth serialization eventually something aware horizon getting closer,issue,negative,positive,positive,positive,positive,positive
628745694,"For your info @tudorcebere , here is how I currently register SyferText objects to serde.

```
def register_to_serde(class_type: type):
    """"""Adds a class `class_type` to the `serde` module of PySyft.

    This is important to enable SyferText types to be sent to remote workers.

    Args:
        class_type (type): The class to register to PySyfts' serde module.
            This enables serde to serialize and deserialize objects of that class.

    Returns:
        (int): The proto ID it is registered with
    """"""

    # Get the maximum integer index of detailers and add 1 to it
    # to create a new index that does not exist yet
    proto_id = max(list(serde.detailers.keys())) + 1

    # Add the simplifier
    serde.detailers[proto_id] = class_type.detail

    # Add the simplifier
    serde.simplifiers[class_type] = (proto_id, class_type.simplify)

    return proto_id


```",currently register type class module important enable sent remote type class register module serialize class proto id registered get maximum integer index add create new index exist yet list add simplifier add simplifier return,issue,negative,positive,positive,positive,positive,positive
628494065,Closing this and opening another one since I missed one conflict :(,opening another one since one conflict,issue,negative,neutral,neutral,neutral,neutral,neutral
628317807,"This is the list of non-native classes that msgpack can serialize that don't yet have Protobuf schemas:

- [ ] AutogradTensor
- [x] BaseDataset
- [x] dtype
- [x] FixedPrecisionTensor
- [x] ForceObjectDeleteMessage
- [ ] GetNotPermittedError
- [x] GetShapeMessage
- [ ] GradFunc
- [x] IsNoneMessage
- [ ] LoggingTensor
- [x] memory_format
- [ ] MultiPointerTensor
- [x] ObjectPointer
- [x] ObjectRequestMessage
- [ ] ObjectWrapper
- [ ] PaillierTensor
- [ ] PlanCommandMessage
- [x] PointerDataset
- [x] PointerPlan
- [ ] PrivateTensor
- [ ] ResponseSignatureError
- [x] SearchMessage
- [x] String
- [ ] VirtualWorker
- [x] WorkerCommandMessage

Not needed:
- ~~TrainConfig~~ (being removed)",list class serialize yet string removed,issue,negative,neutral,neutral,neutral,neutral,neutral
628306964,"(This is sort of an ""accept my bad solution or propose a better one"" PR.)",sort accept bad solution propose better one,issue,positive,negative,neutral,neutral,negative,negative
628306294," Yeah, they absolutely are needed to use FSS protocols, but stuffing those `Plans` into the object store of every single worker during `__init__()` is not a great way to go about that!

I'm perfectly happy for this to get fixed a better way, but I'm not inclined to write a better fix myself right now, both because I'm not knowledgeable about how FSS works and because this is a fix for an outstanding issue assigned to another team. 🙁 ",yeah absolutely use stuffing object store every single worker great way go perfectly happy get fixed better way write better fix right knowledgeable work fix outstanding issue assigned another team,issue,positive,positive,positive,positive,positive,positive
628274607,"@LaRiffle can confirm, but I think these will be needed on workers when you want to do some MPC stuff using the FSS protocol",confirm think want stuff protocol,issue,negative,neutral,neutral,neutral,neutral,neutral
628273013,"I can't tell whether the method is intended to be used for testing or regular usage. If it's needed for regular usage, I'd personally rather keep that usage awkward so that there's a reason to figure out a better way to do this. I won't stand in the way of adding a method to the workers though.",ca tell whether method intended used testing regular usage regular usage personally rather keep usage awkward reason figure better way wo stand way method though,issue,negative,negative,neutral,neutral,negative,negative
628197546,"> I haven't figured out a good way to run the time-based tests. The efficiency tests are skipped during the builds, and maybe this one should be too?

I think this is a good idea! Will edit the issue and also marking it ```Good first issue```",figured good way run efficiency maybe one think good idea edit issue also marking good first issue,issue,positive,positive,positive,positive,positive,positive
628172640,"I mean, I'm not sure that I _want_ to, but it would be fine for now as an incremental step. 😄 ",mean sure would fine incremental step,issue,negative,positive,positive,positive,positive,positive
628170436,"Oh, you want to write `a, b, c = role.load_state()`?
Yeah, it's definitely possible!",oh want write yeah definitely possible,issue,positive,neutral,neutral,neutral,neutral,neutral
628166187,Sounds okay to me! Do we even need tags yet though? 🤷 ,even need yet though,issue,negative,neutral,neutral,neutral,neutral,neutral
628162622,"> > You mean replacing `state.read()` or `role.load()`?
> 
> I was thinking we'd end up with `role.load()` loading from an `ObjectStore` and `role.load_state()` loading from `State`. Not sure if that makes any sense, but it might?

It might! But I still don't know how these 2 are related...
The wires behind the `role.load()` aren't connected yet. I can implement a first `load_state` though, searching by tags, what do you think?",mean thinking end loading loading state sure sense might might still know related behind connected yet implement first though searching think,issue,negative,positive,neutral,neutral,positive,positive
628160768,"> You mean replacing `state.read()` or `role.load()`?

I was thinking we'd end up with `role.load()` loading from an `ObjectStore` and `role.load_state()` loading from `State`. Not sure if that makes any sense, but it might?
",mean thinking end loading loading state sure sense might,issue,negative,positive,neutral,neutral,positive,positive
628144040,"> I suppose we could call the method that reads from `State` objects something like `load_state()`. 🤔

You mean replacing `state.read()` or `role.load()`?",suppose could call method state something like mean,issue,negative,negative,negative,negative,negative,negative
628118808,"> As a suggestion: we may need a function to check if a worker supports a specific framework

Ahh...will add this :)",suggestion may need function check worker specific framework add,issue,negative,neutral,neutral,neutral,neutral,neutral
628068880,"Hello!
I would like to work on this.",hello would like work,issue,negative,neutral,neutral,neutral,neutral,neutral
627970706,"This is related to #3510. If you look at [the bottom of `paillier.py`](https://github.com/OpenMined/PySyft/blob/master/syft/frameworks/torch/tensors/interpreters/paillier.py#L258-L295), there are two methods `simplify` and `detail`, which convert a `PaillierTensor` to Python primitives like `list`, `dict`, `int`, `str`, etc to prepare it for serialization with msgpack. The methods already exist but they don't have a corresponding test to verify that they actually work. There's a [stub for a test](https://github.com/OpenMined/PySyft/blob/368630afaba985ee9c26cc0aadd1c56c42bb38a6/test/serde/serde_helpers.py#L2012-L2032), but it still needs to be filled in.",related look bottom two simplify detail convert python like list prepare serialization already exist corresponding test verify actually work stub test still need filled,issue,negative,positive,positive,positive,positive,positive
627952626,I suppose we could call the method that reads from `State` objects something like `load_state()`. 🤔 ,suppose could call method state something like,issue,negative,neutral,neutral,neutral,neutral,neutral
627795080,"Hey, I guess it gets resolved in #3472 .
Can you check?",hey guess resolved check,issue,negative,neutral,neutral,neutral,neutral,neutral
627753735,"I created a function myself to serialize a Paillier Tensor into a  json/string :D
I would love to contribute to the serde section of PySyft with this function but I am do not understand 100% all the functions and where would this function fit. Nevertheless, here is the code I wrote (if I can help in anything please let me know, it would be a honor to contribute.

```python
from syft.frameworks.torch.tensors.interpreters.paillier import PaillierTensor
from phe.paillier import EncryptedNumber, PaillierPublicKey
import numpy as np
import syft as sy
import torch
import json
hook = sy.TorchHook(torch)

def serialize_paillier(tensor):
  if (isinstance(tensor.child, PaillierTensor)):
    struct = {}
    first_element = tensor.child.child[0]
    if (isinstance(first_element,np.ndarray)):
      values = []
      struct['public_key'] = {'g': first_element[0].public_key.g, 'n': first_element[0].public_key.n}
      for subtensor in tensor.child.child:
        row = [(str(subtensor[i].ciphertext()), str(subtensor[i].exponent)) for i in range(len(subtensor))]
        values.append(row)
      struct['values'] = values
    else:
      struct['public_key'] = {'g': first_element.public_key.g, 'n': first_element.public_key.n}
      struct['values'] = [(str(tensor[i].ciphertext()), str(tensor[i].exponent)) for i in range(len(tensor))]
    return json.dumps(struct)
  else:
    raise TypeError(type(tensor))

def deserialize_paillier(obj):
  if (isinstance(obj,str)):
    struct = json.loads(obj)
    tensor = PaillierTensor()
    public_key = struct['public_key']
    pub = PaillierPublicKey(n=int(public_key['n']))
    if (isinstance(struct['values'][0][0], list)):    
      values = [ [EncryptedNumber(pub, int(x[0]), int(x[1])) for x in y] for y in struct['values'] ]
    else:
      values = [EncryptedNumber(pub, int(x[0]), int(x[1])) for x in struct['values']]
    tensor.child = np.array(values)
    syft_tensor = tensor.wrap()
    return syft_tensor
  else:
    raise TypeError(type(obj))

# The next lines are to test the functions
# Array declaration
array1 = np.array([1,4]) # 1 dimension array
array2 = np.array([[5,2,3],[1,4,4],[2,4,4],[2,4,4]]) # 3 or n dimension array

# Declaring a tensor
x_tensor1 = torch.Tensor(array1)
x_tensor2 = torch.Tensor(array2)

# Encrypting the tensor
pub, pri = sy.keygen()
x_encrypted1 = x_tensor1.encrypt(protocol=""paillier"", public_key=pub)
x_encrypted2 = x_tensor2.encrypt(protocol=""paillier"", public_key=pub)

# Serialization process
obj1 = serialize_paillier(x_encrypted1)
obj2 = serialize_paillier(x_encrypted2)

# Deserialization process
tensor1 = deserialize_paillier(obj1)
tensor2 = deserialize_paillier(obj2)

# Decrypting the tensor
x_decrypted1 = tensor1.decrypt(protocol=""paillier"", private_key=pri)
x_decrypted2 = tensor2.decrypt(protocol=""paillier"", private_key=pri)
``` ",function serialize tensor would love contribute section function understand would function fit nevertheless code wrote help anything please let know would honor contribute python import import import import import torch import hook torch tensor row range row else tensor tensor range tensor return else raise type tensor tensor pub list pub else pub return else raise type next test array declaration array dimension array array dimension array tensor array array tensor pub serialization process process tensor tensor tensor,issue,positive,positive,positive,positive,positive,positive
627245362,"Oh, just found a few duplicate bugs:

- #2070 
- #3349 

Looks like this is fixed by using the new PySyft optim wrapper. ",oh found duplicate like fixed new wrapper,issue,negative,positive,positive,positive,positive,positive
626827203,"I haven't figured out a good way to run the time-based tests. The efficiency tests are skipped during the builds, and maybe this one should be too?
",figured good way run efficiency maybe one,issue,positive,positive,positive,positive,positive,positive
626397762,"@LaRiffle  it should pass all tests as soon as @Syzygianinfern0 merges #3479 
@Syzygianinfern0 the new max and argmax cause memory leaks, check them out if you can :)",pas soon new cause memory check,issue,negative,positive,positive,positive,positive,positive
626368007,"@NiWaRe - I can confirm this works. i can now federate the adam optimizer. the example in the tutorial 2 using `from syft.federated.floptimizer import Optims` is accurate. 

thanks @rimijoker + @iamtrask! ",confirm work federate example tutorial import accurate thanks,issue,negative,positive,positive,positive,positive,positive
626366586,"hey @NiWaRe - i looked through the issues and PRs. I think this might resolve it for us 

https://github.com/OpenMined/PySyft/pull/3179/files

there's now an example in https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/Part%2002%20-%20Intro%20to%20Federated%20Learning.ipynb ",hey think might resolve u example,issue,negative,neutral,neutral,neutral,neutral,neutral
626365855,"also would like to know the answer to this one. some previous issues suggest fl.optimizer module might have resolved this, but it's unclear to me how to use that? ",also would like know answer one previous suggest module might resolved unclear use,issue,negative,negative,negative,negative,negative,negative
626338072,"@Jasopaum A few of the serialization tests need updates, but go ahead and merge it once the tests pass. 😄 ",serialization need go ahead merge pas,issue,negative,neutral,neutral,neutral,neutral,neutral
626336086,"Thanks, @shubham3121! Looks like there are a few test failures related to the `FederatedClient`, but otherwise looks good.",thanks like test related otherwise good,issue,positive,positive,positive,positive,positive,positive
626276156,"> I guess this is a duplicate with #3472 :/

Ohh!! I should have checked the open PRs and issues. :sweat_smile: 
That PR solves this issue hence closing!! ",guess duplicate checked open issue hence,issue,negative,neutral,neutral,neutral,neutral,neutral
626246842,"Hello,
I have a class that inherits the Dataset class, but I can't apply the .federate() method on an instance of this class. Can someone explain why?
Thank you.

class UCI_HAR(Dataset):
    def __init__(self, samples, labels):
        self.samples = samples
        self.labels = labels
        
    def __getitem__(self, index):
        sample, target = self.samples[index], self.labels[index]
        return sample, target

    def __len__(self):
        return len(self.samples)

 ",hello class class ca apply method instance class someone explain thank class self self index sample target index index return sample target self return,issue,negative,neutral,neutral,neutral,neutral,neutral
626246115,"> Can we also use that with MPC now?

Don't know, will address this in another PR soon anyway :)",also use know address another soon anyway,issue,negative,neutral,neutral,neutral,neutral,neutral
626244554,"I tried modifying the ```python self.child.grad``` in a forked repo but then the next error message is:
```bash
\lib\site-packages\msgpack\__init__.py"", line 35, in packb
    return Packer(**kwargs).pack(o)
  File ""msgpack\_packer.pyx"", line 286, in msgpack._cmsgpack.Packer.pack
  File ""msgpack\_packer.pyx"", line 292, in msgpack._cmsgpack.Packer.pack
  File ""msgpack\_packer.pyx"", line 289, in msgpack._cmsgpack.Packer.pack
  File ""msgpack\_packer.pyx"", line 258, in msgpack._cmsgpack.Packer._pack
  File ""msgpack\_packer.pyx"", line 258, in msgpack._cmsgpack.Packer._pack
  File ""msgpack\_packer.pyx"", line 283, in msgpack._cmsgpack.Packer._pack
TypeError: can not serialize 'PaillierTensor' object
```
It looks like the external library [msgpack](https://msgpack-python.readthedocs.io/en/latest/api.html#msgpack.Packer) is having problems when transforming the 'PaillierTensor' object into binary code. 

Does anybody knows any other way to serializer a PaillierTensor? I think that the send function from Workers does serialize this kind of tensors ",tried python forked next error message bash line return packer file line file line file line file line file line file line serialize object like external library transforming object binary code anybody way think send function serialize kind,issue,negative,positive,positive,positive,positive,positive
626195136,"At this point, the serialization seems to be working, but there's an issue with an in-place `detach_` in one of the Udacity tests, which I don't fully understand yet. That's the last piece remaining to make this PR potentially mergeable.",point serialization working issue one fully understand yet last piece make potentially,issue,negative,neutral,neutral,neutral,neutral,neutral
625771829,Interested in the project. The approach is novel. 😊,interested project approach novel,issue,positive,positive,positive,positive,positive,positive
625661200,"> I will look on this

Great! I've assigned it to you. Feel free to ping me if you feel you are caught up in any stage :smile: :+1: ",look great assigned feel free ping feel caught stage smile,issue,positive,positive,positive,positive,positive,positive
625369274,"Hmm, I guess it does. This test:
```python
def test_exceptions_in_stack_trace():

    @sy.func2plan(args_shape=[(4,)])
    def generate_exception(tensor, torch=th):
        return torch.split(tensor)

    split_tensors = generate_exception(th.ones([4]))

    assert len(split_tensors) == 4
```
gives this stack trace, which is so long my eyes glazed over and I tried to follow the advice at the bottom, which is not super-helpful in this case:
```
________________________________________________________________ test_exceptions_in_stack_trace ________________________________________________________________

cls = <class 'syft.frameworks.torch.tensors.interpreters.native.TorchTensor'>
command = ('torch.split', None, (tensor([0., 0., 0., 0.], requires_grad=True),), {})

    @classmethod
    def handle_func_command(cls, command):
        """"""
        Operates as a router for functions. A function call always starts
        by being handled here and 3 scenarii must be considered:

        Real Torch tensor:
            The arguments of the function are real tensors so we should
            run the native torch command

        Torch wrapper:
            The arguments are just wrappers at the top of a chain
            (ex: wrapper>LoggingTensor>Torch tensor), so just forward
            the instruction to the next layer type in the chain (in
            the example above to LoggingTensor.handle_func_command),
            get the response and replace a wrapper on top of all tensors
            found in the response.

        Syft Tensor:
            The arguments are syft tensors of same type: this can happen
            if at any node of the chain where some function is forwarded,
            the handle_func_command modify the function and make a new
            call but keeps the arguments ""un-wrapped"". Making a new call
            means that by default the command is treated here in the
            global router.

        :param command: instruction of a function command: (command name,
        <no self>, arguments[, kwargs_])
        :return: the response of the function command
        """"""
        cmd, _, args_, kwargs_ = command

        try:  # will work if tensors are wrappers

            # Replace all torch tensor with their child attribute
            # Note that we return also args_type which helps handling case 3 in the docstring
            new_args, new_kwargs, new_type, args_type = hook_args.unwrap_args_from_function(
>               cmd, args_, kwargs_, return_args_type=True
            )

syft/frameworks/torch/tensors/interpreters/native.py:328:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

attr = 'torch.split', args_ = (tensor([0., 0., 0., 0.], requires_grad=True),), kwargs_ = {}, return_args_type = True

    def unwrap_args_from_function(attr, args_, kwargs_, return_args_type=False):
        """"""See unwrap_args_from_method for details

        Args:
            attr (str): the name of the function being called
            args_ (list): the arguments being passed to the function
            kwargs_ (dict): the keyword arguments being passed to the function
                (these are not hooked ie replace with their .child attr)
            return_args_type (bool): return the type of the tensors in the
            original arguments

        Returns:
            - the arguments where all tensors are replaced with their child
            - the type of this new child
            (- the type of the tensors in the arguments)
        """"""
        try:
            assert attr not in ambiguous_functions
            # Load the utility function to transform the args
            # TODO rename registry or use another one than for methods
            hook_args = hook_method_args_functions[attr]
            get_tensor_type_function = get_tensor_type_functions[attr]

            # Try running it
            new_args = hook_args(args_)

        except (IndexError, KeyError, AssertionError):  # Update the function in case of an error
            args_hook_function, get_tensor_type_function = build_unwrap_args_from_function(
                args_, return_tuple=True
            )
            # Store the utility functions in registries
            hook_method_args_functions[attr] = args_hook_function
            get_tensor_type_functions[attr] = get_tensor_type_function
            # Run it
>           new_args = args_hook_function(args_)

syft/generic/frameworks/hook/hook_args.py:168:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

x = (tensor([0., 0., 0., 0.], requires_grad=True),)

>   return lambda x: f(lambdas, x)

syft/generic/frameworks/hook/hook_args.py:357:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

lambdas = [<function build_unwrap_args_with_rules.<locals>.<listcomp>.<lambda> at 0x120bf1710>], args_ = (tensor([0., 0., 0., 0.], requires_grad=True),)

    def tuple_one_fold(lambdas, args_):
>       return (lambdas[0](args_[0], **kwargs),)

syft/generic/frameworks/hook/hook_args.py:524:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

i = tensor([0., 0., 0., 0.], requires_grad=True)

>       else lambda i: forward_func[type(i)](i)
        for a, r in zip(args_, rules)  # And do this for all the args / rules provided
    ]

syft/generic/frameworks/hook/hook_args.py:332:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

i = tensor([0., 0., 0., 0.], requires_grad=True)

        torch.Tensor: lambda i: i.child
        if hasattr(i, ""child"")
>       else (_ for _ in ()).throw(PureFrameworkTensorFoundError),
        torch.nn.Parameter: lambda i: i.child
        if hasattr(i, ""child"")
        else (_ for _ in ()).throw(PureFrameworkTensorFoundError),
        AutogradTensor: get_child,
        LoggingTensor: get_child,
        PaillierTensor: get_child,
    }

syft/frameworks/torch/hook/hook_args.py:30:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

.0 = <tuple_iterator object at 0x120bf6b90>

>       else (_ for _ in ()).throw(PureFrameworkTensorFoundError),
        torch.nn.Parameter: lambda i: i.child
        if hasattr(i, ""child"")
        else (_ for _ in ()).throw(PureFrameworkTensorFoundError),
        AutogradTensor: get_child,
        LoggingTensor: get_child,
        PaillierTensor: get_child,
    }
E   syft.exceptions.PureFrameworkTensorFoundError

syft/frameworks/torch/hook/hook_args.py:30: PureFrameworkTensorFoundError

During handling of the above exception, another exception occurred:

self = <syft.execution.plan.func2plan object at 0x120bf6290>
plan_function = <function test_exceptions_in_stack_trace.<locals>.generate_exception at 0x120bf13b0>

    def __call__(self, plan_function):
        plan = Plan(
            name=plan_function.__name__,
            include_state=self.include_state,
            forward_func=plan_function,
            state_tensors=self.state_tensors,
            id=sy.ID_PROVIDER.pop(),
            owner=sy.local_worker,
        )

        # Build the plan automatically
        if self.args_shape:
            args_ = PlaceHolder.create_placeholders(self.args_shape)
            try:
>               plan.build(*args_, trace_autograd=self.trace_autograd)

syft/execution/plan.py:64:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <Plan generate_exception id:40228035406 owner:me>
, trace_autograd = False
args = (PlaceHolder[Id:93047375826]>tensor([0., 0., 0., 0.], requires_grad=True),)
args_placeholders = (PlaceHolder[Id:93047375826]>tensor([0., 0., 0., 0.], requires_grad=True),)
wrapped_torch = <syft.execution.tracing.FrameworkWrapper object at 0x120bf6790>

    def build(self, *args, trace_autograd=False):
        """"""Builds the plan.

        First, run the function to be converted in a plan in a context which
        activates the tracing and record the actions in trace.logs

        Second, store the result ids temporarily to helper ordering the output
        placeholders at return time

        Third, loop through the trace logs and replace the tensors found in the
        actions logged by PlaceHolders. Record those actions in
        plan.actions

        Args:
            args: Input arguments to run the plan
        """"""

        # Enable tracing
        self.toggle_tracing(True)
        self.is_building = True

        if trace_autograd:
            # Wrap arguments that require gradients with AutogradTensor,
            # to be able to trace autograd operations
            args = tuple(
                AutogradTensor().on(arg, wrap=False)
                if isinstance(arg, FrameworkTensor) and arg.requires_grad
                else arg
                for arg in args
            )
            # Add Placeholder after AutogradTensor in the chain
            # so that all operations that happen inside AutogradTensor are recorded by Placeholder
            args_placeholders = tuple(
                PlaceHolder.insert(
                    arg, AutogradTensor, owner=sy.local_worker, role=self.role, tracing=True
                )
                for arg in args
            )
        else:
            # Add Placeholder on top of each arg
            args = args_placeholders = tuple(
                PlaceHolder.create_from(arg, owner=sy.local_worker, role=self.role, tracing=True)
                for arg in args
            )

        # Add state to args if needed
        if self.include_state:
            args += (self.state,)

        with trace(framework_packages[""torch""], self.role, self.owner) as wrapped_torch:
            # Look for framework kwargs
            framework_kwargs = {}
            forward_args = inspect.getfullargspec(self.forward).args
            if ""torch"" in forward_args:
                framework_kwargs[""torch""] = wrapped_torch

>           results = self.forward(*args, **framework_kwargs)

syft/execution/plan.py:221:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

tensor = PlaceHolder[Id:93047375826]>tensor([0., 0., 0., 0.], requires_grad=True), torch = <syft.execution.tracing.FrameworkWrapper object at 0x120bf6790>

    @sy.func2plan(args_shape=[(4,)])
    def generate_exception(tensor, torch=th):
>       return torch.split(tensor)

test/execution/test_plan.py:680:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

args = (PlaceHolder[Id:93047375826]>tensor([0., 0., 0., 0.], requires_grad=True),), kwargs = {}, cmd_name = 'torch.split'
command = ('torch.split', None, (PlaceHolder[Id:93047375826]>tensor([0., 0., 0., 0.], requires_grad=True),), {})

    def trace_wrapper(*args, **kwargs):
        cmd_name = ""."".join((self.package.__name__, attr_name))
        command = (cmd_name, None, args, kwargs)

>       result = package_attr(*args, **kwargs)

syft/execution/tracing.py:30:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

args = (PlaceHolder[Id:93047375826]>tensor([0., 0., 0., 0.], requires_grad=True),), kwargs = {}, tensor_type = <class 'syft.execution.placeholder.PlaceHolder'>
command = ('torch.split', None, (PlaceHolder[Id:93047375826]>tensor([0., 0., 0., 0.], requires_grad=True),), {})
handle_func_command = <bound method PlaceHolder.handle_func_command of <class 'syft.execution.placeholder.PlaceHolder'>>

    @wraps(func)
    def overloaded_func(*args, **kwargs):
        """"""
        Operate the hooking
        """"""

        try:
            tensor_type = (
                type(args[0]) if not isinstance(args[0], (tuple, list)) else type(args[0][0])
            )
        except IndexError:
            tensor_type = syft.framework.Tensor

        command = (cmd_name, None, args, kwargs)

        try:
            handle_func_command = tensor_type.handle_func_command
        except AttributeError:
            handle_func_command = syft.framework.Tensor.handle_func_command

>       response = handle_func_command(command)

syft/generic/frameworks/hook/hook.py:593:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = <class 'syft.execution.placeholder.PlaceHolder'>
command = ('torch.split', None, (PlaceHolder[Id:93047375826]>tensor([0., 0., 0., 0.], requires_grad=True),), {})

    @classmethod
    def handle_func_command(cls, command):
        """""" Receive an instruction for a function to be applied on a Placeholder,
        Replace in the args with their child attribute, forward the command
        instruction to the handle_function_command of the type of the child attributes,
        get the response and wrap it in a Placeholder.
        We use this method to perform the tracing.

        Args:
            command: instruction of a function command: (command name,
                <no self>, arguments[, kwargs])

        Returns:
            the response of the function command
        """"""
        cmd, _, args, kwargs = command

        # Replace all PlaceHolders with their child attribute
        new_args, new_kwargs, new_type = hook_args.unwrap_args_from_function(cmd, args, kwargs)

        # build the new command
        new_command = (cmd, None, new_args, new_kwargs)

        # Send it to the appropriate class and get the response
>       response = new_type.handle_func_command(new_command)

syft/execution/placeholder.py:70:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = <class 'syft.frameworks.torch.tensors.interpreters.native.TorchTensor'>
command = ('torch.split', None, (tensor([0., 0., 0., 0.], requires_grad=True),), {})

    @classmethod
    def handle_func_command(cls, command):
        """"""
        Operates as a router for functions. A function call always starts
        by being handled here and 3 scenarii must be considered:

        Real Torch tensor:
            The arguments of the function are real tensors so we should
            run the native torch command

        Torch wrapper:
            The arguments are just wrappers at the top of a chain
            (ex: wrapper>LoggingTensor>Torch tensor), so just forward
            the instruction to the next layer type in the chain (in
            the example above to LoggingTensor.handle_func_command),
            get the response and replace a wrapper on top of all tensors
            found in the response.

        Syft Tensor:
            The arguments are syft tensors of same type: this can happen
            if at any node of the chain where some function is forwarded,
            the handle_func_command modify the function and make a new
            call but keeps the arguments ""un-wrapped"". Making a new call
            means that by default the command is treated here in the
            global router.

        :param command: instruction of a function command: (command name,
        <no self>, arguments[, kwargs_])
        :return: the response of the function command
        """"""
        cmd, _, args_, kwargs_ = command

        try:  # will work if tensors are wrappers

            # Replace all torch tensor with their child attribute
            # Note that we return also args_type which helps handling case 3 in the docstring
            new_args, new_kwargs, new_type, args_type = hook_args.unwrap_args_from_function(
                cmd, args_, kwargs_, return_args_type=True
            )
            # This handles case 3: it redirects the command to the appropriate class depending
            # of the syft type of the arguments and returns
            if args_type not in FrameworkTensor:
                return args_type.handle_func_command(command)
            # build the new command
            new_command = (cmd, None, new_args, new_kwargs)
            # Send it to the appropriate class and get the response
            try:
                response = new_type.handle_func_command(new_command)
            except RuntimeError:
                # Change the library path to avoid errors on layers like AvgPooling
                list_new_command = list(new_command)
                list_new_command[0] = cls._fix_torch_library(new_command[0])
                new_command = tuple(list_new_command)
                response = new_type.handle_func_command(new_command)

            # Put back the wrappers where needed
            response = hook_args.hook_response(cmd, response, wrap_type=args_type)
        except PureFrameworkTensorFoundError:  # means that it's not a wrapper but a pure tensor

            # Check that the function has not been overwritten
            try:
                # Try to get recursively the attributes in cmd = ""<attr1>.<attr2>.<attr3>...""
                command = cls.rgetattr(cls, cmd)
                return command(*args_, **kwargs_)
            except AttributeError:
                pass

            # Run the native function with the new args
            # Note the the cmd should already be checked upon reception by the worker
            # in the execute_command function
            try:
>               response = cls._get_response(cmd, args_, kwargs_)

syft/frameworks/torch/tensors/interpreters/native.py:362:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cmd = 'torch.split', args_ = (tensor([0., 0., 0., 0.], requires_grad=True),), kwargs_ = {}

    @staticmethod
    def _get_response(cmd, args_, kwargs_):
        """"""
            Return the evaluation of the cmd string parameter
        """"""
        command_method = TorchTensor._get_method(cmd)

        if isinstance(args_, tuple):
>           response = command_method(*args_, **kwargs_)
E           TypeError: split() missing 1 required positional argument: 'split_size_or_sections'

syft/frameworks/torch/tensors/interpreters/native.py:396: TypeError

During handling of the above exception, another exception occurred:

    def test_exceptions_in_stack_trace():

        @sy.func2plan(args_shape=[(4,)])
>       def generate_exception(tensor, torch=th):

test/execution/test_plan.py:679:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <syft.execution.plan.func2plan object at 0x120bf6290>
plan_function = <function test_exceptions_in_stack_trace.<locals>.generate_exception at 0x120bf13b0>

    def __call__(self, plan_function):
        plan = Plan(
            name=plan_function.__name__,
            include_state=self.include_state,
            forward_func=plan_function,
            state_tensors=self.state_tensors,
            id=sy.ID_PROVIDER.pop(),
            owner=sy.local_worker,
        )

        # Build the plan automatically
        if self.args_shape:
            args_ = PlaceHolder.create_placeholders(self.args_shape)
            try:
                plan.build(*args_, trace_autograd=self.trace_autograd)
            except TypeError as e:
                raise ValueError(
>                   ""Automatic build using @func2plan failed!\nCheck that:\n""
                    "" - you have provided the correct number of shapes in args_shape\n""
                    "" - you have no simple numbers like int or float as args. If you do ""
                    ""so, please consider using a tensor instead.""
                )
E               ValueError: Automatic build using @func2plan failed!
E               Check that:
E                - you have provided the correct number of shapes in args_shape
E                - you have no simple numbers like int or float as args. If you do so, please consider using a tensor instead.

syft/execution/plan.py:67: ValueError
=================================================================== short test summary info ====================================================================
FAILED test/execution/test_plan.py::test_exceptions_in_stack_trace - ValueError: Automatic build using @func2plan failed!
====================================================================== 1 failed in 1.03s =======================================================================
```",guess test python tensor return tensor assert stack trace long glazed tried follow advice bottom case class command none tensor command router function call always handled must considered real torch tensor function real run native torch command torch wrapper top chain ex wrapper torch tensor forward instruction next layer type chain example get response replace wrapper top found response tensor type happen node chain function modify function make new call making new call default command global router param command instruction function command command name self return response function command command try work replace torch tensor child attribute note return also handling case tensor true see name function list function function hooked ie replace bool return type original child type new child type try assert load utility function transform rename registry use another one try running except update function case error store utility run tensor return lambda function lambda tensor return tensor else lambda type zip provided tensor lambda child else lambda child else object else lambda child else handling exception another exception self object function self plan plan build plan automatically try self plan id owner false id tensor id tensor object build self plan first run function converted plan context tracing record second store result temporarily helper output return time third loop trace replace found logged record input run plan enable tracing true true wrap require able trace else add chain happen inside else add top add state trace torch look framework torch torch tensor id tensor torch object tensor return tensor id tensor command none id tensor command none result id tensor class command none id tensor bound method class operate try type list else type except command none try except response command class command none id tensor command receive instruction function applied replace child attribute forward command instruction type child get response wrap use method perform tracing command instruction function command command name self response function command command replace child attribute build new command none send appropriate class get response response class command none tensor command router function call always handled must considered real torch tensor function real run native torch command torch wrapper top chain ex wrapper torch tensor forward instruction next layer type chain example get response replace wrapper top found response tensor type happen node chain function modify function make new call making new call default command global router param command instruction function command command name self return response function command command try work replace torch tensor child attribute note return also handling case case command appropriate class depending type return command build new command none send appropriate class get response try response except change library path avoid like list response put back response response except wrapper pure tensor check function try try get command return command except pas run native function new note already checked upon reception worker function try response tensor return evaluation string parameter response split missing positional argument handling exception another exception tensor self object function self plan plan build plan automatically try except raise automatic build provided correct number simple like float please consider tensor instead automatic build check provided correct number simple like float please consider tensor instead short test summary automatic build,issue,positive,positive,positive,positive,positive,positive
625365312,"```
pip install -r pip-dep/requirements_notebook.txt
pip install jupyterlab
```
should also work.",pip install pip install also work,issue,negative,neutral,neutral,neutral,neutral,neutral
625350759,"PySyft doesn't yet support Python 3.8, so it could be related to that. Could you post the versions of PySyft and syft-proto running on each machine?",yet support python could related could post running machine,issue,negative,neutral,neutral,neutral,neutral,neutral
625276173,"Ah, thanks for the reference. In case someone else runs into the same problem (the Jupyter PyPi package is kind of confusingly versioned), I got this working in a venv with:

```
pip install 'syft[udacity]'
pip install notebook==5.7.8  # This installs normal jupyter as well
pip install jupyterlab  # Optional, currently working at 2.1.2
```

Didn't try `make notebook` since that seems more for doing development in the Syft repo than using it as a package. Thanks! ",ah thanks reference case someone else problem package kind confusingly got working pip install pip install normal well pip install optional currently working try make notebook since development package thanks,issue,positive,positive,positive,positive,positive,positive
625258348,"> This one can be merged -- the coverage is failing -- we need to add more tests :(

That's my fault, I should add full tests for the Jail functionality as soon as I get it to work with training a model.",one coverage failing need add fault add full jail functionality soon get work training model,issue,negative,positive,positive,positive,positive,positive
625251115,You can find a set of compatible versions in the [notebook requirements file](https://github.com/OpenMined/PySyft/blob/master/pip-dep/requirements_notebooks.txt). You can also use `make notebook` to set up an environment.,find set compatible notebook file also use make notebook set environment,issue,negative,neutral,neutral,neutral,neutral,neutral
625227442,This one can be merged -- the coverage is failing -- we need to add more tests :(,one coverage failing need add,issue,negative,neutral,neutral,neutral,neutral,neutral
625174418,"Checking this way it fails :\.
LE: There was a flaky test + currently it fails because of the coverage",way flaky test currently coverage,issue,negative,neutral,neutral,neutral,neutral,neutral
625153943,Doesn't the stack trace show the Exceptions that were raised before this one?,stack trace show raised one,issue,negative,neutral,neutral,neutral,neutral,neutral
624755770,"> @rimijoker could you move these changes to the `grid` package?

@hericlesme It's done.",could move grid package done,issue,negative,neutral,neutral,neutral,neutral,neutral
624753923,"> This is great! 💟
> I guess having a tutorial notebook that portrays the amount of speed increase we are looking at might prove to be really interesting. If we are planning to have such a notebook, I would like to work on that 😄

Thanks for the review!
Yes indeed, basically because you pay the price of setting a new connexion (~few ms ?), you should use it only for expensive remote computation. My use case was for FSS where I drop computation time from 1.7 to 0.95s, but I guess the ultimate demo showcase is learnable Plans + this, because a Plan execution is typically a bit long. Would love to work on this with you if you want 😃 ",great guess tutorial notebook amount speed increase looking might prove really interesting notebook would like work thanks review yes indeed basically pay price setting new connexion use expensive remote computation use case drop computation time guess ultimate showcase learnable plan execution typically bit long would love work want,issue,positive,positive,positive,positive,positive,positive
624735344,"> @rimijoker could you move these changes to the `grid` package?

Sure",could move grid package sure,issue,negative,positive,positive,positive,positive,positive
624733777,@rimijoker could you move these changes to the `grid` package?,could move grid package,issue,negative,neutral,neutral,neutral,neutral,neutral
624638392,"> I think we should put syft/frameworks/torch/hook/hook_crypten.py in syft/frameworks/crypten/hook/hook.py instead, @gmuraru ?

Yep, this sounds like a good idea :D",think put instead yep like good idea,issue,positive,positive,positive,positive,positive,positive
624434768,"Currently the issue seems to be with testing on the build machine.
https://dev.azure.com/conda-forge/feedstock-builds/_build/results?buildId=156069&view=logs&j=10bda42a-d420-5c28-a43f-bc4e66405e5c&t=bef775d0-a1a2-55a3-9721-17147029baf0

```
test:
  imports:
  # work on later
    - simplejson
    - simplejson.tests
```

If anyone knows what should replace the default template with please let me know.",currently issue testing build machine test work later anyone replace default template please let know,issue,negative,neutral,neutral,neutral,neutral,neutral
624240953,@tudorcebere This might be helpful for sorting out some of the worker issues you've been looking at.,might helpful worker looking,issue,negative,neutral,neutral,neutral,neutral,neutral
624240725,`Plan` no longer has multiple parents and `Promise` has been removed.,plan longer multiple promise removed,issue,negative,neutral,neutral,neutral,neutral,neutral
624219064,@mari-linhares I'd like to work on this if no one's looking at this already. Could you help me get started?,like work one looking already could help get,issue,positive,neutral,neutral,neutral,neutral,neutral
624213416,"> > I kinda wonder why `allowed_users` is a tuple instead of a list. There's nothing inherently fixed-length about `allowed_users` AFAICT.
> 
> I can change it to a list. The only difference is that tuples are immutable.

Changed it back to a tuple because I got errors in the ```hook``` saying that list is not hashable :\",wonder instead list nothing inherently change list difference immutable back got hook saying list,issue,negative,neutral,neutral,neutral,neutral,neutral
624051366,"Thank you for jumping into such a challenging project!

Unfortunately, this cannot be fixed until wrappers are removed. See @gmuraru 's progress on removing wrappers.",thank project unfortunately fixed removed see progress removing,issue,negative,positive,neutral,neutral,positive,positive
623876219,"I think this issue is already fixed in the following commit:
https://github.com/OpenMined/PySyft/commit/e4b5cab232910968036f8bac1d499b19356de41c

@karlhigley If you agree this issue could be closed",think issue already fixed following commit agree issue could closed,issue,positive,neutral,neutral,neutral,neutral,neutral
623560256,"> I kinda wonder why `allowed_users` is a tuple instead of a list. There's nothing inherently fixed-length about `allowed_users` AFAICT.

I can change it to a list. The only difference is that tuples are immutable.",wonder instead list nothing inherently change list difference immutable,issue,negative,neutral,neutral,neutral,neutral,neutral
623542082,"Thanks! I replicated flake's C901 warning in the master and verified that the warning goes away in this PR:

```dc@lap:~$ conda activate pysyft
dc@lap:~$ conda activate pysyft
(pysyft) dc@lap:~$ cd git-dev/PySyft/
(pysyft) dc@lap:~/git-dev/PySyft$ git checkout master
Already on 'master'
Your branch is up-to-date with 'origin/master'.
(pysyft) dc@lap:~/git-dev/PySyft$ flake8 ./syft/frameworks/torch/nn/rnn.py --select=C901
./syft/frameworks/torch/nn/rnn.py:205:5: C901 'RNNBase.forward' is too complex (12)
    def forward(self, x, h=None):
    ^
1     C901 'RNNBase.forward' is too complex (12)
1
(pysyft) dc@lap:~/git-dev/PySyft$ git checkout cleanup_torch_rnn
Switched to branch 'cleanup_torch_rnn'
Your branch is up-to-date with 'origin/cleanup_torch_rnn'.
(pysyft) dc@lap:~/git-dev/PySyft$ flake8 ./syft/frameworks/torch/nn/rnn.py --select=C901
0
(pysyft) dc@lap:~/git-dev/PySyft$ 
```",thanks replicated flake warning master warning go away lap activate lap activate lap lap git master already branch lap flake complex forward self complex lap git switched branch branch lap flake lap,issue,negative,negative,negative,negative,negative,negative
623526325,"https://del.dog/ylinebubin.txt
Stack trace of `pytest` on torch 1.5 for anyone working on it :+1: ",stack trace torch anyone working,issue,negative,neutral,neutral,neutral,neutral,neutral
623525033,"> How do I run flake?

https://flake8.pycqa.org/en/latest/index.html#quickstart
This might be pretty helpful for more than just running. This is the config we use https://github.com/OpenMined/PySyft/blob/master/.flake8

---
> FWIW, I can't find the string `C901` in the codebase either.

Thats the name of the warning

---
> ./syft/frameworks/torch/nn/rnn.py:205:5: C901 'RNNBase.forward' is too complex (12)

The `(12)` signifies the complexity level (thats what its called)",run flake might pretty helpful running use ca find string either thats name warning complex complexity level thats,issue,positive,negative,neutral,neutral,negative,negative
623512230,"> Have you tried running flake and checking if the warning persists?

How do I run flake? (please excuse my ignorance, I have never contributed to OpenMined before)

In case it helps, this is what I think I know so far. According to Contributing.md, it looks like flake is included as a pre-commit hook. I followed the instructions in Contributing.md to install these pre-commit hooks before I added and committed my changes. I saw some extra stuff happening when I committed (or maybe when I pushed - can't recall), so I presume that this was the pre-commit hooks running. I don't remember seeing any warnings when I did this.

FWIW, I can't find the string `C901` in the codebase either.",tried running flake warning run flake please excuse ignorance never case think know far according like flake included hook install added saw extra stuff happening maybe ca recall presume running remember seeing ca find string either,issue,negative,positive,neutral,neutral,positive,positive
623455793,I kinda wonder why `allowed_users` is a tuple instead of a list. There's nothing inherently fixed-length about `allowed_users` AFAICT.,wonder instead list nothing inherently,issue,negative,neutral,neutral,neutral,neutral,neutral
623444328,Closing since @Prtfw has made further progress on this PR on a different branch.,since made progress different branch,issue,negative,neutral,neutral,neutral,neutral,neutral
623337393,"> b=a.flatten()
> a.get()

After some discussion with @MaksymPetyak it's important to be noted that if anyone is working on this, **don't** use `a.get()` to decide if the pointer exists or not. It is easily misinterpretable that you have a solution if you've managed to make this work. This is since, if made into an inplace operation, it just creates `a` to be a duplicate of `b` and hence it pretends that the tensor exists :thinking: 

Use this instead
```python
import torch as th
import syft as sy

hook = sy.TorchHook(th)
alice = sy.VirtualWorker(hook, id=""alice"")
bob = sy.VirtualWorker(hook, id=""bob"")
crypto_provider = sy.VirtualWorker(hook, id=""james"")

torch = th
syft = sy

# a = torch.ones(1, 5)  # <<<Toggle between this (works as expected)
a = torch.rand(4)  # <<< and this (broken)
a = a.encrypt(workers=[alice, bob], crypto_provider=crypto_provider)

print(f""Before: {len(alice._tensors)}"")  # 1 (expected: 1)
b = a.flatten()
print(f""After: {len(alice._tensors)}"")  # 1 (expected: 2)
```",discussion important noted anyone working use decide pointer easily misinterpretable solution make work since made operation duplicate hence tensor thinking use instead python import torch th import hook th hook bob hook bob hook torch th toggle work broken bob print print,issue,negative,positive,positive,positive,positive,positive
623266618,"Check out this pull request on&nbsp; <a href=""https://app.reviewnb.com/OpenMined/PySyft/pull/3445""><img align=""absmiddle""  alt=""ReviewNB"" height=""28"" class=""BotMessageButtonImage"" src=""https://raw.githubusercontent.com/ReviewNB/support/master/images/button_reviewnb.png""/></a> 

 You'll be able to see Jupyter notebook diff and discuss changes. Powered by <a href='https://www.reviewnb.com'>ReviewNB</a>.",check pull request able see notebook discus powered,issue,negative,positive,positive,positive,positive,positive
623205062,"> This is weird, all tests pass on my machine and the failing one has nothing to do with the commit

It's a flaky test, don't worry about it. I re-ran the test suite hopefully it will pass this time.",weird pas machine failing one nothing commit flaky test worry test suite hopefully pas time,issue,negative,negative,negative,negative,negative,negative
623188405,"> Hey @nin-ed !
> We had a lot of changes recently! A few conflicts to solve and we're good to go :)

Done! Please check once.",hey lot recently solve good go done please check,issue,positive,positive,positive,positive,positive,positive
623171191,"Hey @MaksymPetyak , would you make a pull request with your changes?",hey would make pull request,issue,negative,neutral,neutral,neutral,neutral,neutral
623147994,"This is weird, all tests pass on my machine and the failing one has nothing to do with the commit",weird pas machine failing one nothing commit,issue,negative,negative,negative,negative,negative,negative
623143665,I'm not sure what caused this test to fail but I don't think it is connected to my changes (?),sure test fail think connected,issue,negative,neutral,neutral,neutral,neutral,neutral
623137575,"> The tests already exist [here](https://github.com/OpenMined/PySyft/blob/master/test/torch/nn/test_nn.py) smile

Ah, thanks for pointing this out :)",already exist smile ah thanks pointing,issue,positive,positive,positive,positive,positive,positive
623129126,It's failing test on a small change that is we need to pass field arg to decompose function now to decompose value into required n_bits,failing test small change need pas field decompose function decompose value,issue,negative,negative,negative,negative,negative,negative
623126826,"> operation ... is actually an inplace operation

The number of such edge cases that might be hidden for pretty much every method we have scares me now 
:open_mouth:",operation actually operation number edge might hidden pretty much every method,issue,positive,positive,neutral,neutral,positive,positive
623125760,"> I have not added tests. If you think I should add tests for this change, could you point me to an example of how I might do this?

The tests already exist [here](https://github.com/OpenMined/PySyft/blob/master/test/torch/nn/test_nn.py) :smile: ",added think add change could point example might already exist smile,issue,negative,positive,positive,positive,positive,positive
623125424,"> @Syzygianinfern0 is this related to your recent GC fixes?

Seems to be the case (confirmed from a `git bisect`). Although don't know if I can look into it right away. 

> .flatten operation on 1d array is actually an _inplace_ operation

@MaksymPetyak I had tried the same thing earlier today but that didn't seem to be solving the issue. Can you confirm if that is the only change required with a recent copy of the codebase. ",related recent case confirmed git bisect although know look right away operation array actually operation tried thing today seem issue confirm change recent copy,issue,negative,positive,positive,positive,positive,positive
623123596,"Hey, 
I had a look at this, and I think the issue is that in torch the .flatten operation on 1d array is actually an _inplace_ operation. You can do the above example with .view(-1) and it will work fine.
I have fixed the issue locally by modifying the is_inplace_method in torch_attributes.py
```
        try:
            return self.inplace_methods[method_name]
        except KeyError:
            is_inplace = True if re.search(self._inplace_pattern, method_name) else False
            is_inplace = True if method_name == ""flatten"" else is_inplace # This would fix problem with flatten
            self.inplace_methods[method_name] = is_inplace
            return is_inplace
```
But note that this would only work for 1d array.
Not entirely sure what would be a good fix to this, as I don't think we use the input shape in anyway to decide if the operation is inplace.",hey look think issue torch operation array actually operation example work fine fixed issue locally try return except true else false true flatten else would fix problem flatten return note would work array entirely sure would good fix think use input shape anyway decide operation,issue,positive,positive,positive,positive,positive,positive
623113781,"
Dropping `int16` and `int8` support (for the moment). 
For instance, creating a `int16` would set its field to be 2**16 but dtype to be `int`
> set self.dtype as long or int only 

This creates a problem during `serde` operations as **only the dtype is encoded and sent** and is hence when deserialized (from dtype of `int`) it gives a field of 2**32 :disappointed: 
",dropping support moment instance would set field set long problem sent hence field disappointed,issue,negative,negative,negative,negative,negative,negative
623111084,"> you can let user enter these new ones for initialisation but inside __init__ based on conditional set self.dtype as long or int only so that it works well with rest of the code without any changes.

Maybe the most reasonable for the moment",let user enter new inside based conditional set long work well rest code without maybe reasonable moment,issue,negative,positive,neutral,neutral,positive,positive
623109612,"Hey @nin-ed !
We had a lot of changes recently! A few conflicts to solve and we're good to go :)",hey lot recently solve good go,issue,positive,positive,positive,positive,positive,positive
623108949,"Hey @bicycleman15 !
I believe your PR is still open and needs tests if you'd like to add them :) ",hey believe still open need like add,issue,negative,neutral,neutral,neutral,neutral,neutral
623108626,"@Yugandhartripathi I guess your PR significantly helps for this issue, but the problems is still there.
I've put an example to reproduce in the description
",guess significantly issue still put example reproduce description,issue,negative,positive,positive,positive,positive,positive
623107709,"great, we're quite close then!
Can you run black to reformat/lint your code please? That's what is failing currently in the tests
```
pip install black
black .
```
https://github.com/psf/black
",great quite close run black code please failing currently pip install black black,issue,negative,positive,neutral,neutral,positive,positive
623106815,"> I like the idea of being able to enable/disable that functionality, but I think it would ideally be explicit, like an autograd=True kwarg or something.

Added `trace_autograd` kwarg to `func2plan` and `build` methods.",like idea able functionality think would ideally explicit like something added build,issue,positive,positive,positive,positive,positive,positive
623072531,"Same, don't change it, you won't get clarity by breaking it in many small functions I think.",change wo get clarity breaking many small think,issue,negative,positive,positive,positive,positive,positive
623072407,"Maybe don't change that function, @alhparsa is already working on it for some optimisation purpose, it will create merge conflicts! (And conv2d is complex by nature)",maybe change function already working purpose create merge complex nature,issue,negative,negative,negative,negative,negative,negative
623045686,"Hey, sure. Assigned the issue to you.",hey sure assigned issue,issue,negative,positive,positive,positive,positive,positive
623023298,Hi! I would like to contribute on this issue.,hi would like contribute issue,issue,negative,neutral,neutral,neutral,neutral,neutral
622992604,"Hey, is it okay if I start working on this one?",hey start working one,issue,negative,neutral,neutral,neutral,neutral,neutral
622222927,"> 
> 
> @Metrix1010 Fix those requested changes. Once fixed, I will be able to merge them.

Please let me know if this is correct. I used git rebase to update my local fork but I did not use the force command. I used merge, pull and push. ",fix fixed able merge please let know correct used git rebase update local fork use force command used merge pull push,issue,negative,positive,positive,positive,positive,positive
621898302,(Resolving conflicts with `master` might clear up some of the fixes for other issues that crept in here.),master might clear crept,issue,negative,positive,positive,positive,positive,positive
621775077,"Hey @knexator I guess from the CI that there was a bug in the conflict:
```
./syft/frameworks/torch/mpc/securenn.py:301:32: F821 undefined name 'bob'
    x_bit_sh_0 = x_bit_0.share(bob, alice, field=L, crypto_provider=crypto_provider, **no_wrap)
                               ^
./syft/frameworks/torch/mpc/securenn.py:301:37: F821 undefined name 'alice'
    x_bit_sh_0 = x_bit_0.share(bob, alice, field=L, crypto_provider=crypto_provider, **no_wrap)
                                    ^
2     F821 undefined name 'bob'
2
```
Would you mind having a look at this?",hey guess bug conflict undefined name bob undefined name bob undefined name would mind look,issue,negative,neutral,neutral,neutral,neutral,neutral
621698133,"HI @karlhigley,
Can you suggest any change from my side that will help to solve the issue? ",hi suggest change side help solve issue,issue,positive,neutral,neutral,neutral,neutral,neutral
621222511,Closing this since @gmuraru and @iamtrask are charting a path forward on this refactoring epic.,since charting path forward epic,issue,negative,positive,neutral,neutral,positive,positive
620978995,"> > @karlhigley Please help fix the error in checks
> 
> For the group - as a matter of Github etiquette - it is generally not an accepted practice to publicly request another developer to ""fix"" a PR they did not directly help build. Asking to consult is great - asking to comment or approve/disapprove is essential. However, unless @jabertuhin and Karl helped construct this PR together, it is @jabertuhin 's job to ""fix"" the PR, not Karl's.

I am sorry @karlhigley . Thank you @iamtrask  for pointing out my mistake, it will not happen again.",please help fix error group matter etiquette generally accepted practice publicly request another developer fix directly help build consult great comment essential however unless construct together job fix sorry thank pointing mistake happen,issue,positive,positive,neutral,neutral,positive,positive
620905744,"> It looks like an error in the format of the notebook. The test is having trouble parsing the JSON. Not sure where exactly the issue is in the big diff, but I'd check to make sure the notebook is valid JSON.

Karl - you're such a nice guy. Thank you for sharing your thoughts.",like error format notebook test trouble sure exactly issue big check make sure notebook valid nice guy thank,issue,positive,positive,positive,positive,positive,positive
620904943,"> @karlhigley Please help fix the error in checks

For the group - as a matter of Github etiquette - it is generally not an accepted practice to publicly request another developer to ""fix"" a PR they did not directly help build. Asking to consult is great - asking to comment or approve/disapprove is essential. However, unless @jabertuhin and Karl helped construct this PR together, it is @jabertuhin 's job to ""fix"" the PR, not Karl's.",please help fix error group matter etiquette generally accepted practice publicly request another developer fix directly help build consult great comment essential however unless construct together job fix,issue,positive,positive,positive,positive,positive,positive
620854460,"It looks like an error in the format of the notebook. The test is having trouble parsing the JSON. Not sure where exactly the issue is in the big diff, but I'd check to make sure the notebook is valid JSON.",like error format notebook test trouble sure exactly issue big check make sure notebook valid,issue,negative,positive,positive,positive,positive,positive
620774668,@karlhigley Please help fix the error in checks,please help fix error,issue,negative,neutral,neutral,neutral,neutral,neutral
620052744,"> I'm not sure we want to trace autograd for all input values with requires_grad.

When would we not want that?

>  Maybe this should be done by invoking Plan.build() explicitly with AutogradTensor arguments and not assume Plan will add them automatically?

I like the idea of being able to enable/disable that functionality, but I think it would ideally be explicit, like an `autograd=True` kwarg or something.",sure want trace input would want maybe done explicitly assume plan add automatically like idea able functionality think would ideally explicit like something,issue,positive,positive,positive,positive,positive,positive
620024649,@LaRiffle would you please review this quickly :),would please review quickly,issue,negative,positive,positive,positive,positive,positive
620023227,Nice work @IamRavikantSingh ! It would be great if you can sync with the OpenMined crypten branch so we get the tests running.,nice work would great sync branch get running,issue,positive,positive,positive,positive,positive,positive
620003208,"Got simple backward trace working!

I'm not sure we want to trace autograd for all input values with requires_grad. Maybe this should be done by invoking `Plan.build()` explicitly with AutogradTensor arguments and not assume Plan will add them automatically?
",got simple backward trace working sure want trace input maybe done explicitly assume plan add automatically,issue,negative,positive,positive,positive,positive,positive
619931438,"### Update: First draft of the ""Simple Version"" (see notes in notebook)
The following sub-components have been tested (quick test)
* **PATE-Setup:** Encrypted distribution of data on to ""hosting-groups"" (2 workers: the teacher and the student) The role of the model-owner is assumed for the local machine. (To be a neutral third party extra functionality is needed, see *Shortcomings* and introduction in notebook)
* **Encrypted-FL Student Training:** Tested with a VERY simple model (after first epoch 10% -> which is about right as it would equal guessing) Still takes *VERY LONG* and consumes *VERY MUCH RAM* (at times apparently over 12.21 GB, Google Colab had reiniate a session) time (no CUDA with SMPC possible)
* **Encrypted Label Prediction of each teacher:** Straight forward (also very slow)
* **Noisy Voting, DP-secured labeling of student, public dataset:** Passive Sec. Approach, trusted aggregator necessary (some kind of `.remote_share()` would need to be possible for that to work)
* **Student Model Training:** Very much faster. Performance not representative because no complete training was done and the complete notebook wasn't run in one go entirely (still running :D )

I got a couple of things to work and improve. The goal is to also use the use-case a experimental ground for production-near tests. <br>
*Any feedback (especially concerning the **general concept** and **how to speed up things**  ), ideas, help is welcome.* 👍 ",update first draft simple version see notebook following tested quick test distribution data teacher student role assumed local machine neutral third party extra functionality see introduction notebook student training tested simple model first epoch right would equal guessing still long much ram time apparently session time possible label prediction teacher straight forward also slow noisy voting student public passive sec approach aggregator necessary kind would need possible work student model training much faster performance representative complete training done complete notebook run one go entirely still running got couple work improve goal also use experimental ground feedback especially concerning general concept speed help welcome,issue,positive,positive,positive,positive,positive,positive
619585975,"> @Syzygianinfern0 did you check for any potential GC leaks?

Major leaks currently. But testing on codebase of #3403 they disappear :partying_face:... Related issues I guess :thinking: ",check potential major currently testing disappear related guess thinking,issue,negative,positive,neutral,neutral,positive,positive
619430571,"this error was there because due to whatsoever reason, in this python file, the interpreter was not able to load the path of the file  start_websocket_servers.py.

this cause of error got confirmed because of the realization that no matter what was the path value in this command FILE_PATH = Path(__file__).resolve().parents[4].joinpath(""run_websocket_server.py”)  in the start_websocket_servers.py file, there was no change in the error output. so the solution what i did was that i hardcoded the path of the file run_websocket_server.py in the command like this:  call_alice = [python,  ""run_websocket_server.py"", ""--port"", ""8777"", ""--id"", ""alice”]
instead of original 
[
FILE_PATH = Path(__file__).resolve().parents[4].joinpath(""run_websocket_server.py"")

call_alice = [python, FILE_PATH, ""--port"", ""8777"", ""--id"", ""alice""]
]

this solved the problem . 

",error due whatsoever reason python file interpreter able load path file cause error got confirmed realization matter path value command path file change error output solution path file command like python port id instead original path python port id problem,issue,negative,positive,positive,positive,positive,positive
619403316,"> Just a small question (not sure if it's the best place to ask) but what's the new status with hooks? Does `make_hook(globals)` looks at all the frameworks it can hook and TorchHook hooks only Torch?

Frankly, no idea :-)
`sy.hook()` (which was a shortcut for setting up TorchHook and creating sandbox) was renamed to `sy.make_hook()`, that's all I know.",small question sure best place ask new status hook torch frankly idea setting sandbox know,issue,positive,positive,positive,positive,positive,positive
619378731,"I would like to get rid of `Placeholder.owner`, but in order to do so we might have to make it not an `AbstractObject`, which I suspect would up-end our hook-based tracing. Leaving it for now, since all tensor objects have `owners` at the moment.",would like get rid order might make suspect would tracing leaving since tensor moment,issue,negative,neutral,neutral,neutral,neutral,neutral
619058207,"A `requires_grad` parameter could be good. 👍

I'm not entirely sure what changes when building a `Plan` with `requires_grad=True` either, but the PyTorch JIT stops complaining.",parameter could good entirely sure building plan either,issue,positive,positive,positive,positive,positive,positive
618802742,"hey man, thanks a lot. although I did this earlier. it showed

>  [ERROR: syft 0.2.4 has requirement syft-proto~=0.2.5.a1, but you'll have syft-proto 0.2.9a2 which is incompatible. ]
then I quit this step of upgrading syft-proto but after your answer, I did that anyway and the error got resolved.",hey man thanks lot although error requirement incompatible quit step answer anyway error got resolved,issue,negative,positive,positive,positive,positive,positive
618544623,"One possibility to allow internal access while disabling external access might be to use a ""private"" method, like:
```python
class Example:
    def __init__(self, dtype=""int""):
        if !(dtype == ""int"" or dtype == ""long""):
            raise
        self.dtype = dtype
	
    @staticmethod
    def _init_custom(*args, **kwargs):
        del kwargs['dtype']
        example = Example(*args, **kwargs)
        example.dtype = ""custom""
        return example
```",one possibility allow internal access external access might use private method like python class example self long raise example example custom return example,issue,positive,negative,neutral,neutral,negative,negative
618313465,"If only 2^32 and 2^64 are allowed and share_convert works on those (I should research why) then I guess the current version is easily extendable to N parties, I will fix the merge conflicts
",work research guess current version easily fix merge,issue,negative,positive,positive,positive,positive,positive
618288220,"> That sounds like a mismatch between PySyft and `syft-proto` versions. I'd try re-installing the PySyft requirements from `pip-dep/requirements.txt` and see if that resolves it.

I had the same problem. Re-installing the requirements solved it. Thank you. ",like mismatch try see problem thank,issue,negative,neutral,neutral,neutral,neutral,neutral
618280293,I was quite confuse I first thought you where instantiating the class and not an instance of it :D,quite confuse first thought class instance,issue,negative,positive,positive,positive,positive,positive
618279012,"Thanks for checking this! Indeed I guess this is being addressed currently by @Yugandhartripathi 
I let you discuss with him about share_convert, but his finding was that for fields like 2^32 and 64 which will be the only one accepted as of now to have faster runtime, this logic was not needed.",thanks indeed guess currently let discus finding like one accepted faster logic,issue,positive,positive,neutral,neutral,positive,positive
617771267,That sounds like a mismatch between PySyft and `syft-proto` versions. I'd try re-installing the PySyft requirements from `pip-dep/requirements.txt` and see if that resolves it.,like mismatch try see,issue,negative,neutral,neutral,neutral,neutral,neutral
617720184,"> #2982 has been merged! @knexator should we merge that one? :)

There is a big bug in #2982. They completely ignored the math behind share_convert and commented out all of it, leaving a naive version that is broken:

```
x = torch.tensor([-2, -1, 0, 1, 2]).share(alice, bob, dtype=""custom"", field=32, crypto_provider=crypto).child
relu_deriv(x).get() #gives garbage results 
```

I will fix this in the merging of securenn.py; a test should be added to #2982 to prevent this from happening again",merge one big bug completely math behind leaving naive version broken bob custom garbage fix test added prevent happening,issue,negative,negative,negative,negative,negative,negative
617382814,"Hey @ratmcu, size() is currently being investigated in https://github.com/OpenMined/PySyft/issues/3382
Meanwhile, I suggest that you use `input_ids.shape[1]` instead it should work correctly!",hey size currently meanwhile suggest use instead work correctly,issue,negative,neutral,neutral,neutral,neutral,neutral
617381829,"Well maybe there is a way to fix this, but this is why we didn't manage to get it working :)",well maybe way fix manage get working,issue,negative,neutral,neutral,neutral,neutral,neutral
617381611,"Hey, this is a known issue: it is not possible to hook the size like we did for the shape because the size is used by the print function, which for Pointers wrapped into an empty torch tensor needs to be applied on this wrapper and not on the remote value.
",hey known issue possible hook size like shape size used print function wrapped empty torch tensor need applied wrapper remote value,issue,negative,negative,neutral,neutral,negative,negative
617379307,"We just had a great PR merged (#2982) which will help for this issue which is still open!
https://github.com/OpenMined/PySyft/pull/3148 also adresses secure comparison for more workers, but @artix41 if yoy're willing to do the checks for multiplication & addition I'd be very graeful!",great help issue still open also secure comparison yoy willing multiplication addition,issue,positive,positive,positive,positive,positive,positive
617339088,"Is there any update on this issue? Multiplying and dividing tensors by integers is a pretty common operation, and it took me a while to understand why `torch.mean` returned an absurd value when working with n>=3 workers.",update issue multiplying dividing pretty common operation took understand returned absurd value working,issue,positive,negative,negative,negative,negative,negative
617266087,"The test is failing with:
```
 def float_prec(self):
>       if isinstance(self.child, PointerTensor):
E       AttributeError: 'Parameter' object has no attribute 'child'
```
It is possible because the plan is using a new type -- Parameter and that type do not have a child.",test failing self object attribute possible plan new type parameter type child,issue,negative,positive,neutral,neutral,positive,positive
617180293,"@karlhigley 
thanks for the help with syft-proto!... now I can use your ""template"" for the new field args (assuming we do want to add it)

note: I messed up in my github-fu and accidentally overwrite your commits but i was able to manually find the diff and re-apply them... 

I don't expect this to be working right now (at the very lease because of the new field args for communication actions) but feel free to give it a eyeball incase I am going in the wrong direction. 🙏 ",thanks help use template new field assuming want add note accidentally overwrite able manually find expect working right lease new field communication feel free give eyeball incase going wrong direction,issue,positive,positive,positive,positive,positive,positive
616853086,"> As a suggestion: we may need a function to check if a worker supports a specific framework

Should we keep in each worker a set of supported frameworks? (and have a method with -- ```is_supported(framework_name)``` where we simply check if we support that framework (like we have the methods attached to the worker)",suggestion may need function check worker specific framework keep worker set method simply check support framework like attached worker,issue,positive,neutral,neutral,neutral,neutral,neutral
616258398,Thank you for taking the time! This does improve usability.,thank taking time improve usability,issue,positive,neutral,neutral,neutral,neutral,neutral
616195728,Because I went back to #3360 to find the source of the issue. 😓 ,went back find source issue,issue,negative,neutral,neutral,neutral,neutral,neutral
616136999,"> Hmm, a bit difficult to understand how they passed before and fail now if they aren’t flaky. A conflict with something in `master`?

Yes. I felt the same too. Maybe @vvmnnnkv was not on a recent version of master.",bit difficult understand fail flaky conflict something master yes felt maybe recent version master,issue,negative,negative,negative,negative,negative,negative
616134399,"> PS: it doesn't fix #3329

Yes. It will be made after the #3321 is merged, as mentioned in your issue. That's why it's currently as a `Draft PR`. **Not ready yet.** 
I've fixed #3333 just as it will be related to it. ",fix yes made issue currently draft ready yet fixed related,issue,positive,positive,neutral,neutral,positive,positive
615907121,"Hmm, a bit difficult to understand how they passed before and fail now if they aren’t flaky. A conflict with something in `master`?",bit difficult understand fail flaky conflict something master,issue,negative,negative,negative,negative,negative,negative
615348071,"Could you create a new issue that contains steps to reproduce and the behavior/errors you're seeing?

PySyft used to use a separate `dev` branch that was merged into `master` periodically, but has since moved to merging directly into `master`. The fix in this PR is in the `master` branch, which you can verify by running:
```
$ git branch --contains 21c976a494a43a2aa614e4a28003663e08f3cb49
``` 
which outputs something like:
```
  [... many branches ...]
  karl/trace-from-placeholders
* master
  nolski/tfjs-translation
  overload
  [... many more branches ...]
```",could create new issue reproduce seeing used use separate dev branch master periodically since directly master fix master branch verify running git branch something like many master overload many,issue,negative,positive,positive,positive,positive,positive
615345141,"Might be good to fix this issue independently, but Syft Core has concluded that we should remove wrappers from the code base entirely. (It'll take a while.)",might good fix issue independently core remove code base entirely take,issue,negative,negative,neutral,neutral,negative,negative
615337600,Tutorial failure is unrelated and has been addressed in `master`.,tutorial failure unrelated master,issue,negative,negative,negative,negative,negative,negative
615331223,Test failure is from an unrelated and known flaky test.,test failure unrelated known flaky test,issue,negative,negative,negative,negative,negative,negative
615323912,Flaky tests strike again. This looks good though!,flaky strike good though,issue,negative,positive,positive,positive,positive,positive
614668001,"@NiWaRe 
Thanks a lot !
I will take a look , have a nice weekend !",thanks lot take look nice weekend,issue,positive,positive,positive,positive,positive,positive
614658757,"Hey @johnnylin110, 
sure no problem, here is my code: [Google Colab ResNet](https://colab.research.google.com/drive/1AQX35TJdH0u_mWoEEAkK_CN00xA6TyTY)
Was part of an assignment at university and I also did some comments so should help you to get an understanding of the architecture (ignore some comments, also was confused at times), I would also recommend to read the original paper. 
Concerning the issue with the Adam-Optimizer I created an issue which wasn't responded to yet. ",hey sure problem code part assignment university also help get understanding architecture ignore also confused time would also recommend read original paper concerning issue issue yet,issue,negative,positive,positive,positive,positive,positive
614561658,"```
bob = sy.VirtualWorker(hook, id=""bob"")
alice = sy.VirtualWorker(hook, id=""alice"")
crypto_provider = sy.VirtualWorker(hook, id=""james"")

resnet = models.resnet18()
resnet.fix_prec().share(bob, alice, crypto_provider=crypto_provider)
data = torch.ones(4, 3, 32, 32).fix_prec().share(bob, alice, crypto_provider=crypto_provider)

print(resnet(data))

```",bob hook bob hook hook bob data bob print data,issue,negative,neutral,neutral,neutral,neutral,neutral
614559959,"Can you provide the code you're trying to run ? :)
",provide code trying run,issue,negative,neutral,neutral,neutral,neutral,neutral
614253970,"Hi, I'm not super familiar with the library yet but I've noticed that this is still a problem. It seems like the fix was merged into `dev` rather than `master`. Is there a reason for this? Thanks",hi super familiar library yet still problem like fix dev rather master reason thanks,issue,positive,positive,positive,positive,positive,positive
614081795,"Anyway, #3358 adjusts the thresholds to make this test pass reliably, so this game of whack-a-mole has shifted to other parts of the code base.",anyway make test pas reliably game code base,issue,negative,negative,negative,negative,negative,negative
614081223,"It does allow for reproducibility, because each test run prints out the random seed at the beginning and you can pass it back in with a flag.

IMO, we need tests that are resilient to receiving different numbers, because the tests are already not guaranteed to run in the same order on every run (due to package path changing refactors.) I'd much rather intentionally deal with the problem of tests that flake (by randomizing their order and fixing issues) than have unrelated tests fail unexpectedly while refactoring due to order dependence of the test suite.",allow reproducibility test run random seed beginning pas back flag need resilient different already run order every run due package path much rather intentionally deal problem flake order fixing unrelated fail unexpectedly due order dependence test suite,issue,negative,negative,negative,negative,negative,negative
614040008,"memory error: Process finished with exit code -1073741571 (0xC00000FD)
I don't think it's possible to run it currently, at least on my machine ",memory error process finished exit code think possible run currently least machine,issue,negative,negative,negative,negative,negative,negative
613614818,">Setting fixed random seeds at the beginning of a test run doesn't solve the issue though, because the order of the tests is not fixed, so the numbers generated for each individual test may vary.

I see, I misunderstood. Dynamically setting the seed based on timestamp is not what I'd consider ""fixed seed"" because it doesn't allow for exact reproducibility of a test run across time & machines (which is what all unit/integration tests should strive for imo). But at least the problem is clear now, we need same numbers across runs for this issue to be fixed",setting fixed random beginning test run solve issue though order fixed individual test may vary see misunderstood dynamically setting seed based consider fixed seed allow exact reproducibility test run across time strive least problem clear need across issue fixed,issue,positive,negative,neutral,neutral,negative,negative
613596030,Merging despite unrelated serialization test failure to reduce sources of test flakiness in `master`.,despite unrelated serialization test failure reduce test flakiness master,issue,negative,negative,negative,negative,negative,negative
613590504,Yeah thanks @karlhigley . My tensorflow privacy installation was broken thanks!,yeah thanks privacy installation broken thanks,issue,positive,neutral,neutral,neutral,neutral,neutral
613578957,Even packages installed from source (at least via `pip install .`) should show up on that list.,even source least via pip install show list,issue,negative,negative,negative,negative,negative,negative
613577570,Merging despite unrelated flaky test failure. The game of whack-a-mole continues!,despite unrelated flaky test failure game,issue,negative,negative,negative,negative,negative,negative
613539198,"Yikes, sorry @karlhigley !  I saw you approved the PR and I jumped the gun. I'll get @vvmnnnkv to take a look.",sorry saw gun get take look,issue,negative,negative,negative,negative,negative,negative
613539016,"Since this is blocking fixing the flaky tests that are failing on this PR, I'm merging it anyway. (The `master` branch is deterministically broken right now, and stochastically broken after merging the revert.)",since blocking fixing flaky failing anyway master branch broken right stochastically broken revert,issue,negative,negative,negative,negative,negative,negative
613537348,"@karlhigley tf privacy and tfencrypted are installed from source I think that's why they dont show up here
",privacy source think dont show,issue,negative,neutral,neutral,neutral,neutral,neutral
613536576,"@karlhigley The output is 
Package                Version            
---------------------- -------------------
absl-py                0.9.0              
appnope                0.1.0              
astunparse             1.6.3              
attrs                  19.3.0             
backcall               0.1.0              
bleach                 3.1.0              
cachetools             4.1.0              
certifi                2020.4.5.1         
chardet                3.0.4              
click                  7.1.1              
decorator              4.4.1              
defusedxml             0.6.0              
entrypoints            0.3                
Flask                  1.1.1              
Flask-SocketIO         4.2.1              
gast                   0.3.3              
google-auth            1.13.1             
google-auth-oauthlib   0.4.1              
google-pasta           0.2.0              
grpcio                 1.28.1             
h5py                   2.10.0             
idna                   2.8                
importlib-metadata     1.5.0              
ipykernel              5.1.4              
ipython                7.12.0             
ipython-genutils       0.2.0              
ipywidgets             7.5.1              
itsdangerous           1.1.0              
jedi                   0.16.0             
Jinja2                 2.11.1             
json5                  0.9.0              
jsonschema             3.2.0              
jupyter-client         5.3.4              
jupyter-console        6.1.0              
jupyter-core           4.6.1              
jupyterlab             2.1.0              
jupyterlab-server      1.0.7              
Keras-Preprocessing    1.1.0              
lz4                    3.0.2              
Markdown               3.2.1              
MarkupSafe             1.1.1              
mistune                0.8.4              
msgpack                1.0.0              
nbconvert              5.6.1              
nbformat               5.0.4              
notebook               6.0.3              
numpy                  1.18.1             
oauthlib               3.1.0              
opt-einsum             3.2.0              
pandocfilters          1.4.2              
parso                  0.6.1              
pexpect                4.8.0              
phe                    1.4.0              
pickleshare            0.7.5              
Pillow                 6.2.2              
pip                    20.0.2             
prometheus-client      0.7.1              
prompt-toolkit         3.0.3              
protobuf               3.11.3             
ptyprocess             0.6.0              
pyasn1                 0.4.8              
pyasn1-modules         0.2.8              
Pygments               2.5.2              
pyrsistent             0.15.7             
python-dateutil        2.8.1              
python-engineio        3.11.2             
python-socketio        4.4.0              
pyzmq                  18.1.1             
qtconsole              4.6.0              
requests               2.22.0             
requests-oauthlib      1.3.0              
rsa                    4.0                
scipy                  1.4.1              
Send2Trash             1.5.0              
setuptools             45.2.0.post20200210
six                    1.14.0             
syft                   0.2.4              
syft-proto             0.2.5a1            
tblib                  1.6.0              
tensorboard            2.2.0              
tensorboard-plugin-wit 1.6.0.post3        
tensorflow             2.2.0rc3           
tensorflow-estimator   2.2.0rc0           
termcolor              1.1.0              
terminado              0.8.3              
testpath               0.4.4              
torch                  1.4.0              
torchsummary           1.5.1              
torchvision            0.5.0              
tornado                6.0.4              
traitlets              4.3.3              
urllib3                1.25.8             
wcwidth                0.1.8              
webencodings           0.5.1              
websocket-client       0.57.0             
websockets             8.1                
Werkzeug               1.0.0              
wheel                  0.34.2             
widgetsnbextension     3.5.1              
wrapt                  1.12.1             
zipp                   2.2.0              
zstd                   1.4.4.0    ",output package version bleach click decorator flask gast jinja markdown notebook pillow pip post six post torch tornado wheel,issue,negative,neutral,neutral,neutral,neutral,neutral
613487044,"There is a global seed used, which is set to the timestamp of the start of the test run. (There are actually multiple random seeds at play though (the Python random seed, the PyTorch random seed, and the Numpy random seed), and I'm not sure they all get set. 🤔 

Setting fixed random seeds at the beginning of a test run doesn't solve the issue though, because the order of the tests is not fixed, so the numbers generated for each individual test may vary. If individual tests can't be written in a fashion that makes them (pretty much) deterministic despite the randomness within, they can set whatever random seeds they need to.",global seed used set start test run actually multiple random play though python random seed random seed random seed sure get set setting fixed random beginning test run solve issue though order fixed individual test may vary individual ca written fashion pretty much deterministic despite randomness within set whatever random need,issue,positive,negative,negative,negative,negative,negative
613480707,Post the output of `pip list` in that environment?,post output pip list environment,issue,negative,neutral,neutral,neutral,neutral,neutral
613436605,Has anybody been able to solve this? I installed both tf-privacy and tfencrypted in my pysyft environment but this attiribute error doesn't seem to go away!,anybody able solve environment error seem go away,issue,negative,positive,positive,positive,positive,positive
613434177,It would be great if you can wait till the CKKSTensor is merged to avoid any merge conflict,would great wait till avoid merge conflict,issue,negative,positive,positive,positive,positive,positive
613388186,"Currently, it fails in test ```test_instantiate_tfe_layer``.
On this
```
E       AssertionError: 
E       Not equal to tolerance rtol=0.001, atol=0
E       
E       Mismatched elements: 4 / 20 (20%)
E       Max absolute difference: 0.00031287
E       Max relative difference: 0.00110612
E        x: array([[-0.163999, -1.074379, -1.394909, -0.963268,  0.888889],
E              [-0.163999, -1.074379, -1.394909, -0.963268,  0.888889],
E              [-0.163999, -1.074379, -1.394909, -0.963268,  0.888889],
E              [-0.163999, -1.074379, -1.394909, -0.963268,  0.888889]])
E        y: array([[-0.164181, -1.074468, -1.395135, -0.9634  ,  0.889202],
E              [-0.164181, -1.074468, -1.395135, -0.9634  ,  0.889202],
E              [-0.164181, -1.074468, -1.395135, -0.9634  ,  0.889202],...
```

This is probably due to the random order of the tests. Will try to re-run the tests and check if it passes - if this continues to happen on the PRs (this particular failing we should open an issue)",currently test equal tolerance absolute difference relative difference array array probably due random order try check happen particular failing open issue,issue,negative,negative,neutral,neutral,negative,negative
613348228,"Hi , @NiWaRe 
Thanks for helping me , the model from torch is 66% accuracy!
However still some question, 
1.why the network I use can't train will? Because in pytorch it work perfectly. 
2.How can I get the 66% higher just like you said you get 92%?Just put the dropout on it?If 
convenient, can I get your 92% code , thanks
3. You mention that the 10 lines in tutorial has problem with model, how do you solve it ?
Thanks for your helping again , that helps a lot!
",hi thanks helping model torch accuracy however still question network use ca train work perfectly get higher like said get put dropout convenient get code thanks mention tutorial problem model solve thanks helping lot,issue,positive,positive,positive,positive,positive,positive
612987608,"Yes, assuming there's a reason that no global seed is used.",yes assuming reason global seed used,issue,negative,neutral,neutral,neutral,neutral,neutral
612926920,"I'm not sure that #3179 was intended to add full support for momentum-based optimizers. It certainly seems like a step in the right direction, but it's not clear that momentum-based optimizers are fully compatible with the rest of PySyft.",sure intended add full support certainly like step right direction clear fully compatible rest,issue,positive,positive,positive,positive,positive,positive
612924201,Not sure I follow. Are you suggesting using fixtures to set random seeds?,sure follow suggesting set random,issue,negative,neutral,neutral,neutral,neutral,neutral
612904285,">randomized functions in the tests are inconsistently (re-)seeded

Seems like a great use case for [pytest fixtures](https://docs.pytest.org/en/latest/fixture.html)",inconsistently seeded like great use case,issue,positive,positive,positive,positive,positive,positive
612892237,@Syzygianinfern0 I think this changed most recently in one of your PRs. Give it a look?,think recently one give look,issue,negative,neutral,neutral,neutral,neutral,neutral
612824053,"> What's the error? Post a stack trace.

Error is due to the recent changes in encrypt method.
```
AttributeError                            Traceback (most recent call last)
 in 
----> 1 x = th.Tensor([1,2,3]).encrypt(pub)
      2 y = th.Tensor([2,2,2])

~/Desktop/PySyft/syft/frameworks/torch/tensors/interpreters/native.py in encrypt(self, protocol, **kwargs)
   1018 
   1019         """"""
-> 1020         if protocol.lower() == ""mpc"":
   1021             workers = kwargs.pop(""workers"")
   1022             crypto_provider = kwargs.pop(""crypto_provider"")

AttributeError: 'PaillierPublicKey' object has no attribute 'lower'
```",error post stack trace error due recent encrypt method recent call last pub encrypt self protocol object attribute,issue,negative,negative,neutral,neutral,negative,negative
612812223,"Hey @jaintj95 

as far as I understood in [Part 07 of the PySyft Tuts](https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/Part%2007%20-%20Federated%20Learning%20with%20Federated%20Dataset.ipynb) (in the contrary to the previous tutorial) we use a separate optimizer for each worker, simply by putting together a list of optimizers using the **same** `model.parameters()` (to train one single model for on each worker)
Although not done in the example I think it is perfectly possible to implement different optimizers for each worker if wanted. 

But apart from the possibility of practically doing it, does it make sense theoretically? The data on each worker are potentially non-iid and from different distribution which normally (not considering the Multi-Task-Learning setting) should be combined to describe a generalized distribution. If you alter the optimization for each worker and then update the global model using FederateAverging (using FedSGD or some Gradient Averaging wouldn't work anymore because otherwise the change in the optimizer wouldn't do anything) you would bias the update potentially more towards one worker (e.g. if the learning rate for one is bigger than for the other) ? 

Actually I'm not very experienced in this topic, but just curious why this could be helpful. :) ",hey far understood part tuts contrary previous tutorial use separate worker simply together list train one single model worker although done example think perfectly possible implement different worker apart possibility practically make sense theoretically data worker potentially different distribution normally considering setting combined describe generalized distribution alter optimization worker update global model gradient would work otherwise change would anything would bias update potentially towards one worker learning rate one bigger actually experienced topic curious could helpful,issue,positive,positive,neutral,neutral,positive,positive
612756710,"@Metrix1010 Fix those requested changes. Once fixed, I will be able to merge them.",fix fixed able merge,issue,negative,positive,positive,positive,positive,positive
612655343,"(For anyone picking up this issue, the test randomization is performed with [`pytest-randomly`](https://github.com/pytest-dev/pytest-randomly).)",anyone issue test randomization,issue,negative,neutral,neutral,neutral,neutral,neutral
612654718,"The issue that prompted randomizing the test case order was that changes to the directory structure (without code changes) could cause test failures, since the tests are run in alphabetical order and randomized functions in the tests are inconsistently (re-)seeded.",issue test case order directory structure without code could cause test since run alphabetical order inconsistently seeded,issue,negative,neutral,neutral,neutral,neutral,neutral
612652546,"There are two potential issues here:
1. Randomized functions in tests should be seeded, since integration tests should be deterministic. By randomizing the order of tests, the seed that these tolerance values are tuned against might be getting reset.
2. The rtol value here is working against the test definition, which is what makes the error dependent on seed.

To explain 2 a bit more:The loss of precision from TFE's fixed point representation truncating floating points is relatively worse for values closer to 0, and sampling kernel_initializer from a standard normal means we have a high likelihood of sampling numbers near 0. Relative error between the expected and actual value of the kernel will thus increase for numbers near 0 (whereas absolute error should be better).

If you want to randomize testing order, I'd double check that you're setting seeds after sampling the testcase order (so that each test can still be deterministic). I'd additionally either change the kernel_initializer to a distribution that doesn't have an expected value at 0 (normal -> uniform), or switch from rtol to atol (this is less satisfying but should at least make the test less susceptible to precision errors).",two potential seeded since integration deterministic order seed tolerance tuned might getting reset value working test definition error dependent seed explain bit loss precision fixed point representation floating relatively worse closer sampling standard normal high likelihood sampling near relative error actual value kernel thus increase near whereas absolute error better want randomize testing order double check setting sampling order test still deterministic additionally either change distribution value normal uniform switch le satisfying least make test le susceptible precision,issue,positive,positive,neutral,neutral,positive,positive
612644173,"Hey @johnnylin110 

I guess you simply used the approach of adding ""10 lines of code"" to implement Vanilla FL from [this Tutorial](https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/Part%2006%20-%20Federated%20Learning%20on%20MNIST%20using%20a%20CNN.ipynb) , right?

I copied your code and instead of using the manual implementation of the ResNet34 I used the model from the torchvision library. 
`model=torchvision.models.resnet18(pretrained=False).to(device)`

So far it is training to 42% Accuracy (at epoch 2 on Google Colab) I didn't change anything from ur code except I deleted the lr_scheduler and set the lr=0.01 statically. (I also tried Adam but for unknown reasons at exactly 50% through the first epoch it gives me a Syft-Error....I'll probably create an issue for that)

Given that you have 18% accuracy on Cifar10 it seems to me that your model isn't training at all. (Could be by chance and random weight init. as there are only 10 different options, setting the inference static to one fixed number would yield 10% already) 
As the 10 lines you took from the tutorial are unchanged I think there is a problem with the model, I had similair issues while implementing ResNet Manually. 

If this isn't a sufficient answer for you I can send you my implementation of ResNet (I got over 92% with Batchnorm, Dropout, SGD+momentum etc. on Cifar10) or also the code I'm running right now (the altered version of yours)",hey guess simply used approach code implement vanilla tutorial right copied code instead manual implementation used model library device far training accuracy epoch change anything ur code except set statically also tried unknown exactly first epoch probably create issue given accuracy model training could chance random weight different setting inference static one fixed number would yield already took tutorial unchanged think problem model manually sufficient answer send implementation got dropout also code running right version,issue,negative,positive,neutral,neutral,positive,positive
612642443,"You can do either, and there is (for example) a line of research that seeks to compress gradients to reduce FL communication costs. The Syft ecosystem is oriented toward model aggregation at present, but I'd love to make other approaches workable too.",either example line research compress reduce communication ecosystem toward model aggregation present love make workable,issue,positive,positive,positive,positive,positive,positive
612634982,What's the error? Post a stack trace.,error post stack trace,issue,negative,neutral,neutral,neutral,neutral,neutral
612566953,"My understanding is that in federated learning, you send model parameters to be aggregated, not gradients. ",understanding learning send model,issue,negative,neutral,neutral,neutral,neutral,neutral
612476930,"> I left very few comments but I guess the main part left is that CrypTenWorker.
> Regarding this, I do have a slight concern about creating workers dedicated to specific frameworks. In particular because it means you're making a choice when starting a set up on which interaction you'll allow, and the data you have and use won't be available for workers which are not from this framework.
> I'd rather envision adding to workers some specialities: by default you would get a worker which is fine for pytorch but not let's say for crypten. But at any point you could say `alice.add_crypten_support()` or smthg like this and your worker could also support specific operations for this framework, without loosing its compatibility with pytorch workers. I don't know if this makes sense?

It makes a lot of sense @LaRiffle. Currently I want to have this PR merged and after I can add support for this. If that sounds ok? Or should I push the changes in this PR? (I am thinking that this PR becomes bigger and bigger and it might be hard to track all the changes)",left guess main part left regarding slight concern specific particular making choice starting set interaction allow data use wo available framework rather envision default would get worker fine let say point could say like worker could also support specific framework without loosing compatibility know sense lot sense currently want add support push thinking becomes bigger bigger might hard track,issue,positive,positive,neutral,neutral,positive,positive
612074403,"I fixed this by adding the line `scikit-learn~=0.22.2.post1 `in the **requirements.txt** and then typing `make notebook` again.
After this I could run Tutorial Code 5 and 7 without any problems!",fixed line post make notebook could run tutorial code without,issue,negative,positive,neutral,neutral,positive,positive
612015472,"This would disable the serde tests, which probably isn't what we want.",would disable probably want,issue,negative,neutral,neutral,neutral,neutral,neutral
611812338,I'm currently not sure either to make TenSEAL an optional dependency or not :thinking: ,currently sure either make optional dependency thinking,issue,negative,positive,positive,positive,positive,positive
611623373,"Sure, adding it to the notebook requirements makes sense to me. I've tripped over that issue a few times myself. Submit a PR?",sure notebook sense issue time submit,issue,negative,positive,positive,positive,positive,positive
611617362,"It looks like an unrelated failure from a flaky test. I merged a change that runs the tests in a different random order every time, which is turning up a lot of those. I'll re-run and see if we get lucky on a retry.",like unrelated failure flaky test change different random order every time turning lot see get lucky retry,issue,negative,negative,negative,negative,negative,negative
611616664,"> I think we should probably make `tenseal` an optional dependency with a dependency check to see if it's available. Otherwise LGTM, but I'll defer to others on the new tensor type. +1

Yeah sure, I actually forgot about that, thank you !

**Update**: I will let this for another PR",think probably make optional dependency dependency check see available otherwise defer new tensor type yeah sure actually forgot thank update let another,issue,positive,positive,positive,positive,positive,positive
611613722,"Yeah, I have the same problem. 
Anyone from the dev team? Can you help us?",yeah problem anyone dev team help u,issue,negative,neutral,neutral,neutral,neutral,neutral
611612635,@karlhigley we need to add some parameters to ignore tiny changes.,need add ignore tiny,issue,negative,neutral,neutral,neutral,neutral,neutral
611607395,"It looks like would also imply changes to translated tutorials, so requesting a review from the Writing Team to figure out how to make that happen.",like would also imply review writing team figure make happen,issue,negative,neutral,neutral,neutral,neutral,neutral
611606286,(@imskr This is another example where the main code coverage tests pass but Codecov still fails.),another example main code coverage pas still,issue,negative,positive,positive,positive,positive,positive
611605048,"(Adding a test is still a good idea, of course.)",test still good idea course,issue,negative,positive,positive,positive,positive,positive
611604435,"There are already coverage tests included in the main test suite and Codecov is finicky, so I'd ignore it for now. @imskr, any idea how we can tweak Codecov to stop failing on tiny coverage changes?",already coverage included main test suite ignore idea tweak stop failing tiny coverage,issue,negative,positive,neutral,neutral,positive,positive
611603175,"`pip install --upgrade syft-proto` will force an upgrade to the newest available version of `syft-proto`, which is indeed incompatible with `syft 0.2.4`.

Fixes for the `tornado` version issue were merged in #3196, #3204, and #3288. (It may require manually downgrading your `tornado` version, because the previous dependency specification was overly optimistic about compatibility.)",pip install upgrade force upgrade available version indeed incompatible tornado version issue may require manually tornado version previous dependency specification overly optimistic compatibility,issue,negative,positive,positive,positive,positive,positive
611592981,"Merging the latest `master` into these branches should pull in the fix I mentioned, but I'm unable to fetch the code and do that myself since the branch names contain double quotes, which git thinks is an invalid remote branch to fetch from.",latest master pull fix unable fetch code since branch contain double git invalid remote branch fetch,issue,negative,negative,neutral,neutral,negative,negative
611590453,"Looks like flaky tests to me. I updated the automated testing workflows to skip the core library tests when PRs only change tutorials/translations, which should address that.",like flaky testing skip core library change address,issue,negative,neutral,neutral,neutral,neutral,neutral
611509361,"yes, I restarted the Python kernel many times.",yes python kernel many time,issue,negative,positive,positive,positive,positive,positive
611041487,Still failing codecov - but if you can get that to pass (above 95%) we're good :),still failing get pas good,issue,negative,positive,positive,positive,positive,positive
610992328,"I think the issues you're seeing have to do with flaky tests. It's less that master is broken, and more that some of the tests are not very robust to randomization.",think seeing flaky le master broken robust randomization,issue,negative,negative,negative,negative,negative,negative
610890145,"I do not understand why the tests fail. By running the notebooks locally everything works out fine and my code is exactly the same as in the english original. I have checked this multiple times.

Can you point me to some resources to learn why this fails or how to avoid it?",understand fail running locally everything work fine code exactly original checked multiple time point learn avoid,issue,negative,positive,neutral,neutral,positive,positive
610651050,@H4LL Sure. I will remove my name from the original 3 tutorials first. Then I will PR for the tutorial 4 independently. Thanks. Closed.,sure remove name original first tutorial independently thanks closed,issue,positive,positive,positive,positive,positive,positive
610547860,"Hey @haofanwang , I think this needs more explanation in the way of what you're doing in the later sections in the code. For this reason we should take tutorial 4 out of the PR for now.  I'd still like you to merge the PR still because I'd still like you to take your name off of the original 3 tutorials. 

I'm happy for you to put your name on whatever you work on just so long as you've made a non-trivial contribution to that thing. Generally the best way to be sure about this kind of thing is to ask the original author. I still think this tutorials a good effort, it just needs more work before a PR is made  :)",hey think need explanation way later code reason take tutorial still like merge still still like take name original happy put name whatever work long made contribution thing generally best way sure kind thing ask original author still think good effort need work made,issue,positive,positive,positive,positive,positive,positive
610452974,"> I don't understand why my build is failing...I just added a new notebook file, that's it!
> I guess that the master is broken, Trask mentioned this in #3107

Okay, I merged some other German translations where all the builds were successful, but most of other translators are facing the same issue. @iamtrask ",understand build failing added new notebook file guess master broken german successful facing issue,issue,negative,positive,positive,positive,positive,positive
610441076,"I don't understand why my build is failing...I just added a new notebook file, that's it!
I guess that the master is broken, Trask mentioned this in #3107 ",understand build failing added new notebook file guess master broken,issue,negative,negative,negative,negative,negative,negative
610406980,"> > Rerun all the tests, only if all the checks are successful, it can be merged.
> 
> I am sure to not have touched the code. Of course I can recheck another time!
> Is it possible to see the tests for the original notebook ([""Part 12: Train an Encrypted NN on Encrypted Data""](https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/Part%2012%20-%20Train%20an%20Encrypted%20Neural%20Network%20on%20Encrypted%20Data.ipynb))?

I see that you have cancelled some tests in build 3.6. For viewing them, just head over to the ""Checks"" sections in the same page.",rerun successful sure touched code course recheck another time possible see original notebook part train data see build head page,issue,positive,positive,positive,positive,positive,positive
610404668,"> Rerun all the tests, only if all the checks are successful, it can be merged.

I am sure to not have touched the code. Of course I can recheck another time!
Is it possible to see the tests for the original notebook ([""Part 12: Train an Encrypted NN on Encrypted Data""](https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/Part%2012%20-%20Train%20an%20Encrypted%20Neural%20Network%20on%20Encrypted%20Data.ipynb))?",rerun successful sure touched code course recheck another time possible see original notebook part train data,issue,positive,positive,positive,positive,positive,positive
610387541,"> @JMBehnken Is the translation for #3307 same as #3308?

No, the translations are for two different tutorials. 
Both tutorials are in the main folder for the examples but are nearly named the same. ([Part 8 - Introduction to Plans](https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/Part%2008%20-%20Introduction%20to%20Plans.ipynb) and [Part 8 bis - Introduction to Protocols](https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/Part%2008%20bis%20-%20Introduction%20to%20Protocols.ipynb))",translation two different main folder nearly part introduction part bi introduction,issue,negative,positive,neutral,neutral,positive,positive
610364209,"Sure, will do that by tonight👍

On Tue, 7 Apr 2020 at 5:58 PM, Srishilesh P S <notifications@github.com>
wrote:

> *@srishilesh* requested changes on this pull request.
>
> Rerun all the tests, only if all are successful, it can be merged.
> @r0cketr1kky <https://github.com/r0cketr1kky>
>
> —
> You are receiving this because you were mentioned.
>
>
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/pull/3123#pullrequestreview-389064630>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AJLQTT65ZD3FH2PW2JKJUWTRLML6VANCNFSM4K7B6JQQ>
> .
>
",sure tonight tue wrote pull request rerun successful reply directly view,issue,positive,positive,positive,positive,positive,positive
610342761,"> > Translations for part 02 #3294 has already been reviewed and merged.
> > Closing this pull request.
> 
> @srishilesh What was unclear about my translation? (PRed mine before JMBehnken)

All the code coverage tests were passed for JMBehnKen, and was ready to merge. The issue might be that, you would have mistakenly edited/removed some code.",part already pull request unclear translation mine code coverage ready merge issue might would mistakenly code,issue,negative,positive,positive,positive,positive,positive
610341946,"> Suggestion: you might want to try first if simple multiplication has a GC issue :)

Looks like the normal arithemetic operations don't do that. Just the ones with the more complicated operations do it. Maybe the intermediate tensors during the computataion (the ones preserved for the backprop) are the ones with the problem. ",suggestion might want try first simple multiplication issue like normal complicated maybe intermediate problem,issue,negative,negative,neutral,neutral,negative,negative
610339524,"> Translations for part 02 #3294 has already been reviewed and merged.
> Closing this pull request.

@srishilesh What was unclear about my translation? (PRed mine before JMBehnken)",part already pull request unclear translation mine,issue,negative,neutral,neutral,neutral,neutral,neutral
610336996,"> Thanks @Syzygianinfern0!
> Let us know if you're blocked. I've put the issue under ""High Priority""

Sure. I'll ask for help if stuck.",thanks let u know blocked put issue high priority sure ask help stuck,issue,positive,positive,positive,positive,positive,positive
610336102,"Translations for part 02 #3294 has already been reviewed and merged. 
Closing this pull request. ",part already pull request,issue,negative,neutral,neutral,neutral,neutral,neutral
610326044,"Thanks @Syzygianinfern0!
Let us know if you're blocked. I've put the issue under ""High Priority""
Suggestion: you might want to try first if simple multiplication has a GC issue :) ",thanks let u know blocked put issue high priority suggestion might want try first simple multiplication issue,issue,negative,positive,positive,positive,positive,positive
610280886,And very importantly to note: if you comment out `classifier(b)` the problem is no longer there,importantly note comment classifier problem longer,issue,negative,positive,positive,positive,positive,positive
610225352,"Oh right!
I'll approve, even if I'm not sure why one of the tests doesn't pass...",oh right approve even sure one pas,issue,negative,positive,positive,positive,positive,positive
609418305,"Sounded like you wanted to be able to send the buffers along with the model, so the test should probably `send` the model+buffers to another worker, `get` them back, and then check that received buffers are the same as the sent buffers.",like able send along model test probably send another worker get back check received sent,issue,negative,positive,positive,positive,positive,positive
609112911,"@iamtrask do you think at the moment this modification would be suffice for the movement of non parametric tensor elements as demanded by https://github.com/OpenMined/PySyft/issues/3236 ? . I was hoping until we elegantly add a hook for the buffers underlying the nn.Module and Optimizers(which is not using a buffer definition at the moment from pytorch, which I hope we can add a feature in pytorch.)  we can keep updating the list of iterators from the nn.Module  if a new iterator of elements comes up.",think moment modification would suffice movement non parametric tensor elegantly add hook underlying buffer definition moment hope add feature keep list new come,issue,positive,positive,positive,positive,positive,positive
609080735,I will create a test where I make a model and compare the buffer values directly from pytorch and from my buffer in pysyft. Does this sound right?,create test make model compare buffer directly buffer sound right,issue,negative,positive,positive,positive,positive,positive
609079764,"As of now the buffer is only collected in a variable and I would will collaborate with someone experienced in hooks to integrate my class to hooks and send it to worker nodes. Testing can be performed once data is sent to worker node. In case of any issue in later iteration, we can simply delete the merged file without affecting the integrity of code as the class added is added from an external python file i.e buffers.py

",buffer collected variable would collaborate someone experienced integrate class send worker testing data sent worker node case issue later iteration simply delete file without affecting integrity code class added added external python file,issue,negative,positive,positive,positive,positive,positive
609072403,Made some changes into my previous push after discussing with @karlhigley . Made a new buffer class in generic folder to handle all the buffers in future. Currently it only gathers data from torch and must be later integrated with hooks to send data to worker nodes.,made previous push made new buffer class generic folder handle future currently data torch must later send data worker,issue,negative,negative,neutral,neutral,negative,negative
608976140,"@iamtrask in https://github.com/OpenMined/PySyft/pull/3273 I was driven by the decision of only depending on the nn.Module for iteratable parameters, Seems pytorch follows this design pattern in adding extra elements. So in future we'd only have to update the list of functions from nn.Module in the hook. ",driven decision depending design pattern extra future update list hook,issue,negative,neutral,neutral,neutral,neutral,neutral
608565105,"> This does reduce code duplication, but still has multiple `run_websocket_server.py` files. Could we use a single `run_websocket_server.py` file for everything?

Now, There are only these `run_websocket_server.py` files
```
./test/run_websocket_server.py
./test/scripts/run_websocket_server.py
./run_websocket_server.py
```
I had already include mergeable parts of `/test/run_websocket_server.py` and `./test/scripts/run_websocket_server.py` into `./run_websocket_server.py`. Also, `/test/run_websocket_server.py` and `./test/scripts/run_websocket_server.py` are calling `/run_websocket_server.py` with different arguments. So I think these three can't be merged into a large single file. If you have any suggestions let me know.",reduce code duplication still multiple could use single file everything already include also calling different think three ca large single file let know,issue,negative,positive,neutral,neutral,positive,positive
608505307,@Kritikalcoder Ping me and/or @Jasopaum on Slack if you want to work on Plans/Protocols though!,ping slack want work though,issue,negative,neutral,neutral,neutral,neutral,neutral
608498790,"This has been fixed in the requirements file in #3204, but people with installations from before the fix will still need to run the workaround mentioned here.",fixed file people fix still need run,issue,negative,positive,neutral,neutral,positive,positive
608497916,"Would be great to capture these changes in a PR somehow, so that anyone else running locally in secure mode doesn't hit the same problem. 👍 ",would great capture somehow anyone else running locally secure mode hit problem,issue,positive,positive,positive,positive,positive,positive
608436419,@rotalex I am working on a similar problem. Please contact me on Slack as @Syzygianinfern0,working similar problem please contact slack,issue,negative,neutral,neutral,neutral,neutral,neutral
608427785,"Hello,
I'm really sorry if I'm causing any trouble.
I'd like to contribute to this project and for me it's the first time creating pull requests. 

I read the [Contributors Guidelines](https://github.com/OpenMined/PySyft/blob/master/CONTRIBUTING.md), informed myself with additional sources and chose an entry level issue I could work on (translating tutorials). 

Right now I don't know if I'm contributing in the right way:
- Forked the repository
- Create a branch for each new file/pull request
- Add my files to solve the issue
- Start a pull request after everything is finished

My second insecurity concerns the ""Codecov Report"". Is there any information on how to avoid lowering the code coverage?
I'm sure to not have touched any code inside the notebook while translating the explanations.

Have a nice day!
JM",hello really sorry causing trouble like contribute project first time pull read informed additional chose entry level issue could work right know right way forked repository create branch new request add solve issue start pull request everything finished second insecurity report information avoid lowering code coverage sure touched code inside notebook nice day,issue,negative,positive,positive,positive,positive,positive
608396538,"On further inspection, it is not at all obvious to me how (or even whether) the websocket examples need this change.",inspection obvious even whether need change,issue,negative,neutral,neutral,neutral,neutral,neutral
608389433,"The 3rd notebook mentioned above (training using websockets) has been changed so now these files ([here](https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/advanced/websockets_mnist/run_websocket_client.py), [here](https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/advanced/websockets_mnist_parallel/run_websocket_client.py)) are where the floptimizer changes go. While the changes are straightforward, unfortunately I've not yet been able to get the websockets to run properly in order to test the changes.",notebook training go straightforward unfortunately yet able get run properly order test,issue,negative,positive,neutral,neutral,positive,positive
607991344,I will close this PR and open a new one: #3296 with the serialized input approach.,close open new one input approach,issue,negative,positive,neutral,neutral,positive,positive
607810133,"I think this was solved by #3179, where each worker now maintains it's own optimizer. However I'm pretty new here so I may be missing something.",think worker however pretty new may missing something,issue,negative,positive,neutral,neutral,positive,positive
607571647,"Sorry for the delay, I will just make the PR by today @LaRiffle ",sorry delay make today,issue,negative,negative,negative,negative,negative,negative
607517224,"So the load function with the preloaded argument and the new functionality only comes after CrypTen started using torch nightly features in their codebase, which means if we use that load, we have to use the nightly, or wait till torch 1.5 is released.",load function argument new functionality come torch nightly use load use nightly wait till torch,issue,negative,positive,positive,positive,positive,positive
607515079,"To reiterate our discussion from Slack. To use the load functionality, we need to update to torch nightly, right? (because the CrypTen team added the ```load``` changes after they targeted the pytorch nightly build)",reiterate discussion slack use load functionality need update torch nightly right team added load targeted nightly build,issue,negative,positive,positive,positive,positive,positive
607165336,"I've done a small benchmark, apparently your code is faster than for example my FSS PR on `test/torch` (320s vs 300s on my laptop)


**Oups sorry I closed the PR!!**",done small apparently code faster example sorry closed,issue,negative,negative,negative,negative,negative,negative
607153322,"> I would like to work on this issue

Hey Nilesh did you find any solution?
",would like work issue hey find solution,issue,positive,neutral,neutral,neutral,neutral,neutral
607133466,"Hey, I've seen your PR! That's a good start, add tests and checkout for possible existing numeric approximations they can help you have great speed-up (like what was done on tanh) :) ",hey seen good start add possible help great like done tanh,issue,positive,positive,positive,positive,positive,positive
607099666,"I have done these changes and I think now it works. In the constructor of the class `WebsocketClientWorker` I add:

```Python
if self.secure:
    self.ssl_context = ssl._create_unverified_context()
```

and in the `async_fit` function, instead of:

```Python 
async with websockets.connect(
                    self.url, timeout=TIMEOUT_INTERVAL, max_size=None, ping_timeout=TIMEOUT_INTERVAL
            ) as websocket:
```
I add the `ssl=self.ssl_context` to have:

```Python 
async with websockets.connect(
                    self.url, timeout=TIMEOUT_INTERVAL, max_size=None, ping_timeout=TIMEOUT_INTERVAL,ssl=self.ssl_context
            ) as websocket:
```",done think work constructor class add python function instead python add python,issue,negative,neutral,neutral,neutral,neutral,neutral
606751653,"# [Codecov](https://codecov.io/gh/OpenMined/PySyft/pull/3126?src=pr&el=h1) Report
> Merging [#3126](https://codecov.io/gh/OpenMined/PySyft/pull/3126?src=pr&el=desc) into [master](https://codecov.io/gh/OpenMined/PySyft/commit/9e1bd4fee7ec766575d45f0f59b7806a733991b2&el=desc) will **decrease** coverage by `4.70%`.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/OpenMined/PySyft/pull/3126/graphs/tree.svg?width=650&height=150&src=pr&token=W0kQS1vaXB)](https://codecov.io/gh/OpenMined/PySyft/pull/3126?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master    #3126      +/-   ##
==========================================
- Coverage   99.30%   94.60%   -4.71%     
==========================================
  Files           4      149     +145     
  Lines        1866    15948   +14082     
==========================================
+ Hits         1853    15087   +13234     
- Misses         13      861     +848     
```


| [Impacted Files](https://codecov.io/gh/OpenMined/PySyft/pull/3126?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [syft/codes.py](https://codecov.io/gh/OpenMined/PySyft/pull/3126/diff?src=pr&el=tree#diff-c3lmdC9jb2Rlcy5weQ==) | `100.00% <ø> (ø)` | |
| [syft/dependency\_check.py](https://codecov.io/gh/OpenMined/PySyft/pull/3126/diff?src=pr&el=tree#diff-c3lmdC9kZXBlbmRlbmN5X2NoZWNrLnB5) | `87.50% <ø> (ø)` | |
| [syft/exceptions.py](https://codecov.io/gh/OpenMined/PySyft/pull/3126/diff?src=pr&el=tree#diff-c3lmdC9leGNlcHRpb25zLnB5) | `77.35% <ø> (ø)` | |
| [syft/execution/plan.py](https://codecov.io/gh/OpenMined/PySyft/pull/3126/diff?src=pr&el=tree#diff-c3lmdC9leGVjdXRpb24vcGxhbi5weQ==) | `92.79% <ø> (ø)` | |
| [syft/execution/protocol.py](https://codecov.io/gh/OpenMined/PySyft/pull/3126/diff?src=pr&el=tree#diff-c3lmdC9leGVjdXRpb24vcHJvdG9jb2wucHk=) | `88.02% <ø> (ø)` | |
| [syft/execution/state.py](https://codecov.io/gh/OpenMined/PySyft/pull/3126/diff?src=pr&el=tree#diff-c3lmdC9leGVjdXRpb24vc3RhdGUucHk=) | `91.22% <ø> (ø)` | |
| [syft/federated/federated\_client.py](https://codecov.io/gh/OpenMined/PySyft/pull/3126/diff?src=pr&el=tree#diff-c3lmdC9mZWRlcmF0ZWQvZmVkZXJhdGVkX2NsaWVudC5weQ==) | `95.32% <ø> (ø)` | |
| [syft/federated/train\_config.py](https://codecov.io/gh/OpenMined/PySyft/pull/3126/diff?src=pr&el=tree#diff-c3lmdC9mZWRlcmF0ZWQvdHJhaW5fY29uZmlnLnB5) | `90.76% <ø> (ø)` | |
| [syft/frameworks/keras/hook.py](https://codecov.io/gh/OpenMined/PySyft/pull/3126/diff?src=pr&el=tree#diff-c3lmdC9mcmFtZXdvcmtzL2tlcmFzL2hvb2sucHk=) | `100.00% <ø> (ø)` | |
| [syft/frameworks/keras/layers/constructor.py](https://codecov.io/gh/OpenMined/PySyft/pull/3126/diff?src=pr&el=tree#diff-c3lmdC9mcmFtZXdvcmtzL2tlcmFzL2xheWVycy9jb25zdHJ1Y3Rvci5weQ==) | `100.00% <ø> (ø)` | |
| ... and [173 more](https://codecov.io/gh/OpenMined/PySyft/pull/3126/diff?src=pr&el=tree-more) | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/OpenMined/PySyft/pull/3126?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/OpenMined/PySyft/pull/3126?src=pr&el=footer). Last update [f6e8fd2...c47c962](https://codecov.io/gh/OpenMined/PySyft/pull/3126?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",report master decrease coverage coverage impacted file tree graph coverage master coverage impacted coverage continue review full report legend click learn absolute relative impact affected missing data powered last update read comment,issue,negative,positive,neutral,neutral,positive,positive
606723275,"@iamtrask , I will update the method name asap. I guess #3273 is requesting selected parameters and passing them, where as I am requesting the entire buffer that is maintained by pytorch nn.module. I feel it would be safe to use as future pytorch algorithms are most likely  to keep using the buffer and will only break its functionality when pytorch deprecates the named_buffer. Any future algorithm using some other parameter other than running mean or std will automatically get sent as it would be a part of the buffer and wont have to be explicitly added to the iterator list.
",update method name guess selected passing entire buffer feel would safe use future likely keep buffer break functionality future algorithm parameter running mean automatically get sent would part buffer wont explicitly added list,issue,negative,positive,neutral,neutral,positive,positive
606709584,"Thanks!




------------------&nbsp;原始邮件&nbsp;------------------
发件人:&nbsp;""The Syzygian Inferno""<notifications@github.com&gt;;
发送时间:&nbsp;2020年3月31日(星期二) 晚上11:37
收件人:&nbsp;""OpenMined/PySyft""<PySyft@noreply.github.com&gt;;
抄送:&nbsp;""ganjf""<1194520007@qq.com&gt;;""Author""<author@noreply.github.com&gt;;
主题:&nbsp;Re: [OpenMined/PySyft] Error abou x.encrypt(protocol=""paillier"", public_key=pub) (#3282)





 
Since the feature was implemented very recently it's not available on any release as of now. Please try installing from source.
 Link
 
—
You are receiving this because you authored the thread.
Reply to this email directly, view it on GitHub, or unsubscribe.",thanks inferno author author error since feature recently available release please try source link thread reply directly view,issue,negative,positive,positive,positive,positive,positive
606703792,"Since the feature was implemented very recently it's not available on any release as of now. Please try installing from source.
[Link](https://github.com/OpenMined/PySyft/blob/dev/INSTALLATION.md)
",since feature recently available release please try source link,issue,negative,positive,positive,positive,positive,positive
606699176,"There is  an error ""encrypt() got an unexpected keyword argument 'protocol'.""
I install the library with `pip install syft[udacity]`, the version is 0.2.4, but I found there is difference in /syft/frameworks/torch/tensors/interpreters/native.py/ about the defination of encrypt() method with codes on Github. It seems the updated version about the method encrypt(protocol=""pailiar"", *kwarg) don't exist. When I download the site package `syft` and place it to python3.7/site-packages, it show me an error when I import syft. So I think maybe you have fogot to update the library with pip method. 
And there is syft-proto= 0.2.8.a1， but the latest version of syft=0.2.4 could only match the syft-proto=0.2.5.a1. So I have no idea to update the latest syft which could use `encrypt(protocol=""pailiar"", *kwarg)` to achieve HE. So I really wish you could offer me help.Thanks



 ",error encrypt got unexpected argument install library pip install version found difference encrypt method version method encrypt exist site package place show error import think maybe update library pip method latest version could match idea update latest could use encrypt achieve really wish could offer,issue,negative,positive,positive,positive,positive,positive
606685679,"You can try the following
```python
import torch
import syft as sy

hook = sy.TorchHook(torch)

bob = sy.VirtualWorker(hook, id=""bob"")
alice = sy.VirtualWorker(hook, id=""alice"")
james = sy.VirtualWorker(hook, id=""james"")

x = torch.randint(10, (1, 5), dtype=torch.float32)

# MPC
x_encrypted = x.encrypt(workers=[bob, alice], crypto_provider=james)
x_decrypted = x_encrypted.decrypt()
assert (x == x_decrypted).all()

# Paillier
public, private = sy.frameworks.torch.he.paillier.keygen()
x_encrypted = x.encrypt(protocol=""paillier"", public_key=public)
x_decrypted = x_encrypted.decrypt(protocol=""paillier"", private_key=private)
assert (x == x_decrypted).all()
```


My guess if you've forgotten to hook PySyft. You can do that by adding ```hook = sy.TorchHook(torch)``` after the imports",try following python import torch import hook torch bob hook bob hook hook bob assert public private assert guess forgotten hook hook torch,issue,negative,neutral,neutral,neutral,neutral,neutral
606574207,"I tried to manually give WebsocketClientWorker the cert file but I faced another error:

> ssl.SSLError: [SSL] called a function you should not call

@IonesioJunior did you try the `WebsocketClientWorker` and `WebsocketServerWorker` in `async` mode?",tried manually give file faced another error function call try mode,issue,negative,neutral,neutral,neutral,neutral,neutral
606499841,"@ratmcu  I know there is a bug so need to call .size() method here, but still, why the accuracy of the same approach(same network) will lead different ?
    In my Pytorch CIFAR with the net above is 65% at final , but in pysyft version it only 10% at the end(even when worker set to 1) . Why will this happen? 

Thanks for reply ! very appreciate!",know bug need call method still accuracy approach network lead different net final version end even worker set happen thanks reply appreciate,issue,positive,positive,neutral,neutral,positive,positive
606397615,"> There is also a file name `start_websocket_servers.py` in the `websockets_mnist`. Can't the file be merged into one?

I had already merged `run_websocket_servers.py` from the `websockets_mnist`.  While `start_websocket_servers.py` calls `run_websocket_servers.py`. `start_websocket_servers.py` can't be merged into one single file because of different arguments they pass through `run_websocket_servers.py `.",also file name ca file one already ca one single file different pas,issue,negative,negative,neutral,neutral,negative,negative
606164009,There is also a file name ```start_websocket_servers.py``` in the ```websockets_mnist```. Can't the file be merged into one?,also file name ca file one,issue,negative,neutral,neutral,neutral,neutral,neutral
605999894,They were using an old pytorch version and had the issue but the functionality suggested is still useful. ,old version issue functionality still useful,issue,negative,positive,positive,positive,positive,positive
605830431,"Is there any reason that we have two different methods for in-place and non in-place precision?
Shouldn't we just have one method with inplace as argument? :thinking: ",reason two different non precision one method argument thinking,issue,negative,neutral,neutral,neutral,neutral,neutral
605824007,"@johnnylin110 this is a separate bug due to not being able to call .size() method remotely, batchnorm layer running remotely was the goal. so it was running in this example. ",separate bug due able call method remotely layer running remotely goal running example,issue,negative,positive,neutral,neutral,positive,positive
605739949,"Hello , I am the one who comment in the issue #2498 
And I found it might have still a issue their . So I comment below, and the #2498 is closed so I mention in here , maybe need to take a look?",hello one comment issue found might still issue comment closed mention maybe need take look,issue,negative,negative,neutral,neutral,negative,negative
605739090,"@ratmcu Hi again, I am looking at the code you paste, the different between is you modify the forward part into 
```
if x.location != None:
            print(x.location)
            loc = x.location
            x = x.get()
            print(x.sixe(0))
            x = x.view(x.size(0), -1)
            x = x.send(loc)
        else:
            x = x.view(x.size(0), -1)
        x = self.fc_layer(x)
```
however , this network i try it on pysyft get 10% accuracy only , but in Pytorch version, this can achieve high accuracy , and if use the same code from above(without the part you modifiy) , the pysyft will pop out error message about ""shape [0,-1]  is invalid for input of size XXXX pytorch""
Is this still a bug here? ",hi looking code paste different modify forward part none print print else however network try get accuracy version achieve high accuracy use code without part pop error message shape invalid input size still bug,issue,negative,positive,neutral,neutral,positive,positive
605725320,"Ok so removing tests didn't work out. Tests are still taking roughly double the time of master. Also the advanced/encrypted_lr tutorial notebook is failing due to timeout which again signifies slow down of MPC ops. I don't see any changes that should lead to that much slowdown overall. 
@LaRiffle Is it possible that it is simply taking more time because of the increased field size as we have all ops now happening in field 2**64 by default?",removing work still taking roughly double time master also tutorial notebook failing due slow see lead much slowdown overall possible simply taking time field size happening field default,issue,negative,negative,neutral,neutral,negative,negative
605706131,"Hi,

When downgrading the version of tornado, more recent versions of jupyter notebook (& lab) stop working (notebook 6.0.3). Fixed this by running `pip install syft[udacity,notebooks]` so I can get a proper compatible version",hi version tornado recent notebook lab stop working notebook fixed running pip install get proper compatible version,issue,negative,positive,neutral,neutral,positive,positive
605688283,Protocol design will change a lot in the few days/weeks so I don't think it's worth working on this issue right now!,protocol design change lot think worth working issue right,issue,negative,positive,positive,positive,positive,positive
605681035,"Is this issue still open? Can I take it up?
",issue still open take,issue,negative,neutral,neutral,neutral,neutral,neutral
605636076,"#3092 is merged. Do more tests need to be added ? @iamtrask @karlhigley 
If not, then you can close this issue.",need added close issue,issue,negative,neutral,neutral,neutral,neutral,neutral
605630244,@ratmcu You can start working on a new branch and push the WIP code here. That might be a good way to collaborate.,start working new branch push code might good way collaborate,issue,negative,positive,positive,positive,positive,positive
605627258,"Actually I am not sure. I followed the advise proposed to add the following code at the beginning of my code and it does not work:

```python 
import ssl
try:
    _create_unverified_https_context = ssl._create_unverified_context
except AttributeError:
    # Legacy Python that doesn't verify HTTPS certificates by default
    pass
else:
    # Handle target environment that doesn't support HTTPS verification
    ssl._create_default_https_context = _create_unverified_https_context
``` 

I have also tried adding to the `WebsocketClientWorker`, but no success. Done the same thing with `WebsocketServerWorker` and no success either.",actually sure advise add following code beginning code work python import try except legacy python verify default pas else handle target environment support verification also tried success done thing success either,issue,positive,positive,positive,positive,positive,positive
605557094,@seungjaeryanlee Sure! I'm not working on this issue right now. ,sure working issue right,issue,negative,positive,positive,positive,positive,positive
605556191,@wonderit I'll start working on translating Part 04. Can you confirm that you are not currently translating this notebook? Don't want to do duplicate work :),start working part confirm currently notebook want duplicate work,issue,negative,neutral,neutral,neutral,neutral,neutral
605524081,"@SagarMoghe I already added a function and working on testing it,
I am also adding features to get all the non parameter elements of iterated by an arbitrary function that could be added to the hooked pytorch nn module to be considered at the send().
I would like if we can work on testing the new feature, rather than repeating the same.",already added function working testing also get non parameter arbitrary function could added hooked module considered send would like work testing new feature rather,issue,negative,positive,neutral,neutral,positive,positive
605491076,"@iamtrask @karlhigley  I did some research and I went around and snooped into nn.module code and noticed that line 87 of [nn.module](https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/module.py) has the variable that contains information I need. I am not sure where exactly in the pysyft codebase should I implement the function to get the value of this variable. I am new to pysyft and dont know much about the code structure. Please help me.
PS: does making a function .parameters_and_statistics() which returns the self._buffers containing all the non parameterised attributes of the neuralNet and returning them to the user solves the problem of the issue?
Thank you",research went around code line variable information need sure exactly implement function get value variable new dont know much code structure please help making function non user problem issue thank,issue,positive,positive,positive,positive,positive,positive
605469070,"worker.search() is for local use only. for a remote worker use `me.request_search(['mytag'], location= worker)`. this will send you back an object_pointer that points to the dataset. that enables you to call .get() on it only for now not full functionality of dataset_pointer.
update: me.request_search() returns a dataset_pointer now",local use remote worker use worker send back call full functionality update,issue,negative,positive,neutral,neutral,positive,positive
605441261,"not exactly, fix_precision() should be applied anyway on the remote value when called on a pointer (and it works fine)

the issue is that currently we have this for pointers:
```
a = torch.Tensor([2., 3.]).send(bob)
a_fp = a.fix_precision()
# a_fp is a pointer to a fixed precision, but a is too!
```
while for non pointers:
```
a = torch.Tensor([2., 3.])
a_fp = a.fix_precision()
# a_fp is a wrapper onto a fixed precision, but a is not!
```

So for pointers, `fix_precision` behaves as `fix_precision_` while it shouldn't",exactly applied anyway remote value pointer work fine issue currently bob pointer fixed precision non wrapper onto fixed precision,issue,negative,positive,positive,positive,positive,positive
605438553,"⚠️ I would like to merge https://github.com/OpenMined/PySyft/pull/2982 first since it's an older PR which is already dealing with lots of conflicts.
Let's see if it can be ready to merge in the next days, else we'll merged this one first",warning would like merge first since older already dealing lot let see ready merge next day else one first,issue,negative,positive,positive,positive,positive,positive
605437183,"This is something I always thought OpenMined had to have , thank you @TTitcombe ",something always thought thank,issue,negative,neutral,neutral,neutral,neutral,neutral
605405352,"Hey @AlanAboudib @karlhigley @LaRiffle ,
so if I understand this correctly,

```python
x = th.Tensor([1.,2.,3.]).send(bob)
x_fx = x.fix_precision()
x = x_fx.get()

```
x_fx is a `PointerTensor` and expected behavior is to be a `FixedPrecisionTensor` with `PointerTensor` as child?

Moreover when we .get() the x_fx, it returns `FixedPrecisionTensor`, which I think is a correct behavior, as we haven't called float_precision yet.",hey understand correctly python bob behavior child moreover think correct behavior yet,issue,negative,neutral,neutral,neutral,neutral,neutral
605211802,"I think the underlying issue [is in `BaseWorker`](https://github.com/OpenMined/PySyft/blob/master/syft/workers/base.py#L316-L317). The problem is that the base `Message` class no longer has a `contents` property, so none of the sub-classes do either.",think underlying issue problem base message class longer content property none either,issue,negative,negative,negative,negative,negative,negative
605201009,"You probably run it with `--verbose` arg which causes the `msg.contents` print. Try running the remote worker without the param, as a temporary fix.",probably run verbose print try running remote worker without param temporary fix,issue,negative,negative,neutral,neutral,negative,negative
605200415,@karlhigley Have we had an open issue for that? I would love to try.,open issue would love try,issue,positive,positive,positive,positive,positive,positive
605047222,This will likely be addressed by current @OpenMined/syft-core-team work to refactor the remote execution primitives. Currently looks like `send()` operations will only be allowed in `Protocols`.,likely current work remote execution currently like send,issue,negative,negative,neutral,neutral,negative,negative
605034684,Will try to get that fixed! Thanks for pointing it out.,try get fixed thanks pointing,issue,negative,positive,positive,positive,positive,positive
605030984,"> The Slack org is open and you can join [here](http://slack.openmined.org/). Join the #gsoc channel!

Alright, thanks! For some reason the link on [the blog entry](https://blog.openmined.org/announcing-openmined-google-summer-of-code/) said I should contact an Administrator. ",slack open join join channel alright thanks reason link entry said contact administrator,issue,positive,positive,neutral,neutral,positive,positive
605029396,The Slack org is open and you can join [here](http://slack.openmined.org/). Join the #gsoc channel!,slack open join join channel,issue,positive,neutral,neutral,neutral,neutral,neutral
605024338,"Hello @H4LL !
I'm Nicolas Remerscheid, currently studying in the Master of Data Engineering and Analytics at the Technical University of Munich in Germany (TUM), same as @AbinavRavi 
I have been learning and using PyTorch for nearly two years now. I first took the Deep Learning Nanodegree on Udacity being awarded a Full-Scholarship by Facebook (Top 300/10.000 students) As part of the program I initiated and helped start a Human Activity Recognition Android App which aims at providing a non-intrusive way of surveillance for the elderly (e.g.: If there isn't a movement for a couple of days somebody should check if everything's alright) by using LSTM, CNN Approaches to use Accelerometer and Gyroscope in a normal Smartphone to classify whether a person is walking, going up stairs, resting, etc. After that I also took part in the Udacity first phase challenger scholarship for ""Secure&Private AI"". That is also how I found about this community and the GSoC (by the posting of Sourav Das) 
As my Master is also specialized on Machine Learning I took various Machine Learning and Deep Learning Courses both also containing weekly assignments with practical hands-on PyTorch Projects. The latter also included the mathematical concepts behind Privacy-Preserving (Machine Learning) Techniques such as Differential Privacy and Federated Learning. 
As already visible in my effort to create the HAR-Android-App I'm very committed to advancing the benefit AI can have on society while maintaining privacy and data ownership rights as key rights of decision and freedom. If needed I would be happy to elaborate on my specific motivation for this project or my relevant qualifications and/or to send you my CV or LinkedIn.

Unfortunately I found out about this outstanding possibility too late to contribute much until now. (For now I'm only in the process of translating some of the PySift Notebooks into my native language German as a first contribution #2782 and am in the process of registration for GSoC) 
I would be very grateful however if you could also invite me to the Slack-Community and tell me how I could start contributing and how I could increase my chances of being a part of the GSoC as part of this project. 

Thanks in advance!",hello currently master data engineering analytics technical university tum learning nearly two first took deep learning top part program start human activity recognition android providing way surveillance elderly movement couple day somebody check everything alright use accelerometer gyroscope normal whether person walking going resting also took part first phase challenger scholarship secure private ai also found community posting da master also specialized machine learning took various machine learning deep learning also weekly practical latter also included mathematical behind machine learning differential privacy learning already visible effort create advancing benefit ai society privacy data ownership key decision freedom would happy elaborate specific motivation project relevant send unfortunately found outstanding possibility late contribute much process native language german first contribution process registration would grateful however could also invite tell could start could increase part part project thanks advance,issue,positive,positive,positive,positive,positive,positive
605018611,"@OpenMined/syft-core-team is working on some of the underlying communication primitives, which should make the comms depicted in @LaRiffle's diagram easier. In particular, we created [`CommunicationAction`](https://github.com/OpenMined/PySyft/blob/master/syft/execution/communication.py) as a way to capture and transmit sending/receiving operations to be executed elsewhere. It's still work in progress, but we expect it to underlie a lot of the communications between workers (e.g. in `Protocols`.)",working underlying communication make diagram easier particular way capture transmit executed elsewhere still work progress expect underlie lot,issue,positive,positive,positive,positive,positive,positive
605008109,"(This issue was created from a card on the Syft Core project board, and Github project boards doesn't have a way to capture a description on cards that aren't issues. Hence the long title!)",issue card core project board project way capture description hence long title,issue,negative,negative,neutral,neutral,negative,negative
605007642,"When running locally with `VirtualWorkers` they all run in the same thread, which causes some difficulties with the Torch hook. If you call `torch.ones()` on a `VirtualWorker`, the resulting tensor ends up registered on the `local_worker` instead.",running locally run thread torch hook call resulting tensor registered instead,issue,negative,neutral,neutral,neutral,neutral,neutral
605006894,"Yeah, I agree they should renamed. I like the suggestion of `WebsocketProxy` and `WebsocketWorker`. Seems clean and clear, and would disambiguate the usages of client/server.",yeah agree like suggestion clean clear would,issue,positive,positive,positive,positive,positive,positive
605005107,Would something like [this](https://github.com/cloudfoundry-community/cf-python-client/issues/51#issuecomment-536428838) work to address that?,would something like work address,issue,negative,neutral,neutral,neutral,neutral,neutral
604996746,"We have the `advanced` directory which has a bunch of tutorials in separate folders, but I don't think they're organized by topic yet.",advanced directory bunch separate think organized topic yet,issue,negative,positive,positive,positive,positive,positive
604995245,Thanks for bearing with me while I wrapped my head around this PR. 👍 ,thanks bearing wrapped head around,issue,negative,positive,positive,positive,positive,positive
604977001,"@iamtrask I believe this should be reopened. Not all tutorials have been translated yet. Also, maybe add labels `translation` and `good first issue` ?",believe yet also maybe add translation good first issue,issue,negative,positive,positive,positive,positive,positive
604938422,@karlhigley could you add more context for this issue? (an example with where is happening would be great!),could add context issue example happening would great,issue,positive,positive,positive,positive,positive,positive
604933771,@karlhigley should this still be open? (might be a good idea to rename),still open might good idea rename,issue,negative,positive,positive,positive,positive,positive
604932620,"@LaRiffle, @karlhigley  we could close this issue, right?",could close issue right,issue,negative,positive,positive,positive,positive,positive
604929679,"I just checked!!
Correct overloaded functions are called for both pure torch tensors and wrapper tensor!!
So I guess this issue is resolved !!",checked correct pure torch wrapper tensor guess issue resolved,issue,negative,positive,positive,positive,positive,positive
604927046,@mari-linhares should we close this issue since currently we are on torch 1.4?,close issue since currently torch,issue,negative,neutral,neutral,neutral,neutral,neutral
604880828,"Securenn tests does take more time than other tests. But it should still be faster or equal to the master branch's version of the same tests. The only thing serving to the contrary is double the number of tests every securenn test is duplicated and ran once for dtype=long and once for dtype=int.
I think it's completely because of increased number of tests for same functionalities in both dtypes in a bunch o files I will try to remove some non-essential tests to speed it up.",take time still faster equal master branch version thing serving contrary double number every test ran think completely number bunch try remove speed,issue,negative,positive,neutral,neutral,positive,positive
604806006,Thanks! Looking forward to your reply.,thanks looking forward reply,issue,negative,positive,positive,positive,positive,positive
604777891,"I’d guess that SecureNN is probably the slow part, right?",guess probably slow part right,issue,negative,negative,neutral,neutral,negative,negative
604766798,"I have added some extensive tests here for testing dtype arg compatibility with each and every operation. I almost doubled the size of every test function in AST and FPT and also for securenn. I can remove some parts of it I added for catching corner cases as they might be a little overkill now that dtype arg is working well.
As for the performance impact: I don't think(or atleast I hope) these changes are not making individual tests slower because a major point for removing explicit modulos and using native tensor types for wrapping was to get performance improvement from removal of repeated modulo calls for every function.",added extensive testing compatibility every operation almost doubled size every test function ast also remove added catching corner might little working well performance impact think hope making individual major point removing explicit native tensor wrapping get performance improvement removal repeated modulo every function,issue,positive,positive,neutral,neutral,positive,positive
604758704,"I notice that the tests take ~35 minutes to run on this PR, compared to ~17 minutes on the latest commit on `master`. I'm not sure if that's because this PR adds some slow tests, or if it maybe slows down existing tests. I'll defer to @OpenMined/crypto-team to assess potential performance impacts re: MPC, but I'm hoping we can find a way to speed the test suite back up somewhat.",notice take run latest commit master sure slow maybe slows defer ass potential performance find way speed test suite back somewhat,issue,negative,positive,positive,positive,positive,positive
604736860,Once #2982 is merged. These explicit modulo calls are removed and wrapping of values in field size(moving forward we will only support 32 bit or 64bit) will be handled using native torch tensors with dtype torch.int32 and torch.int64 respectively.,explicit modulo removed wrapping field size moving forward support bit bit handled native torch respectively,issue,positive,neutral,neutral,neutral,neutral,neutral
604735391,zstd is no longer used from release v0.2.4. I think we can close this issue for good now.,longer used release think close issue good,issue,negative,positive,positive,positive,positive,positive
604732517,We have come a long way all the way to 2**64 once #2982 is merged. And will go even further beyond with BigIntTensor abstraction tensor type. So I think we can close this one.,come long way way go even beyond abstraction tensor type think close one,issue,negative,negative,neutral,neutral,negative,negative
604693625,"BTW, some of the changes I suggested above are probably things the @OpenMined/syft-core-team should tackle. I'm not trying to push all the PySyft refactoring onto the Crypten team, I just want to make sure we have a good foundation to build on that will support what Crypten needs. Where the foundation is lacking, I want to make sure that we're talking about the gaps and planning for how to resolve them.

Some things can probably be addressed in this PR (e.g. `CryptenWorker`), some things could be deferred for later (e.g. `Placeholder` method forwarding), and some things might be worthy of their own issues (e.g. establishing groups of communicating workers in a consistent way.) The last category especially is where I think @OpenMined/syft-core-team could help.",probably tackle trying push onto team want make sure good foundation build support need foundation want make sure talking resolve probably could deferred later method forwarding might worthy communicating consistent way last category especially think could help,issue,positive,positive,positive,positive,positive,positive
604498992,@mari-linhares I have been working with tensorflow from past 8-9 months and would love to work on this project.,working past would love work project,issue,positive,positive,positive,positive,positive,positive
604450014,"@iamadarshk 
I'm supposed to apply GSoC in 2020, but this pull request is required for my submission.
Would you mind if you can afford?",supposed apply pull request submission would mind afford,issue,negative,neutral,neutral,neutral,neutral,neutral
604432787,"@sukhadj There's [an open PR](https://github.com/OpenMined/PySyft/pull/2982) that removes both of these classes. I'll leave this issue open until that PR gets merged, but probably not worth trying to fix the issue as described.",open class leave issue open probably worth trying fix issue,issue,negative,positive,neutral,neutral,positive,positive
604058133,"Is this issue still open? If yes, I can work on it.",issue still open yes work,issue,negative,neutral,neutral,neutral,neutral,neutral
603879917,Nothing major!! Go ahead  :+1: ,nothing major go ahead,issue,negative,positive,neutral,neutral,positive,positive
603871062,"@sukhadj @LaRiffle #2500 mentions implementing nn.Dropout class for PySyft.
https://github.com/OpenMined/PySyft/blob/0561a5d21c1787afeeb9753a0487f0c91d38a07d/syft/frameworks/torch/nn/rnn.py#L184
But this PR adds it to precision.py
In order to clean fixed_precision #<span/>2897 I will export dropout to nn (PR #<span/>3253) .
@sukhadj  Are there any catchs I should be familiar of ?",class order clean export dropout familiar,issue,negative,positive,positive,positive,positive,positive
603860028,I think the proposed feature is still useful.,think feature still useful,issue,negative,positive,positive,positive,positive,positive
603682418,"@LaRiffle Based on this [tutorial on Build your own tensor](https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/advanced/Build%20your%20own%20tensor%20type%20(advanced).ipynb) and your comment above 

> So actually once you are in Fixed-precision, you can't do anymore pow, exp, simoid, log, inversion the way you did previously, so you have to redefine them, and I'd say this is the good place.

I would let the above-mentioned functions be in precision.py
And all functions which are not specific to how we operate with FixedPrecisionTensor would be commented out/moved.",based tutorial build tensor comment actually ca pow log inversion way previously redefine say good place would let specific operate would,issue,negative,positive,positive,positive,positive,positive
603680756,"@LaRiffle @iamtrask  I would like to work on this. Two things I will try for a start are:
1. Comment out unnecessary functionalities in FixedPrecisionTensor. And make sure the rest of the code works.
2. Move conv2d implementation from FixedPrecisionTensor to torch.nn",would like work two try start comment unnecessary make sure rest code work move implementation,issue,positive,positive,neutral,neutral,positive,positive
603646781,@LaRiffle Please close this issue if it is resolved.,please close issue resolved,issue,negative,neutral,neutral,neutral,neutral,neutral
603645846,@iamtrask From the comments in #2498 it seems the BatchNorm bug was due to different versions. So you can close this issue if it is solved.,bug due different close issue,issue,negative,negative,neutral,neutral,negative,negative
603291867,It's automated to request Writing Team review when the translations change. 👍 ,request writing team review change,issue,negative,neutral,neutral,neutral,neutral,neutral
603241520,"> 
> Yes - the solution was the FL Optimizer project. We can close this issue.
> […](#)
> On Tue, Mar 17, 2020 at 12:49 PM Aditya Malte ***@***.***> wrote: Any solutions yet? — You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub <[#2070 (comment)](https://github.com/OpenMined/PySyft/issues/2070#issuecomment-600052348)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/ABBAZEQSAB62MQJMRJT2MQTRH5WW5ANCNFSM4HF52S2Q> .

Alright, I'll close the issue then",yes solution project close issue tue mar wrote yet reply directly view comment alright close issue,issue,positive,positive,neutral,neutral,positive,positive
603061344,"# [Codecov](https://codecov.io/gh/OpenMined/PySyft/pull/3191?src=pr&el=h1) Report
> Merging [#3191](https://codecov.io/gh/OpenMined/PySyft/pull/3191?src=pr&el=desc) into [master](https://codecov.io/gh/OpenMined/PySyft/commit/9e1bd4fee7ec766575d45f0f59b7806a733991b2&el=desc) will **decrease** coverage by `4.74%`.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/OpenMined/PySyft/pull/3191/graphs/tree.svg?width=650&height=150&src=pr&token=W0kQS1vaXB)](https://codecov.io/gh/OpenMined/PySyft/pull/3191?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master    #3191      +/-   ##
==========================================
- Coverage   99.30%   94.55%   -4.75%     
==========================================
  Files           4      146     +142     
  Lines        1866    15899   +14033     
==========================================
+ Hits         1853    15034   +13181     
- Misses         13      865     +852     
```


| [Impacted Files](https://codecov.io/gh/OpenMined/PySyft/pull/3191?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [syft/codes.py](https://codecov.io/gh/OpenMined/PySyft/pull/3191/diff?src=pr&el=tree#diff-c3lmdC9jb2Rlcy5weQ==) | `100.00% <ø> (ø)` | |
| [syft/common/util.py](https://codecov.io/gh/OpenMined/PySyft/pull/3191/diff?src=pr&el=tree#diff-c3lmdC9jb21tb24vdXRpbC5weQ==) | `95.00% <ø> (ø)` | |
| [syft/dependency\_check.py](https://codecov.io/gh/OpenMined/PySyft/pull/3191/diff?src=pr&el=tree#diff-c3lmdC9kZXBlbmRlbmN5X2NoZWNrLnB5) | `87.50% <ø> (ø)` | |
| [syft/exceptions.py](https://codecov.io/gh/OpenMined/PySyft/pull/3191/diff?src=pr&el=tree#diff-c3lmdC9leGNlcHRpb25zLnB5) | `77.35% <ø> (ø)` | |
| [syft/execution/action.py](https://codecov.io/gh/OpenMined/PySyft/pull/3191/diff?src=pr&el=tree#diff-c3lmdC9leGVjdXRpb24vYWN0aW9uLnB5) | `100.00% <ø> (ø)` | |
| [syft/execution/computation.py](https://codecov.io/gh/OpenMined/PySyft/pull/3191/diff?src=pr&el=tree#diff-c3lmdC9leGVjdXRpb24vY29tcHV0YXRpb24ucHk=) | `94.44% <ø> (ø)` | |
| [syft/execution/plan.py](https://codecov.io/gh/OpenMined/PySyft/pull/3191/diff?src=pr&el=tree#diff-c3lmdC9leGVjdXRpb24vcGxhbi5weQ==) | `89.88% <ø> (ø)` | |
| [syft/execution/protocol.py](https://codecov.io/gh/OpenMined/PySyft/pull/3191/diff?src=pr&el=tree#diff-c3lmdC9leGVjdXRpb24vcHJvdG9jb2wucHk=) | `88.02% <ø> (ø)` | |
| [syft/execution/state.py](https://codecov.io/gh/OpenMined/PySyft/pull/3191/diff?src=pr&el=tree#diff-c3lmdC9leGVjdXRpb24vc3RhdGUucHk=) | `91.15% <ø> (ø)` | |
| [syft/federated/federated\_client.py](https://codecov.io/gh/OpenMined/PySyft/pull/3191/diff?src=pr&el=tree#diff-c3lmdC9mZWRlcmF0ZWQvZmVkZXJhdGVkX2NsaWVudC5weQ==) | `95.32% <ø> (ø)` | |
| ... and [167 more](https://codecov.io/gh/OpenMined/PySyft/pull/3191/diff?src=pr&el=tree-more) | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/OpenMined/PySyft/pull/3191?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/OpenMined/PySyft/pull/3191?src=pr&el=footer). Last update [ba80473...6c61fc4](https://codecov.io/gh/OpenMined/PySyft/pull/3191?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",report master decrease coverage coverage impacted file tree graph coverage master coverage impacted coverage continue review full report legend click learn absolute relative impact affected missing data powered last update ba read comment,issue,negative,positive,neutral,neutral,positive,positive
603029904,If the review request here for writing team is not automated then I am sorry I must have clicked on the option by mistake.,review request writing team sorry must option mistake,issue,negative,negative,negative,negative,negative,negative
602939628,"@ratmcu I think my syft version is the old one , and I udpate it to the new version which use pytorch1.4.0 . This issue is solve .  Thanks for helping !",think version old one new version use issue solve thanks helping,issue,positive,positive,positive,positive,positive,positive
602724162,"@johnnylin110 what is the pytorch version you are using? Can you check your source to see if it is the same as I mentioned? [colab](https://colab.research.google.com/drive/1rJzcKscyZleiLxMH_mj7UIrGY1DgkXlI)  notebook here has the code, It runs on pytorch `'1.4.0'` ",version check source see notebook code,issue,negative,neutral,neutral,neutral,neutral,neutral
602679309,"If there is some workaround with the existing codebase please do mention. 
([You can find the current built-in here](https://github.com/OpenMined/PySyft/blob/master/syft/frameworks/torch/tensors/interpreters/additive_shared.py#L330))
Otherwise I would address this issue myself in #3242 ",please mention find current otherwise would address issue,issue,negative,neutral,neutral,neutral,neutral,neutral
602529400,"I would like to take up this issue, should we assign a new id to the objects before moving in such a way to avoid collision wrt the target worker and then move it.
can you assign this to me?",would like take issue assign new id moving way avoid collision target worker move assign,issue,negative,positive,positive,positive,positive,positive
602493996,"Hi,
    One other error I get when running the FL MINST example of the PyGrid.

Code:
data = my_grid.search(""#X"", ""#mnist"", ""#dataset"")
target = my_grid.search(""#Y"", ""#mnist"", ""#dataset"")

Error:

```
ValueError                                Traceback (most recent call last)
<ipython-input-5-111653e37eb8> in <module>
----> 1 data = my_grid.search(""#X"", ""#mnist"", ""#dataset"")
      2 target = my_grid.search(""#Y"", ""#mnist"", ""#dataset"")

~/anaconda3/envs/ipykernel_py3.7/lib/python3.7/site-packages/syft/grid/public_grid.py in search(self, *query)
     38         # Connect with grid nodes that contains the dataset and get their pointers
     39         tensor_results = {}
---> 40         for node_id, node_url in match_nodes:
     41             worker = self.__connect_with_node(node_id, node_url)
     42             tensor_results[node_id] = worker.search(query)

ValueError: too many values to unpack (expected 2)
```


Appreciate your help",hi one error get running example code data target error recent call last module data target search self query connect grid get worker query many unpack appreciate help,issue,negative,positive,positive,positive,positive,positive
602455061,"@ratmcu 
I use the code  above , and still this issue happen , can you please tell what your code is ?
Because in my code and the code above both get this problem , and when i change the net  without batchnorm2d , the error is gone . So I think this issue is still here , or someone can try it?",use code still issue happen please tell code code code get problem change net without error gone think issue still someone try,issue,negative,neutral,neutral,neutral,neutral,neutral
602434355,"I tried re creating this issue but it did not occur, So I dug a bit into the BatchNorm.

[here](https://github.com/pytorch/pytorch/blob/a6672f3b305c3805c691f3477e7940d146130a88/torch/nn/modules/batchnorm.py#L11) I could see these running statistics are being able to be registered as parameters or states. 
which extends to these lines if it is just a buffer
[def register_buffer(self, name, tensor):](https://github.com/pytorch/pytorch/blob/a6672f3b305c3805c691f3477e7940d146130a88/torch/nn/modules/module.py#L100)

But I suspect either way these are now taken care by syft in moving. 

So should we still look into this issue https://github.com/OpenMined/PySyft/issues/3236



",tried issue occur dug bit could see running statistic able registered buffer self name tensor suspect either way taken care moving still look issue,issue,negative,positive,positive,positive,positive,positive
602238237,"@karlhigley 
Thanks!
I'll translate Part 13  and make a pull request!",thanks translate part make pull request,issue,negative,positive,positive,positive,positive,positive
602236404,@MADONOKOUKI Many of the notebooks [have been translated](https://github.com/OpenMined/PySyft/pull/3182) by @kouohhashi and could use a review. The notebooks for Part 13 still need translation though!,many could use review part still need translation though,issue,negative,positive,positive,positive,positive,positive
602235244,"@iamtrask 
I'm Japanese. Therefore, this issue is ideal for me!
Is this issue applicable to the application of GSoC 2020?
I wanna try the different types of projects (Combine Federated Learning and SplitNN).
However, because others have already do it, I wanna do it for the application!",therefore issue ideal issue applicable application wan na try different combine learning however already wan na application,issue,positive,positive,positive,positive,positive,positive
602221912,The easiest way to collaborate is probably to push WIP code and work from a shared branch.,easiest way collaborate probably push code work branch,issue,negative,neutral,neutral,neutral,neutral,neutral
602220904,@karlhigley @Kritikalcoder looks like this issue isn't ready to be worked on yet. see https://github.com/OpenMined/PySyft/issues/1824 and in particular issue https://github.com/OpenMined/PySyft/issues/1932 ,like issue ready worked yet see particular issue,issue,positive,positive,positive,positive,positive,positive
602214448,@Prtfw is probably the most knowledgeable about where we are with demos. Thoughts on whether/how to tackle this @Prtfw?,probably knowledgeable demo tackle,issue,negative,neutral,neutral,neutral,neutral,neutral
602152965,Please always use other than your master branch for creating PR,please always use master branch,issue,negative,neutral,neutral,neutral,neutral,neutral
602141010,"# [Codecov](https://codecov.io/gh/OpenMined/PySyft/pull/3234?src=pr&el=h1) Report
> :exclamation: No coverage uploaded for pull request base (`master@6357bb6`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).
> The diff coverage is `97.82%`.

[![Impacted file tree graph](https://codecov.io/gh/OpenMined/PySyft/pull/3234/graphs/tree.svg?width=650&token=W0kQS1vaXB&height=150&src=pr)](https://codecov.io/gh/OpenMined/PySyft/pull/3234?src=pr&el=tree)

```diff
@@            Coverage Diff            @@
##             master    #3234   +/-   ##
=========================================
  Coverage          ?   94.54%           
=========================================
  Files             ?      146           
  Lines             ?    15920           
  Branches          ?        0           
=========================================
  Hits              ?    15052           
  Misses            ?      868           
  Partials          ?        0
```


| [Impacted Files](https://codecov.io/gh/OpenMined/PySyft/pull/3234?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [test/torch/tensors/test\_paillier.py](https://codecov.io/gh/OpenMined/PySyft/pull/3234/diff?src=pr&el=tree#diff-dGVzdC90b3JjaC90ZW5zb3JzL3Rlc3RfcGFpbGxpZXIucHk=) | `100% <100%> (ø)` | |
| [test/torch/tensors/test\_native.py](https://codecov.io/gh/OpenMined/PySyft/pull/3234/diff?src=pr&el=tree#diff-dGVzdC90b3JjaC90ZW5zb3JzL3Rlc3RfbmF0aXZlLnB5) | `100% <100%> (ø)` | |
| [...ft/frameworks/torch/tensors/interpreters/native.py](https://codecov.io/gh/OpenMined/PySyft/pull/3234/diff?src=pr&el=tree#diff-c3lmdC9mcmFtZXdvcmtzL3RvcmNoL3RlbnNvcnMvaW50ZXJwcmV0ZXJzL25hdGl2ZS5weQ==) | `91.06% <93.75%> (ø)` | |
",report exclamation coverage pull request base master click learn coverage impacted file tree graph coverage master coverage impacted coverage,issue,negative,negative,negative,negative,negative,negative
602140345,"I would like to work on this. 
@codeboy5 you can ping me over Slack for Colab as @Syzygianinfern0",would like work ping slack,issue,negative,neutral,neutral,neutral,neutral,neutral
602126007,"@iamtrask @karlhigley , I am new to Syft so can you please guide me where in the code base should I start to look for relevant code to the related issue. Thank you ",new please guide code base start look relevant code related issue thank,issue,positive,negative,neutral,neutral,negative,negative
602101763,@karlhigley Can I work on this issue as well. I have already worked on a use case similar. So we can collaboratively solve this. ,work issue well already worked use case similar collaboratively solve,issue,negative,neutral,neutral,neutral,neutral,neutral
602098844,"hey @LaRiffle 
I was thinking something along these lines , I might be wrong
```python
def softmax(self , dim ):
        """"""calculate the softmax along a given dimension
        """"""
        max_val = self.max(dim, keepdim=True)[0]  # pick the first 
        
        logit = self - max_val
        
        num = logit.exp()
 
        inv = num.sum(dim, keepdim=True)
        
        # generate one
        one = inv * 0 + 1
        
        result = one / inv

        return num * result
```
Could you help me , I just want to make sure I'm going in the right direction.
I think we need an approx reciprocal in this case in my opinion.",hey thinking something along might wrong python self dim calculate along given dimension dim pick first self dim generate one one result one return result could help want make sure going right direction think need reciprocal case opinion,issue,negative,positive,positive,positive,positive,positive
602090675,Let's run for this one then 🚀 ,let run one rocket,issue,negative,neutral,neutral,neutral,neutral,neutral
602088726,Which one would you think is the most classic in classification? :),one would think classic classification,issue,negative,positive,positive,positive,positive,positive
602088028,"Hi, @LaRiffle are we looking for Cross Entry Loss (https://pytorch.org/docs/stable/nn.html#crossentropyloss) or NLL Loss (https://pytorch.org/docs/stable/nn.html#nllloss)? 
A slight difference between the two as Cross-Entropy combines softmax and NLL. I can implement both of these if you would like that?",hi looking cross entry loss loss slight difference two implement would like,issue,negative,negative,neutral,neutral,negative,negative
602077624,Assigned you both. Hope that whoever starts working on it first can post a WIP PR with their early commits so you can collaborate on it.,assigned hope whoever working first post early collaborate,issue,negative,positive,positive,positive,positive,positive
602069639,"So the answer here is that BatchNormalization has internal statistics (means and stds, etc.) which themselves contain private information but are not parameters. 

This means that when you move a model from one machine to another (iterating through model.parameters()), those statistics probably aren't moving with it. 

Solution: extend nn.Module() with a .parameters_and_statistics() iterator which will look for this kind of information so that we can make sure that federated learning properly moves everything from machien to machine.",answer internal statistic contain private information move model one machine another statistic probably moving solution extend look kind information make sure learning properly everything machine,issue,positive,positive,positive,positive,positive,positive
602062225,"Is this bug solve? I have the same problem
even use the pytorch resnet (model= torchvision.models.resnet34(pretrained=False).to(device))can't train 
",bug solve problem even use device ca train,issue,negative,neutral,neutral,neutral,neutral,neutral
602059354,"I would like to take up this issue, can you assign this to me?",would like take issue assign,issue,negative,neutral,neutral,neutral,neutral,neutral
602033868,Hey @BBloggsbott the messages in Slack are temporary. Could you post it here / message me on Slack so I could take a look,hey slack temporary could post message slack could take look,issue,negative,neutral,neutral,neutral,neutral,neutral
601946742,"Thanks @karlhigley, v0.2.4 seems to work. Thanks a lot for the help.",thanks work thanks lot help,issue,positive,positive,positive,positive,positive,positive
601941135,"Well that's interesting it's failing for `test/crypto/test_snn->test_share_convert` on 3.7. It's passing that test every time on local though. 
[UPDATE] Ran it in a loop 100 times and it failed 9 times by causing assertion error getting answer only for value 2**60 off in range +-10.
[UPDATE 2] It is failing for large values for both dtypes, Like 2^60 for long and 2^30 for int
[UPDATE 3[ Ok, I am missing something major here as it's not working for negative values at all. Always giving 1 more than expected result for negative numbers.
I will investigate it further. (Nice catch by github actions :+1:)

As for the other test `test/serde/protobuf/test_protobuf_serde_full.py::test_serde_roundtrip_protobuf[AdditiveSharingTensor]` I think it is dependent on merge of this [PR](https://github.com/OpenMined/syft-proto/pull/48).",well interesting failing passing test every time local though update ran loop time time causing assertion error getting answer value range update failing large like long update missing something major working negative always giving result negative investigate nice catch test think dependent merge,issue,negative,positive,neutral,neutral,positive,positive
601818317,"> > @codeboy5 and those interested please join the [Openmined Slack](https://openmined.slack.com/messages/team_pysyft), and contact me over there (username Benardi Nunes).
> 
> @theparanoidprogrammer

Thanks :) just joined",interested please join slack contact thanks,issue,positive,positive,positive,positive,positive,positive
601793805,"> @codeboy5 and those interested please join the [Openmined Slack](https://openmined.slack.com/messages/team_pysyft), and contact me over there (username Benardi Nunes).

@theparanoidprogrammer ",interested please join slack contact,issue,positive,positive,positive,positive,positive,positive
601772485,"Hello @Benardi . Im currently a Computer Science Junior at LUMS Pakistan. I have experience with Deep Learning,and network Security. I would love to work on this project. Looking forward to being guided by you. Can you please give me an invite link to the Slack platform. Thanks.",hello currently computer science junior experience deep learning network security would love work project looking forward please give invite link slack platform thanks,issue,positive,positive,positive,positive,positive,positive
601770754,"Hi @Benardi 

> Benardi Nunes

Its asking for a username and password. I dont have an account in that workspace, can you send an invite link please. Thanks.
",hi password dont account send invite link please thanks,issue,positive,positive,positive,positive,positive,positive
601700408,"> Don't forget to add a test:
> 
>     * at training you might just want to show the signal decrease
> 
>     * at testing just show the signal is unchanged

Done.
This test just checks if dropout has filtered out some inputs.
A more robust check would be comparing `(num_of_inputs_filtered / input_size)` to p. The first vale is close to p. So should we put a threshold on `((num_of_inputs_filtered / input_size) - p)` ? Thoughts on this?",forget add test training might want show signal decrease testing show signal unchanged done test dropout robust check would first vale close put threshold,issue,negative,positive,positive,positive,positive,positive
601620863,"_(Maybe not the good place but this a feedback I just got)_
**For Windows Users**
Install Microsoft VIsual C++ 14.0 first helps a lot",maybe good place feedback got install visual first lot,issue,negative,positive,positive,positive,positive,positive
601594494,"Hi @youben11, I believe this project is available for GSoC, I know I'm a little late but I would like to ask if this one is already assigned, because I'm interested in working on this one.",hi believe project available know little late would like ask one already assigned interested working one,issue,positive,positive,neutral,neutral,positive,positive
601268124,"I followed the installation.md for windows 
I only needed to change installation part of torch as below:

pip install torch===1.4.0 torchvision===0.5.0 -f https://download.pytorch.org/whl/torch_stable.html

It worked.
Thank you for help
",change installation part torch pip install worked thank help,issue,positive,neutral,neutral,neutral,neutral,neutral
601253354,"@suhacker1 We're in the process of migrating from msgpack to Protobuf in part to improve performance, so optimizing msgpack might not make sense any more. Happy to help you get started working on Protobuf if you want though.",process part improve performance might make sense happy help get working want though,issue,positive,positive,positive,positive,positive,positive
600796875,"Hey @ERICPENGZ 
I could not reproduce your problem. I ran the following commands in a docker container and everything worked fine:
python start_websocket_servers.py
python run_websocket_client.py

Could you try to pull the latest master and retest?",hey could reproduce problem ran following docker container everything worked fine python python could try pull latest master retest,issue,negative,positive,positive,positive,positive,positive
600708313,"@eceisik @rimijoker Just released v0.2.4, which should address this issue. Let me know if upgrading works for you!",address issue let know work,issue,negative,neutral,neutral,neutral,neutral,neutral
600667370,"@ADMoreau Are you still working on this?
@iamtrask is this still relevant?",still working still relevant,issue,negative,positive,positive,positive,positive,positive
600632982,"Ah, okay! That's from a few weeks ago, before v0.2.3 was released. I'm about to release v0.2.4 in the next day or two, so you can do one of these things:
* Update your master branch to the latest commit on the main repo (currently `784cd9df`)
* Install v0.2.3 (and the corresponding version of `syft-proto` listed in the requirements file)
* Install v0.2.4 (once it's released)

The zstd dependency has been removed and should no longer be needed in v0.2.4.",ah ago release next day two one update master branch latest commit main currently install corresponding version listed file install dependency removed longer,issue,negative,positive,positive,positive,positive,positive
600616247,"We've had it on the Syft Core board ever since, and decided yesterday that it makes sense to tackle it with @iamtrask's work on the longer-term future of tensor types as part of v0.4. (Meanwhile, the rest of us are mostly working on sorting out remote execution for v0.3.)",core board ever since decided yesterday sense tackle work future tensor part meanwhile rest u mostly working remote execution,issue,negative,positive,positive,positive,positive,positive
600615923,"> These description / docstring don't seem correct

Hey, can you point out which docstring seems incorrect? @LaRiffle ",description seem correct hey point incorrect,issue,negative,neutral,neutral,neutral,neutral,neutral
600542351,Could you give a link please?,could give link please,issue,negative,neutral,neutral,neutral,neutral,neutral
600502205,"Yes - the solution was the FL Optimizer project. We can close this issue.

On Tue, Mar 17, 2020 at 12:49 PM Aditya Malte <notifications@github.com>
wrote:

> Any solutions yet?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/2070#issuecomment-600052348>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ABBAZEQSAB62MQJMRJT2MQTRH5WW5ANCNFSM4HF52S2Q>
> .
>
",yes solution project close issue tue mar wrote yet reply directly view,issue,positive,positive,neutral,neutral,positive,positive
600470554,"Hi @H4LL , 

I'm Siddharth Garg, a Computer Science Sophomore from VIT University (Institute of Eminence), India. I am interning as a Computer Vision Engineer at FindMind Analytics. I have a specialization in Deep Learning from deeplearning.ai. As well as a professional certification from IBM in Applied AI. I have worked with Python, PyTorch, Tensorflow and a few other deep learning libraries.  

I would like to contribute to this project as part of the GSoC. Can you help me out in getting started?
",hi computer science sophomore university institute eminence computer vision engineer analytics specialization deep learning well professional certification applied ai worked python deep learning would like contribute project part help getting,issue,positive,positive,neutral,neutral,positive,positive
600384943,"@karlhigley I have **commit 7d61c7** on my master branch. Previously, I wrote a simple article for installing pysfyt and get get rid of zstd error [(here)](https://medium.com/secure-and-private-ai-writing-challenge/installing-pysyft-package-ffa1ff0ad83c), but that doesn't seem to work now.",commit master branch previously wrote simple article get get rid error seem work,issue,negative,negative,neutral,neutral,negative,negative
600338345,"My last interrogations are linked to:

https://github.com/OpenMined/PySyft/pull/3083/files?file-filters%5B%5D=.py#r393791192
I need for move not to delete the object but I hardly see how to know when to delete or not. My main concern here is with stale pointers. Id'd rather be conservative on the deletion

https://github.com/OpenMined/PySyft/pull/3083/files?file-filters%5B%5D=.py#r393797731
I don't have an elegant name for move which keeps a local copy. I've added a comment in the docstring to underline this behaviour and why it is here (to mimic .send() behaviour), but I'm happy to continue discussion about this in this PR or in another one",last linked need move delete object hardly see know delete main concern stale id rather conservative deletion elegant name move local copy added comment underline behaviour mimic behaviour happy continue discussion another one,issue,positive,positive,neutral,neutral,positive,positive
600298278,"Hi, what is the movement like on this issue? Could there be an elaboration on the potential use-cases? For instance, is ZK to be used wrt to MPC protocols? Is one to use interactive challenges or SNARKs? Or is this meant to be a standalone system for delegated computing? What are the design goals? For instance, ZK could introduce about ~1000x computational overhead, although for good schemes, communication and verification could be cheap. 

I am not convinced this could gel well with GPU computations, since one requires to store and encode all the intermediate values of a computation, unless the entire ZKP encoding and proving was performed simultaneously on GPU.",hi movement like issue could elaboration potential instance used one use interactive meant system design instance could introduce computational overhead although good communication verification could cheap convinced could gel well since one store encode intermediate computation unless entire proving simultaneously,issue,positive,positive,positive,positive,positive,positive
600271541,"Hahah this issue was created by **frustration**! :D
But I agree so much with you!",issue frustration agree much,issue,negative,positive,positive,positive,positive,positive
600218833,"I have installed gcc using conda and updated it to 4.8 but things did work on MacOS Mojave 10.14.6.

The solution mentioned by in  [#python-zstd](https://github.com/sergey-dryabzhinsky/python-zstd/issues/33#issuecomment-527252753) and @guptakhil12 works for me with a little modification. You just need to install the gcc using brew (if not installed) before exporting the new path. 
Following are the steps that should do the trick.

1.  Install gcc using brew 
   `brew install gcc`

2. Change the gcc-version to a recent the one installed by brew:
    `export CC=/usr/local/Cellar/gcc/9.3.0/bin/gcc-9` (**Note:** Check your gcc-version in this location before using the command)
    `export CFLAGS=""-Wa,-q""`

3. Install zstd using pip.
   `pip install zstd` (This should work now)

4. Install pysyft.
   `pip install syft[udacity]`
",work solution work little modification need install brew new path following trick install brew brew install change recent one brew export note check location command export install pip pip install work install pip install,issue,negative,negative,neutral,neutral,negative,negative
600144632,"notebook requires tornado >= 5.0, downgrading makes jupyter notebooks working badly (like not showing notebooks)",notebook tornado working badly like showing,issue,negative,negative,negative,negative,negative,negative
600125777,We'll need to release a new version to address that. Coming soon!,need release new version address coming soon,issue,negative,positive,positive,positive,positive,positive
600098750,Fixed in master and should work in the next release.,fixed master work next release,issue,negative,positive,neutral,neutral,positive,positive
600094711,"@eceisik Please follow this INSTALLATION.md, that should fix the issue for you.
This would be fixed with a version update, so in the next version of syft it should work fine.",please follow fix issue would fixed version update next version work fine,issue,negative,positive,positive,positive,positive,positive
600063772,@Dhrumilsoni I have tried with the master and I think the bug has been fixed and it works now. ,tried master think bug fixed work,issue,negative,positive,neutral,neutral,positive,positive
600005104,"That method is similar but it's on the worker. We need am method on a
PointerTensor :)

On Sat, Mar 14, 2020 at 12:13 PM Sachin Kumar <notifications@github.com>
wrote:

> I went through the code and found a method similar to the one mentioned by
> you.
> Link:
> https://github.com/OpenMined/PySyft/blob/0561a5d21c1787afeeb9753a0487f0c91d38a07d/syft/generic/object_storage.py#L93
> I also noticed that this issue occurs while working in jupyter notebook.
> So, if you need any more functionalities to be implemented, let me know.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/2448#issuecomment-599049851>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ABBAZER3J74W5U7PUYMV6LTRHNYE3ANCNFSM4IKCFPJA>
> .
>
",method similar worker need method sat mar wrote went code found method similar one link also issue working notebook need let know reply directly view,issue,negative,positive,neutral,neutral,positive,positive
599923876,@LaRiffle Can you please review the above issue. And provide me some advice so that I will try solving it.,please review issue provide advice try,issue,negative,neutral,neutral,neutral,neutral,neutral
599811405,Something went really bad...,something went really bad,issue,negative,negative,negative,negative,negative,negative
599537487,Oh. I didn't see that someone was already working on it.,oh see someone already working,issue,negative,neutral,neutral,neutral,neutral,neutral
599274730,"Yeah, I'm not so sure either. Possible that they could share an underlying implementation?",yeah sure either possible could share underlying implementation,issue,positive,positive,positive,positive,positive,positive
599246890,"@imskr There's already [a PR for it](https://github.com/OpenMined/PySyft/pull/2949), which I've been holding off on merging until I get a better handle on how we want to do versioning across the various Syft repos.",already holding get better handle want across various,issue,negative,positive,positive,positive,positive,positive
599246099,"@karlhigley I would like to work on this, if no one is working. ",would like work one working,issue,negative,neutral,neutral,neutral,neutral,neutral
599242587,"@tudorcebere Looks good, but seems like this PR picked up some `Plan` changes somehow. Are those supposed to be in this PR?",good like picked plan somehow supposed,issue,positive,positive,positive,positive,positive,positive
599242380,"@tudorcebere Looks like this has a minor formatting issue! You can fix it by running `black .` in the root directory of the repo. Also highly recommend [installing the commit hooks](https://github.com/OpenMined/PySyft/blob/master/CONTRIBUTING.md#setting-up-pre-commit-hook), which will handle this for you in the future.",like minor issue fix running black root directory also highly recommend commit handle future,issue,positive,negative,neutral,neutral,negative,negative
599227785,"@karlhigley , I created this class for arbitrarily creating or calling an optimizer relevant to a model trained in a federated setting. I would like to add any good features from it to the code base with further developments if needed.",class arbitrarily calling relevant model trained setting would like add good code base,issue,positive,positive,neutral,neutral,positive,positive
599218306,Duplicate of #3179. Might be worth reviewing #3179 and checking if there aspects from this PR that could be added to that code.,duplicate might worth could added code,issue,negative,positive,positive,positive,positive,positive
599210570,Last thing is to update the requirements file to point at a new `syft-proto` release (once there is one.),last thing update file point new release one,issue,negative,positive,neutral,neutral,positive,positive
599143543,"Hi Adam, @H4LL

I'm Hazem Essam, I'm a Computer Science student at Arab Academy for Science, Technology and Maritime Transport, I would like to be considered for this project in GSoC. I have experience with Deep Learning, Federated Learning, Pytorch and TensorFlow and I took the Secure and Private AI course on Udacity.

I would like to start working on the project. Do you have any suggestions on how to get started? I hope to contribute and get selected in the project, I can send you my resume if you need it, ",hi computer science student academy science technology maritime transport would like considered project experience deep learning learning took secure private ai course would like start working project get hope contribute get selected project send resume need,issue,positive,positive,positive,positive,positive,positive
599135708,"""Hide deleted files"" in the file filter is definitely your friend on this one. 😄 ",hide file filter definitely friend one,issue,positive,neutral,neutral,neutral,neutral,neutral
599132654,https://github.com/OpenMined/PySyft/pull/3158 this is super relevant for this project ;). If you're interested in this project it would be great getting familiar with these changes.,super relevant project interested project would great getting familiar,issue,positive,positive,positive,positive,positive,positive
599106963,"I think we should mention that you can install tf_encrypted using req_udacity.txt in the pip-dep folder, should I make changes in the INSTALLATION.md?",think mention install folder make,issue,negative,neutral,neutral,neutral,neutral,neutral
599082851,"Anyone can work on this issue. @sachin-101 it looks like no-one has begun work. Feel free to jump in.

In the future it's better to simply say ""I'm working on it"" and then immediately create a 'work in progress"" PR so we can see your current status. This also allows people to collaborate with you.",anyone work issue like begun work feel free jump future better simply say working immediately create progress see current status also people collaborate,issue,positive,positive,positive,positive,positive,positive
599049892,"Hi @gmuraru, after following this it works fine. 

> It looks like that code was deprecated and later removed in #476, which [suggests](https://github.com/OpenMined/PyGrid/commit/2b543d075b86a6846d815ab5bdba45b551f48654#diff-b1ef8a3aed029ba9fb6663df43b6c7daL16) using PySyft's `syft.grid` module instead.
",hi following work fine like code later removed module instead,issue,positive,positive,positive,positive,positive,positive
599049851,"I went through the code and found a method similar to the one mentioned by you. 
https://github.com/OpenMined/PySyft/blob/0561a5d21c1787afeeb9753a0487f0c91d38a07d/syft/generic/object_storage.py#L93
I also noticed that this issue occurs while working in jupyter notebook. So, if you need any more functionalities to be implemented, let me know.",went code found method similar one also issue working notebook need let know,issue,negative,neutral,neutral,neutral,neutral,neutral
599023012,"Hi @LaRiffle 
Please review the above PR. And let me know, If I need to make any further changes.",hi please review let know need make,issue,negative,neutral,neutral,neutral,neutral,neutral
599018871,"I think udacity command also installs `tf_encrypted` besides core requirements.
That I think you can manually install in my opinion.",think command also besides core think manually install opinion,issue,negative,neutral,neutral,neutral,neutral,neutral
599018436,"Were you able to install PySyft or not ?
If not then just try running
`python setup.py install`",able install try running python install,issue,negative,positive,positive,positive,positive,positive
598815651,"Hi, @TemitopeOladokun nice work! do you know anyone who knows Pidgin & can review the PR? ",hi nice work know anyone pidgin review,issue,negative,positive,positive,positive,positive,positive
598512280,"@iamtrask I added the class and Changed the Notebook to use it. 
3.7 Tutorials are failing here on the test 
`test/notebooks/test_notebooks.py::test_notebooks_basic[examples/tutorials/Part 12 bis - Encrypted Training on MNIST.ipynb] FAILED [ 52%]`
",added class notebook use failing test bi training,issue,negative,neutral,neutral,neutral,neutral,neutral
598490142,"How can I avoid timeout error?
it looks like timeout=300 may not be big enough for Part 06.

I changed epoch count from 10 to 2 to avoid timeout error.
Is it okay?",avoid error like may big enough part epoch count avoid error,issue,negative,neutral,neutral,neutral,neutral,neutral
598428834,Done. Please let me know if have any further questions. @H4LL ,done please let know,issue,negative,neutral,neutral,neutral,neutral,neutral
598286934,@iamtrask I would like to work on translation to Tamil.,would like work translation,issue,negative,neutral,neutral,neutral,neutral,neutral
598202372,You can see the error logs on the “Checks” tab. Looks like an “invalid character in identifier” error and maybe a few other things.,see error tab like invalid character identifier error maybe,issue,negative,neutral,neutral,neutral,neutral,neutral
598139883,"Hey, yes.
Thank you very much

On Thu, 12 Mar 2020 at 12:34, George-Cristian Muraru <
notifications@github.com> wrote:

> Hey @ZumrutMuftuoglu <https://github.com/ZumrutMuftuoglu>. Are you still
> working on this?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/pull/3126#issuecomment-598091609>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AIREAV5LA5KXCEZRSYWYPIDRHCUDHANCNFSM4K7IMXNQ>
> .
>
",hey yes thank much mar wrote hey still working reply directly view,issue,positive,positive,positive,positive,positive,positive
598130887,"I have realized that the value of `binary` as the input of `simple_objects = msgpack_lib.loads(binary, use_list=False)` is encoded as `windows-1252` (which is expected to be `utf-8`), and that is the reason it is unable to decode with `utf-8`. I am not sure but the reason might be the fact that I use the three different Ubuntu virtual machines (one server and two workers) on top of my `Windows` operating system. Once I run it on an Ubuntu machine (server) with two other Ubuntu virtual machines (workers) on top of it, then it works fine.",value binary input binary reason unable decode sure reason might fact use three different virtual one server two top operating system run machine server two virtual top work fine,issue,positive,positive,positive,positive,positive,positive
598116039,"@imraniac updated accordingly, still doesn't work, the error occurs",accordingly still work error,issue,negative,neutral,neutral,neutral,neutral,neutral
598097613,@imskr could you update the issue description,could update issue description,issue,negative,neutral,neutral,neutral,neutral,neutral
598089741,"will close this one since we will use tags for retrieving data.
LE: Sorry, do not know what was in my head...the end goal was to have a more CrypTen like API, with only tag and rank",close one since use data sorry know head end goal like tag rank,issue,negative,negative,negative,negative,negative,negative
598088468,"Tried the code @LaRiffle used in the description:
```
me.get_obj(x.id)
```
Gives back: ```tensor([1.])``` so I think we can close this one.

@datason thank you for offering to solve this issue :)
",tried code used description back tensor think close one thank offering solve issue,issue,positive,neutral,neutral,neutral,neutral,neutral
597920264,Kindly merge this pull request ,kindly merge pull request,issue,negative,positive,positive,positive,positive,positive
597891859,"@imraniac Oh shoot, i only added this as an example and didnt see that. Regardless, the error still comes up, ive updated the issue accordingly",oh shoot added example didnt see regardless error still come issue accordingly,issue,negative,neutral,neutral,neutral,neutral,neutral
597885035,"@avinath1998 If you are trying to change the whole **model.classifier** block, then your input dimension (which you put 2) is wrong. The input dimension of **model.classifier** should be 256x6x6.
refer: https://github.com/pytorch/vision/blob/master/torchvision/models/alexnet.py

```
self.classifier = nn.Sequential(
            nn.Dropout(),
            nn.Linear(256 * 6 * 6, 4096),
            nn.ReLU(inplace=True),
            nn.Dropout(),
            nn.Linear(4096, 4096),
            nn.ReLU(inplace=True),
            nn.Linear(4096, num_classes),
        )
```",trying change whole block input dimension put wrong input dimension refer,issue,negative,negative,negative,negative,negative,negative
597788734,"I developed this class for the FLOptimizer,
It worked on the example in the tutorial, I couldn't elegantly get around sending arbitrary amount of arguments, may be it would be good to inherit from this class and create a new class for each optimizer, I hopewe can keep this and smooth passing of the cached averages between workers as TODOs. 
```
model = nn.Linear(2,1)
from torch import optim
class FLOptimier():
    # def __init__(self, optimizer_class, **kwargs):
    def __init__(self, optimizer_class, lr = 0.1):
        self.optimizer_class = optimizer_class
        self.opt_dict = defaultdict()
        # self.kwargs = kwargs
        self.lr = lr
    def get_optimizer(self, model):
        if hasattr(model, 'location'):
            opt = self.opt_dict.setdefault(model.location, self.optimizer_class(model.parameters(), lr = self.lr)) 
            # opt.step()
            return opt
        opt = self.opt_dict.setdefault('central', self.optimizer_class(model.parameters(), lr = self.lr)) 
        return opt
def train():
    # Training Logic
    fl_opt = FLOptimier(optim.Adam, lr=0.1)
    loc  = ''
    for iter in range(10):        
        # NEW) iterate through each worker's dataset
        for data,target in datasets:
            
            # NEW) send model to correct worker
            model.send(data.location)
            # if data.location == bob:
            #     opt = opt_bob
            # if data.location == alice:
            #     opt = opt_alice
            opt = fl_opt.get_optimizer(model)
            # 1) erase previous gradients (if they exist)
            opt.zero_grad()
            # 2) make a prediction
            pred = model(data)
            # 3) calculate how much we missed
            loss = ((pred - target)**2).sum()
            # 4) figure out which weights caused us to miss
            loss.backward()
            # 5) change those weights
            opt.step()
            
            # NEW) get model (with gradients)
            model.get()
            # opt.set_new_params(model.parameters())
            # 6) print our progress
            print(loss.get()) # NEW) slight edit... need to call .get() on loss\
# federated averaging
train()
```
also where can a class like this go in the PySyFt?",class worked example tutorial could elegantly get around sending arbitrary amount may would good inherit class create new class keep smooth passing model torch import class self self self model model opt return opt opt return opt train training logic iter range new iterate worker data target new send model correct worker bob opt opt opt model erase previous exist make prediction model data calculate much loss target figure u miss change new get model print progress print new slight edit need call train also class like go,issue,positive,positive,positive,positive,positive,positive
597762952,I would like to add this feature. @iamtrask ,would like add feature,issue,negative,neutral,neutral,neutral,neutral,neutral
597762308,"@gmuraru @LaRiffle 
Is this issue valid?
I am going to solve if yes)",issue valid going solve yes,issue,positive,neutral,neutral,neutral,neutral,neutral
597724132,"I completely revised the translation, which was basically vanilla Google Translate. Although I truly appreciate the work to translate these notebooks, the translation should be performed by someone proficient both in the language and in the library, otherwise we're not really helping anyone. I'd be happy to have another native speaker help out and agree on common terminology (pointers, privacy-preserving AI etc.).",completely translation basically vanilla translate although truly appreciate work translate translation someone proficient language library otherwise really helping anyone happy another native speaker help agree common terminology ai,issue,positive,positive,positive,positive,positive,positive
597717215,"Thanks for the feedback and sorry for the delayed fix. 
",thanks feedback sorry fix,issue,negative,negative,negative,negative,negative,negative
597709496,"Hey @haofanwang, this is a really promising start. I think we still need to work on the narrative and refactor the code to fit this functionality inside the SplitNN class. The idea is we want to be able to use this almost identically to how we would a conventional neural network. Let's work together on slack to make it just right 
",hey really promising start think still need work narrative code fit functionality inside class idea want able use almost identically would conventional neural network let work together slack make right,issue,positive,positive,positive,positive,positive,positive
597635816,"> There are 476 file changes? Is this right? 😮

I don't mess around ",file right mess around,issue,negative,positive,neutral,neutral,positive,positive
597424874,@JulianSprung I am currently a beginner in German. I will fix all of this mentioned in all tutorials.,currently beginner german fix,issue,negative,neutral,neutral,neutral,neutral,neutral
597338200,"Hey @haofanwang  thanks for the tutorial update. It's a great start! however I think the following would be great;

- Instead of concatenating the two images it would be good to split a single image (I don't think the two image option is as intuitive)
- In order to make this scale for an arbitrary number of vertical splits then the vertical split layer should be in its own array; [[a_1],[a_2],[b]]. We can then write loops to deal with these arrays for any number of horizontal/ veritical splits. It also makes the models object slightly cleaner as models get more complex (there is an implicit structure int the model array).
- In the description on what's going on in vertically split training environment you mention the different images as different modalities. This is great and accurate but is maybe not colourful enough to make it as clear as it could be at a glance. It might be good to also describe a real-world use-case to tell more of a story/ capture peoples imagination.

overall I'm super impressed with this, great effort!",hey thanks tutorial update great start however think following would great instead two would good split single image think two image option intuitive order make scale arbitrary number vertical vertical split layer array write deal number also object slightly cleaner get complex implicit structure model array description going vertically split training environment mention different different great accurate maybe enough make clear could glance might good also describe tell capture imagination overall super great effort,issue,positive,positive,positive,positive,positive,positive
597170168,"Hi, I have installed `msgpack 1.0.0`, but still got error, once trying to `loss.get()`. I have my workers on different machines. 
",hi still got error trying different,issue,negative,neutral,neutral,neutral,neutral,neutral
597084250,"This is a real problem, but it turns out that the affected notebooks would still be broken for other reasons.",real problem turn affected would still broken,issue,negative,negative,neutral,neutral,negative,negative
596796906,"Hi, @LaRiffle. I have added more descriptions and comments in the notebook. This notebook follows the style of the previous ones (tutorial 2 & 3) and is a supplement of tutorial series for SplitNN. The concept of SplitNN and its pros & cons have been described (tutorial 1). 

To be consistent with existing tutorials, you can merge this first (as I hope to mention this PR in my proposal for GSoC:D). I will update all tutorials together using the new syntax once your PR has been merged. Thanks.",hi added notebook notebook style previous tutorial supplement tutorial series concept tutorial consistent merge first hope mention proposal update together new syntax thanks,issue,positive,positive,positive,positive,positive,positive
596672507,"We do try to use the assignment system to signal that an issue has been claimed. It's just that sometimes we assign an issue and whoever has claimed it gets busy with other things and never pushes code. It's not uncommon for an issue to be assigned to 2 or 3 people in sequence and still never end up with a PR. So, we tend to err on the side of having too many people working on something than too few.

If you want to signal to people that you're already working on something, the best way is to show your progress in a WIP or draft PR. That also opens it up for other people to build on your work or collaborate with you. 🤷‍♂ ",try use assignment system signal issue sometimes assign issue whoever busy never code uncommon issue assigned people sequence still never end tend err side many people working something want signal people already working something best way show progress draft also people build work collaborate,issue,positive,positive,positive,positive,positive,positive
596665546,"@karlhigley then why there is a system which assigns to some one. If you could have told this well before, I wouldn't have waited. I could've started working on the day I requested. ",system one could told well would could working day,issue,negative,neutral,neutral,neutral,neutral,neutral
596656961,Could whoever has code (even if it's partial or not working yet) push a WIP PR and link it to this issue? It's hard for the maintainers to tell whether people are still working on something unless we can see code being written. 😄 ,could whoever code even partial working yet push link issue hard tell whether people still working something unless see code written,issue,negative,negative,negative,negative,negative,negative
596642350,@vineeth14 .. I am working on it .. please take some other issue. ,working please take issue,issue,negative,neutral,neutral,neutral,neutral,neutral
596639863,"@LaRiffle Yeah, the actions in `Plans` can only be `ComputationActions`. That restriction is captured [in the type annotations in `__init__()`](https://github.com/OpenMined/PySyft/pull/3132/files#diff-df3ce31527cd05c4bf6283bf594bde03R99), but I didn't want to make the name of the property super-long and inconvenient.

I suppose we could also build in a guard clause that would prevent other types from being passed in as actions or something. 🤔 ",yeah restriction type want make name property inconvenient suppose could also build guard clause would prevent something,issue,negative,negative,negative,negative,negative,negative
596624225,"Hey, I'd love to work on this issue",hey love work issue,issue,positive,positive,positive,positive,positive,positive
596590748,Before merging - would you be willing to add a bit more explanation in the notebook about SplitNN and the code you've written?,would willing add bit explanation notebook code written,issue,negative,positive,positive,positive,positive,positive
596545670,"I was working on it and had many issues that would have been resolved over time, so I postponed the work for later but couldn't get back till now. Nothing that works, only a dirty branch [here](https://github.com/youben11/PySyft/tree/pysyft-worker-docker)",working many would resolved time work later could get back till nothing work dirty branch,issue,negative,negative,neutral,neutral,negative,negative
596481976,Yep!  All good.  Move ahead.,yep good move ahead,issue,positive,positive,positive,positive,positive,positive
596470964,Let's avoid `oneof` then. Go ahead with the proposed solution @karlhigley!,let avoid go ahead solution,issue,negative,neutral,neutral,neutral,neutral,neutral
596355492,"Should we also update the following?
```
INSTALLATION.md -- it says python3.6 or above
docker-images/pysyft-worker/Dockerfile -- it uses python:3.6-slim
```",also update following python python,issue,negative,neutral,neutral,neutral,neutral,neutral
596278714,"I would like to work on this issue @iamtrask, if it's still open. Do you want to work on this together @ratmcu?",would like work issue still open want work together,issue,negative,neutral,neutral,neutral,neutral,neutral
596277175,is this issue fixed? or @roshray still working on it?,issue fixed still working,issue,negative,positive,neutral,neutral,positive,positive
596265703,"Hi, Shahnawaz Alam here, graduate student from RWTH Aachen University germany. I am also interested to work on this project. I tried joining the link above but I suppose I cannot join with my old slack account. Its showing ""Contact the workspace administrator for an invitation"" @Benardi  - my email id (shahnawaz.alam.dev@gmail.com)",hi graduate student university also interested work project tried joining link suppose join old slack account showing contact administrator invitation id,issue,positive,positive,positive,positive,positive,positive
596255411,"Hi, My name is Imran Alam, I m an undergraduate student from Jadavpur University. I am interested in working on this project.",hi name undergraduate student university interested working project,issue,negative,positive,positive,positive,positive,positive
596254713,"`oneof` would prevent us from storing both formats, so it seems like they should be separate fields, but Grid could remove one or the other when sending to save bandwidth.",would prevent u like separate grid could remove one sending save,issue,positive,neutral,neutral,neutral,neutral,neutral
596252419,"Should it be oneOf with existing operations and state fields? I.e. does it makes sense to store both operations/state and torchscript at the same time in one Plan? I see it may be beneficial for storage, but not for sending. For example, PySyft might make Plan with both ops and torchscript and send it to PyGrid, but PyGrid would deserialize, remove one unneeded part, serialize back before sending it to worker.",state sense store time one plan see may beneficial storage sending example might make plan send would remove one unneeded part serialize back sending worker,issue,negative,neutral,neutral,neutral,neutral,neutral
596247029,"Heads up that there's a rework of Protocols underway in #3008. This looks like a good change though, so go for it!",rework underway like good change though go,issue,positive,positive,positive,positive,positive,positive
596227063,"Can I give this a try?
If I'm not wrong, the starting point is [here](https://github.com/OpenMined/PySyft/blob/7dc983865a8db7e51918b44bff44ac0ba82b120a/syft/execution/protocol.py#L42) (syft/execution/protocol.py)

I would like to clarify one small thing however,
* Are we accepting the plans as just a `tuple` or both `tuple` and `list`? Will both of the below example work or just one?
```python
protocol = sy.Protocol((inc1, inc2, inc3))    # The plans are passed as a tuple
protocol = sy.Protocol([inc1, inc2, inc3])    # The plans are passed as a list
```

Thank you :octocat: ",give try wrong starting point would like clarify one small thing however list example work one python protocol protocol list thank,issue,negative,negative,negative,negative,negative,negative
596223782,"Hey everyone!
Thanks for your interest :)
Please join the slack channel #gsoc_functional_encryption to continue the discussion there :)",hey everyone thanks interest please join slack channel continue discussion,issue,positive,positive,positive,positive,positive,positive
596221822,"For information, #3150 removes zstd so starting from the next release there won't be these kinds of problems 🎉",information starting next release wo,issue,negative,neutral,neutral,neutral,neutral,neutral
596220955,@youben11 is the port result can be rust code which is compiled to wasm?,port result rust code,issue,negative,neutral,neutral,neutral,neutral,neutral
596220107,"It won’t be merged for a long time - once we’ve pulled in a lot of functionality from 0.3. That metric will probably still be quite high because of major code reorganisation.

Sent from my iPhone

> On 8 Mar 2020, at 13:14, Marianne Linhares Monteiro <notifications@github.com> wrote:
> 
> ﻿
> @mari-linhares commented on this pull request.
> 
> There are 476 file changes? Is this right? 😮
> 
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub, or unsubscribe.
",long time lot functionality metric probably still quite high major code sent mar wrote pull request file right thread reply directly view,issue,negative,positive,positive,positive,positive,positive
596202013,@LaRiffle can you check if that's okay? Also not sure if this might break any blog post links 🤔 ,check also sure might break post link,issue,negative,positive,positive,positive,positive,positive
596199945,"I have same issue.

I seems the problem was already fixed at https://github.com/OpenMined/PySyft/pull/2990 .
But still I could not how to avoid this error...",issue problem already fixed still could avoid error,issue,negative,positive,neutral,neutral,positive,positive
596162479,"> Note that MANY people can pick up this issue. We will likely never close it.
> 
> Steps:
> 
> 1. fork the repo into your own github
> 2. clone your fork down to your local filesystem
> 3. look for a part of the codebase that isn't documented
> 4. read the code and figure out what's going on (this is the hard part)
> 5. add inline documentation using the correct style
> 6. commit and push your code to your fork
> 7. create a pull request back into the main PySyft (which you can do using th big green button on Github""

since the hard part is step 4. Provide more detail arch is helpful.
",note many people pick issue likely never close fork clone fork local look part read code figure going hard part add documentation correct style commit push code fork create pull request back main th big green button since hard part step provide detail arch helpful,issue,positive,negative,neutral,neutral,negative,negative
596134999,"With conda environment on Mac, I found this to be useful for installing zstd, and ultimately using PySyft.

https://github.com/sergey-dryabzhinsky/python-zstd/issues/33#issuecomment-527252753

1. Change the gcc-version to a recent one:
`export CC=/usr/local/Cellar/gcc/9.2.XX/bin/gcc-9` (Check your gcc-version in this location before using the command)
`export CFLAGS=""-Wa,-q""`

2. Install zstd using pip. 
**Note:** If you are using a conda environment, double-check that pip is installed in that environment. :)
`pip install zstd`",environment mac found useful ultimately change recent one export check location command export install pip note environment pip environment pip install,issue,negative,positive,neutral,neutral,positive,positive
596120643,"Hi @Benardi I was interested in working on this. I have experience in DL, TF , Pytorch. I have gone through the tutorials and i am familiar with the codebase.",hi interested working experience gone familiar,issue,negative,positive,positive,positive,positive,positive
596102840,"Not sure about how to add zlib to this. You can continue with this, I shall
drop out due to some other work.

On Sat, 7 Mar 2020 at 3:55 PM, Bolarinwa Saheed Olayemi <
notifications@github.com> wrote:

> @r0cketr1kky <https://github.com/r0cketr1kky> sorry, a PR was approved on
> this issue. I think you can still check it and review if you have some
> suggestions. Would you work on adding zlib? @karlhigley
> <https://github.com/karlhigley> kind of indicated that it will be a good
> replacement.
> Since you have started working on this, adding zlib should be easy. Let me
> know so I'll stop working on it.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/3134?email_source=notifications&email_token=AJLQTT5XTZY7NZ4BFS4SRGDRGIOJLA5CNFSM4LAGXKRKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEODVMSI#issuecomment-596072009>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AJLQTT44RCYUJ2NWNK73EGDRGIOJLANCNFSM4LAGXKRA>
> .
>
",sure add continue shall drop due work sat mar wrote sorry issue think still check review would work kind good replacement since working easy let know stop working reply directly view,issue,positive,positive,positive,positive,positive,positive
596081491,"Hey guys, 
I am pursuing B.Tech from University of Delhi and am fully interested in contributing to this project. I have also started working on this.",hey university fully interested project also working,issue,negative,positive,positive,positive,positive,positive
596081160,We have workers who connect with Grid Nodes. Now we'll have a client that connects to the Grid Gateway. Does that makes sense?,connect grid client grid gateway sense,issue,negative,neutral,neutral,neutral,neutral,neutral
596081027,"What we currently have are workers, if you notice, we no longer have the `WebsocketGridClient` in `syft/grid`. And I think that in terms of functionality, it makes sense to separate from workers. It is not reinventing the wheel. There's already enough that we can reuse, but I thought it best to put it with a new client.",currently notice longer think functionality sense separate wheel already enough reuse thought best put new client,issue,positive,positive,positive,positive,positive,positive
596077408,"Looks good to me @hericlesme !  By no means do I want to ""reinvent the wheel"" though. If we already have a similar way to connect to PyGrid from PySyft, then we should use that method. There's no reason to invent a whole new client for working with PyGrid from PySyft if we already have one.

If we don't already have one, go ahead with this!",good want reinvent wheel though already similar way connect use method reason invent whole new client working already one already one go ahead,issue,negative,positive,positive,positive,positive,positive
596072009,"@r0cketr1kky sorry, a PR was approved on this issue. I think you can still check it and review if you have some suggestions. Would you work on adding zlib? @karlhigley kind of indicated that it will be a good replacement.
Since you have started working on this, adding zlib should be easy. Let me know so I'll stop working on it.",sorry issue think still check review would work kind good replacement since working easy let know stop working,issue,positive,positive,positive,positive,positive,positive
596045967,"@JulianSprung @mindastra @nvw1 Could y'all give these translation a review? Happy to merge this once it's reviewed, but I'm not qualified to evaluate the quality of German translations.",could give translation review happy merge qualified evaluate quality german,issue,positive,positive,positive,positive,positive,positive
596040445,"Yes, I am working on it. Would be great to get some help though. You can
reach out to me on Slack @RakshitNaidu

On Sat, Mar 7, 2020 at 12:03 AM Bolarinwa Saheed Olayemi <
notifications@github.com> wrote:

> @r0cketr1kky <https://github.com/r0cketr1kky> are working on this?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/3134?email_source=notifications&email_token=AJLQTT37AF6AJKHV7X342O3RGE6WPA5CNFSM4LAGXKRKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEOCLYGI#issuecomment-595901465>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AJLQTTYSGWUBJL4RAYH5QM3RGE6WPANCNFSM4LAGXKRA>
> .
>
",yes working would great get help though reach slack sat mar wrote working reply directly view,issue,positive,positive,positive,positive,positive,positive
596019936,"After tinkering with it for a while, I found that it was not working because Python 3.8 was installed in my conda env. Tensorflow(according to docs) is available only for python 3.5-3.7 and hence pip cannot find it if Python 3.8 is installed. So, I would recommend installing python 3.7 in the virtual environment and then running the syft installation command.",found working python according available python hence pip find python would recommend python virtual environment running installation command,issue,negative,positive,positive,positive,positive,positive
595959538,"Hi!

Indeed, this task is not completed yet. The main block I found out has been the use of NumPy in the codebase itself, which has lead me to weird bugs while trying to subclass ndarray.

I'll keep on studying the code and the proper use of ndarray subclassing for Syft, but I am currently on a break from this task.",hi indeed task yet main block found use lead weird trying subclass keep code proper use currently break task,issue,negative,negative,neutral,neutral,negative,negative
595940415,"Hi @LaRiffle 
I'm interested in contributing towards this project. ",hi interested towards project,issue,negative,positive,positive,positive,positive,positive
595937971,"Hi @H4LL 
I am Edwin Toppo, an undergraduate student from India. I have experience in Deep Learning and Pytorch, and have implemented in projects. I've acquired basic knowledge of federated learning and split NNs and I'm still working on it. I am interested to work along, and looking forward to contribute in this project.",hi undergraduate student experience deep learning acquired basic knowledge learning split still working interested work along looking forward contribute project,issue,negative,positive,neutral,neutral,positive,positive
595881756,You need to rebase :( because there is a new version of syft-proto,need rebase new version,issue,negative,positive,positive,positive,positive,positive
595709435,"I don't think the work was completed - I'm currently working on it as a
part of Syft 0.4 but that won't be out for a bit.

On Fri, Mar 6, 2020 at 7:02 AM Samveed <notifications@github.com> wrote:

> Does this now allow the Federated Learning with Encrypted Gradient
> Aggregation tutorial to work? Or is it that we need to add some additional
> piece of code along with the already existing modules?
> Sorry, I was not able to follow the above discussion clearly.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/2771?email_source=notifications&email_token=ABBAZEVAK5UP2JL3S5A4D33RGCNYRA5CNFSM4JVEK7JKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEOAJQOQ#issuecomment-595630138>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ABBAZEX4LRAF32C2SRRD6JDRGCNYRANCNFSM4JVEK7JA>
> .
>
",think work currently working part wo bit mar wrote allow learning gradient aggregation tutorial work need add additional piece code along already sorry able follow discussion clearly reply directly view,issue,positive,positive,neutral,neutral,positive,positive
595700417,"Hey, @mccorby I would like to work on this, is this issue taken up by someone? ",hey would like work issue taken someone,issue,negative,neutral,neutral,neutral,neutral,neutral
595630138,"Does this now allow the Federated Learning with Encrypted Gradient Aggregation tutorial to work? Or is it that we need to add some additional piece of code along with the already existing modules? 
Sorry, I was not able to follow the above discussion clearly.",allow learning gradient aggregation tutorial work need add additional piece code along already sorry able follow discussion clearly,issue,positive,positive,neutral,neutral,positive,positive
595558789,"Can't wait to see progress on this one!

On Mon, Mar 2, 2020 at 5:12 PM Karl Higley <notifications@github.com> wrote:

> From a conversation with @Jasopaum <https://github.com/Jasopaum>, we're
> planning to start working on this and have a preliminary checklist of steps
> forward to get us started:
>
>    - Extract ComputationAction from OperationMessage
>    - Create Action base class
>    - Create CommunicationAction class
>    - Create a Role class (possibly w/ a worker inside?)
>    - Create a Protocol class (w/ building and tracing like Plans)
>    - Partition the trace logs into separate roles
>    - Send Roles to workers
>    - Add the ability to execute Actions from Protocol Roles on workers
>    - Create an Execution abstraction to capture state (inputs, outputs,
>    intermediate results, etc.)
>    - Add protocol id and execution id fields to message classes
>    - Update worker's message dispatch to take ids into account
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/3008?email_source=notifications&email_token=ABBAZEQYFG6FAYZUCLH26TTRFPSHBA5CNFSM4KP3P7M2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOENQEH7Q#issuecomment-593511422>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ABBAZEXSLIPMUHZHWTUYXTTRFPSHBANCNFSM4KP3P7MQ>
> .
>
",ca wait see progress one mon mar wrote conversation start working preliminary forward get u extract create action base class create class create role class possibly worker inside create protocol class building tracing like partition trace separate send add ability execute protocol create execution abstraction capture state intermediate add protocol id execution id message class update worker message dispatch take account reply directly view,issue,positive,negative,negative,negative,negative,negative
595497963,Could you run ```black``` for the code to be auto-formated?,could run black code,issue,negative,negative,negative,negative,negative,negative
595484800,@iamtrask I had opened pull request #3178  for Tutorials in german please review it. ,pull request german please review,issue,negative,neutral,neutral,neutral,neutral,neutral
595369893,"That works for me!

On Thu, Mar 5, 2020 at 4:54 PM Karl Higley <notifications@github.com> wrote:

> I'd probably make the JIT compiled version a field of type
> syft_proto.types.torch.v1.ScriptModule on the Plan schema, because I'm
> not sure that the Torchscript will contain 100% of the information required
> to make Plans work. (It will definitely contain all the information
> required to run the computations in the Plan, but handling
> inputs/outputs/ids/etc isn't necessarily part of that.)
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/2994?email_source=notifications&email_token=AAJ44CRVM6NWZ7U3FCUPPXTRF7KMVA5CNFSM4KO3EHAKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEN6BFHY#issuecomment-595333791>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AAJ44CQPOGTRPVLZHJSNNELRF7KMVANCNFSM4KO3EHAA>
> .
>
",work mar wrote probably make version field type plan schema sure contain information make work definitely contain information run plan handling necessarily part thread reply directly view,issue,positive,positive,positive,positive,positive,positive
595368928,"Hello. Glad to see you are interested in the project :).

As a community, we are using the slack channel from [here](https://openmined.slack.com/) (it is a faster way to communicate).

I think some issues that are marked with ```good first issue``` will help you get more accustomed to the codebase. Also, another great resource to learn more about PySyft are the tutorials -- they can be found in the examples folder.

If you have any further questions you can also contact me on the above mentioned slack channel. Our community is friendly and anyone can help you with any questions.",hello glad see interested project community slack channel faster way communicate think marked good first issue help get accustomed also another great resource learn found folder also contact slack channel community friendly anyone help,issue,positive,positive,positive,positive,positive,positive
595349376,"Hi @LaRiffle
I am Vineet Jain, a final year undergraduate student at IIT Kharagpur. I had experience in DL, TensorFlow, PyTorch, and PySyft. I had done my past summer internship in Federated Learning Project(where I had implemented FL on Raspberry pi's (as clients' server) using PySyft ) where I had used PySyft, Tensorflow federated learning, and Tensorflow Federated Core. I am interested in PySyft projects. I am looking forward to contributing!",hi final year undergraduate student experience done past summer internship learning project raspberry pi server used learning core interested looking forward,issue,negative,neutral,neutral,neutral,neutral,neutral
595346660,"Hi @youben11 
   I am Vineet Jain, a final year undergraduate student at IIT Kharagpur. I had experience in DL, TensorFlow, PyTorch, and PySyft. I had done my past summer internship in Federated Learning Project(where I had implemented FL on Raspberry pi's (as clients' server) using PySyft ) where I had used PySyft, Tensorflow federated learning, and Tensorflow Federated Core. I am interested in the PySyft projects. I would like to work on this.",hi final year undergraduate student experience done past summer internship learning project raspberry pi server used learning core interested would like work,issue,positive,neutral,neutral,neutral,neutral,neutral
595333791,"I'd probably make the JIT compiled version a field of type `syft_proto.types.torch.v1.ScriptModule` on the `Plan` schema, because I'm not sure that the Torchscript will contain 100% of the information required to make Plans work. (It will definitely contain all the information required to run the computations in the Plan, but handling inputs/outputs/ids/etc isn't necessarily part of that.)",probably make version field type plan schema sure contain information make work definitely contain information run plan handling necessarily part,issue,positive,positive,positive,positive,positive,positive
595265583,"I would imagine we can do this conversion on the fly in PyGrid and avoid
storing it twice on protobuf.  If it doesn't take long to run the plan
through the JIT compiler then I say that we do that.  Protobuf can only
have the one true value, and then when we host a plan on PyGrid then it
runs the compiler, splitting the plan into two versions and storing each
separately.  Go ahead and do this Vova if you want.

On Wed, Mar 4, 2020 at 9:58 PM Vova Manannikov <notifications@github.com>
wrote:

> It seems initial thinking was that Plan with list of operations will be
> traced with torch.jit.trace.
> The question is, do we need same Plan protobuf type to (be able to) hold
> both versions of Plan or it's fine to have ops list plan to be
> syft_proto.execution.v1.Plan and torchscript version to be
> syft_proto.types.torch.v1.ScriptModule?
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/2994?email_source=notifications&email_token=AAJ44CWNYOWTPQ7HF5SE2MTRF3FHXA5CNFSM4KO3EHAKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEN2R4VY#issuecomment-594878039>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AAJ44CSCCVVFKCVF6GMTAQ3RF3FHXANCNFSM4KO3EHAA>
> .
>
",would imagine conversion fly avoid twice take long run plan compiler say one true value host plan compiler splitting plan two separately go ahead want wed mar wrote initial thinking plan list question need plan type able hold plan fine list plan version thread reply directly view,issue,positive,positive,positive,positive,positive,positive
595232403,@roshray please DM me on slack when you're done - we have someone who needs this feature asap,please slack done someone need feature,issue,negative,neutral,neutral,neutral,neutral,neutral
594878039,"It seems initial thinking was that Plan with list of operations will be traced with torch.jit.trace.
The question is, do we need same Plan protobuf type to (be able to) hold both versions of Plan or it's fine to have ops list plan to be syft_proto.execution.v1.Plan and torchscript version to be syft_proto.types.torch.v1.ScriptModule?",initial thinking plan list question need plan type able hold plan fine list plan version,issue,negative,positive,positive,positive,positive,positive
594495365,"> Hey @H4LL ,
> my name's Michal, I'm a Master's student from Prague and I'd be very interested in working on this project. I have both school- and work-related knowledge of PyTorch and consider myself rather privacy minded. That's why when I first heard of PySyft (through one of Andrew Trasks' lecture) I had found it very cool and appealing. Looking forward to contribute!

Sure, reach out on slack @Adam J Hall",hey name master student interested working project knowledge consider rather privacy minded first one lecture found cool appealing looking forward contribute sure reach slack hall,issue,positive,positive,positive,positive,positive,positive
594495016,"> @H4LL PySyfter here.
> Have contributed to some of the tutorial translations.
> Would be good to go once I get a deep dive into the library.

Sure, get in touch on slack if you want to give something a bash!",tutorial would good go get deep dive library sure get touch slack want give something bash,issue,positive,positive,positive,positive,positive,positive
594494459,"> Hi, @H4LL, I have left a message on slack for you, just check it. As we have a different time zone, may you give your working time schedule?

replied to this on slack",hi left message slack check different time zone may give working time schedule slack,issue,negative,neutral,neutral,neutral,neutral,neutral
594462995,"@r0cketr1kky : Ideally, ZSTD should be removed from any place where it's used. This should include:
- Production code
- Tests
- Requirement files

And double check that it's not present either in any notebook (I think it's not).

Special care has to be taken when removing it from the production code (`serde`) as we want to leave the door open to have some other compression tool.",ideally removed place used include production code requirement double check present either notebook think special care taken removing production code want leave door open compression tool,issue,positive,positive,positive,positive,positive,positive
594402664,"> @midokura-silvia I am using your code in [Asynchronous-federated-learning-on-MNIST](https://github.com/OpenMined/PySyft/blob/0831588f0795c226ce1057070e967d6846b015e6/examples/tutorials/advanced/websockets-example-MNIST-parallel/Asynchronous-federated-learning-on-MNIST.ipynb), however I don't use as a notebook. There you have:
> 
> ```python
> results = await asyncio.gather(
>         *[
>             rwc.fit_model_on_worker(
>                 worker=worker,
>                 traced_model=traced_model,
>                 batch_size=args.batch_size,
>                 curr_round=curr_round,
>                 max_nr_batches=args.federate_after_n_batches,
>                 lr=learning_rate,
>             )
>             for worker in worker_instances
>         ]
>     )
> ```
> 
> in this case `await` is used outside an `async` function. How didn't you get any error?

I had the same error. but it worked in notebook.  ",code however use notebook python await worker case await used outside function get error error worked notebook,issue,negative,neutral,neutral,neutral,neutral,neutral
594068981,"@H4LL PySyfter here.
Have contributed to some of the tutorial translations.
Would be good to go once I get a deep dive into the library.",tutorial would good go get deep dive library,issue,negative,positive,positive,positive,positive,positive
594040402,"Hi, I am a native speaker and would be happy to help out and translate further parts. What is the current state? ",hi native speaker would happy help translate current state,issue,positive,positive,positive,positive,positive,positive
594029523,"@BBloggsbott I would say no `-m` as it adds a lot of text and may make somebody thing they _need_ your computer architecture for it to run. 

Also, now I'm not sure that we should include the time. Date + hash is enough information to work out the state of the codebase when the tutorial was last edited. Including time + timezone will only add confusion, especially if notebooks get updated by people in different timezones.

I think
```
last updated on: Tue 03 Mar 2020

torch: x.y.z
syft: x.y.z
git hash
```
Is a clean way to provide all the necessary information",would say lot text may make somebody thing computer architecture run also sure include time date hash enough information work state tutorial last time add confusion especially get people different think last tue mar torch git hash clean way provide necessary information,issue,negative,positive,positive,positive,positive,positive
594000722,"Could we proceed with two steps? First remove ZSTD, then add another compression tool?
",could proceed two first remove add another compression tool,issue,negative,positive,positive,positive,positive,positive
593991786,"We'll probably [still want compression](https://eng.uber.com/trip-data-squeeze-json-encoding-compression/) with Protobuf, but we can probably use zlib instead of zstd (if that's any easier to install.)",probably still want compression probably use instead easier install,issue,negative,neutral,neutral,neutral,neutral,neutral
593941699,"Hey @H4LL ,
my name's Michal, I'm a Master's student from Prague and I'd be very interested in working on this project. I have both school- and work-related knowledge of PyTorch and consider myself rather privacy minded. That's why when I first heard of PySyft (through one of Andrew Trasks' lecture) I had found it very cool and appealing. Looking forward to contribute!",hey name master student interested working project knowledge consider rather privacy minded first one lecture found cool appealing looking forward contribute,issue,positive,positive,positive,positive,positive,positive
593934432,"Great, guys. I'm thinking of creating a slack channel for this issue. It is even better to discuss it there too. What do you think? :slightly_smiling_face: ",great thinking slack channel issue even better discus think,issue,positive,positive,positive,positive,positive,positive
593884420,"Hi @mccorby , I would like to work on this.
So, I guess I would need to remove the ZSTD functionalities in the `test` folder right? Is that it? Or do I need to remove ZSTD from the `compression.py` file in `PySyft/syft/serde/` too?",hi would like work guess would need remove test folder right need remove file,issue,negative,positive,positive,positive,positive,positive
593852357,"Is there any reply of this question?
Thanks @klize  for pointing out the question so clear than my post (https://github.com/OpenMined/PySyft/issues/2901)",reply question thanks pointing question clear post,issue,positive,positive,positive,positive,positive,positive
593758430,"I just retried MNIST example with batchsize==512 and federate_after_n_batch==20, and after several rounds, it came up with ''future: <Future finished exception=ConnectionClosedOK('code = 1000 (OK), no reason',)'' and ''websockets.exceptions.ConnectionClosedOK: code = 1000 (OK), no reason'' again. Seems that it's sth. with the data size.",example several came future future finished reason code reason data size,issue,negative,neutral,neutral,neutral,neutral,neutral
593735980,@Jasopaum Operation and OperationMessage now have separate (but related) msgpack serialization methods. The next step is to extract Operation's Protobuf serialization from the existing methods on OperationMessage into new methods on Operation.,operation separate related serialization next step extract operation serialization new operation,issue,negative,positive,neutral,neutral,positive,positive
593511422,"From a conversation with @Jasopaum, we're planning to start working on this and have a preliminary checklist of steps forward to get us started:
- [ ] Extract ComputationAction from OperationMessage
- [ ] Create Action base class
- [ ] Create CommunicationAction class
- [ ] Create a Role class (possibly w/ a worker inside?)
- [ ] Create a Protocol class (w/ building and tracing like Plans)
- [ ] Partition the trace logs into separate roles
- [ ] Send Roles to workers
- [ ] Add the ability to execute Actions from Protocol Roles on workers
- [ ] Create an Execution abstraction to capture state (inputs, outputs, intermediate results, etc.)
- [ ] Add protocol id and execution id fields to message classes
- [ ] Update worker's message dispatch to take ids into account",conversation start working preliminary forward get u extract create action base class create class create role class possibly worker inside create protocol class building tracing like partition trace separate send add ability execute protocol create execution abstraction capture state intermediate add protocol id execution id message class update worker message dispatch take account,issue,positive,negative,negative,negative,negative,negative
593509577,Working with @Jasopaum to define an updated path forward for Protocols. Will open a new issue with our checklist.,working define path forward open new issue,issue,negative,positive,neutral,neutral,positive,positive
593472898,Might need to add a test for this.,might need add test,issue,negative,neutral,neutral,neutral,neutral,neutral
593471990,"Maybe you hadn't pushed the update yet? It was behind master a bit. Anyway, merged in master and we'll see if that fixes the tests.",maybe update yet behind master bit anyway master see,issue,negative,negative,negative,negative,negative,negative
593471942,It worked before by the way. Like a month ago,worked way like month ago,issue,negative,neutral,neutral,neutral,neutral,neutral
593434272,"@karlhigley  my branch is up-to-date with the upstream/master branch.
`git merge upstream/master`
Already up to date.
Can there be any other thing or I am missing something?",branch branch git merge already date thing missing something,issue,negative,negative,negative,negative,negative,negative
593214494,@shuvamlal9 What's the latest commit you have on the `master` branch?,latest commit master branch,issue,negative,positive,positive,positive,positive,positive
593209762,"@karlhigley nope still struggling to get the latest version.
I did what's given there to install the syft package but I'm not able to load that package.",nope still struggling get latest version given install package able load package,issue,negative,positive,positive,positive,positive,positive
593207198,@jabertuhin I think this just needs to merge in the latest commits from the `master` branch.,think need merge latest master branch,issue,negative,positive,positive,positive,positive,positive
593198438,"Hi, @adventuroussrv 
Is there anything that I can fix to pass the tests?",hi anything fix pas,issue,negative,neutral,neutral,neutral,neutral,neutral
593150927,Would be great to also set the `torch.manual_seed` via entrypoints in the config file too.,would great also set via file,issue,positive,positive,positive,positive,positive,positive
593142475,"@AniTho I haven't used fastai but from what you described:

> we freeze all the layer and only train and optimize the final classifier layer 

-> Is transfer learning with feature extraction

> and then we unfreeze the top layers to start optimizing the complete model

-> Is transfer learning with fine-tuning

With this change, we will have the flexibility to specify which `params` to optimize.",used freeze layer train optimize final classifier layer transfer learning feature extraction unfreeze top start complete model transfer learning change flexibility specify optimize,issue,positive,positive,positive,positive,positive,positive
593104964,"Is this problem somewhat like what we do with fastai library that is at the beginning, we freeze all the layer and only train and optimize the final classifier layer and then we unfreeze the top layers to start optimizing the complete model?",problem somewhat like library beginning freeze layer train optimize final classifier layer unfreeze top start complete model,issue,positive,positive,positive,positive,positive,positive
593096855,@karlhigley Failed build says `##[error]The template is not valid. hashFiles('/pip-dep/requirements*.txt') failed. Directory '/home/runner/work/PySyft/PySyft' is empty`,build error template valid directory empty,issue,negative,negative,neutral,neutral,negative,negative
593087158,"I would like to work on this project and I am willing to learn PySyft. Also, I am learning about GCP already. ",would like work project willing learn also learning already,issue,negative,positive,positive,positive,positive,positive
593084817,"> Is there any particular channel for this project or should I message in gsoc slack group

You can use the #gsoc channel :slightly_smiling_face: ",particular channel project message slack group use channel,issue,negative,positive,positive,positive,positive,positive
593084710,"Yess @neeravjain24! Don't worry if you're not familiar with GCloud. There's a lot of tutorials, docs and codelabs to learn. I also recommend taking a look at the PyGrid tutorial. The links are in the issue description.

GCloud links:
https://cloud.google.com/getting-started
https://codelabs.developers.google.com/cloud/",worry familiar lot learn also recommend taking look tutorial link issue description link,issue,negative,positive,positive,positive,positive,positive
593084383,Is there any particular channel for this project or should I message in gsoc slack group,particular channel project message slack group,issue,negative,positive,positive,positive,positive,positive
593084108,Great! There are a lot of interested people.  I think you could also talk to each other about the issue. :rocket: :nerd_face: ,great lot interested people think could also talk issue rocket,issue,positive,positive,positive,positive,positive,positive
593074144,"Hello everyone! Is this issue resolved? If not, can I try it out? @iamtrask ",hello everyone issue resolved try,issue,negative,neutral,neutral,neutral,neutral,neutral
593073089,"Hey, I am interested in doing this project. I have a good maths background and I was always looking to implement something of this kind from scratch. Should be a really memorable learning experience. ",hey interested project good background always looking implement something kind scratch really memorable learning experience,issue,positive,positive,positive,positive,positive,positive
593069797,"I have no experience related to Cloud but I am trying to learn PySyft .
I really want to contribute to this project.
Please can you help me .",experience related cloud trying learn really want contribute project please help,issue,positive,positive,neutral,neutral,positive,positive
593050938,Bandit is contained within the tests.yml file; should this issue now be closed? ,bandit within file issue closed,issue,negative,negative,neutral,neutral,negative,negative
592980751,@imskr Thanks! Feel free to ping me on Slack with any questions.,thanks feel free ping slack,issue,positive,positive,positive,positive,positive,positive
592963953,"Hi @imskr ! Feel free to ask questions on the #gsoc channel or DM me on slack.

You can also comment here for any detail regarding the project.",hi feel free ask channel slack also comment detail regarding project,issue,positive,positive,positive,positive,positive,positive
592927081,"Hey, I would also like to work on this project. ",hey would also like work project,issue,negative,neutral,neutral,neutral,neutral,neutral
592848330,See #2774 for information on the Hindi translation effort. Many of the tutorials [have already been translated](https://github.com/OpenMined/PySyft/pulls?utf8=%E2%9C%93&q=is%3Apr+Hindi).,see information translation effort many already,issue,negative,positive,positive,positive,positive,positive
592780324,Could you guys (and also others that could be interested) contact me on Slack (Jason Paumier) so that we can talk about this?,could also could interested contact slack talk,issue,negative,positive,positive,positive,positive,positive
592686394,"@iamtrask i would like to translate the tutorials to Hindi , Please Let me know if the issue is still open!!
",would like translate please let know issue still open,issue,positive,neutral,neutral,neutral,neutral,neutral
592529003,"Clearing @mccorby as the assignee, as he will be the mentor for this project, but not the assigned person to perform the task. If this issue isn't taken as part of GSoC, then @mccorby will take the ticket himself. :)",clearing assignee mentor project assigned person perform task issue taken part take ticket,issue,negative,neutral,neutral,neutral,neutral,neutral
592510153,Make sure you have the latest version of the PySyft master branch and the latest version of syft-proto. This error indicates an incompatibility between your versions of the two.,make sure latest version master branch latest version error incompatibility two,issue,negative,positive,positive,positive,positive,positive
592422045,"Hi @Jasopaum , I would like to work on this issue. I have made a merged PR at https://github.com/OpenMined/PySyft/pull/3092 and also filled up the application form. I would like to know how could I go further on this issue. Thank you!",hi would like work issue made also filled application form would like know could go issue thank,issue,positive,positive,positive,positive,positive,positive
592366802,"When input parameter is returned from plan, the output is just empty tuple.
Is that by design or :bug:?

Code example:
```
@sy.func2plan(args_shape=[(5, 5),])
def upd_test(tensor):
    tensor.add_(1.)
    return tensor

upd_test.forward = None
t = th.randn(5,5)
out = upd_test(t)
print(out)
```
",input parameter returned plan output empty design bug code example tensor return tensor none print,issue,negative,negative,neutral,neutral,negative,negative
592266395,"Cool, @carlodavid012! I saw that you already know PySyft. I also think that basic PyGrid concepts can be useful. Feel free to chat with me if you need anything!",cool saw already know also think basic useful feel free chat need anything,issue,positive,positive,positive,positive,positive,positive
592131137,"Hi, @H4LL, I have left a message on slack for you, just check it. As we have a different time zone, may you give your working time schedule?",hi left message slack check different time zone may give working time schedule,issue,negative,neutral,neutral,neutral,neutral,neutral
592022845,"Hello @H4LL 
I am Aditya, an Undergrad from India.
I have been familiarizing myself with PySyft code base as well as its usage. Exhaustively learning about Federated learning and SplitNN through lectures, paper and presentations and really getting interested in this domain. Looking forward to contribute to PySyft towards this project.

Thank You!",hello undergrad code base well usage exhaustively learning learning paper really getting interested domain looking forward contribute towards project thank,issue,positive,negative,negative,negative,negative,negative
591963798,"There is a PR on this, currently linked [here](https://github.com/OpenMined/PySyft/pull/3074). Sorry I did not put the reference in the PR :(",currently linked sorry put reference,issue,negative,negative,negative,negative,negative,negative
591900930,"Hey guys, 

Get in touch on slack and we can talk about some ways you can initially contribute!

Cheers!",hey get touch slack talk way initially contribute,issue,negative,neutral,neutral,neutral,neutral,neutral
591897214,"Hey!
I'm a sophomore at  BITS Pilani Goa and am currently doing the Udacity course by openmined
on secure AI. I've done Stanford's cs231n course and would love to work on this project. Could you please guide me on what I'd need to do to complete this task?

 ",hey sophomore goa currently course secure ai done course would love work project could please guide need complete task,issue,positive,positive,positive,positive,positive,positive
591880592,"In order to get rid of this **_zstd_** error on **Windows**, you'll need to install a small package of Microsoft Visual C++ from [here](https://download.microsoft.com/download/5/f/7/5f7acaeb-8363-451f-9425-68a90f98b238/visualcppbuildtools_full.exe) 
After that try installing the package using `pip install syft`",order get rid error need install small package visual try package pip install,issue,negative,negative,negative,negative,negative,negative
591840583,I also would like to work on this project.,also would like work project,issue,negative,neutral,neutral,neutral,neutral,neutral
591695506,"Hello,

I am Abinav, currently a Master's student at Technical University Munich. I would like to be considered for the project for GSoC. I have a work experience of about 2 years with Pytorch and Deep learning. I am halfway through the Secure and Private AI in Udacity. It would be great if you could point out relevant issues to get started with the project. 

Thank you",hello currently master student technical university would like considered project work experience deep learning halfway secure private ai would great could point relevant get project thank,issue,positive,positive,positive,positive,positive,positive
591639408,"Hi,  Adam, @H4LL 

I'm Haofan Wang, currently a graduate student at CMU, I can send you my resume if needed. I'd like to be considered for this project in GSoC. I'm experienced with DL and Pytorch, and I'm taking the course on Udacity now and reading paper of Federated learning and SplitNN.

I'd like to begin working on the project and collaborate with you. Any suggestions for how to get started? I hope to contribute and get selected in the project. Thanks.",hi wang currently graduate student send resume like considered project experienced taking course reading paper learning like begin working project collaborate get hope contribute get selected project thanks,issue,positive,positive,positive,positive,positive,positive
591537555,The [PR corresponding to those changes in PySyft](https://github.com/OpenMined/PySyft/pull/3090) hadn't yet been reviewed and merged. New PySyft version with those changes coming soon.,corresponding yet new version coming soon,issue,negative,positive,positive,positive,positive,positive
591528049,"Note: we want to allow for automatic node teardown after calling .sweep() as an option - where it deposits the results into a ""main cluster node"". In other words, if I spin up a cluster of 10 workers, this is ACTUALLY a cluster of 10 workers and 1 master, where the master can store resources produced by the 10 workers.",note want allow automatic node teardown calling option main cluster node spin cluster actually cluster master master store produced,issue,negative,positive,neutral,neutral,positive,positive
591519550,Out of curiosity - I notice your error bounds are 1e-6. Part of me wishes that we could gte *exactly* the same (but this is out of scope for a project focused on extending our test coverage). How far off are we?,curiosity notice error part could exactly scope project extending test coverage far,issue,negative,positive,positive,positive,positive,positive
591518101,Well done! Master is currently broken so merging despite tests.,well done master currently broken despite,issue,negative,negative,negative,negative,negative,negative
591517597,It's not your fault! Master is currently broken! Thank you for this contribution!,fault master currently broken thank contribution,issue,negative,negative,negative,negative,negative,negative
591487172,"Hi @LaRiffle , I'm interested in this project. I have a good background in Linear Algebra as I'm pursuing a minor in Maths and I am somewhat familiar with Pysyft's codebase.",hi interested project good background linear algebra minor somewhat familiar,issue,positive,positive,positive,positive,positive,positive
591438533,"@iamtrask , I would like to translate tutorial to Hindi. Let me know if this issue is still open.",would like translate tutorial let know issue still open,issue,negative,neutral,neutral,neutral,neutral,neutral
591322236,"> the latest version of syft-proto seems to have issues.
> try: pip install syft-proto==0.1.1a1.post20

Perfect solution！",latest version try pip install perfect,issue,positive,positive,positive,positive,positive,positive
591303247,"the latest version of syft-proto seems to have issues.
try: pip install syft-proto==0.1.1a1.post20",latest version try pip install,issue,negative,positive,positive,positive,positive,positive
591295281,"I met the same Error as your when importing syft.
Did anyone solve this problem?",met error anyone solve problem,issue,negative,neutral,neutral,neutral,neutral,neutral
591240914,"Hi, @adventuroussrv .
I have a pending notebook(Part-4) to translate. After completing that I can go for the part 3.",hi pending notebook translate go part,issue,negative,neutral,neutral,neutral,neutral,neutral
591210715,"@brandonhee After doing, what you suggested I got another error saying dict object has no attribute 'id'. 

Any ideas?",got another error saying object attribute,issue,negative,neutral,neutral,neutral,neutral,neutral
591045218,"Is this issue still open?
Can I be assigned to work on this issue?",issue still open assigned work issue,issue,negative,neutral,neutral,neutral,neutral,neutral
590994217,Hi @jabertuhin @ucalyptus anyone wants to work on the part 3 maybe?,hi anyone work part maybe,issue,negative,neutral,neutral,neutral,neutral,neutral
590983454,See #3092 for the current state of the testing effort.,see current state testing effort,issue,negative,neutral,neutral,neutral,neutral,neutral
590981102,"Ohh, my bad. Thank you for letting me know. You can close this issue.

On Tue, 25 Feb 2020 at 10:34 PM, Pierre Pocreau <notifications@github.com>
wrote:

> Well sc should be a torch tensor, not a list.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/3095?email_source=notifications&email_token=AJLQTT6DAS3DTPBGXXDDB7DREVFSFA5CNFSM4K3N3NI2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEM4VNFY#issuecomment-590960279>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AJLQTTYYZXE6QISVMDMCETDREVFSFANCNFSM4K3N3NIQ>
> .
>
",bad thank know close issue tue wrote well torch tensor list thread reply directly view,issue,negative,negative,negative,negative,negative,negative
590977349,@jimboH yes I'd like to see the code.,yes like see code,issue,positive,neutral,neutral,neutral,neutral,neutral
590971329,"Hi, I would like to work on this issue. Is it still active?",hi would like work issue still active,issue,positive,negative,negative,negative,negative,negative
590960279,"Well sc should be a torch tensor, not a list.",well torch tensor list,issue,negative,neutral,neutral,neutral,neutral,neutral
590947253,@AniTho Thank you! I got some troubles with rounding while testing the handcrafted RNNs but finally solved it. Would you take a look at the test_rnn.py file to see if it really test all the RNNs? ,thank got rounding testing finally would take look file see really test,issue,negative,positive,neutral,neutral,positive,positive
590875309,"Hey all, this was finished as a result of https://github.com/OpenMined/PySyft/pull/2636

Going to close this, feel free to open up a new issue if there are any further concerns!",hey finished result going close feel free open new issue,issue,positive,positive,positive,positive,positive,positive
590846593,"Hi,

msgpack is a required dependency (see requirements.txt) and will be used when searching, if I remember correctly.
You can check your pip packages with pip list.

Greetings",hi dependency see used searching remember correctly check pip pip list,issue,negative,neutral,neutral,neutral,neutral,neutral
590839295,"Sorry, I didn't add more context. I'm running my grid-nodes and the gateway on docker for ubuntu. Do I need to install ```msgpack``` in the grid-nodes containers, the gateway container or in the host machine where I'm trying to execute the search command?",sorry add context running gateway docker need install gateway container host machine trying execute search command,issue,negative,negative,negative,negative,negative,negative
590809787,You forgot to hook torch with `hook = sy.TorchHook(torch) `to extend torch tensors methods.,forgot hook torch hook torch extend torch,issue,negative,neutral,neutral,neutral,neutral,neutral
590525386,"Yes, torch.zeros needs a dtype arg which should be same as dtype for FPT. #2982 Once this is completed we will have a proper dtype property associated with the FPT and AST.",yes need proper property associated ast,issue,negative,neutral,neutral,neutral,neutral,neutral
590509978,"I pushed both the translated notebooks! Part 9 and Part 10 in #3050 :sweat_smile: :grin: 

good close this PR! @karlhigley  :)",part part grin good close,issue,positive,positive,positive,positive,positive,positive
590484279,"Hi, Is this issue available? If so can I work on it?",hi issue available work,issue,negative,positive,positive,positive,positive,positive
590483533,"@adventuroussrv It looks like the version of Part 10 in this PR has conflicts with the one from the other PR I just merged. Could you resolve the conflicts? I would do it myself, but I have no idea which version of the text is preferable. 😅",like version part one could resolve would idea version text preferable,issue,positive,neutral,neutral,neutral,neutral,neutral
590471251,"Hopefully I will be done with the translations by this week.
Sorry, for taking some time.",hopefully done week sorry taking time,issue,negative,negative,negative,negative,negative,negative
590439121,"@jimboH Can you share anything through which I can contact you to collaborate?
",share anything contact collaborate,issue,negative,neutral,neutral,neutral,neutral,neutral
590354800,"It looks like that code was deprecated and later removed in #476, which [suggests](https://github.com/OpenMined/PyGrid/commit/2b543d075b86a6846d815ab5bdba45b551f48654#diff-b1ef8a3aed029ba9fb6663df43b6c7daL16) using PySyft's `syft.grid` module instead.",like code later removed module instead,issue,negative,neutral,neutral,neutral,neutral,neutral
590314355,"Thank you very much for your concern, please feel free to close it. I will
work in folder  called Turkish which I opened on 23 Feb

Kind regards,
Zumrut M.


On Wed, 19 Feb 2020 at 21:31, Karl Higley <notifications@github.com> wrote:

> @ZumrutMuftuoglu <https://github.com/ZumrutMuftuoglu> Still working on
> the translated content for this PR? It's empty right now, but I can leave
> it open if you're still working on it.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/pull/3061?email_source=notifications&email_token=AIREAV4M4PKBVS3OLUYAKGDRDV3HDA5CNFSM4KW6F7V2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEMI57JY#issuecomment-588373927>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AIREAV2J67QATWOLCTB2WTLRDV3HDANCNFSM4KW6F7VQ>
> .
>
",thank much concern please feel free close work folder kind wed wrote still working content empty right leave open still working reply directly view,issue,positive,positive,positive,positive,positive,positive
590304292,"There are two problems around the maxpool.
Here, to calculate the derivative of maxpool, we use share on a torch.zeros tensor but it is of type FloatTensor.
https://github.com/OpenMined/PySyft/blob/f692ac551d41ebb4546274001ad192434b85e522/syft/frameworks/torch/mpc/securenn.py#L575-L577

Maybe we can use something else then torch.zeros ? or convert it to a LongTensor since it's only zeros.

Then to test the maxpool 2d, we call share on a FloatTensor
https://github.com/OpenMined/PySyft/blob/f6e8fd2d736422695c6c20d3d0e86e4c05600752/test/torch/crypto/test_snn.py#L171-L198

But here didn't we forgot to call fix_precision ? because we clearly have float numbers in the x2 tensor.",two around calculate derivative use share tensor type maybe use something else convert since test call share forgot call clearly float tensor,issue,positive,positive,positive,positive,positive,positive
590239966,"@iamtrask 
I can start the translation to Turkish. Is it possible to open an issue for this?",start translation possible open issue,issue,negative,neutral,neutral,neutral,neutral,neutral
590115212,@pierrepocreau I have not done any work on this issue. Please feel free to work on it. ,done work issue please feel free work,issue,positive,positive,positive,positive,positive,positive
590113024,"Hey, may I work on this issue ? ",hey may work issue,issue,negative,neutral,neutral,neutral,neutral,neutral
590096569,@iamtrask I have to implement test case as you have done for conv2d which is by creating a sample object using torch nn and one of the custom implementation and then finding maximum absolute difference in the two model output?,implement test case done sample object torch one custom implementation finding maximum absolute difference two model output,issue,negative,positive,positive,positive,positive,positive
590090613,"Sounds like you should both work together on it.

Sent from my iPhone

> On 23 Feb 2020, at 16:46, AniTho <notifications@github.com> wrote:
> 
> ﻿
> @karlhigley thank you! I will start working on it.
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub, or unsubscribe.
",like work together sent wrote thank start working reply directly view,issue,positive,positive,neutral,neutral,positive,positive
590077919,"I copied the entire code on another notebook and to my surprise, it didn't give any error but now I have encountered another error.
![tempsnip1](https://user-images.githubusercontent.com/41802909/75114484-2bdc1b00-567c-11ea-82c2-611d5c502344.png)
 ",copied entire code another notebook surprise give error another error,issue,negative,neutral,neutral,neutral,neutral,neutral
590076980,"@karlhigley 
import torch as th
from torch import nn,optim
import syft as sy
from syft.workers.virtual import VirtualWorker
from syft.exceptions import WorkerNotFoundException",import torch th torch import import import import,issue,negative,neutral,neutral,neutral,neutral,neutral
590059003,"I have a silly question but have done a full ‘import syft as sy’ before?
I had a similar error when doing strange things during the syft import

What is the full sample of code you re trying to run?",silly question done full import similar error strange import full sample code trying run,issue,negative,positive,neutral,neutral,positive,positive
590057792,"It is and you may!

Sent from my iPhone

> On 22 Feb 2020, at 17:37, jimboH <notifications@github.com> wrote:
> 
> ﻿
> Hi, I would like to know if this is still an active issue. If it is, could I take this issue?
> 
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub, or unsubscribe.
",may sent wrote hi would like know still active issue could take issue thread reply directly view,issue,positive,negative,neutral,neutral,negative,negative
590026025,"Is this issue free to work ? If so, please assign me @LaRiffle ",issue free work please assign,issue,positive,positive,positive,positive,positive,positive
589988135,"@DanyEle We finally got the translation tests running correctly, so I'll merge this when the tests pass.
",finally got translation running correctly merge pas,issue,negative,neutral,neutral,neutral,neutral,neutral
589986982,"@AnchalAgarwal21 Huh, haven't seen that issue with that version. Could you share the output of `pip list` and the imports above in the notebook?",huh seen issue version could share output pip list notebook,issue,negative,neutral,neutral,neutral,neutral,neutral
589979993,"Hi, I would like to know if this is still an active issue. If it is, could I take this issue?",hi would like know still active issue could take issue,issue,positive,negative,negative,negative,negative,negative
589978876,"@DanyEle looks like it passed, but for the wrong reasons. What were trying to do is to test only the notebooks that have been changed during the build. You can have a look at the changes here https://github.com/OpenMined/PySyft/pull/3085 hopefully everything will run ok with that. ",like wrong trying test build look hopefully everything run,issue,negative,negative,negative,negative,negative,negative
589966559,"@arturomf94 is working on this. We'll get it merged, one way or another.",working get one way another,issue,negative,neutral,neutral,neutral,neutral,neutral
589924908,"Already looks better. Now only the tutorials test for build 3.7 are failing with the following error:

Test with pytest:
```
##[error]Process completed with exit code 128.
Run git diff --name-only master examples/tutorials/translations/ > ./test/notebooks/git-diff.txt
fatal: ambiguous argument 'master': unknown revision or path not in the working tree.
Use '--' to separate paths from revisions, like this:
'git <command> [<revision>...] -- [<file>...]'
##[error]Process completed with exit code 128.
```",already better test build failing following error test error process exit code run git master fatal ambiguous argument unknown revision path working tree use separate like command revision file error process exit code,issue,negative,positive,positive,positive,positive,positive
589876482,"**Since slack removes chat after a while backing up this discussion here.** 
@iamtrask @cereallarceny 
trask:anchor: [2:09 AM]
https://github.com/OpenMined/PySyft/issues/2917 <- solving this issue is becoming quite urgently needed. Several folks have talked about solving it - but as far as I know it's still up for grabs.
:+1:4

George Christopoulos  [2:18 AM]
check this
https://github.com/WittmannF/jupyter-translate

Yugandhar:openmined:  [3:38 AM]
George Christopoulos that's a nice script for automating translation work it seems it takes care of things like preserving markdown link syntax etc too.

But, in the end it creates a new file which is not the desired outcome here. It is to make a single notebook series with multilingual support(using community's  translations) (as google translate is not good enough to be trusted blindly yet)

Yugandhar:openmined:  [3:42 AM]
The closest thing that I have found till date is nbExtension(also demonstrated with gif by santteegt in issue comments) but that will require user to set the extension in their local environment moreover it is not viable in my opinion as github doesn't support preview of notebook with nbExtension so only english one will be available for reading online and one would have to perform a ton of steps to setup everything locally to see any other languages present in the notebook.
:+1:1


George Christopoulos  [3:46 PM]
yeah I know nbExtension is good option, but it needs a local setup, so we need to consider the experience of each user...

George Christopoulos  [3:49 PM]
to prevent this we need to write the steps for the local setup on the readme

Yugandhar:openmined:  [3:51 PM]
I believe requirement to do local setup for just viewing notebooks in other languages is not a good option even after providing steps. Compared to that current approach of keeping it all in separate folders on github itself though with several potential issues of keeping things in sync is better in terms of accessibility. (edited) 
:+1:1


Yugandhar:openmined:  [4:04 PM]
I am no expert at cloud but in my opinion a good solution can be making a cloud VM(I used to do it using GCP free credits for compute engine GPU) doing all the setup for nbextension there once then host all MultiLanguage notebooks there(and automate sync with github) and provide a link on top of english version that can be used to access hosted jupyter notebook environment to view the languages in any preferred language available.
It solves in browser accessibility.
Keeps repo clean as there will be only one set on github.
To edit one has to make local setup and follow standard git procedure or we can even make it possible in hosted notebook itself based on some auth idk.


What do you think? (edited) 

cereallarceny:openmined:  [5:00 PM]
jupyter-translate could work, but from my experience using google translate for translation of complex materials is usually pretty terrible…

cereallarceny:openmined:  [5:00 PM]
To me - I’d want to use something like this: https://crowdin.com/


cereallarceny:openmined:  [5:00 PM]
Here’s an example of what it may look like for us: https://crowdin.com/project/all-contributors
:+1:1


Yugandhar:openmined:  [5:02 PM]
That looks good gives us option to translate setup instructions etc too literally making the entire project multilingual. With nice coverage report and progress tracking. (edited) 

cereallarceny:openmined:  [5:18 PM]
I agree. I haven’t found anyone willing to set this up for us. I’d be happy to sign up and apply for a free open-source license if I had someone interested in taking charge of setting it up. I just don’t have the time. :slightly_smiling_face:",since slack chat backing discussion anchor issue becoming quite urgently several far know still check nice script translation work care like markdown link syntax end new file desired outcome make single notebook series multilingual support community translate good enough blindly yet thing found till date also gif issue require user set extension local environment moreover viable opinion support preview notebook one available reading one would perform ton setup everything locally see present notebook yeah know good option need local setup need consider experience user prevent need write local setup believe requirement local setup good option even providing current approach keeping separate though several potential keeping sync better accessibility expert cloud opinion good solution making cloud used free compute engine setup host sync provide link top version used access notebook environment view preferred language available browser accessibility clean one set edit one make local setup follow standard git procedure even make possible notebook based think could work experience translate translation complex usually pretty want use something like example may look like u good u option translate setup literally making entire project multilingual nice coverage report progress agree found anyone willing set u happy sign apply free license someone interested taking charge setting time,issue,positive,positive,positive,positive,positive,positive
589875900,"Hi,

I'm currently working on the translated notebooks. I wanna ask you a couple of questions:

1. It is ok if I start a PR with the translated notebook for two languages (Spanish & Chinese), and later other people can help to incorporate the others?
2. There are some code cells with comments that also require to be translated. However, the plugin I'm using has only support for markdown cells. Would it be okay if those comments are put into a separate markdown cell?",hi currently working wan na ask couple start notebook two later people help incorporate code also require however support markdown would put separate markdown cell,issue,positive,negative,neutral,neutral,negative,negative
589793460,"I was able to workaround by changing the generic/frameworks/hook/hook_args.py file so the register_tensor function is:

```python
def register_tensor(
    tensor: FrameworkTensorType, owner: AbstractWorker, response_ids: List = list()
):
    """"""
    Registers a tensor.

    Args:
        tensor: A tensor.
        owner: The owner that makes the registration.
        response_ids: List of ids where the tensor should be stored
            and each id is pop out when needed.
    """"""

    #tensor.owner = owner
    #try:
    #    tensor.id = response_ids.pop(-1)
    #except IndexError:
    #    raise exceptions.ResponseSignatureError

    owner.register_obj(tensor, response_ids.pop(-1))
```",able file function python tensor owner list list tensor tensor tensor owner owner registration list tensor id pop owner try except raise tensor,issue,negative,positive,positive,positive,positive,positive
589773374,"@iamtrask Worth mentioning that if this had passed the formatting check, the `exec` would have been caught by the automated security scan.",worth check would caught security scan,issue,positive,positive,positive,positive,positive,positive
589767647,@DanyEle Testing out a change to the CI jobs that will bypass the workflow file requirement.,testing change bypass file requirement,issue,negative,neutral,neutral,neutral,neutral,neutral
589759112,"True that we should have such security policy, and having an exec might not be a really good idea.",true security policy might really good idea,issue,positive,positive,positive,positive,positive,positive
589755858,I do apologize for not having been more forward in the original Github Issue,apologize forward original issue,issue,negative,positive,positive,positive,positive,positive
589755658,"This is in large part because when crypten gets merged into master, it would be easy for this exec() to slip in un-noticed.",large part master would easy slip,issue,negative,positive,positive,positive,positive,positive
589755373,"I have a policy against merging ""exec()"" into PySyft's codebase - I'm not sure this qualifies as a legitimate exception.",policy sure legitimate exception,issue,negative,positive,positive,positive,positive,positive
589754285,"Plans surely have a better security guarantee than this at the moment and there is two other parallel work going on trying to use plans (and they should probably work), this is mainly aiming at exploring an alternative (pros and cons against plans), we can then evaluate which works best. ",surely better security guarantee moment two parallel work going trying use probably work mainly aiming exploring alternative evaluate work best,issue,positive,positive,positive,positive,positive,positive
589747274,"> @iamtrask It's supposed to be secure, the execution environment that the function runs on has a limited set of functionalities.

Interesting, is there a reason we're not using Plans? This seems like exactly what Plans were designed for, no?",supposed secure execution environment function limited set interesting reason like exactly designed,issue,positive,positive,positive,positive,positive,positive
589747031,"Sending whitelisted functions from one machine to another is _exactly_ what Plans are supposed to do - if Plans don't support this use case, we need to fix plans (instead of build an alternative)",sending one machine another supposed support use case need fix instead build alternative,issue,negative,neutral,neutral,neutral,neutral,neutral
589746690,"AttributeError: 'numpy.ndarray' object has no attribute 'owner'

Is this issue resolved? 

Infile : syft/frameworks/torch/tensors/interpreters/native.py
Having this line: np.log2(np.abs(self.clone().detach().numpy()) + 1) + base_fractional > max_precision 
is causing issue.",object attribute issue resolved line causing issue,issue,negative,neutral,neutral,neutral,neutral,neutral
589742633,"@iamtrask It's supposed to be secure, the execution environment that the function runs on has a limited set of functionalities.",supposed secure execution environment function limited set,issue,negative,positive,positive,positive,positive,positive
589733369,@LaRiffle Looks like the test failures mostly have to do with serialization and tagging.,like test mostly serialization,issue,negative,positive,positive,positive,positive,positive
589706606,"I'm in the process of doing some clean-up deep in the guts of Plans and Operations, starting with #3078. It may take a while to resolve this issue; not sure if making the output type more flexible or adding separate messages to the Syft protocol will turn out to be a preferable approach. Will keep this issue in mind as we sort through issues with the core abstractions.",process deep starting may take resolve issue sure making output type flexible separate protocol turn preferable approach keep issue mind sort core,issue,positive,positive,positive,positive,positive,positive
589632543,@karlhigley I have more or less the same problem running the same tutorial.  @9sashafr could you find any workaround?,le problem running tutorial could find,issue,negative,neutral,neutral,neutral,neutral,neutral
589573129,"@midokura-silvia I am using your code in [Asynchronous-federated-learning-on-MNIST](https://github.com/OpenMined/PySyft/blob/0831588f0795c226ce1057070e967d6846b015e6/examples/tutorials/advanced/websockets-example-MNIST-parallel/Asynchronous-federated-learning-on-MNIST.ipynb), however I don't use as a notebook. There you have:
```python
results = await asyncio.gather(
        *[
            rwc.fit_model_on_worker(
                worker=worker,
                traced_model=traced_model,
                batch_size=args.batch_size,
                curr_round=curr_round,
                max_nr_batches=args.federate_after_n_batches,
                lr=learning_rate,
            )
            for worker in worker_instances
        ]
    )
``` 
in this case `await` is used outside an `async` function. How didn't you get any error? ",code however use notebook python await worker case await used outside function get error,issue,negative,neutral,neutral,neutral,neutral,neutral
589543888,"@ymsaputra await needs to be called from within a function. So in your file coba_fed_async.py your await calls need to be in a function that is marked as async.

@fermat97 this is not enough information to deduce where the syntax error is coming from. ",await need within function file await need function marked enough information deduce syntax error coming,issue,negative,positive,neutral,neutral,positive,positive
589381936,I will take a look later today or tomorrow!,take look later today tomorrow,issue,negative,neutral,neutral,neutral,neutral,neutral
589303313,"@LaRiffle Your commits are pretty granular, so you can probably:
* Create a second branch pointing at the same commit
* Do an interactive rebase
* Remove the commits related to FSS and the experimental notebooks

Whatever is left would be the general improvements to the hooks, plans, protocols, etc.",pretty granular probably create second branch pointing commit interactive rebase remove related experimental whatever left would general,issue,positive,positive,neutral,neutral,positive,positive
589290993,This PR is just a packaging name change. The next step will be extracting the concept of an Operation (that gets executed on a tensor) from an OperationMessage (which gets sent around between workers.) That addresses some weirdness in the serialization and makes the execution primitives more independent from the messaging protocol.,name change next step concept operation executed tensor sent around weirdness serialization execution independent protocol,issue,negative,neutral,neutral,neutral,neutral,neutral
589209862,"hi @ymsaputra did you find any solution? Hi @midokura-silvia do you have any idea? I got 
```python
results = await asyncio.gather(
                      ^
SyntaxError: invalid syntax
```

and I use python 3.6",hi find solution hi idea got python await invalid syntax use python,issue,negative,neutral,neutral,neutral,neutral,neutral
589177790,"@LaRiffle If the Worker, Hook, and Plan parts of this PR are complete (or nearly so), could we split them out into a separate PR that we can go ahead and merge? Want to be working from the latest/greatest in those parts of the code as we make additional improvements.",worker hook plan complete nearly could split separate go ahead merge want working code make additional,issue,negative,positive,neutral,neutral,positive,positive
589091394,Facing the same Issue with recently published docker image also @karlhigley ,facing issue recently docker image also,issue,negative,neutral,neutral,neutral,neutral,neutral
589076961,"Sorry @kaustubh-seachange for all the work you put in. 
But due to lack of response we have merged #3055 and now have to close this. 
Looking forward to your future contributions :+1: ",sorry work put due lack response close looking forward future,issue,negative,negative,negative,negative,negative,negative
589020890,The source of the problem is incorrect type of the function output. According to `Operation` class (from `syft/messaging/message.py`) the output must be `Tensor`. But `evaluate()` function (from `syft/federated/federated_client.py`) returns dictionary of floats. ,source problem incorrect type function output according operation class output must tensor evaluate function dictionary,issue,negative,neutral,neutral,neutral,neutral,neutral
589020397,"@DanyEle The test that's failing is `test_github_workflows_exist_for_all_languages`, which checks that each language has a GH workflow that runs the translated notebooks for that language when they change. You can find an example workflow file [here](https://github.com/OpenMined/PySyft/blob/master/.github/workflows/tutorials-espa%C3%B1ol.yml).",test failing language language change find example file,issue,negative,neutral,neutral,neutral,neutral,neutral
588749217,@karlhigley Any idea why so many checks are failing? All I did was adding one more file without modifying any existing files.,idea many failing one file without,issue,negative,positive,positive,positive,positive,positive
588620804,"> Sorry for the delays, working on resolving notebook test issue.

thank you so much @karlhigley ",sorry working notebook test issue thank much,issue,negative,negative,negative,negative,negative,negative
588571418,@ucalyptus Could you review this one? Happy to merge once someone who knows Bengali gives it a look.,could review one happy merge someone look,issue,positive,positive,positive,positive,positive,positive
588571189,@ucalyptus Translation test issues seem to be resolved. Could you give this a review?,translation test seem resolved could give review,issue,negative,neutral,neutral,neutral,neutral,neutral
588567457,"@gmuraru This is now triggering a bunch of translation tests, since it (technically) makes changes to a bunch of the translation paths. You might want to locally merge `master` into `pytorch/crypten` and push that directly to `pytorch/crypten` first, then rebase this PR on top.",bunch translation since technically bunch translation might want locally merge master push directly first rebase top,issue,negative,positive,positive,positive,positive,positive
588564248,"This is a PR with the changes + what was added on the Master Branch (to keep it up to date).
The only effective changes were made in:
```
syft/frameworks/crypten/__init__.py
syft/frameworks/crypten/context.py
syft/workers/base.py
```",added master branch keep date effective made,issue,negative,positive,positive,positive,positive,positive
588373927,"@ZumrutMuftuoglu Still working on the translated content for this PR? It's empty right now, but I can leave it open if you're still working on it.",still working content empty right leave open still working,issue,negative,positive,neutral,neutral,positive,positive
588333205,"@vvmnnnkv I think you found a way to JIT trace complicated plans, so closing this draft PR.",think found way trace complicated draft,issue,negative,negative,negative,negative,negative,negative
588291791,The Docker image is out of date. We’re working on getting updates published.,docker image date working getting,issue,negative,neutral,neutral,neutral,neutral,neutral
588291161,"Sorry for the delays, working on resolving notebook test issue.",sorry working notebook test issue,issue,negative,negative,negative,negative,negative,negative
588289629,Sounds like we might need to release a new version with recent fixes.,like might need release new version recent,issue,negative,positive,neutral,neutral,positive,positive
588223506,To add a little context: this is caused by some [breaking changes](https://github.com/msgpack/msgpack-python#major-breaking-changes-in-msgpack-10) in `msgpack` 1.0 which was released yesterday.,add little context breaking yesterday,issue,negative,negative,negative,negative,negative,negative
588116107,@LaRiffle It does not work in the official docker image provided,work official docker image provided,issue,negative,neutral,neutral,neutral,neutral,neutral
588093246,@ucalyptus sorry I don't know Bengali. I did skim through it and requested some markdown changes.,sorry know skim markdown,issue,negative,negative,negative,negative,negative,negative
587566771,That sounds reasonable. Happy to merge a fix when you a get a chance to work on it. No rush.,reasonable happy merge fix get chance work rush,issue,positive,positive,positive,positive,positive,positive
587557977,"Docker context is pysyft root while `entrypoint.sh` referenced in Dockerfile is located in `docker-images/pysyft-notebook/` folder. Build command can be updated to specify correct context path:
`docker build -t $IMAGE -f docker-images/pysyft-notebook/Dockerfile docker-images/pysyft-notebook`
Alternatively, Dockerfile can be updated to specify `entrypoint.sh` location from pysyft root.
",docker context root folder build command specify correct context path docker build image alternatively specify location root,issue,negative,neutral,neutral,neutral,neutral,neutral
587553393,"Seems we need to pass the entrypoint.sh that goes along with the Dockerfile, but I think it needs to passed as it's not in the current working directory, sorry I should've checked this. I can work on it later today if it's not a rush.

Edit: Seems it could be as straightfoward as pointing to the folder (which has the entrypoint.sh) and not the DockerFile itself?",need pas go along think need current working directory sorry checked work later today rush edit could pointing folder,issue,negative,negative,negative,negative,negative,negative
587506806,"@linamnt Thanks for your work on this! Finally got it merged, and it looks like there's [an issue](https://github.com/OpenMined/PySyft/runs/452995051?check_suite_focus=true) with the process of building the Docker image on GH. It's failing with the error:
```
Step 8/10 : COPY ./entrypoint.sh /
COPY failed: stat /var/lib/docker/tmp/docker-builder735825847/entrypoint.sh: no such file or directory
##[error]Process completed with exit code 1.
```
Any idea what that's about or how to address it?",thanks work finally got like issue process building docker image failing error step copy copy file directory error process exit code idea address,issue,negative,positive,neutral,neutral,positive,positive
587470911,"@arturomf94 It looks like `git diff` with the branch reference doesn't work as expected in the translation tests from #3060. Maybe it only checks out one branch?

```

Run git diff --name-only master examples/tutorials/translations/ examples/tutorials/translations/ > ./test/notebooks/git-diff.txt
  git diff --name-only master examples/tutorials/translations/ examples/tutorials/translations/ > ./test/notebooks/git-diff.txt
  pytest test/notebooks/test_notebooks.py::test_notebooks_basic_translations_diff
  [ -e ./test/notebooks/git-diff.txt ] && rm ./test/notebooks/git-diff.txt
  shell: /bin/bash -e {0}
  env:
    pythonLocation: /opt/hostedtoolcache/Python/3.6.10/x64
fatal: ambiguous argument 'master': unknown revision or path not in the working tree.
Use '--' to separate paths from revisions, like this:
'git <command> [<revision>...] -- [<file>...]'
##[error]Process completed with exit code 128.
```",like git branch reference work translation maybe one branch run git master git master shell fatal ambiguous argument unknown revision path working tree use separate like command revision file error process exit code,issue,negative,negative,neutral,neutral,negative,negative
587460175,"Another alternative would be to jail the execution of the sent function in a secure execution environment. This means that only crypten functionalities are available, no filesystem access, no networking etc. I'm checking this [library](https://github.com/zopefoundation/RestrictedPython) and if we can use it to secure the function sharing across workers.",another alternative would jail execution sent function secure execution environment available access library use secure function across,issue,positive,positive,positive,positive,positive,positive
587422817,"thank you so much. It works when I run them as you said, in the background. ",thank much work run said background,issue,negative,positive,positive,positive,positive,positive
587300151,@TTitcombe I've added the watermark to one [notebook](https://github.com/BBloggsbott/PySyft/blob/add-watermarks/examples/tutorials/Part%2001%20-%20The%20Basic%20Tools%20of%20Private%20Deep%20Learning.ipynb) in the tutorials. Can you verify if the information is sufficient?,added watermark one notebook verify information sufficient,issue,negative,neutral,neutral,neutral,neutral,neutral
587281071,"Weird. I've included an empty file, just to check if it was indeed that.",weird included empty file check indeed,issue,negative,negative,negative,negative,negative,negative
587271349,"The test coverage checks are failing because lines 41-43 of test_notebooks.py aren’t run, which I think is because there is no git diff file.",test coverage failing run think git file,issue,negative,neutral,neutral,neutral,neutral,neutral
587148764,"If it helps - for Tensorflow the current roadmap is to use TFF to create Tensorflow's version of ""plans"" and then ship those over (still wrapped in a ""Plan"" like object?)",current use create version ship still wrapped plan like object,issue,positive,neutral,neutral,neutral,neutral,neutral
587094140,"@karlhigley that's right. Perhaps there can be a local test and a remote test (this one). So, the remote one wouldn't really be testing any notebooks locally because no diff? ",right perhaps local test remote test one remote one would really testing locally,issue,negative,positive,neutral,neutral,positive,positive
587093033,"@arturomf94 Something like that could also work. It would even be a little smoother to start translations in a new language, because you wouldn't have to create a new GH Workflow file. One downside is that it looks like the translation tests wouldn't run locally.",something like could also work would even little smoother start new language would create new file one downside like translation would run locally,issue,positive,positive,neutral,neutral,positive,positive
587091250,"This looks reasonable. I was working on a a potential solution on [this branch](https://github.com/arturomf94/PySyft/tree/fix-translation-tests). Only the changed translations would be tested, but don't know whether this would work yet. What do you think?",reasonable working potential solution branch would tested know whether would work yet think,issue,negative,positive,neutral,neutral,positive,positive
586980417,"An alternative would be to send the source code of the function definition (we can get it from the function object using the dill library), then each worker will need to run static analysis (using [AST](https://docs.python.org/3/library/ast.html) or a similar library) to make sure the function is safe.

Running static analysis, we can have a whitelist of allowed function calls, and flag as unsafe any function that goes beyond those calls. We can do the same for attributes, however, we will also need to track variable types as  the _objects attribute might be a safe to access on object X but not on object Y. So the whitelist must be a list of (type, func | attr) pairs to have both flexibility and security.",alternative would send source code function definition get function object dill library worker need run static analysis ast similar library make sure function safe running static analysis function flag unsafe function go beyond however also need track variable attribute might safe access object object must list type flexibility security,issue,positive,positive,positive,positive,positive,positive
586751298,The translation test suite is now taking too long again after so many translations have been added. It probably needs to be split apart into separate actions per language.,translation test suite taking long many added probably need split apart separate per language,issue,negative,positive,positive,positive,positive,positive
586558252,"@adventuroussrv @karlhigley any insights on why the tutorials CI is failing for all PRs related to translations?
Close look at the CI trace suggests pytest errors.",failing related close look trace,issue,negative,neutral,neutral,neutral,neutral,neutral
586285780,"> @jefersonf Why not just use the change you mentioned [here](https://github.com/OpenMined/PySyft/issues/3007#issuecomment-582028097)? I feel only the virtual workers will need to simulate latency.

At first I thought so too, but I think in cases where a tensor is sent to a worker like in the following:

```
torch.tensor([1,2,3]).send(alice, pending_time=2)
```
the same behavior should be hold.",use change feel virtual need simulate latency first thought think tensor sent worker like following behavior hold,issue,negative,positive,positive,positive,positive,positive
586090760,@jefersonf Why not just use the change you mentioned [here](https://github.com/OpenMined/PySyft/issues/3007#issuecomment-582028097)? I feel only the virtual workers will need to simulate latency.,use change feel virtual need simulate latency,issue,negative,neutral,neutral,neutral,neutral,neutral
585954908,"Hi @BBloggsbott, I tried to tackle this. And I've actually started on, if you would like to give some help please take a look at this [branch](https://github.com/jefersonf/PySyft/tree/latency_simulation/syft/).

In fact, the following case is working so far:

```
import torch
import syft as sy
hook = sy.TorchHook(torch)

alice = sy.VirtualWorker(id=""alice"", hook=hook)
bob  = sy.VirtualWorker(id=""bob"", hook=hook)
x = torch.tensor([1,2,3])

# alice waits 2 seconds before sending 'x' to bob.
alice.send(x, bob, pending_time=2)

```




",hi tried tackle actually would like give help please take look branch fact following case working far import torch import hook torch bob bob sending bob bob,issue,positive,positive,neutral,neutral,positive,positive
585869206,"Hi, I can still reproduce the error with the latest version.",hi still reproduce error latest version,issue,negative,positive,positive,positive,positive,positive
585791978,"Since commands could also be executed on other frameworks (i.e. not PyTorch) though, maybe the best thing to do for now is just label this line so the security checks ignore it.",since could also executed though maybe best thing label line security ignore,issue,positive,positive,positive,positive,positive,positive
585789666,"I think the reason `literal_eval` doesn't work here is that `Plan` is actually relying on `eval` to execute commands, not just convert strings to literal data structures. The commands that get evaluated by the `Plan` tests are:

- `torch.nn.functional.linear`
- `torch.nn.functional.relu`
- `torch.nn.functional.log_softmax`

I made a [change](https://github.com/OpenMined/PySyft/pull/2951/files) recently that addressed another `eval`, and maybe we could take a similar approach here. The tricky part is that I'm not sure if all the commands are going to be on `torch.nn.functional`; I think they could also be on other submodules of `torch` (or `torch` directly, like `torch.rand`).",think reason work plan actually execute convert literal data get plan made change recently another maybe could take similar approach tricky part sure going think could also torch torch directly like,issue,negative,positive,positive,positive,positive,positive
585777020,"Happy to merge once reviewed. We're having some trouble with the notebook tests for the translations though, so merging might be blocked for a little bit while we sort that out.",happy merge trouble notebook though might blocked little bit sort,issue,negative,positive,positive,positive,positive,positive
584825886,"Woohoo!!

On Mon, Feb 10, 2020 at 9:19 PM Héricles Emanuel <notifications@github.com>
wrote:

> *Update:* It's official! All merged! 😍 🎉
>
> —
> You are receiving this because you modified the open/close state.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/2776?email_source=notifications&email_token=ABBAZEWT7H3S4P4ASGCN4PDRCHAFZA5CNFSM4JVJMH2KYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOELKKAMI#issuecomment-584359985>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ABBAZEXLBRMOYKQYMPE6BI3RCHAFZANCNFSM4JVJMH2A>
> .
>
",woohoo mon wrote update official state reply directly view,issue,positive,positive,neutral,neutral,positive,positive
584702817,"@loopylangur the PR got merged - could you retest this, please?",got could retest please,issue,negative,neutral,neutral,neutral,neutral,neutral
584698996,"Hi, thanks for the effort doing the parts and uploading them again for the merge. I just have one request. The translation of encription is _**encriptación**_ no _encripción_ . It appears in part 9 and 13b.",hi thanks effort merge one request translation part,issue,negative,positive,positive,positive,positive,positive
584606998,"The unit test failed, seems to be the timeout in pytest.
I have found a timeout setting in test/notebook/test_notebooks.py and  it was set to 300 (at line 88, where the problem occurred)
(But the to change the setting to non-300 value, it only affect my forked repository, not the official to-be-merged repository) 
Not sure the next step to do.
Any suggestion helps!, Thanks a lot!",unit test found setting set line problem change setting value affect forked repository official repository sure next step suggestion thanks lot,issue,positive,positive,positive,positive,positive,positive
584309091,@LaRiffle could you take another look - the only change is that I increased the error threshold with 0.1.,could take another look change error threshold,issue,negative,neutral,neutral,neutral,neutral,neutral
584202378,"Okay, I will try to fix and figure out the rest tomorrow (Midnight here) and update what I have found or thoughts, attemps...etc. 
Thanks for the information!",try fix figure rest tomorrow midnight update found thanks information,issue,negative,positive,positive,positive,positive,positive
584195137,"Maybe we could do something like:
```
if use_cuda:
    torch.set_default_tensor_type(torch.cuda.FloatTensor)
    torch.multiprocessing.set_start_method('spawn', force=True)
```
  ",maybe could something like,issue,negative,neutral,neutral,neutral,neutral,neutral
584193993,"Ideally, we'd do the check to see if a GPU is available in the code, so the user doesn't have to specify, which seems like it should already by handled by `torch.cuda.is_available()` and the `use_cuda` variable.",ideally check see available code user specify like already handled variable,issue,positive,positive,positive,positive,positive,positive
584179004,"Sorry my native language is not English, does ""Can we make this change conditional on whether a GPU is available"" means that: I can do a conditional version of the notebook for GPU (for example, set the argument to let the user define whether or not to use GPU), such as the following pseudo code
```python
class args():
 self.gpu = true (Manually
 device = 'cuda' if cuda_is_available else 'cpu'
 if self.gpu = true:
 model = model.to(device)
else:
 # no op
```
 Hence the 2 versions of processing unit can be done for CI/CD",sorry native language make change conditional whether available conditional version notebook example set argument let user define whether use following pseudo code python class true manually device else true model device else hence unit done,issue,negative,positive,positive,positive,positive,positive
584159093,Increased the error threshold such that this should also fix #2937,error threshold also fix,issue,negative,neutral,neutral,neutral,neutral,neutral
584147271,Let's keep the conversation on this issue over in #2766. Left a comment there about a test failure in the CI checks.,let keep conversation issue left comment test failure,issue,negative,negative,negative,negative,negative,negative
584146917,"@Alfons0329 It looks like the notebook tests are failing on CI, because the CI machines don't have GPUs. Can we make this change conditional on whether a GPU is available?",like notebook failing make change conditional whether available,issue,negative,positive,positive,positive,positive,positive
584113825,"Ah, yeah, I think these types were introduced in newer versions of PyTorch. You’ll currently need 1.4.",ah yeah think currently need,issue,negative,neutral,neutral,neutral,neutral,neutral
584081875,Yeah plans notebook was revised recently so merge conflicts need to be resolved too,yeah notebook recently merge need resolved,issue,negative,neutral,neutral,neutral,neutral,neutral
584048029,"- [ ] Part 04 - Federated Learning via Trusted Aggregator.ipynb @jabertuhin 
- [ ] Part 05 - Welcome to the Sandbox.ipynb @jabertuhin 
- [x] Part 06 - Federated Learning on MNIST using a CNN.ipynb @ucalyptus 
- [x] Part 07 - Federated Learning with Federated Dataset.ipynb @ucalyptus 
- [ ] Part 08 - Introduction to Plans.ipynb @adventuroussrv 
- [ ] Part 08 bis - Introduction to Protocols.ipynb @adventuroussrv 
- [ ] Part 09 - Intro to Encrypted Programs.ipynb @adventuroussrv 
- [ ] Part 10 - Federated Learning with Secure Aggregation.ipynb @adventuroussrv ",part learning via part welcome part learning part learning part introduction part bi introduction part part learning secure,issue,positive,positive,positive,positive,positive,positive
583990814,Yeah sorry I made a typo. I'll do 6 and 7,yeah sorry made typo,issue,negative,negative,negative,negative,negative,negative
583989977,"Hey! @ucalyptus I have almost completed the  

-  Part 08 - Introduction to Plans.ipynb
-  Part 08 bis - Introduction to Protocols.ipynb
-  Part 09 - Intro to Encrypted Programs.ipynb
-  Part 10 - Federated Learning with Secure Aggregation.ipynb",hey almost part introduction part bi introduction part part learning secure,issue,negative,positive,positive,positive,positive,positive
583984479,"@adventuroussrv I will be working on these notebooks - 

1.  Part 04 - Federated Learning via Trusted Aggregator.ipynb
2.  Part 05 - Welcome to the Sandbox.ipynb",working part learning via part welcome,issue,negative,positive,positive,positive,positive,positive
583981366,"@jabertuhin @ucalyptus here's the issue for the translations in Bengali language! are you working or would like to translate any notebook?

I'm currently working on 
- [ ] Part 08 - Introduction to Plans.ipynb
- [ ] Part 08 bis - Introduction to Protocols.ipynb
- [ ] Part 09 - Intro to Encrypted Programs.ipynb
- [ ] Part 10 - Federated Learning with Secure Aggregation.ipynb",issue language working would like translate notebook currently working part introduction part bi introduction part part learning secure,issue,positive,positive,positive,positive,positive,positive
583858453,"If that turns out to be difficult to fix, I think you can label the line with `#nosec` to exclude it from the scan.",turn difficult fix think label line exclude scan,issue,negative,negative,negative,negative,negative,negative
583856939,It looks like `literal_eval` is causing a bunch of test failures and hanging the build. 😢 ,like causing bunch test hanging build,issue,negative,neutral,neutral,neutral,neutral,neutral
583855952,"This was a good start to the discussion. 👍 

Closing since we're in the process of redesigning and writing an RFC for protocols.",good start discussion since process writing,issue,negative,positive,positive,positive,positive,positive
583732247,"There is a problem with Parts 13b and 13c since these notebooks are excluded from the tests. This can be seen in [`test_notebooks.py`](https://github.com/OpenMined/PySyft/blob/master/test/notebooks/test_notebooks.py)

Either the notebooks are fixed or these translations are also ignored.",problem since seen either fixed also,issue,negative,positive,neutral,neutral,positive,positive
583731722,"There is a problem with the tutorial part 10 due to https://github.com/OpenMined/PySyft/pull/2990. 

It can be noted in [`test_notebooks.py`](https://github.com/OpenMined/PySyft/blob/master/test/notebooks/test_notebooks.py) that this notebook is excluded from the tests on the original English version. 

There are two options: either the translation of part 10 is also excluded from the test or https://github.com/OpenMined/PySyft/pull/2990 is fixed. ",problem tutorial part due noted notebook original version two either translation part also test fixed,issue,negative,positive,positive,positive,positive,positive
583721595,"Oh, I see, that was why #2734 was closed. I was trying to work on it.
Somehow, I usually end up with a ""bad"" first issue. Maybe there should be a ""good second issue"" label.",oh see closed trying work somehow usually end bad first issue maybe good second issue label,issue,negative,negative,neutral,neutral,negative,negative
583710136,@Yugandhartripathi @kaustubh-seachange all notebooks apart from 7 have been uploaded onto the hindi tutorials. Can you please follow up on Notebook 7? @kaustubh-seachange you need to add your name to the translations like yugandhar mentioned before. Please add that so that your translations can be merged.,apart onto please follow notebook need add name like please add,issue,positive,neutral,neutral,neutral,neutral,neutral
583704158,"On a related note, GH Actions does support caching, which could eventually support Docker caching natively, but it's definitely not there yet in any elegant form, though we may be able to wrangle some working solution together with the available actions (see https://github.com/actions/cache/issues/31 and https://github.com/actions/cache/pull/37)",related note support could eventually support docker natively definitely yet elegant form though may able wrangle working solution together available see,issue,positive,positive,positive,positive,positive,positive
583701666,"Another way is to connect docker hub with PySyft repo and setup build(s). It will rebuild images automatically on repo update. The build may be faster than in GH Actions because docker hub leverages build cache.
https://docs.docker.com/docker-hub/builds/",another way connect docker hub setup build rebuild automatically update build may faster docker hub build cache,issue,negative,neutral,neutral,neutral,neutral,neutral
583668129,I'm finishing the last few cells tomorrow and I'll make a PR.,finishing last tomorrow make,issue,negative,neutral,neutral,neutral,neutral,neutral
583594223,"You're right, I just saw it now. @MarcioPorto let us know when you're done! ;D",right saw let u know done,issue,negative,positive,positive,positive,positive,positive
583592737,"I think just the first one won't pull requested yet, but we are almost there!",think first one wo pull yet almost,issue,negative,positive,positive,positive,positive,positive
583591151,"Wonderful! Looks like all the tutorials have been translated! Now just wait for them all to be merged.
Great job folks! :heart_eyes: :tada: :rocket: ",wonderful like wait great job rocket,issue,positive,positive,positive,positive,positive,positive
583454955,"This test still fails in the GH Action with the error:
```
FileNotFoundError: [Errno 2] No such file or directory: './data/inputs.npy'
```",test still action error file directory,issue,negative,positive,neutral,neutral,positive,positive
583425621,"@KyloRen1 Thanks so much PR, and apologies it's taken so long to get merged! We've really been struggling with Travis CI, so have migrated off of it and are finally able to get translations merged again.",thanks much taken long get really struggling travis finally able get,issue,negative,positive,positive,positive,positive,positive
583421717,"As @matthiaslau said, this issue comes up because the size() method is not implemented in PySyft https://github.com/OpenMined/PySyft/issues/2201. If you use the code I posted in  https://github.com/OpenMined/PySyft/pull/2343 or write your own method for the size() method, that would break some functionalities of PySyft, but you would get your specific code to work. I also resorted to such solution to get the forward pass working. ",said issue come size method use code posted write method size method would break would get specific code work also solution get forward pas working,issue,negative,neutral,neutral,neutral,neutral,neutral
583417788,"> @codergan It looks like one of the notebooks has a call to `federated_avg` that needs to be updated to use the `data_amount` parameter. Is it possible to make that param optional?

I just make data_num default to be None. And create an list with ones to be data_num in this situation",like one call need use parameter possible make param optional make default none create list situation,issue,negative,neutral,neutral,neutral,neutral,neutral
583406987,There is an issue regarding the ```test_precision``` -- [here](https://github.com/OpenMined/PySyft/issues/2937) -- basically it is what you said @karlhigley - by running all the test we affect the RNG state. For the moment we can bump the error threshold a little bit - will update this PR today,issue regarding basically said running test affect state moment bump error threshold little bit update today,issue,negative,negative,negative,negative,negative,negative
583395212,@codergan It looks like one of the notebooks has a call to `federated_avg` that needs to be updated to use the `data_amount` parameter. Is it possible to make that param optional?,like one call need use parameter possible make param optional,issue,negative,neutral,neutral,neutral,neutral,neutral
583393977,"The test itself passes when run independently from the rest of the test suite, so I suspect there's some sort of coupling happening through shared state. I couldn't identify exactly what the problem is though. (My first guess was workers or the hook, but decoupling them didn't seem to help. Maybe RNG state?)",test run independently rest test suite suspect sort coupling happening state could identify exactly problem though first guess hook seem help maybe state,issue,negative,positive,positive,positive,positive,positive
583168408,Hi I would like to work on this if no one else has started.,hi would like work one else,issue,negative,neutral,neutral,neutral,neutral,neutral
583119231,"Get rid of all movements to devices and use no device at all. The computation will default to CPU. As I mentioned, try removing the tensor.to(device) statements and retry.",get rid use device computation default try removing device retry,issue,negative,neutral,neutral,neutral,neutral,neutral
583057781,"I am training on a cpu and my device assignment looks like this `device = torch.device(""cpu"")`
but still I have the same error , when I remove device references ",training device assignment like device still error remove device,issue,negative,neutral,neutral,neutral,neutral,neutral
583038885,"I recall getting an error similar to yours too. This may be related to GPU compatibility for this piece of code. Can you try to run this on a CPU instead of a GPU, so removing all references to devices like .to(device)?",recall getting error similar may related compatibility piece code try run instead removing like device,issue,negative,neutral,neutral,neutral,neutral,neutral
583019800," Update:
 
 * [x]   Part 01 - The Basic Tools of Private Deep Learning.ipynb
 * [x]   Part 02 - Intro to Federated Learning.ipynb
 * [x]   Part 03 - Advanced Remote Execution Tools.ipynb
 * [x]  Part 04 - Federated Learning via Trusted Aggregator.ipynb
 * [x]  Part 05 - Welcome to the Sandbox.ipynb
 * [x]   Part 06 - Federated Learning on MNIST using a CNN.ipynb
 * [x]  Part 07 - Federated Learning with Federated Dataset.ipynb
 * [x]  Part 08 - Introduction to Plans.ipynb
 * [x]  Part 08 bis - Introduction to Protocols.ipynb
 * [x]  Part 09 - Intro to Encrypted Programs.ipynb
 * [x]  Part 10 - Federated Learning with Secure Aggregation.ipynb
 * [x]  Part 11 - Secure Deep Learning Classification.ipynb
 * [x]  Part 12 - Train an Encrypted Neural Network on Encrypted Data.ipynb
 * [x]  Part 12 bis - Encrypted Training on MNIST.ipynb
 * [x]  Part 13a - Secure Classification with Syft Keras and TFE - Public Training.ipynb
 * [x]  Part 13b - Secure Classification with Syft Keras and TFE - Secure Model Serving.ipynb
 * [x]  Part 13c - Secure Classification with Syft Keras and TFE - Private Prediction Client.ipynb

Almost there :rocket:

Open PRs:
- #2977
- #2980 
- #3020 
- #3023",update part basic private deep part part advanced remote execution part learning via part welcome part learning part learning part introduction part bi introduction part part learning secure part secure deep learning part train neural network part bi training part secure classification public part secure classification secure model part secure classification private prediction almost rocket open,issue,positive,positive,positive,positive,positive,positive
583017703,"The build is failing because it cannot find the `short-conv-mnist.h5` file on Notebook _Part 13b_, but the file is a result of a `model.save` operation on the Notebook _Part 13a_, so it needs to be run first.",build failing find file notebook file result operation notebook need run first,issue,negative,positive,positive,positive,positive,positive
582897956,I'll translate _Part 12 bis - Encrypted Training on MNIST.ipynb_ and _Part 13b - Secure Classification with Syft Keras and TFE - Secure Model Serving.ipynb_.,translate bi training secure classification secure model,issue,positive,positive,positive,positive,positive,positive
582897766,"Hum indeed Docker doesn't  seem up to date at all
We should add a GitHub action to push every new version to the hub...
Will open an Issue to ask for this!",hum indeed docker seem date add action push every new version hub open issue ask,issue,negative,positive,neutral,neutral,positive,positive
582857985,"But if you just did it without support of docker/command line, that's not supposed to work. You have to initiate the gateway and both node using docker from [grid](https://github.com/OpenMined/PyGrid/) documentation or using the following commands:

Gateway (at grid/gateway):
`python gateway.py --port=5000 --start_local_db`

Each node (at grid/app/websocket):
`python websocket_app.py --id=bob --port=3001 --gateway_url=http://localhost:5000`
`python websocket_app.py --id=alice --port=3001 --gateway_url=http://localhost:5000`",without support line supposed work initiate gateway node docker grid documentation following gateway python node python python,issue,negative,neutral,neutral,neutral,neutral,neutral
582830638,"This is the code snippet I used:
```python
import syft as sy 
from syft.workers.node_client import NodeClient
from syft.grid.public_grid import PublicGridNetwork
import torch

hook = sy.TorchHook(torch)
nodes = [""ws://localhost:3000/"",""ws://localhost:3001/""]
compute_nodes = []
for node in nodes:
    compute_nodes.append( NodeClient(hook, node) )
```",code snippet used python import import import import torch hook torch node hook node,issue,negative,neutral,neutral,neutral,neutral,neutral
582743642,"@LaRiffle 

Yeap, still an issue. I pulled a fresh image and I'm still seeing the same problem. If I had to guess, it's because the docker image is on 

`syft                 0.1.18`

and the anaconda version is on 

`syft                   0.2.2a1`

but it might be a lack of 

`syft-proto             0.1.0a1.post36` on the docker image too. Is there a fix already OTW? I can try but I'm not very proficient with Docker",still issue fresh image still seeing problem guess docker image anaconda version might lack docker image fix already try proficient docker,issue,negative,positive,positive,positive,positive,positive
582727289,"in case you didn't see the error that I got :

IndexError: Dimension out of range (expected to be in range of [-1,
0], but got 1)



On Wed, Feb 5, 2020 at 1:45 PM ganesan5 <notifications@github.com> wrote:

> from syft.frameworks.torch.nn import rnn
> In class GRU,
>
> self.gru = rnn.GRU(input_dim, hidden_dim, n_layers, batch_first=True,
> dropout=drop_prob)
> self.fc = nn.Linear(hidden_dim, output_dim)
> self.relu = nn.ReLU()
>
> This uses the GRU/RNN from syft frameworks and it works in federated
> environment.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/3010?email_source=notifications&email_token=ACD4UOALCJ6AQJECTFHRWRTRBMCMRA5CNFSM4KP5IWPKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEK4Q7NA#issuecomment-582553524>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ACD4UODDXLNL3BX55XNYLCDRBMCMRANCNFSM4KP5IWPA>
> .
>
",case see error got dimension range range got wed wrote import class work environment thread reply directly view,issue,negative,positive,neutral,neutral,positive,positive
582725562,"I imported the rnn class implemented by pysyft instead of the native
pytorch and I got the following error:

input dim 7
Starting Training of GRU model
inputs :torch.Size([32, 90, 7])
labels :torch.Size([32, 1])
x inside forward torch.Size([32, 90, 7])
h inside forward torch.Size([2, 32, 128])

---------------------------------------------------------------------------PureFrameworkTensorFoundError
            Traceback (most recent call
last)~/anaconda3/envs/newpytorch/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py
in handle_func_command(cls, command)    290             new_args,
new_kwargs, new_type, args_type =
hook_args.unwrap_args_from_function(--> 291                 cmd, args,
kwargs, return_args_type=True    292             )
~/anaconda3/envs/newpytorch/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook_args.py
in unwrap_args_from_function(attr, args, kwargs, return_args_type)
156         # Try running it--> 157         new_args = hook_args(args)
   158
~/anaconda3/envs/newpytorch/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook_args.py
in <lambda>(x)    349 --> 350     return lambda x: f(lambdas, x)
351
~/anaconda3/envs/newpytorch/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook_args.py
in three_fold(lambdas, args, **kwargs)    527
lambdas[0](args[0], **kwargs),--> 528         lambdas[1](args[1],
**kwargs),    529         lambdas[2](args[2], **kwargs),
~/anaconda3/envs/newpytorch/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook_args.py
in <lambda>(i)    327         # Last if not, rule is probably == 1 so
use type to return the right transformation.--> 328         else
lambda i: forward_func[type(i)](i)    329         for a, r in
zip(args, rules)  # And do this for all the args / rules provided
~/anaconda3/envs/newpytorch/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook_args.py
in <lambda>(i)     29     if hasattr(i, ""child"")---> 30     else (_
for _ in ()).throw(PureFrameworkTensorFoundError),     31
torch.nn.Parameter: lambda i: i.child
~/anaconda3/envs/newpytorch/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook_args.py
in <genexpr>(.0)     29     if hasattr(i, ""child"")---> 30     else (_
for _ in ()).throw(PureFrameworkTensorFoundError),     31
torch.nn.Parameter: lambda i: i.child
PureFrameworkTensorFoundError:

During handling of the above exception, another exception occurred:
IndexError                                Traceback (most recent call
last)<ipython-input-12-156409d28793> in <module>      1 lr =
0.001----> 2 gru_model = train(federated_train_loader, lr,
model_type=""GRU"")
<ipython-input-11-043e717bff98> in train(federated_train_loader,
learn_rate, hidden_dim, EPOCHS, model_type)     38
model.send(worker)     39             model.zero_grad()---> 40
    out, _ = model(inputs.to(device).float(), h)     41
loss = criterion(out, labels.to(device).float())     42
loss.backward()
~/anaconda3/envs/newpytorch/lib/python3.7/site-packages/torch/nn/modules/module.py
in __call__(self, *input, **kwargs)    539             result =
self._slow_forward(*input, **kwargs)    540         else:--> 541
      result = self.forward(*input, **kwargs)    542         for hook
in self._forward_hooks.values():    543             hook_result =
hook(self, input, result)
<ipython-input-10-080fbca62aca> in forward(self, x, h)     15
print('x inside forward {}'.format(x.shape))     16         print('h
inside forward {}'.format(h.shape))---> 17         out, h =
self.gru(x, h)     18         print('out'.format(out[0].shape))     19
        out = self.fc(self.relu(out[:,-1]))
~/anaconda3/envs/newpytorch/lib/python3.7/site-packages/torch/nn/modules/module.py
in __call__(self, *input, **kwargs)    539             result =
self._slow_forward(*input, **kwargs)    540         else:--> 541
      result = self.forward(*input, **kwargs)    542         for hook
in self._forward_hooks.values():    543             hook_result =
hook(self, input, result)
~/anaconda3/envs/newpytorch/lib/python3.7/site-packages/syft/frameworks/torch/nn/rnn.py
in forward(self, x, h)    240         output = x.new(seq_len,
batch_size, self.hidden_size).zero_()    241         for t in
range(seq_len):--> 242             h_for, c_for =
self._apply_time_step(x, h_for, c_for, t)    243             output[t,
:, :] = h_for[-1, :, :]    244
~/anaconda3/envs/newpytorch/lib/python3.7/site-packages/syft/frameworks/torch/nn/rnn.py
in _apply_time_step(self, x, h, c, t, reverse_direction)    326
             )    327                 else:--> 328
h_next[layer, :, :] = rnn_layers[layer](x[t, :, :], h[layer, :, :])
329             else:    330                 if self.is_lstm:
~/anaconda3/envs/newpytorch/lib/python3.7/site-packages/torch/nn/modules/module.py
in __call__(self, *input, **kwargs)    539             result =
self._slow_forward(*input, **kwargs)    540         else:--> 541
      result = self.forward(*input, **kwargs)    542         for hook
in self._forward_hooks.values():    543             hook_result =
hook(self, input, result)
~/anaconda3/envs/newpytorch/lib/python3.7/site-packages/syft/frameworks/torch/nn/rnn.py
in forward(self, x, h)     95      96         gate_x =
self.fc_xh(x)---> 97         gate_h = self.fc_hh(h)     98
x_r, x_z, x_n = gate_x.chunk(self.num_chunks, 1)     99         h_r,
h_z, h_n = gate_h.chunk(self.num_chunks, 1)
~/anaconda3/envs/newpytorch/lib/python3.7/site-packages/torch/nn/modules/module.py
in __call__(self, *input, **kwargs)    539             result =
self._slow_forward(*input, **kwargs)    540         else:--> 541
      result = self.forward(*input, **kwargs)    542         for hook
in self._forward_hooks.values():    543             hook_result =
hook(self, input, result)
~/anaconda3/envs/newpytorch/lib/python3.7/site-packages/torch/nn/modules/linear.py
in forward(self, input)     85      86     def forward(self,
input):---> 87         return F.linear(input, self.weight, self.bias)
   88      89     def extra_repr(self):
~/anaconda3/envs/newpytorch/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook.py
in overloaded_func(*args, **kwargs)    599
handle_func_command = syft.framework.Tensor.handle_func_command    600
--> 601             response = handle_func_command(command)    602
603             return response
~/anaconda3/envs/newpytorch/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py
in handle_func_command(cls, command)    330             # in the
execute_command function    331             try:--> 332
 response = cls._get_response(cmd, args, kwargs)    333
except AttributeError:    334                 # Change the library
path to avoid errors on layers like AvgPooling
~/anaconda3/envs/newpytorch/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py
in _get_response(cmd, args, kwargs)    343         """"""    344
if isinstance(args, tuple):--> 345             response =
eval(cmd)(*args, **kwargs)    346         else:    347
response = eval(cmd)(args, **kwargs)
~/anaconda3/envs/newpytorch/lib/python3.7/site-packages/torch/nn/functional.py
in linear(input, weight, bias)   1368     if input.dim() == 2 and bias
is not None:   1369         # fused op is marginally faster-> 1370
    ret = torch.addmm(bias, input, weight.t())   1371     else:   1372
        output = input.matmul(weight.t())
~/anaconda3/envs/newpytorch/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook.py
in overloaded_func(*args, **kwargs)    599
handle_func_command = syft.framework.Tensor.handle_func_command    600
--> 601             response = handle_func_command(command)    602
603             return response
~/anaconda3/envs/newpytorch/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py
in handle_func_command(cls, command)    330             # in the
execute_command function    331             try:--> 332
 response = cls._get_response(cmd, args, kwargs)    333
except AttributeError:    334                 # Change the library
path to avoid errors on layers like AvgPooling
~/anaconda3/envs/newpytorch/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py
in _get_response(cmd, args, kwargs)    343         """"""    344
if isinstance(args, tuple):--> 345             response =
eval(cmd)(*args, **kwargs)    346         else:    347
response = eval(cmd)(args, **kwargs)
IndexError: Dimension out of range (expected to be in range of [-1,
0], but got 1)


On Wed, Feb 5, 2020 at 1:45 PM ganesan5 <notifications@github.com> wrote:

> from syft.frameworks.torch.nn import rnn
> In class GRU,
>
> self.gru = rnn.GRU(input_dim, hidden_dim, n_layers, batch_first=True,
> dropout=drop_prob)
> self.fc = nn.Linear(hidden_dim, output_dim)
> self.relu = nn.ReLU()
>
> This uses the GRU/RNN from syft frameworks and it works in federated
> environment.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/3010?email_source=notifications&email_token=ACD4UOALCJ6AQJECTFHRWRTRBMCMRA5CNFSM4KP5IWPKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEK4Q7NA#issuecomment-582553524>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ACD4UODDXLNL3BX55XNYLCDRBMCMRANCNFSM4KP5IWPA>
> .
>
",class instead native got following error input dim starting training model inside forward inside forward recent call last command try running lambda return lambda lambda last rule probably use type return right else lambda type zip provided lambda child else lambda child else lambda handling exception another exception recent call last module train train worker model device loss criterion device self input result input else result input hook hook self input result forward self print inside forward print inside forward print self input result input else result input hook hook self input result forward self output range output self else layer layer layer else self input result input else result input hook hook self input result forward self self input result input else result input hook hook self input result forward self input forward self input return input self response command return response command function try response except change library path avoid like response else response linear input weight bias bias none fused marginally ret bias input else output response command return response command function try response except change library path avoid like response else response dimension range range got wed wrote import class work environment thread reply directly view,issue,negative,positive,neutral,neutral,positive,positive
582718195,"> It looks like there's something off with the notebook tests action. It's running all the tests (including the notebooks/translations), but should only run the notebook tests.

running `pytest test test/notebooks/test_notebooks.py::test_notebooks_basic_translations` on my local machine also runs all tests. I don't think this has to do with CI, perhaps the actual test units we have call the main test suite in some way.",like something notebook action running run notebook running test local machine also think perhaps actual test call main test suite way,issue,negative,positive,neutral,neutral,positive,positive
582553524,"from syft.frameworks.torch.nn import rnn
In class GRU, 

self.gru = rnn.GRU(input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob)
self.fc = nn.Linear(hidden_dim, output_dim)
self.relu = nn.ReLU() 

This uses the GRU/RNN from syft frameworks  and it works in federated environment. ",import class work environment,issue,negative,neutral,neutral,neutral,neutral,neutral
582415070,"It looks like there's something off with the notebook tests action. It's running all the tests (including the notebooks/translations), but should only run the notebook tests.",like something notebook action running run notebook,issue,negative,positive,neutral,neutral,positive,positive
582396612,"Update:

- [x]  Part 01 - The Basic Tools of Private Deep Learning.ipynb
- [x]  Part 02 - Intro to Federated Learning.ipynb
- [x]  Part 03 - Advanced Remote Execution Tools.ipynb
- [x] Part 04 - Federated Learning via Trusted Aggregator.ipynb
- [x] Part 05 - Welcome to the Sandbox.ipynb
- [x]  Part 06 - Federated Learning on MNIST using a CNN.ipynb
- [x] Part 07 - Federated Learning with Federated Dataset.ipynb
- [x] Part 08 - Introduction to Plans.ipynb
- [x] Part 08 bis - Introduction to Protocols.ipynb
- [x] Part 09 - Intro to Encrypted Programs.ipynb
- [x] Part 10 - Federated Learning with Secure Aggregation.ipynb
- [x] Part 11 - Secure Deep Learning Classification.ipynb
- [x] Part 12 - Train an Encrypted Neural Network on Encrypted Data.ipynb
- [ ] Part 12 bis - Encrypted Training on MNIST.ipynb
- [x] Part 13a - Secure Classification with Syft Keras and TFE - Public Training.ipynb
- [ ] Part 13b - Secure Classification with Syft Keras and TFE - Secure Model Serving.ipynb
- [ ] Part 13c - Secure Classification with Syft Keras and TFE - Private Prediction Client.ipynb",update part basic private deep part part advanced remote execution part learning via part welcome part learning part learning part introduction part bi introduction part part learning secure part secure deep learning part train neural network part bi training part secure classification public part secure classification secure model part secure classification private prediction,issue,positive,positive,positive,positive,positive,positive
582376105,"Wow, I'm in need of a Github Actions tutorial. @karlhigley or @systemshift can you guide me with this ?
A small gist readme or a blog would also do",wow need tutorial guide small gist would also,issue,positive,negative,neutral,neutral,negative,negative
582161308,"I already checked this issue. That's why I asking the help of pysyft team, maybe somebody tried to solve it",already checked issue help team maybe somebody tried solve,issue,positive,neutral,neutral,neutral,neutral,neutral
582127399,"I extended my example to answer some of your questions, I agree this is STATIC for the moment, but it's quite easy to turn to DYNAMIC: activate the tracing mode, do whatever you want, close the trace and pickup the tapes to build a protocol.",extended example answer agree static moment quite easy turn dynamic activate tracing mode whatever want close trace pickup build protocol,issue,positive,positive,positive,positive,positive,positive
582110712,"The RuntimeError is because the size method is not working with syft, see https://github.com/OpenMined/PySyft/issues/2201.",size method working see,issue,negative,neutral,neutral,neutral,neutral,neutral
582085810,"@LaRiffle sorry, my mistake. I was not instantiating `hook = sy.TorchHook(torch)` because i thought my main file was getting `hook` from another file. So, not to worry about :smile: ",sorry mistake hook torch thought main file getting hook another file worry smile,issue,negative,negative,neutral,neutral,negative,negative
582067683,"Definitely interesting - but there are a few features missing from the prototype above.


```
# Secure aggregation protocol
worker1 = sy.VirtualWorker(hook=hook, id=""worker1"")
worker2 = sy.VirtualWorker(hook=hook, id=""worker2"")
worker3 = sy.VirtualWorker(hook=hook, id=""worker3"")

worker1_model = worker1.Promise.Model()
worker2_model = worker2.Promise.Model()
worker3_model = worker3.Promise.Model()

worker1_shares = worker1_model.share(worker1, worker2, worker3)
worker2_shares = worker2_model.share(worker1, worker2, worker3)
worker3_shares = worker3_model.share(worker1, worker2, worker3)

new_model_shares = (worker1_shares + worker2_shares + worker3_shares) / 3

new_model_shares[""worker1""].declare_output()
new_model_shares[""worker2""].declare_output()
new_model_shares[""worker3""].declare_output()
secure_aggregation_protocol = sy.Protocol(worker1, worker2, worker3)
```

- Would we still be able to declare separate inputs and outputs corresponding to each worker?
- Would we still be able to indicate type information for inputs and outputs?
- Optional: Could .we call .deploy() multiple times?
- Can you show this example involving coordinating between multiple workers? Right now the plan only specifies 1 worker and ""local"" is implied.
- Is it possible to specify that a worker should create a tensor of their own (as opposed to it being an input... i.e. torch.zeros(2,3))
- Let's make an example requiring multiple inputs from multiple different actors which are submitted asynchronously.

To be clear - I like the interface you propose as an option. I think that yours is an interesting STATIC graph API whereas the one I proposed is a DYNAMIC graph API which can be converted into a static graph. We should support both.",definitely interesting missing prototype secure aggregation protocol worker worker worker worker worker worker worker worker worker worker worker worker worker worker worker worker worker worker worker worker worker would still able declare separate corresponding worker would still able indicate type information optional could call multiple time show example multiple right plan worker local possible specify worker create tensor opposed input let make example multiple multiple different clear like interface propose option think interesting static graph whereas one dynamic graph converted static graph support,issue,positive,positive,positive,positive,positive,positive
582060619,"I'm having same issue on OSX/conda env, is the compatibility with 1.4 not yet resolved? do I need to downgrade pytorch to 1.3?",issue compatibility yet resolved need downgrade,issue,negative,neutral,neutral,neutral,neutral,neutral
582050271,"This is a neat idea! I can definitely see it working, particularly with the `worker.torch` syntax.",neat idea definitely see working particularly syntax,issue,positive,positive,neutral,neutral,positive,positive
582031226,"@kaustubh-seachange hey! :)
So i finished 9 and 10 a few days back and have asked to them to merged into the master.  If you have time, you can review them (instead of translating again) --  on pull request 2909. That way we can push for changes asap :)",hey finished day back master time review instead pull request way push,issue,negative,neutral,neutral,neutral,neutral,neutral
582028097,"What do you mean by latency simulation? Would it be an new option to a _VirtualWorker_ like `add_latency=100`?. Like the following example.
```
...
import time

class VirtualWorker(BaseWorker, FederatedClient):
    def _send_msg(self, message: bin, location: BaseWorker, latency: int = 0) -> bin:
        time.sleep(latency)
        return location._recv_msg(message)
```
",mean latency simulation would new option like like following example import time class self message bin location latency bin latency return message,issue,positive,negative,neutral,neutral,negative,negative
582024887,"> @IanQS is this issue solved?

@LaRiffle  Apologies, I haven't followed up since #2931 got solved. I can do it later today and try to open a docker image PR ",issue since got later today try open docker image,issue,negative,neutral,neutral,neutral,neutral,neutral
582014669,"While I was testing, I just realize that I want to send my dataset with tags in pygrid, so I think that is not the best option to me. For now I'm using a stable version that works to me, just a few commits ago.

Here is a small example that you asked for: https://gist.github.com/joaolcaas/4be061459b5893cfc2b73b9a1620c94f

The error here hapens before the any call to send because here exists just one `data_iter`.  The `./data2` is a path for cifar10 dataset. I don't know if you would like to test once the error is related to grid, but is a syft error.



",testing realize want send think best option stable version work ago small example error call send one path know would like test error related grid error,issue,negative,positive,positive,positive,positive,positive
581952668,I can't guess what is happening with the Travis CI tests and the cause is the same as #2990. As @gmuraru said in [this comment](https://github.com/OpenMined/PySyft/pull/2990#issuecomment-581178609) seems to have something to do with the Part 10 tutorial on master too.,ca guess happening travis cause said comment something part tutorial master,issue,negative,neutral,neutral,neutral,neutral,neutral
581942169,@raheja @Yugandhartripathi Would you review this PR and merge them I have already pushed the changes for hindi tutorial 8 into the forked branch. Letme put that in my schedule to complete next tutorial 9 and 10.,would review merge already tutorial forked branch put schedule complete next tutorial,issue,negative,positive,neutral,neutral,positive,positive
581938075,"That was exactly what I was writing, I was using DataLoader from torch and not from syft. Maybe if I use `sy.FederatedDataLoader` it works, but I don't know for sure. I'm going to test it and return with a feedback. ",exactly writing torch maybe use work know sure going test return feedback,issue,negative,positive,positive,positive,positive,positive
581935421,Could you provide a small example? Because it is used bu Tutorial 6 and seems to be working there.,could provide small example used bu tutorial working,issue,negative,negative,negative,negative,negative,negative
581933242,"Hum, so it says that `syft.hook` is a function while it's supposed to be an instance of `TorchHook`",hum function supposed instance,issue,negative,neutral,neutral,neutral,neutral,neutral
581855330,"We may require a new plan builder for crypten. I think we can solve issues 2 and 3 listed above by setupping local parties using virtual workers, running the crypten computation and recording operations.",may require new plan builder think solve listed local virtual running computation recording,issue,negative,positive,neutral,neutral,positive,positive
581765725,@ADMoreau Cool! Drop me a line at `hamish (at) ivey-law.name` and we can discuss possible paths forward.,cool drop line discus possible forward,issue,negative,positive,positive,positive,positive,positive
581215529,"Thanks @karlhigley I can get the data with the method below.
* Clientside
```
data = torch.tensor([1, 1, 1, 1, 1])
data.tag('mytag')
local_worker.load_data([data])
local_worker.start()
```
* Serverside
```
data = remote_client.search('mytag')[0].get()
```
![image](https://user-images.githubusercontent.com/35265996/73621516-5d5f5900-4671-11ea-9d71-d1c761e2dc09.png)

But consider federated learning, we should do the following things:
1. load data on the clientside
1. send model to the clientside
1. train the model with the client data
If I don't like the client data be exposure to the serverside, I can do
```
data = data.private_tensor(allowed_users=(""testing""))
```
before the client load the data.
If I set the data to be private, I can't see the tensor on the serverside. How can I do operations on that tensor to 'train' my model?",thanks get data method data data data image consider learning following load data send model train model client data like client data exposure data testing client load data set data private ca see tensor tensor model,issue,positive,positive,neutral,neutral,positive,positive
581187093,Backward references would also be handy for garbage collection.,backward would also handy garbage collection,issue,negative,positive,positive,positive,positive,positive
581185940,"Hey,
Large Precision is depreciated and will removed in the future,
Can you use _classic_ Fixed Precision for your usecase?",hey large precision removed future use fixed precision,issue,negative,positive,positive,positive,positive,positive
581184733,"So I think that actually plans would be built using pure torch.tensors, which is ok to record operations in the `run_multiprocess`. The only pb is regarding the crypten specific bits:
```

@mpc.run_multiprocess(world_size=2)
def examine_binary_shares():
    x_enc = crypten.load('models/tutorial4_alice_model.pth', dummy_model=dummy_model, src=ALICE)
    
    y = x_enc * 2  # This is easy
    return y
```

Regarding the `crypten.load('path', src...)`, I'd favour replacing it by a simple `syft.search('#tag',src=alice)`  (which needs to be implemented)

If we do this, we can (at the expense of slightly changing the syntax as shown above) record all the meaningful operations by running the plan only once on the client using cleartext pure torch tensors, and then forward this to the remote workers which hold the crypten workers. (Here syft.search would be recorded by a `@tracer` decorator, but would output probably just a random tensors without really doing a search (we don't want to bother alice))
",think actually would built pure record regarding specific easy return regarding simple tag need expense slightly syntax shown record meaningful running plan client pure torch forward remote hold would tracer decorator would output probably random without really search want bother,issue,negative,positive,neutral,neutral,positive,positive
581178609,"It seems that there is an error here (it is lalso present on master, but also in this PR). Do you have some time to investigate :)
```
~/contrib/tests/PySyft/syft/generic/frameworks/hook/hook_args.py in <lambda>(i, **kwargs)
    742         if isinstance(r, (list, tuple))  # if the rule is a list or tuple.
    743         # Last if not, rule is probably == 1 so use type to return the right transformation.
--> 744         else lambda i, **kwargs: register_tensor(i, **kwargs)
    745         for a, r in zip(response, rules)  # And do this for all the responses / rules provided
    746     ]

~/contrib/tests/PySyft/syft/generic/frameworks/hook/hook_args.py in register_tensor(tensor, owner, response_ids)
    710             and each id is pop out when needed.
    711     """"""
--> 712     tensor.owner = owner
    713     try:
    714         tensor.id = response_ids.pop(-1)

AttributeError: 'numpy.ndarray' object has no attribute 'owner'
```",error present master also time investigate lambda list rule list last rule probably use type return right transformation else lambda zip response provided tensor owner id pop owner try object attribute,issue,negative,positive,neutral,neutral,positive,positive
581173299,"I'm having a similar problem using the containerized workers (built from the unmodified pysyft-worker docker image) and the toy example from /examples/deploy_workers:

```
import torch
import syft
from syft import WebsocketClientWorker

hook = syft.TorchHook(torch)

alice = WebsocketClientWorker(hook=hook, id=""alice"", host='127.0.0.1', port=8777)

t = torch.tensor([73, 74, 75])
ta = t.send(alice)

print(ta.get())
```

It fails on t.send, here's what the worker reports (the trace below is printed twice for each failed attempt at `.send`):

> alice_1  | Task exception was never retrieved
> alice_1  | future: <Task finished coro=<WebsocketServerWorker._producer_handler() done, defined at /usr/local/lib/python3.6/site-packages/syft/workers/websocket_server.py:95> exception=IndexError('tuple index out of range',)>
> alice_1  | Traceback (most recent call last):
> alice_1  |   File ""/usr/local/lib/python3.6/site-packages/syft/workers/websocket_server.py"", line 113, in _producer_handler
> alice_1  |     response = self._recv_msg(message)
> alice_1  |   File ""/usr/local/lib/python3.6/site-packages/syft/workers/websocket_server.py"", line 124, in _recv_msg
> alice_1  |     return self.recv_msg(message)
> alice_1  |   File ""/usr/local/lib/python3.6/site-packages/syft/workers/base.py"", line 285, in recv_msg
> alice_1  |     msg = sy.serde.deserialize(bin_message, worker=self)
> alice_1  |   File ""/usr/local/lib/python3.6/site-packages/syft/serde/serde.py"", line 351, in deserialize
> alice_1  |     return _detail(worker, simple_objects)
> alice_1  |   File ""/usr/local/lib/python3.6/site-packages/syft/serde/serde.py"", line 543, in _detail
> alice_1  |     return detailers[obj[0]](worker, obj[1])
> alice_1  |   File ""/usr/local/lib/python3.6/site-packages/syft/messaging/message.py"", line 207, in detail
> alice_1  |     return ObjectMessage(sy.serde._detail(worker, msg_tuple[1]))
> alice_1  | IndexError: tuple index out of range

For good measure, here's what the main process reports:

> WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tf_encrypted/session.py:24: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.
> 
> Websocket connection closed (worker: alice)
> Created new websocket connection
> Traceback (most recent call last):
>   File ""master.py"", line 12, in <module>
>     ta = t.send(alice)
>   File ""/usr/local/lib/python3.6/site-packages/syft/frameworks/torch/tensors/interpreters/native.py"", line 419, in send
>     garbage_collect_data=garbage_collect_data,
>   File ""/usr/local/lib/python3.6/site-packages/syft/workers/base.py"", line 395, in send
>     self.send_obj(obj, worker)
>   File ""/usr/local/lib/python3.6/site-packages/syft/workers/base.py"", line 607, in send_obj
>     return self.send_msg(ObjectMessage(obj), location)
>   File ""/usr/local/lib/python3.6/site-packages/syft/workers/base.py"", line 277, in send_msg
>     bin_response = self._send_msg(bin_message, location)
>   File ""/usr/local/lib/python3.6/site-packages/syft/workers/virtual.py"", line 7, in _send_msg
>     return location._recv_msg(message)
>   File ""/usr/local/lib/python3.6/site-packages/syft/workers/websocket_client.py"", line 104, in _recv_msg
>     ""Websocket connection closed and creation of new connection failed.""
> RuntimeError: Websocket connection closed and creation of new connection failed.
> Exception ignored in: <bound method ObjectPointer.__del__ of [PointerTensor | me:32028884160 -> alice:11842207604]>
> Traceback (most recent call last):
>   File ""/usr/local/lib/python3.6/site-packages/syft/generic/pointers/object_pointer.py"", line 344, in __del__
>     self.owner.send_msg(ForceObjectDeleteMessage(self.id_at_location), self.location)
>   File ""/usr/local/lib/python3.6/site-packages/syft/workers/base.py"", line 277, in send_msg
>     bin_response = self._send_msg(bin_message, location)
>   File ""/usr/local/lib/python3.6/site-packages/syft/workers/virtual.py"", line 7, in _send_msg
>     return location._recv_msg(message)
>   File ""/usr/local/lib/python3.6/site-packages/syft/workers/websocket_client.py"", line 92, in _recv_msg
>     response = self._forward_to_websocket_server_worker(message)
>   File ""/usr/local/lib/python3.6/site-packages/syft/workers/websocket_client.py"", line 87, in _forward_to_websocket_server_worker
>     response = binascii.unhexlify(self.ws.recv()[2:-1])
>   File ""/usr/local/lib/python3.6/site-packages/websocket/_core.py"", line 314, in recv
>     opcode, data = self.recv_data()
>   File ""/usr/local/lib/python3.6/site-packages/websocket/_core.py"", line 331, in recv_data
>     opcode, frame = self.recv_data_frame(control_frame)
>   File ""/usr/local/lib/python3.6/site-packages/websocket/_core.py"", line 344, in recv_data_frame
>     frame = self.recv_frame()
>   File ""/usr/local/lib/python3.6/site-packages/websocket/_core.py"", line 378, in recv_frame
>     return self.frame_buffer.recv_frame()
>   File ""/usr/local/lib/python3.6/site-packages/websocket/_abnf.py"", line 361, in recv_frame
>     self.recv_header()
>   File ""/usr/local/lib/python3.6/site-packages/websocket/_abnf.py"", line 309, in recv_header
>     header = self.recv_strict(2)
>   File ""/usr/local/lib/python3.6/site-packages/websocket/_abnf.py"", line 396, in recv_strict
>     bytes_ = self.recv(min(16384, shortage))
>   File ""/usr/local/lib/python3.6/site-packages/websocket/_core.py"", line 453, in _recv
>     return recv(self.sock, bufsize)
>   File ""/usr/local/lib/python3.6/site-packages/websocket/_socket.py"", line 115, in recv
>     ""Connection is already closed."")
> websocket._exceptions.WebSocketConnectionClosedException: Connection is already closed.

Also, my docker-compose.yml for completeness:

```
version: '3'

services:
  alice:
    image: openmined/pysyft-worker
    environment:
      - WORKER_ID=alice
    ports:
      - 8777:8777
```",similar problem built unmodified docker image toy example import torch import import hook torch ta print worker trace printed twice attempt task exception never future task finished done defined index range recent call last file line response message file line return message file line file line return worker file line return worker file line detail return worker index range good measure main process warning name please use instead connection closed worker new connection recent call last file line module ta file line send file line send worker file line return location file line location file line return message file line connection closed creation new connection connection closed creation new connection exception bound method recent call last file line file line location file line return message file line response message file line response file line data file line frame file line frame file line return file line file line header file line min shortage file line return file line connection already closed connection already closed also completeness version image environment,issue,negative,positive,neutral,neutral,positive,positive
581162066,"It's worth noting that there is a lot of ambiguity in the `model_config` and `fl_config` listed above. We have not determined the correct values here at this moment. Before beginning this issue, one should confer with @iamtrask and @cereallarceny as to the correct config parameters.",worth lot ambiguity listed determined correct moment beginning issue one correct,issue,positive,positive,positive,positive,positive,positive
581143328,"@gmuraru  Sorry for the late reply since I was traveling with my family during 28 Jan to 1 Feb.
I will try to fix it, or add some comments as soon as I finished my school research.
Thanks for the understanding.",sorry late reply since traveling family try fix add soon finished school research thanks understanding,issue,negative,negative,negative,negative,negative,negative
581062876,"Tried to list some challenges for this. What I have been facing so far:
1. Plans support hooked torch operations exclusively, crypten tensor types aren't supported by syft for the moment.
2. When running a multiparty computation, crypten operations supports the use of the `src` parameter which specify a special behavior at party with rank `src`. If we initialized crypten with a single party group then the build will throw an error `invalid tensor source` as the `src` might be for a party with rank greater than the number of parties initialized.
3. As plans are built by running the function and recording the executed ops, running a single crypten party when more are required will block as synchronization is required between parties to complete the computation.",tried list facing far support hooked torch exclusively tensor moment running computation use parameter specify special behavior party rank single party group build throw error invalid tensor source might party rank greater number built running function recording executed running single party block synchronization complete computation,issue,positive,negative,neutral,neutral,negative,negative
581027474,"Hi, I am using PyTorch 1.4.0, and syft version 0.2.3.a1. I am trying to run [grid tutorial on federated learning](https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/grid/federated_learning/mnist/Fed.Learning%20MNIST%20%5B%20Part-1%20%5D%20-%20Populate%20a%20Grid%20Network%20(%20Dataset%20).ipynb). Once I do `compute_nodes.append( NodeClient(hook, node) )`, I get the following error:

> ConnectionRefusedError: [Errno 111] Connection refused

This is the full stack of the error:

> File ""./train.py"", line 26, in <module>
    compute_nodes.append( NodeClient(hook, node) )
  File ""/miniconda3/envs/pysyft/lib/python3.8/site-packages/syft/workers/node_client.py"", line 56, in __init__
    super().__init__(
  File ""/miniconda3/envs/pysyft/lib/python3.8/site-packages/syft/workers/websocket_client.py"", line 57, in __init__
    self.connect()
  File ""/miniconda3/envs/pysyft/lib/python3.8/site-packages/syft/workers/websocket_client.py"", line 69, in connect
    self.ws = websocket.create_connection(**args)
  File ""/miniconda3/envs/pysyft/lib/python3.8/site-packages/websocket/_core.py"", line 515, in create_connection
    websock.connect(url, **options)
  File ""/miniconda3/envs/pysyft/lib/python3.8/site-packages/websocket/_core.py"", line 222, in connect
    self.sock, addrs = connect(url, self.sock_opt, proxy_info(**options),
  File ""/miniconda3/envs/pysyft/lib/python3.8/site-packages/websocket/_http.py"", line 121, in connect
    sock = _open_socket(addrinfo_list, options.sockopt, options.timeout)
  File ""/miniconda3/envs/pysyft/lib/python3.8/site-packages/websocket/_http.py"", line 201, in _open_socket
    raise err
  File ""/miniconda3/envs/pysyft/lib/python3.8/site-packages/websocket/_http.py"", line 176, in _open_socket
    sock.connect(address)
ConnectionRefusedError: [Errno 111] Connection refused",hi version trying run grid tutorial learning hook node get following error connection full stack error file line module hook node file line super file line file line connect file line file line connect connect file line connect sock file line raise err file line address connection,issue,negative,positive,positive,positive,positive,positive
581026619,"I have tried once more, using `pip install syft` on the same environment, and it was successful. Now I can import syft without problem. ",tried pip install environment successful import without problem,issue,positive,positive,positive,positive,positive,positive
581011361,"> It is workin using VirtualWorkers, very slow, but working. But it won´t help as the goal is to use it with PyGrid. Any ideas why the ResponseSignatureError is thrown when using the websocket worker?

Did you try to replicate the code snippet I posted in https://github.com/OpenMined/PySyft/issues/2202 using web workers? Are you still getting the same error I posted there?",slow working help goal use thrown worker try replicate code snippet posted web still getting error posted,issue,negative,negative,negative,negative,negative,negative
581008081,"Hello guys, sorry that recently is a bit busy. I just changed accordingly and plz let me know if there is any problem @LaRiffle @karlhigley ",hello sorry recently bit busy accordingly let know problem,issue,negative,negative,negative,negative,negative,negative
580929020,"@Yugandhartripathi all translations done! I have updated my repo with tutorials 4, 7, 8, 8 bis, 9 and 10. Please do review them and let me know of any changes that need to be made!

@karlhigley are there any checks that these files are failing?",done bi please review let know need made failing,issue,negative,neutral,neutral,neutral,neutral,neutral
580911812,"I tried to update I couldn't, then I removed the environment and install everything from beginning, then I got this error:

> Collecting python-socketio>=4.3.0
Using cached python_socketio-4.4.0-py2.py3-none-any.whl (50 kB)
ERROR: Could not find a version that satisfies the requirement tensorflow<2,>=1.12.0 (from tf-encrypted<0.6.0!=0.5.7,>=0.5.4; extra == ""udacity""->syft[udacity]) (from versions: none)
ERROR: No matching distribution found for tensorflow<2,>=1.12.0 (from tf-encrypted<0.6.0!=0.5.7,>=0.5.4; extra == ""udacity""->syft[udacity])
",tried update could removed environment install everything beginning got error error could find version requirement extra none error matching distribution found extra,issue,negative,neutral,neutral,neutral,neutral,neutral
580815490,@vvmnnnkv Is there a reasonable way to test that the detailer raises an error in the round-trip serialization tests?,reasonable way test detailer error serialization,issue,negative,positive,positive,positive,positive,positive
580815179,"Hmm, this is tricky. I still want to test `Message.simplify()`, but if `Message` is included in the list of classes that have simplifiers and detailers, then the serialization coverage test expects it to be in the round-trip tests, which won't work without a real detailer.",tricky still want test message included list class serialization coverage test wo work without real detailer,issue,negative,positive,positive,positive,positive,positive
580796263,"@kaustubh-seachange @Yugandhartripathi  can this translation be merged into the tutorials? 
I have started translating the other notebooks since we are on a deadline. We plan to release the translations by mid Feb, so all translations and reviews must be completed by next weekend. @kaustubh-seachange can you please ensure Notebook 7 and 8 are reviewed and updated? ",translation since deadline plan release mid must next weekend please ensure notebook,issue,positive,neutral,neutral,neutral,neutral,neutral
580773408,"Hmm, well, we did see some issues with 0.2.2.a1 related to the update to PyTorch 1.4 and we released a newer version (0.2.3.a1) yesterday that might help. Maybe give that a try?",well see related update version yesterday might help maybe give try,issue,positive,neutral,neutral,neutral,neutral,neutral
580754543,"I have installed them couple of days ago, so I think it was the latest version 0.2.2a1. I have followed the pre-installation and installation guide on [PySyft git](https://github.com/OpenMined/PySyft). It is version 3.7.6 for the Python, and version 1.3.0 for the PyTorch. ",couple day ago think latest version installation guide git version python version,issue,negative,positive,positive,positive,positive,positive
580751909,"Wow, that is puzzling. What `syft` version and what Python version?",wow puzzling version python version,issue,positive,positive,neutral,neutral,positive,positive
580726382,"There is no stack trace. I start python prompt. Once I `import syft`, it quits python prompt and just showed `Illegal instruction`. ",stack trace start python prompt import quits python prompt illegal instruction,issue,negative,negative,negative,negative,negative,negative
580691008,I missed that ! Really helpful on what to do to add a new type that will be serialized. Thanks @vvmnnnkv . Implementing a new message type also requires other changes and maybe we can focus only on the message implementation and refer to this for how to make changes to protobuf to support it.,really helpful add new type thanks new message type also maybe focus message implementation refer make support,issue,positive,positive,positive,positive,positive,positive
580583665,@gmuraru No it doesn't fix the issue. The dirty fix itself generates some more issues. Hence changed the test cases according to previous setting  ☺️. ,fix issue dirty fix hence test according previous setting,issue,negative,negative,negative,negative,negative,negative
580556030,"> Resolved a conflict in `travis.yml`, which was caused by moving the list of files ignored by coverage checks into `setup.cfg`. I think `versioneer.py` will need to be added there.

looks like the merge you done got travis working. but the commit I just added still shows the same issue.
Also, now the new branch conflict cannot be solved by me, it shows I don't have write access(it was not the case before when conflicts show up)",resolved conflict moving list coverage think need added like merge done got travis working commit added still issue also new branch conflict write access case show,issue,negative,positive,positive,positive,positive,positive
580418930,@karlhigley I updated and it seems to be working!  I managed to import it and basics from the first tutorial seem to be working as well. Many thanks for such quick help. ,working import first tutorial seem working well many thanks quick help,issue,positive,positive,positive,positive,positive,positive
580394742,@s-marta Just published [a new release](https://pypi.org/project/syft/0.2.3a1/) that we think should address this issue. Could you give it a try and let us know if that resolves your issue?,new release think address issue could give try let u know issue,issue,negative,positive,positive,positive,positive,positive
580363448,"Updating...

- [x]  Part 01 - The Basic Tools of Private Deep Learning.ipynb
- [x]  Part 02 - Intro to Federated Learning.ipynb
- [x]  Part 03 - Advanced Remote Execution Tools.ipynb
- [x] Part 04 - Federated Learning via Trusted Aggregator.ipynb
- [x] Part 05 - Welcome to the Sandbox.ipynb
- [x]  Part 06 - Federated Learning on MNIST using a CNN.ipynb
- [x] Part 07 - Federated Learning with Federated Dataset.ipynb
- [x] Part 08 - Introduction to Plans.ipynb
- [x] Part 08 bis - Introduction to Protocols.ipynb
- [ ] Part 09 - Intro to Encrypted Programs.ipynb
- [ ] Part 10 - Federated Learning with Secure Aggregation.ipynb
- [ ] Part 11 - Secure Deep Learning Classification.ipynb
- [ ] Part 12 - Train an Encrypted Neural Network on Encrypted Data.ipynb
- [ ] Part 12 bis - Encrypted Training on MNIST.ipynb
- [ ] Part 13a - Secure Classification with Syft Keras and TFE - Public Training.ipynb
- [ ] Part 13b - Secure Classification with Syft Keras and TFE - Secure Model Serving.ipynb
- [ ] Part 13c - Secure Classification with Syft Keras and TFE - Private Prediction Client.ipynb",part basic private deep part part advanced remote execution part learning via part welcome part learning part learning part introduction part bi introduction part part learning secure part secure deep learning part train neural network part bi training part secure classification public part secure classification secure model part secure classification private prediction,issue,positive,positive,positive,positive,positive,positive
580327640,"Resolved a conflict in `travis.yml`, which was caused by moving the list of files ignored by coverage checks into `setup.cfg`. I think `versioneer.py` will need to be added there.",resolved conflict moving list coverage think need added,issue,negative,neutral,neutral,neutral,neutral,neutral
580302386,"@joaolcaas I've been pretty busy recently. I am almost done with part 1, but you can definitely start from part 7 onwards. Let's just keep communicating here about our progress",pretty busy recently almost done part definitely start part onwards let keep communicating progress,issue,positive,positive,neutral,neutral,positive,positive
580274903,"Hey @MarcioPorto, could you tell us how far are you at this issue? Me, @jefersonf  and another friend of us are translating some tutorials as well (from 7 ahead), but i want to check with you if there is no problem, since you took this first.",hey could tell u far issue another friend u well ahead want check problem since took first,issue,negative,positive,positive,positive,positive,positive
580255366,I also see this error! But when i use 2 workers it works fine.,also see error use work fine,issue,negative,positive,positive,positive,positive,positive
580189186,I think we need to spin a new pysyft version? @karlhigley,think need spin new version,issue,negative,positive,positive,positive,positive,positive
580186871,"It is workin using VirtualWorkers, very slow, but working. But it won´t help as the goal is to use it with PyGrid. Any ideas why the ResponseSignatureError is thrown when using the websocket worker?",slow working help goal use thrown worker,issue,negative,negative,negative,negative,negative,negative
579762703,"Ah, sorry, I think I addressed the issue that this comment highlighted in #2951, which addressed a security issue in this code.",ah sorry think issue comment security issue code,issue,negative,negative,negative,negative,negative,negative
579539634,@LaRiffle do you want to create the ```cmd``` in a simple way?,want create simple way,issue,negative,neutral,neutral,neutral,neutral,neutral
579532753,Sorry I wasn't paying attention and had to reset the pull request,sorry paying attention reset pull request,issue,negative,negative,negative,negative,negative,negative
579531704,@sukhadj I think we can close this since it is solved by #2871. Right?,think close since right,issue,negative,positive,positive,positive,positive,positive
579531683,"If we can do the translations ourself that's perfect!

On Tue, Jan 28, 2020 at 8:36 PM Santiago Gonzalez Toral <
notifications@github.com> wrote:

> Hi,
>
> I've found this nbextension
> <https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/nbextensions/nbTranslate/README.html>
> called nbTranslate where you can tag cells by languages and then use the
> menu to display the info in the language of preference. It has support for
> automatic translation using google translate and also allows you to export
> a notebook in a specific language so, e.g. there could be a script that
> generates multilingual notebooks e.b. during installation. What do you
> think about this approach?
>
> [image: lang]
> <https://user-images.githubusercontent.com/926341/73303148-dc710f00-41e3-11ea-8e4b-c08612c33dc2.gif>
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/2917?email_source=notifications&email_token=ABBAZEVR6FSN2DQSBCTQVW3RACJMNA5CNFSM4KIL6JB2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEKEZV7Q#issuecomment-579443454>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ABBAZEWWTUAE6IACBOTS7UDRACJMNANCNFSM4KIL6JBQ>
> .
>
",ourself perfect tue toral wrote hi found tag use menu display language preference support automatic translation translate also export notebook specific language could script multilingual installation think approach image thread reply directly view,issue,positive,positive,positive,positive,positive,positive
579443454,"Hi,

I've found this [nbextension](https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/nbextensions/nbTranslate/README.html) called `nbTranslate` where you can tag cells by languages and then use the menu to display the info in the language of preference. It has support for automatic translation using google translate and also allows you to export a notebook in a specific language so, e.g. there could be a script that generates multilingual notebooks e.b. during installation. What do you think about this approach?

![lang](https://user-images.githubusercontent.com/926341/73303148-dc710f00-41e3-11ea-8e4b-c08612c33dc2.gif)
",hi found tag use menu display language preference support automatic translation translate also export notebook specific language could script multilingual installation think approach,issue,negative,neutral,neutral,neutral,neutral,neutral
579442495,"Done on my end, glad to help",done end glad help,issue,positive,positive,positive,positive,positive,positive
579391060,@ADMoreau could you fix the conflict and then we are good to merge :),could fix conflict good merge,issue,negative,positive,positive,positive,positive,positive
579350805,"That would be great! Ideally thought we want to combine them all into a
single notebook series with multilingual support (using our translations)
rather than add multi-lingual support to each.

On Tue, Jan 28, 2020 at 4:33 PM Santiago Gonzalez Toral <
notifications@github.com> wrote:

> Hi guys,
>
> I'm new to PySyft and right now I'm going through all notebook tutorials.
> If you want I can give this a try and add multilingual support to each of
> them
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/2917?email_source=notifications&email_token=ABBAZERHXBWHCQO2HTNDBMLRABM6NA5CNFSM4KIL6JB2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEKD774Y#issuecomment-579338227>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ABBAZER65I5C2VUA4PEDBUDRABM6NANCNFSM4KIL6JBQ>
> .
>
",would great ideally thought want combine single notebook series multilingual support rather add support tue toral wrote hi new right going notebook want give try add multilingual support thread reply directly view,issue,positive,positive,positive,positive,positive,positive
579338227,"Hi guys,

I'm new to PySyft and right now I'm going through all notebook tutorials. If you want I can give this a try and add multilingual support to each of them",hi new right going notebook want give try add multilingual support,issue,negative,positive,positive,positive,positive,positive
579225423,"Yep!
Thank you to fix this!
I really forgot to add` requests` dependency on the requirements.txt file.",yep thank fix really forgot add dependency file,issue,positive,positive,positive,positive,positive,positive
579177675,"In that case, I think we should add only the requirements. Ping @IonesioJunior since he worked on the ```public_grid.py```, maybe you have further feedback :)",case think add ping since worked maybe feedback,issue,negative,neutral,neutral,neutral,neutral,neutral
579141381,"Traceback (most recent call last):
  File ""/home/austin/PycharmProjects/untitled7/test.py"", line 2, in <module>
    from syft.frameworks.torch.tensors.interpreters.precision import FixedPrecisionTensor
  File ""/home/austin/.virtualenvs/untitled7/lib/python3.6/site-packages/syft/__init__.py"", line 44, in <module>
    from syft.grid.public_grid import PublicGridNetwork
  File ""/home/austin/.virtualenvs/untitled7/lib/python3.6/site-packages/syft/grid/public_grid.py"", line 2, in <module>
    import requests
ModuleNotFoundError: No module named 'requests'",recent call last file line module import file line module import file line module import module,issue,negative,neutral,neutral,neutral,neutral,neutral
579138743,"The scikit learn is for the create-sandbox so I assume that is only for notebooks. I'm getting the requests requirement for FixedPrecisionTensor. I'm not sure if this is only for notebooks. Got them both while doing some debugging -> not running full code, so maybe",learn assume getting requirement sure got running full code maybe,issue,negative,positive,positive,positive,positive,positive
579110571,"If you can't find the package through typing `pip list` or other commands that gives you a list of installed packages on your virtual system, you can simply install it manually.
`pip install requests` which might need to be included in requirements.txt or something.",ca find package pip list list virtual system simply install manually pip install might need included something,issue,negative,neutral,neutral,neutral,neutral,neutral
579001717,"I am sorry to be late due to a long break.
I've just installed again `pip install syft[udacity]` and checked the requirements on `syft-proto` has been already merged in some PR. 

But the websocket connection is not resolved in v0.2.2a1, I got still same errors with my packages

Package              Version      
-------------------- -------------
absl-py              0.9.0        
astor                0.8.1        
certifi              2019.11.28   
chardet              3.0.4        
Click                7.0          
Flask                1.1.1        
Flask-SocketIO       4.2.1        
gast                 0.2.2        
google-pasta         0.1.8        
grpcio               1.26.0       
h5py                 2.10.0       
idna                 2.8          
itsdangerous         1.1.0        
Jinja2               2.11.0       
Keras-Applications   1.0.8        
Keras-Preprocessing  1.1.0        
lz4                  3.0.2        
Markdown             3.1.1        
MarkupSafe           1.1.1        
msgpack              0.6.2        
numpy                1.18.1       
opt-einsum           3.1.0        
phe                  1.4.0        
Pillow               6.2.2        
pip                  20.0.2       
pkg-resources        0.0.0        
protobuf             3.11.2       
python-engineio      3.11.2       
python-socketio      4.4.0        
PyYAML               5.3          
requests             2.22.0       
scipy                1.4.1        
setuptools           45.1.0       
six                  1.14.0       
syft                 0.2.2a1      
syft-proto           0.1.1a1.post2
tblib                1.6.0        
tensorboard          1.15.0       
tensorflow           1.15.2       
tensorflow-estimator 1.15.1       
termcolor            1.1.0        
tf-encrypted         0.5.9        
torch                1.3.0        
torchvision          0.4.1        
urllib3              1.25.8       
websocket-client     0.57.0       
websockets           8.1          
Werkzeug             0.16.1       
wheel                0.34.1       
wrapt                1.11.2       
zstd                 1.4.4.0      

I got these ones with `pip install syft[udacity]` and `pip install requests`.",sorry late due long break pip install checked already connection resolved got still package version astor click flask gast jinja markdown pillow pip six torch wheel got pip install pip install,issue,negative,negative,negative,negative,negative,negative
578974926,This issue was fixed by #2964 (for the conv2d layer) and #2945 (for the pooling layer) ,issue fixed layer layer,issue,negative,positive,neutral,neutral,positive,positive
578818363,@fermat97 Could you post a stack trace? That will help with troubleshooting the issue.,could post stack trace help issue,issue,negative,neutral,neutral,neutral,neutral,neutral
578702773,"Important question conv2d get _exactly_ the same values in the same
positions as torch's Conv2d? Aka, can I train with PyTorch's conv2d then
swap it out for this one and have it automatically work?

We've been working on an implementation which is this precise in nn,  but
it doesn't have all features yet.

On Mon, Jan 27, 2020 at 10:15 AM Théo Ryffel <notifications@github.com>
wrote:

> In nn is good!
> But maybe conv2d has to transformed into a class, or maybe not, I let you
> choose the best option here :)
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/2897?email_source=notifications&email_token=ABBAZES3L37ASBK5DPZ7B5LQ72X3JA5CNFSM4KFVASI2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEJ67EHY#issuecomment-578679327>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ABBAZESEHSFC33QBUVHLZ2LQ72X3JANCNFSM4KFVASIQ>
> .
>
",important question get torch aka train swap one automatically work working implementation precise yet mon wrote good maybe class maybe let choose best option thread reply directly view,issue,positive,positive,positive,positive,positive,positive
578679327,"In nn is good!
But maybe conv2d has to transformed into a class, or maybe not, I let you choose the best option here :)",good maybe class maybe let choose best option,issue,positive,positive,positive,positive,positive,positive
578556000,"Hi @karlhigley 
I am not sure if my question is relevant to this thread. I am running the [Federated Learning - MNIST Example of grid tutorial](https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/grid/federated_learning/mnist/Fed.Learning%20MNIST%20%5B%20Part-1%20%5D%20-%20Populate%20a%20Grid%20Network%20(%20Dataset%20).ipynb) on Google Colab. Once using ``` NodeClient(hook, node) ```, I got the following error:

```
OSError: [Errno 99] Cannot assign requested address
```
Do you have any idea? Thank you.",hi sure question relevant thread running learning example grid tutorial hook node got following error assign address idea thank,issue,negative,positive,positive,positive,positive,positive
578464679,@gmuraru the branch no longer exists. We can close this PR. I'll open a new PR with changes 🤘,branch longer close open new,issue,negative,positive,neutral,neutral,positive,positive
578421279,"Pointers can do anything that normal tensors can do. So yes, if you pass in pointers for all these inputs, then it will coordinate the execution of this method on the remote machine.",anything normal yes pas execution method remote machine,issue,negative,positive,neutral,neutral,positive,positive
578410225,"@thefirebanks thanks for uploading the right file, please check some typos under step 2 and under ""comparación encriptada"" and we are good to go.",thanks right file please check step good go,issue,positive,positive,positive,positive,positive,positive
578389891,@karlhigley can you please review and approve the merge? ,please review approve merge,issue,negative,neutral,neutral,neutral,neutral,neutral
578373884,"I'll move the conv2d. Should I put it in the nn module or should I put it in some other class. If another class, are there any suggestions? I jsut want to make sure I'm sticking to a design strategy I may not be aware of.",move put module put class another class want make sure sticking design strategy may aware,issue,negative,positive,positive,positive,positive,positive
578077893,The issue is solved for the pooling implementation but not for Conv2d. The Conv2d implementation also had the same discrepancy but even after rectifying it we do not get an exact match. I guess I should have specified that the PR solves *part* of this issue.,issue implementation implementation also discrepancy even get exact match guess part issue,issue,negative,positive,positive,positive,positive,positive
578074580,"That's strange, it looks like the PR solved it and chnaged the test form approx to exact check didn't it?",strange like test form exact check,issue,negative,positive,neutral,neutral,positive,positive
578069071,As reported - there is still rounding error in the Conv2d implementation. This issue should stay open until it is resolved. I have spent a few more hours looking into it and haven't found anything yet.,still rounding error implementation issue stay open resolved spent looking found anything yet,issue,negative,negative,neutral,neutral,negative,negative
578062513,"You did not understand my questions.
I know what the method is doing.
My question, was about how it uses the pointers to modify the parameters inside the model",understand know method question modify inside model,issue,negative,neutral,neutral,neutral,neutral,neutral
578060628,"so if the weights were [1,2,3], and you call this with a scalar of ""0.5"", the weights would become [0.5, 1, 1.5]",call scalar would become,issue,negative,neutral,neutral,neutral,neutral,neutral
577983810,"> Based on the current state of #2910, we might need to do some thinking together about what a Promise is and how it relates to a Placeholder. The current implementation of Promises is based on Plans (which it probably shouldn't be) and `Promise.keep()` reaches way into the internals of Plans (which it definitely shouldn't.) Sorting that out will probably make `PromiseTensors` and `Protocols` easier to make progress on.

I haven't gotten that far :)  
I'm still wrapping my head around how promise tensor currently interacts with plans. And if I can have it interact with (a new?) protocol class instead (and I am guessing both plans and protocols will likely have similar interfaces)... looking up ""placeholders"" now.",based current state might need thinking together promise current implementation based probably way internals definitely probably make easier make progress gotten far still wrapping head around promise tensor currently interact new protocol class instead guessing likely similar looking,issue,positive,positive,neutral,neutral,positive,positive
577981267,"Based on the current state of #2910, we might need to do some thinking together about what a Promise is and how it relates to a Placeholder. The current implementation of Promises is based on Plans (which it probably shouldn't be) and `Promise.keep()` reaches way into the internals of Plans (which it definitely shouldn't.) Sorting that out will probably make `PromiseTensors` and `Protocols` easier to make progress on.",based current state might need thinking together promise current implementation based probably way internals definitely probably make easier make progress,issue,positive,neutral,neutral,neutral,neutral,neutral
577866019,Travis builds aren't running for...reasons. I've contacted Travis support for their help resolving the issue.,travis running travis support help issue,issue,positive,neutral,neutral,neutral,neutral,neutral
577855719,"@LaRiffle I had to look in the docs on master to [find it](https://pytorch.org/docs/master/notes/extending.html#extending-torch-with-a-tensor-like-type). Looks pretty handy, but obviously a big rework to adopt it.",look master find pretty handy obviously big rework adopt,issue,positive,positive,positive,positive,positive,positive
577853329,"Yeah, `conda` packaging is kinda new and we haven't ironed out all the issues yet. (@systemshift has been working on it recently.)",yeah new yet working recently,issue,negative,positive,neutral,neutral,positive,positive
577852433,"Master would neither merge cleanly, nor give me the opportunity to resolve merge conflicts, so that was the best way I could figure out to do it.",master would neither merge cleanly give opportunity resolve merge best way could figure,issue,positive,positive,positive,positive,positive,positive
577843748,"Absolutely no worries :) Just wanted to let you know. FWIW it's a simple fix although I'm surprised conda didn't make it work out of the box

Thanks for looking into this! ",absolutely let know simple fix although make work box thanks looking,issue,negative,positive,positive,positive,positive,positive
577811811,@socd06 the build with Travis has failed. I think it's due to the changes you made on the translation of part 5. Could you check that out? ,build travis think due made translation part could check,issue,negative,negative,negative,negative,negative,negative
577796921,"Bother solutions look good to me!
Could you point at reading material for ""PyTorch's new custom tensor functionality"" ? thanks :)",bother look good could point reading material new custom tensor functionality thanks,issue,positive,positive,positive,positive,positive,positive
577789792,"Ok good, maybe just `cmd = cmd.split(""."")`  because this is a one line change, and we'll do the rest later",good maybe one line change rest later,issue,negative,positive,positive,positive,positive,positive
577787001,"Is it necessary to force push?
I'd like to avoid this as much as possible, it make me sad :( :D",necessary force push like avoid much possible make sad,issue,negative,negative,negative,negative,negative,negative
577780749,"Rebasing this on master to bring it back to a place where we can auto-update with the ""merge master"" button.",master bring back place merge master button,issue,negative,neutral,neutral,neutral,neutral,neutral
577770498,The test failure in Part 5 is happening because of the PR that moved Grid into PySyft. You can see an example of how to fix it in the [last commit from that PR](https://github.com/OpenMined/PySyft/pull/2760/commits/db8b7ba51a60f5fcb438a87470e29b40ef3ac080).,test failure part happening grid see example fix last commit,issue,negative,negative,negative,negative,negative,negative
577768594,"@IanQS When I create a new virtualenv with `make venv`, I end up with `requests` installed, but it's not directly listed in any of the requirements files. Seems like it must be a transitive dependency of something else in one of the requirements files, but I'm not sure which file or which package.",create new make end directly listed like must transitive dependency something else one sure file package,issue,positive,positive,positive,positive,positive,positive
577766436,"I'm going to leave further optimization of this code for a later issue, since this PR is about fixing a security hole.",going leave optimization code later issue since fixing security hole,issue,positive,neutral,neutral,neutral,neutral,neutral
577764368,"@LaRiffle Ah, good catch. What a difference [a year makes](https://github.com/OpenMined/PySyft/pull/1814), huh? 😄 ",ah good catch difference year huh,issue,negative,positive,positive,positive,positive,positive
577762123,"Looks like the Github Action builds are roughly ten minutes faster than the Travis builds. Leaving the Travis builds enabled for now, until we have some confirmation that the GH Actions work as expected and catch relevant failures.",like action roughly ten faster travis leaving travis confirmation work catch relevant,issue,negative,positive,positive,positive,positive,positive
577751938,"Ah, interesting. Grid functionality just got moved into PySyft with somewhat partial tests, and I bet that's why our check suite didn't catch the dependency issue. Let's call this issue closed and create a separate issue for the `requests` dependency—that way I can assign it to the Grid team.",ah interesting grid functionality got somewhat partial bet check suite catch dependency issue let call issue closed create separate issue way assign grid team,issue,positive,positive,positive,positive,positive,positive
577750702,"Though it need not supersede this issue, I'm in favor of starting research/prototyping/etc on that alternative sooner rather than later. The longer we put it off, the more work we're going to pour into workarounds in the mean time.

I don't fully understand how porting to custom PyTorch tensors would resolve this issue though. Is it because that would allow us to stop using wrapper tensors?",though need supersede issue favor starting alternative sooner rather later longer put work going pour mean time fully understand custom would resolve issue though would allow u stop wrapper,issue,positive,negative,negative,negative,negative,negative
577741432,@vvmnnnkv Caching dependencies sounds like a good optimization. Could you create an issue for it?,like good optimization could create issue,issue,positive,positive,positive,positive,positive,positive
577715093,@matthiaslau  Do you need this to work strictly on remote websockets? I believe this should work on virtual workers right now.  Can you please try?,need work strictly remote believe work virtual right please try,issue,negative,positive,neutral,neutral,positive,positive
577714642,"I remember getting the same error as you on remote websockets and opening an Issue: 

https://github.com/OpenMined/PySyft/issues/2202 . It should have been fixed @LaRiffle  ? ",remember getting error remote opening issue fixed,issue,negative,neutral,neutral,neutral,neutral,neutral
577697436,I would like to start working on this by translating Part 02,would like start working part,issue,negative,neutral,neutral,neutral,neutral,neutral
577686966,"> I work with a local grid setup using websocket worker.

Do you have an idea where to look, so what are those things failing on remote workers?",work local grid setup worker idea look failing remote,issue,negative,negative,neutral,neutral,negative,negative
577685563,"Then something else is failing within that method. Are you testing this on remote workers or virtual workers?

I noticed that some things do work on virtual workers, but do not work on remote workers. Perhaps this is one of those cases.",something else failing within method testing remote virtual work virtual work remote perhaps one,issue,negative,negative,neutral,neutral,negative,negative
577656372,"> I already use our existing PySyft implementation of the LSTM (`from syft.frameworks.torch.nn import LSTM`) which is overwriting the forward method without using `size()`: https://github.com/OpenMined/PySyft/blob/master/syft/frameworks/torch/nn/rnn.py#L205.

This seems like the right approach. ",already use implementation import forward method without size like right approach,issue,negative,positive,positive,positive,positive,positive
577653309,I already use our existing PySyft implementation of the LSTM (`from syft.frameworks.torch.nn import LSTM`) which is overwriting the forward method without using `size()`: https://github.com/OpenMined/PySyft/blob/master/syft/frameworks/torch/nn/rnn.py#L205.,already use implementation import forward method without size,issue,negative,neutral,neutral,neutral,neutral,neutral
577651814,"Actually, it looks like https://github.com/OpenMined/PySyft/pull/2349 is not overriding the forward pass of LSTMs / GRUs, so this method would still be needed for them.",actually like forward pas method would still,issue,negative,neutral,neutral,neutral,neutral,neutral
577650902,"The ""ResponseSignatureError"" is raised because the forward LSTM pass fails.

This occurs because the forward pass in an LSTM uses the tensor.size() method, which is not currently implemented in PySyft.

The same problem would occur for a GRU.

*Workaround* My personal workaround to this problem was using my own version of the size() method, which breaks some other features of PySyft though https://github.com/OpenMined/PySyft/pull/2343

*Clean solution* Override PyTorch's LSTM's forward pass and replace occurrences of the size method calls wit the 'dim' method/attribute, which is indeed supported in PySyft.",raised forward pas forward pas method currently problem would occur personal problem version size method though clean solution override forward pas replace size method wit indeed,issue,negative,positive,positive,positive,positive,positive
577635474,"All good, just is needed to correct 2 typos in second and third paragraph.",good correct second third paragraph,issue,negative,positive,positive,positive,positive,positive
577628472,"@thefirebanks thanks for posting, please check that you are doing the PR with the right file as it does not have the changes in spanish. Also please make sure that you are adding to your forked repo all the changes before doing the PR.  ",thanks posting please check right file also please make sure forked,issue,positive,positive,positive,positive,positive,positive
577529798,"Not in the scope of this PR:
This seems like something we could try for speeding up dependencies step: https://help.github.com/en/actions/automating-your-workflow-with-github-actions/caching-dependencies-to-speed-up-workflows
I can make separate issue if you think it worth's trying out.",scope like something could try speeding step make separate issue think worth trying,issue,positive,positive,positive,positive,positive,positive
577509020,"@karlhigley Sorry, ran into a different bug now. Running 

```
import pysyft as sy
```

results in 

```
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/ian/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/__init__.py"", line 44, in <module>
    from syft.grid.public_grid import PublicGridNetwork
  File ""/home/ian/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/grid/public_grid.py"", line 2, in <module>
    import requests
ModuleNotFoundError: No module named 'requests'
```

Doing `pip install requests` solves the issue. 

Have verified that this is the case on 

```
syft                 0.2.2a1            
syft-proto           0.1.0a1.post36     
```

Should I mark this as closed? ",sorry ran different bug running import recent call last file line module file line module import file line module import module pip install issue case mark closed,issue,negative,negative,negative,negative,negative,negative
577418238,"I'm working on creating Github Actions  for the build [over here](https://github.com/OpenMined/PySyft/pull/2936), so it's probably fine to go with a GH action instead of Travis.",working build probably fine go action instead travis,issue,negative,positive,positive,positive,positive,positive
577418038,"I'd probably just create a single issue. Having looked at the Bandit output, I think we probably care most about medium-high severity issues, and it would be nice to find a way to prevent low severity issues (mostly `assert`s) from breaking the build.",probably create single issue bandit output think probably care severity would nice find way prevent low severity mostly assert breaking build,issue,positive,positive,positive,positive,positive,positive
577398281,I'm good with setting up a bandit config and adding it to the Travis build process. Do you think it would be a good idea to create an issue for everything Bandit finds? ,good setting bandit travis build process think would good idea create issue everything bandit,issue,positive,positive,positive,positive,positive,positive
577386540,"See files usually updated during version bump:
https://github.com/OpenMined/PySyft/pull/2943/files
I guess `docs/conf.py` should be updated to use versioneer while `syft/version.py` file and `[bumpversion]` section in `setup.cfg` can be removed.

",see usually version bump guess use file section removed,issue,negative,negative,negative,negative,negative,negative
577291074,I want to take this up. Is this still valid? ,want take still valid,issue,negative,neutral,neutral,neutral,neutral,neutral
577274323,"> pip install syft[udacity] does not include syft-proto

@klize Could you submit a PR to fix this? Would be much appreciated!",pip install include could submit fix would much,issue,negative,positive,positive,positive,positive,positive
577267694,"Hey guys!
@darkmatter18  @Yugandhartripathi @kaustubh-seachange 

We plan to release the hindi translations by next month, which leaves us a few days to finish all of them and review them too. Any heads-up on when they would be complete? In case it is not possible for some one to finish theirs, please do let the others know. Preferably by this weekend, so that they can be taken up by the rest of us.

Cheers!
Urvashi
",hey plan release next month leaf u day finish review would complete case possible one finish please let know preferably weekend taken rest u,issue,negative,positive,neutral,neutral,positive,positive
577261201,"@IanQS PySyft v0.2.2.a1 has been published to PyPI. Give that a try, and let me know if it works better!",give try let know work better,issue,negative,positive,positive,positive,positive,positive
577260865,"<p>Can you please do a final review? We can then proceed with the merge.</p><p> </p><p>Again, thanks Yugandhar!</p>",please final review proceed thanks,issue,positive,positive,neutral,neutral,positive,positive
577252424,"Exorcisms! 

Sent from my iPhone

> On 22 Jan 2020, at 15:48, Karl Higley <notifications@github.com> wrote:
> 
> ﻿
> @karlhigley requested your review on: #2951 Exorcise a Python eval and transmute into the lesser demon getattr.
> 
> —
> You are receiving this because your review was requested.
> Reply to this email directly, view it on GitHub, or unsubscribe.
",sent wrote review exorcise python transmute lesser demon review reply directly view,issue,negative,positive,neutral,neutral,positive,positive
577244063,"@LaRiffle I'll skip the efficiency tests in the GH Actions then. They seemed to pass consistently on Travis, so maybe we can continue running them there.",skip efficiency pas consistently travis maybe continue running,issue,negative,positive,positive,positive,positive,positive
577235541,Did a test run with `bandit` (skipping the check for `assert`) and it does find a few things.,test run bandit skipping check assert find,issue,negative,neutral,neutral,neutral,neutral,neutral
577206019,"@ucalyptus Looks like the builds on these commits passed. What you're probably seeing is that when you push a new commit, it will cancel any previous queued builds that haven't started running yet.",like probably seeing push new commit cancel previous running yet,issue,negative,negative,neutral,neutral,negative,negative
577199357,"Thank you for the quick answer,
But I had another question, that is not answered (or maybe it is related to the part that you said, the platform is not yet implemented), should I use two separate optimizer if I want to use two clients, and merge them? like the link below?
https://towardsdatascience.com/federated-learning-3097547f8ca3",thank quick answer another question maybe related part said platform yet use two separate want use two merge like link,issue,positive,positive,positive,positive,positive,positive
577190470,"Check out what's going on in the https://github.com/OpenMined/PyGrid/ project. @vvmnnnkv, @cereallarceny , and @IonesioJunior are also working on the model averaging workflow as we speak.",check going project also working model speak,issue,negative,neutral,neutral,neutral,neutral,neutral
577190135,"This is coming - at present we haven't implemented the ""platform"" side of Federated Learning but it's a work in progress.",coming present platform side learning work progress,issue,negative,neutral,neutral,neutral,neutral,neutral
577185380,"Relatively to the performance hit of doing secure computation I think you wouldn't wouldn't even notice the extra node in the tensor chain, but in exchange we get re-usable, more modular code. I'm not opposed to an encoder existing long term, but I have very strong convictions about making FPT it's own module because literally every encrypted computation tensor type will need it.",relatively performance hit secure computation think would would even notice extra node tensor chain exchange get modular code opposed long term strong making module literally every computation tensor type need,issue,positive,positive,positive,positive,positive,positive
577144144,@karlhigley changes made. Added the Translator section  right after Authors both here and in #2942 ,made added translator section right,issue,negative,positive,positive,positive,positive,positive
577105439,"The difference here is that using the encoder, you don't add the FPT node in the tensor chain, so you're simpler & faster. But this reflexion is far from being top priority for the moment^^ ",difference add node tensor chain simpler faster far top priority,issue,negative,positive,positive,positive,positive,positive
577068808,"> @LaRiffle When I try to send a Dataset I get this error:
> 
> `syft.exceptions.UndefinedProtocolTypeError: syft.frameworks.torch.fl.dataset.BaseDataset is not defined in the protocol file`
> 
> Should I modify syst proto package too?

Yes you should!",try send get error defined protocol file modify proto package yes,issue,negative,neutral,neutral,neutral,neutral,neutral
577066971,"@karlhigley unfortunately I think we must get rid of the efficiency test, github travis or actions are not a good place to test for efficiency. This should be made elsewhere with a dedicated server to have a clear idea on how this is evolving in time",unfortunately think must get rid efficiency test travis good place test efficiency made elsewhere server clear idea time,issue,positive,positive,neutral,neutral,positive,positive
577014343,"Hi, sorry about that... Now the difference is shown in ReviewNB. Could you please check it again? @LaRiffle",hi sorry difference shown could please check,issue,negative,negative,negative,negative,negative,negative
576970128,"removing `client.connect()` yields the same error

**Additional Issue**
* scripts in this directory not working on my environment
`examples/tutorials/advanced/websockets-example-MNIST/.. ` 

* wrapping like below in syft.workers.websocket_server.WebsocketServerWorker._consumer_handler:line 93
```python
try:
...
except websockets.exceptions.ConnectionClosed:
            asyncio.ensure_future(self._consumer_handler(websocket))
```
removes my issue number 3 in summary section above.
and this makes me confused as it means the socket has been closed even before the modification.  -> **mind if i know the way to see websocket logs through this framework ?**

* Using virtual worker, the whole job finished successfully but not in case of `WebsocketClientWorker`

* Copying advanced mnist tutorials written by @midokura-silvia into my scripts run_websocket_server.py, start_websocket_server.py and run_websocket_client.py ,

**To reproduce problems**
I run `start_websocket_server.py` with one server like below:
```python
import subprocess
import sys
import os

if os.name == ""nt"":
    python = ""python""
else:
    python = ""python"" + sys.version[0:3]

call_server = [python, ""run_websocket_server.py"", ""--port"", ""8777"", ""--id"", ""server""]


print(""Starting server"")
subprocess.Popen(call_server)

```
on terminal:
```
(venv) .../server$ python test_server.py 
Starting server
(venv) .../server$ Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '.../server/venv/lib/python3.6/site-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.15.0.so'
WARNING:tensorflow:From .../server/venv/lib/python3.6/site-packages/tf_encrypted/session.py:24: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

Serving. Press CTRL-C to stop.

```

then also run `run_websocket_client.py` as a client with a little changes to make 3 workers try to connect to one server above.
```python
...
def main():
    args = define_and_get_arguments()

    hook = sy.TorchHook(torch)

    if args.use_virtual:
        alice = VirtualWorker(id=""alice"", hook=hook, verbose=args.verbose)
        bob = VirtualWorker(id=""bob"", hook=hook, verbose=args.verbose)
        charlie = VirtualWorker(id=""charlie"", hook=hook, verbose=args.verbose)
    else:
        kwargs_websocket = {""host"": ""localhost"", ""hook"": hook, ""verbose"": args.verbose}
        alice = WebsocketClientWorker(id=""alice"", port=8777, **kwargs_websocket)
        bob = WebsocketClientWorker(id=""bob"", port=8777, **kwargs_websocket)
        charlie = WebsocketClientWorker(id=""charlie"", port=8777, **kwargs_websocket)
...
```
that is, one server for alice, bob and chalie.

But both server and client is stucked for unknown reason.
```
(venv) .../client$ python test_client.py
Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '.../client/venv/lib/python3.6/site-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.15.0.so'
WARNING:tensorflow:From .../client/venv/lib/python3.6/site-packages/tf_encrypted/session.py:24: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2020-01-22 17:04:16,624 INFO dataset.py(l:138) - Scanning and sending data to alice, bob, charlie...
2020-01-22 17:04:19,145 DEBUG dataset.py(l:147) - Sending data to worker alice



```

So I give a CTRL C signal to clients and yields this on the client terminal:
```
^CTraceback (most recent call last):
  File ""test_client.py"", line 277, in <module>
    main()
  File ""test_client.py"", line 237, in main
    ).federate(tuple(workers)),
  File "".../client/venv/lib/python3.6/site-packages/syft/frameworks/torch/fl/dataset.py"", line 149, in dataset_federate
    targets = targets.send(worker)
  File "".../client/venv/lib/python3.6/site-packages/syft/frameworks/torch/tensors/interpreters/native.py"", line 418, in send
    garbage_collect_data=garbage_collect_data,
  File "".../client/venv/lib/python3.6/site-packages/syft/workers/base.py"", line 395, in send
    self.send_obj(obj, worker)
  File "".../client/venv/lib/python3.6/site-packages/syft/workers/base.py"", line 607, in send_obj
    return self.send_msg(ObjectMessage(obj), location)
  File "".../client/venv/lib/python3.6/site-packages/syft/workers/base.py"", line 277, in send_msg
    bin_response = self._send_msg(bin_message, location)
  File "".../client/venv/lib/python3.6/site-packages/syft/workers/virtual.py"", line 7, in _send_msg
    return location._recv_msg(message)
  File "".../client/venv/lib/python3.6/site-packages/syft/workers/websocket_client.py"", line 92, in _recv_msg
    response = self._forward_to_websocket_server_worker(message)
  File "".../client/venv/lib/python3.6/site-packages/syft/workers/websocket_client.py"", line 87, in _forward_to_websocket_server_worker
    response = binascii.unhexlify(self.ws.recv()[2:-1])
  File "".../client/venv/lib/python3.6/site-packages/websocket/_core.py"", line 314, in recv
    opcode, data = self.recv_data()
  File "".../client/venv/lib/python3.6/site-packages/websocket/_core.py"", line 331, in recv_data
    opcode, frame = self.recv_data_frame(control_frame)
  File "".../client/venv/lib/python3.6/site-packages/websocket/_core.py"", line 344, in recv_data_frame
    frame = self.recv_frame()
  File "".../client/venv/lib/python3.6/site-packages/websocket/_core.py"", line 378, in recv_frame
    return self.frame_buffer.recv_frame()
  File "".../client/venv/lib/python3.6/site-packages/websocket/_abnf.py"", line 361, in recv_frame
    self.recv_header()
  File "".../client/venv/lib/python3.6/site-packages/websocket/_abnf.py"", line 309, in recv_header
    header = self.recv_strict(2)
  File "".../client/venv/lib/python3.6/site-packages/websocket/_abnf.py"", line 396, in recv_strict
    bytes_ = self.recv(min(16384, shortage))
  File "".../client/venv/lib/python3.6/site-packages/websocket/_core.py"", line 453, in _recv
    return recv(self.sock, bufsize)
  File "".../client/venv/lib/python3.6/site-packages/websocket/_socket.py"", line 102, in recv
    bytes_ = _recv()
  File "".../client/venv/lib/python3.6/site-packages/websocket/_socket.py"", line 84, in _recv
    return sock.recv(bufsize)

```

and on the server terminal:
```
Future exception was never retrieved
future: <Future finished exception=ConnectionClosedError('code = 1006 (connection closed abnormally [internal]), no reason',)>
websockets.exceptions.ConnectionClosedError: code = 1006 (connection closed abnormally [internal]), no reason
Future exception was never retrieved
future: <Future finished exception=ConnectionClosedError('code = 1006 (connection closed abnormally [internal]), no reason',)>
websockets.exceptions.ConnectionClosedError: code = 1006 (connection closed abnormally [internal]), no reason
Future exception was never retrieved
future: <Future finished exception=ConnectionClosedError('code = 1006 (connection closed abnormally [internal]), no reason',)>
websockets.exceptions.ConnectionClosedError: code = 1006 (connection closed abnormally [internal]), no reason
Future exception was never retrieved
future: <Future finished exception=ConnectionClosedError('code = 1006 (connection closed abnormally [internal]), no reason',)>
websockets.exceptions.ConnectionClosedError: code = 1006 (connection closed abnormally [internal]), no reason
Future exception was never retrieved
future: <Future finished exception=ConnectionClosedError('code = 1006 (connection closed abnormally [internal]), no reason',)>
websockets.exceptions.ConnectionClosedError: code = 1006 (connection closed abnormally [internal]), no reason
Future exception was never retrieved
future: <Future finished exception=ConnectionClosedError('code = 1006 (connection closed abnormally [internal]), no reason',)>
websockets.exceptions.ConnectionClosedError: code = 1006 (connection closed abnormally [internal]), no reason
Future exception was never retrieved
future: <Future finished exception=ConnectionClosedError('code = 1006 (connection closed abnormally [internal]), no reason',)>
websockets.exceptions.ConnectionClosedError: code = 1006 (connection closed abnormally [internal]), no reason
Future exception was never retrieved
future: <Future finished exception=ConnectionClosedError('code = 1006 (connection closed abnormally [internal]), no reason',)>
websockets.exceptions.ConnectionClosedError: code = 1006 (connection closed abnormally [internal]), no reason
Future exception was never retrieved
future: <Future finished exception=ConnectionClosedError('code = 1006 (connection closed abnormally [internal]), no reason',)>
websockets.exceptions.ConnectionClosedError: code = 1006 (connection closed abnormally [internal]), no reason
Future exception was never retrieved
future: <Future finished exception=ConnectionClosedError('code = 1006 (connection closed abnormally [internal]), no reason',)>
websockets.exceptions.ConnectionClosedError: code = 1006 (connection closed abnormally [internal]), no reason
Future exception was never retrieved
future: <Future finished exception=ConnectionClosedError('code = 1006 (connection closed abnormally [internal]), no reason',)>
websockets.exceptions.ConnectionClosedError: code = 1006 (connection closed abnormally [internal]), no reason
Future exception was never retrieved
future: <Future finished exception=ConnectionClosedError('code = 1006 (connection closed abnormally [internal]), no reason',)>
websockets.exceptions.ConnectionClosedError: code = 1006 (connection closed abnormally [internal]), no reason
Future exception was never retrieved
future: <Future finished exception=ConnectionClosedError('code = 1006 (connection closed abnormally [internal]), no reason',)>
websockets.exceptions.ConnectionClosedError: code = 1006 (connection closed abnormally [internal]), no reason
Future exception was never retrieved
future: <Future finished exception=ConnectionClosedError('code = 1006 (connection closed abnormally [internal]), no reason',)>
websockets.exceptions.ConnectionClosedError: code = 1006 (connection closed abnormally [internal]), no reason
Future exception was never retrieved
future: <Future finished exception=ConnectionClosedError('code = 1006 (connection closed abnormally [internal]), no reason',)>
websockets.exceptions.ConnectionClosedError: code = 1006 (connection closed abnormally [internal]), no reason
Future exception was never retrieved
future: <Future finished exception=ConnectionClosedError('code = 1006 (connection closed abnormally [internal]), no reason',)>
websockets.exceptions.ConnectionClosedError: code = 1006 (connection closed abnormally [internal]), no reason

```
(server processes hangs on my ```ps``` list, that i have to manually kill the processes)",removing error additional issue directory working environment wrapping like line python try except issue number summary section confused socket closed even modification mind know way see framework virtual worker whole job finished successfully case advanced written reproduce run one server like python import import import o python python else python python python port id server print starting server terminal python starting server falling back insecure randomness since custom could found version fix custom missing file warning name please use instead serving press stop also run client little make try connect one server python main hook torch bob bob else host hook hook verbose bob bob one server bob server client unknown reason python falling back insecure randomness since custom could found version fix custom missing file warning name please use instead scanning sending data bob sending data worker give signal client terminal recent call last file line module main file line main file line worker file line send file line send worker file line return location file line location file line return message file line response message file line response file line data file line frame file line frame file line return file line file line header file line min shortage file line return file line file line return server terminal future exception never future future finished connection closed abnormally internal reason code connection closed abnormally internal reason future exception never future future finished connection closed abnormally internal reason code connection closed abnormally internal reason future exception never future future finished connection closed abnormally internal reason code connection closed abnormally internal reason future exception never future future finished connection closed abnormally internal reason code connection closed abnormally internal reason future exception never future future finished connection closed abnormally internal reason code connection closed abnormally internal reason future exception never future future finished connection closed abnormally internal reason code connection closed abnormally internal reason future exception never future future finished connection closed abnormally internal reason code connection closed abnormally internal reason future exception never future future finished connection closed abnormally internal reason code connection closed abnormally internal reason future exception never future future finished connection closed abnormally internal reason code connection closed abnormally internal reason future exception never future future finished connection closed abnormally internal reason code connection closed abnormally internal reason future exception never future future finished connection closed abnormally internal reason code connection closed abnormally internal reason future exception never future future finished connection closed abnormally internal reason code connection closed abnormally internal reason future exception never future future finished connection closed abnormally internal reason code connection closed abnormally internal reason future exception never future future finished connection closed abnormally internal reason code connection closed abnormally internal reason future exception never future future finished connection closed abnormally internal reason code connection closed abnormally internal reason future exception never future future finished connection closed abnormally internal reason code connection closed abnormally internal reason server list manually kill,issue,negative,negative,neutral,neutral,negative,negative
576952891,"Hi @unzvfu, I would like to work on cleaning up the python wrapper for the cuda-fixnum project, just point me in the right direction. ",hi would like work cleaning python wrapper project point right direction,issue,negative,positive,positive,positive,positive,positive
576914144,"Incredible work! 

Sent from my iPhone

> On 21 Jan 2020, at 19:20, Arshjot Singh Khehra <notifications@github.com> wrote:
> 
> ﻿
> Yes, I'll be happy to do so!
> 
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub, or unsubscribe.
",incredible work sent singh wrote yes happy thread reply directly view,issue,positive,positive,positive,positive,positive,positive
576790811,"@karlhigley for some AutoCancellation being on reason the build checks are failing, any way to solve this from my side?",reason build failing way solve side,issue,negative,neutral,neutral,neutral,neutral,neutral
576787691,@arshjot Thanks for looking into it! Could you submit a PR with those changes?,thanks looking could submit,issue,negative,positive,positive,positive,positive,positive
576771232,I don't think you can push here maybe you'll want ot open a dedicated PR :),think push maybe want open,issue,negative,neutral,neutral,neutral,neutral,neutral
576758886,"@systemshift So it does! I'll close this then, but would still be nice to incorporate `versioneer`. That might be a separate issue though.",close would still nice incorporate might separate issue though,issue,negative,positive,positive,positive,positive,positive
576613049,"I investigated this a bit and it seems we need to do a direct summation instead of calculating sum of sums. The following modifications are required:
* [`conv.py`](https://github.com/OpenMined/PySyft/blob/acdc96828cebae674817d238f68e0e81dfd41071/syft/frameworks/torch/nn/conv.py#L94-L95) - change `.sum(3).sum(3)` to `.sum((3, 4))`
* [`pool.py`](https://github.com/OpenMined/PySyft/blob/acdc96828cebae674817d238f68e0e81dfd41071/syft/frameworks/torch/nn/pool.py#L65) - change `.sum(2).sum(2)` to `.sum((2, 3))`

By making the above changes, we get exactly the same output for both the pooling implementations. However, a rounding error is still present for convolution possibly due to floating-point arithmetic as indicated [here](https://discuss.pytorch.org/t/pytorch-conv2d-vs-numpy-reference-different-outcomes-rounding-error-or-mistake/8921).",bit need direct summation instead calculating sum following change change making get exactly output however rounding error still present convolution possibly due arithmetic,issue,negative,positive,neutral,neutral,positive,positive
576511429,"Yeah, syft 0.1.18 is at least six months old, and there have been fixes to Plans and blueprints since then.",yeah least six old since,issue,negative,negative,neutral,neutral,negative,negative
576505154,"Can't recreate this on a different machine that has`syft 0.2.0a2` so I guess the docker version is behind? 

I didn't install the native version on this machine (the one with the problem) because of #2931 ",ca recreate different machine guess docker version behind install native version machine one problem,issue,negative,negative,negative,negative,negative,negative
576409375,"@iamtrask Bengali is my native and has the 5th largest speaker base in the world. 
https://github.com/OpenMined/PySyft/pull/2938 for Part One ",native th speaker base world part one,issue,negative,negative,negative,negative,negative,negative
576398289,@arturomf94 @ricardopretelt I would love to collaborate with the translation to Spanish as well! ,would love collaborate translation well,issue,positive,positive,positive,positive,positive,positive
576381721,"It seems like the efficiency tests run with fairly variable execution time in Github Actions. I could bump the execution time threshold to make them pass, but that seems to defeat the point of the tests. Alternately, I could skip them in the CI builds. Thoughts on this @iamtrask?",like efficiency run fairly variable execution time could bump execution time threshold make pas defeat point alternately could skip,issue,negative,positive,positive,positive,positive,positive
576370057,"Looks like use of `hexlify` was [introduced last March](https://github.com/OpenMined/PySyft/commit/6917846cf981485ca83f61142e073c9c343eba4c#diff-11214074701249affec97a37c2352924). There's no stated rationale in that PR; the title just suggests that the changes ""fix bugs."" Not sure if `hexlify` was part of those fixes or not.",like use last march stated rationale title fix sure part,issue,positive,positive,positive,positive,positive,positive
576368395,Another kind of workaround specific to transfer learning case could be splitting the model into frozen/trianable parts. In transfer learning you typically don't want to retrain all weights.,another kind specific transfer learning case could splitting model transfer learning typically want retrain,issue,positive,positive,positive,positive,positive,positive
576368052,Sounds like base64 is a safe change to make then. Let's start there and then see if we can further optimize.,like base safe change make let start see optimize,issue,positive,negative,negative,negative,negative,negative
576366829,"Needs checking why it was used, maybe there was a reason. I can say for grid.js, historically it uses JSON payloads, which forces us to send binary as base64",need used maybe reason say historically u send binary base,issue,negative,negative,negative,negative,negative,negative
576363214,I think you have to add data with particular methods in order to get the tensors properly registered with the worker. The [`load_data`](https://github.com/OpenMined/PySyft/blob/master/syft/workers/base.py#L236-L249) method looks like it might be close to what you need.,think add data particular order get properly registered worker method like might close need,issue,negative,positive,neutral,neutral,positive,positive
576362762,"In theory, websocket can handle binary. As least in JavaScript :) The trick is to avoid JSON because it can't contain binary.",theory handle binary least trick avoid ca contain binary,issue,negative,negative,negative,negative,negative,negative
576359288,"This seems like it might be more a matter of compression and encoding efficiency though? Base64 is supported by the `binascii` library and uses four characters for every three bytes (instead of two per byte), so that might be an easy change to make in order to improve bandwidth efficiency.

@luggi961 Would you be up for trying that out and submitting a PR?",like might matter compression efficiency though base library four every three instead two per might easy change make order improve efficiency would trying,issue,positive,negative,negative,negative,negative,negative
576350240,"If the differences were sparse, they'd be smaller. They often won't be though.

Gradient sparsification is a thing; maybe model delta sparsification could be too?",sparse smaller often wo though gradient thing maybe model delta could,issue,negative,neutral,neutral,neutral,neutral,neutral
576332477,"Mad props for taking the time to measure this.

What leads you to believe that transmitting the difference between the old and new model would be any smaller of a file? Would it compress better?",mad prop taking time measure believe difference old new model would smaller file would compress better,issue,negative,positive,neutral,neutral,positive,positive
576320862,"We’re not quite migrated over to Github Actions yet, so we’d currently need to incorporate it into the Travis CI testing process. @suhacker1 would you be interested in setting up a bandit config and adding it to our Travis build process?",quite yet currently need incorporate travis testing process would interested setting bandit travis build process,issue,negative,positive,positive,positive,positive,positive
576216227,I did not mean to merge this! The button changed with all the github actions or something - I don't know how this happened. Reverting.,mean merge button something know,issue,negative,negative,negative,negative,negative,negative
576083092,Thanks for the explanation! Do you have any suggestions on how to fix it in the meantime or should I just wait? :) ,thanks explanation fix wait,issue,negative,positive,positive,positive,positive,positive
576080304,"The library `pysyft-proto` has been renamed to `syft-proto` since `syft v0.2.1a1` was released. Our previous release manager no longer has time to fill that role, and we're a bit behind on publishing releases. 😅 

I'm in the process of sorting out our release pipeline and expect another release to published sometime this week, which should fix the underlying issue and which I assume will fix the `conda` issue.",library since previous release manager longer time fill role bit behind process release pipeline expect another release sometime week fix underlying issue assume fix issue,issue,negative,negative,negative,negative,negative,negative
576024747,"> We just merged [a fix](https://github.com/OpenMined/PySyft/pull/2908) for this yesterday and haven't released a new version yet.

Awesome. That is good to know. I think we can close this issue?",fix yesterday new version yet awesome good know think close issue,issue,positive,positive,positive,positive,positive,positive
576023718,I will start working on this issue and translate Part 01,start working issue translate part,issue,negative,neutral,neutral,neutral,neutral,neutral
576020307,Just fix this one minor thing and then it will be good to merge. :+1: ,fix one minor thing good merge,issue,negative,positive,positive,positive,positive,positive
575999778,"Hi,
Is this issue sorted because I'm facing the same on the PyPi version
Thanks",hi issue sorted facing version thanks,issue,negative,positive,positive,positive,positive,positive
575946569,"Yeah, there’s an open issue for Torch 1.4 compatibility, but 1.4 was just released so we haven’t resolved the issue yet.",yeah open issue torch compatibility resolved issue yet,issue,negative,neutral,neutral,neutral,neutral,neutral
575941856,"Update: I just got it to work by switching PyTorch back to 1.3 using [this build](https://discuss.pytorch.org/t/pytorch-1-3-wheels-for-raspberry-pi-python-3-7/58580) and now it works, so the issue can be closed.  Possibly the above is something to look into for updating syft to PyTorch 1.4.",update got work switching back build work issue closed possibly something look,issue,negative,negative,neutral,neutral,negative,negative
575941151,"Did that and now I get:

$ python3 -c ""import syft""

```
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""/home/pi/.local/lib/python3.7/site-packages/syft/__init__.py"", line 43, in <module>
    from syft.grid.private_grid import PrivateGridNetwork
  File ""/home/pi/.local/lib/python3.7/site-packages/syft/grid/private_grid.py"", line 11, in <module>
    from syft.workers.node_client import NodeClient
  File ""/home/pi/.local/lib/python3.7/site-packages/syft/workers/node_client.py"", line 7, in <module>
    from syft.serde import serialize
  File ""/home/pi/.local/lib/python3.7/site-packages/syft/serde/__init__.py"", line 1, in <module>
    from syft.serde.serde import *
  File ""/home/pi/.local/lib/python3.7/site-packages/syft/serde/serde.py"", line 12, in <module>
    from syft.serde import msgpack
  File ""/home/pi/.local/lib/python3.7/site-packages/syft/serde/msgpack/__init__.py"", line 1, in <module>
    from syft.serde.msgpack import serde
  File ""/home/pi/.local/lib/python3.7/site-packages/syft/serde/msgpack/serde.py"", line 81, in <module>
    from syft.serde.msgpack.torch_serde import MAP_TORCH_SIMPLIFIERS_AND_DETAILERS
  File ""/home/pi/.local/lib/python3.7/site-packages/syft/serde/msgpack/torch_serde.py"", line 297, in <module>
    torch._C.Function: (_simplify_script_module, _detail_script_module),
AttributeError: module 'torch._C' has no attribute 'Function'
```

Could this be an issue with PyTorch 1.4? I am using the [wheel found here](https://github.com/sungjuGit/Pytorch-and-Vision-for-Raspberry-Pi-4B). Haven't found an armv71 build for 1.3. ",get python import recent call last file string line module file line module import file line module import file line module import serialize file line module import file line module import file line module import file line module import file line module module attribute could issue wheel found found build,issue,negative,neutral,neutral,neutral,neutral,neutral
575938689,"Two issues here:
- The test that checks that all the notebooks have been tested should exclude the translation notebooks in the normal test run, but include the check in the translation test run. (Partially fixed by #2919.)
- The efficiency tests run slightly longer in Github Actions, which pushes them over the threshold for acceptable test execution time. Might need to lengthen the acceptable time, or skip these tests in CI. (Fixed in the commits below.)",two test tested exclude translation normal test run include check translation test run partially fixed efficiency run slightly longer threshold acceptable test execution time might need lengthen acceptable time skip fixed,issue,positive,positive,neutral,neutral,positive,positive
575916379,We just merged [a fix](https://github.com/OpenMined/PySyft/pull/2908) for this yesterday and haven't released a new version yet.,fix yesterday new version yet,issue,negative,positive,positive,positive,positive,positive
575912811,"Thank you @klize for reporting. I could reproduce the issue on an archlinux system, with python 3.6 in miniconda. 

I got the same error after installing `pip install syft` and importing `import syft`. Is anyone aware of this bug @LaRiffle @iamtrask ?",thank could reproduce issue system python got error pip install import anyone aware bug,issue,negative,positive,positive,positive,positive,positive
575912526,"So, Since it had softmax at the output, i need to use argmax()",since output need use,issue,negative,neutral,neutral,neutral,neutral,neutral
575885458,@karlhigley @iamtrask Hello! Is my pull request good to go?,hello pull request good go,issue,negative,positive,positive,positive,positive,positive
575855132,"@karlhigley I fixed the formatting in the second commit. The build is still running for it.  Thanks for the link to the commit hooks, that will help in the future.",fixed second commit build still running thanks link commit help future,issue,positive,positive,neutral,neutral,positive,positive
575854932,Thanks for the fix! Looks like the build is saying there’s a code formatting issue of some kind. Set up the [commit hooks](https://github.com/OpenMined/PySyft/blob/master/CONTRIBUTING.md) and they’ll format the code for you when make a commit.,thanks fix like build saying code issue kind set commit format code make commit,issue,positive,positive,positive,positive,positive,positive
575842225,"Try `pip install syft-proto`. It should get installed with the other dependencies if you install with `python setup.py install`, so let us know if you did that and still ended up having this issue. Otherwise, I’m guessing it has to do with building from source, but not sure exactly why.",try pip install get install python install let u know still ended issue otherwise guessing building source sure exactly,issue,negative,positive,positive,positive,positive,positive
575793697,"I think the advanced notebook test is now running more notebooks than before, and some of them have gotten a bit out of date, which is causing test failures that theoretically existed but weren't actually happening before.",think advanced notebook test running gotten bit date causing test theoretically actually happening,issue,negative,positive,positive,positive,positive,positive
575763883,"Superseded by #2919, which parametrizes the notebook tests and helps `pytest` give better error messages.",notebook give better error,issue,negative,positive,positive,positive,positive,positive
575748304,"We can improve on this farther by splitting each notebook out into a separate test, but this is sufficient to fix the tests that are now failing on master so I'm going to merge to unblock everything else.",improve farther splitting notebook separate test sufficient fix failing master going merge unblock everything else,issue,negative,neutral,neutral,neutral,neutral,neutral
575745988,"Yeah, that might be viable! Direct link to the i18n README linked in the SO thread above: https://github.com/jupyter/notebook/tree/master/notebook/i18n",yeah might viable direct link linked thread,issue,negative,positive,neutral,neutral,positive,positive
575660924,"I've been cherry-picking this into my branches when notebook tests are failing, so it does seem useful, but I can't think of a good way to make sure that the exception case gets handled without causing a test failure. I guess we could maybe create an intentionally broken notebook and assert that it throws an exception?",notebook failing seem useful ca think good way make sure exception case handled without causing test failure guess could maybe create intentionally broken notebook assert exception,issue,positive,positive,positive,positive,positive,positive
575544642,"Yeah, we just need to bump the dependency version and fix any compatibility issues I'd say",yeah need bump dependency version fix compatibility say,issue,negative,neutral,neutral,neutral,neutral,neutral
575305722,What's involved in this? Do we just need to bump the dependency version and fix any compatibility issues? Are there new PyTorch features to incorporate?,involved need bump dependency version fix compatibility new incorporate,issue,negative,positive,positive,positive,positive,positive
575237215,"> That's really helpful abstraction!
> 
> One last thing you can to if you want is add a method to NatvieTensor to transform a Torch Tensor to NympuTensor:
> 
> Exaample
> 
> ```python
> x = th.tensor([1.])
> x.numpy_tensor()
> ```
> 
> If yoo find a usecase for it

Done",really helpful abstraction one last thing want add method transform torch tensor python find done,issue,positive,positive,neutral,neutral,positive,positive
575198137,"<p>Thanks a ton Yugandhar! That is indeed a lot to go through :)</p><p>I have fixed most of the issues, barring the 'Author's section in the first cell, that is somehow not visible on my jupyter notebook. Will try to resolve that soon!</p><p> </p><p> </p>",thanks ton indeed lot go fixed barring section first cell somehow visible notebook try resolve soon,issue,positive,positive,positive,positive,positive,positive
574831922,"Ah, the translation that just got merged was based on a version of the notebook from before the changes in this PR.",ah translation got based version notebook,issue,negative,neutral,neutral,neutral,neutral,neutral
574830784,"Confused why CI tests just started failing again, but pretty sure it's not an issue with the content of this PR.",confused failing pretty sure issue content,issue,negative,positive,positive,positive,positive,positive
574705975,"I'm not sure I fully understand it either, just chiming in on the point about inheritance. 😄 ",sure fully understand either point inheritance,issue,negative,positive,positive,positive,positive,positive
574697383,"@bhadreshpsavani Assigned it to you. Happy to help with this, ping me on Slack if you want to talk more about it.",assigned happy help ping slack want talk,issue,positive,positive,positive,positive,positive,positive
574677752,"I don't see the semantic difference between an encoder and a tensor type
(something used in our tensor chain).

On Sun, Jan 12, 2020 at 3:33 PM Karl Higley <notifications@github.com>
wrote:

> My only ask would be to supply the encoder as a constructor param with a
> default value (instead of as an additional parent class via inheritance.)
> 🙂
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/2897?email_source=notifications&email_token=ABBAZESX7SJQJSF2TBSA6W3Q5MZ3VA5CNFSM4KFVASI2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEIW4VYI#issuecomment-573426401>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ABBAZEXYAJMMHOXGJSAMKZ3Q5MZ3VANCNFSM4KFVASIQ>
> .
>
",see semantic difference tensor type something used tensor chain sun wrote ask would supply constructor param default value instead additional parent class via inheritance thread reply directly view,issue,negative,positive,neutral,neutral,positive,positive
574675592,"Sorry - ""inherit"" was the wrong term. 

A user of FixedPrecisionTensor could do so using either IntTensor, LongTensor, or BigIntTensor as the underlying representation, as in:

Wrapper -> FixedPrecisionTensor -> IntTensor
Wrapper -> FixedPrecisionTensor -> LongTensor
Wrapper -> FixedPrecisionTensor -> BigIntTensor

are all viable candidates.",sorry inherit wrong term user could either underlying representation wrapper wrapper wrapper viable,issue,negative,negative,negative,negative,negative,negative
574556456,"I would love to help on this PR and translate the remaining notebooks. I am currently diving back to the project and it can be a good way to catch up. 
Is It ok if I add comments on this one and create another PR for the other ones ?
",would love help translate currently diving back project good way catch add one create another,issue,positive,positive,positive,positive,positive,positive
574502238,"currently working to onboard syft to conda-forge and will be the maintainer on the following [fork](https://github.com/systemshift/staged-recipes/tree/syft).
I have edited the recipe [file](https://github.com/systemshift/staged-recipes/blob/syft/recipes/syft/meta.yaml) but left some comments and will continue to work on it.

but from the FAQ, I think I found the reason behind the error.
```

 7. When or why do I need to use `{{ PYTHON }} -m pip install . -vv`?**

This should be the default install line for most Python packages. This is preferable to `python setup.py` because it handles metadata in a `conda`-friendlier way.
```
",currently working maintainer following fork recipe file left continue work think found reason behind error need use python pip install default install line python preferable python way,issue,negative,negative,neutral,neutral,negative,negative
574403802,Good work! That's a lot to go through I have reviewed part 5 and 6 notebooks for now.,good work lot go part,issue,negative,positive,positive,positive,positive,positive
574279844,"> > Thanks for the changes! Can you remove numpy fo the requirements to validate the change? :)
> 
> I can still see `numpy` used in notebooks, pate and other places in the project.

Ok cool!
",thanks remove validate change still see used pate project cool,issue,positive,positive,positive,positive,positive,positive
574168636,"> Thanks for the changes! Can you remove numpy fo the requirements to validate the change? :)

I can still see `numpy` used in notebooks, pate and other places in the project.",thanks remove validate change still see used pate project,issue,positive,positive,positive,positive,positive,positive
574089267,"> May I ask you to also remove CRTTensor? It is not used too... :/

Let me check with Jason. @Jasopaum ",may ask also remove used let check,issue,negative,neutral,neutral,neutral,neutral,neutral
574035336,"It is used when creating shares bigger than 2**62. If the new `TensorBigInt` does the same, it won't be necessary.
Initially LPT was necessary to allow these operations with big ints in the JVM.

I'll create a PR to delete it.",used bigger new wo necessary initially necessary allow big create delete,issue,negative,positive,neutral,neutral,positive,positive
573984738,"Optionally inherit? Like, two different classes with one that inherits and one that doesn't, or...?",optionally inherit like two different class one one,issue,negative,neutral,neutral,neutral,neutral,neutral
573980163,"> Yeah - and I loop here again with the suggestion that if LargePrecision is not used it should be archived for the moment it would make our life simpler, @mccorby any thoughts?

Is it not being uesd?",yeah loop suggestion used moment would make life simpler,issue,negative,neutral,neutral,neutral,neutral,neutral
573980105,"> Is this a situation where PyTorch's new support for extending tensors would make this easier/simpler?

Sadly no ",situation new support extending would make sadly,issue,negative,negative,negative,negative,negative,negative
573976676,"This work should probably be blocked until PromiseTensor is really at a place we're happy with. The culmination of a lot of discussion on what Protocols are ended with, ""Protocols are a collection of VirtualWorker objects with a PromiseTensor graph traversing them (stored within the VirtualWorkers' collective object stores""",work probably blocked really place happy culmination lot discussion ended collection graph traversing within collective object,issue,negative,positive,positive,positive,positive,positive
573824804,"Rereading the code snippet, I'm not sure if `x` is a pointer to a fixed precision tensor. I *think* it works like this (but I could be wrong):

```python
t = torch.tensor([1, 2, 3, 4.0])
ptr = t.send(james)                      # PointerTensor to a Torch tensor
x_fix_ptr = ptr.fix_prec()               # PointerTensor to a FixedPrecisionTensor
x_ast_ptr = x_fix_ptr.share(bob, alice)  # PointerTensor to an AdditiveSharingTensor
x_fix = x_fix_ptr.get()                  # FixedPrecisionTensor
x_ast = x_ast_ptr.get()                  # AdditiveSharingTensor
```

I'm surprised that `x.get().get()` worked with any `garbage_collect_data` setting. 🤔 ",code snippet sure pointer fixed precision tensor think work like could wrong python torch tensor bob worked setting,issue,negative,positive,neutral,neutral,positive,positive
573766529,Is this a situation where PyTorch's new support for extending tensors would make this easier/simpler?,situation new support extending would make,issue,negative,positive,positive,positive,positive,positive
573575257,"If I remember correctly, we had to use `numpy` to work with very large numbers as it was not possible to implement the basic operations by using only the representation in smaller tensors of those numbers.

`_internal_representation_to_large_ints`: This is where we should put the focus to remove `numpy`. If we could have a `tensor(dtype=object)` then it could easy to replace numpy.",remember correctly use work large possible implement basic representation smaller put focus remove could tensor could easy replace,issue,negative,positive,positive,positive,positive,positive
573551054,"Maybe this should be also in the list:
`Protocol.detail()` doesn't always reconstruct Protocol as it is presented in serialized form, worker_id's may change in detailed object.",maybe also list always reconstruct protocol form may change detailed object,issue,negative,positive,positive,positive,positive,positive
573450384,"The top priority is cross platform support and Plan/Promise support, both of which numpy prevents. Using Torch tensors instead does not.

Sent from my iPhone

> On 12 Jan 2020, at 10:13, Théo Ryffel <notifications@github.com> wrote:
> 
> ﻿
> From what I experienced, when we don't use numpy tensor ops we use torch ones which is ok but put a big dependency on pytorch (we from an historical point of view of pysyft is 100% ok)
> 
> However, I have also the feeling that some expressions (in particular crypto protocols) are better expressed using numpy which is way faster (I'm working on one where I have a 10 times improvements). Additionally numpy is independent from the GAFAs^^
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub, or unsubscribe.
",top priority cross platform support support torch instead sent wrote experienced use tensor use torch put big dependency historical point view however also feeling particular better expressed way faster working one time additionally independent reply directly view,issue,positive,positive,positive,positive,positive,positive
573449602,Interested to work on it @karlhigley. Please tell me what to change,interested work please tell change,issue,positive,positive,positive,positive,positive,positive
573426401,My only ask would be to supply the encoder as a constructor param with a default value (instead of as an additional parent class via inheritance.) 🙂,ask would supply constructor param default value instead additional parent class via inheritance,issue,negative,neutral,neutral,neutral,neutral,neutral
573426100,The CI tests check that the `black` code formatter wouldn’t change any of the files in the commit. It normally runs during the pre-commit hook and fixes any formatting issues for you. I can’t tell from the log section you shared what the problem might be—I suspect the issues to address are farther up in the output. Seems like some kind of compilation error though?,check black code change commit normally hook tell log section problem might suspect address farther output like kind compilation error though,issue,negative,positive,positive,positive,positive,positive
573400130,"From what I experienced, when we don't use numpy tensor ops we use torch ones which is ok but put a big dependency on pytorch (we from an historical point of view of pysyft is 100% ok)

However, I have also the feeling that some expressions (in particular crypto protocols) are better expressed using numpy which is way faster (I'm working on one where I have a 10 times improvements). Additionally numpy is independent from the GAFAs^^",experienced use tensor use torch put big dependency historical point view however also feeling particular better expressed way faster working one time additionally independent,issue,positive,positive,positive,positive,positive,positive
573397219,"That's right!
1. So actually once you are in Fixed-precision, you can't do anymore pow, exp, simoid, log, inversion the way you did previously, so you have to redefine them, and I'd say this is the good place.
2. Less important, some functions like Convolutional should indeed be put in our dedicated `nn` module where rnn already lies.
3. Having references to AdditiveSharingTensor is *super* annoying, but from our design seems hard to avoid, since we want to operate tensors with different types (FPT & AST)

Actually, we could follow the design principle of another lib and define fixed-precision not as a tensor type but as an encoder which is attached to a tensor. This sounds weird but:
- It reconciliate FPT & AST in a single type and solves 3.
- It diminishes the number of tensors types and reduces the tensor chain size
- It is more readable for non-expert users

To avoid the limitation of having to redefine the encoder for the HomomorphicTensor, etc, encoder could be supplied by a inheritance mechanism, but then @karlhigley is not going to be happy lol

In a nutshell
- I don't think 1. is that of a problem
- Issue 2. can be solved easily
- Issue 3. needs more intelligence, to make for example the mul function of FPT readable",right actually ca pow log inversion way previously redefine say good place le important like convolutional indeed put module already super annoying design hard avoid since want operate different ast actually could follow design principle another define tensor type attached tensor weird reconciliate ast single type number tensor chain size readable avoid limitation redefine could inheritance mechanism going happy nutshell think problem issue easily issue need intelligence make example function readable,issue,positive,positive,neutral,neutral,positive,positive
573371368,I will begin working on a properly decoupled BigInt tensor,begin working properly tensor,issue,negative,neutral,neutral,neutral,neutral,neutral
573371101,"Hi @Jasopaum - upon further review of that class it does indeed look like a convolutional layer exists there. However, unbeknownst to me the class has an enormous amount of functionality which is unrelated to FixedPrecision representations. I suspect that this has been done for coding convenience and possibly justified for performance reasons. If so, this is done at the expense of code re-use and good organization and is in urgent need of refactoring.

At present, I will not refer to it and have created a Github issue describing extensive refactoring required (https://github.com/OpenMined/PySyft/issues/2897). Once the refactoring is completed, we can adjust the classes created in this PR to reference wherever the new functionality exists.",hi upon review class indeed look like convolutional layer however unbeknownst class enormous amount functionality unrelated suspect done convenience possibly performance done expense code good organization urgent need present refer issue extensive adjust class reference wherever new functionality,issue,positive,positive,positive,positive,positive,positive
573369258,"We already have our own conv2d implementation, it’s not in the nn module but in the FixedPrecisionTensor class, I think. It was implemented before the rnn so it’s not at the right place (I know we should have moved it before).
Maybe it can be improved but you can at least start from there 🙂",already implementation module class think right place know maybe least start,issue,negative,negative,neutral,neutral,negative,negative
573326976,"> @codergan Looks like CI turned up a formatting issue. Do you have the [pre-commit hook](https://github.com/OpenMined/PySyft/blob/master/CONTRIBUTING.md#setting-up-pre-commit-hook) set up?

Hi, I am following the instruction and got this error when setiing the pre-commit hook:
fatal error: too many errors emitted, stopping now [-ferror-limit=]
20 errors generated.
error: Setup script exited with error: command 'gcc' failed with exit status 1
make: *** [venv/bin/activate] Error 1
May I know what do I suppose to do? And the error of the check seems to be error on formatting, do you know what is the reason for that?",like turned issue hook set hi following instruction got error hook fatal error many stopping error setup script error command exit status make error may know suppose error check error know reason,issue,negative,positive,positive,positive,positive,positive
573324551,@codergan Looks like CI turned up a formatting issue. Do you have the [pre-commit hook](https://github.com/OpenMined/PySyft/blob/master/CONTRIBUTING.md#setting-up-pre-commit-hook) set up?,like turned issue hook set,issue,negative,neutral,neutral,neutral,neutral,neutral
573198101,"> @iamtrask Does removing numpy import implies the use of an alternate library or making alternate implementation?

Ideally to reimplement without importing any other library, but I've been scratching my head how replace numpy arrays with python lists without increasing code complexity too much, but I still believe this is still best approach.
The other option is to hook numpy, as mentioned above, but that should be our last option.

I have been looking at [other](https://wiki.python.org/moin/NumericAndScientific/Libraries) options but nothing stands out, and I don't think it would be wise to add a new dependency just to solve this one issue.  ",removing import use alternate library making alternate implementation ideally without library scratching head replace python without increasing code complexity much still believe still best approach option hook last option looking nothing think would wise add new dependency solve one issue,issue,positive,positive,positive,positive,positive,positive
573161928,@iamtrask Does removing numpy import implies the use of an alternate library or making alternate implementation?,removing import use alternate library making alternate implementation,issue,negative,neutral,neutral,neutral,neutral,neutral
572982807,"About the checklist, Yeah! It's complete. I was wondering to perform CI tests about grid nodes on this repository, but I feel It would be a bad idea (We would probably need to download, install and run PyGrid's stuff in this CI environment which will turn our CI complex and slower). So, I think it'll be better if we do it in PyGrid's repository...",yeah complete wondering perform grid repository feel would bad idea would probably need install run stuff environment turn complex think better repository,issue,negative,negative,neutral,neutral,negative,negative
572980652,Hello @karlhigley! I just restart the CI tests and it works well! Maybe some CI timeout flag was triggered for the first time that it ran.,hello restart work well maybe flag triggered first time ran,issue,negative,positive,positive,positive,positive,positive
572977406,"I have requested for a pull request: fedavg #2893, plz help to review",pull request help review,issue,negative,neutral,neutral,neutral,neutral,neutral
572952876,Lots of work around serde makes this issue not relevant anymore.,lot work around issue relevant,issue,negative,positive,positive,positive,positive,positive
572933973,"@Yugandhartripathi  @raheja I think some translated words to hindi have different meaning in a particular context and I think we can leave it upto 'Vivek' of contributor to come up with appropriate translated word. Just my thought on this :)

Also over a weekend i should be able to complete pending items 9, 10.",think different meaning particular context think leave contributor come appropriate word thought also weekend able complete pending,issue,negative,positive,positive,positive,positive,positive
572851368,"@IonesioJunior Re-ran the CI tests, which passed following fixes merged into master. Unless merging master again breaks the tests for some reason, it looks like the checklist on this PR will be complete.",following master unless master reason like complete,issue,negative,positive,neutral,neutral,positive,positive
572840746,Coverage tests fail because the exception case isn't exercised. 🤕 ,coverage fail exception case,issue,negative,negative,negative,negative,negative,negative
572840225,"@raheja no need to wait for intermediate translations you can proceed to upload the ones you have completed.

As for translator name others have put their names in there I understand your views on it but I think it's more about taking responsibility for the translations which will be done better if there is a person's name on there plus the editor title is a bit ambiguous here as there are often various small changes and fixes in code and notebooks done by countless contributors all of them eligible for editor title but we can't have all the names up there some must work from the shadows and live on in Github commit history's hall of fame.

 ' पूर्वानुमान ' definitely makes more sense here.

As for the remaining notebooks I plan to complete my self assigned parts i.e. 11,12,12-bis,13a in a few days. ",need wait intermediate proceed translator name put understand think taking responsibility done better person name plus editor title bit ambiguous often various small code done countless eligible editor title ca must work live commit history hall definitely sense plan complete self assigned day,issue,positive,positive,neutral,neutral,positive,positive
572839002,"@iamtrask When you create a PR, the big green button has a drop-down that lets you create a ""draft PR"", which can't be merged until you remove the ""draft"" designation. It's a neat new feature I just recently learned about.",create big green button create draft ca remove draft designation neat new feature recently learned,issue,positive,negative,neutral,neutral,negative,negative
572838635,CI tests indicate that we're coupled to exactly PyTorch 1.3.0 (due to TorchVision.),indicate coupled exactly due,issue,negative,negative,negative,negative,negative,negative
572780529,@Ankit-Dhankhar I think [this try/except that decodes bytes to a string](https://github.com/OpenMined/PySyft/blob/ff080c1aff7ef99f5a0411b97ca1e3ac924b9ae4/syft/workers/base.py#L428-L435) is an example of the sort of check this issue is referring to.,think string example sort check issue,issue,negative,neutral,neutral,neutral,neutral,neutral
572779634,"@bhadreshpsavani, it looks to me like the `deregister_ptr` param is doing basically this, as you pointed out. `get_copy` would probably be a clearer name for the param though, so might still be worth changing.",like param basically pointed would probably clearer name param though might still worth,issue,positive,positive,positive,positive,positive,positive
572774831,"@Ankit-Dhankhar I cloned your fork, squashed the commits in this PR, and rebased it on current PySyft master. You can see the [resulting diff](https://github.com/OpenMined/PySyft/commit/39b7f23a25834299f99d6bee062efee0002499d2) over here on the `pr/2376` branch.

Sorry it's taken so long! Okay to force-push the result to your branch so we can finally get this PR merged? 😄 ",fork current master see resulting branch sorry taken long result branch finally get,issue,negative,negative,negative,negative,negative,negative
572741649,@mccorby Are the [examples in the test helpers](https://github.com/OpenMined/PySyft/blob/master/test/serde/serde_helpers.py) sufficient to document the msgpack serialization format? Wondering if we can now close this issue.,test sufficient document serialization format wondering close issue,issue,negative,neutral,neutral,neutral,neutral,neutral
572695838,"> Is [this change](https://github.com/OpenMined/PySyft/commit/5b9161eb326a3e5d5a4c0b6c3de18b8ce467c314#diff-5bfe6150bb5ee943c40230a4bdb0b054L990-R995) (from the serde inconsistency fixes) the relevant change that breaks this?

No. [this change from PR](https://github.com/sukhadj/PySyft/blob/f2754053352e7a0e01edc6eb326b551cf1f34cfe/syft/frameworks/torch/tensors/interpreters/additive_shared.py#L1008) breaking it. Currently commented out. ",change inconsistency relevant change change breaking currently,issue,negative,positive,positive,positive,positive,positive
572688286,"> It's interesting that the round-trip serialization test passes, but the simplification test fails. Makes me wonder if the simplification test assertion has the correct expected value. thinking

Hey, so currently comparison function we employ just compares if class name matches but not the attributes. I'm working on comparison of  _attributes. Not sure if we should just check equality of list :smiley:  ",interesting serialization test simplification test wonder simplification test assertion correct value thinking hey currently comparison function employ class name working comparison sure check equality list,issue,positive,positive,positive,positive,positive,positive
572684401,Is [this change](https://github.com/OpenMined/PySyft/commit/5b9161eb326a3e5d5a4c0b6c3de18b8ce467c314#diff-5bfe6150bb5ee943c40230a4bdb0b054L990-R995) (from the serde inconsistency fixes) the relevant change that breaks this?,change inconsistency relevant change,issue,negative,positive,positive,positive,positive,positive
572682932,"It's interesting that the round-trip serialization test passes, but the simplification test fails. Makes me wonder if the simplification test assertion has the correct expected value. 🤔 ",interesting serialization test simplification test wonder simplification test assertion correct value,issue,positive,positive,positive,positive,positive,positive
572554600,@kaustubh-seachange add your name as translator in the first cell below the author's,add name translator first cell author,issue,negative,positive,positive,positive,positive,positive
572549759,"Yes it's a good idea!
I'd love to see your suggestion on this :)",yes good idea love see suggestion,issue,positive,positive,positive,positive,positive,positive
572549232,"FYI this error comes from recent changes in how we serialize AdditiveSharing tensors
",error come recent serialize,issue,negative,neutral,neutral,neutral,neutral,neutral
571551014,"i exactly followed installation process in README.md file.
```
conda create -n pysyft python=3.6
conda activate pysyft
conda install jupyter notebook
pip install syft[udacity]
```
i explicitly added 

> python=3.6

because python=3 install python3.8 and there is no pytorch or tensorflow version compatible with python3.8",exactly installation process file create activate install notebook pip install explicitly added install python version compatible python,issue,negative,positive,positive,positive,positive,positive
571528285,"Hi,
Could you describe the installation process that you followed? Since there seem to be so many variations, and hence I am facing bugs
Thank you",hi could describe installation process since seem many hence facing thank,issue,negative,positive,positive,positive,positive,positive
571519411,"For sake of clarity, I think this PR should only add the sklearn requirement",sake clarity think add requirement,issue,negative,neutral,neutral,neutral,neutral,neutral
571308707,"Sorry for the late reply.
Could you run:
```pip install -r pip-deps/requirements_tensorflow.txt```

And check if it works?",sorry late reply could run pip install check work,issue,negative,negative,negative,negative,negative,negative
571233286,"Posting the below message here again, since the previous [issue](https://github.com/OpenMined/PySyft/issues/2774)  is closed. @Yugandhartripathi  @kaustubh-seachange @darkmatter18 

Hey all, I have finished my assigned translations. As mentioned above, I am not putting my name under 'translator'. So 'anuvadak' is nbTranslate, while 'sampadak', or editor, is me. I believe we can also use, 'NbTranslate का उपयोग करके ... (your name) द्वारा अनुवादित'. Let me know your thoughts.

Since my notebook numbers are 5, 6, 13b, 13c do you all think we should proceed with uploading the tutorial 4, and the rest before I upload mine? Let me know.

In case others are not getting time to translate the tutorials, I can finish off the remaining ones as well. Again, let me know. :)

For those who might come across the word 'predictions' in their tutorials, the default hindi translation is 'bhavishyavani',. I have used the term, ' पूर्वानुमान ' instead. That made more sense to me.
So, gist --- please let me know your suggestions. :)",posting message since previous issue closed hey finished assigned name editor believe also use name let know since notebook think proceed tutorial rest mine let know case getting time translate finish well let know might come across word default translation used term instead made sense gist please let know,issue,positive,negative,negative,negative,negative,negative
571174385,"from a quick search, `scipy` is called in 2 notebooks, and `lr.py`. So even without the notebooks it was necessary  to add `scipy` to the main `requirements.txt` file.
Now thinking about it, it is possible that some users don't want to use conda(or can't) and would just prefer pip + venv, so that should be considered as well.",quick search even without necessary add main file thinking possible want use ca would prefer pip considered well,issue,negative,positive,positive,positive,positive,positive
570985205,"It seems like the biggest culprit lately has been the addition of the notebook tests to the test suite. I think the notebook dependencies were previously optional and hadn't been added to the Makefile `venv` target yet. IIRC, that's also where the missing `scipy` dependency cropped up, right?",like biggest culprit lately addition notebook test suite think notebook previously optional added target yet also missing dependency right,issue,negative,negative,neutral,neutral,negative,negative
570920413,"Hey all, I have finished my assigned translations. As mentioned above, I am not putting my name under 'translator'. So 'anuvadak' is nbTranslate, while 'sampadak', or editor, is me. I believe we can also use, 'NbTranslate का उपयोग करके ... (your name) द्वारा अनुवादित'.  Let me know your thoughts.

Since my notebook numbers are 5, 6, 13b, 13c  do you all think we should proceed with uploading the tutorial 4, and the rest before I upload mine? Let me know.

In case others are not getting time to translate the tutorials, I can finish off the remaining ones as well. Again, let me know.  :)

For those who might come across the word 'predictions' in their tutorials, the default hindi translation is 'bhavishyavani',. I have used the term, ' पूर्वानुमान ' instead. That made more sense to me. 
So, gist  --- please let me know your suggestions.   :)",hey finished assigned name editor believe also use name let know since notebook think proceed tutorial rest mine let know case getting time translate finish well let know might come across word default translation used term instead made sense gist please let know,issue,positive,neutral,neutral,neutral,neutral,neutral
570910203,"change ""host"" to your local address like ""192.168.x.x"" (not 127.0.0.1), it works on my machine.",change host local address like work machine,issue,negative,neutral,neutral,neutral,neutral,neutral
570900695,"@LaRiffle When I try to send a Dataset I get this error:

`syft.exceptions.UndefinedProtocolTypeError: syft.frameworks.torch.fl.dataset.BaseDataset is not defined in the protocol file`

Should I modify syst proto package too?",try send get error defined protocol file modify proto package,issue,negative,neutral,neutral,neutral,neutral,neutral
570801587,"There seems to be one more problem here.
The comparison of _attributes is not working. Will be working on that :100:  ",one problem comparison working working,issue,negative,neutral,neutral,neutral,neutral,neutral
570801179,"Hey, I have updated the code in #2871  with dirty fix suggested by @LaRiffle. 

> > I would be tempted here by a dirty fix
> 
> Shouldn't it be `tensor.set_garbage_collect_data(<previous value>)`? :-)
> Or is it always True?

It is now set to previous value.",hey code dirty fix would dirty fix previous value always true set previous value,issue,negative,negative,negative,negative,negative,negative
570799003,"> I would be tempted here by a dirty fix

Shouldn't it be `tensor.set_garbage_collect_data(<previous value>)`? :-)
Or is it always True?",would dirty fix previous value always true,issue,negative,negative,negative,negative,negative,negative
570795289,"@PlamenHristov #2826 won't be merged, so I think this is still relevant.",wo think still relevant,issue,negative,positive,positive,positive,positive,positive
570794982,"I'm fine with a dirty fix for now to make `grad_fn` serialization work and get it merged. I do think these issues are related though, in that they're both cases where another kind of operation is entangled with serialization/deserialization. Thinking that might be a sign that there's a missing abstraction here that would provide common structure for operations that need to happen around sending/receiving.",fine dirty fix make serialization work get think related though another kind operation entangled thinking might sign missing abstraction would provide common structure need happen around,issue,negative,negative,neutral,neutral,negative,negative
570793753,"I would be tempted here by a dirty fix

```python
tensor.set_garbage_collect_data(False)

r = (
            sy.serde.msgpack.serde._simplify(worker, tensor.id),
            tensor.field,
            sy.serde.msgpack.serde._simplify(worker, tensor.crypto_provider.id),
            chain,
        )
tensor.set_garbage_collect_data(True)
return r
```

(But this doesn't concern the PointerTensor issue you mentioned @karlhigley 
This phenomenon is due to how Plans are implemented, because they store serialized pointers which needs to deserialize as tensors. It's dirty, it my fault lol, and maybe changing the way Plans are created is the best idea to get rid of this improper deserialization behavior)",would dirty fix python false worker worker chain true return concern issue phenomenon due store need dirty fault maybe way best idea get rid improper behavior,issue,negative,negative,neutral,neutral,negative,negative
570788808,@iamtrask @vvmnnnkv Thoughts on this? Could we introduce some kind of hook methods for making changes before sending or after receiving?,could introduce kind hook making sending,issue,positive,positive,positive,positive,positive,positive
570788631,"Serialization/deserialization itself should never change the state or type of an object, both because that breaks the contract of serialization (""I take your object and translate it to and from a wire-friendly format"") and because that makes it harder to maintain multiple serialization formats by requiring duplicated code in multiple places.

So...it seems like we might need a mechanism for making changes before sending and/or after receiving. There's a similar issue with `PointerTensor`, where deserialization can return either a `PointerTensor` or a `torch.Tensor`, because the deserialization checks to see if the tensor is local and loads it if so.",never change state type object contract serialization take object translate format harder maintain multiple serialization code multiple like might need mechanism making sending similar issue return either see tensor local,issue,negative,negative,neutral,neutral,negative,negative
570785280,"Hey @karlhigley @LaRiffle , the tests are failing due to inconsistent serialization (and one because of syntax error :sweat_smile: ).
I have opened the issue #2882. Any thoughts? :smiley:  ",hey failing due inconsistent serialization one syntax error issue,issue,negative,negative,negative,negative,negative,negative
570717122,"I think this issue requires some clarification. From what I understand `Message.simplify()` and `Message.detail()` should be inverses of each other. However, I don' think that's exactly what's happening. If we consider the test below: 

```
def test_message_detail_returns_specific_type():
    tensor = th.tensor([1, 2, 3, 4])
    operation = message.Operation(
        cmd_name=""_add__"",
        cmd_owner=tensor,
        cmd_args=(tensor,),
        cmd_kwargs={},
        return_ids=96100376575,
    )

    wrapped = message.SearchMessage(operation)
    simplified_operation = message.Message.simplify(sy.local_worker, wrapped)
    detailer = detailers[simplified_operation[0][0]]
    detailed_operation = message.Message.detail(sy.local_worker, simplified_operation)

    assert isinstance(detailed_operation, message.Operation)
```
when [Message.simplify()](https://github.com/OpenMined/PySyft/blob/fd16c9ada84e6df9a7293db8b3a6dd6df109e128/syft/messaging/message.py#L65) takes the contents of `wrapped`, because it reads the `wrapped.contents`, it effectively removes the knowledge of the `SearchMessage` object and returns directly the `Operations` object. 

![image](https://user-images.githubusercontent.com/3893599/71752174-cf802a80-2e86-11ea-96a4-662ef9ce6acd.png)

Next when the simplified object gets passed to [Message.detail()](https://github.com/OpenMined/PySyft/blob/fd16c9ada84e6df9a7293db8b3a6dd6df109e128/syft/messaging/message.py#L91) it only has info for the `Operations` object thus the only thing it can do is wrap it in a `Message` object.

There are two ways to approach this and have a ""fix"" for the issue. Either:

- Don't take the contents of the message on `Message.simplify()`, but the whole `ptr`, then `Message.detail()` can do `return sy.serde.msgpack.serde._detail(worker, msg_tuple[0])`

**OR**

- Keep `Message.simplify()` the same, but have something like the below code in `Message.detail()`  
```
        obj = sy.serde.msgpack.serde._detail(worker, msg_tuple[0])
        if isinstance(obj, Message):
            return obj
        return Message(obj)
```

**Let me know your thoughts.** ",think issue clarification understand however think exactly happening consider test tensor operation tensor wrapped operation wrapped detailer assert content wrapped effectively knowledge object directly object image next simplified object object thus thing wrap message object two way approach fix issue either take content message whole return worker keep something like code worker message return return message let know,issue,positive,positive,positive,positive,positive,positive
570396695,"I haven't been able to replicate these test failures locally, so going to try restarting the build.",able replicate test locally going try build,issue,negative,positive,positive,positive,positive,positive
570342298,"Getters and setters worked out well. 👍 

These notebook tests are killing me though. They take a long time and it's hard to tell why they're failing.",worked well notebook killing though take long time hard tell failing,issue,negative,negative,negative,negative,negative,negative
570279425,@karlhigley I believe we currently have some problems mul and pow. So will go ahead with simple `AddBackward` for now :smile: ,believe currently pow go ahead simple smile,issue,negative,positive,neutral,neutral,positive,positive
570258625,"Closing this in favor of a series of smaller PRs with round-trip serialization tests. Thanks for the review, @vvmnnnkv!",favor series smaller serialization thanks review,issue,positive,positive,neutral,neutral,positive,positive
570211743,"@vvmnnnkv Wanted to get something of reasonable complexity serialized, so I tackled this, but haven’t forgotten about your previous comments. Happy to do some refactoring to handle id getting/setting, avoid unnecessary `CopyFrom`s, etc (either in this PR or as a separate PR.)",get something reasonable complexity tackled forgotten previous happy handle id avoid unnecessary either separate,issue,negative,positive,positive,positive,positive,positive
570200278,"@sukhadj I don’t mean to hassle you about tests, I’m just excited about this one! 😅

I’d pick a gradient function that exercises as much of the code as possible and use that as your test example.",mean hassle excited one pick gradient function much code possible use test example,issue,negative,positive,neutral,neutral,positive,positive
570180176,"@karlhigley @LaRiffle Should we add tests for each gradient function? 
Or will the test for one class (any or specific) suffice? ",add gradient function test one class specific suffice,issue,negative,neutral,neutral,neutral,neutral,neutral
570116287,Well done! An incredible amount of translation!,well done incredible amount translation,issue,negative,positive,positive,positive,positive,positive
570085591,"Notebooks:
 - [Intro to Grid Platform](https://github.com/IonesioJunior/PySyft/blob/add_grid_workers/examples/tutorials/grid/Part%2001%20-%20Intro%20to%20Grid%20Platform.ipynb)
 - [Grid as s Secure MLaaS](https://github.com/IonesioJunior/PySyft/blob/add_grid_workers/examples/tutorials/grid/Part%2002%20-%20Grid%20as%20a%20Secure%20MLaaS%20to%20Cloud%20Providers.ipynb)
 - [Grid applied to smart cities and smart homes](https://github.com/IonesioJunior/PySyft/blob/add_grid_workers/examples/tutorials/grid/Part%2003%20-%20Grid%20applied%20to%20Smart%20Cities%20and%20Smart%20Homes.ipynb)
 - Federated Learning
    - [MNIST](https://github.com/IonesioJunior/PySyft/tree/add_grid_workers/examples/tutorials/grid/federated_learning/mnist)
    - [SPAM Prediction](https://github.com/IonesioJunior/PySyft/tree/add_grid_workers/examples/tutorials/grid/federated_learning/spam_prediction)",grid platform grid secure grid applied smart smart learning prediction,issue,positive,positive,positive,positive,positive,positive
570068726,"Exactly (forgive brevity I’m replying via email on my phone)

Sent from my iPhone

> On 1 Jan 2020, at 10:32, Karl Higley <notifications@github.com> wrote:
> 
> ﻿
> Sure, I'm not in a hurry to remove it, I just want to understand what's going on here and the comments don't entirely spell it out. Based on the keywords .shape, PointerTensor, and ""custom tensor type support"", I'm guessing that the issue might be that calling .shape on a PointerTensor doesn't quite work due to limitations in PyTorch and this message is a workaround for that?
> 
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub, or unsubscribe.
",exactly forgive brevity via phone sent wrote sure hurry remove want understand going entirely spell based custom tensor type support guessing issue might calling quite work due message thread reply directly view,issue,positive,positive,positive,positive,positive,positive
570066434,Most of the CI test failures are due to a version mismatch between `syft-proto` and `PySyft` which will be resolved when #2876 is merged. This PR still needs serialization tests for `GradFunc` though.,test due version mismatch resolved still need serialization though,issue,negative,negative,negative,negative,negative,negative
570065885,"Sure, I'm not in a hurry to remove it, I just want to understand what's going on here and the comments don't entirely spell it out. Based on the keywords `.shape`, `PointerTensor`, and ""custom tensor type support"", I'm guessing that the issue might be that calling `.shape` on a `PointerTensor` doesn't quite work due to limitations in PyTorch and this message is a workaround for that?",sure hurry remove want understand going entirely spell based custom tensor type support guessing issue might calling quite work due message,issue,positive,positive,positive,positive,positive,positive
570017704,"Don’t delete this yet. We need it for pointertensor

Sent from my iPhone

> On 31 Dec 2019, at 16:18, Karl Higley <notifications@github.com> wrote:
> 
> ﻿
> The semantics of ObjectRequestMessage don't lend themselves nicely to this use case either, because ORM indicates that the worker should delete its copy of the tensor after sending it back.
> 
> The comment that led me here says:
> 
> # TODO: remove this message type and use ObjectRequestMessage instead.
> # note that the above to do is likely waiting for custom tensor type support in PyTorch
> # https://github.com/OpenMined/PySyft/issues/2513
> PyTorch now has some kind of custom tensor type support, but I'm not sure what that has to do with GetShapeMessage. Any idea?
> 
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub, or unsubscribe.
",delete yet need sent wrote semantics lend nicely use case either worker delete copy tensor sending back comment led remove message type use instead note likely waiting custom tensor type support kind custom tensor type support sure idea thread reply directly view,issue,positive,positive,positive,positive,positive,positive
569998541,"The semantics of ObjectRequestMessage don't lend themselves nicely to this use case either, because ORM indicates that the worker should delete its copy of the tensor after sending it back.

The code that led me here looks like this:
```
class GetShapeMessage(Message):
    """"""Get the shape property of a tensor in PyTorch

    We needed to have a special message type for this because .shape had some
    constraints in the older version of PyTorch.""""""

    # TODO: remove this message type and use ObjectRequestMessage instead.
    # note that the above to do is likely waiting for custom tensor type support in PyTorch
    # https://github.com/OpenMined/PySyft/issues/2513
```

PyTorch now has some kind of custom tensor type support, but I'm not sure what that has to do with GetShapeMessage. Any idea?",semantics lend nicely use case either worker delete copy tensor sending back code led like class message get shape property tensor special message type older version remove message type use instead note likely waiting custom tensor type support kind custom tensor type support sure idea,issue,positive,positive,positive,positive,positive,positive
569910272,"I can work on this, please assign me the issue.",work please assign issue,issue,negative,neutral,neutral,neutral,neutral,neutral
569827673,@sukhadj This has a few small conflicts with master. Could you resolve them so we can get the CI tests running?,small master could resolve get running,issue,negative,negative,negative,negative,negative,negative
569712945,"Definitely use Numpy’s support for subclassing. Eventually the PyTorch side will do this too (changing FrameworkHook considerably) as PyTorch very recently received support for subclassing 

Sent from my iPhone

> On 30 Dec 2019, at 08:22, Alejandro Sánchez Medina <notifications@github.com> wrote:
> 
> ﻿
> Reopened #2771.
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub, or unsubscribe.
",definitely use support eventually side considerably recently received support sent wrote reply directly view,issue,positive,positive,neutral,neutral,positive,positive
569707529,"For testing, you can add examples in the [serde test helpers](https://github.com/OpenMined/PySyft/blob/master/test/serde/serde_helpers.py) and add `GradFunc` to the list of classes tested for round-trip serialization [here](https://github.com/OpenMined/PySyft/blob/master/test/serde/msgpack/test_msgpack_serde_full.py#L80).",testing add test add list class tested serialization,issue,negative,neutral,neutral,neutral,neutral,neutral
569689053,"Hi @MarksASP95!

Both solutions involve development. I'm currently working and documenting the NumPy integration [on this issue](https://github.com/OpenMined/PySyft./issues/2771).",hi involve development currently working integration issue,issue,negative,neutral,neutral,neutral,neutral,neutral
569634868,"I am still seeing the same issue. I even tried making changes according to commit in the thread, still seeing the same error.

![image](https://user-images.githubusercontent.com/8968772/71577789-8e50e900-2b1b-11ea-993e-5d022fed38a8.png)
",still seeing issue even tried making according commit thread still seeing error image,issue,negative,neutral,neutral,neutral,neutral,neutral
569378022,Nope...should I run pip install tensorflow.privacy?,nope run pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
569332011,"The reason moving the tests breaks them is because it changes the order in which the tests are run. Previously the serde tests ran before the plan tests; with this change, they run after the plan tests. So this exposed an issue that already existed but wasn't yet caught by the tests. I'll see what I can do about that.",reason moving order run previously ran plan change run plan exposed issue already yet caught see,issue,negative,negative,negative,negative,negative,negative
569329418,"Hmm, not sure I've helped much yet. At least we know it's the `model.get()` where the problem occurs, but I think you already knew that.",sure much yet least know problem think already knew,issue,negative,positive,positive,positive,positive,positive
569327466,"This is a weird test failure:
```
=================================== FAILURES ===================================
_____________________________ test_serde_coverage ______________________________

    def test_serde_coverage():
        """"""Checks all types in serde are tested""""""
        for cls, _ in msgpack.serde.simplifiers.items():
            has_sample = cls in samples
>           assert has_sample is True, ""Serde for %s is not tested"" % cls
E           AssertionError: Serde for <class 'test.message.test_plan.test_plan_built_on_class.<locals>.Net'> is not tested
E           assert False is True

test/serde/msgpack/test_serde_full.py:92: AssertionError
```
Passes locally when I run this test file directly, fails when I run the full test suite. Seems like that class must get dynamically added to the serializers by the Plan tests. Not quite sure how to debug that.",weird test failure tested assert true tested class tested assert false true locally run test file directly run full test suite like class must get dynamically added plan quite sure,issue,positive,positive,neutral,neutral,positive,positive
569199909,"> Not 100% sure, but I think the `PureFrameworkTensorFoundError` is telling you that Syft expected to receive a pointer to a remote tensor but got a local Torch tensor instead, and the second error is coming from deep with PyTorch's linear algebra library, where it's trying to do tensor math but not getting valid parameters (maybe as a result of the first issue.) I can't quite trace all the way through the code to verify that's exactly what's happening, but hopefully it's enough to point in a useful direction.

Yes! you were right, moving the model.get() outside loop helped Thanks! But I now face a dimension error saying, ""Dimension out of range (expected to be in range of [-1, 0], but got 1)"" ",sure think telling receive pointer remote tensor got local torch tensor instead second error coming deep linear algebra library trying tensor math getting valid maybe result first issue ca quite trace way code verify exactly happening hopefully enough point useful direction yes right moving outside loop thanks face dimension error saying dimension range range got,issue,positive,positive,positive,positive,positive,positive
569120520,"If this issue has not been assigned to anyone, can I work on it?",issue assigned anyone work,issue,negative,neutral,neutral,neutral,neutral,neutral
569077700,"Not 100% sure, but I think the `PureFrameworkTensorFoundError` is telling you that Syft expected to receive a pointer to a remote tensor but got a local Torch tensor instead, and the second error is coming from deep with PyTorch's linear algebra library, where it's trying to do tensor math but not getting valid parameters (maybe as a result of the first issue.) I can't quite trace all the way through the code to verify that's exactly what's happening, but hopefully it's enough to point in a useful direction.",sure think telling receive pointer remote tensor got local torch tensor instead second error coming deep linear algebra library trying tensor math getting valid maybe result first issue ca quite trace way code verify exactly happening hopefully enough point useful direction,issue,positive,positive,positive,positive,positive,positive
569075658,"[This ipython issue](https://github.com/ipython/ipython/issues/6193) has some potentially relevant info about this socket error. Long story short, IPv6 `::1`, IPv4 `127.0.0.1`, and the `localhost` hostname are often but not always interchangeable. What happens if you change the `WebSocketServerWorker` instantiation to set `host=""127.0.0.1""`?",issue potentially relevant socket error long story short often always interchangeable change set,issue,negative,positive,positive,positive,positive,positive
568931534,@LaRiffle @iamtrask Would you please take a look at this?,would please take look,issue,negative,neutral,neutral,neutral,neutral,neutral
568805783,"Hey, I'm not sure how to apply the solutions you provided, could you be more specific?",hey sure apply provided could specific,issue,negative,positive,positive,positive,positive,positive
568608389,"Installing pytorch with `conda install pytorch==1.3.0 -c pytorch` before syft worked for me on Win10.
(Note exact 1.3.0 version, not just 1.3)",install worked win note exact version,issue,positive,positive,positive,positive,positive,positive
568608125,"Maybe `torch~=1.3.0` can do the job?
It's equivalent of `>=1.3.0, ==1.3.*`.
patch-release should be backward-compatible and safe for update?",maybe job equivalent safe update,issue,negative,positive,positive,positive,positive,positive
568574925,"> CI tests are failing because it can't find the new modules in `syft-proto` that haven't been merged yet. (Maybe other reasons after that, but that's the first reason.)

Updating requirements.txt to use direct git url like `https://github.com/karlhigley/syft-proto@feature/protobuf#egg=syft-proto` should help CI to install correct syft-proto version.",failing ca find new yet maybe first reason use direct git like help install correct version,issue,negative,positive,positive,positive,positive,positive
568538356,"@adilnaut If you don't mind, I would also like to translate to Russian. I suppose you have already started with Part01. So I will start translating 2 and so on. ",mind would also like translate suppose already part start,issue,negative,neutral,neutral,neutral,neutral,neutral
568505949,"CI tests are failing because it can't find the new modules in `syft-proto` that haven't been merged yet. (Maybe other reasons after that, but that's the first reason.)",failing ca find new yet maybe first reason,issue,negative,positive,positive,positive,positive,positive
568479359,I'd like to contribute to this but the description is not quite clear,like contribute description quite clear,issue,positive,positive,positive,positive,positive,positive
568250151,"Hi all, author of cuda-fixnum here; @hardbyte sent me your way.

I started working on a Python wrapper for cuda-fixnum last year, and it's still a goal of the project. Unfortunately I don't have time to work on the HLL interface part of the project at the moment, a situation which is not likely to change in the near future. The current state of my Python work is, frankly, a _mess_, and probably not worth anyone's time. But if a brave soul is willing to take up the mantle, then feel free to get in contact and I'll do my best to guide you away from the pitfalls I came across.",hi author sent way working python wrapper last year still goal project unfortunately time work interface part project moment situation likely change near future current state python work frankly probably worth anyone time brave soul willing take mantle feel free get contact best guide away came across,issue,positive,positive,positive,positive,positive,positive
568206845,"Same! Hoping that the small but repeated costs of accessing more instance variables here are offset by skipping simplification, but we'll have to measure and find out.",small repeated instance offset skipping simplification measure find,issue,negative,negative,negative,negative,negative,negative
568123653,"I can merge this after travis tests are passing - the solution for all the problems will be that someone will start looking into the ""SMS Tests""",merge travis passing solution someone start looking,issue,negative,neutral,neutral,neutral,neutral,neutral
568123311,Well done sir! Thank you for jumping into this! ,well done sir thank,issue,positive,neutral,neutral,neutral,neutral,neutral
568090080,@LaRiffle any updates on this issue? If you want I can give it a try ,issue want give try,issue,negative,neutral,neutral,neutral,neutral,neutral
568049695,"> So one issue with this though is that when PyTorch releases a new version (without our heads up) ALL of our unit tests can start failing out of no-where. This can be very stressful for the dev teams, lol.
> 
> Not 100% against it but the reason we fix to specific versions is that our hooking logic is prone to break version to version. We're quite tightly coupled to PyTorch even now.

So then we fix it to `torch==1.3.1` right?
",one issue though new version without unit start failing stressful dev reason fix specific logic prone break version version quite tightly coupled even fix right,issue,negative,positive,neutral,neutral,positive,positive
568049061,"> even for 1.3.1, I am seeing
> 
> ```
> No local packages or working download links found for torch==1.3.1
> ```

@sandeepwww, I guess you probably have but just to confirm.
Did you double-check your PyTorch version? 
I had similar error until I explicitly did `conda install pytorch==1.3.1`

On windows `pytorch==1.3` won't work ;(",even seeing local working link found guess probably confirm version similar error explicitly install wo work,issue,negative,neutral,neutral,neutral,neutral,neutral
568010026,"Based on the path of the file that it would reformat, it may have something to do with my serde refactoring PR that got merged earlier.",based path file would may something got,issue,negative,neutral,neutral,neutral,neutral,neutral
568002286,I don't understand why black isn't passing - it's working fine on my machine,understand black passing working fine machine,issue,negative,positive,positive,positive,positive,positive
567968880,"> ```
> test/torch/tensors/test_additive_shared.py         508      5    99%   411-416
> ```
> 
> Looks like these lines aren't getting called in the testing suite. Can we either remove them or ensure taht they get run? (this is what's causing OpenCI to fail)

Bump! Would really love to merge this PR!",like getting testing suite either remove ensure get run causing fail bump would really love merge,issue,positive,neutral,neutral,neutral,neutral,neutral
567961889,thank you for this PR - it's a really strong contribution which lots of folks will use!,thank really strong contribution lot use,issue,positive,positive,positive,positive,positive,positive
567958151,"Well it's better to have it this way, but currently it wouldn't change anything, since this test is currently skipped due to it failing during the Travis build because of memory issues. ",well better way currently would change anything since test currently due failing travis build memory,issue,negative,positive,positive,positive,positive,positive
567957762,Well done! Thank you for contributing documentation - we need more PRs like yours!,well done thank documentation need like,issue,positive,neutral,neutral,neutral,neutral,neutral
567957486,Closing due to inactivity. Please do resubmit!,due inactivity please resubmit,issue,negative,negative,negative,negative,negative,negative
567957284,"So one issue with this though is that when PyTorch releases a new version (without our heads up) ALL of our unit tests can start failing out of no-where. This can be very stressful for the dev teams, lol. 

Not 100% against it but the reason we fix to specific versions is that our hooking logic is prone to break version to version. We're quite tightly coupled to PyTorch even now.",one issue though new version without unit start failing stressful dev reason fix specific logic prone break version version quite tightly coupled even,issue,negative,negative,neutral,neutral,negative,negative
567867799,"even for 1.3.1, I am seeing 
```
No local packages or working download links found for torch==1.3.1
```",even seeing local working link found,issue,negative,neutral,neutral,neutral,neutral,neutral
567577044,"I can translate into French although not my native language (I'd be using nbTranslate).
DM me to collaborate.

I need some clarification for this task.

Are we:
1. Creating a hard copy of the tutorials folder translated into a specified language?
2. Updating the main installation file to require each user to install nbTranslate to self select language?
3. Both?

Thanks :)
",translate although native language collaborate need clarification task hard copy folder language main installation file require user install self select language thanks,issue,negative,positive,neutral,neutral,positive,positive
567269177,"There's a lot of machinery to set up to make serialization and deserialization work! This PR probably, very nearly, almost makes a single round-trip Python -> Protobuf -> Python test pass (for `AdditiveSharingTensor`.) I think the overall structure is now mostly complete, but it has some unresolved bugs and a lot more `bufferize` and `unbufferize` methods to write.

(I also haven't figured out a good way to select between msgpack and Protobuf yet. I think it can be done, but I'm still trying to get the basic functionality working right now.)",lot machinery set make serialization work probably nearly almost single python python test pas think overall structure mostly complete unresolved lot write also figured good way select yet think done still trying get basic functionality working right,issue,negative,positive,positive,positive,positive,positive
567236988,"It seems like this does not solve the problem with Travis, so this PR will be closed for now.",like solve problem travis closed,issue,negative,negative,neutral,neutral,negative,negative
567100396,"Working through this reminded me that one of the benefits of the strategy pattern is reducing the number of boolean flags. Thanks for the suggestion, @jacorbachosky!",working one strategy pattern reducing number thanks suggestion,issue,negative,positive,positive,positive,positive,positive
566741649,"**Approach**
I currently have implemented a fix where I add a parameter to check if a tensor had been unwrapped and is now getting rewrapped in the hook response (`rewrap=True` which by default will be False to not break code). 

It takes advantage of the [`build_rule()` in `build_wrap_response_from_function()`](https://github.com/OpenMined/PySyft/blob/8f7705fbba623827f1edaf5a2a351a973e2e001d/syft/generic/frameworks/hook/hook_args.py#L254) to check if the data type is a tensor (and not int, str etc). When it's building a wrap function, it checks if both `rule == 1` on the args passed and ` rewrap==True`, and if so, I set an attribute like `tensor.rewrap = True` which gets checked in the `wrap()` function as to whether to register.

**Passes tests but is slow?**
It currently passes 100% of tests BUT seems inefficient given the point of the build rule is to efficiently check if things need to be wrapped whereas this loops over the args.

**Other possible solutions**
Alternatively, I thought we could pass `wrap_args = {'register'=False}` for these tensors in the hook response, but it seems the [lambda for TorchTensor defined in `backward_func()` as](https://github.com/OpenMined/PySyft/blob/master/syft/frameworks/torch/hook/hook_args.py#L39-L46):
```
backward_func = {
    TorchTensor: lambda i: i.wrap(), # how to give the lambda arg register=False?
    torch.Tensor: lambda i: i.wrap(),
    torch.nn.Parameter: lambda i: torch.nn.Parameter(data=i),
    AutogradTensor: lambda i: AutogradTensor(data=i).on(i, wrap=False),
    LoggingTensor: lambda i: LoggingTensor().on(i, wrap=False),
    PaillierTensor: lambda i: PaillierTensor().on(i, wrap=False),
}
```
**Code changes**
Here is the code changes: 
https://github.com/linamnt/PySyft/commit/97a7a24b3c061c99a73482f6c6c9c3ab4cad3d42
Do I submit a PR so it can be reviewed formally? or wait til the best approach is figured out?",approach currently fix add parameter check tensor unwrapped getting hook response default false break code advantage check data type tensor building wrap function rule set attribute like true checked wrap function whether register slow currently inefficient given point build rule efficiently check need wrapped whereas possible alternatively thought could pas hook response lambda defined lambda give lambda lambda lambda lambda lambda lambda code code submit formally wait til best approach figured,issue,positive,positive,neutral,neutral,positive,positive
566736219,"I'm not entirely sure how to fix that, but I think ScriptModules get bundled into an ObjectWrapper when sent to another worker. The ScriptModule inside an ObjectWrapper should be accessible via `wrapper.obj`.",entirely sure fix think get sent another worker inside accessible via,issue,negative,positive,positive,positive,positive,positive
566649681,"It seems that NumPy has this use case covered and I overlooked the documentation. In the [subclassing doc](https://docs.scipy.org/doc/numpy/user/basics.subclassing.html) it is very well documented how to override the behaviour of ndarray and the defined subclass would allow to extend attributes dynamically. 

As explained in the previous comment, trying to extend numpy.ndarray directly will fail:
```
> import numpy
> numpy.ndarray.n = ""nice""

TypeError: can't set attributes of built-in/extension type 'numpy.ndarray'
```

However, subclassing numpy.ndarray will allow extending attributes dynamically. The follwing code doesn't give the TypeError:
```
import numpy

class B(numpy.ndarray):
  pass

B.n = ""nice""
```
 
Once the proper functions are overriden, the user should be able to use NumPy directly as the input of NumpyHook instead of the previous proposal of providing a wrapped NumPy library. So, the usage will be identical with the only difference that after hooking numpy, the arrays created by the library would be of type **B** instead of **ndarray**.",use case covered documentation doc well override behaviour defined subclass would allow extend dynamically previous comment trying extend directly fail import nice ca set type however allow extending dynamically code give import class pas nice proper user able use directly input instead previous proposal providing wrapped library usage identical difference library would type instead,issue,positive,positive,positive,positive,positive,positive
566583351,This is ready to merge. The change requested is done.,ready merge change done,issue,negative,positive,positive,positive,positive,positive
566479995,"As somewhat expected, I was a bit overconfident with my initial approach to the task, so I'm leaving here an explanation of the main problem to solve in order to integrate NumPy as a supported framework inside Syft.

From the user point of view, we expect the hooking process to look like the **PyTorch** hook:
```
import numpy as np
import syft as sy

hook = sy.NumpyHook(np)
```

The codebase already provides with an abstract class **FrameworkHook**. However, if we try to create directly a **NumpyHook(FrameworkHook)** following the approach of **TorchHook**, we find that the previous code returns a ```TypeError: can't set attributes of built-in/extension type 'numpy.ndarray'``` when trying to extend **numpy.ndarray** with something like ```self._hook_native_tensor(numpy.ndarray, NumpyTensor)```.

In this case, the first hurdle to solve is how to get around the fact that NumPy is not implemented in pure Python but Cython. Trying to [monkey patch](https://gist.github.com/alejandrosame/011a8abfd8e11719de72cb96e7df2d2f) NumPy directly is too unstable, the implementation started to fail without properly raising errors and  required duplication of code to deal with builtin classes.

Therefore, I'm now trying to provide from inside Syft a module that wraps around the necessary NumPy classes, which would behave like a pure Python module for the hooking process. This approach has the advantages of being more robust and able to efficiently reuse the scaffolding code provided by Syft, once properly implemented. In this case, the user would need to hook NumPy like:

```
import syft.<path_to_be_determined>.numpy as np
import syft as sy

hook = sy.NumpyHook(np)
```

If the user tries to hook the **numpy** directly, **Syft** should return an error to redirect the user to use the **wrapped NumPy** (e.g. ```ValueError: Please hook NumPy by importing syft.<path_to_be_determined>.numpy``` with example code). 

I'm still going slow with this task while I'm testing and learning the overall codebase for framework hooks so I'll soon push a WIP PR so anyone can also check the approach and provide feedback!",somewhat bit overconfident initial approach task leaving explanation main problem solve order integrate framework inside user point view expect process look like hook import import hook already abstract class however try create directly following approach find previous code ca set type trying extend something like case first hurdle solve get around fact pure python trying monkey patch directly unstable implementation fail without properly raising duplication code deal class therefore trying provide inside module around necessary class would behave like pure python module process approach robust able efficiently reuse scaffolding code provided properly case user would need hook like import import hook user hook directly return error redirect user use wrapped please hook example code still going slow task testing learning overall framework soon push anyone also check approach provide feedback,issue,positive,positive,neutral,neutral,positive,positive
566216341,"Tons of work left to do on this, but starting a PR so y'all can see what it looks like and provide feedback along the way.",work left starting see like provide feedback along way,issue,negative,neutral,neutral,neutral,neutral,neutral
566118564,"This seems good, but there's no diff...Maybe these changes already made it into master?",good maybe already made master,issue,negative,positive,positive,positive,positive,positive
566078991,"@LaRiffle @iamtrask @karlhigley 

Once this PR (https://github.com/OpenMined/PySyft/pull/2812) is merged, we can close this epic of an issue.  Nice work @vvmnnnkv!",close epic issue nice work,issue,negative,positive,positive,positive,positive,positive
565973995,"Hello, I am a native french speaker, I can take a look at it",hello native speaker take look,issue,negative,neutral,neutral,neutral,neutral,neutral
565900188,"> Hey - this looks good. @ricardopretelt and I decided he would do the odd numbers and I would do the even numbers so if you want to keep contributing maybe we can have a quick chat on Slack to reassign the tutorials evenly between us! :) Saludos!

Hola guys, thanks for replying
 
Sorry if I didn't follow the workflow, it's my first time contributing. 
I'd love to join the Slack and do more work. 
Also, I just saw the testing failed? How can I fix that?

",hey good decided would odd would even want keep maybe quick chat slack reassign evenly u thanks sorry follow first time love join slack work also saw testing fix,issue,positive,positive,positive,positive,positive,positive
565882790,Well done! Awesome translation @jefersonf! :rocket: ,well done awesome translation rocket,issue,positive,positive,positive,positive,positive,positive
565795164,"As nobody has picked this up yet, I'll put my hat in the ring. I'm not a native speaker, however, so I might be better placed reviewing other people's PRs",nobody picked yet put hat ring native speaker however might better people,issue,negative,positive,positive,positive,positive,positive
565622077,"> This PR is not fixing the problem yet. The use case mentioned above is still creating the optimizer with the plan parameters. When moving the optimizer creation after the plan was sent to Bob to use the PlanPointer this fails as optimizer cannot be created on TensorPointers :-/. I don‘t have a good solution to this yet (see slack).

Should we merge?",fixing problem yet use case still plan moving creation plan sent bob use good solution yet see slack merge,issue,positive,positive,positive,positive,positive,positive
565619976,"> @fdroessler @Yugandhartripathi Andrew merged the 1st Hindi notebook in `examples/tutorials/hindi/` folder. So should I change the path to `examples/tutorials/translations/hindi/` cause, it will change the previous dir structure,

Yes please.",st notebook folder change path cause change previous structure yes please,issue,positive,negative,negative,negative,negative,negative
565619661,Sadly a previous PR has created some merge conflicts. Can you attend?,sadly previous merge attend,issue,negative,negative,negative,negative,negative,negative
565488986,Kudos for updating the docs to help the next person. 👍 ,kudos help next person,issue,positive,neutral,neutral,neutral,neutral,neutral
565476498,"@fdroessler @Yugandhartripathi Andrew merged the 1st Hindi notebook in `examples/tutorials/hindi/` folder. So should I change the path to `examples/tutorials/translations/hindi/` cause, it will change the previous dir structure,",st notebook folder change path cause change previous structure,issue,negative,negative,negative,negative,negative,negative
565421980,"This one sealed the deal for me: https://medium.com/@gantlaborde/siraj-rival-no-thanks-fe23092ecd20?

I'm calling this approved and merged.",one sealed deal calling,issue,negative,neutral,neutral,neutral,neutral,neutral
565317222,Issue solved after moving jit function to top of the file,issue moving function top file,issue,negative,positive,positive,positive,positive,positive
565169519,Nice! I'll take Part 2 to get started.,nice take part get,issue,negative,positive,positive,positive,positive,positive
565139848,@darkmatter18 The notebook LGTM. If you can just move the hindi folder in `examples/tutorials/translations/hindi/` as suggested by @fdroessler it will be ready to merge.,notebook move folder ready merge,issue,negative,positive,positive,positive,positive,positive
565072355,"@jefersonf I am still on the first one. Let's use this checklist to mark the ones we have already started on so that other people coming in know which ones they can work on:

- [x] Part 01 - The Basic Tools of Private Deep Learning.ipynb
- [x] Part 02 - Intro to Federated Learning.ipynb
- [x] Part 03 - Advanced Remote Execution Tools.ipynb
- [x] Part 04 - Federated Learning via Trusted Aggregator.ipynb
- [x] Part 05 - Welcome to the Sandbox.ipynb
- [ ] Part 06 - Federated Learning on MNIST using a CNN.ipynb
- [ ] Part 07 - Federated Learning with Federated Dataset.ipynb
- [ ] Part 08 - Introduction to Plans.ipynb
- [ ] Part 08 bis - Introduction to Protocols.ipynb
- [ ] Part 09 - Intro to Encrypted Programs.ipynb
- [ ] Part 10 - Federated Learning with Secure Aggregation.ipynb
- [ ] Part 11 - Secure Deep Learning Classification.ipynb
- [ ] Part 12 - Train an Encrypted Neural Network on Encrypted Data.ipynb
- [ ] Part 12 bis - Encrypted Training on MNIST.ipynb
- [ ] Part 13a - Secure Classification with Syft Keras and TFE - Public Training.ipynb
- [ ] Part 13b - Secure Classification with Syft Keras and TFE - Secure Model Serving.ipynb
- [ ] Part 13c - Secure Classification with Syft Keras and TFE - Private Prediction Client.ipynb

Feel free to take any of these and check it.",still first one let use mark already people coming know work part basic private deep part part advanced remote execution part learning via part welcome part learning part learning part introduction part bi introduction part part learning secure part secure deep learning part train neural network part bi training part secure classification public part secure classification secure model part secure classification private prediction feel free take check,issue,positive,positive,positive,positive,positive,positive
565056854,"Fixed the Requested Change. @Yugandhartripathi Check it. @iamtrask Bugless, you can merge.",fixed change check merge,issue,negative,positive,neutral,neutral,positive,positive
565037144,"Sure!
`WARNING:tf_encrypted:Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/home/jpmc/anaconda3/envs/pysyft/lib/python3.7/site-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'
WARNING:tensorflow:From /home/jpmc/anaconda3/envs/pysyft/lib/python3.7/site-packages/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING:tensorflow:From /home/jpmc/anaconda3/envs/pysyft/lib/python3.7/site-packages/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

/home/jpmc/GraphSAGE-simple/graphsage/encoders.py:31: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.
  init.xavier_uniform(self.weight)
/home/jpmc/GraphSAGE-simple/graphsage/model.py:29: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.
  init.xavier_uniform(self.weight)
Traceback (most recent call last):
  File ""/home/jpmc/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py"", line 302, in handle_func_command
    cmd, args, kwargs, return_args_type=True
  File ""/home/jpmc/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook_args.py"", line 194, in unwrap_args_from_function
    new_args = args_hook_function(args)
  File ""/home/jpmc/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook_args.py"", line 380, in <lambda>
    return lambda x: f(lambdas, x)
  File ""/home/jpmc/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook_args.py"", line 568, in five_fold
    lambdas[1](args[1], **kwargs),
  File ""/home/jpmc/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook_args.py"", line 358, in <lambda>
    else lambda i: forward_func[type(i)](i)
  File ""/home/jpmc/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook_args.py"", line 58, in <lambda>
    else (_ for _ in ()).throw(PureFrameworkTensorFoundError),
  File ""/home/jpmc/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook_args.py"", line 58, in <genexpr>
    else (_ for _ in ()).throw(PureFrameworkTensorFoundError),
syft.exceptions.PureFrameworkTensorFoundError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/jpmc/anaconda3/envs/pysyft/lib/python3.7/runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""/home/jpmc/anaconda3/envs/pysyft/lib/python3.7/runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""/home/jpmc/GraphSAGE-simple/graphsage/model.py"", line 186, in <module>
    run_cora()
  File ""/home/jpmc/GraphSAGE-simple/graphsage/model.py"", line 102, in run_cora
    Variable(torch.LongTensor(labels[np.array(batch_nodes)])))
  File ""/home/jpmc/GraphSAGE-simple/graphsage/model.py"", line 37, in loss
    scores = self.forward(nodes)
  File ""/home/jpmc/GraphSAGE-simple/graphsage/model.py"", line 32, in forward
    embeds = self.enc(nodes)
  File ""/home/jpmc/anaconda3/envs/pysyft/lib/python3.7/site-packages/torch/nn/modules/module.py"", line 493, in __call__
    result = self.forward(*input, **kwargs)
  File ""/home/jpmc/GraphSAGE-simple/graphsage/encoders.py"", line 40, in forward
    self.num_sample)
  File ""/home/jpmc/GraphSAGE-simple/graphsage/aggregators.py"", line 61, in forward
    embed_matrix = self.features(torch.LongTensor(unique_nodes_list))
  File ""/home/jpmc/GraphSAGE-simple/graphsage/model.py"", line 81, in <lambda>
    agg2 = MeanAggregator(lambda nodes : enc1(nodes).t(), cuda=False)
  File ""/home/jpmc/anaconda3/envs/pysyft/lib/python3.7/site-packages/torch/nn/modules/module.py"", line 493, in __call__
    result = self.forward(*input, **kwargs)
  File ""/home/jpmc/GraphSAGE-simple/graphsage/encoders.py"", line 40, in forward
    self.num_sample)
  File ""/home/jpmc/GraphSAGE-simple/graphsage/aggregators.py"", line 61, in forward
    embed_matrix = self.features(torch.LongTensor(unique_nodes_list))
  File ""/home/jpmc/anaconda3/envs/pysyft/lib/python3.7/site-packages/torch/nn/modules/module.py"", line 493, in __call__
    result = self.forward(*input, **kwargs)
  File ""/home/jpmc/anaconda3/envs/pysyft/lib/python3.7/site-packages/torch/nn/modules/sparse.py"", line 117, in forward
    self.norm_type, self.scale_grad_by_freq, self.sparse)
  File ""/home/jpmc/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/frameworks/hook.py"", line 413, in overloaded_func
    response = handle_func_command(command)
  File ""/home/jpmc/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py"", line 338, in handle_func_command
    response = eval(cmd)(*args, **kwargs)
  File ""/home/jpmc/anaconda3/envs/pysyft/lib/python3.7/site-packages/torch/nn/functional.py"", line 1506, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
  File ""/home/jpmc/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/frameworks/hook.py"", line 413, in overloaded_func
    response = handle_func_command(command)
  File ""/home/jpmc/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py"", line 338, in handle_func_command
    response = eval(cmd)(*args, **kwargs)
RuntimeError: index out of range at /pytorch/aten/src/TH/generic/THTensorEvenMoreMath.cpp:193`",sure warning falling back insecure randomness since custom could found version fix custom missing file warning name please use instead warning name please use instead favor favor recent call last file line file line file line lambda return lambda file line file line lambda else lambda type file line lambda else file line else handling exception another exception recent call last file line file line code file line module file line variable file line loss file line forward file line result input file line forward file line forward file line lambda lambda file line result input file line forward file line forward file line result input file line forward file line response command file line response file line return weight input sparse file line response command file line response index range,issue,negative,negative,neutral,neutral,negative,negative
565015394,"@MarcioPorto Have you started this yet? If so, which notebooks haven't you touched on yet? This is something I would like to help.",yet touched yet something would like help,issue,positive,neutral,neutral,neutral,neutral,neutral
564964618,"@LaRiffle  Since it's just one line, I guess we can merge it?",since one line guess merge,issue,negative,neutral,neutral,neutral,neutral,neutral
564949091,"The backward function was not on the list of ambiguous methods so the vesrion of backward() that i needed was not cached. Fixed though by this commit; https://github.com/OpenMined/PySyft/pull/2799

",backward function list ambiguous backward fixed though commit,issue,negative,positive,neutral,neutral,positive,positive
564914771,"Hi All, Count me in for the translation efforts! I would be happy to help!",hi count translation would happy help,issue,positive,positive,positive,positive,positive,positive
564703319,"> Was really looking forward to this functionality. Thanks a lot. BTW you also included the data in your commit. Maybe remove it because it is quite large.
> 
> Also is the `Tutorial 1 - SplitNN Introduction.ipynb` the same as `SplitNN Introduction.ipynb`?

Thanks, I've been trying to get it to work for a while. It is the same, yeh. Just a different title to match in with the rest. Also, taken out the MNIST data, cheers!",really looking forward functionality thanks lot also included data commit maybe remove quite large also tutorial thanks trying get work different title match rest also taken data,issue,positive,positive,positive,positive,positive,positive
564688705,"Was really looking forward to this functionality. Thanks a lot. BTW you also included the data in your commit. Maybe remove it because it is quite large.

Also is the `Tutorial 1 - SplitNN Introduction.ipynb` the same as `SplitNN Introduction.ipynb`?",really looking forward functionality thanks lot also included data commit maybe remove quite large also tutorial,issue,positive,positive,positive,positive,positive,positive
564662479,"> Looks good! The only issue that I found is in the last section(Join the Community) which are same as last time(#2787) which is expected since you must have used the same translator so I suggest you copy the corrected version of that from your previous PR #2787 also refer to the comment I just dropped there and @fdroessler's request for changing the directory structure.

@Yugandhartripathi Hey, not able to find the issue here. Please mention the line, you can",good issue found last section join community last time since must used translator suggest copy corrected version previous also refer comment request directory structure hey able find issue please mention line,issue,positive,positive,positive,positive,positive,positive
564662254,"I have the 3rd tutorial translated to spanish, but we need the previous parts merged with the new updates to do a new PR avoiding version conflicts",tutorial need previous new new version,issue,negative,positive,neutral,neutral,positive,positive
564649728,"@Yugandhartripathi Hey, Thanks for point that. I also didn't noticed that. I am just thinking, how that's done. I will solve them in another pull request",hey thanks point also thinking done solve another pull request,issue,positive,positive,positive,positive,positive,positive
564645526,"@darkmatter18 Hey, I think there is a problem here I just noticed while reviewing #2811  that you fixed all issues here in commit a6610c0 but then just reverted back to the mistakes in the next one(f9c18d1). 
",hey think problem fixed commit back next one,issue,negative,positive,neutral,neutral,positive,positive
564632104,"Sound good! I moved the folder to the path you mentioned. 
",sound good folder path,issue,negative,positive,positive,positive,positive,positive
564594431,"> Hi, I have been working on the test suit for all notebooks. I have just updated it but the PR is not merged yet. However, I have now moved all the translations into a subfolder so maybe you could do the same?
> 
> As in move the español folder into a subfolder of tutorials:
> examples/tutorials/translations/español/
> 
> That way once both of our PRs are merged, yours should be automatically included in the test suit.

Done - translations are now in correct subdirectory.",hi working test suit yet however maybe could move folder way automatically included test suit done correct,issue,negative,neutral,neutral,neutral,neutral,neutral
564516757,"Sounds great!

Sent from my iPhone

> On 11 Dec 2019, at 12:02, froessler <notifications@github.com> wrote:
> 
> ﻿
> In order to avoid cluttering of the ""root"" tutorials directory my suggestion would be to have all translations in aexamples/tutorials/translations/ subdirectory. I have done this for some of the notebook tests already and suggested it in the PRs for Korean, Espanol and Romanian. If this is not opposed by the maintainers I would make this a more general suggestion?
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub, or unsubscribe.
",great sent wrote order avoid root directory suggestion would done notebook already opposed would make general suggestion reply directly view,issue,negative,positive,positive,positive,positive,positive
564509864,"In order to avoid cluttering of the ""root"" tutorials directory my suggestion would be to have all translations in a`examples/tutorials/translations/` subdirectory. I have done this for some of the notebook tests already and suggested it in the PRs for Korean, Espanol and Romanian. If this is not opposed by the maintainers I would make this a more general suggestion?",order avoid root directory suggestion would done notebook already opposed would make general suggestion,issue,negative,positive,neutral,neutral,positive,positive
564508428,"Hi, I have been working on the test suit for all notebooks. I have just updated it but the PR is not merged yet. However, I have now moved all the translations into a subfolder so maybe you could do the same?

As in move the español folder into a subfolder of tutorials:
examples/tutorials/translations/español/

That way once both of our PRs are merged, yours should be automatically included in the test suit.",hi working test suit yet however maybe could move folder way automatically included test suit,issue,negative,neutral,neutral,neutral,neutral,neutral
564383774,Hi @jvmancuso Is this issue still open? I would like to be assigned to this if no one is currently working on it.,hi issue still open would like assigned one currently working,issue,negative,neutral,neutral,neutral,neutral,neutral
564302757,Awesome thanks! Maybe later we can create a glossary of common phrases to ensure that our translation is consistent :),awesome thanks maybe later create glossary common ensure translation consistent,issue,positive,positive,positive,positive,positive,positive
564301068,"Thanks, the print statements made it easier to debug but makes sense to exclude them in general.",thanks print made easier sense exclude general,issue,positive,positive,positive,positive,positive,positive
564255510,"Now done with Part 01, working on Part 02
@seungjaeryanlee",done part working part,issue,negative,neutral,neutral,neutral,neutral,neutral
564255030,Hi @seungjaeryanlee ! I am working on the Part 02. I will leave comment on the issue #2794 if I start another one. Let’s leave comments there. ,hi working part leave comment issue start another one let leave,issue,negative,neutral,neutral,neutral,neutral,neutral
564245095,Hi @wonderit ! I am also thinking of translating notebooks to Korean. Which notebook are you working on? I want to make there is no duplicate work.,hi also thinking notebook working want make duplicate work,issue,negative,neutral,neutral,neutral,neutral,neutral
564239747,"Sorry for the late response. My opinion is that we should (in a way) unify some of the files.
One of the idea is to have a ```start_websocket_servers``` that could be parameterized and depending on one paramter start specific workers.
Eg:
   ```start_websocket_server --notebook mnist-parallel``` and this should start the set of workers for the ```MNIST-Parallel tutorial```.

What do you think @LaRiffle ?",sorry late response opinion way unify one idea could depending one start specific notebook start set tutorial think,issue,negative,negative,negative,negative,negative,negative
564233550,"@iamtrask I see some issues dedicated to each language. ([German](https://github.com/OpenMined/PySyft/issues/2781), [Japanese](https://github.com/OpenMined/PySyft/issues/2780), [Chinese](https://github.com/OpenMined/PySyft/issues/2778)) Can I translate the notebooks to a different language without an issue? I would like to translate the tutorials to Korean.

Also, can the work be divided into multiple PRs? (ex. per notebook)",see language german translate different language without issue would like translate also work divided multiple ex per notebook,issue,negative,neutral,neutral,neutral,neutral,neutral
564205127,This PR is not fixing the problem yet. The use case mentioned above is still creating the optimizer with the plan parameters. When moving the optimizer creation after the plan was sent to Bob to use the PlanPointer this fails as optimizer cannot be created on TensorPointers :-/. I don‘t have a good solution to this yet (see slack).,fixing problem yet use case still plan moving creation plan sent bob use good solution yet see slack,issue,positive,positive,positive,positive,positive,positive
564181323,I'll suggest moving all the translations of the notebooks into a separate folder to avoid a folder explosion in the tutorials root directory.,suggest moving separate folder avoid folder explosion root directory,issue,negative,neutral,neutral,neutral,neutral,neutral
564158907,"Hey guys, a few things to consider before we make pull requests -
(a) Since our work is divided among four, we all need to have a few set of rules that we stick to. For instance, 'name translations', like Bob or Alice if done in Part1, need to followed through till the end.
(b) Andrew has updated in the ticket before, regarding what all needs to be translated. Other than error messages and PySyft library imports, all other english terms should be translated. 
(c) In your notebooks, do not put yourself as 'translators'. We are editors since we are using a software for translation, and just overlooking edits if needed.

Would a sync up on our methods and progress be preferable to everyone?",hey consider make pull since work divided among four need set stick instance like bob done part need till end ticket regarding need error library put since translation would sync progress preferable everyone,issue,negative,neutral,neutral,neutral,neutral,neutral
563472187,"Yes - I followed the instructions outlined [here](https://github.com/OpenMined/PySyft/blob/master/CONTRIBUTING.md). Specifically, it failed during the [installation](https://github.com/OpenMined/PySyft/blob/master/CONTRIBUTING.md#installing-pysyft-after-cloning-repository). This was the outcome of running `python setup.py test` locally as indicated [here](https://github.com/OpenMined/PySyft/blob/master/INSTALLATION.md#6-test-your-installation). ",yes outlined specifically installation outcome running python test locally,issue,negative,neutral,neutral,neutral,neutral,neutral
563462069,"> Hey, I found that the following tests are failing. I think it might have to do with this PR.
> 
> ```python
> test/notebooks/test_notebooks.py::test_notebooks_basic FAILED
> 
> test/notebooks/test_notebooks.py::test_notebooks_advanced FAILED
> 
> test/notebooks/test_notebooks.py::test_fl_sms FAILED
> ```
> 
> Apologies in advance if this due to my specific installation, but these are the only failing tests so thought it might be useful to comment on here.

Could you be a bit more specific? Where are they failing, in a PR or just locally?",hey found following failing think might python advance due specific installation failing thought might useful comment could bit specific failing locally,issue,negative,positive,neutral,neutral,positive,positive
563401992,"Hey, I found that the following tests are failing. I think it might have to do with this PR.
```python
test/notebooks/test_notebooks.py::test_notebooks_basic FAILED

test/notebooks/test_notebooks.py::test_notebooks_advanced FAILED

test/notebooks/test_notebooks.py::test_fl_sms FAILED
```
Apologies in advance if this due to my specific installation, but these are the only failing tests so thought it might be useful to comment on here. ",hey found following failing think might python advance due specific installation failing thought might useful comment,issue,negative,positive,neutral,neutral,positive,positive
563325018,Thanks @iamtrask and @robert-wagner! I've added myself as an translator. And thank you @ricardopretelt for the heads-up. I've deleted that paragraph. Should be fine now.,thanks added translator thank paragraph fine,issue,positive,positive,positive,positive,positive,positive
563324932,"We should allow autograd tensor to be sendable across the wire, but we should serialize the functions using a string version of them (with specific ones whitelisted) instead of serializaing any function at all.

CC: @karlhigley this is related to what you were talking about.",allow tensor sendable across wire serialize string version specific instead function related talking,issue,negative,neutral,neutral,neutral,neutral,neutral
563314894,"@PlamenHristov and @abogaziah, I 100% support porting python-paillier to PyTorch. there will be challenges (primarily with representing large numbrees, which in theory CRTTensor can do but it will be tricky). The best part about doing it this way is that it means your tensor will automatically work in JS and iOS/Android by default.

Also, the author of python-paillier is a great guy and is often around the project (@hardbyte). He may be willing to consult.

Also, if you're no yet a member of a development team, you should 100% apply to one with this project. This would help provide you support as you go from the broader crypto/PySyft community here. ",support primarily large theory tricky best part way tensor automatically work default also author great guy often around project may willing consult also yet member development team apply one project would help provide support go community,issue,positive,positive,positive,positive,positive,positive
563304037,"> Feel free to add your name as having translated this

100% agree. Will merge once you add yourself for credit :) ",feel free add name agree merge add credit,issue,positive,positive,positive,positive,positive,positive
563254027,Feel free to add your name as having translated this,feel free add name,issue,positive,positive,positive,positive,positive,positive
563154401,"Hi @fdroessler !

Yes, I already started working on it. Hopefully, I'll soon send a PR with the first couple of hooked functions (I'm giving priority to the ones used on tutorials right now).",hi yes already working hopefully soon send first couple hooked giving priority used right,issue,positive,positive,positive,positive,positive,positive
563104715,"@abdulbasitds is working 👍 
replace: ""from syft.frameworks.torch.fl import utils""
with
""from syft.frameworks.torch.federated import utils""",working replace import import,issue,negative,neutral,neutral,neutral,neutral,neutral
563091431,"Here is my output:

pi@rasp-m:~ $ python3
Python 3.7.3 (default, Apr  3 2019, 05:39:12)
[GCC 8.2.0] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import torch
>>> print(torch.__version__)
1.3.0a0+de394b6
>>> import syft as sy
>>> print(sy.__version__)
0.2.0a2
>>>",output pi python python default type help copyright license information import torch print import print,issue,negative,neutral,neutral,neutral,neutral,neutral
563046140,"Hi,
the reason for your error is that we currently have a bug with serializing AutogradTensor, I just filled an Issue about this.
So here is a version of your code without the .send() which works. Note that the kay difference is that now you as a local worker will do the sharing while in your code it was workers[0]:
```python
workers = [alice, bob]
x = th.tensor([[0,0], [0,1], [1,0], [1,1]], dtype=th.float)
y = th.tensor([0,0,1,1], dtype=th.float).view(-1,1)
model = th.nn.Linear(2,1)

x_enc = x.fix_precision().share(*workers, crypto_provider=crypto_provider, requires_grad=True)
y_enc = y.fix_precision().share(*workers, crypto_provider=crypto_provider, requires_grad=True)
model_enc = model.fix_precision().share(*workers, crypto_provider=crypto_provider, requires_grad=True)

#x_enc = x_enc.send(workers[0])
#y_enc = y_enc.send(workers[0])
#model_enc = model_enc.send(workers[0])

opt = th.optim.SGD(params=model_enc.parameters(), lr=0.1)
opt = opt.fix_precision()

opt.zero_grad()
y_pred_enc = model_enc(x_enc)
y_pred_enc
y_pred = y_pred_enc.get()
```
I'll close this issue as another one targets for specifically the error mentioned",hi reason error currently bug filled issue version code without work note kay difference local worker code python bob model opt opt close issue another one specifically error,issue,negative,positive,positive,positive,positive,positive
563043188,"Hey thanks for reporting,
Would you mind adding the stacktrace to this issue?
This might help us to provide help without having to launch the whole project :)",hey thanks would mind issue might help u provide help without launch whole project,issue,positive,positive,positive,positive,positive,positive
563042124,Which version of syft are you using? In the latest one it should be working... Tell me if it doesn't,version latest one working tell,issue,negative,positive,positive,positive,positive,positive
563013322,"@iamtrask please can you clarify the task here. 

The nbTranslate extension has to be installed by the user. I tried it using Chrome and Firefox. I can view the tutorials several languages and switch between them.

Are we trying to generate a .pot file for each tutorial, so that .po file can be created as needed for each language per tutorial?",please clarify task extension user tried chrome view several switch trying generate file tutorial file language per tutorial,issue,negative,neutral,neutral,neutral,neutral,neutral
563003538,you need to import like  `from syft.frameworks.torch.federated import utils`,need import like import,issue,negative,neutral,neutral,neutral,neutral,neutral
562986525,"@ricardopretelt 
I opened the issue but I couldn't add the labels you mentioned. Since I am not a contributor to this project, I think I don't have the permission to add labels. ",issue could add since contributor project think permission add,issue,negative,neutral,neutral,neutral,neutral,neutral
562959584,"These were lines of code converted to torchscript (e.g. via @torch.jit.script or torch.jit.ScriptModule). They are not executed, so just skipped them from report with `pragma: no cover` (I've noticed similar thing is done in `test/test_serde.py`)",code converted via executed report cover similar thing done,issue,negative,neutral,neutral,neutral,neutral,neutral
562884871,"@wonderit I think that anyone can open the issue, just for convenience use the same format as the others and the labels translation, good first issue and feature ",think anyone open issue convenience use format translation good first issue feature,issue,negative,positive,positive,positive,positive,positive
562879764,@noumanriazkhan would you mind to attach / upload to colab your minimum reproducible example?,would mind attach minimum reproducible example,issue,negative,neutral,neutral,neutral,neutral,neutral
562878895,"> I just have a question related to the modifications of the tutorials: they are many of them, but most of them are output deletion for example, are they needed?

Sometimes, such output allows users to read notebooks without downloading. By stripping output we might loose ease of read. What do you think?",question related many output deletion example sometimes output read without stripping output might loose ease read think,issue,negative,positive,positive,positive,positive,positive
562878457,"Excellent!

On Sat, Dec 7, 2019 at 6:48 PM arturomf94 <notifications@github.com> wrote:

> Thanks @iamtrask <https://github.com/iamtrask>. Indeed, we've been
> coordinating in order to avoid double work :)
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/2775?email_source=notifications&email_token=ABBAZESAN2YVMWXUOTQXU2TQXPVXNA5CNFSM4JVJLTGKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEGGM74A#issuecomment-562876400>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ABBAZETTA5PKQMZIX42HCGTQXPVXNANCNFSM4JVJLTGA>
> .
>
",excellent sat wrote thanks indeed order avoid double work reply directly view,issue,positive,positive,positive,positive,positive,positive
562878159,Looks like there are lines in test_serde_full.py which aren't getting run - this is causing Travis to fail.,like getting run causing travis fail,issue,negative,negative,negative,negative,negative,negative
562876493,"> I think we're about to merge it #2755

This is great. In this case, I would rather allocate my effort reviewing / improving existing one. Thanks for quick reply! ",think merge great case would rather allocate effort improving one thanks quick reply,issue,positive,positive,positive,positive,positive,positive
562876400,"Thanks @iamtrask. Indeed, we've been coordinating in order to avoid double work :)",thanks indeed order avoid double work,issue,negative,positive,neutral,neutral,positive,positive
562876324,But welcome back @lc0 !!! Great to see you!,welcome back great see,issue,positive,positive,positive,positive,positive,positive
562871470,@iamtrask would you mind to assign me to this one. I am back and happy to bring it to reality :),would mind assign one back happy bring reality,issue,positive,positive,positive,positive,positive,positive
562851664,"Tested with:
```
@func2plan(args_shape=[(1,)])
def plan_double_abs(x):
    x = x + x
    x = torch.abs(x)
    return x

@func2plan()
def plan_test(x):
    f = plan_double_abs(x)
    return f*2
```
It looks like if the ```plan_double_abs``` is built, then we will call the ```plan_double_abs``` in  ```plan_test``` it would go through the ```plan_double_abs``` (which is a ""plan class"").

Added a ```building``` context at the ```owner (worker)``` level.


",tested return return like built call would go plan class added building context owner worker level,issue,negative,neutral,neutral,neutral,neutral,neutral
562849681,Not necessarily. I prefer it this (cleaned) to avoid major merge conflicts when content changes but am happy to revert these changes if you prefer the content to be included.,necessarily prefer avoid major merge content happy revert prefer content included,issue,negative,positive,positive,positive,positive,positive
562837890,"I just have a question related to the modifications of the tutorials: they are many of them, but most of them are output deletion for example, are they needed?",question related many output deletion example,issue,negative,positive,positive,positive,positive,positive
562835756,"Amazing! 🕺🏻
Thanks for this finding :)
Ok what happen now if you supply args_shape in the plan definition?
Example:
``` 
@sy.func2plan(args_shape=[(1,)])
    def plan_abs(data):
        return data.abs()
```
",amazing thanks finding happen supply plan definition example data return,issue,positive,positive,positive,positive,positive,positive
562821311,@Yugandhartripathi can you please review my Pull request #2787 ,please review pull request,issue,negative,neutral,neutral,neutral,neutral,neutral
562689255,"Hey everyone! I am on this task as well. If you are all ok, I can take up 5, 6, 13b and 13c. Work equally divided among all. What say?  ",hey everyone task well take work equally divided among say,issue,negative,neutral,neutral,neutral,neutral,neutral
562651984,"@iamtrask 
Could you please open an issue for Korean also? As a fan of this project, I would like to participate in this issue.",could please open issue also fan project would like participate issue,issue,positive,neutral,neutral,neutral,neutral,neutral
562643943,"As, i started from the beginning, I will go for 2,3,4,5,6. 1 already done",beginning go already done,issue,negative,neutral,neutral,neutral,neutral,neutral
562636406,@Yugandhartripathi @kaustubh-seachange  Love to split the work. Please tell me which notebooks you guys want to work on? ,love split work please tell want work,issue,positive,positive,positive,positive,positive,positive
562625161,"@kaustubh-seachange @darkmatter18 wanna split the work and get it done faster together?
if yes: I am using nbTranslate followed by proof reading then some manual editing and corrections.  What about you? Would love to know if there's a better way to do it.",wan na split work get done faster together yes proof reading manual would love know better way,issue,positive,positive,positive,positive,positive,positive
562552974,I'll open a couple of issues with reference to missing tests or notebooks that need fixing.,open couple reference missing need fixing,issue,negative,negative,neutral,neutral,negative,negative
562226031,"@iamtrask @midokura-silvia There might be something strange going on. Not sure how it is supposed to be but I think because the Virtualworkers in the hook stay for a test session it means I can't create new Websocketworkers with the same name. I am now removing them from the hook before adding new ones. Will see if that creates issues down the line. Tried to use a different hook but I think it will not create a new one but just provide me with the existing hook? 

Edit:
Or I should just understand pytest autouse=True ...
",might something strange going sure supposed think hook stay test session ca create new name removing hook new see line tried use different hook think create new one provide hook edit understand,issue,positive,positive,positive,positive,positive,positive
562197323,"> You are still running the pysyft code before the gpu commit. That's why this error appears.

Yes I have done `git fetch`, `git checkout master` and `git reset --hard origin`
And my latest head is at 

```
 g reset --hard origin
HEAD is now at d8ede46 Add youtube link to README (#2761)
```
Please correct me if I have done something wrong since it is my first time open source contribution, thank you so much!",still running code commit error yes done git fetch git master git reset hard origin latest head reset hard origin head add link please correct done something wrong since first time open source contribution thank much,issue,negative,negative,neutral,neutral,negative,negative
562133079,Make sure to collaborate with these folks too - submit one tutorial at a time via pull reequesets to minimize the chance of double work. https://github.com/OpenMined/PySyft/issues/2775,make sure collaborate submit one tutorial time via pull minimize chance double work,issue,positive,positive,positive,positive,positive,positive
562029351,"You are still running the pysyft code before the gpu commit. That's why this error appears.

",still running code commit error,issue,negative,neutral,neutral,neutral,neutral,neutral
561913414,"@LaRiffle tried the following code - in the ```Plans``` notebook:

```
@func2plan()
def plan_double_abs(x):
    x = x + x
    x = torch.abs(x)
    return x

@func2plan()
def plan_test(x):
    f = plan_double_abs(x)
    return f*2
```
and from what I checked,  if I run ```plan_test.build(torch.tensor([1., -2.]))``` it will simply call the build method for the ```plan_test``` (will not call ```build``` for ```plan_double_abs``` even thought it is called inside ```plan_test```)
and after that I ran:
```
pointer_plan = plan_test.send(device_1) # device_1 is a VirtualWorker
pointer_to_data = device_1.search('input_data')[0]
pointer_to_result = pointer_plan(pointer_to_data)
```

Also, added a print message in the ```execute_commands``` methpd from the ```Plan``` class:
```
for message in self.procedure.operations:
    print(""message "", message)
    bin_message = sy.serde.serialize(message, simplified=True)
    _ = self.owner.recv_msg(bin_message)
```
The messages generated are:
```
message  (33, ((6, ((5, (b'__add__',)), (25, (98142542040, 78527494689, b'device_1', None, (11, (2,)), True)), (6, ((25, (98142542040, 78527494689, b'device_1', None, (11, (2,)), True)),)), (0, ()))), (70741324193,)))
message  (33, ((6, ((5, (b'torch.abs',)), None, (6, ((25, (25994186521, 70741324193, b'device_1', None, None, True)),)), (0, ()))), (91046882485,)))
message  (33, ((6, ((5, (b'__mul__',)), (25, (14581124267, 91046882485, b'device_1', None, None, True)), (6, (2,)), (0, ()))), (82141830512,)))
```
From what it seems ```__add__``` and ```torch.abs``` are from ```plan_double_abs``` and the ```__mul__``` from the ```plan_test``` (from the return).

What I think is happening is that the ```plan_double_abs``` plan is not building the plan inside.
But also, I might be wrong...
",tried following code notebook return return checked run simply call build method call build even thought inside ran also added print message plan class message print message message message message none true none true message none none none true message none none true return think happening plan building plan inside also might wrong,issue,negative,positive,positive,positive,positive,positive
561896211,"Fixed old problems, but now need to add new PrivateTensor and PromiseTensor to pass tests 😅 ",fixed old need add new pas,issue,negative,positive,positive,positive,positive,positive
561879009,"I can start right now with the translation to spanish as it is my native languange, if anyone else wants to contribute can contact me",start right translation native anyone else contribute contact,issue,negative,positive,positive,positive,positive,positive
561862807,Great I'll clean this up tomorrow and finish it.,great clean tomorrow finish,issue,positive,positive,positive,positive,positive,positive
561726695,"I'm having the same issue. I know this is a bit old but have you found a solution for this? (Not necessarily using PySyft, but on any Federated Learning solution)",issue know bit old found solution necessarily learning solution,issue,positive,positive,neutral,neutral,positive,positive
561694380,"I am now at #2761, and the rest configuration has not been changed or reconfigured.
But the issue remains, with the png attached, thanks.

![image](https://user-images.githubusercontent.com/22470089/70155435-34f8c400-16ed-11ea-8d7b-f6bac77d25c0.png)

![image](https://user-images.githubusercontent.com/22470089/70155476-4a6dee00-16ed-11ea-9069-186b2cd415a3.png)
",rest configuration issue remains attached thanks image image,issue,negative,positive,positive,positive,positive,positive
561689574,"> No problem, but should I use
> `pip install syft --upgrade`
> Or `git pull`, I am afraid that the latter method will have some conflict since I have write some notes for my school study in it.
> Thank you so much !

If you have local commits on master you can do the following to have a clean state:
First create a new local branch to store you modifications:
`git checkout -b dev-alfons`
`git stash` or `git commit` (stash or commit your local changes (without commit) to the new branch)
Then get the newest state of master:
`git fetch`
`git checkout master`
`git reset --hard origin`
Then you will have a clean state of master. You can then either cherry-pick your commit or copy-paste the modified file.

",problem use pip install upgrade git pull afraid latter method conflict since write school study thank much local master following clean state first create new local branch store git git stash git commit stash commit local without commit new branch get state master git fetch git master git reset hard origin clean state master either commit file,issue,positive,positive,neutral,neutral,positive,positive
561683229,"> Could you please check, whether we can get rid of
> 
> ```
> torch.set_default_tensor_type(torch.cuda.FloatTensor)
> ```
> 
> with the newest content of master?

No problem, but should I use
`pip install syft --upgrade`
Or `git pull`, I am afraid that the latter method will have some conflict since I have write some notes for my school study in it.
Thank you so much !",could please check whether get rid content master problem use pip install upgrade git pull afraid latter method conflict since write school study thank much,issue,negative,negative,negative,negative,negative,negative
561669528,Feel free to submit notebooks in Pull Requests as you go along :),feel free submit pull go along,issue,positive,positive,positive,positive,positive,positive
561600925,"@fdroessler 
I have the impression that papermill is more powerful than treon, so let's go ahead with papermill.",impression powerful let go ahead,issue,positive,positive,positive,positive,positive,positive
561525049,"Hi there!

@iamtrask reported in the Slack group that the issue is due to the import of NumPy to execute log2 like shown in https://github.com/OpenMined/PySyft/blob/master/syft/frameworks/torch/tensors/interpreters/native.py#L741. 

Since NumPy can only run locally, it cannot be used for Federated Learning yet. The solutions for this error would be to either:
* Hook NumPy as another PySyft framework.
* Implement log2 in PyTorch.

Cheers!",hi slack group issue due import execute log like shown since run locally used learning yet error would either hook another framework implement log,issue,negative,negative,neutral,neutral,negative,negative
561322845,"Let's do that.  I'm sold.

On Tue, Dec 3, 2019 at 10:39 AM Vova Manannikov <notifications@github.com>
wrote:

> Do you have an opinion on wrapping vs non-wrapping?
>
> In point 2, I think it OK to leave dict as is because it's kind of
> ""primitive"" type in serde, so might be fine to do such exclusion for the
> sake of smaller output.
> As for Procedure, it's better to simplify that tuple.
> In point 3, I would make everything (<CODE>, (<DATA>)), so you can always
> unwrap a value in universal way: as its code and list of parameters, even
> when it's 1 param (because who knows if this will change in the future).
>
> what are the next steps so we can begin fixing the issues
> Need to figure out why PR fails in Travis :) I can't reproduce that
> locally in Ubuntu VM. Then we can address listed issues: add simplification
> where it's missing, etc.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/2654?email_source=notifications&email_token=AAJ44CTJ3VYM3RS4E46LE53QWYZM5A5CNFSM4I7D6IHKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEFY5JMA#issuecomment-561108144>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AAJ44CVW2I4SQVHEA2LQW3DQWYZM5ANCNFSM4I7D6IHA>
> .
>
",let sold tue wrote opinion wrapping point think leave kind primitive type might fine exclusion sake smaller output procedure better simplify point would make everything code data always unwrap value universal way code list even param change future next begin fixing need figure travis ca reproduce locally address listed add simplification missing reply directly view,issue,positive,positive,positive,positive,positive,positive
561145379,"I had the same problem and have solved it.

This problem seems only occur on Windows.

Reason: on windows, pip cannot find a version for torch==1.3,  but can find a version for torch==1.3.x (like torch 1.3.1). 
```powershell
(dl) PS C:\Users\Chenghui_S> pip install torch==1.3
Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple
Collecting torch==1.3
ERROR: Could not find a version that satisfies the requirement torch==1.3 (from versions: 0.1.2, 0.1.2.post1, 0.1.2.post2)
ERROR: No matching distribution found for torch==1.3
(dl) PS C:\Users\Chenghui_S> pip install torch==1.3.1
Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple
Requirement already satisfied: torch==1.3.1 in c:\programdata\miniconda3\envs\dl\lib\site-packages (1.3.1)
Requirement already satisfied: numpy in c:\programdata\miniconda3\envs\dl\lib\site-packages (from torch==1.3.1) (1.17.4)
```

So if you change the requirement from 1.3 to 1.3.x (in your computer), you can solve this.

Details:
1. download source code
```powershell
git clone -b dev --single-branch https://github.com/openmined/PySyft.git
```
2. change the requirement file in path:     `./PySyft/pip-dep/requirements.txt`
![批注 2019-12-03 201433](https://user-images.githubusercontent.com/22197327/70050307-96476700-1609-11ea-95cc-066abfc8e728.png)
3. install
```powershell
cd PySyft
python setup.py install
```
4. in this step, if you occurs error about: `Microsoft Visual C++ 14.0 is required`, you can download Visual Studio 2019.  See: https://stackoverflow.com/questions/29846087/microsoft-visual-c-14-0-is-required-unable-to-find-vcvarsall-bat",problem problem occur reason pip find version find version like torch pip install looking error could find version requirement post post error matching distribution found pip install looking requirement already satisfied requirement already satisfied change requirement computer solve source code git clone dev change requirement file path install python install step error visual visual studio see,issue,negative,positive,positive,positive,positive,positive
561108144,"> Do you have an opinion on wrapping vs non-wrapping?

In point 2, I think it OK to leave dict as is because it's kind of ""primitive"" type in serde, so might be fine to do such exclusion for the sake of smaller output.
As for Procedure, it's better to simplify that tuple.
In point 3, I would make everything `(<CODE>, (<DATA>))`, so you can always unwrap a value in universal way: as its code and list of parameters, even when it's 1 param (because who knows if this will change in the future).

> what are the next steps so we can begin fixing the issues

Need to figure out why PR fails in Travis :) I can't reproduce that locally in Ubuntu VM. Then we can address listed issues: add simplification where it's missing, etc.",opinion wrapping point think leave kind primitive type might fine exclusion sake smaller output procedure better simplify point would make everything code data always unwrap value universal way code list even param change future next begin fixing need figure travis ca reproduce locally address listed add simplification missing,issue,positive,positive,positive,positive,positive,positive
560563636,Worth re-iterating that this is a mammoth task and that Jason is an absolute saint for all the work he's done on it. <3,worth mammoth task absolute saint work done,issue,negative,positive,positive,positive,positive,positive
560492063,"I'll second the vote for making serde as concise as possible. On the AndroidWorker side, the parsing happens as much based on the position of particular elements as based on the type codes (which are sometimes skipped over entirely.)",second vote making concise possible side much based position particular based type sometimes entirely,issue,negative,positive,neutral,neutral,positive,positive
560364775,"Indeed! Quite an epic PR! Well done sir!

Looks like there are two Travis errors for now. One is a failing unit test for ""serde coverage"" and another is a failing style test because some part of our unit tests aren't getting run (likely because it . fails before it finishes)",indeed quite epic well done sir like two travis one failing unit test coverage another failing style test part unit getting run likely,issue,negative,positive,neutral,neutral,positive,positive
560286626,"I am working on it.

On Sun, Dec 1, 2019 at 11:05 PM NateSolon <notifications@github.com> wrote:

> Hey @refactormyself <https://github.com/refactormyself> are you still
> working on this? I think this would be a great project for where I'm at
> right now - maybe we could both take a stab at it and compare?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/2734?email_source=notifications&email_token=AEJIRHMOGSEQ7SYJC365YGDQWQYL5A5CNFSM4JNYAFC2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEFRXEPA#issuecomment-560165436>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AEJIRHLNLOQ5IK43DJWZPG3QWQYL5ANCNFSM4JNYAFCQ>
> .
>
",working sun wrote hey still working think would great project right maybe could take stab compare reply directly view,issue,negative,positive,positive,positive,positive,positive
560165671,@LaRiffle does the model need to be trained with federated learning or can I just train a model with vanilla PyTorch and then test the different precisions?,model need trained learning train model vanilla test different,issue,negative,neutral,neutral,neutral,neutral,neutral
560165436,Hey @refactormyself are you still working on this? I think this would be a great project for where I'm at right now - maybe we could both take a stab at it and compare?,hey still working think would great project right maybe could take stab compare,issue,negative,positive,positive,positive,positive,positive
560088496,"Amazing work @vvmnnnkv!  Do you have an opinion on wrapping vs non-wrapping?  Personally I'd love to see Serde be as concise as possible, with no wrapping.  What are your thoughts?

Likewise, what are the next steps so we can begin fixing the issues you've uncovered in your testing?",amazing work opinion wrapping personally love see concise possible wrapping likewise next begin fixing uncovered testing,issue,positive,positive,positive,positive,positive,positive
560087351,"Wow.  I'm so proud of you @vvmnnnkv.  This is one hell of a PR, nicely done.  Let's get this reviewed and merged!",wow one hell nicely done let get,issue,negative,positive,positive,positive,positive,positive
560021781,"#2762 reveals some inconsistencies in serde, I think these can be grouped as follows:
1. No simplification of values. In some cases strings, lists, tuples are just not simplified. You can find these by searching ""not simplified"" in [test_serde_full.py](https://github.com/OpenMined/PySyft/blob/6a23387ca648949635007a603fa6f1606157b380/test/test_serde_full.py)
2. Wrapping in a non-simplified tuple. This is actually same as 1, but I wanted to mention this separately as it's somewhat semantically different from just missing simplification for a value, and is also referenced above as ""magic parens"". We can see this in `dict` type, e.g. simplifying `{1: 2, 3: 4}` will return: `(0, ((1, 2),(3, 4)))`. More consistent result would be simplifying each of those key/value tuples: `(0, ((6, (1, 2)), (6, (3, 4))))`. Also, in Procedure: the tuple that contains simplified operations is not itself simplified.
3. It's not always `(<CODE>, (<DATA>))`. Sometimes it's `(<CODE>, <DATA>)`. Search for ""no wrapping"" in test_serde_full.py to see examples, e.g. compare `str` (`(5, (b""abc"",))`) with `Ellipsis` (`(7, b"""")`).

I haven't tried to fix any of these inconsistencies before discussing here.

Also, I haven't analyzed List vs Tuple (mentioned by @cereallarceny) yet, but this should be simpler having simplification examples for all types in one place.",think grouped simplification simplified find searching simplified wrapping actually mention separately somewhat semantically different missing simplification value also magic see type return consistent result would also procedure simplified simplified always code data sometimes code data search wrapping see compare ellipsis tried fix also list yet simpler simplification one place,issue,negative,positive,positive,positive,positive,positive
559807186,Do remember to import torch before you import syft.,remember import torch import,issue,negative,neutral,neutral,neutral,neutral,neutral
559790691,"Thank you for answering my question, I will try as you suggest.

At 2019-11-27 22:37:11, ""Indrajit Sen Gupta"" <notifications@github.com> wrote:


I was finally able to solve the problem @chunrongH , @LaRiffle , @haikuoY , @hasnain2808 after a lot of trial and error. Here are the sequence of steps that I had followed in Windows 10.

Installed Build Tools for Visual Studio 2019 from here
Created a new environment using conda conda create --name syft python=3.7
Installed the following packages from conda-forge:
conda install -c conda-forge websocket-client
conda install -c conda-forge websockets
conda install -c conda-forge lz4
conda install -c conda-forge tblib
conda install -c conda-forge msgpack-python
conda install -c conda-forge jupyterlab
conda install pytorch torchvision cpuonly -c pytorch

Went to proto repository here and downloaded their repo and installed with:
python setup.py build
python setup.py install

Downloaded the syft repo here and downloaded their repo and installed with:
python setup.py build
python setup.py install


The above process installed everything but ended with an error:

Searching for torch==1.3
Reading https://pypi.org/simple/torch/
No local packages or working download links found for torch==1.3
error: Could not find suitable distribution for Requirement.parse('torch==1.3')

Ignore the above error and start python. I was able to run import syft as sy.

—
You are receiving this because you were mentioned.
Reply to this email directly, view it on GitHub, or unsubscribe.",thank question try suggest sen wrote finally able solve problem lot trial error sequence build visual studio new environment create name following install install install install install install install went proto repository python build python install python build python install process everything ended error searching reading local working link found error could find suitable distribution ignore error start python able run import reply directly view,issue,negative,positive,positive,positive,positive,positive
559151509,"Today I analyzed the issue and here are my observations,

1. I have compared all the  `run_websocket_server.py` in a different directory, they don't contain the same code. 

2. I have also analyzed codebase and come to know that we also have one another file named `start_websocket_servers.py` file which is using `run_websocket_server.py` in the same directories in the tutorials.

I think that suggested changes will not be valid unless we make generalized `start_websocket_servers.py`  and  `run_websocket_server.py` files to solve this issue

@LaRiffle  shall we do it or keep it as it is right now?





",today issue different directory contain code also come know also one another file file think valid unless make generalized solve issue shall keep right,issue,negative,positive,positive,positive,positive,positive
559113445,"I was finally able to solve the problem @chunrongH , @LaRiffle , @haikuoY , @hasnain2808 after a lot of trial and error. Here are the sequence of steps that I had followed in Windows 10.

1.  Installed Build Tools for Visual Studio 2019 from [here](https://visualstudio.microsoft.com/downloads/#build-tools-for-visual-studio-2019)
2. Created a new environment using conda `conda create --name syft python=3.7`
3. Installed the following packages from conda-forge:
```
conda install -c conda-forge websocket-client
conda install -c conda-forge websockets
conda install -c conda-forge lz4
conda install -c conda-forge tblib
conda install -c conda-forge msgpack-python
conda install -c conda-forge jupyterlab
conda install pytorch torchvision cpuonly -c pytorch
```
4. Went to proto repository [here](https://github.com/OpenMined/proto) and downloaded their repo and installed with:
```
python setup.py build
python setup.py install
```
5. Downloaded the syft repo [here](https://github.com/OpenMined/PySyft) and downloaded their repo and installed with:
```
python setup.py build
python setup.py install
```
The above process installed everything but ended with an error:
```
Searching for torch==1.3
Reading https://pypi.org/simple/torch/
No local packages or working download links found for torch==1.3
error: Could not find suitable distribution for Requirement.parse('torch==1.3')
```
6. Ignore the above error and start python. I was able to run `import syft as sy`.",finally able solve problem lot trial error sequence build visual studio new environment create name following install install install install install install install went proto repository python build python install python build python install process everything ended error searching reading local working link found error could find suitable distribution ignore error start python able run import,issue,negative,positive,positive,positive,positive,positive
559046846,Even I am facing this same problem - any solution?,even facing problem solution,issue,negative,neutral,neutral,neutral,neutral,neutral
558680297,"Hey @abogaziah,

I've gotten to a place, where I've setup an env for extending PyTorch with a CUDA implementation, as I believe the best way forward is to ""Port this library to PyTorch - https://python-paillier.readthedocs.io/en/develop/"".
I don't think ""Wrap this library - https://github.com/data61/cuda-fixnum"" is necessary ? @iamtrask  correct me if I am wrong.

I could send you a link to my forked repo and we can work there?

",hey gotten place setup extending implementation believe best way forward port library think wrap library necessary correct wrong could send link forked work,issue,negative,positive,positive,positive,positive,positive
558656145,"The main point of #2 is that there is a difference between how tuple
literals (""()"") simplify in Serde and how tuple objects (""tuple()"")
simplify in Serde.  As worker library authors, we keep seeing examples of
tuple literals that don't simplify.

We want the simplest possible Serde string, and we don't want parentheses
that aren't being simplified as tuples.  Parens without an integer
associated with them are ""magic parens"".  We can presume those are intended
to be tuples, but they don't simplify like tuples.

On Mon, Nov 25, 2019 at 5:18 PM Clara Bennett <notifications@github.com>
wrote:

> I'm a little bit confused about point (2). The example given:
>
> (31, (1, ((6, CONTENT, OF, TUPLE))))
>
> are you saying that this is *intended* to be equivalent to
>
> tuple(31, tuple(1, tuple(tuple(6, CONTENT, OF, TUPLE))))
>
> but is actually equivalent to
>
> tuple(31, tuple(1, tuple(6, CONTENT, OF, TUPLE)))
>
> due to the missing comma? (because (1) == 1 while (1,) == tuple(1)) Or,
> is there something else that you're trying to point at?
>
> —
> You are receiving this because you were assigned.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/2654?email_source=notifications&email_token=AAJ44CVX2VBDMNSCSL5UCALQVQCG3A5CNFSM4I7D6IHKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEFDESRQ#issuecomment-558254406>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AAJ44CX3YJJX66ETKK6O6V3QVQCG3ANCNFSM4I7D6IHA>
> .
>
",main point difference simplify simplify worker library keep seeing simplify want possible string want parenthesis simplified without integer associated magic presume intended simplify like mon wrote little bit confused point example given content saying intended equivalent content actually equivalent content due missing comma something else trying point assigned reply directly view,issue,negative,negative,neutral,neutral,negative,negative
558607334,"@PlamenHristov how far have you reached? maybe we can work together on it!
 ",far maybe work together,issue,negative,positive,neutral,neutral,positive,positive
558585020,Have you solved this issue?  I have met this problem today and I can not solve it.,issue met problem today solve,issue,negative,neutral,neutral,neutral,neutral,neutral
558511526,"Hi @fdroessler . Thank you for spotting the issue out! Indeed, model.get() extracts the model from the remote worker, so calling .get() once again will raise an error, whereas .copy().get() does not raise such an error when using it multiple times. Did this behaviour change? That was my reason for using .copy().get().

Your fix sounds good, BTW!",hi thank spotting issue indeed model remote worker calling raise error whereas raise error multiple time behaviour change reason fix good,issue,negative,positive,positive,positive,positive,positive
558304976,"@LaRiffle @iamtrask Would you please take a look at this PR, I added all of the required changes. Phewww

By the way, 

You can now instantiate a `String` object without explicitly indicating the owner. As with tensor types, the owner will be set to `syft.local_worker` by default:

```
from syft.generic.string import String

text = String('Hello PySyft String')

```",would please take look added way string object without explicitly owner tensor owner set default import string text string string,issue,negative,neutral,neutral,neutral,neutral,neutral
558113229,"Sorry for the late response.
Could you write what command you use to run the server on the raspberry PI?
Did you try with the following?
```python run_websocket_server.py --port <port> --id <id>```",sorry late response could write command use run server raspberry pi try following python port port id id,issue,negative,negative,negative,negative,negative,negative
558068618,"@fdroessler I don't have a preference over which tool to use. Don't know about Papermill, will take a look. 
As long as we avoid copying code for testing... :smile: ",preference tool use know take look long avoid code testing smile,issue,negative,positive,positive,positive,positive,positive
557917373,"Update:
For the notebook:
- `Federated Recurrent Neural Network.ipynb` I now modified the notebook in order to first `get` the models and then send `copies` of them to workers. This seems to fix the issue from before but I am not sure if I am just working around a bug or if this has actually changed.

Maybe @DanyEle could have a look?",update notebook recurrent neural notebook order first get send fix issue sure working around bug actually maybe could look,issue,negative,positive,positive,positive,positive,positive
557916174,"In the advanced folder the following notebooks are currently not tested:

- `Federated Recurrent Neural Network.ipynb`
Reason:
I am not 100% sure but my suspicion is that the `model.copy()` command does not do what the notebook thinks it does. So the in the evaluation cell (last cell) the model is received once via `model.copy().get()` and in the second occurrence it does not exist anymore and it throws an error that the object with that ID does not exist anymore.

EDIT: I can confirm my suspicion, the first time the `model.copy().get()` command is run it works the second time it does not.

- `Build your own tensor type (advanced).ipynb`
Rason:
This notebook requires modification of the source code. I am not sure what the best way of testing this is and also it is not 100% clear if the notebook is up-to-date.",advanced folder following currently tested recurrent neural reason sure suspicion command notebook evaluation cell last cell model received via second occurrence exist error object id exist edit confirm suspicion first time command run work second time build tensor type advanced notebook modification source code sure best way testing also clear notebook,issue,positive,positive,positive,positive,positive,positive
557908545,"Currently the following notebooks are not running:
- `Part 10 - Federated Learning with Secure Aggregation.ipynb`
Reason: 
Details see: https://openmined.slack.com/archives/C6EEFN3A8/p1572184769145600
But it seems that PyTorch does not implement log2 for LongTensors and this causes the following error:
```
~/git/PySyft/syft/frameworks/torch/hook/hook_args.py in <lambda>(i)
     32 backward_func = {
     33     TorchTensor: lambda i: i.wrap(),
---> 34     torch.Tensor: lambda i: i.wrap(),
     35     torch.nn.Parameter: lambda i: torch.nn.Parameter(data=i),
     36     AutogradTensor: lambda i: AutogradTensor(data=i).on(i, wrap=False),

AttributeError: 'numpy.ndarray' object has no attribute 'wrap'
```

- `Part 13b - Secure Classification with Syft Keras and TFE - Secure Model Serving.ipynb` and `Part 13c - Secure Classification with Syft Keras and TFE - Private Prediction Client.ipynb`
Reason:
It seems like the model sharing using syft keras for some reasons blocks such that the serving of the model in Part 13b can't be done thus Part 13c can't be run either.",currently following running part learning secure reason see implement log following error lambda lambda lambda lambda lambda object attribute part secure classification secure model part secure classification private prediction reason like model serving model part ca done thus part ca run either,issue,positive,positive,positive,positive,positive,positive
557907573,"@midokura-silvia We should have probably coordinated better ... I am working on the same thing... just reopened my previous PR. #2755  #2703 

Interesting, did not know about treon. I went for Papermill because that way you can change stuff like epochs so that you don't have timeout or long running notebook issues.",probably better working thing previous interesting know went way change stuff like long running notebook,issue,positive,positive,positive,positive,positive,positive
557907296,I had some problems with my repo so I needed to set it up new. Will start a new PR. Sorry for any inconveniences ,set new start new sorry,issue,negative,negative,neutral,neutral,negative,negative
557741198,"Quite frankly, the parens should never have existed.  They weren't being
simplified by Serde into tuples properly.  It's become quite a headache to
build syft.js's Serde implementation with parens (tuples) not being
simplified as tuples.

We still need someone to sweep through PySyft and do this... If you're
interested!

On Fri, Nov 22, 2019 at 6:51 PM Karl Higley <notifications@github.com>
wrote:

> I'm making some progress on figuring out what's required to catch the
> AndroidWorker up to the current state of the serdes, but quickly hitting
> places where I wish ""2. Eliminate parentheses clouding"" had been completed.
> Not sure exactly what changed since 0.2.0a2, but I'm now seeing repetitive
> parens that break the message unpacking.
>
> (I'm now also looking forward to Protobuf, so that these kinds of
> low-level serialization issues are easier to fix.)
>
> —
> You are receiving this because you were assigned.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/2654?email_source=notifications&email_token=AAJ44CTVZSUDYWF33XJH253QVAS2NA5CNFSM4I7D6IHKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEE6Q3KA#issuecomment-557649320>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AAJ44CSFV5KEIHYJ5RODNRTQVAS2NANCNFSM4I7D6IHA>
> .
>
",quite frankly never simplified properly become quite headache build implementation simplified still need someone sweep interested wrote making progress catch current state quickly wish eliminate parenthesis clouding sure exactly since seeing repetitive break message also looking forward serialization easier fix assigned reply directly view,issue,positive,positive,positive,positive,positive,positive
557649320,"I'm making some progress on figuring out what's required to catch the AndroidWorker up to the current state of the serdes, but quickly hitting places where I wish ""2. Eliminate parentheses clouding"" had been completed. Not sure exactly what changed since 0.2.0a2, but I'm now seeing repetitive parens that break the message unpacking.

(I'm now also looking forward to Protobuf, so that these kinds of low-level serialization issues are easier to fix.)",making progress catch current state quickly wish eliminate parenthesis clouding sure exactly since seeing repetitive break message also looking forward serialization easier fix,issue,positive,positive,positive,positive,positive,positive
557231051,@iamtrask What is your view on all the data files that are necessary for the notebooks to run? I have the ones that don't need the data files running but not sure how to proceed with the others. A separate git lfs or downloading them when the fixture is set-up? What are your thoughts on this?,view data necessary run need data running sure proceed separate git fixture,issue,negative,positive,positive,positive,positive,positive
557134406,"Thanks for following up, I'll have some time today and tomorrow to work on this.",thanks following time today tomorrow work,issue,negative,positive,neutral,neutral,positive,positive
556768093,"Hi, yesterday , in win10 , i try ""python setup.py install ""  without ""udacity"", it works. At the same time, i  do it in the same fashion. But after this , i try ""pip install syft "" in colab. It works as well.Anyway, now i can use PySyft in my local desktop or colab. thanks for yours contributions!",hi yesterday win try python install without work time fashion try pip install work use local thanks,issue,positive,positive,positive,positive,positive,positive
556751071,I will be working on this issue https://github.com/OpenMined/PySyft/issues/2622 and then taking up this. We need a way generalized way to handle unequal chains. ,working issue taking need way generalized way handle unequal,issue,negative,neutral,neutral,neutral,neutral,neutral
556338265,"@iamtrask Done! 

I had to put some extra checks as the command variable was being used with the wrong path (_C._nn) in several calls. I also added a test that performs a foward on a network with several different layers, including AvgPooling.

While I was designing the tests, I noticed that a pointtensor's .size () function is returning unexpected values, is this normal? I am saying this because most pre-imported models from the torchvision library use this function to access the positions of a tensor.",done put extra command variable used wrong path several also added test network several different designing function unexpected normal saying library use function access tensor,issue,negative,negative,neutral,neutral,negative,negative
556174646,"(Also, @chenjinhua1993 - make sure you're on the latest master branch)",also make sure latest master branch,issue,negative,positive,positive,positive,positive,positive
556171980,@jvmancuso looks like your recent chang e(https://github.com/OpenMined/PySyft/commit/ef8a61b264819c4b5b0c830f0f1333aec20752d6) might havee issues on win10 and colab?,like recent chang might win,issue,positive,positive,positive,positive,positive,positive
556169236,"> @iamtrask
> 
> I have thought of this but it turned out that you cannot apply `setattr` on builtin types in python. Any thoughts?

http://clarete.li/forbiddenfruit/ might be able to help here :)",thought turned apply python might able help,issue,negative,positive,positive,positive,positive,positive
556166276,"@iamtrask 

I have thought of this but it turned out that you cannot apply `setattr` on builtin types in python. Any thoughts?",thought turned apply python,issue,negative,neutral,neutral,neutral,neutral,neutral
556161715,"Maybe I can give it a try ?


`Updated 2019-11-22T08:41:22Z`
Since, no one else has been assigned or commented I'll start working on it.
If someone else does the same or makes substantial progress, please write a comment to make sure we are not duplicating work.  ",maybe give try since one else assigned start working someone else substantial progress please write comment make sure work,issue,positive,positive,positive,positive,positive,positive
556057124,"> I was implementing test cases, but I am facing implementation conflict as self data is required to be tensor (as per the requirement of fix_prec function). I don't know how to proceed further, please guide.

Looks like this PR is blocked until we hook numpy and potentially even integrate it with FixedPrecisionTensor?",test facing implementation conflict self data tensor per requirement function know proceed please guide like blocked hook potentially even integrate,issue,negative,neutral,neutral,neutral,neutral,neutral
556053132,@midokura-silvia - if it's been ~7 days or more after checking in with someone who reviewed - and you feel the PR should be approved - you may go ahead and merge.,day someone feel may go ahead merge,issue,negative,neutral,neutral,neutral,neutral,neutral
556051854,"> Interesting progress going on!
> I have a question:
> For FixedPrecision I have .fix_precision() and float_precision() to revert
> For AdditiveShared I have .share() and .get()
> For Polynomial we have .poly() _but what's the one to revert_?

once you go .poly() you never go back!",interesting progress going question revert polynomial one go never go back,issue,positive,positive,positive,positive,positive,positive
556047838,"I'm going to close this due to inactivity. This is, however, an extremely important PR and I do hope you or @gmuraru will pick it up!",going close due inactivity however extremely important hope pick,issue,positive,positive,positive,positive,positive,positive
556043962,Closing due to inactivity. This does seem like a really useful contribution though! Please do resubmit!,due inactivity seem like really useful contribution though please resubmit,issue,positive,positive,neutral,neutral,positive,positive
556042834,Closing this PR due to inactivity. Definitely interested in solving this issue though. Please re-submit at the appropriate time.,due inactivity definitely interested issue though please appropriate time,issue,positive,positive,positive,positive,positive,positive
556038591,"Hey - an odd request. As a UX thing, do you think it would be possible to actually hook string instead of having a separate class?

Aka, instead of doing

```
from syft.generic.string import String

string = String('hello world', owner = hook.local_worker)

string_pointer = string.send(bob)
```

You'd just do

```
string_pointer = 'hello world'.send(bob)
```

This just seems a lot cleaner, no? Not saying we should remove the String() class, but a PythonHook() class which hooked the string class in Python would be really nice",hey odd request thing think would possible actually hook string instead separate class aka instead import string string string world owner bob bob lot cleaner saying remove string class class hooked string class python would really nice,issue,negative,positive,positive,positive,positive,positive
556033113,Hey @marcusvlc - would absolutely love to merge this. Any chance you can add a test per @robert-wagner 's request?,hey would absolutely love merge chance add test per request,issue,positive,positive,positive,positive,positive,positive
556032391,"> I will continue working on the first item from @LaRiffle options and then come back to this issue.

Looks like this is unblocked - great work on https://github.com/OpenMined/PySyft/pull/2741!",continue working first item come back issue like unblocked great work,issue,positive,positive,positive,positive,positive,positive
556021185,"@PlamenHristov You are right. I missed that _REQ part, my bad. The issue (non-issue) is solved :+1: ",right part bad issue,issue,negative,negative,negative,negative,negative,negative
556019980,"```
test/torch/tensors/test_additive_shared.py         508      5    99%   411-416
```

Looks like these lines aren't getting called in the testing suite. Can we either remove them or ensure taht they get run? (this is what's causing OpenCI to fail)",like getting testing suite either remove ensure get run causing fail,issue,negative,negative,negative,negative,negative,negative
556014972,"Would love to add .randn as well, but no need to block this PR to modify the list of supported methods (it's the generic ability that's the hard part)",would love add well need block modify list generic ability hard part,issue,positive,positive,neutral,neutral,positive,positive
556014642,This PR is looking really quite good to me. Fantastic work George! You're really spinning up on the codebase quite quickly!,looking really quite good fantastic work really spinning quite quickly,issue,positive,positive,positive,positive,positive,positive
555608178,"> Just a small report, I'm running into a similar error, but it appears a few lines earlier:
> 
> ```
> exp_avg.mul_(beta1).add_(1 - beta1, grad)
> ```
> 
> The following error appears:
> 
> ```
> TypeError: add_() takes 1 positional argument but 2 were given
> ```
> 
> So it's to be a more general problem than only specific functions like `addcmul_()` and `addcdiv_()`

I encountered an error in the same line, but it raises 

> syft.exceptions.PureFrameworkTensorFoundError

Syft 0.1.26a1
Torch 1.1.0",small report running similar error beta beta grad following error positional argument given general problem specific like error line torch,issue,negative,negative,neutral,neutral,negative,negative
555512234,"I know from a PyTorch contributor it is possible to test in GPU with CircleCI, but we would need a special plan for it.",know contributor possible test would need special plan,issue,negative,positive,positive,positive,positive,positive
555245989,"🙏🙏🙏

On Mon, Nov 18, 2019 at 10:35 PM Plamen Hristov <notifications@github.com>
wrote:

> Maybe I can take a look at this?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/2539?email_source=notifications&email_token=AAJ44CRGW2GCLV3WRGDJCH3QUMKDBA5CNFSM4IOLZDWKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEEMFAII#issuecomment-555241505>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AAJ44CSKX2PGDSZY3C6ETW3QUMKDBANCNFSM4IOLZDWA>
> .
>
",mon wrote maybe take look reply directly view,issue,negative,positive,neutral,neutral,positive,positive
555241505,"Maybe I can take a look at this?

@LaRiffle, can I please ask you to point to an example of the error you were referring to?
",maybe take look please ask point example error,issue,negative,neutral,neutral,neutral,neutral,neutral
555238019,"@AlanAboudib , I think I got to the root of it and I don't think there is a problem with the code.
* The message printout happens here: https://github.com/OpenMined/PySyft/blob/e6ef7c205c7898e4401287791672a41947cf846b/syft/workers/base.py#L290

1. In the first case it says that bob received the **tensor** (`OBJ`), that is a -> tensor -> b
2. In the second printout the log says that bob received a **request for a tensor** (`OBJ_REQ`), that is me -> OBJ_REQ -> bob.

Here is the code where the owner (`me`) sends the tensor request to bob (`location`): https://github.com/OpenMined/PySyft/blob/e6ef7c205c7898e4401287791672a41947cf846b/syft/workers/base.py#L595

After that the tensor is correctly assigned to `a` .

Let me know if I am missing something or if that is not the intended behaviour.",think got root think problem code message first case bob received tensor tensor second log bob received request tensor bob code owner tensor request bob location tensor correctly assigned let know missing something intended behaviour,issue,negative,positive,neutral,neutral,positive,positive
555210179,"We don't have anyone working on this currently unfortunately at the moment, but as soon as someone picks it we'll be good!",anyone working currently unfortunately moment soon someone good,issue,negative,positive,neutral,neutral,positive,positive
555085473,"Excellent!

Sent from my iPhone

> On 18 Nov 2019, at 15:44, Alan Aboudib <notifications@github.com> wrote:
> 
> ﻿
> @iamtrask I discussed the issue @vvmnnnkv this week and we actually agree with that. This should be straight forward now
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub, or unsubscribe.
",excellent sent alan wrote issue week actually agree straight forward reply directly view,issue,positive,positive,positive,positive,positive,positive
555073989,"Great, let us know how it goes :+1: ",great let u know go,issue,positive,positive,positive,positive,positive,positive
555073608,@iamtrask I discussed the issue @vvmnnnkv this week and we actually agree with that. This should be straight forward now,issue week actually agree straight forward,issue,positive,positive,neutral,neutral,positive,positive
555055431,"You can do so whenever you want.  I figure this will be done asynchronous for syft.js.  Besides, syft workers are kind of ""premade integration tests"" for the Serde refactor.  The sooner you implement the above, the sooner you can test against what PySyft does and if the PR's being submitted work as intended.  So go ahead and get started with AndroidWorker!",whenever want figure done asynchronous besides kind integration sooner implement sooner test work intended go ahead get,issue,positive,positive,positive,positive,positive,positive
555053095,"It seems like 1 and 5 have now been completed in PySyft, yeah? At this point, does it make sense for the workers to start trying to catch up to the serialization changes? Better to wait for the list/tuple/magic parens changes to go through?",like yeah point make sense start trying catch serialization better wait go,issue,positive,positive,positive,positive,positive,positive
554948823,Try on the latest code of the dev branch. I just tested your code there and it works.,try latest code dev branch tested code work,issue,negative,positive,positive,positive,positive,positive
554795969,"Great job, ping me when you're ready for a review!",great job ping ready review,issue,positive,positive,positive,positive,positive,positive
554751129,"I upgraded my gcc version to 4.8.5 and also tried installing zstd using pip install --upgrade --force-reinstall zstd and also within a virtual environment. But it keeps failing with the error: command 'gcc' failed with exit status 1 error.
I'm using MacOS Mojave.
Here's the full stack trace:
gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/Users/judytraj/anaconda3/include -arch x86_64 -I/Users/judytraj/anaconda3/include -arch x86_64 -I/Users/judytraj/env/include -I/Users/judytraj/anaconda3/include/python3.6m -c zstd/lib/compress/zstd_compress.c -o build/temp.macosx-10.7-x86_64-3.6/zstd/lib/compress/zstd_compress.o -O2 -DVERSION=""1.4.4.0"" -DZSTD_MULTITHREAD=1 -Izstd/lib -Izstd/lib/common -Izstd/lib/compress -Izstd/lib/decompress
    In file included from /Users/judytraj/anaconda3/lib/gcc/x86_64-apple-darwin11.4.2/4.8.5/include-fixed/syslimits.h:7:0,
                     from /Users/judytraj/anaconda3/lib/gcc/x86_64-apple-darwin11.4.2/4.8.5/include-fixed/limits.h:34,
                     from zstd/lib/compress/zstd_compress.c:14:
    /Users/judytraj/anaconda3/lib/gcc/x86_64-apple-darwin11.4.2/4.8.5/include-fixed/limits.h:168:61: fatal error: limits.h: No such file or directory
     #include_next <limits.h>  /* recurse down to the real one */
                                                                 ^
    compilation terminated.
    error: command 'gcc' failed with exit status 1
    
    ----------------------------------------
Command ""/Users/judytraj/env/bin/python3 -u -c ""import setuptools, tokenize;__file__='/private/var/folders/gl/nvvrj70x0jl8c_sjl8byd0580000gn/T/pip-install-53a8mopu/zstd/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /private/var/folders/gl/nvvrj70x0jl8c_sjl8byd0580000gn/T/pip-record-61j83b2i/install-record.txt --single-version-externally-managed --compile --install-headers /Users/judytraj/env/include/site/python3.6/zstd"" failed with error code 1 in /private/var/folders/gl/nvvrj70x0jl8c_sjl8byd0580000gn/T/pip-install-53a8mopu/zstd/
",version also tried pip install upgrade also within virtual environment failing error command exit status error full stack trace file included fatal error file directory recurse real one compilation error command exit status command import open compile code install record compile error code,issue,negative,positive,positive,positive,positive,positive
554732946,"My hunch is that these shorthands are becoming industry standards (MPC for sure already is, DP as well, FL and HE well on their way)",hunch becoming industry sure already well well way,issue,positive,positive,positive,positive,positive,positive
554729613,"> @iamtrask My bad, I have added feature to allow sending any object to a remote worker indeed. However, not in this PR. It was in the previous version of this PR, but i was causing errors, so I did the PR without this feature. Just with `String` and `StringPointer`. The `serde.py` file is left untouched.
> 
> However, the feature to send any object was added to allow sending SyferText objects such as the `Tokenizer` object. Registering external classes in `serde.py` would require PySyfert to import SyferText, that is why I opted to added that risky feature.
> 
> However, we should probability think of a different way of allowing external objects to be sent. An authorization mechanism ??

Not necessarily - SyferText could simply register more objects to serde when it's imported (so that they can be received), and the assumption would be that the worker would have to have also imported SyferText in order to receive commands.",bad added feature allow sending object remote worker indeed however previous version causing without feature string file left untouched however feature send object added allow sending object external class would require import added risky feature however probability think different way external sent authorization mechanism necessarily could simply register received assumption would worker would also order receive,issue,negative,negative,negative,negative,negative,negative
554729323,"Just to give an update on the ""progress"". 
I've setup my environment with the example test above and am debugging through the code.",give update progress setup environment example test code,issue,negative,neutral,neutral,neutral,neutral,neutral
554694465,Great to see you working on this project!,great see working project,issue,positive,positive,positive,positive,positive,positive
554692507,"> It would be a good idea to move this files to a separate branch called `experimental`? And there we can try to run experiments before merging them into `dev`.
> Thinking about this again: we could have the experiments on our personal fork version and make a PR into `dev` when we know that they work.

Agreed",would good idea move separate branch experimental try run dev thinking could personal fork version make dev know work agreed,issue,positive,positive,positive,positive,positive,positive
554656685,"shorter imports look better, but what about explicit being better than implicit? 

I am afraid, that long term `fl`, `dp` and so on, not going to make it easier for users to use the library",shorter look better explicit better implicit afraid long term going make easier use library,issue,positive,positive,neutral,neutral,positive,positive
554651117,"It would be a good idea to move this files to a separate branch called ```experimental```? And there we can try to run experiments before merging them into ```dev```.
Thinking about this again: we could have the experiments on our personal fork version and make a PR into ```dev``` when we know that they work.",would good idea move separate branch experimental try run dev thinking could personal fork version make dev know work,issue,negative,positive,positive,positive,positive,positive
554650442,This is indeed possible - but I wouldn't want to require this to run PySyft's tests by default. https://stackoverflow.com/questions/3087361/gpu-emulator-for-cuda-programming-without-the-hardware,indeed possible would want require run default,issue,negative,neutral,neutral,neutral,neutral,neutral
554592830,"Hello @LaRiffle, I will like to take this issue as my first issue.",hello like take issue first issue,issue,negative,positive,positive,positive,positive,positive
554299493,"This is because we need to add msg.OBJ to the messages tracked by the plan trace. Right now it’s only msg.CMD

Sent from my iPhone

> On 15 Nov 2019, at 09:41, Théo Ryffel <notifications@github.com> wrote:
> 
> ﻿
> You're right it must be more tricky, i think the code I gave is not appropriate to observe the error which indeed is still there
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub, or unsubscribe.
",need add tracked plan trace right sent wrote right must tricky think code gave appropriate observe error indeed still reply directly view,issue,negative,positive,positive,positive,positive,positive
554288280,"You're right it must be more tricky, i think the code I gave is not appropriate to observe the error which indeed is still there",right must tricky think code gave appropriate observe error indeed still,issue,negative,positive,positive,positive,positive,positive
554287355,I don't think so! beware this might be a tricky issue to solve :),think beware might tricky issue solve,issue,negative,neutral,neutral,neutral,neutral,neutral
554272021,I think this can be safely closed as we have now better ideas on the refactor strategy,think safely closed better strategy,issue,positive,positive,positive,positive,positive,positive
554254088,"I would love to write parts of it with @midokura-silvia if you are willing. Should we use Treon, Andrew or just unittest in separate files/notebooks?",would love write willing use separate,issue,positive,positive,positive,positive,positive,positive
554192619,"Well, it seems like conda has already some zstd header files in its include directory. 
```
~/anaconda3/envs/pysyft/include/zstd.h
~/anaconda3/envs/pysyft/include/zstd_errors.h
```
When installing zstd, conda will add its include directory to gcc's search path. So when compiling zstd source file, gcc will use `zstd.h` in conda instead of its own.
The solution is simple, just move the headers somewhere else, install pysyft, and move them back.",well like already header include directory add include directory search path source file use instead solution simple move somewhere else install move back,issue,positive,neutral,neutral,neutral,neutral,neutral
553835109,"Hey Alan,

I am new to the project. I think I might be able to do that?",hey alan new project think might able,issue,negative,positive,positive,positive,positive,positive
553801426,"Note this is PR for branch https://github.com/OpenMined/PySyft/pull/2723 not master branch. In #2723, unit test test_websocket_worker_multiple_output_response doesn't pass. This PR fixes it.",note branch master branch unit test pas,issue,negative,neutral,neutral,neutral,neutral,neutral
553790499,Tested the code from @amit-rastogi and the error still exists. @robert-wagner are you looking into the issue?,tested code error still looking issue,issue,negative,neutral,neutral,neutral,neutral,neutral
553788697,Could you please describe what was the problem?,could please describe problem,issue,negative,neutral,neutral,neutral,neutral,neutral
553784272,Tested this on the latest ```dev branch``` and there is no problem. @wind23 could you please retest and close the issues if it is solved?,tested latest dev branch problem wind could please retest close,issue,negative,positive,positive,positive,positive,positive
553645635,"Hi, I think this is due to the object pointer in Alice having to be unwrapped  and then re-wrapped when getting the response. 

However, when re-wrapping, the object is incorrectly registered to make the first copy in Alice (due to the default setting of [`register=True` in  `wrap()`](https://github.com/OpenMined/PySyft/blob/1cf824502fc83ef4b8e17135458a14d35753c745/syft/generic/pointers/object_pointer.py#L163)):
```
class ObjectPointer(AbstractObject):
    ...
    def wrap(self, register=True, type=None, **kwargs): 
```

Then, when we actually want to register the response as we normally would when executing the command, the registered response creates a second copy in Alice. 

I'm not super familiar with the code to know if this intended, or actually makes sense (sorry if I've misunderstood something!), but thought it could be helpful. ",hi think due object pointer unwrapped getting response however object incorrectly registered make first copy due default setting wrap class wrap self actually want register response normally would command registered response second copy super familiar code know intended actually sense sorry misunderstood something thought could helpful,issue,positive,positive,neutral,neutral,positive,positive
553572238,"Interesting! So yes I _think_ Websocket with PySyft currently only work in local networks. You need to use PyGrid across devices, but maybe the PyGrid team can confirm",interesting yes currently work local need use across maybe team confirm,issue,positive,positive,positive,positive,positive,positive
553570140,"@LaRiffle to the best of my memory, this doesn't simplify in Serde to include the send command.  Because of that, syft.js will have no idea to send the tensor.  I remember you, me, and @iamtrask had an issue simplifying the send command a while back.

Is this no longer the case?",best memory simplify include send command idea send tensor remember issue send command back longer case,issue,positive,positive,positive,positive,positive,positive
553369390,I will continue working on the first item from @LaRiffle options and then come back to this issue.,continue working first item come back issue,issue,negative,positive,positive,positive,positive,positive
553363980,"But how do make sure that the code doesn't diverge between notebook and unit test?

Could [Treon](https://github.com/ReviewNB/treon) be a solution?",make sure code diverge notebook unit test could solution,issue,positive,positive,positive,positive,positive,positive
553183186,"`send` is not inplace, you need to do: `p = x.send(bob)` instead of `x.send(bob)`",send need bob instead bob,issue,negative,neutral,neutral,neutral,neutral,neutral
553182331,"Hey, PySyft does not support GPU(cuda) yet, but there is an ongoing PR on this
https://github.com/OpenMined/PySyft/pulls",hey support yet ongoing,issue,negative,neutral,neutral,neutral,neutral,neutral
553181398,"Hi, does it work in local mode? (connected through the localhost)

Also, cross device computation will increasingly handled in PyGrid 
https://github.com/OpenMined/PyGrid",hi work local mode connected also cross device computation increasingly handled,issue,negative,neutral,neutral,neutral,neutral,neutral
553179890,Can you add details and fix the display? Some elements are missing to understand your problem,add fix display missing understand problem,issue,negative,negative,negative,negative,negative,negative
553179353,I think there is ongoing work on this topic: https://github.com/OpenMined/PySyft/pull/2690,think ongoing work topic,issue,negative,neutral,neutral,neutral,neutral,neutral
553177193,"This looks like a pytorch installation error.
You should maybe ask on pytorch forums to try to understand how to install pytorch 1.3 with pip with you python / OS",like installation error maybe ask try understand install pip python o,issue,negative,neutral,neutral,neutral,neutral,neutral
553175557,"This has been discussed today @iamtrask @cereallarceny 
With the version of master of today I can run:
```python
@sy.func2plan([th.Size((3,))])
def plan_double_abs(x):
    x = x.send(bob)
    x = x + x
    x = th.abs(x)
    return x

ptr_result = plan_double_abs(th.ones(3))
assert isinstance(ptr_result.child, sy.PointerTensor)
result = ptr_result.get()
print(result)
assert torch.equal(result, th.tensor([2., 2., 2.]))
```
What could be not working as expected?",today version master today run python bob return assert result print result assert result could working,issue,negative,neutral,neutral,neutral,neutral,neutral
552987843,"I can take it - it would be a challenge, but will try to do it :)",take would challenge try,issue,negative,neutral,neutral,neutral,neutral,neutral
552947917,"I've updated pytorch to 1.3.0 and pysyft to 0.2.0a2, and by rerunning the notebooks I now receive the same error as issue #2634 #issuecomment-546368259 

Fix see #2634 ",receive error issue fix see,issue,negative,neutral,neutral,neutral,neutral,neutral
552934262,"Could you resolve this issue? Cause I receive the same error, see issue #2725 

edit: 
Seems to be fixed by replacing `params[remote_index][param_index].set(new_params[param_index])` by `params[remote_index][param_index].data = (new_params[param_index])`, as the parameters were not properly updated",could resolve issue cause receive error see issue edit fixed properly,issue,negative,positive,neutral,neutral,positive,positive
552785532,"my python version is 3.7.4, I think it's supported. 
I run the command python -m pip install syft[udacity] on cmd and I get the same error",python version think run command python pip install get error,issue,negative,neutral,neutral,neutral,neutral,neutral
552782134,"Hi
Are you using a virtual environment?
If yes then are you referring to the correct python installation

For example when you're in a virtual environment and want to install something via pip using this is better

python -m pip install [ package ]
Also are you on a supported python version?",hi virtual environment yes correct python installation example virtual environment want install something via pip better python pip install package also python version,issue,positive,positive,positive,positive,positive,positive
552494900,"Certainly! Setup a calendar invite.

On Mon, Nov 11, 2019 at 10:11 AM Ionésio Junior <notifications@github.com>
wrote:

> @iamtrask <https://github.com/iamtrask>, @LaRiffle
> <https://github.com/LaRiffle>, and @robert-wagner
> <https://github.com/robert-wagner> could we discuss about these use cases?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/pull/2709?email_source=notifications&email_token=ABBAZEWQJGSSDG3QJAB6BBTQTEVWXA5CNFSM4JF5L4FKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEDWKC2A#issuecomment-552378728>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ABBAZEXBQNQEQ6I3RKEMFW3QTEVWXANCNFSM4JF5L4FA>
> .
>
",certainly setup calendar invite mon junior wrote could discus use reply directly view,issue,negative,positive,positive,positive,positive,positive
552424271,I would love to get this merged @robert-wagner @iamtrask @LaRiffle - it's one of the Serde issues.,would love get one,issue,positive,positive,positive,positive,positive,positive
551993802,"It turns out that the models are not correctly updated, even if 
```
for remote_index in range(len(compute_nodes)):
        for param_index in range(len(params[remote_index])):
            params[remote_index][param_index].set_(new_params[param_index])
```
is correctly called.

Following tutorial 10, the `params` list is updated, but the update of these values are not updated neither in `alices_model.parameters()` nor `bobs_model.parameters()`.

Unfortunately, I don't know how to fix this

",turn correctly even range range correctly following tutorial list update neither unfortunately know fix,issue,negative,negative,negative,negative,negative,negative
551561680,"Yes, you can do that.
There is a tutorial [here](https://github.com/OpenMined/PySyft/tree/master/examples/tutorials/advanced/websockets-example-MNIST) - you need to have the websocket servers on different machines and then in the client websocket give the proper IP address",yes tutorial need different client give proper address,issue,negative,neutral,neutral,neutral,neutral,neutral
551423655,"We have three use cases to Private Tensors operations:

**First**: Perform a tensor operation using only itself.
```
x = th.tensor([1,2,3,4,5])

# Wrap a public tensor using a private layer
private_x = x.private_tensor(allowed_users=[SSLCertificate, SSKey, UserAuth])

result_tensor = private_x.t()
```
Should **result_tensor** inherit private_x credentials?




**Second**: Perform a tensor operation with a public tensor.
```
x = th.tensor([1,2,3,4,5])
y = th.tensor([2,2,2,2,2])

// Wrap a public tensor using a private layer
private_x = x.private_tensor(allowed_users=[SSLCertificate, SSKey, UserAuth])

result_tensor = private_x + y
```
Should **result_tensor** be converted to a public tensor or inherit **private_x** credentials?

**Third**: Perform a tensor operation with another private tensor with different credentials.
```
x = th.tensor([1,2,3,4,5])
y = th.tensor([2,2,2,2,2])

// Wrap a public tensor using a private layer
private_x = x.private_tensor(allowed_users=[SSLCertificate, SSKey])
private_y = y.private_tensor(allowed_users=[SSKey, UserAuth])

result_tensor = private_x + y
```

Should **result_tensor** inherit the intersection between **private_x** and **private_y** (Logic AND) or the union between them (Logic OR)?",three use private first perform tensor operation wrap public tensor private layer inherit second perform tensor operation public tensor wrap public tensor private layer converted public tensor inherit third perform tensor operation another private tensor different wrap public tensor private layer inherit intersection logic union logic,issue,negative,positive,neutral,neutral,positive,positive
551322793,"Tensor serde for ""all"" strategy: https://github.com/OpenMined/PySyft/pull/2724
(with few minor changes to fix bunch of failing Plan unit tests)",tensor strategy minor fix bunch failing plan unit,issue,negative,negative,neutral,neutral,negative,negative
550773701,"May i work on this issue?
One thing `deregister_ptr` parameter is already used for the same purpose isn't it?",may work issue one thing parameter already used purpose,issue,negative,neutral,neutral,neutral,neutral,neutral
550755876,"I want to work on it but could not understand what exactly we need to clean up, Can you help me?",want work could understand exactly need clean help,issue,positive,positive,positive,positive,positive,positive
550483668,"Don't you think we should also add some efficiency tests in `test/efficiency_tests`, as I did for `tanh` and `sigmoid`?",think also add efficiency tanh sigmoid,issue,negative,neutral,neutral,neutral,neutral,neutral
549715911,@zouininaS try downgrading python to 3.6 in conda your environment.i.e ```conda activate <your env>``` then ```conda install python=3.6```,try python activate install,issue,negative,neutral,neutral,neutral,neutral,neutral
548959839,"Yeah, that is a good point. However, a lot of the notebooks have weird metadata still included which makes it hard to run them automated so most of the changes that I did is to restart the kernels so the notebooks are clean.",yeah good point however lot weird still included hard run restart clean,issue,positive,positive,neutral,neutral,positive,positive
548811316,"> Not sure I understand your last point about the checkout the changes. For the notebooks I included I have cleared the kernel and outputs before including them in the tests. Do you mean that or something else?

I think @kamathhrishi is asking to checkout the files from the git commit, so that your PR doesn't have 18 files changed with most of them just being changed because you re-run the notebooks :)",sure understand last point included kernel mean something else think git commit,issue,positive,positive,neutral,neutral,positive,positive
548549532,"@robert-wagner I created a solution using try catch to avoid changing the string with each iteration. If it is not good, could you suggest another approach?",solution try catch avoid string iteration good could suggest another approach,issue,negative,positive,positive,positive,positive,positive
548382543,To me this looks like we are hooking _C._nn after we are hooking torch.nn.functional. In my opinion we should not be hooking _C._nn at all which might solve this problem,like opinion might solve problem,issue,negative,neutral,neutral,neutral,neutral,neutral
547993377,"@robert-wagner 
> Hey, could you add an explanation of why we need this

Do you mean why we need `String` and `StringPointer`? This is to allow developing the NLP library SyferText. I used those types for remote tokenization of text",hey could add explanation need mean need string allow library used remote text,issue,negative,negative,negative,negative,negative,negative
547992682,"@iamtrask My bad, I have added  feature to allow sending any object to a remote worker indeed. However, not in this PR. It was in the previous version of this PR, but i was causing errors, so I did the PR without this feature. Just with `String` and `StringPointer`. The `serde.py` file is left untouched.

However, the feature to send any object was added to allow sending SyferText objects such as the `Tokenizer` object. Registering external classes in `serde.py` would require PySyfert to import SyferText, that is why I opted to added that risky feature.

However, we should probability think of a different way of allowing external objects to be sent. An authorization mechanism ??

",bad added feature allow sending object remote worker indeed however previous version causing without feature string file left untouched however feature send object added allow sending object external class would require import added risky feature however probability think different way external sent authorization mechanism,issue,negative,negative,negative,negative,negative,negative
547990214,"Should this issue be reopened? I still get `TypeError: can not serialize 'torch._C.Function' object` with Torch 1.1. 
Or TrainConfig still only works with Torch 1.0.1? @midokura-silvia @mari-linhares 

Thanks!",issue still get serialize object torch still work torch thanks,issue,negative,positive,positive,positive,positive,positive
547920325,I should mention - we explicitly want to prevent people from being able to send types to remote workers which those workers haven't explicitly decided to support.,mention explicitly want prevent people able send remote explicitly decided support,issue,negative,positive,positive,positive,positive,positive
547919745,"""I also made some changes to serde.py in the _detail() function to enable sending and receiving objects of classes that PySyft does not know.""

This seems very risky. Does this mean that I could literally send any object I want to a remote worker and manipulate it?",also made function enable sending class know risky mean could literally send object want remote worker manipulate,issue,negative,negative,negative,negative,negative,negative
547917316,"Hey, could you add an explanation of why we need this",hey could add explanation need,issue,negative,neutral,neutral,neutral,neutral,neutral
547598903,"@mari-linhares  For some reason, the command created by the native.py file for the avg_pool2d layer looks like this:

syft.local_worker.hook.torch._C._nn.native_avg_pool2d

While the max_pool2d looks like this:

syft.local_worker.hook.torch.nn.functional.native_max_pool2d

I am still trying to understand why this particular layer is being called from torch._C and not torch.nn, but for practical testing purposes, I just created an if to change avg_pool2d's command to conform to that of max_pool2d, and it worked normally. I was able to load networks like ResNet and MobileNet.

To fix it, simply open the native.py file and change the construction of the cmd variable to the following:

```
            if (cmd.split (""."")[- 1] == 'avg_pool2d'):
                cmd = 'syft.local_worker.hook.torch.nn.functional.native_avg_pool2d'
            else:
                cmd = (
                    ""syft.local_worker.hook.""
                    + ""."". join (cmd.split (""."") [: - 1])
                    + "".native_""
                    + cmd.split (""."") [- 1]
                )
```
[EDIT]
A more automatic way to correct this problem is to replace calls from _C_nn to nn.functional. I will propose this solution through a pull request.

```
            # Change library path to avoid problems with AvgPooling layer
            cmd = cmd.replace('_C._nn', 'nn.functional')

            cmd = (
                ""syft.local_worker.hook.""
                + ""."".join(cmd.split(""."")[:-1])
                + "".native_""
                + cmd.split(""."")[-1]
            )
```

Then just run python setup.py install again to overwrite the library with your change. I will try to propose a solution that is not unique to avg_pool, but for now this will work.",reason command file layer like like still trying understand particular layer practical testing change command conform worked normally able load like fix simply open file change construction variable following else join edit automatic way correct problem replace propose solution pull request change library path avoid layer run python install overwrite library change try propose solution unique work,issue,positive,positive,positive,positive,positive,positive
547312630,"I don't think that is the reason. I tired to connect the both servers. Even after I use only one raspberry pi with bob, the problem remains. ",think reason tired connect even use one raspberry pi bob problem remains,issue,negative,negative,negative,negative,negative,negative
547311596,"@steph-en-m Thank you for your answer .
When I want to call PATE here:
from syft.frameworks.torch.differential_privacy import pate
(I am working on ubuntu) ",thank answer want call pate import pate working,issue,negative,neutral,neutral,neutral,neutral,neutral
546991951,@zouininaS could you specify what you were trying to do when you got this error or which part of the tutorial this error occurred?? Thanks,could specify trying got error part tutorial error thanks,issue,negative,positive,positive,positive,positive,positive
546807908,"@kamathhrishi Great points thanks so much for looking at this. Yes, ultimately I think something like a `glob.glob('*.ipynb')` or similar would be good. However, some handcrafting will be necessary as some notebooks need a certain environment (workers, Websocketserver etc.) I have just included here those that are running straightforward atm to provide a minimal example.

Yes you are totally right in that it is hard to know that notebooks are part of the test, it should probably be included in the Contributer guide, I will make a note of that.

Not sure I understand your last point about the checkout the changes. For the notebooks I included I have cleared the kernel and outputs before including them in the tests. Do you mean that or something else?",great thanks much looking yes ultimately think something like similar would good however necessary need certain environment included running straightforward provide minimal example yes totally right hard know part test probably included guide make note sure understand last point included kernel mean something else,issue,positive,positive,positive,positive,positive,positive
546741104,@youben11 @iamtrask I have submitted a __very__ raw [WIP] PR just to check if where I am going is in line with your ideas. Let me know your initial thoughts on the approach.,raw check going line let know initial approach,issue,negative,negative,negative,negative,negative,negative
546728154,I was planning on combining papermill with pytest and write them as tests that run in an isolated filesystem. That way I think it should be possible to get websocket notebooks tested too. By using papermill it should also allow for reducing the execution time by parameterising the notebooks (like epochs etc) although in that case some parameters will be set in the first cell. It's an idea so far I'll see how far I get. ,combining write run isolated way think possible get tested also allow reducing execution time like although case set first cell idea far see far get,issue,negative,positive,positive,positive,positive,positive
546724097,Great idea! But how do you plan to flag malfunctioning notebooks? ,great idea plan flag,issue,positive,positive,positive,positive,positive,positive
546630812,Account needs to be added as a maintainer to the pypi package for this to work,account need added maintainer package work,issue,negative,neutral,neutral,neutral,neutral,neutral
546368259,"@codebecker I tried to delete the copy, the cell works but later I have an issue when I launch the train : 

![image](https://user-images.githubusercontent.com/38509329/67577617-1e9c3780-f741-11e9-878c-a945ec35fd83.png)


",tried delete copy cell work later issue launch train image,issue,negative,neutral,neutral,neutral,neutral,neutral
546213269,"I think you should start the websocker_server with the id alice.
```alice = WebsocketClientWorker(id=""alice"", port=8777, **kwargs_websocket_alice)``` - here you are trying to connect to alice, but from what you say you created the server with the id bob:
```python3 run_websocket_server.py --port 8778 --id bob```

Could you try with bob?",think start id trying connect say server id bob python port id bob could try bob,issue,negative,neutral,neutral,neutral,neutral,neutral
546133008,"@luggi961 I tried to reproduce it, but it seems it got fixed.
Could you also retest it on the latest version?",tried reproduce got fixed could also retest latest version,issue,negative,positive,positive,positive,positive,positive
546117576,">Worth noting that ""building up the core syft code to be independent"" is already complete

This comment of mine is not true -- there was a bug hiding some extra dependencies, so I've updated the top-level comment to reflect the extra work.",worth building core code independent already complete comment mine true bug extra comment reflect extra work,issue,positive,positive,positive,positive,positive,positive
546050845,"@tahirdev  is right using get at this point will bring the gradients to your local machine which should be strongly prohibited in secure aggregation. 

I worked around this error by not using a copy of the parameters for calculation. I guess it is nicer to copy them but it's also working this way. 

For the workaround just delete the .copy():

` copy_of_parameter = params[remote_index][param_i].copy()`

change to this:

` copy_of_parameter = params[remote_index][param_i]`


",right get point bring local machine strongly secure aggregation worked around error copy calculation guess copy also working way delete change,issue,negative,positive,positive,positive,positive,positive
545584097,"Hey @LaRiffle, @murarugeorgec.
While testing the working of the code I made some changes and installed the pysyft again.
I made these changes:
```python
@staticmethod
    @overloaded.module
    def torch(module):
        def roll(tensor, shifts, **kwargs):
            print(""Overloaded roll called"")  #New Line
            int_shifts = int(shifts.item())
            return torch.native_roll(tensor, int_shifts, **kwargs)
        module.roll = roll  
```
And 

```python
def handle_func_command(cls, command):
        print(""In handle func command"") #New line
"""""" ... """"""
        except PureFrameworkTensorFoundError:  # means that it's not a wrapper but a pure tensor

            # Check that the function has not been overwritten
            try:
                print(""Pure FrameworkTensor"") #New line
                # Try to get recursively the attributes in cmd = ""<attr1>.<attr2>.<attr3>...""
                command = cls.rgetattr(cls, cmd)
                return command(*args, **kwargs)
            except AttributeError:
                pass
```

Now when I run
 
```python
th.roll(x,2)
print(type(x))
```
The output is 

```
 In handle func command
 Pure FrameworkTensor
 Overloaded roll called
 <class 'torch.Tensor'>
```
**Isn't this working correctly? (Calling correct overloaded function for Pure torch Tensor)**

Moreover, 
When I try running on a wrapper (pointer after sending the tensor to the virtual worker)

x_sh = x.send(bob)
torch.roll(x_sh,2)

Its raising TypeError with the following output:
```
In handle func command
In handle func command
Pure FrameworkTensor
`````
` TypeError: roll() missing 1 required positional argument: 'shifts' `

Is this working normal?
Thanks.",hey testing working code made made python torch module roll tensor print roll new line return tensor roll python command print handle command new line except wrapper pure tensor check function try print pure new line try get command return command except pas run python print type output handle command pure roll class working correctly calling correct function pure torch tensor moreover try running wrapper pointer sending tensor virtual worker bob raising following output handle command handle command pure roll missing positional argument working normal thanks,issue,negative,positive,positive,positive,positive,positive
545529770,@wagnernegrao are you still working at this? I can try to pick this up and add the pytest.,still working try pick add,issue,negative,neutral,neutral,neutral,neutral,neutral
545520474,"@LaRiffle I think I can take this one, if you do not have another issue more urgent :)",think take one another issue urgent,issue,negative,neutral,neutral,neutral,neutral,neutral
545438815,Hey @murarugeorgec!! I am working on this issue. Unfortunately will require 1 or 2 days more to solve it!! 😃,hey working issue unfortunately require day solve,issue,negative,negative,negative,negative,negative,negative
545389919,"Is someone working on this issue? If not I can take it. Or @LaRiffle is there another issue that is more important, but also has a low level of difficulty?",someone working issue take another issue important also low level difficulty,issue,negative,positive,positive,positive,positive,positive
545118306,"Hi Theo @LaRiffle, Thanks for the updated description - that definitely helps! And yes I feel it would be better manageable if I can address change related to each of the points as separate PR.

You can assign it to me. Thanks Theo!",hi thanks description definitely yes feel would better manageable address change related separate assign thanks,issue,positive,positive,positive,positive,positive,positive
545117337,"> Can you explain a bit further what this PR is doing? This seems like a departure from past/current design and I'd like to understand if there are implications elsewhere in the code

It's just a small sugar to simplify our life, see issue https://github.com/OpenMined/PySyft/issues/2689",explain bit like departure design like understand elsewhere code small sugar simplify life see issue,issue,positive,negative,negative,negative,negative,negative
545096157,Can you explain a bit further what this PR is doing? This seems like a departure from past/current design and I'd like to understand if there are implications elsewhere in the code,explain bit like departure design like understand elsewhere code,issue,positive,neutral,neutral,neutral,neutral,neutral
545056049,"- I don't think you have to - since when I defined the plan I specified which Role owned the plan.
```
@sy.func2plan(args_shape=[(1,)], worker=king)
def add_kings_gold(kings_gold, kings_silver):
    ptr = (kings_gold + kings_silver).send(prince, id=""kings bank balance"", garbage_collect=False)
    return True
```

- i think this already does that via .send() and BlockForTensor, although @Jasopaum and I figured out a way to do the same thing without having to specify BlockForTensor explicitly (just make them arguments and pass in PointerTensors to them and it'll happen automatically)

- @Jasopaum and I had a massive discussion about this today. The three of us need to get on a call about this. It's no different. sy.BlockForTensor is a bad idea. ",think since defined plan role plan prince bank balance return true think already via although figured way thing without specify explicitly make pas happen automatically massive discussion today three u need get call different bad idea,issue,negative,negative,neutral,neutral,negative,negative
545028356,"Looks super great, just a few notes:
- `protocol = sy.Protocol(king_ops, queen_ops, prince_ops, more_queen_ops)` should be changed to specify which Role owns which plans
- we can specify a structure of graph for plans, which is in terms of dependency, while having an asynchronous execution
- What exactly is `sy.BlockForTensor` vs `sy.PromiseTensor`?",super great protocol specify role specify structure graph dependency asynchronous execution exactly,issue,positive,positive,positive,positive,positive,positive
545024087,"@iamtrask I think we already have this, you can do
`x.fix_precision(precision_fractional=5).share(alice, bob, crypto_provider=crypto)` 
And it works quite well",think already bob work quite well,issue,negative,neutral,neutral,neutral,neutral,neutral
544996263,Is the issue and the description still up to date?,issue description still date,issue,negative,neutral,neutral,neutral,neutral,neutral
544484535,"Alternatively, we could also have the QUEEN role check the final budget of the prince to make sure it isn't too high.

```python
# Role is functionally equivalent to VirtualWorker but it's purpose is to define what someone WILL do when they fill this role.
# This might allow us to skip calling ""hook.local_worker.is_client_worker"" which would be nice.

king = sy.Role(id=""king"") 
queen = sy.Role(id=""queen"")
prince = sy.Role(id=""prince"")

@sy.func2plan(args_shape=[(1,)], worker=king)
def add_kings_gold(kings_gold, kings_silver):
    ptr = (kings_gold + kings_silver).send(prince, id=""kings bank balance"", garbage_collect=False)
    return True

@sy.func2plan(args_shape=[(1,)], worker=queen)
def queen_ops(queens_gold, queens_silver):
    (queens_gold + queens_silver).send(prince, id=""queens bank balance"", garbage_collect=False)
    return True

@sy.func2plan(args_shape=[(1,)], worker=prince)
def prince_ops(princes_gold, princes_silver):
    
    king_balance = sy.BlockForTensor(""kings bank balance"")
    queen_balance = sy.BlockForTensor(""queens bank balance"")
    
    if(king_balance > queen_balance):
        balance = king_balance + princes_gold + princes_silver
    else:
        balance = queen_balance + princes_gold + princes_silver

    balance.send(queen, id=""princes budget"", garbage_collect=False)
    
    return balance

@sy.func2plan(args_shape=[(1,)], worker=queen)
def more_queen_ops(queens_gold, queens_silver):
    budget = sy.BlockForTensor(""princes budget"")
    if(budget > 10000):
        return Exception(""this is way too much money for a field trip"")
    else:
        # Prince doesn't have too much money
    
protocol = sy.Protocol(king_ops, queen_ops, prince_ops, more_queen_ops)

george = sy.VirtualWorker(hook, id=""King George II"")
elizabeth = sy.VirtualWorker(hook, id=""Queen Elizabeth III"")
charlie = sy.VirtualWorker(hook, id=""Prince Charlie"")

protocol.deploy(king=geroge, queen=elizabeth, prince=charlie)
```

Note that this doesn't require editing the protocol.deploy method at all.",alternatively could also queen role check final budget prince make sure high python role functionally equivalent purpose define someone fill role might allow u skip calling would nice king king queen queen prince prince prince bank balance return true prince bank balance return true bank balance bank balance balance else balance queen budget return balance budget budget budget return exception way much money field trip else prince much money protocol hook king hook queen hook prince note require method,issue,positive,positive,positive,positive,positive,positive
544483335,"Chatting with @Jasopaum offline - I put together an example for how we might initialize this and a use case.

Story: Let's say that cute little Prince Charles wants to know whether to ask his mommy or his daddy for money to go to the store (but not both... for some reason). So, he wants to execute a protocol wherein he compares how much gold and silver his mom and dad have, and then whichever is greater he will ask. 

The resulting sum between his gold and silver and his richer parent's gold and silver will be his budget for the store! This will be the final output of the protocol.

```python
# Role is functionally equivalent to VirtualWorker but it's purpose is to define what someone WILL do when they fill this role.
# This might allow us to skip calling ""hook.local_worker.is_client_worker"" which would be nice.

king = sy.Role(id=""king"") 
queen = sy.Role(id=""queen"")
prince = sy.Role(id=""prince"")

@sy.func2plan(args_shape=[(1,)], worker=king)
def add_kings_gold(kings_gold, kings_silver):
    ptr = (kings_gold + kings_silver).send(prince, id=""kings bank balance"", garbage_collect=False)
    return True

@sy.func2plan(args_shape=[(1,)], worker=queen)
def queen_ops(queens_gold, queens_silver):
    (queens_gold + queens_silver).send(prince, id=""queens bank balance"", garbage_collect=False)
    return True

@sy.func2plan(args_shape=[(1,)], worker=prince)
def prince_ops(princes_gold, princes_silver):
    
    king_balance = sy.BlockForTensor(""kings bank balance"")
    queen_balance = sy.BlockForTensor(""queens bank balance"")
    
    if(king_balance > queen_balance):
        return king_balance + princes_gold + princes_silver
    else:
        return queen_balance + princes_gold + princes_silver

protocol = sy.Protocol(king_ops, queen_ops, prince_ops)

george = sy.VirtualWorker(hook, id=""King George II"")
elizabeth = sy.VirtualWorker(hook, id=""Queen Elizabeth III"")
charlie = sy.VirtualWorker(hook, id=""Prince Charlie"")

protocol.deploy(king=george, queen=elizabeth, prince=charlie)
```",chatting put together example might initialize use case story let say cute little prince know whether ask mommy daddy money go store reason execute protocol wherein much gold silver dad whichever greater ask resulting sum gold silver parent gold silver budget store final output protocol python role functionally equivalent purpose define someone fill role might allow u skip calling would nice king king queen queen prince prince prince bank balance return true prince bank balance return true bank balance bank balance return else return protocol hook king hook queen hook prince,issue,positive,positive,positive,positive,positive,positive
544473856,"I think we'd need to have at least some operations for every call, at the
very least to know what kinds of permissions to give the result tensor, no?

On Sat, Oct 19, 2019 at 4:16 PM Robert (Bobby) Wagner <
notifications@github.com> wrote:

> I think this is a great way to address this problem. We should probably
> use these trust levels at tensor creation time to avoid having to check
> them for every call (since that changes protocols). In practice it is just
> changing a default
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/2681?email_source=notifications&email_token=ABBAZESNCNBFH3SBHYZKDBDQPMQEPA5CNFSM4JCQE4PKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEBXTGBQ#issuecomment-544158470>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ABBAZERZQB4FSXQMETQDUQ3QPMQEPANCNFSM4JCQE4PA>
> .
>
",think need least every call least know give result tensor sat bobby wrote think great way address problem probably use trust tensor creation time avoid check every call since practice default thread reply directly view,issue,positive,positive,neutral,neutral,positive,positive
544471022,"@Jasopaum - I disagree that we should be specifying the order in which the plans should execute. Instead, the plans should execute as fast as possible in an asynchronous manner, only pausing to wait for a tensor from another plan if necessary. I do support the idea that one worker could have multiple plans, but this would lead me to believe that it should be a dictionary of lists.

The main value proposition of a Protocol is to have plans which can execute asynchronously on multiple workers. Otherwise, Protocol is just a plan of plans (which we already can do with normal plans). 

I also noticed in our tutorial that we assume that the output of the first plan is the input to the second plan. This seems to deviate from the above intuition as well. Instead, a plan should support the ability to call .send() to a worker and that worker would (presumably) have a plan waiting to execute when a tensor with that specific ID shows up.",disagree order execute instead execute fast possible asynchronous manner wait tensor another plan necessary support idea one worker could multiple would lead believe dictionary main value proposition protocol execute multiple otherwise protocol plan already normal also tutorial assume output first plan input second plan deviate intuition well instead plan support ability call worker worker would presumably plan waiting execute tensor specific id,issue,positive,positive,neutral,neutral,positive,positive
544469585,"pysyft 0.1.26a
tensorflow 1.13.2
tf_encrypted 0.5.8
It is OK!!!

running pytest
Searching for pytest-flake8
Reading https://pypi.org/simple/pytest-flake8/
Downloading https://files.pythonhosted.org/packages/4b/99/a6e993c0927665522602058e1f2ea61ba1c8c51a60e3006f1eb1153b37e2/pytest_flake8-1.0.4-py2.py3-none-any.whl#sha256=d7e2b6b274a255b7ae35e9224c85294b471a83b76ecb6bd53c337ae977a499af
Best match: pytest-flake8 1.0.4
Processing pytest_flake8-1.0.4-py2.py3-none-any.whl
Installing pytest_flake8-1.0.4-py2.py3-none-any.whl to /mnt/pysyft/.eggs
writing requirements to /mnt/pysyft/.eggs/pytest_flake8-1.0.4-py3.6.egg/EGG-INFO/requires.txt

Installed /mnt/pysyft/.eggs/pytest_flake8-1.0.4-py3.6.egg
Searching for flake8>=3.5
Reading https://pypi.org/simple/flake8/
Downloading https://files.pythonhosted.org/packages/26/de/3f815a99d86eb10464ea7bd6059c0172c7ca97d4bdcfca41051b388a653b/flake8-3.7.8-py2.py3-none-any.whl#sha256=8e9dfa3cecb2400b3738a42c54c3043e821682b9c840b0448c0503f781130696
Best match: flake8 3.7.8
Processing flake8-3.7.8-py2.py3-none-any.whl
Installing flake8-3.7.8-py2.py3-none-any.whl to /mnt/pysyft/.eggs
writing requirements to /mnt/pysyft/.eggs/flake8-3.7.8-py3.6.egg/EGG-INFO/requires.txt

Installed /mnt/pysyft/.eggs/flake8-3.7.8-py3.6.egg
Searching for pyflakes<2.2.0,>=2.1.0
Reading https://pypi.org/simple/pyflakes/
Downloading https://files.pythonhosted.org/packages/84/f2/ed0ffb887f8138a8fe5a621b8c0bb9598bfb3989e029f6c6a85ee66628ee/pyflakes-2.1.1-py2.py3-none-any.whl#sha256=17dbeb2e3f4d772725c777fabc446d5634d1038f234e77343108ce445ea69ce0
Best match: pyflakes 2.1.1
Processing pyflakes-2.1.1-py2.py3-none-any.whl
Installing pyflakes-2.1.1-py2.py3-none-any.whl to /mnt/pysyft/.eggs

Installed /mnt/pysyft/.eggs/pyflakes-2.1.1-py3.6.egg
Searching for pycodestyle<2.6.0,>=2.5.0
Reading https://pypi.org/simple/pycodestyle/
Downloading https://files.pythonhosted.org/packages/0e/0c/04a353e104d2f324f8ee5f4b32012618c1c86dd79e52a433b64fceed511b/pycodestyle-2.5.0-py2.py3-none-any.whl#sha256=95a2219d12372f05704562a14ec30bc76b05a5b297b21a5dfe3f6fac3491ae56
Best match: pycodestyle 2.5.0
Processing pycodestyle-2.5.0-py2.py3-none-any.whl
Installing pycodestyle-2.5.0-py2.py3-none-any.whl to /mnt/pysyft/.eggs

Installed /mnt/pysyft/.eggs/pycodestyle-2.5.0-py3.6.egg
Searching for entrypoints<0.4.0,>=0.3.0
Reading https://pypi.org/simple/entrypoints/
Downloading https://files.pythonhosted.org/packages/ac/c6/44694103f8c221443ee6b0041f69e2740d89a25641e62fb4f2ee568f2f9c/entrypoints-0.3-py2.py3-none-any.whl#sha256=589f874b313739ad35be6e0cd7efde2a4e9b6fea91edcc34e58ecbb8dbe56d19
Best match: entrypoints 0.3
Processing entrypoints-0.3-py2.py3-none-any.whl
Installing entrypoints-0.3-py2.py3-none-any.whl to /mnt/pysyft/.eggs
writing requirements to /mnt/pysyft/.eggs/entrypoints-0.3-py3.6.egg/EGG-INFO/requires.txt

Installed /mnt/pysyft/.eggs/entrypoints-0.3-py3.6.egg
running egg_info
writing syft.egg-info/PKG-INFO
writing dependency_links to syft.egg-info/dependency_links.txt
writing requirements to syft.egg-info/requires.txt
writing top-level names to syft.egg-info/top_level.txt
reading manifest file 'syft.egg-info/SOURCES.txt'
writing manifest file 'syft.egg-info/SOURCES.txt'
running build_ext
============================================================ test session starts =============================================================
platform linux -- Python 3.6.8, pytest-5.2.1, py-1.8.0, pluggy-0.13.0 -- /usr/bin/python3
cachedir: .pytest_cache
rootdir: /mnt/pysyft, inifile: setup.cfg
plugins: flake8-1.0.4
collected 463 items                                                                                                                          

test/test_dependency_check.py::test_tensorflow_available SKIPPED                                                                       [  0%]
test/test_dependency_check.py::test_tf_encrypted_available PASSED                                                                      [  0%]
test/test_dependency_check.py::test_torch_available PASSED                                                                             [  0%]
test/test_dependency_check.py::test_tensorflow_missing PASSED                                                                          [  0%]
test/test_dependency_check.py::test_tf_encrypted_missing PASSED                                                                        [  1%]
test/test_exceptions.py::test_tensors_not_collated_exception PASSED                                                                    [  1%]
test/test_grid.py::test_virtual_grid PASSED                                                                                            [  1%]
test/test_local_worker.py::test_is_client_true PASSED                                                                                  [  1%]
test/test_local_worker.py::test_is_client_false PASSED                                                                                 [  1%]
test/test_local_worker.py::test_in_known_workers PASSED                                                                                [  2%]
test/test_sandbox.py::test_sandbox PASSED                                                                                              [  2%]
test/test_serde.py::test_tuple_simplify PASSED                                                                                         [  2%]
test/test_serde.py::test_list_simplify PASSED                                                                                          [  2%]
test/test_serde.py::test_set_simplify PASSED                                                                                           [  3%]
test/test_serde.py::test_float_simplify PASSED                                                                                         [  3%]
test/test_serde.py::test_int_simplify PASSED                                                                                           [  3%]
test/test_serde.py::test_string_simplify PASSED                                                                                        [  3%]
test/test_serde.py::test_dict_simplify PASSED                                                                                          [  3%]
test/test_serde.py::test_range_simplify PASSED                                                                                         [  4%]
test/test_serde.py::test_torch_tensor_simplify PASSED                                                                                  [  4%]
test/test_serde.py::test_ndarray_simplify PASSED                                                                                       [  4%]
test/test_serde.py::test_ellipsis_simplify PASSED                                                                                      [  4%]
test/test_serde.py::test_torch_device_simplify PASSED                                                                                  [  4%]
test/test_serde.py::test_pointer_tensor_simplify PASSED                                                                                [  5%]
test/test_serde.py::test_torch_Tensor[True] PASSED                                                                                     [  5%]
test/test_serde.py::test_torch_Tensor[False] PASSED                                                                                    [  5%]
test/test_serde.py::test_torch_Tensor_convenience[True] PASSED                                                                         [  5%]
test/test_serde.py::test_torch_Tensor_convenience[False] PASSED                                                                        [  6%]
test/test_serde.py::test_tuple[True] PASSED                                                                                            [  6%]
test/test_serde.py::test_tuple[False] PASSED                                                                                           [  6%]
test/test_serde.py::test_bytearray[True] PASSED                                                                                        [  6%]
test/test_serde.py::test_bytearray[False] PASSED                                                                                       [  6%]
test/test_serde.py::test_ndarray_serde[True] PASSED                                                                                    [  7%]
test/test_serde.py::test_ndarray_serde[False] PASSED                                                                                   [  7%]
test/test_serde.py::test_compress_decompress[41] PASSED                                                                                [  7%]
test/test_serde.py::test_compress_decompress[42] PASSED                                                                                [  7%]
test/test_serde.py::test_compress_decompress[40] PASSED                                                                                [  7%]
test/test_serde.py::test_compressed_serde[41] PASSED                                                                                   [  8%]
test/test_serde.py::test_compressed_serde[42] PASSED                                                                                   [  8%]
test/test_serde.py::test_compressed_serde[40] PASSED                                                                                   [  8%]
test/test_serde.py::test_dict[True] PASSED                                                                                             [  8%]
test/test_serde.py::test_dict[False] PASSED                                                                                            [  9%]
test/test_serde.py::test_range_serde[True] PASSED                                                                                      [  9%]
test/test_serde.py::test_range_serde[False] PASSED                                                                                     [  9%]
test/test_serde.py::test_list[True] PASSED                                                                                             [  9%]
test/test_serde.py::test_list[False] PASSED                                                                                            [  9%]
test/test_serde.py::test_set[True] PASSED                                                                                              [ 10%]
test/test_serde.py::test_set[False] PASSED                                                                                             [ 10%]
test/test_serde.py::test_slice[True] PASSED                                                                                            [ 10%]
test/test_serde.py::test_slice[False] PASSED                                                                                           [ 10%]
test/test_serde.py::test_float[True] PASSED                                                                                            [ 11%]
test/test_serde.py::test_float[False] PASSED                                                                                           [ 11%]
test/test_serde.py::test_hooked_tensor[True-41] PASSED                                                                                 [ 11%]
test/test_serde.py::test_hooked_tensor[False-41] PASSED                                                                                [ 11%]
test/test_serde.py::test_hooked_tensor[True-42] PASSED                                                                                 [ 11%]
test/test_serde.py::test_hooked_tensor[False-42] PASSED                                                                                [ 12%]
test/test_serde.py::test_hooked_tensor[True-40] PASSED                                                                                 [ 12%]
test/test_serde.py::test_hooked_tensor[False-40] PASSED                                                                                [ 12%]
test/test_serde.py::test_pointer_tensor PASSED                                                                                         [ 12%]
test/test_serde.py::test_pointer_tensor_detail[10000] PASSED                                                                           [ 12%]
test/test_serde.py::test_pointer_tensor_detail[10001] PASSED                                                                           [ 13%]
test/test_serde.py::test_numpy_tensor_serde PASSED                                                                                     [ 13%]
test/test_serde.py::test_additive_sharing_tensor_serde[True] PASSED                                                                    [ 13%]
test/test_serde.py::test_additive_sharing_tensor_serde[False] PASSED                                                                   [ 13%]
test/test_serde.py::test_fixed_precision_tensor_serde[True] PASSED                                                                     [ 14%]
test/test_serde.py::test_fixed_precision_tensor_serde[False] PASSED                                                                    [ 14%]
test/test_serde.py::test_serde_object_wrapper_int PASSED                                                                               [ 14%]
test/test_serde.py::test_serialize_and_deserialize_torch_scriptmodule SKIPPED                                                          [ 14%]
test/test_serde.py::test_torch_jit_script_module_serde SKIPPED                                                                         [ 14%]
test/test_serde.py::test_serde_virtual_worker PASSED                                                                                   [ 15%]
test/test_serde.py::test_full_serde_virtual_worker PASSED                                                                              [ 15%]
test/test_serde.py::test_serde_object_wrapper_traced_module PASSED                                                                     [ 15%]
test/test_serde.py::test_no_simplifier_found PASSED                                                                                    [ 15%]
test/test_udacity.py::test_section_1_differential_privacy PASSED                                                                       [ 15%]
test/test_udacity.py::test_section_2_federated_learning PASSED                                                                         [ 16%]
test/test_udacity.py::test_section_3_securing_fl PASSED                                                                                [ 16%]
test/federated/test_federated_client.py::test_add_dataset PASSED                                                                       [ 16%]
test/federated/test_federated_client.py::test_add_dataset_with_duplicate_key PASSED                                                    [ 16%]
test/federated/test_federated_client.py::test_remove_dataset PASSED                                                                    [ 17%]
test/federated/test_federated_client.py::test_set_obj_train_config PASSED                                                              [ 17%]
test/federated/test_federated_client.py::test_set_obj_other PASSED                                                                     [ 17%]
test/federated/test_federated_client.py::test_fit[gaussian_mixture-1] PASSED                                                           [ 17%]
test/federated/test_federated_client.py::test_fit[gaussian_mixture-10] PASSED                                                          [ 17%]
test/federated/test_federated_client.py::test_fit[another_dataset-1] PASSED                                                            [ 18%]
test/federated/test_federated_client.py::test_evaluate SKIPPED                                                                         [ 18%]
test/federated/test_train_config.py::test_train_config_with_jit_script_module SKIPPED                                                  [ 18%]
test/federated/test_train_config.py::test_train_config_with_jit_trace SKIPPED                                                          [ 18%]
test/federated/test_train_config.py::test_train_config_with_jit_trace_send_twice_with_fit SKIPPED                                      [ 19%]
test/federated/test_train_config.py::test___str__ PASSED                                                                               [ 19%]
test/federated/test_train_config.py::test_send PASSED                                                                                  [ 19%]
test/federated/test_train_config.py::test_send_model_and_loss_fn PASSED                                                                [ 19%]
test/federated/test_train_config.py::test_train_config_with_jit_trace_async SKIPPED                                                    [ 19%]
test/federated/test_train_config.py::test_train_config_with_jit_trace_sync SKIPPED                                                     [ 20%]
test/generic/test_id_provider.py::test_pop_no_given_ids PASSED                                                                         [ 20%]
test/generic/test_id_provider.py::test_pop_with_given_ids PASSED                                                                       [ 20%]
test/generic/test_id_provider.py::test_given_ids_side_effect PASSED                                                                    [ 20%]
test/generic/test_id_provider.py::test_set_next_ids PASSED                                                                             [ 20%]
test/generic/test_id_provider.py::test_set_next_ids_with_id_checking PASSED                                                            [ 21%]
test/generic/test_id_provider.py::test_start_recording_ids PASSED                                                                      [ 21%]
test/generic/test_id_provider.py::test_get_recorded_ids PASSED                                                                         [ 21%]
test/generic/test_object_storage.py::test_clear_objects PASSED                                                                         [ 21%]
test/generic/test_object_storage.py::test_clear_objects_return_None PASSED                                                             [ 22%]
test/integration/test_rnn.py::test_rnn_mpc[lstm] PASSED                                                                                [ 22%]
test/integration/test_rnn.py::test_rnn_mpc[gru] PASSED                                                                                 [ 22%]
test/integration/test_rnn.py::test_rnn_mpc[rnn_tanh] PASSED                                                                            [ 22%]
test/integration/test_rnn.py::test_rnn_mpc[rnn_relu] PASSED                                                                            [ 22%]
test/integration/test_rnn.py::test_rnn_federated[lstm] PASSED                                                                          [ 23%]
test/integration/test_rnn.py::test_rnn_federated[gru] PASSED                                                                           [ 23%]
test/integration/test_rnn.py::test_rnn_federated[rnn_tanh] PASSED                                                                      [ 23%]
test/integration/test_rnn.py::test_rnn_federated[rnn_relu] PASSED                                                                      [ 23%]
test/keras/test_sequential.py::test_instantiate_tfe_layer PASSED                                                                       [ 23%]
test/keras/test_sequential.py::test_share PASSED                                                                                       [ 24%]
test/message/test_message.py::test_message_serde PASSED                                                                                [ 24%]
test/message/test_message.py::test_cmd_message PASSED                                                                                  [ 24%]
test/message/test_message.py::test_obj_message PASSED                                                                                  [ 24%]
test/message/test_message.py::test_obj_req_message PASSED                                                                              [ 25%]
test/message/test_message.py::test_get_shape_message PASSED                                                                            [ 25%]
test/message/test_message.py::test_force_object_delete_message PASSED                                                                  [ 25%]
test/message/test_message.py::test_is_none_message PASSED                                                                              [ 25%]
test/message/test_message.py::test_search_message_serde PASSED                                                                         [ 25%]
test/message/test_plan.py::test_plan_built_automatically PASSED                                                                        [ 26%]
test/message/test_plan.py::test_stateful_plan_built_automatically PASSED                                                               [ 26%]
test/message/test_plan.py::test_plan_build PASSED                                                                                      [ 26%]
test/message/test_plan.py::test_stateful_plan_build PASSED                                                                             [ 26%]
test/message/test_plan.py::test_plan_built_automatically_with_any_dimension PASSED                                                     [ 26%]
test/message/test_plan.py::test_raise_exception_for_invalid_shape PASSED                                                               [ 27%]
test/message/test_plan.py::test_raise_exception_when_sending_unbuilt_plan PASSED                                                       [ 27%]
test/message/test_plan.py::test_plan_execute_locally PASSED                                                                            [ 27%]
test/message/test_plan.py::test_add_to_state PASSED                                                                                    [ 27%]
test/message/test_plan.py::test_plan_method_execute_locally PASSED                                                                     [ 28%]
test/message/test_plan.py::test_stateful_plan_method_execute_locally PASSED                                                            [ 28%]
test/message/test_plan.py::test_plan_multiple_send PASSED                                                                              [ 28%]
test/message/test_plan.py::test_stateful_plan_multiple_send PASSED                                                                     [ 28%]
test/message/test_plan.py::test_plan_built_on_class PASSED                                                                             [ 28%]
test/message/test_plan.py::test_multiple_workers PASSED                                                                                [ 29%]
test/message/test_plan.py::test_stateful_plan_multiple_workers PASSED                                                                  [ 29%]
test/message/test_plan.py::test_fetch_plan PASSED                                                                                      [ 29%]
test/message/test_plan.py::test_plan_serde PASSED                                                                                      [ 29%]
test/message/test_plan.py::test_execute_plan_remotely PASSED                                                                           [ 30%]
test/message/test_plan.py::test_execute_plan_module_remotely PASSED                                                                    [ 30%]
test/message/test_plan.py::test_train_plan_locally_and_then_send_it PASSED                                                             [ 30%]
test/message/test_plan.py::test_replace_worker_ids_two_strings PASSED                                                                  [ 30%]
test/message/test_plan.py::test_replace_worker_ids_one_string_one_int PASSED                                                           [ 30%]
test/message/test_plan.py::test_replace_worker_ids_two_ints PASSED                                                                     [ 31%]
test/message/test_plan.py::test__replace_message_ids PASSED                                                                            [ 31%]
test/message/test_plan.py::test_send_with_plan PASSED                                                                                  [ 31%]
test/torch/test_federated_learning.py::TestFederatedLearning::test_toy_federated_learning PASSED                                       [ 31%]
test/torch/test_federated_learning.py::test_lstm PASSED                                                                                [ 31%]
test/torch/test_functions.py::test_combine_pointers PASSED                                                                             [ 32%]
test/torch/test_hook.py::test___init__ PASSED                                                                                          [ 32%]
test/torch/test_hook.py::test_torch_attributes PASSED                                                                                  [ 32%]
test/torch/test_hook.py::test_worker_registration PASSED                                                                               [ 32%]
test/torch/test_hook.py::test_pointer_found_exception PASSED                                                                           [ 33%]
test/torch/test_hook.py::test_build_get_child_type PASSED                                                                              [ 33%]
test/torch/test_hook.py::test_get_pointer_unary_method[abs] PASSED                                                                     [ 33%]
test/torch/test_hook.py::test_get_pointer_binary_method[add] PASSED                                                                    [ 33%]
test/torch/test_hook.py::test_get_pointer_binary_method[mul] PASSED                                                                    [ 33%]
test/torch/test_hook.py::test_get_pointer_to_pointer_unary_method[abs] PASSED                                                          [ 34%]
test/torch/test_hook.py::test_get_pointer_to_pointer_binary_method[add] PASSED                                                         [ 34%]
test/torch/test_hook.py::test_get_pointer_to_pointer_binary_method[mul] PASSED                                                         [ 34%]
test/torch/test_hook.py::test_hook_module_functional[relu] PASSED                                                                      [ 34%]
test/torch/test_hook.py::test_hook_module_functional[celu] PASSED                                                                      [ 34%]
test/torch/test_hook.py::test_hook_module_functional[elu] PASSED                                                                       [ 35%]
test/torch/test_hook.py::test_functional_same_in_both_imports[relu] PASSED                                                             [ 35%]
test/torch/test_hook.py::test_functional_same_in_both_imports[celu] PASSED                                                             [ 35%]
test/torch/test_hook.py::test_functional_same_in_both_imports[elu] PASSED                                                              [ 35%]
test/torch/test_hook.py::test_hook_tensor PASSED                                                                                       [ 36%]
test/torch/test_hook.py::test_properties PASSED                                                                                        [ 36%]
test/torch/test_hook.py::test_signature_cache_change PASSED                                                                            [ 36%]
test/torch/test_hook.py::test_parameter_hooking PASSED                                                                                 [ 36%]
test/torch/test_hook.py::test_torch_module_hook PASSED                                                                                 [ 36%]
test/torch/test_hook.py::test_functional_hook PASSED                                                                                   [ 37%]
test/torch/test_hook.py::test_hook_args_and_cmd_signature_malleability PASSED                                                          [ 37%]
test/torch/test_hook.py::test_torch_func_signature_without_tensor PASSED                                                               [ 37%]
test/torch/test_hook.py::test_RNN_grad_set_backpropagation PASSED                                                                      [ 37%]
test/torch/test_hook.py::test_local_remote_gradient_clipping PASSED                                                                    [ 38%]
test/torch/test_hook.py::test_remote_gradient_clipping PASSED                                                                          [ 38%]
test/torch/test_hook.py::test_local_gradient_clipping PASSED                                                                           [ 38%]
test/torch/crypto/test_snn.py::test_xor_implementation PASSED                                                                          [ 38%]
test/torch/crypto/test_snn.py::test_private_compare PASSED                                                                             [ 38%]
test/torch/crypto/test_snn.py::test_share_convert PASSED                                                                               [ 39%]
test/torch/crypto/test_snn.py::test_relu_deriv PASSED                                                                                  [ 39%]
test/torch/crypto/test_snn.py::test_relu PASSED                                                                                        [ 39%]
test/torch/crypto/test_snn.py::test_division PASSED                                                                                    [ 39%]
test/torch/crypto/test_snn.py::test_maxpool PASSED                                                                                     [ 39%]
test/torch/crypto/test_snn.py::test_maxpool_deriv PASSED                                                                               [ 40%]
test/torch/differential_privacy/test_pate.py::test_base_dataset PASSED                                                                 [ 40%]
test/torch/differential_privacy/test_pate.py::test_base_dataset_torch PASSED                                                           [ 40%]
test/torch/differential_privacy/test_pate.py::test_torch_ref_match PASSED                                                              [ 40%]
test/torch/federated/test_dataloader.py::test_federated_dataloader PASSED                                                              [ 41%]
test/torch/federated/test_dataloader.py::test_federated_dataloader_shuffle PASSED                                                      [ 41%]
test/torch/federated/test_dataloader.py::test_federated_dataloader_num_iterators PASSED                                                [ 41%]
test/torch/federated/test_dataloader.py::test_federated_dataloader_iter_per_worker PASSED                                              [ 41%]
test/torch/federated/test_dataloader.py::test_federated_dataloader_one_worker PASSED                                                   [ 41%]
test/torch/federated/test_dataset.py::test_base_dataset PASSED                                                                         [ 42%]
test/torch/federated/test_dataset.py::test_base_dataset_transform PASSED                                                               [ 42%]
test/torch/federated/test_dataset.py::test_federated_dataset PASSED                                                                    [ 42%]
test/torch/federated/test_dataset.py::test_dataset_to_federate PASSED                                                                  [ 42%]
test/torch/federated/test_dataset.py::test_federated_dataset_search PASSED                                                             [ 42%]
test/torch/federated/test_utils.py::test_extract_batches_per_worker PASSED                                                             [ 43%]
test/torch/federated/test_utils.py::test_add_model PASSED                                                                              [ 43%]
test/torch/federated/test_utils.py::test_scale_model PASSED                                                                            [ 43%]
test/torch/federated/test_utils.py::test_accuracy PASSED                                                                               [ 43%]
test/torch/hook/test_hook_args.py::test_build_rule_syft_tensors_and_pointers PASSED                                                    [ 44%]
test/torch/hook/test_hook_args.py::test_build_rule_numpy PASSED                                                                        [ 44%]
test/torch/linalg/test_linalg.py::test_inv_sym PASSED                                                                                  [ 44%]
test/torch/pointers/test_callable_pointer.py::test_create_callable_pointer PASSED                                                      [ 44%]
test/torch/pointers/test_callable_pointer.py::test_get_obj_callable_pointer PASSED                                                     [ 44%]
test/torch/pointers/test_callable_pointer.py::test_call_callable_pointer PASSED                                                        [ 45%]
test/torch/pointers/test_pointer_tensor.py::test_init PASSED                                                                           [ 45%]
test/torch/pointers/test_pointer_tensor.py::test_create_pointer PASSED                                                                 [ 45%]
test/torch/pointers/test_pointer_tensor.py::test_send_default_garbage_collector_true PASSED                                            [ 45%]
test/torch/pointers/test_pointer_tensor.py::test_send_garbage_collect_data_false PASSED                                                [ 46%]
test/torch/pointers/test_pointer_tensor.py::test_send_gc_false PASSED                                                                  [ 46%]
test/torch/pointers/test_pointer_tensor.py::test_send_gc_true PASSED                                                                   [ 46%]
test/torch/pointers/test_pointer_tensor.py::test_send_disable_gc PASSED                                                                [ 46%]
test/torch/pointers/test_pointer_tensor.py::test_send_get PASSED                                                                       [ 46%]
test/torch/pointers/test_pointer_tensor.py::test_inplace_send_get PASSED                                                               [ 47%]
test/torch/pointers/test_pointer_tensor.py::test_repeated_send PASSED                                                                  [ 47%]
test/torch/pointers/test_pointer_tensor.py::test_remote_autograd PASSED                                                                [ 47%]
test/torch/pointers/test_pointer_tensor.py::test_gradient_send_recv PASSED                                                             [ 47%]
test/torch/pointers/test_pointer_tensor.py::test_method_on_attribute PASSED                                                            [ 47%]
test/torch/pointers/test_pointer_tensor.py::test_grad_pointer PASSED                                                                   [ 48%]
test/torch/pointers/test_pointer_tensor.py::test_move PASSED                                                                           [ 48%]
test/torch/pointers/test_pointer_tensor.py::test_combine_pointers PASSED                                                               [ 48%]
test/torch/pointers/test_pointer_tensor.py::test_remote_to_cpu_device PASSED                                                           [ 48%]
test/torch/pointers/test_pointer_tensor.py::test_get_remote_shape PASSED                                                               [ 49%]
test/torch/pointers/test_pointer_tensor.py::test_remote_function_with_multi_ouput PASSED                                               [ 49%]
test/torch/pointers/test_pointer_tensor.py::test_raising_error_when_item_func_called PASSED                                            [ 49%]
test/torch/tensors/test_additive_shared.py::test_wrap PASSED                                                                           [ 49%]
test/torch/tensors/test_additive_shared.py::test__str__ PASSED                                                                         [ 49%]
test/torch/tensors/test_additive_shared.py::test_encode_decode PASSED                                                                  [ 50%]
test/torch/tensors/test_additive_shared.py::test_virtual_get PASSED                                                                    [ 50%]
test/torch/tensors/test_additive_shared.py::test_autograd_kwarg PASSED                                                                 [ 50%]
test/torch/tensors/test_additive_shared.py::test_send_get PASSED                                                                       [ 50%]
test/torch/tensors/test_additive_shared.py::test_add PASSED                                                                            [ 50%]
test/torch/tensors/test_additive_shared.py::test_sub PASSED                                                                            [ 51%]
test/torch/tensors/test_additive_shared.py::test_mul PASSED                                                                            [ 51%]
test/torch/tensors/test_additive_shared.py::test_public_mul PASSED                                                                     [ 51%]
test/torch/tensors/test_additive_shared.py::test_div PASSED                                                                            [ 51%]
test/torch/tensors/test_additive_shared.py::test_pow PASSED                                                                            [ 52%]
test/torch/tensors/test_additive_shared.py::test_operate_with_integer_constants PASSED                                                 [ 52%]
test/torch/tensors/test_additive_shared.py::test_stack PASSED                                                                          [ 52%]
test/torch/tensors/test_additive_shared.py::test_cat PASSED                                                                            [ 52%]
test/torch/tensors/test_additive_shared.py::test_chunk PASSED                                                                          [ 52%]
test/torch/tensors/test_additive_shared.py::test_roll PASSED                                                                           [ 53%]
test/torch/tensors/test_additive_shared.py::test_nn_linear PASSED                                                                      [ 53%]
test/torch/tensors/test_additive_shared.py::test_matmul PASSED                                                                         [ 53%]
test/torch/tensors/test_additive_shared.py::test_mm PASSED                                                                             [ 53%]
test/torch/tensors/test_additive_shared.py::test_torch_conv2d PASSED                                                                   [ 53%]
test/torch/tensors/test_additive_shared.py::test_fixed_precision_and_sharing PASSED                                                    [ 54%]
test/torch/tensors/test_additive_shared.py::test_fixed_precision_and_sharing_on_pointer PASSED                                         [ 54%]
test/torch/tensors/test_additive_shared.py::test_pointer_on_fixed_precision_and_sharing PASSED                                         [ 54%]
test/torch/tensors/test_additive_shared.py::test_get_item PASSED                                                                       [ 54%]
test/torch/tensors/test_additive_shared.py::test_eq PASSED                                                                             [ 55%]
test/torch/tensors/test_additive_shared.py::test_comp PASSED                                                                           [ 55%]
test/torch/tensors/test_additive_shared.py::test_max PASSED                                                                            [ 55%]
test/torch/tensors/test_additive_shared.py::test_argmax PASSED                                                                         [ 55%]
test/torch/tensors/test_additive_shared.py::test_mod PASSED                                                                            [ 55%]
test/torch/tensors/test_additive_shared.py::test_torch_sum PASSED                                                                      [ 56%]
test/torch/tensors/test_additive_shared.py::test_torch_mean PASSED                                                                     [ 56%]
test/torch/tensors/test_additive_shared.py::test_torch_dot PASSED                                                                      [ 56%]
test/torch/tensors/test_additive_shared.py::test_unbind PASSED                                                                         [ 56%]
test/torch/tensors/test_additive_shared.py::test_handle_func_command PASSED                                                            [ 57%]
test/torch/tensors/test_additive_shared.py::test_init_with_no_crypto_provider PASSED                                                   [ 57%]
test/torch/tensors/test_additive_shared.py::test_zero_refresh PASSED                                                                   [ 57%]
test/torch/tensors/test_additive_shared.py::test_cnn_model PASSED                                                                      [ 57%]
test/torch/tensors/test_autograd.py::test_wrap PASSED                                                                                  [ 57%]
test/torch/tensors/test_autograd.py::test_backward_for_binary_cmd_with_autograd[True-__add__] PASSED                                   [ 58%]
test/torch/tensors/test_autograd.py::test_backward_for_binary_cmd_with_autograd[True-__sub__] PASSED                                   [ 58%]
test/torch/tensors/test_autograd.py::test_backward_for_binary_cmd_with_autograd[True-__mul__] PASSED                                   [ 58%]
test/torch/tensors/test_autograd.py::test_backward_for_binary_cmd_with_autograd[True-__matmul__] PASSED                                [ 58%]
test/torch/tensors/test_autograd.py::test_backward_for_binary_cmd_with_autograd[False-__add__] PASSED                                  [ 58%]
test/torch/tensors/test_autograd.py::test_backward_for_binary_cmd_with_autograd[False-__sub__] PASSED                                  [ 59%]
test/torch/tensors/test_autograd.py::test_backward_for_binary_cmd_with_autograd[False-__mul__] PASSED                                  [ 59%]
test/torch/tensors/test_autograd.py::test_backward_for_binary_cmd_with_autograd[False-__matmul__] PASSED                               [ 59%]
test/torch/tensors/test_autograd.py::test_backward_for_inplace_binary_cmd_with_autograd[__iadd__] PASSED                               [ 59%]
test/torch/tensors/test_autograd.py::test_backward_for_inplace_binary_cmd_with_autograd[__isub__] PASSED                               [ 60%]
test/torch/tensors/test_autograd.py::test_backward_for_binary_cmd_with_inputs_of_different_dim_and_autograd[shapes0-__add__] PASSED    [ 60%]
test/torch/tensors/test_autograd.py::test_backward_for_binary_cmd_with_inputs_of_different_dim_and_autograd[shapes0-__sub__] PASSED    [ 60%]
test/torch/tensors/test_autograd.py::test_backward_for_binary_cmd_with_inputs_of_different_dim_and_autograd[shapes1-__add__] PASSED    [ 60%]
test/torch/tensors/test_autograd.py::test_backward_for_binary_cmd_with_inputs_of_different_dim_and_autograd[shapes1-__sub__] PASSED    [ 60%]
test/torch/tensors/test_autograd.py::test_backward_for_binary_cmd_with_inputs_of_different_dim_and_autograd[shapes2-__add__] PASSED    [ 61%]
test/torch/tensors/test_autograd.py::test_backward_for_binary_cmd_with_inputs_of_different_dim_and_autograd[shapes2-__sub__] PASSED    [ 61%]
test/torch/tensors/test_autograd.py::test_backward_for_binary_cmd_with_inputs_of_different_dim_and_autograd[shapes3-__add__] PASSED    [ 61%]
test/torch/tensors/test_autograd.py::test_backward_for_binary_cmd_with_inputs_of_different_dim_and_autograd[shapes3-__sub__] PASSED    [ 61%]
test/torch/tensors/test_autograd.py::test_backward_for_binary_cmd_with_inputs_of_different_dim_and_autograd[shapes4-__add__] PASSED    [ 61%]
test/torch/tensors/test_autograd.py::test_backward_for_binary_cmd_with_inputs_of_different_dim_and_autograd[shapes4-__sub__] PASSED    [ 62%]
test/torch/tensors/test_autograd.py::test_backward_for_remote_binary_cmd_with_autograd[True-__add__] PASSED                            [ 62%]
test/torch/tensors/test_autograd.py::test_backward_for_remote_binary_cmd_with_autograd[True-__mul__] PASSED                            [ 62%]
test/torch/tensors/test_autograd.py::test_backward_for_remote_binary_cmd_with_autograd[True-__matmul__] PASSED                         [ 62%]
test/torch/tensors/test_autograd.py::test_backward_for_remote_binary_cmd_with_autograd[False-__add__] PASSED                           [ 63%]
test/torch/tensors/test_autograd.py::test_backward_for_remote_binary_cmd_with_autograd[False-__mul__] PASSED                           [ 63%]
test/torch/tensors/test_autograd.py::test_backward_for_remote_binary_cmd_with_autograd[False-__matmul__] PASSED                        [ 63%]
test/torch/tensors/test_autograd.py::test_backward_for_remote_inplace_binary_cmd_with_autograd[__iadd__] PASSED                        [ 63%]
test/torch/tensors/test_autograd.py::test_backward_for_remote_inplace_binary_cmd_with_autograd[__isub__] PASSED                        [ 63%]
test/torch/tensors/test_autograd.py::test_backward_for_remote_binary_cmd_local_autograd[__add__] PASSED                                [ 64%]
test/torch/tensors/test_autograd.py::test_backward_for_remote_binary_cmd_local_autograd[__mul__] PASSED                                [ 64%]
test/torch/tensors/test_autograd.py::test_backward_for_remote_binary_cmd_local_autograd[__matmul__] PASSED                             [ 64%]
test/torch/tensors/test_autograd.py::test_backward_for_remote_unary_cmd_local_autograd[sqrt] PASSED                                    [ 64%]
test/torch/tensors/test_autograd.py::test_backward_for_remote_unary_cmd_local_autograd[asin] PASSED                                    [ 65%]
test/torch/tensors/test_autograd.py::test_backward_for_remote_unary_cmd_local_autograd[sin] PASSED                                     [ 65%]
test/torch/tensors/test_autograd.py::test_backward_for_remote_unary_cmd_local_autograd[sinh] PASSED                                    [ 65%]
test/torch/tensors/test_autograd.py::test_backward_for_remote_unary_cmd_local_autograd[tanh] PASSED                                    [ 65%]
test/torch/tensors/test_autograd.py::test_backward_for_remote_unary_cmd_local_autograd[sigmoid] PASSED                                 [ 65%]
test/torch/tensors/test_autograd.py::test_backward_for_fix_prec_binary_cmd_with_autograd[True-__add__] PASSED                          [ 66%]
test/torch/tensors/test_autograd.py::test_backward_for_fix_prec_binary_cmd_with_autograd[True-__mul__] PASSED                          [ 66%]
test/torch/tensors/test_autograd.py::test_backward_for_fix_prec_binary_cmd_with_autograd[True-__matmul__] PASSED                       [ 66%]
test/torch/tensors/test_autograd.py::test_backward_for_fix_prec_binary_cmd_with_autograd[False-__add__] PASSED                         [ 66%]
test/torch/tensors/test_autograd.py::test_backward_for_fix_prec_binary_cmd_with_autograd[False-__mul__] PASSED                         [ 66%]
test/torch/tensors/test_autograd.py::test_backward_for_fix_prec_binary_cmd_with_autograd[False-__matmul__] PASSED                      [ 67%]
test/torch/tensors/test_autograd.py::test_backward_for_linear_model_on_fix_prec_params_with_autograd PASSED                            [ 67%]
test/torch/tensors/test_autograd.py::test_backward_for_additive_shared_binary_cmd_with_autograd[True-__add__] PASSED                   [ 67%]
test/torch/tensors/test_autograd.py::test_backward_for_additive_shared_binary_cmd_with_autograd[True-__mul__] PASSED                   [ 67%]
test/torch/tensors/test_autograd.py::test_backward_for_additive_shared_binary_cmd_with_autograd[True-__matmul__] PASSED                [ 68%]
test/torch/tensors/test_autograd.py::test_backward_for_additive_shared_binary_cmd_with_autograd[False-__add__] PASSED                  [ 68%]
test/torch/tensors/test_autograd.py::test_backward_for_additive_shared_binary_cmd_with_autograd[False-__mul__] PASSED                  [ 68%]
test/torch/tensors/test_autograd.py::test_backward_for_additive_shared_binary_cmd_with_autograd[False-__matmul__] PASSED               [ 68%]
test/torch/tensors/test_autograd.py::test_backward_for_additive_shared_div_with_autograd[True] PASSED                                  [ 68%]
test/torch/tensors/test_autograd.py::test_backward_for_additive_shared_div_with_autograd[False] PASSED                                 [ 69%]
test/torch/tensors/test_autograd.py::test_addmm_backward_for_additive_shared_with_autograd PASSED                                      [ 69%]
test/torch/tensors/test_autograd.py::test_relu_backward_or_additive_shared_with_autograd PASSED                                        [ 69%]
test/torch/tensors/test_autograd.py::test_backward_for_linear_model_on_additive_shared_with_autograd PASSED                            [ 69%]
test/torch/tensors/test_autograd.py::test_remote_share_with_requires_grad PASSED                                                       [ 69%]
test/torch/tensors/test_autograd.py::test_encrypted_training_with_linear_model PASSED                                                  [ 70%]
test/torch/tensors/test_autograd.py::test_get_float_prec_on_autograd_tensor PASSED                                                     [ 70%]
test/torch/tensors/test_autograd.py::test_serialize_deserialize_autograd_tensor PASSED                                                 [ 70%]
test/torch/tensors/test_autograd.py::test_types_auto_remote_tensors PASSED                                                             [ 70%]
test/torch/tensors/test_autograd.py::test_train_remote_autograd_tensor PASSED                                                          [ 71%]
test/torch/tensors/test_crt_precision.py::test__str__ PASSED                                                                           [ 71%]
test/torch/tensors/test_crt_precision.py::test_eq PASSED                                                                               [ 71%]
test/torch/tensors/test_crt_precision.py::test__neg__ PASSED                                                                           [ 71%]
test/torch/tensors/test_crt_precision.py::test_add PASSED                                                                              [ 71%]
test/torch/tensors/test_crt_precision.py::test_sub PASSED                                                                              [ 72%]
test/torch/tensors/test_crt_precision.py::test_mul PASSED                                                                              [ 72%]
test/torch/tensors/test_crt_precision.py::test_send_and_get PASSED                                                                     [ 72%]
test/torch/tensors/test_crt_precision.py::test_share_and_get PASSED                                                                    [ 72%]
test/torch/tensors/test_gc.py::test_explicit_garbage_collect_pointer PASSED                                                            [ 73%]
test/torch/tensors/test_gc.py::test_explicit_garbage_collect_double_pointer PASSED                                                     [ 73%]
test/torch/tensors/test_gc.py::test_implicit_garbage_collection_pointer PASSED                                                         [ 73%]
test/torch/tensors/test_gc.py::test_implicit_garbage_collect_double_pointer PASSED                                                     [ 73%]
test/torch/tensors/test_gc.py::test_inplace_method_on_pointer PASSED                                                                   [ 73%]
test/torch/tensors/test_gc.py::test_explicit_garbage_collect_logging_on_pointer PASSED                                                 [ 74%]
test/torch/tensors/test_gc.py::test_implicit_garbage_collect_logging_on_pointer PASSED                                                 [ 74%]
test/torch/tensors/test_gc.py::test_websocket_garbage_collection PASSED                                                                [ 74%]
test/torch/tensors/test_large_precision.py::test_wrap PASSED                                                                           [ 74%]
test/torch/tensors/test_large_precision.py::test_fix_prec PASSED                                                                       [ 74%]
test/torch/tensors/test_large_precision.py::test_2d_tensors PASSED                                                                     [ 75%]
test/torch/tensors/test_large_precision.py::test_3d_tensors PASSED                                                                     [ 75%]
test/torch/tensors/test_large_precision.py::test_negative_numbers PASSED                                                               [ 75%]
test/torch/tensors/test_large_precision.py::test_add_multiple_dimensions PASSED                                                        [ 75%]
test/torch/tensors/test_large_precision.py::test_add_negative_values PASSED                                                            [ 76%]
test/torch/tensors/test_large_precision.py::test_add PASSED                                                                            [ 76%]
test/torch/tensors/test_large_precision.py::test_iadd PASSED                                                                           [ 76%]
test/torch/tensors/test_large_precision.py::test_add_different_dims PASSED                                                             [ 76%]
test/torch/tensors/test_large_precision.py::test_mul PASSED                                                                            [ 76%]
test/torch/tensors/test_large_precision.py::test_imul PASSED                                                                           [ 77%]
test/torch/tensors/test_large_precision.py::test_mul_multiple_dims PASSED                                                              [ 77%]
test/torch/tensors/test_large_precision.py::test_concat_ops PASSED                                                                     [ 77%]
test/torch/tensors/test_large_precision.py::test_uint8_representation PASSED                                                           [ 77%]
test/torch/tensors/test_large_precision.py::test_sub PASSED                                                                            [ 77%]
test/torch/tensors/test_large_precision.py::test_isub PASSED                                                                           [ 78%]
test/torch/tensors/test_large_precision.py::test_diff_dims_in_same_tensor PASSED                                                       [ 78%]
test/torch/tensors/test_large_precision.py::test_mod PASSED                                                                            [ 78%]
test/torch/tensors/test_large_precision.py::test_types[x0-expected0] PASSED                                                            [ 78%]
test/torch/tensors/test_large_precision.py::test_types[x1-expected1] PASSED                                                            [ 79%]
test/torch/tensors/test_large_precision.py::test_types[x2-expected2] PASSED                                                            [ 79%]
test/torch/tensors/test_large_precision.py::test_types[x3-expected3] PASSED                                                            [ 79%]
test/torch/tensors/test_large_precision.py::test_types[x4-expected4] PASSED                                                            [ 79%]
test/torch/tensors/test_large_precision.py::test_types[x5-expected5] PASSED                                                            [ 79%]
test/torch/tensors/test_large_precision.py::test_types[x6-expected6] PASSED                                                            [ 80%]
test/torch/tensors/test_large_precision.py::test_types[x7-expected7] PASSED                                                            [ 80%]
test/torch/tensors/test_large_precision.py::test_types[x8-expected8] PASSED                                                            [ 80%]
test/torch/tensors/test_large_precision.py::test_types[x9-expected9] PASSED                                                            [ 80%]
test/torch/tensors/test_logging.py::test_wrap PASSED                                                                                   [ 80%]
test/torch/tensors/test_logging.py::test_overwritten_method_on_log_chain PASSED                                                        [ 81%]
test/torch/tensors/test_logging.py::test_method_on_log_chain PASSED                                                                    [ 81%]
test/torch/tensors/test_logging.py::test_hook_module_functional_on_log_chain[relu] PASSED                                              [ 81%]
test/torch/tensors/test_logging.py::test_hook_module_functional_on_log_chain[celu] PASSED                                              [ 81%]
test/torch/tensors/test_logging.py::test_hook_module_functional_on_log_chain[elu] PASSED                                               [ 82%]
test/torch/tensors/test_logging.py::test_function_on_log_chain PASSED                                                                  [ 82%]
test/torch/tensors/test_logging.py::test_send_get_log_chain PASSED                                                                     [ 82%]
test/torch/tensors/test_logging.py::test_inplace_send_get_log_chain PASSED                                                             [ 82%]
test/torch/tensors/test_logging.py::test_remote_method_on_log_chain PASSED                                                             [ 82%]
test/torch/tensors/test_logging.py::test_remote_function_on_log_chain PASSED                                                           [ 83%]
test/torch/tensors/test_logging.py::test_print_log_chain PASSED                                                                        [ 83%]
test/torch/tensors/test_multi_pointer.py::test_multi_pointers PASSED                                                                   [ 83%]
test/torch/tensors/test_multi_pointer.py::test_dim PASSED                                                                              [ 83%]
test/torch/tensors/test_multi_pointer.py::test_simplify PASSED                                                                         [ 84%]
test/torch/tensors/test_native.py::test___str__ PASSED                                                                                 [ 84%]
test/torch/tensors/test_native.py::test___repr__ PASSED                                                                                [ 84%]
test/torch/tensors/test_native.py::test_overload_reshape PASSED                                                                        [ 84%]
test/torch/tensors/test_native.py::test_owner_default PASSED                                                                           [ 84%]
test/torch/tensors/test_native.py::test_create_pointer PASSED                                                                          [ 85%]
test/torch/tensors/test_native.py::test_create_pointer_defaults PASSED                                                                 [ 85%]
test/torch/tensors/test_native.py::test_get PASSED                                                                                     [ 85%]
test/torch/tensors/test_native.py::test_invalid_remote_get PASSED                                                                      [ 85%]
test/torch/tensors/test_native.py::test_remote_get PASSED                                                                              [ 85%]
test/torch/tensors/test_native.py::test_copy PASSED                                                                                    [ 86%]
test/torch/tensors/test_native.py::test_size PASSED                                                                                    [ 86%]
test/torch/tensors/test_native.py::test_dim PASSED                                                                                     [ 86%]
test/torch/tensors/test_native.py::test_does_not_require_large_precision PASSED                                                        [ 86%]
test/torch/tensors/test_native.py::test_requires_large_precision PASSED                                                                [ 87%]
test/torch/tensors/test_native.py::test_roll PASSED                                                                                    [ 87%]
test/torch/tensors/test_parameter.py::test_param_on_pointer PASSED                                                                     [ 87%]
test/torch/tensors/test_parameter.py::test_param_send_get PASSED                                                                       [ 87%]
test/torch/tensors/test_parameter.py::test_param_inplace_send_get PASSED                                                               [ 87%]
test/torch/tensors/test_parameter.py::test_param_double_send_get PASSED                                                                [ 88%]
test/torch/tensors/test_parameter.py::test_param_remote_binary_method PASSED                                                           [ 88%]
test/torch/tensors/test_parameter.py::test_local_param_in_nn_module_linear PASSED                                                      [ 88%]
test/torch/tensors/test_parameter.py::test_remote_param_in_nn_module_linear PASSED                                                     [ 88%]
test/torch/tensors/test_precision.py::test_wrap PASSED                                                                                 [ 88%]
test/torch/tensors/test_precision.py::test_encode_decode[False] PASSED                                                                 [ 89%]
test/torch/tensors/test_precision.py::test_encode_decode[True] PASSED                                                                  [ 89%]
test/torch/tensors/test_precision.py::test_inplace_encode_decode PASSED                                                                [ 89%]
test/torch/tensors/test_precision.py::test_add_method PASSED                                                                           [ 89%]
test/torch/tensors/test_precision.py::test_methods_for_linear_module[False-t] PASSED                                                   [ 90%]
test/torch/tensors/test_precision.py::test_methods_for_linear_module[False-matmul] PASSED                                              [ 90%]
test/torch/tensors/test_precision.py::test_methods_for_linear_module[True-t] PASSED                                                    [ 90%]
test/torch/tensors/test_precision.py::test_methods_for_linear_module[True-matmul] PASSED                                               [ 90%]
test/torch/tensors/test_precision.py::test_torch_add PASSED                                                                            [ 90%]
test/torch/tensors/test_precision.py::test_torch_add_ PASSED                                                                           [ 91%]
test/torch/tensors/test_precision.py::test_torch_sub_ PASSED                                                                           [ 91%]
test/torch/tensors/test_precision.py::test_torch_sub PASSED                                                                            [ 91%]
test/torch/tensors/test_precision.py::test_torch_mul PASSED                                                                            [ 91%]
test/torch/tensors/test_precision.py::test_torch_div PASSED                                                                            [ 92%]
test/torch/tensors/test_precision.py::test_torch_pow PASSED                                                                            [ 92%]
test/torch/tensors/test_precision.py::test_torch_matmul PASSED                                                                         [ 92%]
test/torch/tensors/test_precision.py::test_torch_addmm PASSED                                                                          [ 92%]
test/torch/tensors/test_precision.py::test_torch_dot PASSED                                                                            [ 92%]
test/torch/tensors/test_precision.py::test_torch_conv2d PASSED                                                                         [ 93%]
test/torch/tensors/test_precision.py::test_torch_nn_functional_linear PASSED                                                           [ 93%]
test/torch/tensors/test_precision.py::test_operate_with_integer_constants PASSED                                                       [ 93%]
test/torch/tensors/test_precision.py::test_fixed_precision_and_sharing PASSED                                                          [ 93%]
test/torch/tensors/test_precision.py::test_get_preserves_attributes PASSED                                                             [ 93%]
test/torch/tensors/test_precision.py::test_comp PASSED                                                                                 [ 94%]
test/torch/tensors/test_tensor.py::test_init PASSED                                                                                    [ 94%]
test/torch/tensors/test_variable.py::test_gradient_serde PASSED                                                                        [ 94%]
test/workers/test_base.py::test_create_already_existing_worker PASSED                                                                  [ 94%]
test/workers/test_base.py::test_clear_object_for_worker_created_with_pre_existing_id PASSED                                            [ 95%]
test/workers/test_base.py::test_create_already_existing_worker_with_different_type PASSED                                              [ 95%]
test/workers/test_base.py::test_execute_command_self PASSED                                                                            [ 95%]
test/workers/test_virtual.py::test_send_msg PASSED                                                                                     [ 95%]
test/workers/test_virtual.py::test_send_msg_using_tensor_api PASSED                                                                    [ 95%]
test/workers/test_virtual.py::test_recv_msg PASSED                                                                                     [ 96%]
test/workers/test_virtual.py::tests_worker_convenience_methods PASSED                                                                  [ 96%]
test/workers/test_virtual.py::test_search PASSED                                                                                       [ 96%]
test/workers/test_virtual.py::test_obj_not_found PASSED                                                                                [ 96%]
test/workers/test_virtual.py::test_get_not_permitted PASSED                                                                            [ 96%]
test/workers/test_virtual.py::test_spinup_time PASSED                                                                                  [ 97%]
test/workers/test_virtual.py::test_send_jit_scriptmodule SKIPPED                                                                       [ 97%]
test/workers/test_websocket_worker.py::test_websocket_worker_basic[True] PASSED                                                        [ 97%]
test/workers/test_websocket_worker.py::test_websocket_worker_basic[False] PASSED                                                       [ 97%]
test/workers/test_websocket_worker.py::test_websocket_workers_search PASSED                                                            [ 98%]
test/workers/test_websocket_worker.py::test_list_objects_remote PASSED                                                                 [ 98%]
test/workers/test_websocket_worker.py::test_objects_count_remote PASSED                                                                [ 98%]
test/workers/test_websocket_worker.py::test_clear_objects_remote PASSED                                                                [ 98%]
test/workers/test_websocket_worker.py::test_connect_close PASSED                                                                       [ 98%]
test/workers/test_websocket_worker.py::test_websocket_worker_multiple_output_response PASSED                                           [ 99%]
test/workers/test_websocket_worker.py::test_evaluate SKIPPED                                                                           [ 99%]
test/workers/test_worker.py::test___init__ PASSED                                                                                      [ 99%]
test/workers/test_worker.py::test_get_unknown_worker PASSED                                                                            [ 99%]
test/workers/test_worker.py::test_search PASSED                                                                                        [100%]

============================================================== warnings summary ==============================================================
/usr/local/lib/python3.6/dist-packages/_pytest/mark/structures.py:325
  /usr/local/lib/python3.6/dist-packages/_pytest/mark/structures.py:325: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/latest/mark.html
    PytestUnknownMarkWarning,

test/torch/differential_privacy/test_pate.py::test_base_dataset_torch
test/torch/differential_privacy/test_pate.py::test_torch_ref_match
  /mnt/pysyft/syft/frameworks/torch/hook/hook.py:484: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
    current_tensor = hook_self.torch.native_tensor(*args, **kwargs)

-- Docs: https://docs.pytest.org/en/latest/warnings.html
========================================== 452 passed, 11 skipped, 3 warnings in 142.63s (0:02:22) ===========================================",running searching reading best match writing egg searching flake reading best match flake writing egg searching reading best match egg searching reading best match egg searching reading best match writing egg running writing writing writing writing reading manifest file writing manifest file running test session platform python collected true false true false true false true false true false true false true false true false true false true false true false true false true false add add sin sinh tanh sigmoid true false false true true false summary unknown typo register custom avoid warning see copy construct tensor use true rather,issue,positive,positive,positive,positive,positive,positive
544384652,"platform linux -- Python 3.6.8, pytest-5.2.1, py-1.8.0, pluggy-0.13.0 -- /usr/bin/python3
cachedir: .pytest_cache
rootdir: /mnt/pysyft25, inifile: setup.cfg
plugins: flake8-1.0.4
collected 458 items                                                                                                                          

test/test_dependency_check.py::test_tensorflow_available SKIPPED                                                                       [  0%]
test/test_dependency_check.py::test_tf_encrypted_available PASSED                                                                      [  0%]
test/test_dependency_check.py::test_torch_available PASSED                                                                             [  0%]
test/test_dependency_check.py::test_tensorflow_missing PASSED                                                                          [  0%]
test/test_dependency_check.py::test_tf_encrypted_missing PASSED                                                                        [  1%]
test/test_exceptions.py::test_tensors_not_collated_exception PASSED                                                                    [  1%]
test/test_grid.py::test_virtual_grid PASSED                                                                                            [  1%]
test/test_local_worker.py::test_is_client_true PASSED                                                                                  [  1%]
test/test_local_worker.py::test_is_client_false PASSED                                                                                 [  1%]
test/test_local_worker.py::test_in_known_workers PASSED                                                                                [  2%]
test/test_sandbox.py::test_sandbox PASSED                                                                                              [  2%]
test/test_serde.py::test_tuple_simplify PASSED                                                                                         [  2%]
test/test_serde.py::test_list_simplify PASSED                                                                                          [  2%]
test/test_serde.py::test_set_simplify PASSED                                                                                           [  3%]
test/test_serde.py::test_float_simplify PASSED                                                                                         [  3%]
test/test_serde.py::test_int_simplify PASSED                                                                                           [  3%]
test/test_serde.py::test_string_simplify PASSED                                                                                        [  3%]
test/test_serde.py::test_dict_simplify PASSED                                                                                          [  3%]
test/test_serde.py::test_range_simplify PASSED                                                                                         [  4%]
test/test_serde.py::test_torch_tensor_simplify PASSED                                                                                  [  4%]
test/test_serde.py::test_ndarray_simplify PASSED                                                                                       [  4%]
test/test_serde.py::test_ellipsis_simplify PASSED                                                                                      [  4%]
test/test_serde.py::test_torch_device_simplify PASSED                                                                                  [  5%]
test/test_serde.py::test_pointer_tensor_simplify PASSED                                                                                [  5%]
test/test_serde.py::test_torch_Tensor[True] PASSED                                                                                     [  5%]
test/test_serde.py::test_torch_Tensor[False] PASSED                                                                                    [  5%]
test/test_serde.py::test_torch_Tensor_convenience[True] PASSED                                                                         [  5%]
test/test_serde.py::test_torch_Tensor_convenience[False] PASSED                                                                        [  6%]
test/test_serde.py::test_tuple[True] PASSED                                                                                            [  6%]
test/test_serde.py::test_tuple[False] PASSED                                                                                           [  6%]
test/test_serde.py::test_bytearray[True] PASSED                                                                                        [  6%]
test/test_serde.py::test_bytearray[False] PASSED                                                                                       [  6%]
test/test_serde.py::test_ndarray_serde[True] PASSED                                                                                    [  7%]
test/test_serde.py::test_ndarray_serde[False] PASSED                                                                                   [  7%]
test/test_serde.py::test_compress_decompress[41] PASSED                                                                                [  7%]
test/test_serde.py::test_compress_decompress[42] PASSED                                                                                [  7%]
test/test_serde.py::test_compress_decompress[40] PASSED                                                                                [  8%]
test/test_serde.py::test_compressed_serde[41] PASSED                                                                                   [  8%]
test/test_serde.py::test_compressed_serde[42] PASSED                                                                                   [  8%]
test/test_serde.py::test_compressed_serde[40] PASSED                                                                                   [  8%]
test/test_serde.py::test_dict[True] PASSED                                                                                             [  8%]
test/test_serde.py::test_dict[False] PASSED                                                                                            [  9%]
test/test_serde.py::test_range_serde[True] PASSED                                                                                      [  9%]
test/test_serde.py::test_range_serde[False] PASSED                                                                                     [  9%]
test/test_serde.py::test_list[True] PASSED                                                                                             [  9%]
test/test_serde.py::test_list[False] PASSED                                                                                            [ 10%]
test/test_serde.py::test_set[True] PASSED                                                                                              [ 10%]
test/test_serde.py::test_set[False] PASSED                                                                                             [ 10%]
test/test_serde.py::test_slice[True] PASSED                                                                                            [ 10%]
test/test_serde.py::test_slice[False] PASSED                                                                                           [ 10%]
test/test_serde.py::test_float[True] PASSED                                                                                            [ 11%]
test/test_serde.py::test_float[False] PASSED                                                                                           [ 11%]
test/test_serde.py::test_hooked_tensor[True-41] PASSED                                                                                 [ 11%]
test/test_serde.py::test_hooked_tensor[False-41] PASSED                                                                                [ 11%]
test/test_serde.py::test_hooked_tensor[True-42] PASSED                                                                                 [ 12%]
test/test_serde.py::test_hooked_tensor[False-42] PASSED                                                                                [ 12%]
test/test_serde.py::test_hooked_tensor[True-40] PASSED                                                                                 [ 12%]
test/test_serde.py::test_hooked_tensor[False-40] PASSED                                                                                [ 12%]
test/test_serde.py::test_pointer_tensor PASSED                                                                                         [ 12%]
test/test_serde.py::test_pointer_tensor_detail[10000] PASSED                                                                           [ 13%]
test/test_serde.py::test_pointer_tensor_detail[10001] PASSED                                                                           [ 13%]
test/test_serde.py::test_numpy_tensor_serde PASSED                                                                                     [ 13%]
test/test_serde.py::test_additive_sharing_tensor_serde[True] PASSED                                                                    [ 13%]
test/test_serde.py::test_additive_sharing_tensor_serde[False] PASSED                                                                   [ 13%]
test/test_serde.py::test_fixed_precision_tensor_serde[True] PASSED                                                                     [ 14%]
test/test_serde.py::test_fixed_precision_tensor_serde[False] PASSED                                                                    [ 14%]
test/test_serde.py::test_serde_object_wrapper_int PASSED                                                                               [ 14%]
test/test_serde.py::test_serialize_and_deserialize_torch_scriptmodule SKIPPED                                                          [ 14%]
test/test_serde.py::test_torch_jit_script_module_serde SKIPPED                                                                         [ 15%]
test/test_serde.py::test_serde_virtual_worker PASSED                                                                                   [ 15%]
test/test_serde.py::test_full_serde_virtual_worker PASSED                                                                              [ 15%]
test/test_serde.py::test_serde_object_wrapper_traced_module PASSED                                                                     [ 15%]
test/test_udacity.py::test_section_1_differential_privacy PASSED                                                                       [ 15%]
test/test_udacity.py::test_section_2_federated_learning PASSED                                                                         [ 16%]
test/test_udacity.py::test_section_3_securing_fl PASSED                                                                                [ 16%]
test/federated/test_federated_client.py::test_add_dataset PASSED                                                                       [ 16%]
test/federated/test_federated_client.py::test_add_dataset_with_duplicate_key PASSED                                                    [ 16%]
test/federated/test_federated_client.py::test_remove_dataset PASSED                                                                    [ 17%]
test/federated/test_federated_client.py::test_set_obj_train_config PASSED                                                              [ 17%]
test/federated/test_federated_client.py::test_set_obj_other PASSED                                                                     [ 17%]
test/federated/test_federated_client.py::test_fit[gaussian_mixture-1] PASSED                                                           [ 17%]
test/federated/test_federated_client.py::test_fit[gaussian_mixture-10] PASSED                                                          [ 17%]
test/federated/test_federated_client.py::test_fit[another_dataset-1] PASSED                                                            [ 18%]
test/federated/test_federated_client.py::test_evaluate SKIPPED                                                                         [ 18%]
test/federated/test_train_config.py::test_train_config_with_jit_script_module SKIPPED                                                  [ 18%]
test/federated/test_train_config.py::test_train_config_with_jit_trace SKIPPED                                                          [ 18%]
test/federated/test_train_config.py::test_train_config_with_jit_trace_send_twice_with_fit SKIPPED                                      [ 18%]
test/federated/test_train_config.py::test___str__ PASSED                                                                               [ 19%]
test/federated/test_train_config.py::test_send PASSED                                                                                  [ 19%]
test/federated/test_train_config.py::test_send_model_and_loss_fn PASSED                                                                [ 19%]
test/federated/test_train_config.py::test_train_config_with_jit_trace_async SKIPPED                                                    [ 19%]
test/federated/test_train_config.py::test_train_config_with_jit_trace_sync SKIPPED                                                     [ 20%]
test/generic/test_id_provider.py::test_pop_no_given_ids PASSED                                                                         [ 20%]
test/generic/test_id_provider.py::test_pop_with_given_ids PASSED                                                                       [ 20%]
test/generic/test_id_provider.py::test_given_ids_side_effect PASSED                                                                    [ 20%]
test/generic/test_id_provider.py::test_set_next_ids PASSED                                                                             [ 20%]
test/generic/test_id_provider.py::test_set_next_ids_with_id_checking PASSED                                                            [ 21%]
test/generic/test_id_provider.py::test_start_recording_ids PASSED                                                                      [ 21%]
test/generic/test_id_provider.py::test_get_recorded_ids PASSED                                                                         [ 21%]
test/generic/test_object_storage.py::test_clear_objects PASSED                                                                         [ 21%]
test/generic/test_object_storage.py::test_clear_objects_return_None PASSED                                                             [ 22%]
test/integration/test_rnn.py::test_rnn_mpc[lstm] PASSED                                                                                [ 22%]
test/integration/test_rnn.py::test_rnn_mpc[gru] PASSED                                                                                 [ 22%]
test/integration/test_rnn.py::test_rnn_mpc[rnn_tanh] PASSED                                                                            [ 22%]
test/integration/test_rnn.py::test_rnn_mpc[rnn_relu] PASSED                                                                            [ 22%]
test/integration/test_rnn.py::test_rnn_federated[lstm] PASSED                                                                          [ 23%]
test/integration/test_rnn.py::test_rnn_federated[gru] PASSED                                                                           [ 23%]
test/integration/test_rnn.py::test_rnn_federated[rnn_tanh] PASSED                                                                      [ 23%]
test/integration/test_rnn.py::test_rnn_federated[rnn_relu] PASSED                                                                      [ 23%]
test/keras/test_sequential.py::test_instantiate_tfe_layer Fatal Python error: Segmentation fault

Thread 0x00007f1143dbf700 (most recent call first):

Thread 0x00007f11435be700 (most recent call first):

Current thread 0x00007f11b19c4740 (most recent call first):
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py"", line 1864 in _create_c_op
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py"", line 2027 in __init__
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py"", line 3616 in create_op
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py"", line 507 in new_func
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py"", line 788 in _apply_op_helper
  File ""<string>"", line 77 in secure_seeded_random_uniform
  File ""/usr/local/lib/python3.6/dist-packages/tf_encrypted/operations/secure_random/secure_random.py"", line 96 in seeded_random_uniform
  File ""/usr/local/lib/python3.6/dist-packages/tf_encrypted/tensor/native.py"", line 394 in value
  File ""/usr/local/lib/python3.6/dist-packages/tf_encrypted/tensor/native.py"", line 241 in sub
  File ""/usr/local/lib/python3.6/dist-packages/tf_encrypted/tensor/native.py"", line 209 in __sub__
  File ""/usr/local/lib/python3.6/dist-packages/tf_encrypted/protocol/pond/pond.py"", line 772 in _share
  File ""/usr/local/lib/python3.6/dist-packages/tf_encrypted/protocol/pond/pond.py"", line 343 in define_private_variable
  File ""/mnt/pysyft25/test/keras/test_sequential.py"", line 37 in test_instantiate_tfe_layer
  File ""/usr/local/lib/python3.6/dist-packages/_pytest/python.py"", line 170 in pytest_pyfunc_call
  File ""/usr/local/lib/python3.6/dist-packages/pluggy/callers.py"", line 187 in _multicall
  File ""/usr/local/lib/python3.6/dist-packages/pluggy/manager.py"", line 86 in <lambda>
  File ""/usr/local/lib/python3.6/dist-packages/pluggy/manager.py"", line 92 in _hookexec
  File ""/usr/local/lib/python3.6/dist-packages/pluggy/hooks.py"", line 286 in __call__
  File ""/usr/local/lib/python3.6/dist-packages/_pytest/python.py"", line 1423 in runtest
  File ""/usr/local/lib/python3.6/dist-packages/_pytest/runner.py"", line 125 in pytest_runtest_call
  File ""/usr/local/lib/python3.6/dist-packages/pluggy/callers.py"", line 187 in _multicall
  File ""/usr/local/lib/python3.6/dist-packages/pluggy/manager.py"", line 86 in <lambda>
  File ""/usr/local/lib/python3.6/dist-packages/pluggy/manager.py"", line 92 in _hookexec
  File ""/usr/local/lib/python3.6/dist-packages/pluggy/hooks.py"", line 286 in __call__
  File ""/usr/local/lib/python3.6/dist-packages/_pytest/runner.py"", line 201 in <lambda>
  File ""/usr/local/lib/python3.6/dist-packages/_pytest/runner.py"", line 229 in from_call
  File ""/usr/local/lib/python3.6/dist-packages/_pytest/runner.py"", line 201 in call_runtest_hook
  File ""/usr/local/lib/python3.6/dist-packages/_pytest/runner.py"", line 176 in call_and_report
  File ""/usr/local/lib/python3.6/dist-packages/_pytest/runner.py"", line 95 in runtestprotocol
  File ""/usr/local/lib/python3.6/dist-packages/_pytest/runner.py"", line 80 in pytest_runtest_protocol
  File ""/usr/local/lib/python3.6/dist-packages/pluggy/callers.py"", line 187 in _multicall
  File ""/usr/local/lib/python3.6/dist-packages/pluggy/manager.py"", line 86 in <lambda>
  File ""/usr/local/lib/python3.6/dist-packages/pluggy/manager.py"", line 92 in _hookexec
  File ""/usr/local/lib/python3.6/dist-packages/pluggy/hooks.py"", line 286 in __call__
  File ""/usr/local/lib/python3.6/dist-packages/_pytest/main.py"", line 256 in pytest_runtestloop
  File ""/usr/local/lib/python3.6/dist-packages/pluggy/callers.py"", line 187 in _multicall
  File ""/usr/local/lib/python3.6/dist-packages/pluggy/manager.py"", line 86 in <lambda>
  File ""/usr/local/lib/python3.6/dist-packages/pluggy/manager.py"", line 92 in _hookexec
  File ""/usr/local/lib/python3.6/dist-packages/pluggy/hooks.py"", line 286 in __call__
  File ""/usr/local/lib/python3.6/dist-packages/_pytest/main.py"", line 235 in _main
  File ""/usr/local/lib/python3.6/dist-packages/_pytest/main.py"", line 191 in wrap_session
  File ""/usr/local/lib/python3.6/dist-packages/_pytest/main.py"", line 228 in pytest_cmdline_main
  File ""/usr/local/lib/python3.6/dist-packages/pluggy/callers.py"", line 187 in _multicall
  File ""/usr/local/lib/python3.6/dist-packages/pluggy/manager.py"", line 86 in <lambda>
  File ""/usr/local/lib/python3.6/dist-packages/pluggy/manager.py"", line 92 in _hookexec
  File ""/usr/local/lib/python3.6/dist-packages/pluggy/hooks.py"", line 286 in __call__
  File ""/usr/local/lib/python3.6/dist-packages/_pytest/config/__init__.py"", line 90 in main
  File ""/mnt/pysyft25/.eggs/pytest_runner-5.1-py3.6.egg/ptr.py"", line 220 in run_tests
  File ""/mnt/pysyft25/.eggs/pytest_runner-5.1-py3.6.egg/ptr.py"", line 209 in run
  File ""/usr/lib/python3.6/distutils/dist.py"", line 974 in run_command
  File ""/usr/lib/python3.6/distutils/dist.py"", line 955 in run_commands
  File ""/usr/lib/python3.6/distutils/core.py"", line 148 in setup
  File ""/usr/local/lib/python3.6/dist-packages/setuptools/__init__.py"", line 145 in setup
  File ""setup.py"", line 34 in <module>
段错误 (核心已转储)
",platform python collected true false true false true false true false true false true false true false true false true false true false true false true false true false fatal python error segmentation fault thread recent call first thread recent call first current thread recent call first file line file line file line file line file line file string line file line file line value file line sub file line file line file line file line file line file line file line lambda file line file line file line file line file line file line lambda file line file line file line lambda file line file line file line file line file line file line file line lambda file line file line file line file line file line lambda file line file line file line file line file line file line file line lambda file line file line file line main file line file line run file line file line file line setup file line setup file line module,issue,positive,positive,neutral,neutral,positive,positive
544382671,I found out a fix. I will be opening a PR fixing it,found fix opening fixing,issue,negative,neutral,neutral,neutral,neutral,neutral
544340419,"The problem still exists!
Replaced the pyft version, the problem still exists",problem still version problem still,issue,negative,neutral,neutral,neutral,neutral,neutral
544273063,"Hi Theo,
I can take this one.
I see similar coding structure (with tag, description, simplify, detail methods etc.) in protocol.py file - so can to some extent imagine what the ""things to do"" are referring to but I think I still need more context as a new person on this.
Thanks in advance Theo!
",hi take one see similar structure tag description simplify detail file extent imagine think still need context new person thanks advance,issue,negative,positive,positive,positive,positive,positive
544270812,"I just ran it on my laptop and got the same warnings but no failure...

![image](https://user-images.githubusercontent.com/43521764/67163142-c72a5000-f36b-11e9-9734-ea465484bd01.png)

@iamtrask , is the failure you got related to crypto_lr test?

I will try to find out why we are getting these warnings",ran got failure image failure got related test try find getting,issue,negative,negative,negative,negative,negative,negative
544262758,"@andrelmfarias any hint on this?
It's working fine on my laptop but also failing on Travis :(",hint working fine also failing travis,issue,negative,positive,positive,positive,positive,positive
544260545,"Hi Jasopaum and Theo,
Thanks!
Yes - as I was exploring the code in the fork that I have - I noticed that : it cannot be dictionary if we want to have the flexibility of several plans for same worker. And that is also evident (in a very concrete manner) from the line me.request_search(...) and onward in test_protocol.py  ",hi thanks yes exploring code fork dictionary want flexibility several worker also evident concrete manner line onward,issue,positive,positive,positive,positive,positive,positive
544252496,"What do you mean exactly with ""As an aside, it'd be cool to have some incrementally more comprehensive PEP linting in the pyproject.toml for black""?",mean exactly aside cool comprehensive pep black,issue,positive,positive,neutral,neutral,positive,positive
544252162,"You might have changed some stuff in the detailers which makes the while thing break: in particular from the failing tests I would say the line `detailer = detailers[idx_or_path]` is the one which triggers the fails,
maybe take a test which is failing _but is quite simple_ and try to understand what didn't work out and why it failed. This is what I do usually when I have tests failing",might stuff thing break particular failing would say line detailer one maybe take test failing quite try understand work usually failing,issue,negative,negative,neutral,neutral,negative,negative
544251124,"Exactly!
this notion of order and the ability to have several plans for the same worker are critical",exactly notion order ability several worker critical,issue,negative,positive,neutral,neutral,positive,positive
544242975,"Hey!
I think Protocol.plans was not a dict in the first place because:
- we can have several plans for a same worker during a protocol
- we need the order in which the plans have to be executed

Maybe @LaRiffle can confirm or correct me?",hey think first place several worker protocol need order executed maybe confirm correct,issue,negative,positive,positive,positive,positive,positive
544199315,"@LaRiffle @iamtrask 

Can anyone review this PR please. It seems that Travis is not happy, but the errors are not related to the part I am pushing (or is it?), any thoughts?",anyone review please travis happy related part pushing,issue,positive,positive,positive,positive,positive,positive
544158470,I think this is a great way to address this problem. We should probably use these trust levels at tensor creation time to avoid having to check them for every call (since that changes protocols). In practice it is just changing a default,think great way address problem probably use trust tensor creation time avoid check every call since practice default,issue,positive,positive,positive,positive,positive,positive
544140771,"> Problem solved. Run `pip install -r requirements.txt` before `python setup.py install`.

No, I have this issue too, but after I run `pip install -r requirements.txt` and `sudo pip install -r requirements.txt` before `python setup.py install`, it still can't pass the test and get an error of `segmentation fault`.
By the way, I have installed pytest the file mentioned.",problem run pip install python install issue run pip install pip install python install still ca pas test get error segmentation fault way file,issue,negative,neutral,neutral,neutral,neutral,neutral
543262376,"@hi-hi-there As I understand it, if you use copy_of_parameter.get() you are basically bringing each user's parameters to the server and then applying fix_precision, which is wrong. We need to apply fix_precision on user's device (pointers) for correct secure aggregation.",understand use basically user server wrong need apply user device correct secure aggregation,issue,negative,negative,neutral,neutral,negative,negative
543111081,Problem solved. Run `pip install -r requirements.txt` before `python setup.py install`.,problem run pip install python install,issue,negative,neutral,neutral,neutral,neutral,neutral
542817278,"FWIW I'm not sure ONNX would be an expressive enough DSL to accomplish everything we do with serde -- it's pretty specific to the standard ML computation graph, but there are commands & classes we have in serde that don't fit into that paradigm

protobuf seems to be the right level of abstraction we'll need in terms of expressivity/flexibility vs. standardization for the long term, and while there might be more favorable alternatives (see the ""alternatives considered"" section in @justin1121's RFC), I don't think ONNX is it",sure would expressive enough accomplish everything pretty specific standard computation graph class fit paradigm right level abstraction need standardization long term might favorable see considered section think,issue,positive,positive,positive,positive,positive,positive
542810765,"Great!  We will move ahead with improving Serde as is and look forward to a
demo of what it could be from you in the future!

On Wed, Oct 16, 2019 at 4:30 PM Jose A. Corbacho <notifications@github.com>
wrote:

>
>    1. Go ahead. We can think about ONNX later, maybe instead of Protobuf
>    (which is used under the hood by ONNX)
>    2. I am not sure about putting so much pressure in this particular
>    item. I tend to look to performance at a later stage and only if necessary.
>
> I'll try to find time to have some ONNX example up and running.
>
> —
> You are receiving this because you were assigned.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/2654?email_source=notifications&email_token=AAJ44CVYD7SCTPTBF7KMN2TQO4XSLA5CNFSM4I7D6IHKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEBM5QYI#issuecomment-542759009>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AAJ44CRI4FK4NKQX3AD42TTQO4XSLANCNFSM4I7D6IHA>
> .
>
",great move ahead improving look forward could future wed wrote go ahead think later maybe instead used hood sure much pressure particular item tend look performance later stage necessary try find time example running assigned reply directly view,issue,positive,positive,positive,positive,positive,positive
542759009,"1. Go ahead. We can think about ONNX later, maybe instead of Protobuf (which is used under the hood by ONNX)
2. I am not sure about putting so much pressure in this particular item. I tend to look to performance at a later stage and only if necessary.

I'll try to find time to have some ONNX example up and running.",go ahead think later maybe instead used hood sure much pressure particular item tend look performance later stage necessary try find time example running,issue,negative,positive,positive,positive,positive,positive
542756073,"I wasn't familiar with ONNX until doing a bit of light research @mccorby.  This looks like a strong alternative.  Are you proposing we would use this as a complete replacement to Serde?

My two concerns so far are:
1. We're really pretty close to getting Serde in a manageable condition and ""if it works, don't break it"".
2. The library for ONNX in Javascript is fairly large (but impressively, it's developed by Microsoft).  I would have expected a smaller file size, but it looks to be almost as big as TensorFlow.js itself!  I don't initially feel comfortable including another dependency that big as I do have to be concerned with the load time of webpages when building syft.js.

Not saying ""no"" - I think it's a great option - but I have a few initial reservations.  Can you speak to any of these concerns?",familiar bit light research like strong alternative would use complete replacement two far really pretty close getting manageable condition work break library fairly large impressively would smaller file size almost big initially feel comfortable another dependency big concerned load time building saying think great option initial speak,issue,positive,positive,positive,positive,positive,positive
542543918,Has anyone explored extending ONNX as a possible alternative?,anyone extending possible alternative,issue,negative,neutral,neutral,neutral,neutral,neutral
542322367,I have added a check to ensure that cuda is installed before running the fix ,added check ensure running fix,issue,negative,neutral,neutral,neutral,neutral,neutral
542144803,"Totally fair point @jvmancuso.  I think the concern is more related to things like a list of tensor or worker ID's.  In this case, I can't see why a list would be ""needed"" over a tuple.  But for sure, there's going to be exceptions to this rule.  Do you know of specific places where this is likely to be an issue?

All that we're trying to do for that point is to establish some sort of consistency.  For collections of data where the structure doesn't matter, we should prefer tuple.  Nevertheless, we will still support list where **needed**.",totally fair point think concern related like list tensor worker id case ca see list would sure going rule know specific likely issue trying point establish sort consistency data structure matter prefer nevertheless still support list,issue,positive,positive,positive,positive,positive,positive
542023557,"Hi @robert-wagner! Yeah I've completed tests.

I guess what @iamtrask have suggested is a good idea for another big PR — refactor all tests to check operations on 3+ worker shared tensors. I think it's beyond this PR.",hi yeah guess good idea another big check worker think beyond,issue,positive,positive,positive,positive,positive,positive
541838801,"To point 3 -- I don't think what you're suggesting forbids this, but want to be sure. I strongly suggest that we keep the ability to serde list -> list and tuple -> tuple. In Python, there are just some functions that will behave differently for tuples/lists, so we need to be able to distinguish on the receiving end of an RPC to enable all the functionality for those functions.

For an example, if I want to hook a function from some framework, but that function has different behavior for tuple & lists (perhaps due to immutability/hashability), the simplifying/detailing of the functions arguments will mistakenly change the behavior of the hooked function. This is because the hook_args implementation passes the args/kwargs to hooked functions through serde, so serde needs to be able to respect the difference",point think suggesting want sure strongly suggest keep ability list list python behave differently need able distinguish end enable functionality example want hook function framework function different behavior perhaps due mistakenly change behavior hooked function implementation hooked need able respect difference,issue,positive,positive,positive,positive,positive,positive
541806630,Hey @meandmymind are you still working on this pull request? It looks like it is almost done,hey still working pull request like almost done,issue,negative,neutral,neutral,neutral,neutral,neutral
541794270,"**UPDATE - October 14th, 2019**

We're currently working on each of these issues.  The following is the order in which we're doing each task above:

- [x] Updating, finalizing, and merging the Proto PR that @vvmnnnkv has done. (Point 5 above)
- [x] Testing current Serde implementation
- [x] Getting rid of msg_type for all Message classes, and potentially removing the codes.py file assuming it’s also no longer needed. (Point 1 above)
- [x] Switching all instances of List to be using Tuple (and ensure that they simplify whether they’re nested within another Tuple or by themselves). (Point 3 above)
- [x] Clearing out all “magic parens” in favor of Tuple. (Point 2 above)",update th currently working following order task proto done point testing current implementation getting rid message class potentially removing file assuming also longer point switching list ensure simplify whether within another point clearing magic favor point,issue,positive,positive,neutral,neutral,positive,positive
541750645,"Thanks for reaching out @LaRiffle. Correct, we will use the approach in #2651 instead. Let's close this pr. ",thanks reaching correct use approach instead let close,issue,positive,positive,positive,positive,positive,positive
541732861,"I'm not sure I agree with this in the long run. While I think this is great behavior for learning to use the framework, I do not think it is good for when the framework is actually in use (IE I think that I would be very unhappy as a user if you suggested to me to run imagenet in a federated way when I could just run it locally)",sure agree long run think great behavior learning use framework think good framework actually use ie think would unhappy user run way could run locally,issue,positive,positive,positive,positive,positive,positive
541714894,"Whatever you'd like!  I've already had most of the items that I listed
approved for development and have someone working on them now.  Let me know
if you're interested in joining efforts!

On Mon, Oct 14, 2019 at 3:27 PM Jose A. Corbacho <notifications@github.com>
wrote:

> @mccorby <https://github.com/mccorby> Did you already read through the
> Serde refactor I put together? We're actually already working on some of
> the ideas you've established here. Great to see we're on the same page!
>
> #2654 <https://github.com/OpenMined/PySyft/issues/2654>
>
> Yes, of course I read it but I'm not 100% sure so I want to give it a try
> to what I have in mind (that takes me too long to unfold with words ) even
> if that just gets me to the same place you are.
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/pull/2660?email_source=notifications&email_token=AAJ44CWUFN52OERQORWWPNDQOR6VFA5CNFSM4JACJV52YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEBE5WXQ#issuecomment-541711198>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AAJ44CQCAPJGG5BLOMHHI4LQOR6VFANCNFSM4JACJV5Q>
> .
>
",whatever like already listed development someone working let know interested joining mon wrote already read put together actually already working established great see page yes course read sure want give try mind long unfold even place reply directly view,issue,positive,positive,positive,positive,positive,positive
541711198,"> @mccorby Did you already read through the Serde refactor I put together? We're actually already working on some of the ideas you've established here. Great to see we're on the same page!
> 
> #2654

Yes, of course I read it but I'm not 100% sure so I want to give it a try to what I have in mind (that takes me too long to unfold with words ) even if that just gets me to the same place you are.",already read put together actually already working established great see page yes course read sure want give try mind long unfold even place,issue,positive,positive,positive,positive,positive,positive
541681771,"handle_command_function is called automatically when you call a torch function. Depending on the type of the args provided to the torch function, the `handle_command_function` of the appropriate class will be called (you can check that there is indeed one per Tensor type class).

The mechanism which handles this is in hook.py line 425

`native.py` is intended to extend the torch Tensor. But recall that torch Tensor can be used either to perform pure torch operation or as wrappers of syft tensors (in which case they are empty and act just as a small shell)
`handle_command_function`  should always check if the function called could not be replaced by an overloaded one, defined in the ""@staticmethod""  def torch of the same class.
`handle_command_function` in native.py should make sure that overloaded functions are used in both cases (as native tensors or wrappers)
Now, this check is done in
```python
# Check that the function has not been overwritten
            try:
                # Try to get recursively the attributes in cmd = ""<attr1>.<attr2>.<attr3>...""
                command = cls.rgetattr(cls, cmd)
                return command(*args, **kwargs)
            except AttributeError:
                pass
```
so you just have to put it out of the wrapper/non wrapper disjunction materialized by the `try / except PureFrameworkTensorFoundError` to have it work in bother cases",automatically call torch function depending type provided torch function appropriate class check indeed one per tensor type class mechanism line intended extend torch tensor recall torch tensor used either perform pure torch operation case empty act small shell always check function could one defined torch class make sure used native check done python check function try try get command return command except pas put wrapper disjunction try except work bother,issue,negative,positive,positive,positive,positive,positive
541681452,"@mccorby Did you already read through the Serde refactor I put together?  We're actually already working on some of the ideas you've established here.  Great to see we're on the same page!

https://github.com/OpenMined/PySyft/issues/2654",already read put together actually already working established great see page,issue,positive,positive,positive,positive,positive,positive
541316332,"I had similar problems on my linux system. The problem is conda's gcc and ld conflict with the system's ones. Using a plain python virtualenvironment instead of conda solves the problem. 

I created a PR #2662 to extend the readme on this issue.",similar system problem conflict system plain python instead problem extend issue,issue,negative,negative,negative,negative,negative,negative
541018076,@LaRiffle Can you please give an example of `handle_func_command` call? And also what is the significance of `handle_fun_command`? I am a little confused. Thank you.,please give example call also significance little confused thank,issue,positive,negative,negative,negative,negative,negative
540637131,"Interesting progress going on!
I have a question:
For FixedPrecision I have .fix_precision() and float_precision() to revert
For AdditiveShared I have .share() and .get()
For Polynomial we have .poly() _but what's the one to revert_?",interesting progress going question revert polynomial one,issue,positive,positive,positive,positive,positive,positive
540636792,"Thanks for chiming in @justin1121 - sorry for not tagging you on the issue!  I'd be thrilled for us to implement Protobuf once we reach a bit more stability and cross-compatibility with Serde.  Appreciate you delaying that RFC until we make more progress here.

@jvmancuso - thanks for joining in as well.  I'll look into Hypothesis more.  I think what I'm looking for in particular is to actually set up a webhook with the PySyft Github repo to report when changes are made to the `dev` branch.  A service which is triggered by the new code, then generates all possible simplification strings and stores them somewhere on the Proto repo.  This could automate some of the discovery of type discrepancies in syft.js.

Basically my concern is that there will inevitably be some change to a class, or the introduction of a brand new class, into PySyft that the syft.js isn't made aware of.  We know that we're definitely going to have versioning problems between PySyft and all other syft-based libraries, but this would at least report changes to the Serde protocol before our users need to report bugs.  This would be testing across multiple repos and multiple languages.  I'll look into this more and report back.",thanks sorry issue u implement reach bit stability appreciate delaying make progress thanks joining well look hypothesis think looking particular actually set report made dev branch service triggered new code possible simplification somewhere proto could discovery type basically concern inevitably change class introduction brand new class made aware know definitely going would least report protocol need report would testing across multiple multiple look report back,issue,positive,positive,neutral,neutral,positive,positive
540626542,"7. I'm not sure what exactly you're hoping to do here, but it sounds like something [Hypothesis](https://hypothesis.readthedocs.io/en/latest/) might be able to help with.",sure exactly like something hypothesis might able help,issue,positive,positive,positive,positive,positive,positive
540617046,"Hey, as the author of the protobufs RFC, just wanted to say this all makes sense to me. Any incremental improvements to the standardization of serde should (could?) help with the effort of Protobufs. Hopefully we'll see some of the development in protobufs come to fruition in the coming months.",hey author say sense incremental standardization could help effort hopefully see development come fruition coming,issue,positive,neutral,neutral,neutral,neutral,neutral
540472617,"4 - Similar to reversing 1.  It's not entirely the same thing because currently `msg_type` refers to a redundant code to specify what type of message it is.  This is not needed because you can already infer the message type in Python by either a) determining the instance of the class or b) reading the Serde code.  Either way, you're right that we could just make our own abstract class in Javascript to keep track of these changes.  I suppose though that it locks us into that decision, even at the risk of more methods being added to that class in Python.  At some point, we'd have to do what PySyft is doing to avoid one really huge complex class.  I suppose that's the thinking behind that mindset in PySyft anyhow.  I wonder if there's some better middle-ground, or perhaps some way to prevent this from causing major typing errors in the event a class is missing in Javascript.

6 - Totally agree, I'm not saying ""no"".  I'm simply saying ""this isn't as important of a goal for the here and now"".",similar reversing entirely thing currently redundant code specify type message already infer message type python either instance class reading code either way right could make abstract class keep track suppose though u decision even risk added class python point avoid one really huge complex class suppose thinking behind anyhow wonder better perhaps way prevent causing major event class missing totally agree saying simply saying important goal,issue,positive,positive,neutral,neutral,positive,positive
540456572,"@LaRiffle I fixed the issue by installing the full Xcode and reinstalling the command line tools. The command `pip install syft` works well now. Please close this issue, thanks. ",fixed issue full command line command pip install work well please close issue thanks,issue,positive,positive,positive,positive,positive,positive
540451883,Could you add more elements about the stacktrace? Haven't you find any useful information on stackaoverflow?,could add find useful information,issue,negative,positive,positive,positive,positive,positive
540296948,"Hmm seems like can't work directly on the pointer, so I called a ""get"" on the pointer.
I'm new to this so if someone thinks this is wrong, do point it out! but for now this works: 

Under **part B**:
Change `fixed_precision_param = copy_of_parameter.fix_precision()`
to `fixed_precision_param = copy_of_parameter.get().fix_precision()`

and change `new_param = (spdz_params[0] + spdz_params[1]).get().float_precision()/2`
To `new_param = (spdz_params[0] + spdz_params[1]).float_precision()/2`

Now the code part B code should run. 

After this. you will need to do the same for the code under **Let's put it all Together!**:
Change `spdz_params.append(params[remote_index][param_i].copy().fix_precision().share(bob, alice, crypto_provider=james).get())`
To `spdz_params.append(params[remote_index][param_i].copy().get().fix_precision().share(bob, alice, crypto_provider=james).get())`

and change `new_param = (spdz_params[0] + spdz_params[1]).get().float_precision()/2`
To `new_param = (spdz_params[0] + spdz_params[1]).float_precision()/2`

This is my output :
![image](https://user-images.githubusercontent.com/55134531/66533580-ff4cba00-eb45-11e9-9ac9-1fd285c94f39.png)
",like ca work directly pointer get pointer new someone wrong point work part change change code part code run need code let put together change bob bob change output image,issue,negative,negative,neutral,neutral,negative,negative
540198105,"1, 2, and 3 I wholeheartedly agree with. 

4. As you mentioned, 4 (from a protocol standpoint) returns us back to reversing 1. Given the symmetry between 1 and 4, perhaps language can manage the different message types however is most appropriate for the language (if statements or abstract class hierarchy). Aka, PySyft could keep doing it the way it currently is, and Javascript could choose to implement a single Message class. I'm not a polyglot expert, but this seems like an appropriate flexibility given we want to allow compatibility between lots of languages, and one which wouldn't affect the abstract protocol.

5. Agreed.

6.  Agreed, although I have a hunch that the compressor will be worth including in the long run (but we can wait until we can run empirical tests before going there).",wholeheartedly agree protocol standpoint u back reversing given symmetry perhaps language manage different message however appropriate language abstract class hierarchy aka could keep way currently could choose implement single message class polyglot expert like appropriate flexibility given want allow compatibility lot one would affect abstract protocol agreed agreed although hunch compressor worth long run wait run empirical going,issue,positive,positive,positive,positive,positive,positive
540192376,I agree with this change. Great suggestion!,agree change great suggestion,issue,positive,positive,positive,positive,positive,positive
540118489,@midokura-silvia Yes. I will make the necessary changes in the unit test test_virtual.py::test_obj_not_found. Thanks.,yes make necessary unit test thanks,issue,positive,positive,neutral,neutral,positive,positive
540053634,I have traced the error to be thrown when we are trying to do a ```np.abs()``` on ```self.clone().detach.numpy()```. I have not found a fix or workaround for this yet.,error thrown trying found fix yet,issue,negative,neutral,neutral,neutral,neutral,neutral
540027190,"This issue happened again on macOS Catalina and all the solutions above cannot fix it. 
Same error message as above. 
`
error: command 'gcc' failed with exit status 1
`",issue catalina fix error message error command exit status,issue,negative,neutral,neutral,neutral,neutral,neutral
539980791,"Yup, I have modified the file on Google Colab so it should be fine now. At least it was the last time I checked. ",file fine least last time checked,issue,negative,positive,neutral,neutral,positive,positive
539976893,"Hi @sukhadj. Could you please fix the unit test test_virtual.py::test_obj_not_found?

You need to modify lines 204-207: 
```
    try:
        y = x + x
    except KeyError as e:
        assert ""If you think this tensor does exist"" in str(e)
```
try something as follows:
```
with pytest.raises(ObjectNotFoundError):
    y = x + x
```
The coverage error should go away then as well.",hi could please fix unit test need modify try except assert think tensor exist try something coverage error go away well,issue,negative,neutral,neutral,neutral,neutral,neutral
539962822,"Hi @LaRiffle, thanks for pinging!
This issue seems to be same as #2439 except in #2439 codes are coming from proto package not from codes.py as suggested here.
So I'm confused - what should be fixed as a first step? :)
Msg types in #2649?
",hi thanks issue except coming proto package confused fixed first step,issue,negative,positive,neutral,neutral,positive,positive
539901996,"Yes I agree this might be a good first step!
@vvmnnnkv I'm pinging here so that you can follow all the convs :)",yes agree might good first step follow,issue,positive,positive,positive,positive,positive,positive
539888470,Could we try to fix this first before merging #2439?,could try fix first,issue,negative,positive,positive,positive,positive,positive
539880229,"No I don't think wo we would rm the stuff from codes.py but reuse the logic of it for serde

But this might conflict with #2439",think wo would stuff reuse logic might conflict,issue,negative,neutral,neutral,neutral,neutral,neutral
539707312,"Hey!
So I think there are different levels of progress here:
1) just put back int codes in serde.py -> easy fast and already a bit helpful but not viable
2) put codes in a dedicated repo -> easily readable by other libs to adapt
3) put codes + simplifiers/detailes in a dedicated repo -> a much higher lift but certainly the end goal we want to achieve

I think 2) is the best one, great job on the first implems using https://github.com/OpenMined/proto/blob/master/proto.json

We should continue on this PR and make it real, I'll try to help on this asap @vvmnnnkv :)
",hey think different progress put back easy fast already bit helpful viable put easily readable adapt put much higher lift certainly end goal want achieve think best one great job first continue make real try help,issue,positive,positive,positive,positive,positive,positive
539399294,"Hey, I wonder if you can leverage what has been done in PyTorch to deal with Tensors & Parameters (which used to be called Variables)
We also create different pointers/wrappers when sending one or another.
Any thoughts?",hey wonder leverage done deal used also create different sending one another,issue,negative,neutral,neutral,neutral,neutral,neutral
539117517,"Agree, and just worth mentioning here we're actively looking for help with that until we can allocate more resources to implementing the protobuf RFC",agree worth actively looking help allocate,issue,positive,positive,neutral,neutral,positive,positive
539075201,"@LaRiffle I think that this PR would actually help out a lot of the work being done with syft.js.  Even if we abandon the work later on for Protobuf, at least we've made some progress in the meantime.  It's my understanding that switching to using Protobuf is a long term goal.  While it is part of an RFC, I've heard of no progress in implementing Serde aspects of that RFC.

Thoughts?",think would actually help lot work done even abandon work later least made progress understanding switching long term goal part progress,issue,positive,negative,neutral,neutral,negative,negative
538204228,"I started looking into this, but it looks like most or all the functions in securenn.py only allow for two workers (alice, bob to be specific). Since I am relatively new to PySyft it's starting to look a little more intense than just changing the syntax to what I suggested earlier.",looking like allow two bob specific since relatively new starting look little intense syntax,issue,positive,positive,neutral,neutral,positive,positive
537841210,"> Maybe you could detail a bit the role of the HBC worker which might not be well understood by other people than the crypto team

I added its formal definition, do you think I should try to explain it a bit more?

",maybe could detail bit role worker might well understood people team added formal definition think try explain bit,issue,negative,neutral,neutral,neutral,neutral,neutral
537629231,"it would be great to know of examples where double serialization is happening, as it seems like that's not the case everywhere -- do you have any of those? It might point to a different bug in the codebase that would be more useful to fix, and it would also be a good idea to update the PR as it's gotten stale and the issue might have been fixed elsewhere in the meantime.",would great know double serialization happening like case everywhere might point different bug would useful fix would also good idea update gotten stale issue might fixed elsewhere,issue,positive,positive,positive,positive,positive,positive
537534595,"Hi @jvmancuso. Sorry about the delay in updating this PR. Have been meaning to ask someone regarding the different options I have to move forward, but didn't know who to ask. I think I changed the code base a bit to attempt a fix on a related issue first, but in the process broke many tests. Do you think it is a good idea to carry on with this PR by fixing these tests? Or, is the breaking of such tests at this stage any indication of something undesirable, meaning that I should approach the original issue a little differently? Any suggestions? ",hi sorry delay meaning ask someone regarding different move forward know ask think code base bit attempt fix related issue first process broke many think good idea carry fixing breaking stage indication something undesirable meaning approach original issue little differently,issue,negative,positive,neutral,neutral,positive,positive
537528186,@robert-wagner did you add this to the issue template? Hoping to get a resolution on this,add issue template get resolution,issue,negative,neutral,neutral,neutral,neutral,neutral
537049465,"Yes, more or less. There is some context missing from this issue, most of it can be found in [this RFC](https://github.com/OpenMined/rfcs/blob/master/20190808-modular-pysyft-frameworks.md), and more specifically [here](https://github.com/OpenMined/rfcs/blob/master/20190808-modular-pysyft-frameworks.md#packaging).

Worth noting that ""building up the core syft code to be independent"" is already complete.  What's left are the two of these checkboxes, and more specifically the latter because I'm about to fix the former.",yes le context missing issue found specifically worth building core code independent already complete left two specifically latter fix former,issue,negative,positive,neutral,neutral,positive,positive
537026030,"I would like to work on this issue. Can you please tell me from where I can start? Thanks.
",would like work issue please tell start thanks,issue,positive,positive,positive,positive,positive,positive
536888916,"Hi,
This is not yet possible. The Android worker only accepts a very limited set of operations. We need to extend it to be able of working with `PyGrid` and plans.",hi yet possible android worker limited set need extend able working,issue,negative,positive,positive,positive,positive,positive
536188632,"""truly optional""? I'm interpreting this as meaning building up the core syft code to be as independent of pytorch as possible, and setting up an optional pytorch backend much like `keras` does with `tensorflow` and `theano, right?",truly optional meaning building core code independent possible setting optional much like right,issue,positive,positive,positive,positive,positive,positive
535880553,"Can anyone fix this to the original PySyft Repo? I'm also facing same issue, when workers are greater than 2.",anyone fix original also facing issue greater,issue,positive,positive,positive,positive,positive,positive
535665539,can you show the full error prompt you got in terminal?,show full error prompt got terminal,issue,negative,positive,positive,positive,positive,positive
534117881,"Closing issue as 
- type annotations now used in PySyft code
- inactivity",issue type used code inactivity,issue,negative,neutral,neutral,neutral,neutral,neutral
533881658,"Hey, thanks for your feedback.
> While when set requires_grad True for Data as well, then it works perfectly fine. But when doing this, I get model gradients as None after backward

This is a bug related to `.squeeze(1)`. Remove this and you will get the gradient. I opened an Issue #2621 

> When we share the model and data to different virtual workers, then obviously it's the Model whose requires_grad should be True and data's requires_grad should be False

You're 100% right. However, if you know about PySyft, you know it relies chain of tensors like `Parameter>AutogradTensor>FixedPrecisionTensor>[AdditiveSharingTensor]...`. We currently hardly handle operating tensors with different chain structure, and in particular we don't support currently operating tensors with autograd and some who don't have them, that's why we asked `require_grad=True` for every tensor. But I'll report this as an issue and we'll try to have a better support. #2622 ",hey thanks feedback set true data well work perfectly fine get model none backward bug related remove get gradient issue share model data different virtual obviously model whose true data false right however know know chain like parameter currently hardly handle operating different chain structure particular support currently operating every tensor report issue try better support,issue,positive,positive,positive,positive,positive,positive
533134511,It should be sufficient to use two web sockets running on two separate machines.,sufficient use two web running two separate,issue,negative,neutral,neutral,neutral,neutral,neutral
532823184,"Oh, got confused because the pythonic name of PySyft-PyTorch will inevitably be `syft_torch`, and that stuff will need to be imported in `syft/frameworks/torch`.",oh got confused pythonic name inevitably stuff need,issue,negative,negative,negative,negative,negative,negative
532812536,"No no - I'm not advocating for *anything* to call syft_torch (ever). I'm
saying we should create a separate PyPI package which literally just
imports syft, torch, and creates a hook for you.

On Wed, Sep 18, 2019 at 7:24 PM jvmancuso <notifications@github.com> wrote:

> Ah, yeah, so that is definitely a separate issue than managing multiple
> hooks. Right now syft_torch etc. need to be imported inside
> syft/frameworks/__init__.py, and since syft/__init__.py imports that
> directory, it's roughly the same as doing it in syft. I'd suggest we leave
> this issue blocked by the work I mentioned above, and resume conversation
> once that stuff lands.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/2620?email_source=notifications&email_token=ABBAZEWTF7VKK3P4O7TMTJDQKJW5XA5CNFSM4IYBYXA2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD7A755Q#issuecomment-532807414>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABBAZEVNQF5KOXS27LA6SM3QKJW5XANCNFSM4IYBYXAQ>
> .
>
",anything call ever saying create separate package literally torch hook wed wrote ah yeah definitely separate issue multiple right need inside since directory roughly suggest leave issue blocked work resume conversation stuff thread reply directly view mute thread,issue,positive,positive,neutral,neutral,positive,positive
532807414,"Ah, yeah, so that is definitely a separate issue than managing multiple hooks.  What I'm proposing would not necessarily auto-create the hooks, just put them in a specific spot when they are created and be able to switch between them when needed.  Right now, syft_torch etc. need to be imported inside `syft/frameworks/__init__.py`, and since `syft/__init__.py` imports that directory, it's roughly the same as doing it in syft.  I'd suggest we leave this issue blocked by the work I mentioned above, and resume this once it lands.",ah yeah definitely separate issue multiple would necessarily put specific spot able switch right need inside since directory roughly suggest leave issue blocked work resume,issue,negative,positive,neutral,neutral,positive,positive
532804365,"This is why I thought that it should be it's own package. syft itself
shouldn't create a hook, but syft_torch should (and shouldn't be imported
internally anywhere)

On Wed, Sep 18, 2019 at 7:02 PM Robert (Bobby) Wagner <
notifications@github.com> wrote:

> All for Jasons changes assuming they dont have similar problems
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/2620?email_source=notifications&email_token=ABBAZETGXFD6KEPDRO3KKILQKJUNBA5CNFSM4IYBYXA2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD7A5ZDY#issuecomment-532798607>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABBAZEV5IRXMOTA4Z54YAQ3QKJUNBANCNFSM4IYBYXAQ>
> .
>
",thought package create hook internally anywhere wed bobby wrote assuming dont similar thread reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
532798360,We actually tried this before when we only had pytorch (I might still have the branch somewhere) Creating the hook automatically causes so many problems when you are importing syft in other parts of the library as well as when you are just running it through an autoformatter/the test suite etc. We probably could hack around that but it would not be fun,actually tried might still branch somewhere hook automatically many library well running test suite probably could hack around would fun,issue,positive,positive,positive,positive,positive,positive
532798058,"Love it! Maybe close this PR when you merge?

On Wed, Sep 18, 2019 at 6:58 PM jvmancuso <notifications@github.com> wrote:

> Yeah, I've been leaning toward a combination here. Currently, syft.torch
> =TorchAttributes(torch) is still called during TorchHook.__init__, but
> I'm assigning syft.framework = syft.torch as well. syft.framework manages
> which framework & hook are currently being used, and when you switch
> between e.g. torch and tensorflow there would be some implicit switch of syft.framework
> = syft.tensorflow. This allows generic/framework-agnostic code to call
> e.g. syft.framework.hook without needing to know which framework is
> currently in use. This switching needs to be a first-class mechanism
> though, and right now it's not, so that's what's been on my todo list.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/2620?email_source=notifications&email_token=ABBAZEVQLP7ZFLQG7IKWURLQKJT5TA5CNFSM4IYBYXA2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD7A5LSQ#issuecomment-532796874>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABBAZEQIANWP7PGUK36AGRDQKJT5TANCNFSM4IYBYXAQ>
> .
>
",love maybe close merge wed wrote yeah leaning toward combination currently torch still well framework hook currently used switch torch would implicit switch code call without needing know framework currently use switching need mechanism though right list thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
532796874,"Yeah, I've been leaning toward a combination here.  Currently, `syft.torch =TorchAttributes(torch)` is still called during `TorchHook.__init__`, but I'm assigning `syft.framework = syft.torch` as well.  `syft.framework` manages which framework & hook are currently being used, and when you switch between e.g. torch and tensorflow there would be some implicit switch of `syft.framework = syft.tensorflow`.  This allows generic/framework-agnostic code to call e.g. `syft.framework.hook` without needing to know which framework is currently in use.

That switching needs to be a first-class mechanism though, and right now it's not, so that's what's been on my todo list.",yeah leaning toward combination currently torch still well framework hook currently used switch torch would implicit switch code call without needing know framework currently use switching need mechanism though right list,issue,positive,positive,neutral,neutral,positive,positive
532794421,"Great point - although I think my assumption was that you'd only use these
if you knew which framework you were using (and you were only using one)

On Wed, Sep 18, 2019 at 6:47 PM jvmancuso <notifications@github.com> wrote:

> There might be a concern here when we're using multiple frameworks in one
> script -- the global state of syft.hook might need to reference more than
> one hook. This can be solved by assigning each one to a specific
> syft.framework.hook, i.e. syft.torch.hook, but then that's a lot of
> global state to maintain, so we'd probably want a solid way of dealing with
> that. Right now it's a bit hand wavy how this is handled, but it's
> definitely been on my todo list.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/2620?email_source=notifications&email_token=ABBAZETNLX2AEWRGAA6PYSDQKJSTNA5CNFSM4IYBYXA2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD7A4JOA#issuecomment-532792504>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABBAZEUE426XVHAVJBC3SK3QKJSTNANCNFSM4IYBYXAQ>
> .
>
",great point although think assumption use knew framework one wed wrote might concern multiple one script global state might need reference one hook one specific lot global state maintain probably want solid way dealing right bit hand wavy handled definitely list thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
532792504,"There might be a concern here when we're using multiple frameworks in one script -- the global state of `syft.hook` might need to reference more than one hook.  This can be solved by assigning each one to a specific `syft.framework.hook`, i.e. `syft.torch.hook`, but then that's a lot of global state to maintain, so we'd probably want a solid way of dealing with that.  Right now it's a bit hand wavy how this is handled, but it's definitely been on my todo list.",might concern multiple one script global state might need reference one hook one specific lot global state maintain probably want solid way dealing right bit hand wavy handled definitely list,issue,positive,positive,neutral,neutral,positive,positive
532146656,"I meet the same error, I think “torch==1.1” in requirements.txt case this bug, however there is no version 1.1, it mast be 1.1.0  for the mark ""=="". I change the  requirements.txt and install it. it's running well.",meet error think case bug however version mast mark change install running well,issue,negative,neutral,neutral,neutral,neutral,neutral
530493825,"And it does indeed look like it double simplification is intended, as in ""simplified (bool): in some cases we want to pass in data which has already been simplified - in which case we must skip double simplification - which would be bad.... so bad... so... so bad"" in [L246 of serde.py](https://github.com/OpenMined/PySyft/blob/dev/syft/serde/serde.py#L246). So the current focus is on simplifying the output and not the `simplify` process in `serde`. Will need time to study the ""data structures"" used in PySyft a bit more before such a goal can be achieved. ",indeed look like double simplification intended simplified bool want pas data already simplified case must skip double simplification would bad bad bad current focus output simplify process need time study data used bit goal,issue,negative,negative,negative,negative,negative,negative
530434638,"> Not a problem @niklausliu! We're happy to have people passionate about the project like yourself. It seems this particular issue has gotten off-topic. I'd suggest you post your questions in the #team_pysyft channel on Slack and give 1-2 days for someone to reply. If not, submit a new issue here.

OK, I got it! Thank you for your help!!!",problem happy people passionate project like particular issue gotten suggest post channel slack give day someone reply submit new issue got thank help,issue,positive,positive,positive,positive,positive,positive
530431996,"Not a problem @niklausliu!  We're happy to have people passionate about the project like yourself.  It seems this particular issue has gotten off-topic.  I'd suggest you post your questions in the #team_pysyft channel on Slack and give 1-2 days for someone to reply.  If not, submit a new issue here.",problem happy people passionate project like particular issue gotten suggest post channel slack give day someone reply submit new issue,issue,positive,positive,positive,positive,positive,positive
530431301,"> > Thanks for your help. I am going to modify my code. Can you leave me your email address? I think maybe I still have a lot of bugs, because this is my first time using pysyft.
> 
> @niklausliu - **We're happy to help in the OpenMined community.** But as a general rule, we're not tech support. While you may have a problem running PySyft, and there may be a legitimate issue here, **everyone** who works on the OpenMined project works for free. If we spent all of our time fixing people's implementations of PySyft, we'd never have time to write code for PySyft itself.
> Either way, providing our personal email addresses so that you can ping us questions is not acceptable.
> 
> I'm going to close this issue for now as it seems that problem you're now having is totally unrelated to the original issue. If that's not the case, please send me a message on Slack and I'll be happy to re-open the issue.

I am sorry for my impoliteness. However, I did not ask OpenMined workers to provide me with free technical support. It may be that there is a problem with my expression. I apologize again for this. I really appreciate the efforts of the OpenMined workers for the PySyft project, and I hope to contribute to the community as a whole.",thanks help going modify code leave address think maybe still lot first time happy help community general rule tech support may problem running may legitimate issue everyone work project work free spent time fixing people never time write code either way providing personal ping u acceptable going close issue problem totally unrelated original issue case please send message slack happy issue sorry impoliteness however ask provide free technical support may problem expression apologize really appreciate project hope contribute community whole,issue,positive,positive,positive,positive,positive,positive
530418160,"> Thanks for your help. I am going to modify my code. Can you leave me your email address? I think maybe I still have a lot of bugs, because this is my first time using pysyft.

@niklausliu - **We're happy to help in the OpenMined community.**  But as a general rule, we're not tech support.  While you may have a problem running PySyft, and there may be a legitimate issue here, **everyone** who works on the OpenMined project works for free.  If we spent all of our time fixing people's implementations of PySyft, we'd never have time to write code for PySyft itself. 
 Either way, providing our personal email addresses so that you can ping us questions is not acceptable.

I'm going to close this issue for now as it seems that problem you're now having is totally unrelated to the original issue.  If that's not the case, please send me a message on Slack and I'll be happy to re-open the issue.",thanks help going modify code leave address think maybe still lot first time happy help community general rule tech support may problem running may legitimate issue everyone work project work free spent time fixing people never time write code either way providing personal ping u acceptable going close issue problem totally unrelated original issue case please send message slack happy issue,issue,positive,positive,positive,positive,positive,positive
530415668,"> They were recently added to pysyft, so they are not included in the main documentation yet.
> 
> You can take a look at the modules here:
> https://github.com/OpenMined/PySyft/blob/dev/syft/frameworks/torch/nn/rnn.py
> 
> But in fact, they work exactly as PyTorch API (same args, etc.) you just need to import them from `syft.frameworks.torch.nn` (eg: `from syft.frameworks.torch.nn import GRU, LSTM, RNN` ) and manage them the same way you would manage a pytorch GRU

Thanks for your help. I will adjust my code again and I will tell you any updates. Thank you again for your help.",recently added included main documentation yet take look fact work exactly need import import manage way would manage thanks help adjust code tell thank help,issue,positive,positive,positive,positive,positive,positive
530412781,"They were recently added to pysyft, so they are not included in the main documentation yet.

You can take a look at the modules here:
https://github.com/OpenMined/PySyft/blob/dev/syft/frameworks/torch/nn/rnn.py

But in fact, they work exactly as PyTorch API (same args, etc.) you just need to import them from `syft.frameworks.torch.nn` (eg: `from syft.frameworks.torch.nn import GRU, LSTM, RNN` ) and manage them the same way you would manage a pytorch GRU",recently added included main documentation yet take look fact work exactly need import import manage way would manage,issue,negative,positive,positive,positive,positive,positive
530410878,"> @niklausliu I found out what your error is: you are using pytorch native GRUs and hooking torch. We do not support hooking pytorch's native RNNs at the moment, you should import the GRU module from `syft.frameworks.torch.nn`.
> 
> Please be aware syft RNNs modules work for federated learning and MPC prediction only (MPC training is not currently supported)

And I can not find syft.framworks.torch.nn in this website https://pysyft.readthedocs.io/en/latest/modules/syft.core.frameworks.html ",found error native torch support native moment import module please aware work learning prediction training currently find,issue,negative,positive,positive,positive,positive,positive
530409387,"> @niklausliu I found out what your error is: you are using pytorch native GRUs and hooking torch. We do not support hooking pytorch's native RNNs at the moment, you should import the GRU module from `syft.frameworks.torch.nn`.
> 
> Please be aware syft RNNs modules work for federated learning and MPC prediction only (MPC training is not currently supported)

But I have seen many examples of syft GRUs module and have not found any difference with my pytorch native GRUs. Can you give me a few examples of the syft GRUs module?
",found error native torch support native moment import module please aware work learning prediction training currently seen many module found difference native give module,issue,negative,positive,positive,positive,positive,positive
530324566,"> @niklausliu I found out what your error is: you are using pytorch native GRUs and hooking torch. We do not support hooking pytorch's native RNNs at the moment, you should import the GRU module from `syft.frameworks.torch.nn`.
> 
> Please be aware syft RNNs modules work for federated learning and MPC prediction only (MPC training is not currently supported)

Thanks for your help. I am going to modify my code. Can you leave me your email address? I think maybe I still have a lot of bugs, because this is my first time using pysyft.",found error native torch support native moment import module please aware work learning prediction training currently thanks help going modify code leave address think maybe still lot first time,issue,positive,positive,positive,positive,positive,positive
530320901,"@niklausliu I found out what your error is: you are using pytorch native GRUs and hooking torch. We do not support hooking pytorch's native RNNs at the moment, you should import the GRU module from `syft.frameworks.torch.nn`.

Please be aware syft RNNs modules work for federated learning and MPC prediction only (MPC training is not currently supported)",found error native torch support native moment import module please aware work learning prediction training currently,issue,negative,positive,positive,positive,positive,positive
530318715,"> Can you please print the output you get from your dataset before and after hooking torch?

![image](https://user-images.githubusercontent.com/31737021/64689389-db537580-d4c0-11e9-8718-1e374d581df4.png)
",please print output get torch image,issue,negative,neutral,neutral,neutral,neutral,neutral
530318231,"> Can you please print the output you get from your dataset before and after hooking torch?
![image](https://user-images.githubusercontent.com/31737021/64689120-4781a980-d4c0-11e9-95d4-6ea294a36e95.png)

![image](https://user-images.githubusercontent.com/31737021/64689149-5cf6d380-d4c0-11e9-94f4-75359fe1e289.png)

![image](https://user-images.githubusercontent.com/31737021/64689251-929bbc80-d4c0-11e9-9a5b-737aba54f4d9.png)

![image](https://user-images.githubusercontent.com/31737021/64689279-9cbdbb00-d4c0-11e9-9966-108178b67676.png)
",please print output get torch image image image image,issue,negative,neutral,neutral,neutral,neutral,neutral
530317688,Still need an admin of OpenMined on Docker Hub to give me rights to push the image into openmined/pysyft-worker to close this PR,still need docker hub give push image close,issue,negative,neutral,neutral,neutral,neutral,neutral
530303614,Can you please print the output you get from your dataset before and after hooking torch?,please print output get torch,issue,negative,neutral,neutral,neutral,neutral,neutral
530299225,"> > Well, I believe the issue is related to the suggestion I gave you, with the `.to(device)` statement, because I encountered similar errors when running it on a CPU/GPU using the `device`.
> > Alternatively, @andrelmfarias could have some other ideas?
> > Is what you posted the output of the code with the `.to(device)` statement removed at all places in your code?
> 
> But I found that I deleted all the statements about the device or the bug I described above.

Sorry, I mean, I deleted all the statements about the device, but it did not work and the bug still exists.",well believe issue related suggestion gave device statement similar running device alternatively could posted output code device statement removed code found device bug sorry mean device work bug still,issue,negative,negative,negative,negative,negative,negative
530288259,"> Well, I believe the issue is related to the suggestion I gave you, with the `.to(device)` statement, because I encountered similar errors when running it on a CPU/GPU using the `device`.
> 
> Alternatively, @andrelmfarias could have some other ideas?
> 
> Is what you posted the output of the code with the `.to(device)` statement removed at all places in your code?

But I found that I deleted all the statements about the device or the bug I described above.",well believe issue related suggestion gave device statement similar running device alternatively could posted output code device statement removed code found device bug,issue,negative,neutral,neutral,neutral,neutral,neutral
530283520,"Well, I believe the issue is related to the suggestion I gave you, with the `.to(device)` statement, because I encountered similar errors when running it on a CPU/GPU using the `device`.

Alternatively, @andrelmfarias  could have some other ideas?

Is what you posted the output of the code with the `.to(device)` statement removed at all places in your code?",well believe issue related suggestion gave device statement similar running device alternatively could posted output code device statement removed code,issue,negative,neutral,neutral,neutral,neutral,neutral
530281693,"Personally, I think we will need to remove them from the public API in the future and have a unique public syft.tensor abstraction. TBH, and speaking from my experience, it's a bit of pain to get used to these kinds of tensors and understand their behavior. It can be an entry barrier for new users.",personally think need remove public future unique public abstraction speaking experience bit pain get used understand behavior entry barrier new,issue,negative,positive,neutral,neutral,positive,positive
530281240,"> Yes, that's exactly what I meant. PySyft does not support CUDA GPUs yet, though we'd like to support this functionality in the future @robert-wagner
> 
> What is the result of running your code when removing all statements `.to(device)` @niklausliu ?

Thanks for your reply. But I have a new bug about rnn.py, you can see more detail as follow:

RuntimeError Traceback (most recent call last)
in ()
1 lr = 0.001
2 #batch_size = 64
----> 3 gru_model = train(federated_train_loader, lr, model_type=""GRU"")

in train(federated_train_loader, learn_rate, hidden_dim, EPOCHS, model_type)
48 print(x.shape)
49 print(label.shape)
---> 50 out, h = model(x, h)
51 loss = criterion(out, label.float())
52 loss.backward()

~/anaconda3/envs/pysyft/lib/python3.6/site-packages/torch/nn/modules/module.py in call(self, *input, **kwargs)
491 result = self._slow_forward(*input, **kwargs)
492 else:
--> 493 result = self.forward(*input, **kwargs)
494 for hook in self._forward_hooks.values():
495 hook_result = hook(self, input, result)

in forward(self, x, h)
10
11 def forward(self, x, h):
---> 12 out, h = self.gru(x, h)
13 out = self.fc(self.relu(out[:,-1]))
14 return out, h

~/anaconda3/envs/pysyft/lib/python3.6/site-packages/torch/nn/modules/module.py in call(self, *input, **kwargs)
491 result = self._slow_forward(*input, **kwargs)
492 else:
--> 493 result = self.forward(*input, **kwargs)
494 for hook in self._forward_hooks.values():
495 hook_result = hook(self, input, result)

~/anaconda3/envs/pysyft/lib/python3.6/site-packages/torch/nn/modules/rnn.py in forward(self, input, hx)
205 hx = self.permute_hidden(hx, sorted_indices)
206
--> 207 self.check_forward_args(input, hx, batch_sizes)
208 _impl = _rnn_impls[self.mode]
209 if batch_sizes is None:

~/anaconda3/envs/pysyft/lib/python3.6/site-packages/torch/nn/modules/rnn.py in check_forward_args(self, input, hidden, batch_sizes)
173
174 def check_forward_args(self, input, hidden, batch_sizes):
--> 175 self.check_input(input, batch_sizes)
176 expected_hidden_size = self.get_expected_hidden_size(input, batch_sizes)
177

~/anaconda3/envs/pysyft/lib/python3.6/site-packages/torch/nn/modules/rnn.py in check_input(self, input, batch_sizes)
151 raise RuntimeError(
152 'input.size(-1) must be equal to input_size. Expected {}, got {}'.format(
--> 153 self.input_size, input.size(-1)))
154
155 @weak_script_method

RuntimeError: input.size(-1) must be equal to input_size. Expected 5, got 0",yes exactly meant support yet though like support functionality future result running code removing device thanks reply new bug see detail follow recent call last train train print print model loss criterion call self input result input else result input hook hook self input result forward self forward self return call self input result input else result input hook hook self input result forward self input input none self input hidden self input hidden input input self input raise must equal got must equal got,issue,positive,positive,neutral,neutral,positive,positive
530280188,"Yes, that's exactly what I meant. PySyft does not support CUDA GPUs yet, though we'd like to support this functionality in the future @robert-wagner 

What is the result of running your code when removing all statements `.to(device)` @niklausliu ?",yes exactly meant support yet though like support functionality future result running code removing device,issue,positive,positive,positive,positive,positive,positive
530279240,"> Can you please show me how the `device` variable is defined?
> 
> Also, you may want to try your code without the `.to(device)` call in your code.
```python
# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False
is_cuda = torch.cuda.is_available()

# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.
if is_cuda:
    device = torch.device(""cuda"")
else:
    device = torch.device(""cpu"")
```",please show device variable defined also may want try code without device call code python true available else return false available set device use device variable later code device else device,issue,positive,positive,positive,positive,positive,positive
530273525,"Can you please show me how the `device` variable is defined?

Also, you may want to try your code without the `.to(device)` call in your code.",please show device variable defined also may want try code without device call code,issue,negative,neutral,neutral,neutral,neutral,neutral
530267383,I am running the tutorial on my macOS Mojave 10.14.4 and it's running without errors too.,running tutorial running without,issue,negative,neutral,neutral,neutral,neutral,neutral
530262646,"> When using `model.to(device)` you are trying to move your data structure to a GPU, right? Well, as far as I know, this operation is not supported in PySyft yet. Keep the computation on the CPU for now.

Thanks for your reply. I solved my previous problem because the version of PySyft was too old. Now there is a new bug.
RuntimeError                              Traceback (most recent call last)
<ipython-input-62-6d641218ab70> in <module>()
      1 lr = 0.001
      2 #batch_size = 64
----> 3 gru_model = train(federated_train_loader, lr, model_type=""GRU"")

<ipython-input-61-0ac6d91a093c> in train(federated_train_loader, learn_rate, hidden_dim, EPOCHS, model_type)
     48             print(x.shape)
     49             print(label.shape)
---> 50             out, h = model(x, h)
     51             loss = criterion(out, label.float())
     52             loss.backward()

~/anaconda3/envs/pysyft/lib/python3.6/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    491             result = self._slow_forward(*input, **kwargs)
    492         else:
--> 493             result = self.forward(*input, **kwargs)
    494         for hook in self._forward_hooks.values():
    495             hook_result = hook(self, input, result)

<ipython-input-54-a172098b1c99> in forward(self, x, h)
     10 
     11     def forward(self, x, h):
---> 12         out, h = self.gru(x, h)
     13         out = self.fc(self.relu(out[:,-1]))
     14         return out, h

~/anaconda3/envs/pysyft/lib/python3.6/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    491             result = self._slow_forward(*input, **kwargs)
    492         else:
--> 493             result = self.forward(*input, **kwargs)
    494         for hook in self._forward_hooks.values():
    495             hook_result = hook(self, input, result)

~/anaconda3/envs/pysyft/lib/python3.6/site-packages/torch/nn/modules/rnn.py in forward(self, input, hx)
    205             hx = self.permute_hidden(hx, sorted_indices)
    206 
--> 207         self.check_forward_args(input, hx, batch_sizes)
    208         _impl = _rnn_impls[self.mode]
    209         if batch_sizes is None:

~/anaconda3/envs/pysyft/lib/python3.6/site-packages/torch/nn/modules/rnn.py in check_forward_args(self, input, hidden, batch_sizes)
    173 
    174     def check_forward_args(self, input, hidden, batch_sizes):
--> 175         self.check_input(input, batch_sizes)
    176         expected_hidden_size = self.get_expected_hidden_size(input, batch_sizes)
    177 

~/anaconda3/envs/pysyft/lib/python3.6/site-packages/torch/nn/modules/rnn.py in check_input(self, input, batch_sizes)
    151             raise RuntimeError(
    152                 'input.size(-1) must be equal to input_size. Expected {}, got {}'.format(
--> 153                     self.input_size, input.size(-1)))
    154 
    155     @weak_script_method

RuntimeError: input.size(-1) must be equal to input_size. Expected 5, got 0",device trying move data structure right well far know operation yet keep computation thanks reply previous problem version old new bug recent call last dab module train train print print model loss criterion self input result input else result input hook hook self input result forward self forward self return self input result input else result input hook hook self input result forward self input input none self input hidden self input hidden input input self input raise must equal got must equal got,issue,negative,positive,neutral,neutral,positive,positive
530253482,"Running the code on Ubuntu 18.04 LTS, but not getting any error. It's training just fine. ",running code getting error training fine,issue,negative,positive,positive,positive,positive,positive
530250492,"When using `model.to(device)` you are trying to move your data structure to a GPU, right? Well, as far as I know, this operation is not supported in PySyft yet. Keep the computation on the CPU for now.",device trying move data structure right well far know operation yet keep computation,issue,negative,positive,positive,positive,positive,positive
529994538,"> Can we wait for this PR to be merged? #2590
> 
> We need this for some pending Grid PRs

Sure!",wait need pending grid sure,issue,negative,positive,positive,positive,positive,positive
529976551,"Can we wait for this PR to be merged? https://github.com/OpenMined/PySyft/pull/2590

We need this for some pending Grid PRs",wait need pending grid,issue,negative,neutral,neutral,neutral,neutral,neutral
529761266,Yes but that also include other libraries that are not important for the given bug.,yes also include important given bug,issue,positive,positive,positive,positive,positive,positive
529725570,Hey @Ankit-Dhankhar This functionality is accomplished by either pip list or conda env list.,hey functionality accomplished either pip list list,issue,negative,positive,positive,positive,positive,positive
529409605,"Is anyone actually using the syft.<tensor type> ones? If it's only being used sparingly could we just move them to ""torch.<tensor type>"" instead?",anyone actually tensor type used sparingly could move tensor type instead,issue,negative,neutral,neutral,neutral,neutral,neutral
529198502,"Thanks @LaRiffle ! 
I used PyTorch 1.1.0. but 1.2.0 also shows the same. so could you let me know more clearly how to deactivate the `multiprocessing`?
and what time line you will add GPU support? MNIST is very simple task so it's okay to use CPU, but typically GPU is very critical and inevitable to train a big model and big data.
",thanks used also could let know clearly deactivate time line add support simple task use typically critical inevitable train big model big data,issue,positive,positive,neutral,neutral,positive,positive
529129902," I agree we have quite some work to do, and I did not intend to suggest a timeline for this work.  But better to make the issue public now so people know this is an open question.

Also, *most* of the tensors are in `syft/frameworks/torch`. `PointerTensor` and `MultiPointerTensor` have already been moved into `syft/generic/pointers`.",agree quite work intend suggest work better make issue public people know open question also already,issue,positive,positive,positive,positive,positive,positive
529128293,"That's strange, I have torch.Size([3])
Maybe update the syft package and rerun this snippet",strange maybe update package rerun snippet,issue,negative,negative,neutral,neutral,negative,negative
529128162,"Hey!
Thanks for thee feedback,
So only CPU is supported currently :/ this explains PB 1
Regarding the 2nd one, which version of PyTorch are you using? I think `multiprocessing` is responsible for the failure, and should be deactivated is this makes sense",hey thanks thee feedback currently regarding one version think responsible failure sense,issue,negative,positive,neutral,neutral,positive,positive
529123898,"That's an interesting point, but maybe we are a bit ahead of schedule. These tensors are currently all in the torch module `syft/frameworks/torch`, and there is still a bit of work in ordeer to make careful choices about which can live outside of it, as many of them are very unrelated to using pytorch. As soon as we have made these choices, I believe it would be good to remove them of the public API and have instead `sy.tensor.SyftTensor` or smthg like this.
We must keep in mind that there will be many developers for quite a bit of time here, so it's important to keep short and comprehensive paths.",interesting point maybe bit ahead schedule currently torch module still bit work make careful live outside many unrelated soon made believe would good remove public instead like must keep mind many quite bit time important keep short comprehensive,issue,positive,positive,positive,positive,positive,positive
529113086,"Don't you think that it works if we overload it and use the following method definition:
```
def reciprocal(self):
    return (0*self + 1) / self
```

?",think work overload use following method definition reciprocal self return self self,issue,negative,neutral,neutral,neutral,neutral,neutral
529087009,@wentaiwu92 ，this bug also got in the way of using much more data residing on each virtual machine to train the local model. Now I convinced myself to treat this as a forced computing constraint in practice. ,bug also got way much data virtual machine train local model convinced treat forced constraint practice,issue,negative,negative,neutral,neutral,negative,negative
529084939,"Hi, @Y-Xu. Unluckily no solution yet, _clear_objects()_ doesn't work probably means that there is one or more references (to the batch data) remained somewhere we don't know even though you attempt to release one from the virtual workers.

Only thing that I can do is to avoid too many epochs in one run.

I hope the leak problem could be noticed by the developers of this repo.",hi unluckily solution yet work probably one batch data somewhere know even though attempt release one virtual thing avoid many one run hope leak problem could,issue,negative,positive,positive,positive,positive,positive
529065952,"Hi, @wentaiwu92, I also encountered the same problem, and I have tried to clear_objects() all the data distributed to different virtual worker every time after each epoch and then reload the data, but it didn't work. The memory still increased along with the training iterations. Did you get any solution? ",hi also problem tried data distributed different virtual worker every time epoch reload data work memory still along training get solution,issue,negative,neutral,neutral,neutral,neutral,neutral
528986616,We need to clarify who the users of this tensor system are in order to make any decision about how public their API should be. Are data scientists/machine learning engineers expected to use these tensors? Are they PySyft contributors? Are they developers of other OpenMined projects and/or developers of ecosystem projects?,need clarify tensor system order make decision public data learning use ecosystem,issue,negative,neutral,neutral,neutral,neutral,neutral
528983330,">I'm inclined to remove things that are only exposed for internal development.

Well, unfortunately there are a number of places that rely on tensor being exposed in the `syft` namespace.  I'm taking this to mean that we have a lot more circularity than we want throughout the code (in particular, tensors seem to be highly intertwined).  Whether this is okay or not, and whatever we end up doing about it, is almost definitely out of scope.  I will keep tensor types in the `syft` namespace until we figure that out.

Opened a discussion issue around this in #2600 ",remove exposed internal development well unfortunately number rely tensor exposed taking mean lot circularity want throughout code particular seem highly whether whatever end almost definitely scope keep tensor figure discussion issue around,issue,negative,negative,neutral,neutral,negative,negative
528980686,"But what we used to overload is functions from torch calling C code, I think it's a bit different, here...",used overload torch calling code think bit different,issue,negative,neutral,neutral,neutral,neutral,neutral
528907487,"@LaRiffle

>However, it will make it harder for people to import objects in their notebook and so on, so I think we should be generous in syft/init.py to provide many shortcuts just like we can currently call sy.PointerTensor(...). This should include all tensors, workers, and objects a normal user is expected to play with (I believe many of them are already there).

In fact, I don't think many things other than the hook and workers are used in the notebooks. It seems very few tensors actually need to be exposed -- PointerTensor/MultiPointerTensor seem to be abstracted away from the user, and similar for the various precision & crypto tensors.

I'm inclined to remove things that are only exposed for internal development. The more we add to `syft/__init__.py`, the more complex our import graph gets. That quickly becomes a much bigger headache than having to add a specific import statement for the class I'm using inside of syft internals.",however make harder people import notebook think generous provide many like currently call include normal user play believe many already fact think many hook used actually need exposed seem abstracted away user similar various precision remove exposed internal development add complex import graph quickly becomes much bigger headache add specific import statement class inside internals,issue,positive,positive,positive,positive,positive,positive
528876139,"Hm -- on the one hand, I like the idea of moving to torchvision because the datasets are a bit less trivially solved than the ones in sklearn.  On the other hand, we're moving away from having pytorch be a required dependency (see for example [this RFC](https://github.com/OpenMined/rfcs/blob/master/20190808-modular-pysyft-frameworks.md) and [these PRs](https://github.com/OpenMined/PySyft/pulls?utf8=%E2%9C%93&q=generalize)).  Similarly, one might want to create a TF version of the sandbox in the PySyft-TensorFlow repo once that code is ready.

I think we should keep the sklearn sandbox here for now, since people seem to use it.  But I also think once we move the frameworks out to PySyft-PyTorch and PySyft-TensorFlow, those repos might want to have their own versions of the sandbox that are a bit more suitable for experimenting with deep learning.

What do you think?",one hand like idea moving bit le trivially hand moving away dependency see example similarly one might want create version sandbox code ready think keep sandbox since people seem use also think move might want sandbox bit suitable deep learning think,issue,positive,positive,positive,positive,positive,positive
528753873,"Yes, I think we should overload it.

This is the same problem we have with dropout and we had with RNNs, they are implemented natively in C++ so we have to overload them. Similarly to what you did with `conv2d`.",yes think overload problem dropout natively overload similarly,issue,negative,neutral,neutral,neutral,neutral,neutral
528751857,"Hi!
I tried to do that but PyTorch's `__rdiv__` is called and returns basically `self.reciprocal() * other` where reciprocal is implemented in C. So I'm not sure how to do that, does anybody have a clue? Could we overload `.reciprocal()`?",hi tried basically reciprocal sure anybody clue could overload,issue,negative,positive,positive,positive,positive,positive
528691723,"@jvmancuso  What do you think about completely removing sklearn dependency (instead of throwing Import Error) and in-place of that use torchvision like module for loading datasets?

If this sounds good I can make required changes for that?",think completely removing dependency instead throwing import error use like module loading good make,issue,negative,positive,positive,positive,positive,positive
527819693,"> If you are willing to add more links to the paper in the fit and _compute_pvalues methods (as you have made in other parts of the code), I promise I will review it as well

For the fit method, you can take a look at Section 2 of [Bloom's paper](https://arxiv.org/pdf/1901.09531.pdf) (it's much easier to understand that the ones about crypto protocols we were discussing 😃) and at this [demo notebook](https://github.com/jbloom22/DASH/blob/master/multiparty_linear_regression.ipynb) I pushed to his repo. You can also find the p-values formula in the notebook, which I took from [Bloom's script in R](https://github.com/jbloom22/DASH/blob/master/dash.r). 

The idea of p-value computation is that, **under the hypothesis H0 that a coefficient is 0**, the t-statistic `coeff / sigma` follows a Student's t-distribution. The pvalue is the probability of getting a larger value than our empirical computed value under the hypothesis that the ""true value"" is 0, we compute it by using the value of the cumulated probability at the tails of the distribution (`2 * t.cdf(- statistic)`. I did my best to explain it here, but it's much better and intuitive to do it on a board 😞 ...

> except that you should also add the case fit_intercept=False in your test. (you can use @pytest.mark.parametrize)

Will do",willing add link paper fit made code promise review well fit method take look section bloom paper much easier understand notebook also find formula notebook took bloom script idea computation hypothesis coefficient sigma student probability getting value empirical value hypothesis true value compute value probability distribution statistic best explain much better intuitive board except also add case test use,issue,positive,positive,positive,positive,positive,positive
527803009,"We were thinking that maybe we could ""hook"" some operations from their github repository: https://github.com/KULeuven-COSIC/SCALE-MAMBA

To use their protocols without needing to implement them ourselves in PySyft.

I don't know if it's clear...",thinking maybe could hook repository use without needing implement know clear,issue,negative,positive,positive,positive,positive,positive
527686889,"> We are given an input of shape (batch_size, channels, height, width) and we output a (batch_size, channels, height/stride, width/stride) tensor. (I omit padding and dilation here, suppose also that kernel_size << height). What we can do is to build an intermediary matrix of shape (batch_size, channels, height * width / stride**2, kernel_size[0] * kernel_size[1]) from a kind of convolution operation and apply max only once on the last dimension. Hopefully this would vectorize the job and get much faster.

Nice, I'll try this ASAP. About the max operation, I've tried it but I went with the maxpool securenn operation since only 1-dim and 2-dim tensors were supported.",given input shape height width output tensor omit padding dilation suppose also height build intermediary matrix shape height width stride kind convolution operation apply last dimension hopefully would job get much faster nice try operation tried went operation since,issue,positive,positive,positive,positive,positive,positive
527686572,"> Have you considered avgpooling as well?

Yes! I've discussed this with @andrelmfarias. I'll implement it as soon as I have the time.",considered well yes implement soon time,issue,positive,neutral,neutral,neutral,neutral,neutral
527550300,"So actually you should have to do it, even if it doesn't raise an error: even if you work with integers, fix precision elements are in a field while integers are not, so it is a  best practice. And actually for some reason it doesn't work if you don't do it (argmax does smthg strange)
Same for crypto provider, it should be possible to not explicitoit,  but it doesn't work for some reason :/",actually even raise error even work fix precision field best practice actually reason work strange provider possible work reason,issue,negative,positive,positive,positive,positive,positive
527511660,"@mortendahl we were discussing SCALE-MAMBA last week, @LaRiffle and I were thinking about trying to ""hook"" it for some MPC operations...",last week thinking trying hook,issue,negative,neutral,neutral,neutral,neutral,neutral
527509325,I assumed that I did not need fix precision encoding on an integer tensor. The need for an explicit crypto provider wasn't clear to me either. Could you explain on both?,assumed need fix precision integer tensor need explicit provider clear either could explain,issue,negative,positive,positive,positive,positive,positive
527508852,Thank you! I checked that both modifications are necessary to fix the problem.,thank checked necessary fix problem,issue,negative,neutral,neutral,neutral,neutral,neutral
527496874,"This should work :)
Add a crypto_provider and call fix_precision() 

```python
import torch
import syft as sy
hook = sy.TorchHook(torch)

alice = sy.VirtualWorker(hook, 'alice')
bob = sy.VirtualWorker(hook, 'bob')
crypto_provider = sy.VirtualWorker(hook, 'crypto_provider')

a = torch.arange(6).fix_precision()
enc_a = a.share(alice, bob, crypto_provider=crypto_provider)
print(enc_a.argmax())
```",work add call python import torch import hook torch hook bob hook hook bob print,issue,negative,neutral,neutral,neutral,neutral,neutral
527463635,"@LaRiffle I suggest you take a look in the [SCALE-MAMBA documentation](https://homes.esat.kuleuven.be/~nsmart/SCALE/Documentation.pdf). Note that some of those protocols might be slower versions that are used to support any `n`, and hence there may be better protocols for the two-party case.",suggest take look documentation note might used support hence may better case,issue,positive,positive,positive,positive,positive,positive
527380934,"This was also solved by changing the gcc version to a more recent one using:
`export CC=/usr/local/Cellar/gcc/9.2.0/bin/gcc-9`
`export CFLAGS=""-Wa,-q""`
and then running:
`pip install --upgrade --force-reinstall zstd`",also version recent one export export running pip install upgrade,issue,negative,neutral,neutral,neutral,neutral,neutral
527292148,"> I found a workaround that worked for my needs. The trick is to hook pysyft **after** you move your model to cuda.

what do you mean？ Hook the worker？But if you hook after these, how can you make federated dataset? For example,in the tutorial example>advanced>CIFAR10. Can you post your code",found worked need trick hook move model hook hook make example tutorial example advanced post code,issue,negative,positive,positive,positive,positive,positive
527189559,I found a workaround that worked for my needs. The trick is to hook pysyft **after** you move your model to cuda.,found worked need trick hook move model,issue,negative,neutral,neutral,neutral,neutral,neutral
527172579,"@LaRiffle @mari-linhares just made the changes, please check if everything looks right. Thanks!",made please check everything right thanks,issue,positive,positive,positive,positive,positive,positive
526991422,"@mari-linhares Hi, this PR has been silent for a while, even though I believe the changes requested should be reviewed. I'm not sure if in that case I should mark the conversations as resolved, so that another approval is done.

Just in case, I indicate in each revision that a `FloatPrecisionTensor` is a normal torch `Tensor`, and there is no class called `FloatPrecisionTensor` (I checked). If this is the case, then the tests need no modification. 

I'd be happy if I could receive some feedback from you. I almost forgot I did this PR and would like to see float precision on pointers working for some projects I'm working on.

Thanks! ",hi silent even though believe sure case mark resolved another approval done case indicate revision normal torch tensor class checked case need modification happy could receive feedback almost forgot would like see float precision working working thanks,issue,positive,positive,positive,positive,positive,positive
526861014,"It is indeed a bug I have come to realise, since in the line https://github.com/OpenMined/PySyft/blob/dev/syft/serde/serde.py#L289 one is supposed to be able to turn off `details` for the `deserialise` function in order to hide all the gory details in the deserialised object, but that is not the case at the moment. 

If I attempt to set the `details` attribute to `False` the following error would be thrown:
```
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-2-8192b19c7fd5> in <module>
      5     return x
      6 
----> 7 x = th.tensor([1,2,3]).send(bob)
      8 
      9 sy.serde._simplify(x.child)

~/PySyft/syft/frameworks/torch/tensors/interpreters/native.py in send(self, inplace, local_autograd, preinitialize_grad, no_wrap, garbage_collect_data, *location)
    394                 local_autograd=local_autograd,
    395                 preinitialize_grad=preinitialize_grad,
--> 396                 garbage_collect_data=garbage_collect_data,
    397             )
    398 

~/PySyft/syft/workers/base.py in send(self, obj, workers, ptr_id, garbage_collect_data, **kwargs)
    354 
    355         # Send the object
--> 356         self.send_obj(obj, worker)
    357 
    358         return pointer

~/PySyft/syft/workers/base.py in send_obj(self, obj, location)
    532                 receive the object.
    533         """"""
--> 534         return self.send_msg(messaging.ObjectMessage(obj), location)
    535 
    536     def request_obj(self, obj_id: Union[str, int], location: ""BaseWorker"") -> object:

~/PySyft/syft/workers/base.py in send_msg(self, message, location)
    236 
    237         # Step 2: send the message and wait for a response
--> 238         bin_response = self._send_msg(bin_message, location)
    239 
    240         # Step 3: deserialize the response

~/PySyft/syft/workers/virtual.py in _send_msg(self, message, location)
      8 class VirtualWorker(BaseWorker, FederatedClient):
      9     def _send_msg(self, message: bin, location: BaseWorker) -> bin:
---> 10         return location._recv_msg(message)
     11 
     12     def _recv_msg(self, message: bin) -> bin:

~/PySyft/syft/workers/virtual.py in _recv_msg(self, message)
     11 
     12     def _recv_msg(self, message: bin) -> bin:
---> 13         return self.recv_msg(message)

~/PySyft/syft/workers/base.py in recv_msg(self, bin_message)
    265         msg = sy.serde.deserialize(bin_message, worker=self)
    266 
--> 267         (msg_type, contents) = (msg.msg_type, msg.contents)
    268 
    269         if self.verbose:

AttributeError: 'tuple' object has no attribute 'msg_type'
```
So I guess I will need to work on perfecting the `verbose` option for the worker(s) say the `local_worker` at least. ",indeed bug come since line one supposed able turn function order hide gory object case moment attempt set attribute false following error would thrown recent call last module return bob send self location send self send object worker return pointer self location receive return location self union location object self message location step send message wait response location step response self message location class self message bin location bin return message self message bin bin self message self message bin bin return message self content object attribute guess need work perfecting verbose option worker say least,issue,negative,negative,neutral,neutral,negative,negative
526591249,Let me not wait on @iamtrask for feedback and start look into it deeper. Sorry about the delay. ,let wait feedback start look sorry delay,issue,negative,negative,negative,negative,negative,negative
526590263,I will work on it anyways then... Hopefully no doubly duplicated efforts. ,work anyways hopefully doubly,issue,negative,neutral,neutral,neutral,neutral,neutral
526108882,"This also fix RNN tests, what was also proposed on #2545.

RNN can now be tested with higher hyperparameters and moved back from `integration` repo",also fix also tested higher back integration,issue,negative,positive,positive,positive,positive,positive
525904766,"TL;DR: torch 1.1.0.

Syft uses torch <= 1.1.0 at this moment. But torch >= 1.1.0 has issues with jit.trace which this tutorial relies on. So if you want to run the tutorial you need to downgrade torch to 1.0.1.",torch torch moment torch tutorial want run tutorial need downgrade torch,issue,negative,neutral,neutral,neutral,neutral,neutral
525874081,"Just a small report, I'm running into a similar error, but it appears a few lines earlier:
```
exp_avg.mul_(beta1).add_(1 - beta1, grad)
```

The following error appears:
```
TypeError: add_() takes 1 positional argument but 2 were given
```

So it's to be a more general problem than only specific functions like `addcmul_()` and `addcdiv_()`",small report running similar error beta beta grad following error positional argument given general problem specific like,issue,negative,negative,neutral,neutral,negative,negative
525739406,"I've the exact same issue seems to me that torch 1.2 (latest) isn't compatible with syft ?.
Any suggestions ",exact issue torch latest compatible,issue,negative,positive,positive,positive,positive,positive
525710766,"> Did you try to load the model without hooking torch?

Yes, it works just fine.",try load model without torch yes work fine,issue,negative,positive,positive,positive,positive,positive
525674468,"Alright then, I might task quite sometime before begin to do this so if anybody else is interested they can work on this. ",alright might task quite sometime begin anybody else interested work,issue,positive,positive,positive,positive,positive,positive
525630036,"Weird... I don't think there is a `native_avg_pool2d` in Pytorch, only `avg_pool2d`. Did you try to load the model without hooking torch?

Maybe the hook changes the name of the method...",weird think try load model without torch maybe hook name method,issue,negative,negative,negative,negative,negative,negative
525449897,@kamathhrishi Might want to check the work I've already begun here: https://github.com/OpenMined/PySyft-TensorFlow/tree/master/syft_tensorflow,might want check work already begun,issue,negative,neutral,neutral,neutral,neutral,neutral
525433400,"A good starting point would be to create a torch tensor, call .tensorflow() and show arithmetic and logical operations with output being a tensorflow tensor wrapped with pytorch tensor and same applied to fixedprecision and additiveshared? ",good starting point would create torch tensor call show arithmetic logical output tensor wrapped tensor applied,issue,positive,positive,positive,positive,positive,positive
525432025,"I could give it a try, could you elaborate more on an example where using TensorFlow would be more useful?  Shouldn't we also overload TensorFlow to work with the chain of tensors? ",could give try could elaborate example would useful also overload work chain,issue,negative,positive,positive,positive,positive,positive
524934087,"@iamtrask and @LaRiffle pointed out that serializing workers is not actually a problem since this consists basically of sending the worker id over the wire.

But the problem is that currently only VirtualWorkers are serializable which means that GridWorkers or WebsocketWorkers will not be able to run these operations.",pointed actually problem since basically sending worker id wire problem currently able run,issue,negative,positive,positive,positive,positive,positive
524906668,">For this PR, @cereallarceny wanted to have packages with constants that can be installed though package installers (pip/npm/etc). I think equivalent for that is having .proto files compiled to different languages in and resulting classes exposed in installable packages (in a separate repo).
I think, in theory this looks good as it separates protocol schema from PySyft code and makes it single point of truth for all dependent projects (including PySyft). In practice it will require more steps when making changes to PySyft and some additional process to version protocol schema itself.

That is exactly what the RFC is trying to do, but we're proposing to use protobuf because it is a more mature version of what seems to be happening here. I think Andrew put it best here https://github.com/OpenMined/rfcs/pull/6#issuecomment-524902438, so I'll defer any further discussion on it there.

I'd also just mention that there are several benefits without including simplifiers/detailers in this standardization, one of which is defining the serialization/deserialization structure/procedures in one place (essentially, achieving parity with this PR), making it more performant (because the structs are predefined), and making it more secure (protobufs have a ton of security-scrutiny from larger orgs).",though package think equivalent different resulting class exposed separate think theory good separate protocol schema code single point truth dependent practice require making additional process version protocol schema exactly trying use mature version happening think put best defer discussion also mention several without standardization one one place essentially parity making performant making secure ton,issue,positive,positive,positive,positive,positive,positive
524797461,@vvmnnnkv There's a few conflicts now.  Please resolve them and I'll take another look.,please resolve take another look,issue,positive,neutral,neutral,neutral,neutral,neutral
524679555,"Created PR to fix this: https://github.com/OpenMined/PySyft/pull/2555

There is harmful defensive code (that I removed) on `dataset_federate` function. It was checking for the data/train_data/test_data/targets/train_labels/test_labels fields in the dataset in a mandatory way. Which is not needed, and it's causing an exception that shouldn't exist.
What matters is that on each iteration of the dataset, it has to return a tuple in the form (data, target), which ImageFolder complies.
With the fix, `ImageFolder` and other datasets with the same problem now can be federated with `.federate()`

@iamtrask can you please review?",fix harmful defensive code removed function mandatory way causing exception exist iteration return form data target fix problem please review,issue,negative,neutral,neutral,neutral,neutral,neutral
524669364,"This error appears when you haven't hooked PySyft:
`hook = sy.TorchHook(torch) `
`bob = sy.VirtualWorker(hook, id=""bob"") `

Can you review you did that?",error hooked hook torch bob hook bob review,issue,negative,neutral,neutral,neutral,neutral,neutral
524605924,"> This is not the case, see here and here.

@jvmancuso hmm, I thought the goal was to replace serde implementation in it's current form. I.e. instead of recursively simplifying objects to basic python types (tuple, int, string, etc.) it would put them in ""rich"" protobuf types. 
For example consider simplified ObjectMessage with torch tensor. Instead of simplifying it to something like:
```
(27, # ObjectMessage code
 (2, # tuple code
  (13, # TorchTensor code
   (61208159134, # tensor_id
    b'...pickled tensor...', # tensor_bin
    None, # chain
    None, # grad_chain
    None, # tags
    None # description
))))
```

It would fill in these values into protobuf types like these (where Command is sent over though SendObjectMessage(Command) rpc)
```
message TorchTensor {
 uint64 tensor_id = 1;
 bytes tensor_bin = 2;
 PointerTensor chain = 3;
 TorchTensor grad_chain = 4;
 repeated string tags = 5;
 string description = 6;
}

message Command {
 string id = 1;
 oneof content {
    TorchTensor torch_tensor = 2;
    ...
 }
}
```

Otherwise (if protobuf will be used just to replace msgpack) developers will still have to look up simplify/detail implementation in PySyft code and re-implement them in other languages (RFC mentions this problem), i.e. the protocol won't be actually standardized? Then there seems to be no much benefit in using protobufs?

> As far as this idea of maintaining messaging constants in a separate repo, I believe the protobuf files in any implementation of that RFC would contain such constants, so we'd definitely appreciate comments over there with regard to pros/cons of having those files in PySyft main versus a separate repo that both PySyft and syft.js both pull from.

For this PR, @cereallarceny wanted to have packages with constants that can be installed though package installers (pip/npm/etc). I think equivalent for that is having .proto files compiled to different languages in and resulting classes exposed in installable packages (in a separate repo). 
I think, in theory this looks good as it separates protocol schema from PySyft code and makes it single point of truth for all dependent projects (including PySyft). In practice it will require more steps when making changes to PySyft and some additional process to version protocol schema itself.
",case see thought goal replace implementation current form instead basic python string would put rich example consider simplified torch tensor instead something like code code code tensor none chain none none none description would fill like command sent though command message chain repeated string string description message command string id content otherwise used replace still look implementation code problem protocol wo actually standardized much benefit far idea separate believe implementation would contain definitely appreciate regard main versus separate pull though package think equivalent different resulting class exposed separate think theory good separate protocol schema code single point truth dependent practice require making additional process version protocol schema,issue,positive,positive,positive,positive,positive,positive
524585298,"Has anyone started working on this issue? If not, can I take this on? ",anyone working issue take,issue,negative,neutral,neutral,neutral,neutral,neutral
524585118,"Hi, sorry! I have actually tackled this issue in an unsubmited PR for
installing PySyft with different frameworks (torch, TFE keras, and
tensorflow so far). I'm still waiting to polish it before submitting, but
should be in early this week.

On Sat, Aug 24, 2019, 1:37 PM Kris Stern <notifications@github.com> wrote:

> I would like to take on/be assigned this issue.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/2535?email_source=notifications&email_token=AB4GTBNUDSORVI4TA3B6P7DQGFWWLA5CNFSM4IN2LXFKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD5CEN7Y#issuecomment-524568319>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AB4GTBODK2B3SSVMTZFEJ3DQGFWWLANCNFSM4IN2LXFA>
> .
>
",hi sorry actually tackled issue different torch far still waiting polish early week sat stern wrote would like take assigned issue thread reply directly view mute thread,issue,negative,negative,neutral,neutral,negative,negative
524568319,I would like to take on/be assigned this issue. ,would like take assigned issue,issue,negative,neutral,neutral,neutral,neutral,neutral
524568214,"Hi @meandmymind, currently the recently merged RNN modules only support federated learning and encrypted predictions (i.e. without setting `requires_grad=True`).

We will be working on a PR to include support for encrypted training as well soon",hi currently recently support learning without setting working include support training well soon,issue,positive,neutral,neutral,neutral,neutral,neutral
524558007,"This long time-execution with RNNs is due one of the last commits that integrated multiplication and division in only one block, which slowed down cumulated multiplications in MPC. RNNs' activation functions (`tanh` and `sigmoid`) are approximated by a polynomial for MPC, so one computation of `tanh` has several multiplications.
For instance, the time-execution of `tanh` for a 3x3 tensor increased around 50x after that commit. It will be corrected soon so that the RNNs will be suitable for MPC.",long due one last multiplication division one block activation tanh sigmoid polynomial one computation tanh several instance tanh tensor around commit corrected soon suitable,issue,negative,positive,neutral,neutral,positive,positive
524491781,">https://github.com/OpenMined/rfcs/pull/6 as far as I understand means throwing away existing serde. All classes that need to be sent over would be created as protobuf definitions and simplified/serialized/deserialized using protobuf instead of using simplify/detail functions.

This is not the case, see [here](https://github.com/OpenMined/rfcs/pull/6#discussion_r317255071) and [here](https://github.com/OpenMined/rfcs/pull/6#discussion_r316795957).

I highly recommend we coordinate this work with that standardization RFC -- I'm sure @cereallarceny will have plenty to catch up on when he gets back.

As far as this idea of maintaining messaging constants in a separate repo, I believe the protobuf files in any implementation of that RFC would contain such constants, so we'd definitely appreciate comments over there with regard to pros/cons of having those files in PySyft main versus a separate repo that both PySyft and syft.js both pull from.",far understand throwing away class need sent would instead case see highly recommend work standardization sure plenty catch back far idea separate believe implementation would contain definitely appreciate regard main versus separate pull,issue,positive,positive,positive,positive,positive,positive
524452310,"@robert-wagner This change is a small improvement on top of existing serde to make protocol more stable and share class constants (used during ""simplification"") to different languages. E.g. TorchTensor class is encoded as tuple `(12, ...simplified tensor data...)`. That `12` is not set anywhere, it's an index of simplifier function in a dict, which is created dynamically. With this change, `12` is exported as a constant to this file: https://github.com/OpenMined/proto/blob/master/proto.json.
Although that protects from indices shift as more classes added to serde, it does not protect from actual change of class' simplify/detail functions implementation.

https://github.com/OpenMined/rfcs/pull/6 as far as I understand means throwing away existing serde. All classes that need to be sent over would be created as protobuf definitions and simplified/serialized/deserialized using protobuf instead of using simplify/detail functions. ",change small improvement top make protocol stable share class used simplification different class simplified tensor data set anywhere index simplifier function dynamically change constant file although index shift class added protect actual change class implementation far understand throwing away class need sent would instead,issue,positive,positive,neutral,neutral,positive,positive
524348142,"@LaRiffle not sure why I couldn't find that issue at the time of posting this. Since this is a duplicate, I'll close this issue.",sure could find issue time posting since duplicate close issue,issue,negative,positive,positive,positive,positive,positive
524256221,"Ok so let's not give up here!

 ## Claim 1
> If I can compute privately exp of a bit then I'm good for any exp(integer)

Idea:
```python 
e = torch.exp(torch.tensor(1.))
# this...
e**5
# can be written
e**(1*2**2 + 0*2**1 + 1*2**0)
# or also
(e**1)**(2**2) * (e**0)**(2**1) * (e**1)**(2**0)
```

## Claim 2
> I can compute privately exp of a single bit 
```python
# Take a bit (0 or 1, here 0 for example)and share it in a *binary* field
x = torch.tensor([0])
x_sh = x.share(alice, bob, crypto_provider=crypto_provider, field=2)

# Access shares
x0, x1 = x_sh.child.child['alice'], x_sh.child.child['bob']
x0 = x0.float()
x1 = x1.float()
print(alice._objects[x0.id_at_location], bob._objects[x1.id_at_location])

# Compute privately the wrap field bit, which decrypts to 1 iff x0+x1 >= 2  
x0_sh = x0.fix_precision().share(alice, bob, crypto_provider=charlie).get()
x1_sh = x1.fix_precision().share(alice, bob, crypto_provider=charlie).get()
wrap_field = x0_sh * x1_sh 

# Compute exp of shares
exp_x0, exp_x1 = [torch.exp(x0), torch.exp(x1)]
alice._objects[exp_x0.id_at_location], bob._objects[exp_x1.id_at_location]

# Share the exp of shares
exp_x0_sh = exp_x0.fix_precision().share(alice, bob, crypto_provider=charlie).get()
exp_x1_sh = exp_x1.fix_precision().share(alice, bob, crypto_provider=charlie).get()

# Apply exp(x0 + x1) =  exp(x0) *  exp(x1) formula + a wrapping correction if needed
one = torch.tensor([1.]).fix_precision()
inv_exp_field_size = torch.exp(-torch.tensor([2.])).fix_precision()

exp_sh = exp_x0_sh * exp_x1_sh * (wrap_field * (inv_exp_field_size - one) + one)

# Open and get 1.0
exp_sh.get().float_prec()
```

Now, how practical is this is another question...
From my first implem, the price to pay should be around 1.5s for a float value, which can be amortized when using vectors",let give claim compute privately bit good integer idea python written also claim compute privately single bit python take bit example share binary field bob access print compute privately wrap field bit bob bob compute share bob bob apply formula wrapping correction one one one open get practical another question first price pay around float value,issue,positive,positive,positive,positive,positive,positive
524232599,"Why it won't work:
```python
x = torch.tensor([[3, 4]])
x_sh = x.share(alice, bob, crypto_provider=crypto_provider)

x0, x1 = x_sh.child.child['alice'], x_sh.child.child['bob']
x0 = x0.float()
x1 = x1.float()

exp_x0, exp_x1 = [torch.exp(x0), torch.exp(x1)]
print(alice._objects[exp_x0.id_at_location], bob._objects[exp_x1.id_at_location])
```
output
```python
(tensor([[inf, inf]]), tensor([[inf, inf]]))
```

Computers are so weak.",wo work python bob print output python tensor tensor weak,issue,negative,negative,negative,negative,negative,negative
524230162,"Actually I can still see the issue. I'm on the latest version of `dev` branch.
![image](https://user-images.githubusercontent.com/24773652/63579510-0b43e300-c5bd-11e9-9f24-41de3c3829dc.png)

",actually still see issue latest version dev branch image,issue,negative,positive,positive,positive,positive,positive
524218574,"Actually, this is not the practice I see, as 3-worker case is usually added to the test function. Example
```python
def test_add(workers):
    bob, alice, james = (workers[""bob""], workers[""alice""], workers[""james""])

    # 2 workers
    t = torch.tensor([1, 2, 3])
    x = torch.tensor([1, 2, 3]).share(bob, alice)

    y = (x + x).get()

    # 3 workers
    assert (y == (t + t)).all()

    t = torch.tensor([1, 2, 3])
    x = torch.tensor([1, 2, 3]).share(bob, alice, james)

    y = (x + x).get()
```",actually practice see case usually added test function example python bob bob bob assert bob,issue,negative,negative,negative,negative,negative,negative
524194771,"Hey,
I would recommend using .shape instead of .size()
We have trouble with .size(), as explained here: https://github.com/OpenMined/PySyft/issues/2201",hey would recommend instead trouble,issue,negative,negative,negative,negative,negative,negative
524194602,I'm closing this since I don't see obvious way of fixing this.,since see obvious way fixing,issue,negative,neutral,neutral,neutral,neutral,neutral
524194221,"Not exactly, by default we provide a generic behaviour for all layers, but sometimes it doesn't work as expected and we need to add specific mechanisms. This happens when people find out they need smthg which doesn't work as expected.

So maybe check if you can use it, and if it fails miserably because of that specific component, then throw an Issue about this and we'll get it fixed :)

",exactly default provide generic behaviour sometimes work need add specific people find need work maybe check use miserably specific component throw issue get fixed,issue,negative,positive,neutral,neutral,positive,positive
524193602,"Could you detail how your usecase differ from the tutorials please? Thanks!
https://github.com/OpenMined/PySyft/tree/dev/examples/tutorials",could detail differ please thanks,issue,positive,positive,positive,positive,positive,positive
524193262,"So, this test is equivalent to:
```python 
def test_websocket_workers_mult(hook, start_remote_worker):
    server, alice = start_remote_worker(id=""alice-remote"", hook=hook, port=8761)
    server, bob = start_remote_worker(id=""bob-remote"", hook=hook, port=8762)
    server, charlie = start_remote_worker(id=""charlie-remote"", hook=hook, port=8763)
    
    x = torch.tensor([[3, 4]])    
    x_ptr = x.send(alice)
    x_move = x_ptr.move(bob)
    x_back = x_move.get()
```
I think we need to get .move() to work, ie to allow remote workers to reference each other

<img width=""426"" alt=""Capture d’écran 2019-08-23 à 08 39 12"" src=""https://user-images.githubusercontent.com/12446521/63571895-d9615b00-c581-11e9-89aa-d062b7242729.png"">
",test equivalent python hook server server bob server bob think need get work ie allow remote reference capture,issue,negative,negative,neutral,neutral,negative,negative
524179585,"I solved this issue by following the instructions on this page: https://discourse.mc-stan.org/t/compilation-error-in-pystan-macos-mojave/6383/3 . 
I installed the package using: 
`sudo installer -pkg  /Library/Developer/CommandLineTools/Packages/macOS_SDK_headers_for_macOS_10.14.pkg -target /`. 
",issue following page package installer,issue,negative,neutral,neutral,neutral,neutral,neutral
524047054,"> Can you .move() data across WebsocketWorkers? I think this is what you need, and it requires end workers to know each others

I don't think so, this fails:

```python
def test_websocket_workers_mult(hook, start_remote_worker):
    server, alice = start_remote_worker(id=""alice-remote"", hook=hook, port=8761)
    server, bob = start_remote_worker(id=""bob-remote"", hook=hook, port=8762)
    server, charlie = start_remote_worker(id=""charlie-remote"", hook=hook, port=8763)
    
    x = torch.tensor([[3, 4]])
    y = torch.tensor([[3, 4]])
    x_sh = x.share(alice, bob, crypto_provider=charlie)
    y_sh = x.share(alice, bob, crypto_provider=charlie)
    
    x_ptr = x.send(alice)
    x_move = x_ptr.move(bob)
```

Error:

```
Traceback (most recent call last):
  File ""/home/marianne/PySyft/syft/workers/websocket_server.py"", line 109, in _producer_handler
    response = self._recv_msg(message)
  File ""/home/marianne/PySyft/syft/workers/websocket_server.py"", line 120, in _recv_msg
    return self.recv_msg(message)
  File ""/home/marianne/PySyft/syft/workers/base.py"", line 274, in recv_msg
    response = self._message_router[msg_type](contents)
  File ""/home/marianne/PySyft/syft/workers/base.py"", line 392, in execute_command
    response = getattr(_self, command_name)(*args, **kwargs)
  File ""/home/marianne/PySyft/syft/generic/object.py"", line 107, in mid_get
    tensor = self.get()
  File ""/home/marianne/PySyft/syft/generic/pointers/pointer_tensor.py"", line 273, in get
    tensor = ObjectPointer.get(self, deregister_ptr=deregister_ptr)
  File ""/home/marianne/PySyft/syft/generic/pointers/object_pointer.py"", line 145, in get
    obj = self.owner.request_obj(self.id_at_location, self.location)
  File ""/home/marianne/PySyft/syft/workers/base.py"", line 549, in request_obj
    obj = self.send_msg(messaging.ObjectRequestMessage(obj_id), location)
  File ""/home/marianne/PySyft/syft/workers/base.py"", line 240, in send_msg
    bin_response = self._send_msg(bin_message, location)
  File ""/home/marianne/PySyft/syft/workers/virtual.py"", line 10, in _send_msg
    return location._recv_msg(message)
  File ""/home/marianne/PySyft/syft/workers/websocket_client.py"", line 103, in _recv_msg
    response = self._forward_to_websocket_server_worker(message)
  File ""/home/marianne/PySyft/syft/workers/websocket_client.py"", line 96, in _forward_to_websocket_server_worker
    self.ws.send(str(binascii.hexlify(message)))
AttributeError: 'NoneType' object has no attribute 'send'
```

",data across think need end know think python hook server server bob server bob bob bob error recent call last file line response message file line return message file line response content file line response file line tensor file line get tensor self file line get file line location file line location file line return message file line response message file line message object attribute,issue,negative,neutral,neutral,neutral,neutral,neutral
524045947,"> From what I see, .location is a string because, get_worker(...) fails almost silently when retrieving workers

Yes, that's exactly the case.",see string almost silently yes exactly case,issue,negative,positive,positive,positive,positive,positive
524039714,"From what I see, .location is a string because, get_worker(...) fails almost silently when retrieving workers, but emits those warnings:
```
WARNING:syft.workers.base:Worker alice-remote couldn't recognize worker charlie-remote
WARNING:syft.workers.base:Worker me couldn't recognize worker bob-remote
```
From my logs I have: `alice-remote KNOWS {'me': <VirtualWorker id:me #objects:0>, 'alice': <VirtualWorker id:alice #objects:0>, 'bob': <VirtualWorker id:bob #objects:0>, 'james': <VirtualWorker id:james #objects:0>, 'alice-remote': <WebsocketServerWorker id:alice-remote #objects:7>}`

Can you .move() data across WebsocketWorkers? I think this is what you need, and it requires end workers to know each others",see string almost silently warning worker could recognize worker warning worker could recognize worker id id id bob id id data across think need end know,issue,negative,neutral,neutral,neutral,neutral,neutral
524025775,"<img width=""988"" alt=""Screen Shot 2019-08-21 at 8 08 38 PM"" src=""https://user-images.githubusercontent.com/4328594/63540444-ff501680-c513-11e9-8667-2de05a59dfa3.png"">

Made some progress.",screen shot made progress,issue,negative,neutral,neutral,neutral,neutral,neutral
524023116,(meaning don't edit them - create new test cases based on them),meaning edit create new test based,issue,negative,positive,positive,positive,positive,positive
524023014,Probably best to just copy those test cases and add additional workers.,probably best copy test add additional,issue,positive,positive,positive,positive,positive,positive
523957354,"Added documentation in new/updated files.
To pass tests it needs this PR merged: https://github.com/OpenMined/proto/pull/3
(Hmm, maybe do not use full class names for syft.* classes?)

Also:
Before the merge it perhaps makes sense to document in some readme how exactly to update `proto.json` file and how to deal with versioning.
E.g. if somebody works on PySyft in a branch and adds a new type in serde, they probably need to fork `OpenMined/proto` repo, add new definition in that fork and use that fork in their PySyft's `requirements.txt` in order to PySyft to work.
Then they would open PR to `OpenMined/repo` and update PySyft's `requirements.txt` again before the PySyft branch merge.

Additionally, it probably would be better to create tags in `OpenMined/proto` (e.g. for each PySyft release) and reference these tags in released versions of PySyft, instead of referencing `master` branch? There might be some different protocol versioning rule for `OpenMined/proto` but currently it seems `proto` changes will be coupled with PySyft changes anyway.",added documentation pas need maybe use full class class also merge perhaps sense document exactly update file deal somebody work branch new type probably need fork add new definition fork use fork order work would open update branch merge additionally probably would better create release reference instead master branch might different protocol rule currently proto coupled anyway,issue,positive,positive,positive,positive,positive,positive
523921159,">Travis is complaining - looks like a flake 8 error

Also I fixed this last night but didn't push because while testing I discovered that the recently merged `test_rnn_mpc.py` has slowed testing by nearly an order of magnitude. Working on a fix for that now with @robert-wagner ",travis like flake error also fixed last night push testing discovered recently testing nearly order magnitude working fix,issue,negative,positive,neutral,neutral,positive,positive
523917620,">I don't really see where this did much to Plan, but it looks good to me.

Generalized references to `torch.Tensor` and changed how you access the hook to make sure it's being pulled from the right place! V light changes, but needed to be in line with the rest of the work.",really see much plan good generalized access hook make sure right place light line rest work,issue,positive,positive,positive,positive,positive,positive
523912784,"It's actually a great limitation, because 2 workers is not the usecase the PySyft is initially designed for (many independent parties training securely). 
Would be great to hear, if there's any consideration about workarounds, or another protocols that supports >2 parties that can be implemented in PySyft in future.",actually great limitation initially designed many independent training securely would great hear consideration another future,issue,positive,positive,positive,positive,positive,positive
523906184,"@iamtrask Yeah, of course. I'm a bit confused about which test cases should I update: `test_mul`, `test_public_mul`, `test_matmul`, `test_pow`, `test_torch_dot` or all of them?",yeah course bit confused test update,issue,negative,negative,negative,negative,negative,negative
523858488,"I don't really see where this did much to Plan, but it looks good to me.",really see much plan good,issue,negative,positive,positive,positive,positive,positive
523812931,"> @DanyEle I do

I've put back the test cases related to gradient clipping for local and remote tensors, slightly modifying them to introduce checks over the `tensor.grad` property of tensors instead of the tensors themselves. 

Got some inspiration from https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html to generate tensors having a simple deterministic `grad` property set. ",put back test related gradient clipping local remote slightly introduce property instead got inspiration generate simple deterministic grad property set,issue,positive,negative,neutral,neutral,negative,negative
523807977,"@LaRiffle please notice that when doing operations in SMPC we are working with fixed_precision tensors. Exponential is not defined for fixed_precision tensors, we would need a polynomial approximation or other numerical methods that require several computations (including division which is really slow now)... 😞 ",please notice working exponential defined would need polynomial approximation numerical require several division really slow,issue,negative,negative,negative,negative,negative,negative
523662970,so what do you think? shall we merge this part and follow the plan and notebook as the next step?,think shall merge part follow plan notebook next step,issue,negative,neutral,neutral,neutral,neutral,neutral
523574289,"@robert-wagner Do you think the two previous ""unit"" tests should be kept?",think two previous unit kept,issue,negative,negative,negative,negative,negative,negative
523458022,"Hi Hrisikesh! Slack Andre Farias, winner of the OpenMined grant, for the latest if you're interested to contribute. Andrew Kontaxis is now coordinating with him, they should decide what to do with this Issue. @akontaxis @andrelmfarias ",hi slack winner grant latest interested contribute decide issue,issue,positive,positive,positive,positive,positive,positive
523389441,@jvmancuso the work have been tested on a single node deploying three workers for now,work tested single node three,issue,negative,negative,neutral,neutral,negative,negative
523194635,"btw, even with current mentioned notebook is failing for me, so I would rather merge this one first and after figure out other parts :)

![image](https://user-images.githubusercontent.com/775466/63384158-9abf7b00-c39e-11e9-8ec6-ba96dba12d01.png)


And if I print y[1:]
```
b'\x04""M\x18h@T\x00\x00\x00\x00\x00\x00\x00\xa6>\x00\x00\x00\xf0\x0f\x92\x06\x92\x01\x92\x06\x94\x92\x05\x91\xa7__add__\x92\x14\x96\xcf\x00\x00\x00\x06\xa2\xc5\\\x9c\t\x00\xff\x02\x14\x0e\x97\xcd-\xa2me\xc0\x92\r\x91\x04\xc3\x92\x06\x91!\x00\tP\x04\xc3\x92\x00\x90\x00\x00\x00\x00'
```",even current notebook failing would rather merge one first figure image print,issue,negative,positive,positive,positive,positive,positive
523138254,"> I think Plan should be a subclass of Message (feel like that would be in the spirit of the work, cc: @iamtrask), but I don't think we need to take care of that in this PR.

TTBOMK, yes!",think plan subclass message feel like would spirit work think need take care yes,issue,positive,neutral,neutral,neutral,neutral,neutral
523049442,"If I had to guess, I would say this is what the original DataLoader's `num_workers` solves.  It makes sense to prepare data in parallel, so that you always have a data point ready, but based on your feedback this is not the case for FederatedDataLoader just yet.  I suspect that the communication required to prepare a single batch of data is pretty costly as well, so a Plan can be used to improve that.  We would love to see a deep dive into the codebase around this issue, I'm sure there are some quick wins to be had!",guess would say original sense prepare data parallel always data point ready based feedback case yet suspect communication prepare single batch data pretty costly well plan used improve would love see deep dive around issue sure quick,issue,positive,positive,positive,positive,positive,positive
523038976,"I think it's okay if you push notebook changes with it, please do! We use NBReview to be able to quickly and easy review notebooks for that exact reason.

I think Plan should be a subclass of Message (feel like that would be in the spirit of the work, cc: @iamtrask), but I don't think we need to take care of that in this PR.",think push notebook please use able quickly easy review exact reason think plan subclass message feel like would spirit work think need take care,issue,positive,positive,positive,positive,positive,positive
522769839,"I would push notebook change in a separate PR, in order not too make it mess here :) ",would push notebook change separate order make mess,issue,negative,negative,negative,negative,negative,negative
522767314,Can we get a status update here please? :),get status update please,issue,negative,neutral,neutral,neutral,neutral,neutral
522762980,"plan works with message internals kind of https://github.com/OpenMined/PySyft/blob/dev/syft/messaging/plan.py#L179

So I am not sure if we intended to replace it the same way as files above",plan work message internals kind sure intended replace way,issue,positive,positive,positive,positive,positive,positive
522621539,"*UPDATE:* So far I've got basic local promises working for addition.

```
a = sy.Promises.FloatTensor(shape=th.Size((3,3)))
b = sy.Promises.FloatTensor(shape=th.Size((3,3)))

print(""Promise A:"")
print(a)

y = a + b
z = y + y

print(""\nPromise Z:"")
print(z)

a.keep(th.ones(3,3))

print(""\nZ After Keep A:"")
print(z)

b.keep(th.ones(3,3))

print(""\nZ After Keep B:"")
print(b)
```
Returns:
```
Promise A:
(Wrapper)>PromiseTensor>None

Promise Z:
(Wrapper)>PromiseTensor>None

Z After Keep A:
(Wrapper)>PromiseTensor>None

Z After Keep B:
tensor([[1., 1., 1.],
        [1., 1., 1.],
        [1., 1., 1.]])
```

Note that the PromiseTensor piece of the chain disappears entirely when it is kept. Note further that I've created a sy.Promises package which allow for initialization of promises with a specific type and shape.",update far got basic local working addition print promise print print print print keep print print keep print promise wrapper none promise wrapper none keep wrapper none keep tensor note piece chain entirely kept note package allow specific type shape,issue,positive,positive,neutral,neutral,positive,positive
522620124,"Will keep that in mind. At the moment, Promise/PrmoiseTensor is mostly a method for constructing asynchronous code execution to increase low level performance. There are a lot of other features that we would need in order to get promises to be more of a user-facing feature.",keep mind moment mostly method asynchronous code execution increase low level performance lot would need order get feature,issue,negative,positive,positive,positive,positive,positive
522469932,"If you are working with websocket-based asynchronous(i.e. parallel) federated learning,  I'd be glad to discuss it with you.",working asynchronous parallel learning glad discus,issue,negative,positive,positive,positive,positive,positive
522467265,Thanks! the problem solved but looks like the efficiency is not decent on GPU with syft.,thanks problem like efficiency decent,issue,positive,positive,positive,positive,positive,positive
522438451,"Try this to bypass this bug:
```
torch.set_default_tensor_type('torch.cuda.FloatTensor')
model = Net().to(device)
torch.set_default_tensor_type('torch.FloatTensor')
```
Some tutorials don't work. You have to face one bug after another.",try bypass bug model net device work face one bug another,issue,negative,neutral,neutral,neutral,neutral,neutral
522348769,@2fasc thanks for posting your code. How do I use it to convert an imagefolder dataset to a dataset that I can federate? ,thanks posting code use convert federate,issue,negative,positive,positive,positive,positive,positive
522341404,"Since there was no further discussion about possible solutions for the wrapping problem, I decided to implement solution 1. ",since discussion possible wrapping problem decided implement solution,issue,negative,neutral,neutral,neutral,neutral,neutral
522324561,"I could see one of the use cases being if in the context of some contractual obligation the promise is guaranteed to be delivered on a specific date (or in stages). However, if the promise is not delivered on time, some contractual agreement is violated, and thereby some punishment say in the form of a payment is incurred... This is quite generic though. For a more concrete example, the promise can be a target indicator value for gauging the impact of an ad campaign on a social media platform. The target indicator can be the popularity of the company running the campaign. ",could see one use context contractual obligation promise specific date however promise time contractual agreement thereby punishment say form payment quite generic though concrete example promise target indicator value gauging impact ad campaign social medium platform target indicator popularity company running campaign,issue,positive,positive,neutral,neutral,positive,positive
522127079,Sure! But I don't where would be the best as this can be call by every type of tensor,sure would best call every type tensor,issue,positive,positive,positive,positive,positive,positive
522126301,Interesting feature idea! I hadn't considered it but it seems plausible that someone would use it! What kind of use case do you think might be interested in such a feature?,interesting feature idea considered plausible someone would use kind use case think might interested feature,issue,positive,positive,positive,positive,positive,positive
522119483,"Given low activity and @kamathhrishi 's last post - I'm changing the title to [WIP] until the functionality is correct (just so signal that there's no need to review the PR at this time)

Best of luck!",given low activity last post title functionality correct signal need review time best luck,issue,positive,positive,positive,positive,positive,positive
522114861,I'm very grateful for your attention to detail on these usability messages. ,grateful attention detail usability,issue,negative,neutral,neutral,neutral,neutral,neutral
521973134,"@cereallarceny 
When proto.json is missing types, build fails. Currently protocol constants are moving target :)
So I had to update proto.json here: https://github.com/OpenMined/proto/pull/2 to match with latest PySyft.
After proto PR is merged, build for this PR should pass.",missing build currently protocol moving target update match latest proto build pas,issue,negative,positive,neutral,neutral,positive,positive
521940839,"**More**
Actually I strictly followed @LaRiffle 's tutorial on CNN+FL at [here](https://github.com/OpenMined/PySyft/blob/dev/examples/tutorials/Part%2006%20-%20Federated%20Learning%20on%20MNIST%20using%20a%20CNN.ipynb)

I copied the code and ran locally on my windows 1050ti PC with python3.7+pytorch1.1.0+PySyft0.1.23.

Still got the same error: 
```
RuntimeError: Expected object of backend CPU but got backend CUDA for argument #2 ‘source’
```
when executing `model = Net().to(device)` where `device = torch.device('cuda')`

So I doubt the availability of **CUDA** in case Pytorch is hooked with PySyft.",actually strictly tutorial copied code ran locally ti still got error object got argument source model net device device doubt availability case hooked,issue,negative,neutral,neutral,neutral,neutral,neutral
521795743,"> > Seems that PySyft does not support GPU(cuda) yet?
> 
> In general it does. Only when uses zero_().fix_precision() for encryption.

However, I tried to send my model to cuda using:
```
model.to(torch.device('cuda:0'))
```
and I got an error that goes: 
**RuntimeError: Expected object of backend CPU but got backend CUDA for argument #2 ‘source’**

But the above only happens when you hook _PySyft_ with _Pytorch_ - I tried to run that line of code without the hook code `hook = sy.TorchHook(th)`  and no error prompted.

So I suppose this error is caused by an validation check in _PySyft_ which expects the model's parameters to be on CPU, rather than GPU(cuda).

**Further**
I didn't find any evidence in the codes under PySyft/examples/tutorials that utilize Cuda or invoke xxx.to(device) to copy tensors/models to the GPU. I love PySyft but I feel like cuda features are probably not supported yet. 

Hope the developers of PySyft could provide more details.",support yet general encryption however tried send model got error go object got argument source hook tried run line code without hook code hook th error suppose error validation check model rather find evidence utilize invoke device copy love feel like probably yet hope could provide,issue,negative,positive,positive,positive,positive,positive
521782353,"> 
> 
> Seems that PySyft does not support GPU(cuda) yet?

In general it does. Only when uses zero_().fix_precision() for encryption.",support yet general encryption,issue,negative,positive,neutral,neutral,positive,positive
521719595,"Out of curiosity: Is there any inherent time-dimensionality to this `Promise` work, such as when the promise is expected to be fulfilled? This might be important for real-life applications I reckon. ",curiosity inherent promise work promise might important reckon,issue,positive,positive,positive,positive,positive,positive
521693038,"oh wait, this should actually be closed by #2502 ",oh wait actually closed,issue,negative,negative,neutral,neutral,negative,negative
521691469,@yanndupis is already working on this one in relation to #2502 ,already working one relation,issue,negative,neutral,neutral,neutral,neutral,neutral
521652491,irrelevant given new async strategy,irrelevant given new strategy,issue,negative,negative,negative,negative,negative,negative
521652422,irrelevant given new promise architecture,irrelevant given new promise architecture,issue,negative,negative,negative,negative,negative,negative
521652266,i'll be replacing this with a new issue soon which I believe to be stronger.,new issue soon believe,issue,negative,positive,positive,positive,positive,positive
521617196,"Note that MANY people can pick up this issue. We will likely never close it. 

Steps:

1) fork the repo into your own github
2) clone your fork down to your local filesystem
3) look for a part of the codebase that isn't documented
4) read the code and figure out what's going on (this is the hard part)
5) add inline documentation using the correct style
6) commit and push your code to your fork
7) create a pull request back into the main PySyft (which you can do using th big green button on Github""",note many people pick issue likely never close fork clone fork local look part read code figure going hard part add documentation correct style commit push code fork create pull request back main th big green button,issue,negative,positive,neutral,neutral,positive,positive
521579721,Hey @vvmnnnkv - I've merged your PR into the OpenMined/proto library.  Can you update the pull request here to pull from that repo instead of your personal one?,hey library update pull request pull instead personal one,issue,negative,neutral,neutral,neutral,neutral,neutral
521569241,"> I just bumped into a lot of error with zstd on an Ubuntu 16.04 machine a few hours ago. They were solved by running:
> 
> `sudo apt-get install python3.6-dev`
@DanyEle How can you do that successfully? I am on the Ubuntu16.04 too and I get the error that the zstd cannot be imported. And when I do as your guide I get the following error:

(pysyft) daisy@ubuntu:~/PySyft$ sudo apt-get install python3.6-dev
Reading package lists... Done
Building dependency tree       
Reading state information... Done
E: Unable to locate package python3.6-dev
E: Couldn't find any package by glob 'python3.6-dev'
E: Couldn't find any package by regex 'python3.6-dev'

![image](https://user-images.githubusercontent.com/11493656/63084676-4c654300-bf7e-11e9-959a-bcc2616790f7.png)
",lot error machine ago running install successfully get error guide get following error daisy install reading package done building dependency tree reading state information done unable locate package could find package could find package image,issue,negative,positive,neutral,neutral,positive,positive
521381659,"My bad creating a PR to master :sob:, sorry about that @robert-wagner and thanks for the new PR!",bad master sob sorry thanks new,issue,negative,negative,negative,negative,negative,negative
521288368,Closing this in favor of doing this manually (Travis will never pass on this pr),favor manually travis never pas,issue,negative,neutral,neutral,neutral,neutral,neutral
521238660,I will try what happens if you force the function to not be taken from the dictionary in the hook. There might be a conflict there.,try force function taken dictionary hook might conflict,issue,negative,neutral,neutral,neutral,neutral,neutral
521236989,"Is this the error you get? 
```
File ""PySyft/syft/frameworks/torch/hook/hook_args.py"", line 75, in <lambda>
    torch.Tensor: lambda i: i.wrap()
AttributeError: 'NoneType' object has no attribute 'wrap'
```",error get file line lambda lambda object attribute,issue,negative,neutral,neutral,neutral,neutral,neutral
521080410,"Well, thank you all very much. I'll try notebook",well thank much try notebook,issue,positive,positive,positive,positive,positive,positive
521078467,"These messages are expected when running the TFEWorkers in a terminal. The
predictions and results happen in the notebooks. If you can follow the
notebook instructions carefully and report any deviations from expected
behavior, please post them here, otherwise I will be closing this issue.

On Tue, Aug 13, 2019 at 22:24 白山茶 <notifications@github.com> wrote:

> WARNING: Logging before flag parsing goes to stderr.
> W0814 10:20:17.627083 10880 secure_random.py:22] Falling back to insecure
> randomness since the required custom op could not be found for the
> installed version of TensorFlow (1.14.0). Fix this by compiling custom ops.
>
> W0814 10:20:18.362116 10880 deprecation_wrapper.py:119] From
> D:\Anaconda\envs\pytorch\lib\site-packages\tf_encrypted\session.py:28: The
> name tf.Session is deprecated. Please use tf.compat.v1.Session instead.
>
> W0814 10:20:34.427498 10880 deprecation_wrapper.py:119] From
> D:\Anaconda\envs\pytorch\lib\site-packages\tf_encrypted\tensor\native.py:403:
> The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder
> instead.
>
> W0814 10:20:34.518264 10880 deprecation_wrapper.py:119] From
> D:\Anaconda\envs\pytorch\lib\site-packages\tf_encrypted\config.py:300: The
> name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto
> instead.
>
> W0814 10:20:34.519479 10880 deprecation_wrapper.py:119] From
> D:\Anaconda\envs\pytorch\lib\site-packages\tf_encrypted\config.py:87: The
> name tf.GraphOptions is deprecated. Please use tf.compat.v1.GraphOptions
> instead.
>
> I0814 10:20:34.520223 10880 session.py:57] Starting session on target
> 'grpc://localhost:4000' using config graph_options {
> }
>
> —
> You are receiving this because you commented.
>
>
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/2493?email_source=notifications&email_token=AB4GTBN2K54RODNSIZ4AAQTQENUETA5CNFSM4IK3YCI2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD4HQG7I#issuecomment-521077629>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AB4GTBKCQCXKX7C3JL7WFKDQENUETANCNFSM4IK3YCIQ>
> .
>
",running terminal happen follow notebook carefully report behavior please post otherwise issue tue wrote warning logging flag go falling back insecure randomness since custom could found version fix custom name please use instead name please use instead name please use instead name please use instead starting session target reply directly view mute thread,issue,positive,negative,neutral,neutral,negative,negative
521077629,"WARNING: Logging before flag parsing goes to stderr.
W0814 10:20:17.627083 10880 secure_random.py:22] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow (1.14.0). Fix this by compiling custom ops.

W0814 10:20:18.362116 10880 deprecation_wrapper.py:119] From D:\Anaconda\envs\pytorch\lib\site-packages\tf_encrypted\session.py:28: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

W0814 10:20:34.427498 10880 deprecation_wrapper.py:119] From D:\Anaconda\envs\pytorch\lib\site-packages\tf_encrypted\tensor\native.py:403: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

W0814 10:20:34.518264 10880 deprecation_wrapper.py:119] From D:\Anaconda\envs\pytorch\lib\site-packages\tf_encrypted\config.py:300: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

W0814 10:20:34.519479 10880 deprecation_wrapper.py:119] From D:\Anaconda\envs\pytorch\lib\site-packages\tf_encrypted\config.py:87: The name tf.GraphOptions is deprecated. Please use tf.compat.v1.GraphOptions instead.

I0814 10:20:34.520223 10880 session.py:57] Starting session on target 'grpc://localhost:4000' using config graph_options {
}",warning logging flag go falling back insecure randomness since custom could found version fix custom name please use instead name please use instead name please use instead name please use instead starting session target,issue,negative,negative,negative,negative,negative,negative
521076614,"Sorry, maybe the screenshot I uploaded doesn't display correctly. I will
write down follow the issue.
Attached is the screenshot of the program running results☺

jvmancuso <notifications@github.com> 于2019年8月14日周三 上午2:45写道：

> Hi @baishanca <https://github.com/baishanca> can you explain a bit more
> what you're experiencing? I'm not sure I see the problem based on what
> you've written here. What exactly is different from the expected behavior?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/2493?email_source=notifications&email_token=AL5QLW7I5TVF5I2JTB6SZDTQEL6L7A5CNFSM4IK3YCI2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD4GTK4I#issuecomment-520959345>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL5QLWZ44WXPPOW344NAK3TQEL6L7ANCNFSM4IK3YCIQ>
> .
>
",sorry maybe display correctly write follow issue attached program running hi explain bit sure see problem based written exactly different behavior reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
521052316,"Am actively working on this issue, and will open a PR to follow up soon. ",actively working issue open follow soon,issue,negative,negative,neutral,neutral,negative,negative
520960654,"Nice work!

In the future, you can include ""Closes `issue_number`"" or ""Fixes `issue_number`"" in the description of a PR to automatically close linked issues, which is a good practice :)",nice work future include description automatically close linked good practice,issue,positive,positive,positive,positive,positive,positive
520959345,Hi @baishanca can you explain a bit more what you're experiencing?  I'm not sure I see the problem based on what you've written here.  What exactly is different from the expected behavior?,hi explain bit sure see problem based written exactly different behavior,issue,negative,positive,positive,positive,positive,positive
520927080,"**Further findings**
With the suspicion that not only the sliced data fragment but also the whole data set are sent to clients when send() is invoked, I tried to detach the tensors (using .detach() or .data) before wrapping them into the **_BaseDataset_** objects.  However, PySyft yielded an error indicating that detached tensor is not eligible. To avoid direct detach() operation, I further tried to use clone() plus requires_grad_(False). As a result, memory usage **_declines_** to a relatively normal level.

**Probable cause**
I guess the very likely cause of this problem is with the computation graph, which may be sent to every client together with their sliced data. This also leads to the copy of the **_entire dataset_** because the dataset (as a tensor) is the predecessor of every slice of data in the graph (and PySyft may need to keep it for back propagation), or maybe all the slices share the same node as the original dataset - I'm not an expert on computation graph of Tensors.

So a possible solution is to create separate tensors for each BaseDataset/client in FL with requires_grad_=False (avoid back-propagation and the corresponding link in the graph). At least simply slicing the original data is not feasible though it's the most intuitive implementation.

**Possible solution**
```
# split data and dispatch
    for i in range(env_cfg.n_clients):
        # prepare client data, train and test separately
        client_train_data.append(
            sy.BaseDataset(data_train_x[split_points_train[i]: split_points_train[i+1]].clone().requires_grad_(False),
                           data_train_y[split_points_train[i]: split_points_train[i+1]].clone().requires_grad_(False)))
        client_test_data.append(
            sy.BaseDataset(data_test_x[split_points_test[i]: split_points_test[i+1]].clone().requires_grad_(False),
                           data_test_y[split_points_test[i]: split_points_test[i+1]].clone().requires_grad_(False)))
```",suspicion sliced data fragment also whole data set sent send tried detach wrapping however error detached tensor eligible avoid direct detach operation tried use clone plus false result memory usage relatively normal level probable cause guess likely cause problem computation graph may sent every client together sliced data also copy tensor predecessor every slice data graph may need keep back propagation maybe share node original expert computation graph possible solution create separate avoid corresponding link graph least simply slicing original data feasible though intuitive implementation possible solution split data dispatch range prepare client data train test separately false false false false,issue,negative,negative,neutral,neutral,negative,negative
520785853,I tried the multiple inheritance approach but bumped into method resolution order (MRO) gotchas with init() method invocation.,tried multiple inheritance approach method resolution order method invocation,issue,negative,neutral,neutral,neutral,neutral,neutral
520414183,"Terrific @vvmnnnkv!  I've created the `proto` repo under the OpenMined name.  You'll be able to submit a PR to it there.  Be sure to do so and set my name as the reviewer so I see it (and send me a link in Slack).  https://github.com/OpenMined/proto

I'd also love to see the JS version go ahead and parse the JSON in the proto repo, so you can import it as a Javascript object into syft.js.  Looks good otherwise!",terrific proto name able submit sure set name reviewer see send link slack also love see version go ahead parse proto import object good otherwise,issue,positive,positive,positive,positive,positive,positive
520388029,"Hi @cereallarceny -
I've made attempt to move `proto.json` into separate repo: https://github.com/vvmnnnkv/PySyft-Proto
Currently it's referenced as git URL in PySyft's requirements.txt. Also it can be installed as npm package: `npm i --save git://github.com/vvmnnnkv/PySyft-Proto`.
Probably it's not good to reference by URL, but it's just a PoC at this moment.
",hi made attempt move separate currently git also package save git probably good reference moment,issue,positive,positive,positive,positive,positive,positive
520377864,"Love this! I greatly hope StatefulPlans supports this style of API (and
possibly others as well).

On Sun, Aug 11, 2019 at 10:30 PM Jasopaum <notifications@github.com> wrote:

> Do you think we could have a class (similar to the Plan class we already
> have) from which user's classes would inherit? For instance, we could have:
>
> class Net(nn.Module, StatefulPlan):
>     def __init__(self):
>         super(Net, self).__init__()
>         self.fc1 = nn.Linear(2, 3)
>         self.fc2 = nn.Linear(3, 2)
>         self.foo = torch.tensor(...)  # Tensor that will be modified
>
>     def forward(self, x):
>         x = F.relu(self.fc1(x))
>         x = self.fc2(x)
>         self.foo = something
>         return F.log_softmax(x, dim=0)
>
> I don't know if it's what you were thinking about but it seems to me like
> it's quite easy to use and not harder than something else to implement.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/issues/2385?email_source=notifications&email_token=ABBAZEXVLY5JT44FJPUUSPTQECAFTA5CNFSM4IGGO272YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD4BJFNY#issuecomment-520262327>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABBAZEUDSVN76G3HLT5QMOLQECAFTANCNFSM4IGGO27Q>
> .
>
",love greatly hope style possibly well sun wrote think could class similar plan class already user class would inherit instance could class net self super net self tensor forward self something return know thinking like quite easy use harder something else implement reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
520372101,Commenting here just to follow this PR. Will need it for Encrypted Linear Regression.,follow need linear regression,issue,negative,neutral,neutral,neutral,neutral,neutral
520349365,"> Well done on this PR @DanyEle
> Why aren't the tests passings? You have just added a new function to hook... weird...

Thanks. It's most likely due to the PyTorch 1.2 being installed in the Travis CI build, because of the pytorch>=1.1 version in the requirements.txt file. There is already a PR open #2491 to address this issue. Other PRs seem to have the same tests not passing too. ",well done added new function hook weird thanks likely due travis build version file already open address issue seem passing,issue,positive,negative,neutral,neutral,negative,negative
520348452,"@mortendahl  When I print the result of client.query_model in Part 13c, they are the same:
![image](https://user-images.githubusercontent.com/11493656/62854735-c5685e80-bd22-11e9-9646-6f1c52709046.png)
So when execute ""predicted_label = np.argmax(res)"", the predicted_label is 0 all the time because the elements in the array res are the same.
Maybe the question is here.",print result part image execute time array maybe question,issue,negative,neutral,neutral,neutral,neutral,neutral
520346230,"failing unit tests are due to pytorch 1.2 release, see  #2491",failing unit due release see,issue,negative,negative,negative,negative,negative,negative
520337304,"Well done on this PR @DanyEle 
Why aren't the tests passings? You have just added a new function to hook... weird...",well done added new function hook weird,issue,negative,negative,negative,negative,negative,negative
520287586,"@mortendahl Hi, I install the tf-encrypted 0.5.7 via pip and  the latest version of Syft 0.1.22a1 via git from a source code installation of the dev branch:
![image](https://user-images.githubusercontent.com/11493656/62843904-0c892c00-bcf0-11e9-9fbd-ed4701984216.png)
![image](https://user-images.githubusercontent.com/11493656/62843909-1579fd80-bcf0-11e9-859b-c68f1293a2c7.png)


Then the accuracy of the trained model  in tutorial Part 13a is 0.9394. But the classification results in tutorial Part 13c are wrong too ( I test 100 cases and all of them are classified as 0):
![image](https://user-images.githubusercontent.com/11493656/62843949-68ec4b80-bcf0-11e9-964d-0253f13156a5.png)

![image](https://user-images.githubusercontent.com/11493656/62843975-9507cc80-bcf0-11e9-9e04-1944e4270ddb.png)

 Maybe the windows system is not suitable for the codes.
",hi install via pip latest version via git source code installation dev branch image image accuracy trained model tutorial part classification tutorial part wrong test classified image image maybe system suitable,issue,negative,positive,positive,positive,positive,positive
520262327,"Do you think we could have a class (similar to the Plan class we already have) from which user's classes would inherit? For instance, we could have:
```
class Net(nn.Module, StatefulPlan):
    def __init__(self):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(2, 3)
        self.fc2 = nn.Linear(3, 2)
        self.foo = torch.tensor(...)  # Tensor that will be modified

    def forward(self, x):
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        self.foo = something
        return F.log_softmax(x, dim=0)
``` 
I don't know if it's what you were thinking about but it seems to me like it's quite easy to use and not harder than something else to implement.",think could class similar plan class already user class would inherit instance could class net self super net self tensor forward self something return know thinking like quite easy use harder something else implement,issue,positive,positive,positive,positive,positive,positive
520194398,"If I execute the codes on a virtual machine of VMware which is Ubuntu 16.04, will the error disappear?

At 2019-07-25 20:45:17, ""Morten Dahl"" <notifications@github.com> wrote:


I will try it as soon as possible.

Thank you, please keep us posted!

And do I need to re-install pysyft from the beginning as your guide in Readme of Pysyft on my computer?

You will need the latest version of TF Encrypted (>= 0.5.7). You will also need the latest version of Syft but I believe part of the fix (4045ef2) has not not made it into an official release yet, meaning you will likely need to run Syft from a source code installation of the dev branch.

—
You are receiving this because you were mentioned.
Reply to this email directly, view it on GitHub, or mute the thread.",execute virtual machine error disappear wrote try soon possible thank please keep u posted need beginning guide computer need latest version also need latest version believe part fix made official release yet meaning likely need run source code installation dev branch reply directly view mute thread,issue,negative,positive,positive,positive,positive,positive
520169010,That sounds good to me @kakirastern.  Feel free to submit a PR when you've got something.  @iamtrask - any thoughts here?,good feel free submit got something,issue,positive,positive,positive,positive,positive,positive
520151237,"Setting `sy.local_worker.verbose=False` yields the following additional info... 
```
worker <VirtualWorker id:me #objects:0> sending 2 tensor([1, 2, 3]) to <VirtualWorker id:bob #objects:1>
worker <VirtualWorker id:me #objects:0> sending 9 31422344287 to <VirtualWorker id:bob #objects:2>
```
And if I turn the verbose option back on by changing to `sy.local_worker.verbose=True`, I see what I would expect to see... 
```
worker <VirtualWorker id:me #objects:0> sending 2 tensor([1, 2, 3]) to <VirtualWorker id:bob #objects:1>
worker <VirtualWorker id:me #objects:0> sending 9 82966780001 to <VirtualWorker id:bob #objects:2>
worker <VirtualWorker id:me #objects:0> sending 2 tensor([ 1., -2.]) to <Plan plan_double_abs id:69601957138 owner:me>
worker <VirtualWorker id:me #objects:0> sending 1 (('__add__', [PointerTensor | me:64383816141 -> 69601957138:44578402202], ([PointerTensor | me:64383816141 -> 69601957138:44578402202],), {}), (57269619476,)) to <Plan plan_double_abs id:69601957138 owner:me>
worker <VirtualWorker id:me #objects:0> sending 1 (('torch.abs', None, ([PointerTensor | me:61746159920 -> 69601957138:57269619476],), {}), (551558933,)) to <Plan plan_double_abs id:69601957138 owner:me>
worker <VirtualWorker id:me #objects:0> sending 9 57269619476 to <Plan plan_double_abs id:69601957138 owner:me>
```
where a few lines correspond with the some of the extra output which may not be needed and could cause some overheads issues during transmission. So from the context of the output as cited previously https://github.com/OpenMined/PySyft/issues/2424#issuecomment-519965686 probably will need to add some truly global `verbose=False` feature to `serde` to tidy up the output a bit... ",setting following additional worker id sending tensor id bob worker id sending id bob turn verbose option back see would expect see worker id sending tensor id bob worker id sending id bob worker id sending tensor plan id owner worker id sending plan id owner worker id sending none plan id owner worker id sending plan id owner correspond extra output may could cause transmission context output previously probably need add truly global feature tidy output bit,issue,negative,positive,neutral,neutral,positive,positive
520128895,Very useful for all other open Pull Requests! Should probably be merged already.,useful open pull probably already,issue,negative,positive,positive,positive,positive,positive
519972443,"I think I realized something that may be related with `wrap()` special cases, this time with `fix_precision()`. I'm getting an error with doing `model.fix_precision()` when that model has been previously sent to a worker. 

The parameters are in this form `Parameter>[PointerTensor | me:8280105820 -> S1:89778439233]`.

`fix_prec()` assumes that if it isn't wrapped, then it is a tensor:
```
if self.is_wrapper:
    self.child = self.child.fix_prec(*args, **kwargs)
    return self
```
and so in this case it tries to operate directly into the `Parameter` object, causing an `AttributeError: 'numpy.ndarray' object has no attribute 'wrap'`

This is another issue altogether, but seems like checking for `wrap` and doing special behavior is messing things up.

Note: This used to work for me on syft 0.1.19a1.",think something may related wrap special time getting error model previously sent worker form parameter wrapped tensor return self case operate directly parameter object causing object attribute another issue altogether like wrap special behavior messing note used work,issue,positive,positive,positive,positive,positive,positive
519965686,"Yeah, I see the same phenomenon too, with my output of the Python version being:
```
(19,
 (((25,
    (1,
     (6,
      ((6,
        ((5, (b'__add__',)),
         (20,
          (97982647266, 93721612411, 94566476898, None, (13, (2,)), False)),
         (6,
          ((20,
            (97982647266,
             93721612411,
             94566476898,
             None,
             (13, (2,)),
             False)),)),
         (0, ()))),
       (6, (30225810401,)))))),
   (25,
    (1,
     (6,
      ((6,
        ((5, (b'torch.abs',)),
         None,
         (6,
          ((20, (83640269041, 30225810401, 94566476898, None, None, True)),)),
         (0, ()))),
       (6, (8729013785,)))))),
   (25, (9, 30225810401))),
  94566476898,
  (1, (93721612411,)),
  (6, (8729013785,)),
  (5, (b'plan_double_abs',)),
  None,
  None,
  True))
```

Am actively checking the code base to see where things went wrong... ",yeah see phenomenon output python version none false none false none none none true none none true actively code base see went wrong,issue,negative,negative,negative,negative,negative,negative
519898514,"> Overwriting variable names at sending in the test, is on purpose, to be sure nothing weird happens when people do this

I'll add a comment. Thanks for letting me know!",variable sending test purpose sure nothing weird people add comment thanks know,issue,positive,positive,neutral,neutral,positive,positive
519730533,Go for it! Please link the PR to this issue when you've submitted it :),go please link issue,issue,negative,neutral,neutral,neutral,neutral,neutral
519281348,@mari-linhares travis did not like the change of the fixture name,travis like change fixture name,issue,negative,neutral,neutral,neutral,neutral,neutral
519274275,"Last bugs with LSTMs were fixed.

Still need to implement some tests",last fixed still need implement,issue,negative,positive,neutral,neutral,positive,positive
518848057,Hey @hanare Could you give this pr a more informative name?,hey could give informative name,issue,negative,neutral,neutral,neutral,neutral,neutral
518764931,"For reference on how this is implemented, the implementation of a ""description"" feature was very similar, which you can see here.

https://github.com/OpenMined/PySyft/blob/dev/syft/frameworks/torch/tensors/interpreters/native.py#L93

The whole project should be doable by only changing native.py (see the link above)",reference implementation description feature similar see whole project doable see link,issue,negative,positive,neutral,neutral,positive,positive
518400224,"I love this concept.  I would be in favor of moving the `proto.json` file into its own repo.  Furthermore, I wonder if we can get rid of the `code` key in that file.  Seems a bit redundant, no?  The only exception would be `VirtualWorker`, but I'm not sure what's going on there.  Ideally, if we had this `proto.json` file in another repo, it could also come with an appropriate `setup.py` and `package.json` file that allows for this to be installed as a package dependency.  Just some more thoughts!  Love the idea @vvmnnnkv.

I think also there's a testing conflict you have to resolve.",love concept would favor moving file furthermore wonder get rid code key file bit redundant exception would sure going ideally file another could also come appropriate file package dependency love idea think also testing conflict resolve,issue,positive,positive,positive,positive,positive,positive
518222255,@chicolinux - anyone can pick this up - lots of people can work on it simultaneously :),anyone pick lot people work simultaneously,issue,negative,neutral,neutral,neutral,neutral,neutral
518207574,"This is an important feature - but it requires user auth to know the difference between the same user re-connecting and another user re-connecting, which means this is more a feature for https://github.com/OpenMined/Grid

@IonesioJunior - I believe you'll be working on a user, based system. This is an important characteristic!",important feature user know difference user another user feature believe working user based system important characteristic,issue,negative,positive,positive,positive,positive,positive
518196110,"As per Slack discussion earlier, perhaps rendering the tutorials into Google Colab versions would be a good way forward too. ",per slack discussion perhaps rendering would good way forward,issue,negative,positive,positive,positive,positive,positive
518195091,"Hi, I would like to work on this issue to try and resolve it",hi would like work issue try resolve,issue,positive,neutral,neutral,neutral,neutral,neutral
518194347,"@vvmnnnkv [You're actually correct here](https://stackoverflow.com/questions/7992559/what-is-the-syntax-rule-for-having-trailing-commas-in-tuple-definitions), I didn't realize it was standard practice.  In this case - I think I'm going to close this ticket.  Sorry @Ankit-Dhankhar - although, I could really use your help here: https://github.com/OpenMined/PySyft/issues/2424",actually correct realize standard practice case think going close ticket sorry although could really use help,issue,negative,negative,neutral,neutral,negative,negative
518130530,Tensors remain in server memory if websocketclient connection closes abruptly https://github.com/OpenMined/PySyft/issues/2442,remain server memory connection abruptly,issue,negative,negative,negative,negative,negative,negative
518086686,"Hello guys! I'm the new kid on the block! I am on Slack channel as well! I would like to work on this issue, if this one is still available to take!! Best Regards!!",hello new block slack channel well would like work issue one still available take best,issue,positive,positive,positive,positive,positive,positive
518038060,"For string (code = 5), it's probably fine to simplify it into `(5, b""string"")` instead of `(5, (b""string"", ))`
by updating `_simplify_str` and `_detail_str` to return and expect string instead of tuple (several tests will need to be fixed too).
But for types like dict (0), list (1), set (3), tuple (6), you can't get rid of extra comma because it's how python displays tuple with a single element:
`tuple(list[1])`
`(1,)`

In python syntax it's not possible to make tuple with single element without that comma, because it's indistinguishable from simple parentheses:
`(1)`
`1` 

`(1,)`
`(1,)`

If you need to generate correct python representation, extra comma needs to be in tuple with single element to make it tuple :) With 2 or more elements comma is not necessary of course.
E.g., list with one element:
`(1, (30300883787,))`
List with 2 elements:
`(1, (30300883787, 123))`
",string code probably fine simplify string instead string return expect string instead several need fixed like list set ca get rid extra comma python single element list python syntax possible make single element without comma indistinguishable simple parenthesis need generate correct python representation extra comma need single element make comma necessary course list one element list,issue,positive,positive,neutral,neutral,positive,positive
517994668,"Go for it @Ankit-Dhankhar!  If we need to leave the `b` in there, that's acceptable to me, but the commas being inserted at the end of strings, tuples, and other objects in PySyft should probably be fixed.  If you think you have a fix, submit a PR and tag this issue id!  😄 ",go need leave acceptable inserted end probably fixed think fix submit tag issue id,issue,negative,positive,neutral,neutral,positive,positive
517975590,"Same line https://github.com/OpenMined/PySyft/blob/64cbc07b655f2f95b1297dc4ec3c4055b4dfe9d7/syft/serde/native_serde.py#L202
is reposponsible for unnecessary commas along with https://github.com/OpenMined/PySyft/blob/64cbc07b655f2f95b1297dc4ec3c4055b4dfe9d7/syft/messaging/plan.py#L647 this line.
But when you remove the trailing comma you get explected output. But PySyft implementation is based on iterative parsing thus that lead to 327 failed test cases. I can change those implementation if required :)",line unnecessary along line remove trailing comma get output implementation based iterative thus lead test change implementation,issue,negative,negative,negative,negative,negative,negative
517971063,"That additional **b** comes from https://github.com/OpenMined/PySyft/blob/64cbc07b655f2f95b1297dc4ec3c4055b4dfe9d7/syft/serde/native_serde.py#L202 encoding string in ""utf-8"" encoding that can be simply solved by not encoding it. But that will lead to memory overhead as ""utf-8"" encoding is flexible in size, unlike fixed size encodings.

Another option is to decode the second element of tuple if the first element is 5 i.e. second element is a string.
Which solution is more preferable? I would like to contribute to this issue.",additional come string simply lead memory overhead flexible size unlike fixed size another option decode second element first element second element string solution preferable would like contribute issue,issue,positive,positive,neutral,neutral,positive,positive
517957066,@jvmancuso It is not possible for that code to live with his code since all of his code is in kotlin for android support (similar to the planned syft.js work) This is in relation to the interoperability points,possible code live code since code android support similar work relation,issue,negative,positive,neutral,neutral,positive,positive
517949215,"was just thinking about this -- if @mccorby needs this for some code, but that code doesn't live in this repository, then shouldn't this functionality live with his code? cc @robert-wagner @yanndupis re: packaging discussion",thinking need code code live repository functionality live code discussion,issue,negative,positive,positive,positive,positive,positive
517784164,PR #2431 fixes this problem. So I'm going to close this issue.,problem going close issue,issue,negative,neutral,neutral,neutral,neutral,neutral
517769484,"After reading SecureNN's research paper, I understand that this is not an issue with pysyft but a limitation in the implemented protocols. Still, I believe some assertions and documented exceptions could be added so that other users are aware of this limitation.",reading research paper understand issue limitation still believe could added aware limitation,issue,negative,positive,positive,positive,positive,positive
517676258,"Yes it works after 1 time. So i think it shouldn't be an issue then.
One question though, cannot see the objects of a remote socket worker using for e.g. ""bob._objects"". Is this for security reason?",yes work time think issue one question though see remote socket worker security reason,issue,positive,negative,neutral,neutral,negative,negative
517675508,I don't know see a way to reopen the pull request. Easiest will be to create a new one and to reference the initial pull request.,know see way reopen pull request easiest create new one reference initial pull request,issue,positive,positive,neutral,neutral,positive,positive
517660793,could you please reopen the PR or should I make a new one?,could please reopen make new one,issue,negative,positive,positive,positive,positive,positive
517651690,"Yes, specifying that it should call the BaseWorker.get_obj() method would make it explicit and easier to understand.",yes call method would make explicit easier understand,issue,positive,neutral,neutral,neutral,neutral,neutral
517646505,@midokura-silvia do you think that we should specify the exact method it should call? keeping in mind that the private feature for tensors should be available for remote worker. I think that introducing the private feature imply using the get_obj() everywhere we wanna use an object because doing otherwise may left a an exploitable flaw,think specify exact method call keeping mind private feature available remote worker think private feature imply everywhere wan na use object otherwise may left exploitable flaw,issue,negative,positive,neutral,neutral,positive,positive
517624249,"The multiple inheritance scheme might produce problems.
So BaseWorker defines the wanted get_obj behaviour.
However which method gets invoked in WebsocketServerWorker?
It inherits from 
1) FederatedClient <- ObjectStorage and
2) VirtualWorker <- BaseWorker <- ObjectStorage

So which get_obj() function does it have?",multiple inheritance scheme might produce behaviour however method function,issue,negative,neutral,neutral,neutral,neutral,neutral
517623896,"I have an old version of `dev`... -> like a noob

Ok this is all good, thanks for spotting it!",old version dev like good thanks spotting,issue,positive,positive,positive,positive,positive,positive
517606847,"> Hey Silvia - if we make a change to that test then I probably have to go back and re-record a non-trivial number of videos. Can we leave the ""return self"" in for now. That would be quite a bit of work for me for a relatively small change.

I put the ""return self"" back in. And I added the possibility to deactivate the return value via an argument to the function. This way, I avoid the problem of serializing the return value.",hey make change test probably go back number leave return self would quite bit work relatively small change put return self back added possibility deactivate return value via argument function way avoid problem return value,issue,negative,negative,neutral,neutral,negative,negative
517586426,Does it work after 1 time? I *think* WebSocketServer only allows one client to connect.,work time think one client connect,issue,negative,neutral,neutral,neutral,neutral,neutral
517495122,"Private tensor disclosure possible through execute_command from BaseWorker
#2432 ",private tensor disclosure possible,issue,negative,neutral,neutral,neutral,neutral,neutral
517482421,@robert-wagner I added the test case. Hope everything looks good!,added test case hope everything good,issue,positive,positive,positive,positive,positive,positive
517479182,"Just realized there's a test file `test_local_worker.py`, might be better to put the test there?
",test file might better put test,issue,negative,positive,positive,positive,positive,positive
517471847,Hey @aristizabal95 could you add a test to make sure this bug does not pop up again (basically just testing to see that the local worker is in the list of known workers),hey could add test make sure bug pop basically testing see local worker list known,issue,negative,positive,positive,positive,positive,positive
517460797,"I am not sure if I have made some mistake or not, the problem is I am getting very high epsilon values than it should be. ",sure made mistake problem getting high epsilon,issue,negative,positive,positive,positive,positive,positive
517427877,"@iamtrask I'm seeing two problems here:
1. VirtualWorkers are not recognizing the local worker.
2. letting the class `AdditiveSharingTensor` assign the default crypto_provider to local_worker behaves differently as explicitly assigning it to local_worker.

As of 1:
when declaring a new worker, the `_known_workers` dict is populated by copying `sy.hook.local_worker._known_workers`. If we run this script
```python
import torch as th
import syft as sy

hook = sy.TorchHook(th)
hook.local_worker._known_workers
# => {}
```
returns an empty dictionary, which means that `hook.local_worker` is not aware of itself, which explains why any other worker won't recognize it. I'm guessing this should be another issue by itself?

As of 2.
I still don't get it, if I don't assign a crypto_provider, then it gets automatically assigned as `sy.hook.local_worker`, which should behave the same as explicitly assigning it to the same value. Any ideas?",seeing two local worker class assign default differently explicitly new worker run script python import torch th import hook th empty dictionary aware worker wo recognize guessing another issue still get assign automatically assigned behave explicitly value,issue,negative,positive,neutral,neutral,positive,positive
517424665,"The WebSocketServer could be prone to a DoS attack
https://github.com/OpenMined/PySyft/issues/2428",could prone do attack,issue,negative,neutral,neutral,neutral,neutral,neutral
517418860,Can you point out what the bug is? I'm varying n_teachers and getting similar sort of epsilon values. Is the bug related to that?,point bug getting similar sort epsilon bug related,issue,negative,neutral,neutral,neutral,neutral,neutral
517386125,"@iamtrask the local worker is not recognized by any of the virtual workers.
```python
print(alice._known_workers)
# => {'alice': <VirtualWorker id:alice #objects:10>, 'bob': <VirtualWorker id:bob #objects:14>, 'jack': <VirtualWorker id:jack #objects:12>}
# The results are the same for bob and jack
```",local worker virtual python print id id bob id jack bob jack,issue,negative,neutral,neutral,neutral,neutral,neutral
517380160,Very interesting bug - I do wonder how deep this bug goes. Is the local worker listed in bob._known_workers?,interesting bug wonder deep bug go local worker listed,issue,negative,positive,positive,positive,positive,positive
517333499,"Test case added, please have a look
",test case added please look,issue,negative,neutral,neutral,neutral,neutral,neutral
517276474,"It's also worth noting that upon creating a plan, I've noticed other places where unnecessary commas are being added, here are a few examples:

`(19, (23885703668, 30300883787, 85156589176, None, (13, (2,)), False))`
`(6, (53361601662,))`
`(6, ((19, (50671613206, 53361601662, 85156589176, None, None, True)),))`
`(1, (30300883787,))`",also worth upon plan unnecessary added none false none none true,issue,negative,negative,neutral,neutral,negative,negative
517209867,"> FYI, for the code snippet above I'm able to fix the error adding this line after importing torch:
> 
> `torch.set_default_tensor_type(torch.cuda.FloatTensor)`
> 
> Not sure if this is ideal for every case...

I am so glad to see this, it  really solved my problem of worrying all afternoon",code snippet able fix error line torch sure ideal every case glad see really problem worrying afternoon,issue,negative,positive,positive,positive,positive,positive
517165295,@jvmancuso please go ahead and merge this one and I am going to open another PR that adds a link to run on colab for bunch of notebooks. This way we keep it more consistent,please go ahead merge one going open another link run bunch way keep consistent,issue,negative,positive,positive,positive,positive,positive
517149432,"I implemented the fixes suggested by @LaRiffle. However, when trying to send a tensor with a `requires_grad=True`, an error is thrown related to the serialization process. I thought this error was due to the fact that I was not serializing/deserializing the requires_grad attribute, so I went ahead and added serialization and de-serialization for that attribute. Nevertheless, the error is still there in the forward propagation phase into the model.

![image](https://user-images.githubusercontent.com/4907418/62272335-264a8980-b43b-11e9-95b6-63bd824975ac.png)
![image](https://user-images.githubusercontent.com/4907418/62272357-35313c00-b43b-11e9-9455-6dc29ff76436.png)
",however trying send tensor error thrown related serialization process thought error due fact attribute went ahead added serialization attribute nevertheless error still forward propagation phase model image image,issue,negative,negative,neutral,neutral,negative,negative
517070308,"Process is (1) update the PR branch with most recent commits from dev, (2) resolve any merge conflicts), and (3) wait for someone with write access to merge (although sometimes a gentle reminder here or in Slack can be helpful).  In this case, I was waiting to hear back to see if you wanted to add commits for the colab link to this one.  I assume that'll be a separate PR though, so will merge now.",process update branch recent dev resolve merge wait someone write access merge although sometimes gentle reminder slack helpful case waiting hear back see add link one assume separate though merge,issue,positive,positive,neutral,neutral,positive,positive
516977490,"> Also, it doesn't seem like the gradient gets serialized if it exists. Is this true?

I confirm this. This doesn't just happen for Autograd tensors though, but also for remote tensors being transmitted with PySyft. And this was one of the reasons for the bug in #2361 ",also seem like gradient true confirm happen though also remote one bug,issue,positive,positive,positive,positive,positive,positive
516956479,"1. federated learning - you send a plan with a model
2. two options. one is where you pass a list of objects in func2plan() and the other is where you instantiate a class with class objects where you want to package the whole class (all its methods) and all its objects into a plan. (_looks like we are going towards the second solution - TR_)
3. haven't decided yet - seems like they could all be stateful but where sometimes the state is empty :)",learning send plan model two one pas list class class want package whole class plan like going towards second solution decided yet like could stateful sometimes state empty,issue,positive,positive,neutral,neutral,positive,positive
516946508,"the tests that failed were only meant for testing this functionality, going to check that coverage doesn't change if I remove those tests",meant testing functionality going check coverage change remove,issue,negative,neutral,neutral,neutral,neutral,neutral
516909528,running on colab would be sweet! we'd welcome a commit here with that change (or a separate PR if you prefer),running would sweet welcome commit change separate prefer,issue,positive,positive,positive,positive,positive,positive
516898940,"I see the point. But returning self then tries to serialize an instance of WebsocketServerWorker to send it over the network. 
We can catch that case and have two different behaviors (VirtualWorker vs WebsocketServerWorker). But it gets more complicated. Or create a separate function with another name, that does the same but does not return self.",see point self serialize instance send network catch case two different complicated create separate function another name return self,issue,negative,negative,negative,negative,negative,negative
516898264,"Also, it doesn't seem like the gradient gets serialized if it exists. Is this true?",also seem like gradient true,issue,positive,positive,positive,positive,positive,positive
516897847,"Hey @iamtrask Sure, I have replied on Slack via DM. Cheers! ",hey sure slack via,issue,negative,positive,positive,positive,positive,positive
516897733,"Am I correct in reading that when you move a set of AutogradTensors to another machine, that they actually create the graph on that machine?",correct reading move set another machine actually create graph machine,issue,negative,neutral,neutral,neutral,neutral,neutral
516896074,Hey @kakirastern - if i give you edit access to those notebooks would you be willing to update them? Ping me on slack :),hey give edit access would willing update ping slack,issue,negative,positive,positive,positive,positive,positive
516701001,"@robert-wagner, still in progress :/  Incorrect privacy loss ",still progress incorrect privacy loss,issue,negative,neutral,neutral,neutral,neutral,neutral
516700895,"@harora Its in progress https://github.com/OpenMined/PySyft/pull/2183 , there is a bug in computing privacy loss which I have to yet resolve. Apart from that, it's a good enough PATE example. ",progress bug privacy loss yet resolve apart good enough pate example,issue,positive,positive,positive,positive,positive,positive
516569439,"I think as of now, Transforms cannot be applied to Pointer, Fixed Precision or Float Precision tensors. @mari-linhares, If you guys are planning to extend the Transforms to Pointer, Fixed Precision or Float Precision, I would like to get involved.",think applied pointer fixed precision float precision extend pointer fixed precision float precision would like get involved,issue,negative,positive,neutral,neutral,positive,positive
516389591,Make sure to message @cereallarceny when this is done because it's a breaking change to syft.js,make sure message done breaking change,issue,negative,positive,positive,positive,positive,positive
516357045,"@iamtrask Could you take a look whether you are okay with the change in test_udacity.py, please?",could take look whether change please,issue,negative,neutral,neutral,neutral,neutral,neutral
516170774,Sure I will add a test case for same :),sure add test case,issue,negative,positive,positive,positive,positive,positive
516074435,@Ankit-Dhankhar Could you add a test to ensure we don't get this bug in the future,could add test ensure get bug future,issue,negative,neutral,neutral,neutral,neutral,neutral
516026208,"> > Would you mind sharing the complete snippet of code you used?
> > Thanks!
> 
> https://github.com/OpenMined/PySyft/blob/dev/examples/tutorials/Part%208%20-%20Federated%20Learning%20on%20MNIST%20using%20a%20CNN.ipynb
> 
> I tried to run exact code from this link but it showed that error.

link broken.",would mind complete snippet code used thanks tried run exact code link error link broken,issue,negative,positive,neutral,neutral,positive,positive
515983393,@LaRiffle done with the changes you can check and let me know if any other changes thanks for pointing out my mistakes it was my first time starting a pulling request,done check let know thanks pointing first time starting request,issue,negative,positive,positive,positive,positive,positive
515874327,I also experienced this bug personally when running some tutorials with one single worker. Would be very nice to have a fix for it when using one single worker!,also experienced bug personally running one single worker would nice fix one single worker,issue,negative,positive,positive,positive,positive,positive
515784772,"@wentaiwu92 you can use ```iter_per_worker=True``` while calling FederatedDataLoader. That will allow you to have one iterator for one worker.
I hope that will help if not let me know I would be happy to help :)",use calling allow one one worker hope help let know would happy help,issue,positive,positive,positive,positive,positive,positive
515767274,Oh is it ? I will check once and confirm and then close it :) ,oh check confirm close,issue,negative,neutral,neutral,neutral,neutral,neutral
515765797,"@kamathhrishi  I think torch.rand, torch.zeros and torch.linspace are hooked. So, we can close this issue ;)",think hooked close issue,issue,negative,neutral,neutral,neutral,neutral,neutral
515753220,"True, that would do to some extent... Maybe will need to add some descriptions about what can be found and expected at `INSTALLATION.md` too. 

And how about adding some material regarding the **workflow**, or just polish up the existing material and expand on this where necessary? ",true would extent maybe need add found material regarding polish material expand necessary,issue,positive,positive,positive,positive,positive,positive
515752423,We could just add a link to INSTALLATION.md for reference? ,could add link reference,issue,negative,neutral,neutral,neutral,neutral,neutral
515706511,"I was implementing test cases, but I am facing implementation conflict as self data is required to be tensor (as per the requirement of fix_prec function). I don't know how to proceed further, please guide.",test facing implementation conflict self data tensor per requirement function know proceed please guide,issue,negative,neutral,neutral,neutral,neutral,neutral
515679834,"Hi @robert-wagner, is help still wanted for this issue? I would like to volunteer for it if so... Please let me know. ",hi help still issue would like volunteer please let know,issue,positive,neutral,neutral,neutral,neutral,neutral
515670462,@amit-rastogi I will check it and close this if no issue arrives I haven't tried it yet,check close issue tried yet,issue,negative,neutral,neutral,neutral,neutral,neutral
515661985,Looks good to me too. Eagerly looking forward to trying it out as soon as it gets merged :),good eagerly looking forward trying soon,issue,positive,positive,positive,positive,positive,positive
515646618,The web socket client overflow error on windows has been addressed by https://github.com/OpenMined/PySyft/pull/2395 ,web socket client overflow error,issue,negative,neutral,neutral,neutral,neutral,neutral
515482736,"I'm going ahead with reducing the timeout to 999999 seconds (277.7 hours) for every platform (including Raspberry PIs). It should still be a higher value for Raspberry PIs and connect() would also not break on Windows due to C timeval overflow error. Also, the code would not get cluttered with platform checks. Please let me know in case there's any feedback on this.",going ahead reducing every platform raspberry still higher value raspberry connect would also break due overflow error also code would get platform please let know case feedback,issue,negative,positive,neutral,neutral,positive,positive
515174037,I am guessing to make the tutorial run perfectly on Colab this is what we need to do: https://research.google.com/colaboratory/local-runtimes.html,guessing make tutorial run perfectly need,issue,positive,positive,positive,positive,positive,positive
515141075,"I would really like to work on this issue though... which is not to be confused with #1905, which deals with the accompanying `Server` tutorial notebook hosted on Colab. ",would really like work issue though confused server tutorial notebook,issue,negative,negative,neutral,neutral,negative,negative
515128244,"I have added test-cases with requires_grad=True but tensor generated with torch.randn([dim]) fails this. Is this expected?

> I have added test cases for random integer arrays of non-symmetric dimensions.
> But for array with float value it is giving `assert tensor_serialized[0] != serde.NO_COMPRESSION` this false.

",added tensor dim added test random integer array float value giving assert false,issue,positive,negative,negative,negative,negative,negative
515128184,"@DanyEle Yes that makes sense. I can think of 2 alternatives here-
1. Reduce the timeout to 999999 seconds for every platform (including Raspberry PIs). 999999 seconds should still be a higher value for Raspberry PIs as well but would also make sure connect() doesn't break on Windows.
2. Reduce the timeout only for Windows to 99999 (27.7 hours)
",yes sense think reduce every platform raspberry still higher value raspberry well would also make sure connect break reduce,issue,positive,positive,positive,positive,positive,positive
515120321,"Well, such a high timeout was introduced to avoid having timeouts on Raspberry PIs when transferring data. However, reducing it 999999 seconds (277.7 hours) is still a reasonably high amount.",well high avoid raspberry transferring data however reducing still reasonably high amount,issue,negative,positive,positive,positive,positive,positive
515118078,"Hey @iamtrask,

A few questions...

1. Can you add one (or more) use cases where the ""state"" is critical?

2. Do you have thoughts about how should be the interface for StatefulPlans?

3. All plans are going to be stateful from this point on, or we'll have two kinds of plans? Regular Plans and StatefulPlans?",hey add one use state critical interface going stateful point two regular,issue,negative,neutral,neutral,neutral,neutral,neutral
515088353,"So this PR is based on what is currently existing in the code base for the `WebsocketServerWorker`, and also on what works. I see the previous `listen` method in the previous version of the notebook which have been kind of `deprecated` so I could not invoke it in this context. ",based currently code base also work see previous listen method previous version notebook kind could invoke context,issue,positive,negative,negative,negative,negative,negative
515082493,I think the PR is ready for some preliminary review. Any feedback or suggestion for improvement would be greatly appreciated. I have kept the changes to a minimum while making the notework work on Google Colab. ,think ready preliminary review feedback suggestion improvement would greatly kept minimum making work,issue,positive,positive,positive,positive,positive,positive
515058655,"I tried substituting for the L63:  `self.ws = websocket.create_connection(**args)` with the following and it seemed to have worked to some degree: 

```
self.ws = websockets.connect(uri=url, **args)
```

But it also seems like in this module to accompany the `import websockets` you will probably also need to do `import asyncio`, which is currently missing in it. I am working on the Websocket Workers tutorials too so I encountered some similar issues. Hope that they will get resolved really soon. ",tried substituting following worked degree also like module accompany import probably also need import currently missing working similar hope get resolved really soon,issue,positive,neutral,neutral,neutral,neutral,neutral
515028667,"> I will try it as soon as possible.

Thank you, please keep us posted!

> And do I need to re-install pysyft from the beginning as your guide in Readme of Pysyft on my computer?

You will need the latest version of TF Encrypted (>= 0.5.7). You will also need the latest version of Syft but I believe part of the fix (https://github.com/OpenMined/PySyft/commit/4045ef26d214d7ea35b2acc4e947b5632648863e) has not made it into an official release yet, meaning you will likely need to run Syft from a source code installation of the `dev` branch.",try soon possible thank please keep u posted need beginning guide computer need latest version also need latest version believe part fix made official release yet meaning likely need run source code installation dev branch,issue,positive,positive,positive,positive,positive,positive
515009512,Thank you very much. I will try it as soon as possible. And do I need to re-install pysyft from the beginning as your guide in Readme of Pysyft on my computer? @mortendahl ,thank much try soon possible need beginning guide computer,issue,negative,positive,neutral,neutral,positive,positive
515006581,"Issue should be solved but happy to have third party verification as well. Would you be available to give it a try @keenlykeenly?

cc @robert-wagner",issue happy third party verification well would available give try,issue,positive,positive,positive,positive,positive,positive
514867604,"Check out this pull request on ReviewNB: https://app.reviewnb.com/OpenMined/PySyft/pull/2391 

 You'll be able to see visual diffs and write comments on notebook cells. Powered by <a href='https://www.reviewnb.com'>ReviewNB</a>.",check pull request able see visual write notebook powered,issue,negative,positive,positive,positive,positive,positive
514723414,@1000ping instead of spawning a separate process on Windows during which pickling error is encountered you can create the WebSocketServer within the current process context itself. I have created a PR with this change. https://github.com/OpenMined/PySyft/pull/2389 ,ping instead spawning separate process error create within current process context change,issue,negative,neutral,neutral,neutral,neutral,neutral
514672813,Feel free to fix the seeds for the random number generation in pytorch. But this would be a separate pull request. Another option would be to make sure that the dataset is so easy and the hyperparameters are well-chosen such that the training can't fail/get stuck.,feel free fix random number generation would separate pull request another option would make sure easy training ca stuck,issue,positive,positive,positive,positive,positive,positive
514669709,"> Concerning the failing unit test: The one failing test contains some randomness that can make it fail from time to time. If it does not fail repeatedly, I wouldn't worry.

With that in mind we should make the test deterministic",concerning failing unit test one failing test randomness make fail time time fail repeatedly would worry mind make test deterministic,issue,negative,negative,negative,negative,negative,negative
514632085,Or should I separate out new classes `WebSocket` and `WebSocketServer` from `WebSocketServerWorker`? Would that approach work? ,separate new class would approach work,issue,negative,positive,positive,positive,positive,positive
514630398,"I am investigating whether the following code would work well for `WebsocketServerWorker`:
```
def listen(self, backlog=5):
        self.socket.listen(backlog)
        logging.info(""Listening on %s"" % self.port)
        self.running = True
        self.cls = WebsocketServerWorker
        while self.running:
            rList, wList, xList = select(self.listeners, [], self.listeners, 1)
            for ready in rList:
                if ready == self.socket:
                    logging.debug(""New client connection."")
                    client, address = self.socket.accept()
                    filenum = client.filenum()
                    self.listeners.append(filenum)
                    self.connections[filenum] = self.cls(client, self)
                else:
                    logging.debug(""Client ready for reading %s."" % ready)
                    client = self.connections[ready].client
                    data = client.recv(1024)
                    filenum = client.filenum()
                    if data:
                        self.connections[filenum].feed(data)
                    else:
                        logging.debug(""Closing client %s."" % ready)
                        self.connections[filenum].close()
                        del self.connections[filenum]
                        self.listeners.remove(ready)
            for failed in xList:
                if failed == self.socket:
                    logging.error(""Socket is broken."")
                    for filenum, con in self.connections:
                        con.close()
                    self.running = False
```
where we have in `__init__():`
```
self.socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
self.listeners = [self.socket]
self.connections = {}
```
Any feedback for suggestions would be much appreciated. ",investigating whether following code would work well listen self backlog listening true select ready ready new client connection client address client self else client ready reading ready client ready data data data else client ready ready socket broken con false feedback would much,issue,positive,positive,neutral,neutral,positive,positive
514574080,Just noted that I was a bit too quick to merge the pull request. I will open a new one that will remove all the redundant time.sleep() commands.,noted bit quick merge pull request open new one remove redundant,issue,negative,positive,neutral,neutral,positive,positive
514537386,"@mccorby 
I discussed this helper function with Jason, and IMHO it is the easiest thing to get around the websocket connection problem that he experienced in #2373.
You are right, we should split unit tests from integration tests (websocket tests are definitely integration tests). But this will be a separate bigger task.",helper function easiest thing get around connection problem experienced right split unit integration definitely integration separate bigger task,issue,positive,positive,positive,positive,positive,positive
514415164,"Hi Jason,

I think we keep falling into the same issue with regard to the sockets or any other network connection in the tests.
This is a problem we have not yet solved but it should be addresses at some point.

I think the solution should be based on mocking the `websocket` instead of trying to use an actual one.

By mocking the responses of the methods of the socket, we can stop relying on it being connected, not falling, etc... We don't want to test the `websocket` class, we want to test our classes

This will require more work though as we have to figure out the responses (part of the issue to describe the serde process).

```
@mock.patch(""websocket.WebSocket.recv"")
def test_objects_count_remote(mock_method, hook, start_proc):
    mock_method.return_value = create_test_response()  # This bit is difficult
    # Rest of the test function
```

",hi think keep falling issue regard network connection problem yet point think solution based instead trying use actual one socket stop connected falling want test class want test class require work though figure part issue describe process hook bit difficult rest test function,issue,negative,negative,negative,negative,negative,negative
514389800,"I have added test cases for random integer arrays of non-symmetric dimensions.
But for array with float value it is giving `assert tensor_serialized[0] != serde.NO_COMPRESSION` this false.
",added test random integer array float value giving assert false,issue,positive,negative,negative,negative,negative,negative
514319474,"I think I was able to fix the error, seems like if I do `sys.path.remove('/usr/local/lib/python3.6/dist-packages/syft-0.1.21a1-py3.6.egg')` and also `sys.path.append('./PySyft')` I would then be able to patch or mask it. As for the `id` issue previously, that turned out to be specific to the `Client` notebook only, which for some reason is using Python 2.7 instead of Python 3.x... I will look more into it and make changes where appropriate for the notebooks to work on Colab. ",think able fix error like egg also would able patch mask id issue previously turned specific client notebook reason python instead python look make appropriate work,issue,negative,positive,positive,positive,positive,positive
514280717,Or if Google Colab proves to be problematic... Would be also be worthwhile to explore alternatives say using Binder for an interactive Jupyter notebook on the Internet?: https://mybinder.readthedocs.io/en/latest/introduction.html,problematic would also explore say binder interactive notebook,issue,negative,neutral,neutral,neutral,neutral,neutral
514275428,"Thanks @LaRiffle... Incidentally when I was checking the code in Google Colab I found the `syft`-native variable `id` to be problematic, whereas the same issue does not crop up when I was testing locally.

The code I used prior to such an error is:
```
! rm -rf ./PySyft
! git clone https://github.com/OpenMined/PySyft.git
# http://pytorch.org/
from os import path
from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag
platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())

accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'

!pip3 install https://download.pytorch.org/whl/cu100/torch-1.1.0-cp36-cp36m-linux_x86_64.whl
!pip3 install https://download.pytorch.org/whl/cu100/torchvision-0.3.0-cp36-cp36m-linux_x86_64.whl
import torch

!cd PySyft; pip3 install -r requirements.txt; pip3 install -r requirements_dev.txt; python3 setup.py install
import os
import sys

module_path = os.path.abspath(os.path.join('./PySyft'))
if module_path not in sys.path:
    sys.path.append(module_path)
```
Following this then I did:
```
import syft as sy
from syft.workers.websocket_server import WebsocketServerWorker

hook = sy.TorchHook(torch)

local_worker = WebsocketServerWorker(
                            host=""localhost"",
                            hook=hook,
                            id=0,
                            port=8182,
                            log_msgs=True,
                            verbose=True)

local_worker.start()  # Might need to Interupt with `control-C`

hook = sy.TorchHook(torch, local_worker=local_worker)
``` 

So the following is the error output:
```
  File ""/content/PySyft/syft/frameworks/torch/tensors/interpreters/abstract.py"", line 19
    id: int = None,
      ^
SyntaxError: invalid syntax
```
Any idea why and how to approach it? Is it just some simple syntax stuff as the error seems to suggest, or does it have to do with `id()` being a Python built-in function? ",thanks incidentally code found variable id problematic whereas issue crop testing locally code used prior error git clone o import path import platform accelerator else pip install pip install import torch pip install pip install python install import o import following import import hook torch might need hook torch following error output file line id none invalid syntax idea approach simple syntax stuff error suggest id python function,issue,negative,positive,neutral,neutral,positive,positive
514240866,Should be good to go now! I added the checks for loss decrease both for the remote and the local version. Anything missing @mari-linhares ?,good go added loss decrease remote local version anything missing,issue,negative,positive,neutral,neutral,positive,positive
514193634,"Ok, I just confirmed that there is a unit test. Could we improve the unit test by using `@pytest.mark.parametrize` and call it for let's say 4 different arrays? Some combination of float and int arrays, with non-symmetric dimensions? The current choice of `numpy.ones((10, 10))` feels a bit limited.",confirmed unit test could improve unit test call let say different combination float current choice bit limited,issue,negative,positive,neutral,neutral,positive,positive
514149182,"Ok excellent, let us know if you're stuck somewhere :)",excellent let u know stuck somewhere,issue,negative,positive,positive,positive,positive,positive
514140430,@midokura-silvia I think it's a good idea to make the tests deterministic as much as possible ? Travis needs to fail only when the intended changes made in a pr have a effect on the codebase. Randomized test make it harder to debug. ,think good idea make deterministic much possible travis need fail intended made effect test make harder,issue,negative,positive,neutral,neutral,positive,positive
514135736,"Concerning the failing unit test: The one failing test contains some randomness that can make it fail from time to time. If it does not fail repeatedly, I wouldn't worry. ",concerning failing unit test one failing test randomness make fail time time fail repeatedly would worry,issue,negative,negative,negative,negative,negative,negative
514097786,"Hi @mari-linhares , I managed to fix the test case not passing. Silly me, I was extracing the model's weights locally and then trying to perform a forward pass then no weights were even present in the model!

The training procedure I used is simply the same one as in the test case `test_encrypted_training_with_linear_model` in the file `test_autograd.py`",hi fix test case passing silly model locally trying perform forward pas even present model training procedure used simply one test case file,issue,negative,negative,negative,negative,negative,negative
514033371,There is no error. It starts ok. But the IP of the container is not accessible from macOS and opening the url with the container IP times out (see https://docs.docker.com/docker-for-mac/networking/#per-container-ip-addressing-is-not-possible) ,error container accessible opening container time see,issue,negative,positive,positive,positive,positive,positive
514029255,Also write a test case to ensure Numpy transform works well. ,also write test case ensure transform work well,issue,positive,neutral,neutral,neutral,neutral,neutral
513976938,"@jvmancuso just changed to Adam. 

I still think it would be valuable over time add ability to run notebooks directly in colab",still think would valuable time add ability run directly,issue,positive,positive,neutral,neutral,positive,positive
513897789,"Working on the issue here: https://github.com/kakirastern/PySyft/tree/fix-broken-demo
Will submit a PR when more certain about the edited tutorials. Currently fixed the `server` tutorial, but not the `client` one yet, which is more difficult as it turned out. ",working issue submit certain currently fixed server tutorial client one yet difficult turned,issue,negative,negative,neutral,neutral,negative,negative
513715993,Test cases are passing on local machine but failing at travis. What can be the problem and how should I resolve this?,test passing local machine failing travis problem resolve,issue,negative,neutral,neutral,neutral,neutral,neutral
513708565,"@robert-wagner can we integrate https://codecov.io/ for coverage test during the pull request integrated in travis.ci? 
Most of organisation use this for check coverage of pull request. ",integrate coverage test pull request use check coverage pull request,issue,negative,neutral,neutral,neutral,neutral,neutral
513677268,"I still have to implement some tests with RNNs modules to check if they behave as expected (i.e. similar results in comparison to pure PyTorch RNNs)

Also I still need to work on some improvement to the implementations:

https://github.com/OpenMined/PySyft/pull/2349/commits/c0a7921a6a3c0729f7f66ad228aa675152a2d42f

https://github.com/OpenMined/PySyft/pull/2349/commits/e6db59d648570cc02824bc004e4c0af44936e9c5
",still implement check behave similar comparison pure also still need work improvement,issue,negative,positive,positive,positive,positive,positive
513615088,"Hello @Liepill , do check out examples->tutorials->advanced , we have a tutorial on how to do that. ",hello check advanced tutorial,issue,negative,positive,positive,positive,positive,positive
513589178,"I was looking in issue #2357 and found this one. Can someone please explain about this issue in more detail. 
Thanks",looking issue found one someone please explain issue detail thanks,issue,positive,positive,positive,positive,positive,positive
513587163,"I was going through serde.py and I found https://github.com/OpenMined/PySyft/blob/e4044e67c8f1d72381de1fbeab42ae779f3f1ea0/syft/serde/serde.py#L372
 but only msgpack is used for serialization. What is a benefit as compared to JSON or protobuf which are more widely used libraries(having a larger community support)? I also had a conversation with @kamathhrishi where he mentioned there was a plan to use these. ",going found used serialization benefit widely used community support also conversation plan use,issue,positive,negative,neutral,neutral,negative,negative
513583429,"Thanks for the prompt response and the tip to start! Sure, will work on it as soon as possible. ",thanks prompt response tip start sure work soon possible,issue,positive,positive,positive,positive,positive,positive
513582286,"Yes any help is welcome is the issue is still there :)
Check that you have the latest version of pysystf and then check out `syft/workers/websocket*` to find the workers.",yes help welcome issue still check latest version check find,issue,positive,positive,positive,positive,positive,positive
513570118,"Once #2349 is merged, we may as well close this PR, as it was created for the purpose of making GRUs and LSTMs usable in PySyft.",may well close purpose making usable,issue,negative,neutral,neutral,neutral,neutral,neutral
513560120,"ENV: linux, python3.6.8, pysyft==0.1.13a1, torch==1.0.1, torchvision==0.2.2

Add the code in run_websocket_client.py:
```
kwargs_websocket_alice = {""host"": ""127.0.0.1"", ""hook"": hook}
alice = WebsocketClientWorker(id=""alice"", port=8777, **kwargs_websocket_alice)
workers = [alice]
```

I run the lines:
python3 run_websocket_server.py --host 127.0.0.1 --port 8777 --id alice
python3 run_websocket_client.py

It shows the bug:
KeyError: (wrapper)>[PointerTensor | me:some series of numbers -> alice:some series of number]

And I change to: pysyft==0.1.19a1, torch==1.1.0, torchvision==0.3.0
It still have.

@LaRiffle @DanyEle ",python add code host hook hook run python host port id python bug wrapper series series number change still,issue,negative,neutral,neutral,neutral,neutral,neutral
513558547,"Hi @iamtrask I would like to help out on this issue if no one has been assigned to it or has volunteered to take on the task yet. And, I have just checked the PySyft repo with a keyword search and it returns no results for `SocketWorker`. ",hi would like help issue one assigned take task yet checked search,issue,positive,neutral,neutral,neutral,neutral,neutral
513549207,@Ankit-Dhankhar Please feel free to open a PR and change it. It does look like an improvement. ,please feel free open change look like improvement,issue,positive,positive,positive,positive,positive,positive
513548774,"I was going through implementation in serde. I found implementation for torch and numpy_tensor_serializer/deserialize using TemporaryFile() which could be done with io.BytesIO too.
e.g.
For serialization
```
def numpy_tensor_serializer(tensor: torch.Tensor) -> bin:
    """"""Strategy to serialize a tensor using numpy npy format.
    If tensor requires to calculate gradients, it will detached.
    """"""
    if tensor.requires_grad:
        warnings.warn(
            ""Torch to Numpy serializer can only be used with tensors that do not require grad. ""
            ""Detaching tensor to continue""
        )
        tensor = torch.detach()

    np_tensor = tensor.numpy()
    outfile = io.BytesIO()
    numpy.save(outfile, np_tensor)
    return outfile.getvalue()
```

For deserialization 
```
def torch_tensor_deserializer(tensor_bin) -> torch.Tensor:
    """"""Strategy to deserialize a binary input in npy format into Torch tensor""""""
    bin_tensor_stream = io.BytesIO(tensor_bin)
    return torch.from_numpy(numpy.load(bin_tensor_stream))
```

Are there some differnce in use-case of efficiency issue for using two different I/O streams, which I am missing.
",going implementation found implementation torch could done serialization tensor bin strategy serialize tensor format tensor calculate torch used require tensor continue tensor return strategy binary input format torch tensor return efficiency issue two different missing,issue,negative,negative,neutral,neutral,negative,negative
513530742,"Hi, could you please follow the template for writing an Issue, so that more people can help solve your problem? Knowing the details about the kind of installation of PySyft and your Operating System would surely help.",hi could please follow template writing issue people help solve problem knowing kind installation operating system would surely help,issue,positive,positive,positive,positive,positive,positive
513397029,">That is, you can't get and clip the gradient of each individual data point without calling .backward separately for each.

Have you looked into the semantics of the torch.autograd.backward function? I believe they allow for this via the grad_tensors kwarg: https://pytorch.org/docs/stable/autograd.html This essentially allows you to do derivatives of tensors w.r.t. tensors (i.e. nontrivial Jacobians), instead of just scalars w.r.t. tensors.

A more approachable blog post about how to interpret what the vector in a Jacobian vector product represents: https://towardsdatascience.com/pytorch-autograd-understanding-the-heart-of-pytorchs-magic-2686cd94ec95",ca get clip gradient individual data point without calling separately semantics function believe allow via essentially instead approachable post interpret vector vector product,issue,negative,neutral,neutral,neutral,neutral,neutral
513389140,Why can't we use micro-batching as mentioned in this paper : https://arxiv.org/pdf/1812.06210.pdf ? I'm not sure if Tensorflow does something different than that to improve the computational time.,ca use paper sure something different improve computational time,issue,positive,positive,positive,positive,positive,positive
513345779,"@jvmancuso what do you think about making these ipynb more approachable with a link `run in colab`?

And with `Adam` it's also a reasonable suggestion ",think making approachable link run also reasonable suggestion,issue,negative,positive,positive,positive,positive,positive
513323526,Just added a few details to the example notebook to make things more complete. Think the PR is ready for a review. Any feedback would be much appreciated. Thanks! ,added example notebook make complete think ready review feedback would much thanks,issue,positive,positive,positive,positive,positive,positive
513296312,"I would also suggest that we just switch the optimizer -- there's no particular reason that Adadelta was used there, and so I'd suggest replacing with SGD + Nesterov Momentum or Adam to be closer to best practices",would also suggest switch particular reason used suggest momentum closer best,issue,positive,positive,positive,positive,positive,positive
513295857,"Yes, please resubmit this PR after modifying the existing Jupyter notebook!",yes please resubmit notebook,issue,positive,neutral,neutral,neutral,neutral,neutral
513117076,"Very interested in this pull request! Are tests passing now? From the Travis CI trace, it looks like the only error reported is the following:

> 1 file would be reformatted, 131 files would be left unchanged.

Running `black syft .` would be enough to fix it.",interested pull request passing travis trace like error following file would would left unchanged running black would enough fix,issue,negative,positive,neutral,neutral,positive,positive
513011369,"or shall I push in original jupyter format? 
so in this case it would be easier to review PR - since the diff would be smaller ",shall push original format case would easier review since would smaller,issue,positive,positive,positive,positive,positive,positive
512879291,"Hi @mari-linhares  I would like to work on this issue. Are there are pointer where I can start from like some paper or blogs?
",hi would like work issue pointer start like paper,issue,positive,neutral,neutral,neutral,neutral,neutral
512857112,"@Ankit-Dhankhar At their core they are the same function (in the source of native tensor for example, one just references the other. The main idea for this is so that people have a shorthand they can write if they want to). You could use whichever one you want and it does the same thing",core function source native tensor example one main idea people shorthand write want could use whichever one want thing,issue,negative,positive,positive,positive,positive,positive
512850829,@robert-wagner Why are there two variable for same function ? Can we replace all fix_prec with fix_precision or vice-versa if they are redundant?,two variable function replace redundant,issue,negative,negative,negative,negative,negative,negative
512845155,"The pb is that the data is not shared correctly here:

The model can be shared in-place but data can't be:
```python
model.share(...) # Is OK
model = model.share(...) # Is OK

data.share(...) # IS *NOT* OK
data = data.share(...) # Is OK
```
Additionally, all the parameters of the model get shared by default: we loop on model.parameters()",data correctly model data ca python model data additionally model get default loop,issue,negative,neutral,neutral,neutral,neutral,neutral
512723074,"Hello, please is anyone working on this. 
I will like to give it a try. Thanks",hello please anyone working like give try thanks,issue,positive,positive,positive,positive,positive,positive
512499610,"Yes, it's indeed working!! Also the quantization example, after removing calls to clone() on the input , but operating in place on the variables, is working!!!! :)",yes indeed working also quantization example removing clone input operating place working,issue,negative,neutral,neutral,neutral,neutral,neutral
512305933,"The `minimal_gru_init.py` does not run completely as we said because the hook on size() can't work: just replace the occurence of size() with .shape in your implem, remove the hook of size() and this error should disappear",run completely said hook size ca work replace size remove hook size error disappear,issue,negative,positive,neutral,neutral,positive,positive
512302025,"Try this for your forward pass: (check carefully the differences with the send/get stufff to understand better what was not working)
```python
    def forward(self, input, hidden, worker=None):
        print(input)
        emb = self.drop(self.encoder(input))

        output = []
        if self.rnn_type in ['GRU', 'GRUCell']:
            hx = hidden
            for i in range(emb.shape[0]): #Daniele: was emb.size(0)

                hx = self.rnn(emb[i, :], hx)
                output.append(hx.unsqueeze(0))

            output = torch.cat(output, dim=0)
        else:
            # else do smthg to instantiate output
            raise ValueError
                
        output = self.drop(output)
        decoded = self.decoder(output.view(output.size(0) * output.size(1), output.size(2)))
        return (decoded.view(output.size(0), output.size(1), decoded.size(1)), hx)
```

And to print the grad safely do:
```python
#BACKPROPAGATION - ISSUES OCCUR HERE! Gradients are [0,0,...,0]
        for k, param_remote in remote_model.named_parameters():
            print(k)
            worker = sy.hook.local_worker.get_worker(param_remote.location)
            print(worker._objects[param_remote.id_at_location].grad)
            #print(param_remote.grad.get())
```
It works on my side I get non-zero gradients",try forward pas check carefully understand better working python forward self input hidden print input input output hidden range output output else else output raise output output return print grad safely python occur print worker print print work side get,issue,positive,positive,positive,positive,positive,positive
512288060,"You get 8 param grad, the 6 first are only zeros but not the two last one:
zeros: encoder.weight, rnn.weight_ih, rnn.weight_hh, rnn.bias_ih, rnn.bias_hh
non-zeros: decoder.weight & decoder.bias",get param grad first two last one,issue,negative,positive,positive,positive,positive,positive
512287777,"If you want to inspect in a preserving manner you can directly access the remote object:
```
worker = sy.hook.local_worker.get_worker(param_remote.location)
print(worker._objects[param_remote.id_at_location].grad)
```",want inspect manner directly access remote object worker print,issue,negative,neutral,neutral,neutral,neutral,neutral
512287628,Rip okay. What is the result of copy locally?,rip result copy locally,issue,negative,neutral,neutral,neutral,neutral,neutral
512256901,Will add a notebook to https://github.com/OpenMined/PySyft/tree/dev/examples/tutorials/advanced to give examples on how to use the two new static methods next. If something needs to be changed in the PR please advise. Otherwise I will probably leave things as is. ,add notebook give use two new static next something need please advise otherwise probably leave,issue,negative,positive,positive,positive,positive,positive
512255898,"Added the arguments `timeout`, `bpf_filter`, `display_filter`, `tshark_path`, and `output_file` to the `get_packets` method in WebsocketClientWorker of syft.workers.websocket_client to facilitate better control of sniffing and to enable specification of a particular capture filter and/or display filter, say `tcp port 80` for the former and `tcp.port == 80` for the latter. Have tested the code locally. 

So effectively now `read_packet` is simply a convenience function. ",added method facilitate better control sniffing enable specification particular capture filter display filter say port former latter tested code locally effectively simply convenience function,issue,positive,positive,positive,positive,positive,positive
512237511,"The numerous tests failing in this PR confirm the hypothesis made in #2221 
https://github.com/OpenMined/PySyft/issues/2201#issuecomment-497712040
Hooking size() is not possible because it is used internally",numerous failing confirm hypothesis made size possible used internally,issue,negative,neutral,neutral,neutral,neutral,neutral
512215483,"Original method was too verbose despite being functional, so I have split the `get_packet_info` functions into two, one called `get_packets` to get pyshark capture object and the number (or `length`) of packets transmitted with a `timeout` set to 50 seconds, and the other called `read_packet` to read one packet from the `capture` output of `get_packets` based on the `index` argument which currently is set to be between `0` and `length - 1`. 

I think this is a better solution than the previous more naive way suggested by former users in some forums. ",original method verbose despite functional split two one get capture object number length set read one packet capture output based index argument currently set length think better solution previous naive way former,issue,negative,positive,neutral,neutral,positive,positive
512155430,"Thanks for the system information @keenlykeenly!

>  all of them are classified as 0. 

This has to do with a Windows bug we're currently investigating: https://github.com/tf-encrypted/tf-encrypted/issues/577!",thanks system information classified bug currently investigating,issue,negative,positive,neutral,neutral,positive,positive
512134686,"I also saved from colab directly, hence a bit updated structure, but I am open for feedback",also saved directly hence bit structure open feedback,issue,negative,positive,neutral,neutral,positive,positive
512079338,"@mortendahl @lc0 But there still exits a problem in tutorial Part 13c. In order to remove the randomness, 
I test 100 samples, but all of them are classified as 0. Even though the model test accuracy is 98.21% in Part 13a when I increase the epochs to 12. 
![image](https://user-images.githubusercontent.com/11493656/61343108-32e9b200-a87f-11e9-9684-0831eab451e6.png)
",still problem tutorial part order remove randomness test classified even though model test accuracy part increase image,issue,negative,neutral,neutral,neutral,neutral,neutral
512069771,"@lc0 Yes! It is the problem of learning rate! When I specify the learning rate of Adadelta as optimizer=keras.optimizers.Adadelta(lr=1.0), the accuracy is 94.6%. 
![image](https://user-images.githubusercontent.com/11493656/61341507-26625b00-a879-11e9-9c37-bfb5218fc616.png)

Thank you so much!",yes problem learning rate specify learning rate accuracy image thank much,issue,negative,positive,positive,positive,positive,positive
512062670,@lc0 Thanks very much. And what can I do to fix it? Change the version of tensorflow to 1.13 or specify the learning rate of Adadelta? And how to do it? I am sorry that I cannot open the link you gave above.,thanks much fix change version specify learning rate sorry open link gave,issue,negative,negative,neutral,neutral,negative,negative
512042076,"Here is an example - https://colab.research.google.com/drive/1l_dLRxws29wqBJeVSmXdGOOXnuTx8VK2#scrollTo=vicyresvIesY

@iamtrask would it make sense to add a version of executed environment(tensorflow/pytorch) in the beginning of such tutorials, so people do not get confused?",example would make sense add version executed environment beginning people get confused,issue,negative,negative,negative,negative,negative,negative
512040475,"I found the issue, from TensorFlow 1.13 to TensorFlow 1.14 seems like default learning rate for Adadelta was changed from `1.0` to `0.001`, that's why currently it's so much also slower to learn

",found issue like default learning rate currently much also learn,issue,negative,positive,positive,positive,positive,positive
511963378,"And I am guessing if I would like `pyshark` to detect the network interface I would need to pass the `tshark_path` argument to the `LiveCapture` method to specify the path of the `tshark` binary as a basic requirement. 

Moreover, I think I should definitely add the following arguments to the `get_data_info` function if suitable for the desired purposes: 
```
* bpf_filter: BPF filter to use on packets.
* display_filter: Display (wireshark) filter to use.
* only_summaries: Only produce packet summaries, much faster but includes very little information
* disable_protocol: Disable detection of a protocol (tshark > version 2)
* decryption_key: Key used to encrypt and decrypt captured traffic.
* encryption_type: Standard of encryption used in captured traffic (must be either 'WEP', 'WPA-PWD', or 'WPA-PWK'. Defaults to WPA-PWK).
* tshark_path: Path of the tshark binary
* output_file: Additionally save captured packets to this file.
```

Will follow up on PR #2360 from this point onwards. ",guessing would like detect network interface would need pas argument method specify path binary basic requirement moreover think definitely add following function suitable desired filter use display filter use produce packet much faster little information disable detection protocol version key used encrypt traffic standard encryption used traffic must either path binary additionally save file follow point onwards,issue,positive,positive,neutral,neutral,positive,positive
511945094,"Other arguments I could add (besides `interface`) to the method are as follows: 

```
* bpf_filter: BPF filter to use on packets.
* display_filter: Display (wireshark) filter to use.
* only_summaries: Only produce packet summaries, much faster but includes very little information
* disable_protocol: Disable detection of a protocol (tshark > version 2)
* decryption_key: Key used to encrypt and decrypt captured traffic.
* encryption_type: Standard of encryption used in captured traffic (must be either 'WEP', 'WPA-PWD', or 'WPA-PWK'. Defaults to WPA-PWK).
* tshark_path: Path of the tshark binary
* output_file: Additionally save captured packets to this file.
```",could add besides interface method filter use display filter use produce packet much faster little information disable detection protocol version key used encrypt traffic standard encryption used traffic must either path binary additionally save file,issue,negative,positive,neutral,neutral,positive,positive
511930270,Rebased and dropped a commit accidentally added on during `git poll origin dev` merge that is not coming from me. Now everything is passing. Will stick to using `git rebase -i ...` for this repo from now on to be safe. Seems like that commit was problematic. ,commit accidentally added git poll origin dev merge coming everything passing stick git rebase safe like commit problematic,issue,positive,positive,positive,positive,positive,positive
511916015,"Noted there is some `test_fit[gaussian_mixture-10]` failure which resulted in the following `Assertion Error`: 
```
E           assert tensor(0.6931, grad_fn=<NllLossBackward>) < tensor(0.6931, grad_fn=<NllLossBackward>)
test/federated/test_federated_client.py:164: AssertionError
```
This is unrelated to the code committed herein, but is causing the Travis CI checks of this PR to fail. 

Also noted from the Travis tests output the four warnings below:
```
/home/travis/virtualenv/python3.6.7/lib/python3.6/site-packages/_pytest/mark/structures.py:324
  /home/travis/virtualenv/python3.6.7/lib/python3.6/site-packages/_pytest/mark/structures.py:324: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/latest/mark.html
    PytestUnknownMarkWarning,

test/federated/test_plan.py::test_plan_method_execute_locally
  /home/travis/build/OpenMined/PySyft/syft/frameworks/torch/tensors/interpreters/native.py:308: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
    response = eval(cmd)(*args, **kwargs)

test/torch/differential_privacy/test_pate.py::test_base_dataset_torch

test/torch/differential_privacy/test_pate.py::test_torch_ref_match
  /home/travis/build/OpenMined/PySyft/syft/frameworks/torch/hook/hook.py:764: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
    current_tensor = hook_self.torch.native_tensor(*args, **kwargs)

-- Docs: https://docs.pytest.org/en/latest/warnings.html
```",noted failure following assertion error assert tensor tensor unrelated code herein causing travis fail also noted travis output four unknown typo register custom avoid warning see implicit dimension choice change call include argument response copy construct tensor use true rather,issue,negative,negative,negative,negative,negative,negative
511884148,"> Wow! Very cool PR! Would you be willing to also include an example (prefarably a notebook or two) showing how to use it? Perhaps in this folder (https://github.com/OpenMined/PySyft/tree/dev/examples/tutorials/advanced)

Sure, I will do so once it has been polished further and approved. ",wow cool would willing also include example notebook two showing use perhaps folder sure polished,issue,positive,positive,positive,positive,positive,positive
511883548,I understand many things needed to be changed in this PR for the current function to capture data transmitted through a particular TCP port used by a `worker`. But I would like to get feedback in this PR in order to carry it to fruition. ,understand many current function capture data particular port used worker would like get feedback order carry fruition,issue,negative,positive,positive,positive,positive,positive
511882908,Wow! Very cool PR! Would you be willing to also include an example (prefarably a notebook or two) showing how to use it? Perhaps in this folder (https://github.com/OpenMined/PySyft/tree/dev/examples/tutorials/advanced),wow cool would willing also include example notebook two showing use perhaps folder,issue,positive,positive,positive,positive,positive,positive
511876373,"Thanks for the tip! I did some experimenting on my own laptop and found that I needed to specify the interface used for my setup to work, otherwise an error `dumpcap: There is no interface with that adapter index` would be thrown. For my interface setting I used `en0` for my WiFi connection. So I will modify the code to be as follows:
```
@staticmethod
def get_packet_info(interface=None):
    """"""
    Returns the size of the serialized data using Wireshark.

    Args:
        interface: A string. Name of the interface to sniff on.

    Returns: Size of the packet sent over WebSockets in a given event.
    """"""
    if interface is None:
        raise Exception(""Please provide the interface used."")
    else:
        capture = pyshark.LiveCapture(interface=interface)
        capture.sniff(timeout=60)
        for packet in capture:
            try:
                packet_info = packet.pretty_print()
            except:
                raise Exception(""Cannot determine packet info."")
        return packet_info
```
I also found out that I cannot do something like `packet.tcp.data` as the `data` attribute for tcp does not exist, or at least not anymore.  I can do something like `packet.tcp.pretty_print`. If I stick to the former, i.e. `packet.pretty_print()`, I would get info for all three layers including `eth`, `ip`, `tcp`. If I go with the latter then only the info regarding the `tcp` layer would be generated for output. Is there a preference as to whether only the `tcp` packets are outputted? I could change the code again if this latter approach is preferred. ",thanks tip found specify interface used setup work otherwise error interface adapter index would thrown interface setting used en connection modify code size data interface string name interface sniff size packet sent given interface none raise exception please provide interface used else capture packet capture try except raise exception determine packet return also found something like data attribute exist least something like stick former would get three go latter regarding layer would output preference whether could change code latter approach preferred,issue,positive,negative,neutral,neutral,negative,negative
511812796,"Getting the first network interface is indeed a good idea. I just tried to boot Wireshark and it detect my wlan Interface as my network interface. 

 About your second point I can't really say, since I don't know those methods or attributes. The way I checked the traffic sent in Wireshark was by setting a filter for the traffic sent (assuming 8777 is alice's port)
`tcp.port == 8777`
And after data was transmitted, I would click on Statistics --> Capture File Properties and look under ""Captured"" for a count of the data transmitted over that port. That included ACKs and re-transmission attempts' data too though. ",getting first network interface indeed good idea tried boot detect interface network interface second point ca really say since know way checked traffic sent setting filter traffic sent assuming port data would click statistic capture file look count data port included data though,issue,negative,positive,positive,positive,positive,positive
511795105,"> Well, that only seems to be working for the ethernet interface:
> 
> ` capture = pyshark.LiveCapture(interface='eth0')`
> 
> But if the user is connected to a WiFi network, this wouldn't work.
> 
> It would be nice to automatically detect the network interface to which user is connected, or let him choose from which network interface Wireshark should listen to (maybe have the network interface as a parameter?), and then sniff packets from there.

Yes, thanks for pointing that out! According to the official `pyshark` docs, the argument `interface` can be set to `None` so that it would automatically detect the first available network interface the user is connected to, if I have not misinterpreted the original wording. 

In the official docs it states that
> param interface: Name of the interface to sniff on. If not given, takes the first available.

So I would change my code in `websocket_client.py` to:
```
...
import pyshark
...

@staticmethod
    def get_packet_size(interface=None):
        """"""
       Returns the size of the serialized data using Wireshark.
       
       Args: TODO
       
       Returns: Size of the packet sent over WebSockets in a given event.
       """"""
        capture = pyshark.LiveCapture(interface=interface)
        capture.sniff(timeout=60)
        
        for packet in capture:
            try:
                packet_size = packet.tcp.data
            except:
                packet_size = None
                raise Exception(""Cannot determine packet size."")
    
        return packet_size
```

However, then I have another issue: Supposed I only sniff on `tcp` packets as WebSocket uses TCP as the transport protocol. Then, should I use the `data` attribute to get the data info, or should I use something like the `pretty_print()` method to get the package details? Or is there a third way to do this? The official docs is not really clear hence my concern. ",well working interface capture user connected network would work would nice automatically detect network interface user connected let choose network interface listen maybe network interface parameter sniff yes thanks pointing according official argument interface set none would automatically detect first available network interface user connected original wording official param interface name interface sniff given first available would change code import size data size packet sent given capture packet capture try except none raise exception determine packet size return however another issue supposed sniff transport protocol use data attribute get data use something like method get package third way official really clear hence concern,issue,positive,positive,positive,positive,positive,positive
511688443,"I added two test cases for AutogradTensor. 

1) Sending and receiving an AutogradTensor remotely.

2) Training a simple NN model with AutogradTensors. However, there seem to be some issues in the forward propagation phase. Maybe @LaRiffle  may take a look at the test case `test_train_remote_autograd_tensor`

here is the error I get

![image](https://user-images.githubusercontent.com/4907418/61271928-26455b00-a7a6-11e9-9764-2559d68e4d20.png)


",added two test sending training simple model however seem forward propagation phase maybe may take look test case error get image,issue,negative,neutral,neutral,neutral,neutral,neutral
511679934,"> I am thinking about adding something in the line of the following in ""websocket_client.py"" and ""websocket_server.py"". Would it work well?
> 
> ```
> ...
> import pyshark
> ...
> 
> @staticmethod
>     def get_packet_size():
>         """"""
>        Returns the size of the serialized data using Wireshark.
>        
>        Args: TODO
>        
>        Returns: Size of the packet sent over WebSockets in a given event.
>        """"""
>         capture = pyshark.LiveCapture(interface='eth0')
>         capture.sniff(timeout=60)
>         
>         for packet in capture:
>             try:
>                 packet_size = packet.data.data
>             except:
>                 packet_size = None
>                 raise Exception(""Cannot determine packet size."")
>     
>         return packet_size
> ```
> 
> If not, I would really appreciate any feedback given so that I can learn from the experience.

Well, that only seems to be working for the ethernet interface:

`        capture = pyshark.LiveCapture(interface='eth0')`

But if the user is connected to a WiFi network, this wouldn't work.

It would be nice to automatically detect the network interface to which user is connected, or let him choose from which network interface Wireshark should listen to (maybe have the network interface as a parameter?), and then sniff packets from there. ",thinking something line following would work well import size data size packet sent given event capture packet capture try except none raise exception determine packet size return would really appreciate feedback given learn experience well working interface capture user connected network would work would nice automatically detect network interface user connected let choose network interface listen maybe network interface parameter sniff,issue,positive,positive,positive,positive,positive,positive
511556672,"Probably some tutorials for developers could be useful: ""how serialization and deserializations works in syft""",probably could useful serialization work,issue,negative,positive,positive,positive,positive,positive
511556203,"Hey @bluerxing,

I believe this was fixed in this PR #2353. You should be able to have the correct behavior by using the dev version of this repo or using pip in the next few days (when the new version of pysyft is submitted).

I'll close this issue, but feel free to leave comments here if you face any issues.

",hey believe fixed able correct behavior dev version pip next day new version close issue feel free leave face,issue,negative,positive,positive,positive,positive,positive
511502267,"I am thinking about adding something in the line of the following in ""websocket_client.py"" and ""websocket_server.py"". Would it work well? 
```
...
import pyshark
...

@staticmethod
    def get_packet_size():
        """"""
       Returns the size of the serialized data using Wireshark.
       
       Args: TODO
       
       Returns: Size of the packet sent over WebSockets in a given event.
       """"""
        capture = pyshark.LiveCapture(interface='eth0')
        capture.sniff(timeout=60)
        
        for packet in capture:
            try:
                packet_size = packet.data.data
            except:
                packet_size = None
                raise Exception(""Cannot determine packet size."")
    
        return packet_size
```
If not, I would really appreciate any feedback given so that I can learn from the experience. ",thinking something line following would work well import size data size packet sent given capture packet capture try except none raise exception determine packet size return would really appreciate feedback given learn experience,issue,positive,positive,neutral,neutral,positive,positive
511483393,I would just add that this is quite reminiscent of the Mesh project from TensorFlow (https://github.com/tensorflow/mesh),would add quite reminiscent mesh project,issue,negative,neutral,neutral,neutral,neutral,neutral
511460587,"Hi, 
In the configuration I'm studying, I want to train a Neural Network where the different parts reside on both a server and a worker/client/data owner.

To do so, I need to initiate the computation at the client’s location, then forward it to the server, before sending it back to the client to finish the computation.

I need after that to compute the gradients and backpropagate them with the `backward` function. Therefore the flow goes the other way. However, an error occurs (a size mismatch) for the last call of `backward`, but when I print the shapes they are correct, and they are at the right location (i.e. on the client’s machine).

You'll find below a minimal example to reproduce this error:

` 
### Forward part
#First tensor, sent to client's location
a = torch.tensor([1.,2.,3.,4.],requires_grad=True)
a = a.send(bob)

#Second tensor, cloned and sent to server
b = a**2
b_ = b.clone().get()

#Third tensor, cloned and sent to client
c = b_**3
c_ = c.clone().send(bob)

#Fourth tensor 
d = c_.sum()

### Backward part
d.backward()
g1 = c_.grad.clone().get()
d.get()
c.backward(g1)
g2 = b_.grad.clone().send(bob)
print(""b shape:"",b.shape)
print(""gradient shape:"", g2.shape)
b.backward(g2)`

<pre>
b shape: torch.Size([4])
gradient shape: torch.Size([4])
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-4-ea3378717307> in <module>()
     21 print(""b shape:"",b.shape)
     22 print(""gradient shape:"", g2.shape)
---> 23 b.backward(g2)

11 frames
/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
    675                 # Send the new command to the appropriate class and get the response
    676                 method = getattr(new_self, method_name)
--> 677                 response = method(*new_args, **new_kwargs)
    678 
    679                 # For inplace methods, just directly return self

/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook.py in overloaded_pointer_method(self, *args, **kwargs)
    511             command = (attr, self, args, kwargs)
    512 
--> 513             response = owner.send_command(location, command)
    514 
    515             return response

/usr/local/lib/python3.6/dist-packages/syft/workers/base.py in send_command(self, recipient, message, return_ids)
    425 
    426         try:
--> 427             ret_val = self.send_msg(codes.MSGTYPE.CMD, message, location=recipient)
    428         except ResponseSignatureError as e:
    429             ret_val = None

/usr/local/lib/python3.6/dist-packages/syft/workers/base.py in send_msg(self, msg_type, message, location)
    221 
    222         # Step 2: send the message and wait for a response
--> 223         bin_response = self._send_msg(bin_message, location)
    224 
    225         # Step 3: deserialize the response

/usr/local/lib/python3.6/dist-packages/syft/workers/virtual.py in _send_msg(self, message, location)
      8 class VirtualWorker(BaseWorker, FederatedClient):
      9     def _send_msg(self, message: bin, location: BaseWorker) -> bin:
---> 10         return location._recv_msg(message)
     11 
     12     def _recv_msg(self, message: bin) -> bin:

/usr/local/lib/python3.6/dist-packages/syft/workers/virtual.py in _recv_msg(self, message)
     11 
     12     def _recv_msg(self, message: bin) -> bin:
---> 13         return self.recv_msg(message)
     14 
     15     @staticmethod

/usr/local/lib/python3.6/dist-packages/syft/workers/base.py in recv_msg(self, bin_message)
    252             print(f""worker {self} received {sy.codes.code2MSGTYPE[msg_type]} {contents}"")
    253         # Step 1: route message to appropriate function
--> 254         response = self._message_router[msg_type](contents)
    255 
    256         # Step 2: Serialize the message to simple python objects

/usr/local/lib/python3.6/dist-packages/syft/workers/base.py in execute_command(self, message)
    363             else:
    364                 try:
--> 365                     response = getattr(_self, command_name)(*args, **kwargs)
    366                 except TypeError:
    367                     # TODO Andrew thinks this is gross, please fix. Instead need to properly deserialize strings

/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
    661                 except BaseException as e:
    662                     # we can make some errors more descriptive with this method
--> 663                     raise route_method_exception(e, self, args, kwargs)
    664 
    665             else:  # means that there is a wrapper to remove

/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
    655                 try:
    656                     if isinstance(args, tuple):
--> 657                         response = method(*args, **kwargs)
    658                     else:
    659                         response = method(args, **kwargs)

/usr/local/lib/python3.6/dist-packages/torch/tensor.py in backward(self, gradient, retain_graph, create_graph)
    105                 products. Defaults to ``False``.
    106         """"""
--> 107         torch.autograd.backward(self, gradient, retain_graph, create_graph)
    108 
    109     def register_hook(self, hook):

/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables)
     91     Variable._execution_engine.run_backward(
     92         tensors, grad_tensors, retain_graph, create_graph,
---> 93         allow_unreachable=True)  # allow_unreachable flag
     94 
     95 

RuntimeError: invalid gradient at index 0 - got [0] but expected shape compatible with [4]
</pre>",hi configuration want train neural network different reside server owner need initiate computation client location forward server sending back client finish computation need compute backward function therefore flow go way however error size mismatch last call backward print correct right location client machine find minimal example reproduce error forward part first tensor sent client location bob second tensor sent server third tensor sent client bob fourth tensor backward part bob print shape print gradient shape shape gradient shape recent call last ea module print shape print gradient shape self send new command appropriate class get response method response method directly return self self command self response location command return response self recipient message try message except none self message location step send message wait response location step response self message location class self message bin location bin return message self message bin bin self message self message bin bin return message self print worker self received content step route message appropriate function response content step serialize message simple python self message else try response except gross please fix instead need properly self except make descriptive method raise self else wrapper remove self try response method else response method backward self gradient false self gradient self hook backward flag invalid gradient index got shape compatible,issue,negative,positive,neutral,neutral,positive,positive
511210039,"And yeah, I agree maybe using WireShark to monitor traffic sent over WebSockets would provide more details regarding the data sent or received, which might be useful to get a breakdown of the data transmitted, at the cost of some computational overheads. ",yeah agree maybe monitor traffic sent would provide regarding data sent received might useful get breakdown data cost computational,issue,positive,positive,positive,positive,positive,positive
511205231,"I successfully managed to implement the serialization and deserialization procedures for AutogradTensor. Nevertheless, my issue with remote backpropagation using a custom class still persists, and a [0,0,0,..0] gradient is produced in all model's parameters.",successfully implement serialization nevertheless issue remote custom class still gradient produced model,issue,negative,positive,positive,positive,positive,positive
511202734,"Hey @dvu4 

I'm facing the exactly similar issue on MacOS Mojave Ver 10.14.5. Were you able to find a solution to this issue?

Conda Version: `4.6.14`
Python Version in Conda environment: `python 3.7.3`

Can anyone else with a similar configuration please help me with the installation?
",hey facing exactly similar issue able find solution issue version python version environment python anyone else similar configuration please help installation,issue,positive,positive,positive,positive,positive,positive
511145470,@Ankit-Dhankhar Any help would be much appreciated. I agree I should use two variables `bin_message` (for data sent) and `bin_response` (for data received) instead of just one `data_size` variable which would seem like a misnomer. ,help would much agree use two data sent data received instead one variable would seem like misnomer,issue,positive,positive,positive,positive,positive,positive
511140838,"I find this issue interesting and would love to help.
@LaRiffle @kakirastern  For size of a object send we can directly acumulate size of [bin_message (for sent data)](https://github.com/OpenMined/PySyft/blob/2eb15a37e5f2318b5c1c8d45cd133dce80ac6490/syft/workers/base.py#L220) and [bin_response (for data received)](https://github.com/OpenMined/PySyft/blob/2eb15a37e5f2318b5c1c8d45cd133dce80ac6490/syft/workers/base.py#L223).
Should we have consider the actual size of data send using wireshark which include IP header and other information. 
Including that would have its own computational overhead but a accurate measure of data sent or received. will be available. On other hand we can directly take compressed size of object and assume them to be actual size with a proportionality constant. In which way should we proceed?
",find issue interesting would love help size object send directly size sent data data received consider actual size data send include header information would computational overhead accurate measure data sent received available hand directly take compressed size object assume actual size proportionality constant way proceed,issue,positive,positive,positive,positive,positive,positive
511081301,"Hey @amit-rastogi,

The new function actually uses `start_proc`, so yes, this issue is still valid.",hey new function actually yes issue still valid,issue,negative,positive,neutral,neutral,positive,positive
511036348,"I am attempting a solution at my branch here: https://github.com/kakirastern/PySyft/tree/monitor-network-usage. I reckon it may take some time if a working solution will indeed be worked out, say a few weeks, as I am new to this repo and thus its code base. ",solution branch reckon may take time working solution indeed worked say new thus code base,issue,positive,negative,negative,negative,negative,negative
510918766,"I added the possibility to choose big fields for CRT tensors but I'm not sure it works yet, I cannot test that before next week",added possibility choose big sure work yet test next week,issue,negative,positive,positive,positive,positive,positive
510911012,"I believe this should be a working implemenetation for the simplify and detail methods, but I get a missing gradient error during the backpropagation. Is there anything missing for the data being sent over? Like some part of the gradient?

from `autograd.py`


```python
  @staticmethod
    def simplify(tensor: ""AutogradTensor"") -> tuple:
        """"""Takes the attributes of an AutogradTensor and saves them in a tuple.

        Args:
            tensor: an AutogradTensor.

        Returns:
            tuple: a tuple holding the unique attributes of the AutogradTensor.
        """"""
        print(""Simplify AutogradTensor"")
        chain = None
        #send the child over
        if hasattr(tensor, ""child""):
            chain = syft.serde._simplify(tensor.child)

        return (
            tensor.owner,
            syft.serde._simplify(tensor.id),
            chain,
            tensor.requires_grad,
            tensor.preinitialize_grad,
            tensor.grad_fn,
            syft.serde._simplify(tensor.tags),
            syft.serde._simplify(tensor.description),
        )
        

    @staticmethod
    def detail(worker: AbstractTensor, tensor_tuple: tuple) -> ""AutogradTensor"":
        """"""
            This function reconstructs an AutogradTensors given its attributes in form of a tuple.
            Args:
                worker: the worker doing the deserialization
                tensor_tuple: a tuple holding the attributes of the AutogradTensor
            Returns:
                AutogradTensor: an AutogradTensor
            Examples:
                shared_tensor = detail(data)
            """"""
        print(""Detail AutogradTensor"")
        owner, tensor_id, chain, requires_grad, preinitialize_grad, grad_fn, tags, description = tensor_tuple

        
        if chain is not None:
            chain = syft.serde._detail(worker, chain)
            
    
        tensor = AutogradTensor(
            owner=owner,
            id=syft.serde._detail(worker, tensor_id),
            preinitialize_grad=preinitialize_grad,
            grad_fn = grad_fn,
            data = chain, #pass the de-serialized data
            tags = syft.serde._detail(worker, tags),
            description = syft.serde._detail(worker, description),
        )
        
        #tensor.child = chain

        return tensor
    
```
",believe working simplify detail get missing gradient error anything missing data sent like part gradient python simplify tensor tensor holding unique print simplify chain none send child tensor child chain return chain detail worker function given form worker worker holding detail data print detail owner chain description chain none chain worker chain tensor worker data chain pas data worker description worker description chain return tensor,issue,negative,negative,neutral,neutral,negative,negative
510907223,"I saw the PR ""[WIP] Implement start_remote_worker #2345"" where its mentioned that start_proc would get replaced with start_remote_worker. Hence, wanted to check if this issue is still valid and needs to be worked upon?",saw implement would get hence check issue still valid need worked upon,issue,negative,neutral,neutral,neutral,neutral,neutral
510876871,"Perhaps no serialization mechanism are implemented for AutogradTensor objects? Not super sure.. I'm trying to look into it.

EDIT: After talking to @LaRiffle , it turns out that serialization is not yet implemented for AutogradTensor objects. So, I'm currently trying to implement serialization for it. 

Thèo suggested that it should be sufficient to add proper `simplify` and`detail` methods to the autograd.py and add AutogradTensor to to OBJ_SIMPLIFIER_AND_DETAILERS in serde.py ",perhaps serialization mechanism super sure trying look edit talking turn serialization yet currently trying implement serialization sufficient add proper simplify detail add,issue,positive,positive,positive,positive,positive,positive
510872374,"I'm trying to adapt your suggestion @LaRiffle , and running your example with my more concrete case:

```python
#Perform forward pass
 output, hidden = remote_model_cpu_train(data_remote, hidden_repackaged, worker)
#Resize the output
output_viewed = output.view(-1, ntokens)
#Compute the loss
loss = criterion(output_viewed, targets_remote)
#Let's backpropagate over here!
loss.backward(hidden) 
```
However, I get the following error in the loss.backward(hidden) step:

![image](https://user-images.githubusercontent.com/4907418/61128878-65786100-a4b3-11e9-8b61-eb205a3d7ab3.png)

![image](https://user-images.githubusercontent.com/4907418/61128938-8e98f180-a4b3-11e9-8c5b-aaef17d9d8b9.png)



",trying adapt suggestion running example concrete case python perform forward pas output hidden worker resize output compute loss loss criterion let hidden however get following error hidden step image image,issue,negative,negative,neutral,neutral,negative,negative
510714121,"> Hi @keenlykeenly, could you provide a few details about the system you're on:
> 
> * OS (macOS, Linux, Windows)?
> * TensorFlow version (eg via `pip list`)?

@mortendahl Thank you for your reply.
It is Windows system. And I use the anaconda virtual environment. The tensorflow version is 1.14.0 rc0.
When I enter 'pip list' in the anaconda prompt, I get:
Package                            Version              Location                             
---------------------------------- -------------------- -------------------------------------
absl-py                            0.7.1                
alabaster                          0.7.12               
anaconda-client                    1.7.2                
anaconda-navigator                 1.9.7                
anaconda-project                   0.8.2                
asn1crypto                         0.24.0               
astor                              0.8.0                
astroid                            2.1.0                
astropy                            3.1.2                
atomicwrites                       1.3.0                
attrs                              19.1.0               
Babel                              2.7.0                
backcall                           0.1.0                
backports.os                       0.1.1                
backports.shutil-get-terminal-size 1.0.0                
beautifulsoup4                     4.7.1                
bitarray                           0.9.3                
bkcharts                           0.2                  
blaze                              0.11.3               
bleach                             3.1.0                
bokeh                              1.2.0                
boto                               2.49.0               
Bottleneck                         1.2.1                
certifi                            2019.3.9             
cffi                               1.12.3               
chardet                            3.0.4                
Click                              7.0                  
cloudpickle                        1.1.1                
clyent                             1.2.2                
colorama                           0.4.1                
comtypes                           1.1.7                
conda                              4.6.14               
conda-build                        3.17.8               
conda-package-handling             0+unknown            
conda-verify                       3.3.0                
contextlib2                        0.5.5                
cryptography                       2.7                  
cycler                             0.10.0               
Cython                             0.29.10              
cytoolz                            0.9.0.1              
dask                               1.2.2                
datashape                          0.5.4                
decorator                          4.4.0                
defusedxml                         0.6.0                
distributed                        1.28.1               
docutils                           0.14                 
entrypoints                        0.3                  
et-xmlfile                         1.0.1                
fastcache                          1.1.0                
filelock                           3.0.12               
Flask                              1.0.3                
Flask-Cors                         3.0.7                
flask-socketio                     4.0.0                
future                             0.17.1               
gast                               0.2.2                
gevent                             1.4.0                
glob2                              0.6                  
google-pasta                       0.1.7                
greenlet                           0.4.15               
grpcio                             1.21.1               
h5py                               2.9.0                
heapdict                           1.0.0                
html5lib                           1.0.1                
idna                               2.8                  
imageio                            2.5.0                
imagesize                          1.1.0                
importlib-metadata                 0.17                 
ipykernel                          5.1.1                
ipython                            7.5.0                
ipython-genutils                   0.2.0                
ipywidgets                         7.4.2                
isort                              4.3.4                
itsdangerous                       1.1.0                
jdcal                              1.4.1                
jedi                               0.13.3               
Jinja2                             2.10.1               
jsonschema                         3.0.1                
jupyter                            1.0.0                
jupyter-client                     5.2.4                
jupyter-console                    6.0.0                
jupyter-core                       4.4.0                
jupyterlab                         0.35.4               
jupyterlab-launcher                0.13.1               
jupyterlab-server                  0.2.0                
keras-applications                 1.0.8                
keras-preprocessing                1.0.9                
keyring                            18.0.0               
kiwisolver                         1.1.0                
lazy-object-proxy                  1.3.1                
libarchive-c                       2.8                  
llvmlite                           0.28.0               
locket                             0.2.0                
lxml                               4.3.3                
lz4                                2.1.6                
markdown                           3.1.1                
MarkupSafe                         1.1.1                
matplotlib                         2.1.0                
mccabe                             0.6.1                
menuinst                           1.4.16               
mistune                            0.8.4                
mkl-fft                            1.0.12               
mkl-random                         1.0.2                
mkl-service                        2.0.2                
more-itertools                     7.0.0                
mpmath                             1.1.0                
msgpack                            0.6.1                
multipledispatch                   0.6.0                
navigator-updater                  0.2.1                
nbconvert                          5.5.0                
nbformat                           4.4.0                
networkx                           2.3                  
nltk                               3.4.1                
nose                               1.3.7                
notebook                           5.7.8                
numba                              0.36.2               
numexpr                            2.6.4                
numpy                              1.16.4               
numpydoc                           0.9.1                
odo                                0.5.1                
olefile                            0.46                 
openpyxl                           2.6.2                
packaging                          19.0                 
pandas                             0.24.2               
pandocfilters                      1.4.2                
parso                              0.4.0                
partd                              0.3.10               
path.py                            12.0.1               
pathlib2                           2.3.3                
patsy                              0.5.0                
pep8                               1.7.1                
phe                                1.4.0                
pickleshare                        0.7.5                
Pillow                             6.0.0                
pip                                19.1.1               
pkginfo                            1.5.0.1              
pluggy                             0.12.0               
ply                                3.11                 
prometheus-client                  0.6.0                
prompt-toolkit                     2.0.9                
protobuf                           3.8.0                
psutil                             5.6.2                
py                                 1.8.0                
pycodestyle                        2.5.0                
pycosat                            0.6.3                
pycparser                          2.19                 
pycrypto                           2.6.1                
pycurl                             7.43.0.2             
pyflakes                           2.1.1                
Pygments                           2.4.2                
pylint                             2.2.2                
pyodbc                             4.0.26               
pyOpenSSL                          19.0.0               
pyparsing                          2.2.0                
pyreadline                         2.1                  
pyrsistent                         0.14.11              
PySocks                            1.7.0                
pytest                             4.6.2                
pytest-arraydiff                   0.3                  
pytest-astropy                     0.5.0                
pytest-doctestplus                 0.3.0                
pytest-openfiles                   0.3.2                
pytest-remotedata                  0.3.1                
python-dateutil                    2.6.1                
python-engineio                    3.7.0                
python-socketio                    4.0.3                
pytz                               2017.3               
PyWavelets                         1.0.3                
pywin32                            223                  
pywinpty                           0.5.5                
PyYAML                             5.1                  
pyzmq                              18.0.0               
QtAwesome                          0.5.7                
qtconsole                          4.5.1                
QtPy                               1.7.1                
requests                           2.22.0               
rope                               0.14.0               
ruamel-yaml                        0.15.46              
scikit-image                       0.13.1               
scikit-learn                       0.19.1               
scipy                              1.0.0                
seaborn                            0.8.1                
Send2Trash                         1.5.0                
setuptools                         41.0.1               
simplegeneric                      0.8.1                
singledispatch                     3.4.0.3              
six                                1.11.0               
sklearn                            0.0                  
snowballstemmer                    1.2.1                
sortedcollections                  1.1.2                
sortedcontainers                   2.1.0                
soupsieve                          1.8                  
Sphinx                             2.1.0                
sphinxcontrib-applehelp            1.0.1                
sphinxcontrib-devhelp              1.0.1                
sphinxcontrib-htmlhelp             1.0.2                
sphinxcontrib-jsmath               1.0.1                
sphinxcontrib-qthelp               1.0.2                
sphinxcontrib-serializinghtml      1.1.3                
sphinxcontrib-websupport           1.1.2                
spyder                             3.3.4                
spyder-kernels                     0.4.4                
SQLAlchemy                         1.3.4                
statsmodels                        0.8.0                
style                              1.1.0                
syft                               0.1.17               
sympy                              1.4                  
tables                             3.4.2                
tblib                              1.4.0                
tensorboard                        1.13.1               
tensorflow                         1.14.0rc0            
termcolor                          1.1.0                
terminado                          0.8.2                
testpath                           0.4.2                
tf-encrypted                       0.5.5                d:\programdata\anaconda3\tf-encrypted
tf-estimator-nightly               1.14.0.dev2019042301 
toolz                              0.9.0                
torch                              1.0.1                
torchvision                        0.2.2                
tornado                            6.0.2                
tqdm                               4.32.1               
traitlets                          4.3.2                
typed-ast                          1.1.1                
typing                             3.6.4                
unicodecsv                         0.14.1               
update                             0.0.1                
urllib3                            1.24.2               
vboxapi                            1.0                  
wcwidth                            0.1.7                
webencodings                       0.5.1                
websocket-client                   0.56.0               
websockets                         7.0                  
Werkzeug                           0.15.4               
wheel                              0.33.4               
widgetsnbextension                 3.4.2                
win-inet-pton                      1.1.0                
win-unicode-console                0.5                  
wincertstore                       0.2                  
wrapt                              1.11.1               
xlrd                               1.2.0                
XlsxWriter                         1.1.8                
xlwings                            0.15.8               
xlwt                               1.3.0                
zict                               0.1.4                
zipp                               0.5.1                
zstd                               1.4.0.0              


Thanks a lot.",hi could provide system o version via pip list thank reply system use anaconda virtual environment version enter list anaconda prompt get package version location alabaster astor astroid blaze bleach bottleneck click cryptography cycler decorator distributed flask future gast greenlet jinja locket markdown nose notebook pep pillow pip pluggy ply rope six sphinx style table dev torch tornado update wheel thanks lot,issue,positive,positive,neutral,neutral,positive,positive
510316685,"Hi guys! Apologies for the radio silence, have been busy the past few months but working on this intermittently. I just opened a PR: https://github.com/OpenMined/PySyft/pull/2350

I kept this stuff in a notebook because I wasn't sure where it should sit in the codebase -- any feedback there would be super helpful! ",hi radio silence busy past working intermittently kept stuff notebook sure sit feedback would super helpful,issue,positive,positive,positive,positive,positive,positive
510271782,I'm gonna run a final test tomorrow and then we'll finally merge this PR :),gon na run final test tomorrow finally merge,issue,negative,neutral,neutral,neutral,neutral,neutral
510191871,"I think we have what we wanted to have there, but maybe Theo should confirm before we merge",think maybe confirm merge,issue,negative,neutral,neutral,neutral,neutral,neutral
510121194,"Hi @keenlykeenly, could you provide a few details about the system you're on: 
- OS (macOS, Linux, Windows)?
- TensorFlow version (eg via `pip list`)?",hi could provide system o version via pip list,issue,negative,neutral,neutral,neutral,neutral,neutral
510059977,"So I would say the sample of code I suggetsed is not supposed to work right now, but we should do the appropriate imprvements in autograd to have it working. It's more a target to achieve :)",would say sample code supposed work right appropriate working target achieve,issue,negative,positive,positive,positive,positive,positive
510059394,"Hey yes you're right, but this is linked to the additive sharing part not the fixed_precision: take the same example  from @vvmnnnkv and remove .share() and .get() it will work

So as a **recap**  we have issues with additive shared tensor with mul or div with integers with n>2 workers",hey yes right linked additive part take example remove work recap additive tensor div,issue,negative,positive,positive,positive,positive,positive
510020019,"@LaRiffle, I do understand that what it does is exactly use whatever comes from the inheritance (that is why I suggested using the in-place multiplication operator and it works properly). In the division by integer case, we are constrained by the precision_fractional we have set and it performs poorly if we need more precision just as pointed by @vvmnnnkv. ",understand exactly use whatever come inheritance multiplication operator work properly division integer case constrained set poorly need precision pointed,issue,negative,negative,neutral,neutral,negative,negative
510013149,"Thank you for the example @LaRiffle . I tried running your code, but got the following error:

```
y.backward()

TypeError: backward() missing 1 required positional argument: 'grad_out'
```

Instead, when running

`y.backward(x)`

This does seem to be working as expected and the backward method is indeed invoked from the custom class. I have yet to verify whether this would work for my particular case though. 
",thank example tried running code got following error backward missing positional argument instead running seem working backward method indeed custom class yet verify whether would work particular case though,issue,negative,negative,neutral,neutral,negative,negative
510008813,"> Good, add also basic .size() tests for all tensors where you added ( in the test_<tensor_type>.py files), or don't forget to push the work if you already added them :)

Yep, I re-named a test for the size of local tensors from test_size to test_local_size and created a new test case for testing the size() method using remote tensors. ",good add also basic added forget push work already added yep test size local new test case testing size method remote,issue,negative,positive,positive,positive,positive,positive
510002527,"@joseilberto we'd love to have division with fixed_precision! We haven't had a use case yet where division by a FixedPrecision divisor was needed, we only needed integer division, that's why you don't see an implementation so far.

One thing to notice, is that for example if you don't see a method (like `__truediv__`) in precision.py it doesn't mean it's not implemented, it means that the basic PyTorch behaviour will be used. For integer division for example you don't need to specify a specific behaviour different from PyTorch.
",love division use case yet division divisor integer division see implementation far one thing notice example see method like mean basic behaviour used integer division example need specify specific behaviour different,issue,positive,positive,neutral,neutral,positive,positive
509999736,"Good, add also basic .size() tests for all tensors where you added ( in the test_<tensor_type>.py files), or don't forget to push the work if you already added them :)",good add also basic added forget push work already added,issue,negative,positive,positive,positive,positive,positive
509998998,"Now the forward pass into LSTMs is working. I added a couple of tests for the size of remote tensors and the usage of the forward phase with LSTMs. 


```
def test_lstm(workers):
    bob = workers[""bob""]
    lstm = nn.LSTM(3, 3)
    inputs = torch.randn(5, 1, 3)
    hidden = (torch.randn(1, 1, 3), torch.randn(1, 1, 3))  # clean out hidden state
    out, hidden = lstm(inputs, hidden)
    assert out.shape == torch.Size([5, 1, 3])
    lstm = nn.LSTM(3, 3)
    lstm.send(bob)
    inputs = torch.randn(5, 1, 3).send(bob)
    hidden = (
        torch.randn(1, 1, 3).send(bob),
        torch.randn(1, 1, 3).send(bob),
    )  # clean out hidden state
    out, hidden = lstm(inputs, hidden)
    #This test will pass once the .size() method is implemented for
    #remote tensors
    assert out.shape == torch.Size([5, 1, 3])
```",forward pas working added couple size remote usage forward phase bob bob hidden clean hidden state hidden hidden assert bob bob hidden bob bob clean hidden state hidden hidden test pas method remote assert,issue,positive,negative,neutral,neutral,negative,negative
509958811,Can you add a test to this change to seee what is now possible?,add test change possible,issue,negative,neutral,neutral,neutral,neutral,neutral
509957488,"The easiest way to do would be to work in the second direction, and the piece of code that we'd like to work would be:
```python
import torch
import torch.autograd as autograd
import torch.nn as nn

import syft as sy
hook = sy.TorchHook(torch)
worker = sy.VirtualWorker(hook, id=""alice"")

class MyFunction(torch.autograd.Function):
    def forward(self, x):
        print(""Custom forward called"")
        return x
    
    def backward(self, grad_out):
        grad_input = grad_out.clone()
        print('Custom backward called!')
        return grad_input


x = torch.tensor([1.5], requires_grad=True)
x = x.send(worker, local_autograd=True)

y = MyFunction(x)

y.backward()
```
Would this address your usecase?",easiest way would work second direction piece code like work would python import torch import import import hook torch worker hook class forward self print custom forward return backward self print backward return worker would address,issue,positive,neutral,neutral,neutral,neutral,neutral
509951111,"Hey! 
So there are many things here,
- Currently with AutogradTensor, you need to specify the gradient for all operations that you use, and in particular you need to explain how the backward is supposed to be computed, so you cant' just add a print statement to some multiplication function, you also need to re-state how to differentiate it. Of course this is not a pb for a function which doesn't modify the data. One awesome thing would be to be able to call the native backward for a function, which might not be always available especially if you don't have access to the graph of computation grad_fn.
- To specify a custom function with a forward and backward, which are understood by Autograd, you currently need to add this function in gradient.py, would be good to offer a way for user to add more functions directly in the code just like @DanyEle tries to do",hey many currently need specify gradient use particular need explain backward supposed cant add print statement multiplication function also need differentiate course function modify data one awesome thing would able call native backward function might always available especially access graph computation specify custom function forward backward understood currently need add function would good offer way user add directly code like,issue,positive,positive,positive,positive,positive,positive
509866940,"Hey @robert-wagner,

I believe it's fixed now, had some minor problems updating the tests but they should pass now.

I've also changed the ports of a few WebSocket tests for precaution (avoiding use the same ports, just in case a connection is not closed).",hey believe fixed minor pas also precaution use case connection closed,issue,negative,negative,neutral,neutral,negative,negative
509837757,hey @mari-linhares Some tests are breaking due to connection errors. I am not sure why that is,hey breaking due connection sure,issue,negative,positive,positive,positive,positive,positive
509815962,"@joseilberto, I think we left out the division for FixedPrecisionTensor on purpose, to avoid a loss of precision when division isn't exact... But I'm not sure why we couldn't have something like a floor division, you're right. Maybe @LaRiffle knows a bit more about FixedPrecisionTensors?",think left division purpose avoid loss precision division exact sure could something like floor division right maybe bit,issue,negative,positive,positive,positive,positive,positive
509774025,I'm merging this without a review to make it so that we can merge pull requests until https://gitlab.com/pycqa/flake8-docstrings/merge_requests/15 is merged. This change will be reverted at that point,without review make merge pull change point,issue,negative,neutral,neutral,neutral,neutral,neutral
509767669,We actually used to have test for this which was super flakey due to the above instability,actually used test super due instability,issue,positive,positive,neutral,neutral,positive,positive
509767461,"@Jasopaum A big problem with operations between more than 2 ast's is that when recombining each of them there is a greater likelyhood in losing precision in the least significant bit. An intuitive way to think about this problem is to think of the last digit as a float which adds up to 1 but is rounded. For the n=2 case, unless you split the number such that both are exactly equal to 0.5, one of the numbers will round to 1 and the other to 0. However, when n>2, it is likely that all will round to 0 leading to a loss in precision",big problem ast greater losing precision least significant bit intuitive way think problem think last digit float rounded case unless split number exactly equal one round however likely round leading loss precision,issue,negative,positive,neutral,neutral,positive,positive
509660543,"@vvmnnnkv, Division in FixedPrecisionTensor is not even implemented. @Jasopaum, maybe division by integer is a nice feature to be implemented soon.",division even maybe division integer nice feature soon,issue,negative,positive,positive,positive,positive,positive
509646554,"Here's another example - calculating avg of multiple zero tensors shared to multiple workers.
Works fine with `num = 2`.

```
num = 10
wks = [ sy.VirtualWorker(hook, id=""wk#%d"" % i) for i in range(num) ]
tensors = [ torch.zeros(5, 5).fix_prec(precision_fractional=16).share(*wks) for _ in range(num) ]
avg = tensors[0]
for i in range(num-1):
  avg += tensors[i+1]
avg /= len(tensors)
avg = avg.get().float_prec()
print(avg)

tensor([[ 1.0000e-16, -1.8447e+02, -1.8447e+02, -1.8447e+02, -1.8447e+02],
        [ 1.8447e+02,  9.2234e+01,  1.8447e+02, -1.8447e+02,  9.2234e+01],
        [ 1.8447e+02,  1.8447e+02,  0.0000e+00, -1.8447e+02,  1.8447e+02],
        [ 1.0000e-16, -1.8447e+02, -1.8447e+02,  1.8447e+02, -1.0000e-16],
        [ 1.8447e+02,  1.0000e-16,  0.0000e+00,  1.8447e+02, -1.8447e+02]])
```

Expected is tensor of zeros.
",another example calculating multiple zero multiple work fine hook range range range print tensor tensor,issue,negative,positive,positive,positive,positive,positive
509628595,"As suggested by @iamtrask , I currently trying to use ""AutogradTensor"" from Pull Request #2293 , however I have not yet managed to get it working with a custom class.

Any ideas on how to combine custom classes in combination with an AutogradTensor?

This is the code I tried with the AutoGradTensor:

```import torch
import torch.autograd as autograd
import torch.nn as nn
import syft as sy

class MyFun(torch.autograd.Function):
    def forward(self, inp):
        return inp
    
    def backward(self, grad_out):
        grad_input = grad_out.clone()
        print('Custom backward called!')
        return grad_input

class MyMod(nn.Module):
    def forward(self, x):
        return MyFun()(x)

#local version - the backward method is indeed invoked. 
mod_test = MyFun()

mod = MyMod()



y = autograd.Variable(torch.randn(1), requires_grad=True)
z = mod(y)
#z.backward()
#remote version - the backward method is not invoked.
hook = sy.TorchHook(torch)
worker = sy.VirtualWorker(hook, id=""alice"")

y_remote = y.send(worker)
y_autograd = sy.AutogradTensor().on(y_remote)
#y_auto_remote = y_auto.send(worker)
z_remote = z.send(worker)
z_autograd = sy.AutogradTensor().on(z_remote)

z_remote.backward()```



However, it says 'ValueError: The gradient for one of the command you used was not found. Check gradients.py to see if it's missing.'",currently trying use pull request however yet get working custom class combine custom class combination code tried import torch import import import class forward self return backward self print backward return class forward self return local version backward method indeed remote version backward method hook torch worker hook worker worker worker however gradient one command used found check see missing,issue,negative,negative,neutral,neutral,negative,negative
509602812,"On Windows the web socket client also fails to connect giving the error below. 

OverflowError: timeout doesn't fit into C timeval

Appears to be due to the timeout interval (TIMEOUT_INTERVAL = 9_999_999) specified in websocket_client.py.",web socket client also connect giving error fit due interval,issue,negative,positive,positive,positive,positive,positive
509598617,I would like to take this up if this is still available.,would like take still available,issue,negative,positive,positive,positive,positive,positive
509592194,"Hey, thanks for the PR but we were already working on same function you modified in another PR (#2300) and I already added the changes you've made there...",hey thanks already working function another already added made,issue,negative,positive,positive,positive,positive,positive
509549082,"> Excellent idea!
> If you want to do this manualy you can also do it is the code:
> In that case you want for a worker to store the amount of data sent and received, like this would be to attributes of a worker: so each time some data is sent or received, you evaluate the size of the serialize data and you add it to this attributes. To catch the event ""data is sent or received"" you will need to inspect how the module `serde` works (ser-ialize / de-serialize). It's more hacky, but helps you understanding the code.

Thanks for the tip! This hacky way sounds really interesting and promising... Am looking into it. Hopefully a PR will follow soon. ",excellent idea want also code case want worker store amount data sent received like would worker time data sent received evaluate size serialize data add catch event data sent received need inspect module work hacky understanding code thanks tip hacky way really interesting promising looking hopefully follow soon,issue,positive,positive,positive,positive,positive,positive
509519923,"@LaRiffle, a quick fix using the in-place operation somehow works:
```
wks = [ sy.VirtualWorker(hook, id=""w#%d"" % i) for i in range(3) ]
t = torch.zeros(3,3)
t = t.fix_prec().share(*wks)
t *= 2
t = t.get()
t.float_prec()
```
For the very specific problem of multiplying by an integer, I submitted a pull request and it passed all tests.",quick fix operation somehow work hook range specific problem multiplying integer pull request,issue,negative,positive,positive,positive,positive,positive
509443508,"> @LaRiffle I've experienced the increasing loss issues with my Adam as well.
> 
> But, since it wasn't raising errors, I tried to see where things went numerically wrong.
> 
> Somehow, in Adam's `step()` method, changing this line
> 
> ```
> exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)
> ```
> 
> to this line
> 
> ```
> exp_avg_sq.mul_(beta2).add_(grad.pow(2).mul_(1 - beta2))
> ```
> 
> and this line
> 
> ```
> p.data.addcdiv_(-step_size, exp_avg, denom)
> ```
> 
> to this line
> 
> ```
> p.data.add_(exp_avg.div(denom).mul_(-step_size))
> ```
> 
> made it work and the loss decreased with no problem.
> 
> So, it seems like `addcmul_()` and `addcdiv_()` functions have issues working with PySyft, but doing what those functions do step by step somehow fixes them.

cool",experienced increasing loss well since raising tried see went numerically wrong somehow step method line beta beta grad grad line beta beta line line made work loss problem like working step step somehow cool,issue,negative,positive,positive,positive,positive,positive
509413433,"Hmm @LaRiffle, this doesn't seem sufficient to fix the problem of >2 workers:

```
wks = [ sy.VirtualWorker(hook, id=""w#%d"" % i) for i in range(3) ]
crypto_prov = sy.VirtualWorker(hook, id=""crypto_prov"")
t = torch.zeros(3,3)
t = t.fix_prec().share(*wks, crypto_provider=crypto_prov)
t = t * 2
t = t.get()
t = t.float_prec()
print(t)

tensor([[-1.8447e+13,  1.8447e+13,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],
        [-1.0000e-03, -1.8447e+13,  1.8447e+13]])
```",seem sufficient fix problem hook range hook print tensor,issue,negative,neutral,neutral,neutral,neutral,neutral
509408176,"EDIT **not enough**
> Use a crypto provider and that should be sufficient",edit enough use provider sufficient,issue,negative,neutral,neutral,neutral,neutral,neutral
509402498,"In this particular case where we multiply by a scalar, I think we do something useless:
we first multiply the multiplier by `base ** precision_fractional` and then truncate. When I remove this, the results are ok.
But I agree that there are still some problems when multiplying 2 ASTs shared between more than 2 workers",particular case multiply scalar think something useless first multiply multiplier base truncate remove agree still multiplying,issue,negative,negative,negative,negative,negative,negative
509261724,"hey @mccorby I really like the spirit of this pr but I think there are some things that we could do to make it better.
Firstly, I think we should write out the words for federated learning and differential privacy. Secondly I think we should add edges to the diagram to show how the different pieces interact. eg a worker has tensors which are modified to perform different algorithms",hey really like spirit think could make better firstly think write learning differential privacy secondly think add diagram show different interact worker perform different,issue,positive,positive,positive,positive,positive,positive
508914903,"@LaRiffle I've experienced the increasing loss issues with my Adam as well.

But, since it wasn't raising errors, I tried to see where things went numerically wrong.

Somehow, in Adam's `step()` method, changing this line
```
exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)
```
to this line
```
exp_avg_sq.mul_(beta2).add_(grad.pow(2).mul_(1 - beta2))
```

and this line
```
p.data.addcdiv_(-step_size, exp_avg, denom)
```
to this line
```
p.data.add_(exp_avg.div(denom).mul_(-step_size))
```

made it work and the loss decreased with no problem.

So, it seems like `addcmul_()` and `addcdiv_()` functions have issues working with PySyft, but doing what those functions do step by step somehow fixes them.",experienced increasing loss well since raising tried see went numerically wrong somehow step method line beta beta grad grad line beta beta line line made work loss problem like working step step somehow,issue,negative,positive,positive,positive,positive,positive
508689282,"@wagnernegrao  has started on this issue I think, but you can also give a try of course

have a look at syft/frameworks/torch/tensors/interpreters/
- autograd.py
- gradients.py

",issue think also give try course look,issue,negative,neutral,neutral,neutral,neutral,neutral
508583403,I'd like to give this a shot if that's ok. Where can I find this in the directory?,like give shot find directory,issue,negative,neutral,neutral,neutral,neutral,neutral
508529350,"Hey @keenlykeenly,

I don't think this is an issue since the model is randomly initialized it's possible that it could classify the first images wrong. Having said that I'll close the issue for now.

But maybe is not a coincidence that it classified all images as zeros, have you trained the model? Can you check how your model classifies other images from the test set?

Thanks!

 ",hey think issue since model randomly possible could first wrong said close issue maybe coincidence classified trained model check model test set thanks,issue,negative,negative,neutral,neutral,negative,negative
508198096,@mccorby please run black on the code,please run black code,issue,negative,negative,negative,negative,negative,negative
508116186,"The major point of failure is that given any AST x, `x * 0 == 0` fails.",major point failure given ast,issue,negative,negative,negative,negative,negative,negative
507895736,"Another important change that option 3 would require is that users will need to call `plan.build` explicitly since the default behaviour will not build the plan.

How do you feel about this? @LaRiffle 

I don't see this as a major problem, and I still think the third option is more intuitive than others.",another important change option would require need call explicitly since default behaviour build plan feel see major problem still think third option intuitive,issue,negative,positive,positive,positive,positive,positive
507786411,Hey @mortendahl Thanks for the ping. The issues regarding the failing udacity notebook are covered in #2327 cc @LaRiffle as well,hey thanks ping regarding failing notebook covered well,issue,negative,positive,positive,positive,positive,positive
507775179,"@iamtrask PR for Udacity: https://github.com/udacity/private-ai/pull/9

Note that parts of the Udacity notebooks were failing for apparently unrelated issues (cc @robert-wagner)",note failing apparently unrelated,issue,negative,positive,neutral,neutral,positive,positive
507746339,"I found out that when restoring a `LongTensor`, `float_precision()` is not returning the original values. 

This test would fail:
```
def test_long():
    x = torch.tensor([1])
    enlarged = x.fix_prec()
    restored = enlarged.float_precision()
    # And now x and restored must be the same
    assert torch.all(torch.eq(x, restored))
```
Are we happy with this?",found original test would fail enlarged must assert happy,issue,negative,positive,positive,positive,positive,positive
507696693,I'll pick this one (unless someone wants to do it as a first in the project),pick one unless someone first project,issue,negative,positive,positive,positive,positive,positive
507559544,I don't see it as a problem to have different behavior locally and remotely. However we should make sure that all relevant cases are tested and cannot get different results.,see problem different behavior locally remotely however make sure relevant tested get different,issue,negative,positive,positive,positive,positive,positive
507531121,"Yes, according @iamtrask , you can write a optimizer list like Part4 or Par10, then you can use Adam, Adadelta or other optimizer with momentum. @2fasc ",yes according write list like part par use momentum,issue,positive,neutral,neutral,neutral,neutral,neutral
507499930,"Would be cool to see applications of CNN's in the field of construction and project management, nothing to do with bug fixes in code - but a life-saving idea nonetheless. I know most devs focus on merchandise and e-commerce when applying a convolutional, yet there exists a vast library of architecture and blueprints from companies in mech engineerin' (Caterpillar, John Deere, Toyota) that remain in the dark  Hopefully if you manage to debug the FederatedDataLoader you could find time to explore new datasets

Gears Churnin'",would cool see field construction project management nothing bug code idea nonetheless know focus merchandise convolutional yet vast library architecture caterpillar remain dark hopefully manage could find time explore new,issue,positive,positive,neutral,neutral,positive,positive
507429256,"The main pro is that: locally a plan will behave exactly like the original function/method to users.
The main con is that: remotely this may not be true (for example: a plan for a Model will not be able to train remotely without using autograd tensors). Although, if this change is not implemented this will not be possible locally or remotely.",main pro locally plan behave exactly like original main con remotely may true example plan model able train remotely without although change possible locally remotely,issue,positive,positive,positive,positive,positive,positive
507428158,"> How does this affect performance/ the ability to send plans? 

It should affect neither. 

There are mainly two cases:
* If a plan is local (worker has the blueprint), it will execute the plan using the blueprint.
* If a plan was sent, it will execute plans in the ""traditional way"".
",affect ability send affect neither mainly two plan local worker blueprint execute plan blueprint plan sent execute traditional way,issue,negative,positive,neutral,neutral,positive,positive
507424300,"How does this affect performance/ the ability to send plans? If it has a dominance relationship with the current implementation for those two categories, I'm all for it. I personally am opposed to having global variables if all possible (they break in multiprocessing situations). Furthermore, I think adding the argument to call, means it will not be used.",affect ability send dominance relationship current implementation two personally opposed global possible break furthermore think argument call used,issue,negative,neutral,neutral,neutral,neutral,neutral
507331547,"@LaRiffle - shouldn't it be possible to do what he's trying to do using AutogradTensor? Is there a way to call .send() on a graph and keep the graph local but just send the tensor to a remote machine so that when you call .backward() it does backprop locally but executes it remotely?

Aka - how does he create a custom op for AutogradTensor?",possible trying way call graph keep graph local send tensor remote machine call locally remotely aka create custom,issue,negative,negative,neutral,neutral,negative,negative
507287975,"The core issue is that when we serialize objects we don't serialize their graph as well. In other words, when you call .send() on a tensor, we don't send the whole graph, we only send that tensor.

However, the fix should be easy. If you send everything BEFORE the forward pass it should work.

TODO: we should add support for someone to send a dynamic graph",core issue serialize serialize graph well call tensor send whole graph send tensor however fix easy send everything forward pas work add support someone send dynamic graph,issue,positive,positive,positive,positive,positive,positive
507070560,"[WORKING on this issue] 

Thank you for the opportunity!! As this is a good-first-issue, I would love to take a stab. I am in need of a contribution. 

Is it okay if I reach out in Slack to ask questions? 

I may need help with test case set up and passing TravisCI, but I noticed the test case only tests for the exception TensorsNotCollocatedException  not the message, I should be okay, I think?",working issue thank opportunity would love take stab need contribution reach slack ask may need help test case set passing test case exception message think,issue,positive,positive,positive,positive,positive,positive
507055821,"Hey @theoptips,

Thanks for reporting this issue! Feel free to make a PR to fix it if you want to :)!",hey thanks issue feel free make fix want,issue,positive,positive,positive,positive,positive,positive
507055683,"Thanks for the contribution @ProfXGiter, feel free to make a PR to fix these typos!",thanks contribution feel free make fix,issue,positive,positive,positive,positive,positive,positive
507046967,"thanks for review @mari-linhares - I added a note to the contributing docs and a ticket (#2323) to track the remaining work. I don't think it would be a ton of work to address the remaining issues, though it's worth noting a few of the issues mypy flags may be legitimate type errors. ",thanks review added note ticket track work think would ton work address though worth may legitimate type,issue,positive,positive,positive,positive,positive,positive
506921057,"I did this 

```
def tensors_to_literals(tensor_list):
    """"""Converts list of torch tensors to list of integers/floats. Fix for not having the functionality which converts list of tensors to tensors
       Args:
           tensor_list[List]: List of torch tensors
        
       Returns:
           literal_list[List]: List of floats/integers
    """"""

    literal_list = []

    for tensor in tensor_list:
        literal_list.append(tensor.item())

    return literal_list
```

Also try using torch.cat to convert list of tensors into a single tensor. ",list torch list fix functionality list list list torch list list tensor return also try convert list single tensor,issue,negative,negative,neutral,neutral,negative,negative
506920178,"I get this error too, when creating a tensor of tensors in a custom class. Does anyone have a work around for the moment?",get error tensor custom class anyone work around moment,issue,negative,neutral,neutral,neutral,neutral,neutral
506856077,"> hey @DanyEle On another note, how does this behave if you call y.send() before you call the mod on it?

Just tried it and did not notice any difference. The backward method from the MyMod class is still not invoked.",hey another note behave call call tried notice difference backward method class still,issue,negative,neutral,neutral,neutral,neutral,neutral
506834370,"hey @DanyEle On another note, how does this behave if you call y.send() before you call the mod on it?",hey another note behave call call,issue,negative,neutral,neutral,neutral,neutral,neutral
506768062,Thank you for the response @LaRiffle . Any idea on how to possibly fix this issue and introduce support for the backward propagation function for the torch.autograd.function in PySyft over remote tensors?,thank response idea possibly fix issue introduce support backward propagation function remote,issue,positive,negative,neutral,neutral,negative,negative
506697234,"As discussed with @DanyEle one reason for this can be:
Regarding nn.Modules operated on remote data, the forward pass method is run by the client (ie the local instance) and then all ops inside (like nn.relu or nn.Linear) are hooked and a message is sent for each of them to the workers which holds the data. Therefore, the remote worker doesn't have the big picture of your nn.module model.
However, when you call backward, the cmd `backward()` is sent directly to the remote worker. In this case, as it doesn't have the big picture of your nn.module model, it doesn't see the custom backward of yours and just performs the default backward.",one reason regarding remote data forward pas method run client ie local instance inside like hooked message sent data therefore remote worker big picture model however call backward backward sent directly remote worker case big picture model see custom backward default backward,issue,negative,negative,neutral,neutral,negative,negative
506255926,"Excellent idea!
If you want to do this manualy you can also do it is the code:
In that case you want for a worker to store the amount of data sent and received, like this would be to attributes of a worker: so each time some data is sent or received, you evaluate the size of the serialize data and you add it to this attributes. To catch the event ""data is sent or received"" you will need to inspect how the module `serde` works (ser-ialize / de-serialize). It's more hacky, but helps you understanding the code.",excellent idea want also code case want worker store amount data sent received like would worker time data sent received evaluate size serialize data add catch event data sent received need inspect module work hacky understanding code,issue,positive,positive,positive,positive,positive,positive
506255485,So I will approach the problem via Wireshark first... ,approach problem via first,issue,negative,positive,positive,positive,positive,positive
505792917,"@robert-wagner I replicated this using the code below-

hook = sy.TorchHook(torch)
x = torch.tensor([1.,2])
y = torch.tensor([2,3.])
bob = sy.VirtualWorker(hook, id=""bob"")
alice = sy.VirtualWorker(hook, id=""alice"")
x_ptr = x.send(bob, alice)
y_ptr = y.send(bob)
z = x_ptr+y_ptr        #####Got syft.exceptions.RemoteObjectFoundError here",replicated code hook torch bob hook bob hook bob bob got,issue,negative,neutral,neutral,neutral,neutral,neutral
505693235,"I hope to work on this issue. Is this still open?
@mari-linhares @robert-wagner ",hope work issue still open,issue,negative,neutral,neutral,neutral,neutral,neutral
505561667,Yes that sounds good. I'll move it to experimental.,yes good move experimental,issue,positive,positive,positive,positive,positive,positive
505428690,"I fixed it putting a requirement setuptool>=41.0.0 in requirements_dev.txt
Code contained in PR on tf_encrypted dependency removal",fixed requirement code dependency removal,issue,negative,positive,neutral,neutral,positive,positive
505394288,"The solution that worked for me on MacOS Mojave 10.14.5:

`conda create -n py3_6_3 python=3.6.3 anaconda`
`conda activate py3_6_3`
`conda install pytorch torchvision -c pytorch`
`pip install --upgrade --force-reinstall zstd`
`pip install syft`",solution worked create anaconda activate install pip install upgrade pip install,issue,positive,neutral,neutral,neutral,neutral,neutral
504931296,Great to hear. Thanks for your great work @mari-linhares !,great hear thanks great work,issue,positive,positive,positive,positive,positive,positive
504887894,"Hi, I am interested in this issue, but might need some help/pointers to start...",hi interested issue might need start,issue,negative,positive,positive,positive,positive,positive
504804666,"Hi I tried to install pysyft on OSX Mac Mojave and have an installation error regarding zstd

```
Requirement already satisfied: syft in ./anaconda3/envs/pysyft/lib/python3.7/site-packages/syft-0.1.19a1-py3.7.egg (0.1.19a1)
Requirement already satisfied: Flask>=1.0.2 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from syft) (1.0.3)
Requirement already satisfied: flask_socketio>=3.3.2 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from syft) (4.0.0)
Requirement already satisfied: lz4>=2.1.6 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from syft) (2.1.6)
Requirement already satisfied: msgpack>=0.6.1 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from syft) (0.6.1)
Requirement already satisfied: numpy>=1.14.0 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from syft) (1.16.4)
Requirement already satisfied: scikit-learn>=0.21.0 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from syft) (0.21.2)
Requirement already satisfied: tblib>=1.4.0 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from syft) (1.4.0)
Requirement already satisfied: tf_encrypted>=0.5.4 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from syft) (0.5.4)
Requirement already satisfied: torch>=1.1 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from syft) (1.1.0)
Requirement already satisfied: torchvision>=0.3.0 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from syft) (0.3.0)
Requirement already satisfied: websocket_client>=0.56.0 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from syft) (0.56.0)
Requirement already satisfied: websockets>=7.0 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from syft) (7.0)
Collecting zstd>=1.4.0.0 (from syft)
  Using cached https://files.pythonhosted.org/packages/8e/27/1ea8086d37424e83ab692015cc8dd7d5e37cf791e339633a40dc828dfb74/zstd-1.4.0.0.tar.gz
Requirement already satisfied: itsdangerous>=0.24 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from Flask>=1.0.2->syft) (1.1.0)
Requirement already satisfied: click>=5.1 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from Flask>=1.0.2->syft) (7.0)
Requirement already satisfied: Jinja2>=2.10 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from Flask>=1.0.2->syft) (2.10.1)
Requirement already satisfied: Werkzeug>=0.14 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from Flask>=1.0.2->syft) (0.15.4)
Requirement already satisfied: python-socketio>=2.1.0 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from flask_socketio>=3.3.2->syft) (4.0.3)
Requirement already satisfied: joblib>=0.11 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from scikit-learn>=0.21.0->syft) (0.13.2)
Requirement already satisfied: scipy>=0.17.0 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from scikit-learn>=0.21.0->syft) (1.3.0)
Requirement already satisfied: tensorflow<2,>=1.12.0 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from tf_encrypted>=0.5.4->syft) (1.13.1)
Requirement already satisfied: pyyaml>=5.1 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from tf_encrypted>=0.5.4->syft) (5.1)
Requirement already satisfied: six in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from torchvision>=0.3.0->syft) (1.12.0)
Requirement already satisfied: pillow>=4.1.1 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from torchvision>=0.3.0->syft) (6.0.0)
Requirement already satisfied: MarkupSafe>=0.23 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from Jinja2>=2.10->Flask>=1.0.2->syft) (1.1.1)
Requirement already satisfied: python-engineio>=3.2.0 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from python-socketio>=2.1.0->flask_socketio>=3.3.2->syft) (3.7.0)
Requirement already satisfied: gast>=0.2.0 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (0.2.2)
Requirement already satisfied: astor>=0.6.0 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (0.8.0)
Requirement already satisfied: wheel>=0.26 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (0.33.4)
Requirement already satisfied: grpcio>=1.8.6 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (1.21.1)
Requirement already satisfied: termcolor>=1.1.0 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (1.1.0)
Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (1.13.0)
Requirement already satisfied: absl-py>=0.1.6 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (0.7.1)
Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (1.13.1)
Requirement already satisfied: keras-preprocessing>=1.0.5 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (1.1.0)
Requirement already satisfied: keras-applications>=1.0.6 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (1.0.8)
Requirement already satisfied: protobuf>=3.6.1 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (3.8.0)
Requirement already satisfied: mock>=2.0.0 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (3.0.5)
Requirement already satisfied: markdown>=2.6.8 in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (3.1.1)
Requirement already satisfied: h5py in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from keras-applications>=1.0.6->tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (2.9.0)
Requirement already satisfied: setuptools in ./anaconda3/envs/pysyft/lib/python3.7/site-packages (from protobuf>=3.6.1->tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (41.0.1)
Building wheels for collected packages: zstd
  Building wheel for zstd (setup.py) ... error
  ERROR: Complete output from command /Users/ducvu/anaconda3/envs/pysyft/bin/python -u -c 'import setuptools, tokenize;__file__='""'""'/private/var/folders/t_/0w9dt0ys3cbfr6g4jkb1c8780000gn/T/pip-install-m5xos6xa/zstd/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/t_/0w9dt0ys3cbfr6g4jkb1c8780000gn/T/pip-wheel-uan2sja0 --python-tag cp37:
  ERROR: running bdist_wheel
  running build
  running build_ext
  building 'zstd' extension
  creating build
  creating build/temp.macosx-10.7-x86_64-3.7
  creating build/temp.macosx-10.7-x86_64-3.7/zstd
  creating build/temp.macosx-10.7-x86_64-3.7/zstd/lib
  creating build/temp.macosx-10.7-x86_64-3.7/zstd/lib/compress
  creating build/temp.macosx-10.7-x86_64-3.7/zstd/lib/common
  creating build/temp.macosx-10.7-x86_64-3.7/zstd/lib/decompress
  creating build/temp.macosx-10.7-x86_64-3.7/src
  gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/Users/ducvu/anaconda3/envs/pysyft/include -arch x86_64 -I/Users/ducvu/anaconda3/envs/pysyft/include -arch x86_64 -I/Users/ducvu/anaconda3/envs/pysyft/include/python3.7m -c zstd/lib/compress/zstd_compress.c -o build/temp.macosx-10.7-x86_64-3.7/zstd/lib/compress/zstd_compress.o -O2 -DVERSION=""1.4.0.0"" -DZSTD_MULTITHREAD=1 -Izstd/lib -Izstd/lib/common -Izstd/lib/compress -Izstd/lib/decompress
  In file included from /Users/ducvu/anaconda3/envs/pysyft/lib/gcc/x86_64-apple-darwin11.4.2/4.8.5/include-fixed/syslimits.h:7:0,
                   from /Users/ducvu/anaconda3/envs/pysyft/lib/gcc/x86_64-apple-darwin11.4.2/4.8.5/include-fixed/limits.h:34,
                   from zstd/lib/compress/zstd_compress.c:14:
  /Users/ducvu/anaconda3/envs/pysyft/lib/gcc/x86_64-apple-darwin11.4.2/4.8.5/include-fixed/limits.h:168:61: fatal error: limits.h: No such file or directory
   #include_next <limits.h>  /* recurse down to the real one */
                                                               ^
  compilation terminated.
  error: command 'gcc' failed with exit status 1
  ----------------------------------------
  ERROR: Failed building wheel for zstd
  Running setup.py clean for zstd
Failed to build zstd
Installing collected packages: zstd
  Running setup.py install for zstd ... error
    ERROR: Complete output from command /Users/ducvu/anaconda3/envs/pysyft/bin/python -u -c 'import setuptools, tokenize;__file__='""'""'/private/var/folders/t_/0w9dt0ys3cbfr6g4jkb1c8780000gn/T/pip-install-m5xos6xa/zstd/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record /private/var/folders/t_/0w9dt0ys3cbfr6g4jkb1c8780000gn/T/pip-record-abluqg99/install-record.txt --single-version-externally-managed --compile:
    ERROR: running install
    running build
    running build_ext
    building 'zstd' extension
    creating build
    creating build/temp.macosx-10.7-x86_64-3.7
    creating build/temp.macosx-10.7-x86_64-3.7/zstd
    creating build/temp.macosx-10.7-x86_64-3.7/zstd/lib
    creating build/temp.macosx-10.7-x86_64-3.7/zstd/lib/compress
    creating build/temp.macosx-10.7-x86_64-3.7/zstd/lib/common
    creating build/temp.macosx-10.7-x86_64-3.7/zstd/lib/decompress
    creating build/temp.macosx-10.7-x86_64-3.7/src
    gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/Users/ducvu/anaconda3/envs/pysyft/include -arch x86_64 -I/Users/ducvu/anaconda3/envs/pysyft/include -arch x86_64 -I/Users/ducvu/anaconda3/envs/pysyft/include/python3.7m -c zstd/lib/compress/zstd_compress.c -o build/temp.macosx-10.7-x86_64-3.7/zstd/lib/compress/zstd_compress.o -O2 -DVERSION=""1.4.0.0"" -DZSTD_MULTITHREAD=1 -Izstd/lib -Izstd/lib/common -Izstd/lib/compress -Izstd/lib/decompress
    In file included from /Users/ducvu/anaconda3/envs/pysyft/lib/gcc/x86_64-apple-darwin11.4.2/4.8.5/include-fixed/syslimits.h:7:0,
                     from /Users/ducvu/anaconda3/envs/pysyft/lib/gcc/x86_64-apple-darwin11.4.2/4.8.5/include-fixed/limits.h:34,
                     from zstd/lib/compress/zstd_compress.c:14:
    /Users/ducvu/anaconda3/envs/pysyft/lib/gcc/x86_64-apple-darwin11.4.2/4.8.5/include-fixed/limits.h:168:61: fatal error: limits.h: No such file or directory
     #include_next <limits.h>  /* recurse down to the real one */
                                                                 ^
    compilation terminated.
    error: command 'gcc' failed with exit status 1
    ----------------------------------------
ERROR: Command ""/Users/ducvu/anaconda3/envs/pysyft/bin/python -u -c 'import setuptools, tokenize;__file__='""'""'/private/var/folders/t_/0w9dt0ys3cbfr6g4jkb1c8780000gn/T/pip-install-m5xos6xa/zstd/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record /private/var/folders/t_/0w9dt0ys3cbfr6g4jkb1c8780000gn/T/pip-record-abluqg99/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /private/var/folders/t_/0w9dt0ys3cbfr6g4jkb1c8780000gn/T/pip-install-m5xos6xa/zstd/
```

I also  tried `pip install --upgrade --force-reinstall zstd` command, but I have the following error.

```
 Collecting zstd
  Using cached https://files.pythonhosted.org/packages/8e/27/1ea8086d37424e83ab692015cc8dd7d5e37cf791e339633a40dc828dfb74/zstd-1.4.0.0.tar.gz
Building wheels for collected packages: zstd
  Building wheel for zstd (setup.py) ... error
  ERROR: Complete output from command /Users/ducvu/anaconda3/envs/pysyft/bin/python -u -c 'import setuptools, tokenize;__file__='""'""'/private/var/folders/t_/0w9dt0ys3cbfr6g4jkb1c8780000gn/T/pip-install-00hap7sd/zstd/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/t_/0w9dt0ys3cbfr6g4jkb1c8780000gn/T/pip-wheel-tl7z0e0e --python-tag cp37:
  ERROR: running bdist_wheel
  running build
  running build_ext
  building 'zstd' extension
  creating build
  creating build/temp.macosx-10.7-x86_64-3.7
  creating build/temp.macosx-10.7-x86_64-3.7/zstd
  creating build/temp.macosx-10.7-x86_64-3.7/zstd/lib
  creating build/temp.macosx-10.7-x86_64-3.7/zstd/lib/compress
  creating build/temp.macosx-10.7-x86_64-3.7/zstd/lib/common
  creating build/temp.macosx-10.7-x86_64-3.7/zstd/lib/decompress
  creating build/temp.macosx-10.7-x86_64-3.7/src
  gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/Users/ducvu/anaconda3/envs/pysyft/include -arch x86_64 -I/Users/ducvu/anaconda3/envs/pysyft/include -arch x86_64 -I/Users/ducvu/anaconda3/envs/pysyft/include/python3.7m -c zstd/lib/compress/zstd_compress.c -o build/temp.macosx-10.7-x86_64-3.7/zstd/lib/compress/zstd_compress.o -O2 -DVERSION=""1.4.0.0"" -DZSTD_MULTITHREAD=1 -Izstd/lib -Izstd/lib/common -Izstd/lib/compress -Izstd/lib/decompress
  In file included from /Users/ducvu/anaconda3/envs/pysyft/lib/gcc/x86_64-apple-darwin11.4.2/4.8.5/include-fixed/syslimits.h:7:0,
                   from /Users/ducvu/anaconda3/envs/pysyft/lib/gcc/x86_64-apple-darwin11.4.2/4.8.5/include-fixed/limits.h:34,
                   from zstd/lib/compress/zstd_compress.c:14:
  /Users/ducvu/anaconda3/envs/pysyft/lib/gcc/x86_64-apple-darwin11.4.2/4.8.5/include-fixed/limits.h:168:61: fatal error: limits.h: No such file or directory
   #include_next <limits.h>  /* recurse down to the real one */
                                                               ^
  compilation terminated.
  error: command 'gcc' failed with exit status 1
  ----------------------------------------
  ERROR: Failed building wheel for zstd
  Running setup.py clean for zstd
Failed to build zstd
Installing collected packages: zstd
  Running setup.py install for zstd ... error
    ERROR: Complete output from command /Users/ducvu/anaconda3/envs/pysyft/bin/python -u -c 'import setuptools, tokenize;__file__='""'""'/private/var/folders/t_/0w9dt0ys3cbfr6g4jkb1c8780000gn/T/pip-install-00hap7sd/zstd/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record /private/var/folders/t_/0w9dt0ys3cbfr6g4jkb1c8780000gn/T/pip-record-wk6c1yyz/install-record.txt --single-version-externally-managed --compile:
    ERROR: running install
    running build
    running build_ext
    building 'zstd' extension
    creating build
    creating build/temp.macosx-10.7-x86_64-3.7
    creating build/temp.macosx-10.7-x86_64-3.7/zstd
    creating build/temp.macosx-10.7-x86_64-3.7/zstd/lib
    creating build/temp.macosx-10.7-x86_64-3.7/zstd/lib/compress
    creating build/temp.macosx-10.7-x86_64-3.7/zstd/lib/common
    creating build/temp.macosx-10.7-x86_64-3.7/zstd/lib/decompress
    creating build/temp.macosx-10.7-x86_64-3.7/src
    gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/Users/ducvu/anaconda3/envs/pysyft/include -arch x86_64 -I/Users/ducvu/anaconda3/envs/pysyft/include -arch x86_64 -I/Users/ducvu/anaconda3/envs/pysyft/include/python3.7m -c zstd/lib/compress/zstd_compress.c -o build/temp.macosx-10.7-x86_64-3.7/zstd/lib/compress/zstd_compress.o -O2 -DVERSION=""1.4.0.0"" -DZSTD_MULTITHREAD=1 -Izstd/lib -Izstd/lib/common -Izstd/lib/compress -Izstd/lib/decompress
    In file included from /Users/ducvu/anaconda3/envs/pysyft/lib/gcc/x86_64-apple-darwin11.4.2/4.8.5/include-fixed/syslimits.h:7:0,
                     from /Users/ducvu/anaconda3/envs/pysyft/lib/gcc/x86_64-apple-darwin11.4.2/4.8.5/include-fixed/limits.h:34,
                     from zstd/lib/compress/zstd_compress.c:14:
    /Users/ducvu/anaconda3/envs/pysyft/lib/gcc/x86_64-apple-darwin11.4.2/4.8.5/include-fixed/limits.h:168:61: fatal error: limits.h: No such file or directory
     #include_next <limits.h>  /* recurse down to the real one */
                                                                 ^
    compilation terminated.
    error: command 'gcc' failed with exit status 1
    ----------------------------------------
ERROR: Command ""/Users/ducvu/anaconda3/envs/pysyft/bin/python -u -c 'import setuptools, tokenize;__file__='""'""'/private/var/folders/t_/0w9dt0ys3cbfr6g4jkb1c8780000gn/T/pip-install-00hap7sd/zstd/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record /private/var/folders/t_/0w9dt0ys3cbfr6g4jkb1c8780000gn/T/pip-record-wk6c1yyz/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /private/var/folders/t_/0w9dt0ys3cbfr6g4jkb1c8780000gn/T/pip-install-00hap7sd/zstd/
```
",hi tried install mac installation error regarding requirement already satisfied egg requirement already satisfied flask requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied torch requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied flask requirement already satisfied click flask requirement already satisfied jinja flask requirement already satisfied flask requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied six requirement already satisfied pillow requirement already satisfied jinja flask requirement already satisfied requirement already satisfied gast requirement already satisfied astor requirement already satisfied wheel requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied mock requirement already satisfied markdown requirement already satisfied requirement already satisfied building collected building wheel error error complete output command open compile code error running running build running building extension build file included fatal error file directory recurse real one compilation error command exit status error building wheel running clean build collected running install error error complete output command open compile code install record compile error running install running build running building extension build file included fatal error file directory recurse real one compilation error command exit status error command open compile code install record compile error code also tried pip install upgrade command following error building collected building wheel error error complete output command open compile code error running running build running building extension build file included fatal error file directory recurse real one compilation error command exit status error building wheel running clean build collected running install error error complete output command open compile code install record compile error running install running build running building extension build file included fatal error file directory recurse real one compilation error command exit status error command open compile code install record compile error code,issue,positive,positive,positive,positive,positive,positive
504747535,"Hey @racinger,

Thanks for creating the issue!

I think this used to work but due to multiple new PRs this behavior may have been compromised. I'll fix it later today, and it should work on the next syft release :).",hey thanks issue think used work due multiple new behavior may fix later today work next release,issue,negative,positive,neutral,neutral,positive,positive
504637768,"There is an issue when plugging LPT in the normal flow of send/share that would break `fix_prec`

Fixing.
",issue plugging normal flow would break fixing,issue,negative,positive,positive,positive,positive,positive
504396082,There is a bug in the tutorial. The backprop is not working correctly. Started looking into it.,bug tutorial working correctly looking,issue,negative,neutral,neutral,neutral,neutral,neutral
504173605,@Polarbeargo You are trying to install syft on python 2. Syft only supports python 3,trying install python python,issue,negative,neutral,neutral,neutral,neutral,neutral
503183951,"Check out this pull request on ReviewNB: https://app.reviewnb.com/OpenMined/PySyft/pull/2296 

 Visit www.reviewnb.com to know how we simplify your Jupyter Notebook workflows.",check pull request visit know simplify notebook,issue,negative,neutral,neutral,neutral,neutral,neutral
502999809,"> How does this compare to the tutorial made in #2217 (other than being different data?) @midokura-silvia @racinger

@robert-wagner 
I believe that this example show how to handle PySyft when the data is already in another device (worker). Most of PySyft tutorials show how to distribute the data within the client code. But it seems to not be a real use case application.

@mari-linhares thanks for the feedbacks. I ll do as you suggested.",compare tutorial made different data believe example show handle data already another device worker show distribute data within client code real use case application thanks,issue,negative,positive,positive,positive,positive,positive
502656789,Before merging this I'll try to move the constant structure to their own files. This will make easier to notice that these structures need to be changed when these files are modified.,try move constant structure make easier notice need,issue,negative,neutral,neutral,neutral,neutral,neutral
502432709,"@midokura-silvia @mari-linhares  It is working now. I installed pysyft from the pull request commit in midokura's fork. Seems like, there were several other changes in the pull request which were not in the dev version, but were needed in order for the example to run. This is probably why it was not working. 

It'll be great when it is merged with the master branch. Thanks a lot for your help.",working pull request commit fork like several pull request dev version order example run probably working great master branch thanks lot help,issue,positive,positive,positive,positive,positive,positive
502391017,"Hey @Adarshsng, are you still getting errors with the most updated version of syft and torch?",hey still getting version torch,issue,negative,neutral,neutral,neutral,neutral,neutral
502390961,"I think this is related to #2175, I'm closing this for now. Feel free to re-open if after #2175 is fixed this is still a problem.",think related feel free fixed still problem,issue,negative,positive,positive,positive,positive,positive
502390791,"I'll close this for now, since I couldn't find a better solution at this time.",close since could find better solution time,issue,positive,positive,positive,positive,positive,positive
502383992,"I think we're all on the same page about plans.

I'm closing this in favor of tutorial 9 - introduction to plans. The tutorials should cover all main use cases of plans.",think page favor tutorial introduction cover main use,issue,negative,positive,positive,positive,positive,positive
502166397,How does this compare to the tutorial made in #2217 (other than being different data?) @midokura-silvia @racinger ,compare tutorial made different data,issue,negative,neutral,neutral,neutral,neutral,neutral
502041543,"I am using torch==1.0.1 and torchvision==0.2.2.post3. torch=1.1.0 will not work. Will take a look at your issue later, latest Monday.
",post work take look issue later latest,issue,negative,positive,positive,positive,positive,positive
502020196,"@mari-linhares  and @midokura-silvia I saw the PR. I am so excited about it. That was exactly what I was trying to do (though not the async part). 

Now, @midokura-silvia's branch has torch>=1.1.0 and torchvision>=0.3.0. I tried with both combinations of (torch1.1.0+torchvision0.3) and (torch1.0.1 +torchvision0.2.2 , because of the bug mentioned in this tracker). I get error in both. Results of the following two cases:

**1. Torch 1.1.0, torchvision 0.3 ==>** I am getting the error mentioned in this bug. `TypeError: Cannot serialize <torch._C.Function object at 0x134a7c2b0>`, and also while converting the loss function to jit trace, I get the error 
```python
# Loss function 
@torch.jit.script
def loss_fn(output, target):
    return F.nll_loss(output, target)
type(loss_fn)
---------------------------------------------------------------------------
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
~/anaconda3/envs/pysyft/lib/python3.7/site-packages/torch/jit/annotations.py in parse_type_line(type_line)
     94     try:
---> 95         arg_ann = eval(arg_ann_str, _eval_env)
     96     except (NameError, SyntaxError) as e:

<string> in <module>

NameError: name 'Optional' is not defined

During handling of the above exception, another exception occurred:

RuntimeError                              Traceback (most recent call last)
<ipython-input-14-9fce5d7056f9> in <module>
      1 # Loss function
----> 2 @torch.jit.script
      3 def loss_fn(output, target):
      4     return F.nll_loss(output, target)
      5 

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/torch/jit/__init__.py in script(obj, optimize, _frames_up, _rcb)
    822     else:
    823         ast = get_jit_def(obj)
--> 824         fn = torch._C._jit_script_compile(ast, _rcb, get_default_args(obj))
    825         # Forward docstrings
    826         fn.__doc__ = obj.__doc__

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/torch/jit/annotations.py in get_signature(fn)
     53         return None
     54 
---> 55     return parse_type_line(type_line)
     56 
     57 

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/torch/jit/annotations.py in parse_type_line(type_line)
     95         arg_ann = eval(arg_ann_str, _eval_env)
     96     except (NameError, SyntaxError) as e:
---> 97         raise RuntimeError(""Failed to parse the argument list of a type annotation: {}"".format(str(e)))
     98 
     99     if not isinstance(arg_ann, tuple):

RuntimeError: Failed to parse the argument list of a type annotation: name 'Optional' is not defined
```
The following is the file related to this version. [Jupyter Notebook LINK](https://colab.research.google.com/drive/1HAFPxIJQ6uVttVdyYRq6lonBqJ5i7nCT) I have put it on google colab with the results. The results in the notebook are from running it on my laptop. 

**2. Torch 1.0.1, torchvision 0.2.2 ==>** To address the problem described in the original bug for this issue, I downgraded to 1.0.1,  but then the vanilla tutorial works. But a MNIST related CNN throws the following error : 
```python
traced_model = torch.jit.trace(model, data)
---------------------------------------------------------------------------
---------------------------------------------------------------------------
PureTorchTensorFoundError                 Traceback (most recent call last)
~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft-0.1.18-py3.7.egg/syft/frameworks/torch/tensors/interpreters/native.py in handle_func_command(cls, command)
    198             new_args, new_kwargs, new_type, args_type = syft.frameworks.torch.hook_args.hook_function_args(
--> 199                 cmd, args, kwargs, return_args_type=True
    200             )

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft-0.1.18-py3.7.egg/syft/frameworks/torch/hook/hook_args.py in hook_function_args(attr, args, kwargs, return_args_type)
    157         # Run it
--> 158         new_args = args_hook_function(args)
    159 

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft-0.1.18-py3.7.egg/syft/frameworks/torch/hook/hook_args.py in <lambda>(x)
    341 
--> 342     return lambda x: f(lambdas, x)
    343 

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft-0.1.18-py3.7.egg/syft/frameworks/torch/hook/hook_args.py in three_fold(lambdas, args, **kwargs)
    511     return (
--> 512         lambdas[0](args[0], **kwargs),
    513         lambdas[1](args[1], **kwargs),

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft-0.1.18-py3.7.egg/syft/frameworks/torch/hook/hook_args.py in <lambda>(i)
    319         # Last if not, rule is probably == 1 so use type to return the right transformation.
--> 320         else lambda i: forward_func[type(i)](i)
    321         for a, r in zip(args, rules)  # And do this for all the args / rules provided

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft-0.1.18-py3.7.egg/syft/frameworks/torch/hook/hook_args.py in <lambda>(i)
     50     if hasattr(i, ""child"")
---> 51     else (_ for _ in ()).throw(PureTorchTensorFoundError),
     52     torch.nn.Parameter: lambda i: i.child

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft-0.1.18-py3.7.egg/syft/frameworks/torch/hook/hook_args.py in <genexpr>(.0)
     50     if hasattr(i, ""child"")
---> 51     else (_ for _ in ()).throw(PureTorchTensorFoundError),
     52     torch.nn.Parameter: lambda i: i.child

PureTorchTensorFoundError: 

During handling of the above exception, another exception occurred:

AttributeError                            Traceback (most recent call last)
<ipython-input-10-1e5257ea3eb4> in <module>
      1 # Create the trace jit version
----> 2 traced_model = torch.jit.trace(model, data)

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/torch/jit/__init__.py in trace(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, _force_outplace)
    634     var_lookup_fn = _create_interpreter_name_lookup_fn(0)
    635     module._create_method_from_trace('forward', func, example_inputs,
--> 636                                      var_lookup_fn, _force_outplace)
    637 
    638     # Check the trace against new traces created from user-specified inputs

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    485             hook(self, input)
    486         if torch._C._get_tracing_state():
--> 487             result = self._slow_forward(*input, **kwargs)
    488         else:
    489             result = self.forward(*input, **kwargs)

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/torch/nn/modules/module.py in _slow_forward(self, *input, **kwargs)
    475         tracing_state._traced_module_stack.append(self)
    476         try:
--> 477             result = self.forward(*input, **kwargs)
    478         finally:
    479             tracing_state.pop_scope()

<ipython-input-7-ca434fff0989> in forward(self, x)
     10     def forward(self, x):
     11         x = F.relu(self.conv1(x))
---> 12         x = F.max_pool2d(x, 2, 2)
     13         x = F.relu(self.conv2(x))
     14         x = F.max_pool2d(x, 2, 2)

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft-0.1.18-py3.7.egg/syft/frameworks/torch/hook/hook.py in overloaded_func(*args, **kwargs)
    703             cmd_name = f""{attr.__module__}.{attr.__name__}""
    704             command = (cmd_name, None, args, kwargs)
--> 705             response = TorchTensor.handle_func_command(command)
    706             return response
    707 

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft-0.1.18-py3.7.egg/syft/frameworks/torch/tensors/interpreters/native.py in handle_func_command(cls, command)
    224             # in the execute_command function
    225             if isinstance(args, tuple):
--> 226                 response = eval(cmd)(*args, **kwargs)
    227             else:
    228                 response = eval(cmd)(args, **kwargs)

~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft-0.1.18-py3.7.egg/syft/frameworks/torch/tensors/interpreters/native.py in <module>

AttributeError: module 'torch._jit_internal' has no attribute 'native_fn'
```
The following is the file related to this version. [Jupyter Notebook LINK](https://colab.research.google.com/drive/1h_hRMxSz9L1k7FkgzVAcMfzi24YIl7xA).

@midokura-silvia since you submitted the PR, it would be very helpful if you could please let me know what configuration should work (like torch version/torchvision/syft version combination) . I tried both and getting these error. 

For relevance, this is my system information:
```
System Version:	macOS 10.14.4 (18E226)
 Kernel Version:	Darwin 18.5.0
 Boot Volume:	Coyote_HD
 Boot Mode:	Normal
 syft                0.1.18
 python           Python 3.7.3 (default, Mar 27 2019, 16:54:48) 
```

Thanks a lot. You folks are doing an excellent job here 😃 Please let me know if we can take this offline. It makes no sense to continue this chain on a closed issue tracker. Also I apologise if these errors are due to some stupid mistake I am making somewhere you can spot.",saw excited exactly trying though part branch torch tried torch torch bug tracker get error following two torch getting error bug serialize object also converting loss function trace get error python loss function output target return output target type recent call last try except string module name defined handling exception another exception recent call last module loss function output target return output target script optimize else ast ast forward return none return except raise parse argument list type annotation parse argument list type annotation name defined following file related version notebook link put notebook running torch address problem original bug issue vanilla tutorial work related following error python model data recent call last command run lambda return lambda return lambda last rule probably use type return right transformation else lambda type zip provided lambda child else lambda child else lambda handling exception another exception recent call last module create trace version model data trace optimize check trace new self input hook self input result input else result input self input self try result input finally forward self forward self command none response command return response command function response else response module module attribute following file related version notebook link since would helpful could please let know configuration work like torch version combination tried getting error relevance system information system version kernel version boot volume boot mode normal python python default mar thanks lot excellent job please let know take sense continue chain closed issue tracker also due stupid mistake making somewhere spot,issue,negative,positive,neutral,neutral,positive,positive
501887896,"Hey @akaanirban from this part of the notebook I'm not sure what can be wrong, can you send the file so I can try to execute it?

Also, maybe @midokura-silvia can help, she's the author of this PR that uses MNIST with train config for async federated training https://app.reviewnb.com/OpenMined/PySyft/pull/2217/files/",hey part notebook sure wrong send file try execute also maybe help author train training,issue,negative,neutral,neutral,neutral,neutral,neutral
501821406,@youben11 Do you have an account on the openmined slack? openmined/pysyft-notebook now exists and I want to discuss pushing to it,account slack want discus pushing,issue,negative,neutral,neutral,neutral,neutral,neutral
501771512,"@mari-linhares , the vanilla tutorial worked flawlessly. However, I tried modifying the script for training MNIST model where the remote device contains the dataset, instead of sending/federating data to workers from the central scheduler. 

I am in Torch 1.0.1, the vanilla TrainConfig tutorial works. But when I try to use a CNN model , I get the following error : 

![screencapture-localhost-8888-notebooks-TrainConfigMnist-ipynb-2019-06-13-18_06_43](https://user-images.githubusercontent.com/22014979/59449066-ae7ebc00-8e06-11e9-83ec-ee834a840fd7.jpg)

Any idea why this is happening?

Thanks in advance.",vanilla tutorial worked flawlessly however tried script training model remote device instead data central torch vanilla tutorial work try use model get following error idea happening thanks advance,issue,negative,positive,positive,positive,positive,positive
501767440,A hacky way to do this would be to add something to the send function which increments a counter based on the size of the message being sent,hacky way would add something send function counter based size message sent,issue,negative,neutral,neutral,neutral,neutral,neutral
501738743,"I can confirm this works with torch 1.0.1. Thanks a lot for the reply. 

But any new installation of pysyft 0.1.18 has dependency of torch>=1.1.0. Anybody trying this with fresh installation might have issues. :smiley:",confirm work torch thanks lot reply new installation dependency torch anybody trying fresh installation might,issue,positive,positive,positive,positive,positive,positive
501625165,"Hey @LaRiffle,
It's actually a good point as I just saw the naming used in the OpenMined repositories on Docker Hub.
Thanks",hey actually good point saw naming used docker hub thanks,issue,positive,positive,positive,positive,positive,positive
501434523,"Having said that, if our intuition is right I'm not sure how easy is to get this fixed",said intuition right sure easy get fixed,issue,positive,positive,positive,positive,positive,positive
501434257,"@robert-wagner I've had a discussion about this with @IonesioJunior some time ago, we think this is due to the fact that garbage collector ""gets stuck"" since every time you're printing something you're creating a new reference to it, that tries to be deleted but then is printed again, ... and so on",discussion time ago think due fact garbage collector stuck since every time printing something new reference printed,issue,negative,positive,neutral,neutral,positive,positive
501393398,"Hey @akaanirban,

There is an error in torch 1.1 (check https://github.com/pytorch/pytorch/issues/20017 for details), if you downgrade torch to 1.0.1 should work as expected :blush: .",hey error torch check downgrade torch work blush,issue,negative,neutral,neutral,neutral,neutral,neutral
501256656,"@youben11 that's a good point. With that in mind, I don't see why we couldn't merge it",good point mind see could merge,issue,negative,positive,positive,positive,positive,positive
501252797,"@robert-wagner of course we can have different tag for different type of images, the initial idea was to have a ready workspace for devs to learn about it easily. We can expand the idea and have another image for running workloads.
@iamtrask ",course different tag different type initial idea ready learn easily expand idea another image running,issue,positive,positive,positive,positive,positive,positive
501250901,@mari-linhares barely made any changes. I will let you know when you should re-review it. ,barely made let know,issue,negative,positive,neutral,neutral,positive,positive
501249716,"@mari-linhares My feelings about this pull request are complicated. On one hand I think it is good to have a docker image with all of PySyft's dependencies installed. On the other hand, this particular docker image launches a jupyter notebook server which in the long run is not what I think the best use of this dockerfile could be. For example other options for this would be to launch something like a worker. I will continue to think on this (the content of the pr looks good, just not sure I agree with all of the ideas behind it)",pull request complicated one hand think good docker image hand particular docker image notebook server long run think best use could example would launch something like worker continue think content good sure agree behind,issue,positive,positive,positive,positive,positive,positive
501247578,"Thanks for the PR @youben11! I'm not a docker person myself, I'll ask someone to review this :dancer: !",thanks docker person ask someone review dancer,issue,negative,positive,positive,positive,positive,positive
501212713,"Good fix, I had just the same issue this morning but didn't have time to fix it :+1: ",good fix issue morning time fix,issue,negative,positive,positive,positive,positive,positive
501203993,"I share also here the install procedure I use on Google colab, which is not very clean but works for people wanting to use the last updates from `dev` branch (and their amazing bugs!)

```
!pip install tf-encrypted

! URL=""https://github.com/openmined/PySyft.git"" && FOLDER=""PySyft"" && if [ ! -d $FOLDER ]; then git clone -b dev --single-branch $URL; else (cd $FOLDER && git pull $URL && cd ..); fi;

!cd PySyft; python setup.py install  > /dev/null

import os
import sys
module_path = os.path.abspath(os.path.join('./PySyft'))
if module_path not in sys.path:
    sys.path.append(module_path)

!pip install --upgrade --force-reinstall lz4
!pip install --upgrade --force-reinstall websocket
!pip install --upgrade --force-reinstall websockets
!pip install --upgrade --force-reinstall zstd
```",share also install procedure use clean work people wanting use last dev branch amazing pip install folder git clone dev else folder git pull fi python install import o import pip install upgrade pip install upgrade pip install upgrade pip install upgrade,issue,positive,positive,positive,positive,positive,positive
501196179,"For information, this is my config to build and run the latest code from PySyft on Colab:
```
!pip install tf-encrypted

! URL=""https://github.com/openmined/PySyft.git"" && FOLDER=""PySyft"" && if [ ! -d $FOLDER ]; then git clone -b dev --single-branch $URL; else (cd $FOLDER && git pull $URL && cd ..); fi;

!cd PySyft; python setup.py install  > /dev/null

import os
import sys
module_path = os.path.abspath(os.path.join('./PySyft'))
if module_path not in sys.path:
    sys.path.append(module_path)

!pip install --upgrade --force-reinstall lz4
!pip install --upgrade --force-reinstall websocket
!pip install --upgrade --force-reinstall websockets
!pip install --upgrade --force-reinstall zstd
```

I'm sure this is sub optimal, but it works ;)",information build run latest code pip install folder git clone dev else folder git pull fi python install import o import pip install upgrade pip install upgrade pip install upgrade pip install upgrade sure sub optimal work,issue,positive,positive,positive,positive,positive,positive
501191177,"#2274 should solve
It will be merged very soon so if you can build the code from source in your colab you should benefit from it quickly, otherwise the 1.19 release will arrive in a few days. :)",solve soon build code source benefit quickly otherwise release arrive day,issue,positive,positive,positive,positive,positive,positive
501189126,"Hey, indeed there is a bug in our last release 0.1.18 when operating with constant values, I'm working on a fix right now.",hey indeed bug last release operating constant working fix right,issue,negative,positive,neutral,neutral,positive,positive
501104766,"Hi. I download the Pysyft you released yesterday from github and that error disappears!
But it seems abnormal and this instruction remains running for a long long time but does not move on:
![捕获](https://user-images.githubusercontent.com/11493656/59321232-dafddf80-8d03-11e9-964a-01618c685098.PNG)


![notebook](https://user-images.githubusercontent.com/11493656/59321100-50b57b80-8d03-11e9-822f-1789241c0db8.PNG)

",hi yesterday error abnormal instruction remains running long long time move notebook,issue,negative,negative,neutral,neutral,negative,negative
501096939,"I update the syft as you suggest using pip install -U syft==0.1.17. 
And the version information is as follows .

Requirement already up-to-date: syft==0.1.17 in d:\programdata\anaconda3\lib\site-packages (0.1.17)
Requirement already satisfied, skipping upgrade: torchvision in d:\programdata\anaconda3\lib\site-packages (from syft==0.1.17) (0.2.2)
Requirement already satisfied, skipping upgrade: sklearn in d:\programdata\anaconda3\lib\site-packages\sklearn-0.0-py3.6.egg (from syft==0.1.17) (0.0)
Requirement already satisfied, skipping upgrade: zstd in d:\programdata\anaconda3\lib\site-packages\zstd-1.4.0.0-py3.6-win-amd64.egg (from syft==0.1.17) (1.4.0.0)
Requirement already satisfied, skipping upgrade: lz4 in d:\programdata\anaconda3\lib\site-packages\lz4-2.1.6-py3.6-win-amd64.egg (from syft==0.1.17) (2.1.6)
Requirement already satisfied, skipping upgrade: tf-encrypted>=0.5.4 in d:\programdata\anaconda3\tf-encrypted (from syft==0.1.17) (0.5.5)
Requirement already satisfied, skipping upgrade: websockets>=7.0 in d:\programdata\anaconda3\lib\site-packages\websockets-7.0-py3.6-win-amd64.egg (from syft==0.1.17) (7.0)
Requirement already satisfied, skipping upgrade: torch>=1.0.1 in d:\programdata\anaconda3\lib\site-packages (from syft==0.1.17) (1.0.1)
Requirement already satisfied, skipping upgrade: flask-socketio in d:\programdata\anaconda3\lib\site-packages\flask_socketio-4.0.0-py3.6.egg (from syft==0.1.17) (4.0.0)
Requirement already satisfied, skipping upgrade: tblib in d:\programdata\anaconda3\lib\site-packages (from syft==0.1.17) (1.4.0)
Requirement already satisfied, skipping upgrade: msgpack in d:\programdata\anaconda3\lib\site-packages (from syft==0.1.17) (0.6.1)
Requirement already satisfied, skipping upgrade: websocket-client in d:\programdata\anaconda3\lib\site-packages\websocket_client-0.56.0-py3.6.egg (from syft==0.1.17) (0.56.0)
Requirement already satisfied, skipping upgrade: Flask in d:\programdata\anaconda3\lib\site-packages (from syft==0.1.17) (1.0.3)
Requirement already satisfied, skipping upgrade: numpy in d:\programdata\anaconda3\lib\site-packages (from torchvision->syft==0.1.17) (1.16.4)
Requirement already satisfied, skipping upgrade: six in c:\users\administrator\appdata\roaming\python\python36\site-packages (from torchvision->syft==0.1.17) (1.11.0)
Requirement already satisfied, skipping upgrade: pillow>=4.1.1 in d:\programdata\anaconda3\lib\site-packages (from torchvision->syft==0.1.17) (6.0.0)
Requirement already satisfied, skipping upgrade: scikit-learn in d:\programdata\anaconda3\lib\site-packages (from sklearn->syft==0.1.17) (0.19.1)
Requirement already satisfied, skipping upgrade: tensorflow<2,>=1.12.0 in d:\programdata\anaconda3\lib\site-packages\tensorflow-1.14.0rc0-py3.6-win-amd64.egg (from tf-encrypted>=0.5.4->syft==0.1.17) (1.14.0rc0)
Requirement already satisfied, skipping upgrade: pyyaml>=5.1 in d:\programdata\anaconda3\lib\site-packages (from tf-encrypted>=0.5.4->syft==0.1.17) (5.1)
Requirement already satisfied, skipping upgrade: python-socketio>=2.1.0 in d:\programdata\anaconda3\lib\site-packages\python_socketio-4.0.3-py3.6.egg (from flask-socketio->syft==0.1.17) (4.0.3)
Requirement already satisfied, skipping upgrade: itsdangerous>=0.24 in d:\programdata\anaconda3\lib\site-packages (from Flask->syft==0.1.17) (1.1.0)
Requirement already satisfied, skipping upgrade: Werkzeug>=0.14 in d:\programdata\anaconda3\lib\site-packages (from Flask->syft==0.1.17) (0.15.4)
Requirement already satisfied, skipping upgrade: click>=5.1 in d:\programdata\anaconda3\lib\site-packages (from Flask->syft==0.1.17) (7.0)
Requirement already satisfied, skipping upgrade: Jinja2>=2.10 in d:\programdata\anaconda3\lib\site-packages (from Flask->syft==0.1.17) (2.10.1)
Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in d:\programdata\anaconda3\lib\site-packages\absl_py-0.7.1-py3.6.egg (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft==0.1.17) (0.7.1)
Requirement already satisfied, skipping upgrade: astor>=0.6.0 in d:\programdata\anaconda3\lib\site-packages\astor-0.8.0-py3.6.egg (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft==0.1.17) (0.8.0)
Requirement already satisfied, skipping upgrade: gast>=0.2.0 in d:\programdata\anaconda3\lib\site-packages\gast-0.2.2-py3.6.egg (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft==0.1.17) (0.2.2)
Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in d:\programdata\anaconda3\lib\site-packages\google_pasta-0.1.7-py3.6.egg (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft==0.1.17) (0.1.7)
Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in d:\programdata\anaconda3\lib\site-packages\grpcio-1.21.1-py3.6-win-amd64.egg (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft==0.1.17) (1.21.1)
Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in d:\programdata\anaconda3\lib\site-packages\keras_applications-1.0.8-py3.6.egg (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft==0.1.17) (1.0.8)
Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in d:\programdata\anaconda3\lib\site-packages\keras_preprocessing-1.0.9-py3.6.egg (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft==0.1.17) (1.0.9)
Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in d:\programdata\anaconda3\lib\site-packages\protobuf-3.8.0-py3.6-win-amd64.egg (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft==0.1.17) (3.8.0)
Requirement already satisfied, skipping upgrade: tensorboard<1.14.0,>=1.13.0 in d:\programdata\anaconda3\lib\site-packages\tensorboard-1.13.1-py3.6.egg (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft==0.1.17) (1.13.1)
Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in d:\programdata\anaconda3\lib\site-packages\termcolor-1.1.0-py3.6.egg (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft==0.1.17) (1.1.0)
Requirement already satisfied, skipping upgrade: tf-estimator-nightly<1.14.0.dev2019042302,>=1.14.0.dev2019042301 in d:\programdata\anaconda3\lib\site-packages\tf_estimator_nightly-1.14.0.dev2019042301-py3.6.egg (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft==0.1.17) (1.14.0.dev2019042301)
Requirement already satisfied, skipping upgrade: wheel>=0.26 in d:\programdata\anaconda3\lib\site-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft==0.1.17) (0.33.4)
Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in d:\programdata\anaconda3\lib\site-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft==0.1.17) (1.11.1)
Requirement already satisfied, skipping upgrade: python-engineio>=3.2.0 in d:\programdata\anaconda3\lib\site-packages\python_engineio-3.7.0-py3.6.egg (from python-socketio>=2.1.0->flask-socketio->syft==0.1.17) (3.7.0)
Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in d:\programdata\anaconda3\lib\site-packages (from Jinja2>=2.10->Flask->syft==0.1.17) (1.1.1)
Requirement already satisfied, skipping upgrade: h5py in d:\programdata\anaconda3\lib\site-packages (from keras-applications>=1.0.6->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft==0.1.17) (2.9.0)
Requirement already satisfied, skipping upgrade: setuptools in d:\programdata\anaconda3\lib\site-packages (from protobuf>=3.6.1->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft==0.1.17) (41.0.1)
Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in d:\programdata\anaconda3\lib\site-packages\markdown-3.1.1-py3.6.egg (from tensorboard<1.14.0,>=1.13.0->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft==0.1.17) (3.1.1)


But I still get the error:
AttributeError                            Traceback (most recent call last)
<ipython-input-8-5b486064ddb2> in <module>
----> 1 model.share(alice, bob, carol)

D:\ProgramData\Anaconda3\lib\site-packages\syft\frameworks\keras\model\sequential.py in share(model, target_graph, *workers)
     38 
     39     with target_graph.as_default():
---> 40         tfe_model, batch_input_shape = _rebuild_tfe_model(model, stored_keras_weights)
     41 
     42         # Set up a new tfe.serving.QueueServer for the shared TFE model

D:\ProgramData\Anaconda3\lib\site-packages\syft\frameworks\keras\model\sequential.py in _rebuild_tfe_model(keras_model, stored_keras_weights)
    115     for keras_layer in keras_model.layers:
    116         tfe_layer = _instantiate_tfe_layer(keras_layer, stored_keras_weights)
--> 117         tfe_model.add(tfe_layer)
    118 
    119         if hasattr(tfe_layer, ""_batch_input_shape""):

d:\programdata\anaconda3\tf-encrypted\tf_encrypted\keras\models\sequential.py in add(self, layer)
     42                          ""tfe.keras.Sequential model."")
     43 
---> 44       batch_shape = layer._batch_input_shape  # pylint: disable=protected-access
     45 
     46       # Instantiate an input layer.

AttributeError: 'Conv2D' object has no attribute '_batch_input_shape'

The only change I made is: 
config_filename = ""/tmp/tfe.config""
 in C:\Users\Administrator\Desktop\covert security\codes\PySyft-dev\PySyft-dev\syft\workers\tfe.py 
to 
config_filename = ""D:\ProgramData\Anaconda3\lib\site-packages\syft\workers\tfe.config"",
because in the windows OS the directory /tmp does not exist.

I am sorry to confuse you, maybe there are some version probloms in my notebook environment. I will check it carefully. And thank you very much for your help.",update suggest pip install version information requirement already requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade egg requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade torch requirement already satisfied skipping upgrade egg requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade egg requirement already satisfied skipping upgrade flask requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade six requirement already satisfied skipping upgrade pillow requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade egg requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade click requirement already satisfied skipping upgrade jinja requirement already satisfied skipping upgrade egg requirement already satisfied skipping upgrade astor egg requirement already satisfied skipping upgrade gast egg requirement already satisfied skipping upgrade egg requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade egg requirement already satisfied skipping upgrade egg requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade egg requirement already satisfied skipping upgrade egg requirement already satisfied skipping upgrade dev dev egg dev requirement already satisfied skipping upgrade wheel requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade egg requirement already satisfied skipping upgrade jinja requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade markdown egg still get error recent call last module bob carol share model model set new model add self layer model input layer object attribute change made o directory exist sorry confuse maybe version notebook environment check carefully thank much help,issue,positive,positive,positive,positive,positive,positive
501017466,"> From what I see, `torch.nn.functional.linear` is correctly hooked and the command is sent to a worker.
> But then this worker stills call this command on pointers (it should call it on tensors), and this is where it fails because .dim() is hooked so `if input.dim() == 2` tries to assess if a pointer tensor is true or false.

Hey @LaRiffle @mari-linhares input.dim() called on a pointer tensor returns an int",see correctly hooked command sent worker worker call command call hooked ass pointer tensor true false hey pointer tensor,issue,negative,negative,neutral,neutral,negative,negative
501017147,"@robert-wagner I think the cause of the error is related to the fact that the input is a pointer, but even if that's the case I think we should throw a better error with a better description.",think cause error related fact input pointer even case think throw better error better description,issue,negative,positive,positive,positive,positive,positive
501002544,Hi @mari-linhares I looked into this error. It looks like the line that fails is `if input.dim() == 2 and bias is not None:` I checked the behavior of both of of these functions independently on the input types and they both return a boolean. I am not sure what would be the cause of this error,hi error like line bias none checked behavior independently input return sure would cause error,issue,negative,positive,positive,positive,positive,positive
500992871,Hey @midokura-silvia @DanyEle I will fix the phrasing of this. What I mean by constant uptime is that they data is always available. This is contrasted with data that goes in and out of availability,hey fix phrasing mean constant data always available data go availability,issue,negative,positive,neutral,neutral,positive,positive
500953192,"> Maybe it's a bit early for a review, but don't forget to add extensive tests including negative values in the original float space, overflow cases like c = a + b when a + b > q, etc

I did not mean to approve this (meant to request changes) whoops. Thanks for the catch",maybe bit early review forget add extensive negative original float space overflow like mean approve meant request whoop thanks catch,issue,negative,positive,neutral,neutral,positive,positive
500854543,"Hi @keenlykeenly, unfortunately I was unable to reproduce your bug with the information provided -- when I try the notebook it works smoothly on both the pip package and the dev branch.  Did you change any code in the notebook?

It looks like your version of PySyft is slightly out of date though, you're using syft-0.1.15a1, while the current version from pip should be syft-0.1.17.  I recommend reinstalling with `pip install -U syft` in your environment and retrying this notebook.  Hope that helps!",hi unfortunately unable reproduce bug information provided try notebook work smoothly pip package dev branch change code notebook like version slightly date though current version pip recommend pip install environment notebook hope,issue,positive,negative,neutral,neutral,negative,negative
500812576,"Canceling. It helped us to decide if going for the NumPy solution. Thanks, dear PR",u decide going solution thanks dear,issue,positive,positive,positive,positive,positive,positive
500703494,"Hi, thanks for reporting this error,
I believe the error was first in the client side to due `mean = torch.as_tensor(mean, dtype=torch.float32, device=tensor.device)`.
This a bug due to upgrading to torchvision 0.3, which was fixed in the dev branch yesterday. If you use directly the source code I'd recommend pulling and retrying you shouldn't have this error anymore (at least not this one). Alternatively check that you have indeed downgraded to torchvision to 0.2.2 (in which the line `mean = torch.as_tensor(mean, dtype=torch.float32, device=tensor.device)` doesn't exist).
So if you can manage to do one of these changes and report how it goes, I'd love to help further!

One last thing, indeed PySyft supports PyTorch 1.1.0 even if there are some bugs like this one that we try to solve as quickly as possible.
",hi thanks error believe error first client side due mean mean bug due fixed dev branch yesterday use directly source code recommend error least one alternatively check indeed line mean mean exist manage one report go love help one last thing indeed even like one try solve quickly possible,issue,positive,negative,neutral,neutral,negative,negative
500659822,"> > We will do a release of tf-encrypted on Monday that fixes this issue in the pip package.
> 
> I just pushed tf-encrypted version 0.5.5 to PyPI, and the original AttributeError bug in this issue is fixed when using TF 1.14.0-rc0. For anyone reading this, please ensure you've either upgraded tf-encrypted to 0.5.5 or downgraded your version of TensorFlow to 1.13.1.
> 
> > FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tfe.config'
> 
> This one should be fixed by #2254, which is now in `dev`. Please open up a new bug report if this continues to be a problem there.
> 
> > ValueError: name: ""group_deps"" ...
> 
> This one is more interesting -- @mortendahl any idea what could be going on here? If this is more than a quick fix, I suggest moving that discussion to a new issue since this one should be resolved now.

Thank you very much. When I reinstall the tf-encrypted to version 0.5.5 and reinstall pysft, the error disappear. But there exist another problem. And I start a  new issue to discuss it. 

Thank you again for your quick reply.",release issue pip package version original bug issue fixed anyone reading please ensure either version file directory one fixed dev please open new bug report problem name one interesting idea could going quick fix suggest moving discussion new issue since one resolved thank much reinstall version reinstall error disappear exist another problem start new issue discus thank quick reply,issue,positive,positive,positive,positive,positive,positive
500596686,"This is now fixed in dev
Ans will be in master very soon,
The issue was torchvision update from 0.2.2 to 0.3",fixed dev master soon issue update,issue,negative,positive,neutral,neutral,positive,positive
500582119,">We will do a release of tf-encrypted on Monday that fixes this issue in the pip package.

I just pushed tf-encrypted version 0.5.5 to PyPI, and the original AttributeError bug in this issue is fixed when using TF 1.14.0-rc0.  For anyone reading this, please ensure you've either upgraded tf-encrypted to 0.5.5 or downgraded your version of TensorFlow to 1.13.1.

> FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tfe.config'

This one should be fixed by #2254, which is now in `dev`.  Please open up a new bug report if this continues to be a problem there.

>ValueError: name: ""group_deps"" ...

This one is more interesting -- @mortendahl any idea what could be going on here?  If this is more than a quick fix, I suggest moving that discussion to a new issue since this one should be resolved now.",release issue pip package version original bug issue fixed anyone reading please ensure either version file directory one fixed dev please open new bug report problem name one interesting idea could going quick fix suggest moving discussion new issue since one resolved,issue,positive,positive,positive,positive,positive,positive
500579699,"A couple of remarks: the [readme file](https://github.com/OpenMined/PySyft) clearly states 

> PySyft supports Python >= 3.6 and PyTorch 1.1.0

Anyways, I went ahead and tried what you suggest, that is python 3.6.7, torch=1.0.1, and torchvision=0.2.2, and still does not work. 

Any further suggestions are very much appreciated. Thanks",couple file clearly python anyways went ahead tried suggest python still work much thanks,issue,positive,positive,positive,positive,positive,positive
500564728,"I noticed two more weird things in your configuration:

- You are using Python 3.7.3 --> Try using Python3.6 instead. I always run PySyft on Python 3.6.7. 
- You are using Pytorch 1.1.0 --> Try using Pytorch 1.0.1 instead. I don't think PySyft supports PyTorch 1.1, yet, although there are plans to port it to that version. ",two weird configuration python try python instead always run python try instead think yet although port version,issue,negative,negative,negative,negative,negative,negative
500550281,"OK, I think I go that part now. 
But I am now getting a different error though when running the client, which also crashes the servers:

**Error on the client side**

```
Traceback (most recent call last):
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/frameworks/torch/hook/hook_args.py"", line 145, in hook_function_args
KeyError: 'torch.as_tensor'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""run_websocket_client.py"", line 273, in <module>
    main()
  File ""run_websocket_client.py"", line 233, in main
    ).federate(tuple(workers)),
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/frameworks/torch/federated/dataset.py"", line 161, in dataset_federate
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/torch/utils/data/dataloader.py"", line 560, in __next__
    batch = self.collate_fn([self.dataset[i] for i in indices])
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/torch/utils/data/dataloader.py"", line 560, in <listcomp>
    batch = self.collate_fn([self.dataset[i] for i in indices])
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/torchvision/datasets/mnist.py"", line 95, in __getitem__
    img = self.transform(img)
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/torchvision/transforms/transforms.py"", line 61, in __call__
    img = t(img)
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/torchvision/transforms/transforms.py"", line 164, in __call__
    return F.normalize(tensor, self.mean, self.std, self.inplace)
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/torchvision/transforms/functional.py"", line 206, in normalize
    mean = torch.as_tensor(mean, dtype=torch.float32, device=tensor.device)
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/frameworks/torch/hook/hook.py"", line 708, in overloaded_func
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/frameworks/torch/tensors/interpreters/native.py"", line 199, in handle_func_command
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/frameworks/torch/hook/hook_args.py"", line 152, in hook_function_args
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/frameworks/torch/hook/hook_args.py"", line 182, in build_hook_args_function
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/frameworks/torch/hook/hook_args.py"", line 411, in build_get_tensor_type
IndexError: list index out of range
```

**Error on the Server side**

```
python start_websocket_servers.py
Starting server for Alice
Starting server for Bob
Starting server for Charlie
 acortis@Jeeg   ~/my_codes/testbed/PySyft/examples/tutorials/advanced/websockets-example-MNIST     dev    ERROR:asyncio:Task exception was never retrieved
future: <Task finished coro=<WebsocketServerWorker._consumer_handler() done, defined at /Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/workers/websocket_server.py:74> exception=ConnectionClosed('WebSocket connection is closed: code = 1006 (connection closed abnormally [internal]), no reason')>
Traceback (most recent call last):
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websockets/protocol.py"", line 674, in transfer_data
    message = yield from self.read_message()
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websockets/protocol.py"", line 742, in read_message
    frame = yield from self.read_data_frame(max_size=self.max_size)
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websockets/protocol.py"", line 815, in read_data_frame
    frame = yield from self.read_frame(max_size)
  File ""/Users/acortis/myERROR:asyncio:Task exception was never retrieved
future: <Task finished coro=<WebsocketServerWorker._consumer_handler() done, defined at /Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/workers/websocket_server.py:74> exception=ConnectionClosed('WebSocket connection is closed: code = 1006 (connection closed abnormally [internal]), no reason')>
Traceback (most recent call last):
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websockets/protocol.py"", line 674, in transfer_data
    message = yield from self.read_message()
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websockets/protocol.py"", line 742, in read_message
    frame = yield from self.read_data_frame(max_size=self.max_size)
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websockets/protocol.py"", line 815, in read_data_frame
    frame = yield from self.read_frame(max_size)
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websockets/protocol.py"", line 884, in read_frame
    extensions=self.extensions,
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websockets/framing.py"", line 99, in read
    data = yield from reader(2)
  File ""/Users/acortis/.pyenv/versions/3.7.3/lib/python3.7/asyncio/streams.py"", line 677, in readexactly
    raise IncompleteReadError(incomplete, n)
asyncio.streams.IncompleteReadError: 0 bytes read on a total of 2 expected bytes

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/workers/websocket_server.py"", line 84, in _consumer_handler
    msg = await websocket.recv()
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websockets/protocol.py"", line 434, in recv
    yield from self.ensure_open()
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websockets/protocol.py"", line 646, in ensure_open
    ) from self.transfer_data_exc
websockets.exceptions.ConnectionClosed: WebSocket connection is closed: code = 1006 (connection closed abnormally [internal]), no reason
ERROR:asyncio:Task exception was never retrieved
future: <Task finished coro=<WebsocketServerWorker._consumer_handler() done, defined at /Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/workers/websocket_server.py:74> exception=ConnectionClosed('WebSocket connection is closed: code = 1006 (connection closed abnormally [internal]), no reason')>
Traceback (most recent call last):
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websockets/protocol.py"", line 674, in transfer_data
    message = yield from self.read_message()
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websockets/protocol.py"", line 742, in read_message
    frame = yield from self.read_data_frame(max_size=self.max_size)
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websockets/protocol.py"", line 815, in read_data_frame
    frame = yield from self.read_frame(max_size)
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websockets/protocol.py"", line 884, in read_frame
    extensions=self.extensions,
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websockets/framing.py"", line 99, in read
    data = yield from reader(2)
  File ""/Users/acortis/.pyenv/versions/3.7.3/lib/python3.7/asyncio/streams.py"", line 677, in readexactly
    raise IncompleteReadError(incomplete, n)
asyncio.streams.IncompleteReadError: 0 bytes read on a total of 2 expected bytes

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/workers/websocket_server.py"", line 84, in _consumer_handler
    msg = await websocket.recv()
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websockets/protocol.py"", line 434, in recv
    yield from self.ensure_open()
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websockets/protocol.py"", line 646, in ensure_open
    ) from self.transfer_data_exc
websockets.exceptions.ConnectionClosed: WebSocket connection is closed: code = 1006 (connection closed abnormally [internal]), no reason
_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websockets/protocol.py"", line 884, in read_frame
    extensions=self.extensions,
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websockets/framing.py"", line 99, in read
    data = yield from reader(2)
  File ""/Users/acortis/.pyenv/versions/3.7.3/lib/python3.7/asyncio/streams.py"", line 677, in readexactly
    raise IncompleteReadError(incomplete, n)
asyncio.streams.IncompleteReadError: 0 bytes read on a total of 2 expected bytes

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/workers/websocket_server.py"", line 84, in _consumer_handler
    msg = await websocket.recv()
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websockets/protocol.py"", line 434, in recv
    yield from self.ensure_open()
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websockets/protocol.py"", line 646, in ensure_open
    ) from self.transfer_data_exc
websockets.exceptions.ConnectionClosed: WebSocket connection is closed: code = 1006 (connection closed abnormally [internal]), no reason
>....
websockets.exceptions.ConnectionClosed: WebSocket connection is closed: code = 1006 (connection closed abnormally [internal]), no reason
_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websockets/protocol.py"", line 884, in read_frame
    extensions=self.extensions,
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websockets/framing.py"", line 99, in read
    data = yield from reader(2)
  File ""/Users/acortis/.pyenv/versions/3.7.3/lib/python3.7/asyncio/streams.py"", line 677, in readexactly
    raise IncompleteReadError(incomplete, n)
asyncio.streams.IncompleteReadError: 0 bytes read on a total of 2 expected bytes

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/workers/websocket_server.py"", line 84, in _consumer_handler
    msg = await websocket.recv()
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websockets/protocol.py"", line 434, in recv
    yield from self.ensure_open()
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websockets/protocol.py"", line 646, in ensure_open
    ) from self.transfer_data_exc
websockets.exceptions.ConnectionClosed: WebSocket connection is closed: code = 1006 (connection closed abnormally [internal]), no reason
zsh: parse error near `)'
```",think go part getting different error though running client also error client side recent call last file line handling exception another exception recent call last file line module main file line main file line file line batch index file line batch index file line file line file line return tensor file line normalize mean mean file line file line file line file line file line list index range error server side python starting server starting server bob starting server dev error task exception never future task finished done defined connection closed code connection closed abnormally internal reason recent call last file line message yield file line frame yield file line frame yield file task exception never future task finished done defined connection closed code connection closed abnormally internal reason recent call last file line message yield file line frame yield file line frame yield file line file line read data yield reader file line raise incomplete read total exception direct cause following exception recent call last file line await file line yield file line connection closed code connection closed abnormally internal reason error task exception never future task finished done defined connection closed code connection closed abnormally internal reason recent call last file line message yield file line frame yield file line frame yield file line file line read data yield reader file line raise incomplete read total exception direct cause following exception recent call last file line await file line yield file line connection closed code connection closed abnormally internal reason line file line read data yield reader file line raise incomplete read total exception direct cause following exception recent call last file line await file line yield file line connection closed code connection closed abnormally internal reason connection closed code connection closed abnormally internal reason line file line read data yield reader file line raise incomplete read total exception direct cause following exception recent call last file line await file line yield file line connection closed code connection closed abnormally internal reason parse error near,issue,negative,negative,neutral,neutral,negative,negative
500515133,"You still need to specify the port and ID of the worker. For example for Alice:

  python3 run_websocket_server.py --host 127.0.0.1 --port 8777 --id alice",still need specify port id worker example python host port id,issue,negative,neutral,neutral,neutral,neutral,neutral
500504380,"The error is related to the torchvision `0.3.0` version.
Will edit a fix for it",error related version edit fix,issue,negative,neutral,neutral,neutral,neutral,neutral
500494181,"Hello DanyEle, thanks for your answer but I am still confused. 

I am running the examples as they are provided in 

`https://github.com/OpenMined/PySyft/blob/dev/examples/tutorials/advanced/websockets-example-MNIST/README.md
`

How am I supposed to run the python commands while running both server and client on the same machine?

I have tried (in two distinct bash shells):

`>> python run_websocket_server.py --host 127.0.0.1`

and

`>> python run_websocket_client.py`

and I get 

`ConnectionRefusedError: [Errno 61] Connection refused`

What am I doing wrong?",hello thanks answer still confused running provided supposed run python running server client machine tried two distinct bash python host python get connection wrong,issue,negative,negative,neutral,neutral,negative,negative
500485837,Cool feel free to start on this one!,cool feel free start one,issue,positive,positive,positive,positive,positive,positive
500473589,It seems to me like a lot is already done,like lot already done,issue,negative,neutral,neutral,neutral,neutral,neutral
500470788,I can advance on this tonight if nobody is working on it,advance tonight nobody working,issue,negative,neutral,neutral,neutral,neutral,neutral
500466166,Hey @jvmancuso have you gotten a chance to test this on a windows machine?,hey gotten chance test machine,issue,negative,neutral,neutral,neutral,neutral,neutral
500455491,"`    alice = WebsocketClientWorker(id=""alice"", port=8777, **kwargs_websocket)
`
This cannot work. You need to specify a valid host for websockets. Supposing you're running this example with local workers, you may want to use:

```
kwargs_websocket_alice = {""host"": ""127.0.0.1"", ""hook"": hook}

alice = WebsocketClientWorker(id=""alice"", port=8777, **kwargs_websocket_alice)
```

Alternatively, if you want to make use of virtual workers - which are not actually web sockets - the following would work:

`    alice = sy.VirtualWorker(hook, id=""alice"")    `
`",work need specify valid host supposing running example local may want use host hook hook alternatively want make use virtual actually web following would work hook,issue,negative,neutral,neutral,neutral,neutral,neutral
500453822,"I just bumped into a lot of error with zstd on an Ubuntu 16.04 machine a few hours ago. They were solved by running:

`sudo apt-get install python3.6-dev`",lot error machine ago running install,issue,negative,neutral,neutral,neutral,neutral,neutral
500402334,"Thank you.  I did see/try the 'pip install --upgrade --force-reinstall zstd' command, but it failed with similar ZSTD errors which led me to another work-around.  Just wanted to mention incase others benefit from it.  ",thank install upgrade command similar led another mention incase benefit,issue,positive,neutral,neutral,neutral,neutral,neutral
500394707,"> Hey, can you confirm you don't have a gpu or cuda?

I do not have an external GPU.

Specs:
Memory: 15,4 GiB
Processor: Intel Core i7-7500U CPU @ 2.70GHz x 4
Graphics: Intel HD Graphics 620 (Kaby Lake GT2)
OS: Ubuntu 18.10 64 Bit

Completly fresh installation with Anaconda and pip. 

",hey confirm external spec memory gib processor core graphic graphic lake o bit fresh installation anaconda pip,issue,negative,positive,neutral,neutral,positive,positive
500386274,"Oh ok, so all the computations are done with numpy that handles large number on its own even on constrained hardware! Sorry, I was not seeing things like that 
So you might also need to use a np object in your _restore_large_number function then, don't you?",oh done large number even constrained hardware sorry seeing like might also need use object function,issue,negative,negative,negative,negative,negative,negative
500383717,"> Hey, can you confirm you don't have a gpu or cuda?

I have a GPU and CUDA installed, but even when disabling CUDA, this still happens.",hey confirm even still,issue,negative,neutral,neutral,neutral,neutral,neutral
500380725,"> But maybe I misunderstood something!
Maybe it's me who is misunderstanding everything :)
",maybe misunderstood something maybe misunderstanding everything,issue,negative,neutral,neutral,neutral,neutral,neutral
500379956,"NumPy works with `objects` to represent large numbers. Not sure how it operates with them internally but it seems to be working.
If we're not using NumPy, we need then to find out how to solve the issue with the overflow and how to do the multiplications.
One problem (or another) of using NumPy is that we'll need to find an equivalent in other languages. There is a promising one for the JVM but I still need to try it (KMath).

Maybe what we need is a new way of computing based only on big integers :)",work represent large sure internally working need find solve issue overflow one problem another need find equivalent promising one still need try maybe need new way based big,issue,negative,positive,positive,positive,positive,positive
500375803,"I am not sure using numpy solves the original problem stated above: ""native hardware does not support precision which is large enough for the cryptographic use cases we'd like to solve"".
But maybe I misunderstood something!",sure original problem stated native hardware support precision large enough cryptographic use like solve maybe misunderstood something,issue,positive,positive,positive,positive,positive,positive
500363622,And i was wondering if i am just to dump to get everything right... got the same Problem on any Tutorial which uses the MNIST Dataset.,wondering dump get everything right got problem tutorial,issue,negative,positive,positive,positive,positive,positive
500345831,"> Hello @DanyEle,
> you can see the discussion here:
> https://openmined.slack.com/archives/C6EEFN3A8/p1559737323042400?thread_ts=1559737323.042400
> relate to [issue 1893](https://github.com/OpenMined/PySyft/issues/1893) here.
> I encounter the same problem as you do :).

I confirm that issue also happens to me in Tutorial Part 6.",hello see discussion relate issue encounter problem confirm issue also tutorial part,issue,negative,neutral,neutral,neutral,neutral,neutral
500344636,"> Oh I didn't new we had already some solutions!
> Would be great to have something also for Virtualworkers since they are very practical for debug, and at the worker scale to have like a graph of bandwidth usage between workers

Also it would be very useful to have a breakdown of the data transmitted as data points or models.",oh new already would great something also since practical worker scale like graph usage also would useful breakdown data data,issue,positive,positive,positive,positive,positive,positive
500335793,"Hello @DanyEle, 
you can see the discussion here:
https://openmined.slack.com/archives/C6EEFN3A8/p1559737323042400?thread_ts=1559737323.042400
relate to [issue 1893](https://github.com/OpenMined/PySyft/issues/1893) here.
 I encounter the same problem as you do :).",hello see discussion relate issue encounter problem,issue,negative,neutral,neutral,neutral,neutral,neutral
500264474,"> Instructions can be found [here](https://github.com/tf-encrypted/tf-encrypted/blob/master/README.md#installation)

And I try changing the **config_filename = ""/tmp/tfe.config""** in C:\Users\Administrator\Desktop\covert security\codes\PySyft-dev\PySyft-dev\syft\workers\tfe.py to **config_filename = ""/tfe.config""**, and get the following error:

---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-19-5b486064ddb2> in <module>
----> 1 model.share(alice, bob, carol)

D:\ProgramData\Anaconda3\lib\site-packages\syft-0.1.15a1-py3.6.egg\syft\frameworks\keras\model\sequential.py in share(model, target_graph, *workers)
     31 
     32     # Handle input combinations to configure TFE
---> 33     player_to_worker_mapping = _configure_tfe(workers)
     34 
     35     if target_graph is None:

D:\ProgramData\Anaconda3\lib\site-packages\syft-0.1.15a1-py3.6.egg\syft\frameworks\keras\model\sequential.py in _configure_tfe(workers)
     99         config.get_player(""server0""), config.get_player(""server1""), config.get_player(""server2"")
    100     )
--> 101     tfe.set_protocol(prot)
    102 
    103     return player_to_worker_mapping

c:\users\administrator\tf-encrypted\tf_encrypted\__init__.py in set_protocol(prot)
     40   # add global names according to new protocol
     41   if prot is not None:
---> 42     methods = inspect.getmembers(prot, predicate=inspect.ismethod)
     43     public_methods = [
     44         method for method in methods if not method[0].startswith('_')]

D:\ProgramData\Anaconda3\lib\inspect.py in getmembers(object, predicate)
    340         # looking in the __dict__.
    341         try:
--> 342             value = getattr(object, key)
    343             # handle the duplicate key
    344             if key in processed:

c:\users\administrator\tf-encrypted\tf_encrypted\protocol\pond\pond.py in initializer(self)
    599   @property
    600   def initializer(self) -> tf.Operation:
--> 601     return tf.group(*_initializers)
    602 
    603   def clear_initializers(self) -> None:

D:\ProgramData\Anaconda3\lib\site-packages\tensorflow-1.14.0rc0-py3.6-win-amd64.egg\tensorflow\python\ops\control_flow_ops.py in group(*inputs, **kwargs)
   3621   if kwargs:
   3622     raise ValueError(""Unknown keyword arguments: "" + "", "".join(kwargs.keys()))
-> 3623   with ops.name_scope(name, ""group_deps"", inputs) as name:
   3624     # Grouping no inputs means do nothing
   3625     if not inputs:

D:\ProgramData\Anaconda3\lib\site-packages\tensorflow-1.14.0rc0-py3.6-win-amd64.egg\tensorflow\python\framework\ops.py in __enter__(self)
   6506       if self._values is None:
   6507         self._values = []
-> 6508       g = _get_graph_from_inputs(self._values)
   6509       self._g_manager = g.as_default()
   6510       self._g_manager.__enter__()

D:\ProgramData\Anaconda3\lib\site-packages\tensorflow-1.14.0rc0-py3.6-win-amd64.egg\tensorflow\python\framework\ops.py in _get_graph_from_inputs(op_input_list, graph)
   6133         graph = graph_element.graph
   6134       elif original_graph_element is not None:
-> 6135         _assert_same_graph(original_graph_element, graph_element)
   6136       elif graph_element.graph is not graph:
   6137         raise ValueError(""%s is not from the passed-in graph."" % graph_element)

D:\ProgramData\Anaconda3\lib\site-packages\tensorflow-1.14.0rc0-py3.6-win-amd64.egg\tensorflow\python\framework\ops.py in _assert_same_graph(original_item, item)
   6069   if original_item.graph is not item.graph:
   6070     raise ValueError(""%s must be from the same graph as %s."" %
-> 6071                      (item, original_item))
   6072 
   6073 

ValueError: name: ""group_deps""
op: ""NoOp""
input: ""^group_deps/NoOp""
input: ""^group_deps/NoOp_1""
 must be from the same graph as name: ""group_deps""
op: ""NoOp""
input: ""^group_deps/NoOp""
input: ""^group_deps/NoOp_1""
.
",found try get following error recent call last module bob carol share model handle input configure none server server server return add global according new protocol none method method method object predicate looking try value object key handle duplicate key key self property self return self none group raise unknown name name grouping nothing self none graph graph none graph raise graph item raise must graph item name noop input input must graph name noop input input,issue,negative,positive,neutral,neutral,positive,positive
500261967,"> Instructions can be found [here](https://github.com/tf-encrypted/tf-encrypted/blob/master/README.md#installation)

I install the tf-encrypted dependency from source as you suggest and get the following error:
FileNotFoundError                         Traceback (most recent call last)
<ipython-input-6-5b486064ddb2> in <module>
----> 1 model.share(alice, bob, carol)

D:\ProgramData\Anaconda3\lib\site-packages\syft-0.1.15a1-py3.6.egg\syft\frameworks\keras\model\sequential.py in share(model, target_graph, *workers)
     55     # Tell the TFE workers to launch TF servers
     56     for player_name, worker in player_to_worker_mapping.items():
---> 57         worker.start(player_name, *workers)
     58 
     59     # Push and initialize shared model on servers

D:\ProgramData\Anaconda3\lib\site-packages\syft-0.1.15a1-py3.6.egg\syft\workers\tfe.py in start(self, player_name, *workers)
     23 
     24         config, _ = self.config_from_workers(workers)
---> 25         config.save(config_filename)
     26 
     27         if self._auto_managed:

c:\users\administrator\tf-encrypted\tf_encrypted\config.py in save(self, filename)
    232     :param str filename: Name of file to save to.
    233     """"""
--> 234     with open(filename, 'w') as f:
    235       json.dump(self.hostmap, f)
    236 

FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tfe.config'",found install dependency source suggest get following error recent call last module bob carol share model tell launch worker push initialize model start self save self param name file save open file directory,issue,positive,neutral,neutral,neutral,neutral,neutral
500247292,"Error while running websockets example on my macbook pro

```
=======
python ./run_websocket_server.py

=======
python ./run_websocket_client.py
Traceback (most recent call last):
  File ""./run_websocket_client.py"", line 273, in <module>
    main()
  File ""./run_websocket_client.py"", line 211, in main
    alice = WebsocketClientWorker(id=""alice"", port=8777, **kwargs_websocket)
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/workers/websocket_client.py"", line 57, in __init__
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websocket/_core.py"", line 514, in create_connection
    websock.connect(url, **options)
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websocket/_core.py"", line 223, in connect
    options.pop('socket', None))
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websocket/_http.py"", line 120, in connect
    sock = _open_socket(addrinfo_list, options.sockopt, options.timeout)
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websocket/_http.py"", line 197, in _open_socket
    raise err
  File ""/Users/acortis/my_codes/testbed/PySyft/.env/lib/python3.7/site-packages/websocket/_http.py"", line 172, in _open_socket
    sock.connect(address)
ConnectionRefusedError: [Errno 61] Connection refused
```


```

Software:

    System Software Overview:

      System Version: macOS 10.14.5 (18F132)
      Kernel Version: Darwin 18.6.0
      Boot Volume: Macintosh HD
      Boot Mode: Normal

Python 3.7.3 (default, Jun  8 2019, 16:41:03)

In [2]: torch.__version__
Out[2]: '1.1.0'

pysyfy commit 9685467662d21bbf534af746640e19926b27c23f (HEAD -> dev, origin/dev, origin/HEAD)
```",error running example pro python python recent call last file line module main file line main file line file line file line connect none file line connect sock file line raise err file line address connection system overview system version kernel version boot volume boot mode normal python default commit head dev,issue,negative,positive,neutral,neutral,positive,positive
500226692,"I had moved the data to a different path, but this isn't the problem.
I restored the path on the data, to be exactly the same as the repo path, but I had the same error.
I replaced the cell with your suggestions and here is the new error occurred.

```python
    ---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-4-7a53acbaa3ff> in <module>
      1 federated_train_loader = sy.FederatedDataLoader( # <-- this is now a FederatedDataLoader 
      2     datasets.MNIST('../data', train=True, download=True)
----> 3     .federate((bob, alice)), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset
      4     batch_size=args.batch_size, shuffle=True, **kwargs)
      5 

~/anaconda3/lib/python3.7/site-packages/syft/frameworks/torch/federated/dataset.py in dataset_federate(dataset, workers)
    159     datasets = []
    160     data_loader = torch.utils.data.DataLoader(dataset, batch_size=data_size)
--> 161     for dataset_idx, (data, targets) in enumerate(data_loader):
    162         worker = workers[dataset_idx % len(workers)]
    163         logger.debug(""Sending data to worker %s"", worker.id)

~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py in __next__(self)
    558         if self.num_workers == 0:  # same-process loading
    559             indices = next(self.sample_iter)  # may raise StopIteration
--> 560             batch = self.collate_fn([self.dataset[i] for i in indices])
    561             if self.pin_memory:
    562                 batch = _utils.pin_memory.pin_memory_batch(batch)

~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py in default_collate(batch)
     66     elif isinstance(batch[0], container_abcs.Sequence):
     67         transposed = zip(*batch)
---> 68         return [default_collate(samples) for samples in transposed]
     69 
     70     raise TypeError((error_msg_fmt.format(type(batch[0]))))

~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py in <listcomp>(.0)
     66     elif isinstance(batch[0], container_abcs.Sequence):
     67         transposed = zip(*batch)
---> 68         return [default_collate(samples) for samples in transposed]
     69 
     70     raise TypeError((error_msg_fmt.format(type(batch[0]))))

~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py in default_collate(batch)
     68         return [default_collate(samples) for samples in transposed]
     69 
---> 70     raise TypeError((error_msg_fmt.format(type(batch[0]))))

TypeError: batch must contain tensors, numbers, dicts or lists; found <class 'PIL.Image.Image'>
```",data different path problem path data exactly path error cell new error python recent call last module bob new distribute across data enumerate worker sending data worker self loading index next may raise batch index batch batch batch batch zip batch return raise type batch batch zip batch return raise type batch batch return raise type batch batch must contain found class,issue,negative,positive,neutral,neutral,positive,positive
500225857,"I don't actually know, I suspect pytest does extra stuff which leads to over reference some objects like pointers. It's annoying because then the behaviour differs between test and real world execution
However I'm not sure that the statement  `pointers of pointers don't get deleted with garbage collection (GC)` is still false

I would suggest closing this as we experience normal behaviour in out pointers of pointers GC tests",actually know suspect extra stuff reference like annoying behaviour test real world execution however sure statement get garbage collection still false would suggest experience normal behaviour,issue,negative,negative,neutral,neutral,negative,negative
500224815,The best way to solve this at the moment would be to install your tf-encrypted dependency from source. We will do a release of tf-encrypted on Monday that fixes this issue in the pip package.,best way solve moment would install dependency source release issue pip package,issue,positive,positive,positive,positive,positive,positive
500223940,"At l.50 we do
```
# Replace all syft tensor with their child attribute
            new_args, new_kwargs, new_type = syft.frameworks.torch.hook_args.hook_function_args(
                attr.__name__, args, kwargs
            )
```
But ideally we should be replace `attr.__name__` with smthg like `attr.__module__+'.'+attr.__name__`

However hooked functions have a module which is changed and we would like to keep the original module. Note the hooked functions are in hook.py and with @overload.module and @overload.function decorator in tensor definition files.

I'd like to underline that this is not a trivial issue",replace tensor child attribute ideally replace like however hooked module would like keep original module note hooked decorator tensor definition like underline trivial issue,issue,positive,positive,positive,positive,positive,positive
500222114,"Hi, this error is now related to #2255 
I will therefore close this one, and add you in the other one.",hi error related therefore close one add one,issue,negative,neutral,neutral,neutral,neutral,neutral
500221563,"This is a bit mysterious to me :/
One thing, why have you changed the path of data `../data` to `.`?

Second thing, can you try replacing the cell
```
federated_train_loader = sy.FederatedDataLoader( # <-- this is now a FederatedDataLoader 
    datasets.MNIST('../data', train=True, download=True,
                   transform=transforms.Compose([
                       transforms.ToTensor(),
                       transforms.Normalize((0.1307,), (0.3081,))
                   ]))
    .federate((bob, alice)), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset
    batch_size=args.batch_size, shuffle=True, **kwargs)

test_loader = torch.utils.data.DataLoader(
    datasets.MNIST('../data', train=False, transform=transforms.Compose([
                       transforms.ToTensor(),
                       transforms.Normalize((0.1307,), (0.3081,))
                   ])),
    batch_size=args.test_batch_size, shuffle=True, **kwargs)
```
with
```
federated_train_loader = sy.FederatedDataLoader( # <-- this is now a FederatedDataLoader 
    datasets.MNIST('../data', train=True, download=True)
    .federate((bob, alice)), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset
    batch_size=args.batch_size, shuffle=True, **kwargs)

test_loader = torch.utils.data.DataLoader(
    datasets.MNIST('../data', train=False),
    batch_size=args.test_batch_size, shuffle=True, **kwargs)
```
What happens now?",bit mysterious one thing path data second thing try cell bob new distribute across bob new distribute across,issue,negative,positive,neutral,neutral,positive,positive
500221047,"Oh I didn't new we had already some solutions!
Would be great to have something also for Virtualworkers since they are very practical for debug, and at the worker scale to have like a graph of bandwidth usage between workers",oh new already would great something also since practical worker scale like graph usage,issue,positive,positive,positive,positive,positive,positive
500220440,One manual approach to monitor traffic sent over websockets is via Wireshark. But having it integrated in PySyft would indeed be cool!,one manual approach monitor traffic sent via would indeed cool,issue,negative,positive,positive,positive,positive,positive
500197773,I guess we could close this issue since it got fixed and merged already in dev? #2239 :smile:  ,guess could close issue since got fixed already dev smile,issue,negative,positive,positive,positive,positive,positive
500196568,"I created a draft with one the possibilities I see we could use to deal with the operations of large numbers. Basically it uses NumPy for such operations. 
The main difference with the other PR is that the number is reconstructed before operating (see `def add()`.

https://github.com/OpenMined/PySyft/pull/2257/files

Please note this is not a PR to merge but only for discussing it",draft one see could use deal large basically main difference number reconstructed operating see add please note merge,issue,negative,positive,positive,positive,positive,positive
500175444,"Hi :smile: , I tested it on a Linux 4.19 Manjaro distribution and also on Centos7, both running on an x86_64 machine.",hi smile tested distribution also running machine,issue,negative,positive,positive,positive,positive,positive
500120267,"Hi, and thank you for the pull request! It's definitely a good idea to have a Docker image for PySyft, with all dependencies packed in it. I also thought about it :smile:   . Which system did you test it on so far?",hi thank pull request definitely good idea docker image also thought smile system test far,issue,positive,positive,positive,positive,positive,positive
500120150,"> What do you mean by constant uptime?

I believe it means at a regular time interval, like every X minutes?

",mean constant believe regular time interval like every,issue,negative,negative,negative,negative,negative,negative
500088334,"AttributeError                            Traceback (most recent call last)
<ipython-input-7-5b486064ddb2> in <module>()
----> 1 model.share(alice, bob, carol)

D:\ProgramData\Anaconda3\lib\site-packages\syft-0.1.15a1-py3.6.egg\syft\frameworks\keras\model\sequential.py in share(model, target_graph, *workers)
     38 
     39     with target_graph.as_default():
---> 40         tfe_model, batch_input_shape = _rebuild_tfe_model(model, stored_keras_weights)
     41 
     42         # Set up a new tfe.serving.QueueServer for the shared TFE model

D:\ProgramData\Anaconda3\lib\site-packages\syft-0.1.15a1-py3.6.egg\syft\frameworks\keras\model\sequential.py in _rebuild_tfe_model(keras_model, stored_keras_weights)
    112     """"""
    113 
--> 114     tfe_model = tfe.keras.Sequential()
    115 
    116     for keras_layer in keras_model.layers:

D:\ProgramData\Anaconda3\lib\site-packages\tf_encrypted-0.5.4-py3.6.egg\tf_encrypted\keras\engine\sequential.py in __init__(self, layers, name)
     10   """"""
     11   def __init__(self, layers=None, name=None):
---> 12     super(Sequential, self).__init__(name=name)
     13 
     14     self._layers = []

D:\ProgramData\Anaconda3\lib\site-packages\tf_encrypted-0.5.4-py3.6.egg\tf_encrypted\keras\engine\base_layer.py in __init__(self, trainable, name, **kwargs)
     51 
     52     self.trainable = trainable
---> 53     self._init_set_name(name)
     54     self.built = False
     55 

D:\ProgramData\Anaconda3\lib\site-packages\tf_encrypted-0.5.4-py3.6.egg\tf_encrypted\keras\engine\base_layer.py in _init_set_name(self, name, zero_based)
    108   def _init_set_name(self, name, zero_based=True):
    109     if not name:
--> 110       self._name = base_layer_utils.unique_layer_name(
    111           generic_utils.to_snake_case(self.__class__.__name__),
    112           zero_based=zero_based)

AttributeError: module 'tensorflow.python.keras.engine.base_layer_utils' has no attribute 'unique_layer_name'

How can I solve this problem? Thanks.",recent call last module bob carol share model model set new model self name self super sequential self self trainable name trainable name false self name self name name module attribute solve problem thanks,issue,positive,positive,neutral,neutral,positive,positive
499989987,Would really love someone to test this on a Windows machine since I don't have one available to me!,would really love someone test machine since one available,issue,positive,positive,positive,positive,positive,positive
499953471,"My PR is here #2248
I am not really sure about what it means to compute a mean for int, I did a sum and an int div",really sure compute mean sum div,issue,negative,positive,neutral,neutral,positive,positive
499892857,"Thanks @LaRiffle! 🙏 

Wanted to get @iamtrask's opinion on the change to the notebooks as well..",thanks get opinion change well,issue,positive,positive,positive,positive,positive,positive
499828459,"Today I tried this approach and it works for the conversion. 
```python
train_dataset = datasets.MNIST('.', train=True, download=True,
                   transform=transform)

train_base = sy.BaseDataset(data=train_dataset.data, targets=train_dataset.targets)
train_base_federated = train_base.federate((bob, alice))
federated_trainloader = sy.FederatedDataLoader(train_base_federated, 
                                                batch_size=64, 
                                                shuffle=True)
```
But it's strange... because now other error appears.
```python
---------------------------------------------------------------------------
PureTorchTensorFoundError                 Traceback (most recent call last)
~/anaconda3/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in handle_func_command(cls, command)
    198             new_args, new_kwargs, new_type, args_type = syft.frameworks.torch.hook_args.hook_function_args(
--> 199                 cmd, args, kwargs, return_args_type=True
    200             )

~/anaconda3/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook_args.py in hook_function_args(attr, args, kwargs, return_args_type)
    147         # Try running it
--> 148         new_args = hook_args(args)
    149 

~/anaconda3/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook_args.py in <lambda>(x)
    341 
--> 342     return lambda x: f(lambdas, x)
    343 

~/anaconda3/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook_args.py in seven_fold(lambdas, args, **kwargs)
    543     return (
--> 544         lambdas[0](args[0], **kwargs),
    545         lambdas[1](args[1], **kwargs),

~/anaconda3/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook_args.py in <lambda>(i)
    319         # Last if not, rule is probably == 1 so use type to return the right transformation.
--> 320         else lambda i: forward_func[type(i)](i)
    321         for a, r in zip(args, rules)  # And do this for all the args / rules provided

~/anaconda3/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook_args.py in <lambda>(i)
     50     if hasattr(i, ""child"")
---> 51     else (_ for _ in ()).throw(PureTorchTensorFoundError),
     52     torch.nn.Parameter: lambda i: i.child

~/anaconda3/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook_args.py in <genexpr>(.0)
     50     if hasattr(i, ""child"")
---> 51     else (_ for _ in ()).throw(PureTorchTensorFoundError),
     52     torch.nn.Parameter: lambda i: i.child

PureTorchTensorFoundError: 

During handling of the above exception, another exception occurred:

RuntimeError                              Traceback (most recent call last)
<timed exec> in <module>

<ipython-input-18-72ddef6ce5b6> in train(args, model, device, federated_train_loader, optimizer, epoch)
      5         data, target = data.to(device), target.to(device)
      6         optimizer.zero_grad()
----> 7         output = model(data)
      8         loss = F.nll_loss(output, target)
      9         loss.backward()

~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    491             result = self._slow_forward(*input, **kwargs)
    492         else:
--> 493             result = self.forward(*input, **kwargs)
    494         for hook in self._forward_hooks.values():
    495             hook_result = hook(self, input, result)

<ipython-input-17-ceb0955942ca> in forward(self, x)
      8 
      9     def forward(self, x):
---> 10         x = F.relu(self.conv1(x))
     11         x = F.max_pool2d(x, 2, 2)
     12         x = F.relu(self.conv2(x))

~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    491             result = self._slow_forward(*input, **kwargs)
    492         else:
--> 493             result = self.forward(*input, **kwargs)
    494         for hook in self._forward_hooks.values():
    495             hook_result = hook(self, input, result)

~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py in forward(self, input)
    336                             _pair(0), self.dilation, self.groups)
    337         return F.conv2d(input, self.weight, self.bias, self.stride,
--> 338                         self.padding, self.dilation, self.groups)
    339 
    340 

~/anaconda3/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook.py in overloaded_func(*args, **kwargs)
    705             cmd_name = f""{attr.__module__}.{attr.__name__}""
    706             command = (cmd_name, None, args, kwargs)
--> 707             response = TorchTensor.handle_func_command(command)
    708             return response
    709 

~/anaconda3/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in handle_func_command(cls, command)
    207             new_command = (cmd, None, new_args, new_kwargs)
    208             # Send it to the appropriate class and get the response
--> 209             response = new_type.handle_func_command(new_command)
    210             # Put back the wrappers where needed
    211             response = syft.frameworks.torch.hook_args.hook_response(

~/anaconda3/lib/python3.7/site-packages/syft/frameworks/torch/pointers/object_pointer.py in handle_func_command(cls, command)
     86 
     87         # Send the command
---> 88         response = owner.send_command(location, command)
     89 
     90         return response

~/anaconda3/lib/python3.7/site-packages/syft/workers/base.py in send_command(self, recipient, message, return_ids)
    421 
    422         try:
--> 423             ret_val = self.send_msg(MSGTYPE.CMD, message, location=recipient)
    424         except ResponseSignatureError as e:
    425             ret_val = None

~/anaconda3/lib/python3.7/site-packages/syft/workers/base.py in send_msg(self, msg_type, message, location)
    219 
    220         # Step 2: send the message and wait for a response
--> 221         bin_response = self._send_msg(bin_message, location)
    222 
    223         # Step 3: deserialize the response

~/anaconda3/lib/python3.7/site-packages/syft/workers/virtual.py in _send_msg(self, message, location)
      4 class VirtualWorker(BaseWorker):
      5     def _send_msg(self, message: bin, location: BaseWorker) -> bin:
----> 6         return location._recv_msg(message)
      7 
      8     def _recv_msg(self, message: bin) -> bin:

~/anaconda3/lib/python3.7/site-packages/syft/workers/virtual.py in _recv_msg(self, message)
      7 
      8     def _recv_msg(self, message: bin) -> bin:
----> 9         return self.recv_msg(message)

~/anaconda3/lib/python3.7/site-packages/syft/workers/base.py in recv_msg(self, bin_message)
    250             print(f""worker {self} received {sy.codes.code2MSGTYPE[msg_type]} {contents}"")
    251         # Step 1: route message to appropriate function
--> 252         response = self._message_router[msg_type](contents)
    253 
    254         # Step 2: Serialize the message to simple python objects

~/anaconda3/lib/python3.7/site-packages/syft/workers/base.py in execute_command(self, message)
    379                 command = getattr(command, path)
    380 
--> 381             response = command(*args, **kwargs)
    382 
    383         # some functions don't return anything (such as .backward())

~/anaconda3/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook.py in overloaded_func(*args, **kwargs)
    705             cmd_name = f""{attr.__module__}.{attr.__name__}""
    706             command = (cmd_name, None, args, kwargs)
--> 707             response = TorchTensor.handle_func_command(command)
    708             return response
    709 

~/anaconda3/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in handle_func_command(cls, command)
    224             # in the execute_command function
    225             if isinstance(args, tuple):
--> 226                 response = eval(cmd)(*args, **kwargs)
    227             else:
    228                 response = eval(cmd)(args, **kwargs)

RuntimeError: Expected 4-dimensional input for 4-dimensional weight 20 1 5, but got 3-dimensional input of size [5, 28, 28] instead
```",today tried approach work conversion python bob strange error python recent call last command try running lambda return lambda return lambda last rule probably use type return right transformation else lambda type zip provided lambda child else lambda child else lambda handling exception another exception recent call last timed module train model device epoch data target device device output model data loss output target self input result input else result input hook hook self input result forward self forward self self input result input else result input hook hook self input result forward self input return input command none response command return response command none send appropriate class get response response put back response command send command response location command return response self recipient message try message except none self message location step send message wait response location step response self message location class self message bin location bin return message self message bin bin self message self message bin bin return message self print worker self received content step route message appropriate function response content step serialize message simple python self message command command path response command return anything command none response command return response command function response else response input weight got input size instead,issue,negative,positive,positive,positive,positive,positive
499695470,"Hey @geochri are you running the tutorial ""as is"" or have you made any modifications?
Also, do you have gpus or cuda?",hey running tutorial made also,issue,negative,neutral,neutral,neutral,neutral,neutral
499689825,"It is used internally when you're printing Tensors objects for example, so hooking .size() might (and does) break many processes",used internally printing example might break many,issue,negative,positive,positive,positive,positive,positive
499656377,@LaRiffle could you clarify where the module of functions should be be retrieved in this file? There does not appear to be anything which explicitly checks to see if they are in the exclude_functions list,could clarify module file appear anything explicitly see list,issue,negative,neutral,neutral,neutral,neutral,neutral
499649590,"> If you interpreted it as a TrainingManager, then we probably would have implement it to be in charge of talking to the workers.

I am very much of the viewpoint that we should move away from having the workers themselves be a part of the api to call functions (other than send to worker). That being said, I don't think that api choice is a good reason to not merge the functionality. We can update it later",probably would implement charge talking much viewpoint move away part call send worker said think choice good reason merge functionality update later,issue,negative,positive,positive,positive,positive,positive
499642605,@LaRiffle Do you know why for build tensor type first_layer would be true but the length of lambdas would be <1,know build tensor type would true length would,issue,negative,positive,positive,positive,positive,positive
499641842,"> My only question is about the line alice.fit(""xor""). Can you help me understand semantically why I'm calling .fit() on alice instead of on train_config (which I assumed would choose to train on alice?)

Because you tell the worker to train, assuming he already obtained the training parameters. I think this just a question of how you interpret TrainConfig. I see it as a parameter set which you send to the worker and then tell the worker to train. 

If you interpreted it as a TrainingManager, then we probably would have implement it to be in charge of talking to the workers.

",question line help understand semantically calling instead assumed would choose train tell worker train assuming already training think question interpret see parameter set send worker tell worker train probably would implement charge talking,issue,negative,neutral,neutral,neutral,neutral,neutral
499638953,@IonesioJunior @LaRiffle is taking the lead on this issue. This issue will continue to be updates as progress is made (there will be many sub issues linked here),taking lead issue issue continue progress made many sub linked,issue,negative,positive,positive,positive,positive,positive
499638205,"This is a VERY impressive PR! You guys have built so much in so little time! Excellent work!

My only question is about the line alice.fit(""xor""). Can you help me understand semantically why I'm calling .fit() on alice instead of on train_config (which I assumed would choose to train on alice?)

Mostly a curiosity - very excited about this work!",impressive built much little time excellent work question line help understand semantically calling instead assumed would choose train mostly curiosity excited work,issue,positive,positive,positive,positive,positive,positive
499494127,"What was the conclusion of the discussion to move the serde functionality to the classes? It will not work for all cases, but for many it will work and make the maintenance easier.",conclusion discussion move functionality class work many work make maintenance easier,issue,negative,positive,positive,positive,positive,positive
499402750,@mari-linhares kindly this is ready to be reviewed. Thanks a lot :),kindly ready thanks lot,issue,positive,positive,positive,positive,positive,positive
499237308,Has anyone started to develop this? I would like to follow the development of this issue.,anyone develop would like follow development issue,issue,negative,neutral,neutral,neutral,neutral,neutral
499193317,"@LaRiffle sure, added a simple raises assertion test there :smile: ",sure added simple assertion test smile,issue,positive,positive,positive,positive,positive,positive
499189389,"@robert-wagner closing this for a new PR, fixed the noise of unrelated previous things #2239",new fixed noise unrelated previous,issue,negative,positive,neutral,neutral,positive,positive
499171936,"@robert-wagner I guess because I transferred this repository from my old account to this new account, it had old changes, so the above changes are to get the current master merged in my fork then the latest 4 commits is related to the actual issue in this PR (since the previous changes are not even my changes right? it's from the original repository). Sure please let me know if I misunderstood something or if I should check my branches again :smile: ",guess transferred repository old account new account old get current master fork latest related actual issue since previous even right original repository sure please let know misunderstood something check smile,issue,positive,positive,positive,positive,positive,positive
499155029,"@iamtrask kindly that can be reviewed so it can be merged if it's fine, thank you :smile: ",kindly fine thank smile,issue,positive,positive,positive,positive,positive,positive
499006663,"> It only works for 1D tensors right?

I broke something when I passed to `np` 😱 . I'll see if I can fix it",work right broke something see fix,issue,negative,positive,positive,positive,positive,positive
498966726,Let's start by updating PySyft. The latest version is 0.1.17.a1 which is 5 versions after the one you have.,let start latest version one,issue,negative,positive,positive,positive,positive,positive
498961334,"I agree. Debug messages just appear at the server and not on the workers themselves when using websockets. It would nice to have them also on the workers.

Replicated on:

**Desktop:**
OS: Ubuntu 18.04 LTS, Raspbian 4.14",agree appear server would nice also replicated o,issue,positive,positive,positive,positive,positive,positive
498960744,"> Hi guys,
> 
> I am a new PySyft user and started to work with the library this weekend.
> I tried to train a toy GRU model remotely and got some errors related to the Tensor.size() method on the forward pass of the GRU layer.
> 
> I understand from #2201 that you have not implemented this method for remote tensors yet.
> 
> What I understand from the error is that without the .size() method the GRU layer won't work.
> 
> Do you have an idea if this method is going to be implemented and when?
> 
> Thank you!

I guess you can just keep track of the conversation going on at #2201 ",hi new user work library weekend tried train toy model remotely got related method forward pas layer understand method remote yet understand error without method layer wo work idea method going thank guess keep track conversation going,issue,negative,negative,neutral,neutral,negative,negative
498951220,"> Initial review. Will comment more later if I see other stuff (its the end of the day here)

Thanks for the late night review. It was the end of the day here too. We should be doing something else! :)",initial review comment later see stuff end day thanks late night review end day something else,issue,negative,negative,neutral,neutral,negative,negative
498934294,"I have already tried all the mentioned commands I even tried using it within the enviornment in which I had pytorch Installed and I got back the same error my current conda version is 4.5x and the torch version is 1.x @iamtrask  
",already tried even tried within got back error current version torch version,issue,negative,neutral,neutral,neutral,neutral,neutral
498908760,"@iamtrask so basically any instance of ""syft.frameworks.torch.pointers.PointerTensor"" which have a call to "".item"" function should be raising an error with a message as described above? or there is something I misunderstood? :smile: , if it's right so it's as easy as implementing a "".item"" function inside ""syft.frameworks.torch.pointers.PointerTensor"" and raising the error there. I'm willing to make a quick PR if that's fine, Thank you :smile: ",basically instance call function raising error message something misunderstood smile right easy function inside raising error willing make quick fine thank smile,issue,positive,positive,positive,positive,positive,positive
498831859,"> @robert-wagner I'd love to have your view on this point (namely we have a method which could apply for the pointer object AND the point target)

Sorry for the delay in getting back to you on this. I need to adjust my notification preferences for GitHub (I currently get way to many messages to deal with)

My question is why does the size of the pointer matter (what utility do we get out of it? I can definitely see the case for getting the size of the object that it is pointing to but I am not sure what the point of getting the size of the pointer is (other than knowing it is a pointer but in many cases there are better ways to do that)",love view point namely method could apply pointer object point target sorry delay getting back need adjust notification currently get way many deal question size pointer matter utility get definitely see case getting size object pointing sure point getting size pointer knowing pointer many better way,issue,positive,positive,positive,positive,positive,positive
498593257,"For completeness: In order to create more complex neural networks containing relus etc. even more functions need to be excluded from the hooking. 

In file syft/frameworks/torch/hook/torch_attributes.py, line 33-, uncomment torch and torch.nn.functional.
```
# List modules that we will hook
        self.torch_modules = {
            # ""torch"": torch,
            ""torch.functional"": torch.functional,
            # ""torch.nn.functional"": torch.nn.functional,
        }
```",completeness order create complex neural even need file line torch list hook torch torch,issue,negative,negative,negative,negative,negative,negative
498556996,"I think the .dim() method has been fixed since this issue is open but I have now another error when trying to use Batchnorm with the same modification as above:

---------------------------------------------------------------------------
PureTorchTensorFoundError                 Traceback (most recent call last)
/usr/local/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/frameworks/torch/tensors/interpreters/native.py in handle_func_command(cls, command)
    198             new_args, new_kwargs, new_type, args_type = syft.frameworks.torch.hook_args.hook_function_args(
--> 199                 cmd, args, kwargs, return_args_type=True
    200             )

/usr/local/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/frameworks/torch/hook/hook_args.py in hook_function_args(attr, args, kwargs, return_args_type)
    157         # Run it
--> 158         new_args = args_hook_function(args)
    159 

/usr/local/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/frameworks/torch/hook/hook_args.py in <lambda>(x)
    341 
--> 342     return lambda x: f(lambdas, x)
    343 

/usr/local/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/frameworks/torch/hook/hook_args.py in eight_fold(lambdas, args, **kwargs)
    556         lambdas[0](args[0], **kwargs),
--> 557         lambdas[1](args[1], **kwargs),
    558         lambdas[2](args[2], **kwargs),

/usr/local/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/frameworks/torch/hook/hook_args.py in <lambda>(i)
    319         # Last if not, rule is probably == 1 so use type to return the right transformation.
--> 320         else lambda i: forward_func[type(i)](i)
    321         for a, r in zip(args, rules)  # And do this for all the args / rules provided

/usr/local/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/frameworks/torch/hook/hook_args.py in <lambda>(i)
     50     if hasattr(i, ""child"")
---> 51     else (_ for _ in ()).throw(PureTorchTensorFoundError),
     52     torch.nn.Parameter: lambda i: i.child

/usr/local/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/frameworks/torch/hook/hook_args.py in <genexpr>(.0)
     50     if hasattr(i, ""child"")
---> 51     else (_ for _ in ()).throw(PureTorchTensorFoundError),
     52     torch.nn.Parameter: lambda i: i.child

PureTorchTensorFoundError: 

During handling of the above exception, another exception occurred:

RuntimeError                              Traceback (most recent call last)
<timed exec> in <module>

<ipython-input-6-72ddef6ce5b6> in train(args, model, device, federated_train_loader, optimizer, epoch)
      5         data, target = data.to(device), target.to(device)
      6         optimizer.zero_grad()
----> 7         output = model(data)
      8         loss = F.nll_loss(output, target)
      9         loss.backward()

/usr/local/lib/python3.7/site-packages/torch-1.0.1-py3.7-macosx-10.14-x86_64.egg/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    487             result = self._slow_forward(*input, **kwargs)
    488         else:
--> 489             result = self.forward(*input, **kwargs)
    490         for hook in self._forward_hooks.values():
    491             hook_result = hook(self, input, result)

<ipython-input-5-7560ae2ae6d3> in forward(self, x)
     10     def forward(self, x):
     11         x = F.relu(self.conv1(x))
---> 12         x = self.bn1(x)
     13         x = F.max_pool2d(x, 2, 2)
     14         x = F.relu(self.conv2(x))

/usr/local/lib/python3.7/site-packages/torch-1.0.1-py3.7-macosx-10.14-x86_64.egg/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    487             result = self._slow_forward(*input, **kwargs)
    488         else:
--> 489             result = self.forward(*input, **kwargs)
    490         for hook in self._forward_hooks.values():
    491             hook_result = hook(self, input, result)

/usr/local/lib/python3.7/site-packages/torch-1.0.1-py3.7-macosx-10.14-x86_64.egg/torch/nn/modules/batchnorm.py in forward(self, input)
     74             input, self.running_mean, self.running_var, self.weight, self.bias,
     75             self.training or not self.track_running_stats,
---> 76             exponential_average_factor, self.eps)
     77 
     78     def extra_repr(self):

/usr/local/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/frameworks/torch/hook/hook.py in overloaded_func(*args, **kwargs)
    706             cmd_name = f""{attr.__module__}.{attr.__name__}""
    707             command = (cmd_name, None, args, kwargs)
--> 708             response = TorchTensor.handle_func_command(command)
    709             return response
    710 

/usr/local/lib/python3.7/site-packages/syft-0.1.17-py3.7.egg/syft/frameworks/torch/tensors/interpreters/native.py in handle_func_command(cls, command)
    224             # in the execute_command function
    225             if isinstance(args, tuple):
--> 226                 response = eval(cmd)(*args, **kwargs)
    227             else:
    228                 response = eval(cmd)(args, **kwargs)

/usr/local/lib/python3.7/site-packages/torch-1.0.1-py3.7-macosx-10.14-x86_64.egg/torch/nn/functional.py in batch_norm(input, running_mean, running_var, weight, bias, training, momentum, eps)
   1621     return torch.batch_norm(
   1622         input, weight, bias, running_mean, running_var,
-> 1623         training, momentum, eps, torch.backends.cudnn.enabled
   1624     )
   1625 

RuntimeError: running_mean should contain 11333 elements not 20
---------------------------------------------------------------------------

Where the 11333 seems to be a bit random (I tried several times and the error does not give the same number each time). Maybe it is now due to the .size() method (#2201)?",think method fixed since issue open another error trying use modification recent call last command run lambda return lambda lambda last rule probably use type return right transformation else lambda type zip provided lambda child else lambda child else lambda handling exception another exception recent call last timed module train model device epoch data target device device output model data loss output target self input result input else result input hook hook self input result forward self forward self self input result input else result input hook hook self input result forward self input input self command none response command return response command function response else response input weight bias training momentum return input weight bias training momentum contain bit random tried several time error give number time maybe due method,issue,negative,negative,neutral,neutral,negative,negative
498475157,"> Deep Learning.ipynb'

`fatal: invalid reference: upstream/dev` after running `git checkout`
",deep fatal invalid reference running git,issue,negative,neutral,neutral,neutral,neutral,neutral
498384572,"Well since everything is fixed here, I am going to close the issue! 

This was more than helpful - it is was an amazing piece of work and I am looking forward to looking at other work on PySyft and PyTorch. : ) ",well since everything fixed going close issue helpful amazing piece work looking forward looking work,issue,positive,positive,positive,positive,positive,positive
498335990,"Thank you very much @TheCedarPrince for the useful fixes to the tutorial I wrote and good job in setting it all up on the two Raspberry PIs! I hope the tutorial helped you with some guidance on how to go through the whole procedure to setup PySyft and Pytorch, at least. :) 

I'm surely going to apply your fixes to my tutorial, but a static IP address, even if suggested to carry out experiments multiple times, is not actually a necessary condition to run the RNN example. ",thank much useful tutorial wrote good job setting two raspberry hope tutorial guidance go whole procedure setup least surely going apply tutorial static address even carry multiple time actually necessary condition run example,issue,positive,positive,positive,positive,positive,positive
498326142,"@jidroid404 
Could you run `git remote add upstream git@github.com:OpenMined/PySyft.git`
then run `git checkout upstream/dev -- 'examples/tutorials/Part 1 - The Basic Tools of Private Deep Learning.ipynb'`",could run git remote add upstream git run git basic private deep,issue,negative,negative,neutral,neutral,negative,negative
498314064,"> Getting `nothing to commit` on doing so.

I forgot this is in a fork. Let me see if there is an easy way to do this",getting nothing commit forgot fork let see easy way,issue,negative,positive,positive,positive,positive,positive
498302949,You need to run `black syft` to get this pr to pass travis. Alternatively by running `make install_hooks` black will run automatically before every commit,need run black get pas travis alternatively running make black run automatically every commit,issue,negative,negative,negative,negative,negative,negative
498296816,Mind taking a look at the linked PR @robert-wagner?,mind taking look linked,issue,negative,neutral,neutral,neutral,neutral,neutral
498278740,"Hey @DanyEle and @iamtrask 

# Can confirm, this bug is now fixed! :tada: :tada: :tada: 

## Also, @DanyEle since I have your attention here, I wanted to also make you aware of some errors and thoughts I encountered while following your [article](https://blog.openmined.org/federated-learning-of-a-rnn-on-raspberry-pis/). Here they are: 

- When you are trying to install PyTorch on the RPi, you must first have installed `pyyaml==5.1`
- I had to run `sudo apt-get update && sudo reboot` after installing PyTorch on the RPi as I had some issues moving forward with installs
- In the `requirements.txt` for PySyft (when you are trying to build and install it on the RPi) you need to remove the following packages for it to compile/build correctly:
    - torch
- On Part 2 in Section 1 of ""Start the worker servers on the Raspberry PIs"" - I was going crazy until I figured out there was an error in the command you specified - it should be as follows:
    - **Raspberry Pi 1:** `python run_websocket_server.py --host 10.42.0.55 --port 8777 --id alice`
    - **Raspberry Pi 2:** `python run_websocket_server.py --host 10.42.0.56 --port 8778 --id bob`
- It is worth making a note in the instructions that training on the RPi using the federated method often takes a very long time - for me, it took about 2 hours for my RPi 3B+'s 
- I found the instructions about using screen confusing so you may want to clear that up just a little bit or include pictures about how to use this with respect to connecting to a raspberry pi
- I found setting the alias `alias python=python3.6` while following your instructions so I would suggest adding that as a way of setting your default RPi Python to Python3.6

I also think it may be useful to have actually demonstrated how to assign a static IP to the Raspberry Pi's; I stubbed out the basic outline of how to do that here (these steps are to be followed on the RPi's): 

- Run `netstat -nr`
    - Write down the Gateway Address associated with Destination 0.0.0.0

- Run `sudo nano /etc/dhcpcd.conf` and at the top of the file write, 
  - `ip_address=[Write in the Gateway address but with the last numbers specified to a number you want]/24` (example: if my gateway address is 10.42.0.1, then I would write in something like: `ip_address=10.42.0.77/24`)
  - `static routers=[Write down the Gateway address]`
  - `static domain_name_servers=[Write down the Gateway address from earlier]`

- Reboot the RPi and SSH into the RPi using the ip_address you just specified earlier. 

## I hope this was helpful - thanks for the help with setting this up properly; this was awesome! Keep up the great work and good luck with grad school @DanyEle! ",hey confirm bug fixed also since attention also make aware following article trying install must first run update moving forward trying build install need remove following correctly torch part section start worker raspberry going crazy figured error command raspberry pi python host port id raspberry pi python host port id bob worth making note training method often long time took found screen may want clear little bit include use respect raspberry pi found setting alias alias following would suggest way setting default python python also think may useful actually assign static raspberry pi stubbed basic outline run write gateway address associated destination run top file write write gateway address last number want example gateway address would write something like static write gateway address static write gateway address hope helpful thanks help setting properly awesome keep great work good luck grad school,issue,positive,positive,positive,positive,positive,positive
498258911,try: `git pull origin dev`. then try to push again,try git pull origin dev try push,issue,negative,neutral,neutral,neutral,neutral,neutral
498256053,For ignoring some file you can add all the files you want to commit then run `git stash`. Careful: this will undo any changes to any file not staged (added).,file add want commit run git stash careful undo file staged added,issue,negative,negative,neutral,neutral,negative,negative
498255296,"something in your directory is not added. If you run git status it will tell you what it is
",something directory added run git status tell,issue,negative,neutral,neutral,neutral,neutral,neutral
498245127,"Hey @jidroid404, 

You don't need to add more files to the commit neither create a new PR, you can modify the file locally, create a new commit and then push to your local branch (this PR will be automatically updated), here are the commands:

```
# go to your local copy of this repo
cd <path where PySyft was cloned> 
# update your local branch
git pull origin dev
# modify syft/grid.py as suggested 
...
# add changes
git add syft/grid.py
# commit changes
git commit
# push changes
git push origin dev
```",hey need add commit neither create new modify file locally create new commit push local branch automatically go local copy path update local branch git pull origin dev modify add git add commit git commit push git push origin dev,issue,positive,positive,neutral,neutral,positive,positive
498220852,"Hi guys,

I am a new PySyft user and started to work with the library this weekend. 
I tried to train a toy GRU model remotely and got some errors related to the Tensor.size() method on the forward pass of the GRU layer.

I understand from #2201 that you have not implemented this method for remote tensors yet. 

What I understand from the error is that without the .size() method the GRU layer won't work.

Do you have an idea if this method is going to be implemented and when?

Thank you!",hi new user work library weekend tried train toy model remotely got related method forward pas layer understand method remote yet understand error without method layer wo work idea method going thank,issue,negative,negative,neutral,neutral,negative,negative
498195153,"Alright, I looked into it and it was because of the misplaced line ` with torch.no_grad():`, which was referring to a larger block. Here is the fixed code for the predict method

```
def predict(model, input_line, worker, n_predictions=3):
    model = model.copy().get()
    print('\n> %s' % input_line)
    model_remote = model.send(worker)
    line_tensor = lineToTensor(input_line)
    line_remote = line_tensor.copy().send(worker)
    #line_tensor = lineToTensor(input_line)
    #output = evaluate(model, line_remote)
    # Get top N categories
    hidden = model_remote.initHidden()
    hidden_remote = hidden.copy().send(worker)
        
    with torch.no_grad():
        for i in range(line_remote.shape[0]):
            output, hidden_remote = model_remote(line_remote[i], hidden_remote)
        
    topv, topi = output.copy().get().topk(n_predictions, 1, True)
    predictions = []

    for i in range(n_predictions):
        value = topv[0][i].item()
        category_index = topi[0][i].item()
        print('(%.2f) %s' % (value, all_categories[category_index]))
        predictions.append([value, all_categories[category_index]])
```

",alright line block fixed code predict method predict model worker model print worker worker output evaluate model get top hidden worker range output topi true range value topi print value value,issue,positive,positive,positive,positive,positive,positive
498186503,You should update conda and pip. If it doesn't have torch 1.x it's likely very old.,update pip torch likely old,issue,negative,positive,neutral,neutral,positive,positive
498173046,"> > Or we could also just multiply the learning rate by the scaling factor (same as the one used to convert to FixedPoint) and do something similar to what I did but only with integer values
> > Do you think it is better?
> 
> This is exactly what FixedPrecision does for you, let's keep this abstraction in this case.
> 
> So I checked, `public_mul` exists but currently does not allow to do this. It allows you to multiply an additiveSharedTensor with a MultiPointerTensor (`other`). So cool extension would be when other is an int or long, convert it in MultiPointerTensor in the public_mul function (l.332 in additive_shared.py)
> This will able you to run:
> 
> ```
> t = torch.tensor([1., 2, 3, 4]).fix_precision().share(alice, bob, crypto_provider=james)
> lr = torch.tensor([0.5]).fix_precision()
> t.child.child.child * lr.child.child
> ```
> 
> Then to have this `t * lr` working you need to modify also `mul` in precision.py

I thought about something like this but I didn't know how to handle the different number of layers for each operand (here, you did it by calling child several times). I wanted to have something where the user only has to call `t * lr` ",could also multiply learning rate scaling factor one used convert something similar integer think better exactly let keep abstraction case checked currently allow multiply cool extension would long convert function able run bob working need modify also thought something like know handle different number operand calling child several time something user call,issue,positive,positive,positive,positive,positive,positive
498165099,"> Or we could also just multiply the learning rate by the scaling factor (same as the one used to convert to FixedPoint) and do something similar to what I did but only with integer values
> Do you think it is better?

This is exactly what FixedPrecision does for you, let's keep this abstraction in this case.


So I checked, `public_mul` exists but currently does not allow to do this. It allows you to multiply an additiveSharedTensor with a MultiPointerTensor (`other`). So cool extension would be when other is an int or long, convert it in MultiPointerTensor in the public_mul function (l.332 in additive_shared.py)
This will able you to run:
``` 
t = torch.tensor([1., 2, 3, 4]).fix_precision().share(alice, bob, crypto_provider=james)
lr = torch.tensor([0.5]).fix_precision()
t.child.child.child * lr.child.child
```
Then to have this `t * lr` working you need to modify also `mul` in precision.py",could also multiply learning rate scaling factor one used convert something similar integer think better exactly let keep abstraction case checked currently allow multiply cool extension would long convert function able run bob working need modify also,issue,positive,positive,positive,positive,positive,positive
498091276,Also please run `black syft`,also please run black,issue,negative,negative,negative,negative,negative,negative
498068577,"Or we could also just multiply the learning rate by the scaling factor (same as the one used to convert to FixedPoint) and do something similar to what I did but only with integer values
Do you think it is better?",could also multiply learning rate scaling factor one used convert something similar integer think better,issue,negative,positive,positive,positive,positive,positive
498068210,"Yes I believe you’re right !
I need to check on my laptop because we have a multiplication between an additivesharing tensor and normal tensor I think and it is called public_mul",yes believe right need check multiplication tensor normal tensor think,issue,negative,positive,positive,positive,positive,positive
498067547,"So instead of what I did, we should enable multiplication between FixedPrecisionTensor > Tensor and FixedPrecisionTensor > AdditiveSharingTensor, which is not currently possible. Am I right?",instead enable multiplication tensor currently possible right,issue,negative,positive,positive,positive,positive,positive
498053839,"@LaRiffle Hey LaRiffle, I was the person who pinged you on Slack.  I see Jasopaum is working on the issue.  I will ping you for more information if I need it.  Thanks!

Note: My username on Slack used to be maxwells_daemon, but I changed it to vghorakavi to help keep things clear.   ",hey person slack see working issue ping information need thanks note slack used help keep clear,issue,positive,positive,positive,positive,positive,positive
498032943,"Okay lesson learned. :) Thanks peeps.
python3 -m pytest test/test_serde.py ",lesson learned thanks python,issue,negative,positive,positive,positive,positive,positive
498031835,Not really @jidroid404 from the previous print-screen error you sent your pytest is running python2.7,really previous error sent running python,issue,negative,negative,negative,negative,negative,negative
498031748,"Oh indeed @amit-rastogi, nice catch!",oh indeed nice catch,issue,negative,positive,positive,positive,positive,positive
498031591,From the error details your python version appears to be 2.7. Could you check with python 3.x? ,error python version could check python,issue,negative,neutral,neutral,neutral,neutral,neutral
498030858,"right... weird...  can you check if you have all the dependencies installed?

run:

```
pip install -r requirements.txt
pip install -r requirements_dev.txt
```",right weird check run pip install pip install,issue,negative,negative,negative,negative,negative,negative
498029439,"@jidroid404 try to run as I described on my previous comment. conftest.py is not a valid unit test, so probably that's why you see the error.

Go to Desktop/PysSyft/ and run pytest test/*

This should execute without errors.
",try run previous comment valid unit test probably see error go run execute without,issue,negative,negative,negative,negative,negative,negative
498028553,"Then throwing off this import error, while running all of the unit tests
![Screenshot from 2019-06-02 18-16-19](https://user-images.githubusercontent.com/43285614/58761590-b6677200-8563-11e9-8ea3-7b4d86c01684.png)

",throwing import error running unit,issue,negative,neutral,neutral,neutral,neutral,neutral
498026919,"Hey @DanyEle - tried your suggestions on part two but still the same error as before; here is the predict function that I was trying to use per your suggestion:

```
def predict(model, input_line, worker, n_predictions=3):
    model = model.copy().get()
    print('\n> %s' % input_line)
    with torch.no_grad():
        model_remote = model.send(worker).copy().get()
        line_tensor = lineToTensor(input_line)
        line_remote = line_tensor.copy().send(worker)
        #line_tensor = lineToTensor(input_line)
        #output = evaluate(model, line_remote)
        # Get top N categories
        hidden = model_remote.initHidden()
        hidden_remote = hidden.copy().send(worker)

        for i in range(line_remote.shape[0]):
            output, hidden_remote = model_remote(line_remote[i], hidden_remote)
        
        topv, topi = output.copy().get().topk(n_predictions, 1, True)
        predictions = []

        for i in range(n_predictions):
            value = topv[0][i].item()
            category_index = topi[0][i].item()
            print('(%.2f) %s' % (value, all_categories[category_index]))
            predictions.append([value, all_categories[category_index]])


```

P.S. For reference, here is the error log:

```


> Qing
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-23-6650cbe85de0> in <module>
      1 
----> 2 predict(model_pointers[""alice""], ""Qing"", alice)
      3 predict(model_pointers[""bob""], ""Qing"", bob)
      4 
      5 predict(model_pointers[""alice""], ""Daniele"", alice)

<ipython-input-22-7031e812578d> in predict(model, input_line, worker, n_predictions)
      3     print('\n> %s' % input_line)
      4     with torch.no_grad():
----> 5         model_remote = model.send(worker).copy().get()
      6         line_tensor = lineToTensor(input_line)
      7         line_remote = line_tensor.copy().send(worker)

/home/src/Programs/miniconda3/envs/federated/lib/python3.6/site-packages/syft/frameworks/torch/hook/hook.py in module_send_(nn_self, dest)
    950 
    951             if module_is_missing_grad(nn_self):
--> 952                 create_grad_objects(nn_self)
    953 
    954             for p in nn_self.parameters():

/home/src/Programs/miniconda3/envs/federated/lib/python3.6/site-packages/syft/frameworks/torch/hook/hook.py in create_grad_objects(model)
    943             for p in model.parameters():
    944                 o = p.sum()
--> 945                 o.backward()
    946                 p.grad -= p.grad
    947 

/home/src/Programs/miniconda3/envs/federated/lib/python3.6/site-packages/syft/frameworks/torch/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
    651                 except BaseException as e:
    652                     # we can make some errors more descriptive with this method
--> 653                     raise route_method_exception(e, self, args, kwargs)
    654 
    655             else:  # means that there is a wrapper to remove

/home/src/Programs/miniconda3/envs/federated/lib/python3.6/site-packages/syft/frameworks/torch/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
    645                 try:
    646                     if isinstance(args, tuple):
--> 647                         response = method(*args, **kwargs)
    648                     else:
    649                         response = method(args, **kwargs)

/home/src/Programs/miniconda3/envs/federated/lib/python3.6/site-packages/torch/tensor.py in backward(self, gradient, retain_graph, create_graph)
    105                 products. Defaults to ``False``.
    106         """"""
--> 107         torch.autograd.backward(self, gradient, retain_graph, create_graph)
    108 
    109     def register_hook(self, hook):

/home/src/Programs/miniconda3/envs/federated/lib/python3.6/site-packages/torch/autograd/__init__.py in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables)
     91     Variable._execution_engine.run_backward(
     92         tensors, grad_tensors, retain_graph, create_graph,
---> 93         allow_unreachable=True)  # allow_unreachable flag
     94 
     95 

RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn

```",hey tried part two still error predict function trying use per suggestion predict model worker model print worker worker output evaluate model get top hidden worker range output topi true range value topi print value value reference error log recent call last module predict predict bob bob predict predict model worker print worker worker model self except make descriptive method raise self else wrapper remove self try response method else response method backward self gradient false self gradient self hook backward flag element require grad,issue,positive,positive,neutral,neutral,positive,positive
498025591,@jidroid404  as @amit-rastogi pointed you should run the file using pytest. Also if you want to run all the unit tests you can cd to the PySyft folder and run: `pytest test/*`,pointed run file also want run unit folder run,issue,negative,neutral,neutral,neutral,neutral,neutral
498007030,"@jidroid404  you can run unit tests using pytest. E.g from inside test folder run the command 
pytest test_serde.py",run unit inside test folder run command,issue,negative,neutral,neutral,neutral,neutral,neutral
498003004,"Did you execute the following command in your pysyft environment? If not, then please run this command and check.

conda install pytorch torchvision -c pytorch",execute following command environment please run command check install,issue,negative,neutral,neutral,neutral,neutral,neutral
498001828,Looks you haven't installed the appropriate version of torch or don't have torch installed in your conda environment. So activate your conda environment and install pytorch. Conda environments are a good way to keep separate dependencies. So if you have had a different version of torch in your system which you usually use. You can still use a specific version of torch separately using virtual environments such as conda.  ,appropriate version torch torch environment activate environment install good way keep separate different version torch system usually use still use specific version torch separately virtual,issue,negative,positive,positive,positive,positive,positive
497990037,"Hey @DanyEle in response to your questions: 

1a. Which version of PySyft are you using on the Raspberry Pi's? How did you install it?
  - PySyft on Raspberry Pi: `syft==0.1.14a1`
      - Installed following your directions in the article you wrote using the commands:

```
git clone https://github.com/OpenMined/PySyft.git
cd PySyft
pip3 install -r requirements.txt
python3 setup.py build
sudo -E python3 setup.py install
```
1b. Which version of PySyft are you using on your laptop? How did you install it?
  - PySyft on laptop running Ubuntu 16.04: `syft==0.1.14a1`
      - Installed via running `pip install syft==0.1.14a1` in a conda python environment (the specific versioning was to match the Raspberry Pi's version of PySyft).


2. Did you try using the model locally by getting it with model.copy().get() at all places where it is used in the predict phase? It may be an issue with the remote execution, so running it locally with native PyTorch would solve it.
   - Trying this now - will update soon. ",hey response version raspberry pi install raspberry pi following article wrote git clone pip install python build python install version install running via running pip install python environment specific match raspberry pi version try model locally getting used predict phase may issue remote execution running locally native would solve trying update soon,issue,negative,negative,neutral,neutral,negative,negative
497981696,"No, I don’t think you’re too picky and  changing the learning rate to Fixed Precision should be enough!
I can close this PR, then",think picky learning rate fixed precision enough close,issue,negative,positive,neutral,neutral,positive,positive
497979039,"This issue #2214 is related
And #2219 attempts to give fix.",issue related give fix,issue,negative,neutral,neutral,neutral,neutral,neutral
497978967,"I see your point, but you should probably also convert the learning rate into fixed precision if you want to be coherent int terms of spaces you're operating in, even if in this specific case it is not elegant because we're used to lr being a float. So what I would suggest is having the lr being ""only"" FixedPrecision but operating with AdditiveSharedTensor.

But maybe I'm being too picky ahah - it's just that when we're dealing with the crypto protocols, if we change the usage and hypothesis we also change the guarantees in terms of security.",see point probably also convert learning rate fixed precision want coherent operating even specific case elegant used float would suggest operating maybe picky dealing change usage hypothesis also change security,issue,positive,positive,positive,positive,positive,positive
497973545,"Hi, I'm glad to know you're actually trying my code for Raspberry Pis and that it all seems to be running up to the last point. I have two questions:

1. Which version of PySyft are you using on the Raspberry PIs and on  your laptop?  How did you install it?

2. Did you try using the model locally by getting it with model.copy().get() at all places where it is used in the predict phase? It may be an issue with the remote execution, so running it locally with native PyTorch would solve it.",hi glad know actually trying code raspberry running last point two version raspberry install try model locally getting used predict phase may issue remote execution running locally native would solve,issue,positive,positive,neutral,neutral,positive,positive
497954369,"Oh yes of course!
You have given to your optimizer the parameters of the original model, not of the copy, thats why the copy of the model doesn't improve.
Another thing is that during an epoch, you only send once the model to the first worker, so when you will have data batches owned by the other worker, it will fail.

I believe this Issue is solved, if you have other issues related to your use case, please let us know!",oh yes course given original model copy thats copy model improve another thing epoch send model first worker data worker fail believe issue related use case please let u know,issue,positive,positive,neutral,neutral,positive,positive
497886480,"I agree with @iamtrask, I'll close this issue for now and re-open it at [Grid](https://github.com/OpenMined/Grid/)",agree close issue grid,issue,negative,neutral,neutral,neutral,neutral,neutral
497881920,"It was for training a model encrypted via additive sharing MPC. Specifically, we would need a float learning rate in gradient descent. But maybe we can find another way?",training model via additive specifically would need float learning rate gradient descent maybe find another way,issue,negative,neutral,neutral,neutral,neutral,neutral
497842076,Solving this might be moree of a Grid project than a PySyft one - primarily because it will require two people to be able to connect to the same worker and interact with the same tensors on that worker. This requires things like user roles and permission and managing multiple connections.,might grid project one primarily require two people able connect worker interact worker like user permission multiple,issue,negative,positive,positive,positive,positive,positive
497805077,"What is the use case for this?
By default, as (partially) explained in #2176, I'm opposed to mixing FixedPrecisionTensors with floats scalars, because FixedPrecisionTensors represent objects in a finite field where it is impossible to consider the notion of floats.

Bu if there is a case where it makes sense, then I'm open to hear about it :)",use case default partially opposed represent finite field impossible consider notion bu case sense open hear,issue,negative,negative,negative,negative,negative,negative
497785282,"The reason of this error is that with virtualworkers, a `syft.exceptions.ResponseSignatureError` is sent back from servers workers to the client, which is not supported by socketworkers.
Maybe we would like to handle Exception forwarding through some serialization process.",reason error sent back client maybe would like handle exception forwarding serialization process,issue,negative,neutral,neutral,neutral,neutral,neutral
497761385,"Sure, I will!
But I also wanted to know if someone has an idea for a better implementation ",sure also know someone idea better implementation,issue,positive,positive,positive,positive,positive,positive
497735234,"Run the whole code by replacing ""bobmodel=model.send(data.location)"" with ""bobmodel=model.copy().send(data.location)"" you see that loss is not decreasing for latter case.",run whole code see loss decreasing latter case,issue,negative,positive,neutral,neutral,positive,positive
497717731,"[`Link`](https://drive.google.com/file/d/1CnvBwgLMd4W1jtXlT2PBRuGjWQBmHpV0/view?usp=sharing)
If you change this line ""bobmodel=model.send(data.location)"" to ""bobmodel=model.copy().send(data.location)"" then loss is not decreasing.",link change line loss decreasing,issue,negative,neutral,neutral,neutral,neutral,neutral
497717477,@robert-wagner I'd love to have your view on this point (namely we have a method which could apply for the pointer object AND the point target),love view point namely method could apply pointer object point target,issue,positive,positive,positive,positive,positive,positive
497712040,"This will be complicated as is, because .size() is used in many places to get informations about the current object and not to what it's pointing at. (like torch.save())

Namely we would like to have `t.size() == torch.Size([0])` for `t = torch.tensor([1, 2, 3, 4]).send(bob)` while .shape is used to look at the target object so `t.shape == torch.Size([4])`",complicated used many get current object pointing like namely would like bob used look target object,issue,positive,neutral,neutral,neutral,neutral,neutral
497710211,"Hey, if you have the whole code I'd love to see it to better understand our use case. Should I infer that all the data is owned by bob, as you only the model once per epoch and to bob?

Also, you should update `pytorch=1.0.1 -> pytorch=1.1` and `pysyft=0.1.13 -> pysyft=0.1.15a1`; many changes are happening currently :)",hey whole code love see better understand use case infer data bob model per epoch bob also update many happening currently,issue,positive,positive,positive,positive,positive,positive
497709912,"> > @LaRiffle It actually was breaking for me. Had a long talk with @mortendahl and @jvmancuso about it yesterday evening and this seemed to be the most reasonable fix for now
> 
> Maybe we should file an Issue about it to address this, it's an important limitation

done #2208 ",actually breaking long talk yesterday evening reasonable fix maybe file issue address important limitation done,issue,negative,positive,positive,positive,positive,positive
497706525,"> @LaRiffle It actually was breaking for me. Had a long talk with @mortendahl and @jvmancuso about it yesterday evening and this seemed to be the most reasonable fix for now

Maybe we should file an Issue about it to address this, it's an important limitation",actually breaking long talk yesterday evening reasonable fix maybe file issue address important limitation,issue,negative,positive,positive,positive,positive,positive
497706148,@LaRiffle It actually was breaking for me. Had a long talk with @mortendahl and @jvmancuso about it yesterday evening and this seemed to be the most reasonable fix for now,actually breaking long talk yesterday evening reasonable fix,issue,negative,positive,neutral,neutral,positive,positive
497653925,"> > Travis fails due to bug in torch version 1.1.0
> 
> This is surprising since I thought Travis built using Torch version 1.0.1

My bad Andrew I told you smthg wrong, Travis will fetch the latest version (but with requirement >=1.0.1) so it will get 1.1",travis due bug torch version surprising since thought travis built torch version bad told wrong travis fetch latest version requirement get,issue,negative,negative,neutral,neutral,negative,negative
497641134,"> Travis fails due to bug in torch version 1.1.0

This is surprising since I thought Travis built using Torch version 1.0.1",travis due bug torch version surprising since thought travis built torch version,issue,negative,positive,positive,positive,positive,positive
497611801,"Hey, someone pinged me in slack about this Issue but Slack isn't very good to save un-responded message threads (https://superuser.com/questions/1199066/why-is-my-slack-dm-list-incomplete) so I lost _you_!
I would be glad to give me info but basically: moving to fixed precision is a constraint of the crypto protocols we use for additive sharing. This means that **everything** which needs to be secret shared should be in fixed precision (not only the neural network weights). Otherwise this violate the guarantees of correctness of the secret sharing protocols.
Note that you can still broadcast non private values with `.send(*workers)` which creates a MultiPointerTensor instead of an AdditiveSharedTensor. In that case it can be a float, as long as you don't want to operate it with AdditiveSharedTensors.",hey someone slack issue slack good save message lost would glad give basically moving fixed precision constraint use additive everything need secret fixed precision neural network otherwise violate correctness secret note still broadcast non private instead case float long want operate,issue,positive,positive,neutral,neutral,positive,positive
497608736,Fixed the remaining issues with the dim() method and the test cases not passing. Should be good to be merged now!,fixed dim method test passing good,issue,negative,positive,positive,positive,positive,positive
497458160,"> Travis fails due to bug in torch version 1.1.0

What exactly is the bug?",travis due bug torch version exactly bug,issue,negative,positive,neutral,neutral,positive,positive
497422039,Travis fails due to bug in torch version 1.1.0,travis due bug torch version,issue,negative,negative,negative,negative,negative,negative
497391703,"Hey @LaRiffle,

the description is not clear to me, is there a problem with conftest.py or is it an issue inside syft?",hey description clear problem issue inside,issue,negative,positive,positive,positive,positive,positive
497390782,"The decision for now is: 

* plans will not be implemented using jit because we need to support syft tensors and operations inside of plans (for our best knowledge at this point we would need to change c++ code in order to do so).

* jit modules are super nice for regular FL (non-encrypted FL) so we'll support it (#2169).",decision need support inside best knowledge point would need change code order super nice regular support,issue,positive,positive,positive,positive,positive,positive
497301125,An instance of a jit.ScriptModule provides you directly with a serializable respresentation. You don't need to provide data to trace the model. ,instance directly need provide data trace model,issue,negative,positive,neutral,neutral,positive,positive
497161963,@midokura-silvia do you have a scenario where we want to use jit.ScriptModule instead of jit.trace?,scenario want use instead,issue,negative,neutral,neutral,neutral,neutral,neutral
497155022,"Hey @RunshanHu ,

I've just executed it with pysyft most updated version (dev branch) and pytorch 1.1 and 1.0.1 with no errors.

Can you check if you have all the correct/updated dependencies installed?

Feel free to ping me on slack if you continue to have problems, closing it for now.",hey executed version dev branch check feel free ping slack continue,issue,positive,positive,positive,positive,positive,positive
497106594,"I fixed this by running

```
pip uninstall numpy
```

and then from Syft's home directory I ran

```python setup.py install```

and then I could import syft again.",fixed running pip home directory ran python install could import,issue,negative,positive,neutral,neutral,positive,positive
497096388,"Thanks for the review! I will modify the code and create a new PR.

For the additively shared floats, they actually were not floats but int tensors that's why it worked when I shared them. Do you still think we should remove conv2d from AdditivelySharingTensor? Maybe the users would like to share int tensors without using the fix_prec intermediary (I don't know if this makes sense).",thanks review modify code create new additively actually worked still think remove maybe would like share without intermediary know sense,issue,positive,positive,positive,positive,positive,positive
496947945,"> Why are polynomial tensor files commented?

The test is failing in very unexpected ways (some kind of segfault which I couldn't track down).

Also, the rest of the codebase isn't yet using it, and it likely needs significant refactoring before the reset of the codebase can use it. In particular, it's not yet actually a tensor type, it's a class with static functions. We can revisit it after the course is released.",polynomial tensor test failing unexpected way kind could track also rest yet likely need significant reset use particular yet actually tensor type class static revisit course,issue,negative,positive,positive,positive,positive,positive
496888309,"Ah I said it is a really good PR!
From the tests I observed something is not clear - you can (should) never share additively floats (well in theory because you succeeded here ahah). Float should be converted to fixedprecision tensors
This way, you actually need to define conv2d only in fixed_precision.py not in additive_shared.py (I just tried it it works). This avoids duplicate code.
Also, the code in conv2d is really tricky to understand, you might want to add a few comments to explain how you transform your data to do the convolution in a single matrix multiplication, or link any useful reference.",ah said really good something clear never share additively well theory float converted way actually need define tried work duplicate code also code really tricky understand might want add explain transform data convolution single matrix multiplication link useful reference,issue,positive,positive,positive,positive,positive,positive
496831128,"> def dim(self):
>     for share in self.child.values():
>         return len(share.shape)

I've implemented that. However, the following tests are still not passing:

 test/torch/tensors/test_additive_shared.py::test_nn_linear FAILED        [ 55%]

test/torch/tensors/test_precision.py::test_torch_nn_functional_linear FAILED [ 92%]

You may check the issues in the latest committed version.",dim self share return however following still passing may check latest version,issue,negative,positive,positive,positive,positive,positive
496824244,"> I looked into the remaining two tests not passing, and they seem to be related to AdditiveSharedTensors not having the dim() method. I tried to implement as:
> 
> ```
> def dim(self):
>         sum_dim = 0
>         for share in self.child.values():
>             sum_dim += len(share.shape)
>         return sum_dim
> ```
> 
> But this does not seem to be working. Any suggestions on how to implement the dim() method for AdditiveSharedTensors?

Why do you sum for all the shares? I think this should work:
```
def dim(self):
    for share in self.child.values():
        return len(share.shape)
```",two passing seem related dim method tried implement dim self share return seem working implement dim method sum think work dim self share return,issue,positive,positive,neutral,neutral,positive,positive
496811174,"I looked into the remaining two tests not passing, and they seem to be related to AdditiveSharedTensors not having the dim() method. I tried to implement as:
```
def dim(self):
        sum_dim = 0
        for share in self.child.values():
            sum_dim += len(share.shape)
        return sum_dim
```

But this does not seem to be working. Any suggestions on how to implement the dim() method for AdditiveSharedTensors?",two passing seem related dim method tried implement dim self share return seem working implement dim method,issue,negative,positive,neutral,neutral,positive,positive
496744578,"> Create a new unit test function for testing transform

Done :) ",create new unit test function testing transform done,issue,negative,positive,positive,positive,positive,positive
496639916,Uhm... It looks like all tests related to remote websockets are now failing. What did I break?,like related remote failing break,issue,negative,negative,neutral,neutral,negative,negative
496599780,"Another point: maybe first start with operate together tensors of the same dimension, which is determined by the precision parameter. This will give you tensors fo the same size which is helpful. This size will be determined by the values allocated for the decimal numbers (directly linked the precision parameter) and the values of the integers part, which you can first say it's only the size of a single LongTensor, and we'll add a integer precision parameter for it as well later, as we used to have before fore fixed precision tensors (https://github.com/OpenMined/PySyft/commit/32dc45160a7bce78dc1dbe750974b548eba26117#diff-eee9ccaf3c5a0ebc4cf135d97bbd3fbb)",another point maybe first start operate together dimension determined precision parameter give size helpful size determined decimal directly linked precision parameter part first say size single add integer precision parameter well later used fore fixed precision,issue,positive,positive,positive,positive,positive,positive
496597437,"Hey @mccorby I'm looking into it right now,
I think you're doing the right thing no worries :)
So actually it would be in a chain where indeed the head would be a `torch.Tensor`, but maybe in this kind of way: I have torch.tensor([3.0]) which I want to express in fixed precision with fixed_precision=512 (stupid but why not). In that case, the head is that torch.tensor and below I get the LargePrecisionTensor",hey looking right think right thing actually would chain indeed head would maybe kind way want express fixed precision stupid case head get,issue,negative,positive,neutral,neutral,positive,positive
496547227,"Hey @JonathanChiang,

I'm not aware of anyone working on it, but I don't see a specific reason why one couldn't use sklearn to federated learning.

To use syft you will need some kind of hook process (check torch/hook/) make syft tensors and operations compatible with sklearn. 

I'll close this issue, for now, feel free to reach out on slack if you have more questions.",hey aware anyone working see specific reason one could use learning use need kind hook process check make compatible close issue feel free reach slack,issue,positive,positive,positive,positive,positive,positive
496163445,"Travis is failing due to a problem with torch 1.1.0, unit tests run through with torch 1.0.1.
See pytorch issue 20017, a fix was merged in pytorch via pull request 20386",travis failing due problem torch unit run torch see issue fix via pull request,issue,negative,negative,negative,negative,negative,negative
495991139,"_Disclaimer: I needed this running (asap) to train a large-ish dataset on GPU, so it's more like a hacky workaround than an actual solution, but I'll be happy if it helps anyone with the same problem. Or can be used to build up a proper fix._ 

So I was experiencing the same problem as @jopasserat . I think the problem was that the function that handles function commands in hooks.py needed to convert a _non-tensor_ to a _torch.tensor_ , but this exception was not contemplated. So basically I am catching the `IndexError` that happens in those cases. 

Apart from that I'm using `torch.set_default_tensor_type(torch.cuda.FloatTensor)`. I tried to convert the non-cuda tensors to cuda but for some reason in the wrapped tensors `.to()` method doesn't seem to work for me. So unless I set it to default I get the problem @bhushan23 was mentioning. Plus, I need to set the `num_workers=0` (I think the method has been overwritten so it does not run anymore) and `pin_memory=False` (as that will only work with dense CPU tensors).",running train like hacky actual solution happy anyone problem used build proper problem think problem function function convert exception basically catching apart tried convert reason wrapped method seem work unless set default get problem plus need set think method run work dense,issue,negative,positive,positive,positive,positive,positive
495909280,"I've been doing some progress on this issue (see https://github.com/OpenMined/PySyft/pull/2147/) but I'm not sure I am going in the right direction.
There are a few things I'm finding for which I'd like some input:
- Am I overcomplicated things :) ?
- A `torch.Tensor` can't be at the head in the chain. If this would be possible we wouldn't need this class!
- I'm using `.child` to hold the tensor generated from the original array. Not sure if this is correct
- The input is now a `np.array`. Numpy arrays can hold very big numbers as `object`s
- Numbers of different sizes are decomposed into tensors of different dimensions. There is a function that fill up the number with the minor last dimension so that the tensors can be operated with. 
- Multiplication is still to be done and I'm trying to figure out how to do it

It'd be good to have a scenario where these tensors could be put to work. If anyone can provide with one I would be happy to make it work (if all the above is still valid!)

Cheers",progress issue see sure going right direction finding like input ca head chain would possible would need class hold tensor original array sure correct input hold big object different size decomposed different function fill number minor last dimension multiplication still done trying figure good scenario could put work anyone provide one would happy make work still valid,issue,positive,positive,positive,positive,positive,positive
495697651,They are now almost removed except one,almost removed except one,issue,negative,neutral,neutral,neutral,neutral,neutral
495689475,Where can they be found precisely? I'm not sure I've seen them,found precisely sure seen,issue,negative,positive,positive,positive,positive,positive
495539507,"For this small example it is sufficient to exclude torch.nn.linear from the hooking process.
in the function syft.frameworks.torch.hook.hook.TorchHook._hook_torch_module :
```
# ignore linear
if func == ""linear"":
  continue
```
However, we should understand what happens during the hooking process that is incompatible with jit.",small example sufficient exclude process function ignore linear linear continue however understand process incompatible,issue,negative,negative,negative,negative,negative,negative
495335767,"Added back the test cases in https://github.com/OpenMined/PySyft/pull/1995/files

Note that once the tensor.dim() method is implemented for remote tensors in PySyft, also the forward pass into standard LSTMs is going to work.",added back test note method remote also forward pas standard going work,issue,negative,negative,neutral,neutral,negative,negative
494784501,I think I have mistakenly deleted the Jupyter Notebook I created in my last Pull Request. My bad! I will also need to fix the formatting.,think mistakenly notebook last pull request bad also need fix,issue,negative,negative,negative,negative,negative,negative
494392034,The first usecase of the new pointers is to send a torch.jit.ScriptModule to a worker.,first new send worker,issue,negative,positive,positive,positive,positive,positive
494362415,"Hey @songchuangyuan,

I've just executed the notebook using PySyft most current version (dev branch) and it works.

Can you check if you're using an updated version of PySyft and re-run the notebook? Thanks!",hey executed notebook current version dev branch work check version notebook thanks,issue,negative,positive,neutral,neutral,positive,positive
494120908,"Question: can we re-use torch jit's implementation of [serialization](https://pytorch.org/docs/stable/jit.html#torch.jit.save) and still work PySyft specific tensors?

I believe ideally the operations performed by scriptModules would automatically adapt based on the input tensor (a.k.a if an encrypted tensor is given the output should also be an encrypted tensor), not sure if this would work out of the box.",question torch implementation serialization still work specific believe ideally would automatically adapt based input tensor tensor given output also tensor sure would work box,issue,positive,positive,positive,positive,positive,positive
494005150,I would suggest upgrade everyone to 1.1 so that we avoid cases where we have different behaviours depending of the version,would suggest upgrade everyone avoid different depending version,issue,negative,neutral,neutral,neutral,neutral,neutral
493954742,"> Hey @alhparsa, thanks for the PR!!! Nice job!!!
> 
> FYI: pysyft is now using the [google style for docstrings](https://sphinxcontrib-napoleon.readthedocs.io/en/latest/example_google.html). So the docstrings you've added need to be changed in order to generate proper documentation.

Thanks, ya I wasn't sure which style is being used. thanks for providing a link to it, I will update the files accordingly in the next commits. I submitted the pr as a draft to discuss the implementation of few things. 

Firstly, would you it be better if `PaillierEncryption` class is added as an attribute to the worker or should be kept separately. This way, the need for passing `encrypted_tensor list` as a parameter for arithmetic operations would be obsolete, which means they can overload the `AbstractTensor`'s. 

Secondly, any ideas for `matmul`? I don't think implementing it from scratch using python would be a great idea, it would be pretty slow compared to `torch`'s. Does anyone know if it uses `torch`'s  regular multiplication under the hood? if it does, by overriding that the problem would be solved. 

Thirdly, there is currently a problem with overloading. The best usage of Paillier's is if the provided tensor is type `torch.LongTensor`. I think we should wait for #2145 to be merged so it can be used properly. Because, the sweet spot I found is length 14, which allows for couple of arithmetic operations. The greatest length for encryption can be used is 30 I think but just for encryption. They can be easy cracked. ",hey thanks nice job style added need order generate proper documentation thanks ya sure style used thanks providing link update accordingly next draft discus implementation firstly would better class added attribute worker kept separately way need passing list parameter arithmetic would obsolete overload secondly think scratch python would great idea would pretty slow torch anyone know torch regular multiplication hood problem would thirdly currently problem best usage provided tensor type think wait used properly sweet spot found length couple arithmetic length encryption used think encryption easy cracked,issue,positive,positive,positive,positive,positive,positive
493952747,"Hey @alhparsa, thanks for the PR!!! Nice job!!!

FYI: pysyft is now using the [google style for docstrings](https://sphinxcontrib-napoleon.readthedocs.io/en/latest/example_google.html). So the docstrings you've added need to be changed in order to generate proper documentation.",hey thanks nice job style added need order generate proper documentation,issue,positive,positive,positive,positive,positive,positive
493888815,"Hello @mari-linhares,

I am working on this issue.
Thanks,",hello working issue thanks,issue,negative,positive,positive,positive,positive,positive
493766492,Maybe you could start by enforcing similar precision just as we might have done for FixedPrecision tensors?,maybe could start similar precision might done,issue,negative,neutral,neutral,neutral,neutral,neutral
493711434,It was passing before change the requirements.txt so I assume it works :),passing change assume work,issue,negative,neutral,neutral,neutral,neutral,neutral
493662725,Could padding be a solution in your case? I mean casting n2 in 2^128 with all the MSB at 0,could padding solution case mean casting,issue,negative,negative,negative,negative,negative,negative
493659246,"What should we do when two `LargePrecisionTensor`s represent numbers of different precision?
For example, let n1 in 2^128 and n2 in 2^64 and objective bits 32
This will result in two matrices with different dimensions: matrix_n1 1x4 and matrix_n2 1x2. 

I can find a way of doing (finding the offset and then only taking into account relevant cells but it will be cumbersome and slow). So if anyone can give me a hint, more than welcomed!

",two represent different precision example let objective result two matrix different find way finding offset taking account relevant cumbersome slow anyone give hint,issue,negative,positive,neutral,neutral,positive,positive
493656835,"Appending these two lines at the end of the hook.py file adds support for LSTM/GRU cells and GRUs:

```
 #Daniele: added GRUs
self.torch.nn.modules.rnn._rnn_impls[""GRU""] = self.torch.gru

##Daniele:override _VF.LSTM_Cell and _VF.GRU_Cell with torch.LSTM_Cell and torch.GRU_Cell
self.torch.nn.modules.rnn._VF = self.torch
```

This fix works fine with virtual workers, but it does not seem to be compatible with actual websockets.",two end file support added override fix work fine virtual seem compatible actual,issue,positive,positive,positive,positive,positive,positive
493227151,@SohamMazumder We haven't hooked BatchNorm yet. So you will have to stick to Linear and CNN layers till then :/ ,hooked yet stick linear till,issue,negative,neutral,neutral,neutral,neutral,neutral
492819120,"As discussed with @DanyEle this is due to error while merging the code, this branch is broken after https://github.com/OpenMined/PySyft/pull/1995/commits/dc849169cfc18aa1b1c70c76fe3d9f7676f69a66",due error code branch broken,issue,negative,negative,negative,negative,negative,negative
492672574,"The unit test issue is solved in #2143. 
The hook had already stored values for 'Tensor.backward', as backward() is used in the unit test test/syft_torch/test_hook.py::test_RNN_grad_set_backpropagation.",unit test issue hook already backward used unit test,issue,negative,neutral,neutral,neutral,neutral,neutral
492430692,"This issue is breaking [tutorial 8](examples/tutorials/Part%208%20-%20Federated%20Learning%20on%20MNIST%20using%20a%20CNN.ipynb) at the moment when used with CUDA.

[Python 3.7, PySyft from master branch]

I've tried to apply @mari-linhares 's [workaround](https://github.com/OpenMined/PySyft/issues/1893#issuecomment-478717757) to no success so far:
  - when set after distributing the dataset, the instruction crashes with `IndexError: list index out of range`

```
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
/home/xxx/PySyft/venv/lib/python3.7/site-packages/syft-0.1.14a1-py3.7.egg/syft/frameworks/torch/hook/hook_args.py in hook_function_args(attr, args, kwargs, return_args_type)
    135         # TODO rename registry or use another one than for methods
--> 136         hook_args = hook_method_args_functions[attr]
    137         get_tensor_type_function = get_tensor_type_functions[attr]

KeyError: 'torch.set_default_tensor_type'

During handling of the above exception, another exception occurred:

IndexError                                Traceback (most recent call last)
<ipython-input-6-fb50db14b868> in <module>
      3 if device.type == ""cuda"":
      4   os.environ[""CUDA_VISIBLE_DEVICES""] = ""0""
----> 5   torch.set_default_tensor_type(torch.cuda.FloatTensor)

/home/xxx/PySyft/venv/lib/python3.7/site-packages/syft-0.1.14a1-py3.7.egg/syft/frameworks/torch/hook/hook.py in overloaded_func(*args, **kwargs)
    691             cmd_name = f""{attr.__module__}.{attr.__name__}""
    692             command = (cmd_name, None, args, kwargs)
--> 693             response = TorchTensor.handle_func_command(command)
    694             return response
    695 

/home/xxx/PySyft/venv/lib/python3.7/site-packages/syft-0.1.14a1-py3.7.egg/syft/frameworks/torch/tensors/interpreters/native.py in handle_func_command(cls, command)
    191             # Note that we return also args_type which helps handling case 3 in the docstring
    192             new_args, new_kwargs, new_type, args_type = syft.frameworks.torch.hook_args.hook_function_args(
--> 193                 cmd, args, kwargs, return_args_type=True
    194             )
    195             # This handles case 3: it redirects the command to the appropriate class depending

/home/xxx/PySyft/venv/lib/python3.7/site-packages/syft-0.1.14a1-py3.7.egg/syft/frameworks/torch/hook/hook_args.py in hook_function_args(attr, args, kwargs, return_args_type)
    141     except (IndexError, KeyError, AssertionError):  # Update the function in case of an error
    142         args_hook_function, get_tensor_type_function = build_hook_args_function(
--> 143             args, return_tuple=True
    144         )
    145         # Store the utility functions in registries

/home/xxx/PySyft/venv/lib/python3.7/site-packages/syft-0.1.14a1-py3.7.egg/syft/frameworks/torch/hook/hook_args.py in build_hook_args_function(args, return_tuple)
    171     # Build a function with this rule to efficiently the child type of the
    172     # tensor found in the args
--> 173     get_tensor_type_function = build_get_tensor_type(rule)
    174     return args_hook_function, get_tensor_type_function
    175 

/home/xxx/PySyft/venv/lib/python3.7/site-packages/syft-0.1.14a1-py3.7.egg/syft/frameworks/torch/hook/hook_args.py in build_get_tensor_type(rules, layer)
    392 
    393     if first_layer:
--> 394         return lambdas[0]
    395     else:
    396         return lambdas

IndexError: list index out of range
```

  - when set right after `import torch`, data distribution fails with `RuntimeError: expected type torch.FloatTensor but got torch.cuda.FloatTensor`

```
RuntimeError                              Traceback (most recent call last)
<ipython-input-8-4085cd6569bc> in <module>
      5                        transforms.Normalize((0.1307,), (0.3081,))
      6                    ]))
----> 7     .federate((bob, alice)), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset
      8     batch_size=args.batch_size, shuffle=True, **kwargs)
      9 

/home/xxx/PySyft/venv/lib/python3.7/site-packages/syft-0.1.14a1-py3.7.egg/syft/frameworks/torch/federated/dataset.py in dataset_federate(dataset, workers)
     89     datasets = []
     90     data_loader = torch.utils.data.DataLoader(dataset, batch_size=data_size)
---> 91     for dataset_idx, (data, targets) in enumerate(data_loader):
     92         worker = workers[dataset_idx % len(workers)]
     93         logger.debug(""Sending data to worker %s"", worker.id)

/home/xxx/PySyft/venv/lib/python3.7/site-packages/torch/utils/data/dataloader.py in __next__(self)
    613         if self.num_workers == 0:  # same-process loading
    614             indices = next(self.sample_iter)  # may raise StopIteration
--> 615             batch = self.collate_fn([self.dataset[i] for i in indices])
    616             if self.pin_memory:
    617                 batch = pin_memory_batch(batch)

/home/xxx/PySyft/venv/lib/python3.7/site-packages/torch/utils/data/dataloader.py in <listcomp>(.0)
    613         if self.num_workers == 0:  # same-process loading
    614             indices = next(self.sample_iter)  # may raise StopIteration
--> 615             batch = self.collate_fn([self.dataset[i] for i in indices])
    616             if self.pin_memory:
    617                 batch = pin_memory_batch(batch)

/home/xxx/PySyft/venv/lib/python3.7/site-packages/torchvision/datasets/mnist.py in __getitem__(self, index)
     93 
     94         if self.transform is not None:
---> 95             img = self.transform(img)
     96 
     97         if self.target_transform is not None:

/home/xxx/PySyft/venv/lib/python3.7/site-packages/torchvision/transforms/transforms.py in __call__(self, img)
     58     def __call__(self, img):
     59         for t in self.transforms:
---> 60             img = t(img)
     61         return img
     62 

/home/xxx/PySyft/venv/lib/python3.7/site-packages/torchvision/transforms/transforms.py in __call__(self, tensor)
    161             Tensor: Normalized Tensor image.
    162         """"""
--> 163         return F.normalize(tensor, self.mean, self.std, self.inplace)
    164 
    165     def __repr__(self):

/home/xxx/PySyft/venv/lib/python3.7/site-packages/torchvision/transforms/functional.py in normalize(tensor, mean, std, inplace)
    206     mean = torch.tensor(mean, dtype=torch.float32)
    207     std = torch.tensor(std, dtype=torch.float32)
--> 208     tensor.sub_(mean[:, None, None]).div_(std[:, None, None])
    209     return tensor
    210 

/home/xxx/PySyft/venv/lib/python3.7/site-packages/syft-0.1.14a1-py3.7.egg/syft/frameworks/torch/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
    637                 except BaseException as e:
    638                     # we can make some errors more descriptive with this method
--> 639                     raise route_method_exception(e, self, args, kwargs)
    640 
    641             else:  # means that there is a wrapper to remove

/home/xxx/PySyft/venv/lib/python3.7/site-packages/syft-0.1.14a1-py3.7.egg/syft/frameworks/torch/hook/hook.py in overloaded_native_method(self, *args, **kwargs)
    631                 try:
    632                     if isinstance(args, tuple):
--> 633                         response = method(*args, **kwargs)
    634                     else:
    635                         response = method(args, **kwargs)

RuntimeError: expected type torch.FloatTensor but got torch.cuda.FloatTensor
```

This might also break other tutorials when using GPUs, have not tried yet.",issue breaking tutorial learning moment used python master branch tried apply success far set instruction list index range recent call last rename registry use another one handling exception another exception recent call last module command none response command return response command note return also handling case case command appropriate class depending except update function case error store utility build function rule efficiently child type tensor found rule return layer return else return list index range set right import torch data distribution type got recent call last module bob new distribute across data enumerate worker sending data worker self loading index next may raise batch index batch batch loading index next may raise batch index batch batch self index none none self self return self tensor tensor tensor return tensor self normalize tensor mean mean mean mean none none none none return tensor self except make descriptive method raise self else wrapper remove self try response method else response method type got might also break tried yet,issue,positive,positive,neutral,neutral,positive,positive
492214519,"Trying this code in an actual environment after installing the code in the branch ""lstm"", but I get the following  error when trying to send a tensor pointer to a worker. To replicate:

```
import syft as sy
import torch

hook = sy.TorchHook(torch)
alice = sy.VirtualWorker(hook, id=""alice"")
random_tensor = torch.randn(5,3)

tensor_sent = random_tensor.send(alice)
```

![image](https://user-images.githubusercontent.com/4907418/57697471-970bb200-7653-11e9-82fe-d3948d85f94d.png)

The weird thing is that the corresponding test in test_hook.py is actually passing and when executing that code snippet from within the PySyft directory, no issue occurs.

",trying code actual environment code branch get following error trying send tensor pointer worker replicate import import torch hook torch hook image weird thing corresponding test actually passing code snippet within directory issue,issue,negative,negative,negative,negative,negative,negative
491629043,Well done Victor!! Welcome to OpenMined :),well done victor welcome,issue,positive,positive,positive,positive,positive,positive
491617518,"Thanks for trying @pkc-harry!

Probably it was the syft version... I don't think it was numpy.",thanks trying probably version think,issue,negative,positive,positive,positive,positive,positive
491583243,"I've done a near identical build from scratch.

test/workers/test_worker.py::test_get_unknown_worker PASSED                                                                                                     [ 99%]
test/workers/test_worker.py::test_search PASSED                                                                                                                   [100%]
=============================================================== 236 passed, 12 warnings in 59.35 seconds ================================================================
Well it gets me moving, but doesn't identify the original  problem.  On a web search, I've noticed a few  'illegal instruction' errors logged with python modules. 
@mari-linhares : I'll carry on checking this out, but I don't expect a solution soon. Ta !

Modules as above, but syft (0.1.14a1). numpy (1.16.3)

",done near identical build scratch well moving identify original problem web search instruction logged python carry expect solution soon ta,issue,negative,positive,positive,positive,positive,positive
491196801,"Any more opinions out there? 
@robert-wagner wrote:

> Traditionally the client is the one who calls commands. I would prefer if we moved away from the terms client and server regardless as they seem to add confusion. 

As a new option, we could also remove the word client and name the classes:
WebsocketProxy + WebsocketWorker

In my opinion the original naming WebsocketServerWorker and WebsocketClientWorker is confusing, as you think of setting up a federated training where client and server have different meanings.",wrote traditionally client one would prefer away client server regardless seem add confusion new option could also remove word client name class opinion original naming think setting training client server different,issue,negative,positive,positive,positive,positive,positive
490909405,"Sure.
I cleared out all other installs and tried it with

torch (1.0.1)
torchvision (0.2.2.post3)
syft (0.1.13a1)

same error resulting. [test/federated/test_plan.py::test_plan_built_on_method Illegal instruction]",sure tried torch post error resulting illegal instruction,issue,negative,neutral,neutral,neutral,neutral,neutral
490900833,"LGTM, I'll have a closer look later today.",closer look later today,issue,negative,neutral,neutral,neutral,neutral,neutral
490896550,@pkc-harry can you install torch 1.0.1 instead of torch 1.0.1.post2 and try it out?,install torch instead torch post try,issue,negative,neutral,neutral,neutral,neutral,neutral
490781805,"Added the default message about PySyft at the end of the Jupyter Notebook, improved some explanatory text and applied the other changes requested.",added default message end notebook explanatory text applied,issue,negative,neutral,neutral,neutral,neutral,neutral
490685889," ======================================================================
I've tried a local install and I'm getting ..
ERROR: syft 0.1.14a1 has requirement torch==1.0.1, but you'll have torch 1.0.1.post2 which is incompatible.
torch               1.0.1.post2


Then I did the torchvision install and got...
torch                1.1.0      
torchvision         0.2.2.post3
ERROR: syft 0.1.14a1 has requirement torch==1.0.1, but you'll have torch 1.1.0 which is incompatible.

no syft !
",tried local install getting error requirement torch post incompatible torch post install got torch post error requirement torch incompatible,issue,negative,neutral,neutral,neutral,neutral,neutral
490639593,"Hey @avitalsh,

> I assume it has to do with the fact that conv2D supports float tensors, where SMPC works on integers (so we use .fix_prec()).

I've just tried and I think this is the case as well..

> Is there a way to solve this issue and to perform secure inference with convolutional neural networks?

Yes, feel free to create a PR!",hey assume fact float work use tried think case well way solve issue perform secure inference convolutional neural yes feel free create,issue,positive,positive,positive,positive,positive,positive
490597782,"Oh @DanyEle, can you also add at the end of the tutorial the default message about pysyft, like it was done [here](https://render.githubusercontent.com/view/ipynb?commit=8083f73cde594de6de2c0435555dcd160c25be70&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f4f70656e4d696e65642f5079537966742f383038336637336364653539346465366465326330343335353535646364313630633235626537302f6578616d706c65732f7475746f7269616c732f50617274253230312532302d2532305468652532304261736963253230546f6f6c732532306f6625323050726976617465253230446565702532304c6561726e696e672e6970796e62&nwo=OpenMined%2FPySyft&path=examples%2Ftutorials%2FPart+1+-+The+Basic+Tools+of+Private+Deep+Learning.ipynb&repository_id=97641933&repository_type=Repository#Congratulations!!!---Time-to-Join-the-Community!).",oh also add end tutorial default message like done,issue,negative,neutral,neutral,neutral,neutral,neutral
490364306,"Sorry for the many commits, yesterday night I messed up badly with Git. Going to try and see if I can get a test up for this fix.

EDIT: Added a test case for a simple RNN + checking if gradient updates are present following remote backpropagation. Not sure if the file` test_hook.py` is the right place where I should have put the test case. ",sorry many yesterday night badly git going try see get test fix edit added test case simple gradient present following remote sure file right place put test case,issue,negative,negative,neutral,neutral,negative,negative
490192557,"I'm looking into this, but am running into the problem that there's no good way of getting unaccumulated batch gradients in PyTorch. That is, you can't get and clip the gradient of each individual data point without calling `.backward` separately for each. See the discussion here from someone else that ran into the same issue:

https://stackoverflow.com/questions/53798023/computing-gradients-for-every-individual-sample-in-a-batch-in-pytorch

Unless we can figure out a way to get unaccumulated gradients, the optimizer will have to work with an effective batch size of 1 from an efficiency perspective. Otherwise, there's no way to clip gradients from individual data points.",looking running problem good way getting unaccumulated batch ca get clip gradient individual data point without calling separately see discussion someone else ran issue unless figure way get unaccumulated work effective batch size efficiency perspective otherwise way clip individual data,issue,positive,positive,positive,positive,positive,positive
490148366,"Hey, This is a super high value pull request. It looks like flake8 is not happy with indentation which is causing travis to fail. That being said could you add a test to make sure this is not broken again in the future",hey super high value pull request like flake happy indentation causing travis fail said could add test make sure broken future,issue,positive,positive,positive,positive,positive,positive
490049512,"Thanks for this! The tests are super helpful!!!

I've fixed this issue at the train_config branch as well, if you want to have a look.",thanks super helpful fixed issue branch well want look,issue,positive,positive,positive,positive,positive,positive
489930377,"I believe the issue is related to the fact that the .grad and .data attributes are still not supported by PySyft, but there seems to be some code about it in syft/frameworks/torch about it. This comment seems to suggest that the .grad and .grad.data tensors are not supported yet?

            # TODO: add .data and .grad to syft tensors

However, it turns out that by de-commenting the following lines in syft/frameworks/torch/hook.py (which were previously commented), the gradients are properly computed following the backpropagation phase.

![image](https://user-images.githubusercontent.com/4907418/57285656-f6961a80-70b3-11e9-8fab-c5bc4cb2ed10.png)



",believe issue related fact still code comment suggest yet add however turn following previously properly following phase image,issue,negative,neutral,neutral,neutral,neutral,neutral
489924862,"I tried replicating my issue with the hidden layer, the model, the output and the input arguments obtained via the `""copy().get()""` function and the backpropagation seems to be successfully working in that case, with all gradients being present in the model's parameters.

This is the current non-working version:
![image](https://user-images.githubusercontent.com/4907418/57276202-20921180-70a1-11e9-9238-9fa10f6e9201.png)

Working version, with all variables extracted via the .get() function:

![image](https://user-images.githubusercontent.com/4907418/57276561-4bc93080-70a2-11e9-9cc4-b673a307bf07.png)


I presume there could be some issues the PySyft backpropagation function when operating on the remote pointers for such case?",tried issue hidden layer model output input via copy function successfully working case present model current version image working version extracted via function image presume could function operating remote case,issue,negative,positive,neutral,neutral,positive,positive
489590631,"Thank you for running my example!!
Yes, that's exactly the same output I got too. Isn't the pointed loss supposed to have grad_fn=<NllLossBackward> too? (the first tensor you're showing) . However, the issue is not in the loss per se,  but later on. In fact, after the backpropagation phase, not all the gradients are present as model's parameters in the federated version. (just 2 gradients are present among the model's parameters, whereas in the sequential version there are 4 gradients among the model parameters). So, it actually breaks here. This seems to be the same issue reported at: https://discuss.pytorch.org/t/list-model-parameters-0-grad-doubt-in-weight-updates/8422

```
  for param in model_ptr.parameters():
        #if(param.grad is not None):
        #Daniele: code breaks here, as not all gradient parameters are there
        param.data.add_(-args.learning_rate, param.grad.data)
```

I've attached a full example about my federated code for RNNs (kinda messy though). Bear in mind to change the following line before running it:

`os.chdir(""/home/daniele/py_thesis/RNN_Example"")`


",thank running example yes exactly output got pointed loss supposed first tensor showing however issue loss per se later fact phase present model version present among model whereas sequential version among model actually issue param none code gradient attached full example code messy though bear mind change following line running,issue,negative,positive,neutral,neutral,positive,positive
489587154,"I've tried to run the snippet above, and I got the following error:

```python
File ""original_syft_bug.py"", line 12, in <module>
    output = np.ones(1, 18)
  File ""/home/marianne/anaconda3/envs/syft/lib/python3.6/site-packages/numpy/core/numeric.py"", line 203, in ones
    a = empty(shape, dtype, order)
TypeError: data type not understood
```

I've changed line 12 to: `output = torch.from_numpy(np.ones((1, 18)))`

And the script doesn't break, it gives me the following output:

```python
tensor(-1., dtype=torch.float64, requires_grad=True)
tensor(-1., dtype=torch.float64, grad_fn=<NllLossBackward>)
```

I'm using syft from dev branch.",tried run snippet got following error python file line module output file line empty shape order data type understood line output script break following output python tensor tensor dev branch,issue,negative,negative,neutral,neutral,negative,negative
489403705,There are some remaining issues related to the weights not being updated and the loss not being properly initialized. I opened an issue about them:  https://github.com/OpenMined/PySyft/issues/2122,related loss properly issue,issue,negative,neutral,neutral,neutral,neutral,neutral
489400700,"There has not been much of a discussion about it. I still think it will be necessary if we intend to expand PySyft to other systems but we can reopen this if we need to
Or maybe I can come back with a plan :)",much discussion still think necessary intend expand reopen need maybe come back plan,issue,negative,positive,neutral,neutral,positive,positive
489394929,@mari-linhares I have ported the analysis implementation in Pytorch. I am working on implementing an complete PATE example and get results close to the paper.,ported analysis implementation working complete pate example get close paper,issue,negative,positive,neutral,neutral,positive,positive
489386841,If this is still relevant maybe list missing types?,still relevant maybe list missing,issue,negative,positive,neutral,neutral,positive,positive
489386808,@jlebensold is this still a valid issue? I don't think I understand the concept of plan and client/server interaction here. Can you add more details?,still valid issue think understand concept plan interaction add,issue,negative,neutral,neutral,neutral,neutral,neutral
489386628,"Currently not I'm working on this, but I would like to help in the future.",currently working would like help future,issue,positive,neutral,neutral,neutral,neutral,neutral
489385854,"I think this was partially covered by serializing/deserializing strings explicitly, is this right @iamtrask ?",think partially covered explicitly right,issue,negative,positive,neutral,neutral,positive,positive
489120535,"No strong opinions, but I would say client is more informative than remote.",strong would say client informative remote,issue,positive,positive,positive,positive,positive,positive
489089395,I agree with the name of `Proxy`. I thought of using it for the `SocketIO` object too as that's its function in the setup,agree name proxy thought object function setup,issue,negative,neutral,neutral,neutral,neutral,neutral
489063301,"> Could we avoid deriving the BaseWorker from FederatedClient?

Yes, nice catch.

> Any plans on how to set the dataset variable in the federated client?

Is not yet implemented I imagine FederatedClient could have a method to set the dataset. The data should be local. You would probably set it when you start a WebsocketServerWorker.

I haven't put much thought on that yet, potentially is a problem to be fixed.",could avoid yes nice catch set variable client yet imagine could method set data local would probably set start put much thought yet potentially problem fixed,issue,negative,positive,positive,positive,positive,positive
489060531,"Could we avoid deriving the BaseWorker from FederatedClient? 

The WebsocketClientWorker derives from it and doesn't need this functionality. 
VirtualWorker and WebsocketServerWorker (and WebsocketIOServerWorker) could derive directly from FederatedClient.

Any plans on how to set the dataset variable in the federated client?",could avoid need functionality could derive directly set variable client,issue,negative,positive,neutral,neutral,positive,positive
488633582,"@DanyEle That's amazing :) A Jupyter notebook in the format of other tutorials under Advanced. Feel free to submit a PR for it.

**Bonus:** It would be great if you could make an example of it trying to predict the next word given a context. This is particularly great because it makes it more intuitive as to why we are doing federated learning :)
Its optional though if you would like you can still submit a PR for the current example  :) ",amazing notebook format advanced feel free submit bonus would great could make example trying predict next word given context particularly great intuitive learning optional though would like still submit current example,issue,positive,positive,positive,positive,positive,positive
488627780,"Alright, I finally managed to get the training running for a simple RNN. The issue I was bumpint into was related to the fact that not all parameters were being set in the model and I was just trying to access the first one. Should I open a pull request for my example with RNNs, even though it's not in a jupyter notebook, but in a plain Python file or should I put it in a jupyter notebook and then open a pull request?",alright finally get training running simple issue related fact set model trying access first one open pull request example even though notebook plain python file put notebook open pull request,issue,negative,positive,neutral,neutral,positive,positive
488590633,"Thanks for the link, I was actually working on getting a very similar example to work in a federated way, namely: https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html . This RNN is also based off linear layers, as you suggested. However, I've been having little success on getting that working, as I had the very same issue as you had when performing the forward pass (the error I posted above)",thanks link actually working getting similar example work way namely also based linear however little success getting working issue forward pas error posted,issue,positive,positive,neutral,neutral,positive,positive
488582309,https://pytorch.org/tutorials/intermediate/char_rnn_generation_tutorial.html this is for generating names. There is also a charecter level classifier. ,generating also level classifier,issue,negative,neutral,neutral,neutral,neutral,neutral
488581971,"@DanyEle I don't think we support RNNs too. Haven't tried it yet. But , one way to go about RNNs is to implement them from scratch using linear layers like the charecter level name generator given in Pytorch tutorials. Thank you for trying though :) it will be quite sometime till we get torch LSTM/RNN working. Temporarily it would be great to have the RNN from scratch example , if you would like to tackle that you could go ahead :) ",think support tried yet one way go implement scratch linear like level name generator given thank trying though quite sometime till get torch working temporarily would great scratch example would like tackle could go ahead,issue,positive,positive,positive,positive,positive,positive
488399760,"Well I've been working the whole day on trying to fix my issues on training a RNN in a federated way, but still bumped into the same error I posted above. Even with the partial solution about sending pointers to hidden layers, the backward propagation procedure did not work and the gradient could not be computed. I wonder if RNNs are supported by PySyft?",well working whole day trying fix training way still error posted even partial solution sending hidden backward propagation procedure work gradient could wonder,issue,negative,negative,neutral,neutral,negative,negative
488266009,"I've updated the demo in the repo to clarify that the matrix `R` need not be shared publicly:
https://github.com/jbloom22/DASH/",clarify matrix need publicly,issue,negative,neutral,neutral,neutral,neutral,neutral
488241643,"I think I manged to solve it on my local end: basically you had to create a pointer to the hidden layer and then send the hidden layer's point to the worker as well, then operate on both the model's pointer and hidden layer's pointer. Now i'm going to try and see if I can also fix your example code as well.

EDIT: My example was partially running with an RNN, not an LSTM. I tried applying the same approach to your code too, but that didn't work.  There seems to be some issues with the forward/backward propagation steps when making use of a hidden layer.",think solve local end basically create pointer hidden layer send hidden layer point worker well operate model pointer hidden layer pointer going try see also fix example code well edit example partially running tried approach code work propagation making use hidden layer,issue,positive,negative,negative,negative,negative,negative
488240321,"> I tried running your code and even tried creating my own example with LSTM / RNNs, however when operating on the model pointer and not on the model itself, I always get the same error you also got in your 'Federated LSTM-Predicting Next Word.ipynb' notebook when running the forward pass on the LSTM.
> 
> ![image](https://user-images.githubusercontent.com/4907418/57010660-1e8e0580-6bfe-11e9-8561-eb8a6094fefe.png)
> 
> When operating on the model.get() or the plain model (i.e.: not the one being pointed to), I don't have any issues though.
> 
> Any ideas why this issue related to the model pointer could happen?

@DanyEle Thank you for reproducing the issue :) . PySyft currently does not have support for LSTM yet, which @LaRiffle is trying to solve in #1995 and has some issues. If you are interested in solving it you can talk to him about it. ",tried running code even tried example however operating model pointer model always get error also got next notebook running forward pas image operating plain model one pointed though issue related model pointer could happen thank issue currently support yet trying solve interested talk,issue,positive,positive,neutral,neutral,positive,positive
488236997,"I tried running your code and even tried creating my own example with LSTM / RNNs, however when operating on the model pointer and not on the model itself, I always get the same error you also got in your 'Federated LSTM-Predicting Next Word.ipynb' notebook when running the forward pass on the LSTM.

![image](https://user-images.githubusercontent.com/4907418/57010660-1e8e0580-6bfe-11e9-8561-eb8a6094fefe.png)


When operating on the model.get() or the plain model (i.e.: not the one being pointed to), I don't have any issues though. 

Any ideas why this issue related to the model pointer could happen?",tried running code even tried example however operating model pointer model always get error also got next notebook running forward pas image operating plain model one pointed though issue related model pointer could happen,issue,negative,negative,neutral,neutral,negative,negative
487938931,"I see, thanks @LaRiffle, everything makes a lot more sense now!",see thanks everything lot sense,issue,negative,positive,positive,positive,positive,positive
487938341,"@mari-linhares Yes because the model is added to the args in `plan__call__` (through self.self), and those args are sent to the correct worker in the non-local setting, while they are not in the local case where you do local building because of the `if isinstance(arg, torch.Tensor):` clause in build_plan",yes model added sent correct worker setting local case local building clause,issue,negative,neutral,neutral,neutral,neutral,neutral
487937387,"@midokura-silvia 

> Where shall we put the function that implements the training loop? In my opinion the worker could be a possible location.

Yes. This federated client abstraction is just so we can have all the training loop related logic living in a single place. If you look at base in this PR it inherits from FederatedClient.

> Is it okay to add a way of calling a method of the remote worker? I am just thinking of modifying the execute_command() function to allow calling methods of self additionally to calling methods of pointers.

Yes, that's the plan! But I think we can create a new MSGTYPE for running training.",shall put function training loop opinion worker could possible location yes client abstraction training loop related logic living single place look base add way calling method remote worker thinking function allow calling self additionally calling yes plan think create new running training,issue,positive,negative,negative,negative,negative,negative
487935882,"Thanks for having a look @LaRiffle, the funny thing is that I see this error when I try to build the plan locally. When I send the TrainConfig it actually sends the model weights and the plan.",thanks look funny thing see error try build plan locally send actually model plan,issue,negative,positive,positive,positive,positive,positive
487934728,"Where shall we put the function that implements the training loop? In my opinion the worker could be a possible location. 
Is it okay to add a way of calling a method of the remote worker? I am just thinking of modifying the execute_command() function to allow calling methods of self additionally to calling methods of pointers.
This way we don't need to send the implementation of the training loop. Instead we have a standard implementation that is configured by the TrainConfig. 
It could also be used to obtain information from the remote worker as returning the number of objects or their string representation.

",shall put function training loop opinion worker could possible location add way calling method remote worker thinking function allow calling self additionally calling way need send implementation training loop instead standard implementation could also used obtain information remote worker number string representation,issue,negative,negative,neutral,neutral,negative,negative
487923913,"Oh I got it! The reason it believes F.linear must be computed locally is because the weights of the nets are local! If you check https://github.com/OpenMined/PySyft/blob/dev/examples/tutorials/Part%209%20-%20Introduction%20to%20Plan.ipynb cell 13 you observe that we also send the weights of the model to the plan.
So this is what is missing here",oh got reason must locally local check cell observe also send model plan missing,issue,negative,negative,neutral,neutral,negative,negative
487921580,"So when you build your plan you have this odd thing: you as a plan order to build the plan on args which from your point of view are pointers owned by ""me"" to yourself.
At that point and for some reason, the call to F.linear is made on these pointers but is not hooked to be sent to the pointer location (you as a plan), therefore you end up doing `if input.dim() == 2` on pointers",build plan odd thing plan order build plan point view point reason call made hooked sent pointer location plan therefore end,issue,negative,negative,negative,negative,negative,negative
487919995,"From what I see, `torch.nn.functional.linear` is correctly hooked and the command is sent to a worker.
But then this worker stills call this command on pointers (it should call it on tensors), and this is where it fails because .dim() is hooked so `if input.dim() == 2` tries to assess if a pointer tensor is true or false.",see correctly hooked command sent worker worker call command call hooked ass pointer tensor true false,issue,negative,negative,neutral,neutral,negative,negative
487810001,"I *think* we only want to share the parameters... parameters + plan == everything needed :). If by ""sharing the entire model"" you mean actually sending a python object we're specifically trying to avoid this for security reasons.",think want share plan everything entire model mean actually sending python object specifically trying avoid security,issue,negative,negative,negative,negative,negative,negative
487675487,"Agree, I think a detailers dict/list would still be needed, right?",agree think would still right,issue,negative,positive,positive,positive,positive,positive
487674452,I think it may be a better idea to move each simplifier and detailer to the file which defines the object. In that case serde would only need to keep the higher level logic and the simplifiers for built in python types making everything easier,think may better idea move simplifier detailer file object case would need keep higher level logic built python making everything easier,issue,positive,positive,positive,positive,positive,positive
486920962,"Hi @iamtrask ! Yep, I'm on slack (username is also akontaxis). 

It's going alright -- I put together a [basic notebook](https://nbviewer.jupyter.org/github/akontaxis/PySyft/blob/plaintext_speed_regression/examples/experimental/plaintext_speed_regression_example.ipynb) that walks through an example of the linear regression case. Securely performing the linear solve at the end is still a to do, so was planning to tackle that next, but definitely open to any guidance on scope/next steps!",hi yep slack also going alright put together basic notebook example linear regression case securely linear solve end still tackle next definitely open guidance,issue,positive,positive,neutral,neutral,positive,positive
486617366,"Conflict fixed here, feel free to integrate changes here or not
https://github.com/OpenMined/PySyft/pull/2099",conflict fixed feel free integrate,issue,negative,positive,positive,positive,positive,positive
486491728,"Right now, I feel like we can treat each specific case differently like was done in #2098.",right feel like treat specific case differently like done,issue,positive,positive,neutral,neutral,positive,positive
486210893,"So maybe what we could do is, instead of recreating a worker of each plan, to use the plan owner. 
Example:
you have a plan f and some data x, which you all send to bob. F is unbuild. When you do f(x) the first time, you tell bob ""Hey, the next commands you'll get should be stored in the my plan f"", you run the commands in f, and then ""Ok bob, now build the plan with those commands and run it"", and you and him set the plan to ""built"". The second time (or the first time if you sent your plan f already built), when you do f(x2), actually you say to bob ""Hey, remember f? Give him my x2 and run it"".

This way you relie on Bob ability to catch calls, and plan appear more like what they should be: benign objects, which can be stored by workers and can have Pointers referencing them (in line with #2096)",maybe could instead worker plan use plan owner example plan data send bob unbuild first time tell bob hey next get plan run bob build plan run set plan built second time first time sent plan already built actually say bob hey remember give run way bob ability catch plan appear like benign line,issue,positive,positive,neutral,neutral,positive,positive
486137328,@iamtrask pointers to np array would be a good idea! We had this idea with Sylvia also for the TrainConfig object Marianne is building: we are now sending many things so it's worth having generic pointers,array would good idea idea also object building sending many worth generic,issue,positive,positive,positive,positive,positive,positive
486134130,This is a really good idea - we already have pointers to all sorts of things which don't have any meaningful inheritance structure. A good first use case for this might be pointers to numpy arrays or some other framework object (numpy arrays are suitably similar to torch tensors but are different enough to test the abstraction),really good idea already meaningful inheritance structure good first use case might framework object suitably similar torch different enough test abstraction,issue,positive,positive,positive,positive,positive,positive
485957965,This is a really high value contribution - thank you @IonesioJunior ,really high value contribution thank,issue,positive,positive,positive,positive,positive,positive
485674827,"@mari-linhares thank you! It works :+1:  

`pip install https://github.com/OpenMined/PySyft/archive/dev.zip`",thank work pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
485354161,"Hi @mari-linhares 

Some of my thoughts on the ""FL experiment"" example as its current state:
1. add a readme to guide user to run the server with either
  - `FLASK_APP=server.py flask run`; or
  - add `app.run()` in `server.py` and run `python server.py`
2. a clean-up on `ipynb`.

I might put a PR when I got some time.",hi experiment example current state add guide user run server either flask run add run python might put got time,issue,negative,neutral,neutral,neutral,neutral,neutral
485352301,"Hi @iamtrask 

Are you able to reproduce this error from your side?
The simplest way is to replicate the search and asserts again after the first round in [this standard test file for websocket worker](https://github.com/OpenMined/PySyft/blob/4251f728bdff186328b7c24603dedf09e3037230/test/workers/test_websocket_worker.py#L51-L55).
",hi able reproduce error side way replicate search first round standard test file worker,issue,negative,positive,positive,positive,positive,positive
485331225,"> OMG Raspberry PI!!! Any chance you'd be willing to write a blogpost tutorial about your experience with this?!!?!

Hey, I would be really glad to do that if the whole training procedure was working. For now, I managed to fix the data distribution part, as the timeout issues occurred there. However, for some weird reason the training stops at the first training iteration. I tried waiting for a few hours yesterday, however nothing happened after iteration (1), when the initial loss is computed.

![training_loss_alice](https://user-images.githubusercontent.com/4907418/56485764-a0cb4b00-64d5-11e9-8cf1-fb2c8c443c81.png)



My main reason to use raspberry PIs is for text processing though, so I am going to try and see if I manage to get them working for that purpose. I saw there is a nice example about that in the examples/advances tutorials: ""Federated Word Vectors"". I will try and adapt that code to make it work in a federated way on the raspberry PIs.

",raspberry pi chance willing write tutorial experience hey would really glad whole training procedure working fix data distribution part however weird reason training first training iteration tried waiting yesterday however nothing iteration initial loss main reason use raspberry text though going try see manage get working purpose saw nice example word try adapt code make work way raspberry,issue,positive,positive,positive,positive,positive,positive
485288258,@2fasc just tried this code snippet with the most current version (dev branch) and it runs. Can you try again?,tried code snippet current version dev branch try,issue,negative,neutral,neutral,neutral,neutral,neutral
485287899,"@LaRiffle any idea about how to make this work? I've tried for a bit, but I'm having a hard time.

I think the problem is the ways plans are built ([more specifically line 146](https://github.com/OpenMined/PySyft/blob/cd4d6e985c03b9cf57b784c4f49eed47e116bbda/syft/workers/plan.py#L146)). Any ideas or suggestions?",idea make work tried bit hard time think problem way built specifically line,issue,negative,negative,negative,negative,negative,negative
485286019,OMG Raspberry PI!!! Any chance you'd be willing to write a blogpost tutorial about your experience with this?!!?!,raspberry pi chance willing write tutorial experience,issue,negative,positive,positive,positive,positive,positive
485285936,@LiviaCavalcanti @jcezarms FYI: there is already an id generator entity abstraction at [abstract.py](https://github.com/OpenMined/PySyft/blob/dev/syft/workers/abstract.py),already id generator entity abstraction,issue,negative,neutral,neutral,neutral,neutral,neutral
485248423,"Added two more fixes on the server-side, as the server may also time out when handling slow clients.",added two server may also time handling slow,issue,negative,negative,negative,negative,negative,negative
485237125,Ran the command `black syft` . Should be good to go.,ran command black good go,issue,negative,positive,positive,positive,positive,positive
485232418,"@DanyEle  Its failing the Style Check , could you run the command `black syft` and commit the change? ",failing style check could run command black commit change,issue,negative,negative,negative,negative,negative,negative
485151190,"Does this issue depend on #1928? If not, I'd be interested in tackling it.",issue depend interested tackling,issue,negative,positive,positive,positive,positive,positive
485148545,"@iamtrask what about something along the lines of `random.SystemRandom().getrandombits(n)`? In this case, `n` would be up to discussion, I'd say 128 fits the purpose. A higher `n` contributes ~an extra bit~ in terms of security on hashing, which I suppose is a priority for PySyft.",something along case would discussion say purpose higher extra security suppose priority,issue,negative,positive,positive,positive,positive,positive
485143669,"Just to point out, they also [support custom states](http://docs.celeryproject.org/en/latest/userguide/tasks.html#custom-states), which in my opinion would be a nice feature to support here as wel.",point also support custom opinion would nice feature support,issue,positive,positive,positive,positive,positive,positive
485143570,"@mari-linhares it mentions it by the name ""state"". If you `CTRL+F state` on the given link, you can see for example [how they manage `PENDING` states](http://docs.celeryproject.org/en/latest/getting-started/first-steps-with-celery.html#result-backend-doesn-t-work-or-tasks-are-always-in-pending-state), and in their docs there's also a [list of all built-in states](http://docs.celeryproject.org/en/latest/userguide/tasks.html#built-in-states).",name state state given link see example manage pending also list,issue,negative,neutral,neutral,neutral,neutral,neutral
485134193,"```
import torch
import torch.nn as nn
import torch.nn.functional as F
import syft as sy


class Simple_CNN(nn.Module):
    def __init__(self):
        super(Simple_CNN, self).__init__()
        self.conv1 = nn.Conv2d(3, 20, 3, 3)
        self.conv2 = nn.Conv2d(20, 50, 3, 3)

        self.fc1 = nn.Linear(50, 500)
        self.fc2 = nn.Linear(500, 2)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = F.max_pool2d(x, 2, 2)
        x = F.relu(self.conv2(x))
        x = F.max_pool2d(x, 2, 2)
        x = x.view(x.shape[0], -1)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return F.log_softmax(x, dim=1)


def reproduce_error():
    model = Simple_CNN()

    hook = sy.TorchHook(torch)
    client = sy.VirtualWorker(hook, id=""client"")
    bob = sy.VirtualWorker(hook, id=""bob"")
    alice = sy.VirtualWorker(hook, id=""alice"")
    crypto_provider = sy.VirtualWorker(hook, id=""crypto_provider"")

    model.fix_precision().share(alice, bob, crypto_provider=crypto_provider)


if __name__ == ""__main__"":
    reproduce_error()
```",import torch import import import class self super self forward self return model hook torch client hook client bob hook bob hook hook bob,issue,positive,positive,positive,positive,positive,positive
485091122,"It is defined here: https://github.com/OpenMined/PySyft/blob/dev/syft/frameworks/torch/hook.py#L981

Can you share a code sample failing please?",defined share code sample failing please,issue,negative,neutral,neutral,neutral,neutral,neutral
485079428,@robert-wagner could you take another look?,could take another look,issue,negative,neutral,neutral,neutral,neutral,neutral
485011428,"My current settings:
syft == 0.1.12a1
Python == 3.6.7
torch == 1.0.1.post2

The error still persists with these settings, but discarding the possibility of a bug has lessened my effort to find the problem. I believe it's something related to the multiple versions of python / libraries that I use on my machine. I'll dig deeper.
Thank you anyway  :smiley:.",current python torch post error still possibility bug effort find problem believe something related multiple python use machine dig thank anyway,issue,negative,neutral,neutral,neutral,neutral,neutral
484833580,"@alhparsa Go ahead , it would be great to have it part of PySyft :) ",go ahead would great part,issue,positive,positive,positive,positive,positive,positive
484733933,"@IonesioJunior, I've just tried using the `dev` branch and it works. Can you try again with the most updated version of `dev`?",tried dev branch work try version dev,issue,negative,neutral,neutral,neutral,neutral,neutral
484615677,"@feigaoxyz can you open a new issue (or issues) pointing to parts of the documentation that are not clear? 

Thank you!",open new issue pointing documentation clear thank,issue,positive,positive,neutral,neutral,positive,positive
484411123,"Not sure if `flake8 . --count --exit-zero --statistics` should be `flake8 . --count --exit-zero --statistics --select=E,F,W,C90`. Is that just supposed to display flake8's default errors as warnings in travis?",sure flake count statistic flake count statistic supposed display flake default travis,issue,negative,positive,positive,positive,positive,positive
484393995,"Yes this is much better, I like it a lot!",yes much better like lot,issue,positive,positive,positive,positive,positive,positive
484384796,">  What kind of subset are you interested in selecting?
 
I'm using `torch.utils.data.random_split(dataset, size_set)` to split datasets into train, test and validation sets. This basically creates a new class that contains the original dataset and adds a list of indices assigned to each split. 


> I assume it is linked to this example: https://github.com/2fasc/Distributed_Malaria/blob/master/src/federated_training.py

Exactly. I'm curious how imbalanced label distributions affect federated / distributed training. 
",kind subset interested split train test validation basically new class original list index assigned split assume linked example exactly curious label affect distributed training,issue,positive,positive,positive,positive,positive,positive
484327962,"@LiviaCavalcanti 

> Hey, is this problem free, in the way that I can work on it?

Yes , go ahead! It would great to have your help on this :) ",hey problem free way work yes go ahead would great help,issue,positive,positive,positive,positive,positive,positive
484327748,"Hey, is this problem free, in the way that I can  work on it?",hey problem free way work,issue,negative,positive,positive,positive,positive,positive
484214680,"I've just executed the script with no error, probably this was naturally fixed by time. @LaRiffle, @robert-wagner ",executed script error probably naturally fixed time,issue,negative,positive,neutral,neutral,positive,positive
484093489,I'm a huge fan of decoupling TrainConfig from Plan specifically - this is great! Let's do it!,huge fan plan specifically great let,issue,positive,positive,positive,positive,positive,positive
484071902,"@LaRiffle @iamtrask how do you feel about this?

```python
# run script to start client workers....

## -------------- SERVER  (Scheduler) ------------------

# start a locak worker
me = local_worker()

# model definition
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(2, 3)
        self.fc2 = nn.Linear(3, 2)

    @sy.method2plan
    def forward(self, x):
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return F.log_softmax(x, dim=0)

    @sy.method2plan
    def forward_no_softmax(self, x):
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x

net = Net()
workers = [alice, bob]

def update_model_callback_fn(res):
    net.set_weights(res.model.weights)
    pass

train_config = sy.TrainConfig(model=net, batch_size=16, epochs=1, loss='mse', optimizer='adam')

for worker in workers:
   train_config.send(worker)
   worker.run_training(update_model_callback_fn)


```",feel python run script start client server start worker model definition class net self super net self forward self return self return net net bob pas worker worker,issue,positive,positive,neutral,neutral,positive,positive
484066707,"Fastest way to do this is probably to have a dict of optimizers, the key being the data.location, this would keep the code simple",way probably key would keep code simple,issue,negative,neutral,neutral,neutral,neutral,neutral
484066221,"Hey @2fasc - seems like the solution here is to have different optimizers for different machines (one for bob, another for alice, etc.) Eventually we'll write custom Federated optimizers but for now this is the solution :)",hey like solution different different one bob another eventually write custom solution,issue,positive,neutral,neutral,neutral,neutral,neutral
484064085,Is there a way for us to perhaps clear out the momentum as needed? (reset to None),way u perhaps clear momentum reset none,issue,negative,positive,positive,positive,positive,positive
484060980,"Ok here is the trouble: Adam uses momentum (actually: second moments of the gradients), which means it stores the gradients in a list and for each batch produces a correction of the current gradient based on the old ones. When changing of batch owner (so in Part 8 of tutorial at the middle of the epoch), you have now gradients from alice which you want to correct with moments of old gradients owned by bob: this is not possible as the data needs to be at the same location and it raises an error, which is here a bit tricky to find.
This is also why momentum is not supported so far on SGD.

The fix for this would probably imply to rewrite the optimizers. This is an important project and maybe could be correlated to the notions of aggregator needed for Federated or Secure Averaging.

Thank you for reporting the error!",trouble momentum actually second list batch correction current gradient based old batch owner part tutorial middle epoch want correct old bob possible data need location error bit tricky find also momentum far fix would probably imply rewrite important project maybe could correlated aggregator secure thank error,issue,negative,positive,neutral,neutral,positive,positive
484057272,I suspect there is a bug in the hooking as the loss is increasing,suspect bug loss increasing,issue,negative,neutral,neutral,neutral,neutral,neutral
484056751,"Oh actually it fails, but after a certain number of batch iterations
```
Train Epoch: 1 [0/60032 (0%)]	Loss: 2.303720
Train Epoch: 1 [1920/60032 (3%)]	Loss: 3.148396
Train Epoch: 1 [3840/60032 (6%)]	Loss: 4.953410
Train Epoch: 1 [5760/60032 (10%)]	Loss: 6.552952
Train Epoch: 1 [7680/60032 (13%)]	Loss: 8.274794
Train Epoch: 1 [9600/60032 (16%)]	Loss: 9.585523
Train Epoch: 1 [11520/60032 (19%)]	Loss: 11.709550
Train Epoch: 1 [13440/60032 (22%)]	Loss: 14.805451
Train Epoch: 1 [15360/60032 (26%)]	Loss: 14.508088
Train Epoch: 1 [17280/60032 (29%)]	Loss: 18.298759
Train Epoch: 1 [19200/60032 (32%)]	Loss: 16.543806
Train Epoch: 1 [21120/60032 (35%)]	Loss: 19.365683
Train Epoch: 1 [23040/60032 (38%)]	Loss: 23.546900
Train Epoch: 1 [24960/60032 (42%)]	Loss: 26.782951
Train Epoch: 1 [26880/60032 (45%)]	Loss: 28.923700
Train Epoch: 1 [28800/60032 (48%)]	Loss: 28.413818
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<timed exec> in <module>

<ipython-input-6-72ddef6ce5b6> in train(args, model, device, federated_train_loader, optimizer, epoch)
      8         loss = F.nll_loss(output, target)
      9         loss.backward()
---> 10         optimizer.step()
     11         model.get() # <-- NEW: get the model back
     12         if batch_idx % args.log_interval == 0:

~/code/env/pysyft/lib/python3.7/site-packages/torch/optim/adam.py in step(self, closure)
     92                 # Decay the first and second moment running average coefficient
     93                 exp_avg.mul_(beta1).add_(1 - beta1, grad)
---> 94                 exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)
     95                 if amsgrad:
     96                     # Maintains the maximum of all 2nd moment running avg. till now

~/code/PySyft/syft/frameworks/torch/hook.py in overloaded_native_method(self, *args, **kwargs)
    650                 # Send the new command to the appropriate class and get the response
    651                 method = getattr(new_self, method_name)
```",oh actually certain number batch train epoch loss train epoch loss train epoch loss train epoch loss train epoch loss train epoch loss train epoch loss train epoch loss train epoch loss train epoch loss train epoch loss train epoch loss train epoch loss train epoch loss train epoch loss train epoch loss recent call last timed module train model device epoch loss output target new get model back step self closure decay first second moment running average coefficient beta beta grad beta beta grad grad maximum moment running till self send new command appropriate class get response method,issue,negative,positive,positive,positive,positive,positive
484054999,"Yes, I can get this example working. 

(A side note, perhaps it would be better to have some detail instructions in files to help others running.)",yes get example working side note perhaps would better detail help running,issue,positive,positive,positive,positive,positive,positive
484054157,"I'm looking at it right now
First observation: Adam optim works in the setting of https://github.com/OpenMined/PySyft/blob/dev/examples/tutorials/Part%208%20-%20Federated%20Learning%20on%20MNIST%20using%20a%20CNN.ipynb if you replace the SGD optim with Adam.",looking right first observation work setting replace,issue,negative,positive,positive,positive,positive,positive
484053145,@mari-linhares - it seems like we should either ditch .send() altogether OR make .send() not lazy (and as a result have to run mock data through it - which despite typing concerns is actually default behavior in both Tensorflow Eager and PyTorch's tracing mechanisms) ,like either ditch altogether make lazy result run mock data despite actually default behavior eager tracing,issue,negative,negative,negative,negative,negative,negative
484052669,"Note - I think it's quite likely that the Async / Futures framework will be able to do everything Plans intend to do - although the code required for it is considerably more complex (as is the UX). Plans offer a simpler, more intuitive interface:

1) take some code
2) wrap it in a function (With a @plan decorator)
3) send that code wherever you want
4) execute it whenever you want using a simple function.",note think quite likely framework able everything intend although code considerably complex offer simpler intuitive interface take code wrap function plan decorator send code wherever want execute whenever want simple function,issue,negative,positive,neutral,neutral,positive,positive
484052164,"Context manager seems to have some critical UX limitations here. We need the ability to explicitly send plans, serialize plans, store plans, and search for plans. I don't see how a context manager would enable this. A context manager could be swapped out for the decorator we're currently using - but this seems tangential to the plan architecture decisions we're talking about.",context manager critical need ability explicitly send serialize store search see context manager would enable context manager could decorator currently tangential plan architecture talking,issue,negative,neutral,neutral,neutral,neutral,neutral
484051606,+1 to this - and in fact we should probably start switching to a much larger hash instead of an int. We will eventually get to a scale where collisions (accidential or malicious) are a bigger deal.,fact probably start switching much hash instead eventually get scale accidential malicious bigger deal,issue,negative,positive,neutral,neutral,positive,positive
484051368,Hmm - it's not totally clear to me why this would be the case. Will require a deeper look. I don't think we have any unit tests around Adam so this might just require new functionality to get working.,totally clear would case require look think unit around might require new functionality get working,issue,negative,positive,positive,positive,positive,positive
484050555,Very interesting feature! What kind of subset are you interested in selecting?,interesting feature kind subset interested,issue,positive,positive,positive,positive,positive,positive
484050258,Have you gotten https://github.com/OpenMined/PySyft/tree/dev/examples/experimental/Federated%20Learning%20Experiment to work on your local setup?,gotten work local setup,issue,negative,neutral,neutral,neutral,neutral,neutral
484050203,This is usually because a function (in this case search()) is returning pointers with self.garbage_collect_data==True. This means that when the pointers are deleted (garbage collected) that it sends a delete command to the remote machine.,usually function case search garbage collected delete command remote machine,issue,negative,negative,negative,negative,negative,negative
484041864,@replomancer you may go ahead. it's a much required feature right now and it would be great to have your help :),may go ahead much feature right would great help,issue,positive,positive,positive,positive,positive,positive
483999763,"@midokura-silvia 
I hear your concern, it is super important to parallelize and have async modes:
@iamtrask is working on async for all kinds of operations: namely you seed an op, have a pre-reference to the result (already done) but don't wait for the remote execution to run.
There an ongoing PR to send plans to multiple workers (ie .send(alice, bob) ) #2051 

I think this should help a lot!

Regarding the logical graph of plan I explained above, actually it would be sent all at once: if you send a plan, all its logical dependencies should be sent, just like we built it all at once too. You should still handle a single object",hear concern super important parallelize working namely seed result already done wait remote execution run ongoing send multiple ie bob think help lot regarding logical graph plan actually would sent send plan logical sent like built still handle single object,issue,positive,positive,positive,positive,positive,positive
483993830,"@LaRiffle 
The main concern I have is that the training is being controlled (started and supervised) by the local wrapper of the remote worker. This makes it difficult to parallelize the execution of a large number of workers. The goal should be to package the model and the plan in the beginning, send it to the remote worker and then wait (do something else) until it comes back with the result.",main concern training local wrapper remote worker difficult parallelize execution large number goal package model plan beginning send remote worker wait something else come back result,issue,negative,negative,neutral,neutral,negative,negative
483990531,"In the case we want plans to perform a complete training we will need to support if / for statements. This is not possible currently because those can't be caught by our python plan instance.

Looking at the Spark syntax, I wonder if we can try to use special methods on plans to specify logic such as `.foreach(...)` `.if(...)` etc. This would mean keep plans simple and linear but add ability to inter-connect them to create a logical graph of plans.

Here is an example of what it could look like:
```python
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(2, 3)
        self.fc2 = nn.Linear(3, 2)

    @sy.method2plan
    def forward(self, x):
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return F.log_softmax(x, dim=0)

    @sy.method2plan
    def forward_no_softmax(self, x):
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x


net = Net()

net.send(device_1)
# net.forward is a plan
net.forward.send(device_1)

# existing
pointer_to_data = device_1.search('input_data')[0]
pointer_to_result = net.forward(pointer_to_data)

# future ?
training = net.forward.foreach(lambda batch: batch)
dataloader = [ptr_data for ptr_data in device_1.search('input_data')]
training(dataloader)

# or just
dataloader = [ptr_data for ptr_data in device_1.search('input_data')]
training = net.forward.foreach(dataloader)

# future ? if == provided
@sy.func2plan
def is_encrypted(data):
    return data.is_encrypted()

plan = (
    net.forward_no_softmax
    .providing(is_encrypted)
    .otherwise(net.forward)
)
```

Any comments?",case want perform complete training need support possible currently ca caught python plan instance looking spark syntax wonder try use special specify logic would mean keep simple linear add ability create logical graph example could look like python class net self super net self forward self return self return net net plan future training lambda batch batch training training future provided data return plan,issue,positive,positive,neutral,neutral,positive,positive
483981485,"@midokura-silvia I totally agree! The reason why it was a worker is because we needed to use the functionality to catch function and method calls on torch tensors, just the way it is done by workers sending commands between each others. If we can extract this feature then I don't think we need the plan to be a worker.",totally agree reason worker use functionality catch function method torch way done sending extract feature think need plan worker,issue,negative,neutral,neutral,neutral,neutral,neutral
483575179,"It would be good if a plan could be completely independent of a worker, i.e. not be a worker itself. It should be like a sort of recipe. And a worker should only depend on a plan and a model to be able to run a training.",would good plan could completely independent worker worker like sort recipe worker depend plan model able run training,issue,positive,positive,positive,positive,positive,positive
483517859,"from syft.he.paillier import KeyPair

my error is No module named 'syft.he'.
how to solve these error?",import error module solve error,issue,negative,neutral,neutral,neutral,neutral,neutral
483283248,I'd definitely be interested in taking up this project if it's still unassigned!,definitely interested taking project still unassigned,issue,positive,positive,positive,positive,positive,positive
483235011,"And in case you're not satisfied by my cheeky reference to the Pythagorean Theorem (https://en.wikipedia.org/wiki/Plimpton_322) as the proof of the Lemma, here's a home-brewed geometric proof (there must be plenty of short algebraic proofs in the lit):

Let P be the orthogonal projection from R^N to C^perp (the orthogonal complement of the column space of C), so PC = 0. Let b and g be the fit parameters for:

y = xb + Cg + e

Then the residual e is orthogonal to both x and col(C), hence to Px which is in their span. Since e is orthogonal to col(C), we also know Pe = e. So applying P to both sides gives

Py = (Px)b + e

and this is an orthogonal decomposition (!), so by uniqueness the regression problem Py on Px has the same estimate b and the same residual vector e as the original regression problem of y on x and C. All that's changed is the number of degrees of freedom.

[explicitly, P = I - QQ^T, which leads to the formulas].",case satisfied cheeky reference theorem proof lemma geometric proof must plenty short algebraic lit let orthogonal projection orthogonal complement column space let fit residual orthogonal col hence span since orthogonal col also know side orthogonal decomposition uniqueness regression problem estimate residual vector original regression problem number freedom explicitly,issue,positive,positive,positive,positive,positive,positive
483216397,"Well that'd be sweet! I'll do my best to answer any questions. I also just joined the slack as jbloom.

Roughly speaking, efficient distributed algorithms _are_ privacy-preserving algorithms because efficiency requires minimizing the number of bits serialized over the network.

In the case of linear regression, we can ""quotient out"" rotational invariance,  factoring the problem into plaintext compression followed by network usage that is independent of n.

In the simplest case of y regressed on X, this just amounts to staring at the formula:
`beta = (X^T X)^-1 (X^T y)`

So:
1) Compute `X^T X`, reducing k n-vectors to (k choose 2) numbers.
2) Compute `X^T y`, reducing the n-vector to a k-vector.
3) Compute `beta`.

Steps 1 and 2 are the big data steps, but trivially parallelize over p groups of samples, e.g.`X^T X = X1^T X1 + ... + Xp^T Xp`. So compute these summands in plaintext, and for Step 3, just SMPC the sums and the tiny linear solve to obtain `beta`. The only extra bit needed for the standard error is the number `y^T y`.

This gets more fun when you have a ton of features that you'd like to test one-by-one, while including a common set of confounders. We implemented the ""singly-distributed"" version in Hail (https://hail.is) and used it to compute the largest genetic association to date in a couple hours (http://www.nealelab.is/uk-biobank/), testing 4K traits at each of ~13M locations in the genome across ~360K Brits with ~20 additional covariates, with the data partitioned into intervals of rows in the variant-by-individual matrix.*

To accommodate the growing number of individuals in these studies, we're moving to a more general block (i.e. checkerboard) partitioning strategy. The DASH note is just the natural generalization to ""doubly-distributed"" (on features and also samples) linear regression. Once we have block partitioning, we'll implement the non-SMPC version in a few lines of Python. We're also discussing with Hoon Cho (https://hhcho.com/) and others how to best provide a provably-secure SMPC version to the statistical genetics community, building on the great work that he and Bonnie Berger have done in the area.

To be clear, none of this is specific to genomics, and I'd love for the mathematical ideas (useful in _theory_) to find their way into whatever (esp. open-source!) frameworks make them useful in practice. :)

*For BLAS3 vectorization, Hail also lifts the math to process regressions in 2d groups along both the trait and variant axes. The team is now building a Kubernetes/C++ backend as an alternative to Spark/Scala, which will facilitate compiling the parts of the computational graph that are big linear algebra to GPU / TPU.",well sweet best answer also slack roughly speaking efficient distributed efficiency number network case linear regression quotient rotational invariance problem compression network usage independent case staring formula beta compute reducing choose compute reducing compute beta big data trivially parallelize compute step tiny linear solve obtain beta extra bit standard error number fun ton like test common set version hail used compute genetic association date couple testing genome across additional data partitioned matrix accommodate growing number moving general block checkerboard partitioning strategy dash note natural generalization also linear regression block partitioning implement version python also hoon cho best provide version statistical genetics community building great work berger done area clear none specific love mathematical useful find way whatever make useful practice blas hail also math process along trait variant ax team building alternative facilitate computational graph big linear algebra,issue,positive,positive,positive,positive,positive,positive
483205034,"I don't t remember what @replomancer wrote , but one way of doing this is to have a bash script run first that find all jupyter notebooks and runs jupyter convert ... The command to convert jupyter notebooks to Python script and run the Python scripts as unit tests. ",remember wrote one way bash script run first find convert command convert python script run python unit,issue,negative,positive,positive,positive,positive,positive
483156603,I think I even wrote about this on Slack a few months ago. I'd like to get involved in development again. Can I take this one?,think even wrote slack ago like get involved development take one,issue,negative,neutral,neutral,neutral,neutral,neutral
482766231,"I think what I meant is that it would be nice if there was minimal thought for a user when interacting with this abstraction.  With a context manager, one could take code that runs in the normal way (i.e. interactively sending tensors/RPCs), wrap it with a single line, and all of a sudden have it execute as a plan.  So a user can focus on the logic of their code without worrying about batching things up, and then the jump from that to something more optimized is a one-step thought.

What might make a context manager useful at addressing the original comment is that lazy methods can be handled in a way that seems non-lazy.  I'm a bit far removed from the codebase so I'm not sure what this means in practice, but I hope this makes sense conceptually.",think meant would nice minimal thought user abstraction context manager one could take code normal way sending wrap single line sudden execute plan user focus logic code without worrying jump something thought might make context manager useful original comment lazy handled way bit far removed sure practice hope sense conceptually,issue,positive,positive,positive,positive,positive,positive
482679270,"I feel that we're trying to hard to make the tensor interface work for the plan interface (pointers, search, send, ...) when in practice it doesn't bring that many benefits as we expect.

Having said that I think the first option (send -> delegate (or something else)) could be a cleaner and easier to follow interface than actually trying to explain how send works for plans.",feel trying hard make tensor interface work plan interface search send practice bring many expect said think first option send delegate something else could cleaner easier follow interface actually trying explain send work,issue,negative,positive,positive,positive,positive,positive
482679096,One of those APIs was a context manager that compiles code that's sent and executes when you leave it -- could be an interesting option to investigate,one context manager code sent leave could interesting option investigate,issue,negative,positive,positive,positive,positive,positive
482678669,"Just to chime in an opinion without much context -- the ability to take code that's executed dynamically (i.e. without a plan) and turn it into code that's compiled statically (i.e. with a plan) should require as little modification as possible, since I imagine the intended workflow would be to develop code dynamically (for intuition) in preparation to deploy it statically (for speed).  There are past issues where we explored various APIs for this, although they may have never left the Grid project.",chime opinion without much context ability take code executed dynamically without plan turn code statically plan require little modification possible since imagine intended would develop code dynamically intuition preparation deploy statically speed past various although may never left grid project,issue,negative,negative,neutral,neutral,negative,negative
482651440,"You're right this is a real problem. The lazy behaviour is because we need to build the plan prior to sending it, so we wait until it is executed on some data to sent it, otherwise we should run it on mock data which would very un practical.

One thing easy would be to change the name .send() to something else so that there would be no confusion, like .delegate()
Another possibility would be that A send a plan empty to B and B fills it when the sender A executes it with some pointers to B, with some mechanism to create. If C request plan execution to B before it is built it would raise some error.",right real problem lazy behaviour need build plan prior sending wait executed data sent otherwise run mock data would un practical one thing easy would change name something else would confusion like another possibility would send plan empty sender mechanism create request plan execution built would raise error,issue,negative,positive,neutral,neutral,positive,positive
482570527,"Sure - I've used the ""Federated CIFAR 10 Example"" here on GitHub from `/examples/tutorials/advanced/`and only changed the line `model = Net().to(device)` into `import torchvision.models as models; model = models.resnet18().to(device)` while leaving everything else untouched. 

You can reproduce this by simply changing this line on the tutorial in the jupyter notebook and start the training process. ",sure used example line model net device import model device leaving everything else untouched reproduce simply line tutorial notebook start training process,issue,negative,positive,positive,positive,positive,positive
482499974,"Hi @flo257 - it sounds like there's an issue with the way the model is deserialized. In particular, we have to wrap all of our custom tensor types (wrapped by empty tensors). There's no reason why your operation shouldn't work - but it's hard for me to debug without seeing the code. Can you upload what you've got here? How can I reproduce?",hi like issue way model particular wrap custom tensor wrapped empty reason operation work hard without seeing code got reproduce,issue,negative,negative,neutral,neutral,negative,negative
481791982,"Ah! I changed the remote branch name. I forgot this was opened

This is the new PR

https://github.com/OpenMined/PySyft/pull/2056",ah remote branch name forgot new,issue,negative,positive,neutral,neutral,positive,positive
481751550,"@flo257 Thank you for raising this issue.We haven't particularly thought of developing support for pretrained models from torch vision , but in the near future we will ensure the support for it is taken care of :) ",thank raising particularly thought support torch vision near future ensure support taken care,issue,positive,positive,neutral,neutral,positive,positive
481231089,"@mari-linhares I'll add an option to have several locations at the same time - it's work already done but I should have cleaned and pushed it, so if you need it tell me I will make it available faster",add option several time work already done need tell make available faster,issue,negative,positive,positive,positive,positive,positive
481230774,Except the point you mention everything is good for me!,except point mention everything good,issue,negative,positive,positive,positive,positive,positive
480877598,"Thanks @peter9711 for reporting this issue, don't hesitate tu put the full stacktrace next time, the real message was in the part you cut. I'm issuing a fix in a few minutes!",thanks peter issue hesitate tu put full next time real message part cut issuing fix,issue,negative,positive,positive,positive,positive,positive
480867982,The thing is that we haven't hooked torch.randn yet. Check issue https://github.com/OpenMined/PySyft/issues/2046 we should hopefully get it ready soon. For now what you could do is create a random array in numpy and convert it to a torch tensor. ,thing hooked yet check issue hopefully get ready soon could create random array convert torch tensor,issue,positive,negative,negative,negative,negative,negative
480599610,Can you give an example of what you would like and you error you get at the moment ?,give example would like error get moment,issue,negative,neutral,neutral,neutral,neutral,neutral
480472267,Excellent work Silvia! And Also excellent reviewing Bobby!,excellent work also excellent bobby,issue,positive,positive,positive,positive,positive,positive
480423958,"Cool, makes sense. Thanks for the great explanation!",cool sense thanks great explanation,issue,positive,positive,positive,positive,positive,positive
480352737,"@mari-linhares There are some minor differences which is why it helps to have a separate tutorial on it. 
For, instance unlike Torch data loader you can't load text inside the training loop and then convert them to torch tensors, you need to convert them beforehand so that they could be sent to the desired workers and there are some attributes that need to be created such as data and target. 
Although they aren't significant it helps to have the user informed about such intricacies and have code reference that works :) ",minor separate tutorial instance unlike torch data loader ca load text inside training loop convert torch need convert beforehand could sent desired need data target although significant user informed code reference work,issue,negative,positive,positive,positive,positive,positive
480349734,Is there any major difference in the creation of a federated data loader to a regular pytorch data loader?,major difference creation data loader regular data loader,issue,negative,positive,neutral,neutral,positive,positive
479181688,"@mari-linhares 
try changing `torch.set_default_tensor_type(torch.cuda.FloatTensor)` with `torch.set_default_tensor_type(torch.FloatTensor)` you will be able to reproduce original error.

`set_default_tensor_type` creates tensors of specified type and I think, setting to cuda float tensor is leading to ensuring hook is also using cuda.floattensor and hence no error as both `new_data` and `native_param_data` are on cuda

Ref: https://pytorch.org/docs/stable/torch.html#torch.set_default_tensor_type",try able reproduce original error type think setting float tensor leading hook also hence error ref,issue,negative,positive,positive,positive,positive,positive
479172574,"@bhushan23 do you know why changing the tensor to FloatTensor works? I'm not using my work computer right now, but I assume since there's no error that the data is transferred over to cuda. I'll check when I get home.",know tensor work work computer right assume since error data transferred check get home,issue,negative,positive,positive,positive,positive,positive
479016881,Irrelevant given new Async Design schema,irrelevant given new design schema,issue,negative,negative,negative,negative,negative,negative
478992953,Hey @midokura-silvia!! This is some great work! Are you in PySyft's slack? I'd love to have a chat.,hey great work slack love chat,issue,positive,positive,positive,positive,positive,positive
478760232,"> FYI, for the code snippet above I'm able to fix the error adding this line after importing torch:
> 
> `torch.set_default_tensor_type(torch.cuda.FloatTensor)`
> 
> Not sure if this is ideal for every case...

@mari-linhares nice finding. This is changing default tensor type and should be considered as a work around for now. What we are truely looking for is to to data transfer over cuda",code snippet able fix error line torch sure ideal every case nice finding default tensor type considered work around looking data transfer,issue,positive,positive,positive,positive,positive,positive
478717757,"FYI, for the code snippet above I'm able to fix the error adding this line after importing torch:

`torch.set_default_tensor_type(torch.cuda.FloatTensor)`

Not sure if this is ideal for every case...
",code snippet able fix error line torch sure ideal every case,issue,negative,positive,positive,positive,positive,positive
478714493,"Hey @LaRiffle, can you point me to where in celery project syntax it mentions task status? I couldn't find it.

Should the status be a string indicating the last operation performed with the plan?

",hey point celery project syntax task status could find status string last operation plan,issue,negative,neutral,neutral,neutral,neutral,neutral
478691100,I've been taking a look. Very promising. I'll try to find time to adapt it to what we need for Android,taking look promising try find time adapt need android,issue,negative,positive,positive,positive,positive,positive
478576777,"The start_proc method is just to run two threads. Presumably in most environments it would not be required since each machine will run on it’s own main thread. This is test harness code and should not be part of the core lib

> On Apr 1, 2019, at 7:35 AM, Marianne Linhares Monteiro <notifications@github.com> wrote:
> 
> For all examples available, or being built, the start_proc <https://github.com/OpenMined/PySyft/blob/dev/test/conftest.py#L10> function is used to create a websocket server.
> 
> Is this wrapper function always needed? If so, should we move this function to syft?
> 
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub <https://github.com/OpenMined/PySyft/issues/2029>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AAN9JgIOdKFUrAMpoycKHuitSP9LWBTiks5vce8HgaJpZM4cVfo5>.
> 

",method run two presumably would since machine run main thread test harness code part core wrote available built function used create server wrapper function always move function thread reply directly view mute thread,issue,negative,positive,positive,positive,positive,positive
478381266,Oh thank you so much @mari-linhares !!!! I have been banging my head for this for such a long time now for this! ,oh thank much banging head long time,issue,negative,positive,neutral,neutral,positive,positive
478366438,"Hi @mshubhankar, I've modified your code to use a fake dataset and I was able to train a model using multi-layers and crossentropy ([here](https://gist.github.com/mari-linhares/c6c76ed8933b6cfed785d6c95b34e5fe)).

The only big difference from my example to yours is that you're using AdamOptimizer, try to use SGD instead. I think momentum is not yet supported so that's why you may be seeing a strange behavior.

",hi code use fake able train model big difference example try use instead think momentum yet may seeing strange behavior,issue,negative,negative,neutral,neutral,negative,negative
478291487,Thank you for looking into the matter @mari-linhares . The link to the gist code is [here](https://gist.github.com/mshubhankar/94bb81d13290ed29f687fdeafefee5d9) .,thank looking matter link gist code,issue,negative,neutral,neutral,neutral,neutral,neutral
477806391,"@robert-wagner just tried your solution (#2000) with a small modification and it seems to work, can you check if it makes sense? I've just made the PR #2022. Thanks!",tried solution small modification work check sense made thanks,issue,positive,negative,neutral,neutral,negative,negative
477755453,"Hey @mshubhankar, I'm having a look at this. I'll let you know if I find anything. Can you share the notebook you're using (a [gist](https://gist.github.com/) link would be great)? Thanks!",hey look let know find anything share notebook gist link would great thanks,issue,positive,positive,positive,positive,positive,positive
477241402,"Thanks, Bobby! I ran `pre-commit install` instead of `make install_hooks` and it seems to do the job.",thanks bobby ran install instead make job,issue,negative,positive,positive,positive,positive,positive
477039455,"@XinDongol 
No, only one model is trained in Tutorial 8, in a completely sequential way. The federated_train_loader will provide in each step a remote batch of data and the model in trained on this batch. 
With the current implementation of the FederatedDataLoader, first all batches of bob are provided then the batches of alice are returned.
In the end it is the same as training the model one epoch on bob's data and then continue to train the model one epoch on alice's data.
So no federated averaging is used in this setting.",one model trained tutorial completely sequential way provide step remote batch data model trained batch current implementation first bob provided returned end training model one epoch bob data continue train model one epoch data used setting,issue,negative,positive,neutral,neutral,positive,positive
476953983,"@kamathhrishi 
Thanks for your reply. 

So if we have two clients.
```Python
bob = sy.VirtualWorker(hook, id=""bob"")  # <-- NEW: define remote worker bob
alice = sy.VirtualWorker(hook, id=""alice"")  # <-- NEW: and alice
```
This tutorial is actually training two independent models. One is bob's model on bob's data and the other one is alice's model on alice's data.

**Is it correct?**",thanks reply two python bob hook bob new define remote worker bob hook new tutorial actually training two independent one bob model bob data one model data correct,issue,negative,positive,neutral,neutral,positive,positive
476848670,"Please run black syft
you can set this up to automatically run by running make install_hooks",please run black set automatically run running make,issue,negative,negative,negative,negative,negative,negative
476774196,"Hello @XinDongol We aren't doing Federated Averaging with this tutorial. The tutorial was just to demonstrate how we could train an image classifier using federated learning. Sure , you could perform federated averaging if you would like :) ",hello tutorial tutorial demonstrate could train image classifier learning sure could perform would like,issue,positive,positive,positive,positive,positive,positive
476606943,This is awesome! I was just reading socket.io documentation last night. Very good chance we'll re-use this code for other connectors as well.,awesome reading documentation last night good chance code well,issue,positive,positive,positive,positive,positive,positive
476415231,"@iamtrask I added requirement installation, and moved the file to the PySyft root folder. I referenced the file from the 'installation' section in the  main README.md file as @robert-wagner recommended.",added requirement installation file root folder file section main file,issue,negative,positive,positive,positive,positive,positive
476409957,"@LaRiffle Here is a PR for type annotations I had started earlier. I completed the functions I had started with. However, I didn't annotation entire files. I need some more code studying to understand all the variable types.

",type however annotation entire need code understand variable,issue,negative,neutral,neutral,neutral,neutral,neutral
476394551,"Very grateful for this contribution!

might need to add ""pip install -r requirements.txt"" as well just before ""python setup.py install""",grateful contribution might need add pip install well python install,issue,positive,neutral,neutral,neutral,neutral,neutral
476381339,"Yeah, that is the first place I would look. Also maybe link it from the readme like we have with contributing.md",yeah first place would look also maybe link like,issue,positive,positive,positive,positive,positive,positive
476379198,You mean in the same folder as the main README.md file?,mean folder main file,issue,negative,negative,neutral,neutral,negative,negative
476355912,"Hey, would it be possible for you to put this in a .md file",hey would possible put file,issue,negative,neutral,neutral,neutral,neutral,neutral
476158055,"> I'm curious - do you think it would make sense to pass the compression code with the message as well? This would allow the receiving party to know how the rest of the message was compressed.

If we end up using some kind of configuration that should make it as I would expect the entire system to agree on the compression used. 
If we like more flexibility then a possibility would be adding such configuration on every message but in my opinion, that would increase the size of the stream being sent without adding much value in most cases.
We could add an extra byte to let the receiver know if the sender used `msgpack`, plain text Json, etc...",curious think would make sense pas compression code message well would allow party know rest message compressed end kind configuration make would expect entire system agree compression used like flexibility possibility would configuration every message opinion would increase size stream sent without much value could add extra let receiver know sender used plain text,issue,positive,positive,neutral,neutral,positive,positive
475057403,"> This tutorial is some of the best light vacation reading I've ever had. Really really excellent.

Thank you! :)",tutorial best light vacation reading ever really really excellent thank,issue,positive,positive,positive,positive,positive,positive
475015823,This tutorial is some of the best light vacation reading I've ever had. Really really excellent.,tutorial best light vacation reading ever really really excellent,issue,positive,positive,positive,positive,positive,positive
474186195,"Okay! Finally added tests for ~6 gradient functions. 

@iamtrask What's left to do to merge all this?",finally added gradient left merge,issue,negative,neutral,neutral,neutral,neutral,neutral
474058786,"@LaRiffle Tried this out. Trying to naively return the known worker with the same id, causes over half of the tests to fail. I am of the impression it might be best to make this simply throw a verbose error for the moment. #2000 for reference to my changes ",tried trying naively return known worker id half fail impression might best make simply throw verbose error moment reference,issue,negative,positive,neutral,neutral,positive,positive
473066833,"Awesome, I'll work on bringing that back (unless @replomancer wants to do it) and add some new annotations.",awesome work back unless add new,issue,positive,positive,positive,positive,positive,positive
472915171,"Yeah, sorry about that, will try to resolve. Currently fighting some weird issue with flake8 when run locally. Once it's resolved I will address the reformatting issues.",yeah sorry try resolve currently fighting weird issue flake run locally resolved address,issue,negative,negative,negative,negative,negative,negative
472894879,"Thank you @LaRiffle , I will work on the changes. One question, If I insert wrong types, will they be detected by the automated check?",thank work one question insert wrong check,issue,negative,negative,negative,negative,negative,negative
472892426,"At any moment, you can check all the virtual workers present on your process by retrieving syft.hook.local_worker.(known_workers) as they get automatically added to this list on __init__. Just making a search and returning the already existing one if any should fix the pb",moment check virtual present process get automatically added list making search already one fix,issue,negative,neutral,neutral,neutral,neutral,neutral
472892054,Hey @MarcioPorto It looks like that pr was made to the torch 0.3.1 branch and never made it into the torch 1.0 branch. Would be happy to have mypy support,hey like made torch branch never made torch branch would happy support,issue,positive,positive,positive,positive,positive,positive
472888778,"@antonrd As a heads up, Travis is failing because you need to run `black syft`",travis failing need run black,issue,negative,negative,negative,negative,negative,negative
472883996,Small PR that would hopefully help a bit with this issue: https://github.com/OpenMined/PySyft/pull/1994,small would hopefully help bit issue,issue,positive,negative,negative,negative,negative,negative
472694437,"@robert-wagner @iamtrask I am planning on doing some further work on this issue, and I noticed that `.mypy_cache/` was removed from `.gitignore` in ab6c727c877019640342d3297e9a86028487cce9. I also can't locate a lot of the work done in https://github.com/OpenMined/PySyft/pull/1641.

Does this mean we're moving away from using mypy?

UPDATE: mypy stubs files were deleted in 1721cfee916dbcfc5fe951a8b31ae48d4a5639b2",work issue removed also ca locate lot work done mean moving away update,issue,negative,negative,negative,negative,negative,negative
472144038,@Ankk98 Feel free to work on it! I will be iterating on it over time but would love any help.,feel free work time would love help,issue,positive,positive,positive,positive,positive,positive
471957843,"Sorry - i meant ""type annotations"" which we want for all methods.",sorry meant type want,issue,negative,negative,negative,negative,negative,negative
471759453,"Oh this is strange, and you didn't make any changes in the code or imports ?",oh strange make code,issue,negative,negative,neutral,neutral,negative,negative
471658639,"> Can we add static type information to method parameters?

What are you thinking about? (which methods?)",add static type information method thinking,issue,negative,positive,positive,positive,positive,positive
471247563,"> Would you mind sharing the complete snippet of code you used?
> Thanks!

https://github.com/OpenMined/PySyft/blob/dev/examples/tutorials/Part%208%20-%20Federated%20Learning%20on%20MNIST%20using%20a%20CNN.ipynb

 I tried to run exact code from this link but it showed that error.",would mind complete snippet code used thanks tried run exact code link error,issue,negative,positive,positive,positive,positive,positive
471247463,"*THIS IS  THE CODE SNIPPET :- *
federated_train_loader = sy.FederatedDataLoader( # <-- this is now a FederatedDataLoader 
    datasets.MNIST('../data', train=True, download=True,
                   transform=transforms.Compose([
                       transforms.ToTensor(),
                       transforms.Normalize((0.1307,), (0.3081,))
                   ]))
    .federate((bob, alice)), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset
    batch_size=args.batch_size, shuffle=True, **kwargs)

test_loader = torch.utils.data.DataLoader(
    datasets.MNIST('../data', train=False, transform=transforms.Compose([
                       transforms.ToTensor(),
                       transforms.Normalize((0.1307,), (0.3081,))
                   ])),
    batch_size=args.test_batch_size, shuffle=True, **kwargs)

*THIS IS THE ERROR :- *

---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-8-4085cd6569bc> in <module>
      3                    transform=transforms.Compose([
      4                        transforms.ToTensor(),
----> 5                        transforms.Normalize((0.1307,), (0.3081,))
      6                    ]))
      7     .federate((bob, alice)), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset

AttributeError: 'MNIST' object has no attribute 'federate'
",code snippet bob new distribute across error recent call last module bob new distribute across object attribute,issue,negative,positive,neutral,neutral,positive,positive
471178365,"Hi, this has been fixed in #1982
The change should be already in dev branch, and next week in master
You can now use this code and it should work!",hi fixed change already dev branch next week master use code work,issue,negative,positive,neutral,neutral,positive,positive
471178170,"Would you mind sharing the complete snippet of code you used?
Thanks!",would mind complete snippet code used thanks,issue,negative,positive,positive,positive,positive,positive
471172522,"I think it is now fixed. The major issue you add was `% self.field` because it is not behaving as you would expect: `-3 % 100 == 97 != -3`
I've created an algebric_modulo method which fixes this, but for now I've just removed moduli, they are only and however needed with larger numeric values, so algebric_modulo will be useful",think fixed major issue add would expect method removed however useful,issue,negative,positive,positive,positive,positive,positive
470916020,"Nice catch ! What I'll do instead is to pass the kwargs to the FederatedDataLoader, even if for now it is not handled (added a warning for clarity)
Also, I will update tutorial Part 8.",nice catch instead pas even handled added warning clarity also update tutorial part,issue,negative,positive,positive,positive,positive,positive
470864511,Thank you for leaving good comments here - makes it really easy to stay updated :),thank leaving good really easy stay,issue,positive,positive,positive,positive,positive,positive
470303533,"@robert-wagner I have taken your comments into account, please check my new update to this PR",taken account please check new update,issue,negative,positive,positive,positive,positive,positive
470130991,"Hey @alaaboudib , most of the time notifications are sent through either the code channel or through email for new prs but they can sometimes get missed. If you want a specific person to review your pr, it is usually best to either tag them in the pr or ping them on slack. It is possible to assign reviewers but I am not sure the permissions needed for that",hey time sent either code channel new sometimes get want specific person review usually best either tag ping slack possible assign sure,issue,positive,positive,positive,positive,positive,positive
470098675,"@LaRiffle @iamtrask 
Do you guys receive automatic notifications for PRs or should I tag reviewers explicitly? 

It seems that I cannot choose reviewers for this PR",receive automatic tag explicitly choose,issue,negative,neutral,neutral,neutral,neutral,neutral
470019706,"max is one between others (torch.split, etc.), basically all functions that can return more than one tensors with fail if they are run remotely as we explicitely always make the assumption the response is a unique tensor.",one basically return one fail run remotely always make assumption response unique tensor,issue,negative,negative,neutral,neutral,negative,negative
469928612,"@iamtrask I was wondering, if we should build an interface to directly enable all torch tensor functionalities to pointer tensor? Is that something useful? Do we require all torch functionality for pointer tensor? Why do we specifically need max?",wondering build interface directly enable torch tensor pointer tensor something useful require torch functionality pointer tensor specifically need,issue,negative,positive,positive,positive,positive,positive
469867390,"```
import torch 
import syft as sy
hook = sy.TorchHook(torch)
bob = sy.VirtualWorker(hook, id=""bob"")
x = torch.tensor([1,2,3,4,5])
x_ptr = x.send(bob)
print(x_ptr.max())
```

Currently, `x_ptr.max()` returns  `(Wrapper)>[PointerTensor | me:73509977871 -> bob:73509977871]`
and instead, should return `5` right?
",import torch import hook torch bob hook bob bob print currently wrapper bob instead return right,issue,negative,positive,positive,positive,positive,positive
469493067,@robert-wagner what about having a local queue and a remote queue and having two different async listeners?,local queue remote queue two different,issue,negative,negative,neutral,neutral,negative,negative
469305064,Hey @alaaboudib I tagged you in the pr (it is linked above this message),hey tagged linked message,issue,negative,neutral,neutral,neutral,neutral,neutral
469294158,Hey @alaaboudib I didn't see that you were interested in doing this issue before completing it myself this morning. Sorry about that :slightly_smiling_face: ,hey see interested issue morning sorry,issue,negative,negative,negative,negative,negative,negative
469261181,"@LaRiffle np! btw, do we need this on the `dev` branch? I wasn't too familiar with the branching strategy in this repository.",need dev branch familiar branching strategy repository,issue,negative,positive,positive,positive,positive,positive
469202719,So while this will technically get rid of the error in #1893 I'm not sure it's the fix we want long term. We really do want to support GPUs as opposed to always pushing everything to the CPU. :),technically get rid error sure fix want long term really want support opposed always pushing everything,issue,negative,positive,positive,positive,positive,positive
469056900,"in data(): `new_data` is cuda whereas native_param_data is `cpu`
fix should be moving new_data to cpu while setting native_param_data
Please correct me if I'm wrong",data whereas fix moving setting please correct wrong,issue,negative,negative,negative,negative,negative,negative
469056274,"I would like to take this up.
Could you please give me some pointers?",would like take could please give,issue,positive,neutral,neutral,neutral,neutral,neutral
469018147,Yes sure go ahead! :),yes sure go ahead,issue,positive,positive,positive,positive,positive,positive
469016785,"Hello @iamtrask, @robert-wagner , 

I am new to OpenMined.

I made an attempt to contribute to this issue, just a few type annotations to syft/workers/virutal.py.

Can I submit a PR?

Thanks",hello new made attempt contribute issue type submit thanks,issue,negative,positive,positive,positive,positive,positive
469010020,"@robert-wagner I am interested in this issue. However, I am new to PySyft, I just followed the 8 tutorials. Can you please explain this issue a bit more? maybe give a concrete example of what you are willing to have as a result?",interested issue however new please explain issue bit maybe give concrete example willing result,issue,positive,positive,positive,positive,positive,positive
468391024,"I think your solution is elegant by making async tasks a chain,  however, have you ever checked this paper? http://papers.nips.cc/paper/4687-large-scale-distributed-deep-networks.pdf   I just had a glance,  it might be more practical for large scale , though you may say it's not real asyn...

>  To apply SGD to large data sets, we introduce Downpour SGD, a variant of asynchronous stochastic gradient descent that uses multiple replicas of a single DistBelief model. The basic approach is as follows: We divide the training data into a number of subsets and run a copy of the model on each of these subsets. The models communicate updates through a centralized parameter server, which keeps the current state of all parameters for the model, sharded across many machines (e.g., if we have 10 parameter server shards, each shard is responsible for storing and applying updates to 1/10th of the model parameters) (Figure 2). This approach is asynchronous in two distinct aspects: the model replicas run independently of each other, and the parameter server shards also run independently of one another.",think solution elegant making chain however ever checked paper glance might practical large scale though may say real apply large data introduce downpour variant asynchronous stochastic gradient descent multiple single model basic approach divide training data number run copy model communicate parameter server current state model sharded across many parameter server shard responsible model figure approach asynchronous two distinct model run independently parameter server also run independently one another,issue,positive,positive,positive,positive,positive,positive
468359968,"This seems complicated, would involve registering datasets objects which we dont want to do, better way would be to make a special method to search a dataset (ie given a set of tags T, and search T + #train and T + #test and build a Dataset out of the referenced)",complicated would involve dont want better way would make special method search ie given set search train test build,issue,negative,positive,positive,positive,positive,positive
467616116,Yeah! NamedTensors look awesome. This would definitely be a fun project at some point.,yeah look awesome would definitely fun project point,issue,positive,positive,positive,positive,positive,positive
467488320,Elaborate a little bit on all of routing of how to load this data?,elaborate little bit routing load data,issue,negative,positive,positive,positive,positive,positive
467480678,"Working on AutogradTensor and running into this issue. I'm storing gradients after backprop to `.grad` on Autograd tensors, but the gradients aren't available on the Wrapper at the top of the chain with `.grad`. I think we'll need `.grad` to work on Wrappers to use PyTorch's optimizers.",working running issue available wrapper top chain think need work use,issue,negative,positive,positive,positive,positive,positive
467480521,Hey - not sure the status of this but i think this bug was on 0.3.1 which is now deprecated. We'd like to instead build this on torch 1.0 branch (master/dev),hey sure status think bug like instead build torch branch,issue,positive,positive,positive,positive,positive,positive
467316410,"Thanks a lot.
I'll try on torch_031 branch.",thanks lot try branch,issue,negative,positive,positive,positive,positive,positive
467316000,"The tutorials on Federated Learning are very much working :) 

https://github.com/OpenMined/PySyft/tree/dev/examples/tutorials for Torch1 version of PySyft. Currently, Torch 1 supports only federated learning and DP is under experimental which you could review if you would like to. 

 We did have SMPC on our previous version supported for torch 0.3.1 version only.

https://github.com/OpenMined/PySyft/tree/torch_031/examples/tutorials
",learning much working torch version currently torch learning experimental could review would like previous version torch version,issue,negative,positive,neutral,neutral,positive,positive
467274121,"Making progress. This time I set it up so that AutogradTensor automatically checks if a method has a gradient function defined in gradients.py. As we add gradients to derivatives.yaml, they'll automatically be available in the autograd system.

Something I need help with is having `.grad` work for Wrappers... ",making progress time set automatically method gradient function defined add automatically available system something need help work,issue,positive,positive,positive,positive,positive,positive
467031433,"Well , This is still not ready for review. I have to complete it. ",well still ready review complete,issue,positive,positive,positive,positive,positive,positive
466826624,"In the last commit I wrote some functionality to generate grad_fn classes from a file called derivatives.yaml using build_gradients.py. It's similar to this file from Pytorch: https://github.com/pytorch/pytorch/blob/master/tools/autograd/derivatives.yaml. Except that I'm generating a Python file. 

This structure should make it easier to construct gradient functions for Tensor methods. I think the next step is to generate methods that can be attached to Autograd. ",last commit wrote functionality generate class file similar file except generating python file structure make easier construct gradient tensor think next step generate attached,issue,positive,neutral,neutral,neutral,neutral,neutral
466779965,"Nice changes! Now there is still something to think about: the role of the PlanWorker is here to 1. batch the commands and 2. to execute them all at once. Maybe what we really what to do is to have a PlanWorker working as an auxiliary of the local worker (so on the same machine) (doing 1.), and when the plan is ready for execution, to send it to a real remote worker (which will do 2.). Thoughts?",nice still something think role batch execute maybe really working auxiliary local worker machine plan ready execution send real remote worker,issue,positive,positive,positive,positive,positive,positive
466528108,I *think* I fixed tests (they work on my machine) - we'll see if Travis likes it.,think fixed work machine see travis,issue,negative,positive,neutral,neutral,positive,positive
465728210,Progress! You can get the graph using `.grad_fn.next_functions`. Let's see if I can hack something out today,progress get graph let see hack something today,issue,negative,neutral,neutral,neutral,neutral,neutral
465725147,"I've been exploring this. I think the best option here is to use the `grad_fn` methods created by torch operations. For example:

```python
x = torch.tensor([1., 2., 3.], requires_grad=True)
y = x**2
z = y.mean()

grad_z_y = z.grad_fn(torch.ones_like(z)) # gradient of z w.r.t. y
# grad_z_y == tensor([0.3333, 0.3333, 0.3333])

grad_y_x = y.grad_fn(grad_z_y) # gradient of y w.r.t. x
# grad_y_x == tensor([0.6667, 1.3333, 2.0000])

# we should actually accumulate here
x.grad = grad_y_x

# now we should be able to run the optimizer step
```

If I can figure out how to go backwards through the graph, I should be able to use `.grad_fn` to calculate all the necessary gradients.

@iamtrask Would having the outputs of `.grad_fn` be good enough for DP?

",exploring think best option use torch example python gradient tensor gradient tensor actually accumulate able run step figure go backwards graph able use calculate necessary would good enough,issue,positive,positive,positive,positive,positive,positive
465464749,"I saw what happened. This happened just because I runed it twice on my spyder. Maybe this was what iamtrask said 'the VirtualWorker was created twice'.
This program can only run once on your python or restart it!!
Thank you all for help!
",saw runed twice maybe said twice program run python restart thank help,issue,positive,neutral,neutral,neutral,neutral,neutral
465457042,"> Does the code run when it is in the notebook?

I run it in my spyder.",code run notebook run,issue,negative,neutral,neutral,neutral,neutral,neutral
465456759,"> This is almost certainly because the VirtualWorker was created twice.

Can you tell me more? I just create bob once by 'bob = sy.VirtualWorker(hook, id=""bob"")'. Where is the other one? Do you mean that one 'hook = sy.TorchHook(torch)'? In the tutorial, you say that create 'me' (<VirtualWorker id:me #tensors:0>) automatically. But does it affact 'bob'? I saw 'z' belongs to 'bob' by the command 'print(z)' and can't get back.
Or can you tell me the right case?
Thank you!",almost certainly twice tell create bob hook bob one mean one torch tutorial say create id automatically saw command ca get back tell right case thank,issue,positive,positive,neutral,neutral,positive,positive
465257393,"With this in mind, gaussian sampling is very easy to do in an additivly shared setting (the sum of two gaussians is a gaussian)",mind sampling easy setting sum two,issue,negative,positive,positive,positive,positive,positive
465193734,"TODO: make this string comparison more efficient

https://github.com/OpenMined/PySyft/blob/dev/syft/frameworks/torch/tensors/interpreters/precision.py#L190",make string comparison efficient,issue,negative,neutral,neutral,neutral,neutral,neutral
464797052,"It's not about GPUs at the moment, it's juste about sending a command .to('cpu') over the network",moment sending command network,issue,negative,neutral,neutral,neutral,neutral,neutral
464764592,I'm not sure that's possible in travis - we don't have GPU support there.,sure possible travis support,issue,positive,positive,positive,positive,positive,positive
464193316,"I am still getting the same error messages and exceptions as reported originally. 
EDIT: I installed the latest syft-0.1.1a2 version using pip for my test. I used both your notebook and the MNIST example copied to this issue. 
EDIt: Tried with syft-0.1.2a1 still the same error and now it hangs after printing errors/exceptions.
@LaRiffle can you open this issue and leave it open until it is resolved?",still getting error originally edit latest version pip test used notebook example copied issue edit tried still error printing open issue leave open resolved,issue,negative,positive,positive,positive,positive,positive
463327705,Note: while DP will be an early user of this project - all work should be decoupled from DP as we'll be using it for other areas as well (like encrypted training),note early user project work well like training,issue,positive,positive,neutral,neutral,positive,positive
463279594,"Hi @bigdata2 
This is now solved! We have made a notebook tutorial for this case: https://github.com/OpenMined/PySyft/blob/dev/examples/tutorials/Part%208%20-%20Federated%20Learning%20on%20MNIST%20using%20a%20CNN.ipynb
",hi made notebook tutorial case,issue,negative,neutral,neutral,neutral,neutral,neutral
462890028,"After further review, this pull request will not be merged because the logic for generating tripples is not general enough. Just keeping this around for my reference until the new version is written",review pull request logic generating general enough keeping around reference new version written,issue,negative,positive,neutral,neutral,positive,positive
462802052,"```
Traceback (most recent call last):
  File ""test.py"", line 37, in <module>
    model = Net().to(device)                                                                                                                                   
  File ""/network/home/maloneyj/.local/lib/python3.6/site-packages/torch/nn/modules/module.py"", line 381, in to
    return self._apply(convert)
  File ""/network/home/maloneyj/.local/lib/python3.6/site-packages/torch/nn/modules/module.py"", line 187, in _apply
    module._apply(fn)
  File ""/network/home/maloneyj/.local/lib/python3.6/site-packages/torch/nn/modules/module.py"", line 193, in _apply
    param.data = fn(param.data)
  File ""/network/home/maloneyj/PySyft/syft/frameworks/torch/hook.py"", line 339, in data
    self.native_param_data.set_(new_data)  # .wrap()
RuntimeError: Expected object of backend CPU but got backend CUDA for argument #2 'source'
```",recent call last file line module model net device file line return convert file line file line file line data object got argument,issue,negative,neutral,neutral,neutral,neutral,neutral
462797173,I think we can add .grad and .data creation to __init__ of AbstractTensor which would make this work. ,think add creation would make work,issue,negative,neutral,neutral,neutral,neutral,neutral
462422332,"@LaRiffle - ok good point - maybe we can do a followon later which really leans on search as sortof ""what deep learning will look like in the future."" This would actually make for a killer blogpost too.",good point maybe later really search deep learning look like future would actually make killer,issue,negative,positive,positive,positive,positive,positive
462394359,"@jlebensold I believe that this MNIST demo is intended for people joining OM with a PyTorch background, so we should be as close as possible from the PyTorch official example to that people understand that FL can be turned on with very few changes.
 So I would rather focus on having a search + FederatedDataset + FederatedLoader stack for the data (very close to the official example)
and also I agree cuda would be cool, but I don't know how hard this is.",believe intended people joining om background close possible official example people understand turned would rather focus search stack data close official example also agree would cool know hard,issue,positive,positive,neutral,neutral,positive,positive
462380177,"@LaRiffle and I are working through an example.

I think that any MNIST demo needs to have the following design requirements:

1. The orchestrator (federated server) should not know about the individual datasets or tensors on each worker
2. CUDA support
3. An approach to messaging that is protocol independent and supports different implementations of the same code",working example think need following design orchestrator server know individual worker support approach protocol independent different code,issue,negative,neutral,neutral,neutral,neutral,neutral
462273742,"Can you add the stacktrace?
One **good-first-issue** would be in the case you have only cpu, and try to call .to(device), to fix the error which is only due to us not serializing devices. This could be easily handled.
_The part with the gpu and cuda is not part of the good-first-issue._",add one would case try call device fix error due u could easily handled part part,issue,negative,positive,positive,positive,positive,positive
462072808,"I'm doing good progress in having the CNN layers + Pool + backward working in a full FL setting.
Ping me if you open a PR on this, I'll add my work to have the complete example with the FederatedDataset :) ",good progress pool backward working full setting ping open add work complete example,issue,positive,positive,positive,positive,positive,positive
462040632,Can you give a code snippet showing how to reproduce a failure?,give code snippet showing reproduce failure,issue,negative,negative,negative,negative,negative,negative
462006055,@robert-wagner I think this is related to `randperm`. Is it possible we're not hooking it correctly? ,think related possible correctly,issue,negative,neutral,neutral,neutral,neutral,neutral
462003060,"Hi @robert-wagner here is the code.
```
import syft as sy
import copy
import torch
from torch import nn, optim
from torchvision import datasets, transforms
import torch.nn.functional as F
import argparse

# Training settings
parser = argparse.ArgumentParser(description='PyTorch MNIST Example')
parser.add_argument('--batch-size', type=int, default=64, metavar='N',
                    help='input batch size for training (default: 64)')
parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',
                    help='input batch size for testing (default: 1000)')
parser.add_argument('--epochs', type=int, default=10, metavar='N',
                    help='number of epochs to train (default: 10)')
parser.add_argument('--lr', type=float, default=0.01, metavar='LR',
                    help='learning rate (default: 0.01)')
parser.add_argument('--momentum', type=float, default=0.5, metavar='M',
                    help='SGD momentum (default: 0.5)')
parser.add_argument('--no-cuda', action='store_true', default=False,
                    help='disables CUDA training')
parser.add_argument('--seed', type=int, default=1, metavar='S',
                    help='random seed (default: 1)')
parser.add_argument('--log-interval', type=int, default=10, metavar='N',
                    help='how many batches to wait before logging training status')
args = parser.parse_args([])
args.cuda = not args.no_cuda and torch.cuda.is_available()

class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)
        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)
        self.conv2_drop = nn.Dropout2d()
        self.fc1 = nn.Linear(320, 50)
        self.fc2 = nn.Linear(50, 10)

    def forward(self, x):
        x = F.relu(F.max_pool2d(self.conv1(x), 2))
        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))
        x = x.view(-1, 320)
        x = F.relu(self.fc1(x))
        x = F.dropout(x, training=self.training)
        x = self.fc2(x)
        return F.log_softmax(x, dim=1)

model = Net()

kwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}
train_loader = torch.utils.data.DataLoader(
    datasets.MNIST('../data', train=True, download=True,
                   transform=transforms.Compose([
                       transforms.ToTensor(),
                       transforms.Normalize((0.1307,), (0.3081,))
                   ])),
    batch_size=args.batch_size, shuffle=True, **kwargs)
test_loader = torch.utils.data.DataLoader(
    datasets.MNIST('../data', train=False, transform=transforms.Compose([
                       transforms.ToTensor(),
                       transforms.Normalize((0.1307,), (0.3081,))
                   ])),
    batch_size=args.test_batch_size, shuffle=True, **kwargs)

dataset_train = datasets.MNIST('../data/', train=True, download=True,
                       transform=transforms.Compose([
                       transforms.ToTensor(),
                       transforms.Normalize((0.1307,), (0.3081,))
                ]))

hook = sy.TorchHook(torch)
# create a couple workers
bob = sy.VirtualWorker(hook, id=""bob"")
alice = sy.VirtualWorker(hook, id=""alice"")
secure_worker = sy.VirtualWorker(hook, id=""secure_worker"")

bob.add_workers([alice, secure_worker])
alice.add_workers([bob, secure_worker])
secure_worker.add_workers([alice, bob])

train_distributed_dataset  = []
for batch_idx, (data,target) in enumerate(train_loader):
    if batch_idx > 4: break
    data = sy.Var(data)
    target = sy.Var(target.long())
    data.send(bob)
    target.send(bob)
    train_distributed_dataset.append((data, target))

bobs_model = Net()
bobs_opt = optim.SGD(params=bobs_model.parameters(),lr=0.1)
bobs_model = bobs_model.send(bob)

for batch_idx, (data,target) in enumerate(train_distributed_dataset):

    print(data)
    bobs_model.send(data.location)
    # Train Bob's Model
    bobs_opt.zero_grad() 
    bobs_pred = bobs_model(data)
    bobs_loss = F.nll_loss(bobs_pred, target)
    bobs_loss.backward()
    bobs_opt.step()
    bobs_loss = bobs_loss.get().data[0]
```",hi code import import copy import torch torch import import import import training parser example batch size training default batch size testing default train default rate default momentum momentum default training seed seed default many wait logging training status class net self super net self forward self return model net true else hook torch create couple bob hook bob hook hook bob bob data target enumerate break data data target bob bob data target net bob data target enumerate print data train bob model data target,issue,positive,positive,positive,positive,positive,positive
461689753,Hey @bigdata2 Could you send the code which throws that error?,hey could send code error,issue,negative,neutral,neutral,neutral,neutral,neutral
461652653,this will allow people to know that if they keep using the same version of the software nothing changes,allow people know keep version nothing,issue,negative,neutral,neutral,neutral,neutral,neutral
461652541,seems customary to only update master when we actually change version numbers (which we can totally do regularly... but we want to be intentional about it),customary update master actually change version totally regularly want intentional,issue,negative,neutral,neutral,neutral,neutral,neutral
461652426,Just as a matter of practice -  let's do dev,matter practice let dev,issue,negative,neutral,neutral,neutral,neutral,neutral
461499274,"Hi @pranav-ap,  Just make a PR with corrected spelling.",hi make corrected spelling,issue,negative,neutral,neutral,neutral,neutral,neutral
461178072,"Calling send on a parameter containing a pointer tensor calls _simplify_pointer_tensor twice
Parameter>[PointerTensor - 67201391700@bob]
simplifying pointer tensor
simplifying pointer tensor
detailing pointing tensor
detailing pointing tensor",calling send parameter pointer tensor twice parameter bob pointer tensor pointer tensor pointing tensor pointing tensor,issue,negative,neutral,neutral,neutral,neutral,neutral
460917056,"Late, but you might find this useful: https://github.com/dadadel/pyment",late might find useful,issue,negative,neutral,neutral,neutral,neutral,neutral
460877844,"Hi, torch 1.0 does not work for me, I get the following exception;

> Process Process-1:
> Traceback (most recent call last):
>   File ""/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook_args.py"", line 104, in hook_function_args
>     hook_args = hook_method_args_functions[attr]
> KeyError: 'torch._C.set_num_threads'
> 
> During handling of the above exception, another exception occurred:
> 
> Traceback (most recent call last):
>   File ""/usr/lib/python3.6/multiprocessing/process.py"", line 258, in _bootstrap
>     self.run()
>   File ""/usr/lib/python3.6/multiprocessing/process.py"", line 93, in run
>     self._target(*self._args, **self._kwargs)
>   File ""/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py"", line 111, in _worker_loop
>     torch.set_num_threads(1)
>   File ""/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook.py"", line 489, in overloaded_attr
>     response = TorchTensor.handle_func_command(command)
>   File ""/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/tensors/interpreters/native.py"", line 158, in handle_func_command
>     new_args, new_type = syft.frameworks.torch.hook_args.hook_function_args(cmd, args)
>   File ""/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook_args.py"", line 112, in hook_function_args
>     args, return_tuple=True
>   File ""/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook_args.py"", line 134, in build_hook_args_function
>     get_tensor_type_function = build_get_tensor_type(rule)
>   File ""/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook_args.py"", line 327, in build_get_tensor_type
>     return lambdas[0]
> IndexError: list index out of range
> Traceback (most recent call last):
>   File ""/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook_args.py"", line 104, in hook_function_args
>     hook_args = hook_method_args_functions[attr]
> KeyError: 'torch.randperm'
> 
> During handling of the above exception, another exception occurred:
> 
> Traceback (most recent call last):
>   File ""test1.py"", line 83, in <module>
>     for batch_idx, (data,target) in enumerate(train_loader):
>   File ""/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py"", line 819, in __iter__
>     return _DataLoaderIter(self)
>   File ""/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py"", line 584, in __init__
>     self._put_indices()
>   File ""/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py"", line 646, in _put_indices
>     indices = next(self.sample_iter, None)
>   File ""/usr/local/lib/python3.6/dist-packages/torch/utils/data/sampler.py"", line 160, in __iter__
>     for idx in self.sampler:
>   File ""/usr/local/lib/python3.6/dist-packages/torch/utils/data/sampler.py"", line 73, in __iter__
>     return iter(torch.randperm(n).tolist())
>   File ""/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook.py"", line 489, in overloaded_attr
>     response = TorchTensor.handle_func_command(command)
>   File ""/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/tensors/interpreters/native.py"", line 158, in handle_func_command
>     new_args, new_type = syft.frameworks.torch.hook_args.hook_function_args(cmd, args)
>   File ""/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook_args.py"", line 112, in hook_function_args
>     args, return_tuple=True
>   File ""/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook_args.py"", line 134, in build_hook_args_function
>     get_tensor_type_function = build_get_tensor_type(rule)
>   File ""/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook_args.py"", line 327, in build_get_tensor_type
>     return lambdas[0]
> IndexError: list index out of range",hi torch work get following exception process recent call last file line handling exception another exception recent call last file line file line run file line file line response command file line file line file line rule file line return list index range recent call last file line handling exception another exception recent call last file line module data target enumerate file line return self file line file line index next none file line file line return iter file line response command file line file line file line rule file line return list index range,issue,negative,neutral,neutral,neutral,neutral,neutral
460816275,"Good idea - also like the ""many_fold"" final option.",good idea also like final option,issue,positive,positive,positive,positive,positive,positive
460676936,In the new master branch based on torch 1.0 - we have automatic garbage collection - which should mitigate this.,new master branch based torch automatic garbage collection mitigate,issue,negative,positive,positive,positive,positive,positive
460675936,"We're doing a massive refactor with the release of pytorch 1.0, please re-open an issue if you still have this problem, thanks! :)",massive release please issue still problem thanks,issue,negative,positive,neutral,neutral,positive,positive
460675251,The current version of PySyft does not support Tensorflow. See https://arxiv.org/pdf/1902.01046.pdf for a Federated Learning implementation in Tensorflow.,current version support see learning implementation,issue,negative,neutral,neutral,neutral,neutral,neutral
460674115,Hi @miranthajayatilake thanks for reporting this. Are you still having trouble with `PointerTensor` on our master branch? We've just refactored for torch 1,hi thanks still trouble master branch torch,issue,negative,neutral,neutral,neutral,neutral,neutral
460673459,Hi @miranthajayatilake we've gone through a significant refactor for Torch 1. Check out our new federated learning implementation.,hi gone significant torch check new learning implementation,issue,negative,positive,positive,positive,positive,positive
460672896,This should be resolved at this point. Please open a new issue if you're still having trouble.,resolved point please open new issue still trouble,issue,negative,negative,neutral,neutral,negative,negative
460672846,We will revisit this in torch 1.0 - the big issue here is that we need to add CRTTensor to be able to handle larger values #1524 ,revisit torch big issue need add able handle,issue,negative,positive,positive,positive,positive,positive
460672355,"Hi @bigdata2 can you see if you're experiencing these issues on the new master branch? 

Thanks!",hi see new master branch thanks,issue,negative,positive,positive,positive,positive,positive
460672278,Graph mode is the tensorflow way - which would be strange to do in pytorch,graph mode way would strange,issue,negative,negative,neutral,neutral,negative,negative
460672020,We've got a good plan for this in torch 1.0 - see the torch 1.0 refactor,got good plan torch see torch,issue,negative,positive,positive,positive,positive,positive
460671615,i don't think this is an issue in torch_1 which is moving to master today,think issue moving master today,issue,negative,neutral,neutral,neutral,neutral,neutral
460446042,Hey @akki2825 Thank you very much for your work this pr. It looks like #1851 already implemented the same functionality (Looks like some wires got crossed somewhere). As such I am closing this.,hey thank much work like already functionality like got crossed somewhere,issue,positive,positive,positive,positive,positive,positive
460203649,"Also, we need to set bias=False in model Linear(2, 1) to have it working, just it has been done in Tuto 2, we need to investigate this.",also need set model linear working done need investigate,issue,negative,neutral,neutral,neutral,neutral,neutral
460201739,"Assumingly this is caused by `bobs_opt.step()` which should be `bobs_opt.step(bobs_data.shape[0])` 
Do someone confirm we now need to provide this argument (how does this also related to providing a similar argument to backward ? ",assumingly someone confirm need provide argument also related providing similar argument backward,issue,negative,neutral,neutral,neutral,neutral,neutral
460166341,"Great job!
You need to run `black .` at the root of the repo to reformat your python files correctly. This is why the Travis checks failed.",great job need run black root python correctly travis,issue,positive,positive,positive,positive,positive,positive
460056281,Looks great to me! You'll need to rebase to the latest branch - but it shouldn't be hard! Make a PR!,great need rebase latest branch hard make,issue,positive,positive,positive,positive,positive,positive
459995250,It'll take me a few days to get around to doing the merge conflict here (bit of a deadline for the rest of the base) - would be grateful for your help if you're willing.,take day get around merge conflict bit deadline rest base would grateful help willing,issue,positive,negative,negative,negative,negative,negative
459977086,"@robert-wagner I left a couple of questions open in this PR.
They can easily be found by looking for the word ""TODO"".
I usually leave a suggestion below.",left couple open easily found looking word usually leave suggestion,issue,negative,positive,neutral,neutral,positive,positive
459976960,"Sorry akki, there seem to be some overlap in our works...
I basically refactored all test files, except from `./test/workers/test_worker.py` and `./test/test_serde.py`.

@robert-wagner it seems that I can't add you to the reviewers of the PR I just opened. I left a couple of comments in the PR if you want to read them first!",sorry seem overlap work basically test except ca add left couple want read first,issue,negative,negative,neutral,neutral,negative,negative
459955135,I just wanted to mention that if you see this in the Torch 1.0 branch it probably means that we hooked a torch attribute (something in torch.*) that we shouldn't have. The solution is to figure out what this thing is and add it to self.exclude in torch_attributes.py.,mention see torch branch probably hooked torch attribute something torch solution figure thing add,issue,negative,neutral,neutral,neutral,neutral,neutral
459918089,I had to comment out a few unit tests - strangely all of the failing tests work when i run them in a notebook - but they struggle when in the unit test suite. Very strange.,comment unit strangely failing work run notebook struggle unit test suite strange,issue,negative,negative,neutral,neutral,negative,negative
459798203,Please wait in the future for Travis to pass before merging. It prevents dumb errors,please wait future travis pas dumb,issue,negative,negative,negative,negative,negative,negative
459725280,"I'm not sure async is a requirement, but indeed a notebook (like tutorial Part 1 on master) is missing!",sure requirement indeed notebook like tutorial part master missing,issue,negative,positive,positive,positive,positive,positive
459431741,Unfortunately I cannot assign you to the issue but claiming in the comments is good enough,unfortunately assign issue good enough,issue,negative,positive,neutral,neutral,positive,positive
459419780,I could try and do this one if you want to assign me :),could try one want assign,issue,negative,neutral,neutral,neutral,neutral,neutral
458947491,Pleasure. Looking forward to contribute to 1.0 refactor.,pleasure looking forward contribute,issue,positive,neutral,neutral,neutral,neutral,neutral
458861925,"looks like there's a missing ""import copy"" in hook.py",like missing import copy,issue,negative,negative,negative,negative,negative,negative
458548583,Hey @kamathhrishi you want to run `black test` on your code to fix the travis error,hey want run black test code fix travis error,issue,negative,negative,negative,negative,negative,negative
458542327,I guess we need to first finish having notebooks that demonstrates sending and receiving tensors for which sending tensors asynchronously is a requirement ?,guess need first finish sending sending requirement,issue,negative,positive,positive,positive,positive,positive
458326585,Yup! the idea behind the experimental folder is to allow us to exchange notebooks freely. I added a brief description in experimental/README.md,idea behind experimental folder allow u exchange freely added brief description,issue,positive,positive,neutral,neutral,positive,positive
458195336,"Yeah - all these are test cases which we want to have support for. It doesn't all have to happen at once, but it's a VERY good idea to get this working before we start adding lots of complex functionality because GC is such a tough thing to add in later.",yeah test want support happen good idea get working start lot complex functionality tough thing add later,issue,positive,positive,neutral,neutral,positive,positive
457815774,"But then x_ptr should be deleted as well, no ? This seems a bit unlikely
What's more interesting is this example:
```
x = torch.Tensor([1, 2])
x  = x.send(bob)
x = LoggingTensor().on(x)

assert x.id in bob._objects

del x
assert x.id not in bob._objects
```
Which I think also doesn't work",well bit unlikely interesting example bob assert assert think also work,issue,positive,neutral,neutral,neutral,neutral,neutral
457766091,"Thanks for the update. I was also wondering if the version with PyTorch 1.0 will have a feature to let workers load training data separately? Specifically, the case where the entire training data is not read by the client first, but workers can read the training data independently from a local storage. Also, it would be nice to have a feature when workers can join a client asynchronously, i.e. a worker can indicate that it is now ready to join the federated learning pool of other workers and then take part in the model transmission and reception of averaged model parameters.  ",thanks update also wondering version feature let load training data separately specifically case entire training data read client first read training data independently local storage also would nice feature join client worker indicate ready join learning pool take part model transmission reception model,issue,positive,positive,positive,positive,positive,positive
457615192,This is NOT expected behavior and we should definitely get that REF count back down to 2 using weakref.,behavior definitely get ref count back,issue,negative,neutral,neutral,neutral,neutral,neutral
457565919,"One work around for `owners` could be adding owner as a property:

```
@property
        def owner(self):
            if not hasattr(self, ""_owner""):
                self._owner = hook_self.local_worker
            return self._owner

        @owner.setter
        def owner(self, new_owner):
            self._owner = new_owner
            return self

        tensor_type.owner = owner
```",one work around could owner property property owner self self return owner self return self owner,issue,negative,neutral,neutral,neutral,neutral,neutral
457564221,"Note that hooking `torch.tensor` is not trivial since you can't add any attributes, if you try you get:
`AttributeError: 'builtin_function_or_method' object has no attribute 'my_attr'`
",note trivial since ca add try get object attribute,issue,negative,neutral,neutral,neutral,neutral,neutral
457558863,"Nicely spotted, the code in https://github.com/OpenMined/PySyft/blob/master/examples/other/experimental/MNIST%20Example.ipynb does not perform  privacy preserving training or anything federated. I suspect it was a demo which wasn't finished, that's why it's in `experimental` :)",nicely spotted code perform privacy training anything suspect finished experimental,issue,negative,positive,positive,positive,positive,positive
457555679,"Hi @bigdata2,
There are known issues with remote memory management (remote value is not destroyed when the pointer to it disappears), which are being addressed in the new PySyft version (compatible with PyTorch 1.0) which should be released in February.",hi known remote memory management remote value pointer new version compatible,issue,negative,negative,neutral,neutral,negative,negative
457515108,Should we close this issue for now? I think we're quite good.,close issue think quite good,issue,negative,positive,positive,positive,positive,positive
457514768,"I've been working on having a very high coverage, however at some point you end make a stupid test just to cover a single line which really doesn't gives you much. I'm a bit cautious about using quotes #pragma because it makes the code less readable
I think you can go up to 97% but I would prefer that we spend time doing tests that are really relevant and writing code :)",working high coverage however point end make stupid test cover single line really much bit cautious code le readable think go would prefer spend time really relevant writing code,issue,negative,negative,neutral,neutral,negative,negative
457512505,"I think this isn't too bad however I'd like some more tests to be performed or questions to be answered:
- have a GC test file
- How new tensors types like the LoggingTensor (will) implement __del__ and GC ?",think bad however like test file new like implement,issue,negative,negative,negative,negative,negative,negative
456013602,The .child interface is a bit easier for Torch 1.0 now that the last PR has been merged - I do recommend moving your new code to the Torch 1.0 branch if you're interested.,interface bit easier torch last recommend moving new code torch branch interested,issue,positive,positive,positive,positive,positive,positive
456012602,"Really, really great job on this - absolutely love the smoothness of creating new tensor types! It's even better than I had hoped!",really really great job absolutely love smoothness new tensor even better hoped,issue,positive,positive,positive,positive,positive,positive
456012429,@LaRiffle - would be great to fix that relative import when you get the chance - but I won't hold the PR for it.,would great fix relative import get chance wo hold,issue,positive,positive,positive,positive,positive,positive
455905225,I am reopening this because we are unable to call send on torch.tensor which means either we need to hook torch.tensor or get pytorch to fix this issue upstream (ideally both) cc @iamtrask ,unable call send either need hook get fix issue upstream ideally,issue,negative,positive,positive,positive,positive,positive
455781885,"hey @iamtrask , I have moved  
1. log.py file from syft/frameworks/torch/tensors/ into syft/frameworks/torch/tensors/decorator folder
2. Other files from syft/frameworks/torch/tensors/  into  syft/frameworks/torch/tensors/interpreters folder. 
3. added and updated all required import statements from the syft/ , test/ folder.

Please tell me, if there any additional suggestions and corrections.
[Organized tensors -> Decorators and Interpreters](https://github.com/param087/PySyft/tree/torch_1)",hey file folder folder added import folder please tell additional organized,issue,negative,neutral,neutral,neutral,neutral,neutral
455751083,"hello @iamtrask -  I have started to work on this issue, If I get stuck somewhere I will let you know. ",hello work issue get stuck somewhere let know,issue,negative,neutral,neutral,neutral,neutral,neutral
455583337,"Hey @param087 - basically this is about creating two new folders in syft/frameworks/torch/tensors. One folder should be called ""decorators"" and the other should be called ""interpreters"".  Decorators are things like ""LoggingTensor"" which don't actually change functionality but just do something extra (like write to a file). Anything which changes functionality (pretty much everything else) is an ""Interpreter"".

I will likely address this issue over the weekend - but feel free to take a stab at it today if you like! It's really just about moving files around and then making sure all the dependencies still work (unit tests pass and such). You'll probably have to change a few import statements here and there",hey param basically two new one folder like actually change functionality something extra like write file anything functionality pretty much everything else interpreter likely address issue weekend feel free take stab today like really moving around making sure still work unit pas probably change import,issue,positive,positive,positive,positive,positive,positive
455255050,"Thank you for adding a test as well, especially given the tight deadline",thank test well especially given tight deadline,issue,positive,negative,neutral,neutral,negative,negative
454668684,"Hi Andrew,
I want to work on this issue. Any example or sample regarding Organize tensors -> Decorators and Interpreters will be very helpful.",hi want work issue example sample regarding organize helpful,issue,negative,neutral,neutral,neutral,neutral,neutral
454648361,"It seems problem related to the torch GPU torch version 0.3.0 vs  0.3.1 just comment the following lines in first shell of colab notebook.

```
#accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'
#!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}linux_x86_64.whl torchvision
#import torch
```

It will work just fine or you can check for torch GPU v0.3.1
here the working colab notebook of me : 
https://colab.research.google.com/drive/1OWl-iud3gSM7ZYyEkK2EVr0q8zNIe0C9",problem related torch torch version comment following first shell notebook accelerator else pip install import torch work fine check torch working notebook,issue,negative,positive,positive,positive,positive,positive
454431283,"I'd defer to @iamtrask, but I imagine this could be done in SPDZ",defer imagine could done,issue,negative,neutral,neutral,neutral,neutral,neutral
454380480,Looking great in terms of functionality! I'm inclined to merge it as is at the moment although I think we can improve the addition of custom methods to LogTensor. (eliminate the  handle_method_command method). But in the spirit of keeping things moving I think this is a great piece of work.,looking great functionality merge moment although think improve addition custom eliminate method spirit keeping moving think great piece work,issue,positive,positive,positive,positive,positive,positive
454373932,Do we really need a separate tensor for this or shall we just make it a part of SPDZ? ,really need separate tensor shall make part,issue,negative,positive,positive,positive,positive,positive
454301404,"Asyncio definitely would be convenient as a standard library, but I'd
consider taking a look at dask distributed and/or grpc before making a
final decision.

On Tue, Jan 15, 2019, 2:54 AM Théo Ryffel <notifications@github.com wrote:

> Very interested about what can come out with asyncio!
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/OpenMined/PySyft/pull/1808#issuecomment-454298029>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AHhphRaz-2xnwTSRBZmOyIhs1J8RxpJpks5vDYk1gaJpZM4ZygDV>
> .
>
",definitely would convenient standard library consider taking look distributed making final decision tue wrote interested come thread reply directly view mute thread,issue,positive,positive,neutral,neutral,positive,positive
454070171,Great call! Thank you for doing the due diligence research on this - sounds like we dodged a bullet.,great call thank due diligence research like bullet,issue,positive,positive,positive,positive,positive,positive
453869095,"I'll close this PR for now, I've been searching more about async operations in Python and I think threading is not the way to go.

Threading is clean and easily readable. But the operational systems control when it's executed not us, and can be especially difficult to deal with shared data structures (structure would need to be locked).

Asyncio looks like a better option: async / await are builtin since python 3.5 and asyncio is an std library.",close searching python think way go clean easily readable operational control executed u especially difficult deal data structure would need locked like better option await since python library,issue,positive,positive,neutral,neutral,positive,positive
453858955,"@LaRiffle I've just made the description more clear, let me know if there's anything unclear to you. Thanks for the feedback!",made description clear let know anything unclear thanks feedback,issue,positive,positive,positive,positive,positive,positive
452882690,I _think_ we're good to close this issue based on https://github.com/OpenMined/PySyft/pull/1805 - @LaRiffle ?,good close issue based,issue,negative,positive,positive,positive,positive,positive
452881971,It seems like we're really close on this one - only a couple places where we lack! I spotted missing docstrings in VirtualWorker (virtual.py),like really close one couple lack spotted missing,issue,negative,neutral,neutral,neutral,neutral,neutral
452390472,Btw - huge applause on the branch name - you win branch name of the year!,huge applause branch name win branch name year,issue,positive,positive,positive,positive,positive,positive
451687402,"Hey, Thanks for the heads up @LaRiffle . I based this off of one of the examples in the torch directory but if definitely would be better to base these off of the core tutorial series. I am going to discard this pr and resubmit basing it off of the core tutorial series",hey thanks based one torch directory definitely would better base core tutorial series going discard resubmit core tutorial series,issue,positive,negative,neutral,neutral,negative,negative
451638903,">  My concern comes more into play when we think about other packages such as **pyro**. At several instances in the pyro package there are is instance checks for torch.Tensor which affect the logic of the package. Do we want to have the pysyft play nicely with these other ecosystem packages out of the box or do we want to have to hook all of them ahead of time?

Ok I see your point, again if you have an example it would definitely be great, otherwise I can try to imagine.
I think that there is a trade-off at this point:
**PRO** Faster computation as chains are shorter and less tensors have to be allocated (from what I see it around ~25% faster)
**CON** Need to specify in advance the scope of modules you want to use (at the very least with a `hook.add_hook_for(pyro)`)
**PRO** The code is simpler to write (see garbage collection or method hooking)
**CON** `.send()` can't be inplace and this is painful
I can't think at others but please feel free to add them.
As I said this PR is more experimental as I wanted to see how far we can go _in practice_ with pointers. 

",concern come play think pyro several pyro package instance affect logic package want play nicely ecosystem box want hook ahead time see point example would definitely great otherwise try imagine think point pro faster computation shorter le see around faster con need specify advance scope want use least pyro pro code simpler write see garbage collection method con ca painful ca think please feel free add said experimental see far go,issue,positive,positive,positive,positive,positive,positive
451448443,My concern with other modules in the ecosystem has less to due with the nn module since at the very least we can hook it. My concern comes more into play when we think about other packages such as pyro. At several instances in the pyro package there are is instance checks for torch.Tensor which affect the logic of the package. Do we want to have the pysyft play nicely with these other ecosystem packages out of the box or do we want to have to hook all of them ahead of time?,concern ecosystem le due module since least hook concern come play think pyro several pyro package instance affect logic package want play nicely ecosystem box want hook ahead time,issue,positive,positive,neutral,neutral,positive,positive
451409584,"> I have concerns about how well this change will play with other projects in the PyTorch ecosystem. It seems to me that we would also need to hook each of those projects which is a no go for me

I would be a bit more optimistic:
One example maybe is torch.nn.Linear (see https://pytorch.org/docs/stable/_modules/torch/nn/modules/linear.html#Linear)
You'll ""send"" the module, namely all the parameters and then call it on a pointer:
```
x_ptr = torch.Tensor([1, 2]).send(bob)
lin = torch.nn.Linear(2, 2)
lin_ptr = lin.send(bob)
lin_ptr(x_ptr)
```
The `forward` is as follows:
```
def forward(self, input):
         return F.linear(input, self.weight, self.bias)
```
Which means that the input is not checked against and just `F.linear` has to be hooked.

This is just one example, but I think it works",well change play ecosystem would also need hook go would bit optimistic one example maybe see send module namely call pointer bob lin bob forward forward self input return input input checked hooked one example think work,issue,positive,neutral,neutral,neutral,neutral,neutral
451312177,"> At the current time this pull request does not work with the nn module. A minimal working counter example is as follows
> 
> ```
> import torch
> import syft as sy
> hook = sy.TorchHook(torch)
> alice = sy.VirtualWorker(hook=hook)
> x = torch.Tensor([1,2,3,4])
> x_ptr = x.send(alice)
> y = torch.nn.functional.relu(x_ptr)
> ```

This is due to an error in `_detail_pointer_tensor` wher the worker.id is supposed to be a str:
`alice = sy.VirtualWorker(hook=hook, id=""alice"")` will fix your example until I get the function corrected.",current time pull request work module minimal working counter example import torch import hook torch due error supposed fix example get function corrected,issue,negative,negative,neutral,neutral,negative,negative
451255249,"At the current time this pull request does not work with the nn module. A minimal working counter example is as follows
```
import torch
import syft as sy
hook = sy.TorchHook(torch)
alice = sy.VirtualWorker(hook=hook)
x = torch.Tensor([1,2,3,4])
x_ptr = x.send(alice)
y = torch.nn.functional.relu(x_ptr)
```
The above code throws the error
``` 

---------------------------------------------------------------------------
PointerFoundError                         Traceback (most recent call last)
~/Projects/OpenMined/PySyft/venv/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/frameworks/torch/hook.py in overloaded_attr(*args, **kwargs)
    264                 # Transform the args
--> 265                 new_args = hook_args(args)
    266                 # Run the native function with the new args

~/Projects/OpenMined/PySyft/venv/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/frameworks/torch/hook.py in <lambda>(x)
    340             f = folds[len(lambdas)]
--> 341             return lambda x: f(lambdas, x)
    342 

~/Projects/OpenMined/PySyft/venv/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/frameworks/torch/hook.py in one_fold(lambdas, args)
    346         def one_fold(lambdas, args):
--> 347             return lambdas[0](args[0])
    348 

~/Projects/OpenMined/PySyft/venv/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/frameworks/torch/hook.py in <lambda>(i)
    332                 # Last if not, rule is probably == 1 so use type to return the right transformation.
--> 333                 else lambda i: forward_func[type(i)](i)
    334                 for a, r in zip(args, rules)  # And do this for all the args / rules provided

~/Projects/OpenMined/PySyft/venv/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/frameworks/torch/hook.py in <lambda>(p)
    321             forward_func = {
--> 322                 PointerTensor: lambda p: (_ for _ in ()).throw(PointerFoundError(p)),
    323                 hook_self.torch.Tensor: lambda i: i,

~/Projects/OpenMined/PySyft/venv/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/frameworks/torch/hook.py in <genexpr>(.0)
    321             forward_func = {
--> 322                 PointerTensor: lambda p: (_ for _ in ()).throw(PointerFoundError(p)),
    323                 hook_self.torch.Tensor: lambda i: i,

PointerFoundError: [PointerTensor - id:647936865 owner:me loc:0 id@loc:4191063577]

During handling of the above exception, another exception occurred:

AttributeError                            Traceback (most recent call last)
<ipython-input-8-406a1677dc07> in <module>
----> 1 y =torch.nn.functional.relu(x_ptr)

~/Projects/OpenMined/PySyft/venv/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/frameworks/torch/hook.py in overloaded_attr(*args, **kwargs)
    279                 message = (cmd_name, None, args, kwargs)
    280                 # Send the command
--> 281                 response = owner.send_command(location, message)
    282                 return response
    283 

~/Projects/OpenMined/PySyft/venv/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/workers/base.py in send_command(self, recipient, message)
    272         """"""
    273 
--> 274         response = self.send_msg(MSGTYPE.CMD, message, location=recipient)
    275         return response
    276 

~/Projects/OpenMined/PySyft/venv/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/workers/base.py in send_msg(self, msg_type, message, location)
    134 
    135         # Step 2: send the message and wait for a response
--> 136         bin_response = self._send_msg(bin_message, location)
    137 
    138         # Step 3: deserialize the response

~/Projects/OpenMined/PySyft/venv/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/workers/virtual.py in _send_msg(self, message, location)
      4 class VirtualWorker(BaseWorker):
      5     def _send_msg(self, message, location):
----> 6         return location._recv_msg(message)
      7 
      8     def _recv_msg(self, message):

~/Projects/OpenMined/PySyft/venv/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/workers/virtual.py in _recv_msg(self, message)
      7 
      8     def _recv_msg(self, message):
----> 9         return self.recv_msg(message)

~/Projects/OpenMined/PySyft/venv/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/workers/base.py in recv_msg(self, bin_message)
    156         """"""
    157         # Step 0: deserialize message
--> 158         (msg_type, contents) = serde.deserialize(bin_message, worker=self)
    159 
    160         # Step 1: route message to appropriate function

~/Projects/OpenMined/PySyft/venv/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/serde.py in deserialize(binary, worker, compressed, compress_scheme)
    153     # as msgpack's inability to serialize torch tensors or ... or
    154     # python slice objects
--> 155     return _detail(worker, simple_objects)
    156 
    157 

~/Projects/OpenMined/PySyft/venv/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/serde.py in _detail(worker, obj)
    735     """"""
    736     if type(obj) == list:
--> 737         return detailers[obj[0]](worker, obj[1])
    738     else:
    739         return obj

~/Projects/OpenMined/PySyft/venv/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/serde.py in _detail_collection_tuple(worker, my_tuple)
    375     # Step 1: deserialize each part of the collection
    376     for part in my_tuple:
--> 377         pieces.append(_detail(worker, part))
    378 
    379     return tuple(pieces)

~/Projects/OpenMined/PySyft/venv/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/serde.py in _detail(worker, obj)
    735     """"""
    736     if type(obj) == list:
--> 737         return detailers[obj[0]](worker, obj[1])
    738     else:
    739         return obj

~/Projects/OpenMined/PySyft/venv/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/serde.py in _detail_collection_tuple(worker, my_tuple)
    375     # Step 1: deserialize each part of the collection
    376     for part in my_tuple:
--> 377         pieces.append(_detail(worker, part))
    378 
    379     return tuple(pieces)

~/Projects/OpenMined/PySyft/venv/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/serde.py in _detail(worker, obj)
    735     """"""
    736     if type(obj) == list:
--> 737         return detailers[obj[0]](worker, obj[1])
    738     else:
    739         return obj

~/Projects/OpenMined/PySyft/venv/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/serde.py in _detail_collection_tuple(worker, my_tuple)
    375     # Step 1: deserialize each part of the collection
    376     for part in my_tuple:
--> 377         pieces.append(_detail(worker, part))
    378 
    379     return tuple(pieces)

~/Projects/OpenMined/PySyft/venv/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/serde.py in _detail(worker, obj)
    735     """"""
    736     if type(obj) == list:
--> 737         return detailers[obj[0]](worker, obj[1])
    738     else:
    739         return obj

~/Projects/OpenMined/PySyft/venv/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/serde.py in _detail_pointer_tensor(worker, tensor_tuple)
    632     obj_id = tensor_tuple[0]
    633     id_at_location = tensor_tuple[1]
--> 634     worker_id = tensor_tuple[2].decode(""utf-8"")
    635 
    636     # If the pointer received is pointing at the current worker, we load the tensor instead

AttributeError: 'int' object has no attribute 'decode'
```",current time pull request work module minimal working counter example import torch import hook torch code error recent call last transform run native function new lambda return lambda return lambda last rule probably use type return right transformation else lambda type zip provided lambda lambda lambda lambda lambda id owner id handling exception another exception recent call last module message none send command response location message return response self recipient message response message return response self message location step send message wait response location step response self message location class self message location return message self message self message self message return message self step message content step route message appropriate function binary worker compressed inability serialize torch python slice return worker worker type list return worker else return worker step part collection part worker part return worker type list return worker else return worker step part collection part worker part return worker type list return worker else return worker step part collection part worker part return worker type list return worker else return worker pointer received pointing current worker load tensor instead object attribute,issue,negative,positive,neutral,neutral,positive,positive
451124700,@robert-wagner I've added a hook on the functions of `torch.nn.functional` to see how it would work. It's a bit more complicated with `torch.nn` because we need to use Parameters which we don't support atm,added hook see would work bit complicated need use support,issue,negative,negative,negative,negative,negative,negative
451067751,"@robert-wagner As for now I've provided a hook only for methods on pointers.
In the hook.py code you can see experimental code for hooking methods on other syft tensors (where you need to forward to the child), I'm working on this to have it clear and robust.*
`torch.nn` (as well as `torch` and `torch.nn.functional`)  is slightly different as it concerns functions. It has to be hooked to support execution on native torch tensors, pointer tensors and syft tensors. This means that contrary to methods we don't know what is the nature of the args until the call is made.
In the previous version of Pysyft we did hook `torch.nn.functional` and relied on the fact that `torch.nn` almost always rely on `torch.nn.functional`. As you and @iamtrask mentioned, this time we will also need to hook `torch.nn` otherwise you need to give args that are torch tensors (which is not the case as we remove the torch heads). I believe this doesn't add code complexity, and I can work on an example today or tomorrow to show this. It will use * and will make it clearer.",provided hook code see experimental code need forward child working clear robust well torch slightly different hooked support execution native torch pointer contrary know nature call made previous version hook fact almost always rely time also need hook otherwise need give torch case remove torch believe add code complexity work example today tomorrow show use make clearer,issue,positive,positive,neutral,neutral,positive,positive
450480282,"> All torch modules break. I suppose the most obvious are all the layer types (every layer type, every loss function, as well as any API calls with other torch tensors)

They already break if you give them empty wrappers standing for pointers, that's why we had to hook them, analyse the args / kwargs to search of pointers and if there are some, send the command to the appropriate location.



",torch break suppose obvious layer every layer type every loss function well torch already break give empty standing hook analyse search send command appropriate location,issue,negative,positive,positive,positive,positive,positive
450479669,"Something which is not clear to me is how `del x_ptr` actually calls `x_ptr.child.__del__` (as x_ptr is an instance of torch.tensor). Where does this happen ?

Additionally I experience strange behaviours on notebooks like:
__Cell 0__
```
# Imports and setup
```
__Cell 1__
```
x = torch.Tensor([1, 2, 3, 4])
x_ptr = x.send(bob)
x_ptr.child # <-- try with and without that line
```
__Cell 2__
```
del x_ptr
```
If you keep the last line of Cell 1, *the del has no effect*. If you remove, it will work.",something clear actually instance happen additionally experience strange like setup bob try without line keep last line cell effect remove work,issue,positive,positive,neutral,neutral,positive,positive
450272270,"> Welcome to OpenMined, @katnoria!! You should also join our slack team (slack.openmined.org), particularly the #team_pysyft channel.

Thank you @iamtrask :smile: ",welcome also join slack team particularly channel thank smile,issue,positive,positive,positive,positive,positive,positive
450173809,It looks like you need to rerun black,like need rerun black,issue,negative,negative,negative,negative,negative,negative
450165022,"> @mari-linhares test objects is removed in another already submitted pr.

Oh, great :).",test removed another already oh great,issue,positive,positive,positive,positive,positive,positive
450162722,@mari-linhares test objects is removed in another already submitted pr.,test removed another already,issue,negative,neutral,neutral,neutral,neutral,neutral
450161234,Hey @robert-wagner - i did my best to merge things based on what I know of your changes - would appreciate a quick readthrough to make sure it's right though.,hey best merge based know would appreciate quick make sure right though,issue,positive,positive,positive,positive,positive,positive
450158801,Great first contribution @uhvardhan!! Welcome to OpenMined!,great first contribution welcome,issue,positive,positive,positive,positive,positive,positive
450158501,"Welcome to OpenMined, @katnoria!! You should also join our slack team (slack.openmined.org), particularly the #team_pysyft channel.",welcome also join slack team particularly channel,issue,positive,positive,positive,positive,positive,positive
450157211,"This is a great start! I think we should definitely have a few tests for this guy before merging! Preferably something that includes tests for both Tensors and Variables. Bonus points for showing it working with SNNTensor.

I'd also be a huge fan of adding a notebook in the tutorials showing how to use this with SNNTensor.",great start think definitely guy preferably something bonus showing working also huge fan notebook showing use,issue,positive,positive,positive,positive,positive,positive
450058000,"> Thanks for the PR, great work! If you have the time, I think replacing the `<var_name> (<type>):` notation from Args to `<var_name>:` could be helpful since this doesn't follow Google python style guide.
> 
> For example:
> 
> ```
> command (str): The command name
> ```
> Will be replaced by something similar to:
> 
> ```
> command: A string indicating the command name. 
> ```
Thanks for reviewing Marianne. I have made the suggested changes.
",thanks great work time think type notation could helpful since follow python style guide example command command name something similar command string command name thanks made,issue,positive,positive,positive,positive,positive,positive
450040448,"If you have the time, I think replacing the `<var_name> (<type>):` notation from Args to `<var_name>:` could be helpful since this doesn't follow Google python style guide. You can see what I mean by this format by having a look at my review in this PR: https://github.com/OpenMined/PySyft/pull/1799.

For example:
```
command (str): The command name
```
Will be replaced by something similar to:
```
command: A string indicating the command name. 
```
",time think type notation could helpful since follow python style guide see mean format look review example command command name something similar command string command name,issue,negative,negative,negative,negative,negative,negative
450038509,"Thanks for the PR, great work! If you have the time, I think replacing the `<var_name> (<type>):` notation from Args to `<var_name>:` could be helpful since this doesn't follow Google python style guide.

For example:
```
command (str): The command name
```
Will be replaced by something similar to:
```
command: A string indicating the command name. 
```
",thanks great work time think type notation could helpful since follow python style guide example command command name something similar command string command name,issue,positive,positive,positive,positive,positive,positive
449884252,"Thanks much Andrew, I just fixed the style errors and running black syft locally shows no errors.

> katnoria$ black syft
> All done! ✨ 🍰 ✨
> 23 files left unchanged.",thanks much fixed style running black locally black done shortcake left unchanged,issue,negative,negative,neutral,neutral,negative,negative
449868584,"Looks like there are a few style errors - run black to fix :)

(pip install black)

then from the PySyft directory run

black syft",like style run black fix pip install black directory run black,issue,negative,negative,negative,negative,negative,negative
449768635,Discarding this because it would be faster to redo the pr than fix these merge conflicts. Yikes,would faster redo fix merge,issue,negative,neutral,neutral,neutral,neutral,neutral
449766243,Will work on resolving merge conflicts. The majority of this was written before @iamtrask 's pr today,work merge majority written today,issue,negative,neutral,neutral,neutral,neutral,neutral
449702762,"With the current master (commit 33e23644b026815d76c9e5d6594e3d0b8fe6830b) all tests pass on Mac OS (112 tests in total). So, closing the issue as resolved.",current master commit pas mac o total issue resolved,issue,negative,neutral,neutral,neutral,neutral,neutral
449686342,"As mentioned in the PR you made - I intentionally removed functionality which was copy-pasted from the 0.3.1 implementation which we intend to re-write (lest we start making progress based on old code). 

However, I _think_ the issue you specifically flagged above (the code example you wrote down) works now. 

Should we chat more or should I close this?",made intentionally removed functionality implementation intend lest start making progress based old code however issue specifically code example wrote work chat close,issue,negative,positive,neutral,neutral,positive,positive
449686176,Hmm - I'm really not sure. Maybe try rebuilding your virtual environment?,really sure maybe try virtual environment,issue,negative,positive,positive,positive,positive,positive
449683805,"I *think* this issue was addressed in https://github.com/OpenMined/PySyft/pull/1791. 

At the moment, I elected to NOT serialize .owner because it can always be inferred by whoever is doing the deserialization (.owner is just supposed to reflect who is currently managing it, and we DO need it but only for when we're using VirtualWorker). 

However, ID is now serialized/deserialized with both Tensor and PointerTensor",think issue moment serialize always whoever supposed reflect currently need however id tensor,issue,negative,neutral,neutral,neutral,neutral,neutral
449683454,Hey @bigdata2 - you are almost certainly running into this issue. We're addressing it in the Torch 1.0 Refactor. You can track progress (or help out) by watching this issue https://github.com/OpenMined/PySyft/issues/1701,hey almost certainly running issue torch track progress help watching issue,issue,positive,positive,positive,positive,positive,positive
449683363,"The only costs of having the top level object is.

1) initializing the tensors (more init cost)
2) having to forward commands to .child tensors

I think we can minimize (1) if we use a Pool of wrappers (there's nothing particularly unique about any one of them, so we should be able to re-use them pretty easily), and (2) is quite minimal as well in terms of cost.",top level object cost forward think minimize use pool nothing particularly unique one able pretty easily quite minimal well cost,issue,positive,positive,positive,positive,positive,positive
449683278,"> Oh I see. Do you have an example of torch module which would break? Usually we also hook them as well

All torch modules break. I suppose the most obvious are all the layer types (every layer type, every loss function, as well as any API calls with other torch tensors)",oh see example torch module would break usually also hook well torch break suppose obvious layer every layer type every loss function well torch,issue,negative,negative,negative,negative,negative,negative
449683150,"One good follow-on project might be to report statistics to the notebook as an option (right now it only writes to a file). Another might be more statistics relating to message size, number of messages, etc.",one good project might report statistic notebook option right file another might statistic message size number,issue,negative,positive,positive,positive,positive,positive
449652027,@LaRiffle any final decisions? From the discussion above I would say it will be implemented in a way similar to what you described as `2.` in your fist comment?,final discussion would say way similar fist comment,issue,negative,neutral,neutral,neutral,neutral,neutral
449203072,"I am facing out of memory issue during MNIST training, see [issue](https://github.com/OpenMined/PySyft/issues/1781). Are these issues related? Can you explain the problem a little more and if there is any resolution/workaround for that?  ",facing memory issue training see issue related explain problem little,issue,negative,negative,neutral,neutral,negative,negative
449161396,"Hey Ogofo, I don't have a specific plan, but I'll try to have a better look on this part of the code to make sure it makes sense. I'll add updates in this thread.",hey specific plan try better look part code make sure sense add thread,issue,positive,positive,positive,positive,positive,positive
449119667,I don't have much preference other than it's really nice that sphinx documentation gets automatically generated. Thoughts?,much preference really nice sphinx documentation automatically,issue,negative,positive,positive,positive,positive,positive
449097976,"Well, this issue is about ""first version of (...) statistical tracking"". I've written something for start and my PR has been accepted. I don't know if people use it and what they think about it. There's always room for improvement, but I found it hard to do better without more explicit requirements.

I would close this issue and create new ones if there are more concrete ideas for statistics-related features.",well issue first version statistical written something start accepted know people use think always room improvement found hard better without explicit would close issue create new concrete,issue,positive,positive,positive,positive,positive,positive
449029768,"I noticed, that in this version you have to register all workers to ""me"" aka the local_worker otherwise we do not get a virtual worker during deserialization but a string with the id of the worker (e.g. Pointer.location will be ""Alice"" instead of the VirtualWorker with id Alice) 

I am not sure if that is the desired/expected behavior. 

",version register aka otherwise get virtual worker string id worker instead id sure behavior,issue,negative,positive,positive,positive,positive,positive
448537819,"I think some functionality like this is addressed in https://github.com/OpenMined/PySyft/issues/1701. Do you have a specific plan for the implementation already? Otherwise, I would guess that your suggestion can work :D ",think functionality like specific plan implementation already otherwise would guess suggestion work,issue,negative,neutral,neutral,neutral,neutral,neutral
448532294,I suggest creating a ticket to implement the WebSocket worker in torch_1 branch. I don't think we should put more work than necessary into an outdated version of the repository :) ,suggest ticket implement worker branch think put work necessary outdated version repository,issue,negative,negative,negative,negative,negative,negative
448400296,"@robert-wagner 
Thank you for your kind reply. I got it.",thank kind reply got,issue,positive,positive,positive,positive,positive,positive
448133901,"Hello!
I think this issue still needs discussion and bigger rewrite. I've been a little out of touch lately and I'm not sure what's the plan exactly. Please don't close it yet.",hello think issue still need discussion bigger rewrite little touch lately sure plan exactly please close yet,issue,positive,positive,positive,positive,positive,positive
447895058,In the original comment x and y are both mpc shared variables. We currently do not have the functions any and all implemented for mpc tensors as it leaks information most of the time. This behavior should return an error rather than a result that doesn't make sense ,original comment currently information time behavior return error rather result make sense,issue,negative,positive,positive,positive,positive,positive
447687046,"@robert-wagner, @Ogofo any thoughts on this? Maybe close this issue if you think this is intended behaviour?

Thank you! Cheers!",maybe close issue think intended behaviour thank,issue,negative,neutral,neutral,neutral,neutral,neutral
447683693,"Hi @mari-linhares,

Thank you for explaining in detail. 
Understand about the behavior. I need to call ""child"" of chain.

Thank you again for describing in detail :)",hi thank explaining detail understand behavior need call child chain thank detail,issue,positive,neutral,neutral,neutral,neutral,neutral
447639634,"Hey everyone,

Quick question: is it possible for the worker to implement the send operation and then have a garbage collection operation to clean the ""transferred"" tensor?",hey everyone quick question possible worker implement send operation garbage collection operation clean transferred tensor,issue,negative,positive,positive,positive,positive,positive
447637546,"Hi @0shimax,

**TL;DR**: I think this is the current expected behaviour, not sure if intended or not, but it seems to be the way that ""wrapper"" tensors are implemented.

To be clear I'm definetly not the best person to say if this is expected behaviour or not, but I would say that if we consider that  `fix_precision` creates a [`FixedPrecisionTensor_`](https://github.com/OpenMined/PySyft/blob/5403658ec2d9a9ea2043c4b3bf09fa23e957735d/syft/core/frameworks/torch/tensor.py#L1223) parent to the FloatTensor which is basically a wrapper to the sy.FloatTensor, it is expected behavior.

The wrapper doesn't behave as a tensor. What I mean with this is that if you compare the tensor values to any number it will not have direct access to the values on the tensor, it will just return a Fixed precision tensor:

```
>>> sy.FloatTensor([-1.0, 1.0, 11]).fix_precision() < 0
[Fixed precision tensor]
```

In other words, if you try to iterate on this tensor it's empty.
```
>>> [tensor for tensor in sy.FloatTensor([-1.0, 1.0, 11])]
[-1.0, 1.0, 11.0]

>>> [tensor for tensor in sy.FloatTensor([-1.0, 1.0, 11]).fix_precision()]
[]
```

On the other hand if you run the same operation with a Float tensor you'll see:

```
>>> sy.FloatTensor([-1.0, 1.0, 11]) < 0
 1
 0
 0
[syft.core.frameworks.torch.tensor.ByteTensor of size 3]
```
This ""wrapper behaviour"" can be seen in other situations, per instance, if you send a tensor to another virtual worker:

```
>>> [tensor for tensor in sy.FloatTensor([-1.0, 1.0, 11]).send(bob)]
[]

>>> sy.FloatTensor([-1.0, 1.0, 11]).send(bob) < 0
FloatTensor[_PointerTensor - id:4734155120 owner:me loc:bob id@loc:23451730700]
```

So the wrapper tensor just return a tensor object, which is basically an empty iterator. If we check the documentation for any and all, we'll see that the default behaviour of the any function is to return False if the iterator is empty, and for the all function to return True.

```
Help on built-in function any in module builtins:

any(iterable, /)
    Return True if bool(x) is True for any x in the iterable.    
    If the iterable is empty, return False.

Help on built-in function all in module builtins:

all(iterable, /)
    Return True if bool(x) is True for all values x in the iterable.    
    If the iterable is empty, return True.
```

To have the expected output in the code snippet you just sent, a option would be to use the child tensors (I'm not sure if this is good practice, but probably not):

```
import syft as sy

hook = sy.TorchHook(verbose=False)
me = hook.local_worker
me.is_client_worker = False

bob = sy.VirtualWorker(id=""bob"", hook=hook, is_client_worker=False)
alice = sy.VirtualWorker(id=""alice"", hook=hook, is_client_worker=False)
workers = [bob, alice]

y = sy.FloatTensor([1., 2.0]).fix_precision().share(*workers)
x = sy.FloatTensor([-1., -2.0]).fix_precision().share(*workers)

def any_less_than_zero(wrapper_tensor):
    for element in wrapper_tensor.child.child:
        if element <= 0:
            return True
    return False
def all_less_than_zero(wrapper_tensor):
    for element in wrapper_tensor.child.child:
        if element >= 0:
            return False
    return True

print(any_less_than_zero(y), all_less_than_zero(y)) 
print(any_less_than_zero(x), all_less_than_zero(x))
# False False
# True True
```
",hi think current behaviour sure intended way wrapper clear best person say behaviour would say consider parent basically wrapper behavior wrapper behave tensor mean compare tensor number direct access tensor return fixed precision tensor fixed precision tensor try iterate tensor empty tensor tensor tensor tensor hand run operation float tensor see size wrapper behaviour seen per instance send tensor another virtual worker tensor tensor bob bob id owner bob id wrapper tensor return tensor object basically empty check documentation see default behaviour function return false empty function return true help function module iterable return true bool true iterable iterable empty return false help function module iterable return true bool true iterable iterable empty return true output code snippet sent option would use child sure good practice probably import hook false bob bob bob element element return true return false element element return false return true print print false false true true,issue,positive,positive,neutral,neutral,positive,positive
446533857,"I do agree with you, I think we could avoid these tensors attribute because:
1. owner is trivial
2. id is not: we expect a ptr = x.send()  then x2 = ptr.get() to return an x2 with the same id than x. But if the id is transmitted to the PointerTensor and given back this would work.",agree think could avoid attribute owner trivial id expect return id id given back would work,issue,negative,neutral,neutral,neutral,neutral,neutral
