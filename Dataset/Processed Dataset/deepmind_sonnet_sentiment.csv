id,original_comment,processed_comment,source,sentiment_VADER,sentiment_textblob,sentiment_pattern,sentiment_bert,sentiment_spacy,max_voted_sentiment
1868559882,"@tomhennigan 
Thanks very much for you reply! 

Looks like the notebook you linked to has the same problem as before...

```python
---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
[<ipython-input-2-eb53432bd9f1>](https://localhost:8080/#) in <cell line: 7>()
      7 try:
----> 8   import sonnet.v2 as snt
      9   tf.enable_v2_behavior()

4 frames
ImportError: cannot import name 'context' from 'tensorflow.python' (/usr/local/lib/python3.10/dist-packages/tensorflow/python/__init__.py)

During handling of the above exception, another exception occurred:

ImportError                               Traceback (most recent call last)
[/usr/local/lib/python3.10/dist-packages/sonnet/src/recurrent.py](https://localhost:8080/#) in <module>
     34 # pylint: disable=g-direct-tensorflow-import
     35 # Required for specializing `UnrolledLSTM` per device.
---> 36 from tensorflow.python import context as context_lib
     37 from tensorflow.python.eager import function as function_lib
     38 # pylint: enable=g-direct-tensorflow-import

ImportError: cannot import name 'context' from 'tensorflow.python' (/usr/local/lib/python3.10/dist-packages/tensorflow/python/__init__.py)
```

....But installing from `git` as you recommended earlier fixes it:

```python
#!pip install dm-sonnet dm-tree
!pip install git+https://github.com/google-deepmind/sonnet.git dm-tree
```

Full execution completes via this edited notebook on Colab: https://colab.research.google.com/drive/1jZcQtxEGVzoKLvLVglyRr2pYyZfne10-?usp=sharing

Closing. ",thanks much reply like notebook linked problem python recent call last cell line try import import name handling exception another exception recent call last module per device import context import function import name git python pip install pip install full execution via notebook,issue,negative,positive,positive,positive,positive,positive
1868475353,"Hi @drscotthawley , there is a version of the VQ-VAE example updated for Sonnet 2 here: https://github.com/google-deepmind/sonnet/blob/v2/examples/vqvae_example.ipynb",hi version example sonnet,issue,negative,neutral,neutral,neutral,neutral,neutral
1868371027,"@tomhennigan Thanks for your help!  I confirm that that works for the basic install-check. 


This may be a new Issue but I'll mention it here: My real hope was to to run the [VQ-VAE example](https://github.com/google-deepmind/sonnet/blob/v1/sonnet/examples/vqvae_example.ipynb), which I've been able to update a bit by updating the `tensorflow` calls, e.g. 

```python
#tf.gfile.MakeDirs(local_data_dir)
tf.io.gfile.makedirs(local_data_dir)
```

But it seems that `sonnet` itself suffers from an error for which downgrading `tensorflow` seems unlikely to fix:

```python
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
[<ipython-input-8-d52ca6c4f82a>](https://localhost:8080/#) in <cell line: 20>()
     18   return tf.nn.relu(h)
     19 
---> 20 class Encoder(snt.AbstractModule):
     21   def __init__(self, num_hiddens, num_residual_layers, num_residual_hiddens,
     22                name='encoder'):

AttributeError: module 'sonnet' has no attribute 'AbstractModule'
```

This error was already brought up in Issue #128 , but that Issue is marked Closed and yet I'm seeing in the newest version of `sonnet`. 

Was the example tested for Sonnet 2?   #128  suggests that `AbstractModule` was removed in v. 2. 
Thanks! ",thanks help confirm work basic may new issue mention real hope run example able update bit python sonnet error unlikely fix python recent call last cell line return class self module attribute error already brought issue issue marked closed yet seeing version sonnet example tested sonnet removed thanks,issue,positive,positive,neutral,neutral,positive,positive
1868353853,"Hi @drscotthawley , I replied on [your other thread](https://github.com/google-deepmind/sonnet/issues/273#issuecomment-1868353582) which should help unblock you with Sonnet 2.",hi thread help unblock sonnet,issue,negative,neutral,neutral,neutral,neutral,neutral
1868353582,"Hi all, this seems like a backwards incompatibility in the latest version of TensorFlow. It is fixed in Sonnet since ee6c95cb598c89ebc2d22264629e5b86b6f7f07a, you can install from head in Colab with:

```python
!pip install git+https://github.com/google-deepmind/sonnet.git
```

Example: https://colab.research.google.com/gist/tomhennigan/5708fee0b1f19b511e27172ef979cce3/example-of-installing-sonnet-from-head.ipynb

I'll look into pushing a new release in the new year so this doesn't keep biting people. Thanks for the heads up.
",hi like backwards incompatibility latest version fixed sonnet since install head python pip install example look pushing new release new year keep biting people thanks,issue,positive,positive,positive,positive,positive,positive
1868340101,"I checked this on Colab, deepnote, and pycharm just to be sure but seems to be giving issues only in Colab.

Heres a link: https://embed.deepnote.com/32c0b48c-e711-49c0-90a4-f6f1a3200d56/04566bb746de42ef97d61a57198444bd/5b43e925c358484a80f92428d2c42872?height=861.7999877929688

```
!pip install tensorflow tensorflow-probability dm-sonnet
#!pip uninstall -y dm-sonnet
!pip install --upgrade dm-sonnet

import tensorflow as tf
import sonnet as snt

print(""TensorFlow version {}"".format(tf.__version__))
print(""Sonnet version {}"".format(snt.__version__))
```

Requirement already satisfied: tensorflow in /shared-libs/python3.9/py/lib/python3.9/site-packages (2.10.0)
Requirement already satisfied: tensorflow-probability in /root/venv/lib/python3.9/site-packages (0.23.0)
Requirement already satisfied: dm-sonnet in /root/venv/lib/python3.9/site-packages (2.0.1)
Requirement already satisfied: keras-preprocessing>=1.1.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from tensorflow) (1.1.2)
Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from tensorflow) (0.4.0)
Requirement already satisfied: termcolor>=1.1.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from tensorflow) (2.0.1)
Requirement already satisfied: six>=1.12.0 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from tensorflow) (1.16.0)
Requirement already satisfied: wrapt>=1.11.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from tensorflow) (1.14.1)
Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from tensorflow) (0.27.0)
Requirement already satisfied: opt-einsum>=2.3.2 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from tensorflow) (3.3.0)
Requirement already satisfied: astunparse>=1.6.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from tensorflow) (1.6.3)
Requirement already satisfied: typing-extensions>=3.6.6 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from tensorflow) (4.4.0)
Requirement already satisfied: protobuf<3.20,>=3.9.2 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from tensorflow) (3.19.6)
Requirement already satisfied: google-pasta>=0.1.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from tensorflow) (0.2.0)
Requirement already satisfied: packaging in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from tensorflow) (21.3)
Requirement already satisfied: flatbuffers>=2.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from tensorflow) (22.9.24)
Requirement already satisfied: keras<2.11,>=2.10.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from tensorflow) (2.10.0)
Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from tensorflow) (2.10.0)
Requirement already satisfied: libclang>=13.0.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from tensorflow) (14.0.6)
Requirement already satisfied: tensorboard<2.11,>=2.10 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from tensorflow) (2.10.1)
Requirement already satisfied: numpy>=1.20 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from tensorflow) (1.23.4)
Requirement already satisfied: absl-py>=1.0.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from tensorflow) (1.3.0)
Requirement already satisfied: grpcio<2.0,>=1.24.3 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from tensorflow) (1.50.0)
Requirement already satisfied: h5py>=2.9.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from tensorflow) (3.7.0)
Requirement already satisfied: setuptools in /root/venv/lib/python3.9/site-packages (from tensorflow) (58.1.0)
Requirement already satisfied: dm-tree in /root/venv/lib/python3.9/site-packages (from tensorflow-probability) (0.1.8)
Requirement already satisfied: decorator in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from tensorflow-probability) (5.1.1)
Requirement already satisfied: cloudpickle>=1.3 in /root/venv/lib/python3.9/site-packages (from tensorflow-probability) (3.0.0)
Requirement already satisfied: tabulate>=0.7.5 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from dm-sonnet) (0.9.0)
Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)
Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)
Requirement already satisfied: requests<3,>=2.21.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.28.1)
Requirement already satisfied: markdown>=2.6.8 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.4.1)
Requirement already satisfied: google-auth<3,>=1.6.3 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.21.0)
Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)
Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)
Requirement already satisfied: werkzeug>=1.0.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.2.2)
Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from packaging->tensorflow) (3.0.9)
Requirement already satisfied: cachetools<6.0,>=2.0.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (5.2.0)
Requirement already satisfied: rsa<5,>=3.1.4 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.9)
Requirement already satisfied: pyasn1-modules>=0.2.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)
Requirement already satisfied: urllib3<2.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (1.26.12)
Requirement already satisfied: requests-oauthlib>=0.7.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)
Requirement already satisfied: importlib-metadata>=4.4 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (5.0.0)
Requirement already satisfied: idna<4,>=2.5 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.4)
Requirement already satisfied: charset-normalizer<3,>=2 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.1.1)
Requirement already satisfied: certifi>=2017.4.17 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2022.9.24)
Collecting MarkupSafe>=2.1.1
  Using cached MarkupSafe-2.1.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)
Requirement already satisfied: zipp>=0.5 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (3.9.0)
Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)
Requirement already satisfied: oauthlib>=3.0.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.2)
Installing collected packages: MarkupSafe
  Attempting uninstall: MarkupSafe
    Found existing installation: MarkupSafe 2.0.0
    Not uninstalling markupsafe at /shared-libs/python3.9/py-core/lib/python3.9/site-packages, outside environment /root/venv
    Can't uninstall 'MarkupSafe'. No files were found to uninstall.
Successfully installed MarkupSafe-2.1.3

[notice] A new release of pip is available: 23.0.1 -> 23.3.2
[notice] To update, run: pip install --upgrade pip
Requirement already satisfied: dm-sonnet in /root/venv/lib/python3.9/site-packages (2.0.1)
Requirement already satisfied: wrapt>=1.11.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from dm-sonnet) (1.14.1)
Requirement already satisfied: numpy>=1.16.3 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from dm-sonnet) (1.23.4)
Requirement already satisfied: tabulate>=0.7.5 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from dm-sonnet) (0.9.0)
Requirement already satisfied: dm-tree>=0.1.1 in /root/venv/lib/python3.9/site-packages (from dm-sonnet) (0.1.8)
Requirement already satisfied: absl-py>=0.7.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from dm-sonnet) (1.3.0)

[notice] A new release of pip is available: 23.0.1 -> 23.3.2
[notice] To update, run: pip install --upgrade pip
TensorFlow version 2.10.0
Sonnet version 2.0.1",checked sure giving link pip install pip pip install upgrade import import sonnet print version print sonnet version requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied gast requirement already satisfied requirement already satisfied six requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied decorator requirement already satisfied requirement already satisfied tabulate requirement already satisfied wheel requirement already satisfied requirement already satisfied requirement already satisfied markdown requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied markdown requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied markdown requirement already satisfied requirement already satisfied collected found installation outside environment ca found successfully notice new release pip available notice update run pip install upgrade pip requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied tabulate requirement already satisfied requirement already satisfied notice new release pip available notice update run pip install upgrade pip version sonnet version,issue,positive,positive,positive,positive,positive,positive
1868331188,"I'm not a bot just telling you what I thought may fix the problem. sorry it didnt work, i'm still playing with your code to see if theres anything else I can do.",bot telling thought may fix problem sorry didnt work still code see there anything else,issue,negative,negative,negative,negative,negative,negative
1868329722,"""If you specifically need TensorFlow 2.4.0,""?  You were the one who recommended that version!

Docker images in Colab??  What are you talking about? 

> Update Code for TensorFlow Compatibility: Alternatively, you can modify your code to work with the TensorFlow version that is readily available via pip.

 ??  It's not my code.

Your reply has all the non-specificity of a LLM-powered bot.  Reporting this to GitHub. ",specifically need one version docker talking update code compatibility alternatively modify code work version readily available via pip code reply bot,issue,negative,positive,positive,positive,positive,positive
1868326584,"@Lilneo786  Nope, that version of tensorflow is no longer available via `pip`:
```python
ERROR: Could not find a version that satisfies the requirement tensorflow==2.4.0 (from versions: 2.8.0rc0, 2.8.0rc1, 2.8.0, 2.8.1, 2.8.2, 2.8.3, 2.8.4, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.9.1, 2.9.2, 2.9.3, 2.10.0rc0, 2.10.0rc1, 2.10.0rc2, 2.10.0rc3, 2.10.0, 2.10.1, 2.11.0rc0, 2.11.0rc1, 2.11.0rc2, 2.11.0, 2.11.1, 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.12.1, 2.13.0rc0, 2.13.0rc1, 2.13.0rc2, 2.13.0, 2.13.1, 2.14.0rc0, 2.14.0rc1, 2.14.0, 2.14.1, 2.15.0rc0, 2.15.0rc1, 2.15.0, 2.15.0.post1)
ERROR: No matching distribution found for tensorflow==2.4.0
```

Note: For each test, I performed a `Disconnect and delete runtime` to re-start from a fresh environment. 

Please let me know when the README's instructions have been updated and re-tested.",nope version longer available via pip python error could find version requirement post error matching distribution found note test disconnect delete fresh environment please let know,issue,negative,positive,positive,positive,positive,positive
1868326550,"@Lilneo786 thanks for your reply.  I was just coming back after trying to update the Sonnet version, to announce that it doesn't help, when I now see your reply.  So, be aware that that 

> Or you can update Sonnet to a version that is compatible with your current TensorFlow version:
>
> pip install --upgrade dm-sonnet

Actually has no effect and produces the exact same error as before, as my Colab now shows. 

```
dm-sonnet         2.0.1
```

I will try downgrading `tensorflow` next.  
",thanks reply coming back trying update sonnet version announce help see reply aware update sonnet version compatible current version pip install upgrade actually effect exact error try next,issue,negative,positive,neutral,neutral,positive,positive
1868325290,"The issue you are facing is caused by a compatibility problem between the TensorFlow and Sonnet versions you are attempting to use. The error message indicates that Sonnet is attempting to import a module called 'context' from 'tensorflow.python', but it is unable to locate it in the installed TensorFlow version.

If you want to keep using the same version of Sonnet, you can downgrade TensorFlow: 

` pip install tensorflow==2.4.0`

 Or you can update Sonnet to a version that is compatible with your current TensorFlow version:

`pip install --upgrade dm-sonnet`
",issue facing compatibility problem sonnet use error message sonnet import module unable locate version want keep version sonnet downgrade pip install update sonnet version compatible current version pip install upgrade,issue,negative,negative,negative,negative,negative,negative
1868325144,"> I cannot install Sonnet 2.0 or Tensorflow<2 on my mac M1.
> 
> I cannot have a working pair of TensorFlow and sonnet on my mac. However, I could install them on colab by:
> 
> `pip install ""tensorflow-gpu<2"" ""dm-sonnet<2"" ""tensorflow-probability==0.7.0""`

Trying this pip install on Colab no longer works (at least for me): 

```python
ERROR: Could not find a version that satisfies the requirement tensorflow-gpu<2 (from versions: 2.8.0rc0, 2.8.0rc1, 2.8.0, 2.8.1, 2.8.2, 2.8.3, 2.8.4, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.9.1, 2.9.2, 2.9.3, 2.10.0rc0, 2.10.0rc1, 2.10.0rc2, 2.10.0rc3, 2.10.0, 2.10.1, 2.11.0rc0, 2.11.0rc1, 2.11.0rc2, 2.11.0, 2.12.0)
ERROR: No matching distribution found for tensorflow-gpu<2
```",install sonnet mac working pair sonnet mac however could install pip install trying pip install longer work least python error could find version requirement error matching distribution found,issue,negative,negative,negative,negative,negative,negative
1837541652,"This repository seems to implement VQ-VAE for video: https://github.com/ritheshkumar95/pytorch-vqvae

+1 for an updated example for raw audio!",repository implement video example raw audio,issue,negative,negative,negative,negative,negative,negative
1762748173,"I apologized for overlooking the official document before asking, where it is pretty clear: using trace_on, trace_export and trace_off to inspect the underlying graph.  ",official document pretty clear inspect underlying graph,issue,positive,positive,positive,positive,positive,positive
1742085287,"Hi, the comment you linked to has information on how to port code from sonnet 1 -> 2 and what has changed between the libraries.

Good luck with porting the code for your project.",hi comment linked information port code sonnet good luck code project,issue,positive,positive,positive,positive,positive,positive
1742024915,"@tomhennigan 

In this post https://github.com/google-deepmind/sonnet/issues/128
you mentioned aome changes to convert a class in sonnet 1 to sonnet2 

would you please tell me exactly what to do about i3d.py in this link: 
https://github.com/google-deepmind/kinetics-i3d

1- converting snt.AbstractModule to snt.Module 
2- ? 
",post convert class sonnet sonnet would please tell exactly link converting,issue,negative,positive,positive,positive,positive,positive
1741781102,"I am not very familiar with Keras, I would suggest asking for support on their issue tracker, hopefully someone will have a recipe for you.

There is a generic guide on migrating checkpoints here which you could try to follow https://www.tensorflow.org/guide/migrate/migrating_checkpoints",familiar would suggest support issue tracker hopefully someone recipe generic guide could try follow,issue,positive,positive,positive,positive,positive,positive
1741774051,"@tomhennigan 

Thanks for your response, 
exactly, I want to finetune the checkpoints you  mentioned in your link : 
https://www.tensorflow.org/hub/tutorials/action_recognition_with_tf_hub

I have written the tf1 version of finetune code. now I want to write it in tf2. 
the limitation is that Ihad to use .ckpt checkpoints and save the fine-tuned model in .ckpt format. Can I do it with keras? Do you have any link or hint? 
",thanks response exactly want link written version code want write limitation use save model format link hint,issue,positive,positive,positive,positive,positive,positive
1741772975,"Hi, it should be possible to implement this in TF2/Sonnet 2, but this will require [learning and understanding ](https://sonnet.readthedocs.io/en/latest/) Sonnet 2.

If you just want to make use of a pretrained I3D model then perhaps using Keras + TF2 would be simpler, they have an example that includes using I3D and some pretrained weights to make predictions for a video: https://www.tensorflow.org/hub/tutorials/action_recognition_with_tf_hub",hi possible implement require learning understanding sonnet want make use id model perhaps would simpler example id make video,issue,negative,neutral,neutral,neutral,neutral,neutral
1741752023,"Thanks

How should I convert it to tf2 ?
It is an i3d model. for action recognition 
I have some weights in .ckpt format which is in tf1 format and want to load them in a model and retrain the model 


On Sat, Sep 30, 2023 at 3:37 PM Tom Hennigan ***@***.***>
wrote:

> Hi @creativesh <https://github.com/creativesh> , snt.AbstractModule is
> part of Sonnet 1, it looks like the code you are wanting to run will only
> work with TF1 not TF2.
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/google-deepmind/sonnet/issues/271#issuecomment-1741751704>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AFOLMRPAVS434CME24IOEZDX5ADQNANCNFSM6AAAAAA5NNGEJ4>
> .
> You are receiving this because you were mentioned.Message ID:
> ***@***.***>
>
",thanks convert id model action recognition format format want load model retrain model sat wrote hi part sonnet like code wanting run work reply directly view id,issue,positive,positive,positive,positive,positive,positive
1741752002,"Hi @tomhennigan 

Could I rewrite it to use tf2 ? ",hi could rewrite use,issue,negative,neutral,neutral,neutral,neutral,neutral
1741751704,"Hi @creativesh , `snt.AbstractModule` is part of Sonnet 1, it looks like the code you are wanting to run will only work with TF1 not TF2.",hi part sonnet like code wanting run work,issue,negative,neutral,neutral,neutral,neutral,neutral
1633823096,"Dear Tom Hennigan,
We really appreciated your feedback for these quality issues.

The bot had a problem to use the Github API and redirect the code to the correct branch, now it's fixed and you can see updated links that redirect to correct snippet code, thank you very much.

I would ask you if the problem of finding this issues is not important in the model evaluation and test code in general, or only for the test that you have identified. Moreover, I noticed that the bot identified also the issue in batch_norm.py. Also in that case we have a component that is low value?

Thank you in advance.
 ",dear really feedback quality bot problem use redirect code correct branch fixed see link redirect correct snippet code thank much would ask problem finding important model evaluation test code general test moreover bot also issue also case component low value thank advance,issue,positive,positive,positive,positive,positive,positive
1627135359,"Thanks (to whoever wrote the bot), but changing these tests is pretty low value and not worth the time it would take to code/review.

FYI the links provided are pointing to the wrong branch (our default branch is `v2` not `master`).

We'll leave things smelling as they are for now.",thanks whoever wrote bot pretty low value worth time would take link provided pointing wrong branch default branch master leave smelling,issue,positive,positive,neutral,neutral,positive,positive
1396183046,"Hi @Denzeduous , indeed the first error is from using the wrong Sonnet package 😄 

With regards to not being able to downgrade, I'm afraid that DNC requires TF1 and Sonnet <2.

I wonder what wold happen if you installed the old version of cloudpickle to satisfy TFP during install, and then force upgraded it to 1.2.0.",hi indeed first error wrong sonnet package able downgrade afraid sonnet wonder wold happen old version satisfy install force,issue,negative,negative,neutral,neutral,negative,negative
1384652376,"I unfortunately cannot downgrade Sonnet, so that is not an option. There is an issue with tensorflow-probability 0.8.0 (required by Sonnet 1.36) requiring cloudpickle==1.1.1, while Gymnasium, which I am using to simulate and train with, requires cloudpickle>=1.2.0.",unfortunately downgrade sonnet option issue sonnet gymnasium simulate train,issue,negative,negative,negative,negative,negative,negative
1384649098,"This is the specific spot the error is occurring at: https://github.com/deepmind/dnc/blob/master/dnc/addressing.py#L58

Downloading an older version of Sonnet (if it will still work, that is) would also work, if that's a possibility, though I can't find a way to install an older version.

Also, I realized that it's `dm-sonnet` and not `sonnet` for `pip install`, so I have switched over to that instead of the source version. However, finding the pypi now gives me access to older versions, so I'm going to try playing around with them and see what I can do.",specific spot error older version sonnet still work would also work possibility though ca find way install older version also sonnet pip install switched instead source version however finding access older going try around see,issue,negative,positive,positive,positive,positive,positive
1328072961,"I looked into the file I sent you and found that encoding uses onehot and avg_probs averages the columns over the range [BHW,num], so avg_probs has a range of [0, 1] (it can't actually get close to one, I tested the maximum value of avg_probs is no more than 0.01) so the minimum value of perplexity is greater than e**0 == 1.",file sent found range range ca actually get close one tested maximum value minimum value perplexity greater,issue,positive,positive,positive,positive,positive,positive
1328035861,"I have the same doubts, perhaps does anyone know what the meaning of ""perplexity"" is (it would be better to be more specific) but I have found a file that is available for exporting perplexity, and you can look at that file in the hope that it is helpful for you.
https://github.com/zalandoresearch/pytorch-vq-vae/blob/master/vq-vae.ipynb",perhaps anyone know meaning perplexity would better specific found file available perplexity look file hope helpful,issue,positive,positive,positive,positive,positive,positive
1291949838,"Thanks, @tomhennigan. I'm going to reach out to the authors directly.",thanks going reach directly,issue,negative,positive,positive,positive,positive,positive
1291939099,"Hi, the authors are not core contributors to Sonnet so don't read the issues posted here. I would suggest reaching out to them directly, their email addresses are at the top of the paper.",hi core sonnet read posted would suggest reaching directly top paper,issue,negative,positive,positive,positive,positive,positive
1253749324,"Hi, please see my answer here https://github.com/deepmind/sonnet/issues/247#issuecomment-1178988316 for an example of using exponential decay with Sonnet 2.",hi please see answer example exponential decay sonnet,issue,negative,neutral,neutral,neutral,neutral,neutral
1253726615,A gentle reminder regarding the request.,gentle reminder regarding request,issue,negative,positive,positive,positive,positive,positive
1231780517,"> Probably, `e` in the paper stands for the `z_q(x)`. The author did not write as `z_q(x)` because its calculation evolves argmin, which is not-differentiable. However, this is not a problem to implement it naively as `z_q(x)`, because tensorflow, as well as pytorch, will stop the gradient before argmin operation, thus it works as intended and causes no BUG.
> 
> That is my new understanding.

please close this if admin thinks this explanation is right.",probably paper author write calculation however problem implement naively well stop gradient operation thus work intended bug new understanding please close explanation right,issue,negative,positive,neutral,neutral,positive,positive
1231778876,"Probably, `e` in the loss formula in the paper actually stands for the `z_q(x)`. The author did not write as `z_q(x)` because its calculation evolves argmin, which is not-differentiable.  However, this is not a problem to implement it naively as `z_q(x)`, because tensorflow, as well as pytorch, will stop the gradient before argmin operation, thus it works as intended and causes no BUG. 

That is my new understanding.",probably loss formula paper actually author write calculation however problem implement naively well stop gradient operation thus work intended bug new understanding,issue,negative,negative,neutral,neutral,negative,negative
1225482625,"Hi @raphaelmourad , we don't have any public APIs in Sonnet for this, but you can see an example of how you might write a `LayerAdapter` (converts a Sonnet module with a `__call__` method to a Keras `Layer`) in our tests:

https://github.com/deepmind/sonnet/blob/7298417de2e8b6ff9f7708ecd4596293ee62577d/sonnet/src/conformance/keras_test.py#L157-L217

I think from a Keras `Layer` is is quite easy to create a Keras `Model` (if `Model` is indeed the type you want). I am not very familiar with Keras, but I think you can just do `tf.keras.Sequential(layers=[MyLayer()])`.",hi public sonnet see example might write sonnet module method layer think layer quite easy create model model indeed type want familiar think,issue,positive,positive,positive,positive,positive,positive
1224507610,"Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/deepmind/sonnet/pull/251/checks?check_run_id=7980026961) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.",thanks pull request like may first contribution open source project look pull request need sign contributor license agreement view invocation check information date status view section bottom pull request,issue,positive,positive,positive,positive,positive,positive
1178988316,"Hi @isabellahuang, Sonnet 2 doesn't ship with any pre-defined learning rate schedules, but you can pass a `tf.Variable` as a learning rate and then assign a value to that variable to the result of your schedule:

```python
def exponential_decay(learning_rate, decay_steps, decay_rate):
  return lambda global_step: learning_rate * tf.math.pow(decay_rate, (global_step / decay_steps))

lr_schedule = exponential_decay(learning_rate, decay_steps, decay_rate)
global_step = tf.Variable(0)
learning_rate = tf.Variable(lr_schedule(global_step))
optimizer = snt.optimizers.Adam(learning_rate=learning_rate)

for batch in dataset:
  # .. snip ..
  learning_rate.assign(lr_schedule(global_step))
  optimizer.apply(updates, parameters)
  global_step.assign_add(1)
```

There is another example in our tests:

https://github.com/deepmind/sonnet/blob/d1cd37117bcb98223b3e4b930717d418abb76484/sonnet/src/optimizers/adam_test.py#L120-L125",hi sonnet ship learning rate pas learning rate assign value variable result schedule python return lambda batch snip another example,issue,negative,neutral,neutral,neutral,neutral,neutral
1161520281,"I'm afraid I don't have an M1 to test on, I'm glad you got things working in Colab and I hope that unblocks you.

Sonnet 1 is in maintenance mode only at this point (there have been [no changes in v1 for 2 years](https://github.com/deepmind/sonnet/tree/v1)), we recommend all users migrate to TensorFlow 2 and Sonnet 2 (or to [JAX](https://github.com/google/jax) + [Haiku](https://github.com/deepmind/dm-haiku) if you prefer).

I would expect Sonnet 2 to ""just work"" on M1 (if you `pip install --upgrade ""dm-sonnet>=2""`) since it is a pure Python library with no native code.",afraid test glad got working hope sonnet maintenance mode point recommend migrate sonnet prefer would expect sonnet work pip install upgrade since pure python library native code,issue,positive,positive,neutral,neutral,positive,positive
1161304593,"I cannot install Sonnet 2.0 or Tensorflow<2 on my mac M1. 

I cannot have a working pair of TensorFlow and sonnet on my mac. However, I could install them on colab by:
 
`pip install ""tensorflow-gpu<2"" ""dm-sonnet<2"" ""tensorflow-probability==0.7.0""`",install sonnet mac working pair sonnet mac however could install pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
1160414236,"Hi @maryamkiashemshaki it sounds like you've got Sonnet 1.0 installed alongside TensorFlow 2.X.

If you want to use TensorFlow 2, then you need to use Sonnet 2.0 (released in March 2020). You can find installation instructions here: https://github.com/deepmind/sonnet#installation

If you need to use Sonnet 1.X (for example to work with some legacy code) then please install TensorFlow 1. If you are using pip I think you can use: `pip install ""tensorflow<2""`.",hi like got sonnet alongside want use need use sonnet march find installation need use sonnet example work legacy code please install pip think use pip install,issue,positive,neutral,neutral,neutral,neutral,neutral
1132425818,"> @szq261299你介意在你的 Python 解释器中打印这个输出吗：
> 
> ```python
> import sonnet as snt
> print(dir(snt))
> print(snt.__version__)
> ```

2022-05-20 11:39:34.302485: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
['BaseBatchNorm', 'BatchApply', 'BatchNorm', 'Bias', 'Conv1D', 'Conv1DLSTM', 'Conv1DTranspose', 'Conv2D', 'Conv2DLSTM', 'Conv2DTranspose', 'Conv3D', 'Conv3DLSTM', 'Conv3DTranspose', 'DeepRNN', 'Deferred', 'DepthwiseConv2D', 'Dropout', 'Embed', 'ExponentialMovingAverage', 'Flatten', 'GRU', 'GroupNorm', 'InstanceNorm', 'LSTM', 'LSTMState', 'LayerNorm', 'Linear', 'Mean', 'Metric', 'Module', 'Optimizer', 'RNNCore', 'Reshape', 'Sequential', 'Sum', 'TrainableState', 'UnrolledLSTM', 'UnrolledRNN', 'VanillaRNN', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', 'absolute_import', 'allow_empty_variables', 'build', 'custom_variable_getter', 'deep_rnn_with_residual_connections', 'deep_rnn_with_skip_connections', 'distribute', 'division', 'dynamic_unroll', 'flatten', 'format_variables', 'initializers', 'leaky_clip_by_value', 'log_variables', 'lstm_with_recurrent_dropout', 'merge_leading_dims', 'mixed_precision', 'nets', 'no_name_scope', 'once', 'optimizers', 'pad', 'print_function', 'regularizers', 'reshape', 'scale_gradient', 'split_leading_dim', 'static_unroll']
2.0.0",python python import sonnet print print successfully dynamic library,issue,positive,neutral,neutral,neutral,neutral,neutral
1113523579,"Thank you @tomhennigan , that colab was very informative. Would be a great addition to the docs. ",thank informative would great addition,issue,positive,positive,positive,positive,positive,positive
1102347744,"Thank you @tomhennigan! Yes I see, it makes sense. 

Hm yes good idea, that might work. I am planning to rework the code base for TF2 anyways so it is not of major importance to make it work as is, I just have it as a reference. Thank you, it's very nice of you offering to tinker with an example and come up with a fix, but no need to spend time on that in this case, since I plan on reworking the code quite a bit. 

I see no worries, neither am I. May I ask what you would use as training framework together with sonnet? I saw in the repo that it does not come with one out of the box: 
>""Sonnet does not ship with a training framework and users are encouraged to build their own or adopt those built by others."" 

Would you recommend writing my own or to incorporate another API (like Keras or which API in that case)? 

For a bit more context, this is the code base I am tinkering around with: https://github.com/deepmind/deepmind-research/tree/master/learning_to_simulate. Which is using sonnet, graph_nets (https://github.com/deepmind/graph_nets#graph-nets-library), and estimator for a TF1 version. In the graph_nets Github they have this example (https://github.com/deepmind/graph_nets#run-sort-demo-in-browser--run-tf2-version, click the TF2 version) and it seems that they are writing their own training framework at least.  ",thank yes see sense yes good idea might work rework code base anyways major importance make work reference thank nice offering tinker example come fix need spend time case since plan code quite bit see neither may ask would use training framework together sonnet saw come one box sonnet ship training framework build adopt built would recommend writing incorporate another like case bit context code base around sonnet estimator version example click version writing training framework least,issue,positive,negative,neutral,neutral,negative,negative
1096402170,"Thanks @oke464 , Sonnet 2 was not built with graph mode in mind, for example we don't add control dependencies for stateful operations so I'm not sure we can relax this check (I think it is correctly defending against some subtle behavioural changes that would give incorrect results)..

Perhaps a fix would be to wrap the Sonnet module you're passing into your estimator instance in a tf.function? e.g. `model_fn = tf.function(my_sonnet_model)`. I think that might Give Sonnet what it needs (tf2 behaviours) while giving tf estimator what it needs (something it can run in graph mode).

I'm not very familiar with Estimator, but if you have an example in a colab that I can play with I can try and come up with a fix.",thanks sonnet built graph mode mind example add control stateful sure relax check think correctly subtle would give incorrect perhaps fix would wrap sonnet module passing estimator instance think might give sonnet need giving estimator need something run graph mode familiar estimator example play try come fix,issue,positive,positive,positive,positive,positive,positive
1094228992,"Hi @tomhennigan, thank you for your quick response. Apologies for my simple mistake, realize that it was quite apparent from the assert behavior... 

Thank you for your recommendation to check the TF version, it seems that the program is using the correct version and that eager execution is in fact enabled when I start the program. However it is disabled somewhere, which got me curious to look into it further. The codebase I'm modifying (or building on top of) is using on the Estimator API, and after some digging around it seems (to my understanding) that it is Estimator that will switch off eager execution, could this be the case? From the class definition of Estimator in estimator.py (https://github.com/tensorflow/estimator/blob/777318086559b5ee473fa097de95e2beec5adf78/tensorflow_estimator/python/estimator/estimator.py#L125): 

```python
'''
@compatibility(eager)
  Calling methods of `Estimator` will work while eager execution is enabled.
  However, the `model_fn` and `input_fn` is not executed eagerly, `Estimator`
  will switch to graph mode before calling all user-provided functions (incl.
  hooks), so their code has to be compatible with graph mode execution. Note
  that `input_fn` code using `tf.data` generally works in both graph and eager
  modes.
  @end_compatibility
'''
```

This is done prior to the initialization of sonnet modules, thus I believe this is the reason eager execution is disabled when ``tf.init_scope()`` is called. Not sure if there is a workaround for this.

Again, thank you for your help, I wish you a wonderful day! :) ",hi thank quick response simple mistake realize quite apparent assert behavior thank recommendation check version program correct version eager execution fact start program however disabled somewhere got curious look building top estimator digging around understanding estimator switch eager execution could case class definition estimator python compatibility eager calling estimator work eager execution however executed eagerly estimator switch graph mode calling code compatible graph mode execution note code generally work graph eager done prior sonnet thus believe reason eager execution disabled sure thank help wish wonderful day,issue,positive,positive,positive,positive,positive,positive
1088811372,"Hi @oke464 this assertion makes sure that at the very top level (that is what the `tf.init_scope()` thing is doing) that eager execution **is** enabled.

Assertions make sure that the statement evaluates to true (e.g. in TF2 `assert tf.executing_eagerly()` should evaluate to `assert True` which will not raise an error).

I suspect that your program is not actually using TF 2.X. I would suggest running the following to check:

```
import tensorflow as tf
print(tf.__version__)
```",hi assertion sure top level thing eager execution make sure statement true assert evaluate assert true raise error suspect program actually would suggest running following check import print,issue,positive,positive,positive,positive,positive,positive
1088731276,"Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

For more information, open the [CLA check for this pull request](https://github.com/deepmind/sonnet/pull/240/checks?check_run_id=5834756627).",thanks pull request like may first contribution open source project look pull request need sign contributor license agreement information open check pull request,issue,positive,positive,positive,positive,positive,positive
1079902784,"Hi @isabellahuang , from your example it looks like you might be missing a call to `snt.mixed_precision.enable(tf.float16)`.

Here is an example of using mixed f32/f16: https://colab.research.google.com/gist/tomhennigan/2d54c6660b50f66a79699f419c8d7307/example-of-mixed-precision-in-sonnet-2.ipynb which includes a routine to check the tf graph for operations in f16/f32.

If you are looking to speed up training in general, then a quick win would be to pass `jit_compile=True` to `@tf.function` which will compile your program using XLA.",hi example like might missing call example mixed routine check graph looking speed training general quick win would pas compile program,issue,positive,positive,positive,positive,positive,positive
1078466194,"Thanks @tomhennigan , I think some leftover `import tensorflow.v1.compat as tf` imports threw that error. I've successfully migrated to TF 2.5 now. ",thanks think leftover import threw error successfully,issue,positive,positive,positive,positive,positive,positive
1077702176,"> Sonnet 2 throws an error when eager execution is disabled. Is there a way to get Sonnet 2 working without eager execution?

Hi @isabellahuang , Sonnet 2 is designed to work both eagerly and inside `@tf.function`. I would guess the error you are getting is because you are using TensorFlow 1 which defaults to graph mode (we do check to make sure you are using TF2)? What version of TensorFlow do you have installed? You can check with:

```python
import tensorflow as tf
print(tf.__version__)
```",sonnet error eager execution disabled way get sonnet working without eager execution hi sonnet designed work eagerly inside would guess error getting graph mode check make sure version check python import print,issue,positive,positive,positive,positive,positive,positive
1077700231,"HI @xfchen0912 , in TensorFlow 2 memory is freed eagerly when there are no more references to the model in Python. So you can do something like:

```python
model_a = ...
model_b = ...

copy_weights(model_a, model_b)

del model_a  # If there are no other references to model_a GPU memory associated with it will be released.
```",hi memory freed eagerly model python something like python memory associated,issue,positive,neutral,neutral,neutral,neutral,neutral
1071738340,"Hey @tomhennigan, thanks so much! I'm trying to migrate the rest of the code before I can fully confirm these changes work, and am working through some issues now. One of them is that Sonnet 2 throws an error when eager execution is disabled. Is there a way to get Sonnet 2 working without eager execution? ",hey thanks much trying migrate rest code fully confirm work working one sonnet error eager execution disabled way get sonnet working without eager execution,issue,positive,positive,neutral,neutral,positive,positive
1068435116,"> The main changes I made are to add a __call__() method that initializes all the variables once (with the @snt.once decorator), then returns the value using the old _build() method. Is this correct?

In your usecase you can actually move variable creation to the constructor if you prefer. the `@snt.once` pattern is used because many module parameters depend on the shape of the input to that module, it is convenient to do this the first time you run `__call__`.

> Also, how do we deal with the previous enter_variable_scope() call and @snt.reuse_variables decorator? The self.inverse method is called outside of the module, which I understand is a reason for using @snt.reuse_variables on it. I simply got rid of them in the new module but I'm not sure this is right.

No need for this, in Sonnet 2 variable sharing is done using regular Python objects (e.g. just create your modules once, and just create parameters of your module once, to reuse parameters just refer to the ones you made before).

> Lastly, is the @snt.reuse_variables decorator in the original module even used, seeing as there are no tf.get_variable calls in the self.inverse method? Every existing example I've seen for how to use @snt.reuse_variables has a tf.get_variable call in the method.

It isn't needed for reusing variables (because as you say there aren't any in that method), it will have a side effect in Sonnet 1 of entering a name scope so operations would have a clear name in the TF graph, this won't affect correctness or performance but might be useful for debugging.

In Sonnet 2 all module methods enter a name scope, so if you are debugging a `tf.function` you should find that your code already has sensible names for operations.

> want to know how to do it correctly

There are a few other changes you can make:

1. No need for control deps or group since in TF2 effectful operations (e.g. assign) will happen in program order.
2. It would be useful to add a name to your variables for debugging.
3. You can skip the tf.cond in your call, in TF2 you can use `tf.function` and it's ""autograph"" feature will convert python control flow to tf control flow.
4. I'd suggest `name=None` in the constructor, Sonnet will pick a name based on your class name if the user does not pass one.
5. You don't seem to use the `accumulate` argument in `__call__`.

Here is my version of your module, seems to work: https://colab.research.google.com/gist/tomhennigan/520f004cc781e8231f53ea9dd62bea86/example-of-porting-to-sonnet-2.ipynb",main made add method decorator value old method correct actually move variable creation constructor prefer pattern used many module depend shape input module convenient first time run also deal previous call decorator method outside module understand reason simply got rid new module sure right need sonnet variable done regular python create create module reuse refer made lastly decorator original module even used seeing method every example seen use call method say method side effect sonnet entering name scope would clear name graph wo affect correctness performance might useful sonnet module enter name scope find code already sensible want know correctly make need control group since effectful assign happen program order would useful add name skip call use autograph feature convert python control flow control flow suggest constructor sonnet pick name based class name user pas one seem use accumulate argument version module work,issue,positive,positive,positive,positive,positive,positive
1066531938,"Hi @RlChen0 , apologies it has been quite a while since I've used TF. Yes your suggestion would work, you can also query one of the traced functions on the restored model for the parameters it uses, that might be a bit more robust (e.g. it would work even if you change the names):

https://colab.research.google.com/gist/tomhennigan/43509a6d9156cf658666d6e158b557f6/example-of-selecting-variables-for-optimization.ipynb",hi quite since used yes suggestion would work also query one model might bit robust would work even change,issue,positive,neutral,neutral,neutral,neutral,neutral
1066513197,"Hi, @tomhennigan, but pretrained load from SavedModel has no attribute 'trainable_variables'.
```python
params = tape.watched_variables()
pretrained_param = [param for param in params
         if 'pretrained' in param.name]
finetune_param = [param for param in params
         if 'finetune' in param.name]
# or finetune_params = finetune.trainable_variables
params = (pretrain_params, finetune_params)
pretrain_grads, finetune_grads = tape.gradient(loss, params)
```
does this work?",hi load attribute python param param param param loss work,issue,negative,neutral,neutral,neutral,neutral,neutral
1066503862,"Hi @RlChen0 , sure you just need to separate the gradients for pretrain and tune, the easiest way is to do this when you call into `tape.gradient`. Here is an example: https://colab.research.google.com/gist/tomhennigan/f6bf5520995e08fe54ade0736af9443b/example-of-selecting-variables-for-optimization.ipynb#scrollTo=WmcE3abMvMW2",hi sure need separate pretrain tune easiest way call example,issue,positive,positive,positive,positive,positive,positive
1066488897,"Hi, @tomhennigan. I'm still confused about how to apply different learning rates.
Is there a way to do something like this?

```python
pretrained = tf.saved_model.load(model_path)
finetune = snt.Linear(100, name='finetune')

opt1 = snt.optimizers.Adam(learning_rate)
opt2 = snt.optimizers.Adam(learning_rate * 10)

opt1.apply(pretained_grads, pretrained_params)
opt2.apply(finetune_grads, finetune_params)
```
",hi still confused apply different learning way something like python opt opt,issue,negative,negative,negative,negative,negative,negative
1066333931,"The example in the notebook is performing the spectral norm on the Linear module. For 2D and 3D Conv layers you would need to implement accordingly. You could use the ConvND class and follow the notebook like logic:

```python
class SNConv2D(sonnet.src.conv.ConvND):
  """"""2D convolution with spectral normalisation.""""""

  def __init__(self,sn_eps=0.0001, *args,**kwargs):
    """"""Constructor.""""""
    super().__init__(num_spatial_dims=2, data_format= ""NHWC"", *args,**kwargs)
    self._spectral_normalizer = SpectralNormalizer(epsilon=sn_eps)

  def __call__(self, inputs):

    self._initialize(inputs)

    if self.padding_func:
      inputs = tf.pad(inputs, self._padding)
    
    normed_w = self._spectral_normalizer(self.w)

    outputs = tf.nn.convolution(
          inputs,
          normed_w,
          strides=self.stride,
          padding=self.conv_padding,
          dilations=self.rate,
          data_format=self.data_format)
    
    if self.with_bias:
      outputs = tf.nn.bias_add(outputs, self.b, data_format=self.data_format)

    return outputs
```

And you should be able to do the same for an SNConv3D function, just increment num_spatial_dims to 3 and change data_format to ""NDHWC"".",example notebook spectral norm linear module would need implement accordingly could use class follow notebook like logic python class convolution spectral self constructor super self return able function increment change,issue,positive,positive,positive,positive,positive,positive
1062786278,"Perfect solution to my problem.Thanks, Tom, you always help a lot.",perfect solution always help lot,issue,positive,positive,positive,positive,positive,positive
1062664213,"Hi @RlChen0, the simplest way is to only request gradients to variables you want to train (e.g. use `module.trainable_variables` instead of `tape.watched_variables()`):

```python
pretrained = snt.nets.MLP([300, 100, 10])
finetune = snt.nets.MLP([100, 10])

def forward(x):
  x = pretrained(x)
  x = tf.nn.relu(x)
  x = finetune(x)
  return x

x = tf.ones([1, 1])
with tf.GradientTape() as tape:
  y = forward(x)
  loss = tf.reduce_sum(y)

params = finetune.trainable_variables
grads = tape.gradient(loss, params)
```

If this is cumbersome (e.g. you are using a library which itself calls `tape.watched_variables()` or you don't have one module encapsulating what you want to finetune) then you can use a context manager to stop gradients being computed for specific parts of your forward pass:

```python
def forward(x):
  with snt.custom_variable_getter(tf.stop_gradient):
    x = pretrained(x)
  x = tf.nn.relu(x)
  x = finetune(x)
  return x

with tf.GradientTape() as tape:
  y = forward(x)
  loss = tf.reduce_sum(y)

params = tape.watched_variables()
grads = tape.gradient(loss, params)
```

I put an example together in this Colab: https://colab.research.google.com/gist/tomhennigan/acf921df9a7e7dbbfd431414fd408fcb/example-of-selecting-variables-for-optimization.ipynb",hi way request want train use instead python forward return tape forward loss loss cumbersome library one module want use context manager stop specific forward pas python forward return tape forward loss loss put example together,issue,negative,neutral,neutral,neutral,neutral,neutral
1059400203,Would it work to simply update self.w with the newly normalised weights and then pass the input through the layer? And does the weight matrix need to be reshaped to be 2D before normalisation takes place? I noticed the tfa and pytorch code for spectral norm does this.,would work simply update newly pas input layer weight matrix need place code spectral norm,issue,negative,positive,neutral,neutral,positive,positive
1046035507,"We don't have a built in way to do this, but you can monkey patch modules and add your own print statements. Here is an example that hooks every call method of every module class and prints input/output shapes:

https://colab.research.google.com/gist/tomhennigan/ebcee49d928c2c7f2e868d3552a8f85b/example-of-printing-call-method-input-and-output-shapes.ipynb",built way monkey patch add print example every call method every module class,issue,negative,negative,neutral,neutral,negative,negative
1044136532,"hi @AnaRhisT94 , we haven't had other reports of this so I wonder if this is something specific to your setup. How did you install Sonnet? What OS are you using? Which package manager?

One thing to note from the versions you listed, Sonnet v1.36 was designed for TF 1.X and you have TF 2.8.0 installed. If you want to use TF 2 (for new codebases you almost definitely do want to) then please upgrade Sonnet to >=2.0. Our [documentation](https://sonnet.readthedocs.io/en/latest/) and installation instructions all cover Sonnet 2 and TF 2.",hi wonder something specific setup install sonnet o package manager one thing note listed sonnet designed want use new almost definitely want please upgrade sonnet documentation installation cover sonnet,issue,positive,positive,neutral,neutral,positive,positive
992289170,Hi @tomhennigan. Thanks so much for the response. I switched to the latest version of Tensorflow and that seems to have fixed my problem. ,hi thanks much response switched latest version fixed problem,issue,negative,positive,positive,positive,positive,positive
991973098,"HI @jcformanek , this looks like a bug in TensorFlow's autograph feature. Sonnet uses autograph to enable us to write code with simple, easy to understand syntax that works equivalently in eager mode or graph mode.

Please ensure you're using the latest version of TensorFlow and see if the bug re-occurs. If the bug still exists after upgrading then [file a bug on their repo](https://github.com/tensorflow/tensorflow/issues) with instructions on how to reproduce the issue.

One thing we can potentially do in Sonnet to workaround this issue is to make our use of autograph lazier. I'll try that in #227 and once that has merged you can install the very latest version of Sonnet (which will include my fix) using:

```bash
$ pip install git+https://github.com/deepmind/sonnet
```

This will defer our use of autograph until you use a feature that requires it. Perhaps you will be lucky and the features you want from Sonnet will not require Sonnet to use autograph. If not you'll need to wait for the TF bug to get fixed after you file it.",hi like bug autograph feature sonnet autograph enable u write code simple easy understand syntax work equivalently eager mode graph mode please ensure latest version see bug bug still file bug reproduce issue one thing potentially sonnet issue make use autograph try install latest version sonnet include fix bash pip install defer use autograph use feature perhaps lucky want sonnet require sonnet use autograph need wait bug get fixed file,issue,positive,positive,positive,positive,positive,positive
989654537,"Hi @gautica , it seems to work correctly for me: https://colab.research.google.com/gist/tomhennigan/f45c0db3ab5b7f271dafbeb4ef2287b1/example-of-using-w_init-with-sonnet-mlp.ipynb

Please make sure that you are using TensorFlow 2 and Sonnet 2 since this is what our documentation refers to (the API has changed vs. TF1/Sonnet 1).",hi work correctly please make sure sonnet since documentation,issue,positive,positive,positive,positive,positive,positive
986172196,"I'm working on the example you suggested with TF/Sonnet v2. It seems like in v1, the deepRNN defined using sonnet can be substituted directly into tensorflow dynamic_rnn as the cell. Starting from v2, the cell for tensorflow RNN requires to implement the call method and other things. I wonder if there's an example showing how to accomplish this for TF/sonnet. v2. Thanks ",working example like defined sonnet substituted directly cell starting cell implement call method wonder example showing accomplish thanks,issue,positive,positive,positive,positive,positive,positive
971555164,"For anyone with the same issue, you need the tensorflow hook as detailed in discussion here:

https://discuss.tensorflow.org/t/pyinstaller-tensorflow-sonnet/5835/5

It looks like some parts of tensorflow used by sonnet were not being packaged without this.",anyone issue need hook detailed discussion like used sonnet without,issue,negative,positive,positive,positive,positive,positive
967699902,"Hi @dmagee, Sonnet makes use of Autograph in TensorFlow 2. It looks like TensorFlow Autograph (which requires being able to locate the Python source code for a given function to transpile it) is not compatible with the way pyinstaller is re-packaging Python libraries (such as Sonnet) that you depend on. I would suggest raising this as a bug on [TensorFlow](https://github.com/tensorflow/tensorflow/issues), this is not a bug the Sonnet authors can fix.",hi sonnet use autograph like autograph able locate python source code given function compatible way python sonnet depend would suggest raising bug bug sonnet fix,issue,negative,positive,positive,positive,positive,positive
927662426,"Hi @DriesSmit , I'm not familiar with `LayerNormMLP` (as in the implementation you are using, I can guess as to what the architecture is) in particular, but in general `LayerNorm` and `MLP` should work fine at batch size 1.",hi familiar implementation guess architecture particular general work fine batch size,issue,negative,positive,positive,positive,positive,positive
917886358,"Hi @tomhennigan ,
I have made the changes .Could you please review the changes and let me know if any other changes are required?",hi made please review let know,issue,negative,neutral,neutral,neutral,neutral,neutral
915042783,I attempted packaging via bdist_wheel but for some reason the test suite was failing (via pytest). I don't remember the exact details. I'll have to give it another shot and paste the error here.,via reason test suite failing via remember exact give another shot paste error,issue,negative,positive,positive,positive,positive,positive
915033094,"Sonnet v2 is a pure python library (unlike Sonnet 1) so building into a whl is the standard Python stanza: `python setup.py sdist bdist_wheel`. No need to use bazel for building Sonnet 2.

The `v2` branch is the latest, `master` contains Sonnet 1 and no further development effort is planned there. I have been meaning to rename `master` to `v1` for a while, I will check with the other maintainers and see about doing that today.",sonnet pure python library unlike sonnet building standard python stanza python need use building sonnet branch latest master sonnet development effort meaning rename master check see today,issue,negative,positive,positive,positive,positive,positive
913501252,"Hi ,
I tried to run the Notebook with TF 2.2.0 and it works. Please find the notebook: https://colab.research.google.com/drive/18GT4HVkjDwHB4e2AEU2G8XYU__A2t-F6?usp=sharing
Hope this helps",hi tried run notebook work please find notebook hope,issue,positive,neutral,neutral,neutral,neutral,neutral
907652540,"Sorry, this was my mistake.  In this particular model, not all graph variables are connected in each step, so need to ensure there are no `None` values in the gradients:
`grads = tape.gradient(loss, model.trainable_variables, unconnected_gradients=tf.UnconnectedGradients.ZERO)`",sorry mistake particular model graph connected step need ensure none loss,issue,negative,negative,negative,negative,negative,negative
903550724,"Hi @DriesSmit I think we call them `shortcut` in the code. You should be able to see them in the `__call__` method of the blocks:

https://github.com/deepmind/sonnet/blob/0e25f47fac469c0c2180abba0b985aca46f529ce/sonnet/src/nets/resnet.py#L91-L104
 https://github.com/deepmind/sonnet/blob/0e25f47fac469c0c2180abba0b985aca46f529ce/sonnet/src/nets/resnet.py#L166-L179",hi think call code able see method,issue,negative,positive,positive,positive,positive,positive
901791354,"Hi @DriesSmit , Sonnet 2 does not impose any restrictions on what methods you define or what you pass into them. You can find more details on the design in this RFC: https://github.com/tensorflow/community/blob/master/rfcs/20190117-tf-module.md

I guess your module might look something like the following:

```python
class MyModule(snt.Module):
  def __init__(self):
    self.conv = snt.Conv1D(..)
    self.ff = snt.Linear(..)

  def __call__(self, a, b):
    a = self.conv(a)
    a = tf.nn.relu(a)
    a = self.flatten(a)
    a = self.ff(a)
    return tf.stack(a, b)
```",hi sonnet impose define pas find design guess module might look something like following python class self self return,issue,negative,neutral,neutral,neutral,neutral,neutral
898636439,"We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.
In order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.

ℹ️ **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Fdeepmind%2Fsonnet%2Fpull%2F211) for more info**.

<!-- need_author_cla -->",found contributor license agreement sender pull request unable find commit author maybe used different address git used sign login double check someone else need sign well confirm order pas check please resolve problem comment fixed bot comment think anything information go,issue,positive,negative,neutral,neutral,negative,negative
882143472,"Awesome, sounds good, thank you! Ok yeah I wasn't as familiar with the non-EMA version so I just guessed on that one",awesome good thank yeah familiar version one,issue,positive,positive,positive,positive,positive,positive
882095869,"Thanks for filing this! Yes I think it would probably be appropriate to set `trainable=False` for `VectorQuantizerEMA.embeddings` (since this bit is used in TensorFlow to indicate whether a mutable variable should be updated by an optimizer, and in VQ-EMA we update the embeddings as part of the forward pass when training).

I think we want to leave `VectorQuantizer.embeddings` as is (since IIRC this is updated by the optimizer).

If you don't mind I'll send a patch for this and ask someone who knows more about the network than me to review just to make sure we're not missing something subtle. Should land within a week.",thanks filing yes think would probably appropriate set since bit used indicate whether mutable variable update part forward pas training think want leave since mind send patch ask someone network review make sure missing something subtle land within week,issue,positive,positive,positive,positive,positive,positive
863290722,I'd suggest taking a look at [deepmind/acme](https://github.com/deepmind/acme) which has a number of RL agents (e.g. [IMPALA](https://github.com/deepmind/acme/tree/master/acme/agents#discrete-control)) implemented with Sonnet 2 which [use vtrace in the learner](https://github.com/deepmind/acme/blob/fce4a6ef901f6bc82311845f13a9a2699cbab585/acme/agents/tf/impala/learning.py#L133). They also include an [example which uses gym](https://github.com/deepmind/acme/blob/master/examples/control/run_d4pg_gym.py).,suggest taking look number impala sonnet use learner also include example gym,issue,negative,neutral,neutral,neutral,neutral,neutral
862765248,"BTW Tom  I'm working on Argonne Labs on a summer internship and have been
tasked with building a reinforcement learning system with the vtrace
algorithm using Open gym as the environment.  We are trying to solve a
special reinforcement learning problem and we want to uses a scalable
architecture so we can parallelize the problem I'm trying to repurpose your
experiment.py and vtrace.py from your scalable-agent repo.  and replace the
environment with open gym instead of deep mind lab.  Is there anyone on
your team who might be able to give me some pointers.  I'm drinking from
the firehose here.

Ed Friesema
Check out my github page www.github.com/efriesema for my latest projects!




On Wed, Jun 16, 2021 at 3:09 PM Ed Friesema ***@***.***> wrote:

> Thanks Tom,  the pip install from github seems to have fixed the problem
>
>
> Ed Friesema
> Check out my github page www.github.com/efriesema for my latest projects!
>
>
>
>
> On Tue, Jun 15, 2021 at 11:50 PM Tom Hennigan ***@***.***>
> wrote:
>
>> HI @efriesema <https://github.com/efriesema> , we test wtith TensorFlow
>> 2.5 (e.g.
>> https://github.com/deepmind/sonnet/runs/2792353483?check_suite_focus=true)
>> so I don't think that will be the issue.
>>
>> If you run just the following, does it print the version you expect:
>>
>> import tensorflow as tfprint(""TensorFlow version {}"".format(tf.__version__))
>>
>> You may want additionally to try installing the latest version from the
>> github repo rather than the last stable release:
>>
>> pip install pip install ***@***.***
>>
>> —
>> You are receiving this because you were mentioned.
>> Reply to this email directly, view it on GitHub
>> <https://github.com/deepmind/sonnet/issues/204#issuecomment-862097235>,
>> or unsubscribe
>> <https://github.com/notifications/unsubscribe-auth/AC247BTUEUM4PY7Y22LRSUTTTBCRXANCNFSM46YHGCIA>
>> .
>>
>
",working summer internship building reinforcement learning system algorithm open gym environment trying solve special reinforcement learning problem want scalable architecture parallelize problem trying repurpose replace environment open gym instead deep mind lab anyone team might able give drinking check page latest wed wrote thanks pip install fixed problem check page latest tue wrote hi test think issue run following print version expect import version may want additionally try latest version rather last stable release pip install pip install reply directly view,issue,negative,positive,positive,positive,positive,positive
862762639,"Thanks Tom,  the pip install from github seems to have fixed the problem


Ed Friesema
Check out my github page www.github.com/efriesema for my latest projects!




On Tue, Jun 15, 2021 at 11:50 PM Tom Hennigan ***@***.***>
wrote:

> HI @efriesema <https://github.com/efriesema> , we test wtith TensorFlow
> 2.5 (e.g.
> https://github.com/deepmind/sonnet/runs/2792353483?check_suite_focus=true)
> so I don't think that will be the issue.
>
> If you run just the following, does it print the version you expect:
>
> import tensorflow as tfprint(""TensorFlow version {}"".format(tf.__version__))
>
> You may want additionally to try installing the latest version from the
> github repo rather than the last stable release:
>
> pip install pip install ***@***.***
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/deepmind/sonnet/issues/204#issuecomment-862097235>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AC247BTUEUM4PY7Y22LRSUTTTBCRXANCNFSM46YHGCIA>
> .
>
",thanks pip install fixed problem check page latest tue wrote hi test think issue run following print version expect import version may want additionally try latest version rather last stable release pip install pip install reply directly view,issue,negative,positive,positive,positive,positive,positive
862097235,"HI @efriesema , we test wtith TensorFlow 2.5 (e.g. https://github.com/deepmind/sonnet/runs/2792353483?check_suite_focus=true) so I don't think that will be the issue.

If you run just the following, does it print the version you expect:

```python
import tensorflow as tf
print(""TensorFlow version {}"".format(tf.__version__))
```

You may want additionally to try installing the latest version from the github repo rather than the last stable release:

```python
pip install pip install git+https://github.com/deepmind/sonnet@v2
```",hi test think issue run following print version expect python import print version may want additionally try latest version rather last stable release python pip install pip install,issue,negative,positive,positive,positive,positive,positive
856690535,"Hey, Tom, yes, you are right, appreciate your quick and clear explanation.",hey yes right appreciate quick clear explanation,issue,positive,positive,positive,positive,positive,positive
856623156,"Hi @mingyr, in this case I would suggest having two variables, one referencing the model and the other being a tf.function applying it:

```python
model = snt.nets.MLP([300, 100, 10])
infer = tf.function(model)
logits = infer(x)
params = model.trainable_variables
```

In general you want to put as much code as you can inside a `tf.function`, so I would suggest looking at ways to put both the logits computation and the loss computation, gradient computation and optimizer update into a single `tf.function`. We have an example of this in our [MNIST example](https://github.com/deepmind/sonnet/blob/v2/examples/simple_mnist.py) and it should be straightforward to make that data parallel over many GPUs following our [distributed Cifar10](https://github.com/deepmind/sonnet/blob/v2/examples/distributed_cifar10.ipynb) example.",hi case would suggest two one model python model infer model infer general want put much code inside would suggest looking way put computation loss computation gradient computation update single example example straightforward make data parallel many following distributed example,issue,negative,positive,positive,positive,positive,positive
854457433,"Hi @wxntech , we don't have a hosted copy (e.g. on github pages) of Sonnet 1 docs any longer, but you can still find the code for 1.x in the [`master`](https://github.com/deepmind/sonnet/tree/master) branch, and the [docs for the last commit can be found here](https://github.com/deepmind/sonnet/blob/master/docs/index.md) and [per-public symbol docs can be found here](https://github.com/deepmind/sonnet/blob/master/docs/sonnet.md).",hi copy sonnet longer still find code master branch last commit found symbol found,issue,negative,neutral,neutral,neutral,neutral,neutral
779720867,I upgrade my tf to 2.4.1 and it worked! I guess tf 2.2.0 is somehow incompatible with the code. Thanks a lot! ,upgrade worked guess somehow incompatible code thanks lot,issue,negative,positive,positive,positive,positive,positive
779637404,"Hi @tomhennigan! I also tried your original code without any changes. The result was still NaN. I thought it could be an environmental problem, but there was no error coming up. ",hi also tried original code without result still nan thought could environmental problem error coming,issue,negative,positive,positive,positive,positive,positive
778815202,"Hi @EBGU , there's quite a lot of code there! I recognize at least some of this from our vqvae example notebook? Rather than printing the whole file it might be more useful if you could highlight what you have changed?

I've just ran our vqvae notebook using a free GPU instance on Google Colab, with TF 2.4.1, you can see the results in the gist below:

https://colab.research.google.com/gist/tomhennigan/62edee62a4638e0d0ab9738a757043ed/tf2_vq_vae_training_example.ipynb

As far as I can tell things are working correctly?",hi quite lot code recognize least example notebook rather printing whole file might useful could highlight ran notebook free instance see gist far tell working correctly,issue,positive,positive,positive,positive,positive,positive
775779299,"Hi @pshrini I think this is a TF issue not a Sonnet issue (we do not depend on or use `gast` directly but TF does).

I would suggest making sure you have the latest version of TensorFlow ([2.4.1](https://pypi.org/project/tensorflow/2.4.1/) has been released recently) and all other deps. If you continue to have issues after upgrading I would suggest filing an issue on TensorFlow.",hi think issue sonnet issue depend use gast directly would suggest making sure latest version recently continue would suggest filing issue,issue,negative,positive,positive,positive,positive,positive
770189687,"Hi @Pranav-India, that API is only used in Sonnet 1 which only supports TensorFlow 1 and is deprecated.

If you need to use TensorFlow 1 for some reason then you can find the source for Sonnet 1 in the `master` branch, the method is defined here https://github.com/deepmind/sonnet/blob/master/sonnet/python/modules/base.py#L536.

We recommend that new projects use Sonnet 2 and TensorFlow 2. You can find documentation on Sonnet 2 at https://sonnet.readthedocs.io/en/latest/.

We use GitHub issues for discussion and don't have a Slack/Discord I'm afraid.",hi used sonnet need use reason find source sonnet master branch method defined recommend new use sonnet find documentation sonnet use discussion afraid,issue,negative,negative,negative,negative,negative,negative
727250602,"Thanks for getting back to me without delay!

I couldn't find in the Sonnet Documentation how to use this modules.
What should I do if I only get the w in snt.conv2D and process it like a SN?",thanks getting back without delay could find sonnet documentation use get process like,issue,positive,positive,neutral,neutral,positive,positive
721014995,For others that come across this issue I believe the following is sufficient: `pip install dm-sonnet<2`,come across issue believe following sufficient pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
716036408,"Hi,
You can save the model by this:
```tf.saved_model.save(my_model, ""the_saved_model"")```
And for loading your model back use this:
```new_model = tf.saved_model.load(""the_saved_model"")```",hi save model loading model back use,issue,negative,neutral,neutral,neutral,neutral,neutral
702799929,"I don't think there is a public API in TF allowing us to hook `saved_model.load` to recreate your module as a Sonnet module, but it should be possible do this in a wrapper:

```python
class RestoredModule(snt.Module):
  def __init__(self, obj):
    super().__init__()
    self.obj = obj
    self._all_variables = list(obj.signatures['serving_default'].variables)

  def __call__(self, *args):
    return self.obj(*args)

def load_snt(path: str) -> RestoredModule:
  obj = tf.saved_model.load(path)  # NOTE: This is a _UserObject from TF.
  return RestoredModule(obj)
```

Should be straightforward to use:

```python
class MyModel(snt.Module):
  @snt.once
  def create_vars(self, x):
    self.w = tf.Variable(tf.ones([x.shape[-1], 10]), name='w')
    self.b = tf.Variable(tf.zeros([10]), trainable=False)

  @tf.function(input_signature=[tf.TensorSpec([1, 1])])
  def __call__(self, x):
    self.create_vars(x)
    return tf.matmul(x, self.w) + self.b

m = MyModel()
m(tf.ones([1, 1]))
tf.saved_model.save(m, '/tmp/model/')

r = load_snt('/tmp/model/')  # Use our special loader.
r(tf.ones([1, 1]))
assert isinstance(r, snt.Module)
assert not isinstance(r, MyModel)
assert len(r.variables) == 2
assert len(r.trainable_variables) == 1
```",think public u hook recreate module sonnet module possible wrapper python class self super list self return path path note return straightforward use python class self self return use special loader assert assert assert assert,issue,positive,positive,positive,positive,positive,positive
699579090,"using `pip install dm-sonnet` failed for me and maybe you can use
`pip install dm-sonnet-gpu==1.23` 
to solve it",pip install maybe use pip install solve,issue,negative,neutral,neutral,neutral,neutral,neutral
674107867,Interesting. I think the wheels for Sonnet 2 are platform-agnostic because Sonnet 2 does not have any native code. So you only really need to build `tree`.,interesting think sonnet sonnet native code really need build tree,issue,negative,positive,positive,positive,positive,positive
674076808,"Sorry, I talked about Sonnet2. But, it will be a little thing.
I see. I'll use Bazel for installation. Thank you.

As you may know, Nvidia published wheels of TensorFlow for Jetson in [https://developer.download.nvidia.com/compute/redist/jp/v44/tensorflow/](https://developer.download.nvidia.com/compute/redist/jp/v44/tensorflow/). However, thers is a delay in releasing latest versions.",sorry sonnet little thing see use installation thank may know however delay latest,issue,negative,negative,neutral,neutral,negative,negative
674040306,"Thanks for writing this up!

Neither Sonnet 1 nor `tree` have wheels for aarm64, and I'm afraid this will remain the case for a while. So, the only way of installing Sonnet 1 on Jetson is indeed by downloading Bazel (as you did) and building both `tree` and Sonnet 1 from source. Note that you'll likely have to build TensorFlow from source as well for the same reason.
",thanks writing neither sonnet tree afraid remain case way sonnet indeed building tree sonnet source note likely build source well reason,issue,positive,negative,negative,negative,negative,negative
665747091,"Hi! The Sonnet ResNet implementation closely follows this TensorFlow implementation (which also initializes the last batch norm in the residual block to 0): https://github.com/tensorflow/tpu/blob/d35e48588cfdab24aaddd045e37d0e967166931f/models/official/resnet/resnet_model.py#L443.

As for why: for example the [Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour](https://arxiv.org/pdf/1706.02677.pdf) paper mentions initializing the last batch norm to 0 for easier training. From section 5.1: `Setting γ = 0 in the last BN of each residual block causes the forward/backward signal initially to propagate through the identity shortcut of ResNets, which we found to ease optimization at the start of training.`

Does this answer your question?",hi sonnet implementation closely implementation also last batch norm residual block example accurate large training hour paper last batch norm easier training section setting last residual block signal initially propagate identity found ease optimization start answer question,issue,negative,positive,positive,positive,positive,positive
663806316,"Navigate to the doc folder. On the left side of the directory path, there is a button. If you click on it, you can choose 1.x tags. ",navigate doc folder left side directory path button click choose,issue,negative,neutral,neutral,neutral,neutral,neutral
662041164,"I figured out that the root cause why I was experiencing a ""zero moving variance"" in the first training step is because there was a dummy call with` tf.zeros` tensors to ensure variables created (where `is_training` is set to `False`), as in [tf_utils.create_variables](https://github.com/deepmind/acme/blob/master/acme/tf/utils.py#L78-L95). However, the current implementation of `snt.BatchNorm` assumes that variables would be created with the first batch --- **regardless of `is_training=False`**. If the argument `is_training=False` was given, it should NOT initialize the variance, but it appears that the dummy calls would make the moving variance incorrectly initialized. If variable initialization is done *before* the first forward pass (e.g. initialize the moving average with 1), there would be no problem.",figured root cause zero moving variance first training step dummy call ensure set false however current implementation would first batch regardless argument given initialize variance dummy would make moving variance incorrectly variable done first forward pas initialize moving average would problem,issue,negative,positive,neutral,neutral,positive,positive
662010782,"@tomhennigan Even if eps > 0 (say 1e-3), the first moving variance reported is regardless 0.0 which makes the activation too large. It will always blow up the layer and training as well -- in the very first training iteration loss can go infinite, because the moving variance would be updated AFTER the first forward training pass. So I don't think the current implementation of initialization is correct.

Please note that Keras BatchNorm initializes moving variance with one: https://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/python/layers/normalization.py#L133",even say first moving variance regardless activation large always blow layer training well first training iteration loss go infinite moving variance would first forward training pas think current implementation correct please note moving variance one,issue,negative,positive,positive,positive,positive,positive
660451869,"Hey @dangerzone, `TpuReplicator` is now equivalent to `TPUStrategy`, there used to be one key difference (`TpuReplicator` used to create **replicated** variables [e.g. same initial value but not required to be in sync otherwise] while `TPUStrategy` used to require **mirrored** variables [meaning you need to use a special API for assignment to ensure values remained mirrored]) but TF team recently (I think you may need to use [TF 2.3.0rc2](https://pypi.org/project/tensorflow/2.3.0rc2/)) relaxed `TPUStrategy` (and `MirroredStrategy`) to not require using this mirrored assignment API.

As such I would suggest looking for any docs for `TPUStrategy` that explain how to do what you want. Usage (constructor etc) with `TpuReplicator` would be equivalent.

In the next release of Sonnet we will likely make `TpuReplicator` an alias for `TPUStrategy` and remove the symbol entirely in a future release. Before doing this we want to find some time to run a few experiments to make sure there are no surprises.",hey equivalent used one key difference used create replicated initial value sync otherwise used require mirrored meaning need use special assignment ensure mirrored team recently think may need use relaxed require mirrored assignment would suggest looking explain want usage constructor would equivalent next release sonnet likely make alias remove symbol entirely future release want find time run make sure,issue,positive,positive,positive,positive,positive,positive
653888232,"Thanks, @meta-inf !
Indeed the parameter name I proposed is wrong. I will dive a bit deeper into the topic to get a better understanding of RNNs, LSTMs, and the code (any useful links are welcome). 
But the approach I'm proposing is kind of intuitive: make currently hardcoded variable a parameter to increase method flexibility.
If somebody can confirm that extracting this parameter will make sense for other use cases - I'm happy to create a pull request with the improvement!
Of course, you are more than welcome to suggest a more suitable name for this parameter :)",thanks indeed parameter name wrong dive bit topic get better understanding code useful link welcome approach kind intuitive make currently variable parameter increase method flexibility somebody confirm parameter make sense use happy create pull request improvement course welcome suggest suitable name parameter,issue,positive,positive,positive,positive,positive,positive
653057174,"@SergeyVolodko I'm not sure what you meant by `initial_state`, since the `LSTMState` created in `lstm_with_recurrent_dropout` is used to store the dropout rate, and is not an initial state. The initial state of `_RecurrentDropoutWrapper` consists of both the initial state of the base RNN core, as well as a dropout mask (see [here](https://github.com/deepmind/sonnet/blob/1f5c0c241653ef692f8a5c4385d6ea5e5e44bdef/sonnet/src/recurrent.py#L1149)), and it doesn't seem like we should change the entire state to 0.

I guess the easiest fix is to set that cell parameter to 0: it's a placeholder and is never used. But any change that makes my original code example work would be fine to me.",sure meant since used store dropout rate initial state initial state initial state base core well dropout mask see seem like change entire state guess easiest fix set cell parameter never used change original code example work would fine,issue,positive,positive,neutral,neutral,positive,positive
652846840,"Hi @agnusmaximus if you want to run on the CPU then create and use your modules inside a `with tf.device(""CPU""):` block. For example:

```python
x = tf.ones([1, 28 * 28])
with tf.device(""CPU""):
  mod = snt.nets.MLP([300, 100, 10])
  logits = mod(x)
```

It may be useful to know that outside of a `with tf.device` scope TensorFlow's default device placement policy will silently move tensors from the CPU to the GPU, you may want to set TF's device policy to explicit if you want to ensure all computation remains on the CPU:

```python
tf.config.experimental.set_device_policy(""explicit"")
```

If you want your whole TF program to only run using CPU then you can configure TensorFlow to ignore all other devices using the following at the start of your program:

```python
# Ignore all devices other than available CPU(s).
cpus = tf.config.list_physical_devices(""CPU"")
tf.config.set_visible_devices(cpus)
```",hi want run create use inside block example python may useful know outside scope default device placement policy silently move may want set device policy explicit want ensure computation remains python explicit want whole program run configure ignore following start program python ignore available,issue,negative,positive,positive,positive,positive,positive
651402003,"> Seems it is because you are trying to store a None value to the initial state of a while loop. Changing the None value on this line to 0. appears to fix this.

The line mentioned:
`  rate = LSTMState(hidden=dropout, cell=None)`

@meta-inf do you think that extracting `cell` / initial state to the parameters of `lstm_with_recurrent_dropout` can fix the issue?

So your usage gonna look something like:
`self.train_core, test_core = snt.lstm_with_recurrent_dropout(1, dropout=0.5, initial_state=0)`",trying store none value initial state loop none value line fix line rate think cell initial state fix issue usage gon na look something like,issue,negative,neutral,neutral,neutral,neutral,neutral
651395852,"Thank you @superbobry !
Sure, there is no problem to skip the changes. Or maybe to restructure them…
I think I was a bit unclear about the reasoning for this PR, even to myself. So let me try to rewrite it :)

The selection of `recurrent.py` as a refactoring target is not random. When thinking where my contribution could be the most useful I’ve run a great code BI tool against the repository and it revealed that `recurrent.py` is actually a significant outlier across the entire project. 
![image](https://user-images.githubusercontent.com/6623519/86057695-93a1d880-ba57-11ea-9511-3749655b903d.png)
(Legend: Circles are files in folders, their size - number of lines of code, color insensitivity - commit frequency)

It has the highest change frequency and the biggest size.
![image](https://user-images.githubusercontent.com/6623519/86057865-d794dd80-ba57-11ea-8a3b-03f3fdc6788a.png)

So the major reason to think of refactoring this file not just the size, but the frequency of changes/fixes. (Because we commit when we need to fix or modify something )

Zooming a bit deeper the analysis identified that there is quite a high chances that `static_unroll` and `dynamic_unroll` methods are problematic:
![image](https://user-images.githubusercontent.com/6623519/86059613-f6e13a00-ba5a-11ea-8822-28f8d8f4777f.png)
( `__init__` and `__call__` seems to be aggregated through all the classes so we can skip their results)

And when I was trying to reproduce the example from #161 something was failing in `dynamic_unroll` for me.

Intuitively, **these two methods are actual targets of my refactoring**.  My intuitive plan was:
1. (current PR) Clean up a bit before the extraction and get familiar with the code and not break anything.
2. Extract `static_unroll` and `dynamic_unroll` to a dedicated file like: `recurrent_internals.py` or `unroll.py`. 

But seems like I completely formulated this plan only now :)

The idea of this refactoring is to extract `static_unroll` and `dynamic_unroll` with their internals to a separate file like `unroll.py`. 
And I can see 3 major benefits from that:
- Better isolate most frequently changed code, which can help to focus maintenance effort in the future.
- `recurrent.py` will contain only classes of networks that with time seems to be only getting added, not modified.
- Better align the structure with usage. From the code usages the methods seem to be called like: `snt.dynamic_unroll()` with no `recurrent` in the path. While structure-wise, currently, the methods belong to `recurrent.py`.

Of course, this refactoring idea is based only on numbers without knowing the details of your challenges :)

So if you think the extraction of `unroll` methods can make sense I would be happy to shift the focus of this PR and implement the change. Otherwise, no problem to close this branch.

How do you think?",thank sure problem skip maybe think bit unclear reasoning even let try rewrite selection target random thinking contribution could useful run great code tool repository revealed actually significant outlier across entire project image legend size number code color insensitivity commit frequency highest change frequency biggest size image major reason think file size frequency commit need fix modify something bit analysis quite high problematic image class skip trying reproduce example something failing intuitively two actual intuitive plan current clean bit extraction get familiar code break anything extract file like like completely plan idea extract internals separate file like see major better isolate frequently code help focus maintenance effort future contain class time getting added better align structure usage code seem like recurrent path currently belong course idea based without knowing think extraction unroll make sense would happy shift focus implement change otherwise problem close branch think,issue,positive,positive,positive,positive,positive,positive
651114413,"Thanks for the PR, Sergey!

I understand your concerns regarding the size of `recurrent.py`. Big modules could be tricky to work with, but I'm not sure that splitting `recurrent.py` into multiple smaller modules would significantly improve readability/maintainability. Having internal functions defined closer to the usage sites makes refactoring easier; `_` names clearly indicate that these are not designed for use outside of Sonnet. So, all in all, I'd rather not merge this. I hope it's okay. That said, please do not hesitate to tackle #161, we'd welcome a fix for that!

> I’ve noticed quite a few TODOs in recurrent.py. Maybe you have some refactoring plans or ideas for this file which should be considered in the current or next PRs?

I don't think we have any refactoring planned atm. Most TODOs are there to provide context or serve as a reminder, but none are critical to implement/fix.
",thanks understand regarding size big could tricky work sure splitting multiple smaller would significantly improve internal defined closer usage easier clearly indicate designed use outside sonnet rather merge hope said please hesitate tackle welcome fix quite maybe file considered current next think provide context serve reminder none critical,issue,positive,positive,positive,positive,positive,positive
650842252,"Sorry for the mess with the commit authors, a bit an unexpected issue but seems to be solved :)
Will squash the commits if needed",sorry mess commit bit unexpected issue squash,issue,negative,negative,negative,negative,negative,negative
650841881,"CLAs look good, thanks!

ℹ️ **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Fdeepmind%2Fsonnet%2Fpull%2F178) for more info**.

<!-- ok -->",look good thanks information go,issue,positive,positive,positive,positive,positive,positive
650841167,"All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.

We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.

*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).

ℹ️ **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Fdeepmind%2Fsonnet%2Fpull%2F178) for more info**.

<!-- need_author_consent -->",pull request submitter commit one someone pull request submitter need confirm project please confirm leaving comment pull request note project maintainer may author leave comment comment properly consent manually confirm consent commit author set label yes project information go,issue,positive,neutral,neutral,neutral,neutral,neutral
647482665,Thank you for quick response! Has solved my issue.,thank quick response issue,issue,negative,positive,positive,positive,positive,positive
647451788,"@hamcam98 the `prev_state` supplied on input will be the same shape as whatever that module returns from the `initial_state` method (this is true for all the different RNN modules). So for the LSTM you can see there is a LSTMState namedtuple, that has the `.hidden` and `.cell` attributes: https://github.com/deepmind/sonnet/blob/v2/sonnet/src/recurrent.py#L848

I hope this answers your question, please reopen if not.",input shape whatever module method true different see hope question please reopen,issue,positive,positive,positive,positive,positive,positive
644051472,"`AffineGridWarper` is not available in Sonnet 2. 

Unfortunately, I don't think we have Sonnet 1 API docs hosted anywhere, cc @tomhennigan.",available sonnet unfortunately think sonnet anywhere,issue,negative,negative,neutral,neutral,negative,negative
640616375,On the same example: it seems that we are only training stage 1 of the paper. In order to perform generation we would also need to train the prior (using PixelCNN for example). Is this included somewhere?,example training stage paper order perform generation would also need train prior example included somewhere,issue,negative,neutral,neutral,neutral,neutral,neutral
638983048,"@tomhennigan Thanks! I did not set the default epsilon. But I was using a large network (ResNet50), not sure if that is overflow caused by magnifying from many BatchNorm layers in the network. I will leave the issue closed, and will come back if I got a chance to make a minimum reproducible example.",thanks set default epsilon large network sure overflow many network leave issue closed come back got chance make minimum reproducible example,issue,positive,positive,positive,positive,positive,positive
638655468,"Hey @pluskid I suspect this is only the case if you are setting `eps=0`, we (inline with the paper) include a small epsilon (default: `1e-5`) to avoid division by zero (https://sonnet.readthedocs.io/en/latest/api.html#batchnorm) and indeed for a randomly initialized batchnorm layer I do not get `NaN` for any value of is_training+test_local_stats:

```python
x = tf.random.normal([4, 4])
for is_training in (True, False):
  for test_local_stats in (True, False):
    bn = snt.BatchNorm(True, True)
    y = bn(x, is_training=is_training, test_local_stats=test_local_stats)
    assert not tf.reduce_any(tf.math.is_nan(y))
```

If you want to keep `eps=0` and avoid division by zero you could pass `test_local_stats=True` to your BatchNorm layers to use the mean/variance of the current batch rather than the average.",hey suspect case setting paper include small epsilon default avoid division zero indeed randomly layer get nan value python true false true false true true assert want keep avoid division zero could pas use current batch rather average,issue,positive,negative,neutral,neutral,negative,negative
623457055,"Thanks for the clarification. I now realise that `self._ema_w` remains unnormalized throughout training, so my concern doesn't apply. ",thanks clarification remains throughout training concern apply,issue,negative,positive,positive,positive,positive,positive
623452552,"Hi @stangelid apologies for the delay. I checked with Aäron van den Oord and he sent the following:

```
Hi Stefanos,
self._ema_w are the moving averages of the unnormalized weights.
https://arxiv.org/pdf/1711.00937.pdf
Equation (9) in the Appendix defines the weights (e_i) as
- The moving averages of the unnormalized weights (sum of z_ij)
- Divided by the moving averages of the counts of the codebook (sum of number of elements in each cluster)
This seems to correspond well with the code?
```
`",hi delay checked van den oord sent following hi moving equation appendix moving sum divided moving sum number cluster correspond well code,issue,negative,neutral,neutral,neutral,neutral,neutral
621139360,"Hi - I'm afraid this isn't the best place for open ended questions like this - I would advise to try a larger online community (reddit, stackexchange, ...) for this kind of discussion. If you have a specific question about the code please post here, and a specific question about the model would be best forwarded to the original authors: https://arxiv.org/abs/1711.00937",hi afraid best place open ended like would advise try community kind discussion specific question code please post specific question model would best original,issue,positive,positive,positive,positive,positive,positive
616550720,"BTW we have DNC in nets but have not exposed it as part of the public API yet. I suspect this is because we want to add an example of how to use it and helps us to be sure it faithfully reproduces the original paper, but if you'd like an early look it is open source. 

[0] https://github.com/deepmind/sonnet/tree/v2/sonnet/src/nets/dnc",exposed part public yet suspect want add example use u sure faithfully original paper like early look open source,issue,positive,positive,positive,positive,positive,positive
615140829,"Closing out some old issues, please reopen if this is still a blocker.",old please reopen still blocker,issue,negative,positive,neutral,neutral,positive,positive
615127862,"Hey @vinhngx, sorry it took us so long to get back to you here. We have been very focussed on Sonnet 2 and V1 is largely frozen at this point. I'm going to close out this PR.

FWIW for future readers we do have experimental FP16 mixed precision support in Sonnet 2 https://sonnet.readthedocs.io/en/latest/api.html#module-sonnet.mixed_precision.",hey sorry took u long get back sonnet largely frozen point going close future experimental mixed precision support sonnet,issue,negative,negative,neutral,neutral,negative,negative
615126799,"Hey @pmangg , sorry we didn't get back to you here!

Development on Sonnet has switched to V2 and now our docs are hosted on RTD (https://sonnet.readthedocs.io/en/latest/). Please let us know if you find any issues and feel free to @me so it doesn't take us a year to get back to you next time! ",hey sorry get back development sonnet switched please let u know find feel free take u year get back next time,issue,positive,negative,neutral,neutral,negative,negative
615125711,Hi @davemssavage sorry we didn't get back to you here. Development on Sonnet has switched from V1 to V2 and we're closing out old PRs and issues related to V1.,hi sorry get back development sonnet switched old related,issue,negative,negative,neutral,neutral,negative,negative
615124890,Hey @laurelkeys sorry we didn't get back to you on this. We have flipped the default branch on github from v1 to v2 and v1 is largely frozen at this stage. I'm going to close this out along with other patches going to Sonnet 1.X.,hey sorry get back default branch largely frozen stage going close along going sonnet,issue,negative,negative,neutral,neutral,negative,negative
615112949,"Thank you for the report @karliell , we have pushed a `2.0.0` release of Sonnet now so you can just do `!pip install dm-sonnet`.

There is also a new `1.1.0` release of `graph-nets` which has been picked up by colab which is compatible with TF2 and Sonnet 2 ([example here](https://github.com/deepmind/graph_nets/blob/f7db5fd9d531544d5b2fb285b1a6ed3352dd0192/graph_nets/demos_tf2/models.py)).

I think thigs are working correctly now, please re-open if not!",thank report release sonnet pip install also new release picked compatible sonnet example think working correctly please,issue,positive,positive,positive,positive,positive,positive
615110437,Thanks for the report! We will update these lines to be `!pip install dm-sonnet tqdm` since the latest version of TF does not pin a broken version of gast 😄 ,thanks report update pip install since latest version pin broken version gast,issue,negative,positive,neutral,neutral,positive,positive
614153926,@tomhennigan  I have added the f64 case to the EMA test (`testEmaUpdating`) as that is the only use case where things would crash (indeed without this patch those tests would fail for f64). Is that good enough?,added case test use case would crash indeed without patch would fail good enough,issue,negative,positive,neutral,neutral,positive,positive
614058762,"It does work when changing to gast version 0.3.3
!pip install dm-sonnet==2.0.0b0 gast==0.3.3 tqdm",work gast version pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
613939160,@tfqbasha you can follow this issue https://github.com/deepmind/kinetics-i3d/issues/85 to see if the developers will respond to the update request.,follow issue see respond update request,issue,negative,neutral,neutral,neutral,neutral,neutral
613862808,Thanks @ialong ! Please add a test with f64 to make sure we don't regress on this.,thanks please add test make sure regress,issue,positive,positive,positive,positive,positive,positive
613362439,"
Thanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

:memo: **Please visit <https://cla.developers.google.com/> to sign.**

Once you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.

----

#### What to do if you already signed the CLA

##### Individual signers

*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).

##### Corporate signers

*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).
*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).
*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).
		

ℹ️ **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Fdeepmind%2Fsonnet%2Fpull%2F168) for more info**.

<!-- need_sender_cla -->",thanks pull request like may first contribution open source project look help look pull request need sign contributor license agreement memo please visit sign fixed please reply verify already individual possible different address commit check data verify set git corporate company point contact authorized participate ask added group authorized know point contact direct project maintainer public version used register authorized contributor must used git commit check data verify set git used register authorized contributor must also attached account information go,issue,positive,positive,neutral,neutral,positive,positive
605122156,Hey @joaogui1 as with deepmind/dm-haiku#6 this is available via the variance scaling initializer. We've included the various ways of driving this in the docs https://sonnet.readthedocs.io/en/latest/api.html#variancescaling.,hey available via variance scaling included various way driving,issue,negative,positive,positive,positive,positive,positive
599789120,"@malcolmreynolds After some thought, maybe it wasn't clear what I was trying to describe.
What if instead of flat_inputs it was shaped as [B,1,D] and embeddings as [1,K,D] wouldn't that produce equivalent results with far fewer computations? ",thought maybe clear trying describe instead shaped would produce equivalent far,issue,negative,positive,neutral,neutral,positive,positive
597936227,"On TensorFlow 2.2 or higher, the gast bug has been fixed and gast 0.3+ would be required.",higher gast bug fixed gast would,issue,negative,positive,positive,positive,positive,positive
594854822,"I once had ran into this issue, worked around by installing gast 0.2.2. Somehow later I got gast updated to 0.3.3 and apparently does not have issue any more. Could you guys check (@ignacio-rocco) if the latest version of gast (0.3.3+) resolves this issue?",ran issue worked around gast somehow later got gast apparently issue could check latest version gast issue,issue,negative,positive,positive,positive,positive,positive
594166315,"@tfqbasha as mentioned above, models written in Sonnet v1 will not work unmodified with V2. I would suggest asking the authors of Kinetics directly whether they are planning on making a Sonnet v2 version available.",written sonnet work unmodified would suggest kinetics directly whether making sonnet version available,issue,negative,positive,positive,positive,positive,positive
594097650,"Hey,
I was using deepmind's kinetics-i3d repository and got this AttributeError. Below are the versions of tf and snt I am using.
TensorFlow version 2.1.0
Sonnet version 2.0.0b0

Based on the discussion above, I see that  AbstractModule is not used in sonnet2.0. Do I have to go back to sonnet1.0 or is there a kinetics-i3d based on sonnet2.0?",hey repository got version sonnet version based discussion see used sonnet go back sonnet based sonnet,issue,negative,neutral,neutral,neutral,neutral,neutral
593176837,"Thank you! Come to think of it, I agree with you",thank come think agree,issue,positive,neutral,neutral,neutral,neutral,neutral
592911181,"In addition, a test was added to the TODO list to check if the sum was a floating point.",addition test added list check sum floating point,issue,negative,neutral,neutral,neutral,neutral,neutral
591433443,"> Hey @hanbyul-kim, thanks for fixing the docs! I've left a few comments.

I resolved all the comments you gave me last night and rebased v2 again. Please review them again.",hey thanks fixing left resolved gave last night please review,issue,positive,positive,neutral,neutral,positive,positive
587210028,"Maybe I can explain better.. Let's say you have an embedding dimension of 4, dictionary size / num_embeddings of 5, so self.embeddings will have shape [4, 5].

The code as written allows users to pass in any tensor with a final dimension of 4 - all the preceding dimensions are flattened to a single one, which we could think of as batch size. So inputs with shape [7, 4] produces a flat_input of shape [7, 4] again. Inputs of shape [3, 11, 4] produ ces flat_inputs of shape [33, 4].

Now let's say we have some flat_inputs of shape [3, 4], and for each of them we want to compute the distance to each embedding, which we then find the minimum distance of. The code as written for distances produces an output of size [33, 5], where element i,j is the distance between input element i and dictionary element j. This is all the possible pairwise distances that can be calculated, which your code does not do.

Your suggestion will only ""work"", as in run without an error, for flat_inputs having the same shape as (or a shape broadcastable to the shape of) the embeddings - but the distances generated by your code will only contain the distances between input element i and dictionary element i. You can't do the following argmax (or argmin!) because you don't have all the relevant distances calculated.

Possibly your confusion is that you're thinking about an input of batch size 1 only - through broadcasting, your approach does compute all the distances required - but essentially through luck, and if you go to batch size >=2 the calculation will fail. Arbitrary batch sizes should be supported basically everywhere in Sonnet because that's how this code is run in practice,


As for argmin versus argmax, this is a good question. I'm actually not sure if there is a microoptimisation at play here or whether it's a stylistic preference - I did a little cleanup and added docs for the release but all the logic is unchanged from the original implementation by Aäron van den Oord, including that detail.",maybe explain better let say dimension dictionary size shape code written pas tensor final dimension preceding single one could think batch size shape shape shape shape let say shape want compute distance find minimum distance code written output size element distance input element dictionary element possible pairwise calculated code suggestion work run without error shape shape shape code contain input element dictionary element ca following relevant calculated possibly confusion thinking input batch size approach compute essentially luck go batch size calculation fail arbitrary batch size basically everywhere sonnet code run practice versus good question actually sure play whether stylistic preference little cleanup added release logic unchanged original implementation van den oord detail,issue,positive,positive,positive,positive,positive,positive
587116978,"@malcolmreynolds I don't quite see the difference yet so I will give it some more thought.

Also why do 
https://github.com/deepmind/sonnet/blob/e097a6678569314f6dd0f0083e91e2cd01aefeff/sonnet/src/nets/vqvae.py#L108
```python
encoding_indices = tf.argmax(-distances, 1)
```

instead of 

```python
encoding_indices = tf.argmin(distances, 1)
```",quite see difference yet give thought also python instead python,issue,negative,neutral,neutral,neutral,neutral,neutral
587113933,"The two code segments are not equivalent - the code as it exists in the module is computing the distance between every corresponding pair of entries flat_input and embedding, and note that it will work for different size inputs as long as flat_inputs.shape[1] == self.embeddings.shape[0]. Your version only computes the distance for when you have an equal number of flat inputs and embeddings, which is not necessarily going to be true, and more importantly it computes the distance from minibatch element i to embedding i only, instead of the all pairs version.

Hope this helps, please reopen if this is not clear.
",two code equivalent code module distance every corresponding pair note work different size long version distance equal number flat necessarily going true importantly distance element instead version hope please reopen clear,issue,positive,positive,neutral,neutral,positive,positive
580311411,"Hi @lucky096 there is no automated way to convert Sonnet 1 -> Sonnet 2 and the library is not backwards compatible.

The main change between the Sonnet 1 and 2 is how variables and submodules are created and used. Sonnet 2 doesn't have any magical reuse of modules or variables, instead users are expected to use normal Python code to manage this (e.g. save parameters as `self.w = tf.Variable(...)`).

We provide `@snt.once` to make a method run once and only once, this can make data dependent initialization (very common in most neural nets) more convenient.

```python
# TensorFlow 2 / Sonnet 2
class AddNModule(snt.Module):

  @snt.once
  def _initialize(self, x):
    # Make sure to initialize variables and submodules once and only once.
    self.n = tf.Variable(tf.ones(x.shape))
    self.s = SomeSubModule()

  def __call__(self, x):
    self._initialize(x)
    return self.s(self.n + x)

# TensorFlow 1 / Sonnet 1
class AddNModule(snt.AbstractModule):
  def __call__(self, x):
    n = tf.get_variable(""n"", x.shape, initializer=tf.ones)
    return SomeSubModule()(n + x)
```

I have ported a lot of code between Sonnet 1 -> Sonnet 2 and for most modules moving initialization into a method annotated with `@snt.once` is all you need to change (aside from changing to `snt.Module` name and dealing with things that have been renamed in TensorFlow).",hi lucky way convert sonnet sonnet library backwards compatible main change sonnet used sonnet magical reuse instead use normal python code manage save provide make method run make data dependent common neural convenient python sonnet class self make sure initialize self return sonnet class self return ported lot code sonnet sonnet moving method need change aside name dealing,issue,positive,positive,positive,positive,positive,positive
579852998,@loopylangur could you upgrade `tree` and let us know if this helps?,could upgrade tree let u know,issue,negative,neutral,neutral,neutral,neutral,neutral
579761699,"Hey @tomhennigan, I need to upgrade to sonnet2/tf2, can you confirm is there any way to upgrade the code written in sonnet1 to sonnet2? For instance, the `snt.AbstractModule` from sonnet1 is now just `snt.Module`. I checked and they are not same. It seems  backward compatibility is not there. So did you mean that to maintain models designed in sonnet1, we should stick to sonnet1/tf1 and we can't upgrade them to sonnet2/tf2?",hey need upgrade confirm way upgrade code written sonnet sonnet instance sonnet checked backward compatibility mean maintain designed sonnet stick ca upgrade,issue,negative,negative,negative,negative,negative,negative
579430770,"Hi @loopylangur, the failure you're seeing is a result of switching Sonnet 2 to [deepmind/tree](https://github.com/deepmind/tree) which did not (until recently, see deepmind/tree@66ace75ebec22c1bacb4a57446b0b5a4db254104) work well with `wrapt.ObjectProxy` objects used by `tf.AutoTrackable`. 

I will do a bugfix release of `tree` in the coming days which should fix the issue.",hi failure seeing result switching sonnet recently see work well used release tree coming day fix issue,issue,negative,negative,negative,negative,negative,negative
557469683,"Unfortunately the same is true of the kernals that Sonnet uses that it would be awkward to support WNC as it is in PyTorch. Supporting it would involve transposing the input before running it through the kernal and transposing it again afterwards. I don't think we want to do this by default as it can be costly so it may be worth thinking about how often/where you want to perform the transpose.

If you want something like this in your code you could wrap snt.Conv1D like this:
```
class WNCConv1D(snt.Module):
  def __init__(self, *args, **kwargs):
    self._conv = snt.Conv1D(*args, **kwargs)

  def __call__(self, inputs):
    inputs = tf.transpose(inputs, [1, 0, 2])
    outputs = self._conv(inputs)
    return tf.transpose(outputs, [1, 0, 2])
```
    ",unfortunately true sonnet would awkward support supporting would involve input running afterwards think want default costly may worth thinking want perform transpose want something like code could wrap like class self self return,issue,positive,positive,neutral,neutral,positive,positive
554792906,"Hey @huiwenzhang, I would suggest upgrading to Sonnet 2.0 (and TensorFlow 2.0) to get an experience more like PyTorch:

```
$ pip install tensorflow-gpu tensorflow-probability
$ pip install ""dm-sonnet>=2.0.0b0"" --pre
```

Please take a look at one of our examples to see how to use Sonnet with TensorFlow 2.0: https://colab.research.google.com/github/deepmind/sonnet/blob/v2/examples/mlp_on_mnist.ipynb

In general TensorFlow and Sonnet pass `tf.Tensor` instances around. You can convert the result of the function into a numpy array using `x.numpy()`. For example the following program will print logit values from `net`:

```python
import tensorflow as tf
import sonnet as snt

net = snt.nets.MLP([1000, 100, 10])
logits = net(tf.ones([8, 28 * 28]))
print(logits.numpy())
```",hey would suggest sonnet get experience like pip install pip install please take look one see use sonnet general sonnet pas around convert result function array example following program print net python import import sonnet net net print,issue,positive,positive,neutral,neutral,positive,positive
552701336,"I found the reason:

Other ones perhaps worth adding in:
    typing.Collection -- added in 3.6
    typing.Deque -- added in 3.6.1
    typing.ContextManager -- **added in 3.6**
    typing.Counter -- added in 3.6.1
    typing.ChainMap -- added in 3.6.1
    typing.AsyncGenerator -- added in 3.5.4
    typing.ClassVar -- added in 3.5.3
",found reason perhaps worth added added added added added added added,issue,negative,positive,positive,positive,positive,positive
538731379,"Hey @ArnaudC, if the code you're using wants `snt.AbstractModule` then it's likely that it's been designed for Sonnet 1 + TensorFlow 1 (in Sonnet 2 we just have `snt.Module`, [docs here](https://sonnet.readthedocs.io/en/latest/modules.html)).

I'll see if we can give a better error message in this case, but for now you'll want to use the 1.X series of both TensorFlow and Sonnet.

Also (to save you some time) the current stable version of `tensorflow-probability` does not support the latest TF1 release so we should use the older version for now:

```shell
$ pip install ""tensorflow-gpu<2"" ""dm-sonnet<2"" ""tensorflow-probability==0.7.0""
```

If you're developing new code then I would suggest using TensorFlow 2 and Sonnet 2 but if you have existing code that you don't want to rewrite then downgrading to TF1/Sonnet 1 should do the trick.",hey code likely designed sonnet sonnet see give better error message case want use series sonnet also save time current stable version support latest release use older version shell pip install new code would suggest sonnet code want rewrite trick,issue,positive,positive,positive,positive,positive,positive
538727485,"Uninstalling and reinstalling is not working for me. (tf-gpu)

```
pip3 uninstall ""dm-sonnet>=2.0.0b0""
pip3 uninstall ""tensorflow-probability>=0.8.0rc0""
```
Then

```
pip3 install --upgrade tensorflow-gpu
pip3 install ""tensorflow-probability>=0.8.0rc0"" --pre
pip3 install ""dm-sonnet>=2.0.0b0"" --pre
```
My tf and Sonnet version :
```
print(""TensorFlow version {}"".format(tf.__version__))
print(""Sonnet version {}"".format(snt.__version__))
```

TensorFlow version **2.0.0**
Sonnet version **2.0.0b0**
Python **3.6.8**
library **cudart64_100.dll**

<module 'sonnet' from 'F:\\Python\\Python 3.6.8\\lib\\site-packages\\sonnet\\__init__.py'>
module 'sonnet' has no attribute '**AbstractModule**'
  File ""C:\Users\a\ImageGeneration\VAEv2.py"", line 100, in <module>
    class Encoder(snt.AbstractModule):


",working pip pip pip install upgrade pip install pip install sonnet version print version print sonnet version version sonnet version python library module module attribute file line module class,issue,negative,neutral,neutral,neutral,neutral,neutral
535592818,"I'm assuming that you want to create a recurrent module, which can be used in `tf.nn.dynamic_rnn`(for TF v1) etc, and which consists of an LSTM and MLP in sequence? This can be done but not with Sequential, that is strictly for chains of feed forward modules. Try:

```python
my_module = snt.DeepRNN([snt.LSTM(...), snt.MLP(...)])
```

`DeepRNN` looks at all the modules provided, works out which ones are recurrent (eg you could have two LSTMs with an MLP between them, meaning that the recurrent state size of the overall module is `((first_lstm_h, first_lstm_c), (second_lstm_h, second_lstm_c))`.

You can see examples of this for TF v1 here: https://github.com/deepmind/sonnet/blob/master/sonnet/examples/rnn_shakespeare.py - obviously lots needs to change for TF/Sonnet v2, but the core way in which you compose modules together is the same.",assuming want create recurrent module used sequence done sequential strictly feed forward try python provided work recurrent could two meaning recurrent state size overall module see obviously lot need change core way compose together,issue,negative,neutral,neutral,neutral,neutral,neutral
533485797,"Hey @ignacio-rocco, thanks for the tip, I wasn't aware of `%tensorflow_version`. It's quite a bit faster than pip installing, I'll update our colab examples to use it.",hey thanks tip aware quite bit faster pip update use,issue,negative,positive,positive,positive,positive,positive
533457799,"@tomhennigan I've stepped against this problem again in Google Colab.
Please see this notebook. https://colab.research.google.com/drive/1cDM3U3yF4oNnZoPIyRG2Oc5CHbN7JMog
However, if you invert the order of the first two cells the issue is solved.",stepped problem please see notebook however invert order first two issue,issue,negative,positive,positive,positive,positive,positive
532020713,"> When I uninstalled and reinstalled , it works now . But I can't reproduce this problem. It is so strange....

Uninstalling + reinstalling seems to be a solution that worked for me = =.",uninstalled work ca reproduce problem strange solution worked,issue,negative,negative,neutral,neutral,negative,negative
531771952,FYI Sonnet 2 is now available in beta on PyPi with support for TensorFlow 2. You can find more info in the read me :smile:.,sonnet available beta support find read smile,issue,positive,positive,positive,positive,positive,positive
531482841,"Hi Tom,
Get it. Thank you so much! Have a nice weekend.
Alan Kaifu Lu

On Sat, Sep 14, 2019 at 3:21 AM Tom Hennigan <notifications@github.com>
wrote:

> Hi @kaifuluca2016 <https://github.com/kaifuluca2016>, Sonnet 2 (unlike
> Sonnet 1) is a pure Python library so there is only one version of the
> library to install for all situations (regardless of operating system or
> GPU/non-GPU).
>
> TensorFlow itself has also recently changed
> <https://groups.google.com/a/tensorflow.org/d/msg/discuss/O_YIjW5vWp0/41u69M1oDgAJ>
> such that the GPU version will work even if you don't have a GPU.
>
> As such the instructions in the README are actually accurate for any OS or
> GPU/non-GPU 😄, they just assume that you can install packages via pip.
> If you are unsure about how to use pip on your system please consult this
> TensorFlow documentation <https://www.tensorflow.org/install/pip>. Once
> you have installed TensorFlow you should find installing Sonnet very simple.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/deepmind/sonnet/issues/146?email_source=notifications&email_token=AFKNDSTWK323WKE6FASMIZDQJSGI3A5CNFSM4IWVL5UKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD6WWJEA#issuecomment-531457168>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AFKNDSUDW254YWKN3VYJN5DQJSGI3ANCNFSM4IWVL5UA>
> .
>
",hi get thank much nice weekend alan sat wrote hi sonnet unlike sonnet pure python library one version library install regardless operating system also recently version work even actually accurate o assume install via pip unsure use pip system please consult documentation find sonnet simple reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
531457168,"Hi @kaifuluca2016, Sonnet 2 (unlike Sonnet 1) is a pure Python library so there is only one version of the library to install for all situations (regardless of operating system or GPU/non-GPU).

TensorFlow itself has also [recently changed](https://groups.google.com/a/tensorflow.org/d/msg/discuss/O_YIjW5vWp0/41u69M1oDgAJ) such that the GPU version will work even if you don't have a GPU.

As such the instructions in the README are actually accurate for any OS or GPU/non-GPU 😄, they just assume that you can install packages via `pip`. If you are unsure about how to use `pip` on your system please consult [this TensorFlow documentation](https://www.tensorflow.org/install/pip). Once you have installed TensorFlow you should find installing Sonnet very simple.",hi sonnet unlike sonnet pure python library one version library install regardless operating system also recently version work even actually accurate o assume install via pip unsure use pip system please consult documentation find sonnet simple,issue,negative,positive,positive,positive,positive,positive
529981915,That fixed the issue! thanks for the quick reply @tomhennigan ,fixed issue thanks quick reply,issue,negative,positive,positive,positive,positive,positive
529957728,"Hey @ignacio-rocco this looks like a TensorFlow issue with the `gast>0.3.0`. You can work around it for now by downgrading that dependency:

```shell
$ pip install gast==0.2.2
```

I'll follow up with the autograph team in TensorFlow to see how they recommend fixing. Thanks for the heads up!",hey like issue gast work around dependency shell pip install follow autograph team see recommend fixing thanks,issue,positive,positive,positive,positive,positive,positive
528854677,"Hi @bionicles, thanks for the interest. DNC in v2 is very much on my todo list, can't give a guaranteed timeframe but hopefully soon. I'll ping this issue when there is something to look at.",hi thanks interest much list ca give hopefully soon ping issue something look,issue,positive,positive,positive,positive,positive,positive
528679587,"No, it was not mentioned in the papers (both the multiple codebooks and the 256-way softmax). I agree with you that it is quite odd indeed",multiple agree quite odd indeed,issue,negative,negative,neutral,neutral,negative,negative
528678848,"Thank you so much for letting me know about your great work!
I have some last questions.

> I implemented the multiple codebooks here.

The multiple codebooks seems reasonable and effective, but was it mentioned in the papers?

> As for the 256 way softmax, you can simply output 3* 256 channels instead of 3 in your last conv layer, reshape appropriately and use softmax loss.

I see, so the authors did not use MSE for the model reported in their paper?",thank much know great work last multiple multiple reasonable effective way simply output instead last layer reshape appropriately use loss see use model paper,issue,positive,positive,positive,positive,positive,positive
528437369,"I implemented the multiple codebooks [here](https://github.com/pclucas14/vq-vae/blob/master/vqvae.py#L202). As for the 256 way softmax, you can simply output 3* 256 channels instead of 3 in your last conv layer, reshape appropriately and use softmax loss. 

For what it's worth, I found that using a [discretized logistic loss](https://github.com/pclucas14/vq-vae/blob/master/utils.py#L74)  works as well and is more parameter efficient. ",multiple way simply output instead last layer reshape appropriately use loss worth found logistic loss work well parameter efficient,issue,negative,positive,positive,positive,positive,positive
528242357,"Hi,

>  (use a 256-way softmax, and multiple codebooks per latents)

Could you explain more about this?

How should we apply the 256-way softmax to this model?
The decoder in ""vqvae_example.ipynb"" returns one value for each pixel instead of 256 values.

and how can we get  multiple codebooks per latents?",hi use multiple per could explain apply model one value instead get multiple per,issue,negative,neutral,neutral,neutral,neutral,neutral
518961524,"Just stumbled back on this thread, @malcolmreynolds added `snt.nets.VectorQuantizer` and `snt.nets.VectorQuantizerEMA` to Sonnet 2 in deepmind/sonnet@67f036929d6be76ef142767a5d088ea60211b8fa.

If it's still relevant for you then you can install Sonnet 2 using the instructions at https://github.com/deepmind/sonnet/tree/v2 and give it a try 😄.",back thread added sonnet still relevant install sonnet give try,issue,negative,positive,positive,positive,positive,positive
515283222,"@tomhennigan @lorenrose1013 thanks for your guidance. I've fixed the lint errors. 

As I've got time to go through more sonnet examples, I might make more AMP patches available, e.g. rmc_learn_to_execute next. 

I'd like to break this down into a series of bite-sized chunks so that it's easier to implement, test and  digest.",thanks guidance fixed lint got time go sonnet might make available next like break series easier implement test digest,issue,positive,positive,positive,positive,positive,positive
514986128,BTW if there are more AMP patches to come it might be worth discussing details over email (we are currently working on AMP with Sonnet 2 and TensorFlow 2). My work email is my github username `@google.com` if you want to discuss that.,come might worth currently working sonnet work want discus,issue,negative,positive,positive,positive,positive,positive
514985247,"@vinhngx would you running `pylint` over your code. In particular I think it will complain since lines are not within 80chr and you're mixing `""` and `'` in the same file (c.f. https://google.github.io/styleguide/pyguide.html).

@lorenrose1013 mind taking a look at this patch too?",would running code particular think complain since within file mind taking look patch,issue,negative,positive,positive,positive,positive,positive
514845899,"Thanks for your response! I was able to figure out how to get more updated versions of everything and it seems like the library is working fine now.

For 2), I had installed via `pip install dm-sonnet` but I suspect that something went wrong in the course of me uninstalling and reinstalling various versions of tensorflow and tensorflow-probability while debugging earlier - I reinstalled everything on a clean environment and it worked fine.",thanks response able figure get everything like library working fine via pip install suspect something went wrong course various everything clean environment worked fine,issue,positive,positive,positive,positive,positive,positive
514757951,"Re 1), we only ensure the library runs with the latest public stable version of TF (and TFP). If you want to use an old version like TF 1.8.0 your best bet is probably going back through sonnet versions to find one that we pushed around that time. All the version dates are in CHANGES.md, and there should be a corresponding git tag, so this shouldn't be a problem. If you _really_ want the latest Sonnet (bear in mind going to our old versions may reintroduce bugs we have now fixed, change interfaces such that code you write then doesn't work on latest version, etc) and you are hard-limited by needing to use an old TF, then you will still probably be able to use some subset of the library, although you might need to comment out various things in Sonnet to get it to import.

I would strongly recommend not doing this if you're doing real work that matters, as there are just too many things at play to predict how well it will work. We have extensive automated testing which exercises current Sonnet and current TF, but you would effectively be using a completely untested configuration, and anything could happen. If you really can't modify your environment to install up to date TF, then an old Sonnet version is better.

You're right that the dependency information is somewhat out of date, and there are different numbers in different places. I believe that we currently require TF >= 1.13 - I'll fix the places that say otherwise.

2) How did you do the install here? `pip install dm-sonnet`, or did you just clone the github repo?

3) Indeed, we should change the error message to not mention `tensorflow-probability-gpu`. Thanks for the report, will be fixed in our next version.",ensure library latest public stable version want use old version like best bet probably going back sonnet find one around time version corresponding git tag problem want latest sonnet bear mind going old may reintroduce fixed change code write work latest version needing use old still probably able use subset library although might need comment various sonnet get import would strongly recommend real work many play predict well work extensive testing current sonnet current would effectively completely untested configuration anything could happen really ca modify environment install date old sonnet version better right dependency information somewhat date different different believe currently require fix say install pip install clone indeed change error message mention thanks report fixed next version,issue,positive,positive,positive,positive,positive,positive
511908414,"Hi @ricvo,

This is pretty much what I would expect to happen. Sonnet wraps tf.make_template, and anything called inside the template which creates variables has to do so with `tf.get_variable`. If the thing you're wrapping doesn't do that, as appears to be the case here, then the template breaks. This is not something that's really feasible or desirable to fix at this stage for TF 1.

As you figured out, initialising some Keras layer inside the constructor in a `self._enter_variable_scope()` will stop this problem at least, but there could be other subtle behaviours - for example, I'm not sure if custom getters as they are used in Sonnet will work inside the Keras part of your model. I would consider any mixing of Sonnet & Keras in TF v1 to be unsupported, anything might go wrong.

The good news is that in TF 2, Keras and Sonnet share a base class, so certainly basic functionality (eg, querying a top level module for all the variables it contains) will correctly work with arbitrary nestings of the two libraries. I still wouldn't necessarily _recommend_ it, you're always going to have a better experience sticking to one library or the other, but it will work a lot better than it does now. If you're interested, Sonnet for TF2 is in alpha here: https://github.com/deepmind/sonnet/tree/v2

Closing, but please reopen if you have further questions.",hi pretty much would expect happen sonnet anything inside template thing wrapping case template something really feasible desirable fix stage figured layer inside constructor stop problem least could subtle example sure custom used sonnet work inside part model would consider sonnet unsupported anything might go wrong good news sonnet share base class certainly basic functionality querying top level module correctly work arbitrary two still would necessarily always going better experience sticking one library work lot better interested sonnet alpha please reopen,issue,positive,positive,neutral,neutral,positive,positive
508794841,"Just an update, we decided to postpone the update until version 3.9 is released. Meanwhile you should set `--incompatible_disable_deprecated_attr_params=false` if you are building with bazel.
I will leave this issue open for now.",update decided postpone update version meanwhile set building leave issue open,issue,negative,neutral,neutral,neutral,neutral,neutral
508547041,"Thanks for pointing it out!
This will be fixed in the next release.",thanks pointing fixed next release,issue,negative,positive,positive,positive,positive,positive
506066814,"My fix there is for protobuf lite. As far as I can see sonnet uses normal protobuf which already has the fix since this commit https://github.com/protocolbuffers/protobuf/commit/d5f0dac497f833d06f92d246431f4f2f42509e04

Available in master or v3.9.0-rc1. 
Good luck!",fix lite far see sonnet normal already fix since commit available master good luck,issue,positive,positive,positive,positive,positive,positive
503053217,"@edoardogiacomello yes, if you write as TF 2.0 with eager execution, you can just write things in the order you want them to happen, no control dependencies will be required.

As for the discrete values - the discreteness in VQ-VAE is not that things get mapped to integer valued codes, but rather that there is a finite/discrete set of codes in your codebook. So you're right that EMA or gradients will provide small adjustments to the values, but that is all working as intended.

As for batching, the TF / Sonnet 1.0 version supports batched data so I think you can do close to a line-by-line translation, I don't think any big changes are necessary. Alternatively, we will be adding a  Sonnet 2.0 version of VQ VAE in the next few months.",yes write eager execution write order want happen control discrete discreteness get integer valued rather set right provide small working intended sonnet version data think close translation think big necessary alternatively sonnet version next,issue,positive,positive,neutral,neutral,positive,positive
502988575,"I'm trying to implement the VQ EMA block in tensorflow 2.0, since I come from a GAN background and I'd like to learn more about this approach.
It seems quite straightforward, since if I'm not mistaken there will be no need to enforce control dependencies anymore. 
Still, I'm missing some points, like how the encoding could be updated while still being discrete (won't any update, made either with Ema or a gradient, change the value such that they become non-integer values?) or how to deal with batches of data. ",trying implement block since come gan background like learn approach quite straightforward since mistaken need enforce control still missing like could still discrete wo update made either gradient change value become deal data,issue,negative,positive,neutral,neutral,positive,positive
502685462,"When I uninstalled and reinstalled , it works now . But  I can't reproduce this problem.  It is so strange....",uninstalled work ca reproduce problem strange,issue,negative,negative,neutral,neutral,negative,negative
502684411,"```python 
print(snt.__file__)

AttributeError                            Traceback (most recent call last)
<ipython-input-5-86bcd137c072> in <module>
----> 1 print(snt.__file__)

AttributeError: module 'sonnet' has no attribute '__file__'

```
",python print recent call last module print module attribute,issue,negative,neutral,neutral,neutral,neutral,neutral
502628946,I can't reproduce this in a clean colab. Perhaps you have a file in your current directory called `sonnet.py` and you're importing that instead of the library? Can you try printing the output of `print(snt.__file__)`?,ca reproduce clean perhaps file current directory instead library try printing output print,issue,negative,positive,positive,positive,positive,positive
502516572,"@tomhennigan
hello, my python version is 3.6.4, I followed your instructions and the results are as follows：
  
```python 
import sonnet as snt
print(dir(snt))
['__doc__', '__loader__', '__name__', '__package__', '__path__', '__spec__']

print(snt.__version__)
AttributeError                            Traceback (most recent call last)
<ipython-input-10-980fa547e124> in <module>
      1 import sonnet as snt
      2 print(dir(snt))
----> 3 print(snt.__version__)

AttributeError: module 'sonnet' has no attribute '__version__'

```
In order to find the version number of sonnet, I type the following on the command line.

```bash 
pip list 
...
dm-sonnet                          1.33
...
```
so  what should I do ?",hello python version python import sonnet print print recent call last fae module import sonnet print print module attribute order find version number sonnet type following command line bash pip list,issue,negative,neutral,neutral,neutral,neutral,neutral
502013747,"@szq261299 would you mind printing the output of this in your Python interpreter:

```python
import sonnet as snt
print(dir(snt))
print(snt.__version__)
```",would mind printing output python interpreter python import sonnet print print,issue,negative,neutral,neutral,neutral,neutral,neutral
501960383,"when i try to install the graph-nets , i meet the same problem.......",try install meet problem,issue,negative,neutral,neutral,neutral,neutral,neutral
501348870,"Authors answered question via email : (use a 256-way softmax, and multiple codebooks per latents)",question via use multiple per,issue,negative,neutral,neutral,neutral,neutral,neutral
499048549,"solved the problem...
no need to make an extra tmp/sonnet as it is alread present in bazel-bin/sonnet/tmp/sonnet.
the whl file will be created over the above path..
and then pip installing it will download dm-sonnet as well as tensorflow-probability as per the required version on its own.",problem need make extra present file path pip well per version,issue,negative,neutral,neutral,neutral,neutral,neutral
498913193,"Also, is MSE loss actually used for CIFAR-10 ? (instead of e.g. LL under a logistic, or a 256-way softmax)",also loss actually used instead logistic,issue,negative,neutral,neutral,neutral,neutral,neutral
490889312,"thanks,it is from kenetics-I3D repository.I figure it out .it is due to tensorflow's version is too low.thanks",thanks figure due version,issue,negative,positive,neutral,neutral,positive,positive
490136433,"@poweryin where is this `evaluate_sample.py` from? Is it from the Kinetics repository?

Also, could you paste the output of running the following in your interpreter:

```
import sonnet as snt
print(dir(snt))
print(snt.__version__)
```",kinetics repository also could paste output running following interpreter import sonnet print print,issue,negative,neutral,neutral,neutral,neutral,neutral
488680127,"It is because the shape of the output can be anywhere within a range instead of being an exact value. Within the tensorflow layers they have chosen to use the minimum default shape wheras in Sonnet we have chosen the maximal.

Within Sonnet you can change the output shape (to any valid shape falling within the range) by using the  `output_shape` kwargs. To get the equivalent in your case use
```snt.Conv2DTranspose(output_channels=256, kernel_shape=4, stride=[1, 2], padding=""VALID"", output_shape=[7, 10])(inputs)```",shape output anywhere within range instead exact value within chosen use minimum default shape sonnet chosen maximal within sonnet change output shape valid shape falling within range get equivalent case use valid,issue,negative,positive,positive,positive,positive,positive
485875483,"Hi @ferreirafabio 

 I'm not exactly sure what you are asking - do you think that the argument orders of `snt.Conv2DTranspose` and `tf.layers.conv2d_transpose` should necessarily be the same / in the same order? This is not something we try and do at all, and we can't make the order of arguments the same as the underlying tf.nn.conv2d_transpose op because the first two arguments of that function are the tensor to operate on and the tensor containing the filters. We have chosen different names for some arguments, generally for consistency within the Sonnet library.

You can get your desired result if you are explicit with your kwargs, ie:

```
inputs = tf.placeholder(name='foo', shape=[None, 1, 1, 218],dtype=tf.float32)
snt.Conv2DTranspose(output_channels=64, kernel_shape=1, stride=5, padding='VALID')(inputs)
```

This yields shape (?, 5, 5, 64) output shape.

Please let me know if I'm misunderstanding?",hi exactly sure think argument necessarily order something try ca make order underlying first two function tensor operate tensor chosen different generally consistency within sonnet library get desired result explicit ie none shape output shape please let know misunderstanding,issue,negative,positive,positive,positive,positive,positive
485870961,"@UCC-team what versions of Sonnet & TF are you working with? I remember seeing that error a while back and it was to do with non-matching versions of TF and TFP. Right now in a fresh virtualenv, I can run `pip install tensorflow tensorflow-probability dm-sonnet` and I get a working setup.

As noted above, `dm-sonnet-gpu` is no longer updated as all the GPU specific code was upstreamed into TF. I just pushed a final dummy package to pypi, so that if a user installs dm-sonnet-gpu they get an error on importing which says to use dm-sonnet instead.",sonnet working remember seeing error back right fresh run pip install get working setup noted longer specific code final dummy package user get error use instead,issue,negative,positive,positive,positive,positive,positive
483199469,Thanks a lot for the always amazing answers!,thanks lot always amazing,issue,positive,positive,positive,positive,positive,positive
483197891,"For clarification - the first example is just demonstrating that different variables can be regularized differently. Obviously it's up to users to determine what combination of regularizers works for their situation.

For the second example, once you acquire the regularizers for the whole graph you should be able to filter based on the string names - something like:

```
graph_regularizers = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)
graph_a_reg = [reg for reg in graph_regularizers if reg.name.startswith('module_a/')
graph_b_reg = [reg for reg in graph_regularizers if reg.name.startswith('module_b/')
```",clarification first example different differently obviously determine combination work situation second example acquire whole graph able filter based string something like reg reg reg reg,issue,negative,positive,positive,positive,positive,positive
482798800,"Via experiments, seems the problems mentioned above are not that important, so just close the thread.",via important close thread,issue,negative,positive,positive,positive,positive,positive
482005861,"how should i do it?
>>> import sonnet

the error is as follow:
WARNING:tensorflow:From /root/miniconda3/lib/python3.7/site-packages/tensorflow_probability/python/distributions/deterministic.py:386: RegisterKL.__init__ (from tensorflow.python.ops.distributions.kullback_leibler) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
Traceback (most recent call last):
  File ""/root/miniconda3/lib/python3.7/site-packages/sonnet/__init__.py"", line 47, in _ensure_dependency_available_at_version
    pkg = importlib.import_module(package_name)
  File ""/root/miniconda3/lib/python3.7/importlib/__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 1006, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 983, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 967, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 677, in _load_unlocked
  File ""<frozen importlib._bootstrap_external>"", line 728, in exec_module
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
  File ""/root/miniconda3/lib/python3.7/site-packages/tensorflow_probability/__init__.py"", line 21, in <module>
    from tensorflow_probability.python import *  # pylint: disable=wildcard-import
  File ""/root/miniconda3/lib/python3.7/site-packages/tensorflow_probability/python/__init__.py"", line 22, in <module>
    from tensorflow_probability.python import distributions
  File ""/root/miniconda3/lib/python3.7/site-packages/tensorflow_probability/python/distributions/__init__.py"", line 77, in <module>
    from tensorflow_probability.python.distributions.vector_diffeomixture import quadrature_scheme_softmaxnormal_gauss_hermite
  File ""/root/miniconda3/lib/python3.7/site-packages/tensorflow_probability/python/distributions/vector_diffeomixture.py"", line 28, in <module>
    from tensorflow.contrib.linalg.python.ops import linear_operator_addition as linop_add_lib
ModuleNotFoundError: No module named 'tensorflow.contrib.linalg'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/root/miniconda3/lib/python3.7/site-packages/sonnet/__init__.py"", line 64, in <module>
    _ensure_dependency_available_at_version('tensorflow_probability', '0.4.0')
  File ""/root/miniconda3/lib/python3.7/site-packages/sonnet/__init__.py"", line 54, in _ensure_dependency_available_at_version
    package_name, min_version, pip_name, pip_name))
SystemError: Sonnet requires tensorflow_probability (minimum version 0.4.0) to be installed. If using pip, run `pip install tensorflow-probability` or `pip install tensorflow-probability-gpu`
",import sonnet error follow warning removed library probability update use instead recent call last file line file line return name level package level file frozen line file frozen line file frozen line file frozen line file frozen line file frozen line file line module import file line module import file line module import file line module import module handling exception another exception recent call last file line module file line module file line sonnet minimum version pip run pip install pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
476758722,"I believe this is fixed in b18ca77dd which should be part of `dm-sonnet-gpu==1.29` but unfortunately that wasn't pushed along with `dm-sonnet` (unsure why, will ask around).

As a workaround, I'd suggest the following:

```shell
$ pip uninstall dm-sonnet-gpu
$ pip install ""dm-sonnet>=1.29"" tensorflow-gpu tensorflow-probability-gpu
```

Since Sonnet no longer has any C++ code `dm-sonnet` and `dm-sonnet-gpu` are actually identical apart from requirements on GPU variants of TF and TFP. I think going forward we plan to deprecate `dm-sonnet-gpu` and suggest users pip install the GPU variants of TF if they want.",believe fixed part unfortunately along unsure ask around suggest following shell pip pip install since sonnet longer code actually identical apart think going forward plan deprecate suggest pip install want,issue,negative,negative,neutral,neutral,negative,negative
476651206,"hi,i have got the same problem ,did U know how to do ? @JCMiles @malcolmreynolds ",hi got problem know,issue,negative,neutral,neutral,neutral,neutral,neutral
473571130,"Regarding the problem of installing dm-sonnet-gpu. I'm seeing a problem with this as well, but I believe the issue is a misspecified package. Here is the output of the `pip install dm-sonnet-gpu` command:
```
Collecting tensor-probability-gpu>=0.4.0 (from dm-sonnet-gpu)
  Could not find a version that satisfies the requirement tensor-probability-gpu>=0.4.0 (from dm-sonnet-gpu) (from versions: )
No matching distribution found for tensor-probability-gpu>=0.4.0 (from dm-sonnet-gpu)
```

Notice that it's looking for `tensor-probability-gpu` but the correct package is `tensorflow-probability-gpu`.",regarding problem seeing problem well believe issue package output pip install command could find version requirement matching distribution found notice looking correct package,issue,negative,neutral,neutral,neutral,neutral,neutral
471962775,"Hey @flowpoint, we're planning to make a major release of Sonnet to support TensorFlow 2 (c.f. deepmind/sonnet#117). The current plan is to make this public by the end of the month. We spoke a bit about this at the TF Dev Summit (https://www.youtube.com/watch?v=rlpQjnUvoKw).

Python 3.7 support I believe was blocked on TensorFlow supporting 3.7 which came out in TF 1.13 (https://github.com/tensorflow/tensorflow/releases/tag/v1.13.1), afaik there are no blockers from Sonnet, please let us know if that is not the case.",hey make major release sonnet support current plan make public end month spoke bit dev summit python support believe blocked supporting came sonnet please let u know case,issue,positive,positive,neutral,neutral,positive,positive
471522063,@malcolmreynolds That was really enlightening for me. I got my answer and also got more (About control dependency usages)! Thank you very much!,really enlightening got answer also got control dependency thank much,issue,positive,positive,positive,positive,positive,positive
471505651,"@h-shad this comment is referring to two fairly subtle issues.

The first is that in this module weights are updated online, rather than during the backwards pass as would be more normal with an RNN setup. Due to the way ""legacy"" TF 1.0 variables work, if the code was written without this control dependency then the accesses to self._w could be aliased together, so that even for timestep `t` we would use the weights from timestep `0`. In this module, we want for the  the forwards pass for timestep `t+1` to use the weights updated with EMA from timestep `t`, and this control dependency accomplishes that, assuming that the inputs to this module have some ordering dependency.

The latter part of the comment is referring to an additional complication - imagine we have a `VectorQuantizerEMA` used somewhere in the middle of an RL agent. At each timestep, we must execute all the ops, produce an action to give to the environment, which produces the observation as the input for the next timestep. In this case we are fine with the code as written - having a control dependency on `inputs` implies transitively that the whole previous timestep has been executed. Note that switching to resource variables would help here, but we are unable to do this for all of Sonnet due to needing to support legacy codebases.

On the other hand, imagine applying the `VectorQuantizerEMA` to every timestep of some fully known input sequence - eg, in a language model. Then this control dependency on `inputs` does not produce the result we want - TensorFlow could schedule the execution of the ops in any order, for example it could execute the weight updates in the order of `T-1`, `T-2`, ... `0`. This is most likely not what we want, but from inside the code you're pointing to, there's no way to fix it, as we can't see any of the other Tensors we would want to produce a dependency on. If you wanted to do this and have the updates happen in causal order, you would need to use control dependencies at the outer level, as the code says.

If this seems difficult to get your head around - problems like this don't happen in TF 2.0. A version of Sonnet using TF 2.0 / Eager first is under way and will be open sourced when ready.
",comment two fairly subtle first module rather backwards pas would normal setup due way legacy work code written without control dependency could together even would use module want forward pas use control dependency assuming module dependency latter part comment additional complication imagine used somewhere middle agent must execute produce action give environment observation input next case fine code written control dependency transitively whole previous executed note switching resource would help unable sonnet due needing support legacy hand imagine every fully known input sequence language model control dependency produce result want could schedule execution order example could execute weight order likely want inside code pointing way fix ca see would want produce dependency happen causal order would need use control outer level code difficult get head around like happen version sonnet eager first way open ready,issue,positive,negative,neutral,neutral,negative,negative
471199843,This code should work. Can you narrow it down to a minimal reproducible example?,code work narrow minimal reproducible example,issue,negative,negative,negative,negative,negative,negative
470310541,"Unfortunately, this issue was never reopened although there's an open question. Could this be reopened please?",unfortunately issue never although open question could please,issue,negative,negative,negative,negative,negative,negative
465127496,"i tested it the same day, with a simple example
thanks for explanation and for the advice ",tested day simple example thanks explanation advice,issue,negative,positive,neutral,neutral,positive,positive
463150022,"@diegolascasas @malcolmreynolds 
after downgrading numpy 1.16 to numpy 1.15.4 I was able to remove those deprecation warnings

but I'm still getting this one:

/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead
  return _inspect.getargspec(target)
/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)

could you please check it?
",able remove deprecation still getting one use instead return target size may indicate binary incompatibility got return could please check,issue,negative,positive,positive,positive,positive,positive
462782541,"@malcolmreynolds warnings are coming from tf-probability when I build the model.
can you please tell me wich is the current numpy version on gcloud?
I think the update to numpy 1.16 was made when I installed tf-probability 0.5.0
I'm currently investigating about that.",coming build model please tell current version think update made currently investigating,issue,negative,neutral,neutral,neutral,neutral,neutral
462747394,"@JCMiles glad to hear things are working. About the deprecation warnings, as far as I can see we are not calling np.asscalar anywhere in Sonnet, so I believe those warnings are coming from something else (maybe TF). If there are other specific deprecated functions please post which ones, and I can see if we are causing any of them. Note that fixing these might not be possible in the short term, as Sonnet primarily needs to support the version of Numpy used in google's internal repository, which is not yet at 1.16.",glad hear working deprecation far see calling anywhere sonnet believe coming something else maybe specific please post see causing note fixing might possible short term sonnet primarily need support version used internal repository yet,issue,positive,positive,positive,positive,positive,positive
462524853,"Hi @diegolascasas , thx for the replay and the clarification about current version.

I can confirm that with the following configuration:
- Linux Debian
- CUDA 10.0
- tensorflow-gpu 1.12
- tesnsorflow-probability 0.5.0
- dm-sonnet 1.29 (non-GPU)

Everything's fine !
The only annoying thing still the deprecation warnings  (a lots of them)  I posted  previously
if you have numpy 1.16.1 
",hi replay clarification current version confirm following configuration everything fine annoying thing still deprecation lot posted previously,issue,negative,negative,negative,negative,negative,negative
462489882,"Sorry for the delay getting back to you @londoed! I don't think a chat room is on the cards for the moment, but we do plan to create great docs for Sonnet 2 and please feel free to file bugs on here, we do actively look into everything that is reported!",sorry delay getting back think chat room moment plan create great sonnet please feel free file actively look everything,issue,positive,positive,positive,positive,positive,positive
462439834,"Hi @JCMiles, thanks for flagging this.

Can you test your setup with `dm-sonnet` (non-GPU)?

The reason we created the two versions was due to some custom ops that we developed and needed separate builds. We ended up merging them to Tensorflow contrib after a while, so `dm-sonnet` and `dm-sonnet-gpu` are currently identical, except for the dependencies. `dm-sonnet` works with both `tensorflow` and `tensorflow-gpu`, so it should be what you're looking for. 

Please tell us if this works for you. 
Meanwhile we'll address the dependency issue to make sure `dm-sonnet-gpu` works for all users.",hi thanks flagging test setup reason two due custom separate ended currently identical except work looking please tell u work meanwhile address dependency issue make sure work,issue,positive,positive,positive,positive,positive,positive
461396884,"This is normal - for each trainable variable, Adam creates two auxiliary variables, for first and second order moments:
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/adam.py#L131 - and similarly needs two additional scalars for the decay rates: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/adam.py#L124

You can see the same thing happening with the following toy example, to demonstrate that this is not something introduced by Sonnet/Slim mixing, or Estimator, or anything else.

```python
import sonnet as snt
import tensorflow as tf

input = tf.random_uniform([16, 784])
logits = snt.Linear(10)(input)
loss = tf.reduce_mean(logits)  # dummy loss function, still demonstrates the point
adam = tf.train.AdamOptimizer(learning_rate=1e-3)
train_op = adam.minimize(loss)

print(tf.get_collection(tf.GraphKeys.VARIABLES))
```

I get this output:

```
[<tf.Variable 'linear/w:0' shape=(784, 10) dtype=float32_ref>,
 <tf.Variable 'linear/b:0' shape=(10,) dtype=float32_ref>,
 <tf.Variable 'beta1_power:0' shape=() dtype=float32_ref>,
 <tf.Variable 'beta2_power:0' shape=() dtype=float32_ref>,
 <tf.Variable 'linear/w/Adam:0' shape=(784, 10) dtype=float32_ref>,
 <tf.Variable 'linear/w/Adam_1:0' shape=(784, 10) dtype=float32_ref>,
 <tf.Variable 'linear/b/Adam:0' shape=(10,) dtype=float32_ref>,
 <tf.Variable 'linear/b/Adam_1:0' shape=(10,) dtype=float32_ref>]
```

It's worth pointing out though that you should be somewhat careful when mixing different high level libraries - in particular, assumptions about how variables are shared could differ, so you are right to be checking whether the list of created variables looks correct. In this case though, I think you are fine.

Please reopen if you have any further questions!
",normal trainable variable two auxiliary first second order similarly need two additional decay see thing happening following toy example demonstrate something estimator anything else python import sonnet import input input loss dummy loss function still point loss print get output worth pointing though somewhat careful different high level particular could differ right whether list correct case though think fine please reopen,issue,negative,positive,positive,positive,positive,positive
460267567,Sounds awesome! Is there any way that a Gitter chat room or something similar could be opened for Sonnet? I think it would help users to have a resource like that when making the switch over to Sonnet 2 and also alert the developers to incompatibilities or general bugs.,awesome way chat room something similar could sonnet think would help resource like making switch sonnet also alert general,issue,positive,positive,positive,positive,positive,positive
459555131,"Dear @tomhennigan , no worries.

Thanks a lot for your alternative but more concise solution.

I will close the thread.",dear thanks lot alternative concise solution close thread,issue,positive,positive,positive,positive,positive,positive
459390176,"Hi @mingyr, apologies for the delay getting back to you. Your code looks familiar to a bunch of code I've seen internally.

A slightly more concise way of achieving this copy operation can be seen below, the output of the program should be a dictionary where both values are the same:

```python
import sonnet as snt
import tensorflow as tf

model_a = snt.nets.MLP([1, 2, 3], activation=tf.nn.sigmoid)
model_b = snt.nets.MLP([1, 2, 3], activation=tf.nn.sigmoid)

# Connect modules to the graph to ensure variables are created.
x = tf.placeholder(tf.float32, [None, 1])
out_a = model_a(x)
out_b = model_b(x)

# Copy parameter values from b to a.
copy_weights = tf.group(*[va.assign(vb) for va, vb in zip(model_a.variables, model_b.variables)])

sess = tf.Session()
sess.run(tf.global_variables_initializer())
sess.run(copy_weights)
print(sess.run({'a': out_a, 'b': out_b}, feed_dict={x: [[1.]]}))
```",hi delay getting back code familiar bunch code seen internally slightly concise way copy operation seen output program dictionary python import sonnet import connect graph ensure none copy parameter zip sess print,issue,negative,positive,positive,positive,positive,positive
459384220,"Hi @KatharinaLin, `use_dropout` was added to nets.MLP in Sonnet 1.26. To make sure you're on the latest Sonnet please use `pip install --upgrade dm-sonnet`.",hi added sonnet make sure latest sonnet please use pip install upgrade,issue,positive,positive,positive,positive,positive,positive
459331108,"Absolutely! We've been discussing with many researchers and engineers at DeepMind and Google Brain how to approach this.

The internals of Sonnet are not compatible with TF2 as they stand, for example Sonnet makes use of graph collections, `tf.get_variable`, `tf.make_template` and `tf.variable_scope` which are all going away in TF2.

We've taken the opportunity to design a TF2 first base class for Sonnet, and we've [proposed up-streaming this into core TensorFlow as `tf.Module`](https://github.com/tensorflow/community/pull/56). Please take a look and comment on the RFC!

We're currently working on rebuilding Sonnet against `tf.Module`, making sure more advanced workflows like using custom getters (e.g. [bayes by backprop](https://github.com/deepmind/sonnet/blob/087cb9d97e374f4bf2b36662dc89f38545ea5fba/sonnet/python/custom_getters/bayes_by_backprop.py)) are still possible. We're also making sure Sonnet will work with [TensorFlow distribution strategy](https://github.com/tensorflow/community/pull/25).

These changes will require a new major release of Sonnet (aka. Sonnet 2). It will feel very familiar for anyone who has used Sonnet before and we hope with `tf.Module` the internals will be even simpler and modules can be closer to the math. We're being mindful to make sure the migration is not expensive for users (e.g. as much as possible using the builtin modules will be the same as V1).

For a preview of how this might look please have a look at [the examples on the RFC](https://github.com/tensorflow/community/blob/976bc376830869726ab7b55cde40886b57e55483/rfcs/20190117-tf-module.md#examples).

We'll be up-streaming our progress on Sonnet 2 over the next month or two :smile: ",absolutely many brain approach internals sonnet compatible stand example sonnet use graph going away taken opportunity design first base class sonnet core please take look comment currently working sonnet making sure advanced like custom still possible also making sure sonnet work distribution strategy require new major release sonnet aka sonnet feel familiar anyone used sonnet hope internals even simpler closer math mindful make sure migration expensive much possible preview might look please look progress sonnet next month two smile,issue,positive,positive,positive,positive,positive,positive
451218880,Thanks for the spot - this will be fixed in the next public version.,thanks spot fixed next public version,issue,negative,positive,neutral,neutral,positive,positive
451152322,"Tensorflow Probability is required for the Bayes by Backprop custom getter, this is the case regardless of whether or not the GPU versions of TF are used. When you do `pip install tensorflow-probability-gpu`, the library will still be importable in python under the name `tensorflow_probability` (as is the case with TF itself).

Note that if you are wanting to run only GPU versions, then there is currently a bug in the Sonnet install script: https://github.com/deepmind/sonnet/pull/109 - this will be fixed the next time we push a public version. In the meantime, because there is no actual CUDA code in Sonnet any more, you should be able to do the following in a fresh virtualenv to get everything setup:

```shell
pip install tensorflow-gpu tensorflow-probability-gpu
pip install dm-sonnet
```

Please reopen this ticket if you have any problems.",probability custom getter case regardless whether used pip install library still importable python name case note wanting run currently bug sonnet install script fixed next time push public version actual code sonnet able following fresh get everything setup shell pip install pip install please reopen ticket,issue,positive,positive,positive,positive,positive,positive
446076848,"By the way, the following code snippet is the way currently I am using, however, I notice each basic module comes up with a clone method, so I just wonder is there a more elegant way.

```
import tensorflow as tf
import sonnet as snt

class ConvNet(snt.AbstractModule):
    def __init__(self, num_actions, name = 'conv_net'):
        super(ConvNet, self).__init__(name = name)

        with self._enter_variable_scope():
            self._conv1 = snt.Conv2D(32, 8, 4)
            self._conv2 = snt.Conv2D(64, 4, 2)
            self._conv3 = snt.Conv2D(64, 3, 1)

            self._lin1 = snt.Linear(512)
            self._lin2 = snt.Linear(num_actions)

    def _build(self, inputs):
        outputs = snt.Sequential([self._conv1, tf.nn.relu,
                                  self._conv2, tf.nn.relu,
                                  self._conv3, tf.nn.relu,
                                  snt.BatchFlatten(),
                                  self._lin1, tf.nn.relu,
                                  self._lin2])(inputs)

        return outputs


class Synchronizer():
    def __init__(self, module_original, module_target):
        self._original = '%s_original_network_variables' % module_original.module_name
        self._target = '%s_target_network_variables' % module_target.module_name

        for var in module_original.get_variables():
            self._add_variable(var, self._original)

        for var in module_target.get_variables():
            self._add_variable(var, self._target)

    def _add_variable(self, var, collection_name):
        if var not in tf.get_collection(collection_name):
            tf.add_to_collection(collection_name, var)

    def __call__(self):

        o_params = tf.get_collection(self._original)
        t_params = tf.get_collection(self._target)

        sychronize_ops = [tf.assign(t, o) for t, o in zip(t_params, o_params)]

        return sychronize_ops


def test_convnet():
    convnet = ConvNet(4)

    inputs = tf.constant(1.0, tf.float32, [32, 84, 84, 4])

    outputs = convnet(inputs)

    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())

        v = sess.run(outputs)
        print(v)

def test_synchronize():
    convnet = ConvNet(4)
    convnet2 = ConvNet(4)

    inputs = tf.constant(1.0, tf.float32, [8, 84, 84, 4])

    outputs = convnet(inputs)
    outputs2 = convnet2(inputs)

    sess = tf.Session()
    sess.run(tf.global_variables_initializer())

    print(""before synchronization"")
    v, v2 = sess.run([outputs, outputs2])

    print(""v:"")
    print(v)
    print(""v2:"")
    print(v2)

    synchronizer = Synchronizer(convnet, convnet2)

    sychronize_ops = synchronizer()

    print(""after synchronization"")

    sess.run(sychronize_ops)
    v, v2 = sess.run([outputs, outputs2])

    print(""v:"")
    print(v)
    print(""v2:"")
    print(v2)


if __name__ == '__main__':
    # test_convnet()
    test_synchronize()

        
``` ",way following code snippet way currently however notice basic module come clone method wonder elegant way import import sonnet class self name super self name name self return class synchronizer self self self zip return sess print sess print synchronization print print print print synchronizer synchronizer synchronizer print synchronization print print print print,issue,positive,positive,positive,positive,positive,positive
445506349,"Solution:
replace 
`pip install sonnet`
with 
`pip install dm-sonnet`",solution replace pip install sonnet pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
443829564,Aha! My data was not being shuffled upon restore and the model would begin to overfit to highly correlated batches (more MLP layers allowed it to overfit more) - I should have realized. Thank you for your help. ,aha data upon restore model would begin overfit highly correlated overfit thank help,issue,positive,positive,positive,positive,positive,positive
443780625,"Thanks for catching this - your fix will be in the next public version.
",thanks catching fix next public version,issue,negative,positive,positive,positive,positive,positive
443774855,"@slerman12 The example I tested was just a toy example, it wasn't hooked up to any real data, I was just seeing whether the Adam variables were restored or not.

If it works with a single layer MLP but not with multiple layers that is very strange - what is vocab_size set to? I'm wondering if 256 << vocab_size, whether somehow the bottleneck creates instability in general. You could try making multiple Linears explicitly (with ReLUs between them) - that should be exactly equivalent to the MLP, but without knowing what is wrong in your setup it might give a useful datapoint.

I have a few other ideas but I should clarify they are all guesses.

* Is there something in the data input which could be getting restored incorrectly, e.g. do you have a curriculum over difficulty of samples which could be being reset to some initial difficulty, thus ruining training?
* Similarly, are you doing RL and learning from a replay buffer which goes back to being empty on restoration?
* Does this drop in performance ever occur without a  restore/save taking place? In my experience, async optimization can produce sudden drops in performance like this?
* Are you using any custom getters?

If you can provide a full self contained example I might be able to offer further advice. However, we definitely haven't seen anything like this internally, and there are lots of people using something analogous to your setup (Sonnet layers, Adam/ other optimizers with auxiliary variables, tf.Saver) and we haven't had any reports of anything like this. Using the Google compute infrastructure requires checkpointing, as individual machines may be taken out of service during training, so this would have become an obvious issue by now.",example tested toy example hooked real data seeing whether work single layer multiple strange set wondering whether somehow bottleneck instability general could try making multiple explicitly exactly equivalent without knowing wrong setup might give useful clarify something data input could getting incorrectly curriculum difficulty could reset initial difficulty thus training similarly learning replay buffer go back empty restoration drop performance ever occur without taking place experience optimization produce sudden performance like custom provide full self example might able offer advice however definitely seen anything like internally lot people something analogous setup sonnet auxiliary anything like compute infrastructure individual may taken service training would become obvious issue,issue,positive,positive,neutral,neutral,positive,positive
443723105,"Changing:

`logits = snt.nets.mlp.MLP([256, 256, 256, 256, vocab_size])(x)`

to

`logits = snt.nets.mlp.MLP([vocab_size])(x)`

fixed the problem for me. I don't know if it's just a coincidence or if the stacked MLP layers somehow interfere with regular saving.",fixed problem know coincidence somehow interfere regular saving,issue,negative,positive,neutral,neutral,positive,positive
443663072,"Glad to know that, in that case I will close this thread. ",glad know case close thread,issue,negative,positive,positive,positive,positive,positive
443661686,"Gorgeous solution! Many thanks!
I will close the thread.
",gorgeous solution many thanks close thread,issue,positive,positive,positive,positive,positive,positive
443577657,"Hmm, but getting rid of the Sonnet `MLP` layers fixed it. I'm still using a Sonnet `Linear` layer, and different Sonnet methods like `LayerNorm`, `BatchApply,` and `BatchReshape`. Other than that, I'm using TensorFlow embeddings and LSTMs. It doesn't seem to drop without the `MLP` layers, or at least, if it does, then it's by a small amount rather than all the way back to near-0.

With the example you tried, did you check if the accuracy of the restored model would drop after 90 or so training iterations? Did you test it with `MLP` layers? My accuracy would be .7 to .8 before restoring and then stay in that range for about 90 training iterations after restoring, and then drop to 0.01 all of a sudden. Without the `MLP` layers, it stays in that range. Some of my `MLP` layers are also inside a `BatchApply`. I'm not sure why these would cause an issue since I imagine they're just `Linear` layers stacked on one another.

Edit: I'm actually still using an `MLP` layer elsewhere I just noticed. Some of the ones I commented out were in a Sonnet Module, some in a `BatchApply`, and others outside of the module and just standalone.",getting rid sonnet fixed still sonnet linear layer different sonnet like seem drop without least small amount rather way back example tried check accuracy model would drop training test accuracy would stay range training drop sudden without stay range also inside sure would cause issue since imagine linear one another edit actually still layer elsewhere sonnet module outside module,issue,negative,positive,neutral,neutral,positive,positive
443567033,"Yes, the saver is also after the train op. Looks like all of the variables are restored. I'm not sure why the training resumes properly but then suddenly goes down as if starting from scratch. Then it comes up again once it trains again.

My restoration code is:

```
with tf.Session() as sess:
    sess.run(init)

    directory_name = ""directory""
    path = os.getcwd()
    log_directory = path + ""/"" + directory_name + ""/""

    if not os.path.exists(log_directory + ""Saved/""):
        os.makedirs(log_directory + ""Saved/"")
    if tf.train.checkpoint_exists(log_directory + ""Saved/model""):
        saver.restore(sess, log_directory + ""Saved/model"")
```

Then I do normal batch training. Once every number of batches, I save with` saver.save(sess, log_directory + ""Saved/model"")`.

Seems the problem is not related to Sonnet, but I'm not sure what else it could be.

",yes saver also train like sure training properly suddenly go starting scratch come restoration code sess directory path path sess normal batch training every number save sess problem related sonnet sure else could,issue,positive,positive,positive,positive,positive,positive
443563993,"Is the declaration of the tf.Saver after the call to optimizer.minimize(loss)? That's the point when the auxiliary variables get created, I would think.

If you print out `saver._var_list` after it's been created, you can see whether the Adam variables are in the checkpoint or not. For what it's worth I just did a quick test with a sonnet module hooked to a toy loss, then made an AdamOptimizer and called minimize, then made a Saver. All the auxiliary Adam variables were definitely in `saver._var_list`, and were saving / restoring correctly for me.",declaration call loss point auxiliary get would think print see whether worth quick test sonnet module hooked toy loss made minimize made saver auxiliary definitely saving correctly,issue,negative,positive,positive,positive,positive,positive
443562585,"I'm not sure if I did this correctly, but the following code...

```
old = [x.eval() for x in optimizer.variables()]

saver.restore(sess, log_directory + ""Saved/model"")

new = [x.eval() for x in optimizer.variables()]

for i, x in enumerate(old):
        if (x == new[i]).any():
            print(optimizer.variables()[i])
```

yielded:

```
<tf.Variable 'Variable/Adam:0' shape=(179, 20) dtype=float32_ref>
<tf.Variable 'Variable/Adam_1:0' shape=(179, 20) dtype=float32_ref>
<tf.Variable 'mlp/linear_0/b/Adam:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'mlp/linear_0/b/Adam_1:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'mlp/linear_0/w/Adam:0' shape=(64, 256) dtype=float32_ref>
<tf.Variable 'mlp/linear_0/w/Adam_1:0' shape=(64, 256) dtype=float32_ref>
<tf.Variable 'mlp/linear_1/w/Adam:0' shape=(256, 256) dtype=float32_ref>
<tf.Variable 'mlp/linear_1/w/Adam_1:0' shape=(256, 256) dtype=float32_ref>
<tf.Variable 'mlp/linear_2/b/Adam:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'mlp/linear_2/b/Adam_1:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'mlp/linear_2/w/Adam:0' shape=(256, 256) dtype=float32_ref>
<tf.Variable 'mlp/linear_2/w/Adam_1:0' shape=(256, 256) dtype=float32_ref>
<tf.Variable 'mlp/linear_3/b/Adam:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'mlp/linear_3/b/Adam_1:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'mlp/linear_3/w/Adam:0' shape=(256, 256) dtype=float32_ref>
<tf.Variable 'mlp/linear_3/w/Adam_1:0' shape=(256, 256) dtype=float32_ref>
<tf.Variable 'mlp/linear_4/w/Adam:0' shape=(256, 179) dtype=float32_ref>
<tf.Variable 'mlp/linear_4/w/Adam_1:0' shape=(256, 179) dtype=float32_ref>
```

My `saver = tf.train.Saver()` line is after `optimizer = tf.train.AdamOptimizer()` and the construction of my Sonnet modules. ",sure correctly following code old sess new enumerate old new print saver line construction sonnet,issue,negative,positive,positive,positive,positive,positive
443561811,"Hi @mingyr 

You should be able to do this with a custom getter. Something like this:

```python
def spectral_norm_getter(getter, name, *args, **kwargs):
  var = getter(name, *args, **kwargs)
  spectral_normed_var = spectral_norm(var)
  return spectral_normed_var

conv2d = snt.Conv2D(..., custom_getter={'w': spectral_norm_getter})
```

This assumes you have the definition of `spectral_norm` available, and it will only apply it to the weight variable (not the bias).",hi able custom getter something like python getter name getter name return definition available apply weight variable bias,issue,negative,positive,positive,positive,positive,positive
443560034,"Can you verify that the Adam moving average variables are actually in the checkpoint? If you create a saver for the Sonnet module before you've instantiated the optimizer, this will only make save / restore nodes for the weights, not the associated optimization variables. You can check if they are getting restored by printing out some values of both the weights and optimization variables before and after the `saver.restore()` call.",verify moving average actually create saver sonnet module make save restore associated optimization check getting printing optimization call,issue,positive,negative,neutral,neutral,negative,negative
443556513,"
Thanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

:memo: **Please visit <https://cla.developers.google.com/> to sign.**

Once you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.

----

#### What to do if you already signed the CLA

##### Individual signers

*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).

##### Corporate signers

*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).
*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).
*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).
		

<!-- need_sender_cla -->",thanks pull request like may first contribution open source project look help look pull request need sign contributor license agreement memo please visit sign fixed please reply verify already individual possible different address commit check data verify set git corporate company point contact authorized participate ask added group authorized know point contact direct project maintainer public version used register authorized contributor must used git commit check data verify set git used register authorized contributor must also attached account,issue,positive,positive,neutral,neutral,positive,positive
443553258,"Combining Sonnet with models defined in other systems such as Keras  or Slim will produce some issues as related to variable sharing. You may be able to get it to work by constructing the ResNet50 inside the constructor, inside a `with _enter_variable_scope():` block, but even then I think you would need to be careful that your top level module (ie ResNet50 Encoder) is not constructed multiple times.

To clarify, this is unlikely to work:

```python
class MyModule(snt.AbstractModule):
  # ...
  def _build(self, inputs):
    encoder = ResNet50Encoder()
    return encoder(inputs)
```

This _might_, assuming MyModule is the top level of your module stack:

```python
class MyModule(snt.AbstractModule):
  def __init__(self, name='my_module'):
    super(MyModule, self).__init__(name=name)
    with self._enter_variable_scope():
      self._encoder = Resnet50Encoder()
  
  def _build(self, inputs):
    return self._encoder(inputs)
```

It's hard to give definitive answers without looking hrough how the Keras model (and everything it depends on) is implemented.. but in general, mixing libraries is tricky. If you have a pretrained model in a specific library, you will probably get on best working entirely within that library. Sonnet is built on top of `tf.make_template`, which supports transparent reuse for anything that calls `tf.get_variable`. Our `_build` methods are wrapped by a `make_template`, under the hood. Anything calling `tf.Variable` directly breaks this assumption, and will lead to the kind of errors you are seeing.

If you have a pretrained checkpoint for a sonnet module, you can load that with a `tf.Saver` as normal. If you have a checkpoint for a module which you now want to connect as part of a larger graph, you can make a saver which refers to just a subpart of the graph using `snt.get_saver`, or in general passing a dict to `tf.Saver` to perform rewrites mapping between graph names and checkpoint names (you're probably going to want to remove some prefix from the graph names to make them line up with the checkpoint names).


",combining sonnet defined slim produce related variable may able get work inside constructor inside block even think would need careful top level module ie multiple time clarify unlikely work python class self return assuming top level module stack python class self super self self return hard give definitive without looking model everything general tricky model specific library probably get best working entirely within library sonnet built top transparent reuse anything wrapped hood anything calling directly assumption lead kind seeing sonnet module load normal module want connect part graph make saver subpart graph general passing perform graph probably going want remove prefix graph make line,issue,positive,positive,positive,positive,positive,positive
441973473,"Thank you clearing things up! I'm still facing some problems with the kind of syntax you introduced, which is why I'm reopening. 

Particularly, I want to pass binary flag `is_training` through `sess.run()`. I tried using the lambda notation you introduced by passing lambda arguments (x,y) for the “inputs” and the “is_training"" flag like so: `node_model_fn=lambda x,y: ConvNet1D(name='CnnNodes’)(x,y)`

However, this yields the error `TypeError: _build() takes 2 positional arguments but 3 were given.`

The code I'm using is the following:


```
class CNNEncoderGraphIndependent(snt.AbstractModule):

    def __init__(self, name=""CNNEncoderGraphIndependent""):
        super(CNNEncoderGraphIndependent, self).__init__(name=name)

        with self._enter_variable_scope():
            self._network = modules.GraphIndependent(
              edge_model_fn=EncodeProcessDecode.make_mlp_model_edges,
              node_model_fn=lambda: ConvNet1D(name='CnnNodes'),
              global_model_fn=lambda: ConvNet1D(name='CnnGlobals')
            )

    def _build(self, inputs, is_training):
        return self._network(inputs)


class CNNDecoderGraphIndependent(snt.AbstractModule):
    ...#omitted due to brevity but equal interfaces as used in CNNEncoderGraphIndependent 

class EncodeProcessDecode(snt.AbstractModule, BaseModel):
    def __init__(self, config, name=""EncodeProcessDecode""):
        super(EncodeProcessDecode, self).__init__(name=name)

        self._encoder = CNNEncoderGraphIndependent()
        self._decoder = CNNDecoderGraphIndependent()
        self.is_training = tf.placeholder(tf.bool, shape=(), name='is_training')


    def _build(self, input_op, num_processing_steps, is_training):
        latent = self._encoder(input_op, is_training) 
        ...
        for _ in range(num_processing_steps):
            ...
            decoded_op = self._decoder(latent, is_training)
            ...
        return output_ops
```

I want to feed True/False flags in a sess.run() into the placeholder ‘self.model.is_training’ like so:

```
self.model = EncodeProcessDecode()
self.model.output_ops_train = self.model(self.model.input_ph, self.config.n_rollouts, self.model.is_training)

```

but this yields the said error. What am I missing?

",thank clearing still facing kind syntax particularly want pas binary flag tried lambda notation passing lambda flag like however error positional code following class self super self self return class due brevity equal used class self super self self latent range latent return want feed like said error missing,issue,positive,positive,positive,positive,positive,positive
441739522,"Sure - let's have an example where both encode() and decode() use some common variables C, as well as each having their own variables. You can't access the C variables with tf.get_variable from both the `snt.reuse_variables` decorated methods - but you can have a third (maybe private) method which access the C variables, and connects them as appropriate.

Let's say you want an autoencoder where some of the weights in encode and decode are tied, specifically the transpose of each other. I'll give examples with hardcoded sizes and no bias for brevity. This won't work because you're accessing c in both methods:

```python
class ModuleA(snt.AbstractModule):
  def __init__(self, name='module_a'):
    super(ModuleA, self).__init__(name=name)

  @snt.reuse_variables
  def encode(self, inputs):
    w_enc_1 = tf.get_variable('w_enc_1', shape=[32, 16])
    c = tf.get_variable('c', shape=[16, 8])

    h = tf.nn.relu(tf.matmul(inputs, w_enc_1))
    return tf.matmul(h, c)

  @snt.reuse_variables
  def decode(self, inputs):
    c = tf.get_variable('c', shape=[16, 8])
    w_dec_1 = tf.get_variable('w_dec_1', shape=[16, 32])

    h = tf.nn.relu(tf.matmul(inputs, tf.transpose(c)))
    return tf.matmul(h, w_dec_1)


  def _build(self, inputs):
    return self.decode(self.encode(inputs))
```

If you factor out the accessing of `c` to a separate method, also decorated, you get this, which will work:

```python
class ModuleB(snt.AbstractModule):
  def __init__(self, name='module_b'):
    super(ModuleB, self).__init__(name=name)

  @snt.reuse_variables
  def _get_common_variable(self):
    return tf.get_variable('c', shape=[16, 8])

  @snt.reuse_variables
  def encode(self, inputs):
    w_enc_1 = tf.get_variable('w_enc_1', shape=[32, 16])
    c = self._get_common_variable()

    h = tf.nn.relu(tf.matmul(inputs, w_enc_1))
    return tf.matmul(h, c)

  @snt.reuse_variables
  def decode(self, inputs):
    c = self._get_common_variable()
    w_dec_1 = tf.get_variable('w_dec_1', shape=[16, 32])

    h = tf.nn.relu(tf.matmul(inputs, tf.transpose(c)))
    return tf.matmul(h, w_dec_1)


  def _build(self, inputs):
    return self.decode(self.encode(inputs))
```

This might seem like a tedious hoop to force users to jump through - but the alternative (allow sharing of c from each method) would mean that the users are responsible for making sure there are no name clashes across all of their reuse_variables decorated methods. If they make a mistake they get unintentional sharing, which could lead to extremely hard to catch bugs.

",sure let example encode decode use common well ca access decorated third maybe private method access appropriate let say want encode decode tied specifically transpose give size bias brevity wo work python class self super self encode self return decode self return self return factor separate method also decorated get work python class self super self self return encode self return decode self return self return might seem like tedious hoop force jump alternative allow method would mean responsible making sure name across decorated make mistake get unintentional could lead extremely hard catch,issue,positive,positive,neutral,neutral,positive,positive
441714790,"In the VAE example, it would only be necessary to use the variables of each method in isolation. What if I want to use variables from encode() in decode(), or vice versa? Is there a recommended approach for this besides using the constructor? If I do use the constructor, would I still need to decorate my methods in order to use the constructor variables?",example would necessary use method isolation want use encode decode vice approach besides constructor use constructor would still need decorate order use constructor,issue,negative,neutral,neutral,neutral,neutral,neutral
441704212,"@slerman12 it's correct that you can get the same effects with _enter_variable_scope, however to create actual variables at that point (rather than submodules) it's often not convenient as you won't know the input dimensionality you are dealing with. You can obviously add 'input_size' to the constructor kwargs for a module, but Sonnet generally avoids this in favour of shape inference (as with most of TF).

The original use case for `@reuse_variables` was for VAEs, where it's natural to have multiple externally accessible entry points - ie `encode()` and `decode()` rather than just `_build()`. The idea is that encode and decode have their own disjoint sets of variables (you can obviously come up with exceptions to this, but that's usually the case) and so they are each in charge of building those particular variables. They are built whenever a decorated method is called (which implies that you have some specific input to work with, and can build variables the right size).

The purpose of `_enter_variable_scope` is different - it's for people who prefer declaring their submodules up front, rather than in _build - mostly a stylistic preference.

",correct get effect however create actual point rather often convenient wo know input dimensionality dealing obviously add constructor module sonnet generally shape inference original use case natural multiple externally accessible entry ie encode decode rather idea encode decode disjoint obviously come usually case charge building particular built whenever decorated method specific input work build right size purpose different people prefer front rather mostly stylistic preference,issue,positive,positive,positive,positive,positive,positive
440432971,"According to the docstring of GraphNetwork, the callables passed must return a sonnet module or equivalent (this just means something that has a `__call__` method to which you pass input tensors). In this case, the delayed execution is there so that the `edge_model_fn`, `nodel_model_fn` etc all end up with a scope that is internal to the GraphNetwork. The simplest way to do this, with the Module I posted above, would be:

```python
self._network = modules.GraphNetwork(
    lambda: TransposeCNNModel(name='edge'),
    lambda: TransposeCNNModel(name='node'), 
    # ... etc
```

Obviously replace the TransposeCNNModel with whatever Sonnet module you want.

I hope this clears things up - please reopen if you still have questions.
",according must return sonnet module equivalent something method pas input case execution end scope internal way module posted would python lambda lambda obviously replace whatever sonnet module want hope please reopen still,issue,positive,neutral,neutral,neutral,neutral,neutral
440431565,"Thanks for your suggestion, we will endeavour to support this at some point.",thanks suggestion support point,issue,positive,positive,positive,positive,positive,positive
440429883,"Thank you for your answer. I was particularly interested in adapting the following `deepmind/graph_nets` use case from the examples:

```
self._network = modules.GraphNetwork(Model.make_mlp_model,
                                               Model.make_mlp_model,
                                               Model.make_mlp_model) 
```

where `make_mlp_model` are callback functions. I don't know think that the OO (i.e. passing object instances instead of function references) solution you suggest will work in this case since the API docs of `modules.GraphNetwork` states the following:

> A callable that returns an edge model function. The callable must return a Sonnet module (or equivalent). If passed `None`, will pass through inputs (the default).",thank answer particularly interested following use case know think passing object instead function solution suggest work case since following callable edge model function callable must return sonnet module equivalent none pas default,issue,positive,positive,neutral,neutral,positive,positive
440254219,"If you have a module that you want to compose out of other modules, and some of the submodules require extra arguments like `is_training`, the canonical thing to do would be to define a new subclass of `AbstractModule`, rather than writing a function as you have. In particular, defining a module allows you to explicitly reuse variables by just calling the module twice (potentially with different `is_training` kwarg values).

Your example would be something like this:

```python
class TransposeCnnModel(snt.AbstractModule):
  def __init__(self, name='transpose_cnn_model'):
    super(TransposeCnnModel, self).__init__(name=name)

  def _build(self, inputs, is_training):
    inputs = tf.expand_dims(inputs, axis=2)

    outputs = snt.Conv1DTranspose(output_channels=2, kernel_shape=10, stride=1)(inputs)
    outputs = snt.BatchNorm()(outputs, is_training=is_training)
    outputs = tf.nn.relu(outputs)
    outputs = snt.Conv1DTranspose(output_channels=2, kernel_shape=10, stride=1)(outputs)
    outputs = snt.BatchNorm()(outputs, is_training=is_training)
    outputs = tf.nn.relu(outputs)
    outputs = snt.BatchFlatten()(outputs)
    keep_prob = 0.7 if is_training else 1.0
    outputs = tf.nn.dropout(outputs, keep_prob=keep_prob)
    outputs = snt.Linear(output_size=128)(outputs)

    return outputs    
```

You would probably want to make more things configurable as constructor args (e.g. final output size, channels in the conv, dropout probability for training etc) but the above should fit the API that the GraphNet library expects.

As to your second point, I'm not sure exactly what you mean by Sonnet callback functions - could you be more specific?",module want compose require extra like canonical thing would define new subclass rather writing function particular module explicitly reuse calling module twice potentially different example would something like python class self super self self else return would probably want make constructor final output size dropout probability training fit library second point sure exactly mean sonnet could specific,issue,positive,positive,positive,positive,positive,positive
440184768,thanks @dm-jrae we had a journal club where we were going through the attention is all you need paper and since I had [implemented](https://github.com/kashif/pytorch-relational-rnn) the relational RNN in pytorch a few months back I remembered the scaling factor was not the one in the paper... and another [implementation](https://github.com/l0SG/relational-rnn-pytorch) in pytorch also mentioned it in its comments,thanks journal club going attention need paper since relational back scaling factor one paper another implementation also,issue,negative,positive,neutral,neutral,positive,positive
433710896,"I noticed that there are now overviews of the modules etc. linked at the bottom of the documentation page at the github.io site, (but not in the corresponding md file in docs here). I don't know if it was there when I posted this issue, but having it there is a start. The modules page is not exactly an easy-reader, though.",linked bottom documentation page site corresponding file know posted issue start page exactly though,issue,negative,positive,positive,positive,positive,positive
428780131,The suggestion is nice. I will close the thread.,suggestion nice close thread,issue,negative,positive,positive,positive,positive,positive
428779546,"Fully understanding, so I will close the thread.",fully understanding close thread,issue,negative,neutral,neutral,neutral,neutral,neutral
428258686,"Hi @mengdong,
Sonnet supports float16 inputs. 
What is your use case?",hi sonnet float use case,issue,negative,neutral,neutral,neutral,neutral,neutral
428256135,"Hi @EliasHasle, thanks for the feedback!

We are planning a revamp in the documentation, and will take your input into account.
We can come up with a couple of iPython notebooks that showcases some of Sonnet's functionalities.",hi thanks feedback revamp documentation take input account come couple sonnet,issue,negative,positive,positive,positive,positive,positive
428250608,"I'm sorry, I'm not sure I understand your question. 
How are you creating clip_split? What is its shape?",sorry sure understand question shape,issue,negative,neutral,neutral,neutral,neutral,neutral
428249064,"Hi,

There is not an exact analogy in Sonnet, but you can do exactly this with `batch_norm_creator = functools.partial(BatchNorm, decay_rate=0.9, ...)` and then `self._batch_norm_1 = batch_norm_creator()`  (`import functools`).",hi exact analogy sonnet exactly import,issue,negative,positive,positive,positive,positive,positive
428248259,"Hi,

Thanks for the question. In our experience, since the name of the variables are quite short (sometimes following paper notation), it has been easy to make typos and has bitten us in the past :) So we prefer erring on the strict side on this one. I apologize, as I understand this might not be the most convenient specification sometimes.",hi thanks question experience since name quite short sometimes following paper notation easy make bitten u past prefer erring strict side one apologize understand might convenient specification sometimes,issue,positive,positive,neutral,neutral,positive,positive
409530629,"Fixed as of e15eb742e50044b70e1e4bc008b7598d158786d7 - the old behaviour is still the default as we want to maintain checkpoint compatibility, but setting `legacy_bias_behaviour` to False will apply only one bias.",fixed old behaviour still default want maintain compatibility setting false apply one bias,issue,negative,negative,neutral,neutral,negative,negative
408774241,You first sample from the PixelCNN to get generated discrete codes. Then those are put in the decoder network of the VQ-VAE (a convnet with strides) to go from codes to images.,first sample get discrete put network go,issue,negative,positive,positive,positive,positive,positive
408764216,"> Once the PixelCNN is trained you take the generated codes and use the decoder network to get the image

Do you mean the decoder network of the trained PixelCNN  ?
",trained take use network get image mean network trained,issue,negative,negative,negative,negative,negative,negative
408709750,"@kosklain Thanks a lot for your response. I have putted a numpy array because when I put `relational_cell.initial_state(batch_size=1)` I cannot feed it into my dictionary. 

If I put `relational_cell.initial_state(batch_size=1)` as an initial state I get the next error: 

`TypeError: The value of a feed cannot be a tf.Tensor object. Acceptable feed values include Python scalars, strings, lists, numpy ndarrays, or TensorHandles.For reference, the tensor object was Tensor(""worker2/strided_slice:0"", shape=(1, 2048, 12), dtype=float32, device=/device:CPU:0) which was passed to the feed with key Tensor(""worker2/Placeholder_4:0"", shape=(1, 2048, 12), dtype=float32, device=/device:CPU:0).`


 Part of the code where I feed the initial state into tf:

        # Update the global network using gradients from loss
        # Generate network statistics to periodically save
        rnn_state = self.local_AC.state_init
        feed_dict = {self.local_AC.target_v: discounted_rewards,
                     self.local_AC.state: np.stack(states, axis=0),
                     self.local_AC.prev_rewards: np.vstack(prev_rewards),
                     self.local_AC.prev_actions: prev_actions,
                     self.local_AC.actions: actions,
                     self.local_AC.timestep: np.vstack(timesteps),
                     self.local_AC.advantages: advantages,
                     self.local_AC.state_in: rnn_state}
        v_l, p_l, e_l, g_n, v_n, _ = sess.run([self.local_AC.value_loss,
                                               self.local_AC.policy_loss,
                                               self.local_AC.entropy,
                                               self.local_AC.grad_norms,
                                               self.local_AC.var_norms,
                                               self.local_AC.apply_grads],
                                              feed_dict=feed_dict)


Is for that that I changed to an initial state as a numpy array.",thanks lot response array put feed dictionary put initial state get next error value feed object acceptable feed include python reference tensor object tensor feed key tensor part code feed initial state update global network loss generate network statistic periodically save initial state array,issue,positive,positive,neutral,neutral,positive,positive
408694122,"First the VQ-VAE is trained (as in this notebook). This allows you to compress images into discrete codes with the encoder, and reconstruct with the decoder. If you want to sample new images you can train a generative model (e.g., PixelCNN) on the discrete codes (instead of on the pixels). Once the PixelCNN is trained you take the generated codes and use the decoder network to get the image. This is what is meant with a **prior**, as in the VAE sense: a model on top of the latents. So in the paper the PixelCNN is **not** used as a decoder (but that's also possible).",first trained notebook compress discrete reconstruct want sample new train generative model discrete instead trained take use network get image meant prior sense model top paper used also possible,issue,negative,positive,positive,positive,positive,positive
408383556,"It looks like `BatchFlatten` is getting confused about the shapes to expect. Please use `relational_cell.initial_state(batch_size)` as an initial state, not a numpy array, as you're doing.",like getting confused expect please use initial state array,issue,negative,negative,negative,negative,negative,negative
399097655,"@mingyr 

I think there are a few different things going on here - firstly, I can't reproduce your result about the device placement changing the result, but there are a number of things that could influence this. I can however reproduce the issue of getting a different result when using placeholders vs using tf.constant. The following code, I believe, does both the accuracy computations at once and I'm consistently seeing accuracy_ph = 0.0, accuracy_const=0.88:

```
def test7():
  labels_np = np.array([1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0,
                        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]).astype(np.int32)
  logits_np = np.array([1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,
                        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]).astype(np.int32)

  labels_const = tf.constant(labels_np, tf.int32)
  logits_const = tf.constant(logits_np, tf.int32)
  labels_ph = tf.placeholder(dtype=tf.int32, shape=[None])
  logits_ph = tf.placeholder(dtype=tf.int32, shape=[None])

  accuracy_const, accuracy_update_const = tf.metrics.accuracy(
      labels_const, logits_const, name=""acc_const"")
  with tf.control_dependencies([accuracy_update_const]):
    accuracy_const = tf.identity(accuracy_const)

  accuracy_ph, accuracy_update_ph = tf.metrics.accuracy(
      labels_ph, logits_ph, name=""acc_ph"")
  with tf.control_dependencies([accuracy_update_ph]):
    accuracy_ph = tf.identity(accuracy_ph)

  with tf.Session() as session:
    session.run([tf.global_variables_initializer(),
                 tf.local_variables_initializer()])

    to_fetch = {
        ""accuracy_const"": accuracy_const,
        ""accuracy_ph"": accuracy_ph,
    }
    feed_dict = {
        labels_ph: labels_np,
        logits_ph: logits_np,
    }
    print(session.run(to_fetch, feed_dict))
```

Note that this doesnt use Sonnet, just raw TF  & tf.metrics, so I believe the problem is independent of Sonnet. I don't have time to dig further into this now but I suggest you open a ticket with the TF GitHub, referencing this one.

",think different going firstly ca reproduce result device placement result number could influence however reproduce issue getting different result following code believe accuracy consistently seeing test none none session print note doesnt use sonnet raw believe problem independent sonnet time dig suggest open ticket one,issue,negative,positive,neutral,neutral,positive,positive
399076500,"@mingyr `snt.get_variables_in_module` takes a `collection` kwarg, which has the same options as `tf.get_collection`. If you change your code to `snt.get_variables_in_module(metrics, tf.GraphKeys.LOCAL_VARIABLES)` you'll get the same result as from the direct `get_collection` call.",collection change code metric get result direct call,issue,negative,positive,neutral,neutral,positive,positive
394343807,"Dear @malcolmreynolds 

I think you explained everything crystal clear. Sincerely appreciate it. 

Yes, you are quite right. I am looking to concatenate on the channels dimension. I am considering some dense recurrent structure to see whether there is performance improvement of the model I constructed.

BTW, probably Sonnet can consider provide such an interface since I might not be the only one who would like to try such a dense recurrent structure.
",dear think everything crystal clear sincerely appreciate yes quite right looking concatenate dimension considering dense recurrent structure see whether performance improvement model probably sonnet consider provide interface since might one would like try dense recurrent structure,issue,positive,positive,positive,positive,positive,positive
394334354,"Hi @mingyr 

There are a few bugs in the error message here, apologies for the confusion. This will be fixed in the next version. The corrected error message should say:

```
ValueError: The outputs of the provided cores are not able to be concatenated along the first feature dimension. Core 0 has shape [32, 32, 4], whereas Core 1 has shape [32, 32, 8] - these must only differ in the first dimension
```

You've selected skip connections in DeepRNN so it's trying to concatenate the outputs from the two cores together to provide the final output. The sizes shown are the sizes without batch dimension, and the implementation concatenates on the first non-batch dimension. Therefore the rest of the shapes (in this case [32, 4] and [32, 8]) need to be the same, but they aren't.

If you disable skip connections this won't be a problem. If you definitely want skip connections, then presumably you are looking to concatenate on the channels dimension? You could either modify DeepRNN so that the concatenation dimension is customisable, or you could transpose your data into NCHW format, meaning you would have [4, 32, 32] and [8, 32, 32] which can be concatenated. Obviously this will require changes elsewhere too.

I hope this helps! Please let me know if the above isn't clear.

",hi error message confusion fixed next version corrected error message say provided able along first feature dimension core shape whereas core shape must differ first dimension selected skip trying concatenate two together provide final output size shown size without batch dimension implementation first dimension therefore rest case need disable skip wo problem definitely want skip presumably looking concatenate dimension could either modify concatenation dimension could transpose data format meaning would obviously require elsewhere hope please let know clear,issue,negative,positive,positive,positive,positive,positive
394321486,"Hi @buaa-luzhi 

The resampler function has been moved to TensorFlow as of Sonnet version 1.11. You should find the function available as `tf.contrib.resampler.resampler()`.",hi function sonnet version find function available,issue,negative,positive,positive,positive,positive,positive
394157451,"@japan4415 
Hello,
I have the same problem as you.  Solved?

Thank you so much !",japan hello problem thank much,issue,negative,positive,positive,positive,positive,positive
393919653,"Hi @arvind-cp,

We just released a new version that fixes the Python 3 compatibility problems.
It will soon be in PyPI as well.

I'll close this issue, but feel free to reopen it if you spot anything else.",hi new version python compatibility soon well close issue feel free reopen spot anything else,issue,positive,positive,positive,positive,positive,positive
393500067,"Hi Arvind,

Thank you for the contribution, but as mentioned in the issue you raised, `keep_dims` is deprecated in the version of Tensorflow we support (1.8). ",hi thank contribution issue raised version support,issue,positive,neutral,neutral,neutral,neutral,neutral
393483941,"Hi Arvind,

Thank you for your feedback!

`keep_dims` is deprecated in the latest version of Tensorflow. See answer to issue  #81.

Sonnet should be 100% python3 compatible, this `cPickle` import slipped through us.
We'll address the mistake and update this issue when the changes are pushed.",hi thank feedback latest version see answer issue sonnet python compatible import slipped u address mistake update issue,issue,negative,positive,positive,positive,positive,positive
393208612,"Hey, this has gone in today's release, you can use it by `snt.SeparableConv1D`  (more concretely, see commit  8a7ca0ab0407164e6135880bb15fbe8fa1c08ced ). Closing as this issue is now resolved.[](url)",hey gone today release use concretely see commit issue resolved,issue,negative,positive,positive,positive,positive,positive
393002173,"Hi, @kosklain, probably you can wrap another API from tensorflow, probably it is a little more easier: https://www.tensorflow.org/api_docs/python/tf/layers/SeparableConv1D
The problem is I am not quite sure there exists some corresponding native implementation in C++ or not. ",hi probably wrap another probably little easier problem quite sure corresponding native implementation,issue,negative,positive,positive,positive,positive,positive
390642923,"Oh sorry, we meant wrapping `tf.nn.separable_conv2d`, with some additional transformations.",oh sorry meant wrapping additional,issue,negative,negative,negative,negative,negative,negative
390622852,"Dear @diegolascasas: 
Does it mean there is no essentially difference between CPU version of sonnet and GPU version of sonnet, isn't it? So in most cases, the two wheels are interchangeable, yes?",dear mean essentially difference version sonnet version sonnet two interchangeable yes,issue,positive,negative,negative,negative,negative,negative
390621586,"Dear @kosklain:

Thanks for your respond. By the way, where did you find the ""magic"" `tf.nn.separable_conv1d`?

When I try to locate it, why I cannot find it?
```

(tensorflow)[yuming@cibci1 ~]$ python
Python 2.7.5 (default, Aug  2 2016, 04:20:16)
[GCC 4.8.5 20150623 (Red Hat 4.8.5-4)] on linux2
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow
>>> tensorflow.__version__
'1.8.0'
>>>
>>> dir(tensorflow.nn)
['__builtins__', '__doc__', '__file__', '__name__', '__package__', '__path__', 'all_candidate_sampler', 'atrous_conv2d', 'atrous_conv2d_transpose', 'avg_pool', 'avg_pool3d', 'batch_norm_with_global_normalization', 'batch_normalization', 'bias_add', 'bidirectional_dynamic_rnn', 'compute_accidental_hits', 'conv1d', 'conv2d', 'conv2d_backprop_filter', 'conv2d_backprop_input', 'conv2d_transpose', 'conv3d', 'conv3d_backprop_filter_v2', 'conv3d_transpose', 'convolution', 'crelu', 'ctc_beam_search_decoder', 'ctc_greedy_decoder', 'ctc_loss', 'depthwise_conv2d', 'depthwise_conv2d_native', 'depthwise_conv2d_native_backprop_filter', 'depthwise_conv2d_native_backprop_input', 'dilation2d', 'dropout', 'dynamic_rnn', 'elu', 'embedding_lookup', 'embedding_lookup_sparse', 'erosion2d', 'fixed_unigram_candidate_sampler', 'fractional_avg_pool', 'fractional_max_pool', 'fused_batch_norm', 'in_top_k', 'l2_loss', 'l2_normalize', 'leaky_relu', 'learned_unigram_candidate_sampler', 'local_response_normalization', 'log_poisson_loss', 'log_softmax', 'log_uniform_candidate_sampler', 'lrn', 'max_pool', 'max_pool3d', 'max_pool_with_argmax', 'moments', 'nce_loss', 'normalize_moments', 'pool', 'quantized_avg_pool', 'quantized_conv2d', 'quantized_max_pool', 'quantized_relu_x', 'raw_rnn', 'relu', 'relu6', 'relu_layer', 'rnn_cell', 'sampled_softmax_loss', 'selu', 'separable_conv2d', 'sigmoid', 'sigmoid_cross_entropy_with_logits', 'softmax', 'softmax_cross_entropy_with_logits', 'softmax_cross_entropy_with_logits_v2', 'softplus', 'softsign', 'sparse_softmax_cross_entropy_with_logits', 'static_bidirectional_rnn', 'static_rnn', 'static_state_saving_rnn', 'sufficient_statistics', 'swish', 'tanh', 'top_k', 'uniform_candidate_sampler', 'weighted_cross_entropy_with_logits', 'weighted_moments', 'with_space_to_batch', 'xw_plus_b', 'zero_fraction']
>>>
>>>

```

You see, no tf.nn.separable_conv1d list there.

Thanks for pointing out the way you find it.
",dear thanks respond way find magic try locate find python python default red hat type help copyright license information import see list thanks pointing way find,issue,positive,positive,positive,positive,positive,positive
390618274,"Hi mingyr,

We'll get this added. It looks to be as straightforward as adding a wrapper around `tf.nn.separable_conv1d`.",hi get added straightforward wrapper around,issue,negative,positive,positive,positive,positive,positive
390607399,"Well, if you installed a `tensorflow` wheel you can generate the `gpu=false` sonnet wheel and it should work fine.

I'll close this issue for now, but feel free to reopen it if there is any problem with your installation.",well wheel generate sonnet wheel work fine close issue feel free reopen problem installation,issue,positive,positive,positive,positive,positive,positive
389003198,"Hi, @diegolascasas:

Yes, however, the problem is if we build from source and only enable CUDA, technically speaking we have GPU enable, however, the generated wheel will be tensorflow instead of tensorflow-gpu. So here the dependency problem occurs.

Actually before TensorFlow 1.8, there is no such warning. 
",hi yes however problem build source enable technically speaking enable however wheel instead dependency problem actually warning,issue,negative,neutral,neutral,neutral,neutral,neutral
388866147,"Hi @mingyr, 
`dm-sonnet-gpu` requires `tensorflow-gpu` as a dependency, but `dm-sonnet` does not. You can generate a `dm-sonnet` wheel if your do not set `gpu` to true, and that should solve your issue. But if you generate a Tensorflow wheel from source using GPU settings, its project name should be `tensorflow-gpu` and it should satisfy the dependency... Is that what you need?",hi dependency generate wheel set true solve issue generate wheel source project name satisfy dependency need,issue,positive,positive,positive,positive,positive,positive
387709402,"Thanks, I get it! sorry for my mistake. :)",thanks get sorry mistake,issue,negative,negative,negative,negative,negative,negative
387692754,"Hi @Burning-Bear 

In the latest version of TF, `keepdims` is the correct kwarg name. `keep_dims` was the old name, which is still available but deprecated - see https://www.tensorflow.org/api_docs/python/tf/reduce_prod

In general we develop Sonnet against the newest public release of TensorFlow only, so while most of it will work with older versions it is not guaranteed. If you are unable to upgrade your version of TF for whatever reason, the best option is to use a correspondingly old version of Sonnet - you can check this here https://github.com/deepmind/sonnet/blob/master/CHANGES.md - in your case, Sonnet 1.14 should fully support TF 1.4.0. I would recommend using the latest stable versions of TF & Sonnet if at all possible though.",hi latest version correct name old name still available see general develop sonnet public release work older unable upgrade version whatever reason best option use correspondingly old version sonnet check case sonnet fully support would recommend latest stable sonnet possible though,issue,positive,positive,positive,positive,positive,positive
384008294,"@gaceladri thanks for your report - this is now fixed in version 1.20. You can get the updated version from GitHub master right now, or if you install with `pip` the updated wheels are available now. Please reopen this ticket if you have any problems.",thanks report fixed version get version master right install pip available please reopen ticket,issue,positive,positive,positive,positive,positive,positive
380824676,"@danisbohan the resampler code is now no longer part of Sonnet, it has been moved into core TF. If you update your versions of TF and Sonnet (we recommend doing `pip install dm-sonnet`) you should be fine.

Note that we do not officially support Windows, but the Sonnet code is now pure Python so should work anyway.",code longer part sonnet core update sonnet recommend pip install fine note officially support sonnet code pure python work anyway,issue,positive,positive,positive,positive,positive,positive
380343853,I've met same trouble. What about a windows user? How to make it work on Windows 10 with Tensorflow and Sonnet,met trouble user make work sonnet,issue,negative,negative,negative,negative,negative,negative
366954782,Thanks - this has been accepted internally and will be in the next public version which we should be pushing this week.,thanks accepted internally next public version pushing week,issue,positive,positive,neutral,neutral,positive,positive
365445773,"Maybe install an older version of sonnet (e.g. 1.3)???

git clone --branch v1.3 https://github.com/deepmind/sonnet sonnet",maybe install older version sonnet git clone branch sonnet,issue,negative,positive,positive,positive,positive,positive
365416278,"Hi @VastoLorde95 - you need to upgrade your version of TensorFlow. The current version of Sonnet only supports TF 1.5.0. I realise now there is a mistake in our README, which still says 1.2 - I'll correct that asap. In the meantime though, it's worth checking https://github.com/deepmind/sonnet/blob/master/CHANGES.md - whenever we push a release that requires a specific version of TF we mention it there, and you can see at that top that 1.16 (current version from pip) requires TF 1.5.0

We looked into making this get automatically added when you do pip install, but it's a bit tricky because there are tensorflow and tensorflow-gpu packages, and either will work.

Sorry for the confusion - let me know if you can't get it working with TF 1.5.0.",hi need upgrade version current version sonnet mistake still correct though worth whenever push release specific version mention see top current version pip making get automatically added pip install bit tricky either work sorry confusion let know ca get working,issue,negative,positive,neutral,neutral,positive,positive
360531854,Thank you very much for your time. I really appreciated it!,thank much time really,issue,negative,positive,positive,positive,positive,positive
360530582,"Thanks, I can reproduce this now.

The issue is, as the warning says, you are passing in a Tensor where the final dimension (channels) is not know at graph construction time. If you print the shape of next_element before connection you can see it is of shape (?, ?, 224, 224, ?), and for the conv module to work correctly the final question mark is not allowed.

The reason is the py_func produces output of completely unknown shape (if you put a breakpoint in preprocess() you can see that video_cube has no shape information. After going through crop_and_resize some of the dimensions get static shape information, because of your 224x224 window, but crucially this doesn't affect the channel dimension, which remains unknown.

You can fix this with a single call to set_shape at the end of preprocess:

```python
  video_cube_crop = tf.image.crop_and_resize(video_cube,
                                             boxes,
                                             tf.range(tf.shape(video_cube)[0], dtype=tf.int32),
                                             tf.constant([224, 224], dtype=tf.int32))
  video_cube_crop.set_shape(tf.TensorShape([None, 224, 224, 3]))  # Assert 3 channel data.
  # Normalize [-1, +1]
  # ...

  return video_cube_crop, label, length
```

The code crashes further on for me with a type error (int32/int64 mismatch) but if definitely connects the I3d module successfully.

Closing, but feel free to reopen if the line above doesn't work for you.

",thanks reproduce issue warning passing tensor final dimension know graph construction time print shape connection see shape module work correctly final question mark reason output completely unknown shape put see shape information going get static shape information window crucially affect channel dimension remains unknown fix single call end python none assert channel data normalize return label length code type error mismatch definitely id module successfully feel free reopen line work,issue,positive,positive,positive,positive,positive,positive
360525841,"[input.zip](https://github.com/deepmind/sonnet/files/1664759/input.zip)

You can try again:
1) Pull from the same .git above
2) Unzip this 'input.zip' somewhere... it contains two identical .npy files (train and test lists) and the frames of one single video sample (S001C001P001R001A001).
3) Numpy files are of the form:
[['S001C001P001R001A001', 1, 103],
['S001C001P001R001A001', 1, 103],
.... ] # this for 5000 rows, anyone pointing to the same video sample.
4) You can organize them something like:
/tmp/
---|_ frames
------|_ S001C001P001R001A001/
---------|_ 0001.jpg
---------|_ 0002.jpg
---------|_ ...
---|_ lists
------|_ training_list.npy
------|_ testing_list.npy
5) Change 'input_data_NTURGBD.py' line 10 to '/tmp'
6) Change 'test_input.py' line 17 to '/tmp'
The other paths aren't involved for now...
Thank you in advance

",try pull somewhere two identical train test one single video sample form anyone pointing video organize something like change line change line involved thank advance,issue,positive,negative,neutral,neutral,negative,negative
360313449,"@elmuz I'm afraid I can't reproduce this. I made a fresh virtualenv and install TF and Sonnet with pip. I made the following changes to test_input.py, some of this is guesswork at what your actual data is like so please feel free to correct me. Alternatively, if you can provide something that matches your training_list.npy / testing_list.npy, such that I can clone the repo and run a single command to trigger the crash, then I can investigate more. Here's the relevant bit of code, with the ""if False"" block included so you can see where I started making modifications to the file. When I run this, the code constructs and connects the InceptionI3d model without problems, and hits the breakpoint at the bottom fine.

```python
  if False:
    # .npy data are in the form of [filename(string), label(int), video-length(int)]
    training_data = np.load(os.path.join(FLAGS.dataset_path, 'lists', 'training_list.npy'))
    testing_data = np.load(os.path.join(FLAGS.dataset_path, 'lists', 'testing_list.npy'))

    #augmentation = False

    filenames = tf.constant(training_data['file'])
    labels = tf.cast(tf.constant(training_data['label']), dtype=tf.int32)
    lengths = tf.constant(training_data['frames'])
    #num_frames = tf.constant(np.repeat(FLAGS.num_frames_per_clip, np.shape(training_data)), dtype=tf.int32)


    #dataset = tf.data.Dataset.from_tensor_slices((filenames, labels, lengths, num_frames))
    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels, lengths))
    dataset = dataset.map(lambda filename, label, length: tuple(tf.py_func(pack_frames, [filename, label, length, FLAGS.num_frames_per_clip], [tf.uint8, label.dtype, length.dtype])))

  num_data = 1000
  length = 100
  height, width = 384, 512
  channels = 3
  fake_x = tf.cast(tf.zeros([num_data, length, height, width, channels]), tf.uint8)
  fake_y = tf.cast(tf.constant(np.random.rand(num_data) * 100), tf.int64)

  dataset = tf.data.Dataset.from_tensor_slices((fake_x, fake_y, tf.cast(fake_y, tf.int64)))
  dataset = dataset.map(preprocess)
  dataset = dataset.prefetch(50)
  dataset = dataset.batch(FLAGS.batch_size)

  iterator = dataset.make_initializable_iterator()
  next_element, next_label, _ = iterator.get_next()


  #rgb_input = tf.placeholder(tf.float32, shape=(None, FLAGS.num_frames_per_clip, FLAGS.crop_size, FLAGS.crop_size, 3), name='INPUT')
  #Y = tf.placeholder(tf.int64, [None])

  with tf.variable_scope('RGB'):
    rgb_model = InceptionI3d(num_classes=10, spatial_squeeze=True, final_endpoint='Logits')
  print('before rgb_model connection, next_element: %s' % next_element)
  logits, _ = rgb_model(next_element, is_training=False, dropout_keep_prob=FLAGS.dropout_keep_prob)
  print('after rgb_model connection')
  import pdb; pdb.set_trace()
```

Prints the following before a PDB prompt:

```shell
before rgb_model connection, next_element: Tensor(""IteratorGetNext:0"", shape=(?, ?, 224, 224, 3), dtype=float32)
after rgb_model connection
```
",afraid ca reproduce made fresh install sonnet pip made following guesswork actual data like please feel free correct alternatively provide something clone run single command trigger crash investigate relevant bit code false block included see making file run code model without bottom fine python false data form string label augmentation false lambda label length label length length height width length height width none none print connection print connection import following prompt shell connection tensor connection,issue,negative,negative,neutral,neutral,negative,negative
359843623,"I think the easiest way is to clone this repository: https://elmuz@bitbucket.org/elmuz/ntu-rgb.git which is more a toy example... The file you can launch is _test_input.py_, which relies on _input_data_NTURGBD.py_ for frame packeting and augmentation. I don't think you need any real data. Just give it fake, since it crashes before any proper processing, as soon it builds the graph. There are probably more errors than the one I was talking about that I will find out as soon as I3D error will be solved.
Hope you can investigate a bit into it.
For the record, TF v. 1.4.1, Sonnet v. 1.14",think easiest way clone repository toy example file launch frame augmentation think need real data give fake since proper soon graph probably one talking find soon id error hope investigate bit record sonnet,issue,negative,negative,neutral,neutral,negative,negative
359811475,"@elmuz could you provide a script that is a full reproduction for this issue? You don't need to send me your data, something which uses tf.data.Dataset.from_tensor_slices(tf.random(...)) to generate data of the right shape is sufficient. If you can upload that, plus the versions of TF and Sonnet that you are using, I can investigate further.",could provide script full reproduction issue need send data something generate data right shape sufficient plus sonnet investigate,issue,negative,positive,positive,positive,positive,positive
359805446,"> it looks like you are connecting rgb_input to the Inception3D module. What size is that Tensor?

it was exactly the same. In fact the error is present by doing

```
  with tf.variable_scope('RGB'):
    rgb_model = InceptionI3d(num_classes=10, spatial_squeeze=True, final_endpoint='Logits')
  logits, _ = rgb_model(next_element, is_training=False, dropout_keep_prob=FLAGS.dropout_keep_prob)
```",like module size tensor exactly fact error present,issue,negative,positive,positive,positive,positive,positive
359804434,"I was wrong while writing this issue post. I edited the post accordingly. My input is 5D [batch, frames, height, width, channels].
Here's how I create the input:
```
dataset = tf.data.Dataset.from_tensor_slices((filenames, labels, lengths, num_frames))
  dataset = dataset.map(lambda filename, label, length, n_frames: tuple(tf.py_func(pack_frames, [filename, label, length, n_frames], [tf.uint8, label.dtype, length.dtype, n_frames.dtype])))
  dataset = dataset.map(preprocess)
```
from here Dataset is converted from ""string"" (like 'filenames' tensor) into [num_frames, height, width, channels] with alla augmentation needed. All others input slices are not touched.
```
  dataset = dataset.prefetch(50)
  dataset = dataset.batch(FLAGS.batch_size)
  iterator = dataset.make_initializable_iterator()
  next_input, next_label, _, _ = iterator.get_next()
```
Batch function add one dimension on top of input tensor. In fact if I print `tf.shape(next_element)` it shows up correctly.",wrong writing issue post post accordingly input batch height width create input lambda label length label length converted string like tensor height width augmentation input touched batch function add one dimension top input tensor fact print correctly,issue,negative,neutral,neutral,neutral,neutral,neutral
359801686,"Thanks. In your code above, you say `next_input` is [batch, 224, 224, 3], but it looks like you are connecting `rgb_input` to the Inception3D module. What size is that Tensor?",thanks code say batch like module size tensor,issue,positive,positive,positive,positive,positive,positive
359800432,"Sure! Here's the full stack trace:

```
python3 Sandbox/dev/NTU-RGBD/test_input.py                                                                                   alessio@sonja
/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Traceback (most recent call last):
  File ""Sandbox/dev/NTU-RGBD/test_input.py"", line 124, in <module>
    test()
  File ""Sandbox/dev/NTU-RGBD/test_input.py"", line 71, in test
    logits, _ = rgb_model(next_element, is_training=False, dropout_keep_prob=FLAGS.dropout_keep_prob)
  File ""/usr/local/lib/python3.5/dist-packages/sonnet/python/modules/base.py"", line 264, in __call__
    outputs, subgraph_name_scope = self._template(*args, **kwargs)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/template.py"", line 268, in __call__
    result = self._call_func(args, kwargs, check_for_new_variables=False)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/template.py"", line 217, in _call_func
    result = self._func(*args, **kwargs)
  File ""/usr/local/lib/python3.5/dist-packages/sonnet/python/modules/base.py"", line 152, in _build_wrapper
    output = self._build(*args, **kwargs)
  File ""/home/alessio/Sandbox/dev/NTU-RGBD/i3d.py"", line 170, in _build
    stride=[2, 2, 2], name=end_point)(net, is_training=is_training)
  File ""/usr/local/lib/python3.5/dist-packages/sonnet/python/modules/base.py"", line 264, in __call__
    outputs, subgraph_name_scope = self._template(*args, **kwargs)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/template.py"", line 268, in __call__
    result = self._call_func(args, kwargs, check_for_new_variables=False)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/template.py"", line 217, in _call_func
    result = self._func(*args, **kwargs)
  File ""/usr/local/lib/python3.5/dist-packages/sonnet/python/modules/base.py"", line 152, in _build_wrapper
    output = self._build(*args, **kwargs)
  File ""/home/alessio/Sandbox/dev/NTU-RGBD/i3d.py"", line 65, in _build
    use_bias=self._use_bias)(inputs)
  File ""/usr/local/lib/python3.5/dist-packages/sonnet/python/modules/base.py"", line 264, in __call__
    outputs, subgraph_name_scope = self._template(*args, **kwargs)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/template.py"", line 268, in __call__
    result = self._call_func(args, kwargs, check_for_new_variables=False)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/template.py"", line 217, in _call_func
    result = self._func(*args, **kwargs)
  File ""/usr/local/lib/python3.5/dist-packages/sonnet/python/modules/base.py"", line 152, in _build_wrapper
    output = self._build(*args, **kwargs)
  File ""/usr/local/lib/python3.5/dist-packages/sonnet/python/modules/conv.py"", line 2714, in _build
    ""Number of input channels must be known at module build time"")
sonnet.python.modules.base_errors.UnderspecifiedError: Number of input channels must be known at module build time

originally defined at:
  File ""/usr/local/lib/python3.5/dist-packages/sonnet/python/modules/conv.py"", line 2645, in __init__
    super(Conv3D, self).__init__(custom_getter=custom_getter, name=name)
  File ""/usr/local/lib/python3.5/dist-packages/sonnet/python/modules/base.py"", line 124, in __init__
    custom_getter_=self._custom_getter)


originally defined at:
  File ""/home/alessio/Sandbox/dev/NTU-RGBD/i3d.py"", line 43, in __init__
    super(Unit3D, self).__init__(name=name)
  File ""/usr/local/lib/python3.5/dist-packages/sonnet/python/modules/base.py"", line 124, in __init__
    custom_getter_=self._custom_getter)


originally defined at:
  File ""Sandbox/dev/NTU-RGBD/test_input.py"", line 70, in test
    rgb_model = InceptionI3d(num_classes=10, spatial_squeeze=True, final_endpoint='Logits')
  File ""/home/alessio/Sandbox/dev/NTU-RGBD/i3d.py"", line 139, in __init__
    super(InceptionI3d, self).__init__(name=name)
  File ""/usr/local/lib/python3.5/dist-packages/sonnet/python/modules/base.py"", line 124, in __init__
    custom_getter_=self._custom_getter)
```
",sure full stack trace python conversion second argument float future float import recent call last file line module test file line test file line file line result file line result file line output file line net file line file line result file line result file line output file line file line file line result file line result file line output file line number input must known module build time number input must known module build time originally defined file line super self file line originally defined file line super self file line originally defined file line test file line super self file line,issue,positive,positive,positive,positive,positive,positive
359796084,"@elmuz Hi, could you post the full stack trace please, so I can see which Conv3D module invocation is causing the problem?",hi could post full stack trace please see module invocation causing problem,issue,negative,positive,positive,positive,positive,positive
357329221,"Hi,

Sorry for the delay.

There's nothing specific in Sonnet for conversion to a C++-serveable form, but the underlying data structure created by Sonnet can be saved out as a normal GraphDef / MetaGraphDef. I'm not actually aware of people who use Sonnet doing this regularly - Sonnet is for our research team, and most of the models built with it aren't going directly into production. There have been a few exceptions, I can check if anyone has any more specific guidance, but in the meantime I would recommend looking at the basic TF serving guides, like [this one](https://www.tensorflow.org/serving/serving_basic).

Once the model is built and trained, you export it, providing a signature for the input / output tensors, and you can then serve with the tensorflow_model_server binary or similar.",hi sorry delay nothing specific sonnet conversion form underlying data structure sonnet saved normal actually aware people use sonnet regularly sonnet research team built going directly production check anyone specific guidance would recommend looking basic serving like one model built trained export providing signature input output serve binary similar,issue,positive,positive,neutral,neutral,positive,positive
355582381,"Sorry, missed this.  This is for the docs readme subpage here:

https://github.com/deepmind/sonnet/tree/master/docs

not the top level folder (which is what you're linking).

",sorry top level folder linking,issue,negative,neutral,neutral,neutral,neutral,neutral
353014342,"Hi @malcolmreynolds thanks for clearing this up! In hindsight this makes total sense as the cell would have no idea which variable (w or b) was being initalized. Usefully, the following also works for specifying only w:
```
initalizers = {
  'hidden_to_hidden': {
    'w': tf.truncated_normal_initializer(stddev=1.0)
  }
}
```
Thanks again!",hi thanks clearing hindsight total sense cell would idea variable usefully following also work thanks,issue,positive,positive,neutral,neutral,positive,positive
352439671,"Note - apologies, this is a pretty bad error message which doesn't help users - we will fix internally and have something which points out the exact mistake in the next version.",note pretty bad error message help fix internally something exact mistake next version,issue,negative,negative,neutral,neutral,negative,negative
352439051,"Hi @dbusbridge - the issue is the initializers dict. You need to provide a 2 level dict, as the weights you are trying to initialize are part of the `hidden_to_hidden` submodule. Try the following:

```
initalizers = {
    'hidden_to_hidden': {
        'w': tf.truncated_normal_initializer(stddev=1.0),
        'b': tf.zeros_initializer(),
    }
}
```",hi issue need provide level trying initialize part try following,issue,negative,neutral,neutral,neutral,neutral,neutral
343245974,"@dbusbridge If you reinstall Sonnet from either GitHub head, or pip, you should have a version that works with TF 1.4.0. Please let me know whether this is fixed for you!",reinstall sonnet either head pip version work please let know whether fixed,issue,negative,positive,neutral,neutral,positive,positive
343163739,"Hi, the logo appears to show up in our main page (https://github.com/deepmind/sonnet) and the docs page (https://deepmind.github.io/sonnet/). Where do you see that this needs fixing?",hi show main page page see need fixing,issue,negative,positive,positive,positive,positive,positive
342123444,"@dbusbridge Hi, thanks for the report. This is due to a recent change in whether Tensors are iterable or not, which isn't reflected in our current nest library. As you say, Sonnet is supported against one specific version of TF, and that won't necessarily be in sync with GitHub HEAD, or in this case the current stable version which arrived last week.

This is fixed internally and we should be pushing a new Sonnet version this week, I'll close this ticket once we've done that.",hi thanks report due recent change whether iterable reflected current nest library say sonnet one specific version wo necessarily sync head case current stable version last week fixed internally pushing new sonnet version week close ticket done,issue,positive,positive,neutral,neutral,positive,positive
342107124,"there is a guide in the official document, sorry just find it now.
First, install bazel;
Second, build it to whl style;
Third, insthll the whl file.",guide official document sorry find first install second build style third file,issue,negative,negative,neutral,neutral,negative,negative
341591034,"Sorry, I found I can direct use it without importing, just by add some prefix. ",sorry found direct use without add prefix,issue,negative,negative,negative,negative,negative,negative
341404677,"Another Docker image including Sonnet is [Deepo](https://github.com/ufoym/deepo). Closing this, as I think there are a bunch of externally supported possibilities.",another docker image sonnet think bunch externally,issue,negative,neutral,neutral,neutral,neutral,neutral
341268925,"@malcolmreynolds Thanks a lot for pointing out that. I also think tensorflow-ers have sufficient reason for doing so. I used to be a software programmer and fully understand that theoretic correctness doesn't imply practical feasibility.
Yes, you are quite right. I am too indulged into the complex way and forget it can be verified in some much simplified way. Thanks for pointing out that.
I will close this thread since if it didn't work in the way as expected, it should be a tensorflow issue instead sonnet.
",thanks lot pointing also think sufficient reason used programmer fully understand theoretic correctness imply practical feasibility yes quite right complex way forget much simplified way thanks pointing close thread since work way issue instead sonnet,issue,positive,positive,positive,positive,positive,positive
341093998,"@mingyr The choice of None for gradient computation instead of zero is explained here: https://github.com/tensorflow/tensorflow/issues/783 - there is clearly some debate over whether it's the right thing, but changing the default in TF would require a long deprecation cycle.

As to verifying whether it works correctly when combining the two losses, you can try building one graph which optimises the two losses separately, and retrieve the two gradient contributions to the common part, and then compare them to the combined gradient for the common part from the added-loss setup. Given the same input values, you should be able to add the two contributions from the first two and get the same gradients.",choice none gradient computation instead zero clearly debate whether right thing default would require long deprecation cycle whether work correctly combining two try building one graph two separately retrieve two gradient common part compare combined gradient common part setup given input able add two first two get,issue,negative,positive,neutral,neutral,positive,positive
340311266,@malcolmreynolds Got it. Yes it is more convenient that the batch dimension is totally put out of consideration. I will close the thread.,got yes convenient batch dimension totally put consideration close thread,issue,negative,neutral,neutral,neutral,neutral,neutral
340282963,"@mingyr BatchReshape takes as input the desired output shape, _without_ the batch dimension (to allow for situations where the batch dimension is unknown at graph construction time. Try the following to strip the batch dimension:

```
    def _build(self, inputs):
        return snt.BatchReshape(inputs.get_shape().as_list()[1:])(self._ln(snt.BatchFlatten()(inputs)))
```

",input desired output shape batch dimension allow batch dimension unknown graph construction time try following strip batch dimension self return,issue,negative,negative,neutral,neutral,negative,negative
340202604,Closed due to inactivity. Feel free to reopen the bug if you have any problem installing from pip.,closed due inactivity feel free reopen bug problem pip,issue,negative,positive,neutral,neutral,positive,positive
340144483,"@malcolmreynolds I also confirmed that if we add the respectively two losses together, it can also work. The problem here is, is there an easy way we can verify it is working in the way as intended? I mean for CommonPart module, two inputs contribute to the gradients, how could I verify that? I save the result into Matlab mat and import it into Matlab, however I lost my clue how to make comparison due to my limited knowledge of TensorFlow, So @malcolmreynolds do you have any idea? Thanks.

Please refer to the following code:

```
import numpy as np
import tensorflow as tf
import sonnet as snt
from tensorflow.python import debug as tf_debug

import scipy.io as sio

# common part shared by two targets
class CommonPart(snt.AbstractModule):
    def __init__(self, name = ""common_part""):
        super(CommonPart, self).__init__(name = name)
        with self._enter_variable_scope():
            self._conv = snt.Conv2D(4, [3, 3])

    def _build(self, inputs):
        return self._conv(inputs)

# one target with specific output 1
class Output1(snt.AbstractModule):
    def __init__(self, output_size, name = ""output1""):
        super(Output1, self).__init__(name = name)
        with self._enter_variable_scope():
            self._lin = snt.Linear(output_size)

    def _build(self, inputs):
        return self._lin(inputs)

# another target with specific output 2
class Output2(snt.AbstractModule):
    def __init__(self, output_size, name = ""output2""):
        super(Output2, self).__init__(name = name)
        with self._enter_variable_scope():
            self._lin = snt.Linear(output_size)

    def _build(self, inputs):
        return self._lin(inputs)

# t1 is input for target1
t1 = tf.truncated_normal([1, 5, 5, 1])

# t2 is input for target 2
t2 = tf.truncated_normal([1, 5, 5, 1])

# l1 is ground truth label for target 1
l1 = tf.constant([[1, 0]])

# l2 is ground truth label for target 2
l2 = tf.constant([[0, 1, 0, 0]])

opt = tf.train.AdamOptimizer(0.01)

# we create the model, the two-head monster
common_part = CommonPart()
output1 = Output1(2)
output2 = Output2(4)

# feed-forward computation
i1 = common_part(t1)
i2 = common_part(t2)

o1 = output1(snt.BatchFlatten()(i1))
o2 = output2(snt.BatchFlatten()(i2))

# losses for separated targets
l1 = tf.nn.softmax_cross_entropy_with_logits(labels = l1, logits = o1)
l2 = tf.nn.softmax_cross_entropy_with_logits(labels = l2, logits = o2)

l = l1 + l2

g1 = [(grad, var) for grad, var in opt.compute_gradients(l1)
      if grad is not None]
g2 = [(grad, var) for grad, var in opt.compute_gradients(l2)
      if grad is not None]

g = opt.compute_gradients(l)

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())

    g1_val, g2_val, g_val = sess.run([g1, g2, g])

    output = { 'g1': g1_val, 'g2': g2_val, 'g': g_val }

    sio.savemat(""output.mat"", output)

```

By the way, even if the filtered version is working:

```
g1 = [(grad, var) for grad, var in opt.compute_gradients(l1)
      if grad is not None]
g2 = [(grad, var) for grad, var in opt.compute_gradients(l2)
      if grad is not None]

```
However, is there a potential misalignment between variables? What I mean is, when we call opt.apply_gradients(g1) later, how it can anticipate the variables have been filtered in the previous compute_gradients call? Will such a mismatch cause partial variables updated in an incorrect way?

Further, if the above way (adding losses together then computing the gradients) is workable, then it is okay. Otherwise, it relies on the existence of misalignment or not. If there is misalignment, it will be a headache for multi-GPU training, since the stereotype average_gradients(tower_grads) will not work if we do not filtering. So this would be a dilemma.

Although to some extent get_variables can solve the problem, however my question here is why None be assigned as gradient for incomplete op node?  Why we can not have 0 substitute the None? What is the philosophy? So @malcolmreynolds can we point to TensorFlow team about this?

Welcome further discussion. ",also confirmed add respectively two together also work problem easy way verify working way intended mean module two contribute could verify save result mat import however lost clue make comparison due limited knowledge idea thanks please refer following code import import import sonnet import import common part two class self name super self name name self return one target specific output class output self name output super output self name name self return another target specific output class output self name output super output self name name self return input target input target ground truth label target ground truth label target opt create model monster output output output output computation output output grad grad grad none grad grad grad none sess output output way even version working grad grad grad none grad grad grad none however potential misalignment mean call later anticipate previous call mismatch cause partial incorrect way way together workable otherwise existence misalignment misalignment headache training since stereotype work filtering would dilemma although extent solve problem however question none assigned gradient incomplete node substitute none philosophy point team welcome discussion,issue,positive,positive,neutral,neutral,positive,positive
340131891,"@malcolmreynolds Yes, I confirmed it works with get_variables, and I compared the outputs with WinMerge and they are identical. Please refer to the following code:

```
import numpy as np
import tensorflow as tf
import sonnet as snt
from tensorflow.python import debug as tf_debug

# common part shared by two targets
class CommonPart(snt.AbstractModule):
    def __init__(self, name = ""common_part""):
        super(CommonPart, self).__init__(name = name)
        with self._enter_variable_scope():
            self._conv = snt.Conv2D(4, [3, 3])

    def _build(self, inputs):
        return self._conv(inputs)

# one target with specific output 1
class Output1(snt.AbstractModule):
    def __init__(self, output_size, name = ""output1""):
        super(Output1, self).__init__(name = name)
        with self._enter_variable_scope():
            self._lin = snt.Linear(output_size)

    def _build(self, inputs):
        return self._lin(inputs)

# another target with specific output 2
class Output2(snt.AbstractModule):
    def __init__(self, output_size, name = ""output2""):
        super(Output2, self).__init__(name = name)
        with self._enter_variable_scope():
            self._lin = snt.Linear(output_size)

    def _build(self, inputs):
        return self._lin(inputs)

# t1 is input for target1
t1 = tf.truncated_normal([1, 5, 5, 1])

# t2 is input for target 2
t2 = tf.truncated_normal([1, 5, 5, 1])

# l1 is ground truth label for target 1
l1 = tf.constant([[1, 0]])

# l2 is ground truth label for target 2
l2 = tf.constant([[0, 1, 0, 0]])

opt = tf.train.AdamOptimizer(0.01)

# we create the model, the two-head monster
common_part = CommonPart()
output1 = Output1(2)
output2 = Output2(4)

# feed-forward computation
i1 = common_part(t1)
i2 = common_part(t2)

o1 = output1(snt.BatchFlatten()(i1))
o2 = output2(snt.BatchFlatten()(i2))

# losses for separated targets
l1 = tf.nn.softmax_cross_entropy_with_logits(labels = l1, logits = o1)
l2 = tf.nn.softmax_cross_entropy_with_logits(labels = l2, logits = o2)


TARGET1_VARIABLES = '_target1_variables_'
TARGET2_VARIABLES = '_target2_variables_'

def add_variable(var, collection_name, restore=True):
    if var not in tf.get_collection(collection_name):
      tf.add_to_collection(collection_name, var)

for var in common_part.get_variables():
    add_variable(var, TARGET1_VARIABLES)
    add_variable(var, TARGET2_VARIABLES)

for var in output1.get_variables():
    add_variable(var, TARGET1_VARIABLES)

for var in output2.get_variables():
    add_variable(var, TARGET2_VARIABLES)

g1 = opt.compute_gradients(l1, tf.get_collection(TARGET1_VARIABLES))
g2 = opt.compute_gradients(l2, tf.get_collection(TARGET2_VARIABLES))

g1_1 = [(grad, var) for grad, var in opt.compute_gradients(l1)
      if grad is not None]

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())

    # sess = tf_debug.LocalCLIDebugWrapperSession(sess)

    g1_val, g1_1_val = sess.run([g1, g1_1])

    g1_val = np.asarray(g1_val)
    g1_1_val = np.asarray(g1_1_val)

    print(""g1_val -> "")
    print(g1_val)
    print(""****************************************"")
    print(""g1_1_val -> "")
    print(g1_1_val)


```

I will keep it updating for the following part.",yes confirmed work identical please refer following code import import import sonnet import common part two class self name super self name name self return one target specific output class output self name output super output self name name self return another target specific output class output self name output super output self name name self return input target input target ground truth label target ground truth label target opt create model monster output output output output computation output output grad grad grad none sess sess sess print print print print print keep following part,issue,positive,positive,positive,positive,positive,positive
339968822,"@malcolmreynolds : I am sincerely appreciating your quick respond. However, probably I should first inspect it is a true problem or not by using tfdbg, but I really appreciate your dedication. I will keep you updated for the following part later. I got a terrible network connection to the cluster node which resides in the campus IDC.
Have a nice weekend.",sincerely quick respond however probably first inspect true problem really appreciate dedication keep following part later got terrible network connection cluster node campus nice weekend,issue,positive,positive,neutral,neutral,positive,positive
339963637,"@mingyr the compute_gradients call executes fine, but you are then requesting some of these None values from session.run, which causes the error you see. If you remove the `(None, variable)` elements from the result of compute_gradients the whole thing should run. Replace the last part with:

```
g1 = [(grad, var) for grad, var in opt.compute_gradients(l1)
      if grad is not None]
g2 = [(grad, var) for grad, var in opt.compute_gradients(l2)
      if grad is not None]

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())

    g1_val, g2_val = sess.run([g1, g2])

    print(g1_val)
```",call fine none error see remove none variable result whole thing run replace last part grad grad grad none grad grad grad none sess print,issue,negative,positive,positive,positive,positive,positive
339954096,"@malcolmreynolds Really? Could you please tell me the version of TensorFlow and Sonnet when you run the code? I could fully understand the None output, but on the latest version it just stop working:

```
(tensorflow)[yuming@cibci2 working-files]$ python 45.py
2017-10-27 23:08:12.324778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1031] Found device 0 with properties:
name: Quadro P5000 major: 6 minor: 1 memoryClockRate(GHz): 1.7335
pciBusID: 0000:03:00.0
totalMemory: 15.89GiB freeMemory: 15.65GiB
2017-10-27 23:08:12.491193: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1031] Found device 1 with properties:
name: Quadro P5000 major: 6 minor: 1 memoryClockRate(GHz): 1.7335
pciBusID: 0000:82:00.0
totalMemory: 15.89GiB freeMemory: 15.78GiB
2017-10-27 23:08:12.491302: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1046] Device peer to peer matrix
2017-10-27 23:08:12.491322: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1052] DMA: 0 1
2017-10-27 23:08:12.491327: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1062] 0:   Y N
2017-10-27 23:08:12.491331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1062] 1:   N Y
2017-10-27 23:08:12.491342: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Quadro P5000, pci bus id: 0000:03:00.0, compute capability: 6.1)
2017-10-27 23:08:12.491347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] Creating TensorFlow device (/device:GPU:1) -> (device: 1, name: Quadro P5000, pci bus id: 0000:82:00.0, compute capability: 6.1)
Traceback (most recent call last):
  File ""45.py"", line 73, in <module>
    g1_val, g2_val = sess.run([g1, g2])
  File ""/home/yuming/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 889, in run
    run_metadata_ptr)
  File ""/home/yuming/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1105, in _run
    self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)
  File ""/home/yuming/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 414, in __init__
    self._fetch_mapper = _FetchMapper.for_fetch(fetches)
  File ""/home/yuming/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 234, in for_fetch
    return _ListFetchMapper(fetch)
  File ""/home/yuming/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 341, in __init__
    self._mappers = [_FetchMapper.for_fetch(fetch) for fetch in fetches]
  File ""/home/yuming/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 234, in for_fetch
    return _ListFetchMapper(fetch)
  File ""/home/yuming/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 341, in __init__
    self._mappers = [_FetchMapper.for_fetch(fetch) for fetch in fetches]
  File ""/home/yuming/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 234, in for_fetch
    return _ListFetchMapper(fetch)
  File ""/home/yuming/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 341, in __init__
    self._mappers = [_FetchMapper.for_fetch(fetch) for fetch in fetches]
  File ""/home/yuming/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 231, in for_fetch
    (fetch, type(fetch)))
TypeError: Fetch argument None has invalid type <type 'NoneType'>
(tensorflow)[yuming@cibci2 working-files]$

```

The version I currently used:

```
(tensorflow)[yuming@cibci2 working-files]$ pip list
dm-sonnet-gpu (1.13)
tensorflow (1.4.0rc0)

```",really could please tell version sonnet run code could fully understand none output latest version stop working python found device name major minor found device name major minor device peer peer matrix device device name bus id compute capability device device name bus id compute capability recent call last file line module file line run file line file line file line return fetch file line fetch fetch file line return fetch file line fetch fetch file line return fetch file line fetch fetch file line fetch type fetch fetch argument none invalid type type version currently used pip list,issue,negative,positive,neutral,neutral,positive,positive
339951440,"@mingyr sorry, I'm not quite sure I follow. When I run your code both the compute_gradients lines execute fine - by default they get the gradients with respect to all variables, so there are some `None` returns due to the gradients with respect to variables in output1 not having any contribution to loss2, and vice versa. One option is to give compute_gradients a list of the variables to differentiate with respect to, by calling `get_variables` on common_part and the relevant output module. You could also just add the two losses together at the end and differentiate that, although you may not always want to provide data to both inputs.

If you want to put variables in specific collections, you could use a custom_getter in the variable_scope within which your modules are declared. I don't think it's necessary in this case though.

Apologies if I've misunderstood the problem - please let me know if the .get_variables suggestion works.
",sorry quite sure follow run code execute fine default get respect none due respect output contribution loss vice one option give list differentiate respect calling relevant output module could also add two together end differentiate although may always want provide data want put specific could use within declared think necessary case though misunderstood problem please let know suggestion work,issue,positive,positive,neutral,neutral,positive,positive
339519602,"@malcolmreynolds : Got it, great thanks for the detailed explanation.",got great thanks detailed explanation,issue,positive,positive,positive,positive,positive,positive
339332376,"Hi @mingyr - we provided LayerNorm as a separate module so that people can try using it in various places, without being tied to a particular RNN architecture. There is a constructor kwarg `use_layer_norm` for the LSTM which inserts a LayerNorm module inside the LSTM, before the activations, and so if you want to get the same behaviour as LayerNormBasicLSTMCell you can use that.",hi provided separate module people try various without tied particular architecture constructor module inside want get behaviour use,issue,negative,positive,neutral,neutral,positive,positive
338095233,@malcolmreynolds I am sincerely appreciating the detailed explanation and fully understanding the situation. The important thing is not we invent something perfect but we invent something based on which we can advance our daily job. I am glad that Sonnet is such a library which helps me a great deal. Thanks for the contribution made by you engineers at Deepmind which benefits the deep learning community a lot. ,sincerely detailed explanation fully understanding situation important thing invent something perfect invent something based advance daily job glad sonnet library great deal thanks contribution made deep learning community lot,issue,positive,positive,positive,positive,positive,positive
337869771,We don't use Docker internally so we won't be able to add an officially supported Docker image to the main repository. There is a Python 3 Docker image here: https://hub.docker.com/r/smizy/sonnet/ which looks like it might suit your needs.,use docker internally wo able add officially docker image main repository python docker image like might suit need,issue,negative,positive,positive,positive,positive,positive
337868827,@shushan2017 all the results for the Nature paper were done with a Hogwild SGD setup across multiple CPUs (32 cores in some cases) - I'd recommend looking into that for the best performance.,nature paper done setup across multiple recommend looking best performance,issue,positive,positive,positive,positive,positive,positive
337810117,Maybe a docker image will be a good option!,maybe docker image good option,issue,negative,positive,positive,positive,positive,positive
337777897,"@malcolmreynolds 
Thank you for your answer. I'm concerned about GPU. I want to get higher speed. If DNC isn't suitable for GPU, then I don't bother with it.
About the calculation errors, I just feel sorry, 0.4 is probably remember before the calculation of ACC, and GPU, into 0.003, because the calculation is too slow, I run only once, this information can not explain what. The conclusion is that DNC is really not suitable for running on gpu.
Again, thank you very much！！！！！",thank answer concerned want get higher speed suitable bother calculation feel sorry probably remember calculation calculation slow run information explain conclusion really suitable running thank,issue,negative,positive,positive,positive,positive,positive
337608913,"@mingyr Hi, thanks for your detailed comment.

I've looked into this before and unfortunately there are no publicly exposed APIs from TF which allow us to have more control over this. I would like to be able to capture the surrounding device context when constructing a module, as your middle example shows. However unlike the various kinds of scopes, `tf.device` doesn't return anything you can hang onto and reenter, eg:

```
with tf.variable_scope('some_name') as scope:
  print(scope)  # Prints a VariableScope object we can query, reenter, etc

with tf.device('/cpu:0') as device_information:
  print(device_information)  # prints `None`
```

Without being able to capture the context, we cannot respect device placement directives around where we construct modules. If you read the TF source you see that this works by accessing various private members of the `Graph` object and others, and it would be a huge maintenance burden for us to start relying on these private APIs.

We've had some conversations with the TF team about creating an external more advanced use of device placement (and other things(), and those discussions are ongoing. I hope to have some improvement in this area in the public version soon.

It's very useful to hear from users about the pain points of the library, so once again thankyou.
",hi thanks detailed comment unfortunately publicly exposed allow u control would like able capture surrounding device context module middle example however unlike various return anything onto scope print scope object query print none without able capture context respect device placement around construct read source see work various private graph object would huge maintenance burden u start private team external advanced use device placement ongoing hope improvement area public version soon useful hear pain library,issue,positive,positive,positive,positive,positive,positive
337605359,"@shushan2017 as far as I'm aware the most up to date version of TF is 1.4.0rc0 - I'm not aware of any 1.5 branch. You're correct that Sonnet requests the exact version 1.3.0 - we aim to track whatever version of TF is installed by `pip install tensorflow{-gpu}`. When TF 1.4.0 hits stable (ie, there is a non-release-candidate tagged version) we will update Sonnet to make that the supported version. As you've found, if you want to use the current version of Sonnet with a different version of TF you will have to hack things, and the result is unsupported.

It doesn't surprise me too much that the GPU version runs slowly - the DNC architecture is not particularly well suited to GPU, having lots of smaller Tensors that need to be operated on as opposed to larger matrix multiples / convolutions. During development of NTM / DNC we never used GPUs as there seemed to be no benefit to them. A 10x slowdown wouldn't particularly surprise me.

That said, I would expect the answers produced to be the same. When you say calculations ""don't quite seem right"", can you be more specific?

",far aware date version aware branch correct sonnet exact version aim track whatever version pip install stable ie tagged version update sonnet make version found want use current version sonnet different version hack result unsupported surprise much version slowly architecture particularly well lot smaller need opposed matrix development never used benefit slowdown would particularly surprise said would expect produced say quite seem right specific,issue,negative,positive,positive,positive,positive,positive
337425691,"After the installation of tf1.5gpu, the operation is normal, it seems to be the problem of TF, but sonnet seems to only need tf1.3 version, I forced the installation of version 1.5.
But the problem seems to come out, the code runs very slowly, 10 times slower than CPU, and the calculations don't seem quite right.
",installation operation normal problem sonnet need version forced installation version problem come code slowly time seem quite right,issue,negative,negative,neutral,neutral,negative,negative
336318648,"@malcolmreynolds Oh, it doesn't matter. Thank you very much for your attention and answer. I'll go and see.",oh matter thank much attention answer go see,issue,negative,positive,positive,positive,positive,positive
336094137,@shushan2017 Sorry for the delay - I think this is a TF issue rather than anything Sonnet-specific. This issue looks related: https://github.com/tensorflow/tensorflow/issues/3224 - can you see if the various suggestions there work for you?,sorry delay think issue rather anything issue related see various work,issue,negative,negative,negative,negative,negative,negative
335979299,"@malcolmreynolds : Yes, yes, it works. Such a way I also used to construct fuzzy neural network, however, I just forgot about it. I am sincerely appreciating your quick respond. Great company, great engineers.",yes yes work way also used construct fuzzy neural network however forgot sincerely quick respond great company great,issue,positive,positive,positive,positive,positive,positive
335769764,"Hi @mingyr 

I believe the issue is in this line in your 3rd code block:

```
self._cells = tf.nn.rnn_cell.MultiRNNCell([Cell(8)] * num_layers, state_is_tuple = True)
```

Firstly, I would recommend using snt.DeepRNN rather than mixing Sonnet and Layers. However the key problem is that you are only making one instance of `Cell`, and then referencing that `num_layers` times meaning the weights will be shared in both depth and time, which is probably not what you want. Try the following:

```
self._cells = tf.nn.rnn_cell.MultiRNNCell(
    [Cell(8, name='cell_%d' % layer_idx) for layer_idx in range(num_layers)],
    state_is_tuple=True)
```

You're now creating multiple instances of Cell, which will have different weights.

Please let me know if this fixes your problem.
            ",hi believe issue line code block cell true firstly would recommend rather sonnet however key problem making one instance cell time meaning depth time probably want try following cell range multiple cell different please let know problem,issue,negative,positive,neutral,neutral,positive,positive
331319969,"@malcolmreynolds  thanks!!!!!
My environment is： win7(64bit) Anaconda3 (64-bit) python3.6(64bit) 1080ti-card(CUDA8+CUDNN6)     tf-gpu1.3 
then i install dm-sonnet-gpu  ,and run \sonnet\examples\rnn_shakespeare.py , It works on GPU
but run dm-DNC(https://github.com/deepmind/dnc----train.py)  it is error：
An error ocurred while starting the kernel
2017???? 08:37:34.935876: W C:\tf_jenkins\home\workspace\nightly?win\M\windows?gpu\PY\36\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017???? 08:37:35.741301: I C:\tf_jenkins\home\workspace\nightly?win\M\windows?gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:955] Found device 0 with properties: 
name: GeForce GTX 1080 Ti
major: 6 minor: 1 memoryClockRate (GHz) 1.721
pciBusID 0000:04:00.0
Total memory: 11.00GiB
Free memory: 10.72GiB
2017???? 08:37:35.741301: I C:\tf_jenkins\home\workspace\nightly?win\M\windows?gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:976] DMA: 0 
2017???? 08:37:35.741301: I C:\tf_jenkins\home\workspace\nightly?win\M\windows?gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:986] 0: Y 
2017???? 08:37:35.741301: I C:\tf_jenkins\home\workspace\nightly?win\M\windows?gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) ?> (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0)
2017???? 08:37:42.907917: E C:\tf_jenkins\home\workspace\nightly?win\M\windows?gpu\PY\36\tensorflow\stream_executor\cuda\cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS
2017???? 08:37:42.907917: F C:\tf_jenkins\home\workspace\nightly?win\M\windows?gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_event_mgr.cc:203] Unexpected Event status: 1
2017???? 08:39:55.881633: W C:\tf_jenkins\home\workspace\nightly?win\M\windows?gpu\PY\36\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017???? 08:39:56.474434: I C:\tf_jenkins\home\workspace\nightly?win\M\windows?gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:955] Found device 0 with properties: 
name: GeForce GTX 1080 Ti
major: 6 minor: 1 memoryClockRate (GHz) 1.721
pciBusID 0000:04:00.0
Total memory: 11.00GiB
Free memory: 10.72GiB
2017???? 08:39:56.474434: I C:\tf_jenkins\home\workspace\nightly?win\M\windows?gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:976] DMA: 0 
2017???? 08:39:56.474434: I C:\tf_jenkins\home\workspace\nightly?win\M\windows?gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:986] 0: Y 
2017???? 08:39:56.474434: I C:\tf_jenkins\home\workspace\nightly?win\M\windows?gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) ?> (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0)
2017???? 08:40:02.511645: E C:\tf_jenkins\home\workspace\nightly?win\M\windows?gpu\PY\36\tensorflow\stream_executor\cuda\cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS
2017???? 08:40:02.511645: F C:\tf_jenkins\home\workspace\nightly?win\M\windows?gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_event_mgr.cc:203] Unexpected Event status: 1
",thanks environment win bit anaconda python bit install run work run error starting kernel library use available machine could speed found device name ti major minor total memory free memory device device name ti bus id error polling event status query event unexpected event status library use available machine could speed found device name ti major minor total memory free memory device device name ti bus id error polling event status query event unexpected event status,issue,positive,positive,positive,positive,positive,positive
331221901,"@shushan2017 We don't officially support Windows, although now that the PyPI packages don't contain any C++ (and neither does DNC) this should work. Could you post the error message you receive along with a full backtrace?",officially support although contain neither work could post error message receive along full,issue,negative,positive,positive,positive,positive,positive
328239400,"Hi, Kosklain:

Great thanks for your feedback and help. It works. I would think you have explained everything crystal clear.

By the way, I did buy several books on TensorFlow, however I would think the author are just focusing on how to use it. I just wonder could you please kindly refer me to some material or books I can get a deeper understanding of TensorFlow?  I know it is irrelevant to this thread, but if you could, I am sincerely appreciating it.

Have a nice weekend.",hi great thanks feedback help work would think everything crystal clear way buy several however would think author use wonder could please kindly refer material get understanding know irrelevant thread could sincerely nice weekend,issue,positive,positive,positive,positive,positive,positive
328237209,"Hi,

Following the code in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/device_setter.py 
your function should distinguish the `op`s  it should put on gpu and the ones it should put on cpu. For example, to put variables on cpu and all the other ops on gpu, you should be able to do the following:

```python
from tensorflow.core.framework import node_def_pb2

[...]
def device_setter(op):
  _variable_ops = [""Variable"", ""VariableV2"", ""VarHandleOp""]
  node_def = op if isinstance(op, node_def_pb2.NodeDef) else op.node_def
  return  '/cpu:0' if node_def.op in _variable_ops else '/gpu:0'
[...]   

with tf.device(device_setter):
  outputs = rcnn_output(t)
```

Please let me know if anything is unclear.",hi following code function distinguish put put example put able following python import variable else return else please let know anything unclear,issue,negative,positive,positive,positive,positive,positive
327807142,"Hi @shyamalschandra,

As @mingyr said, the code in the main `README` is there for demonstration purposes and is not runnable, and Sonnet is compatible (and in fact requires) Tensorflow 1.3.

You should not need to comment out these lines of code. Could you post more information, like the error message, version of Tensorflow, Sonnet and Python you are using?

You should be able to run the examples as regular Python scripts:

```sh
python  rnn_shakespeare.py
python  module_with_build_args.py
```

Although it is advisable that you read the code, which is a runnable demonstration on how you can work with Sonnet modules.

Note that you can also run them as Bazel binaries:

```sh
bazel run :rnn_shakespeare 
bazel run :module_with_build_args
```

which will rebuild Sonnet if needed and might be useful if you want to make modifications to the library code.
",hi said code main demonstration runnable sonnet compatible fact need comment code could post information like error message version sonnet python able run regular python sh python python although advisable read code runnable demonstration work sonnet note also run sh run run rebuild sonnet might useful want make library code,issue,positive,positive,positive,positive,positive,positive
327653723,"I would think the code train_data = get_training_data() is a demo that how you can acquire your input data, no guarantee such a function must exist and it should work.

I think  Sonnet is compatible with Tensorflow 1.3.0 since I build everything from scratch and it works fine.

For other questions, left to be answered by engineers from Deepmind. Maybe a model repo like TensorFlow could also be considered to setup for easy of use.",would think code acquire input data guarantee function must exist work think sonnet compatible since build everything scratch work fine left maybe model like could also considered setup easy use,issue,positive,positive,positive,positive,positive,positive
327347161,"Hi, Kosklain:

Sincerely appreciate your respond and your suggestion.

However, it seems still not work for me when I take your suggestion. If it is feasible, could you please give a little demo of your idea? I am not quite sure I understand it correctly and thoroughly. Great thanks.

Check the following code and pay attention to test2, the lambda works for tf.constant but not for Sonnet module:

```python
import sonnet as snt

class RCNNOutput(snt.AbstractModule):
    def __init__(self, out_size, custom_getter = None, name = ""rcnn_output""):
        super(RCNNOutput, self).__init__(custom_getter = custom_getter, name = name)
        with self._enter_variable_scope():
            bf = snt.BatchFlatten(name = ""bf"")
            fc0 = snt.Linear(output_size = 256, custom_getter = custom_getter, name = ""fc0"")
            fc1 = snt.Linear(output_size = out_size, custom_getter = custom_getter, name = ""fc1"")
            self._seq = snt.Sequential([bf, fc0, tf.nn.relu, fc1], name = ""seq"")

    def _build(self, inputs):
        return self._seq(inputs)

def test():
    import numpy as np

    def cpu_placement(getter, name, *args, **kwargs):
        with tf.device('/cpu:0'):
            return getter(name, *args, **kwargs)

    rcnn_output = RCNNOutput(4, custom_getter = cpu_placement)

    with tf.device('/cpu:0'):
        t = tf.constant(np.ones([8, 32, 32, 3]), np.float32)

    with tf.device('/gpu:0'):
        outputs = rcnn_output(t)

    writer = tf.summary.FileWriter(""rcnn_output_output"", tf.get_default_graph())

    config = tf.ConfigProto(log_device_placement = True)

    with tf.Session(config = config) as sess:
        sess.run([tf.global_variables_initializer(), tf.local_variables_initializer()])

        v = sess.run(outputs)
        print(v)

    writer.close()
def test2():
    import numpy as np

    with tf.device(lambda op: '/cpu:0'):
        rcnn_output = RCNNOutput(4)

    with tf.device(lambda op: '/gpu:0'):
        t = tf.constant(np.ones([8, 32, 32, 3]), np.float32)

    with tf.device('/gpu:0'):
        outputs = rcnn_output(t)

    writer = tf.summary.FileWriter(""rcnn_output_output"", tf.get_default_graph())

    config = tf.ConfigProto(log_device_placement = True)

    with tf.Session(config = config) as sess:
        sess.run([tf.global_variables_initializer(), tf.local_variables_initializer()])

        v = sess.run(outputs)
        print(v)

    writer.close()

if __name__ == ""__main__"":
    test2()

```",hi sincerely appreciate respond suggestion however still work take suggestion feasible could please give little idea quite sure understand correctly thoroughly great thanks check following code pay attention test lambda work sonnet module python import sonnet class self none name super self name name name name name name self return test import getter name return getter name writer true sess print test import lambda lambda writer true sess print test,issue,positive,positive,positive,positive,positive,positive
326963519,"Hey, thanks for raising this. The cleanest way to do this would be using the fact that `tf.device` accepts a `lambda`. Using that lambda you can make variables belong to cpu and the rest to gpu. An example of those kinds of lambda functions can be found at https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/device_setter.py (basically you need to distinguish between `Variable` ops and the rest). There should probably be a function like that already, (feel free to submit a PR to TF if you think that would be useful :) ).",hey thanks raising way would fact lambda lambda make belong rest example lambda found basically need distinguish variable rest probably function like already feel free submit think would useful,issue,positive,positive,positive,positive,positive,positive
326960915,Thanks for rasing this. This should no longer happen with the current installation templates. Feel free to re-open if anything else arises.,thanks longer happen current installation feel free anything else,issue,positive,positive,positive,positive,positive,positive
326777154,"Hi,
Based on the latest check in of Sonnet, I have figured out a pretty ugly way of doing it, but it is far from the solution, isn't it?

```
import tensorflow as tf
import sonnet as snt

class RCNNOutput(snt.AbstractModule):
    def __init__(self, out_size, custom_getter = None, name = ""rcnn_output""):
        super(RCNNOutput, self).__init__(custom_getter = custom_getter, name = name)
        with self._enter_variable_scope():
            bf = snt.BatchFlatten(name = ""bf"")
            fc0 = snt.Linear(output_size = 256, custom_getter = custom_getter, name = ""fc0"")
            fc1 = snt.Linear(output_size = out_size, custom_getter = custom_getter, name = ""fc1"")
            self._seq = snt.Sequential([bf, fc0, tf.nn.relu, fc1], name = ""seq"")

    def _build(self, inputs):
        return self._seq(inputs)

def test():
    import numpy as np

    def cpu_placement(getter, name, *args, **kwargs):
        with tf.device('/cpu:0'):
            return getter(name, *args, **kwargs)

    rcnn_output = RCNNOutput(4, custom_getter = cpu_placement)

    with tf.device('/cpu:0'):
        t = tf.constant(np.ones([8, 32, 32, 3]), np.float32)

    with tf.device('/gpu:0'):
        outputs = rcnn_output(t)

    writer = tf.summary.FileWriter(""rcnn_output_output"", tf.get_default_graph())

    config = tf.ConfigProto(log_device_placement = True)

    with tf.Session(config = config) as sess:
        sess.run([tf.global_variables_initializer(), tf.local_variables_initializer()])

        v = sess.run(outputs)
        print(v)

    writer.close()

if __name__ == ""__main__"":
    test()
```",hi based latest check sonnet figured pretty ugly way far solution import import sonnet class self none name super self name name name name name name self return test import getter name return getter name writer true sess print test,issue,negative,positive,positive,positive,positive,positive
326266825,"Merged in 72a5676e670d02f4025fbcfe64b855583ee82079.
Sorry for taking so long, but we had to delay version 1.11 to adapt the code for Tensorflow 1.3. 
",sorry taking long delay version adapt code,issue,negative,negative,negative,negative,negative,negative
324472841,"@EnricoBeltramo if you have trouble building from source, the next version we release will have no C++ inside the wheel file, so should be easily installable on Windows. Most likely ETA is next week sometime.",trouble building source next version release inside wheel file easily likely eta next week sometime,issue,negative,negative,neutral,neutral,negative,negative
324472434,Thank you very much: I'll try to build from source,thank much try build source,issue,negative,positive,positive,positive,positive,positive
324041594,"Hello @dekked, thanks for spotting this!
We will merge this internally and your name should be in the proper commit in the next version we push.",hello thanks spotting merge internally name proper commit next version push,issue,positive,positive,neutral,neutral,positive,positive
323928057,"The prompt error is
```
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
E:\Anaconda3\lib\site-packages\tensorflow\python\client\session.py in _do_call(self, fn, *args)
   1326     try:
-> 1327       return fn(*args)
   1328     except errors.OpError as e:

E:\Anaconda3\lib\site-packages\tensorflow\python\client\session.py in _run_fn(session, feed_dict, fetch_list, target_list, options, run_metadata)
   1305                                    feed_dict, fetch_list, target_list,
-> 1306                                    status, run_metadata)
   1307 

E:\Anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback)
     88             try:
---> 89                 next(self.gen)
     90             except StopIteration:

E:\Anaconda3\lib\site-packages\tensorflow\python\framework\errors_impl.py in raise_exception_on_not_ok_status()
    465           compat.as_text(pywrap_tensorflow.TF_Message(status)),
--> 466           pywrap_tensorflow.TF_GetCode(status))
    467   finally:

InvalidArgumentError: The node 'Sum' has inputs from different frames. The input 'Sum/input' is in frame 'rnn/while/act_core/while/rnn/while/act_core/while/'. The input 'range' is in frame ''.

During handling of the above exception, another exception occurred:

InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-1-82ae56723932> in <module>()
    131 a = test()
    132 
--> 133 a.fit(batch_x, batch_y)

<ipython-input-1-82ae56723932> in fit(self, x, y)
    121             sess.run(tf.global_variables_initializer())
    122             for i in np.arange(10):
--> 123                 _,a = sess.run([self._train_step, self._cost], feed_dict={self._inputs: x, self._targets: y})
    124                 print (a)
    125 

E:\Anaconda3\lib\site-packages\tensorflow\python\client\session.py in run(self, fetches, feed_dict, options, run_metadata)
    893     try:
    894       result = self._run(None, fetches, feed_dict, options_ptr,
--> 895                          run_metadata_ptr)
    896       if run_metadata:
    897         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

E:\Anaconda3\lib\site-packages\tensorflow\python\client\session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)
   1122     if final_fetches or final_targets or (handle and feed_dict_tensor):
   1123       results = self._do_run(handle, final_targets, final_fetches,
-> 1124                              feed_dict_tensor, options, run_metadata)
   1125     else:
   1126       results = []

E:\Anaconda3\lib\site-packages\tensorflow\python\client\session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)
   1319     if handle is None:
   1320       return self._do_call(_run_fn, self._session, feeds, fetches, targets,
-> 1321                            options, run_metadata)
   1322     else:
   1323       return self._do_call(_prun_fn, self._session, handle, feeds, fetches)

E:\Anaconda3\lib\site-packages\tensorflow\python\client\session.py in _do_call(self, fn, *args)
   1338         except KeyError:
   1339           pass
-> 1340       raise type(e)(node_def, op, message)
   1341 
   1342   def _extend_graph(self):

InvalidArgumentError: The node 'Sum' has inputs from different frames. The input 'Sum/input' is in frame 'rnn/while/act_core/while/rnn/while/act_core/while/'. The input 'range' is in frame ''.
```",prompt error recent call last self try return except session status self type value try next except status status finally node different input frame input frame handling exception another exception recent call last ae module test ae fit self print run self try result none self handle handle handle else self handle handle none return else return handle self except pas raise type message self node different input frame input frame,issue,negative,positive,neutral,neutral,positive,positive
323927244,"This is the original file I encountered the wrong
```python
import numpy as np
import pandas as pd
import datetime
import talib 
import matplotlib.pylab as plt
import seaborn as sns
% matplotlib inline

import tensorflow as tf
from sonnet.python.modules.base import AbstractModule
from sonnet.python.modules.basic import BatchApply, Linear, BatchFlatten
from sonnet.python.modules.rnn_core import RNNCore
from sonnet.python.modules.gated_rnn import LSTM
from sonnet.python.modules.basic_rnn import DeepRNN
from sonnet.python.modules.pondering_rnn import ACTCore

from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets(""MNIST_data/"", one_hot=True)


batch_size = 20
n_steps = 28
n_input = 28
out_classes = 10
hidden_size = 10
threshold = 0.99
pondering_coefficient = 0.1

batch_x, batch_y = mnist.train.next_batch(batch_size)
batch_x = batch_x.reshape((batch_size, n_steps, n_input))

batch_x = np.transpose(batch_x, axes=[1,0,2])

from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets(""MNIST_data/"", one_hot=True)


batch_size = 20
n_steps = 28
n_input = 28
out_classes = 10
hidden_size = 10
threshold = 0.99
pondering_coefficient = 0.1

batch_x, batch_y = mnist.train.next_batch(batch_size)
batch_x = batch_x.reshape((batch_size, n_steps, n_input))

batch_x = np.transpose(batch_x, axes=[1,0,2])

class test(object):
    
    def __init__(self,
                batch_size = 20,
                n_steps = 28,
                n_input = 28,
                out_classes = 10,
                hidden_size = 10,
                threshold = 0.99,
                pondering_coefficient = 0.1,
                max_gard_norm = 50,
                learning_rate = 1e-4,
                optimizer_epsilon = 1e-10,
                 
                ):
        self._inputs = tf.placeholder(
            dtype=tf.float32, shape=[n_steps, batch_size, n_input], name='inputs')

        self._targets = tf.placeholder(
            dtype=tf.float32, shape=[batch_size, out_classes], name='targets')

        initializer = {'b_gates':tf.truncated_normal_initializer(stddev=1.0), 
                       'w_gates':tf.truncated_normal_initializer(stddev=1.0)}
        regularizer = {'b_gates':tf.contrib.layers.l2_regularizer(0.1), 
                       'w_gates':tf.contrib.layers.l2_regularizer(0.1)}

        act_core = LSTM(hidden_size, regularizers=regularizer, initializers=initializer)
        
        controller = ACTCore(
            core=act_core, 
            output_size=out_classes, 
            threshold=threshold, 
            get_state_for_halting=self._get_hidden_state)

        initial_state = controller.initial_state(batch_size)

        tmp, act_final_cumul_state = \
        tf.nn.dynamic_rnn(cell=controller, 
                          inputs=self._inputs, 
                          initial_state=initial_state, 
                          time_major=True)
        act_output, (act_final_iteration, act_final_remainder) = tmp

        final_output = act_output[-1,:,:]

        regularization_loss = tf.reduce_sum(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))
        pondering_cost = (act_final_iteration + act_final_remainder) * pondering_coefficient
        rnn_cost = tf.nn.softmax_cross_entropy_with_logits(labels=self._targets, logits=final_output)

        self._cost = tf.reduce_mean(rnn_cost) + \
        tf.reduce_mean(pondering_cost) + tf.reduce_mean(regularization_loss)
        
        # Set up optimizer with global norm clipping.
        trainable_variables = tf.trainable_variables()
        grads, _ = tf.clip_by_global_norm(
            tf.gradients(self._cost, trainable_variables), max_gard_norm)
        global_step = tf.get_variable(
            name=""global_step"",
            shape=[],
            dtype=tf.int64,
            initializer=tf.zeros_initializer(),
            trainable=False,
            collections=[tf.GraphKeys.GLOBAL_VARIABLES, tf.GraphKeys.GLOBAL_STEP])
        
        optimizer = tf.train.RMSPropOptimizer(
            learning_rate=learning_rate, epsilon=optimizer_epsilon)
        self._train_step = optimizer.apply_gradients(
            zip(grads, trainable_variables), global_step=global_step)   
        

    def fit(self, x, y):
        with tf.Session() as sess:
            sess.run(tf.global_variables_initializer())
            for i in np.arange(10):
                _,a = sess.run([self._train_step, self._cost], feed_dict={self._inputs: x, self._targets: y})
                print (a)

    def _get_hidden_state(self, state):
        next_hidden, next_cell = state
        return next_hidden

#tf.reset_default_graph()
a = test()

a.fit(batch_x, batch_y)
```",original file wrong python import import import import import import import import import linear import import import import import threshold import threshold class test object self threshold regularizer controller set global norm clipping zip fit self sess print self state state return test,issue,negative,positive,neutral,neutral,positive,positive
323909854,"I signed it!

On Tue, Aug 22, 2017 at 12:31 AM googlebot <notifications@github.com> wrote:

> Thanks for your pull request. It looks like this may be your first
> contribution to a Google open source project. Before we can look at your
> pull request, you'll need to sign a Contributor License Agreement (CLA).
>
> 📝 *Please visit https://cla.developers.google.com/
> <https://cla.developers.google.com/> to sign.*
>
> Once you've signed, please reply here (e.g. I signed it!) and we'll
> verify. Thanks.
> ------------------------------
>
>    - If you've already signed a CLA, it's possible we don't have your
>    GitHub username or you're using a different email address. Check your
>    existing CLA data <https://cla.developers.google.com/clas> and verify
>    that your email is set on your git commits
>    <https://help.github.com/articles/setting-your-email-in-git/>.
>    - If your company signed a CLA, they designated a Point of Contact who
>    decides which employees are authorized to participate. You may need to
>    contact the Point of Contact for your company and ask to be added to the
>    group of authorized contributors. If you don't know who your Point of
>    Contact is, direct the project maintainer to go/cla#troubleshoot.
>    - In order to pass this check, please resolve this problem and have
>    the pull request author add another comment and the bot will run again.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/deepmind/sonnet/pull/60#issuecomment-323909552>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/ABhGr4TU20MZ4fJlrDFjTkoV951UgLvRks5sakuTgaJpZM4O-Eno>
> .
>
",tue wrote thanks pull request like may first contribution open source project look pull request need sign contributor license agreement memo please visit sign please reply verify thanks already possible different address check data verify set git company point contact authorized participate may need contact point contact company ask added group authorized know point contact direct project maintainer order pas check please resolve problem pull request author add another comment bot run thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
323909552,"Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

:memo: **Please visit <https://cla.developers.google.com/> to sign.**

Once you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.

---

- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).
- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.
- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.

<!-- need_sender_cla -->",thanks pull request like may first contribution open source project look pull request need sign contributor license agreement memo please visit sign please reply verify thanks already possible different address check data verify set git company point contact authorized participate may need contact point contact company ask added group authorized know point contact direct project maintainer order pas check please resolve problem pull request author add another comment bot run,issue,positive,positive,positive,positive,positive,positive
323746497,"Hello @AlphaSmartDog,
Can you give us a running version of the code raising this error?
It can be either the rest of the code from which you extracted this sample, or a minimal reproducible example if possible.",hello give u running version code raising error either rest code extracted sample minimal reproducible example possible,issue,negative,negative,neutral,neutral,negative,negative
323120124,"Closing this, we have been pushing binary builds & making GH tags for a little while now.",pushing binary making little,issue,negative,negative,negative,negative,negative,negative
322838319,"Hi @EnricoBeltramo, 
Windows is currently not supported, but you can try building Sonnet from source following our [installing from source](https://deepmind.github.io/sonnet/#installing-from-source) instructions.  Note that you will probably need to adapt the commands to make them work on Windows, though.",hi currently try building sonnet source following source note probably need adapt make work though,issue,negative,neutral,neutral,neutral,neutral,neutral
322544613,"@malcolmreynolds: Great!
By the way, I was on linux like @auroua. I'm glad to see this issue is resolved!",great way like glad see issue resolved,issue,positive,positive,positive,positive,positive,positive
322287174,"@leesunfreshing Hi, we don't have anything seq2seq specific in Sonnet. The RNN cores we have should be compatible with the TF RNN containers (eg tf.nn.dynamic_rnn) so I imagine using a sonnet module will work... As far as I can see only the decoder is provided because you need to be feeding the decoder always with the output of the previous timestep, and there is also the opportunity to do beam search which requires extra code. For the encoder, you simply feed your sequence into a (different) RNN in the standard way (tf.nn.dynamic_rnn), ignore the output sequence and then use the final hidden state as the input to the decoder. I'm not an expert on seq2seq, but I believe this is why they didn't provide any special code for the encoder.

If you have further questions on this I suggest filing an issue on the main TF GitHub.",hi anything specific sonnet compatible imagine sonnet module work far see provided need feeding always output previous also opportunity beam search extra code simply feed sequence different standard way ignore output sequence use final hidden state input expert believe provide special code suggest filing issue main,issue,negative,positive,neutral,neutral,positive,positive
322245632,"The warning should be fixed now, thanks for pointing that out.",warning fixed thanks pointing,issue,negative,positive,positive,positive,positive,positive
321284062,"The PyPI packages are only built for python 2.7 and 3.4... I'll look into providing packages for 3.{5,6} as well.",built python look providing well,issue,negative,neutral,neutral,neutral,neutral,neutral
321277673,"Encounter the same problem. 
os: Ubuntu 16.04
python: 3.5.2",encounter problem o python,issue,negative,neutral,neutral,neutral,neutral,neutral
321216747,"Are you on Mac or Linux? We only provide pre built wheels for the GPU version in Linux, as there are no official tensorflow-gpu packages for Mac & GPU.",mac provide built version official mac,issue,negative,neutral,neutral,neutral,neutral,neutral
319373480,Can you try to run the build with the additional flag `--bazelrc=tensorflow/tools/bazel.rc`?,try run build additional flag,issue,negative,neutral,neutral,neutral,neutral,neutral
319368854,@afhuertass Can you try installing the pip package (either 'dm-sonnet' or 'dm-sonnet-gpu') ?,try pip package either,issue,negative,neutral,neutral,neutral,neutral,neutral
319367289,Closing this issue as everyone in the thread seems to have the situation resolved. Please reopen if necessary.,issue everyone thread situation resolved please reopen necessary,issue,negative,neutral,neutral,neutral,neutral,neutral
319314476,"oh, I forgot I shift to tf1.1 for another project.

sure, it works well with tf1.2",oh forgot shift another project sure work well,issue,positive,positive,positive,positive,positive,positive
319310745,"Could you please run the following command that prints the TF version and report the output here?

`$ python -c 'import tensorflow as tf; print(tf.__version__)'`",could please run following command version report output python print,issue,negative,neutral,neutral,neutral,neutral,neutral
319275454,"more seriously, even I build the *.whl package from source for Mac, I still got:

$ python train.py 
Traceback (most recent call last):
  File ""train.py"", line 22, in <module>
    import sonnet as snt
  File ""/Library/Python/2.7/site-packages/sonnet/__init__.py"", line 126, in <module>
    from sonnet.python.ops.resampler import resampler
  File ""/Library/Python/2.7/site-packages/sonnet/python/ops/resampler.py"", line 33, in <module>
    tf.resource_loader.get_path_to_datafile(""_resampler.so""))
  File ""/Library/Python/2.7/site-packages/tensorflow/python/framework/load_library.py"", line 64, in load_op_library
    None, None, error_msg, error_code)
tensorflow.python.framework.errors_impl.NotFoundError: dlopen(/Library/Python/2.7/site-packages/sonnet/python/ops/_resampler.so, 6): Symbol not found: __ZN10tensorflow15shape_inference16InferenceContext15WithRankAtLeastENS0_11ShapeHandleExPS2_
  Referenced from: /Library/Python/2.7/site-packages/sonnet/python/ops/_resampler.so
  Expected in: flat namespace
 in /Library/Python/2.7/site-packages/sonnet/python/ops/_resampler.so
$ ",seriously even build package source mac still got python recent call last file line module import sonnet file line module import file line module file line none none symbol found flat,issue,negative,negative,neutral,neutral,negative,negative
319255774,"but I also got the same issue as 

Mac install fails #29
Open
I herd results build from source but that could be more problems #42
Open
_resampler.so: undefined symbol #25
",also got issue mac install open herd build source could open undefined symbol,issue,negative,neutral,neutral,neutral,neutral,neutral
319253916,"works well with dnc project,thanks",work well project thanks,issue,positive,positive,positive,positive,positive,positive
319149378,Anyone still having trouble - please see https://github.com/deepmind/sonnet/issues/56 - there are preliminary Wheel files available on PyPI. Please try to install and let us know how you get on.,anyone still trouble please see preliminary wheel available please try install let u know get,issue,negative,positive,neutral,neutral,positive,positive
319148963,Hi @josheeg  - please see https://github.com/deepmind/sonnet/issues/56 - there are preliminary Wheel files available on PyPI. Please try to install using that and let us know how you get on.,hi please see preliminary wheel available please try install let u know get,issue,positive,positive,positive,positive,positive,positive
319146623,"Hi @loveJasmine - we've got some preliminary wheel files up on PyPI as of today. The package names are ""dm-sonnet"" or ""dm-sonnet-gpu"" depending on whether you have tensorflow or tensorflow-gpu installed.

We will change the readme next week to indicate that is the recommended installation procedure, but in the meantime could you try `pip install dm-sonnet` or `pip install dm-sonnet-gpu` and let us know how you get on.",hi got preliminary wheel today package depending whether change next week indicate installation procedure could try pip install pip install let u know get,issue,negative,neutral,neutral,neutral,neutral,neutral
319137304,"Hi @Shuolongbj , thanks for flagging this!
In order to accept your PR, we need you to do a couple of things:
- Remove the ""#if you installed v1.6 already"" comment and the old uninstallation method, since it is now incorrect.
- Remove the changes that update the WORKSPACE file. We only support _stable_ Tensorflow releases, so we won't update our submodule pointer until version `1.3.0` is released (Tensorflow's most current tag in the `r1.3` branch is `v1.3.0-rc1`, and the `rc1` suffix means it is a _release candidate_, not a stable release).
- Rebase your branch to our most current commit (pushed today, 2017-07-31).
- Squash your branch to a single commit with a message stating that this commit corrects the installation instructions.
",hi thanks flagging order accept need couple remove already comment old method since incorrect remove update file support wo update pointer version current tag branch suffix stable release rebase branch current commit today squash branch single commit message commit installation,issue,positive,positive,neutral,neutral,positive,positive
317845468,"@malcolmreynolds and @fastturtle, thank you guys for your explanations and for making me understand why it wouldn't be necessarily an undesirable behavior. I can't think of a different solution and mostly it seems that this is the desired visualization. I appreciate your time.
",thank making understand would necessarily undesirable behavior ca think different solution mostly desired visualization appreciate time,issue,positive,positive,positive,positive,positive,positive
317693052,"Thanks for bringing this to our attention. The issue here is that `_enter_variable_scope()` enters a `tf.variable_scope()`, which creates a name scope. This ultimately [increments the counter](url) the `tf.Graph` object uses to uniquify name scopes. The result is that if you use `_enter_variable_scope()` to define variables inside `__init__`, then when  `_build()` is called for the first time the name scope has ""_1"" appended to it.

This is common behavior in TensorFlow and occurs when variables are created before they are used, for example:
```python
with tf.variable_scope(""scope""):
  v = tf.get_variable(""v"", shape=[])
  
with tf.variable_scope(""scope"", reuse=True):
  # We have now entered the name_scope ""scope_1""
  x = v * 2
```

![image](https://user-images.githubusercontent.com/1386091/28566343-c74ae8fc-7126-11e7-8582-3e9996099640.png)

It sounds like you want  to enter a variable scope _without_ entering a name scope. I would advise against this, because it can lead to even weirder graphs (what happens if you accidentally create an Op?) and isn't possible with public TensorFlow functions. Did you have a different solution in mind?",thanks attention issue name scope ultimately counter object name result use define inside first time name scope common behavior used example python scope scope image like want enter variable scope entering name scope would advise lead even accidentally create possible public different solution mind,issue,positive,positive,neutral,neutral,positive,positive
317557787,"@vierja The reason for the discrepancy is that _enter_variable_scope vs defining submodules in _build only unifies the variable_scopes entered, meaning that the variables have the same name whichever way round you do it. However, every time you enter the variable_scope you get a new name scope which will be uniquified if necessary by adding _N. The Tensorboard graph visualises namescopes, rather than variable scopes per se, although there is obviously overlap.

In your second example, the variables (and the ops associated with them - read, assign, init etc) are inside the first time you enter name_scope, which is `main_module` at the bottom. When you call _build, you reenter a name_scope with the same name and TF uniquifies it to `main_module_1`, and you see the add and matmul inside the smaller block up top. If you connect the module a second time you would get another small block, `main_module_2`, with again just a Matmul and Add inside. Similarly, if you connect the module a second as you have it written in the first module, you also get a second block as the name_scope is entered a second time.

I don't think it's possible to change this name_scope behaviour without some hacking of TF, and I don't think that would necessarily be desirable - when connecting modules multiple times you probably want that to show as separate name_scopes in Tensorboard. Otherwise, a module shared lots of times would end up looking extremely confusing as all the input / output connections go through one block.

I hope this explanation helps - please let me know if you have other comments or questions.


",reason discrepancy meaning name whichever way round however every time enter get new name scope necessary graph rather variable per se although obviously overlap second example associated read assign inside first time enter bottom call name see add inside smaller block top connect module second time would get another small block add inside similarly connect module second written first module also get second block second time think possible change behaviour without hacking think would necessarily desirable multiple time probably want show separate otherwise module lot time would end looking extremely input output go one block hope explanation please let know,issue,negative,positive,neutral,neutral,positive,positive
317121797,@guillaume-chevalier Thanks for your contribution - we will merge this internally and it should be in the version we push to GitHub next week.,thanks contribution merge internally version push next week,issue,negative,positive,neutral,neutral,positive,positive
317097437,"(To be precise, my current employer signed the corporate CLA, so he added me to a Google Group containing my email to allow me to contribute)",precise current employer corporate added group allow contribute,issue,negative,positive,positive,positive,positive,positive
316731313,"@diegolascasas 
Submitted the file consistent to the latest r1.3,please refer to as you update Tensorflow submodule to 1.3.
FYI.
https://github.com/tensorflow/tensorflow/blob/r1.3/WORKSPACE

",file consistent latest please refer update,issue,negative,positive,positive,positive,positive,positive
316220120,"@Shuolongbj you mean changing the docs or change sonnet in order to behave the same way for both examples? The latter I'm not sure how to do, any insight is much appreciated.",mean change sonnet order behave way latter sure insight much,issue,negative,positive,neutral,neutral,positive,positive
316147201,"Yes, thanks for the clarification.
However, we avoid updating the submodule so it always points to the commit that was tagged with the release version (i.e.[12f033d](https://github.com/tensorflow/tensorflow/tree/12f033df4c8fa3feb88ce936eb1581eaa92b303e)). If you go to that commit you'll see that `io_basel_rules_closure` was not yet updated. 

When Tensorflow 1.3 is released, we will either remove or update the submodule pointer.",yes thanks clarification however avoid always commit tagged release version go commit see yet either remove update pointer,issue,positive,positive,positive,positive,positive,positive
315613636,"@diegolascasas 
1、Keep updated with TensorFlow.
FYI.
https://github.com/tensorflow/tensorflow/blob/master/WORKSPACE

2、Look forward to your more efficient approach

> Although we might even remove this workaround altogether.",forward efficient approach although might even remove altogether,issue,negative,neutral,neutral,neutral,neutral,neutral
315610339,"Hi @Shuolongbj, any particular reason for this PR?

The commit in Tensorflow's repository we're pointing to still has the old hash (4be...). When we update the submodule's head (maybe when v1.3 is released) we will also update the hash. Although we might even remove this workaround altogether.",hi particular reason commit repository pointing still old hash update head maybe also update hash although might even remove altogether,issue,negative,positive,positive,positive,positive,positive
315600681,"Hi @afhuertass,

Sonnet should be using the version of tensorflow you installed with pip. 

Do you get only CPU devices when you run a session with device placement being logged?
([see here](https://www.tensorflow.org/tutorials/using_gpu))

And do you get GPU devices when you run tensorflow ops without Sonnet?",hi sonnet version pip get run session device placement logged see get run without sonnet,issue,negative,neutral,neutral,neutral,neutral,neutral
315127519,"I'm not 100% sure, but I think variable sharing would fail (since it's creating a new variable each time), but I'd want to check that first :)

It's certainly possible that something in TF-slim caused this, it might not always interact well with Sonnet, though I think that also uses tf.get_variable.",sure think variable would fail since new variable time want check first certainly possible something might always interact well sonnet though think also,issue,negative,positive,neutral,neutral,positive,positive
315118682,"@tfgg Thanks for the clarification and the example! I must have missed that bit in the docs. I'm not creating any variables directly so it's probably down to some TF slim utils.

Besides being kind of annoying, does this behaviour cause any unwanted effects on the computation?

Closing the issue, thanks!.",thanks clarification example must bit directly probably slim besides kind annoying behaviour cause unwanted effect computation issue thanks,issue,positive,positive,neutral,neutral,positive,positive
315025874,"Thanks for the report and clear example. It looks like it's because the variables were created with tf.Variable rather than tf.get_variable, this is known to interact poorly with variable scopes. It's [mentioned in the docs](https://deepmind.github.io/sonnet/#implement-build-method) but might be a bit buried.

Here's my code:
https://gist.github.com/tfgg/d815ec514697a16bc1067acdbb6f0e1f
which outputs
```
[u'main_module/submodule_a/a:0', u'main_module/submodule_b/b:0']
[u'main_module/submodule_a/a:0', u'main_module/submodule_b/b:0']
```
",thanks report clear example like rather known interact poorly variable might bit buried code,issue,positive,negative,neutral,neutral,negative,negative
314842915,"@Shuolongbj  Hi, i make Sonnet work on google Cloud after a while, i did it by compiling the library on my machine, upload the wheel file to Google Cloud Storage, and specifying the --package option when uploading the job. 

After a while I came to realize that the trainign was going slow, so I started to think that the gpu was not being used. what i think,  needs to be done is recompiling the sonnet library against a GPU supported Tensorflow, and it maybe work fine in that case.

Thanks for your answer. :) 
",hi make sonnet work cloud library machine wheel file cloud storage package option job came realize going slow think used think need done sonnet library maybe work fine case thanks answer,issue,positive,positive,positive,positive,positive,positive
314716800,"FYI.
Google Cloud ML Engine already has an optimized and GPU-enabled TensorFlow version installed.  you could remove the tensorflow line from setup.py to make it work,or the GPU not being used if you download the CPU-only tensorflow package from PyPI and shadowing the existing TensorFlow installation.",cloud engine already version could remove line make work used package shadowing installation,issue,negative,neutral,neutral,neutral,neutral,neutral
314470148,"@PFCM Cool! I have installed sonnet almost 10 times, all failed, untill now. thank you. ",cool sonnet almost time untill thank,issue,positive,positive,positive,positive,positive,positive
312915952,"@githuboml thanks for the suggestion - this is now fixed in our internal repository, and will be part of the version we push to GitHub next week.",thanks suggestion fixed internal repository part version push next week,issue,negative,positive,neutral,neutral,positive,positive
311494542,"I missed the update and was trying to use the docs for the newer version, my mistake.

Thanks for the help!",update trying use version mistake thanks help,issue,negative,positive,positive,positive,positive,positive
311487890,"Hi jontoto,

`reuse_variables` was recently moved from `experimental` to `utils`.
Can you provide a bit more context on how you are getting this error?
Maybe a reproducible code snippet or a stack trace.
Also, can you confirm you are using version 1.3?",hi recently experimental provide bit context getting error maybe reproducible code snippet stack trace also confirm version,issue,negative,positive,neutral,neutral,positive,positive
311364271,Closed due to inactivity. Please reopen if the solution doesn't solve your problem.,closed due inactivity please reopen solution solve problem,issue,negative,negative,negative,negative,negative,negative
311136897,"@guillaume-chevalier it turned out to be easier than I thought it would be:
`sed -i 's/python /python3 /' bazel-bin/install`
`./bazel-bin/install /tmp/sonnet`
`pip3 install /tmp/sonnet/*.whl`

Tested and working in Python 3.5.2.",turned easier thought would pip install tested working python,issue,negative,neutral,neutral,neutral,neutral,neutral
311122570,"Thank you, Shuolongbj. Fortuneately, your post revealed one slight mishap, and I remembered another. My only errors were I did not checkout r1.2 in tensorflow (I instead checked out master), and when I did the configure files for bazel in Tensorflow, I realize I called the opt flags as command line arguments, rather than specify them in the configure file of tensorflow. This potentially desynchronized the Tensorflow and Sonnet configurations and probably resulted in the error. I can confirm that sonnet 1.2 installs successfully on mac with Tensorflow 1.2.0.

I added these flags as they are when the tensorflow configure file asks for optimizatoin flags to optimize my build for my mac (this is for my personal machine, these flags may no apply specifically to your machine. Note the syntax though '-m[flag]'):
`-mavx -mavx2 -mfma -msse4.2`",thank post revealed one slight mishap another instead checked master configure realize opt command line rather specify configure file potentially sonnet probably error confirm sonnet successfully mac added configure file optimize build mac personal machine may apply specifically machine note syntax though flag,issue,positive,positive,positive,positive,positive,positive
310896610,@malcolmreynolds Could you also tag the git commit with that version and/or cut a release on GH?,could also tag git commit version cut release,issue,negative,neutral,neutral,neutral,neutral,neutral
310882308,"FYI.
cd sonnet/tensorflow
git checkout r1.2
./configure
bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package
bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg
pip uninstall tensorflow
pip install /tmp/tensorflow_pkg/tensorflow-1.2.0-cp36-cp36m-macosx_10_7_x86_64.whl
cd ../
bazel build --config=opt //:install
bazel-bin/install /tmp/sonnet_pkg
pip uninstall sonnet
pip install /tmp/sonnet_pkg/sonnet-1.2-py3-none-any.whl


",git build pip pip install build install pip sonnet pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
310865948,"oh hi @hannes-brt  ! i'm having the same problem tryin to use Sonnet for a Google Cloud Ml , i try to upload a wheel i build in my PC ( running ubuntu 16.04 ) and use the --package option on the gcloud command to install it, but i get this error when i try to run the job:

	NotFoundError: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.21' not found (required by /root/.local/lib/python2.7/site-packages/sonnet/python/ops/_resampler.so)

Any hints? Thanks in advance",oh hi problem use sonnet cloud try wheel build running use package option command install get error try run job version found thanks advance,issue,negative,positive,positive,positive,positive,positive
310697951,"I get the same error as alshedivat's latest post, but for the latest version of sonnet with latest version of tensorflow installed. I am on Mac OSX 10.12.5. I reinstalled tensorflow from sonnet's recursive git repository of tensorflow (1.2) and it works fine. I then installed sonnet as described in README, but this is what I get. I am outside of install directory. This is with most recent sonnet and sonnet's tensorflow, I did this last night. I'd love to get this working. Should this be a separate issue, or should we try to recreate these errors on more systems for a better consensus?

```
>>> import sonnet as snt
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/Users/dsp/virtualenv/tf/lib/python2.7/site-packages/sonnet/__init__.py"", line 111, in <module>
    from sonnet.python.ops.resampler import resampler
  File ""/Users/dsp/virtualenv/tf/lib/python2.7/site-packages/sonnet/python/ops/resampler.py"", line 33, in <module>
    tf.resource_loader.get_path_to_datafile(""_resampler.so""))
  File ""/Users/dsp/virtualenv/tf/lib/python2.7/site-packages/tensorflow/python/framework/load_library.py"", line 64, in load_op_library
    None, None, error_msg, error_code)
tensorflow.python.framework.errors_impl.NotFoundError: dlopen(/Users/dsp/virtualenv/tf/lib/python2.7/site-packages/sonnet/python/ops/_resampler.so, 6): Symbol not found: __ZN10tensorflow14TensorShapeRep12SlowCopyFromERKS0_
  Referenced from: /Users/dsp/virtualenv/tf/lib/python2.7/site-packages/sonnet/python/ops/_resampler.so
  Expected in: flat namespace
 in /Users/dsp/virtualenv/tf/lib/python2.7/site-packages/sonnet/python/ops/_resampler.so
```",get error latest post latest version sonnet latest version mac sonnet recursive git repository work fine sonnet get outside install directory recent sonnet sonnet last night love get working separate issue try recreate better consensus import sonnet recent call last file line module file line module import file line module file line none none symbol found flat,issue,positive,positive,positive,positive,positive,positive
310461717,"@malcolmreynolds Thanks, it works now with TF 1.2.0, but seems to be backwards incompatible (as mentioned in the comment above). If I use TF < 1.2.0, I get the following error:

```
$ python
Python 3.5.2 (default, Jun  6 2017, 00:26:23)
[GCC 4.2.1 Compatible Apple LLVM 8.1.0 (clang-802.0.42)] on darwin
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import sonnet
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/Users/maruan/.pyenv/versions/venv3.5/lib/python3.5/site-packages/sonnet/__init__.py"", line 111, in <module>
    from sonnet.python.ops.resampler import resampler
  File ""/Users/maruan/.pyenv/versions/venv3.5/lib/python3.5/site-packages/sonnet/python/ops/resampler.py"", line 33, in <module>
    tf.resource_loader.get_path_to_datafile(""_resampler.so""))
  File ""/Users/maruan/.pyenv/versions/venv3.5/lib/python3.5/site-packages/tensorflow/python/framework/load_library.py"", line 64, in load_op_library
    None, None, error_msg, error_code)
tensorflow.python.framework.errors_impl.NotFoundError: dlopen(/Users/maruan/.pyenv/versions/venv3.5/lib/python3.5/site-packages/sonnet/python/ops/_resampler.so, 6): Symbol not found: __ZN10tensorflow15shape_inference16InferenceContext15WithRankAtLeastENS0_11ShapeHandleExPS2_
  Referenced from: /Users/maruan/.pyenv/versions/venv3.5/lib/python3.5/site-packages/sonnet/python/ops/_resampler.so
  Expected in: flat namespace
 in /Users/maruan/.pyenv/versions/venv3.5/lib/python3.5/site-packages/sonnet/python/ops/_resampler.so
```

I am not sure if there is an easy workaround, but you may want to mention in the readme that the current version supports only the latest TF release and update `setup.py`. Hope this helps.",thanks work backwards incompatible comment use get following error python python default compatible apple type help copyright license information import sonnet recent call last file line module file line module import file line module file line none none symbol found flat sure easy may want mention current version latest release update hope,issue,positive,positive,positive,positive,positive,positive
310275294,It looks like the latest version fixed this. Closing.,like latest version fixed,issue,negative,positive,positive,positive,positive,positive
310200540,"Compiling against newer headers solves the problem though the same issue occurs when TF is outdated (i.e., < 1.2.0).",problem though issue outdated,issue,negative,negative,negative,negative,negative,negative
308388714,"Hi @leesunfreshing,
Can you pull the recent changes and check whether the issue persists?
`snt.Conv1DLSTM`, `snt.Conv1DLSTM` and `snt.python.modules.gated_rnn.ConvLSTM` should be available.",hi pull recent check whether issue available,issue,negative,positive,positive,positive,positive,positive
308118604,Glad you got it working - we will update the build instructions.,glad got working update build,issue,negative,positive,positive,positive,positive,positive
308118523,"@josheeg thanks for your interest. To clarify, Sonnet is a higher level framework on top on TensorFlow, so device assignments like OpenCL or FPGA are orthogonal to what Sonnet lets you do. If and when they are supported by TensorFlow, you will be able to use Sonnet modules (containing supported ops) on those devices.

We don't have the engineering bandwidth currently to produce anything like video tutorials (no one works on Sonnet full time, it's all best-effort by people who are primarily on other projects). The rnn_shakespeare example is intended to showcase some of the main features. We'll look into providing more in the future.",thanks interest clarify sonnet higher level framework top device like orthogonal sonnet able use sonnet engineering currently produce anything like video one work sonnet full time people primarily example intended showcase main look providing future,issue,positive,positive,positive,positive,positive,positive
308114217,@hannes-brt we've added a changelog and have started bumping version numbers (currently it's 1.1). Wheel files & PyPI will follow soon.,added bumping version currently wheel follow soon,issue,negative,neutral,neutral,neutral,neutral,neutral
307473182,"How should one build Sonnet for Python 3? 

I tried to set the TensorFlow headers for Python 3, and it compiles... however the result of the compilation is a `.whl` wheel file that is only compatible with Python 2. 

Surprisingly, the wheel works correctly in Python 2 after a pip install, despite the tf headers config. But, how to compile explicitly for Python 3 and pip3? With pip3, it says that it is ""not a supported wheel on this platform.""",one build sonnet python tried set python however result compilation wheel file compatible python surprisingly wheel work correctly python pip install despite compile explicitly python pip pip wheel platform,issue,negative,positive,positive,positive,positive,positive
305955423,"The

بتاريخ ٢٥‏/٠٥‏/٢٠١٧ ٨:٣٦ م، كتب ""Adrià Puigdomènech"" <
notifications@github.com>:

> @edrozenberg <https://github.com/edrozenberg> yes, I agree with you. As
> mentioned, we would not want users to be forced to compile tensorflow, but
> by no means this implies we will force such users to use pre-compiled
> binaries, both things should just be available as options.
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/deepmind/sonnet/issues/5#issuecomment-304072809>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/AReUWU_b7_geDT9O5bMrx926xuzkEEafks5r9bwOgaJpZM4M3kA9>
> .
>
",yes agree would want forced compile force use available thread reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
305165810,"Great, I'll close the issue then. Feel free to reopen if you find any problem.",great close issue feel free reopen find problem,issue,positive,positive,positive,positive,positive,positive
304984246,"Hi, thanks for the explanation. Wrote a little script that changes the sonnet workspace based on the tensorflow workspace and everything installs fine now.",hi thanks explanation wrote little script sonnet based everything fine,issue,positive,positive,positive,positive,positive,positive
304934958,Note: Edited my previous comment to correct the change.,note previous comment correct change,issue,negative,negative,negative,negative,negative,negative
304750405,"Hello, thanks for reporting the issue.

This is due to a workaround that is needed to keep Tensorflow as a dependency. We will update our code to reflect the recent changes in the Tensorflow repository, which will eliminate this issue, but for now you can edit Sonnet's WORKSPACE file and change the `http_archive` entry to the following: 

```
http_archive(
    name = ""io_bazel_rules_closure"",
    sha256 = ""4be8a887f6f38f883236e77bb25c2da10d506f2bf1a8e5d785c0f35574c74ca4"",
    strip_prefix = ""rules_closure-aac19edc557aec9b603cd7ffe359401264ceff0d"",
    urls = [
        ""http://mirror.bazel.build/github.com/bazelbuild/rules_closure/archive/aac19edc557aec9b603cd7ffe359401264ceff0d.tar.gz"",  # 2017-05-10
        ""https://github.com/bazelbuild/rules_closure/archive/aac19edc557aec9b603cd7ffe359401264ceff0d.tar.gz"",
    ],
)
```

Does this solve your problem?",hello thanks issue due keep dependency update code reflect recent repository eliminate issue edit sonnet file change entry following name sha solve problem,issue,negative,positive,neutral,neutral,positive,positive
304296712,"@CBrauer great to hear that, thanks for the response.",great hear thanks response,issue,positive,positive,positive,positive,positive,positive
304289374,"Yes, I tried it again and it worked.

Thanks

Charles

 

From: Adrià Puigdomènech [mailto:notifications@github.com] 
Sent: Thursday, May 25, 2017 7:13 AM
To: deepmind/sonnet <sonnet@noreply.github.com>
Cc: CBrauer <CBrauer@CypressPoint.com>; Mention <mention@noreply.github.com>
Subject: Re: [deepmind/sonnet] Configure failed on Mac OSX (#26)

 

@CBrauer <https://github.com/cbrauer>  was this a transient issue? (i.e. did the comment above solve your issue?)

—
You are receiving this because you were mentioned.
Reply to this email directly, view it on GitHub <https://github.com/deepmind/sonnet/issues/26#issuecomment-304020116> , or mute the thread <https://github.com/notifications/unsubscribe-auth/ABQZcsv4kZm3z-ExFjMw_pf_2W8C_YfHks5r9YxxgaJpZM4NFiA_> .  <https://github.com/notifications/beacon/ABQZcsoa9ZZG0PU0HL7cO3UYrUVk1FX9ks5r9YxxgaJpZM4NFiA_.gif> 

",yes tried worked thanks sent may sonnet mention mention subject configure mac transient issue comment solve issue reply directly view mute thread,issue,positive,positive,neutral,neutral,positive,positive
304142374,"I have also noticed that the `tensorflow` requirement in `install_requires=` causes some issues. In particular, I was using Sonnet on Google Cloud ML Engine. Their VM already has an optimized and GPU-enabled TensorFlow version installed. But installing the Sonnet wheel caused the machine to download the CPU-only `tensorflow` package from PyPI and shadowing the existing TensorFlow installation, resulting in the GPU not being used. I had to remove the `tensorflow` line from `setup.py` to make it work.",also requirement particular sonnet cloud engine already version sonnet wheel machine package shadowing installation resulting used remove line make work,issue,negative,positive,positive,positive,positive,positive
304141711,@malcolmreynolds That sounds great - having binaries on PyPI and regular releases should make things much easier.,great regular make much easier,issue,positive,positive,positive,positive,positive,positive
304072809,"@edrozenberg yes, I agree with you. As mentioned, we would not want users to be forced to compile tensorflow, but by no means this implies we will force such users to use pre-compiled binaries, both things should just be available as options.",yes agree would want forced compile force use available,issue,negative,positive,neutral,neutral,positive,positive
304055822,"@hannes-brt Hi, thanks for your question. I agree with all your points, we're not happy with the installation experience at the moment and obviously users have had a variety of issues with it. We've held back on offering a PyPI solution so far, principally because of developer time, but I've managed to get an engineer allocated to this full time for the next few weeks, who is going to look at packaging shortly.

My proposal is that every week, when we export from our internal version to GH, we will also bump the version number, create wheel files for Linux / Mac and python 2.7/3.4, upload them to PyPI, and update a changelog. I hope that should make use cases like yours much more straightforward - but please let me know if you think we should be doing different / additional things in order to make things user friendly.


",hi thanks question agree happy installation experience moment obviously variety back offering solution far principally developer time get engineer full time next going look shortly proposal every week export internal version also bump version number create wheel mac python update hope make use like much straightforward please let know think different additional order make user friendly,issue,positive,positive,positive,positive,positive,positive
304049218,"@kosklain thanks, I'll try the sonnet compile later with the latest.

Regarding your statement ""Ideally we want to not have to compile tensorflow"" that's fine but I hope tensorflow and sonnet will continue to make it possible (and not too difficult) for people to compile their own. I want to run whichever Linux I want (I don't use Centos or Ubuntu) and to be able to install GPU libraries and other components in the locations I prefer. Precompiled stuff often makes assumptions that don't work for certain users or for the way they prefer to do things. Thanks!",thanks try sonnet compile later latest regarding statement ideally want compile fine hope sonnet continue make possible difficult people compile want run whichever want use able install prefer stuff often work certain way prefer thanks,issue,positive,positive,positive,positive,positive,positive
304020116,@CBrauer was this a transient issue? (i.e. did the comment above solve your issue?),transient issue comment solve issue,issue,negative,neutral,neutral,neutral,neutral,neutral
304019323,Closing and following progress on #25 (apart from having the workaround that you point out).,following progress apart point,issue,negative,neutral,neutral,neutral,neutral,neutral
304010059,"Duplicate of #25 . Also, as pointed out, please move out of the sonnet to import it, as you might be importing only the python dependencies (a fix for this use case is coming in the following days).",duplicate also pointed please move sonnet import might python fix use case coming following day,issue,negative,neutral,neutral,neutral,neutral,neutral
304009580,"@thomkeh python 3 is supported now :)

Regarding the compilation issues, marking this as duplicate of #25 to follow progress there.",python regarding compilation marking duplicate follow progress,issue,negative,neutral,neutral,neutral,neutral,neutral
304008482,"Ideally we want to not have to compile tensorflow (given that it can get complex and might take a lot of time) even with new compilers. We are resolving the issues for people that compile sonnet with gcc 5x, partly solved by using:

```bazel build --config=opt --copt=""-D_GLIBCXX_USE_CXX11_ABI=0"" :install```

For now I think it's safe to say that this issue will be resolved when #25 is resolved. Marking as duplicate to track progress there.",ideally want compile given get complex might take lot time even new people compile sonnet partly build install think safe say issue resolved resolved marking duplicate track progress,issue,positive,positive,positive,positive,positive,positive
304007571,"We missed out exposing this in `__init__.py` so it's not accessible directly under `snt`, but you should be able to get to it manually with `snt.python.modules.gated_rnn.ConvLSTM`. We'll fix this ASAP.",accessible directly able get manually fix,issue,negative,positive,positive,positive,positive,positive
304007158,"I have tried snt.Conv1DLSTM, snt.Conv2DLSTM and snt.ConvLSTM, none of those works... is that one works for you? @diegolascasas ",tried none work one work,issue,negative,neutral,neutral,neutral,neutral,neutral
303935019,"Try several times or switch the version(git checkout r1.1 or r1.2).FYI.#5,#32
",try several time switch version git,issue,negative,neutral,neutral,neutral,neutral,neutral
303834604,"Hi there.
What version of bazel do you have?
`bazel version` will tell you that.",hi version version tell,issue,negative,neutral,neutral,neutral,neutral,neutral
303162555,"@cmwatson3524524 The dagger jar file is a dependency of TensorFlow - even if you don't want Android, I can't really say how easy / practical it is for this to be removed. You would have to raise an issue against TensorFlow to find out.

I don't think there is a Sonnet related issue here, the problem is that Bazel does not interact well with the network environment where you are. Please re-open if you feel there is a Sonnet-specific problem.
",dagger jar file dependency even want android ca really say easy practical removed would raise issue find think sonnet related issue problem interact well network environment please feel problem,issue,negative,positive,positive,positive,positive,positive
303157199,"Hey, after a bit of discussion, Windows support is not on the roadmap at the moment. Of course, PRs are always welcome :)

Just adding a note to this: @leconteur  your installation (without compilation) will not include the C++ bits of our library (currently that is the resampler).",hey bit discussion support moment course always welcome note installation without compilation include library currently,issue,positive,positive,positive,positive,positive,positive
302910399,"Thanks a lot!
The installation is done!
",thanks lot installation done,issue,negative,positive,positive,positive,positive,positive
302884239,"Sonnet is not currently in PyPI, the sonnet package you get from `pip install sonnet` is a package related to NetworkX. Please make sure to install Sonnet following the [installation instructions](https://github.com/deepmind/sonnet#installation-instructions).",sonnet currently sonnet package get pip install sonnet package related please make sure install sonnet following installation,issue,positive,positive,positive,positive,positive,positive
302880233,"https://github.com/deepmind/dnc

I've installed sonnet by using pip install sonnet 
However when I run ""python train.py""
I got AttributeError: 'module' object has no attribute 'AbstractModule'
 in addressing py line 58
Thanks!
",sonnet pip install sonnet however run python got object attribute line thanks,issue,negative,positive,positive,positive,positive,positive
302880184,Hi there. Could you possibly share your code here? There isn't a train.py in this repository.,hi could possibly share code repository,issue,negative,neutral,neutral,neutral,neutral,neutral
302431297,"@sathishreddy : I am receiving the same error.  Is there a way to adjust the proxy settings in bazel through 'configure'?

Looking at [https://github.com/bazelbuild/bazel/issues/587](url) it appears that my problem might be that our proxy goes through http not https and that proxies using http are ignored by default.  Is there a way to get 'configure' to adjust this default behavior?

Alternately, I am not planning to do anything with android which it appears to be the use of this 'dagger'.  If that is correct and if there is not an explicit need for it, then can i remove it from the build?",error way adjust proxy looking problem might proxy go default way get adjust default behavior alternately anything android use correct explicit need remove build,issue,negative,neutral,neutral,neutral,neutral,neutral
302321540,"@cmwatson3524524 : This again similar issue but now the issue with github ssl  verification; May be put the follwoing line in your .bashrc file
`export GIT_SSL_NO_VERIFY=1`
",similar issue issue verification may put line file export,issue,negative,neutral,neutral,neutral,neutral,neutral
302300587,"```
	sudo apt-get dist-upgrade
```

fixed it for me on ubuntu 14.04 LTS

i found the bazel error fix elsewhere and it was stated it was an earlier version kernel issue
[https://github.com/bazelbuild/bazel/issues/1972](https://github.com/bazelbuild/bazel/issues/1972)
",fixed found error fix elsewhere stated version kernel issue,issue,negative,positive,neutral,neutral,positive,positive
302134090,"Can you do: `touch blah.cc && gcc -c -Wthread-safety blah.cc`?

I suspect it will fail for you.. On my Mac (10.12.4) that line completes without an error, most likely because gcc is actually aliased to Clang:

```
$ gcc --version
Configured with: --prefix=/Applications/Xcode.app/Contents/Developer/usr --with-gxx-include-dir=/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk/usr/include/c++/4.2.1
Apple LLVM version 8.0.0 (clang-800.0.42.1)
Target: x86_64-apple-darwin16.5.0
Thread model: posix
InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin
```
I'm not sure why this discrepancy would be there. Do you have XCode installed, and if so what version?",touch suspect fail mac line without error likely actually clang version apple version target thread model sure discrepancy would version,issue,negative,neutral,neutral,neutral,neutral,neutral
302129485,@Shuolongbj can you post what you get when running 'gcc --version' ?,post get running version,issue,negative,neutral,neutral,neutral,neutral,neutral
300840866,"Great thank you! I did suspect that it was something like that as our corporate network inspects and re-issues the certificates.  I was able to download the files and modify the WORKSPACE as suggested.  I have new error that I imagine is related.

```
[cmwatson@xx tensorflow]$ ./configure
Please specify the location of python. [Default is /usr/bin/python]:
Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -march=native]:
Do you wish to use jemalloc as the malloc implementation? [Y/n]
jemalloc enabled
Do you wish to build TensorFlow with Google Cloud Platform support? [y/N]
No Google Cloud Platform support will be enabled for TensorFlow
Do you wish to build TensorFlow with Hadoop File System support? [y/N]
No Hadoop File System support will be enabled for TensorFlow
Do you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N]
No XLA support will be enabled for TensorFlow
Found possible Python library paths:
  /usr/lib/python2.7/site-packages
  /usr/lib64/python2.7/site-packages
Please input the desired Python library path to use.  Default is [/usr/lib/python2.7/site-packages]

Using python library path: /usr/lib/python2.7/site-packages
Do you wish to build TensorFlow with OpenCL support? [y/N]
No OpenCL support will be enabled for TensorFlow
Do you wish to build TensorFlow with CUDA support? [y/N]
No CUDA support will be enabled for TensorFlow
Configuration finished
Warning: ignoring http_proxy in environment.
INFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.
Warning: ignoring http_proxy in environment.
..............
ERROR: /home/cmwatson/.cache/bazel/_bazel_cmwatson/69b7f2b22f6b880ca0a532b8cb646acd/external/com_google_dagger/BUILD:13:1: no such package '@com_google_dagger_compiler//': java.io.IOException: Error downloading [http://domain-registry-maven.storage.googleapis.com/repo1.maven.org/maven2/com/google/dagger/dagger-compiler/2.8/dagger-compiler-2.8.jar, http://maven.ibiblio.org/maven2/com/google/dagger/dagger-compiler/2.8/dagger-compiler-2.8.jar, http://repo1.maven.org/maven2/com/google/dagger/dagger-compiler/2.8/dagger-compiler-2.8.jar] to /home/cmwatson/.cache/bazel/_bazel_cmwatson/69b7f2b22f6b880ca0a532b8cb646acd/external/com_google_dagger_compiler/dagger-compiler-2.8.jar: Tried to reconnect at offset 8,481,153 but server didn't support it and referenced by '@com_google_dagger//:com_google_dagger'.
ERROR: /home/cmwatson/.cache/bazel/_bazel_cmwatson/69b7f2b22f6b880ca0a532b8cb646acd/external/com_google_dagger/BUILD:13:1: no such package '@com_google_dagger_compiler//': java.io.IOException: Error downloading [http://domain-registry-maven.storage.googleapis.com/repo1.maven.org/maven2/com/google/dagger/dagger-compiler/2.8/dagger-compiler-2.8.jar, http://maven.ibiblio.org/maven2/com/google/dagger/dagger-compiler/2.8/dagger-compiler-2.8.jar, http://repo1.maven.org/maven2/com/google/dagger/dagger-compiler/2.8/dagger-compiler-2.8.jar] to /home/cmwatson/.cache/bazel/_bazel_cmwatson/69b7f2b22f6b880ca0a532b8cb646acd/external/com_google_dagger_compiler/dagger-compiler-2.8.jar: Tried to reconnect at offset 8,481,153 but server didn't support it and referenced by '@com_google_dagger//:com_google_dagger'.
ERROR: Evaluation of query ""deps(((//tensorflow/... - //tensorflow/contrib/nccl/...) - //tensorflow/examples/android/...))"" failed: errors were encountered while computing transitive closure.

```

I downloaded the dagger-compiler-2.8.jar file but now do not know how to get configure to look for it.  Any thoughts?",great thank suspect something like corporate network able modify new error imagine related please specify location python default please specify optimization use compilation option default wish use implementation wish build cloud platform support cloud platform support wish build file system support file system support wish build compiler experimental support found possible python library please input desired python library path use default python library path wish build support support wish build support support configuration finished warning environment starting clean may take consider clean several warning environment error package error jar tried reconnect offset server support error package error jar tried reconnect offset server support error evaluation query transitive closure jar file know get configure look,issue,positive,positive,positive,positive,positive,positive
300654417,"@cmwatson3524524 . The issue mainly due to proxy setting. You need to change  your **WORKSPACE** file in **sonnet/tensorflow**.  Please check the below example.

comment below lines:
```
#http_file(
#  name = ""weblas_weblas_js"",
#  url = ""https://raw.githubusercontent.com/waylonflinn/weblas/v0.9.0/dist/weblas.js"",
#)
```

and add follwoing lines to the WORKSAPCE file
```
http_file(
  name = ""weblas_weblas_js"",
  url = ""file:///local_path/weblas.js"",  
)

```
download weblas.js and store it in your local directory. Similarly you have to repeat this step for 3 or 4 files (OrbitControls.js, three.min.js, ...). ",issue mainly due proxy setting need change file please check example comment name add file name file store local directory similarly repeat step,issue,negative,negative,neutral,neutral,negative,negative
300277676,"Previous issue was from old bazel version.  I upgraded to 0.4.5 -- now having this issue which I cannot make sense.
```

[cmwatson@xx tensorflow]$ ./configure
Please specify the location of python. [Default is /usr/bin/python]:
Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -march=native]:
Do you wish to use jemalloc as the malloc implementation? [Y/n]
jemalloc enabled
Do you wish to build TensorFlow with Google Cloud Platform support? [y/N]
No Google Cloud Platform support will be enabled for TensorFlow
Do you wish to build TensorFlow with Hadoop File System support? [y/N]
No Hadoop File System support will be enabled for TensorFlow
Do you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N]
No XLA support will be enabled for TensorFlow
Found possible Python library paths:
  /usr/lib/python2.7/site-packages
  /usr/lib64/python2.7/site-packages
Please input the desired Python library path to use.  Default is [/usr/lib/python2.7/site-packages]

Using python library path: /usr/lib/python2.7/site-packages
Do you wish to build TensorFlow with OpenCL support? [y/N]
No OpenCL support will be enabled for TensorFlow
Do you wish to build TensorFlow with CUDA support? [y/N]
No CUDA support will be enabled for TensorFlow
Configuration finished
Warning: ignoring http_proxy in environment.
INFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.
Warning: ignoring http_proxy in environment.
...........
ERROR: /home/cmwatson/sonnet/tensorflow/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@weblas_weblas_js//file': Error downloading [https://raw.githubusercontent.com/waylonflinn/weblas/v0.9.0/dist/weblas.js] to /home/cmwatson/.cache/bazel/_bazel_cmwatson/69b7f2b22f6b880ca0a532b8cb646acd/external/weblas_weblas_js/weblas.js: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target and referenced by '//tensorflow/tensorboard/bower:bower'.
ERROR: /home/cmwatson/.cache/bazel/_bazel_cmwatson/69b7f2b22f6b880ca0a532b8cb646acd/external/com_google_dagger/BUILD:13:1: no such package '@com_google_dagger_compiler//': java.io.IOException: Error downloading [http://domain-registry-maven.storage.googleapis.com/repo1.maven.org/maven2/com/google/dagger/dagger-compiler/2.8/dagger-compiler-2.8.jar, http://maven.ibiblio.org/maven2/com/google/dagger/dagger-compiler/2.8/dagger-compiler-2.8.jar, http://repo1.maven.org/maven2/com/google/dagger/dagger-compiler/2.8/dagger-compiler-2.8.jar] to /home/cmwatson/.cache/bazel/_bazel_cmwatson/69b7f2b22f6b880ca0a532b8cb646acd/external/com_google_dagger_compiler/dagger-compiler-2.8.jar: Tried to reconnect at offset 8,481,153 but server didn't support it and referenced by '@com_google_dagger//:com_google_dagger'.
ERROR: Evaluation of query ""deps(((//tensorflow/... - //tensorflow/contrib/nccl/...) - //tensorflow/examples/android/...))"" failed: errors were encountered while computing transitive closure.

```

",previous issue old version issue make sense please specify location python default please specify optimization use compilation option default wish use implementation wish build cloud platform support cloud platform support wish build file system support file system support wish build compiler experimental support found possible python library please input desired python library path use default python library path wish build support support wish build support support configuration finished warning environment starting clean may take consider clean several warning environment error package error path building unable find valid certification path target bower error package error jar tried reconnect offset server support error evaluation query transitive closure,issue,positive,positive,neutral,neutral,positive,positive
300201540,"I used pip to upgrade TensorFlow to 1.1 but having an error when trying to configure the headers to bazel build:

```
[cmwatson@xx tensorflow]$ ./configure
Please specify the location of python. [Default is /usr/bin/python]:
Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -march=native]:
Do you wish to use jemalloc as the malloc implementation? [Y/n]
jemalloc enabled
Do you wish to build TensorFlow with Google Cloud Platform support? [y/N]
No Google Cloud Platform support will be enabled for TensorFlow
Do you wish to build TensorFlow with Hadoop File System support? [y/N]
No Hadoop File System support will be enabled for TensorFlow
Do you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N]
No XLA support will be enabled for TensorFlow
Found possible Python library paths:
  /usr/lib/python2.7/site-packages
  /usr/lib64/python2.7/site-packages
Please input the desired Python library path to use.  Default is [/usr/lib/python2.7/site-packages]

Using python library path: /usr/lib/python2.7/site-packages
Do you wish to build TensorFlow with OpenCL support? [y/N]
No OpenCL support will be enabled for TensorFlow
Do you wish to build TensorFlow with CUDA support? [y/N]
No CUDA support will be enabled for TensorFlow
Configuration finished
INFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.
.........
ERROR: package contains errors: tensorflow.
ERROR: no such package '@io_bazel_rules_closure//closure': error loading package 'external': Could not load //external package.

```
I am able to import tensorflow, so is there an option that I'm missing on 'configure'?",used pip upgrade error trying configure build please specify location python default please specify optimization use compilation option default wish use implementation wish build cloud platform support cloud platform support wish build file system support file system support wish build compiler experimental support found possible python library please input desired python library path use default python library path wish build support support wish build support support configuration finished starting clean may take consider clean several error package error package error loading package could load package able import option missing,issue,positive,positive,positive,positive,positive,positive
299395903,"use tensorflow 1.1.0-rc2 replacing the sonnet/tensorflow if 1.1.0-rc2 is used and
`bazel build --config=opt --genrule_strategy=standalone --spawn_strategy=standalone :install `
 this works for me !",use used build install work,issue,negative,neutral,neutral,neutral,neutral,neutral
299137453,"yeah i can imagine, there are many gotchas in setting this beast... for starter, what is your environment like? things like operating system, java, python, tensorflow and bazel versions? are you able to run everything else except sonnet? ",yeah imagine many setting beast starter environment like like operating system python able run everything else except sonnet,issue,positive,positive,positive,positive,positive,positive
299135629,"@animesh  I faced the same error and followd your ways , but I still get the _resampler.so: undefined symbol error .I guess that there might some steps were wrong in this process.",faced error way still get undefined symbol error guess might wrong process,issue,negative,negative,negative,negative,negative,negative
298758894,"Great - I'll wait for those changes on your end and push this back out.

And of course, no problem at all with any delay! I appreciate the library, and certainly have no expectations beyond that. Thank you for the feedback.",great wait end push back course problem delay appreciate library certainly beyond thank feedback,issue,positive,positive,positive,positive,positive,positive
298757041,"Hi @ashern - thanks for the contribution, sorry we didn't get to it quickly. From a quick glance it looks like a useful thing we'd like to have - as you say, we would be looking for unit tests for any contributed modules.

A reason for the delay on our side is that upstream TF has recently changed how RNNCell works - it now inherits from the base._Layer class which means that any Sonnet RNNCore now effectively implements two RNN APIs which is not a good setup to have. We're looking into how to get around this - most likely changing upstream TF so that dynamic_rnn & the rest don't check for something being an RNNCell, but check for the required functionality (ie a state_size method) being available. This will allow us to make RNNCore not inherit from RNNCell.. At that point, a modified version of your PR would be welcome - I'll let you know when things are stable.",hi thanks contribution sorry get quickly quick glance like useful thing like say would looking unit reason delay side upstream recently work class sonnet effectively two good setup looking get around likely upstream rest check something check functionality ie method available allow u make inherit point version would welcome let know stable,issue,positive,positive,positive,positive,positive,positive
298755418,"I've gone ahead and closed this - but for my needs this is a nice improvement & working well.

I am happy to put together some tests around this change & resubmit if there's interest.",gone ahead closed need nice improvement working well happy put together around change resubmit interest,issue,positive,positive,positive,positive,positive,positive
298551254,"I again faced this issue on another machine. I downgraded to Python2.7 and
made a re-installation attempt which seems to have worked. So I would
suggest to check the Python version, seems like Python3 compatibility is
less polished...

Regards,

Ani


--------------------------""The Answer Lies In The
Genome""--------------------------

On Tue, May 2, 2017 at 12:40 AM, PFCM <notifications@github.com> wrote:

> I'm also getting this as per @thesilencelies
> <https://github.com/thesilencelies>. Tried tensorflow 1.1.0, then
> 1.1.0-rc2 when that didn't work. In both cases ldd on the produced
> _resampler.so shows:
>
>         linux-vdso.so.1 =>  (0x00007ffe9c52b000)
>         libm.so.6 => /lib/x86_64-linux-gnu/libm.so.6 (0x00007f87868d3000)
>         libpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f87866b5000)
>         libstdc++.so.6 => /usr/lib/x86_64-linux-gnu/libstdc++.so.6 (0x00007f878632d000)
>         libgcc_s.so.1 => /lib/x86_64-linux-gnu/libgcc_s.so.1 (0x00007f8786116000)
>         libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007f8785d4f000)
>         /lib64/ld-linux-x86-64.so.2 (0x000055b1b0e70000)
>
> ie. it doesn't look as if the op library is being linked to anything
> tensorflow related? Using bazel 0.4.5 on ubuntu 17.10 if it helps.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/deepmind/sonnet/issues/25#issuecomment-298451818>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/AABT0R8ndLe82tEOetXwxkEBPcMSRtE3ks5r1l9mgaJpZM4NEYT9>
> .
>
",faced issue another machine python made attempt worked would suggest check python version like python compatibility le polished ani answer genome tue may wrote also getting per tried work produced ie look library linked anything related thread reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
298451818,"~I'm also getting this as per @thesilencelies. Tried tensorflow 1.1.0, then 1.1.0-rc2 when that didn't work. In both cases `ldd` on the produced `_resampler.so` shows:~
```
        linux-vdso.so.1 =>  (0x00007ffe9c52b000)
        libm.so.6 => /lib/x86_64-linux-gnu/libm.so.6 (0x00007f87868d3000)
        libpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f87866b5000)
        libstdc++.so.6 => /usr/lib/x86_64-linux-gnu/libstdc++.so.6 (0x00007f878632d000)
        libgcc_s.so.1 => /lib/x86_64-linux-gnu/libgcc_s.so.1 (0x00007f8786116000)
        libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007f8785d4f000)
        /lib64/ld-linux-x86-64.so.2 (0x000055b1b0e70000)
```

~ie. it doesn't look as if the op library is being linked to anything tensorflow related? Using bazel 0.4.5 on ubuntu 17.10 if it helps.~

Forget about this.

Fixed it by building Sonnet with

```
bazel build --config=opt --copt=""-D_GLIBCXX_USE_CXX11_ABI=0"" :install
```

I believe the issue was that Tensorflow was being built with GCC 4.x while Sonnet was using the system default which is >= 5.",also getting per tried work produced look library linked anything related forget fixed building sonnet build install believe issue built sonnet system default,issue,negative,positive,neutral,neutral,positive,positive
298246297,"I have the same problem as @thesilencelies. I did a git pull in sonnet/tensorflow after which I followed the sonnet installation instructions, but I still get the _resampler.so: undefined symbol error",problem git pull sonnet installation still get undefined symbol error,issue,negative,neutral,neutral,neutral,neutral,neutral
298173099,Maybe add a note to README that python 3 is now supported?,maybe add note python,issue,negative,neutral,neutral,neutral,neutral,neutral
298073330,"Commit https://github.com/deepmind/sonnet/commit/578e3360741891428ea51c36741bbabc82265942 should add Python 3 support. I am closing this issue, but please reopen it if the problem persists.",commit add python support issue please reopen problem,issue,positive,neutral,neutral,neutral,neutral,neutral
298072968,"Commit https://github.com/deepmind/sonnet/commit/578e3360741891428ea51c36741bbabc82265942 should add python3 support. I'm closing this issue, but please create a new one or reopen it if you have any problems with python3 compatibility.",commit add python support issue please create new one reopen python compatibility,issue,positive,positive,positive,positive,positive,positive
298071474,"@bfredl, this pull request is now merged with you as author.
Thank you for your contribution!",pull request author thank contribution,issue,negative,neutral,neutral,neutral,neutral,neutral
298007632,"I checked out the 1.1 branch of tensorflow in the one in the sonnet tree, compiled tensorflow from that (which works), then rebuilt sonnet. However I still get the above error for _ZN10tensorflow8internal21checkOpMessageBuilder9NewString. I had the warning mentioned in #16 during build.
I guess I did something wrong, but I'm a little unsure how to implement the solution mentioned above...",checked branch one sonnet tree work rebuilt sonnet however still get error warning build guess something wrong little unsure implement solution,issue,negative,negative,negative,negative,negative,negative
297905067,"Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

:memo: **Please visit <https://cla.developers.google.com/> to sign.**

Once you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.

---

- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).
- If you signed the CLA as a corporation, please let us know the company's name.

<!-- need_sender_cla -->",thanks pull request like may first contribution open source project look pull request need sign contributor license agreement memo please visit sign please reply verify thanks already possible different address check data verify set git corporation please let u know company name,issue,positive,positive,positive,positive,positive,positive
297670172,"I installed a lot of times, the error should be accidental.Reinstall again can solve it.",lot time error solve,issue,negative,neutral,neutral,neutral,neutral,neutral
296828968,"@Tutufa glad you got it sorted - As far as I'm aware we're not specifying versions of GCC anywhere in the Sonnet repository, but depending on what is installed on your system bazel may pick up mismatching versions. We'll be updating the install instructions soon to try to cover the issues that people have been having, thanks for providing this information.",glad got sorted far aware anywhere sonnet repository depending system may pick install soon try cover people thanks providing information,issue,positive,positive,positive,positive,positive,positive
296826473,"Hi, thanks for the PR. We can accept this if you upload a new commit which places it inside the (new) directory sonnet/contrib/examples - just so we can make it clear to other users which parts of Sonnet are officially supported etc.",hi thanks accept new commit inside new directory make clear sonnet officially,issue,positive,positive,positive,positive,positive,positive
296799113,"Yes, it was gcc version mismatch. Do the following:

1. Compile r1.1 TF from github, install TF
2. Compile Sonnet (switch to r1.1 in tensorflow dir inside sonnet), Install Sonnet

I used gcc 5.*
",yes version mismatch following compile install compile sonnet switch inside sonnet install sonnet used,issue,negative,neutral,neutral,neutral,neutral,neutral
296770157,"I also followed the procedure suggested by @sathishreddy for installing TF1.1 (just leaving out --config=cuda). Within the sonnet dir I had the same '_gen_resampler could not be imported' error as before, but outside it was able to successfully run the resampler test. Thanks so much! ",also procedure leaving within sonnet could error outside able successfully run test thanks much,issue,positive,positive,positive,positive,positive,positive
296712955,"I am having the same problem on Linux Mint 18.1. I followed the proceedure above and the output I get is 

     import sonnet as snt
    Traceback (most recent call last):
     File ""<stdin>"", line 1, in <module>
     File ""/home/avrono/TensorFlow/local/lib/python2.7/site-packages/sonnet/__init__.py"", line 102, in 
    <module>
            from sonnet.python.ops.resampler import resampler
      File ""/home/avrono/TensorFlow/local/lib/python2.7/site-packages/sonnet/python/ops/resampler.py"", line 33, in <module>
        tf.resource_loader.get_path_to_datafile(""_resampler.so""))
      File ""/home/avrono/TensorFlow/local/lib/python2.7/site-
    packages/tensorflow/python/framework/load_library.py"", line 64, in load_op_library
       None, None, error_msg, error_code)
    tensorflow.python.framework.errors_impl.NotFoundError: 
    /home/avrono/TensorFlow/local/lib/python2.7/site-packages/sonnet/python/ops/_resampler.so: 
    undefined symbol: _ZN10tensorflow8internal21CheckOpMessageBuilder9NewStringB5cxx11Ev
",problem mint output get import sonnet recent call last file line module file line module import file line module file line none none undefined symbol,issue,negative,neutral,neutral,neutral,neutral,neutral
296669902,"```
cat /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/execroot/sonnet/bazel-out/local-fastbuild/testlogs/sonnet/python/pondering_rnn_test/test.log
exec ${PAGER:-/usr/bin/less} ""$0"" || exit 1
-----------------------------------------------------------------------------
Traceback (most recent call last):
  File ""/home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/bazel-sandbox/9fc9d257-78be-40af-8d1a-aae9a9c04001-430/execroot/sonnet/bazel-out/local-fastbuild/bin/sonnet/python/pondering_rnn_test.runfiles/sonnet/sonnet/python/modules/pondering_rnn_test.py"", line 24, in <module>
    from sonnet.python.modules import basic_rnn
  File ""/home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/bazel-sandbox/9fc9d257-78be-40af-8d1a-aae9a9c04001-430/execroot/sonnet/bazel-out/local-fastbuild/bin/sonnet/python/pondering_rnn_test.runfiles/sonnet/sonnet/__init__.py"", line 102, in <module>
    from sonnet.python.ops.resampler import resampler
  File ""/home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/bazel-sandbox/9fc9d257-78be-40af-8d1a-aae9a9c04001-430/execroot/sonnet/bazel-out/local-fastbuild/bin/sonnet/python/pondering_rnn_test.runfiles/sonnet/sonnet/python/ops/resampler.py"", line 33, in <module>
    tf.resource_loader.get_path_to_datafile(""_resampler.so""))
  File ""/home/kovalenko/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/load_library.py"", line 64, in load_op_library
    None, None, error_msg, error_code)
tensorflow.python.framework.errors_impl.NotFoundError: /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/bazel-sandbox/9fc9d257-78be-40af-8d1a-aae9a9c04001-430/execroot/sonnet/bazel-out/local-fastbuild/bin/sonnet/python/pondering_rnn_test.runfiles/sonnet/sonnet/python/ops/_resampler.so: undefined symbol: _ZN10tensorflow8internal21CheckOpMessageBuilder9NewStringB5cxx11Ev
Use --strategy=TestRunner=standalone to disable sandboxing for the failing actions.
```",cat pager exit recent call last file line module import file line module import file line module file line none none undefined symbol use disable failing,issue,negative,neutral,neutral,neutral,neutral,neutral
296669692,"Could you paste in the contents of one of the log files for a test that doesn't use the resampler, eg the contents of /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/execroot/sonnet/bazel-out/local-fastbuild/testlogs/sonnet/python/pondering_rnn_test/test.log ?",could paste content one log test use content,issue,negative,neutral,neutral,neutral,neutral,neutral
296667525,"```
bazel test sonnet/python:all
WARNING: /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/external/org_tensorflow/tensorflow/workspace.bzl:72:5: tf_repo_name was specified to tf_workspace but is no longer used and will be removed in the future.
WARNING: /home/kovalenko/sonnet/sonnet/python/BUILD:119:1: in srcs attribute of cc_library rule //sonnet/python:ops/_resampler_gpu: please do not import '//sonnet/cc/kernels:resampler_op_gpu.cu.cc' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_custom_op_library', the error might have been caused by the macro implementation in /home/kovalenko/sonnet/sonnet/tensorflow.bzl:98:16.
WARNING: /home/kovalenko/sonnet/sonnet/python/BUILD:119:1: in srcs attribute of cc_binary rule //sonnet/python:ops/_resampler.so: please do not import '//sonnet/cc:ops/resampler.cc' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_custom_op_library', the error might have been caused by the macro implementation in /home/kovalenko/sonnet/sonnet/tensorflow.bzl:108:25.
WARNING: /home/kovalenko/sonnet/sonnet/python/BUILD:119:1: in srcs attribute of cc_binary rule //sonnet/python:ops/_resampler.so: please do not import '//sonnet/cc/kernels:resampler_op.cc' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_custom_op_library', the error might have been caused by the macro implementation in /home/kovalenko/sonnet/sonnet/tensorflow.bzl:108:25.
WARNING: /home/kovalenko/sonnet/sonnet/python/BUILD:119:1: in srcs attribute of cc_binary rule //sonnet/python:ops/_resampler.so: please do not import '//sonnet/cc/kernels:resampler_op.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_custom_op_library', the error might have been caused by the macro implementation in /home/kovalenko/sonnet/sonnet/tensorflow.bzl:108:25.
INFO: Found 14 targets and 25 test targets...
INFO: From ProtoCompile external/org_tensorflow/tensorflow/core/framework/op_gen_overrides.pb.cc:
bazel-out/local-fastbuild/genfiles/external/protobuf/src: warning: directory does not exist.
bazel-out/local-fastbuild/genfiles/external/protobuf/src: warning: directory does not exist.
INFO: From Compiling external/org_tensorflow/tensorflow/core/framework/allocator.cc:
external/org_tensorflow/tensorflow/core/framework/allocator.cc:113:12: warning: 'tensorflow::Allocator* tensorflow::{anonymous}::MakeCpuAllocator()' defined but not used [-Wunused-function]
 Allocator* MakeCpuAllocator() {
            ^
FAIL: //sonnet/python:mlp_test (see /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/execroot/sonnet/bazel-out/local-fastbuild/testlogs/sonnet/python/mlp_test/test.log).
FAIL: //sonnet/python:batch_norm_test (see /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/execroot/sonnet/bazel-out/local-fastbuild/testlogs/sonnet/python/batch_norm_test/test.log).
FAIL: //sonnet/python:convnet_test (see /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/execroot/sonnet/bazel-out/local-fastbuild/testlogs/sonnet/python/convnet_test/test.log).
FAIL: //sonnet/python:util_test (see /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/execroot/sonnet/bazel-out/local-fastbuild/testlogs/sonnet/python/util_test/test.log).
FAIL: //sonnet/python:conv_test (see /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/execroot/sonnet/bazel-out/local-fastbuild/testlogs/sonnet/python/conv_test/test.log).
FAIL: //sonnet/python:alexnet_test (see /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/execroot/sonnet/bazel-out/local-fastbuild/testlogs/sonnet/python/alexnet_test/test.log).
FAIL: //sonnet/python:rnn_core_test (see /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/execroot/sonnet/bazel-out/local-fastbuild/testlogs/sonnet/python/rnn_core_test/test.log).
FAIL: //sonnet/python:basic_test (see /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/execroot/sonnet/bazel-out/local-fastbuild/testlogs/sonnet/python/basic_test/test.log).
FAIL: //sonnet/python:basic_rnn_test (see /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/execroot/sonnet/bazel-out/local-fastbuild/testlogs/sonnet/python/basic_rnn_test/test.log).
FAIL: //sonnet/python:base_test (see /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/execroot/sonnet/bazel-out/local-fastbuild/testlogs/sonnet/python/base_test/test.log).
FAIL: //sonnet/python:block_matrix_test (see /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/execroot/sonnet/bazel-out/local-fastbuild/testlogs/sonnet/python/block_matrix_test/test.log).
FAIL: //sonnet/python:gated_rnn_test (see /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/execroot/sonnet/bazel-out/local-fastbuild/testlogs/sonnet/python/gated_rnn_test/test.log).
FAIL: //sonnet/python:attention_test (see /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/execroot/sonnet/bazel-out/local-fastbuild/testlogs/sonnet/python/attention_test/test.log).
FAIL: //sonnet/python:experimental_test (see /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/execroot/sonnet/bazel-out/local-fastbuild/testlogs/sonnet/python/experimental_test/test.log).
FAIL: //sonnet/python:initializers_test (see /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/execroot/sonnet/bazel-out/local-fastbuild/testlogs/sonnet/python/initializers_test/test.log).
FAIL: //sonnet/python:scale_gradient_test (see /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/execroot/sonnet/bazel-out/local-fastbuild/testlogs/sonnet/python/scale_gradient_test/test.log).
FAIL: //sonnet/python:dilation_test (see /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/execroot/sonnet/bazel-out/local-fastbuild/testlogs/sonnet/python/dilation_test/test.log).
FAIL: //sonnet/python:conv_gpu_test (see /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/execroot/sonnet/bazel-out/local-fastbuild/testlogs/sonnet/python/conv_gpu_test/test.log).
FAIL: //sonnet/python:resampler_test (see /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/execroot/sonnet/bazel-out/local-fastbuild/testlogs/sonnet/python/resampler_test/test.log).
FAIL: //sonnet/python:sequential_test (see /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/execroot/sonnet/bazel-out/local-fastbuild/testlogs/sonnet/python/sequential_test/test.log).
FAIL: //sonnet/python:clip_gradient_test (see /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/execroot/sonnet/bazel-out/local-fastbuild/testlogs/sonnet/python/clip_gradient_test/test.log).
FAIL: //sonnet/python:pondering_rnn_test (see /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/execroot/sonnet/bazel-out/local-fastbuild/testlogs/sonnet/python/pondering_rnn_test/test.log).
FAIL: //sonnet/python:spatial_transformer_test (see /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/execroot/sonnet/bazel-out/local-fastbuild/testlogs/sonnet/python/spatial_transformer_test/test.log).
FAIL: //sonnet/python:embed_test (see /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/execroot/sonnet/bazel-out/local-fastbuild/testlogs/sonnet/python/embed_test/test.log).
INFO: Elapsed time: 101.583s, Critical Path: 88.86s
//sonnet/python:nest_test                                                PASSED in 1.8s
//sonnet/python:alexnet_test                                             FAILED in 1 out of 2 in 2.2s
  /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/execroot/sonnet/bazel-out/local-fastbuild/testlogs/sonnet/python/alexnet_test/test.log
//sonnet/python:attention_test                                           FAILED in 1 out of 2 in 1.8s
  /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/execroot/sonnet/bazel-out/local-fastbuild/testlogs/sonnet/python/attention_test/test.log
//sonnet/python:base_test                                                FAILED in 1 out of 2 in 1.9s
  /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/execroot/sonnet/bazel-out/local-fastbuild/testlogs/sonnet/python/base_test/test.log
//sonnet/python:basic_rnn_test                                           FAILED in 1 out of 2 in 2.5s
  /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/execroot/sonnet/bazel-out/local-fastbuild/testlogs/sonnet/python/basic_rnn_test/test.log
//sonnet/python:basic_test                                               FAILED in 1 out of 2 in 2.4s
  /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/execroot/sonnet/bazel-out/local-fastbuild/testlogs/sonnet/python/basic_test/test.log
//sonnet/python:batch_norm_test                                          FAILED in 1 out of 2 in 1.9s
  /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/execroot/sonnet/bazel-out/local-fastbuild/testlogs/sonnet/python/batch_norm_test/test.log
//sonnet/python:block_matrix_test                                        FAILED in 1 out of 2 in 1.9s
  /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/execroot/sonnet/bazel-out/local-fastbuild/testlogs/sonnet/python/block_matrix_test/test.log
//sonnet/python:clip_gradient_test                                       FAILED in 1 out of 2 in 2.1s
  /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/execroot/sonnet/bazel-out/local-fastbuild/testlogs/sonnet/python/clip_gradient_test/test.log
//sonnet/python:conv_gpu_test                                            FAILED in 1 out of 2 in 1.9s
  /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/execroot/sonnet/bazel-out/local-fastbuild/testlogs/sonnet/python/conv_gpu_test/test.log
//sonnet/python:conv_test                                                FAILED in 1 out of 2 in 2.2s
  /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/execroot/sonnet/bazel-out/local-fastbuild/testlogs/sonnet/python/conv_test/test.log
//sonnet/python:convnet_test                                             FAILED in 1 out of 2 in 1.9s
  /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/execroot/sonnet/bazel-out/local-fastbuild/testlogs/sonnet/python/convnet_test/test.log
//sonnet/python:dilation_test                                            FAILED in 1 out of 2 in 2.0s
  /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/execroot/sonnet/bazel-out/local-fastbuild/testlogs/sonnet/python/dilation_test/test.log
//sonnet/python:embed_test                                               FAILED in 1 out of 2 in 2.0s
  /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/execroot/sonnet/bazel-out/local-fastbuild/testlogs/sonnet/python/embed_test/test.log
//sonnet/python:experimental_test                                        FAILED in 1 out of 2 in 1.9s
  /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/execroot/sonnet/bazel-out/local-fastbuild/testlogs/sonnet/python/experimental_test/test.log
//sonnet/python:gated_rnn_test                                           FAILED in 1 out of 2 in 2.0s
  /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/execroot/sonnet/bazel-out/local-fastbuild/testlogs/sonnet/python/gated_rnn_test/test.log
//sonnet/python:initializers_test                                        FAILED in 1 out of 2 in 1.9s
  /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/execroot/sonnet/bazel-out/local-fastbuild/testlogs/sonnet/python/initializers_test/test.log
//sonnet/python:mlp_test                                                 FAILED in 1 out of 2 in 1.9s
  /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/execroot/sonnet/bazel-out/local-fastbuild/testlogs/sonnet/python/mlp_test/test.log
//sonnet/python:pondering_rnn_test                                       FAILED in 1 out of 2 in 1.9s
  /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/execroot/sonnet/bazel-out/local-fastbuild/testlogs/sonnet/python/pondering_rnn_test/test.log
//sonnet/python:resampler_test                                           FAILED in 1 out of 2 in 2.0s
  /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/execroot/sonnet/bazel-out/local-fastbuild/testlogs/sonnet/python/resampler_test/test.log
//sonnet/python:rnn_core_test                                            FAILED in 1 out of 2 in 2.3s
  /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/execroot/sonnet/bazel-out/local-fastbuild/testlogs/sonnet/python/rnn_core_test/test.log
//sonnet/python:scale_gradient_test                                      FAILED in 1 out of 2 in 1.9s
  /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/execroot/sonnet/bazel-out/local-fastbuild/testlogs/sonnet/python/scale_gradient_test/test.log
//sonnet/python:sequential_test                                          FAILED in 1 out of 2 in 2.0s
  /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/execroot/sonnet/bazel-out/local-fastbuild/testlogs/sonnet/python/sequential_test/test.log
//sonnet/python:spatial_transformer_test                                 FAILED in 1 out of 2 in 1.9s
  /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/execroot/sonnet/bazel-out/local-fastbuild/testlogs/sonnet/python/spatial_transformer_test/test.log
//sonnet/python:util_test                                                FAILED in 1 out of 2 in 1.9s
  /home/kovalenko/.cache/bazel/_bazel_kovalenko/58aa37c963f86b8a87c9ab34d5bad7a3/execroot/sonnet/bazel-out/local-fastbuild/testlogs/sonnet/python/util_test/test.log

Executed 25 out of 25 tests: 1 test passes and 24 fail locally.
```

@malcolmreynolds Also, I checkout r1.1 from git in sonnet/tensorflow and my TF version is 1.1.0",test warning longer used removed future warning attribute rule please import directly either move file package depend appropriate rule since rule macro error might macro implementation warning attribute rule please import directly either move file package depend appropriate rule since rule macro error might macro implementation warning attribute rule please import directly either move file package depend appropriate rule since rule macro error might macro implementation warning attribute rule please import directly either move file package depend appropriate rule since rule macro error might macro implementation found test warning directory exist warning directory exist warning anonymous defined used allocator fail see fail see fail see fail see fail see fail see fail see fail see fail see fail see fail see fail see fail see fail see fail see fail see fail see fail see fail see fail see fail see fail see fail see fail see time critical path executed test fail locally also git version,issue,negative,negative,negative,negative,negative,negative
296665659,Thanks for the report. Can you try running the unit tests by doing `bazel test sonnet/python:all` in the root of the repository? That will give us a bit of a clearer idea of what is happening.,thanks report try running unit test root repository give u bit clearer idea happening,issue,negative,positive,positive,positive,positive,positive
296663078,"@dsouzadyn That's a hypothetical example (Sonnet is not a data loading library, we just provide one in the examples folder as motivation). In this case the data has to be a single TensorFlow Tensor, because it is being passed into a Linear module and you can't apply a Linear to anything but a single Tensor, but in general the data could be something different, and it's up to you to write a module that deals with your specific shape of data. Sonnet doesn't make restrictions on what the input to a module should be - it's common to have a single Tensor, but you can also write modules that take in tuples, namedtuples, etc - as long as the leaf values in these structures are either TensorFlow Tensors or python primitives (which can then be converted to Tensors) you should be fine.

Please see rnn_shakespeare.py for an example - the dataset object included there does something similar and returns a tuple of (observations, targets). You could then make a module which internally splits this apart, applies an inner model to the observations to make predictions, then a loss function, etc.

The fact that modules take TensorFlow Tensor objects as input and output is already documented in the Readme, under the question ""Q: Can I mix this with other high level TF APIs, eg TF Slim?"". I'm closing this but please reopen if you find that this section is insufficient.




",hypothetical example sonnet data loading library provide one folder motivation case data single tensor linear module ca apply linear anything single tensor general data could something different write module specific shape data sonnet make input module common single tensor also write take long leaf either python converted fine please see example object included something similar could make module internally apart inner model make loss function fact take tensor input output already question mix high level slim please reopen find section insufficient,issue,positive,positive,neutral,neutral,positive,positive
296658702,"In the readme specifically there's a snippet showing that you get the training/test data after calling functions. I would like to know what format does this data use, is it the same as Tensorflow or something else?",specifically snippet showing get data calling would like know format data use something else,issue,negative,neutral,neutral,neutral,neutral,neutral
296619087,would really appreciate python3 support),would really appreciate python support,issue,positive,positive,positive,positive,positive,positive
296369834,"While I got the same error as reported, resolved with moving out from build directory. 

$ git clone https://github.com/deepmind/sonnet.git
$ cd sonnet/tensorflow
$ ./configure
$ cd ../
$ mkdir /tmp/sonnet
$ bazel build --config=opt :install
$ ./bazel-bin/install /tmp/sonnet
$ pip install /tmp/sonnet/*.whl
$ python

>>> import sonnet as snt
>>> import tensorflow as tf
>>> snt.resampler(tf.constant([0.]), tf.constant([0.]))
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""sonnet/python/ops/resampler.py"", line 65, in resampler
    raise ImportError(""_gen_resampler could not be imported."")
ImportError: _gen_resampler could not be imported.


$ cd  # out from sonnet source directory.
$ python

>>> import sonnet as snt
>>> import tensorflow as tf
>>> snt.resampler(tf.constant([0.]), tf.constant([0.]))
<tf.Tensor 'resampler/Resampler:0' shape=(1,) dtype=float32>",got error resolved moving build directory git clone build install pip install python import sonnet import recent call last file line module file line raise could could sonnet source directory python import sonnet import,issue,negative,neutral,neutral,neutral,neutral,neutral
296363674,"Any news on the PR? If it looks to shabby to merge, just say a word and close.",news shabby merge say word close,issue,negative,neutral,neutral,neutral,neutral,neutral
296344852,"@gyang1011  try ""/tmp/tensorflow_pkg/tensorflow-1.1.0-cp27-cp27mu-linux_x86_64.whl"".
""rc1"" string seems to be removed in r1.1 branch.
I also follow the above instruction and have successfully installed on [alpine based docker image](https://github.com/smizy/docker-sonnet). resampler output is fine.
",try string removed branch also follow instruction successfully alpine based docker image output fine,issue,positive,positive,positive,positive,positive,positive
296337626,I use virtual box so I chose to disable CUDA (no GPU and OpenCL),use virtual box chose disable,issue,negative,neutral,neutral,neutral,neutral,neutral
296333850,"![image](https://cloud.githubusercontent.com/assets/16380725/25299856/3688b4b4-2736-11e7-94ac-18254dcecc29.png)

Not that. It just the example to use the resampler from sonnet. Maybe python3 is not work now.",image example use sonnet maybe python work,issue,negative,neutral,neutral,neutral,neutral,neutral
296325022,"@arnaghizadeh I follow the instruction in your link but I still encounter this problem:
      ImportError: _gen_resampler could not be imported

Is /tmp/tensorflow_pkg/tensorflow-1.1.0rc1-cp27-cp27mu-linux_x86_64.whl a gpu version of tensorflow?
",follow instruction link still encounter problem could version,issue,negative,neutral,neutral,neutral,neutral,neutral
296238501,"Check that you did not try the example from the sonnet folder, it often doesn't work. ",check try example sonnet folder often work,issue,negative,neutral,neutral,neutral,neutral,neutral
296237769,"It's not work at last. Although there is not bug while installing, it raised the Import Error while using the verify example. ",work last although bug raised import error verify example,issue,negative,neutral,neutral,neutral,neutral,neutral
296156926,"@normanheckscher Ok, I see. Thanks for the response! I makes sense that you should use the tensorflow version that this repository links against.

Python3 is not officially supported but #10 made it sound like compatibility is just some small code changes away.",see thanks response sense use version repository link python officially made sound like compatibility small code away,issue,positive,positive,positive,positive,positive,positive
296156458,@arnaghizadeh it looks like an older version of tensorflow is needed. Working around tensorflow @ 36a47f2 is the only way I've been able to get Sonnet running.,like older version working around way able get sonnet running,issue,negative,positive,positive,positive,positive,positive
296155705,"@thomkeh I managed to get it working by being very particular with my tensorflow install. I'm guessing that the issue lies somewhere around interoperability with Tensorflow as I've played with differing versions of TensorFlow in both the sonnet directory and in my workstation environment (using virtualenv).

After building and installing an older version of Tensorflow I have been able to get Sonnet running. I'd suggest using git to build tensorflow @ 36a47f2, as this is the version which Sonnet is linked against. I'm currently using it to bang out multi-cpu models with mnist... variable success (recursive pun intended)... so yeah, it does work.

Is python 3 supported?",get working particular install guessing issue somewhere around sonnet directory environment building older version able get sonnet running suggest git build version sonnet linked currently bang variable success recursive pun intended yeah work python,issue,positive,positive,positive,positive,positive,positive
296152176,"I have the same error as @normanheckscher (""undefined symbol: ZN10tensorflow..."") but my tensorflow is simply 1.0.1 from pip and I'm using Python3. So whatever @normanheckscher thinks was the problem, can't be the problem.",error undefined symbol simply pip python whatever problem ca problem,issue,negative,neutral,neutral,neutral,neutral,neutral
296084092,"I followed the steps described by @roman3017 in issue number #5. Now sonnet is working. Seems to be some lib refences issues between tensorflow 1.0.1 and sonnet:
Please use the below instructions to install sonnet: 

```
cd sonnet/tensorflow
git checkout r1.1
./configure
bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg
sudo -H pip uninstall tensorflow
sudo -H pip install /tmp/tensorflow_pkg/tensorflow-1.1.0rc1-cp27-cp27mu-linux_x86_64.whl
cd ../
bazel build --config=opt //:install
bazel-bin/install /tmp/sonnet_pkg
sudo -H pip uninstall sonnet
sudo -H pip install /tmp/sonnet_pkg/sonnet-1.0-py2-none-any.whl
```",issue number sonnet working sonnet please use install sonnet git build pip pip install build install pip sonnet pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
296059977,"floodsung@floodsung:~/Documents/sonnet$ bazel build --config=opt :install
Warning: ignoring http_proxy in environment.
Extracting Bazel installation...
.........
WARNING: Config values are not defined in any .rc file: opt
WARNING: /home/floodsung/.cache/bazel/_bazel_floodsung/7e8a8460c09d6f45cdda8156f9433431/external/org_tensorflow/tensorflow/workspace.bzl:72:5: tf_repo_name was specified to tf_workspace but is no longer used and will be removed in the future.
WARNING: /home/floodsung/Documents/sonnet/sonnet/python/BUILD:119:1: in srcs attribute of cc_binary rule //sonnet/python:ops/_resampler.so: please do not import '//sonnet/cc:ops/resampler.cc' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_custom_op_library', the error might have been caused by the macro implementation in /home/floodsung/Documents/sonnet/sonnet/tensorflow.bzl:108:25.
WARNING: /home/floodsung/Documents/sonnet/sonnet/python/BUILD:119:1: in srcs attribute of cc_binary rule //sonnet/python:ops/_resampler.so: please do not import '//sonnet/cc/kernels:resampler_op.cc' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_custom_op_library', the error might have been caused by the macro implementation in /home/floodsung/Documents/sonnet/sonnet/tensorflow.bzl:108:25.
WARNING: /home/floodsung/Documents/sonnet/sonnet/python/BUILD:119:1: in srcs attribute of cc_binary rule //sonnet/python:ops/_resampler.so: please do not import '//sonnet/cc/kernels:resampler_op.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_custom_op_library', the error might have been caused by the macro implementation in /home/floodsung/Documents/sonnet/sonnet/tensorflow.bzl:108:25.

Do you have the same WARNINGs?",build install warning environment installation warning defined file opt warning longer used removed future warning attribute rule please import directly either move file package depend appropriate rule since rule macro error might macro implementation warning attribute rule please import directly either move file package depend appropriate rule since rule macro error might macro implementation warning attribute rule please import directly either move file package depend appropriate rule since rule macro error might macro implementation,issue,negative,positive,positive,positive,positive,positive
296025891,"Hi, 
  I am also facing the simialr issue; My enviroment is Ubuntu 16.04, Tensorflow '1.0.1'. I am getting follwoing error, when I try to import sonnet
```
----> 1 import sonnet as snt
/home/sathish/anaconda3/envs/py27/lib/python2.7/site-packages/sonnet/__init__.py in <module>()
    100 from sonnet.python.ops import nest
    101 from sonnet.python.ops.initializers import restore_initializer
--> 102 from sonnet.python.ops.resampler import resampler
    103 from sonnet.python.ops.resampler import resampler_is_available

/home/sathish/anaconda3/envs/py27/lib/python2.7/site-packages/sonnet/python/ops/resampler.py in <module>()
     31   # Link the shared object.
     32   _resampler_so = tf.load_op_library(
---> 33       tf.resource_loader.get_path_to_datafile(""_resampler.so""))
     34 
     35 

/home/sathish/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/framework/load_library.pyc in load_op_library(library_filename)
     62       # pylint: disable=protected-access
     63       raise errors_impl._make_specific_exception(
---> 64           None, None, error_msg, error_code)
     65       # pylint: enable=protected-access
     66   finally:

NotFoundError: /home/sathish/anaconda3/envs/py27/lib/python2.7/site-packages/sonnet/python/ops/_resampler.so: undefined symbol: _ZN10tensorflow8internal21CheckOpMessageBuilder9NewStringB5cxx11Ev
```

This is output from the command `nm _resampler.so | grep CheckOpMessageBuilder`
`0000000000017bfa W _ZN10tensorflow8internal21CheckOpMessageBuilder7ForVar1Ev
                 U _ZN10tensorflow8internal21CheckOpMessageBuilder7ForVar2Ev
                 U _ZN10tensorflow8internal21CheckOpMessageBuilder9NewStringB5cxx11Ev
                 U _ZN10tensorflow8internal21CheckOpMessageBuilderC1EPKc
                 U _ZN10tensorflow8internal21CheckOpMessageBuilderD1Ev
`

This is the output form command: `nm _pywrap_tensorflow.so | grep CheckOpMessageBuilder`

`00000000023ba280 T _ZN10tensorflow8internal21CheckOpMessageBuilder7ForVar2Ev
00000000023ba2b0 T _ZN10tensorflow8internal21CheckOpMessageBuilder9NewStringEv
00000000023ba0a0 T _ZN10tensorflow8internal21CheckOpMessageBuilderC1EPKc
00000000023ba0a0 T _ZN10tensorflow8internal21CheckOpMessageBuilderC2EPKc
00000000023ba250 T _ZN10tensorflow8internal21CheckOpMessageBuilderD1Ev
00000000023ba250 T _ZN10tensorflow8internal21CheckOpMessageBuilderD2Ev
`",hi also facing issue getting error try import sonnet import sonnet module import nest import import import module link object raise none none finally undefined symbol output command output form command ba baa baa ba ba,issue,negative,neutral,neutral,neutral,neutral,neutral
295968634,"As an update, I used [this](https://github.com/deepmind/sonnet/issues/5#issuecomment-292795066) method (takes a lot of time to compile) and it seems to be working. Currently I cannot run sonnet properly from official instructions.",update used method lot time compile working currently run sonnet properly official,issue,negative,neutral,neutral,neutral,neutral,neutral
295835265,"$ nm /usr/lib/python2.7/site-packages/sonnet/python/ops/_resampler.so | grep CheckOpMessageBuilder
00000000000176ba W _ZN10tensorflow8internal21CheckOpMessageBuilder7ForVar1Ev
                 U _ZN10tensorflow8internal21CheckOpMessageBuilder7ForVar2Ev
                 U _ZN10tensorflow8internal21CheckOpMessageBuilder9NewStringB5cxx11Ev
                 U _ZN10tensorflow8internal21CheckOpMessageBuilderC1EPKc
                 U _ZN10tensorflow8internal21CheckOpMessageBuilderD1Ev

As for $SITE_PACKAGES_DIR/tensorflow/python/_pywrap_tensorflow.so, the output is a huge list of similarly formatted lines. ",ba output huge list similarly,issue,negative,positive,positive,positive,positive,positive
295793476,"Hi,

The second error is expected, as you're trying to import from the source directory, which doesn't have the compiled library available.

As for the first, seems like some symbols that Sonnet expects to be present are not. Can you run ""nm $file | grep CheckOpMessageBuilder"" on the sonnet _resampler.so file, as well as $SITE_PACKAGES_DIR/tensorflow/python/_pywrap_tensorflow.so.

For reference, I see the following (on Mac):

```
$ nm /tmp/sonnet/sonnet/python/ops/_resampler.so | grep CheckOpMessageBuilder
0000000000001a30 t __ZN10tensorflow8internal21CheckOpMessageBuilder7ForVar1Ev
                 U __ZN10tensorflow8internal21CheckOpMessageBuilder7ForVar2Ev
                 U __ZN10tensorflow8internal21CheckOpMessageBuilder9NewStringEv
                 U __ZN10tensorflow8internal21CheckOpMessageBuilderC1EPKc
                 U __ZN10tensorflow8internal21CheckOpMessageBuilderD1Ev

$ nm _pywrap_tensorflow.so  | grep CheckOpMessageBuilder
0000000001b8de00 T __ZN10tensorflow8internal21CheckOpMessageBuilder7ForVar2Ev
0000000001b8de30 T __ZN10tensorflow8internal21CheckOpMessageBuilder9NewStringEv
0000000001b8ddb0 T __ZN10tensorflow8internal21CheckOpMessageBuilderC1EPKc
0000000001b8dc80 T __ZN10tensorflow8internal21CheckOpMessageBuilderC2EPKc
0000000001b8dde0 T __ZN10tensorflow8internal21CheckOpMessageBuilderD1Ev
0000000001b8ddc0 T __ZN10tensorflow8internal21CheckOpMessageBuilderD2Ev
```

ie, the resampler file contains references to a bunch of external symbols, but they are all defined in the main tensorflow static library. I suspect you will see that you don't have those symbols available, which should help us debug further.

",hi second error trying import source directory library available first like sonnet present run file sonnet file well reference see following mac ie file bunch external defined main static library suspect see available help u,issue,negative,positive,positive,positive,positive,positive
295761991,"I got the same error as @schani for both Python 2.7 and Python 3.6
There is a warning during compiling
```
please do not import '//sonnet/cc:ops/resampler.cc' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_custom_op_library', the error might have been caused by the macro implementation in /home/??/sonnet/sonnet/tensorflow.bzl:108:25.
```",got error python python warning please import directly either move file package depend appropriate rule since rule macro error might macro implementation,issue,negative,positive,positive,positive,positive,positive
295561706,"Managed to get it to work.
My separately installed tensorflow version (outside the sonnet directory) was originally form the head and a version of 1.1.0rc2. I changed this tensorflow version with git, recompiled and installed the resultant tensorflow-1.1.0rc1-cp27-cp27mu-linux_x86_64.whl. After this, sonnet build, installs and runs as expected.

`cd ~/workspace/tensorflow`
`git checkout r1.1`
`./configure`
`bazel build -c opt --copt=-mavx --copt=-mfpmath=both --copt=-msse4.2 --copt=-msse4.1 --config=cuda -k //tensorflow/tools/pip_package:build_pip_package --verbose_failures`
`bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp//tensorflow_pkg/`
`pip install --upgrade /tmp/tensorflow_pkg/tensorflow-1.1.0rc1-cp27-cp27mu-linux_x86_64.whl`
`cd ~/workspace`
`git clone --recursive https://github.com/deepmind/sonnet`
`etc etc etc from the sonnet instructions`
",get work separately version outside sonnet directory originally form head version version git resultant sonnet build git build opt pip install upgrade git clone recursive sonnet,issue,negative,positive,positive,positive,positive,positive
295479053,"@malcolmreynolds It builds, I just can't import it. I'll try and look a little further into it sometime over the next few days when I get more time.

Python 2.7.12 (default, Nov 19 2016, 06:48:10) 
[GCC 5.4.0 20160609] on linux2
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import sonnet as snt
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/norman/.virtualenvs/tf/local/lib/python2.7/site-packages/sonnet/__init__.py"", line 102, in <module>
    from sonnet.python.ops.resampler import resampler
  File ""/home/norman/.virtualenvs/tf/local/lib/python2.7/site-packages/sonnet/python/ops/resampler.py"", line 33, in <module>
    tf.resource_loader.get_path_to_datafile(""_resampler.so""))
  File ""/home/norman/.virtualenvs/tf/local/lib/python2.7/site-packages/tensorflow/python/framework/load_library.py"", line 64, in load_op_library
    None, None, error_msg, error_code)
tensorflow.python.framework.errors_impl.NotFoundError: /home/norman/.virtualenvs/tf/local/lib/python2.7/site-packages/sonnet/python/ops/_resampler.so: undefined symbol: _ZN10tensorflow15shape_inference16InferenceContext15WithRankAtLeastENS0_11ShapeHandleEiPS2_
>>> 
",ca import try look little sometime next day get time python default type help copyright license information import sonnet recent call last file line module file line module import file line module file line none none undefined symbol,issue,negative,negative,neutral,neutral,negative,negative
295359528,"Assuming that I managed to clean the bazel caches correctly (`bazel clean --expunge`) then yes, it does work, i.e. I get no compile errors.",assuming clean correctly clean expunge yes work get compile,issue,positive,positive,positive,positive,positive,positive
295340085,@bfredl we hope to have python3 internal testing up and running shortly.,hope python internal testing running shortly,issue,negative,neutral,neutral,neutral,neutral,neutral
295336345,"@normanheckscher @leesunfreshing @johnnogent @cgarciae  We have pushed a fix, please can you try and build again?",fix please try build,issue,negative,neutral,neutral,neutral,neutral,neutral
295335961,@esc @roman3017 We have pushed a different fix which does not remove the const semantics - please let me know if this fixes the issue.,different fix remove semantics please let know issue,issue,negative,neutral,neutral,neutral,neutral,neutral
294634253,"As stated in the Readme, Python 3 is currently not supported. There is a [pending PR](https://github.com/deepmind/sonnet/pull/10)  adding this support, we hope to have it integrated soon.",stated python currently pending support hope soon,issue,positive,neutral,neutral,neutral,neutral,neutral
294379739,"Thanks @esc 
Updated the fork to match with new master branch.",thanks fork match new master branch,issue,negative,positive,positive,positive,positive,positive
294377971,Thanks so much for your swift response--- and all good then! You have convinced me you know what you are doing.,thanks much swift response good convinced know,issue,positive,positive,positive,positive,positive,positive
294374975,"Thanks for raising this.

As you mention, doing this has a high risk, and we are fully aware of that. It is also by the reasons you point out that we still did it in this case (low number of public clones + being only in its first 1.5 weeks). If this same situation were to happen at any point in the future, history rewrite will surely be our last resort (as it should be for any git repository, again for those reasons). All PRs will be notified of the required rebase.",thanks raising mention high risk fully aware also point still case low number public first situation happen point future history rewrite surely last resort git repository notified rebase,issue,negative,positive,positive,positive,positive,positive
294372677,"Incidentally, you may want to notify @rakshit-agrawal that his fork is broken and needs to be fixed.",incidentally may want notify fork broken need fixed,issue,negative,negative,negative,negative,negative,negative
294372547,"I am not sure how familiar you are with git, but you do realize that force-pushing a `master` branch does present somewhat of a risk?

I see that, with such a small history and limited number of public clones this may be considered a reasonable thing to do. However, at least one person has already executed a `git pull` on their local clone: https://github.com/deepmind/sonnet/network which means that old and new history have been merged there. (Which is exactly the danger of force-pushing to `master`).

Is something like this likely to happen again? If yes, do you intend to create some guidelines as to how people should be using their forks and clones?",sure familiar git realize master branch present somewhat risk see small history limited number public may considered reasonable thing however least one person already executed git pull local clone old new history exactly danger master something like likely happen yes intend create people,issue,negative,positive,neutral,neutral,positive,positive
294300969,"The other thing to do is to check if `nvidias-smi` is on the `PATH`, execute it and make sure it returns with a 0 as exit code.",thing check path execute make sure exit code,issue,negative,positive,positive,positive,positive,positive
294286250,"Now I get exactly the same errors in python2 and python3, so they're probably due to differences in testing environment. Apart from building I just set `TEST_SRCDIR` and run `nosetests2/3`. I use recent-ish tensorflow-git.

@diegolascasas would you be able to run the tests with python3 on your infrastructure?",get exactly python python probably due testing environment apart building set run use would able run python infrastructure,issue,negative,positive,positive,positive,positive,positive
294280047,"Yes, that has been done now. We've put more checks in our exportation procedure to avoid this situation in the future.",yes done put exportation procedure avoid situation future,issue,negative,neutral,neutral,neutral,neutral,neutral
294278129,"Just to clarify: you will force update the 'deepmind/sonnet'  'master' on github?

On 15 April 2017 00:17:10 CEST, ""Adrià Puigdomènech"" <notifications@github.com> wrote:
>We really appreciate that you noticed this, as Tim said this got in
>when merging new changes. In order to have a clean commit history with
>the correct path at all times, I fixed the mistake in the corresponding
>spurious commit (this will unfortunately break your local repository,
>you may need to re-clone). I'll close this for now, my apologies since
>in this case the credit assignment is not ideal!
>
>-- 
>You are receiving this because you authored the thread.
>Reply to this email directly or view it on GitHub:
>https://github.com/deepmind/sonnet/pull/19#issuecomment-294247069

-- 
Sent from my Android device with K-9 Mail. Please excuse my brevity.",clarify force update cest wrote really appreciate said got new order clean commit history correct path time fixed mistake corresponding spurious commit unfortunately break local repository may need close since case credit assignment ideal thread reply directly view sent android device mail please excuse brevity,issue,positive,positive,positive,positive,positive,positive
294247069,"We really appreciate that you noticed this, as Tim said this got in when merging new changes. In order to have a clean commit history with the correct path at all times, I fixed the mistake in the corresponding spurious commit (this will unfortunately break your local repository, you may need to re-clone). I'll close this for now, my apologies since in this case the credit assignment is not ideal!",really appreciate said got new order clean commit history correct path time fixed mistake corresponding spurious commit unfortunately break local repository may need close since case credit assignment ideal,issue,positive,positive,positive,positive,positive,positive
294245284,@malcolmreynolds: Please fix the code. I will close this pull request once it is not needed. No credit is required.,please fix code close pull request credit,issue,positive,neutral,neutral,neutral,neutral,neutral
294141580,"How would one use this? is it:

```
pip install sonnet[tensorflow]
```

And:

```
pip install sonnet[tensorflow-gpu]
```",would one use pip install sonnet pip install sonnet,issue,negative,neutral,neutral,neutral,neutral,neutral
294138655,"The fix is good, but just changing the source code in the git clone ""appears"" not to fix the problem. A rebuild like:

```
 bazel build --config=opt :install && pip uninstall --yes sonnet && pip install /tmp/sonnet/*
```

is required for the changes to be picked up.",fix good source code git clone fix problem rebuild like build install pip yes sonnet pip install picked,issue,positive,positive,positive,positive,positive,positive
294136254,"Looks like the correct path got lost when merging internal changes:

https://github.com/deepmind/sonnet/commit/bcc6f39cbb89d734d51ffd886aad571ef1fb5089#diff-19d411cc222fde5e46b617d9733e7b9e",like correct path got lost internal,issue,negative,neutral,neutral,neutral,neutral,neutral
293973279,"This, together with #6, made the build succeed, but after installing the wheel file, it seems like it can't find the native library:

```
[17:41]: python
Python 2.7.13 |Continuum Analytics, Inc.| (default, Dec 20 2016, 23:09:15)
[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)] on linux2
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
Anaconda is brought to you by Continuum Analytics.
Please check out: http://continuum.io/thanks and https://anaconda.org
>>> import sonnet as snt
>>> import tensorflow as tf
>>> snt.resampler(tf.constant([0.]), tf.constant([0.]))
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/ubuntu/anaconda3/envs/p27-tf1/lib/python2.7/site-packages/sonnet/python/ops/resampler.py"", line 62, in resampler
    raise ImportError(""_gen_resampler could not be imported."")
ImportError: _gen_resampler could not be imported.
```

The wheel file also doesn't contain a native library:

```
[17:44]: unzip -l ./sonnet-install/sonnet-1.0-py2-none-any.whl  | less
Archive:  ./sonnet-install/sonnet-1.0-py2-none-any.whl
  Length      Date    Time    Name
---------  ---------- -----   ----
     4817  2017-04-13 17:41   sonnet/__init__.py
     8064  2017-04-13 17:41   sonnet/examples/dataset_shakespeare.py
      809  2017-04-13 17:41   sonnet/examples/__init__.py
    11702  2017-04-13 17:41   sonnet/examples/rnn_shakespeare.py
     3751  2017-04-13 17:41   sonnet/examples/module_with_build_args.py
   892315  2017-04-13 17:41   sonnet/examples/data/ts.train.txt
   111539  2017-04-13 17:41   sonnet/examples/data/ts.valid.txt
   111540  2017-04-13 17:41   sonnet/examples/data/ts.test.txt
      844  2017-04-13 17:41   sonnet/python/__init__.py
     5452  2017-04-13 17:41   sonnet/python/modules/experimental.py
    15044  2017-04-13 17:41   sonnet/python/modules/base.py
     7712  2017-04-13 17:41   sonnet/python/modules/pondering_rnn.py
    13392  2017-04-13 17:41   sonnet/python/modules/rnn_core.py
    20102  2017-04-13 17:41   sonnet/python/modules/batch_norm.py
     7109  2017-04-13 17:41   sonnet/python/modules/embed.py
    12396  2017-04-13 17:41   sonnet/python/modules/util.py
      829  2017-04-13 17:41   sonnet/python/modules/__init__.py
     7812  2017-04-13 17:41   sonnet/python/modules/block_matrix.py
     7402  2017-04-13 17:41   sonnet/python/modules/attention.py
     2053  2017-04-13 17:41   sonnet/python/modules/clip_gradient.py
   105355  2017-04-13 17:41   sonnet/python/modules/conv.py
     2044  2017-04-13 17:41   sonnet/python/modules/scale_gradient.py
    34392  2017-04-13 17:41   sonnet/python/modules/gated_rnn.py
    19266  2017-04-13 17:41   sonnet/python/modules/basic_rnn.py
    23212  2017-04-13 17:41   sonnet/python/modules/spatial_transformer.py
     3510  2017-04-13 17:41   sonnet/python/modules/sequential.py
    43211  2017-04-13 17:41   sonnet/python/modules/basic.py
    21282  2017-04-13 17:41   sonnet/python/modules/nets/convnet.py
    10619  2017-04-13 17:41   sonnet/python/modules/nets/alexnet.py
     1301  2017-04-13 17:41   sonnet/python/modules/nets/__init__.py
     8110  2017-04-13 17:41   sonnet/python/modules/nets/mlp.py
    13456  2017-04-13 17:41   sonnet/python/modules/nets/dilation.py
   264952  2017-04-13 17:41   sonnet/python/ops/_resampler.so
    10734  2017-04-13 17:41   sonnet/python/ops/nest.py
      833  2017-04-13 17:41   sonnet/python/ops/__init__.py
     3377  2017-04-13 17:41   sonnet/python/ops/initializers.py
     2860  2017-04-13 17:41   sonnet/python/ops/resampler.py
       10  2017-04-13 17:41   sonnet-1.0.dist-info/DESCRIPTION.rst
     1134  2017-04-13 17:41   sonnet-1.0.dist-info/metadata.json
        7  2017-04-13 17:41   sonnet-1.0.dist-info/top_level.txt
       92  2017-04-13 17:41   sonnet-1.0.dist-info/WHEEL
      888  2017-04-13 17:41   sonnet-1.0.dist-info/METADATA
     3867  2017-04-13 17:41   sonnet-1.0.dist-info/RECORD
---------                     -------
  1819196                     43 files
```",together made build succeed wheel file like ca find native library python python analytics default red hat type help copyright license information anaconda brought continuum analytics please check import sonnet import recent call last file line module file line raise could could wheel file also contain native library le archive length date time name,issue,positive,neutral,neutral,neutral,neutral,neutral
293954714,"> Can you verify your changes still make sonnet Python3 compatible?

Mostly, the new `testing/parameterized/parameterized.py` caused some trouble. 

The only remaining sonnet failure is:
```
======================================================================
ERROR: testHasVariableScope (sonnet.python.modules.util_test.UtilTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/home/bjorn/dev/sonnet/sonnet/python/modules/util_test.py"", line 258, in testHasVariableScope
    self.assertTrue(snt.has_variable_scope(linear))
  File ""/home/bjorn/dev/sonnet/sonnet/python/modules/util.py"", line 312, in has_variable_scope
    return hasattr(obj, ""variable_scope"") or ""variable_scope"" in dir(obj)
  File ""/home/bjorn/dev/sonnet/sonnet/python/modules/base.py"", line 261, in variable_scope
    self._ensure_is_connected()
  File ""/home/bjorn/dev/sonnet/sonnet/python/modules/base.py"", line 351, in _ensure_is_connected
    ""first."".format(self.scope_name))
sonnet.python.modules.base.NotConnectedError: Variables in linear not instantiated yet, __call__ the module first.
```

But there some more failures in the parameterized tests tests:
https://gist.github.com/bfredl/60f529c629e48e72d5e19824be271a83

I might look into them later.",verify still make sonnet python compatible mostly new trouble sonnet failure error recent call last file line linear file line return file line file line first linear yet module first might look later,issue,negative,positive,neutral,neutral,positive,positive
293934887,"Hi bfredl,
Thank you for your contribution, and sorry for the delay.
We are ready to merge your PR, but can you first rebase it to the latest commit and solve the conflicts?
Note that we added some bits of functionality to the code. They were already in the process of being released and we needed to add them before accepting any PR. Can you verify your changes still make sonnet Python3 compatible?",hi thank contribution sorry delay ready merge first rebase latest commit solve note added functionality code already process add verify still make sonnet python compatible,issue,positive,positive,positive,positive,positive,positive
293933077,"Thanks!
We pushed a commit with you as author. 
We had to adapt the way we are exporting the code, so some minor changes in other parts of the code were also included in your commit. They should be only cosmetic, but if you disagree with them being in your commit, please notify us. ",thanks commit author adapt way code minor code also included commit cosmetic disagree commit please notify u,issue,positive,positive,neutral,neutral,positive,positive
293882684,"Hi albertz,
Thank you for your contribution, and sorry for the delay.
We are ready to merge your PR, but can you first rebase it to the latest commit?",hi thank contribution sorry delay ready merge first rebase latest commit,issue,positive,positive,positive,positive,positive,positive
293850520,"It looks like bazel has a problem with sandboxing on your machine.
Can you tru re-running the command with
```
--genrule_strategy=standalone --spawn_strategy=standalone
```
added to the command line?",like problem machine command added command line,issue,negative,neutral,neutral,neutral,neutral,neutral
293814871,"Ah, perhaps I didn't construe the statement in the docs correctly. It doesn't say the variables are shared across multiple instances of MyMLP. It says given a single instance of MyMLP (that is connected into the graph multiple times) that the variables are shared. 

I should just try it out. Closing.",ah perhaps construe statement correctly say across multiple given single instance connected graph multiple time try,issue,negative,negative,neutral,neutral,negative,negative
293601203,Yes now it runs smoothly. Plz close the issue,yes smoothly close issue,issue,negative,positive,positive,positive,positive,positive
293545048,"It seems to be mostly supported already, but some fixes are needed. See #10. At least all functionality used by `rnn_shakesphere.py` works fine.",mostly already see least functionality used work fine,issue,negative,positive,positive,positive,positive,positive
293442747,"@kosklain: Originally I had installed the latest master branch of TF from the source, which was not working with sonnet for me when I just configured the headers.",originally latest master branch source working sonnet,issue,negative,positive,positive,positive,positive,positive
293412060,"Very simply, if you want us to take your patch, you need to comply with the CLA requirements. We can revisit the inherent CLA of the apache license in a different bug, but we are not able to be flexible on this.",simply want u take patch need comply revisit inherent apache license different bug able flexible,issue,negative,positive,positive,positive,positive,positive
293251358,"@normanheckscher Now it works. Seven hours ago, it did not work, but now it works. Nothing has changed. So wired.",work seven ago work work nothing wired,issue,negative,neutral,neutral,neutral,neutral,neutral
293250303,"@normanheckscher Since my previous tensorflow version is 0.12, I both built sonnet and tensorflow 1.1 from source. Now tensorflow works well, but sonnet cannot work and _gen_resampler could not be imported.
My Ubuntu is 14.04, CUDA is 8.1 and cuDNN 5.1. I am using a Titan X.",since previous version built sonnet source work well sonnet work could,issue,negative,negative,negative,negative,negative,negative
293197176,"@roman3017 I am trying to investigate why you needed to reinstall TensorFlow as well. Ideally, a person that has installed TensorFlow via the pip package shouldn't need to reinstall the library. To have more information, what version of TensorFlow was installed in your system before you uninstalled it?",trying investigate reinstall well ideally person via pip package need reinstall library information version system uninstalled,issue,positive,positive,positive,positive,positive,positive
293189808,"@Kongsea that initial test works for me. I've even run the sonnet/examples/rnn_shakespeare.py example without getting that error. 

Ubuntu 16.04 LTS
Latest CUDA and cuDNN from Nvidia
GTX 1080
TensorFlow compiled and installed (prior to compiling and installing sonnet) from the head with GPU enabled.",initial test work even run example without getting error latest prior sonnet head,issue,negative,positive,positive,positive,positive,positive
293159885,"I have used the method @roman3017 mentioned and compiled and installed both sonnet and tensorflow.
However, when running the example:

`snt.resampler(tf.constant([0.]), tf.constant([0.]))`

It gives the same error as @roman3017 :

> Traceback (most recent call last):
>   File ""<stdin>"", line 1, in <module>
>   File ""sonnet/python/ops/resampler.py"", line 62, in resampler
>     raise ImportError(""_gen_resampler could not be imported."")
> ImportError: _gen_resampler could not be imported.",used method sonnet however running example error recent call last file line module file line raise could could,issue,negative,neutral,neutral,neutral,neutral,neutral
293060995,"Thanks Tom, but it makes our life easier if DM employees can instead submit changes to the internal systems, as we are using that as the source of truth, and each GitHub PR creates some amount of extra obstacles.

Come find me tomorrow if you have questions..",thanks life easier instead submit internal source truth amount extra come find tomorrow,issue,positive,positive,neutral,neutral,positive,positive
293060252,"Thanks! Assigning to Diego for merging internally.

Please note: unlike TensorFlow, we will not be directly merging patches via GitHub, as we are our using our internal source control system as the single source of truth for Sonnet. Instead, once reviewed, we will incorporate your change to our system, and then push all changes including yours to GitHub, with a commit which ensures you retain attribution. This process is also used by [Bazel](https://github.com/bazelbuild/bazel). We expect our version of this to be up and running in the next few days - any questions, please let me know.",thanks internally please note unlike directly via internal source control system single source truth sonnet instead incorporate change system push commit retain attribution process also used expect version running next day please let know,issue,positive,positive,neutral,neutral,positive,positive
293059500,"Thanks for this - as you say, we knew the codebase was more or less 2/3 compatible but didn't have Python 3 testing infrastructure yet so wanted to err on the side of caution.

Assigning to Diego to test internally & review.

Please note: unlike TensorFlow, we will not be directly merging patches via GitHub, as we are our using our internal source control system as the single source of truth for Sonnet. Instead, once reviewed, we will incorporate your change to our system, and then push all changes including yours to GitHub, with a commit which ensures you retain attribution. This process is also used by [Bazel](https://github.com/bazelbuild/bazel). We expect our version of this to be up and running in the next few days - any questions, please let me know.",thanks say knew le compatible python testing infrastructure yet err side caution test internally review please note unlike directly via internal source control system single source truth sonnet instead incorporate change system push commit retain attribution process also used expect version running next day please let know,issue,positive,positive,neutral,neutral,positive,positive
293058056,"Hi,

Sorry but I'm not sure I see the purpose of this PR? What does printing the Error class several during class definition achieve?",hi sorry sure see purpose printing error class several class definition achieve,issue,negative,neutral,neutral,neutral,neutral,neutral
293057274,"@normanheckscher thanks for the fix - we'll get it in ASAP, and I'll close this issue once the changes are pushed back out to GitHub.",thanks fix get close issue back,issue,negative,positive,neutral,neutral,positive,positive
293057033,"Hi,

Can you provide a few more details? What platform are you on, and how did you (originally) install TF?",hi provide platform originally install,issue,negative,positive,positive,positive,positive,positive
293050764,"The problem is that the is_macos check fails in the sed_hyphen_i() function if you are using something like homebrew instead of the default sed.  If you are using homebrew or another version of sed on macOS then comment out everything and just leave sed -i ""$@""",problem check function something like instead default another version comment everything leave,issue,negative,neutral,neutral,neutral,neutral,neutral
292907023,"Works for me with OSX 10.12.4

On a side note: Mac GPU support in TensorFlow is deprecated as of the TensorFlow r1.1",work side note mac support,issue,negative,neutral,neutral,neutral,neutral,neutral
292889614,"We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.

<!-- need_author_cla -->",found contributor license agreement sender pull request unable find commit author maybe used different address git used sign login double check someone else need sign well confirm,issue,positive,negative,negative,negative,negative,negative
292799143,"I've pushed the image to docker hub in case anyone wants to use it for experimentation

```bash
docker run -p 8888:8888 -it davemssavage/sonnet
```",image docker hub case anyone use experimentation bash docker run,issue,negative,neutral,neutral,neutral,neutral,neutral
292797937,"An alternate approach from upgrading to TFr1.1 is included in this merge request:

https://github.com/deepmind/sonnet/pull/7

I've included the compile error fix from @roman3017 in that, can tidy that up assuming it's accepted",alternate approach included merge request included compile error fix tidy assuming accepted,issue,negative,positive,positive,positive,positive,positive
292795170,"Can't use with python3?
I got error with TFr1.1 and patch #6:
```
Python 3.5.2 (default, Apr  9 2017, 13:56:10)
[GCC 5.4.0 20160609] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import sonnet as snt
>>> import tensorflow as tf
>>> snt.resampler(tf.constant([0.]), tf.constant([0.]))
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
AttributeError: module 'sonnet' has no attribute 'resampler'
```",ca use python got error patch python default type help copyright license information import sonnet import recent call last file line module module attribute,issue,negative,neutral,neutral,neutral,neutral,neutral
292795066,"@kosklain: Yes, I am referring to the submodule and these are steps which worked for me together with the patch #6:
```bash
cd sonnet/tensorflow
git checkout r1.1
./configure
bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg
sudo -H pip uninstall tensorflow
sudo -H pip install /tmp/tensorflow_pkg/tensorflow-1.1.0rc1-cp27-cp27mu-linux_x86_64.whl
cd ../
bazel build --config=opt //:install
bazel-bin/install /tmp/sonnet_pkg
sudo -H pip uninstall sonnet
sudo -H pip install /tmp/sonnet_pkg/sonnet-1.0-py2-none-any.whl
```",yes worked together patch bash git build pip pip install build install pip sonnet pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
292790942,"@roman3017 thanks for looking into this. When you mention ""using r1.1 branch of tensorflow"", are you referring to the version linked here to obtain the headers (i.e. the submodule)? If so, I will merge your resampler_op.cc fix and make our submodule point to the r1.1 branch to make sure everyone can compile without an issue.",thanks looking mention branch version linked obtain merge fix make point branch make sure everyone compile without issue,issue,positive,positive,positive,positive,positive,positive
292789013,"@normanheckscher: Thanks, cd out of the sonnet source directory instead of changing LD_LIBRARY_PATH works for me.",thanks sonnet source directory instead work,issue,negative,positive,positive,positive,positive,positive
292773484,Instead of augmenting the LD_LIBRARY_PATH: cd out of the sonnet source directory before running python.,instead sonnet source directory running python,issue,negative,neutral,neutral,neutral,neutral,neutral
292754997,"@google-admin: This project has already LICENSE file with Apache License 2.0 included, which I will respect. I have already signed agreement with Github, which I believe is binding for all projects posted here. Please see: https://help.github.com/articles/github-terms-of-service. Here is a relevant quote from it:

> 6. Contributions Under Repository License
>
> Whenever you make a contribution to a repository containing notice of a license, you license your contribution under the same terms, and you agree that you have the right to license your contribution under those terms. If you have a separate agreement to license your contributions under different terms, such as a contributor license agreement, that agreement will supercede.
> 
> Isn't this just how it works already? Yep. This is widely accepted as the norm in the open-source community; it's commonly referred to by the shorthand ""inbound=outbound"". We're just making it explicit.
> 

Is your CLA conflicting this agreement with Github or the Apache License 2.0 of this project that you are requesting to sign an additional Contributor License Agreements? In particular I wonder why I have to disclose my address and phone number to Google in order to make a contribution.",project already license file apache license included respect already agreement believe binding posted please see relevant quote repository license whenever make contribution repository notice license license contribution agree right license contribution separate agreement license different contributor license agreement agreement work already yep widely accepted norm community commonly shorthand making explicit conflicting agreement apache license project sign additional contributor license particular wonder disclose address phone number order make contribution,issue,positive,positive,neutral,neutral,positive,positive
292749309,"Got it working after using r1.1 branch for tensorflow, recompiled and installed from source. The master branch for tensorflow did not work for me. Also had to augment LD_LIBRARY_PATH and use the patch https://github.com/deepmind/sonnet/issues/6, both are described above.
```python
>>> snt.resampler(tf.constant([0.]), tf.constant([0.]))
Tensor(""resampler/Resampler:0"", shape=(1,), dtype=float32)
```
```bash
~/projects/tensor/sonnet/sonnet/examples$ python rnn_shakespeare_test.py 
2017-04-08 16:08:26.416213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-04-08 16:08:26.416596: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties: 
name: GeForce GT 750M
major: 3 minor: 0 memoryClockRate (GHz) 0.967
pciBusID 0000:02:00.0
Total memory: 1.95GiB
Free memory: 1.10GiB
2017-04-08 16:08:26.416616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 
2017-04-08 16:08:26.416622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y 
2017-04-08 16:08:26.416633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GT 750M, pci bus id: 0000:02:00.0)
..
----------------------------------------------------------------------
Ran 2 tests in 59.776s

OK
```",got working branch source master branch work also augment use patch python tensor bash python successful node read negative value must least one node node zero found device name major minor total memory free memory device device name bus id ran,issue,positive,positive,neutral,neutral,positive,positive
292743764,"The problem with _resampler.so is:
```python
>>> import tensorflow as tf
>>> _gen_resampler = tf.load_op_library(tf.resource_loader.get_path_to_datafile(""_resampler.so""))
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/load_library.py"", line 64, in load_op_library
    None, None, error_msg, error_code)
tensorflow.python.framework.errors_impl.NotFoundError: _resampler.so: cannot open shared object file: No such file or directory
```
After augmenting the LD_LIBRARY_PATH:
```bash
~/projects/tensor$ export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/lib/python2.7/dist-packages/sonnet/python/ops
```
I am getting bit different problem:
```python
>>> import tensorflow as tf
>>> _gen_resampler = tf.load_op_library(tf.resource_loader.get_path_to_datafile(""_resampler.so""))
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/load_library.py"", line 64, in load_op_library
    None, None, error_msg, error_code)
tensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python2.7/dist-packages/sonnet/python/ops/_resampler.so: undefined symbol: _ZN10tensorflow15shape_inference16InferenceContext15WithRankAtLeastENS0_11ShapeHandleEiPS2_
```",problem python import recent call last file line module file line none none open object file file directory bash export getting bit different problem python import recent call last file line module file line none none undefined symbol,issue,negative,neutral,neutral,neutral,neutral,neutral
292730668,"However even with compile fix from @roman3017 sonnet is not working, I see this error message when running the basic sanity check

```bash
$ cd ~/
$ python
>>> import sonnet as snt
>>> import tensorflow as tf
>>> snt.resampler(tf.constant([0.]), tf.constant([0.]))
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python2.7/dist-packages/sonnet/python/ops/resampler.py"", line 62, in resampler
    raise ImportError(""_gen_resampler could not be imported."")
ImportError: _gen_resampler could not be imported.
```

Digging in a bit further to resampler.py it appears the _resampler.so file has some errors

```bash
$ python
>>> import sonnet as snt
>>> import tensorflow as tf
>>> _gen_resampler = tf.load_op_library(tf.resource_loader.get_path_to_datafile(""/usr/local/lib/python2.7/dist-packages/sonnet/python/ops/_resampler.so""))
Traceback (most recent call last):
  File ""<stdin>"", line 2, in <module>
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/load_library.py"", line 64, in load_op_library
    None, None, error_msg, error_code)
tensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python2.7/dist-packages/sonnet/python/ops/_resampler.so: undefined symbol: _ZN10tensorflow8internal21CheckOpMessageBuilder9NewStringB5cxx11Ev
```",however even compile fix sonnet working see error message running basic sanity check bash python import sonnet import recent call last file line module file line raise could could digging bit file bash python import sonnet import recent call last file line module file line none none undefined symbol,issue,negative,neutral,neutral,neutral,neutral,neutral
292728736,There is a file ```_resampler.so-2.params``` but not the ```_resampler.so``` it is looking for. Can't build the wheel due to this error.,file looking ca build wheel due error,issue,negative,negative,negative,negative,negative,negative
292699466,"Sonnet is only compatible with legacy, right?



  <https://mailtrack.io/> Sent with Mailtrack
<https://mailtrack.io/install?source=signature&lang=en&referral=r.aguirre62@gmail.com&idSignature=22>

My highest regards,
Rolando P. Aguirre

@rpaguirre

On Fri, Apr 7, 2017 at 11:38 PM, googlebot <notifications@github.com> wrote:

> Thanks for your pull request. It looks like this may be your first
> contribution to a Google open source project. Before we can look at your
> pull request, you'll need to sign a Contributor License Agreement (CLA).
>
> 📝 *Please visit https://cla.developers.google.com/
> <https://cla.developers.google.com/> to sign.*
>
> Once you've signed, please reply here (e.g. I signed it!) and we'll
> verify. Thanks.
> ------------------------------
>
>    - If you've already signed a CLA, it's possible we don't have your
>    GitHub username or you're using a different email address. Check your
>    existing CLA data <https://cla.developers.google.com/clas> and verify
>    that your email is set on your git commits
>    <https://help.github.com/articles/setting-your-email-in-git/>.
>    - If you signed the CLA as a corporation, please let us know the
>    company's name.
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/deepmind/sonnet/pull/6#issuecomment-292699022>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/AYfWQf_KeXK0_Hpqbxm2oB_DW3OvLgs8ks5rtytLgaJpZM4M3nU->
> .
>
",sonnet compatible legacy right sent highest wrote thanks pull request like may first contribution open source project look pull request need sign contributor license agreement memo please visit sign please reply verify thanks already possible different address check data verify set git corporation please let u know company name thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
292698651,"Same here with gcc 5.4. This fixed it for me:
```patch
diff --git a/sonnet/cc/kernels/resampler_op.cc b/sonnet/cc/kernels/resampler_op.cc
index f0a5e64..32d5ae3 100644
--- a/sonnet/cc/kernels/resampler_op.cc
+++ b/sonnet/cc/kernels/resampler_op.cc
@@ -236,8 +236,8 @@ struct ResamplerGrad2DFunctor<CPUDevice, T>{
     memset(grad_data, 0, sizeof(T) * grad_data_size);
     memset(grad_warp, 0, sizeof(T) * grad_warp_size);
 
-    const int data_batch_stride = data_height * data_width * data_channels;
-    const int warp_batch_stride = num_sampling_points * 2;
+    int data_batch_stride = data_height * data_width * data_channels;
+    int warp_batch_stride = num_sampling_points * 2;
     const int output_batch_stride = num_sampling_points * data_channels;
     const T zero = static_cast<T>(0.0);
     const T one = static_cast<T>(1.0);
```
Even though installation seems to fail:
```python
Python 2.7.12 (default, Nov 19 2016, 06:48:10) 
[GCC 5.4.0 20160609] on linux2
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import sonnet as snt
>>> import tensorflow as tf
>>> snt.resampler(tf.constant([0.]), tf.constant([0.]))
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""sonnet/python/ops/resampler.py"", line 62, in resampler
    raise ImportError(""_gen_resampler could not be imported."")
ImportError: _gen_resampler could not be imported.
```",fixed patch git index fae dae zero one even though installation fail python python default type help copyright license information import sonnet import recent call last file line module file line raise could could,issue,negative,negative,neutral,neutral,negative,negative
