id,original_comment,processed_comment,source,sentiment_VADER,sentiment_textblob,sentiment_pattern,sentiment_bert,sentiment_spacy,max_voted_sentiment
2019850429,"I am facing this issue too on auto-keras == 1.1.0.
This seems to happen when the tuner is set to either of 'bayesian', 'hyperband' or 'random'.",facing issue happen tuner set either,issue,negative,neutral,neutral,neutral,neutral,neutral
2019546915,@sideshot - Thanks. I used your workaround and it works perfectly for me.,thanks used work perfectly,issue,positive,positive,positive,positive,positive,positive
2010720907,"## [Codecov](https://app.codecov.io/gh/keras-team/autokeras/pull/1911?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) Report
All modified and coverable lines are covered by tests :white_check_mark:
> Project coverage is 100.00%. Comparing base [(`5549d89`)](https://app.codecov.io/gh/keras-team/autokeras/commit/5549d89469cdb2558962212f81d300bdfe3ee974?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) to head [(`a09fd90`)](https://app.codecov.io/gh/keras-team/autokeras/pull/1911?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
> Report is 1 commits behind head on master.


<details><summary>Additional details and impacted files</summary>


```diff
@@            Coverage Diff            @@
##            master     #1911   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           48        48           
  Lines         2175      2175           
=========================================
  Hits          2175      2175           
```



</details>

[:umbrella: View full report in Codecov by Sentry](https://app.codecov.io/gh/keras-team/autokeras/pull/1911?dropdown=coverage&src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).   
:loudspeaker: Have feedback on the report? [Share it here](https://about.codecov.io/codecov-pr-comment-feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
",report covered project coverage base head report behind head master summary additional impacted coverage master coverage umbrella view full report sentry feedback report share,issue,negative,negative,negative,negative,negative,negative
2010684950,"Yup I think lower bound (tf<2.16.0) would be better I came across the error while running autokeras library solved when I installed version tf=2.15.0 and might thought on editing libraries specs anyways thank you 
",think lower bound would better came across error running library version might thought spec anyways thank,issue,negative,positive,positive,positive,positive,positive
2010653916,"Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/keras-team/autokeras/pull/1910/checks?check_run_id=22905144665) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.",thanks pull request like may first contribution open source project look pull request need sign contributor license agreement view invocation check information date status view section bottom pull request,issue,positive,positive,positive,positive,positive,positive
2008233831,"## [Codecov](https://app.codecov.io/gh/keras-team/autokeras/pull/1908?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) Report
Attention: Patch coverage is `99.14530%` with `1 lines` in your changes are missing coverage. Please review.
> Project coverage is 99.63%. Comparing base [(`ec4ebd1`)](https://app.codecov.io/gh/keras-team/autokeras/commit/ec4ebd16817380e8586f4ca61b16998d0a4aed09?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) to head [(`87774e6`)](https://app.codecov.io/gh/keras-team/autokeras/pull/1908?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).

> :exclamation: Current head 87774e6 differs from pull request most recent head 11d9b77. Consider uploading reports for the commit 11d9b77 to get more accurate results

| [Files](https://app.codecov.io/gh/keras-team/autokeras/pull/1908?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) | Patch % | Lines |
|---|---|---|
| [autokeras/utils/data\_utils.py](https://app.codecov.io/gh/keras-team/autokeras/pull/1908?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL3V0aWxzL2RhdGFfdXRpbHMucHk=) | 88.88% | [1 Missing :warning: ](https://app.codecov.io/gh/keras-team/autokeras/pull/1908?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) |

<details><summary>Additional details and impacted files</summary>


```diff
@@             Coverage Diff             @@
##           master    #1908       +/-   ##
===========================================
+ Coverage        0   99.63%   +99.63%     
===========================================
  Files           0       48       +48     
  Lines           0     2174     +2174     
===========================================
+ Hits            0     2166     +2166     
- Misses          0        8        +8     
```



</details>

[:umbrella: View full report in Codecov by Sentry](https://app.codecov.io/gh/keras-team/autokeras/pull/1908?dropdown=coverage&src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).   
:loudspeaker: Have feedback on the report? [Share it here](https://about.codecov.io/codecov-pr-comment-feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
",report attention patch coverage missing coverage please review project coverage base head exclamation current head pull request recent head consider commit get accurate patch missing warning summary additional impacted coverage master coverage umbrella view full report sentry feedback report share,issue,negative,negative,neutral,neutral,negative,negative
1996236441,"I tried using the tensorflow==2.15.0 and restarted the kernel, imported os and the tensorflow amc it worked.
Thank you ",tried kernel o worked thank,issue,negative,neutral,neutral,neutral,neutral,neutral
1996180524,"> @haifeng-jin this works for me ty

does the execution go all the way? ",work execution go way,issue,negative,neutral,neutral,neutral,neutral,neutral
1996179872,"Do you know when this might be fixed for keras 3 to be supported?
Regards
 Aya
________________________________
From: Haifeng Jin ***@***.***>
Sent: Thursday, March 14, 2024 12:45 AM
To: keras-team/autokeras ***@***.***>
Cc: Aya121298 ***@***.***>; Author ***@***.***>
Subject: Re: [keras-team/autokeras] Bug: import autokeras as ak --> ModuleNotFoundError: No module named 'tensorflow.keras.layers.experimental' (Issue #1906)


You can either downgrade the TensorFlow version to less than 2.16. Or Use 2.16 or above versions of TensorFlow and install the corresponding tf_keras, and then export the environment variable TF_USE_LEGACY_KERAS=1.

AutoKeras does not support Keras 3 yet.

—
Reply to this email directly, view it on GitHub<https://github.com/keras-team/autokeras/issues/1906#issuecomment-1996016885>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/BEY2HW247ELFKCCDXCEATL3YYDJIRAVCNFSM6AAAAABES534RWVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTSOJWGAYTMOBYGU>.
You are receiving this because you authored the thread.Message ID: ***@***.***>
",know might fixed sent march author subject bug import ak module issue either downgrade version le use install corresponding export environment variable support yet reply directly view id,issue,negative,positive,neutral,neutral,positive,positive
1996173070,"thank you
________________________________
From: Haifeng Jin ***@***.***>
Sent: Thursday, March 14, 2024 12:45 AM
To: keras-team/autokeras ***@***.***>
Cc: Aya121298 ***@***.***>; Author ***@***.***>
Subject: Re: [keras-team/autokeras] Bug: import autokeras as ak --> ModuleNotFoundError: No module named 'tensorflow.keras.layers.experimental' (Issue #1906)


You can either downgrade the TensorFlow version to less than 2.16. Or Use 2.16 or above versions of TensorFlow and install the corresponding tf_keras, and then export the environment variable TF_USE_LEGACY_KERAS=1.

AutoKeras does not support Keras 3 yet.

—
Reply to this email directly, view it on GitHub<https://github.com/keras-team/autokeras/issues/1906#issuecomment-1996016885>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/BEY2HW247ELFKCCDXCEATL3YYDJIRAVCNFSM6AAAAABES534RWVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTSOJWGAYTMOBYGU>.
You are receiving this because you authored the thread.Message ID: ***@***.***>
",thank sent march author subject bug import ak module issue either downgrade version le use install corresponding export environment variable support yet reply directly view id,issue,positive,negative,neutral,neutral,negative,negative
1996016885,"You can either downgrade the TensorFlow version to less than 2.16. Or Use 2.16 or above versions of TensorFlow and install the corresponding `tf_keras`, and then export the environment variable `TF_USE_LEGACY_KERAS=1`.

AutoKeras does not support Keras 3 yet.",either downgrade version le use install corresponding export environment variable support yet,issue,negative,neutral,neutral,neutral,neutral,neutral
1930431410,@SarthakNikhal Sorry for the late reply. Anyone interested can work on this.,sorry late reply anyone interested work,issue,negative,negative,negative,negative,negative,negative
1928838262,"Its numpy latest version problem. Use pip install numpy==1.23.4  
",latest version problem use pip install,issue,negative,positive,positive,positive,positive,positive
1879913888,"**- Problem:** I get this error if the dataset has 41 or fewer rows. There is no error when the data set is 42 or higher!

**- Fix:** The Following change in batch_size fixes this problem: default is 32
search.fit(x=X_train, y=y_train, verbose=0,  epochs=10, batch_size=12)

 
**- Details:** Autokeras 1.1, Code, and passing/failing data sets are attached. 

### code
url = 'auto-insurance_41a.csv'
dataframe = read_csv(url, header=None)
print(dataframe.shape)
# split into input and output elements
data = dataframe.values
data = data.astype('float32')
X, y = data[:, :-1], data[:, -1]
print(X.shape, y.shape)
# separate into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)
search = StructuredDataRegressor(max_trials=15, loss='mean_absolute_error')
search.fit(x=X_train, y=y_train, verbose=0,  epochs=10)
### code

### error
Reloading Tuner from ./structured_data_regressor/tuner0.json

---------------------------------------------------------------------------

ValueError                                Traceback (most recent call last)

[<ipython-input-49-5ada482acc10>](https://localhost:8080/#) in <cell line: 11>()
      9 search = StructuredDataRegressor(max_trials=15, loss='mean_absolute_error')
     10 # perform the search
---> 11 search.fit(x=X_train, y=y_train, verbose=0,  epochs=10)
     12 # evaluate the model
     13 mae, _ = search.evaluate(X_test, y_test, verbose=0)

2 frames

[/usr/local/lib/python3.10/dist-packages/autokeras/tasks/structured_data.py](https://localhost:8080/#) in fit(self, x, y, epochs, callbacks, validation_split, validation_data, **kwargs)
    137         self.check_in_fit(x)
    138 
--> 139         history = super().fit(
    140             x=x,
    141             y=y,

[/usr/local/lib/python3.10/dist-packages/autokeras/auto_model.py](https://localhost:8080/#) in fit(self, x, y, batch_size, epochs, callbacks, validation_split, validation_data, verbose, **kwargs)
    286         # Split the data with validation_split.
    287         if validation_data is None and validation_split:
--> 288             dataset, validation_data = data_utils.split_dataset(
    289                 dataset, validation_split
    290             )

[/usr/local/lib/python3.10/dist-packages/autokeras/utils/data_utils.py](https://localhost:8080/#) in split_dataset(dataset, validation_split)
     44     num_instances = dataset.reduce(np.int64(0), lambda x, _: x + 1).numpy()
     45     if num_instances < 2:
---> 46         raise ValueError(
     47             ""The dataset should at least contain 2 batches to be split.""
     48         )

ValueError: The dataset should at least contain 2 batches to be split.
## Error

[auto-insurance_41a.csv](https://github.com/keras-team/autokeras/files/13851956/auto-insurance_41a.csv)
[auto-insurance_42a.csv](https://github.com/keras-team/autokeras/files/13851957/auto-insurance_42a.csv)


",problem get error error data set higher fix following change problem default code data attached code print split input output data data data data print separate train test search code error tuner recent call last cell line search perform search evaluate model mae fit self history super fit self verbose split data none lambda raise least contain split least contain split error,issue,negative,positive,neutral,neutral,positive,positive
1876301694,"I got the same error for StructuredDataClassifier,
Since Numpy 1.24, np.object is deprecated, and to be replaced with object
```
ERROR:500 Internal Server Error: module 'numpy' has no attribute 'object'.
`np.object` was a deprecated alias for the builtin `object`. To avoid this error in existing code, use `object` by itself. Doing this will not modify any behavior and is safe.
The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
```
on here
```
  File ""C:\Users\PA\anaconda3\envs\py3117\Lib\site-packages\autokeras\adapters\input_adapters.py"", line 73, in convert_to_dataset
    if isinstance(dataset, np.ndarray) and dataset.dtype == np.object:
```
I replaced np.object --> object, It worked.
Can we update the library.
Using
Python 3.11.7
Autokeras 1.0.20
Numpy 1.26.3
",got error since object error internal server error module attribute alias object avoid error code use object modify behavior safe originally guidance see original release note file line object worked update library python,issue,negative,positive,positive,positive,positive,positive
1872335641,"Thanks.  My project was running for 48 hours and then failed at this part.  I noticed it was required too.  I haven't gotten the results yet.  Still working my way through it.  

Are you using something else?",thanks project running part gotten yet still working way something else,issue,negative,positive,positive,positive,positive,positive
1872321568,"Because I wanted to call adapt(), so I made a dataset, and batch_size seems to be a required argument.
I haven't used AutoKeras for quite a while, things can change, though.",call adapt made argument used quite change though,issue,negative,neutral,neutral,neutral,neutral,neutral
1872166473,"@KirkSuD Why did you set the batch size?  batch_size=32

> Hi, I encountered same issue.
> 
> I made a workaround without modifying code of autokeras because I'm using Google Colab.
> 
> ```
> ak_model = StructuredDataClassifier(
>     column_names=features,
>     project_name=project_name,
>     directory=""model"",
>     seed=0,
> )
> history = ak_model.fit(train_X, train_y, validation_data=(test_X, test_y))
> # print(""eval train:"", ak_model.evaluate(train_X, train_y))  # same error here
> # print(""eval test:"", ak_model.evaluate(test_X, test_y))  # same error here
> 
> # fix it buy calling adapt()
> model = keras.models.load_model(f""model/{project_name}/best_model"",
>     custom_objects=autokeras.CUSTOM_OBJECTS)
> dataset, validation_data = ak_model._convert_to_dataset(
>     x=train_X, y=train_y, validation_data=(test_X, test_y), batch_size=32
> )
> ak_model.tuner.adapt(model, dataset)
> 
> # now save adapted model, we can do predict, evaluate now  :)
> model.save(f""model/{project_name}/best_model_adapted"", save_format=""tf"")
> print(""eval train:"", model.evaluate(train_X, train_y))
> print(""eval test:"", model.evaluate(test_X, test_y))
> ```
> 
> I think this issue is due to adapt() not being called for some reason under some situations, so MultiCategoryEncoding's table is not initialized. It hasn't seen any data, so it doesn't know how to encode data.

",set batch size hi issue made without code model history print train error print test error fix buy calling adapt model model save model predict evaluate print train print test think issue due adapt reason table seen data know encode data,issue,negative,negative,negative,negative,negative,negative
1867458063,"same issue, I have tried to change autokeras _convert_to_dataset function but not work",issue tried change function work,issue,negative,neutral,neutral,neutral,neutral,neutral
1798107007,"I have encountered a similar error. 

Search: Running Trial #5

Value             |Best Value So Far |Hyperparameter
vanilla           |vanilla           |text_block_1/block_type
none              |none              |text_block_1/embedding_1/pretraining
64                |64                |text_block_1/embedding_1/embedding_dim
0.25              |0.25              |text_block_1/embedding_1/dropout
5                 |5                 |text_block_1/conv_block_1/kernel_size
False             |False             |text_block_1/conv_block_1/separable
False             |False             |text_block_1/conv_block_1/max_pooling
1                 |1                 |text_block_1/conv_block_1/num_blocks
1                 |1                 |text_block_1/conv_block_1/num_layers
256               |256               |text_block_1/conv_block_1/filters_0_0
128               |128               |text_block_1/conv_block_1/filters_0_1
0                 |0                 |text_block_1/conv_block_1/dropout
64                |64                |text_block_1/conv_block_1/filters_1_0
32                |32                |text_block_1/conv_block_1/filters_1_1
0                 |0                 |classification_head_1/dropout
sgd               |adam              |optimizer
0.001             |0.001             |learning_rate

Traceback (most recent call last):
  File ""C:\Users\yvorlv\miniconda3\envs\tensorflow\lib\site-packages\keras_tuner\engine\base_tuner.py"", line 273, in _try_run_and_update_trial
    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)
  File ""C:\Users\yvorlv\miniconda3\envs\tensorflow\lib\site-packages\keras_tuner\engine\base_tuner.py"", line 238, in _run_and_update_trial
    results = self.run_trial(trial, *fit_args, **fit_kwargs)
  File ""C:\Users\yvorlv\miniconda3\envs\tensorflow\lib\site-packages\keras_tuner\engine\tuner.py"", line 314, in run_trial
    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)
  File ""C:\Users\yvorlv\miniconda3\envs\tensorflow\lib\site-packages\autokeras\engine\tuner.py"", line 91, in _build_and_fit_model
    model = self._try_build(trial.hyperparameters)
  File ""C:\Users\yvorlv\miniconda3\envs\tensorflow\lib\site-packages\keras_tuner\engine\tuner.py"", line 164, in _try_build
    model = self._build_hypermodel(hp)
  File ""C:\Users\yvorlv\miniconda3\envs\tensorflow\lib\site-packages\keras_tuner\engine\tuner.py"", line 155, in _build_hypermodel
    model = self.hypermodel.build(hp)
  File ""C:\Users\yvorlv\miniconda3\envs\tensorflow\lib\site-packages\keras_tuner\engine\hypermodel.py"", line 120, in _build_wrapper
    return self._build(hp, *args, **kwargs)
  File ""C:\Users\yvorlv\miniconda3\envs\tensorflow\lib\site-packages\autokeras\graph.py"", line 250, in build
    outputs = block.build(hp, inputs=temp_inputs)
  File ""C:\Users\yvorlv\miniconda3\envs\tensorflow\lib\site-packages\autokeras\engine\block.py"", line 38, in _build_wrapper
    return super()._build_wrapper(hp, *args, **kwargs)
  File ""C:\Users\yvorlv\miniconda3\envs\tensorflow\lib\site-packages\keras_tuner\engine\hypermodel.py"", line 120, in _build_wrapper
    return self._build(hp, *args, **kwargs)
  File ""C:\Users\yvorlv\miniconda3\envs\tensorflow\lib\site-packages\autokeras\blocks\wrapper.py"", line 159, in build
    output_node = self._build_block(hp, output_node, block_type)
  File ""C:\Users\yvorlv\miniconda3\envs\tensorflow\lib\site-packages\autokeras\blocks\wrapper.py"", line 165, in _build_block
    max_tokens = self.max_tokens or hp.Choice(
  File ""C:\Users\yvorlv\miniconda3\envs\tensorflow\lib\site-packages\keras_tuner\engine\hyperparameters\hyperparameters.py"", line 300, in Choice
    return self._retrieve(hp)
  File ""C:\Users\yvorlv\miniconda3\envs\tensorflow\lib\site-packages\keras_tuner\engine\hyperparameters\hyperparameters.py"", line 208, in _retrieve
    return self.values[hp.name]
KeyError: 'text_block_1/max_tokens'
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\Users\yvorlv\miniconda3\envs\tensorflow\lib\site-packages\autokeras\tasks\text.py"", line 160, in fit
    history = super().fit(
  File ""C:\Users\yvorlv\miniconda3\envs\tensorflow\lib\site-packages\autokeras\auto_model.py"", line 292, in fit
    history = self.tuner.search(
  File ""C:\Users\yvorlv\miniconda3\envs\tensorflow\lib\site-packages\autokeras\engine\tuner.py"", line 193, in search
    super().search(
  File ""C:\Users\yvorlv\miniconda3\envs\tensorflow\lib\site-packages\keras_tuner\engine\base_tuner.py"", line 234, in search
    self.on_trial_end(trial)
  File ""C:\Users\yvorlv\miniconda3\envs\tensorflow\lib\site-packages\keras_tuner\engine\base_tuner.py"", line 338, in on_trial_end
    self.oracle.end_trial(trial)
  File ""C:\Users\yvorlv\miniconda3\envs\tensorflow\lib\site-packages\keras_tuner\engine\oracle.py"", line 108, in wrapped_func
    ret_val = func(*args, **kwargs)
  File ""C:\Users\yvorlv\miniconda3\envs\tensorflow\lib\site-packages\keras_tuner\engine\oracle.py"", line 586, in end_trial
    self._check_consecutive_failures()
  File ""C:\Users\yvorlv\miniconda3\envs\tensorflow\lib\site-packages\keras_tuner\engine\oracle.py"", line 543, in _check_consecutive_failures
    raise RuntimeError(
RuntimeError: Number of consecutive failures exceeded the limit of 3.
Traceback (most recent call last):
  File ""C:\Users\yvorlv\miniconda3\envs\tensorflow\lib\site-packages\keras_tuner\engine\base_tuner.py"", line 273, in _try_run_and_update_trial
    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)
  File ""C:\Users\yvorlv\miniconda3\envs\tensorflow\lib\site-packages\keras_tuner\engine\base_tuner.py"", line 238, in _run_and_update_trial
    results = self.run_trial(trial, *fit_args, **fit_kwargs)
  File ""C:\Users\yvorlv\miniconda3\envs\tensorflow\lib\site-packages\keras_tuner\engine\tuner.py"", line 314, in run_trial
    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)
  File ""C:\Users\yvorlv\miniconda3\envs\tensorflow\lib\site-packages\autokeras\engine\tuner.py"", line 91, in _build_and_fit_model
    model = self._try_build(trial.hyperparameters)
  File ""C:\Users\yvorlv\miniconda3\envs\tensorflow\lib\site-packages\keras_tuner\engine\tuner.py"", line 164, in _try_build
    model = self._build_hypermodel(hp)
  File ""C:\Users\yvorlv\miniconda3\envs\tensorflow\lib\site-packages\keras_tuner\engine\tuner.py"", line 155, in _build_hypermodel
    model = self.hypermodel.build(hp)
  File ""C:\Users\yvorlv\miniconda3\envs\tensorflow\lib\site-packages\keras_tuner\engine\hypermodel.py"", line 120, in _build_wrapper
    return self._build(hp, *args, **kwargs)
  File ""C:\Users\yvorlv\miniconda3\envs\tensorflow\lib\site-packages\autokeras\graph.py"", line 250, in build
    outputs = block.build(hp, inputs=temp_inputs)
  File ""C:\Users\yvorlv\miniconda3\envs\tensorflow\lib\site-packages\autokeras\engine\block.py"", line 38, in _build_wrapper
    return super()._build_wrapper(hp, *args, **kwargs)
  File ""C:\Users\yvorlv\miniconda3\envs\tensorflow\lib\site-packages\keras_tuner\engine\hypermodel.py"", line 120, in _build_wrapper
    return self._build(hp, *args, **kwargs)
  File ""C:\Users\yvorlv\miniconda3\envs\tensorflow\lib\site-packages\autokeras\blocks\wrapper.py"", line 159, in build
    output_node = self._build_block(hp, output_node, block_type)
  File ""C:\Users\yvorlv\miniconda3\envs\tensorflow\lib\site-packages\autokeras\blocks\wrapper.py"", line 165, in _build_block
    max_tokens = self.max_tokens or hp.Choice(
  File ""C:\Users\yvorlv\miniconda3\envs\tensorflow\lib\site-packages\keras_tuner\engine\hyperparameters\hyperparameters.py"", line 300, in Choice
    return self._retrieve(hp)
  File ""C:\Users\yvorlv\miniconda3\envs\tensorflow\lib\site-packages\keras_tuner\engine\hyperparameters\hyperparameters.py"", line 208, in _retrieve
    return self.values[hp.name]
KeyError: 'text_block_1/max_tokens'",similar error search running trial value value far vanilla none false false recent call last file line trial file line trial file line trial file line model file line model file line model file line return file line build file line return super file line return file line build file line file line choice return file line return recent call last file line module file line fit history super file line fit history file line search super file line search trial file line trial file line file line file line raise number consecutive limit recent call last file line trial file line trial file line trial file line model file line model file line model file line return file line build file line return super file line return file line build file line file line choice return file line return,issue,positive,positive,neutral,neutral,positive,positive
1743807542,"## [Codecov](https://app.codecov.io/gh/keras-team/autokeras/pull/1894?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) Report
All modified lines are covered by tests :white_check_mark:
> Comparison is base [(`5abd2d5`)](https://app.codecov.io/gh/keras-team/autokeras/commit/5abd2d51396134b1d3e5831adb8d25572f39c003?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) 100.00% compared to head [(`85a03b6`)](https://app.codecov.io/gh/keras-team/autokeras/pull/1894?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) 100.00%.
> Report is 2 commits behind head on master.

> :exclamation: Current head 85a03b6 differs from pull request most recent head 817a12f. Consider uploading reports for the commit 817a12f to get more accurate results

<details><summary>Additional details and impacted files</summary>


```diff
@@            Coverage Diff            @@
##            master     #1894   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           50        50           
  Lines         2927      2927           
=========================================
  Hits          2927      2927           
```


| [Files](https://app.codecov.io/gh/keras-team/autokeras/pull/1894?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) | Coverage Δ | |
|---|---|---|
| [autokeras/tasks/structured\_data.py](https://app.codecov.io/gh/keras-team/autokeras/pull/1894?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL3Rhc2tzL3N0cnVjdHVyZWRfZGF0YS5weQ==) | `100.00% <ø> (ø)` | |


</details>

[:umbrella: View full report in Codecov by Sentry](https://app.codecov.io/gh/keras-team/autokeras/pull/1894?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).   
:loudspeaker: Have feedback on the report? [Share it here](https://about.codecov.io/codecov-pr-comment-feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
",report covered comparison base head report behind head master exclamation current head pull request recent head consider commit get accurate summary additional impacted coverage master coverage coverage umbrella view full report sentry feedback report share,issue,positive,negative,neutral,neutral,negative,negative
1741423412,I will need to do another release in keras_tuner to fix it.,need another release fix,issue,negative,neutral,neutral,neutral,neutral,neutral
1741410292,"Здравствуйте  Тигран, говорят помогает 

!pip install autokeras
!pip uninstall keras-tuner
!pip install keras-tuner==1.3.5

",pip install pip pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
1709646625,"Hi, Aryagm 
Does above code worked for you?
If yes please help me it is not working for me",hi code worked yes please help working,issue,positive,neutral,neutral,neutral,neutral,neutral
1692508351,"I'm getting this issue too, were you able to fix it?",getting issue able fix,issue,negative,positive,positive,positive,positive,positive
1663623812,"Hi! It might be related to this https://github.com/keras-team/autokeras/issues/1246#issuecomment-1327808073

I had a similar issue and by converting my input into strings I solved it",hi might related similar issue converting input,issue,negative,neutral,neutral,neutral,neutral,neutral
1659658871,So sorry for the late reply. I never received a notification and completely forgot about the issue.,sorry late reply never received notification completely forgot issue,issue,negative,negative,negative,negative,negative,negative
1649425690,"> Please use below code in Anaconda cmd prompt pip install keras pip install keras-tuner

thanks man 
",please use code anaconda prompt pip install pip install thanks man,issue,positive,positive,positive,positive,positive,positive
1641192677,"Hi, 

Not sure if you're still encountering this issue. I tried checking out your dataset, but couldn't access it. Are there enough samples in data? Another option if working with small sample sizes is to decrease batch_size significantly in the fit method.

Hope this helps.",hi sure still issue tried could access enough data another option working small sample size decrease significantly fit method hope,issue,positive,positive,positive,positive,positive,positive
1635023972,"> Fit consists of 2 steps, search and final fit. The ""last trained model"" is the best model during search and final fit with your entire training set. During the search it was only trained with a split of the data you provided.
> 
> So the difference in accuracy is mainly because it is using different dataset to evaluate.
> 
> If you use `clf.fit(x_train, y_train, validation_data=(x_test, y_test)` and `clf.evaluate(x_test, y_test)`, the accuracy should be the same.

Are you sure?   I think it's using best loss rather than best val_ metric.",fit search final fit last trained model best model search final fit entire training set search trained split data provided difference accuracy mainly different evaluate use accuracy sure think best loss rather best metric,issue,positive,positive,positive,positive,positive,positive
1634996507,might want to mention this issue in the faq :),might want mention issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1632955081,"Same here with a random forest and 25k input one-hot tensors of dimension (>130,000, 2). Yes, this needs a 128GB RAM machine.",random forest input dimension yes need ram machine,issue,negative,negative,negative,negative,negative,negative
1620048603,"I am not from the Autokeras team, but when training ML models, the optimal number of epochs is a difficult problem and there is no final answer. Usually models improve until a local minima and then they can't go further.
I would suggest you to check Tensorflow's callbacks as I believe they work with Autokeras, so you can control the learning rate to optimize said local minima, or stop at the best epoch.
As for trying to get global minima, there is no way to ensure a model will reach global minima, so instead raise the number of trials.",team training optimal number difficult problem final answer usually improve local minimum ca go would suggest check believe work control learning rate optimize said local minimum stop best epoch trying get global minimum way ensure model reach global minimum instead raise number,issue,positive,positive,neutral,neutral,positive,positive
1600745281,"> @berab Would you please sign the google cla? Thanks

I just did.",would please sign thanks,issue,positive,positive,positive,positive,positive,positive
1581715034,This appears to be fixed in v1.1  for `max_model_size>=23555082` (the size of the hardcoded Resnet model?). Anything smaller and a `FailedTrialError` is raised and not handled. ,fixed size model anything smaller raised handled,issue,negative,positive,neutral,neutral,positive,positive
1505253893,"Is this bug still unresolved？
win10-bit, anaconda 2022, python=3.9.13 autokeras=1.0.20
Expect the target data for classification_head_4 to have shape [2], but got [].",bug still anaconda expect target data shape got,issue,negative,neutral,neutral,neutral,neutral,neutral
1501968171,"I have switched to autoglucon, it works like a charm on my apple silicon mac.",switched work like charm apple silicon mac,issue,positive,neutral,neutral,neutral,neutral,neutral
1501965692,I'm still getting this issue with autokeras 1.1.0; tensorflow-macos 2.10.0 is installed and working on my M1 MacbookPro.,still getting issue working,issue,negative,neutral,neutral,neutral,neutral,neutral
1493436631,"## [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1873?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) Report
Patch and project coverage have no change.
> Comparison is base [(`2b335fa`)](https://codecov.io/gh/keras-team/autokeras/commit/2b335fa36bb881d2f11dde465f962726ce19533c?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) 100.00% compared to head [(`3dddc0c`)](https://codecov.io/gh/keras-team/autokeras/pull/1873?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) 100.00%.

<details><summary>Additional details and impacted files</summary>


```diff
@@            Coverage Diff            @@
##            master     #1873   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           50        50           
  Lines         2929      2927    -2     
=========================================
- Hits          2929      2927    -2     
```


| [Impacted Files](https://codecov.io/gh/keras-team/autokeras/pull/1873?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) | Coverage Δ | |
|---|---|---|
| [autokeras/utils/utils.py](https://codecov.io/gh/keras-team/autokeras/pull/1873?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL3V0aWxzL3V0aWxzLnB5) | `100.00% <ø> (ø)` | |

Help us with your feedback. Take ten seconds to tell us [how you rate us](https://about.codecov.io/nps?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team). Have a feature suggestion? [Share it here.](https://app.codecov.io/gh/feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)

</details>

[:umbrella: View full report in Codecov by Sentry](https://codecov.io/gh/keras-team/autokeras/pull/1873?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).   
:loudspeaker: Do you have feedback about the report comment? [Let us know in this issue](https://about.codecov.io/codecov-pr-comment-feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
",report patch project coverage change comparison base head summary additional impacted coverage master coverage impacted coverage help u feedback take ten tell u rate u feature suggestion share umbrella view full report sentry feedback report comment let u know issue,issue,positive,negative,negative,negative,negative,negative
1489543475,Bumping this because it's a valid request that I also think could be beneficial.,bumping valid request also think could beneficial,issue,negative,neutral,neutral,neutral,neutral,neutral
1485573956,All issues can be resolved on the KerasTuner side. We do not need a release in AutoKeras.,resolved side need release,issue,negative,neutral,neutral,neutral,neutral,neutral
1484797704,"Encountered a similar error in tensorflow 2.12.0 using scikeras example code:

[https://github.com/adriangb/scikeras/issues/291](url)",similar error example code,issue,negative,neutral,neutral,neutral,neutral,neutral
1474230916,"## [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1865?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) Report
Patch and project coverage have no change.
> Comparison is base [(`2289dc8`)](https://codecov.io/gh/keras-team/autokeras/commit/2289dc87aeabe8de8952627f3ccc27e80195bf10?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) 100.00% compared to head [(`3d6315a`)](https://codecov.io/gh/keras-team/autokeras/pull/1865?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) 100.00%.

<details><summary>Additional details and impacted files</summary>


```diff
@@            Coverage Diff            @@
##            master     #1865   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           50        50           
  Lines         2929      2929           
=========================================
  Hits          2929      2929           
```



Help us with your feedback. Take ten seconds to tell us [how you rate us](https://about.codecov.io/nps?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team). Have a feature suggestion? [Share it here.](https://app.codecov.io/gh/feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)

</details>

[:umbrella: View full report in Codecov by Sentry](https://codecov.io/gh/keras-team/autokeras/pull/1865?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).   
:loudspeaker: Do you have feedback about the report comment? [Let us know in this issue](https://about.codecov.io/codecov-pr-comment-feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
",report patch project coverage change comparison base head da summary additional impacted coverage master coverage help u feedback take ten tell u rate u feature suggestion share umbrella view full report sentry feedback report comment let u know issue,issue,positive,negative,negative,negative,negative,negative
1470868805,"## [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1864?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) Report
Patch and project coverage have no change.
> Comparison is base [(`b88dc25`)](https://codecov.io/gh/keras-team/autokeras/commit/b88dc25b314f63514d0fe7fb15affc19df120700?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) 100.00% compared to head [(`fb165a3`)](https://codecov.io/gh/keras-team/autokeras/pull/1864?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) 100.00%.

<details><summary>Additional details and impacted files</summary>


```diff
@@            Coverage Diff            @@
##            master     #1864   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           50        50           
  Lines         2929      2929           
=========================================
  Hits          2929      2929           
```



Help us with your feedback. Take ten seconds to tell us [how you rate us](https://about.codecov.io/nps?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team). Have a feature suggestion? [Share it here.](https://app.codecov.io/gh/feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)

</details>

[:umbrella: View full report in Codecov by Sentry](https://codecov.io/gh/keras-team/autokeras/pull/1864?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).   
:loudspeaker: Do you have feedback about the report comment? [Let us know in this issue](https://about.codecov.io/codecov-pr-comment-feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
",report patch project coverage change comparison base head summary additional impacted coverage master coverage help u feedback take ten tell u rate u feature suggestion share umbrella view full report sentry feedback report comment let u know issue,issue,positive,negative,negative,negative,negative,negative
1465056676,"## [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1861?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) Report
Patch and project coverage have no change.
> Comparison is base [(`f2557f6`)](https://codecov.io/gh/keras-team/autokeras/commit/f2557f6e6f1aa48b03a949a273f110e3560c9dc0?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) 100.00% compared to head [(`4f084ad`)](https://codecov.io/gh/keras-team/autokeras/pull/1861?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) 100.00%.

<details><summary>Additional details and impacted files</summary>


```diff
@@            Coverage Diff            @@
##            master     #1861   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           50        50           
  Lines         2929      2929           
=========================================
  Hits          2929      2929           
```



Help us with your feedback. Take ten seconds to tell us [how you rate us](https://about.codecov.io/nps?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team). Have a feature suggestion? [Share it here.](https://app.codecov.io/gh/feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)

</details>

[:umbrella: View full report in Codecov by Sentry](https://codecov.io/gh/keras-team/autokeras/pull/1861?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).   
:loudspeaker: Do you have feedback about the report comment? [Let us know in this issue](https://about.codecov.io/codecov-pr-comment-feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
",report patch project coverage change comparison base head fad summary additional impacted coverage master coverage help u feedback take ten tell u rate u feature suggestion share umbrella view full report sentry feedback report comment let u know issue,issue,positive,negative,negative,negative,negative,negative
1464830787,I am facing the same issue with `overwrite=True`. Is there a solution to this issue?,facing issue solution issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1453865247,"> ""May be you can try auto_model.tuner.results_summary()? We will have a better solution in the next few months by improving Keras Tuner.""

This returns AttributeError: 'Functional' object has no attribute 'tuner' in my case, running on colab with tf v 2.8.3",may try better solution next improving tuner object attribute case running,issue,positive,positive,positive,positive,positive,positive
1453863662,"Also keen for this, can't see it added anywhere as of yet",also keen ca see added anywhere yet,issue,negative,neutral,neutral,neutral,neutral,neutral
1450800199,"> Over a year later and I'm also getting this issue. Seems oddly sudden because it was working previously but the suggested fix above isn't working for me. Any update on this issue or what is causing it?

I was able to solve my issue by clearing the session using `tf.keras.backend.clear_session()` and reinitializing my model without using the fit method. Hope this helps.",year later also getting issue oddly sudden working previously fix working update issue causing able solve issue clearing session model without fit method hope,issue,negative,positive,positive,positive,positive,positive
1449188544,Over a year later and I'm also getting this issue. Seems oddly sudden because it was working previously but the suggested fix above isn't working for me. Any update on this issue or what is causing it?,year later also getting issue oddly sudden working previously fix working update issue causing,issue,negative,negative,neutral,neutral,negative,negative
1448462348,"I'm also getting this issue, using base colab versions other than reverting back to tf 2.8.3 - fixed this by changing tuner to 'greedy'",also getting issue base back fixed tuner,issue,negative,negative,negative,negative,negative,negative
1439271854,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1855?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) Report
Base: **100.00**% // Head: **100.00**% // No change to project coverage :thumbsup:
> Coverage data is based on head [(`4625137`)](https://codecov.io/gh/keras-team/autokeras/pull/1855?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) compared to base [(`8ef17fc`)](https://codecov.io/gh/keras-team/autokeras/commit/8ef17fcac06d839348b2e424e8ba6a7c9d2c7cd3?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
> Patch coverage: 100.00% of modified lines in pull request are covered.

<details><summary>Additional details and impacted files</summary>


```diff
@@            Coverage Diff            @@
##            master     #1855   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           50        50           
  Lines         2929      2929           
=========================================
  Hits          2929      2929           
```


| [Impacted Files](https://codecov.io/gh/keras-team/autokeras/pull/1855?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) | Coverage Δ | |
|---|---|---|
| [autokeras/adapters/output\_adapters.py](https://codecov.io/gh/keras-team/autokeras/pull/1855?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL2FkYXB0ZXJzL291dHB1dF9hZGFwdGVycy5weQ==) | `100.00% <ø> (ø)` | |
| [autokeras/analysers/input\_analysers.py](https://codecov.io/gh/keras-team/autokeras/pull/1855?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL2FuYWx5c2Vycy9pbnB1dF9hbmFseXNlcnMucHk=) | `100.00% <ø> (ø)` | |
| [autokeras/engine/adapter.py](https://codecov.io/gh/keras-team/autokeras/pull/1855?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL2VuZ2luZS9hZGFwdGVyLnB5) | `100.00% <ø> (ø)` | |
| [autokeras/engine/block.py](https://codecov.io/gh/keras-team/autokeras/pull/1855?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL2VuZ2luZS9ibG9jay5weQ==) | `100.00% <ø> (ø)` | |
| [autokeras/engine/head.py](https://codecov.io/gh/keras-team/autokeras/pull/1855?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL2VuZ2luZS9oZWFkLnB5) | `100.00% <ø> (ø)` | |
| [autokeras/engine/io\_hypermodel.py](https://codecov.io/gh/keras-team/autokeras/pull/1855?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL2VuZ2luZS9pb19oeXBlcm1vZGVsLnB5) | `100.00% <ø> (ø)` | |
| [autokeras/preprocessors/common.py](https://codecov.io/gh/keras-team/autokeras/pull/1855?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL3ByZXByb2Nlc3NvcnMvY29tbW9uLnB5) | `100.00% <ø> (ø)` | |
| [autokeras/preprocessors/encoders.py](https://codecov.io/gh/keras-team/autokeras/pull/1855?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL3ByZXByb2Nlc3NvcnMvZW5jb2RlcnMucHk=) | `100.00% <ø> (ø)` | |
| [autokeras/preprocessors/postprocessors.py](https://codecov.io/gh/keras-team/autokeras/pull/1855?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL3ByZXByb2Nlc3NvcnMvcG9zdHByb2Nlc3NvcnMucHk=) | `100.00% <ø> (ø)` | |
| [autokeras/tasks/structured\_data.py](https://codecov.io/gh/keras-team/autokeras/pull/1855?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL3Rhc2tzL3N0cnVjdHVyZWRfZGF0YS5weQ==) | `100.00% <ø> (ø)` | |
| ... and [20 more](https://codecov.io/gh/keras-team/autokeras/pull/1855?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) | |

Help us with your feedback. Take ten seconds to tell us [how you rate us](https://about.codecov.io/nps?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team). Have a feature suggestion? [Share it here.](https://app.codecov.io/gh/feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)

</details>

[:umbrella: View full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1855?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).   
:loudspeaker: Do you have feedback about the report comment? [Let us know in this issue](https://about.codecov.io/codecov-pr-comment-feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
",report base head change project coverage coverage data based head base patch coverage pull request covered summary additional impacted coverage master coverage impacted coverage help u feedback take ten tell u rate u feature suggestion share umbrella view full report feedback report comment let u know issue,issue,positive,negative,negative,negative,negative,negative
1436149425,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1854?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) Report
Base: **100.00**% // Head: **100.00**% // No change to project coverage :thumbsup:
> Coverage data is based on head [(`cbd03e2`)](https://codecov.io/gh/keras-team/autokeras/pull/1854?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) compared to base [(`94f3750`)](https://codecov.io/gh/keras-team/autokeras/commit/94f3750b4cd69db3879270d1a7875471b23481eb?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
> Patch has no changes to coverable lines.

<details><summary>Additional details and impacted files</summary>


```diff
@@            Coverage Diff            @@
##            master     #1854   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           50        50           
  Lines         2929      2929           
=========================================
  Hits          2929      2929           
```



Help us with your feedback. Take ten seconds to tell us [how you rate us](https://about.codecov.io/nps?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team). Have a feature suggestion? [Share it here.](https://app.codecov.io/gh/feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)

</details>

[:umbrella: View full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1854?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).   
:loudspeaker: Do you have feedback about the report comment? [Let us know in this issue](https://about.codecov.io/codecov-pr-comment-feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
",report base head change project coverage coverage data based head base patch summary additional impacted coverage master coverage help u feedback take ten tell u rate u feature suggestion share umbrella view full report feedback report comment let u know issue,issue,positive,negative,negative,negative,negative,negative
1432979762,"The highest compatible version seem to be 2.10.1, there is also some kind of change in tensorflow 2.11.0 which breaks some conversion in older autokeras versions.
But with AutoKeras 1.1.0 Tensorflow 2.10.1 works perfectly for me.",highest compatible version seem also kind change conversion older work perfectly,issue,positive,positive,positive,positive,positive,positive
1416928199,"Kind of fix it by stating the TensorFlow version. In my case, I stated to install tensorflow==2.11, then it allow me to install the AutoKeras library.",kind fix version case stated install allow install library,issue,positive,positive,positive,positive,positive,positive
1416199747,"For anyone encounter this problem, you may follow the following instructions to install TensorFlow.

```shell
conda create --name=test python=3.10 -y
conda run -n test conda install cuda-nvcc=11.3.58 cudatoolkit=11.2.2 cudnn=8.1.0 -c conda-forge -c nvidia -y
conda run -n test pip install tensorflow
conda run -n test mkdir -p $CONDA_PREFIX/etc/conda/activate.d
conda run -n test printf 'export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CONDA_PREFIX/lib/\nexport XLA_FLAGS=--xla_gpu_cuda_data_dir=$CONDA_PREFIX/lib/\n' > $CONDA_PREFIX/etc/conda/activate.d/env_vars.sh
conda run -n test mkdir -p $CONDA_PREFIX/lib/nvvm/libdevice
conda run -n test cp $CONDA_PREFIX/lib/libdevice.10.bc $CONDA_PREFIX/lib/nvvm/libdevice/
```",anyone encounter problem may follow following install shell create run test install run test pip install run test run test run test run test,issue,negative,neutral,neutral,neutral,neutral,neutral
1416196551,"The example you give should work, right?
If you wang to set the `deviance` as the objective, just do `objective=keras_tuner.Objective('val_deviance', direction='min')`.",example give work right wang set objective,issue,negative,positive,positive,positive,positive,positive
1416185562,"It might be a TensorFlow installation problem.
Would you please try `import keras from tensorflow` in your Python commandline?
It it gives the same error, then it is the TF install problem.",might installation problem would please try import python error install problem,issue,negative,neutral,neutral,neutral,neutral,neutral
1414362560,"OK, I won't notify you about black[jupyter] again, unless you re-open this PR. 😢",wo notify black unless,issue,negative,negative,negative,negative,negative,negative
1413575887,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1846?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) Report
Base: **100.00**% // Head: **100.00**% // No change to project coverage :thumbsup:
> Coverage data is based on head [(`4cc352b`)](https://codecov.io/gh/keras-team/autokeras/pull/1846?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) compared to base [(`98873d8`)](https://codecov.io/gh/keras-team/autokeras/commit/98873d83f5e37ca9e9ca1214337a46a1b5f14d0e?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
> Patch has no changes to coverable lines.

> :exclamation: Current head 4cc352b differs from pull request most recent head 0b0597d. Consider uploading reports for the commit 0b0597d to get more accurate results

<details><summary>Additional details and impacted files</summary>


```diff
@@            Coverage Diff            @@
##            master     #1846   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           50        50           
  Lines         2920      2920           
=========================================
  Hits          2920      2920           
```



Help us with your feedback. Take ten seconds to tell us [how you rate us](https://about.codecov.io/nps?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team). Have a feature suggestion? [Share it here.](https://app.codecov.io/gh/feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)

</details>

[:umbrella: View full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1846?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).   
:loudspeaker: Do you have feedback about the report comment? [Let us know in this issue](https://about.codecov.io/codecov-pr-comment-feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
",report base head change project coverage coverage data based head base patch exclamation current head pull request recent head consider commit get accurate summary additional impacted coverage master coverage help u feedback take ten tell u rate u feature suggestion share umbrella view full report feedback report comment let u know issue,issue,positive,negative,negative,negative,negative,negative
1398925149,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1834?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) Report
Base: **100.00**% // Head: **100.00**% // No change to project coverage :thumbsup:
> Coverage data is based on head [(`23ae553`)](https://codecov.io/gh/keras-team/autokeras/pull/1834?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) compared to base [(`1b750f0`)](https://codecov.io/gh/keras-team/autokeras/commit/1b750f0b8053fa601db4c693ebc8f724e06f4b02?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
> Patch has no changes to coverable lines.

<details><summary>Additional details and impacted files</summary>


```diff
@@            Coverage Diff            @@
##            master     #1834   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           50        50           
  Lines         2920      2920           
=========================================
  Hits          2920      2920           
```



Help us with your feedback. Take ten seconds to tell us [how you rate us](https://about.codecov.io/nps?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team). Have a feature suggestion? [Share it here.](https://app.codecov.io/gh/feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)

</details>

[:umbrella: View full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1834?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).   
:loudspeaker: Do you have feedback about the report comment? [Let us know in this issue](https://about.codecov.io/codecov-pr-comment-feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
",report base head change project coverage coverage data based head ae base patch summary additional impacted coverage master coverage help u feedback take ten tell u rate u feature suggestion share umbrella view full report feedback report comment let u know issue,issue,positive,negative,negative,negative,negative,negative
1375647732,"After talking with some of my colleagues, the fix for this could be downgrading tensorflow to version 2.10.1. This has been adressed as a bug earlier as well so I will close the issue. ",talking fix could version bug well close issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1375620808,"I'm having the same issue, but only when I use validation data",issue use validation data,issue,negative,neutral,neutral,neutral,neutral,neutral
1373360106,"No, but  I got it working by placing the lib in my working directory. Not a pretty fix but better than nothing.

From: Haifeng Jin ***@***.***>
Sent: Thursday, 5 January 2023 21:37
To: keras-team/autokeras ***@***.***>
Cc: Julia Wąsala ***@***.***>; Author ***@***.***>
Subject: Re: [keras-team/autokeras] Bug: libdevice not found at ./libdevice / doesn't run on GPU (Issue #1813)


It doesn't look like a AutoKeras issue, but a local setup issue.
Can you run TF successfully on GPU with your setup?

—
Reply to this email directly, view it on GitHub<https://github.com/keras-team/autokeras/issues/1813#issuecomment-1372715586>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AIISAST3TZACQD55RRXGINDWQ4WFPANCNFSM6AAAAAAS6QYCMQ>.
You are receiving this because you authored the thread.Message ID: ***@***.******@***.***>>
",got working working directory pretty fix better nothing sent author subject bug found run issue look like issue local setup issue run successfully setup reply directly view id,issue,positive,positive,positive,positive,positive,positive
1372715586,"It doesn't look like a AutoKeras issue, but a local setup issue.
Can you run TF successfully on GPU with your setup?",look like issue local setup issue run successfully setup,issue,positive,positive,positive,positive,positive,positive
1366871624,"Yeah, this is awesome!! Keep us posted on how it goes!",yeah awesome keep u posted go,issue,positive,positive,positive,positive,positive,positive
1366869497,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1822?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) Report
Base: **100.00**% // Head: **100.00**% // No change to project coverage :thumbsup:
> Coverage data is based on head [(`03df7d5`)](https://codecov.io/gh/keras-team/autokeras/pull/1822?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) compared to base [(`b6ace29`)](https://codecov.io/gh/keras-team/autokeras/commit/b6ace29cad7cab6d1dd05b6ff3f400102424ae68?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
> Patch has no changes to coverable lines.

<details><summary>Additional details and impacted files</summary>


```diff
@@            Coverage Diff            @@
##            master     #1822   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           51        51           
  Lines         3383      3422   +39     
=========================================
+ Hits          3383      3422   +39     
```


| [Impacted Files](https://codecov.io/gh/keras-team/autokeras/pull/1822?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) | Coverage Δ | |
|---|---|---|
| [autokeras/graph.py](https://codecov.io/gh/keras-team/autokeras/pull/1822/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL2dyYXBoLnB5) | `100.00% <0.00%> (ø)` | |
| [autokeras/pipeline.py](https://codecov.io/gh/keras-team/autokeras/pull/1822/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL3BpcGVsaW5lLnB5) | `100.00% <0.00%> (ø)` | |
| [autokeras/auto\_model.py](https://codecov.io/gh/keras-team/autokeras/pull/1822/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL2F1dG9fbW9kZWwucHk=) | `100.00% <0.00%> (ø)` | |
| [autokeras/engine/head.py](https://codecov.io/gh/keras-team/autokeras/pull/1822/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL2VuZ2luZS9oZWFkLnB5) | `100.00% <0.00%> (ø)` | |
| [autokeras/blocks/basic.py](https://codecov.io/gh/keras-team/autokeras/pull/1822/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL2Jsb2Nrcy9iYXNpYy5weQ==) | `100.00% <0.00%> (ø)` | |
| [autokeras/engine/tuner.py](https://codecov.io/gh/keras-team/autokeras/pull/1822/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL2VuZ2luZS90dW5lci5weQ==) | `100.00% <0.00%> (ø)` | |
| [autokeras/keras\_layers.py](https://codecov.io/gh/keras-team/autokeras/pull/1822/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL2tlcmFzX2xheWVycy5weQ==) | `100.00% <0.00%> (ø)` | |
| [autokeras/tuners/greedy.py](https://codecov.io/gh/keras-team/autokeras/pull/1822/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL3R1bmVycy9ncmVlZHkucHk=) | `100.00% <0.00%> (ø)` | |
| [autokeras/blocks/wrapper.py](https://codecov.io/gh/keras-team/autokeras/pull/1822/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL2Jsb2Nrcy93cmFwcGVyLnB5) | `100.00% <0.00%> (ø)` | |
| [autokeras/engine/serializable.py](https://codecov.io/gh/keras-team/autokeras/pull/1822/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL2VuZ2luZS9zZXJpYWxpemFibGUucHk=) | `100.00% <0.00%> (ø)` | |
| ... and [6 more](https://codecov.io/gh/keras-team/autokeras/pull/1822/diff?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) | |

Help us with your feedback. Take ten seconds to tell us [how you rate us](https://about.codecov.io/nps?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team). Have a feature suggestion? [Share it here.](https://app.codecov.io/gh/feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)

</details>

[:umbrella: View full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1822?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).   
:loudspeaker: Do you have feedback about the report comment? [Let us know in this issue](https://about.codecov.io/codecov-pr-comment-feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
",report base head change project coverage coverage data based head base patch summary additional impacted coverage master coverage impacted coverage help u feedback take ten tell u rate u feature suggestion share umbrella view full report feedback report comment let u know issue,issue,positive,negative,negative,negative,negative,negative
1366855889,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1823?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) Report
Base: **100.00**% // Head: **100.00**% // No change to project coverage :thumbsup:
> Coverage data is based on head [(`01f242e`)](https://codecov.io/gh/keras-team/autokeras/pull/1823?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) compared to base [(`c2199f9`)](https://codecov.io/gh/keras-team/autokeras/commit/c2199f90d87918391e9c8d01097a6ec1d2a62565?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
> Patch coverage: 100.00% of modified lines in pull request are covered.

<details><summary>Additional details and impacted files</summary>


```diff
@@            Coverage Diff            @@
##            master     #1823   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           51        51           
  Lines         3383      3383           
=========================================
  Hits          3383      3383           
```


| [Impacted Files](https://codecov.io/gh/keras-team/autokeras/pull/1823?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) | Coverage Δ | |
|---|---|---|
| [autokeras/adapters/input\_adapters.py](https://codecov.io/gh/keras-team/autokeras/pull/1823/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL2FkYXB0ZXJzL2lucHV0X2FkYXB0ZXJzLnB5) | `100.00% <100.00%> (ø)` | |

Help us with your feedback. Take ten seconds to tell us [how you rate us](https://about.codecov.io/nps?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team). Have a feature suggestion? [Share it here.](https://app.codecov.io/gh/feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)

</details>

[:umbrella: View full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1823?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).   
:loudspeaker: Do you have feedback about the report comment? [Let us know in this issue](https://about.codecov.io/codecov-pr-comment-feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
",report base head change project coverage coverage data based head fe base patch coverage pull request covered summary additional impacted coverage master coverage impacted coverage help u feedback take ten tell u rate u feature suggestion share umbrella view full report feedback report comment let u know issue,issue,positive,negative,negative,negative,negative,negative
1364467776,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1821?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) Report
Base: **100.00**% // Head: **100.00**% // No change to project coverage :thumbsup:
> Coverage data is based on head [(`b0323f9`)](https://codecov.io/gh/keras-team/autokeras/pull/1821?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) compared to base [(`535fe10`)](https://codecov.io/gh/keras-team/autokeras/commit/535fe10367aafce90ed55bf886dee0b9b6accc36?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
> Patch has no changes to coverable lines.

<details><summary>Additional details and impacted files</summary>


```diff
@@            Coverage Diff            @@
##            master     #1821   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           51        51           
  Lines         3383      3383           
=========================================
  Hits          3383      3383           
```



Help us with your feedback. Take ten seconds to tell us [how you rate us](https://about.codecov.io/nps?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team). Have a feature suggestion? [Share it here.](https://app.codecov.io/gh/feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)

</details>

[:umbrella: View full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1821?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).   
:loudspeaker: Do you have feedback about the report comment? [Let us know in this issue](https://about.codecov.io/codecov-pr-comment-feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
",report base head change project coverage coverage data based head base fe patch summary additional impacted coverage master coverage help u feedback take ten tell u rate u feature suggestion share umbrella view full report feedback report comment let u know issue,issue,positive,negative,negative,negative,negative,negative
1363906038,"> > I didn't remove overwrite=True, now I'm running an autosklearn code on the same dataset, and it's working, and I don't have any issues with it. When I run AK On Colab sometimes it passes the 3rd trial and sometimes don't but on Kaggle it didn't pass the 3rd trial.
> 
> hi , I'm beginner in deep learning area , and I only use Collab . is there any other servers I can use to run my codes ? thank you very much

You can use >> https://www.kaggle.com/
it will give you grate resources for learning, and you can run your codes either.",remove running code working run ak sometimes trial sometimes pas trial hi beginner deep learning area use use run thank much use give grate learning run either,issue,negative,positive,neutral,neutral,positive,positive
1363435626,"> I didn't remove overwrite=True, now I'm running an autosklearn code on the same dataset, and it's working, and I don't have any issues with it. When I run AK On Colab sometimes it passes the 3rd trial and sometimes don't but on Kaggle it didn't pass the 3rd trial.

hi , I'm beginner in deep learning area , and I only use Collab . is there any other servers I can use to run my codes ?
thank you very much",remove running code working run ak sometimes trial sometimes pas trial hi beginner deep learning area use use run thank much,issue,negative,positive,neutral,neutral,positive,positive
1358626586,"I didn't remove overwrite=True, 
now I'm running an autosklearn code on the same dataset, and it's working, and I don't have any issues with it.
When I run AK On Colab sometimes it passes the 3rd trial and sometimes don't but on kaggle it didn't pass the 3rd trial.",remove running code working run ak sometimes trial sometimes pas trial,issue,negative,neutral,neutral,neutral,neutral,neutral
1354608386,update: weight decay is the culprit. Need a fix for this.,update weight decay culprit need fix,issue,negative,neutral,neutral,neutral,neutral,neutral
1354304489,"## [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1817?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) Report
Patch and project coverage have no change.
> Comparison is base [(`cabfbf0`)](https://codecov.io/gh/keras-team/autokeras/commit/cabfbf0507c24a53e549cafc9ecbdb7a45419345?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) 100.00% compared to head [(`d43dc20`)](https://codecov.io/gh/keras-team/autokeras/pull/1817?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) 100.00%.

> :exclamation: Current head d43dc20 differs from pull request most recent head b4a4e15. Consider uploading reports for the commit b4a4e15 to get more accurate results

<details><summary>Additional details and impacted files</summary>


```diff
@@            Coverage Diff             @@
##            master     #1817    +/-   ##
==========================================
  Coverage   100.00%   100.00%            
==========================================
  Files           50        51     +1     
  Lines         2929      3383   +454     
==========================================
+ Hits          2929      3383   +454     
```


[see 33 files with indirect coverage changes](https://codecov.io/gh/keras-team/autokeras/pull/1817/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)

Help us with your feedback. Take ten seconds to tell us [how you rate us](https://about.codecov.io/nps?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team). Have a feature suggestion? [Share it here.](https://app.codecov.io/gh/feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)

</details>

[:umbrella: View full report in Codecov by Sentry](https://codecov.io/gh/keras-team/autokeras/pull/1817?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).   
:loudspeaker: Do you have feedback about the report comment? [Let us know in this issue](https://about.codecov.io/codecov-pr-comment-feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
",report patch project coverage change comparison base head exclamation current head pull request recent head bae consider commit bae get accurate summary additional impacted coverage master coverage see indirect coverage help u feedback take ten tell u rate u feature suggestion share umbrella view full report sentry feedback report comment let u know issue,issue,positive,negative,neutral,neutral,negative,negative
1352291706,"It is really strange. I don't think there is any randomness in the first 3 trials.
The tuner would try 3 sets of predefined hyperparameters before exploring the rest.

Is it possible that it is because that you removed `overwrite=True`, which caused the problem?

It seems an important bug, but I cannot reproduce it on my computer.",really strange think randomness first tuner would try exploring rest possible removed problem important bug reproduce computer,issue,negative,positive,positive,positive,positive,positive
1351573426,"When I run 2 trials the code works well, as you said the problem happens with the BERT model in the 3rd trial. One time it worked with 10 trials and I had good results. The error occurs randomly.

> @YASIRAQ It seems like a bug, but I cannot reproduce it. The 3rd trial is always the Bert model. There is no randomness in the first 3 trials. Do you see this error if you run [this tutorial](https://autokeras.com/tutorial/text_classification/) for 5 trials?

",run code work well said problem model trial one time worked good error randomly like bug reproduce trial always model randomness first see error run tutorial,issue,negative,positive,positive,positive,positive,positive
1351327523,"> 
I run the tutorial , it worked well
the most important I want to tell you that I worked on my dataset on Sunday , it worked well . the problem happened yesterday
may be this bug happens randomly ?
",run tutorial worked well important want tell worked worked well problem yesterday may bug randomly,issue,negative,negative,neutral,neutral,negative,negative
1350346753,"@YASIRAQ It seems like a bug, but I cannot reproduce it.
The 3rd trial is always the Bert model. There is no randomness in the first 3 trials.
Do you see this error if you run [this tutorial](https://autokeras.com/tutorial/text_classification/) for 5 trials?",like bug reproduce trial always model randomness first see error run tutorial,issue,negative,positive,positive,positive,positive,positive
1349943710,"> @YASIRAQ Would you please confirm the autokeras and keras-tuner version you are using? You can run `pip freeze` to show them.
> 
> It would be even better if you can provide a short colab notebook to reproduce the error. You can use fake data and fix the seed. Thanks.

the versions I use are :
auto keras =1.0.20
keras-tuner =1.1.3

if you do not mind explaining what i must do exactly ?
thank you very much",would please confirm version run pip freeze show would even better provide short notebook reproduce error use fake data fix seed thanks use auto mind explaining must exactly thank much,issue,positive,positive,positive,positive,positive,positive
1349863011,"@YASIRAQ Would you please confirm the autokeras and keras-tuner version you are using?
You can run `pip freeze` to show them.

It would be even better if you can provide a short colab notebook to reproduce the error.
You can use fake data and fix the seed.
Thanks.",would please confirm version run pip freeze show would even better provide short notebook reproduce error use fake data fix seed thanks,issue,negative,positive,neutral,neutral,positive,positive
1340988149,"> I received a similar error when I had tensorflow 2.11.0 installed. The offending line was:
> 
> ```
> tf.cast(self.weight_decay, variable.dtype)
> ```
> 
> where `self.weight_decay = 'AdamWeightDecay'` and `variable.dtype = tf.float32`. I don't have a re-producing script to run but, I hit this when running `StructuredDataClassifier.fit`.
> 
> Rolling back to tensorflow `2.10.1` resolved this issue for me.
> 
> Full stacktrace

Many thanks @erichulburd, using TensorFlow 2.10.1 solved the issue. 
",received similar error line script run hit running rolling back resolved issue full many thanks issue,issue,negative,positive,positive,positive,positive,positive
1340088536,"I received a similar error when I had tensorflow 2.11.0 installed. The offending line was:

```
tf.cast(self.weight_decay, variable.dtype)
```

where `self.weight_decay = 'AdamWeightDecay'` and `variable.dtype = tf.float32`. I don't have a re-producing script to run but, I hit this when running `StructuredDataClassifier.fit`. 

Rolling back to tensorflow `2.10.1` resolved this issue for me.

<details>
<summary>Full stacktrace</summary>
```
Out[2]: 'AdamWeightDecay'
Out[3]: <tf.Tensor 'Cast_2:0' shape=() dtype=float32>
2022-12-06 11:32:24.139522: W tensorflow/core/framework/op_kernel.cc:1807] OP_REQUIRES failed at cast_op.cc:121 : UNIMPLEMENTED: Cast string to float is not supported
2022-12-06 11:32:24.141576: W tensorflow/core/framework/op_kernel.cc:1807] OP_REQUIRES failed at cast_op.cc:121 : UNIMPLEMENTED: Cast string to float is not supported
Traceback (most recent call last):
  File ""~/repo/.venv/lib/python3.8/site-packages/autokeras/utils/utils.py"", line 101, in run_with_adaptive_batch_size
    history = func(x=x, validation_data=validation_data, **fit_kwargs)
  File ""~/repo/.venv/lib/python3.8/site-packages/autokeras/utils/utils.py"", line 89, in <lambda>
    batch_size, lambda **kwargs: model.fit(**kwargs), **fit_kwargs
  File ""~/repo/.venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py"", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""~/repo/.venv/lib/python3.8/site-packages/tensorflow/python/eager/execute.py"", line 52, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.UnimplementedError: Graph execution error:

Detected at node 'Cast_5' defined at (most recent call last):
    File ""/Applications/PyCharm CE.app/Contents/plugins/python-ce/helpers/pydev/pydevd.py"", line 2141, in <module>
      main()
    File ""/Applications/PyCharm CE.app/Contents/plugins/python-ce/helpers/pydev/pydevd.py"", line 2132, in main
      globals = debugger.run(setup['file'], None, None, is_module)
    File ""/Applications/PyCharm CE.app/Contents/plugins/python-ce/helpers/pydev/pydevd.py"", line 1441, in run
      return self._exec(is_module, entry_point_fn, module_name, file, globals, locals)
    File ""/Applications/PyCharm CE.app/Contents/plugins/python-ce/helpers/pydev/pydevd.py"", line 1448, in _exec
      pydev_imports.execfile(file, globals, locals)  # execute the script
    File ""/Applications/PyCharm CE.app/Contents/plugins/python-ce/helpers/pydev/_pydev_imps/_pydev_execfile.py"", line 18, in execfile
      exec(compile(contents+""\n"", file, 'exec'), glob, loc)
    File ""~/repo/qcaan/classifier.py"", line 54, in <module>
      train(Classifier.AUTO_KERAS)
    File ""~/repo/qcaan/classifier.py"", line 41, in train
      train_results = classifier.train()
    File ""~/repo/qcaan/classifier.py"", line 21, in train
      return autokeras.train()
    File ""~/repo/qcaan/classifiers/autokeras.py"", line 108, in train
      ak_classifier.fit(
    File ""~/repo/.venv/lib/python3.8/site-packages/autokeras/tasks/structured_data.py"", line 326, in fit
      history = super().fit(
    File ""~/repo/.venv/lib/python3.8/site-packages/autokeras/tasks/structured_data.py"", line 139, in fit
      history = super().fit(
    File ""~/repo/.venv/lib/python3.8/site-packages/autokeras/auto_model.py"", line 292, in fit
      history = self.tuner.search(
    File ""~/repo/.venv/lib/python3.8/site-packages/autokeras/engine/tuner.py"", line 193, in search
      super().search(
    File ""~/repo/.venv/lib/python3.8/site-packages/keras_tuner/engine/base_tuner.py"", line 183, in search
      results = self.run_trial(trial, *fit_args, **fit_kwargs)
    File ""~/repo/.venv/lib/python3.8/site-packages/keras_tuner/engine/tuner.py"", line 295, in run_trial
      obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)
    File ""~/repo/.venv/lib/python3.8/site-packages/autokeras/engine/tuner.py"", line 101, in _build_and_fit_model
      _, history = utils.fit_with_adaptive_batch_size(
    File ""~/repo/.venv/lib/python3.8/site-packages/autokeras/utils/utils.py"", line 88, in fit_with_adaptive_batch_size
      history = run_with_adaptive_batch_size(
    File ""~/repo/.venv/lib/python3.8/site-packages/autokeras/utils/utils.py"", line 101, in run_with_adaptive_batch_size
      history = func(x=x, validation_data=validation_data, **fit_kwargs)
    File ""~/repo/.venv/lib/python3.8/site-packages/autokeras/utils/utils.py"", line 89, in <lambda>
      batch_size, lambda **kwargs: model.fit(**kwargs), **fit_kwargs
    File ""~/repo/.venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py"", line 65, in error_handler
      return fn(*args, **kwargs)
    File ""~/repo/.venv/lib/python3.8/site-packages/keras/engine/training.py"", line 1650, in fit
      tmp_logs = self.train_function(iterator)
    File ""~/repo/.venv/lib/python3.8/site-packages/keras/engine/training.py"", line 1249, in train_function
      return step_function(self, iterator)
    File ""~/repo/.venv/lib/python3.8/site-packages/keras/engine/training.py"", line 1233, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File ""~/repo/.venv/lib/python3.8/site-packages/keras/engine/training.py"", line 1222, in run_step
      outputs = model.train_step(data)
    File ""~/repo/.venv/lib/python3.8/site-packages/keras/engine/training.py"", line 1027, in train_step
      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)
    File ""~/repo/.venv/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py"", line 527, in minimize
      self.apply_gradients(grads_and_vars)
    File ""~/repo/.venv/lib/python3.8/site-packages/autokeras/keras_layers.py"", line 360, in apply_gradients
      return super(AdamWeightDecay, self).apply_gradients(
    File ""~/repo/.venv/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py"", line 1140, in apply_gradients
      return super().apply_gradients(grads_and_vars, name=name)
    File ""~/repo/.venv/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py"", line 632, in apply_gradients
      self._apply_weight_decay(trainable_variables)
    File ""~/repo/.venv/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py"", line 1159, in _apply_weight_decay
    File ""~/repo/.venv/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py"", line 1155, in distributed_apply_weight_decay
      for variable in variables:
    File ""~/repo/.venv/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py"", line 1151, in weight_decay_fn
Node: 'Cast_5'
Cast string to float is not supported
	 [[{{node Cast_5}}]] [Op:__inference_train_function_333096]
python-BaseException

Process finished with exit code 130 (interrupted by signal 2: SIGINT)
```
</details>",received similar error line script run hit running rolling back resolved issue summary full cast string float cast string float recent call last file line history file line lambda lambda file line raise none file line graph execution error node defined recent call last file line module main file line main setup none none file line run return file file line file execute script file line compile file file line module train file line train file line train return file line train file line fit history super file line fit history super file line fit history file line search super file line search trial file line trial file line history file line history file line history file line lambda lambda file line return file line fit file line return self file line data file line data file line loss file line minimize file line return super self file line return super file line file line file line variable file line node cast string float node process finished exit code interrupted signal,issue,positive,positive,positive,positive,positive,positive
1335950477,"Yes, AutoKeras uses Keras under the hood and did not do much for metrics. ",yes hood much metric,issue,negative,positive,positive,positive,positive,positive
1327808073,"Hi, I am having the same issue using pandas.DataFrame. When the data has all string columns or all numeric columns it is working, but when it is a mix of numeric and categorical columns it expects all inputs to be string. Since I give some numeric columns while predicting, it gives me the same error complaining about numeric ones.

```
TRAIN_DATA_URL = ""https://storage.googleapis.com/tf-datasets/titanic/train.csv""
TEST_DATA_URL = ""https://storage.googleapis.com/tf-datasets/titanic/eval.csv""

train_file_path = tf.keras.utils.get_file(""train.csv"", TRAIN_DATA_URL)
test_file_path = tf.keras.utils.get_file(""eval.csv"", TEST_DATA_URL)

x_train = pd.read_csv(train_file_path)
y_train = x_train.pop(""survived"")

x_test = pd.read_csv(test_file_path)
y_test = x_test.pop(""survived"")

clf = ak.StructuredDataClassifier(
    overwrite=True, max_trials=1
)
clf.fit(
    x_train,
    y_train,
    epochs=1,
)
model = clf.export_model()
predicted_y = model.predict(x_test)
```

```
>> x_train.dtypes
sex                    object
age                   float64
n_siblings_spouses      int64
parch                   int64
fare                  float64
class                  object
deck                   object
embark_town            object
alone                  object
dtype: object

>> model.inputs
[<KerasTensor: shape=(None, 9) dtype=string (created by layer 'input_1')>]
```
",hi issue data string working mix categorical string since give error model sex object age float parch fare float class object deck object object alone object object none layer,issue,negative,neutral,neutral,neutral,neutral,neutral
1306706342,"Hey  @fchollet or  @haifeng-jin ,
Please review the changes in overview.md file and merge the pull request.
thanks
Owais",hey please review file merge pull request thanks,issue,positive,positive,positive,positive,positive,positive
1296289387,"Here is the full trace

```
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/Users/milesmartinez/miniforge3/envs/lemon/lib/python3.10/site-packages/autokeras/__init__.py"", line 1, in <module>
    from autokeras.auto_model import AutoModel
  File ""/Users/milesmartinez/miniforge3/envs/lemon/lib/python3.10/site-packages/autokeras/auto_model.py"", line 11, in <module>
    from autokeras import graph as graph_module
  File ""/Users/milesmartinez/miniforge3/envs/lemon/lib/python3.10/site-packages/autokeras/graph.py"", line 5, in <module>
    from autokeras import hypermodels
  File ""/Users/milesmartinez/miniforge3/envs/lemon/lib/python3.10/site-packages/autokeras/hypermodels/__init__.py"", line 7, in <module>
    from autokeras.hypermodels.heads import ClassificationHead
  File ""/Users/milesmartinez/miniforge3/envs/lemon/lib/python3.10/site-packages/autokeras/hypermodels/heads.py"", line 5, in <module>
    from autokeras import keras_layers
  File ""/Users/milesmartinez/miniforge3/envs/lemon/lib/python3.10/site-packages/autokeras/keras_layers.py"", line 11, in <module>
    Combiner = inspect.getmro(preprocessing.Normalization()._combiner.__class__)[1]
AttributeError: 'Normalization' object has no attribute '_combiner'
```

although `pip install autokeras==1.0.19 --no-deps` resolves it ",full trace recent call last file line module file line module import file line module import graph file line module import file line module import file line module import file line module combiner object attribute although pip install,issue,negative,positive,positive,positive,positive,positive
1295741424,"We don't have support for this right now.
You will have to train it by yourself after exporting the model.",support right train model,issue,negative,positive,positive,positive,positive,positive
1289596423,"I do not have a mac to debug it right now.
Would someone please paste the full stacktrace?

Thanks.
It seems an important issue. No one can use AutoKeras on Mac.",mac right would someone please paste full thanks important issue one use mac,issue,positive,positive,positive,positive,positive,positive
1289586426,"It is mainly because AutoKeras would iterate through the dataset once to get some information before it starts.
It hangs forever?
I will need a snippet to reproduce on colab to debug it.",mainly would iterate get information forever need snippet reproduce,issue,negative,positive,positive,positive,positive,positive
1287850082,Encountered this same issue using tensorflow-metal on M1 Mac and this fixed it for me `pip install autokeras==1.0.19 --no-deps` works just fine now hope it helps,issue mac fixed pip install work fine hope,issue,positive,positive,positive,positive,positive,positive
1276544455,"It is not easy to do in AutoKeras right now.
I will mark it as a feature request see if more people are interested.",easy right mark feature request see people interested,issue,positive,positive,positive,positive,positive,positive
1267733539,"It is about what your labels looks like.
You can try to print the `y_train` in this tutorial:
https://autokeras.com/tutorial/image_classification/

And compare the format to yours.",like try print tutorial compare format,issue,negative,neutral,neutral,neutral,neutral,neutral
1262640736,"I'm curious if there is any reason why AdaNet wasn't initially included in AutoKeras. The results seemed promising, so I assume either (a) its algorithms were subsequently outclassed or (b) its integration would involve a level of complexity that wasn't worthwhile for this library.

",curious reason initially included promising assume either subsequently integration would involve level complexity library,issue,positive,positive,neutral,neutral,positive,positive
1245891623,"This is a bug. Related discussion: https://github.com/keras-team/autokeras/discussions/1773
Contribution is welcome!",bug related discussion contribution welcome,issue,negative,positive,positive,positive,positive,positive
1237447812,Is there any update on this issue? I am noticing same issue running on Windows,update issue issue running,issue,negative,neutral,neutral,neutral,neutral,neutral
1237333482,"@daviembrito I ended up using a generic hyperparameter optimizer with a simple, handcrafted, chain-structured search space. It worked reasonably well in my use case, but it also introduces a large human bias with quite a limited search space of possible network architectures.

You can have a look at it here:

https://github.com/maechler/a2e
https://github.com/maechler/a2e/blob/master/experiments/automl/deep_easing_feed_forward_dropout.py
https://github.com/maechler/a2e/blob/master/a2e/model/keras/_feed_forward.py#L111
https://github.com/maechler/a2e/blob/master/a2e/model/keras/_lstm.py#L6",ended generic simple search space worked reasonably well use case also large human bias quite limited search space possible network look,issue,negative,positive,neutral,neutral,positive,positive
1235794580,"> 

I was trying to create a LSTM Autoencoder, but couldn't realize how to do this. Do you have a clue now?
",trying create could realize clue,issue,negative,neutral,neutral,neutral,neutral,neutral
1234321238,"hello . I have text classification issue . I want to keep everything as auto except I want to specify word2vec 
technique as word embedding . how can I do that ? thank you",hello text classification issue want keep everything auto except want specify technique word thank,issue,negative,neutral,neutral,neutral,neutral,neutral
1234285590,hello . I want to do text classification by using auto-keras . but I want to specify word2vec as word embedding technique. how can  I do that ? thank you very much,hello want text classification want specify word technique thank much,issue,negative,positive,positive,positive,positive,positive
1234155401,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1770?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) Report
> Merging [#1770](https://codecov.io/gh/keras-team/autokeras/pull/1770?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) (20c380a) into [master](https://codecov.io/gh/keras-team/autokeras/commit/64e6c3ac087ffd326cd1e472f2c4ad3e0feaf3ae?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) (64e6c3a) will **not change** coverage.
> The diff coverage is `n/a`.

```diff
@@            Coverage Diff            @@
##            master     #1770   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           51        51           
  Lines         3425      3425           
=========================================
  Hits          3425      3425           
```



Help us with your feedback. Take ten seconds to tell us [how you rate us](https://about.codecov.io/nps?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team). Have a feature suggestion? [Share it here.](https://app.codecov.io/gh/feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)
",report ca master change coverage coverage coverage master coverage help u feedback take ten tell u rate u feature suggestion share,issue,positive,neutral,neutral,neutral,neutral,neutral
1233568699,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1769?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) Report
> Merging [#1769](https://codecov.io/gh/keras-team/autokeras/pull/1769?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) (ac26500) into [master](https://codecov.io/gh/keras-team/autokeras/commit/4c928bbda1f8a16ddd89dde291e5965fcf4f7160?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) (4c928bb) will **not change** coverage.
> The diff coverage is `n/a`.

```diff
@@            Coverage Diff            @@
##            master     #1769   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           51        51           
  Lines         3425      3425           
=========================================
  Hits          3425      3425           
```



Help us with your feedback. Take ten seconds to tell us [how you rate us](https://about.codecov.io/nps?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team). Have a feature suggestion? [Share it here.](https://app.codecov.io/gh/feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)
",report master change coverage coverage coverage master coverage help u feedback take ten tell u rate u feature suggestion share,issue,positive,neutral,neutral,neutral,neutral,neutral
1232444170,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1766?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) Report
> Merging [#1766](https://codecov.io/gh/keras-team/autokeras/pull/1766?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) (749a1a2) into [master](https://codecov.io/gh/keras-team/autokeras/commit/490436db8b667b32bafdf5eeadca24aa003fb524?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) (490436d) will **not change** coverage.
> The diff coverage is `100.00%`.

```diff
@@            Coverage Diff            @@
##            master     #1766   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           51        51           
  Lines         3411      3425   +14     
=========================================
+ Hits          3411      3425   +14     
```


| [Impacted Files](https://codecov.io/gh/keras-team/autokeras/pull/1766?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) | Coverage Δ | |
|---|---|---|
| [autokeras/blocks/basic.py](https://codecov.io/gh/keras-team/autokeras/pull/1766/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL2Jsb2Nrcy9iYXNpYy5weQ==) | `100.00% <100.00%> (ø)` | |
| [autokeras/blocks/preprocessing.py](https://codecov.io/gh/keras-team/autokeras/pull/1766/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL2Jsb2Nrcy9wcmVwcm9jZXNzaW5nLnB5) | `100.00% <100.00%> (ø)` | |
| [autokeras/utils/io\_utils.py](https://codecov.io/gh/keras-team/autokeras/pull/1766/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL3V0aWxzL2lvX3V0aWxzLnB5) | `100.00% <100.00%> (ø)` | |

Help us with your feedback. Take ten seconds to tell us [how you rate us](https://about.codecov.io/nps?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team). Have a feature suggestion? [Share it here.](https://app.codecov.io/gh/feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)
",report aa master change coverage coverage coverage master coverage impacted coverage help u feedback take ten tell u rate u feature suggestion share,issue,positive,neutral,neutral,neutral,neutral,neutral
1225986235,"Hi @haifeng-jin @ywtaccelerator, does the suggested solution measures the F1 for the whole dataset, that is, after each epoch? 
F1-score native support was removed from Keras 2 since this quantity was evaluated for each batch, which might be misleading, since this metric is only meaningful for the whole dataset.
Is the batch problem still there when defining a customized metric such as F1-score in auto-keras? thanks",hi solution whole epoch native support removed since quantity batch might misleading since metric meaningful whole batch problem still metric thanks,issue,positive,positive,positive,positive,positive,positive
1225119687,"Fit consists of 2 steps, search and final fit.
The ""last trained model"" is the best model during search and final fit with your entire training set.
During the search it was only trained with a split of the data you provided.

So the difference in accuracy is mainly because it is using different dataset to evaluate.

If you use `clf.fit(x_train, y_train, validation_data=(x_test, y_test)` and `clf.evaluate(x_test, y_test)`, the accuracy should be the same.",fit search final fit last trained model best model search final fit entire training set search trained split data provided difference accuracy mainly different evaluate use accuracy,issue,positive,positive,positive,positive,positive,positive
1218422893,"> Thanks for the PR! However, we prefer to keep the current simple bibtex for now until the cff files are widely adopted in popular repos.

It might be an idea to add the `DOI` https://doi.org/10.1145/3292500.3330648 because it will help reference managers like [Endnote](http://endnote.com) or [Zotero](https://www.zotero.org) keep tracking the reference-updates.",thanks however prefer keep current simple widely adopted popular might idea add help reference like keep,issue,positive,positive,positive,positive,positive,positive
1217115072,"> If you have in your folder script with the name ""autokeras.py"" rename it.

Thanks 🚀",folder script name rename thanks rocket,issue,negative,positive,positive,positive,positive,positive
1210120981,It stops whenever maximum number of epochs are reached in just 1 case and it out put the last model and last epoch ,whenever maximum number case put last model last epoch,issue,negative,neutral,neutral,neutral,neutral,neutral
1205898550,"Did this actually get added at some point? Not seeing anything in the docs about it, nor immediately seeing any references in the code (though there does seem to be an older issue regarding the same feature: #132 )",actually get added point seeing anything immediately seeing code though seem older issue regarding feature,issue,negative,positive,neutral,neutral,positive,positive
1202090789,how to use the current framework in object detection by adapting some bbox predictor? is it possible,use current framework object detection predictor possible,issue,negative,neutral,neutral,neutral,neutral,neutral
1200017806,"This exact same error happens to me whenever I import autokeras on Mac, hopefully it gets fixed.",exact error whenever import mac hopefully fixed,issue,negative,positive,positive,positive,positive,positive
1193945295,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1752?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) Report
> Merging [#1752](https://codecov.io/gh/keras-team/autokeras/pull/1752?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) (f4904f3) into [master](https://codecov.io/gh/keras-team/autokeras/commit/af9168fcc6ac07d3a7e9835d034763239bdfe4ff?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) (af9168f) will **not change** coverage.
> The diff coverage is `n/a`.

```diff
@@            Coverage Diff            @@
##            master     #1752   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           51        51           
  Lines         3411      3411           
=========================================
  Hits          3411      3411           
```



------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1752?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1752?src=pr&el=footer&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team). Last update [af9168f...f4904f3](https://codecov.io/gh/keras-team/autokeras/pull/1752?src=pr&el=lastupdated&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
",report master change coverage coverage coverage master coverage continue review full report legend click learn absolute relative impact affected missing data powered last update read comment,issue,negative,positive,neutral,neutral,positive,positive
1193913566,"Hi All.. Does this issue resolved ? 
I am still facing the same issue ""unimplemented graph execution error"". 

if we are testing in same environment its working fine but when test in another its shows error.

@haifeng-jin : Can you please advise on this.",hi issue resolved still facing issue graph execution error testing environment working fine test another error please advise,issue,negative,positive,positive,positive,positive,positive
1193103997,"Hi, I encountered same issue.

I made a workaround without modifying code of autokeras because I'm using Google Colab.

```
ak_model = StructuredDataClassifier(
    column_names=features,
    project_name=project_name,
    directory=""model"",
    seed=0,
)
history = ak_model.fit(train_X, train_y, validation_data=(test_X, test_y))
# print(""eval train:"", ak_model.evaluate(train_X, train_y))  # same error here
# print(""eval test:"", ak_model.evaluate(test_X, test_y))  # same error here

# fix it buy calling adapt()
model = keras.models.load_model(f""model/{project_name}/best_model"",
    custom_objects=autokeras.CUSTOM_OBJECTS)
dataset, validation_data = ak_model._convert_to_dataset(
    x=train_X, y=train_y, validation_data=(test_X, test_y), batch_size=32
)
ak_model.tuner.adapt(model, dataset)

# now save adapted model, we can do predict, evaluate now  :)
model.save(f""model/{project_name}/best_model_adapted"", save_format=""tf"")
print(""eval train:"", model.evaluate(train_X, train_y))
print(""eval test:"", model.evaluate(test_X, test_y))

```

I think this issue is due to adapt() not being called for some reason under some situations,  
so MultiCategoryEncoding's table is not initialized. It hasn't seen any data, so it doesn't know how to encode data.
",hi issue made without code model history print train error print test error fix buy calling adapt model model save model predict evaluate print train print test think issue due adapt reason table seen data know encode data,issue,negative,negative,negative,negative,negative,negative
1183099691,"workaround - you need to resize imeages

```py
def process_path(filename):
  # ....
  image = tf.image.resize(image, [256, 256])
  return image, label
```
so maybe this is not realy autokers bug.",need resize image image return image label maybe bug,issue,negative,neutral,neutral,neutral,neutral,neutral
1172983059,"@haifeng-jin , thank you for your help.

Almost worked your solution. I had to add another level of the index array like the following code:

`auto_model.tuner.hyper_pipeline.outputs[0][0].preprocessor.labels
`
When you make a more elegant way to fix this problem, please, let me know.

Thank again for your help.",thank help almost worked solution add another level index array like following code make elegant way fix problem please let know thank help,issue,positive,positive,positive,positive,positive,positive
1170915316,"model = clf.export_model() 输出的model感觉是最后一次训练的model，不是best model
please help me，thank you ，谢谢",model model please help,issue,positive,neutral,neutral,neutral,neutral,neutral
1170370869,"try export PYTHONWARNINGS='ignore:semaphore_tracker:UserWarning'. this is a warning, we can close this warming.",try export warning close warming,issue,negative,neutral,neutral,neutral,neutral,neutral
1169650721,"A workaround that prevents the downstream issues is to replace the else branch as follows;

```
            copied_fit_kwargs = copy.copy(fit_kwargs)

            # Remove early-stopping since no validation data.
            # Remove early-stopping since it is inserted.
            copied_fit_kwargs[""callbacks""] = self._remove_early_stopping(callbacks)
            # Decide the number of epochs.
            copied_fit_kwargs[""epochs""] = 0

            self.hypermodel.set_fit_args(0, epochs=copied_fit_kwargs[""epochs""])
            pipeline, model, history = self.final_fit(**copied_fit_kwargs)
```",downstream replace else branch remove since validation data remove since inserted decide number pipeline model history,issue,negative,neutral,neutral,neutral,neutral,neutral
1167764580,"It should be something similar to the following:
```py
auto_model.tuner.hyper_pipeline.outputs[0].preprocessor.labels
```
It corresponds to this attribute: https://github.com/keras-team/autokeras/blob/8e128ca7f9ca6f9efb7276be0262c53bd4b279ed/autokeras/preprocessors/encoders.py#L30
It should be a list of strings corresponding the class labels of the probabilities.
Please let me know if it works.
We may have a more elegent way to get this information in the future.",something similar following attribute list corresponding class please let know work may way get information future,issue,negative,neutral,neutral,neutral,neutral,neutral
1161874259,"Hi! What is the state of resolving the bug please? I couldn't find any workaround and I'd like to use the exported model in other frameworks not supporting AK exported objects. I appreciate some progress on the issue, thanks.",hi state bug please could find like use model supporting ak appreciate progress issue thanks,issue,positive,positive,positive,positive,positive,positive
1159937869,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1741?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) Report
> Merging [#1741](https://codecov.io/gh/keras-team/autokeras/pull/1741?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) (81b85b1) into [master](https://codecov.io/gh/keras-team/autokeras/commit/efe94d22db641cfda564009d0bfb330bc9eea261?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) (efe94d2) will **not change** coverage.
> The diff coverage is `100.00%`.

```diff
@@            Coverage Diff            @@
##            master     #1741   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           51        51           
  Lines         3411      3411           
=========================================
  Hits          3411      3411           
```


| [Impacted Files](https://codecov.io/gh/keras-team/autokeras/pull/1741?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) | Coverage Δ | |
|---|---|---|
| [autokeras/keras\_layers.py](https://codecov.io/gh/keras-team/autokeras/pull/1741/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL2tlcmFzX2xheWVycy5weQ==) | `100.00% <100.00%> (ø)` | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1741?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1741?src=pr&el=footer&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team). Last update [efe94d2...81b85b1](https://codecov.io/gh/keras-team/autokeras/pull/1741?src=pr&el=lastupdated&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
",report master change coverage coverage coverage master coverage impacted coverage continue review full report legend click learn absolute relative impact affected missing data powered last update read comment,issue,negative,positive,neutral,neutral,positive,positive
1155090247,"Optimizer will be a larger block of settings including learning rate, instead of considering optimizer and learning rate separately.",block learning rate instead considering learning rate separately,issue,negative,neutral,neutral,neutral,neutral,neutral
1148068336,I Have the same issue with multiclass probabilities. I need to know what is the class predicted but I do not have certain. Hava a simple way to solve this problem?,issue need know class certain simple way solve problem,issue,negative,positive,positive,positive,positive,positive
1146743886,"@haifeng-jin is there a chance for an early abort in case of constant production of `nan`?
thx",chance early abort case constant production nan,issue,negative,positive,neutral,neutral,positive,positive
1136637849,"Thanks, after I set lookback divisible by batch_size it works.",thanks set divisible work,issue,negative,positive,positive,positive,positive,positive
1135147281,"Since you've installed tensorflow-macos you can instruct pip to ignore the tensorflow>=2.8.0 dependency with:
```
pip install autokeras==1.0.19 --no-deps
```",since instruct pip ignore dependency pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
1131956958,This is [Issue 1554](https://github.com/keras-team/autokeras/issues/1554). It seems possible to work around it by setting the batch size so that `lookback` is divisible by `batch_size`. ,issue possible work around setting batch size divisible,issue,negative,neutral,neutral,neutral,neutral,neutral
1130382156,"@Anselmoo I will make the fix then, it may take some time. Thanks.",make fix may take time thanks,issue,negative,positive,positive,positive,positive,positive
1129198209,"running both latest versions `autkeras 1.0.2` and `tensorflow-macos 2.8.0` as i am on mac m1

might have something to do with tensorflow-macos but thanks for the reply ",running latest mac might something thanks reply,issue,negative,positive,positive,positive,positive,positive
1129193066,Please update AutoKeras and TensorFlow to the latest version. The error would disappear.,please update latest version error would disappear,issue,negative,positive,positive,positive,positive,positive
1129189466,"has anybody been able to fix this problem?

facing the same issue and desperately need to get it to work for an experiment i am undergoing for my bachelors degree :D ",anybody able fix problem facing issue desperately need get work experiment undergoing degree,issue,negative,negative,neutral,neutral,negative,negative
1128831864,"> Thanks for the fix!
> 
> If history is None, it should trigger [this error](https://github.com/keras-team/keras-tuner/blob/master/keras_tuner/engine/tuner_utils.py#L283). To your test, does it trigger it? We can first add a `if` to check its None, return an empty dict.
> 
> Check for empty dict in `Oracle.update_trial` to return [invalid status](https://github.com/keras-team/keras-tuner/blob/84eb5c40660fc0fa3745bcb04ee4b4693f80dc07/keras_tuner/engine/trial.py#L32).
> 
> I can make the change if you prefer?

Will be the changes small, then I would prefer if you would do it because I have to first get into the code. Otherwise, I will take later a look.",thanks fix history none trigger error test trigger first add check none return empty check empty return invalid status make change prefer small would prefer would first get code otherwise take later look,issue,positive,positive,neutral,neutral,positive,positive
1126660164,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1726?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) Report
> Merging [#1726](https://codecov.io/gh/keras-team/autokeras/pull/1726?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) (d505e46) into [master](https://codecov.io/gh/keras-team/autokeras/commit/c51da2dd87b195ab3bd0941ea70862c3cf66e9a9?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) (c51da2d) will **not change** coverage.
> The diff coverage is `n/a`.

```diff
@@            Coverage Diff            @@
##            master     #1726   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           51        51           
  Lines         3411      3411           
=========================================
  Hits          3411      3411           
```



------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1726?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1726?src=pr&el=footer&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team). Last update [c51da2d...d505e46](https://codecov.io/gh/keras-team/autokeras/pull/1726?src=pr&el=lastupdated&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
",report de master change coverage coverage coverage master coverage continue review full report legend click learn absolute relative impact affected missing data powered last update de read comment,issue,negative,positive,neutral,neutral,positive,positive
1126303514,"The TimeSeriesForecaster is still in experimental stage. We will take a look into this as we improve it.
Thanks for the report!",still experimental stage take look improve thanks report,issue,positive,positive,positive,positive,positive,positive
1111679266,"@nassssro0444
My question is: the code to reproduce the error only uses tensorflow. It did not use autokeras.
So did you run into this error when you use autokeras?
Would you paste the code of using autokeras to produce this error?",question code reproduce error use run error use would paste code produce error,issue,negative,neutral,neutral,neutral,neutral,neutral
1111675617,"@haifeng-jin  sorry i didn't undrstund what are u trying to say , but  anything i can do to fix this error ??

this is the error looks like :
https://colab.research.google.com/drive/10H7r_-SrvLuGNo6atli5f9Nqbe59DcGX?usp=sharing",sorry trying say anything fix error error like,issue,negative,negative,negative,negative,negative,negative
1111661053,"@nassssro0444 
Does this code appear anywhere in autokeras?
How to get this error with autokeras?",code appear anywhere get error,issue,negative,neutral,neutral,neutral,neutral,neutral
1111567021,"hey bro just add this instruction to your notebook
from tensorflow.keras.preprocessing import preprocess_input the error msg
will be shown here :

---------------------------------------------------------------------------

ImportError                               Traceback (most recent call last)

<ipython-input-1-2569fd104ea5> <https://localhost:8080/#> in <module>()
----> 1 from tensorflow.keras.preprocessing import preprocess_input


ImportError: cannot import name 'preprocess_input' from
'tensorflow.keras.preprocessing'
(/usr/local/lib/python3.7/dist-packages/keras/api/_v2/keras/preprocessing/__init__.py)

---------------------------------------------------------------------------
NOTE: If your import is failing due to a missing package, you can
manually install dependencies using either !pip or !apt.

To view examples of installing some common dependencies, click the
""Open Examples"" button below.
---------------------------------------------------------------------------


‫في الأربعاء، 27 أبريل 2022 في 8:23 م تمت كتابة ما يلي بواسطة ‪Haifeng
Jin‬‏ ***@***.***‬‏>:‬

> @nassssro0444 <https://github.com/nassssro0444> @AI-07
> <https://github.com/AI-07>
> I cannot reproduce this error. My notebook:
>
> https://colab.research.google.com/drive/1vdWhiiwceim6qdvSGwi7O-8A9MOgH8ff?usp=sharing
>
> Would you please provide a bug reproduction notebook?
> Thanks.
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/keras-team/autokeras/issues/942#issuecomment-1111339217>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AWLTFEOEOTEHPOWCFH2HBKDVHGA3JANCNFSM4KQOM5FQ>
> .
> You are receiving this because you were mentioned.Message ID:
> ***@***.***>
>
",hey add instruction notebook import error shown recent call last module import import name note import failing due missing package manually install either pip apt view common click open button reproduce error notebook would please provide bug reproduction notebook thanks reply directly view id,issue,negative,positive,neutral,neutral,positive,positive
1111436158,"@NickSmyr @Neproxx , if there is no other PRs from your side, I may start to draft another release.",side may start draft another release,issue,negative,neutral,neutral,neutral,neutral,neutral
1111431079,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1716?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) Report
> Merging [#1716](https://codecov.io/gh/keras-team/autokeras/pull/1716?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) (9fa2a9f) into [master](https://codecov.io/gh/keras-team/autokeras/commit/8d6a2e4a944a6f93976c8069072b18f66142fa66?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) (8d6a2e4) will **not change** coverage.
> The diff coverage is `100.00%`.

```diff
@@            Coverage Diff            @@
##            master     #1716   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           51        51           
  Lines         3414      3412    -2     
=========================================
- Hits          3414      3412    -2     
```


| [Impacted Files](https://codecov.io/gh/keras-team/autokeras/pull/1716?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) | Coverage Δ | |
|---|---|---|
| [autokeras/blocks/preprocessing.py](https://codecov.io/gh/keras-team/autokeras/pull/1716/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL2Jsb2Nrcy9wcmVwcm9jZXNzaW5nLnB5) | `100.00% <100.00%> (ø)` | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1716?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1716?src=pr&el=footer&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team). Last update [8d6a2e4...9fa2a9f](https://codecov.io/gh/keras-team/autokeras/pull/1716?src=pr&el=lastupdated&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
",report master dae change coverage coverage coverage master coverage impacted coverage continue review full report legend click learn absolute relative impact affected missing data powered last update dae read comment,issue,negative,positive,neutral,neutral,positive,positive
1111422808,"This is the last update for the ImageAugmentation block, thank you very much for the fast merging!",last update block thank much fast,issue,negative,positive,neutral,neutral,positive,positive
1111339217,"@nassssro0444  @AI-07 
I cannot reproduce this error. My notebook:
https://colab.research.google.com/drive/1vdWhiiwceim6qdvSGwi7O-8A9MOgH8ff?usp=sharing

Would you please provide a bug reproduction notebook?
Thanks.",reproduce error notebook would please provide bug reproduction notebook thanks,issue,negative,positive,positive,positive,positive,positive
1110695832,"> > Hi @kevinkit , the minimum tensorflow requirement is 2.1.0 . It would be great if this requirement could be documented.
> 
> Hi @jcrodriguez1989 I'm getting the same error on google colab with tf version 2.8.0. Any idea what could be the reason?

i'm getting the same error did you find any solution ?",hi minimum requirement would great requirement could hi getting error version idea could reason getting error find solution,issue,negative,positive,positive,positive,positive,positive
1107909651,"@NickSmyr The PR is merged. Thanks for your contribution!
AutoKeras will have another release soon before TF 2.9.0 stable release.
Your commit will be in it.",thanks contribution another release soon stable release commit,issue,positive,positive,positive,positive,positive,positive
1107909328,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1710?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) Report
> Merging [#1710](https://codecov.io/gh/keras-team/autokeras/pull/1710?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) (ec4f18e) into [master](https://codecov.io/gh/keras-team/autokeras/commit/797b1a4fc5f95bea538156175fc3d4c391f6da5d?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) (797b1a4) will **not change** coverage.
> The diff coverage is `100.00%`.

```diff
@@            Coverage Diff            @@
##            master     #1710   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           51        51           
  Lines         3415      3418    +3     
=========================================
+ Hits          3415      3418    +3     
```


| [Impacted Files](https://codecov.io/gh/keras-team/autokeras/pull/1710?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) | Coverage Δ | |
|---|---|---|
| [autokeras/blocks/preprocessing.py](https://codecov.io/gh/keras-team/autokeras/pull/1710/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL2Jsb2Nrcy9wcmVwcm9jZXNzaW5nLnB5) | `100.00% <100.00%> (ø)` | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1710?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1710?src=pr&el=footer&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team). Last update [797b1a4...ec4f18e](https://codecov.io/gh/keras-team/autokeras/pull/1710?src=pr&el=lastupdated&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
",report master ba change coverage coverage coverage master coverage impacted coverage continue review full report legend click learn absolute relative impact affected missing data powered last update ba read comment,issue,negative,positive,neutral,neutral,positive,positive
1107873892,"Hey @haifeng-jin ,

[Neproxx](https://github.com/Neproxx) and I need to contribute to an open source project in the context of a university course ([KTH DevOps course](https://github.com/KTH/devops-course/)). We have proposed a PR a week ago (see #1710 ) for this issue  and it would help us out a lot if you could review it and either merge it or tell us about necessary changes. If everything is fine, we would pose a PR for the rest of the hyperparameters that need to be changed. It is important to us to have this done within the next 10 days, so we would be very greatful if you could spare some time to look at the PR.

Many thanks!",hey need contribute open source project context university course course week ago see issue would help u lot could review either merge tell u necessary everything fine would pose rest need important u done within next day would could spare time look many thanks,issue,positive,positive,positive,positive,positive,positive
1106829786,"After I reached about 100 trials, follow-up runs only do one loop and then stop. Why it does not reach defined max_trials=200?",one loop stop reach defined,issue,negative,neutral,neutral,neutral,neutral,neutral
1104953983,"I have the same issue, but with a custom autoModel. One experiment runs fine, then the second one I get this error. I've encountered it with python 3.7.11, autokeras 1.0.16.post1, keras-tuner  1.0.4, scikit-learn 1.0.2, numpy 1.19.5, pandas 1.3.5, tensorflow 2.5.2, ",issue custom one experiment fine second one get error python post,issue,negative,positive,positive,positive,positive,positive
1104802347,"Fixed.  I actually created test script in home directory named autokeras.py and with command ```import autokeras``` the python was trying to import that test script instead of autokeras library. After I renamed my test script autokeras.py to something else, it started to work.",fixed actually test script home directory command import python trying import test script instead library test script something else work,issue,negative,positive,neutral,neutral,positive,positive
1101590585,"pip3 also throws this error:
```
autokeras 1.0.18 requires keras-tuner>=1.1.0, but you have keras-tuner 1.1.2.master which is incompatible.
```

tried ```pip3 install --force-reinstall autokeras``` which reinstalled everything without error but no help

tried on clean Ubuntu installation and got same error",pip also error master incompatible tried pip install everything without error help tried clean installation got error,issue,negative,positive,positive,positive,positive,positive
1101587477,"I tried both installations:
```
pip3 install autokeras
```
and
```
python3 -m pip install git+https://github.com/keras-team/keras-tuner.git
python3 -m pip install autokeras
```
",tried pip install python pip install python pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
1100748057,This bug is present upstream in keras-tuner and there is a keras-tuner specific dirty fix described here [keras-tuner issue 175](https://github.com/keras-team/keras-tuner/issues/175#issuecomment-829440429). I wonder if we may adapt that fix to be compatible with autokeras? That might give us enough context to then implement the solution described [here in issue 1479](https://github.com/keras-team/autokeras/issues/1479#issuecomment-802279289),bug present upstream specific dirty fix issue wonder may adapt fix compatible might give u enough context implement solution issue,issue,negative,negative,negative,negative,negative,negative
1097047196,"Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

For more information, open the [CLA check for this pull request](https://github.com/keras-team/autokeras/pull/1710/checks?check_run_id=5995467697).",thanks pull request like may first contribution open source project look pull request need sign contributor license agreement information open check pull request,issue,positive,positive,positive,positive,positive,positive
1094255141,@haifeng-jin Corrected and reran linter with no errors as per commit 23f6e4f,corrected linter per commit,issue,negative,neutral,neutral,neutral,neutral,neutral
1094186332,"@kutal10 
There are still some errors:
```
./autokeras/blocks/basic.py:266:42: W291 trailing whitespace
./autokeras/blocks/basic.py:267:57: W291 trailing whitespace
./autokeras/blocks/basic.py:311:10: E703 statement ends with a semicolon
```

You can use `sh shell/lint.sh` to run locally to check for the linting errors.
Thanks",still trailing trailing statement semicolon use sh run locally check thanks,issue,negative,positive,neutral,neutral,positive,positive
1094143611,"> Thanks for the PR! Please fix the following erros shown in the CI tests.
> 
> ```
> ./autokeras/blocks/basic.py:265:86: E501 line too long (89 > 85 characters)
> ./autokeras/blocks/basic.py:266:86: E501 line too long (88 > 85 characters)
> ```

@haifeng-jin No problem - just fixed the docstring length in the two specified lines in commit [f59cbdd] above ",thanks please fix following shown line long line long problem fixed length two commit,issue,positive,positive,neutral,neutral,positive,positive
1094103725,"OK, I won't notify you about version 4.x.x again, unless you re-open this PR or update to a 4.x.x release yourself.",wo notify version unless update release,issue,negative,neutral,neutral,neutral,neutral,neutral
1092518713,"I saw that, thank you @eschibli. It is a pity because the library would benefit a lot from this fix in my opinion.",saw thank pity library would benefit lot fix opinion,issue,positive,negative,neutral,neutral,negative,negative
1092079559,@rzese this is [issue 1479](https://github.com/keras-team/autokeras/issues/1479). It hasn't been solved yet and I'm not aware of a workaround unfortunately. ,issue yet aware unfortunately,issue,negative,negative,negative,negative,negative,negative
1090559410,"@Neproxx Great to see you like to contribute!
We don't have a complete list of which has been done and which to be done.
You may just work on any block that is not done yet.",great see like contribute complete list done done may work block done yet,issue,positive,positive,positive,positive,positive,positive
1088644990,"Hey, [NickSmyr](https://github.com/NickSmyr) and I would like to contribute to this issue, so we are wondering whether it is still relevant and which blocks still need changes.",hey would like contribute issue wondering whether still relevant still need,issue,negative,positive,positive,positive,positive,positive
1086495726,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1707?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) Report
> Merging [#1707](https://codecov.io/gh/keras-team/autokeras/pull/1707?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) (6739ca1) into [master](https://codecov.io/gh/keras-team/autokeras/commit/42dc88e4ad323a95bfd6b08df4d88200dd80e4e7?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) (42dc88e) will **not change** coverage.
> The diff coverage is `n/a`.

```diff
@@            Coverage Diff            @@
##            master     #1707   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           51        51           
  Lines         3417      3417           
=========================================
  Hits          3417      3417           
```



------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1707?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1707?src=pr&el=footer&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team). Last update [42dc88e...6739ca1](https://codecov.io/gh/keras-team/autokeras/pull/1707?src=pr&el=lastupdated&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
",report ca master change coverage coverage coverage master coverage continue review full report legend click learn absolute relative impact affected missing data powered last update ca read comment,issue,negative,positive,neutral,neutral,positive,positive
1084814526,"Similar Error here!

OS: MacOS Monterey Ver 12.2.1 (Apple M1)

Python : 3.9.11
numpy: 1.21.2
pandas: 1.4.1
autokeras : 1.0.2
keras : 2.8.0
keras-tuner : 1.1.0
tensorflow-deps 2.8.0
tensorflow-macos 2.8.0
tensorflow-metadata 1.7.0
tensorflow-metal 0.4.0",similar error o apple python,issue,negative,neutral,neutral,neutral,neutral,neutral
1081349193,"That problem may be caused by keras-tuner instead of autokeras.
in keras_tuner/engine/tuner_utils.py:

From original code block =>
```
def format_time(self, t):
    return time.strftime(""%Hh %Mm %Ss"", time.gmtime(t))
```

alternative dirty fix => (only insert days information without further month and year information though.)
```
def format_time(self, t):
    days = divmod(t, 86400)
    return str(int(days[0])) + ""d "" + time.strftime(""%Hh %Mm %Ss"", time.gmtime(t))
```

autokeras had shown correct number of days after this fix in keras-tuner, just for reference.",problem may instead original code block self return alternative dirty fix insert day information without month year information though self day return day shown correct number day fix reference,issue,negative,negative,negative,negative,negative,negative
1069818398,"Hi, I am actually currently facing with the same issue, with the same error when trying to implement ImageClassifier with custom f1-score metric as a custom objective suggested/implemented in the faq section. Can I ask what is the work around this issue? 

I noticed that F1 score is well supported by the Autokeras but not sure what to make out with this error. Here is the snippet of my error message:

ValueError                                Traceback (most recent call last)
~\AppData\Local\Temp/ipykernel_12316/2665656444.py in <module>
      3 # Evaluate on the testing data.
      4 print('Accuracy: {accuracy}'.format(
----> 5     accuracy=clf.evaluate(x_test, y_test)))

~\anaconda3\envs\autokeras\lib\site-packages\autokeras\auto_model.py in evaluate(self, x, y, batch_size, verbose, **kwargs)
    488         pipeline = self.tuner.get_best_pipeline()
    489         dataset = pipeline.transform(dataset)
--> 490         model = self.tuner.get_best_model()
    491         return utils.evaluate_with_adaptive_batch_size(
    492             model=model, batch_size=batch_size, x=dataset, verbose=verbose, **kwargs

~\anaconda3\envs\autokeras\lib\site-packages\autokeras\engine\tuner.py in get_best_model(self)
     61     def get_best_model(self):
     62         with keras_tuner.engine.tuner.maybe_distribute(self.distribution_strategy):
---> 63             model = tf.keras.models.load_model(self.best_model_path)
     64         return model
     65 

~\anaconda3\envs\autokeras\lib\site-packages\keras\utils\traceback_utils.py in error_handler(*args, **kwargs)
     65     except Exception as e:  # pylint: disable=broad-except
     66       filtered_tb = _process_traceback_frames(e.__traceback__)
---> 67       raise e.with_traceback(filtered_tb) from None
     68     finally:
     69       del filtered_tb

~\anaconda3\envs\autokeras\lib\site-packages\keras\saving\saved_model\load.py in revive_custom_object(identifier, metadata)
    999   else:
   1000     raise ValueError(
-> 1001         f'Unable to restore custom object of type {identifier}. '
   1002         f'Please make sure that any custom layers are included in the '
   1003         f'`custom_objects` arg when calling `load_model()` and make sure that '





ValueError: Unable to restore custom object of type _tf_keras_metric. Please make sure that any custom layers are included in the `custom_objects` arg when calling `load_model()` and make sure that all layers implement `get_config` and `from_config`.",hi actually currently facing issue error trying implement custom metric custom objective section ask work around issue score well sure make error snippet error message recent call last module evaluate testing data print accuracy evaluate self verbose pipeline model return self self model return model except exception raise none finally identifier else raise restore custom object type identifier make sure custom included calling make sure unable restore custom object type please make sure custom included calling make sure implement,issue,positive,positive,positive,positive,positive,positive
1062895108,"Still have issue with ""Incompatible shapes: [128,1] vs. [99,1]"" but tried with ""batch size=1"" and it works good. After the model is trained it does not predict any values on model.predict. Any leads here?
ps: I am using ak.TimeseriesForecaster 
 
![Screenshot from 2022-03-09 16-52-15](https://user-images.githubusercontent.com/54292052/157445910-9e015ed0-ebee-4dbb-957d-57fe6012bd91.png)
t",still issue incompatible tried batch work good model trained predict,issue,negative,positive,positive,positive,positive,positive
1061255168,"Bump on this one.  Is it possible to use multiple image inputs with AutoModel?  I see that rakshith291 posted some code to rename layers, but where does that go, somewhere in the source of the fit function?  ",bump one possible use multiple image see posted code rename go somewhere source fit function,issue,negative,positive,positive,positive,positive,positive
1059808349,"**Similar Error here!** 
### **'Normalization' object has no attribute '_combiner'**

```python
import numpy as np
import tensorflow as tf
from tensorflow.keras.datasets import mnist
import autokeras as ak

---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
Input In [2], in <module>
----> 1 import autokeras as ak

File ~/dev/miniforge3/envs/ml/lib/python3.9/site-packages/autokeras/__init__.py:1, in <module>
----> 1 from autokeras.auto_model import AutoModel
      2 from autokeras.engine.block import Block
      3 from autokeras.engine.head import Head

File ~/dev/miniforge3/envs/ml/lib/python3.9/site-packages/autokeras/auto_model.py:11, in <module>
      8 import tensorflow as tf
      9 from tensorflow.python.util import nest
---> 11 from autokeras import graph as graph_module
     12 from autokeras import hypermodels
     13 from autokeras import nodes as input_module

File ~/dev/miniforge3/envs/ml/lib/python3.9/site-packages/autokeras/graph.py:5, in <module>
      2 import tensorflow as tf
      3 from tensorflow.python.util import nest
----> 5 from autokeras import hypermodels
      6 from autokeras import nodes
      7 from autokeras.engine import head as head_module

File ~/dev/miniforge3/envs/ml/lib/python3.9/site-packages/autokeras/hypermodels/__init__.py:7, in <module>
      5 from autokeras.hypermodels.basic import RNNBlock
      6 from autokeras.hypermodels.basic import XceptionBlock
----> 7 from autokeras.hypermodels.heads import ClassificationHead
      8 from autokeras.hypermodels.heads import RegressionHead
      9 from autokeras.hypermodels.preprocessing import CategoricalToNumerical

File ~/dev/miniforge3/envs/ml/lib/python3.9/site-packages/autokeras/hypermodels/heads.py:5, in <module>
      2 from tensorflow.python.util import nest
      4 from autokeras import adapters
----> 5 from autokeras import keras_layers
      6 from autokeras import utils
      7 from autokeras.engine import head as head_module

File ~/dev/miniforge3/envs/ml/lib/python3.9/site-packages/autokeras/keras_layers.py:11, in <module>
      8 from tensorflow.python.util import nest
     10 CombinerPreprocessingLayer = inspect.getmro(preprocessing.Normalization)[1]
---> 11 Combiner = inspect.getmro(preprocessing.Normalization()._combiner.__class__)[1]
     13 INT = 'int'
     14 NONE = 'none'

AttributeError: 'Normalization' object has no attribute '_combiner'`
```


- OS: MacOS Monterey Ver 12.2.1 (Apple M1)
- Python : 3.9.10
- numpy: 1.22.2
- pandas: 1.4.1
- autokeras : 1.0.2
- keras : 2.8.0
- keras-tuner : 1.1.0
- tensorflow-deps           2.8.0
- tensorflow-macos          2.8.0             
- tensorflow-metadata       1.7.0                    
- tensorflow-metal          0.4.0 ",similar error object attribute python import import import import ak recent call last input module import ak file module import import block import head file module import import nest import graph import import file module import import nest import import import head file module import import import import import file module import nest import import import import head file module import nest combiner none object attribute o apple python,issue,negative,neutral,neutral,neutral,neutral,neutral
1052695769,"> Hi @kevinkit , the minimum tensorflow requirement is 2.1.0 . It would be great if this requirement could be documented.

Hi @jcrodriguez1989 I'm getting the same error on google colab with tf version 2.8.0. Any idea what could be the reason?",hi minimum requirement would great requirement could hi getting error version idea could reason,issue,negative,positive,positive,positive,positive,positive
1046151733,We don't have this feature yet. Welcome to discuss on what the API should look like.,feature yet welcome discus look like,issue,positive,positive,positive,positive,positive,positive
1046151564,Please use TF 2.8.0 instead. There are some compatibility issues with the preprocessing layers in 2.7.0.,please use instead compatibility,issue,negative,neutral,neutral,neutral,neutral,neutral
1045988294,"I am also facing the same problem and solved bypassing directory name 
Thank you @psonglao ",also facing problem directory name thank,issue,negative,neutral,neutral,neutral,neutral,neutral
1044447382,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1688?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) Report
> Merging [#1688](https://codecov.io/gh/keras-team/autokeras/pull/1688?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) (7036dcf) into [master](https://codecov.io/gh/keras-team/autokeras/commit/aa266a75008f9ee57f9af3e1bb6df4b9af65e642?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) (aa266a7) will **not change** coverage.
> The diff coverage is `100.00%`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1688/graphs/tree.svg?width=650&height=150&src=pr&token=yDvddb2DDZ&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)](https://codecov.io/gh/keras-team/autokeras/pull/1688?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)

```diff
@@            Coverage Diff            @@
##            master     #1688   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           51        51           
  Lines         3355      3365   +10     
=========================================
+ Hits          3355      3365   +10     
```


| [Impacted Files](https://codecov.io/gh/keras-team/autokeras/pull/1688?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) | Coverage Δ | |
|---|---|---|
| [autokeras/auto\_model.py](https://codecov.io/gh/keras-team/autokeras/pull/1688/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL2F1dG9fbW9kZWwucHk=) | `100.00% <100.00%> (ø)` | |
| [autokeras/blocks/\_\_init\_\_.py](https://codecov.io/gh/keras-team/autokeras/pull/1688/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL2Jsb2Nrcy9fX2luaXRfXy5weQ==) | `100.00% <100.00%> (ø)` | |
| [autokeras/blocks/basic.py](https://codecov.io/gh/keras-team/autokeras/pull/1688/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL2Jsb2Nrcy9iYXNpYy5weQ==) | `100.00% <100.00%> (ø)` | |
| [autokeras/blocks/heads.py](https://codecov.io/gh/keras-team/autokeras/pull/1688/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL2Jsb2Nrcy9oZWFkcy5weQ==) | `100.00% <100.00%> (ø)` | |
| [autokeras/blocks/preprocessing.py](https://codecov.io/gh/keras-team/autokeras/pull/1688/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL2Jsb2Nrcy9wcmVwcm9jZXNzaW5nLnB5) | `100.00% <100.00%> (ø)` | |
| [autokeras/engine/head.py](https://codecov.io/gh/keras-team/autokeras/pull/1688/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL2VuZ2luZS9oZWFkLnB5) | `100.00% <100.00%> (ø)` | |
| [autokeras/engine/named\_hypermodel.py](https://codecov.io/gh/keras-team/autokeras/pull/1688/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL2VuZ2luZS9uYW1lZF9oeXBlcm1vZGVsLnB5) | `100.00% <100.00%> (ø)` | |
| [autokeras/engine/tuner.py](https://codecov.io/gh/keras-team/autokeras/pull/1688/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL2VuZ2luZS90dW5lci5weQ==) | `100.00% <100.00%> (ø)` | |
| [autokeras/graph.py](https://codecov.io/gh/keras-team/autokeras/pull/1688/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL2dyYXBoLnB5) | `100.00% <100.00%> (ø)` | |
| [autokeras/hyper\_preprocessors.py](https://codecov.io/gh/keras-team/autokeras/pull/1688/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL2h5cGVyX3ByZXByb2Nlc3NvcnMucHk=) | `100.00% <100.00%> (ø)` | |
| ... and [6 more](https://codecov.io/gh/keras-team/autokeras/pull/1688/diff?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1688?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1688?src=pr&el=footer&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team). Last update [aa266a7...7036dcf](https://codecov.io/gh/keras-team/autokeras/pull/1688?src=pr&el=lastupdated&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
",report master change coverage coverage impacted file tree graph coverage master coverage impacted coverage continue review full report legend click learn absolute relative impact affected missing data powered last update read comment,issue,negative,positive,neutral,neutral,positive,positive
1040882117,"> Please click the button next to the failed test and follow the instructions to sign ""google cla"". Thanks.
I have signed it.",please click button next test follow sign thanks,issue,positive,positive,neutral,neutral,positive,positive
1038684904,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1684?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) Report
> Merging [#1684](https://codecov.io/gh/keras-team/autokeras/pull/1684?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) (5896905) into [master](https://codecov.io/gh/keras-team/autokeras/commit/85bf1e28e39b4e12da795bce88b9a93bb92ef213?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) (85bf1e2) will **not change** coverage.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1684/graphs/tree.svg?width=650&height=150&src=pr&token=yDvddb2DDZ&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)](https://codecov.io/gh/keras-team/autokeras/pull/1684?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)

```diff
@@            Coverage Diff            @@
##            master     #1684   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           51        51           
  Lines         3355      3355           
=========================================
  Hits          3355      3355           
```



------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1684?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1684?src=pr&el=footer&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team). Last update [85bf1e2...5896905](https://codecov.io/gh/keras-team/autokeras/pull/1684?src=pr&el=lastupdated&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
",report master change coverage coverage impacted file tree graph coverage master coverage continue review full report legend click learn absolute relative impact affected missing data powered last update read comment,issue,negative,positive,neutral,neutral,positive,positive
1035139422,"The problem is that the format required for training is float32 and the default data format after importing the data is uint8, Newer versions of tensorflow also give warnings about this problem. The following code works: 

```
import tensorflow as tf
import autokeras as ak
import numpy as np 

(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()
clf = ak.ImageClassifier(overwrite = True,max_trials = 1)

x_train_float = x_train.astype(np.float32)
clf.fit(x_train_float, y_train, epochs = 1)
model = clf.export_model()

x_tensor = tf.convert_to_tensor(x_test.astype(np.float32))
with tf.GradientTape() as g:
    g.watch(x_tensor)
    y_pred = model(x_tensor)
    dx = g.gradient(y_pred,x_tensor)
    print(dx)

```",problem format training float default data format data also give problem following code work import import ak import overwrite true model model print,issue,negative,positive,positive,positive,positive,positive
1029541686,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1675?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) Report
> Merging [#1675](https://codecov.io/gh/keras-team/autokeras/pull/1675?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) (c13c6d9) into [master](https://codecov.io/gh/keras-team/autokeras/commit/8f483a2dc6780d6721a8208b74030b150e62359f?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) (8f483a2) will **not change** coverage.
> The diff coverage is `100.00%`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1675/graphs/tree.svg?width=650&height=150&src=pr&token=yDvddb2DDZ&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)](https://codecov.io/gh/keras-team/autokeras/pull/1675?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)

```diff
@@            Coverage Diff            @@
##            master     #1675   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           51        51           
  Lines         3355      3355           
=========================================
  Hits          3355      3355           
```


| [Impacted Files](https://codecov.io/gh/keras-team/autokeras/pull/1675?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) | Coverage Δ | |
|---|---|---|
| [autokeras/keras\_layers.py](https://codecov.io/gh/keras-team/autokeras/pull/1675/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL2tlcmFzX2xheWVycy5weQ==) | `100.00% <100.00%> (ø)` | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1675?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1675?src=pr&el=footer&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team). Last update [8f483a2...c13c6d9](https://codecov.io/gh/keras-team/autokeras/pull/1675?src=pr&el=lastupdated&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
",report master fa change coverage coverage impacted file tree graph coverage master coverage impacted coverage continue review full report legend click learn absolute relative impact affected missing data powered last update fa read comment,issue,negative,positive,neutral,neutral,positive,positive
1028454102,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1673?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) Report
> Merging [#1673](https://codecov.io/gh/keras-team/autokeras/pull/1673?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) (a2d4516) into [master](https://codecov.io/gh/keras-team/autokeras/commit/e0d86ab067ae4d29c427844da8baf03119127178?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) (e0d86ab) will **not change** coverage.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1673/graphs/tree.svg?width=650&height=150&src=pr&token=yDvddb2DDZ&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)](https://codecov.io/gh/keras-team/autokeras/pull/1673?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)

```diff
@@            Coverage Diff            @@
##            master     #1673   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           51        51           
  Lines         3355      3355           
=========================================
  Hits          3355      3355           
```



------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1673?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1673?src=pr&el=footer&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team). Last update [e0d86ab...a2d4516](https://codecov.io/gh/keras-team/autokeras/pull/1673?src=pr&el=lastupdated&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
",report ad master change coverage coverage impacted file tree graph coverage master coverage continue review full report legend click learn absolute relative impact affected missing data powered last update ad read comment,issue,negative,positive,neutral,neutral,positive,positive
1025727431,"@AntonioDomenech 
thank you I solved the problem the same as you mentioned which later I found in documentation later after posting .

Thank you ",thank problem later found documentation later posting thank,issue,negative,neutral,neutral,neutral,neutral,neutral
1024259152,"I can confirm that the combination of the other edits suggested in this issue, with the addition of compiling the model with the custom metric in evaluate solves the issue. For me it works with the following version of autoModel.evaluate:

```
    def evaluate(self, x, y=None, batch_size=32, verbose=1, custom_objects={},**kwargs):
        """"""Evaluate the best model for the given data.

        # Arguments
            x: Any allowed types according to the input node. Testing data.
            y: Any allowed types according to the head. Testing targets.
                Defaults to None.
            batch_size: Number of samples per batch.
                If unspecified, batch_size will default to 32.
            verbose: Verbosity mode. 0 = silent, 1 = progress bar.
                Controls the verbosity of
                [keras.Model.evaluate](http://tensorflow.org/api_docs/python/tf/keras/Model#evaluate)
            **kwargs: Any arguments supported by keras.Model.evaluate.

        # Returns
            Scalar test loss (if the model has a single output and no metrics) or
            list of scalars (if the model has multiple outputs and/or metrics).
            The attribute model.metrics_names will give you the display labels for
            the scalar outputs.
        """"""
        self._check_data_format((x, y))
        if isinstance(x, tf.data.Dataset):
            dataset = x
            x = dataset.map(lambda x, y: x)
            y = dataset.map(lambda x, y: y)
        x = self._adapt(x, self.inputs, batch_size)
        y = self._adapt(y, self._heads, batch_size)
        dataset = tf.data.Dataset.zip((x, y))
        pipeline = self.tuner.get_best_pipeline()
        dataset = pipeline.transform(dataset)
        if custom_objects:
            model = self.tuner.get_best_model(custom_objects=custom_objects)
            # only gets metrics from custom_objects for now
            model.compile(metrics=[val for key,val in custom_objects.items()])
        else:
            model = self.tuner.get_best_model()
        return utils.evaluate_with_adaptive_batch_size(
            model=model, batch_size=batch_size, x=dataset, verbose=verbose, **kwargs
```

I compile the model with only the metrics provided in custom objects.",confirm combination issue addition model custom metric evaluate issue work following version evaluate self evaluate best model given data according input node testing data according head testing none number per batch unspecified default verbose verbosity mode silent progress bar verbosity scalar test loss model single output metric list model multiple metric attribute give display scalar lambda lambda pipeline model metric key else model return compile model metric provided custom,issue,positive,positive,positive,positive,positive,positive
1024248264,"> I also notice this problem with the evaluation method. So I tried to solve it the same way you did. But this error returns:
> 
> ```
> /home/riccardo/Desktop/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1323 test_function  *
>     return step_function(self, iterator)
> /home/riccardo/Desktop/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1314 step_function  **
>     outputs = model.distribute_strategy.run(run_step, args=(data,))
> /home/riccardo/Desktop/venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1285 run
>     return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
> /home/riccardo/Desktop/venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2833 call_for_each_replica
>     return self._call_for_each_replica(fn, args, kwargs)
> /home/riccardo/Desktop/venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3608 _call_for_each_replica
>      return fn(*args, **kwargs)
> /home/riccardo/Desktop/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1309 run_step  **
>     with ops.control_dependencies(_minimum_control_deps(outputs)):
> /home/riccardo/Desktop/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:2888 _minimum_control_deps
>     outputs = nest.flatten(outputs, expand_composites=True)
> /home/riccardo/Desktop/venv/lib/python3.8/site-packages/tensorflow/python/util/nest.py:416 flatten
>     return _pywrap_utils.Flatten(structure, expand_composites)
> 
> TypeError: '<' not supported between instances of 'function' and 'str'
> ```

This problem is still going on. This post https://stackoverflow.com/questions/65549053/typeerror-not-supported-between-instances-of-function-and-str says that it can be fixed by compiling the model, but automodel doesnt have direct access to the loss and optimizer. I wonder whether compiling without it can be fixed. I'm going to try it out.
It would be great if this issue could be fixed, it's been going on a long time.
Either that, or maybe remove from the documentation that custom metrics can be used, because it makes it look like it's simple to use but at the moment it is not",also notice problem evaluation method tried solve way error return self data run return return return flatten return structure problem still going post fixed model doesnt direct access loss wonder whether without fixed going try would great issue could fixed going long time either maybe remove documentation custom metric used look like simple use moment,issue,negative,positive,positive,positive,positive,positive
1024238539,"@krishdb38 You didn't load the custom objects created by AutoKeras, that's why you get the error if I'm correct. You can load any custom objects in the load_model() command.

So insted of loading the model the way you did it:
`model = tf.keras.models.load_model(""model_auto_keras_rc_50_trials.h5"")`

You should load the model with custom objects like this:
`model = tf.keras.models.load_model(""model_auto_keras_rc_50_trials.h5"", custom_objects=ak.CUSTOM_OBJECTS)`

Note that `ak.CUSTOM_OBJECTS` are the custom objects from AutoKeras, so you need to import AutoKeras when loading the model.

I hope this helps :)",load custom get error correct load custom command loading model way model load model custom like model note custom need import loading model hope,issue,negative,neutral,neutral,neutral,neutral,neutral
1019409827,"I am having this same issue. I want to force the output of the model to be between 0 and 1 so a dense output layer with a sigmoid activation seems appropriate. However, I am not able to use the class defined here as output in an `AutoModel`, it just keeps raising a `NotImplementedError` and fails to build the model. ",issue want force output model dense output layer sigmoid activation appropriate however able use class defined output raising build model,issue,negative,positive,positive,positive,positive,positive
1018209267,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1666?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) Report
> Merging [#1666](https://codecov.io/gh/keras-team/autokeras/pull/1666?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) (3d68eb7) into [master](https://codecov.io/gh/keras-team/autokeras/commit/335e0708273932bd50977e59852de836c40b09ca?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) (335e070) will **not change** coverage.
> The diff coverage is `100.00%`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1666/graphs/tree.svg?width=650&height=150&src=pr&token=yDvddb2DDZ&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)](https://codecov.io/gh/keras-team/autokeras/pull/1666?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)

```diff
@@            Coverage Diff            @@
##            master     #1666   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           51        51           
  Lines         3353      3355    +2     
=========================================
+ Hits          3353      3355    +2     
```


| [Impacted Files](https://codecov.io/gh/keras-team/autokeras/pull/1666?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) | Coverage Δ | |
|---|---|---|
| [autokeras/auto\_model.py](https://codecov.io/gh/keras-team/autokeras/pull/1666/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL2F1dG9fbW9kZWwucHk=) | `100.00% <100.00%> (ø)` | |
| [autokeras/blocks/basic.py](https://codecov.io/gh/keras-team/autokeras/pull/1666/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL2Jsb2Nrcy9iYXNpYy5weQ==) | `100.00% <100.00%> (ø)` | |
| [autokeras/blocks/heads.py](https://codecov.io/gh/keras-team/autokeras/pull/1666/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL2Jsb2Nrcy9oZWFkcy5weQ==) | `100.00% <100.00%> (ø)` | |
| [autokeras/blocks/preprocessing.py](https://codecov.io/gh/keras-team/autokeras/pull/1666/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL2Jsb2Nrcy9wcmVwcm9jZXNzaW5nLnB5) | `100.00% <100.00%> (ø)` | |
| [autokeras/blocks/reduction.py](https://codecov.io/gh/keras-team/autokeras/pull/1666/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL2Jsb2Nrcy9yZWR1Y3Rpb24ucHk=) | `100.00% <100.00%> (ø)` | |
| [autokeras/blocks/wrapper.py](https://codecov.io/gh/keras-team/autokeras/pull/1666/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL2Jsb2Nrcy93cmFwcGVyLnB5) | `100.00% <100.00%> (ø)` | |
| [autokeras/engine/block.py](https://codecov.io/gh/keras-team/autokeras/pull/1666/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL2VuZ2luZS9ibG9jay5weQ==) | `100.00% <100.00%> (ø)` | |
| [autokeras/engine/tuner.py](https://codecov.io/gh/keras-team/autokeras/pull/1666/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL2VuZ2luZS90dW5lci5weQ==) | `100.00% <100.00%> (ø)` | |
| [autokeras/graph.py](https://codecov.io/gh/keras-team/autokeras/pull/1666/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL2dyYXBoLnB5) | `100.00% <100.00%> (ø)` | |
| [autokeras/keras\_layers.py](https://codecov.io/gh/keras-team/autokeras/pull/1666/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL2tlcmFzX2xheWVycy5weQ==) | `100.00% <100.00%> (ø)` | |
| ... and [5 more](https://codecov.io/gh/keras-team/autokeras/pull/1666/diff?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1666?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1666?src=pr&el=footer&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team). Last update [335e070...3d68eb7](https://codecov.io/gh/keras-team/autokeras/pull/1666?src=pr&el=lastupdated&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
",report deb master change coverage coverage impacted file tree graph coverage master coverage impacted coverage continue review full report legend click learn absolute relative impact affected missing data powered last update deb read comment,issue,negative,positive,neutral,neutral,positive,positive
1017121423,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1664?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) Report
> Merging [#1664](https://codecov.io/gh/keras-team/autokeras/pull/1664?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) (2fcc51a) into [master](https://codecov.io/gh/keras-team/autokeras/commit/c9383a0321341e1311e80e344fba3a52d0425cc5?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) (c9383a0) will **not change** coverage.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1664/graphs/tree.svg?width=650&height=150&src=pr&token=yDvddb2DDZ&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)](https://codecov.io/gh/keras-team/autokeras/pull/1664?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)

```diff
@@            Coverage Diff            @@
##            master     #1664   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           51        51           
  Lines         3353      3353           
=========================================
  Hits          3353      3353           
```



------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1664?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1664?src=pr&el=footer&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team). Last update [c9383a0...2fcc51a](https://codecov.io/gh/keras-team/autokeras/pull/1664?src=pr&el=lastupdated&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
",report master ca change coverage coverage impacted file tree graph coverage master coverage continue review full report legend click learn absolute relative impact affected missing data powered last update ca read comment,issue,negative,positive,neutral,neutral,positive,positive
1013678176,"you have to set 'batch_size' in fit() method.

for example:
`StructuredDataClassifier.fit( x, y, epochs=10, validation_split=0.2, batch_size=64 )`

it is supported by `keras.Model.fit`. see [here](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit) 😁",set fit method example see,issue,negative,positive,positive,positive,positive,positive
1012666769,"@AntonioDomenech I have the same structure in the model.
when I save the best model 

and load model using 
model = tf.keras.models.load_model(""model_auto_keras_rc_50_trials.h5"")

I cant load saying Unknown layer MultiCategory Encoding.

did you solve the problem?
![image](https://user-images.githubusercontent.com/45994360/149435352-f39ed593-d72e-4301-be8b-e36e01be47c5.png)

I don't know how to solve this ",structure model save best model load model model cant load saying unknown layer solve problem image know solve,issue,positive,positive,positive,positive,positive,positive
1012287652,"I've found the same behaviour. 
The first created network is always the same.
Does someone have a solution?",found behaviour first network always someone solution,issue,negative,positive,positive,positive,positive,positive
1009349995,"Same issue for me, I can run on CPU but not in gpu, without any code modifications to the text classification notebook, running all on Colab throws 

> UnknownError: 2 root error(s) found.
>   (0) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
> 	 [[node model/conv1d/conv1d (defined at /usr/local/lib/python3.7/dist-packages/autokeras/utils/utils.py:88) ]]
> 	 [[gradient_tape/model/embedding/embedding_lookup/Reshape/_76]]
>   (1) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
> 	 [[node model/conv1d/conv1d (defined at /usr/local/lib/python3.7/dist-packages/autokeras/utils/utils.py:88) ]]
> 0 successful operations.
> 0 derived errors ignored. [Op:__inference_train_function_5467]
> 
> Function call stack:
> train_function -> train_function",issue run without code text classification notebook running root error found unknown get convolution algorithm probably initialize try looking see warning log message printed node defined unknown get convolution algorithm probably initialize try looking see warning log message printed node defined successful derived function call stack,issue,negative,positive,positive,positive,positive,positive
999534048,"I had a same problem, my storage directory was too long. So try to replace files to the root.",problem storage directory long try replace root,issue,negative,negative,neutral,neutral,negative,negative
997168317,"> When I try to follow [this example](https://blogs.rstudio.com/ai/posts/2019-04-16-autokeras/) and fit an image classification model, I keep receiving the following error. I have not been able to find a resolution and I would be grateful for your insight.
> 
> Error in py_call_impl(callable, dots$args, dots$keywords) : AttributeError: 'Graph' object has no attribute 'hypermodel'
> 
> Detailed traceback: File ""C:\Users\avren\AppData\Local\r-miniconda\envs\r-reticulate\lib\site-packages\autokeras\tasks\image.py"", line 89, in **init** super().**init**( File ""C:\Users\avren\AppData\Local\r-miniconda\envs\r-reticulate\lib\site-packages\autokeras\tasks\image.py"", line 35, in **init** super().**init**(inputs=input_module.ImageInput(), outputs=outputs, **kwargs) File ""C:\Users\avren\AppData\Local\r-miniconda\envs\r-reticulate\lib\site-packages\autokeras\auto_model.py"", line 142, in **init** self.tuner = tuner( File ""C:\Users\avren\AppData\Local\r-miniconda\envs\r-reticulate\lib\site-packages\autokeras\tuners\task_specific.py"", line 157, in **init** super().**init**(initial_hps=IMAGE_CLASSIFIER, **kwargs) File ""C:\Users\avren\AppData\Local\r-miniconda\envs\r-reticulate\lib\site-packages\autokeras\tuners\greedy.py"", line 230, in **init** super().**init**(oracle=oracle, hyperm

I have triggered a similar error message when I was using Autokeras==1.0.15 and keras-tuner==1.1.0. 
And I fix it by downgrading the keras-tuner to 1.0.4. 
Maybe you can have a try to use a lower version keras-tuner. 
I think this may be caused by the new version keras-tuner who has modified some properties in 'hypermodel'.
I hope this can help you.",try follow example fit image classification model keep following error able find resolution would grateful insight error callable object attribute detailed file line super file line super file line tuner file line super file line super triggered similar error message fix maybe try use lower version think may new version hope help,issue,positive,positive,positive,positive,positive,positive
992962807,"Hi,

This looks wonderful!  Thanks you so much!

I'll test it out and let you know how it works!

Thanks,",hi wonderful thanks much test let know work thanks,issue,positive,positive,positive,positive,positive,positive
992907254,"Hello, 


I was researching the same thing for using AutoKeras, and I developed an approach to solve this using a combination of a [Timeout function](https://stackoverflow.com/a/66515961/3138885), [Model History](https://stackoverflow.com/a/55173869/3138885) and [ModelCheckPoint](https://keras.io/api/callbacks/model_checkpoint/)

The approach is more or less the following : 


 ```python
import time
import signal
import json, codecs
import tensorflow as tf
import autokeras as ak
from functools import wraps
from tensorflow.keras.callbacks import ModelCheckpoint

TIMEOUT_AK = 60 #or any time in seconds

def timeout(timeout_secs: int):
    def wrapper(func):
        @wraps(func)
        def time_limited(*args, **kwargs):
            # Register an handler for the timeout
            def handler(signum, frame):
                raise Exception(f""Timeout for function '{func.__name__}'"")

            # Register the signal function handler
            signal.signal(signal.SIGALRM, handler)

            # Define a timeout for your function
            signal.alarm(timeout_secs)

            result = None
            try:
                result = func(*args, **kwargs)
            except Exception as exc:
                raise exc
            finally:
                # disable the signal alarm
                signal.alarm(0)

            return result

        return time_limited

    return wrapper


def saveHist(path, history):
    with codecs.open(path, 'w', encoding='utf-8') as f:
        json.dump(history, f, separators=(',', ':'), sort_keys=True, indent=4) 

def loadHist(path):
    n = {} # set history to empty
    if os.path.exists(path): # reload history if it exists
        with codecs.open(path, 'r', encoding='utf-8') as f:
            n = json.loads(f.read())
    return n

def appendHist(h1, h2):
    if h1 == {}:
        return h2
    else:
        dest = {}
        for key, value in h1.items():
            dest[key] = value + h2[key]
        return dest

class LossHistory(Callback):
    # https://stackoverflow.com/a/53653154/852795
    def on_epoch_end(self, epoch, logs = None):
        new_history = {}
        for k, v in logs.items(): # compile new history from logs
            new_history[k] = [v] # convert values into lists
        current_history = loadHist(history_filename) # load history from current training
        current_history = appendHist(current_history, new_history) # append the logs
        saveHist(history_filename, current_history) # save history from current training

@timeout(TIMEOUT_AK)
def train_with_timeout(clf, model_checkpoint,history_checkpoint) :
    clf.fit(trainX, trainY , epochs=5, callbacks=[model_checkpoint,history_checkpoint],validation_split=0.3)

##### a lot of code ########
##### a lot of code ########
##### a lot of code ########
##### a lot of code ########
##### a lot of code ########

history_checkpoint = LossHistory()
model_checkpoint = ModelCheckpoint(""model.h5"", verbose = 1, mode=""min"",save_freq = 1,  save_best_only=True)
clf = ak.ImageClassifier() (or any other method ImageRegressor for example)

try:
    train_with_timeout(clf, model_checkpoint,history_checkpoint)
except : 
    print(""AutoKeras timed-out after :"" + str(TIMEOUT_AK) + "" seconds"")

# you can load the model for further usage : 
clf = tensorflow.keras.models.load_model(""model.h5"")

# also the history 
history = loadHist(""history.txt"")

##### a lot of code ########
##### a lot of code ########
##### a lot of code ########
##### a lot of code ########
##### a lot of code ########

```


And you'll have : 
- trained file as h5 you can use for prediction and evaluation
- history for plotting and various purposes 

Let me know if this helped 😄 
",hello thing approach solve combination function model history approach le following python import time import signal import import import ak import import time wrapper register handler handler signum frame raise exception function register signal function handler handler define function result none try result except exception raise finally disable signal alarm return result return return wrapper path history path history path set history empty path reload history path return return else key value key value key return class self epoch none compile new history convert load history current training append save history current training trainy lot code lot code lot code lot code lot code verbose min method example try except print load model usage also history history lot code lot code lot code lot code lot code trained file use prediction evaluation history plotting various let know,issue,positive,positive,neutral,neutral,positive,positive
985791335,"Apparently, its still trying to `split` the data despite explicitly providing the validation set? 🤔 ",apparently still trying split data despite explicitly providing validation set,issue,negative,positive,neutral,neutral,positive,positive
985787199,"Still having this error :( I can confirm that I am indeed sending >set batch size but apparently in the very end of the data, it fails",still error confirm indeed sending set batch size apparently end data,issue,negative,positive,neutral,neutral,positive,positive
983876258,"@haifeng-jin I know you might be busy with a lot of work, but if you could just take out 2 minutes and provide some guidance; it would be very, very welcome!",know might busy lot work could take provide guidance would welcome,issue,negative,positive,positive,positive,positive,positive
980803330,"Thank you @hanzigs , that solved the issue. 

I believe my problem was using keras2onnx instead of tf2onnx. Package versioning may have had something to do with it, but probably not.

` onnx_model, _ = tf2onnx.convert.from_keras(model) `",thank issue believe problem instead package may something probably model,issue,negative,neutral,neutral,neutral,neutral,neutral
980467452,"@torronen 
Following combinations working fine for me
```
pip install tensorflow==2.5.0
pip install keras==2.4.3
pip install keras-tuner==1.0.3
pip install autokeras==1.0.16
pip install tf2onnx==1.9.2
pip install keras2onnx==1.7.0
pip install onnxruntime==1.8.0
pip install onnxmltools==1.7.0

model = StructuredDataClassifier(...........)
akmodel.fit(......)
onnx_model, _ = tf2onnx.convert.from_keras(model)
```",following working fine pip install pip install pip install pip install pip install pip install pip install pip install model model,issue,negative,positive,positive,positive,positive,positive
980462442,"Might be due to old version of keras2onnx
```
pip install git+https://github.com/microsoft/onnxconverter-common
pip install git+https://github.com/onnx/keras-onnx
```

Can not confirm it yet, but just in case for others, in case I forget to come back.
",might due old version pip install pip install confirm yet case case forget come back,issue,negative,negative,neutral,neutral,negative,negative
980461082,"Here is the model summary

```
Model: ""model""
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         [(None, 2651)]            0
_________________________________________________________________
multi_category_encoding (Mul (None, 2651)              0
_________________________________________________________________
normalization (Normalization (None, 2651)              5303
_________________________________________________________________
dense (Dense)                (None, 32)                84864
_________________________________________________________________
re_lu (ReLU)                 (None, 32)                0
_________________________________________________________________
dense_1 (Dense)              (None, 32)                1056
_________________________________________________________________
re_lu_1 (ReLU)               (None, 32)                0
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 33
_________________________________________________________________
classification_head_1 (Activ (None, 1)                 0
=================================================================
Total params: 91,256
Trainable params: 85,953
Non-trainable params: 5,303
_________________________________________________________________
```",model summary model model layer type output shape param none none normalization normalization none dense dense none none dense none none dense none none total trainable,issue,negative,neutral,neutral,neutral,neutral,neutral
980460892,"I still have same issue on Tensorflow 2.5.2, Python 3.9.7

```
Traceback (most recent call last):
  File ""Q:\autokeras\autokeras10.py"", line 168, in <module>
    onnx_model = keras2onnx.convert_keras(model, model.name)
  File ""C:\Users\inno1\.conda\envs\autokeras\lib\site-packages\keras2onnx\main.py"", line 62, in convert_keras
    tf_graph = build_layer_output_from_model(model, output_dict, input_names, output_names)
  File ""C:\Users\inno1\.conda\envs\autokeras\lib\site-packages\keras2onnx\_parser_tf.py"", line 302, in build_layer_output_from_model
    return extract_outputs_from_subclassing_model(model, output_dict, input_names, output_names)
  File ""C:\Users\inno1\.conda\envs\autokeras\lib\site-packages\keras2onnx\_parser_tf.py"", line 263, in extract_outputs_from_subclassing_model
    graph_def, converted_input_indices = _convert_to_constants(
  File ""C:\Users\inno1\.conda\envs\autokeras\lib\site-packages\keras2onnx\_graph_cvt.py"", line 437, in convert_variables_to_constants_v2
    tensor_data = _get_tensor_data(func)
  File ""C:\Users\inno1\.conda\envs\autokeras\lib\site-packages\keras2onnx\_graph_cvt.py"", line 209, in _get_tensor_data
    data = val_tensor.numpy()
  File ""C:\Users\inno1\.conda\envs\autokeras\lib\site-packages\tensorflow\python\framework\ops.py"", line 1094, in numpy
    maybe_arr = self._numpy()  # pylint: disable=protected-access
  File ""C:\Users\inno1\.conda\envs\autokeras\lib\site-packages\tensorflow\python\framework\ops.py"", line 1062, in _numpy
    six.raise_from(core._status_to_exception(e.code, e.message), None)  # pylint: disable=protected-access
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot convert a Tensor of dtype resource to a NumPy array.
```",still issue python recent call last file line module model file line model file line return model file line file line file line data file line file line none file string line convert tensor resource array,issue,negative,neutral,neutral,neutral,neutral,neutral
980308852,"I ended up taking a sample to do model search. I will complete training on Keras after.
I will keep issue open, because the inital problem (=how to train with big datasets) is not resolved with this workaround.

If anyone else needs, this is my code:

```
train_file_path = ""myfile.csv""
DATASET_PORTION = 10 # take 1/10

n = sum(1 for line in open(train_file_path)) - 1 
 s = int(n / DATASET_PORTION)
skip = sorted(random.sample(range(1,n+1),n-s))
train_set = pd.read_csv(train_file_path, low_memory=True, skiprows=skip)
train_set = sklearn.utils.shuffle(train_set)
train_set.reset_index(inplace=True, drop=True)
```",ended taking sample model search complete training keep issue open problem train big resolved anyone else need code take sum line open skip sorted range,issue,negative,positive,neutral,neutral,positive,positive
979194043,"@haifeng-jin Would it be possible to ask for addition of example on how to use make_csv_dataset to https://autokeras.com/tutorial/load/ ?

Link above ( https://www.tensorflow.org/guide/data#consuming_tfrecord_data ) suggests make_csv_dataset. However consuming it in Autokeras does not seem intuitive.",would possible ask addition example use link however consuming seem intuitive,issue,negative,neutral,neutral,neutral,neutral,neutral
976740131,@koh-joshua Do you have a final code example that worked for you when using autokeras for multispectral images? Would be great to hear about autokeras and multispectral images,final code example worked would great hear,issue,positive,positive,positive,positive,positive,positive
976105190,"I've used the ```TimeseriesForecaster``` class under AutoKeras 1.16 and TF 2.5 and it works pretty well. (Although the ```lookback``` window has to be divisible by ```batch size```.)

It's the ```AutoModel``` version of it still throws the ```Incompatible shapes``` error, except that some of the smaller batch sizes _might_ work:

```python
lookback = 32
batch_size = 8

input_node = ak.TimeseriesInput(lookback=lookback)
output_node = ak.RNNBlock()(input_node)
output_node = ak.TemporalReduction()(output_node)
output_node = ak.RegressionHead()(output_node)

reg = ak.AutoModel(inputs=input_node, outputs=output_node, max_trials=3, overwrite=True)
reg.fit(x_train, y_train, batch_size=batch_size)
```

The ```AutoModel``` object above (if successfully ran and trained) does not need full training data like the ```TimeseriesForecaster``` does. The length of the predicted array is ```(y_test.size - lookback + 1)``` and the predicted values seems to lag behind real values at the distance of ```lookback```.",used class work pretty well although window divisible batch size version still incompatible error except smaller batch size work python reg object successfully ran trained need full training data like length array lag behind real distance,issue,positive,positive,positive,positive,positive,positive
975990621,Seems I am unable to map the value from make_csv_dataset to suitable format for autokeras.fit but it is probably my lack of knowledge,unable map value suitable format probably lack knowledge,issue,negative,positive,neutral,neutral,positive,positive
974697659,"Ok.. I got to make it work on test data.. Must export the trained model.
Then, load the exported model and predict on test data with it.
We can evaluate the model on test data withou exporting it by:

print(clf.evaluate(X_test, y_test))

To export the model after training it. For a ""clf"" model:
```
import autokeras as ak
import tensorflow as tf
from tensorflow.keras.models import load_model

model = clf.export_model()

try:
    model.save(""model_autokeras"", save_format=""tf"")
except Exception:
    model.save(""model_autokeras.h5"")

loaded_model = load_model(""model_autokeras"", custom_objects=ak.CUSTOM_OBJECTS)

predicted_y = loaded_model.predict(tf.expand_dims(X_test,1), batch_size = 32)  #batch_sizer here is the same used for train
```

",got make work test data must export trained model load model predict test data evaluate model test data print export model training model import ak import import model try except exception used train,issue,negative,neutral,neutral,neutral,neutral,neutral
974558817,"Please, how to predict TimeSeriesForecaster on out of sample test without including original training samples to it? @haifeng-jin",please predict sample test without original training,issue,negative,positive,positive,positive,positive,positive
974527943,"I also want to know why it is required that original training data must be present on test data (out of sample test).
This way, how it could be used to predict out of sample in production environment?
Should I append the original training data to every new input for predicting?",also want know original training data must present test data sample test way could used predict sample production environment append original training data every new input,issue,positive,positive,positive,positive,positive,positive
972629750,"I resolved this problem by setting environment variable `LD_PRELOAD` to path to `libgomp-d22c30c5.so.1.0.0`.

```bash
export LD_PRELOAD='/PATH/TO/libgomp-d22c30c5.so.1.0.0'
```
For this particular issue,

```bash
export LD_PRELOAD='/usr/local/lib/python3.6/dist-packages/scikit_learn.libs/libgomp-d22c30c5.so.1.0.0'
```

And execute program again.",resolved problem setting environment variable path bash export particular issue bash export execute program,issue,negative,positive,positive,positive,positive,positive
963169648,"I guess I could answer the question: _You have to stick to the version given in `requirement.txt`_ 

An easy try to reset the versions is:

```bash
pip install --force-reinstall autokeras==1.0.17rc1 keras-nightly==2.8.0.dev2021101807 keras-tuner==1.1.0rc0 tf-nightly==2.8.0.dev20211016
```

All these packages are _not_ available on `conda` (but you can still install the rest with it, e.g. `conda install jupyterlab`).",guess could answer question stick version given easy try reset bash pip install dev dev available still install rest install,issue,negative,positive,positive,positive,positive,positive
949494481,"In case anyone finds this, I'm not using autokeras but just kerastuner 1.0.3 installed through conda. I got the error message above when trying to run ""import kerastuner"", and the solution was to downgrade kerastuner to 1.01",case anyone got error message trying run import solution downgrade,issue,negative,neutral,neutral,neutral,neutral,neutral
947610995,"I'm having the exact same problem in colab

I used the exact code from the timeseries tutorial with my tabular data:

```
predict_from = 1
predict_until = 10
lookback = 3
clf = ak.TimeseriesForecaster(
    lookback=lookback,
    predict_from=predict_from,
    predict_until=predict_until,
    max_trials=1,
    objective=""val_loss"",
)

clf.fit(
    x=x_train,
    y=y_train,
    validation_data=(x_test, y_test),
    batch_size=32,
    epochs=10,
)
```

Output:

```
Search: Running Trial #1

Hyperparameter    |Value             |Best Value So Far 
timeseries_bloc...|True              |?                 
timeseries_bloc...|lstm              |?                 
timeseries_bloc...|2                 |?                 
regression_head...|0                 |?                 
optimizer         |adam              |?                 
learning_rate     |0.001             |?                 

Epoch 1/10
2021-10-20 11:51:51.322633: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
2021-10-20 11:51:52.437468: E tensorflow/stream_executor/cuda/cuda_dnn.cc:352] Loaded runtime CuDNN library: 8.0.5 but source was compiled with: 8.1.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.
2021-10-20 11:51:52.438853: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at cudnn_rnn_ops.cc:1553 : Unknown: Fail to find the dnn implementation.
2021-10-20 11:51:52.441772: E tensorflow/stream_executor/cuda/cuda_dnn.cc:352] Loaded runtime CuDNN library: 8.0.5 but source was compiled with: 8.1.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.
2021-10-20 11:51:52.442871: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at cudnn_rnn_ops.cc:1553 : Unknown: Fail to find the dnn implementation.
---------------------------------------------------------------------------
UnknownError                              Traceback (most recent call last)
/tmp/ipykernel_8334/638650037.py in <module>
      4     validation_data=(x_test, y_test),
      5     batch_size=32,
----> 6     epochs=10,
      7 )

17 frames
/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     58     ctx.ensure_initialized()
     59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
---> 60                                         inputs, attrs, num_outputs)
     61   except core._NotOkStatusException as e:
     62     if name is not None:

UnknownError:    Fail to find the dnn implementation.
	 [[{{node CudnnRNN}}]]
	 [[model/bidirectional/backward_lstm/PartitionedCall]] [Op:__inference_train_function_477706]

Function call stack:
train_function -> train_function -> train_function
```



",exact problem used exact code tutorial tabular data output search running trial value far epoch successfully dynamic library loaded library source library need matching major version equal higher minor version binary install upgrade library building make sure library loaded compatible version compile configuration unknown fail find implementation loaded library source library need matching major version equal higher minor version binary install upgrade library building make sure library loaded compatible version compile configuration unknown fail find implementation recent call last module name except name none fail find implementation node function call stack,issue,negative,positive,neutral,neutral,positive,positive
945488920,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1634?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) Report
> Merging [#1634](https://codecov.io/gh/keras-team/autokeras/pull/1634?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) (b6ed669) into [master](https://codecov.io/gh/keras-team/autokeras/commit/a50dbc1fa21a8168d33180e98ba96c2cfc897a4d?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) (a50dbc1) will **not change** coverage.
> The diff coverage is `100.00%`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1634/graphs/tree.svg?width=650&height=150&src=pr&token=yDvddb2DDZ&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)](https://codecov.io/gh/keras-team/autokeras/pull/1634?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)

```diff
@@            Coverage Diff            @@
##            master     #1634   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           51        51           
  Lines         3339      3350   +11     
=========================================
+ Hits          3339      3350   +11     
```


| [Impacted Files](https://codecov.io/gh/keras-team/autokeras/pull/1634?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) | Coverage Δ | |
|---|---|---|
| [autokeras/engine/tuner.py](https://codecov.io/gh/keras-team/autokeras/pull/1634/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL2VuZ2luZS90dW5lci5weQ==) | `100.00% <100.00%> (ø)` | |
| [autokeras/keras\_layers.py](https://codecov.io/gh/keras-team/autokeras/pull/1634/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL2tlcmFzX2xheWVycy5weQ==) | `100.00% <100.00%> (ø)` | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1634?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1634?src=pr&el=footer&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team). Last update [a50dbc1...b6ed669](https://codecov.io/gh/keras-team/autokeras/pull/1634?src=pr&el=lastupdated&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
",report bed master change coverage coverage impacted file tree graph coverage master coverage impacted coverage continue review full report legend click learn absolute relative impact affected missing data powered last update bed read comment,issue,negative,positive,neutral,neutral,positive,positive
943717049,"Any chance this could be addressed in the near future? Let me know if can provide any more info to help troubleshoot.

Thanks for all your work on Autokeras.

Best,
Ian",chance could near future let know provide help thanks work best,issue,positive,positive,positive,positive,positive,positive
939743941,"This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.
",issue automatically marked stale recent activity closed activity thank,issue,negative,negative,negative,negative,negative,negative
939743209,"Further activity.

On Mon, Oct 11, 2021, 3:03 PM stale[bot] ***@***.***> wrote:

> This issue has been automatically marked as stale because it has not had
> recent activity. It will be closed if no further activity occurs. Thank you
> for your contributions.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/keras-team/autokeras/pull/1433#issuecomment-939742422>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AEVLQ5VE7SP7PXH5VU46C2TUGKD25ANCNFSM4TWC3CMQ>
> .
> Triage notifications on the go with GitHub Mobile for iOS
> <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>
> or Android
> <https://play.google.com/store/apps/details?id=com.github.android&referrer=utm_campaign%3Dnotification-email%26utm_medium%3Demail%26utm_source%3Dgithub>.
>
>
",activity mon stale bot wrote issue automatically marked stale recent activity closed activity thank reply directly view triage go mobile android,issue,negative,negative,negative,negative,negative,negative
933757079,"@haifeng-jin I don't think this is resolved. I updated autokeras and ran the StructuredDataRegressor example today and this issue still exists. 

More generally, **where are the hyperparameter details stored for each Trial after training**?  I see a bunch of json files but the trail names are gibberish.",think resolved ran example today issue still generally trial training see bunch trail gibberish,issue,negative,positive,neutral,neutral,positive,positive
931784373,"I believe this is resolved by https://github.com/keras-team/keras-tuner/pull/594
It will be fixed with the next release of KerasTuner and AutoKeras.",believe resolved fixed next release,issue,negative,positive,neutral,neutral,positive,positive
929656319,"I had the same problem and found the suggested hack to setup.py useful (i.e. remove the tensorflow requirement in setup.py and install tensorflow  [wheel for arm64](https://github.com/apple/tensorflow_macos/releases/download/v0.1alpha3/tensorflow_addons_macos-0.1a3-cp38-cp38-macosx_11_0_arm64.whl))
",problem found hack useful remove requirement install wheel arm,issue,negative,positive,positive,positive,positive,positive
929583129,does `import kerastuner` or `import keras_tuner` work in your case?,import import work case,issue,negative,neutral,neutral,neutral,neutral,neutral
928615552,"Thanks for the Clarification.
Actually I thought based on dataset data types, categorical fields to be mentioned as categorical and only numerical fields to be mentioned as numerical, I didn't except it is the value based numerical mentioning.
",thanks clarification actually thought based data categorical categorical numerical numerical except value based numerical,issue,positive,positive,neutral,neutral,positive,positive
928346942,"Yes, I think it is fair.
Is there any use cases that you think should not be converted to numerical in the beginning?",yes think fair use think converted numerical beginning,issue,positive,positive,positive,positive,positive,positive
927123361,"ok, I found problem: because I forgot add normalize operation when predict images.",found problem forgot add normalize operation predict,issue,negative,neutral,neutral,neutral,neutral,neutral
925396258,I think this issue is resolved in KerasTuner already? Please reopen it if it is not resolved.,think issue resolved already please reopen resolved,issue,positive,neutral,neutral,neutral,neutral,neutral
925395374,"Currently, there is no way to stop the store, unless you sublcass the Tuner.",currently way stop store unless tuner,issue,negative,neutral,neutral,neutral,neutral,neutral
918390782,"Hello everyone, 

any news about this issue? I'm getting the same error in here with my data (normalizing or not).

J.",hello everyone news issue getting error data,issue,negative,neutral,neutral,neutral,neutral,neutral
918294671,"

> 
> 
> @Karim-53 Thank you for the reply.
> I just tried.
> The solution is a little bit tricky.
> This code runs fine. You can use it as a reference.
> 
> ```python
> import autokeras as ak
> import numpy as np
> from sklearn.model_selection import train_test_split
> 
> 
> n_points = 100
> n_features = 6
> n_classes = 10
> X = np.random.rand(n_points, n_features)
> print(X.shape, X.dtype)# random (100, 6) shaped array
> y = np.random.randint(low=0, high=n_classes, size=n_points)
> print(y.shape, y.dtype)
> X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)
> 
> clf = ak.StructuredDataClassifier(max_trials=1)
> clf.fit(X_train, y_train, epochs=2)
> predicted_y = clf.predict(X_test)
> clf.evaluate(X_test, y_test)
> 
> model = clf.export_model()
> import tensorflow as tf
> 
> X_test = tf.data.Dataset.from_tensor_slices(X_test.astype(np.unicode)).batch(32)
> predicted_y_2 = model.predict(X_test)
> print(predicted_y_2)
> ```

Hi, this does not work for me when I run it in Colab. I get an error: ""UnimplementedError:  Cast string to double is not supported"" Any ideas how to get this running? And it seems to me that the original issue has not been fixed yet, correct?",thank reply tried solution little bit tricky code fine use reference python import ak import import print random shaped array print model import print hi work run get error cast string double get running original issue fixed yet correct,issue,positive,positive,neutral,neutral,positive,positive
909827756,"I gone through their code in
https://github.com/keras-team/autokeras/blob/master/autokeras/keras_layers.py
in line 55 for MultiCategoryEncoding, mentioned Encode the categorical features to numerical features.

image

I tried manually encoding before building model, it worked, this was not happening before I guess,
so code entering None type

image

added codes to get column_types and column_names in StructuredDataClassifier
got model with consistent onnx/tf results

Can I confirm whether converting the data all to numerical is a fair way, before this step data undergoes preprocessing and normalized, so both category and numeric fields are in float type and in this step creating a dictionary showing all fields as ""numerical"" and passing to StructuredDataClassifier
```
data_dtypes = data.dtypes.apply(lambda x: x.name).to_dict()
for key in data_dtypes.keys():
    data_dtypes[key] = ""numerical""
```
Thanks",gone code line encode categorical numerical image tried manually building model worked happening guess code entering none type image added get got model consistent confirm whether converting data numerical fair way step data category float type step dictionary showing numerical passing lambda key key numerical thanks,issue,positive,positive,positive,positive,positive,positive
907460075,"Had this same issue while running latest version of autokeras in Colab environment.
While using this f1 custom objective, the object's .fit() worked OK, but failed to .predict() or .export_model() after training. Keras was demanding the custom objects, and they weren't being passed on.

Fixed it by changing the StructuredDataClassifierTuner function like this, I leave it here for reference of whomever might find this useful:

```
my_custom_objects={'f1_score_cust': f1_score_custom}
my_custom_objects.update(ak.CUSTOM_OBJECTS)

from keras_tuner.engine import hypermodel as hm_module
def get_best_model_custom(self):
  with hm_module.maybe_distribute(self.distribution_strategy):
    model = tf.keras.models.load_model(self.best_model_path, custom_objects=my_custom_objects)
  return model
autok.tuner.get_best_model = get_best_model_custom.__get__(autok.tuner,ak.tuners.task_specific.StructuredDataClassifierTuner)
```



Here f1_score_custom is a custom function, ak is autokeras, and autok is an StructuredDataClassifier instance.",issue running latest version environment custom objective object worked training demanding custom fixed function like leave reference whomever might find useful import self model return model custom function ak instance,issue,positive,positive,positive,positive,positive,positive
903235420,FYI I had tried to do a very simple quick search at the repo and apparently these 2 places are the only references to the example data sets hosted on `scikit-learn.org`,tried simple quick search apparently example data,issue,negative,positive,positive,positive,positive,positive
903234480,"Hi Keras team, 

First of all, thanks a lot for your efforts in creating / maintain this fantastic library!

FYI, this is my very first PR created at this repo so please do let me know if there is anything wrong with this PR and I would try my best to fix that!

Thanks!",hi team first thanks lot maintain fantastic library first please let know anything wrong would try best fix thanks,issue,positive,positive,positive,positive,positive,positive
901165076,"I'm receiving the same warning, when using the fit function of the StructuredDataClassifier on rather high-dimensional, sparse tabular data (e.g. of shape 5,000x3,500). Autokeras takes a lot of time before starting to train a model in those instances. Is there a way to better process or load sparse & high-dimensional data with Autokeras?",warning fit function rather sparse tabular data shape lot time starting train model way better process load sparse data,issue,negative,positive,positive,positive,positive,positive
899602184,"The only working work-around i'v found
```py
    hp = keras_tuner.HyperParameters()
    is_bi_1 = hp.Fixed('rnn_block_1/bidirectional', False)
    input_node = ak.Input()

    prf_regressor = input_node
    prf_regressor = ak.RNNBlock(
        return_sequences=False
        #, bidirectional=False <----- !!!! DO NOT PASS PARAMETER CREATED EARLIER. YOU NEED ONLY TO CREATE IT. IF YOU PASS IT - IT BREAKES
        )(prf_regressor)
    prf_regressor = ak.RegressionHead()(prf_regressor)
    model = ak.AutoModel(
        inputs=[input_node],
        outputs=[prf_regressor],
        hyperparameters=hp
    )
    ```",working found false pas parameter need create pas model,issue,negative,negative,negative,negative,negative,negative
895442769,"Ah, thanks. @cyyeung1234
I think having just a function or something that can export a CSV with all tried hyperparameters, the model's performance, and marking the search progress would be helpful. Being able to see, for example, the top 10 best models all have the same filter size is more helpful than just the top hyperparameters. At least for further refinements.",ah thanks think function something export tried model performance marking search progress would helpful able see example top best filter size helpful top least,issue,positive,positive,positive,positive,positive,positive
895440073,@jrhorne Doing model.summary() is a partial solution but it doesn't show everything. ,partial solution show everything,issue,negative,negative,neutral,neutral,negative,negative
887553524,"@haifeng-jin may I ask you to help with multi GPU?
In order not to create a new topic...

I get an error:
```
Epoch 1/1000
2021-07-27 16:15:38.726497: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
2021-07-27 16:15:39.515468: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
44/44 [==============================] - ETA: 0s - loss: 0.9194 - accuracy: 0.59802021-07-27 16:15:44.049919: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: ""TensorSliceDataset/_1""
op: ""TensorSliceDataset""
input: ""Placeholder/_0""
attr {
  key: ""Toutput_types""
  value {
    list {
      type: DT_DOUBLE
    }
  }
}
attr {
  key: ""output_shapes""
  value {
    list {
      shape {
        dim {
          size: 6558
        }
      }
    }
  }
}
```

For fix this — I need to set:
https://www.tensorflow.org/api_docs/python/tf/data/experimental/AutoShardPolicy

```python
options = tf.data.Options()
options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA
```

And how to put this option to StructuredDataClassifier?
```python
model = ak.StructuredDataClassifier(max_trials=params['max_trials'],
				project_name=model_name+ext_type,
				directory='data/models_saved_data/',
				distribution_strategy=tf.distribute.MirroredStrategy()
				)
model.fit(x_train, y_train,
      epochs=params['epochs'],
      batch_size=32,
      )
```


",may ask help order create new topic get error epoch successfully dynamic library successfully dynamic library eta loss accuracy auto policy apply data policy apply file policy following reason found source name input key value list type key value list shape dim size fix need set python put option python model,issue,positive,positive,neutral,neutral,positive,positive
887054344,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1561?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) Report
> Merging [#1561](https://codecov.io/gh/keras-team/autokeras/pull/1561?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) (81969ad) into [master](https://codecov.io/gh/keras-team/autokeras/commit/caeb53c0023ac6d895767dbe258ee44b462c08e4?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) (caeb53c) will **not change** coverage.
> The diff coverage is `100.00%`.

> :exclamation: Current head 81969ad differs from pull request most recent head 122e951. Consider uploading reports for the commit 122e951 to get more accurate results
[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1561/graphs/tree.svg?width=650&height=150&src=pr&token=yDvddb2DDZ&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)](https://codecov.io/gh/keras-team/autokeras/pull/1561?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)

```diff
@@            Coverage Diff            @@
##            master     #1561   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           51        51           
  Lines         3328      3339   +11     
=========================================
+ Hits          3328      3339   +11     
```


| [Impacted Files](https://codecov.io/gh/keras-team/autokeras/pull/1561?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) | Coverage Δ | |
|---|---|---|
| [autokeras/auto\_model.py](https://codecov.io/gh/keras-team/autokeras/pull/1561/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL2F1dG9fbW9kZWwucHk=) | `100.00% <100.00%> (ø)` | |
| [autokeras/engine/tuner.py](https://codecov.io/gh/keras-team/autokeras/pull/1561/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL2VuZ2luZS90dW5lci5weQ==) | `100.00% <100.00%> (ø)` | |
| [autokeras/tasks/image.py](https://codecov.io/gh/keras-team/autokeras/pull/1561/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL3Rhc2tzL2ltYWdlLnB5) | `100.00% <100.00%> (ø)` | |
| [autokeras/tasks/structured\_data.py](https://codecov.io/gh/keras-team/autokeras/pull/1561/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL3Rhc2tzL3N0cnVjdHVyZWRfZGF0YS5weQ==) | `100.00% <100.00%> (ø)` | |
| [autokeras/tasks/text.py](https://codecov.io/gh/keras-team/autokeras/pull/1561/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL3Rhc2tzL3RleHQucHk=) | `100.00% <100.00%> (ø)` | |
| [autokeras/tasks/time\_series\_forecaster.py](https://codecov.io/gh/keras-team/autokeras/pull/1561/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL3Rhc2tzL3RpbWVfc2VyaWVzX2ZvcmVjYXN0ZXIucHk=) | `100.00% <100.00%> (ø)` | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1561?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1561?src=pr&el=footer&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team). Last update [caeb53c...122e951](https://codecov.io/gh/keras-team/autokeras/pull/1561?src=pr&el=lastupdated&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
",report ad master change coverage coverage exclamation current head ad pull request recent head consider commit get accurate impacted file tree graph coverage master coverage impacted coverage continue review full report legend click learn absolute relative impact affected missing data powered last update read comment,issue,negative,positive,neutral,neutral,positive,positive
882603041,"I am getting this same error while running a ML model in deepfacelab colab, and after the error, the cell stops executing.",getting error running model error cell,issue,negative,neutral,neutral,neutral,neutral,neutral
881137332,"@FrankFeenix can you recall what the problem was? I'm having the same issue, immediately upon import.",recall problem issue immediately upon import,issue,negative,neutral,neutral,neutral,neutral,neutral
880909939,"Or, and maybe I've missed it, but is there an elegant way to export the optimal hyperparameters found by AutoKeras?",maybe elegant way export optimal found,issue,positive,positive,positive,positive,positive,positive
878322675,"The same problem has occured to me on trial-by-trial basis with StructuredRegressor, i.e. with few trials val losses are calculated, but with others are not . It occured so after increasing batch size to smth like 254 (on batch_size=64 all val losses were NaNs).",problem basis calculated increasing batch size like,issue,negative,neutral,neutral,neutral,neutral,neutral
870433907,"I also notice this problem with the evaluation method. So I tried to solve it the same way you did.
But this error returns:
```
/home/riccardo/Desktop/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1323 test_function  *
    return step_function(self, iterator)
/home/riccardo/Desktop/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1314 step_function  **
    outputs = model.distribute_strategy.run(run_step, args=(data,))
/home/riccardo/Desktop/venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1285 run
    return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
/home/riccardo/Desktop/venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2833 call_for_each_replica
    return self._call_for_each_replica(fn, args, kwargs)
/home/riccardo/Desktop/venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3608 _call_for_each_replica
     return fn(*args, **kwargs)
/home/riccardo/Desktop/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1309 run_step  **
    with ops.control_dependencies(_minimum_control_deps(outputs)):
/home/riccardo/Desktop/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:2888 _minimum_control_deps
    outputs = nest.flatten(outputs, expand_composites=True)
/home/riccardo/Desktop/venv/lib/python3.8/site-packages/tensorflow/python/util/nest.py:416 flatten
    return _pywrap_utils.Flatten(structure, expand_composites)

TypeError: '<' not supported between instances of 'function' and 'str'
```",also notice problem evaluation method tried solve way error return self data run return return return flatten return structure,issue,negative,neutral,neutral,neutral,neutral,neutral
868579357,"As a reminder, [Dependabot Preview will be shut down on August 3rd, 2021][announcement].  You can merge this pull request to migrate to GitHub-native Dependabot. You can [read the docs][docs] to learn more about what's changing, as well as find out how to get support if you need help migrating.

[announcement]: https://github.blog/2021-04-29-goodbye-dependabot-preview-hello-dependabot/
[docs]: https://docs.github.com/en/code-security/supply-chain-security/keeping-your-dependencies-updated-automatically/upgrading-from-dependabotcom-to-github-native-dependabot
",reminder preview shut august announcement merge pull request migrate read learn well find get support need help announcement,issue,positive,neutral,neutral,neutral,neutral,neutral
864872856,"Ok, my problem was that the Sigmoid postprocessing wasn't included inside the export.

Perhaps its an obvious issue, but for anyone who encounters the same situation, you need to manually post-process the prediction:

`predicted_y[predicted_y < 0.5] = 0 
predicted_y[predicted_y > 0.5] = 1`",problem sigmoid included inside export perhaps obvious issue anyone situation need manually prediction,issue,negative,neutral,neutral,neutral,neutral,neutral
863299523,"I made some more testing, and it must be related to the import into Tensorflow.
While using the same dataset inside the AutoML, the prediction is binary (0. or 1.):
![image](https://user-images.githubusercontent.com/79153884/122418750-b8ee6600-cf8a-11eb-82df-3b5c25beaf85.png)


But inside Keras it is a Regression(?) (1.457812154 or 8.147856324)

![image](https://user-images.githubusercontent.com/79153884/122418793-c3106480-cf8a-11eb-8905-4f2c41a4707b.png)


`x_to_predict = pd.read_csv(""C:/Users/*****/Desktop/titanic-dataset/titanic_test.csv"", quotechar='""', skipinitialspace=True)
x_to_predict_numpy = x_to_predict.to_numpy()
clf = ak.StructuredDataClassifier(overwrite=True, max_trials=3, seed=42)
clf.fit(""C:/Users/******/Desktop/titanic-dataset/titanic_train.csv"", ""survived"", epochs=10)
result = clf.predict(x_to_predict_numpy.astype(np.unicode))
print(result)
model = clf.export_model()
model.save(""model_autokeras"", save_format=""tf"")
loaded_model = load_model(""model_autokeras"", custom_objects=ak.CUSTOM_OBJECTS)
predicted_y = loaded_model.predict(x_to_predict_numpy.astype(np.unicode))
print(predicted_y)`

sorry the code doesn't want to format correctly. I don't know why...",made testing must related import inside prediction binary image inside regression image result print result model print sorry code want format correctly know,issue,negative,negative,negative,negative,negative,negative
863032113,"Fixed it by converting my data to unicode before calling predict():

`predicted_y = loaded_model.predict(x_to_predict_numpy.astype(np.unicode))`

But the loaded model is not performing a binary classification. 
It returns float values for the survived target.",fixed converting data calling predict loaded model binary classification float target,issue,negative,positive,neutral,neutral,positive,positive
862803230,"Hi, 
Is it possible to get class labels from the exported model?
Example, once we get the best model with '.fit' then '.predict' returns the class label. I am trying to pickle the AutoKeras super model but after unpickling it throws the exception:

```
---------------------------------------------------------------------------
NotFoundError                             Traceback (most recent call last)
<ipython-input-25-ce88bf2aa9e2> in <module>
      1 # print(clf.inputs)
      2 # print(type(clf.directory))
----> 3 predicted_y = clf.predict(X_test)

~/anaconda3/envs/mxnet_latest_p37/lib/python3.7/site-packages/autokeras/tasks/structured_data.py in predict(self, x, **kwargs)
    157         x = self.read_for_predict(x)
    158 
--> 159         return super().predict(x=x, **kwargs)
    160 
    161     def evaluate(self, x, y=None, **kwargs):

~/anaconda3/envs/mxnet_latest_p37/lib/python3.7/site-packages/autokeras/auto_model.py in predict(self, x, batch_size, verbose, **kwargs)
    432         self._check_data_format((x, None), predict=True)
    433         dataset = self._adapt(x, self.inputs, batch_size)
--> 434         pipeline = self.tuner.get_best_pipeline()
    435         model = self.tuner.get_best_model()
    436         dataset = pipeline.transform_x(dataset)

~/anaconda3/envs/mxnet_latest_p37/lib/python3.7/site-packages/autokeras/engine/tuner.py in get_best_pipeline(self)
     65 
     66     def get_best_pipeline(self):
---> 67         return pipeline_module.load_pipeline(self.best_pipeline_path)
     68 
     69     def _pipeline_path(self, trial_id):

~/anaconda3/envs/mxnet_latest_p37/lib/python3.7/site-packages/autokeras/pipeline.py in load_pipeline(filepath, custom_objects)
     74         custom_objects = {}
     75     with tf.keras.utils.custom_object_scope(custom_objects):
---> 76         return Pipeline.from_config(io_utils.load_json(filepath))
     77 
     78 

~/anaconda3/envs/mxnet_latest_p37/lib/python3.7/site-packages/autokeras/utils/io_utils.py in load_json(path)
     32 def load_json(path):
     33     with tf.io.gfile.GFile(path, ""r"") as f:
---> 34         obj = f.read()
     35     return json.loads(obj)
     36 

~/anaconda3/envs/mxnet_latest_p37/lib/python3.7/site-packages/tensorflow/python/lib/io/file_io.py in read(self, n)
    115       string if in string (regular) mode.
    116     """"""
--> 117     self._preread_check()
    118     if n == -1:
    119       length = self.size() - self.tell()

~/anaconda3/envs/mxnet_latest_p37/lib/python3.7/site-packages/tensorflow/python/lib/io/file_io.py in _preread_check(self)
     78                                            ""File isn't open for reading"")
     79       self._read_buf = _pywrap_file_io.BufferedInputStream(
---> 80           compat.path_to_str(self.__name), 1024 * 512)
     81 
     82   def _prewrite_check(self):

NotFoundError: ./structured_data_classifier/best_pipeline; No such file or directory
```

However, saving the model via the following works great but it has no way to return the class label. 
```
best_model = clf.export_model()
best_model.save(""data/autokerasbest16jun2021_2"", save_format=""tf"")
best_model = load_model(""data/autokeras16jun2021"", custom_objects=ak.CUSTOM_OBJECTS)
```
Is it possible to:
1) Save and retrieve the Super AutoKeras model?
or
2) Is it possible to get class label predictions from the exported model?",hi possible get class model example get best model class label trying pickle super model exception recent call last module print print type predict self return super evaluate self predict self verbose none pipeline model self self return self return path path path return read self string string regular length self file open reading self file directory however saving model via following work great way return class label possible save retrieve super model possible get class label model,issue,positive,positive,positive,positive,positive,positive
861154131,"Any updates on this issue? I'm having the same problem with the following setup:
- OS type and version:	Ubuntu 18.04.5 LTS
- Python: 3.7.10
- autokeras: 1.0.14
- keras-tuner: 1.0.2
- scikit-learn: 0.24.2
- numpy: 1.18.5
- pandas: 1.2.4
- tensorflow: 2.3.0",issue problem following setup o type version python,issue,negative,neutral,neutral,neutral,neutral,neutral
857496443,"any updates to that topic? I'm also interested in small models with max. 150.000 parameters. 

Are the better solutions than changing the  self._max_fail_streak in kerastuner/engine/hypermodel.py so far?",topic also interested small better far,issue,positive,positive,positive,positive,positive,positive
854909087,"@eschibli After you said that I saw it worked for me as well. As you said I don't know if it's working correctly, but it's working. But it isn't making predictions. I don't know why!",said saw worked well said know working correctly working making know,issue,negative,neutral,neutral,neutral,neutral,neutral
853487804,"I can't vouch for whether it's performing correctly or not, but setting the batch size to the lookback allows it to run for me. ",ca vouch whether correctly setting batch size run,issue,negative,neutral,neutral,neutral,neutral,neutral
852759634,"Hi,
This is not ONNX issue, this is issue in tensorflow, 
""Resource types are supported through only saved model converter since TF 2.5""

is there any option in autokeras exporting model to overcome this issue
Thanks

",hi issue issue resource saved model converter since option model overcome issue thanks,issue,positive,positive,positive,positive,positive,positive
851279720,"I got the same error, even when i normalize the data before using the fit function.

The traceback:

```
Search: Running Trial #1 
Hyperparameter |Value |Best Value So Far structured_data...|True |? structured_data...|2 |? structured_data...|False |? structured_data...|0 |? structured_data...|32 |? structured_data...|32 |? regression_head...|0 |? optimizer |adam |? learning_rate |0.001 |? 
Traceback (most recent call last): 
File ""~/Automl/.venv/lib/python3.7/site-packages/kerastuner/engine/hypermodel.py"", line 104, in build model = self.hypermodel.build(hp) 
File ""~/Automl/.venv/lib/python3.7/site-packages/kerastuner/engine/hypermodel.py"", line 64, in _build_wrapper return self._build(hp, *args, **kwargs)
File ""~/Automl/.venv/lib/python3.7/site-packages/autokeras/graph.py"", line 250, in build outputs = block.build(hp, inputs=temp_inputs) 
File ""~/Automl/.venv/lib/python3.7/site-packages/autokeras/engine/block.py"", line 38, in _build_wrapper return super()._build_wrapper(hp, *args, **kwargs) 
File ""~/Automl/.venv/lib/python3.7/site-packages/kerastuner/engine/hypermodel.py"", line 64, in _build_wrapper return self._build(hp, *args, **kwargs) 
File ""~/Automl/.venv/lib/python3.7/site-packages/autokeras/blocks/wrapper.py"", line 251, in build if self.normalize is None and hp.Boolean(NORMALIZE): 
File ""~/Automl/.venv/lib/python3.7/site-packages/kerastuner/engine/hyperparameters.py"", line 814, in Boolean return self._retrieve(hp) 
File ""~/Automl/.venv/lib/python3.7/site-packages/kerastuner/engine/hyperparameters.py"", line 625, in _retrieve return self.values[hp.name] KeyError: 'structured_data_block_2/normalize' 
Invalid model 0/5 
```

and the key error

```
KeyError                                  Traceback (most recent call last)
~/Automl/.venv/lib/python3.7/site-packages/kerastuner/engine/hypermodel.py in build(self, hp)
    103                 with maybe_distribute(self.distribution_strategy):
--> 104                     model = self.hypermodel.build(hp)
    105             except:

~/Automl/.venv/lib/python3.7/site-packages/kerastuner/engine/hypermodel.py in _build_wrapper(self, hp, *args, **kwargs)
     63             hp = hp.copy()
---> 64         return self._build(hp, *args, **kwargs)
     65 

~/Automl/.venv/lib/python3.7/site-packages/autokeras/graph.py in build(self, hp)
    249             ]
--> 250             outputs = block.build(hp, inputs=temp_inputs)
    251             outputs = nest.flatten(outputs)

~/Automl/.venv/lib/python3.7/site-packages/autokeras/engine/block.py in _build_wrapper(self, hp, *args, **kwargs)
     37         with hp.name_scope(self.name):
---> 38             return super()._build_wrapper(hp, *args, **kwargs)
     39 

~/Automl/.venv/lib/python3.7/site-packages/kerastuner/engine/hypermodel.py in _build_wrapper(self, hp, *args, **kwargs)
     63             hp = hp.copy()
---> 64         return self._build(hp, *args, **kwargs)
     65 

~/Automl/.venv/lib/python3.7/site-packages/autokeras/blocks/wrapper.py in build(self, hp, inputs)
    250 
--> 251         if self.normalize is None and hp.Boolean(NORMALIZE):
    252             with hp.conditional_scope(NORMALIZE, [True]):

~/Automl/.venv/lib/python3.7/site-packages/kerastuner/engine/hyperparameters.py in Boolean(self, name, default, parent_name, parent_values)
    813                          conditions=self._conditions)
--> 814             return self._retrieve(hp)
    815 

~/Automl/.venv/lib/python3.7/site-packages/kerastuner/engine/hyperparameters.py in _retrieve(self, hp)
    624             if self._conditions_are_active(hp.conditions):
--> 625                 return self.values[hp.name]
    626             return None  # Ensures inactive values are not relied on by user.

KeyError: 'structured_data_block_2/normalize'

During handling of the above exception, another exception occurred:

RuntimeError                              Traceback (most recent call last)
<ipython-input-11-5e49ad249fd6> in <module>
     13     start_time = time.time()
     14 
---> 15     reg.fit(X_train, y_train, validation_split=0.25, epochs=5, callbacks=[mc], verbose=1)
     16 
     17     hours = int((time.time() - start_time)/3600)

~/Automl/.venv/lib/python3.7/site-packages/autokeras/tasks/structured_data.py in fit(self, x, y, epochs, callbacks, validation_split, validation_data, **kwargs)
    139             validation_split=validation_split,
    140             validation_data=validation_data,
--> 141             **kwargs
    142         )
    143 

~/Automl/.venv/lib/python3.7/site-packages/autokeras/auto_model.py in fit(self, x, y, batch_size, epochs, callbacks, validation_split, validation_data, **kwargs)
    277             validation_data=validation_data,
    278             validation_split=validation_split,
--> 279             **kwargs
    280         )
    281 

~/Automl/.venv/lib/python3.7/site-packages/autokeras/engine/tuner.py in search(self, epochs, callbacks, validation_split, **fit_kwargs)
    179         self.oracle.update_space(hp)
    180 
--> 181         super().search(epochs=epochs, callbacks=new_callbacks, **fit_kwargs)
    182 
    183         # Train the best model use validation data.

~/Automl/.venv/lib/python3.7/site-packages/kerastuner/engine/base_tuner.py in search(self, *fit_args, **fit_kwargs)
    129 
    130             self.on_trial_begin(trial)
--> 131             self.run_trial(trial, *fit_args, **fit_kwargs)
    132             self.on_trial_end(trial)
    133         self.on_search_end()

~/Automl/.venv/lib/python3.7/site-packages/kerastuner/engine/tuner.py in run_trial(self, trial, *fit_args, **fit_kwargs)
    170         copied_fit_kwargs['callbacks'] = callbacks
    171 
--> 172         self._build_and_fit_model(trial, fit_args, copied_fit_kwargs)
    173 
    174     def save_model(self, trial_id, model, step=0):

~/Automl/.venv/lib/python3.7/site-packages/autokeras/engine/tuner.py in _build_and_fit_model(self, trial, fit_args, fit_kwargs)
     96         pipeline.save(self._pipeline_path(trial.trial_id))
     97 
---> 98         model = self.hypermodel.build(trial.hyperparameters)
     99         self.adapt(model, fit_kwargs[""x""])
    100 

~/Automl/.venv/lib/python3.7/site-packages/kerastuner/engine/hypermodel.py in _build_wrapper(self, hp, *args, **kwargs)
     62             # to the search space.
     63             hp = hp.copy()
---> 64         return self._build(hp, *args, **kwargs)
     65 
     66 

~/Automl/.venv/lib/python3.7/site-packages/kerastuner/engine/hypermodel.py in build(self, hp)
    111                 if i == self._max_fail_streak:
    112                     raise RuntimeError(
--> 113                         'Too many failed attempts to build model.')
    114                 continue
    115 

RuntimeError: Too many failed attempts to build model.
```

The code I used for the call was:
```
reg = ak.StructuredDataRegressor(overwrite=True, max_trials=5, seed=1)

reg.fit(X_train, y_train, validation_split=0.25, epochs=5, callbacks=[mc], verbose=1)",got error even normalize data fit function search running trial value far recent call last file line build model file line return file line build file line return super file line return file line build none normalize file line return file line return invalid model key error recent call last build self model except self return build self self return super self return build self none normalize normalize true self name default return self return return none inactive user handling exception another exception recent call last module fit self fit self search self super train best model use validation data search self trial trial trial self trial trial self model self trial model model self search space return build self raise many build model continue many build model code used call reg,issue,positive,positive,positive,positive,positive,positive
850987358,The project is also interesting for me. What is the status? Is there a possibility to contribute?,project also interesting status possibility contribute,issue,negative,positive,positive,positive,positive,positive
850248067,"If you have in your folder script with the name ""autokeras.py"" rename it.",folder script name rename,issue,negative,neutral,neutral,neutral,neutral,neutral
849645413,"If you install the autokeras by the following command
pip install git+https://github.com/keras-team/keras-tuner.git
pip install autokeras
when run pip install autokeras, tensorflow2.5.0 is downloaded and installed automatically, beacuse the version of cudatoolkit you installed is not compatible with tensorflow2.5.0

import tensorflow as tf
tf.__version__  # 2.5.0
tf.test.is_gpu_available() # False

so you should install autokeras  by the following command
     pip install autokeras==1.0.13
     pip uninstall tensorflow
     pip install tensorflow-gpu==2.4.0
Remember, you must install autokeras first, the tensorflow2.5.0 is installed automatically at the same time, then you must uninstall the tensorflow2.5.0 and install tensorflow2.4.0.

If you install tensorflow2.4.0 first, and then you install autokeras1.0.13, you will get a lot erros.",install following command pip install pip install run pip install automatically version compatible import false install following command pip install pip pip install remember must install first automatically time must install install first install get lot,issue,negative,positive,neutral,neutral,positive,positive
848811176,"Hi, I have the same problem.
During Training the loss is nan after some trials",hi problem training loss nan,issue,negative,neutral,neutral,neutral,neutral,neutral
845992739,"> Please use below code in Anaconda cmd prompt
> pip install keras
> pip install keras-tuner

I did, it did not work, even if I pipped it on an anaconda cmd and launched Pycharm from Anaconda. but I copied the code to a jupyter notebook and everything worked fine!
One more question if you I may ask,
I uploaded the jupyter notebook to an Azure notebook to train my model there, however, the keras-tuner kept giving an error states the following:
""AttributeError: module 'tensorflow.keras.layers.experimental.preprocessing' has no attribute 'RandomRotation'""
(even though I have the latest version of TensorFlow.
any idea, please?
",please use code anaconda prompt pip install pip install work even pipped anaconda anaconda copied code notebook everything worked fine one question may ask notebook azure notebook train model however kept giving error following module attribute even though latest version idea please,issue,positive,positive,positive,positive,positive,positive
845988063,"Please use below code in Anaconda cmd prompt
pip install keras
pip install keras-tuner
",please use code anaconda prompt pip install pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
845574861,Hi there sorry for taking some time to reply to this. While I'm trying to reproduce this I suggest looking at the TimeSeriesForecaster tutorial that has been added recently to see if there are any differences in your code.,hi sorry taking time reply trying reproduce suggest looking tutorial added recently see code,issue,negative,negative,negative,negative,negative,negative
841870644,"@haifeng-jin

I am also facing a similar issue. In my case, I believe the problem is with RNNBlock.

- I am facing an error when trying to set either of the Parameters = [""bidirectional"", 'layer_type"", ""num_layers""] in RNNBlock.
- No issues are faced when trying to set only [""return_sequences""] Parameter or not setting any Parameters.

My Code:
```python
import autokeras as ak

# Model
input_layer = ak.Input()
rnn_layer = ak.RNNBlock(bidirectional=True, return_sequences=True, layer_type='lstm')(input_layer)
dense_layer = ak.DenseBlock()(rnn_layer)
output_layer = ak.ClassificationHead()(dense_layer)

model = ak.AutoModel(input_layer, output_layer, max_trials=10, overwrite=True)
```

The Error I am getting is:
```
    model = ak.AutoModel(input_layer, output_layer, max_trials=10, overwrite=True)
  File ""/home/krishna/.local/lib/python3.6/site-packages/autokeras/auto_model.py"", line 151, in __init__
    **kwargs
  File ""/home/krishna/.local/lib/python3.6/site-packages/autokeras/tuners/greedy.py"", line 230, in __init__
    super().__init__(oracle=oracle, hypermodel=hypermodel, **kwargs)
  File ""/home/krishna/.local/lib/python3.6/site-packages/autokeras/engine/tuner.py"", line 54, in __init__
    self.hypermodel.hypermodel.save(os.path.join(self.project_dir, ""graph""))
  File ""/home/krishna/.local/lib/python3.6/site-packages/autokeras/graph.py"", line 331, in save
    io_utils.save_json(filepath, self.get_config())
  File ""/home/krishna/.local/lib/python3.6/site-packages/autokeras/graph.py"", line 188, in get_config
    blocks = [blocks_module.serialize(block) for block in self.blocks]
  File ""/home/krishna/.local/lib/python3.6/site-packages/autokeras/graph.py"", line 188, in <listcomp>
    blocks = [blocks_module.serialize(block) for block in self.blocks]
  File ""/home/krishna/.local/lib/python3.6/site-packages/autokeras/blocks/__init__.py"", line 46, in serialize
    return tf.keras.utils.serialize_keras_object(obj)
  File ""/home/krishna/.local/lib/python3.6/site-packages/tensorflow/python/keras/utils/generic_utils.py"", line 245, in serialize_keras_object
    config = instance.get_config()
  File ""/home/krishna/.local/lib/python3.6/site-packages/autokeras/blocks/basic.py"", line 192, in get_config
    ""bidirectional"": hyperparameters.serialize(self.bidirectional),
  File ""/home/krishna/.local/lib/python3.6/site-packages/kerastuner/engine/hyperparameters.py"", line 1007, in serialize
    'config': obj.get_config()}
AttributeError: 'bool' object has no attribute 'get_config'

```",also facing similar issue case believe problem facing error trying set either bidirectional faced trying set parameter setting code python import ak model model error getting model file line file line super file line graph file line save file line block block file line block block file line serialize return file line file line bidirectional file line serialize object attribute,issue,negative,positive,positive,positive,positive,positive
841794306,"Same issue for me and no idea how to fix it. Error message dosn't give me a glue what to do.
Any ideas to solve that problem?",issue idea fix error message do give glue solve problem,issue,negative,neutral,neutral,neutral,neutral,neutral
841765205,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1566?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) Report
> Merging [#1566](https://codecov.io/gh/keras-team/autokeras/pull/1566?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) (ce06105) into [master](https://codecov.io/gh/keras-team/autokeras/commit/09c06f7cc17ce0a6dbc528d2d1c5fd8aa033b2f5?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) (09c06f7) will **not change** coverage.
> The diff coverage is `100.00%`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1566/graphs/tree.svg?width=650&height=150&src=pr&token=yDvddb2DDZ&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)](https://codecov.io/gh/keras-team/autokeras/pull/1566?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)

```diff
@@            Coverage Diff            @@
##            master     #1566   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           51        51           
  Lines         3324      3324           
=========================================
  Hits          3324      3324           
```


| [Impacted Files](https://codecov.io/gh/keras-team/autokeras/pull/1566?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) | Coverage Δ | |
|---|---|---|
| [autokeras/\_\_init\_\_.py](https://codecov.io/gh/keras-team/autokeras/pull/1566/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL19faW5pdF9fLnB5) | `100.00% <100.00%> (ø)` | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1566?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1566?src=pr&el=footer&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team). Last update [09c06f7...ce06105](https://codecov.io/gh/keras-team/autokeras/pull/1566?src=pr&el=lastupdated&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
",report ce master change coverage coverage impacted file tree graph coverage master coverage impacted coverage continue review full report legend click learn absolute relative impact affected missing data powered last update ce read comment,issue,negative,positive,neutral,neutral,positive,positive
841592262,"The only arg to make to hp is `pretrained`, but seems the PR is not changing it correctly.
The PR is making min_size a hp, I am not sure why.
I am closing this PR. If you still like to work on it, please let me know. I will reopen it.",make correctly making sure still like work please let know reopen,issue,positive,positive,positive,positive,positive,positive
841503623,"> Please uninstall it and install it with this command. `pip install git+https://github.com/keras-team/keras-tuner.git@1.0.2rc0#egg=keras-tuner-1.0.2rc0`

I am facing the same issue and this one didn't work out for me,
it threw an error saying:
""ERROR: Could not find a version that satisfies the requirement keras-tuner-1-0-2rc0 (unavailable) (from versions: none)
ERROR: No matching distribution found for keras-tuner-1-0-2rc0 (unavailable)
""",please install command pip install facing issue one work threw error saying error could find version requirement unavailable none error matching distribution found unavailable,issue,negative,neutral,neutral,neutral,neutral,neutral
841314177,"@luisfrossi Thank you for the issue. Would you please share the colab link with us? From our understanding, it is not likely to happen.",thank issue would please share link u understanding likely happen,issue,positive,neutral,neutral,neutral,neutral,neutral
836062532,"I give up on this library. Too many bugs. If it works, it takes days, weeks and consume all the computer resources, including harddisk space. ",give library many work day consume computer space,issue,negative,positive,positive,positive,positive,positive
835841772,"@marcus-wang9527 , thank you very much for your reply!

I tried all the steps as you suggested but unfortunately still no success.  :-(

I see the following output when I run ""python setup.py install"" after commenting out the line 24.

Really LOTS of output. But as far as I see, it does not install the autokeras at all. When I later run ""conda list"" in my virtual environment, I do not see autokeras in the list of packages that are installed in the virtual environment. Any suggestions..? 

Output of the installation:

(python38) autokeras % python setup.py install
running install
running bdist_egg
running egg_info
writing autokeras.egg-info/PKG-INFO
writing dependency_links to autokeras.egg-info/dependency_links.txt
writing requirements to autokeras.egg-info/requires.txt
writing top-level names to autokeras.egg-info/top_level.txt
reading manifest file 'autokeras.egg-info/SOURCES.txt'
writing manifest file 'autokeras.egg-info/SOURCES.txt'
installing library code to build/bdist.macosx-11.0-arm64/egg
running install_lib
running build_py
creating build/bdist.macosx-11.0-arm64/egg
creating build/bdist.macosx-11.0-arm64/egg/benchmark
copying build/lib/benchmark/run.py -> build/bdist.macosx-11.0-arm64/egg/benchmark
creating build/bdist.macosx-11.0-arm64/egg/benchmark/experiments
copying build/lib/benchmark/experiments/__init__.py -> build/bdist.macosx-11.0-arm64/egg/benchmark/experiments
copying build/lib/benchmark/experiments/experiment.py -> build/bdist.macosx-11.0-arm64/egg/benchmark/experiments
copying build/lib/benchmark/experiments/structured_data.py -> build/bdist.macosx-11.0-arm64/egg/benchmark/experiments
copying build/lib/benchmark/experiments/text.py -> build/bdist.macosx-11.0-arm64/egg/benchmark/experiments
copying build/lib/benchmark/experiments/image.py -> build/bdist.macosx-11.0-arm64/egg/benchmark/experiments
copying build/lib/benchmark/__init__.py -> build/bdist.macosx-11.0-arm64/egg/benchmark
copying build/lib/benchmark/README.md -> build/bdist.macosx-11.0-arm64/egg/benchmark
creating build/bdist.macosx-11.0-arm64/egg/autokeras
creating build/bdist.macosx-11.0-arm64/egg/autokeras/blocks
copying build/lib/autokeras/blocks/wrapper.py -> build/bdist.macosx-11.0-arm64/egg/autokeras/blocks
copying build/lib/autokeras/blocks/reduction.py -> build/bdist.macosx-11.0-arm64/egg/autokeras/blocks
copying build/lib/autokeras/blocks/__init__.py -> build/bdist.macosx-11.0-arm64/egg/autokeras/blocks
copying build/lib/autokeras/blocks/basic.py -> build/bdist.macosx-11.0-arm64/egg/autokeras/blocks
copying build/lib/autokeras/blocks/preprocessing.py -> build/bdist.macosx-11.0-arm64/egg/autokeras/blocks
copying build/lib/autokeras/blocks/heads.py -> build/bdist.macosx-11.0-arm64/egg/autokeras/blocks
creating build/bdist.macosx-11.0-arm64/egg/autokeras/preprocessors
copying build/lib/autokeras/preprocessors/__init__.py -> build/bdist.macosx-11.0-arm64/egg/autokeras/preprocessors
copying build/lib/autokeras/preprocessors/encoders.py -> build/bdist.macosx-11.0-arm64/egg/autokeras/preprocessors
copying build/lib/autokeras/preprocessors/common.py -> build/bdist.macosx-11.0-arm64/egg/autokeras/preprocessors
copying build/lib/autokeras/preprocessors/postprocessors.py -> build/bdist.macosx-11.0-arm64/egg/autokeras/preprocessors
creating build/bdist.macosx-11.0-arm64/egg/autokeras/tasks
copying build/lib/autokeras/tasks/time_series_forecaster.py -> build/bdist.macosx-11.0-arm64/egg/autokeras/tasks
copying build/lib/autokeras/tasks/__init__.py -> build/bdist.macosx-11.0-arm64/egg/autokeras/tasks
copying build/lib/autokeras/tasks/structured_data.py -> build/bdist.macosx-11.0-arm64/egg/autokeras/tasks
copying build/lib/autokeras/tasks/text.py -> build/bdist.macosx-11.0-arm64/egg/autokeras/tasks
copying build/lib/autokeras/tasks/image.py -> build/bdist.macosx-11.0-arm64/egg/autokeras/tasks
copying build/lib/autokeras/auto_model.py -> build/bdist.macosx-11.0-arm64/egg/autokeras
copying build/lib/autokeras/graph.py -> build/bdist.macosx-11.0-arm64/egg/autokeras
copying build/lib/autokeras/constants.py -> build/bdist.macosx-11.0-arm64/egg/autokeras
copying build/lib/autokeras/__init__.py -> build/bdist.macosx-11.0-arm64/egg/autokeras
creating build/bdist.macosx-11.0-arm64/egg/autokeras/utils
copying build/lib/autokeras/utils/layer_utils.py -> build/bdist.macosx-11.0-arm64/egg/autokeras/utils
copying build/lib/autokeras/utils/__init__.py -> build/bdist.macosx-11.0-arm64/egg/autokeras/utils
copying build/lib/autokeras/utils/types.py -> build/bdist.macosx-11.0-arm64/egg/autokeras/utils
copying build/lib/autokeras/utils/data_utils.py -> build/bdist.macosx-11.0-arm64/egg/autokeras/utils
copying build/lib/autokeras/utils/utils.py -> build/bdist.macosx-11.0-arm64/egg/autokeras/utils
copying build/lib/autokeras/utils/io_utils.py -> build/bdist.macosx-11.0-arm64/egg/autokeras/utils
creating build/bdist.macosx-11.0-arm64/egg/autokeras/tuners
copying build/lib/autokeras/tuners/task_specific.py -> build/bdist.macosx-11.0-arm64/egg/autokeras/tuners
copying build/lib/autokeras/tuners/bayesian_optimization.py -> build/bdist.macosx-11.0-arm64/egg/autokeras/tuners
copying build/lib/autokeras/tuners/greedy.py -> build/bdist.macosx-11.0-arm64/egg/autokeras/tuners
copying build/lib/autokeras/tuners/hyperband.py -> build/bdist.macosx-11.0-arm64/egg/autokeras/tuners
copying build/lib/autokeras/tuners/__init__.py -> build/bdist.macosx-11.0-arm64/egg/autokeras/tuners
copying build/lib/autokeras/tuners/random_search.py -> build/bdist.macosx-11.0-arm64/egg/autokeras/tuners
creating build/bdist.macosx-11.0-arm64/egg/autokeras/adapters
copying build/lib/autokeras/adapters/output_adapters.py -> build/bdist.macosx-11.0-arm64/egg/autokeras/adapters
copying build/lib/autokeras/adapters/__init__.py -> build/bdist.macosx-11.0-arm64/egg/autokeras/adapters
copying build/lib/autokeras/adapters/input_adapters.py -> build/bdist.macosx-11.0-arm64/egg/autokeras/adapters
copying build/lib/autokeras/hyper_preprocessors.py -> build/bdist.macosx-11.0-arm64/egg/autokeras
copying build/lib/autokeras/keras_layers.py -> build/bdist.macosx-11.0-arm64/egg/autokeras
copying build/lib/autokeras/pipeline.py -> build/bdist.macosx-11.0-arm64/egg/autokeras
creating build/bdist.macosx-11.0-arm64/egg/autokeras/analysers
copying build/lib/autokeras/analysers/input_analysers.py -> build/bdist.macosx-11.0-arm64/egg/autokeras/analysers
copying build/lib/autokeras/analysers/__init__.py -> build/bdist.macosx-11.0-arm64/egg/autokeras/analysers
copying build/lib/autokeras/analysers/output_analysers.py -> build/bdist.macosx-11.0-arm64/egg/autokeras/analysers
copying build/lib/autokeras/nodes.py -> build/bdist.macosx-11.0-arm64/egg/autokeras
creating build/bdist.macosx-11.0-arm64/egg/autokeras/engine
copying build/lib/autokeras/engine/io_hypermodel.py -> build/bdist.macosx-11.0-arm64/egg/autokeras/engine
copying build/lib/autokeras/engine/adapter.py -> build/bdist.macosx-11.0-arm64/egg/autokeras/engine
copying build/lib/autokeras/engine/serializable.py -> build/bdist.macosx-11.0-arm64/egg/autokeras/engine
copying build/lib/autokeras/engine/__init__.py -> build/bdist.macosx-11.0-arm64/egg/autokeras/engine
copying build/lib/autokeras/engine/hyper_preprocessor.py -> build/bdist.macosx-11.0-arm64/egg/autokeras/engine
copying build/lib/autokeras/engine/preprocessor.py -> build/bdist.macosx-11.0-arm64/egg/autokeras/engine
copying build/lib/autokeras/engine/named_hypermodel.py -> build/bdist.macosx-11.0-arm64/egg/autokeras/engine
copying build/lib/autokeras/engine/head.py -> build/bdist.macosx-11.0-arm64/egg/autokeras/engine
copying build/lib/autokeras/engine/node.py -> build/bdist.macosx-11.0-arm64/egg/autokeras/engine
copying build/lib/autokeras/engine/block.py -> build/bdist.macosx-11.0-arm64/egg/autokeras/engine
copying build/lib/autokeras/engine/tuner.py -> build/bdist.macosx-11.0-arm64/egg/autokeras/engine
copying build/lib/autokeras/engine/analyser.py -> build/bdist.macosx-11.0-arm64/egg/autokeras/engine
creating build/bdist.macosx-11.0-arm64/egg/tests
creating build/bdist.macosx-11.0-arm64/egg/tests/unit_tests
creating build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/blocks
copying build/lib/tests/unit_tests/blocks/preprocessing_test.py -> build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/blocks
copying build/lib/tests/unit_tests/blocks/wrapper_test.py -> build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/blocks
copying build/lib/tests/unit_tests/blocks/__init__.py -> build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/blocks
copying build/lib/tests/unit_tests/blocks/heads_test.py -> build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/blocks
copying build/lib/tests/unit_tests/blocks/basic_test.py -> build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/blocks
copying build/lib/tests/unit_tests/blocks/reduction_test.py -> build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/blocks
copying build/lib/tests/unit_tests/auto_model_test.py -> build/bdist.macosx-11.0-arm64/egg/tests/unit_tests
creating build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/preprocessors
copying build/lib/tests/unit_tests/preprocessors/common_test.py -> build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/preprocessors
copying build/lib/tests/unit_tests/preprocessors/encoders_test.py -> build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/preprocessors
copying build/lib/tests/unit_tests/preprocessors/__init__.py -> build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/preprocessors
copying build/lib/tests/unit_tests/preprocessors/postprocessors_test.py -> build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/preprocessors
creating build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/tasks
copying build/lib/tests/unit_tests/tasks/text_test.py -> build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/tasks
copying build/lib/tests/unit_tests/tasks/__init__.py -> build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/tasks
copying build/lib/tests/unit_tests/tasks/structured_data_test.py -> build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/tasks
copying build/lib/tests/unit_tests/tasks/image_test.py -> build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/tasks
copying build/lib/tests/unit_tests/tasks/time_series_forecaster_test.py -> build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/tasks
copying build/lib/tests/unit_tests/typed_api_test.py -> build/bdist.macosx-11.0-arm64/egg/tests/unit_tests
copying build/lib/tests/unit_tests/pipeline_test.py -> build/bdist.macosx-11.0-arm64/egg/tests/unit_tests
copying build/lib/tests/unit_tests/nodes_test.py -> build/bdist.macosx-11.0-arm64/egg/tests/unit_tests
copying build/lib/tests/unit_tests/__init__.py -> build/bdist.macosx-11.0-arm64/egg/tests/unit_tests
creating build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/utils
copying build/lib/tests/unit_tests/utils/utils_test.py -> build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/utils
copying build/lib/tests/unit_tests/utils/io_utils_test.py -> build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/utils
copying build/lib/tests/unit_tests/utils/data_utils_test.py -> build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/utils
copying build/lib/tests/unit_tests/utils/__init__.py -> build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/utils
copying build/lib/tests/unit_tests/hyper_preprocessors_test.py -> build/bdist.macosx-11.0-arm64/egg/tests/unit_tests
creating build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/tuners
copying build/lib/tests/unit_tests/tuners/hyperband_test.py -> build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/tuners
copying build/lib/tests/unit_tests/tuners/task_specific_test.py -> build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/tuners
copying build/lib/tests/unit_tests/tuners/__init__.py -> build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/tuners
copying build/lib/tests/unit_tests/tuners/random_search_test.py -> build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/tuners
copying build/lib/tests/unit_tests/tuners/greedy_test.py -> build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/tuners
creating build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/adapters
copying build/lib/tests/unit_tests/adapters/input_adapters_test.py -> build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/adapters
copying build/lib/tests/unit_tests/adapters/output_adapters_test.py -> build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/adapters
copying build/lib/tests/unit_tests/adapters/__init__.py -> build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/adapters
copying build/lib/tests/unit_tests/graph_test.py -> build/bdist.macosx-11.0-arm64/egg/tests/unit_tests
creating build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/analysers
copying build/lib/tests/unit_tests/analysers/__init__.py -> build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/analysers
copying build/lib/tests/unit_tests/analysers/input_analysers_test.py -> build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/analysers
copying build/lib/tests/unit_tests/analysers/output_analysers_test.py -> build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/analysers
copying build/lib/tests/unit_tests/keras_layers_test.py -> build/bdist.macosx-11.0-arm64/egg/tests/unit_tests
creating build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/engine
copying build/lib/tests/unit_tests/engine/__init__.py -> build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/engine
copying build/lib/tests/unit_tests/engine/block_test.py -> build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/engine
copying build/lib/tests/unit_tests/engine/adapter_test.py -> build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/engine
copying build/lib/tests/unit_tests/engine/head_test.py -> build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/engine
copying build/lib/tests/unit_tests/engine/tuner_test.py -> build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/engine
copying build/lib/tests/unit_tests/engine/node_test.py -> build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/engine
creating build/bdist.macosx-11.0-arm64/egg/tests/integration_tests
copying build/lib/tests/integration_tests/io_api_test.py -> build/bdist.macosx-11.0-arm64/egg/tests/integration_tests
copying build/lib/tests/integration_tests/__init__.py -> build/bdist.macosx-11.0-arm64/egg/tests/integration_tests
copying build/lib/tests/integration_tests/task_api_test.py -> build/bdist.macosx-11.0-arm64/egg/tests/integration_tests
copying build/lib/tests/integration_tests/functional_api_test.py -> build/bdist.macosx-11.0-arm64/egg/tests/integration_tests
byte-compiling build/bdist.macosx-11.0-arm64/egg/benchmark/run.py to run.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/benchmark/experiments/__init__.py to __init__.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/benchmark/experiments/experiment.py to experiment.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/benchmark/experiments/structured_data.py to structured_data.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/benchmark/experiments/text.py to text.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/benchmark/experiments/image.py to image.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/benchmark/__init__.py to __init__.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/blocks/wrapper.py to wrapper.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/blocks/reduction.py to reduction.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/blocks/__init__.py to __init__.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/blocks/basic.py to basic.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/blocks/preprocessing.py to preprocessing.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/blocks/heads.py to heads.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/preprocessors/__init__.py to __init__.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/preprocessors/encoders.py to encoders.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/preprocessors/common.py to common.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/preprocessors/postprocessors.py to postprocessors.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/tasks/time_series_forecaster.py to time_series_forecaster.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/tasks/__init__.py to __init__.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/tasks/structured_data.py to structured_data.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/tasks/text.py to text.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/tasks/image.py to image.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/auto_model.py to auto_model.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/graph.py to graph.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/constants.py to constants.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/__init__.py to __init__.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/utils/layer_utils.py to layer_utils.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/utils/__init__.py to __init__.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/utils/types.py to types.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/utils/data_utils.py to data_utils.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/utils/utils.py to utils.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/utils/io_utils.py to io_utils.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/tuners/task_specific.py to task_specific.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/tuners/bayesian_optimization.py to bayesian_optimization.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/tuners/greedy.py to greedy.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/tuners/hyperband.py to hyperband.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/tuners/__init__.py to __init__.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/tuners/random_search.py to random_search.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/adapters/output_adapters.py to output_adapters.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/adapters/__init__.py to __init__.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/adapters/input_adapters.py to input_adapters.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/hyper_preprocessors.py to hyper_preprocessors.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/keras_layers.py to keras_layers.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/pipeline.py to pipeline.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/analysers/input_analysers.py to input_analysers.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/analysers/__init__.py to __init__.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/analysers/output_analysers.py to output_analysers.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/nodes.py to nodes.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/engine/io_hypermodel.py to io_hypermodel.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/engine/adapter.py to adapter.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/engine/serializable.py to serializable.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/engine/__init__.py to __init__.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/engine/hyper_preprocessor.py to hyper_preprocessor.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/engine/preprocessor.py to preprocessor.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/engine/named_hypermodel.py to named_hypermodel.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/engine/head.py to head.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/engine/node.py to node.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/engine/block.py to block.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/engine/tuner.py to tuner.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/autokeras/engine/analyser.py to analyser.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/blocks/preprocessing_test.py to preprocessing_test.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/blocks/wrapper_test.py to wrapper_test.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/blocks/__init__.py to __init__.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/blocks/heads_test.py to heads_test.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/blocks/basic_test.py to basic_test.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/blocks/reduction_test.py to reduction_test.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/auto_model_test.py to auto_model_test.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/preprocessors/common_test.py to common_test.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/preprocessors/encoders_test.py to encoders_test.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/preprocessors/__init__.py to __init__.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/preprocessors/postprocessors_test.py to postprocessors_test.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/tasks/text_test.py to text_test.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/tasks/__init__.py to __init__.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/tasks/structured_data_test.py to structured_data_test.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/tasks/image_test.py to image_test.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/tasks/time_series_forecaster_test.py to time_series_forecaster_test.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/typed_api_test.py to typed_api_test.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/pipeline_test.py to pipeline_test.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/nodes_test.py to nodes_test.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/__init__.py to __init__.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/utils/utils_test.py to utils_test.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/utils/io_utils_test.py to io_utils_test.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/utils/data_utils_test.py to data_utils_test.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/utils/__init__.py to __init__.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/hyper_preprocessors_test.py to hyper_preprocessors_test.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/tuners/hyperband_test.py to hyperband_test.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/tuners/task_specific_test.py to task_specific_test.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/tuners/__init__.py to __init__.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/tuners/random_search_test.py to random_search_test.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/tuners/greedy_test.py to greedy_test.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/adapters/input_adapters_test.py to input_adapters_test.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/adapters/output_adapters_test.py to output_adapters_test.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/adapters/__init__.py to __init__.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/graph_test.py to graph_test.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/analysers/__init__.py to __init__.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/analysers/input_analysers_test.py to input_analysers_test.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/analysers/output_analysers_test.py to output_analysers_test.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/keras_layers_test.py to keras_layers_test.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/engine/__init__.py to __init__.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/engine/block_test.py to block_test.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/engine/adapter_test.py to adapter_test.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/engine/head_test.py to head_test.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/engine/tuner_test.py to tuner_test.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/tests/unit_tests/engine/node_test.py to node_test.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/tests/integration_tests/io_api_test.py to io_api_test.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/tests/integration_tests/__init__.py to __init__.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/tests/integration_tests/task_api_test.py to task_api_test.cpython-38.pyc
byte-compiling build/bdist.macosx-11.0-arm64/egg/tests/integration_tests/functional_api_test.py to functional_api_test.cpython-38.pyc
creating build/bdist.macosx-11.0-arm64/egg/EGG-INFO
copying autokeras.egg-info/PKG-INFO -> build/bdist.macosx-11.0-arm64/egg/EGG-INFO
copying autokeras.egg-info/SOURCES.txt -> build/bdist.macosx-11.0-arm64/egg/EGG-INFO
copying autokeras.egg-info/dependency_links.txt -> build/bdist.macosx-11.0-arm64/egg/EGG-INFO
copying autokeras.egg-info/requires.txt -> build/bdist.macosx-11.0-arm64/egg/EGG-INFO
copying autokeras.egg-info/top_level.txt -> build/bdist.macosx-11.0-arm64/egg/EGG-INFO
zip_safe flag not set; analyzing archive contents...
creating 'dist/autokeras-1.0.13-py3.8.egg' and adding 'build/bdist.macosx-11.0-arm64/egg' to it
removing 'build/bdist.macosx-11.0-arm64/egg' (and everything under it)
Processing autokeras-1.0.13-py3.8.egg
Removing /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages/autokeras-1.0.13-py3.8.egg
Copying autokeras-1.0.13-py3.8.egg to /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages
autokeras 1.0.13 is already the active version in easy-install.pth

Installed /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages/autokeras-1.0.13-py3.8.egg
Processing dependencies for autokeras==1.0.13
Searching for pandas==1.2.4
Best match: pandas 1.2.4
Adding pandas 1.2.4 to easy-install.pth file

Using /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages
Searching for scikit-learn==0.24.2
Best match: scikit-learn 0.24.2
Adding scikit-learn 0.24.2 to easy-install.pth file

Using /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages
Searching for keras-tuner==1.0.3
Best match: keras-tuner 1.0.3
Adding keras-tuner 1.0.3 to easy-install.pth file

Using /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages
Searching for packaging==20.9
Best match: packaging 20.9
Adding packaging 20.9 to easy-install.pth file

Using /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages
Searching for numpy==1.19.5
Best match: numpy 1.19.5
Adding numpy 1.19.5 to easy-install.pth file
Installing f2py script to /Users/me/miniforge3/envs/python38/bin
Installing f2py3 script to /Users/me/miniforge3/envs/python38/bin
Installing f2py3.8 script to /Users/me/miniforge3/envs/python38/bin

Using /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages
Searching for pytz==2021.1
Best match: pytz 2021.1
Adding pytz 2021.1 to easy-install.pth file

Using /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages
Searching for python-dateutil==2.8.1
Best match: python-dateutil 2.8.1
Adding python-dateutil 2.8.1 to easy-install.pth file

Using /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages
Searching for scipy==1.6.3
Best match: scipy 1.6.3
Adding scipy 1.6.3 to easy-install.pth file

Using /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages
Searching for joblib==1.0.1
Best match: joblib 1.0.1
Adding joblib 1.0.1 to easy-install.pth file

Using /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages
Searching for threadpoolctl==2.1.0
Best match: threadpoolctl 2.1.0
Adding threadpoolctl 2.1.0 to easy-install.pth file

Using /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages
Searching for ipython==7.23.1
Best match: ipython 7.23.1
Adding ipython 7.23.1 to easy-install.pth file
Installing iptest script to /Users/me/miniforge3/envs/python38/bin
Installing iptest3 script to /Users/me/miniforge3/envs/python38/bin
Installing ipython script to /Users/me/miniforge3/envs/python38/bin
Installing ipython3 script to /Users/me/miniforge3/envs/python38/bin

Using /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages
Searching for tensorboard==2.5.0
Best match: tensorboard 2.5.0
Adding tensorboard 2.5.0 to easy-install.pth file
Installing tensorboard script to /Users/me/miniforge3/envs/python38/bin

Using /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages
Searching for requests==2.25.1
Best match: requests 2.25.1
Adding requests 2.25.1 to easy-install.pth file

Using /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages
Searching for pyparsing==2.4.7
Best match: pyparsing 2.4.7
Adding pyparsing 2.4.7 to easy-install.pth file

Using /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages
Searching for six==1.15.0
Best match: six 1.15.0
Adding six 1.15.0 to easy-install.pth file

Using /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages
Searching for Pygments==2.9.0
Best match: Pygments 2.9.0
Adding Pygments 2.9.0 to easy-install.pth file
Installing pygmentize script to /Users/me/miniforge3/envs/python38/bin

Using /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages
Searching for jedi==0.18.0
Best match: jedi 0.18.0
Adding jedi 0.18.0 to easy-install.pth file

Using /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages
Searching for pexpect==4.8.0
Best match: pexpect 4.8.0
Adding pexpect 4.8.0 to easy-install.pth file

Using /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages
Searching for traitlets==5.0.5
Best match: traitlets 5.0.5
Adding traitlets 5.0.5 to easy-install.pth file

Using /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages
Searching for decorator==5.0.7
Best match: decorator 5.0.7
Adding decorator 5.0.7 to easy-install.pth file

Using /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages
Searching for pickleshare==0.7.5
Best match: pickleshare 0.7.5
Adding pickleshare 0.7.5 to easy-install.pth file

Using /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages
Searching for matplotlib-inline==0.1.2
Best match: matplotlib-inline 0.1.2
Adding matplotlib-inline 0.1.2 to easy-install.pth file

Using /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages
Searching for appnope==0.1.2
Best match: appnope 0.1.2
Adding appnope 0.1.2 to easy-install.pth file

Using /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages
Searching for setuptools==49.6.0.post20210108
Best match: setuptools 49.6.0.post20210108
Adding setuptools 49.6.0.post20210108 to easy-install.pth file
Installing easy_install script to /Users/me/miniforge3/envs/python38/bin

Using /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages
Searching for prompt-toolkit==3.0.18
Best match: prompt-toolkit 3.0.18
Adding prompt-toolkit 3.0.18 to easy-install.pth file

Using /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages
Searching for backcall==0.2.0
Best match: backcall 0.2.0
Adding backcall 0.2.0 to easy-install.pth file

Using /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages
Searching for absl-py==0.12.0
Best match: absl-py 0.12.0
Adding absl-py 0.12.0 to easy-install.pth file

Using /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages
Searching for google-auth-oauthlib==0.4.4
Best match: google-auth-oauthlib 0.4.4
Adding google-auth-oauthlib 0.4.4 to easy-install.pth file
Installing google-oauthlib-tool script to /Users/me/miniforge3/envs/python38/bin

Using /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages
Searching for tensorboard-plugin-wit==1.8.0
Best match: tensorboard-plugin-wit 1.8.0
Adding tensorboard-plugin-wit 1.8.0 to easy-install.pth file

Using /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages
Searching for tensorboard-data-server==0.6.0
Best match: tensorboard-data-server 0.6.0
Adding tensorboard-data-server 0.6.0 to easy-install.pth file

Using /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages
Searching for google-auth==1.30.0
Best match: google-auth 1.30.0
Adding google-auth 1.30.0 to easy-install.pth file

Using /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages
Searching for Werkzeug==1.0.1
Best match: Werkzeug 1.0.1
Adding Werkzeug 1.0.1 to easy-install.pth file

Using /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages
Searching for Markdown==3.3.4
Best match: Markdown 3.3.4
Adding Markdown 3.3.4 to easy-install.pth file
Installing markdown_py script to /Users/me/miniforge3/envs/python38/bin

Using /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages
Searching for grpcio==1.33.2
Best match: grpcio 1.33.2
Adding grpcio 1.33.2 to easy-install.pth file

Using /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages
Searching for wheel==0.36.2
Best match: wheel 0.36.2
Processing wheel-0.36.2-py3.8.egg
wheel 0.36.2 is already the active version in easy-install.pth
Installing wheel script to /Users/me/miniforge3/envs/python38/bin

Using /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages/wheel-0.36.2-py3.8.egg
Searching for protobuf==3.15.8
Best match: protobuf 3.15.8
Adding protobuf 3.15.8 to easy-install.pth file

Using /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages
Searching for chardet==4.0.0
Best match: chardet 4.0.0
Adding chardet 4.0.0 to easy-install.pth file
Installing chardetect script to /Users/me/miniforge3/envs/python38/bin

Using /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages
Searching for idna==2.10
Best match: idna 2.10
Adding idna 2.10 to easy-install.pth file

Using /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages
Searching for urllib3==1.26.4
Best match: urllib3 1.26.4
Adding urllib3 1.26.4 to easy-install.pth file

Using /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages
Searching for certifi==2020.12.5
Best match: certifi 2020.12.5
Adding certifi 2020.12.5 to easy-install.pth file

Using /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages
Searching for parso==0.8.2
Best match: parso 0.8.2
Adding parso 0.8.2 to easy-install.pth file

Using /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages
Searching for ptyprocess==0.7.0
Best match: ptyprocess 0.7.0
Adding ptyprocess 0.7.0 to easy-install.pth file

Using /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages
Searching for ipython-genutils==0.2.0
Best match: ipython-genutils 0.2.0
Processing ipython_genutils-0.2.0-py3.8.egg
ipython-genutils 0.2.0 is already the active version in easy-install.pth

Using /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages/ipython_genutils-0.2.0-py3.8.egg
Searching for wcwidth==0.2.5
Best match: wcwidth 0.2.5
Adding wcwidth 0.2.5 to easy-install.pth file

Using /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages
Searching for requests-oauthlib==1.3.0
Best match: requests-oauthlib 1.3.0
Adding requests-oauthlib 1.3.0 to easy-install.pth file

Using /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages
Searching for cachetools==4.2.2
Best match: cachetools 4.2.2
Adding cachetools 4.2.2 to easy-install.pth file

Using /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages
Searching for pyasn1-modules==0.2.8
Best match: pyasn1-modules 0.2.8
Adding pyasn1-modules 0.2.8 to easy-install.pth file

Using /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages
Searching for rsa==4.7.2
Best match: rsa 4.7.2
Adding rsa 4.7.2 to easy-install.pth file
Installing pyrsa-decrypt script to /Users/me/miniforge3/envs/python38/bin
Installing pyrsa-encrypt script to /Users/me/miniforge3/envs/python38/bin
Installing pyrsa-keygen script to /Users/me/miniforge3/envs/python38/bin
Installing pyrsa-priv2pub script to /Users/me/miniforge3/envs/python38/bin
Installing pyrsa-sign script to /Users/me/miniforge3/envs/python38/bin
Installing pyrsa-verify script to /Users/me/miniforge3/envs/python38/bin

Using /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages
Searching for oauthlib==3.1.0
Best match: oauthlib 3.1.0
Adding oauthlib 3.1.0 to easy-install.pth file

Using /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages
Searching for pyasn1==0.4.8
Best match: pyasn1 0.4.8
Adding pyasn1 0.4.8 to easy-install.pth file

Using /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages
Finished processing dependencies for autokeras==1.0.13",thank much reply tried unfortunately still success see following output run python install line really lot output far see install later run list virtual environment see list virtual environment output installation python python install running install running running writing writing writing writing reading manifest file writing manifest file library code running running flag set archive content egg removing everything egg removing egg egg already active version egg searching best match file searching best match file searching best match file searching best match file searching best match file script script script searching best match file searching best match file searching best match file searching best match file searching best match file searching best match file script script script script searching best match file script searching best match file searching best match file searching best match six six file searching best match file script searching best match file searching best match file searching best match file searching best match decorator decorator file searching best match file searching best match file searching best match file searching post best match post post file script searching best match file searching best match file searching best match file searching best match file script searching best match file searching best match file searching best match file searching best match file searching best match markdown markdown file script searching best match file searching best match wheel egg wheel already active version wheel script egg searching best match file searching best match file script searching best match file searching best match file searching best match file searching best match file searching best match file searching best match egg already active version egg searching best match file searching best match file searching best match file searching best match file searching best match file script script script script script script searching best match file searching best match file finished,issue,positive,positive,positive,positive,positive,positive
834942119,"> ERROR: Could not find a version that satisfies the requirement tensorflow>=2.3.0 (from autokeras) (from versions: none)
> ERROR: No matching distribution found for tensorflow>=2.3.0
> 
> But I do have Tensorflow version : 2.4.0-rc0 installed on my Mac M1.
> 
> I tried the solution provided by marcus-wang9527 but could not get it installed in my conda environment. :((

sorry about the solution, I found it maybe have a little problem. It will not install arm compatible pandas and sklearn, which will let the setup.py to install the wrong version. Also it wil not install the Cython in the beginning.
I just fixed it and I installed from the beginning on my M1 mac again. You can try it. @loheden 
",error could find version requirement none error matching distribution found version mac tried solution provided could get environment sorry solution found maybe little problem install arm compatible let install wrong version also install beginning fixed beginning mac try,issue,negative,negative,negative,negative,negative,negative
834762094,"I am heavily suffering from the same problem. I am not able to upgrade autokeras in miniforge3 on MAC OS M1. Whatever I do, the autokeras version remains as 1.0.2. How am I supposed to solve this?

Here is what I get when I try to install the latest version:

(python38) % pip install autokeras==1.0.12
Collecting autokeras==1.0.12
  Using cached autokeras-1.0.12-py3-none-any.whl (164 kB)
ERROR: Could not find a version that satisfies the requirement tensorflow>=2.3.0 (from autokeras) (from versions: none)
ERROR: No matching distribution found for tensorflow>=2.3.0

But I do have Tensorflow version :   2.4.0-rc0 installed on my Mac M1.

I tried the solution provided by marcus-wang9527 but could not get it installed in my conda environment. :((",heavily suffering problem able upgrade mac o whatever version remains supposed solve get try install latest version python pip install error could find version requirement none error matching distribution found version mac tried solution provided could get environment,issue,negative,positive,positive,positive,positive,positive
834726745,"On Mac OS M1, when I try to install autokeras 1.0.12, I get the following error:

(python38) % pip install autokeras==1.0.12
Collecting autokeras==1.0.12
  Using cached autokeras-1.0.12-py3-none-any.whl (164 kB)
Requirement already satisfied: scikit-learn in /Users/me/miniforge3/envs/python38/lib/python3.8/site-packages (from autokeras==1.0.12) (0.24.2)
ERROR: Could not find a version that satisfies the requirement tensorflow>=2.3.0 (from autokeras) (from versions: none)
ERROR: No matching distribution found for tensorflow>=2.3.0


And my installed tensorflow version is: 2.4.0-rc0

How am I supposed to solve this problem? Spent countless number of hours on this issue now..",mac o try install get following error python pip install requirement already satisfied error could find version requirement none error matching distribution found version supposed solve problem spent countless number issue,issue,negative,positive,neutral,neutral,positive,positive
834086460,"@rahman-tud Yes, I thought you said your issue was the same issue. Clearly it was not. ",yes thought said issue issue clearly,issue,positive,positive,positive,positive,positive,positive
834066980,"As you have said before, I have tried both ways. Could not resolve the issue. I am not using RP. Using PYNQ.",said tried way could resolve issue,issue,negative,neutral,neutral,neutral,neutral,neutral
833437547,"Like I mentioned, you can bypass it by ```import sklearn``` before importing autokeras. 

The following code works on my RPi 4 and it would take like 2-3 hours to finish (I overclocked it to 1750 MHz with a cooling fan).

```python
import sklearn   # do this first
import autokeras as ak
from tensorflow.keras.datasets import fashion_mnist
from sklearn.metrics import classification_report

(data_train, target_train), (data_test, target_test) = \
             fashion_mnist.load_data()
clf = ak.ImageClassifier(overwrite=True, max_trials=1)
clf.fit(data_train, target_train)
predictions = clf.predict(data_test).astype('int8')
print(classification_report(target_test, predictions))
```",like bypass import following code work would take like finish cooling fan python import first import ak import import print,issue,positive,positive,positive,positive,positive,positive
833431611,"Nope, tried several things, none worked.",nope tried several none worked,issue,negative,neutral,neutral,neutral,neutral,neutral
833360518,"Hi, i can confirm this issue is still present in the latest Autokeras version: v1.0.12. In my case i found out when i wanted to to get the best model after using a StructuredDataClassifier (using custom metrics loss function) with: 

`# get the best performing model`
`best_model = reg.export_model()`

Which ended up with the following error:

> ValueError: Unable to restore custom object of type _tf_keras_metric currently. Please make sure that the layer implements 'get_config'and 'from_config' when saving. In addition, please use the 'custom_objects' arg when calling 'load_model()'.

I managed to fix this issue with the solution of @KeikiHekili mentioned earlier  (the changes in `autokeras/auto_model.py` and `autokeras/autokeras/engine/tuner.py` ) and also changing the following in `autokeras/auto_model.py`

Original:

```
    def export_model(self):
        """"""Export the best Keras Model.

        # Returns
            tf.keras.Model instance. The best model found during the search, loaded
            with trained weights.
        """"""
        return self.tuner.get_best_model()
```

Changed:

```
    def export_model(self, custom_objects={}):
        """"""Export the best Keras Model.

        # Returns
            tf.keras.Model instance. The best model found during the search, loaded
            with trained weights.
        """"""
        if custom_objects:
            return self.tuner.get_best_model(custom_objects=custom_objects)
        else:
            return self.tuner.get_best_model()
```



After this change i could use a custom metric as follow:

```
import kerastuner
reg = ak.StructuredDataRegressor(max_trials=3, overwrite=True, metrics=[spearman_rankcor],objective=kerastuner.Objective('spearman_rankcor', direction='max'))
# Feed the structured data regressor with training data.
reg.fit(training_data[feature_names], training_data[TARGET_NAME], epochs=10)
```



I performed the model export and saving with:

```
# get the best performing model
best_model = reg.export_model(custom_objects={'spearman_rankcor': spearman_rankcor})
# summarize the loaded model
best_model.summary()
# Now save the model with round number
logging.info(""saving model: %s"", MODEL_FILE)
best_model.save(MODEL_FILE)
```

I still need to validate the actual model and if custom metric is used properly but so far the logging output looks ok.

 ",hi confirm issue still present latest version case found get best model custom metric loss function get best model ended following error unable restore custom object type currently please make sure layer saving addition please use calling fix issue solution also following original self export best model instance best model found search loaded trained return self export best model instance best model found search loaded trained return else return change could use custom metric follow import reg feed structured data regressor training data model export saving get best model summarize loaded model save model round number saving model still need validate actual model custom metric used properly far logging output,issue,positive,positive,positive,positive,positive,positive
831396128,"Hey @haifeng-jin!
I did run `sh shell/format.sh` prior to adding and committing. Yet the code format tests fail because there is a single file that is being shown as requiring reformating. I tried checking out the master branch in a fresh pull and running the command `sh shell/format.sh` locally and all files are left unchanged. 

![image](https://user-images.githubusercontent.com/17949650/116907468-3a01d000-ac5f-11eb-9aa6-86b56165c3d2.png)

The file in question is `autokeras/keras_layers.py` which isn't even affected by the commits of this pull request. 

![image](https://user-images.githubusercontent.com/17949650/116907524-51d95400-ac5f-11eb-9d2e-6a52426c274d.png)

Could you help resolving this?",hey run sh prior yet code format fail single file shown tried master branch fresh pull running command sh locally left unchanged image file question even affected pull request image could help,issue,negative,negative,neutral,neutral,negative,negative
830360901,"actually this worked for me:
```
from tensorflow import keras
inputs = keras.layers.Input(shape=(11,), dtype='string')
x = base_model.layers[1](inputs)
x = base_model.layers[2](x)

x = keras.layers.Dense(176)(x)
x = keras.layers.ReLU()(x)
x = keras.layers.Dense(400)(x)
x = keras.layers.ReLU()(x)
x = keras.layers.Dense(464)(x)
x = keras.layers.ReLU()(x)
x = keras.layers.Dense(3)(x)
x = keras.layers.Softmax()(x)

layer_3 = keras.Model(inputs, x)
```

i was able to get a 90+ accuracy on my task with it",actually worked import able get accuracy task,issue,negative,positive,positive,positive,positive,positive
830352159,"@NullCodex I suppose 
`base_model.layers[1].get_weights()` will do the trick, but i think MultiCategoryEncoder layer cant be directly integrated into a Sequential model like a normal dense layer. So i tried finding the underlying changement of MCE Layer and did a similar encoding manuelly beforehand.",suppose trick think layer cant directly sequential model like normal dense layer tried finding underlying changement layer similar beforehand,issue,negative,positive,neutral,neutral,positive,positive
830328584,"@niemand-01 how are you copying over the weights? I actually ended up creating a new model by copying the layer from the base model and then appending layers. It's something like:

```
base_model = load_model()
x = base_model.layers[1](x)
```

where the index is for the multicategorical layer.",actually ended new model layer base model something like index layer,issue,negative,negative,negative,negative,negative,negative
829534750,"Hi NullCodex,

i encountered the same problem yesterday and i found out the real problem is that we need to copy the weights in the ""Multi_cetegory_encoding"" layer, other weights in dense or some other layer can be learned during training, but category layer is somehow learned inside autokeras. Now i would like to know if we can train this layer or is there an equivalent layer with similiar behavior to ""Multi_cetegory_encoding"" layer that we can use. @haifeng-jin 

Niemand-01",hi problem yesterday found real problem need copy layer dense layer learned training category layer somehow learned inside would like know train layer equivalent layer behavior layer use,issue,negative,positive,positive,positive,positive,positive
827526960,"autokeras                 1.0.12
keras-tuner               1.0.2
tensorflow                2.4.1 

I have the same issue, that is export_model() returns the architecture of the best model with the weights of the last epoch instead of the best epoch.

However I think the problem is in keras-tuner because I found a [line](https://github.com/keras-team/keras-tuner/blob/86cff68ae4c7f35bb6557e75ec6a60e0766454d2/kerastuner/engine/tuner.py#L184) in the `save_model()` method of keras-team/keras-tuner/blob/master/kerastuner/engine/tuner.py that says:

`# TODO: save the top epoch checkpoints instead of last ones.`

I fixed it by saving the complete model architecture in `_checkpoint_model()` in keras-team/keras-tuner/blob/master/kerastuner/engine/tuner.py with this code:

```
def _checkpoint_model(self, model, trial_id, epoch):
        fname = self._get_checkpoint_fname(trial_id, epoch)
        # Save in TF format.
        model.save_weights(fname)
        path = self._get_checkpoint_dir(trial_id, epoch) # NEW LINE
        model.save(path+'/model') # NEW LINE
        return fname
```

Then in my main code I load the best saved model with `tensorflow.keras.models.load_model()`, after finding the best trial id and the best epoch.

I hope my experience can help someone else.",issue architecture best model last epoch instead best epoch however think problem found line method save top epoch instead last fixed saving complete model architecture code self model epoch epoch save format path epoch new line new line return main code load best saved model finding best trial id best epoch hope experience help someone else,issue,positive,positive,positive,positive,positive,positive
827211417,"More info: varying the lookback parameter varies the exception values.

`lookback = 30` -> `Incompatible shapes: [128,1] vs. [99,1]`
`lookback = 10` -> `Incompatible shapes: [128,1] vs. [119,1]`

in general

`lookback = L` -> `Incompatible shapes: [BATCH,1] vs. [(BATCH - L + 1),1]`",parameter exception incompatible incompatible general incompatible batch batch,issue,negative,positive,neutral,neutral,positive,positive
826320057,"Hey @haifeng-jin A pretty simple request:-
There is this Custom AutoKeras layer `<autokeras.keras_layers.ExpandLastDim at 0x7f8bfcbed250>,`
which is basically just the `tf.expand_dims` op. 

Could we re-create the layer in Keras (like AK did) and could you summarize it's importance/function? it's code just seems to be this

```py
@tf.keras.utils.register_keras_serializable()
class ExpandLastDim(preprocessing.PreprocessingLayer):
    def call(self, inputs):
        return tf.expand_dims(inputs, axis=-1)
```

Thanks in advance!",hey pretty simple request custom layer basically could layer like ak could summarize code class call self return thanks advance,issue,positive,positive,positive,positive,positive,positive
822227367,"Any updates on the implementation?
I require it as part of my ongoing project, anything i can do to help with the development process ?",implementation require part ongoing project anything help development process,issue,negative,neutral,neutral,neutral,neutral,neutral
822191510,"Same thing happening to PYNQ environment as well when importing the library. Library can't be imported at all. Always shows the same error related to so file. The error log as following:

```
ERROR:root:An unexpected error occurred while tokenizing input
The following traceback may be corrupted or invalid
The error message is: ('EOF in multi-line string', (1, 2))

---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/sklearn/__check_build/__init__.py in <module>()
     43 try:
---> 44     from ._check_build import check_build  # noqa
     45 except ImportError as e:

ImportError: /usr/local/lib/python3.6/dist-packages/sklearn/__check_build/../../scikit_learn.libs/libgomp-d22c30c5.so.1.0.0: cannot allocate memory in static TLS block

During handling of the above exception, another exception occurred:

ImportError                               Traceback (most recent call last)
<ipython-input-5-b7c74cbf5af0> in <module>()
----> 1 import sklearn

/usr/local/lib/python3.6/dist-packages/sklearn/__init__.py in <module>()
     79     # it and importing it first would fail if the OpenMP dll cannot be found.
     80     from . import _distributor_init  # noqa: F401
---> 81     from . import __check_build  # noqa: F401
     82     from .base import clone
     83     from .utils._show_versions import show_versions

/usr/local/lib/python3.6/dist-packages/sklearn/__check_build/__init__.py in <module>()
     44     from ._check_build import check_build  # noqa
     45 except ImportError as e:
---> 46     raise_build_error(e)

/usr/local/lib/python3.6/dist-packages/sklearn/__check_build/__init__.py in raise_build_error(e)
     39 to build the package before using it: run `python setup.py install` or
     40 `make` in the source directory.
---> 41 %s"""""" % (e, local_dir, ''.join(dir_content).strip(), msg))
     42 
     43 try:

ImportError: /usr/local/lib/python3.6/dist-packages/sklearn/__check_build/../../scikit_learn.libs/libgomp-d22c30c5.so.1.0.0: cannot allocate memory in static TLS block
___________________________________________________________________________
Contents of /usr/local/lib/python3.6/dist-packages/sklearn/__check_build:
__pycache__               setup.py                  _check_build.cpython-36m-aarch64-linux-gnu.so
__init__.py
___________________________________________________________________________
It seems that scikit-learn has not been built correctly.

If you have installed scikit-learn from source, please do not forget
to build the package before using it: run `python setup.py install` or
`make` in the source directory.

If you have used an installer, please check that it is suited for your
Python version, your operating system and your platform.
```",thing happening environment well library library ca always error related file error log following error root unexpected error input following may corrupted invalid error message string recent call last module try import except allocate memory static block handling exception another exception recent call last module import module first would fail found import import import clone import module import except build package run python install make source directory try allocate memory static block content built correctly source please forget build package run python install make source directory used installer please check python version operating system platform,issue,negative,positive,neutral,neutral,positive,positive
822006193,"I got this guy who apparently did it here:- https://stackoverflow.com/questions/66944411/issue-replicating-autokeras-structureddataclassifier/67084576#67084576 without any isolation of code, only of the model. His answer is the accepted one, the other one is mine.

This seems to be impossible since you can't reconstruct layers that aren't defined in TF/Keras from the weights alone and his layers certainly weren't. Any idea what he did? His answer seems very unclear and vague to me.",got guy apparently without isolation code model answer accepted one one mine impossible since ca reconstruct defined alone certainly idea answer unclear vague,issue,negative,negative,negative,negative,negative,negative
820546966,"I have the same problem.

I think that this line should be changed from this: https://github.com/keras-team/autokeras/blob/0d22c6f6a611cdfc017a24c28c68e7925b7f7feb/autokeras/engine/tuner.py#L63

to something like this:
`model = tf.keras.models.load_model(self.best_model_path, custom_objects={""custom_metric"": custom_metric})
`
when there is a custom metric provided by the user.

(Source: https://github.com/tensorflow/tensorflow/issues/33648#issuecomment-594908246)
",problem think line something like model custom metric provided user source,issue,negative,neutral,neutral,neutral,neutral,neutral
820367561,"Thanks, got it



At 2021-04-07 05:19:05, ""Haifeng Jin"" ***@***.***> wrote:

@fengyuan1993012 You can use the AutoModel API to abandon it.
There is an argument in the __init__ function of StructuredDataBlock.
However, as long as you set enough number of trials, it should converge on a model with good performance.
If normalization is not good for the performance, it should be abandoned through the trials.

—
You are receiving this because you were mentioned.
Reply to this email directly, view it on GitHub, or unsubscribe.",thanks got wrote use abandon argument function however long set enough number converge model good performance normalization good performance abandoned reply directly view,issue,negative,positive,positive,positive,positive,positive
816731697,"To be clear, i also used model.compile with the same optimizer setting to fit the model.",clear also used setting fit model,issue,positive,positive,positive,positive,positive,positive
816106378,I am using `keras.models.clone_model` which does not carry over the weights. I wanted to take the autokeras model as a starting point and examine the effect of adding additional layers but when i cloned the model the accuracy never improves since i am training from scratch.,carry take model starting point examine effect additional model accuracy never since training scratch,issue,negative,neutral,neutral,neutral,neutral,neutral
816104580,"This issue is resolved in the latest master.
We have renamed the tests/autokeras to tests/unittests.
It must be something else.",issue resolved latest master must something else,issue,negative,positive,positive,positive,positive,positive
816103576,"If you just clone the model, the weights should be already trained. Did you reinitialize the weights?",clone model already trained,issue,negative,neutral,neutral,neutral,neutral,neutral
814452849,"The regressor only accepts vectors for now.
What is the meaning of the dimension of 60 and 10?
Do you consider it as structured data?",regressor meaning dimension consider structured data,issue,negative,neutral,neutral,neutral,neutral,neutral
814448304,"For the blocks, they cannot be used stand-alone. The blocks contains the hyperparameters, which is defined in keras-tuner. To find out what layers are used in the block, you have to check the source code of the block.",used defined find used block check source code block,issue,negative,neutral,neutral,neutral,neutral,neutral
814446495,"@fengyuan1993012 You can use the `AutoModel` API to abandon it.
There is an argument in the `__init__` function of `StructuredDataBlock`.
However, as long as you set enough number of trials, it should converge on a model with good performance.
If normalization is not good for the performance, it should be abandoned through the trials.",use abandon argument function however long set enough number converge model good performance normalization good performance abandoned,issue,negative,positive,positive,positive,positive,positive
813039602,"Thanks for asking that, i have been meaning to write about it and also get opinions but did not get time. The labels being taken as input may seem ambiguous but it is passed at the last only for computing loss and is not passed through any learnable layers, you can verify the same inside the arcface layer class implementation. 

If you use the extracted encoder for a separate validation for image retrieval using a knn or index like NearPy(ANN) you can verify the test accuracy of about 85% top1 and 88% top5 accuracy score on unseen query images(the evaluated hyper-model has some differences so scores may vary slightly).

It might be possible to separate the logic for loss computation but i have left it according to the keras-arcface implementation linked in my page, i will look onto it. However I will shortly upload the validation example on the feature encoder. 

Do let me know your thoughts on this.",thanks meaning write also get get time taken input may seem ambiguous last loss learnable verify inside layer class implementation use extracted separate validation image retrieval index like ann verify test accuracy top top accuracy score unseen query may vary slightly might possible separate logic loss computation left according implementation linked page look onto however shortly validation example feature let know,issue,positive,positive,positive,positive,positive,positive
812917412,I still have the same question on how to include the labels rather than the probabilities of an exported model,still question include rather model,issue,negative,neutral,neutral,neutral,neutral,neutral
812640113,"Thanks, quick Q: why do you pass in the y_train as second input?",thanks quick pas second input,issue,negative,positive,positive,positive,positive,positive
812461724,"Hi, just an update i made something for dml with autokeras based on arcface. Do give it a look if you like https://github.com/sidphbot/AutoKeras-ArcFaceHead",hi update made something based give look like,issue,negative,neutral,neutral,neutral,neutral,neutral
812314281,"Hi, I did some search to use AutoKeras in conda env on my M1-chip Macbook Pro.
My system info:

- System version: `macOS 11.2.3`
- Python: `Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 15:50:57)`


I installed the [tensorflow_macos](https://github.com/apple/tensorflow_macos) by following the [instuction](https://github.com/apple/tensorflow_macos/issues/153). 
However, instead of using miniforge3 to create the conda env, I used the miniconda to create the env.
By using the miniconda, I used the conda-forge channel to install the arm-compatible packages.
**Following the steps I used:**
1. Inspired from this [stackoverflow](https://stackoverflow.com/questions/65415996/how-to-specify-the-architecture-or-platform-for-a-new-conda-environment-apple), I created the env by:
`CONDA_SUBDIR=osx-arm64 conda env create -n ak_arm --file environment.yml -C conda-forge`
You can get the `.yml` file from the tensorflow_macos instruction or [here](https://raw.githubusercontent.com/mwidjaja1/DSOnMacARM/main/environment.yml)
2. After creating the env, activate the env, to set the env vars to ensure future packages will install arm64 version:
`conda activate ak_arm`
`conda env config vars set CONDA_SUBDIR=osx-arm64`
3. Install the tensorflow macos version:
`pip install --upgrade --force --no-dependencies https://github.com/apple/tensorflow_macos/releases/download/v0.1alpha3/tensorflow_macos-0.1a3-cp38-cp38-macosx_11_0_arm64.whl https://github.com/apple/tensorflow_macos/releases/download/v0.1alpha3/tensorflow_addons_macos-0.1a3-cp38-cp38-macosx_11_0_arm64.whl`
4. Install the keras-tuner
`pip install git+https://github.com/keras-team/keras-tuner.git`
5. For the autokeras, I could not the directly using `pip install autokeras` duo to the `setup.py ` set the normal tensorflow as the requirement. This time we can build from the source:
Download the source code,
`git clone https://github.com/keras-team/autokeras.git`
sometimes may need to install Cython:
`pip3 install Cython`
Also we need pandas and sklearn, this will install the arm compatible version, do not let the setup.py to install:
`conda install pandas scikit-learn -c conda-forge`
edit the line24 in setup.py (I just commented it), then:
`python setup.py install`

Above are the steps I used to setup the Autokeras in conda env on my M1-chip Mackbook.
Hope it can help you.
",hi search use pro system system version python python default following however instead create used create used channel install following used inspired create file get file instruction activate set ensure future install arm version activate set install version pip install upgrade force install pip install could directly pip install duo set normal requirement time build source source code git clone sometimes may need install pip install also need install arm compatible version let install install edit line python install used setup hope help,issue,positive,positive,neutral,neutral,positive,positive
812134595,"I meant the ""blocks"" - like `TextClassification` block - what keras layers is that block made up of? and can I use it outside AutoKeras, say standalone colab?",meant like block block made use outside say,issue,negative,neutral,neutral,neutral,neutral,neutral
812024464,"
Thanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

:memo: **Please visit <https://cla.developers.google.com/> to sign.**

Once you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.

----

#### What to do if you already signed the CLA

##### Individual signers

*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).

##### Corporate signers

*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).
*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).
*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).
		

ℹ️ **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Fkeras-team%2Fautokeras%2Fpull%2F1542) for more info**.

<!-- need_sender_cla -->",thanks pull request like may first contribution open source project look help look pull request need sign contributor license agreement memo please visit sign fixed please reply verify already individual possible different address commit check data verify set git corporate company point contact authorized participate ask added group authorized know point contact direct project maintainer public version used register authorized contributor must used git commit check data verify set git used register authorized contributor must also attached account information go,issue,positive,positive,neutral,neutral,positive,positive
811734249,"hello, I am using autokeras to train a regression model. however, I find the normalization will lead to low accuracy. I would appreciate it if you could tell me where I can abandon the normalization layer. Thanks",hello train regression model however find normalization lead low accuracy would appreciate could tell abandon normalization layer thanks,issue,negative,positive,neutral,neutral,positive,positive
810656745,"Meanwhile, as I understand, the custom layers are actually blocks. would you mind explaining what layers/tensor-ops each block does which may be replicated in Keras with pre-existing layers?",meanwhile understand custom actually would mind explaining block may replicated,issue,negative,neutral,neutral,neutral,neutral,neutral
810535389,"@stancsz I assume the current RegressionHead support it, which means you can use any currently supported regression tasks for multivariate regression.",assume current support use currently regression regression,issue,negative,neutral,neutral,neutral,neutral,neutral
810533285,"As AutoKeras is still not stable enough, it is not time for us to separate another repo for it. Meanwhile, I will be consulting others from Keras team to see if there is a solution to pack the custom layers without importing the original code.",still stable enough time u separate another meanwhile consulting team see solution pack custom without original code,issue,negative,positive,positive,positive,positive,positive
810424694,"@haifeng-jin  Without looking at the current code, it seems like simply assigning very high or `Inf`  loss to invalid models would solve the problem rather elegently. ",without looking current code like simply high loss invalid would solve problem rather,issue,negative,positive,neutral,neutral,positive,positive
810352575,I'm interested in using autokeras for multivariate use case. (Sequence of N input and 1 output. ) im wondering if this has been done before? ,interested use case sequence input output wondering done,issue,negative,positive,positive,positive,positive,positive
809759571,"I agree with @eschibli proposal - even if we can have the standalone code for the custom layers used in AutoKeras, then we can still re-create the exact keras code. @haifeng-jin would you happen to know if this is possible OR if the custom layers currently can be re-created without any dependencies to `AutoKeras`?

Could you try making a standalone colab notebook for showing how we can use the AutoKeras custom layers seperately?",agree proposal even code custom used still exact code would happen know possible custom currently without could try making notebook showing use custom,issue,negative,positive,neutral,neutral,positive,positive
809310606,"> Is there some other configuration that can be used instead? It's just 60K samples with 784 features each. All perfectly scaled between zero and one. Same thing with targets. It could come from images or anything else. How AutoKeras can help with such simple arrangement of good scaled data?

you could try use `ak.Input()` instead of `ak.StructuredDataInput()` ",configuration used instead perfectly scaled zero one thing could come anything else help simple arrangement good scaled data could try use instead,issue,positive,positive,positive,positive,positive,positive
808077168,Any update? I'm facing this problem trying to create an AutoModel with multiple ImageInputs ,update facing problem trying create multiple,issue,negative,neutral,neutral,neutral,neutral,neutral
807363615,"If you have very specific models and hyperparameters to tune in mind, I suggest you try Keras Tuner.",specific tune mind suggest try tuner,issue,negative,neutral,neutral,neutral,neutral,neutral
806067788,"I haven't play around w/ Products10K and I will try to see if I can make the ImageEmbedder work with it (I think a custom batch generation may be needed like given a batch size, ex: n=64, generate random sample of n/2 classes w/ 2 samples each). ",play around try see make work think custom batch generation may like given batch size ex generate random sample class,issue,positive,negative,negative,negative,negative,negative
805795013,"Thanks for your help and apologies for the delay, it was a bit difficult to get the large datasets I am working with to run on the code because of limited resources. 

However, now that it runs fine my inference would be that it works great for smaller datasets(successfully tested with ~0.87 top-5 retreival accuracy score on custom validation loop on a grocery store dataset with 80 classes). 

however the performance decreases with number of classes. With huge datasets like Products10k, with 9690 classes, the loss is pretty much always nan. Also the huge batch size requirement is a bit difficult for huge datasets and/or limited resources, so for huge datasets I am moving on to implement Arcface loss with a product clustering multi-task model which generalizes a bit better to dataset size. ",thanks help delay bit difficult get large working run code limited however fine inference would work great smaller successfully tested accuracy score custom validation loop grocery store class however performance number class huge like class loss pretty much always nan also huge batch size requirement bit difficult huge limited huge moving implement loss product clustering model bit better size,issue,positive,positive,positive,positive,positive,positive
805461775,It should be possible to at least ameliorate the issue by moving the custom layers to another repo with fewer dependencies. I don't think it's possible to easily cache a model that uses custom layers without requiring those layers to be defined before loading. ,possible least ameliorate issue moving custom another think possible easily cache model custom without defined loading,issue,negative,positive,neutral,neutral,positive,positive
803249971,"Hi, 
The code below can built an LSTM model for times-series forecasting: 

model = Sequential()
model.add(LSTM(  **N**  , activation='relu', input_shape=(trainX.shape[1], trainX.shape[2]), return_sequences=True))
model.add(LSTM( **n** , activation='relu', return_sequences=False))
model.add(Dropout(0.2))
model.add(Dense(trainY.shape[1]))

model.compile(optimizer='adam', loss='mse')
model.summary()

Have you an idea how I can use the autokeras to built an LSTM. the idea is to find the best **N** and **n** (see the code).

I thank you in advance for your help. ",hi code built model forecasting model sequential dropout dense idea use built idea find best see code thank advance help,issue,positive,positive,positive,positive,positive,positive
802279289,"A possible fix to pull request:
* Handle the consecutive oversize model error during the initial trials.
* Have a way to mark a trial as invalid so that the trial would be selected as the best trials later.",possible fix pull request handle consecutive oversize model error initial way mark trial invalid trial would selected best later,issue,negative,positive,positive,positive,positive,positive
802277623,"I somehow realized that the default (greedy) tuner would be more suitable to solve this problem.
It would go through a list of models ( I expect at least one of those would work and not over-sized), and make modifications to that model.

From the error message above, it seems there is a bug.
It fails while going through the initial model list.
I will inspect it.",somehow default greedy tuner would suitable solve problem would go list expect least one would work make model error message bug going initial model list inspect,issue,negative,positive,neutral,neutral,positive,positive
802267034,I think the second call should start after the first call is finished. Do you see any sign that the second call starts before the first one ends?,think second call start first call finished see sign second call first one,issue,negative,positive,positive,positive,positive,positive
802253577,"@mandalbiswadip Yes. However, the fixes in the Transformer block are useful. I will take care of it to merge those lines.",yes however transformer block useful take care merge,issue,positive,positive,positive,positive,positive,positive
802124927,If you use playground dataset that are meant to be regression like Boston house pricing does the same problem occurs? ,use playground meant regression like boston house problem,issue,negative,neutral,neutral,neutral,neutral,neutral
800017952,@Arcyno how did you install，when i install autokeras in my tensorflow2.3.2 docker ，the pip will auto install tensorflow2.4,install docker pip auto install,issue,negative,neutral,neutral,neutral,neutral,neutral
799807735,"@haifeng-jin @elloza 

I did try, and as elloza says, it isn't working. Varying the tuner does not appear to prevent the same model from being repeatedly tried and rejected for size.",try working tuner appear prevent model repeatedly tried size,issue,negative,neutral,neutral,neutral,neutral,neutral
799751823,@haifeng-jin  it worked after rebasing. I guess this feature is already handled in #1525,worked guess feature already handled,issue,negative,neutral,neutral,neutral,neutral,neutral
799691029,"and also @sidphbot about how many classes is your dataset? If you are not generating triplets from the input (instead of relying on the default sampling) you may want larger batch size (don't forget to adjust your learning rate accordingly if needed) so your batch contains at least 2 samples from the same class (one for the anchor and another for positive), most of the DML losses implemented on TFA assumed that. But if you can't increase your batch size, you may want to want to do something similar to https://stackoverflow.com/questions/55484923/how-to-make-dataset-for-triplet-loss for your input.",also many class generating input instead default sampling may want batch size forget adjust learning rate accordingly batch least class one anchor another positive assumed ca increase batch size may want want something similar input,issue,positive,positive,positive,positive,positive,positive
799606717,"Hi,

I think the above example notebook for Autokeras + Deep Metrics Learning has the example with cifar10 and it has tangible loss `0.4605` with only 2 epochs, may you fork the notebook and test it? (It used the stock implmentation of `EmbeddingHead` and `ImageEmbedder`), I haven't tried it on NMIST and CIFAR100.",hi think example notebook deep metric learning example tangible loss may fork notebook test used stock tried,issue,negative,neutral,neutral,neutral,neutral,neutral
798809316,"Indeed, the solution was simply 

```
from scipy.sparse import csr_matrix
X_train = X_train.toarray()
```

as pointed out in this (accepted) SO answer on the exact same issue: https://stackoverflow.com/questions/66495126/typeerror-unsupported-type-class-scipy-sparse-csr-csr-matrix-for-structured/66614090#66614090

We can safely close this now @haifeng-jin.",indeed solution simply import pointed accepted answer exact issue safely close,issue,positive,positive,positive,positive,positive,positive
798649125,"Hi Thanks for confirming, it is really wierd i am still getting the error in pycharm syntax highlighting 

![image](https://user-images.githubusercontent.com/21005899/111038168-da89ff80-8427-11eb-9363-e525cb1775e5.png)


but the code still runs although, strangely if the data is not shuffled, the model collapses (loss = margin) as some batches will contain samples from just one class hence cannot be constrasted by any contrastive loss triplet loss included.

when the data is shuffled, the loss is always nan, i tried some tfds datasets(mnist and cifar100) too in as_supervised mode along with the dataset I am working with, the results were always same. 

I could be doing something wrong, can you provide a working notebook where there is any tangible model convergence recorded, no matter the data",hi thanks confirming really still getting error syntax image code still although strangely data model loss margin contain one class hence contrastive loss triplet loss included data loss always nan tried mode along working always could something wrong provide working notebook tangible model convergence matter data,issue,negative,negative,neutral,neutral,negative,negative
797888929,@haifeng-jin removed the WIP tag. Feel free to merge. ,removed tag feel free merge,issue,positive,positive,positive,positive,positive,positive
797719536,"@djokester The error is caused by a bug, which I just fixed in #1534.
This was a flaw in our design for this user-defined hp mechanism.
It has never been exposed by previous changes.
The Embedding block is a little special, which exposed the flaw.

You can rebase the master. The tests should pass then.",error bug fixed flaw design mechanism never exposed previous block little special exposed flaw rebase master pas,issue,negative,positive,neutral,neutral,positive,positive
797636003,"@shun-lin ye, I know that man. but as I said before, I want to export the model code where it just uses Tensorflow and Keras; i.e recreate the model with only `tf.keras` and not using `Autokeras`",ye know man said want export model code recreate model,issue,negative,neutral,neutral,neutral,neutral,neutral
797582446,"I think this is exactly what save model in Tensorflow does right? https://www.tensorflow.org/guide/saved_model

Save model does not depends on the module but it produces the raw graph and weights.",think exactly save model right save model module raw graph,issue,positive,positive,positive,positive,positive,positive
797367191,@shun-lin I mean that there be a way where I can export the code only in pure Keras and TensorFlow rather than depending on AutoKeras modules. @haifeng-jin ,mean way export code pure rather depending,issue,negative,negative,neutral,neutral,negative,negative
797140248,I use `tf.data.Dataset.from_generator` for getting my data and do not want that to happen. If there are two calls can you make sure that the first call gets over so that the next call can make a fresh call to that generator? An easy option might be to get a local iterator from the dataset to do your pass i.e. using `iter(dataset)`.,use getting data want happen two make sure first call next call make fresh call generator easy option might get local pas iter,issue,positive,positive,positive,positive,positive,positive
797126708,Is there some other configuration that can be used instead? It's just 60K samples with 784 features each. All perfectly scaled between zero and one. Same thing with targets. It could come from images or anything else. How AutoKeras can help with such simple arrangement of good scaled data?,configuration used instead perfectly scaled zero one thing could come anything else help simple arrangement good scaled data,issue,positive,positive,positive,positive,positive,positive
797092104,"Hi, it looks like the EmbeddingHead is callable (see screenshot below), does the EmbeddingHead in your implementation inherits from `head_module.Head`? This class has `__call__` implemented so should be callable. Sorry for low quality screenshot I am on my phone 😂

![93F34009-4B38-4C85-8AAE-108B632E0E13](https://user-images.githubusercontent.com/16867893/110863491-9c4cde80-8275-11eb-9420-0ebba9033b5f.png)
",hi like callable see implementation class callable sorry low quality phone,issue,negative,negative,negative,negative,negative,negative
797070422,"I think you can with the Model class that is stored in `self.tuner` right?

Does the below work?

```
clf = ak.ModelClass()
model = clf.export_model()
model.save(...)
```

And I think you can used the saved_model elsewhere without importing autokeras.
",think model class right work model think used elsewhere without,issue,negative,positive,positive,positive,positive,positive
797022090,"This is likely because of the search space.
The raw pixels are treated as structured data.
The search space of structured data tasks may not work for these inputs.",likely search space raw structured data search space structured data may work,issue,negative,negative,negative,negative,negative,negative
797019087,It is because we will first analyze the data before training.,first analyze data training,issue,negative,positive,positive,positive,positive,positive
796293789,"The code is a part of a distributed pipeline and is also protected by Non-Disclosure Agreement however the you can find the relevant code excerpt below with parameter values, see if it helps, 

# Data

df = pd.read_csv(csvfile)
df_copy = df[df[parameters.ycol].notnull()].copy()
df_copy[parameters.ycol] = LabelEncoder().fit_transform(df_copy[parameters.ycol])
x = np.array(df_copy[parameters.xcol].values.tolist())
y = np.array(df_copy[parameters.ycol].values.tolist())

x = get_chunk(x)									# loads chunk of images with custom data preparation

x = tf.convert_to_tensor(x, dtype=tf.float32)
y = tf.convert_to_tensor(y, dtype=tf.int32)
dataset = tf.data.Dataset.from_tensor_slices((x, y))

#shape : <BatchDataset shapes: ((None, 180, 180, 3), (None,)), types: (tf.float32, tf.int32)>

train_data = dataset.batch(batch_size)

————

# Hyper-Model 1

input_node = ak.ImageInput()
processed_input = ak.Normalization()(input_node)
processed_input = ak.ImageAugmentation()(processed_input)
output_1 = ak.ResNetBlock(version='v2', pretrained=False)(processed_input)
output_node = EmbeddingHead(embedding_size=512)(output_1)                                  # 	throws not callable error

clf = ak.AutoModel(

    inputs=input_node,
    outputs=output_node,
    overwrite=True,
    distribution_strategy=tf.distribute.MirroredStrategy(),
    max_trials=100,														#  runs till 20-30 trials before - #1479 bug , #175 tuner-bug
    max_model_size=100000000
)

————

# Hyper-Model 2	

#works but feature collapse, also sometimes when ran longer ends up with many oversized models with bfc allocator GPU OOM errors

clf = ImageEmbedder(

    overwrite=True,
    max_model_size=100000000,
    max_trials=100,														#  runs till 20-30 trials before - #1479 bug , #175 tuner-bug
    distribution_strategy=tf.distribute.MirroredStrategy(),
    embedding_size=512
)

————

tensorboard_callback = keras.callbacks.TensorBoard(log_dir=model_dir_path + '/automodel-log')

clf.fit(train_data, epochs=5, callbacks=[tensorboard_callback])
",code part distributed pipeline also agreement however find relevant code excerpt parameter see data chunk custom data preparation shape none none callable error till bug work feature collapse also sometimes ran longer many oversized allocator till bug,issue,negative,positive,positive,positive,positive,positive
796238886,"yeah, so Autokeras uses some customized layers. So If I train the model, can I export all the minimal, basic code needed to construct that layer and use it independently of `AutoKeras`?",yeah train model export minimal basic code construct layer use independently,issue,negative,negative,neutral,neutral,negative,negative
796092845,"No, it will not random flip in prediction. The model knows whether it is doing fit or predict, and will choose different path in the computation graph.",random flip prediction model whether fit predict choose different path computation graph,issue,negative,negative,neutral,neutral,negative,negative
796090814,"I am not sure how to do it.
It is the same as saving some customized layers with the Keras model and load it without the customized layer code.
If you can find a solution to that it can be applied.",sure saving model load without layer code find solution applied,issue,positive,positive,positive,positive,positive,positive
796036136,"You made a good point, the implementation of `EmbeddingHead` is very similar to `ClassificationHead`, is it possible for you to share a notebook where the error w/ `EmbeddingHead` occurs?

Also I will be making a lightweight package that contains the integration with AutoKeras and DML losses from TensorFlow Addons (like `EmbeddingHead`, `ImageEmbedder`, etc) shown in the above notebook until they are merged back into this repository.",made good point implementation similar possible share notebook error also making lightweight package integration like shown notebook back repository,issue,positive,positive,positive,positive,positive,positive
795247709,"Hey thanks for the explanation regarding autokeras functioning. Yes other DML losses also need to be considered, infact that was why i asked about ways to tune loss. I did not account for the fact that only the loss is compared to find the best model here. 

However I feel even if we fix the loss, the head can be used with custom architectures in auto-model to get a refined search space, instead of a pipeline which will introduce a lot of not-working architectures. Due to the incremental training nature, the penalties will probably keep accumulating till the model decides it cannot produce better embeddings and starts to cheat by producing same embeddings in-order to cancel out in loss function and produce minimum loss which is margin here. 

So please let me know about the error i posted.",hey thanks explanation regarding yes also need considered way tune loss account fact loss find best model however feel even fix loss head used custom get refined search space instead pipeline introduce lot due incremental training nature probably keep till model produce better cheat cancel loss function produce minimum loss margin please let know error posted,issue,negative,positive,positive,positive,positive,positive
794928058,"@haifeng-jin would you be kind enough to review the changes made for dropout? 
I wanted to implement changes for all the hyperparameters for embedding through this pull request. ",would kind enough review made dropout implement pull request,issue,positive,positive,positive,positive,positive,positive
794909450,@djokester Thanks for the PR! I see you mark it as [WIP]. Is it ready for review now?,thanks see mark ready review,issue,positive,positive,positive,positive,positive,positive
794342029,"Thanks for finding this useful!

In regards to loss stuck at margin, this is (almost) the equivalent of loss returning `NaN` for classification/regress problem as the loss for Triplet Loss is capped at the margin ([explanation](https://gombru.github.io/2019/04/03/ranking_loss/)) so a potential work-around may be an `earlyStopping` callback for embedding models (maybe in `EmbeddingHead`) that will stop the training and move on to the next model when `loss >= margin`.

And yes I agree that the loss margin should be tune-able or should be a `HyperParameter`, but the problem is that the best model is currently picked by the lowest loss and when we change margin the loss may not be comparable meaningfully, we may want to rely on other metrics to find the best model (ex: clustering quality on validation set), and this is also needed if we want to make the deep metrics learning loss itself to be a `HyperParameter` (ex: `tfa.losses.ContrastiveLoss`,`tfa.losses.TripletSemiHardLoss`, `tfa.losses.LiftedStructLoss` are all DML losses that try to accomplish the same thing) and to find a good embedding model we should try/tune all those losses (but again the smallest loss != best model so some investigation need to be done here).",thanks finding useful loss stuck margin almost equivalent loss nan problem loss triplet loss capped margin explanation potential may maybe stop training move next model loss margin yes agree loss margin problem best model currently picked loss change margin loss may comparable meaningfully may want rely metric find best model ex clustering quality validation set also want make deep metric learning loss ex try accomplish thing find good model loss best model investigation need done,issue,positive,positive,positive,positive,positive,positive
793756913,"Great ! It is definitely useful. M actually a student working on automatic product catalouging. Its just too many classes for softmax based classification so deep metric learning is really essential for me. 

However I am encountering an issue would very much like some help on the same. Although the implementation of the image embedder as a whole works, the model is encountering feature collapse. I tested the loss with euclidean and cosine distance but the loss was stuck at margin (1.0002-1.0004), model had collapsed in the initial trials itself.

I am running it for 20-30 trials before the regular too many oversized models error is thrown.

I wanted to know if you can guide me for using the embedding head alone in auto-model to perform a more guided/restricted search space. The HeadModule.Head subclassing implementation seems perfect yet it is not a callable like classification or regression heads or any other block. 

Output = ak.ClassificationHead()(processed_input)     # works

Output = EmbeddingHead()(processed_input)     # throws EmbeddingHead not a callable block

Output = EmbeddingHead()    # works but it does not serve the purpose as it does not have the input features

Apologies for the trouble, but if you have any suggestions or ideas regarding the above error or avoiding feature collapse, it would be very helpful to my thesis. 

Also there is a very good way to tackle model collapse if everything is encapsulated with custom trials mainly so as to tune the triplet loss margin too. How ever that seems to be a lot of work for tuning just one parameter. I would really like to know if you have any ideas on how to tune the loss margin as well.",great definitely useful actually student working automatic product many class based classification deep metric learning really essential however issue would much like help although implementation image whole work model feature collapse tested loss cosine distance loss stuck margin model initial running regular many oversized error thrown know guide head alone perform search space implementation perfect yet callable like classification regression block output work output callable block output work serve purpose input trouble regarding error feature collapse would helpful thesis also good way tackle model collapse everything custom mainly tune triplet loss margin ever lot work tuning one parameter would really like know tune loss margin well,issue,negative,positive,positive,positive,positive,positive
793267738,I don't think we can support this type. Is it possible to convert it to numpy array?,think support type possible convert array,issue,negative,neutral,neutral,neutral,neutral,neutral
792808036,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1523?src=pr&el=h1) Report
> Merging [#1523](https://codecov.io/gh/keras-team/autokeras/pull/1523?src=pr&el=desc) (a5919d2) into [master](https://codecov.io/gh/keras-team/autokeras/commit/eaa39c14d7d4f7fdab880eeacbe6a3b7eba6d295?el=desc) (eaa39c1) will **not change** coverage.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1523/graphs/tree.svg?width=650&height=150&src=pr&token=yDvddb2DDZ)](https://codecov.io/gh/keras-team/autokeras/pull/1523?src=pr&el=tree)

```diff
@@            Coverage Diff            @@
##            master     #1523   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           51        51           
  Lines         3404      3404           
=========================================
  Hits          3404      3404           
```



------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1523?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1523?src=pr&el=footer). Last update [eaa39c1...6cd09d3](https://codecov.io/gh/keras-team/autokeras/pull/1523?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",report ad master change coverage coverage impacted file tree graph coverage master coverage continue review full report legend click learn absolute relative impact affected missing data powered last update read comment,issue,negative,positive,neutral,neutral,positive,positive
791638387,Hi @eschibli! Did you try tuner = 'random'?. I am trying something similar to your test but I have the same problem. I am further limiting the model size to only 153600 parameters in order to find small architectures for tensorflow lite for microcontrollers. Could you suggest me some way to use ImageClassifier for this? Thank you so much!,hi try tuner trying something similar test problem limiting model size order find small lite could suggest way use thank much,issue,negative,negative,neutral,neutral,negative,negative
790033375,You mean it doesn't even cache the weights on your disk after the download?,mean even cache disk,issue,negative,negative,negative,negative,negative,negative
790030846,"@mandalbiswadip Thanks for the PR!
Would you rebase the latest master branch and try again?
It seems there are some conflicts.",thanks would rebase latest master branch try,issue,negative,positive,positive,positive,positive,positive
789704368,"I'm having the same issue, and I opened [keras-tuner issue #493](https://github.com/keras-team/keras-tuner/issues/493) with some details on my attempts to set up such an environment.

Thanks keras-team in advance for your help (and for such a great ecosystem of tools-- autokeras is awesome!)",issue issue set environment thanks advance help great ecosystem awesome,issue,positive,positive,positive,positive,positive,positive
788717279,"That would be perfect.  I looked around but couldn't find an issue for it.  Do you happen to have a link handy so that I can watch the issue?

Otherwise, you can close this ""will not fix.""  Sequence to Dataset will resolve this issue for me.",would perfect around could find issue happen link handy watch issue otherwise close fix sequence resolve issue,issue,positive,positive,positive,positive,positive,positive
788257502,"Ah. But it looks like the BERT model specifically doesn't actually cache the tokenizer or the weights locally, so it isn't quite that simple. Do I understand that correctly? ",ah like model specifically actually cache locally quite simple understand correctly,issue,negative,neutral,neutral,neutral,neutral,neutral
788250117,"> 
> 
> It might because the training uses GPU and when loading you don't have GPU?
> I am not sure if it works in this case.
> It seems except for the first line, all the printed info is warnings instead of errors.

I've never used my GPU for training, but I'll try setting it up to discard the option you mentioned.",might training loading sure work case except first line printed instead never used training try setting discard option,issue,negative,positive,positive,positive,positive,positive
788246409,"We use this function to download the file. All the caching mechanisms are relying on this function.
https://www.tensorflow.org/api_docs/python/tf/keras/utils/get_file",use function file function,issue,negative,neutral,neutral,neutral,neutral,neutral
788243033,"I believe Keras and TF team are trying to build a bridge between the Sequence and TF Dataset format.
When it is done, the users can easily convert the Sequences to Datasets, which is supported in AutoKeras.",believe team trying build bridge sequence format done easily convert,issue,negative,positive,positive,positive,positive,positive
788241090,"It might because the training uses GPU and when loading you don't have GPU?
I am not sure if it works in this case.
It seems except for the first line, all the printed info is warnings instead of errors.",might training loading sure work case except first line printed instead,issue,negative,positive,positive,positive,positive,positive
788117433,Where does AutoKeras cache the downloads? It shouldn't be difficult to work around the issue by manually downloading the pertinent files. ,cache difficult work around issue manually pertinent,issue,negative,negative,negative,negative,negative,negative
787508781,"Hello,
having the same issue in here. Any solution to it?
Thanks",hello issue solution thanks,issue,positive,positive,positive,positive,positive,positive
786986008,"Sorry, you're right.  from_generator does stream the batches one at a time.  There's just an issue with my implementation:  I've wrapped a Keras Sequence with a Python generator, then that with an interleave and it appears that at some stage of this process Tensorflow is attempting to load the entire 600,000 image data set at once.

Maybe my real feature request is to support Keras [Sequences](https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence) in addition to Datasets:  I need CPU multi-threading in order to pre-process my data efficiently enough for this process to be practical.
",sorry right stream one time issue implementation wrapped sequence python generator interleave stage process load entire image data set maybe real feature request support addition need order data efficiently enough process practical,issue,positive,negative,neutral,neutral,negative,negative
786919516,"Sure. There are a bunch of GPU warnings (I do not use a GPU) and the critical error of kernel died.
```
An error ocurred while starting the kernel

2021󈚦󈚾 17:07:07.868734: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found
2021󈚦󈚾 17:07:07.870459: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021󈚦󈚾 17:07:13.500853: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021󈚦󈚾 17:07:13.503441: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library nvcuda.dll
2021󈚦󈚾 17:07:13.534758: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1060 computeCapability: 6.1
coreClock: 1.6705GHz coreCount: 10 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 178.99GiB/s
2021󈚦󈚾 17:07:13.536583: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found
2021󈚦󈚾 17:07:13.537917: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cublas64_11.dll'; dlerror: cublas64_11.dll not found
2021󈚦󈚾 17:07:13.539245: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cublasLt64_11.dll'; dlerror: cublasLt64_11.dll not found
2021󈚦󈚾 17:07:13.540595: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cufft64_10.dll'; dlerror: cufft64_10.dll not found
2021󈚦󈚾 17:07:13.542187: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'curand64_10.dll'; dlerror: curand64_10.dll not found
2021󈚦󈚾 17:07:13.543475: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cusolver64_10.dll'; dlerror: cusolver64_10.dll not found
2021󈚦󈚾 17:07:13.544782: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cusparse64_11.dll'; dlerror: cusparse64_11.dll not found
2021󈚦󈚾 17:07:13.546020: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cudnn64_8.dll'; dlerror: cudnn64_8.dll not found
2021󈚦󈚾 17:07:13.546585: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2021󈚦󈚾 17:07:13.548224: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance‑critical operations: AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021󈚦󈚾 17:07:13.550784: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021󈚦󈚾 17:07:13.551434: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267] 
2021󈚦󈚾 17:07:13.551843: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021󈚦󈚾 17:07:14.594800: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021󈚦󈚾 17:07:15.418992: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
```",sure bunch use critical error kernel error starting kernel could load dynamic library found ignore set machine set successfully dynamic library found device name could load dynamic library found could load dynamic library found could load dynamic library found could load dynamic library found could load dynamic library found could load dynamic library found could load dynamic library found could load dynamic library found please make sure missing properly would like use follow guide setup platform skipping binary deep neural network library use following enable rebuild appropriate compiler device interconnect strength edge matrix set none optimization registered currently considered may change future consider,issue,positive,positive,neutral,neutral,positive,positive
786917999,"@rogeravs1997 Thanks for the issue!
Would you paste the error message as well?",thanks issue would paste error message well,issue,negative,positive,positive,positive,positive,positive
786917464,"@shun-lin Thanks for the issue!
We will see if more people are interested in this feature.",thanks issue see people interested feature,issue,positive,positive,positive,positive,positive,positive
786911336,"Loading batch by batch is the reason that people use python generators.
By writing it in a different way, I expect it would solve the problem.",loading batch batch reason people use python writing different way expect would solve problem,issue,negative,neutral,neutral,neutral,neutral,neutral
786188810,"I have same issue for latest AutoKeras release using AutoModel for image regresison, with 'bayesian' tuner. 
Update: I think I may have found the culprit for this error. It's the metrics_tracking.py script in the Keras-Tuner package:
**kerastuner/engine/metrics_tracking.py.**

I have modified the get_best_value(self) function in Line 86:

    def get_best_value(self):
        values = list(
            obs.mean() for obs in self._observations.values())
        if not values:
            return None
        if self.direction == 'min':
            if np.isnan(np.nanmin(values)):
                return 999
            else:
                return np.nanmin(values)
        return np.nanmax(values)

I think when the metric scores (loss or custom metric) are all NAN, this causes np.nanmin(values) to return NAN, which then leads to the ValueError. Instead, we want np.nanmin(values) to return a number, in this case 999. Doing this avoids the dreaded ValueError exception and AutoKeras happily continues:

 15/15 - 24s - loss: nan - mae: nan - mape: nan - val_loss: nan - val_mae: nan - val_mape: nan
Epoch 2/200
15/15 - 1s - loss: nan - mae: nan - mape: nan - val_loss: nan - val_mae: nan - val_mape: nan
Epoch 3/200
15/15 - 1s - loss: nan - mae: nan - mape: nan - val_loss: nan - val_mae: nan - val_mape: nan
Epoch 4/200
15/15 - 1s - loss: nan - mae: nan - mape: nan - val_loss: nan - val_mae: nan - val_mape: nan
Epoch 5/200
15/15 - 1s - loss: nan - mae: nan - mape: nan - val_loss: nan - val_mae: nan - val_mape: nan
Epoch 6/200
15/15 - 1s - loss: nan - mae: nan - mape: nan - val_loss: nan - val_mae: nan - val_mape: nan
Epoch 7/200
15/15 - 1s - loss: nan - mae: nan - mape: nan - val_loss: nan - val_mae: nan - val_mape: nan
Epoch 8/200
15/15 - 1s - loss: nan - mae: nan - mape: nan - val_loss: nan - val_mae: nan - val_mape: nan
Epoch 9/200
15/15 - 1s - loss: nan - mae: nan - mape: nan - val_loss: nan - val_mae: nan - val_mape: nan
Epoch 10/200
15/15 - 1s - loss: nan - mae: nan - mape: nan - val_loss: nan - val_mae: nan - val_mape: nan
/home/joshua/PycharmProjects/pythonProject2/venv/lib/python3.8/site-packages/kerastuner/engine/metrics_tracking.py:92: RuntimeWarning: All-NaN axis encountered
  if np.isnan(np.nanmin(values)):
Trial 8 Complete [00h 00m 35s]
**val_loss: 999**
Best val_loss So Far: 305.5285949707031
Total elapsed time: 00h 19m 06s

This fix prevents AutoKeras from crashing due to ValueError. I am still testing it further, hopefully this helps! 

",issue latest release image tuner update think may found culprit error script package self function line self list return none return else return return think metric loss custom metric nan return nan instead want return number case exception happily loss nan mae nan nan nan nan nan epoch loss nan mae nan nan nan nan nan epoch loss nan mae nan nan nan nan nan epoch loss nan mae nan nan nan nan nan epoch loss nan mae nan nan nan nan nan epoch loss nan mae nan nan nan nan nan epoch loss nan mae nan nan nan nan nan epoch loss nan mae nan nan nan nan nan epoch loss nan mae nan nan nan nan nan epoch loss nan mae nan nan nan nan nan axis trial complete best far total time fix due still testing hopefully,issue,negative,positive,positive,positive,positive,positive
786186061,"Unfortunately, when I set to 'bayesian', it crashed at only trial #8 with ""ValueError: NAN, value too big for float64"". 
Update: Provided a quick fix for the NAN error. 
However, I have noticed that Bayesian takes 3 x longer to train compared to greedy. In addition, the performance may not be better or even worse compared to greedy (up to 100 trials). The only problem with greedy is the premature termination, which is quite annoying. Different random seed seems to lead to different max trials being completed in greedy tuner, which is erratic and unstable in my opinion. There's definitely merit in keeping greedy as it is fast and able to provide good performance but work needs to be done to improve it. ",unfortunately set trial nan value big float update provided quick fix nan error however longer train greedy addition performance may better even worse greedy problem greedy premature termination quite annoying different random seed lead different greedy tuner erratic unstable opinion definitely merit keeping greedy fast able provide good performance work need done improve,issue,negative,positive,neutral,neutral,positive,positive
786169731,I had similar issues with AutoModel using the default greedy tuner. This is for 2D image inputs for regression task. It will complete up to ~110 max trials but no more than that. Was wondering what is happening until I saw this post. I will try 'bayesian' for now. ,similar default greedy tuner image regression task complete wondering happening saw post try,issue,negative,positive,neutral,neutral,positive,positive
780822191,@shun-lin Thank you for the answer. I will check the compatibility for keras-tuner and tf 2.4.,thank answer check compatibility,issue,negative,neutral,neutral,neutral,neutral,neutral
780472775,"https://colab.research.google.com/drive/1wmQx004H-a1QLsOmhmJcw4f4DubjC7qT?usp=sharing

If you uncomment the two parameters in the StructuredDataClassifier definition and run the cell you will get the error.
This might be an error I made.",two definition run cell get error might error made,issue,negative,neutral,neutral,neutral,neutral,neutral
780348288,"This issue is same as https://github.com/keras-team/autokeras/issues/1348.

I also noticed that, the model generated by this extra trial is being considered as best model, irrespective of objective metrics.
Where-as, one of the models generated in the normal trials had the best score. But, that is being neglected.
I am also specifying a separate validation data.",issue also model extra trial considered best model irrespective objective metric one normal best score also separate validation data,issue,positive,positive,positive,positive,positive,positive
780310514,"CLAs look good, thanks!

ℹ️ **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Fkeras-team%2Fautokeras%2Fpull%2F1508) for more info**.

<!-- ok -->",look good thanks information go,issue,positive,positive,positive,positive,positive,positive
780100296,"@mdalvi
I cannot reproduce the bug.
Do you see `structured_data_block_2` in your output or `structured_data_block_1`?
It would be great if you can set a seed `StructuredDataRegressor(..., seed=5, ...)`.
That would either don't cause the error, or help me reproduce the error : )",reproduce bug see output would great set seed would either cause error help reproduce error,issue,negative,positive,positive,positive,positive,positive
780096562,"@garyee Would you paste your code?
I am trying to reproduce the issue.
We actually did save the custom metric.",would paste code trying reproduce issue actually save custom metric,issue,negative,neutral,neutral,neutral,neutral,neutral
780093125,"It does not.

The ""Load Images from Disk"" method is suitable for an image classification problem, but not for an image regression problem (e.g., regression from an image to a scalar.)  As far as I can tell, the ""Load Data with Python Generators"" method requires the entire Dataset to fit into memory at once.",load disk method suitable image classification problem image regression problem regression image scalar far tell load data python method entire fit memory,issue,negative,positive,positive,positive,positive,positive
780090635,"This is a tutorial for loading data from disk in a streaming manner.
Does it solve the problem?
https://autokeras.com/tutorial/load/",tutorial loading data disk streaming manner solve problem,issue,negative,neutral,neutral,neutral,neutral,neutral
780089332,"I am not familiar with ONNX.
However, AutoKeras is using some custom layers and extending the preprocessing layer class, which is a latest feature of Keras.
Therefore, I guess it is not supported in ONNX yet. ",familiar however custom extending layer class latest feature therefore guess yet,issue,negative,positive,positive,positive,positive,positive
780083372,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1505?src=pr&el=h1) Report
> Merging [#1505](https://codecov.io/gh/keras-team/autokeras/pull/1505?src=pr&el=desc) (c3e1e48) into [master](https://codecov.io/gh/keras-team/autokeras/commit/6b4d27a5b1fd6bc0345f66d7fe7b9a84a602bdfd?el=desc) (6b4d27a) will **not change** coverage.
> The diff coverage is `100.00%`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1505/graphs/tree.svg?width=650&height=150&src=pr&token=yDvddb2DDZ)](https://codecov.io/gh/keras-team/autokeras/pull/1505?src=pr&el=tree)

```diff
@@            Coverage Diff            @@
##            master     #1505   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           44        44           
  Lines         3277      3277           
=========================================
  Hits          3277      3277           
```


| [Impacted Files](https://codecov.io/gh/keras-team/autokeras/pull/1505?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [autokeras/analysers/input\_analysers.py](https://codecov.io/gh/keras-team/autokeras/pull/1505/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2FuYWx5c2Vycy9pbnB1dF9hbmFseXNlcnMucHk=) | `100.00% <100.00%> (ø)` | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1505?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1505?src=pr&el=footer). Last update [6b4d27a...c3e1e48](https://codecov.io/gh/keras-team/autokeras/pull/1505?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",report cee master change coverage coverage impacted file tree graph coverage master coverage impacted coverage continue review full report legend click learn absolute relative impact affected missing data powered last update cee read comment,issue,negative,positive,neutral,neutral,positive,positive
780077102,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1503?src=pr&el=h1) Report
> Merging [#1503](https://codecov.io/gh/keras-team/autokeras/pull/1503?src=pr&el=desc) (09fa1de) into [master](https://codecov.io/gh/keras-team/autokeras/commit/91ce2085028b0e451f95e81833075bd0a00db291?el=desc) (91ce208) will **not change** coverage.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1503/graphs/tree.svg?width=650&height=150&src=pr&token=yDvddb2DDZ)](https://codecov.io/gh/keras-team/autokeras/pull/1503?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##            master     #1503    +/-   ##
==========================================
  Coverage   100.00%   100.00%            
==========================================
  Files           51        44     -7     
  Lines         3408      3277   -131     
==========================================
- Hits          3408      3277   -131     
```


| [Impacted Files](https://codecov.io/gh/keras-team/autokeras/pull/1503?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [autokeras/preprocessors/\_\_init\_\_.py](https://codecov.io/gh/keras-team/autokeras/pull/1503/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL3ByZXByb2Nlc3NvcnMvX19pbml0X18ucHk=) | | |
| [autokeras/blocks/\_\_init\_\_.py](https://codecov.io/gh/keras-team/autokeras/pull/1503/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2Jsb2Nrcy9fX2luaXRfXy5weQ==) | | |
| [autokeras/\_\_init\_\_.py](https://codecov.io/gh/keras-team/autokeras/pull/1503/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL19faW5pdF9fLnB5) | | |
| [autokeras/analysers/\_\_init\_\_.py](https://codecov.io/gh/keras-team/autokeras/pull/1503/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2FuYWx5c2Vycy9fX2luaXRfXy5weQ==) | | |
| [autokeras/tasks/\_\_init\_\_.py](https://codecov.io/gh/keras-team/autokeras/pull/1503/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL3Rhc2tzL19faW5pdF9fLnB5) | | |
| [autokeras/adapters/\_\_init\_\_.py](https://codecov.io/gh/keras-team/autokeras/pull/1503/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2FkYXB0ZXJzL19faW5pdF9fLnB5) | | |
| [autokeras/tuners/\_\_init\_\_.py](https://codecov.io/gh/keras-team/autokeras/pull/1503/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL3R1bmVycy9fX2luaXRfXy5weQ==) | | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1503?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1503?src=pr&el=footer). Last update [91ce208...28e168d](https://codecov.io/gh/keras-team/autokeras/pull/1503?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",report fade master ce change coverage coverage impacted file tree graph coverage master coverage impacted coverage continue review full report legend click learn absolute relative impact affected missing data powered last update ce read comment,issue,negative,positive,neutral,neutral,positive,positive
780019807,"> I have the same issue.
> It happens when the score of the trial is NaN in my case.
> 
> We need to repoen the issue.
> 
> A workaround would be to remove the trial that has a NaN score.

@q-55555 Can you let me know how to do that? (removing a trial for which the val_loss is NaN)",issue score trial nan case need issue would remove trial nan score let know removing trial nan,issue,negative,neutral,neutral,neutral,neutral,neutral
779525780,"Looks like TPU is supported as KerasTuner now supports TPU, here is an example: https://colab.research.google.com/drive/1AaFDTQaq8B5p3-FKtNDdMdhlmUHtwOIM?authuser=1#scrollTo=HUJ0LxZnbQnc

and it's quite simple actually with only 2 lines of code:

```
resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=tpu_address)
strategy = tf.distribute.TPUStrategy(resolver)
clf = ak.ImageClassifier(max_trials=3, distribution_strategy=strategy)
```

Note: It looks like using `with strategy.scope()` will not work (same as KerasTuner) and the TPU strategy have to be passed down this way. I think it will be great if this is added somewhere in the documentation (I'm happy to contribute if needed), also thanks for the awesome package!

Edit: Actually there are some models generate that are not compatible with TPU will break, see the same colab above.",like example quite simple actually code resolver strategy resolver note like work strategy way think great added somewhere documentation happy contribute also thanks awesome package edit actually generate compatible break see,issue,positive,positive,positive,positive,positive,positive
779434988,"I didn't know that. Thanks for the answers. Hopefully, it would be supported in Windows soon.",know thanks hopefully would soon,issue,positive,positive,positive,positive,positive,positive
779434364,It would be stored in the `/tmp` folder. It would only be downloaded once as long as you don't clear your folder.,would folder would long clear folder,issue,negative,positive,neutral,neutral,positive,positive
779433435,"It is probably because it is a defect of the algorithm. It prefers exploitation over exploration.
For a small search space, it cannot find a new set of hps.",probably defect algorithm exploitation exploration small search space find new set,issue,negative,negative,neutral,neutral,negative,negative
779431359,"I don't see why this is happening, maybe you can set smaller batch size to avoid this error.",see happening maybe set smaller batch size avoid error,issue,negative,neutral,neutral,neutral,neutral,neutral
779431008,"Do you mean your X only has one feature?
If so, you can reshape to (num_instances, 1).",mean one feature reshape,issue,negative,negative,negative,negative,negative,negative
779430547,"We are using TensorFlow as the backend and do not directly touch the hardware.
So as long as TensorFlow supports M1, AutoKeras should do, too.",directly touch hardware long,issue,negative,positive,neutral,neutral,positive,positive
779427864,"Sorry, it is not supported for `h5` format for now.
Please let me know if we suggested that both h5 and tf format works in the documentation, I will change that.",sorry format please let know format work documentation change,issue,negative,negative,negative,negative,negative,negative
779426632,"As a temporary solution, you may try using random search as the tuning algorithm.
We will fix this issue systematically later.",temporary solution may try random search tuning algorithm fix issue systematically later,issue,negative,negative,negative,negative,negative,negative
779425992,"I am not familiar with Docker. If anyone could submit a pull request for it, it is much appreciated.",familiar docker anyone could submit pull request much,issue,negative,positive,positive,positive,positive,positive
778895646,"It looks like it's an error on the kears-tuner side, keras-tuner 1.0.2 looks like it is not competible with tf 2.4, may you upgrade keras-tuner in your environment to the latest to see if that will help?

`pip3 install --upgrade keras-tuner` on terminal or 

`!pip3 install --upgrade keras-tuner` on Colab.

I had the same issue on Colab and upgrading keras-tuner to latest resolved the issue.",like error side like may upgrade environment latest see help pip install upgrade terminal pip install upgrade issue latest resolved issue,issue,positive,positive,positive,positive,positive,positive
778551692,"We really haven't test the env of Raspberry Pi.
Anyone if have some insights please help.",really test raspberry pi anyone please help,issue,positive,positive,positive,positive,positive,positive
778551506,"core dump may be caused by too large models. According to our tests, the latest version should work with tf 2.4.0 and tf 2.3.0.",core dump may large according latest version work,issue,negative,positive,positive,positive,positive,positive
778551379,"Do you get nan for all the trials?
How many trials did you set?
If all the trials are nan, would you please share your dataset with us. We may further inspect.",get nan many set nan would please share u may inspect,issue,positive,positive,positive,positive,positive,positive
778551291,"This is an expected behavior since we want to provide the users the end-to-end solutions.
If you want to get the probabilities, you can export the model with `automodel.export_model()`.
",behavior since want provide want get export model,issue,negative,neutral,neutral,neutral,neutral,neutral
778551102,"Maybe it is because of the compatibility with the OS?
Would you try to run on Colab?",maybe compatibility o would try run,issue,negative,neutral,neutral,neutral,neutral,neutral
778546308,@mandalbiswadip Thank you! please do. We don't have other people working on this right now.,thank please people working right,issue,positive,positive,positive,positive,positive,positive
778325283,"I can take up Embedding, Transformer, and MultiHeadSelfAttention block in the coming few days.",take transformer block coming day,issue,negative,neutral,neutral,neutral,neutral,neutral
777824942,"In StructuredDataClassifier model which is ExportedautoKeras_model does not support ExportedautoKeras_model.classes_
and does not have history, where as Keras model supports both, is it possible to get that in StructuredDataClassifier model",model support history model possible get model,issue,negative,neutral,neutral,neutral,neutral,neutral
777770733,I am not sure. What do you see currently as the output of these?,sure see currently output,issue,negative,positive,positive,positive,positive,positive
777766781,"We are working on this, mainly need to enable the feature in Keras Tuner.
This issue is also tracked by #1286 .",working mainly need enable feature tuner issue also tracked,issue,negative,positive,positive,positive,positive,positive
777766310,"We are not using multiprocessing anymore, so I assume the problem is solved.
Another reason for people getting not implemented error is because the testing directory names cause the python interpreter unable to find the correct path, which is also been fixed.
Please paste any snippet if you still getting this error.
Reopening it now.",assume problem another reason people getting error testing directory cause python interpreter unable find correct path also fixed please paste snippet still getting error,issue,negative,negative,negative,negative,negative,negative
777762215,"It is mainly caused by AutoKeras not covering the suitable models for your dataset.
If you can send us your dataset, we can take some time to inspect the reasons.",mainly covering suitable send u take time inspect,issue,negative,positive,positive,positive,positive,positive
777760563,"If anyone is having any error caused by running AutoKeras on TPU.
Please paste it here.",anyone error running please paste,issue,negative,neutral,neutral,neutral,neutral,neutral
777760139,"This is a really old issue.
I expect we already support TPU,
but having some performance issues.
Should be solved when we support compile function for AutoModels.",really old issue expect already support performance support compile function,issue,positive,positive,neutral,neutral,positive,positive
777759086,"Sorry for the late reply.
Thank you for the issue.
You may submit a pull request for this. I will approvee and merge.",sorry late reply thank issue may submit pull request merge,issue,negative,negative,negative,negative,negative,negative
775224449,"Hi,

did get the same error apparently. I got an error message:
`ValueError: Unable to restore custom object of type _tf_keras_metric currently. Please make sure that the layer implements 'get_config'and 'from_config' when saving. In addition, please use the 'custom_objects' arg when calling 'load_model()'.
` 
I used the StructuredDataClassifier. Apparently the custom metric is not saved with the model.",hi get error apparently got error message unable restore custom object type currently please make sure layer saving addition please use calling used apparently custom metric saved model,issue,positive,positive,neutral,neutral,positive,positive
771370533,"Hi, Can you keep this open, I am still looking for some solution, Thanks",hi keep open still looking solution thanks,issue,positive,positive,neutral,neutral,positive,positive
771079658,"> I have many more changes i made to get the desired functionality in a separate branch. Sometime in the next week I'll take a look at which of those are generally helpful to other people and include it. Do you prefer a second pull request or should i add them here if they depend on these changes as well?
> […](#)
> On Fri, Jan 29, 2021, 11:57 PM Haifeng Jin ***@***.*** wrote: Since we are having more people interested in this feature, I would put this in the milestone and gradually push it forward. Since we have a tighter requirement for the APIs, I will make minor changes to the pull request. — You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub <[#1433 (comment)](https://github.com/keras-team/autokeras/pull/1433#issuecomment-769889500)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AEVLQ5WSAOROIDNUEO53V7TS4LLHJANCNFSM4TWC3CMQ> .

Either way is OK. Thank you!",many made get desired functionality separate branch sometime next week take look generally helpful people include prefer second pull request add depend well wrote since people interested feature would put milestone gradually push forward since requirement make minor pull request reply directly view comment either way thank,issue,positive,positive,positive,positive,positive,positive
770530532,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1495?src=pr&el=h1) Report
> Merging [#1495](https://codecov.io/gh/keras-team/autokeras/pull/1495?src=pr&el=desc) (e5fc3c2) into [master](https://codecov.io/gh/keras-team/autokeras/commit/a99277a8185953cd9c6ad41a8f16a9d5400825b3?el=desc) (a99277a) will **not change** coverage.
> The diff coverage is `100.00%`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1495/graphs/tree.svg?width=650&height=150&src=pr&token=yDvddb2DDZ)](https://codecov.io/gh/keras-team/autokeras/pull/1495?src=pr&el=tree)

```diff
@@            Coverage Diff            @@
##            master     #1495   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           44        44           
  Lines         3274      3277    +3     
=========================================
+ Hits          3274      3277    +3     
```


| [Impacted Files](https://codecov.io/gh/keras-team/autokeras/pull/1495?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [autokeras/blocks/basic.py](https://codecov.io/gh/keras-team/autokeras/pull/1495/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2Jsb2Nrcy9iYXNpYy5weQ==) | `100.00% <100.00%> (ø)` | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1495?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1495?src=pr&el=footer). Last update [a99277a...e5fc3c2](https://codecov.io/gh/keras-team/autokeras/pull/1495?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",report master aa change coverage coverage impacted file tree graph coverage master coverage impacted coverage continue review full report legend click learn absolute relative impact affected missing data powered last update aa read comment,issue,negative,positive,neutral,neutral,positive,positive
770174530,creating a new PR for this. Had some problems dealing with the CLA agreement for email associated with my previous commit.,new dealing agreement associated previous commit,issue,positive,negative,neutral,neutral,negative,negative
770087880,"I have many more changes i made to get the desired functionality in a
separate branch.  Sometime in the next week I'll take a look at which of
those are generally helpful to other people and include it.  Do you prefer
a second pull request or should i add them here if they depend on these
changes as well?

On Fri, Jan 29, 2021, 11:57 PM Haifeng Jin <notifications@github.com wrote:

> Since we are having more people interested in this feature, I would put
> this in the milestone and gradually push it forward.
> Since we have a tighter requirement for the APIs, I will make minor
> changes to the pull request.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/keras-team/autokeras/pull/1433#issuecomment-769889500>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AEVLQ5WSAOROIDNUEO53V7TS4LLHJANCNFSM4TWC3CMQ>
> .
>
",many made get desired functionality separate branch sometime next week take look generally helpful people include prefer second pull request add depend well wrote since people interested feature would put milestone gradually push forward since requirement make minor pull request reply directly view,issue,positive,positive,positive,positive,positive,positive
769889500,"Since we are having more people interested in this feature, I would put this in the milestone and gradually push it forward.
Since we have a tighter requirement for the APIs, I will make minor changes to the pull request.",since people interested feature would put milestone gradually push forward since requirement make minor pull request,issue,negative,positive,neutral,neutral,positive,positive
769343707,"We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.
In order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.

ℹ️ **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Fkeras-team%2Fautokeras%2Fpull%2F1493) for more info**.

<!-- need_author_cla -->",found contributor license agreement sender pull request unable find commit author maybe used different address git used sign login double check someone else need sign well confirm order pas check please resolve problem comment fixed bot comment think anything information go,issue,positive,negative,neutral,neutral,negative,negative
764840451,"I noticed that this is taking a long time to download them. Is there any way in which I can pre-download these models or not download them at all? Something like what we see with TPoT?

Also, it seems that there's no mention of this anywhere in the documentation",taking long time way something like see also mention anywhere documentation,issue,negative,negative,neutral,neutral,negative,negative
763571473,"Ok I have managed to understand the issue for me : all the numeric data have to me cast as str before calling ""predict()"" (though I am not sure why). I hope it will help people",understand issue data cast calling predict though sure hope help people,issue,positive,positive,positive,positive,positive,positive
763373768,"This might be the same as seen in #1489. This is on Ubuntu, tried on two different machines",might seen tried two different,issue,negative,neutral,neutral,neutral,neutral,neutral
761862795,"There are tons of applications for image in image out, like image segmentation, reinforcement learning, GANs, and so on",image image like image segmentation reinforcement learning,issue,negative,neutral,neutral,neutral,neutral,neutral
759853299,@haifeng-jin we have to open this ticket. I think this is not done completely.,open ticket think done completely,issue,negative,positive,neutral,neutral,positive,positive
756520184,"Thank you sir for your support.

On Mon, 4 Jan 2021 at 17:54, Mehmet Gunes <notifications@github.com> wrote:

> @hemangjoshi37a <https://github.com/hemangjoshi37a> change overwrite=True
> to overwrite=False . It should works.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/keras-team/autokeras/issues/1476#issuecomment-753946207>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AC6RPGO4KH2L5VTVXLRTXPLSYGXPLANCNFSM4VNH4FIA>
> .
>


-- 
Regards,
Hemang Joshi,
Email : hemangjoshi37a@gmail.com
mobile : +919409077371
",thank sir support mon wrote change work reply directly view joshi mobile,issue,positive,positive,neutral,neutral,positive,positive
756250431,"Renaming the layers in the following way solved the problem for me.

for layer in model_con_1.layers :
          layer._name = layer.name + str('_1')
for layer in model_con_2.layers :
         layer._name = layer.name + str('_2')",following way problem layer layer,issue,negative,neutral,neutral,neutral,neutral,neutral
756158441,"I'm getting this error on Big Sur, python3.8 when calling `multiprocessing.queues.Queue.qsize()`, why is the issue closed? Something feels weird about this issue that no one tried to fix. Even in the `queues.py` module, there's a comment marking the line as problematic and yet nothing seems to change over time.

```
def qsize(self):
    # Raises NotImplementedError on Mac OSX because of broken sem_getvalue()
    return self._maxsize - self._sem._semlock._get_value()
```
",getting error big sur python calling issue closed something weird issue one tried fix even module comment marking line problematic yet nothing change time self mac broken return,issue,negative,negative,negative,negative,negative,negative
755734608,"@haifeng-jin You can already use Kerastuner to create the history of the final model, why not in autokeras?",already use create history final model,issue,negative,neutral,neutral,neutral,neutral,neutral
753438815,"
![auokeras bug](https://user-images.githubusercontent.com/42462113/103452082-a2f92b80-4cf1-11eb-8ece-af8cf78fe86c.JPG)

One more issue which I observed is, I executed a program with max_trials=500 and epochs=5000. After completing 500th trial, it has again started a trial or something similar to that with 5000 epochs.

It seems like, the root cause is same, hence posting in this bug issue itself",bug one issue executed program th trial trial something similar like root cause hence posting bug issue,issue,negative,neutral,neutral,neutral,neutral,neutral
753334542,"docker should mount host directory to `/work`, instead of `/app`

the `pwd` in container prints `/work` for `haifengjin/autokeras:latest` (ff0ffdc713a9)
```
$ docker run -it -v $(pwd):/app --shm-size 2G haifengjin/autokeras pwd
/work
```",docker mount host directory instead container latest docker run,issue,negative,positive,positive,positive,positive,positive
752986380,"> 
> 
> > I found the bug. When `.fit()` is called, it get stuck when calling` _prepare_data()`, which get stucks in`split_data()`. Then, `split_data()` get sutck when calling `dataset.reduce().` This happens because Image data preprocessing from Keras creates an infinite generator, but according to [tensorflow docs, reduce() ](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#reduce)runs until the dataset is exhausted. The point is that as it is infinite, the dataset never gets exhausted.
> 
> Hi man how did you by pass it ? I also have the same problem ?
> did you mangae to make it finite in some way limit the generator ?

Hi! You have to manually set the number of instances you are going to use. First, wrap your generator into a function like this:

```
def get_train_generator():
    train_generator = preprocessing_images.flow_from_directory(
        train_path,
        target_size=target_size,
        batch_size=batch_size,
        class_mode=""categorical"", # classes are provided in categorical format for a 2-unit output layer
        shuffle=True,
        color_mode=""grayscale"",
        seed=1234567890
    )

    for i in range(20):
        #print(""[ Delivering a batch ]"")
        yield train_generator.next()
        #print(""[ Next batch! ]"")
```

There, you are going to have 20 batches of batch_size (integer) images. Then, create a TensorFlow dataset , using the function above like this:

```
train_dataset = tf.data.Dataset.from_generator(get_train_generator,output_types=('uint8', 'uint8'),
    output_shapes=(tf.TensorShape((None, 256, 256, 1)), tf.TensorShape((None,2))))
```

You will have to change output_shape and type according to your instances. You can be less specific and use None, I think it works too.

Do the same think for your validation dataset in case you want to use one.

Then, you use train_dataset to feed your fit function.
```
clf = ak.ImageClassifier(max_trials=250)
clf.fit(train_dataset, validation_data = val_dataset, epochs=200)
```

I hope it helps. I am busy, but reply if you need something else!",found bug get stuck calling get get calling image data infinite generator according reduce exhausted point infinite never exhausted hi man pas also problem make finite way limit generator hi manually set number going use first wrap generator function like categorical class provided categorical format output layer range print batch yield print next batch going integer create function like none none change type according le specific use none think work think validation case want use one use feed fit function hope busy reply need something else,issue,positive,positive,neutral,neutral,positive,positive
752935981,"Yes, it seems the GS file system API is not build for Windows (see https://github.com/tensorflow/tensorflow/issues/38477). The only way to get this working (that I know of, without compiling any sources) is to don't run with Windows (e.g. Ubuntu / MacOS / Google Colab).",yes file system build see way get working know without run,issue,negative,neutral,neutral,neutral,neutral,neutral
751545324,"The changes I made actually enable a lot of different capabilities.  It
just makes a generic head that can be used for a lot of things in different
ways.

On Mon, Dec 28, 2020 at 6:35 AM gregegg <notifications@github.com> wrote:

> I have a use case for this capability.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/keras-team/autokeras/pull/1433#issuecomment-751523863>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AEVLQ5SAMZXMIFLFDRQTYHLSW6ZB7ANCNFSM4TWC3CMQ>
> .
>
",made actually enable lot different generic head used lot different way mon wrote use case capability reply directly view,issue,negative,positive,neutral,neutral,positive,positive
751524314,"I think I too am interested in this capability.  Is this related to #1429?

",think interested capability related,issue,negative,positive,positive,positive,positive,positive
751487055,"> I found the bug. When `.fit()` is called, it get stuck when calling` _prepare_data()`, which get stucks in`split_data()`. Then, `split_data()` get sutck when calling `dataset.reduce().` This happens because Image data preprocessing from Keras creates an infinite generator, but according to [tensorflow docs, reduce() ](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#reduce)runs until the dataset is exhausted. The point is that as it is infinite, the dataset never gets exhausted.

Hi man how did you by pass it ? I also have the same problem ?
did you mangae to make it finite in some way limit the generator ?",found bug get stuck calling get get calling image data infinite generator according reduce exhausted point infinite never exhausted hi man pas also problem make finite way limit generator,issue,negative,negative,neutral,neutral,negative,negative
751139152,"@haifeng-jin tf 2.3.0 has me in a catch-22 where Illegal instruction (core dumped) happens on importing TF.

Up to 2.2 works on a I5 3570 so now stuck between the 2?",illegal instruction core work stuck,issue,negative,negative,negative,negative,negative,negative
748880823,"@arirkts369 

You probably need to use tf.TensorShape([None, 3]) instead of tf.TensorShape([None, 1]) in the example above.  In my application, I was regressing to a scalar but in your case you are classifying to one of three classes.  ",probably need use none instead none example application scalar case one three class,issue,negative,neutral,neutral,neutral,neutral,neutral
748853380,"> @VictorReaver1999 I was also getting the ""Cannot take the length of shape with unknown rank"" error. The issue is that autokeras.utils.data_utils.batched doesn't know what to do with the generator. Since the generators in the example are indeed outputting batches, just monkey-patching this function to return True will get you up and running for now.
> 
> ```
> train_dataset = tf.data.Dataset.from_generator(lambda: callable_iterator(train_generator),output_types=(tf.float32, tf.float32))
> val_dataset = tf.data.Dataset.from_generator(lambda: callable_iterator(val_generator),output_types=(tf.float32, tf.float32))
> 
> # Autokeras data_utils gets confused by the generator.
> # Just let it know that the data is indeed batched.
> ak.utils.data_utils.batched = lambda _: True
> 
> clf = ak.ImageRegressor(
>     max_trials=args.max_trials,
>     directory=args.save_model_dir)
> ```
> 
> **Update (above left for posterity):**
> 
> I found that there was a place downstream that was also failing in spite of the monkey-patch. As I experimented with AutoKeras, I found a cleaner way that both clears the downstream error and avoids the ugly monkey-patching:
> 
> ```
> def callable_iterator(generator, expected_batch_size):
>   for img_batch, targets_batch in generator:
>     if img_batch.shape[0] == expected_batch_size:
>       yield img_batch, targets_batch
> 
> train_dataset = tf.data.Dataset.from_generator(
>     lambda: callable_iterator(train_generator, args.batch_size),
>     output_types=(tf.float32, tf.float32),
>     output_shapes=(tf.TensorShape([None, args.crop_size, args.crop_size, 1 if args.gray else 3]),
>                    tf.TensorShape([None, 1])))
> val_dataset = tf.data.Dataset.from_generator(
>     lambda: callable_iterator(val_generator, args.batch_size),
>     output_types=(tf.float32, tf.float32),
>     output_shapes=(tf.TensorShape([None, args.crop_size, args.crop_size, 1 if args.gray else 3]),
>                    tf.TensorShape([None, 1])))
> ```
> 
> Obviously the things starting with `args.` should be replaced with something appropriate to your code.
> 
> This surfaces the appropriate dimensions to the necessary places in AutoKeras. AutoKeras does not behave well if you give it any incomplete batches, so I had to modify callable_iterator as above to reject incomplete batches from the iterator.

Hi I have 3 classes and 32 batches for some reason when I try to add this patch to the code it gives me an error

ValueError: `generator` yielded an element of shape (32, 3) where an element of shape (None, 1) was expected

also change the values (None,1) in the patch to  (32,3), it runs but nothing happens at all.",also getting take length shape unknown rank error issue know generator since example indeed function return true get running lambda lambda confused generator let know data indeed lambda true update left posterity found place downstream also failing spite experimented found cleaner way downstream error ugly generator generator yield lambda none else none lambda none else none obviously starting something appropriate code appropriate necessary behave well give incomplete modify reject incomplete hi class reason try add patch code error generator element shape element shape none also change none patch nothing,issue,negative,negative,neutral,neutral,negative,negative
748692643,"Yes, I am waiting for this as well, Thanks",yes waiting well thanks,issue,positive,positive,positive,positive,positive,positive
746147979,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1465?src=pr&el=h1) Report
> Merging [#1465](https://codecov.io/gh/keras-team/autokeras/pull/1465?src=pr&el=desc) (381ba53) into [master](https://codecov.io/gh/keras-team/autokeras/commit/1732f2732b1762f0bf88c252255de6c029e6603d?el=desc) (1732f27) will **not change** coverage.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1465/graphs/tree.svg?width=650&height=150&src=pr&token=yDvddb2DDZ)](https://codecov.io/gh/keras-team/autokeras/pull/1465?src=pr&el=tree)

```diff
@@            Coverage Diff            @@
##            master     #1465   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           44        44           
  Lines         3271      3274    +3     
=========================================
+ Hits          3271      3274    +3     
```


| [Impacted Files](https://codecov.io/gh/keras-team/autokeras/pull/1465?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [autokeras/auto\_model.py](https://codecov.io/gh/keras-team/autokeras/pull/1465/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2F1dG9fbW9kZWwucHk=) | `100.00% <0.00%> (ø)` | |
| [autokeras/blocks/basic.py](https://codecov.io/gh/keras-team/autokeras/pull/1465/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2Jsb2Nrcy9iYXNpYy5weQ==) | `100.00% <0.00%> (ø)` | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1465?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1465?src=pr&el=footer). Last update [1732f27...381ba53](https://codecov.io/gh/keras-team/autokeras/pull/1465?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",report ba master change coverage coverage impacted file tree graph coverage master coverage impacted coverage continue review full report legend click learn absolute relative impact affected missing data powered last update ba read comment,issue,negative,positive,neutral,neutral,positive,positive
744374649,"So, is there some missing dependency? Any direction in how to solve this?",missing dependency direction solve,issue,negative,negative,negative,negative,negative,negative
744284318,"> ### Bug Description
> When I try to run a sample code using the text classifier, there is error in loading the BERT checkpoint from google cloud system
> 
> > ""UnimplementedError: File system scheme 'gs' not implemented (file: 'gs://cloud-tpu-checkpoints/bert/keras_bert/uncased_L-12_H-768_A-12\vocab.txt')""
> 
> complete trace :
> [autokeras_error.txt](https://github.com/keras-team/autokeras/files/5671936/autokeras_error.txt)
> 
> ### Bug Reproduction
> Code for reproducing the bug:
> 
> ```
> import autokeras as ak
> import numpy as np
> clf = ak.TextClassifier(overwrite=True,max_trials=10)
> clf.fit(tr_x, tr_y, epochs=1,validation_data=(te_x,te_y))
> ```
> 
> Data used by the code:
> 
> ```
> tr_x = np.array([""If you like adult comedy cartoons, like South Park, then this is nearly a similar format about the small adventures of three teenage girls at Bromwell High. Keisha, Natella and Latrina have given exploding sweets and behaved like bitches, I think Keisha is a good leader. There are also small stories going on with the teachers of the school. There's the idiotic principal, Mr. Bip, the nervous Maths teacher and many others. The cast is also fantastic, Lenny Henry's Gina Yashere, EastEnders Chrissie Watts, Tracy-Ann Oberman, Smack The Pony's Doon Mackichan, Dead Ringers' Mark Perry and Blunder's Nina Conti. I didn't know this came from Canada, but it is very good. Very good!"",\
>         ""good movie"",    
>         ""I basically skimmed through the movie but just enough to catch watch the plot was about. To tell you the truth it was kind of boring to me and at some spots it didn't make sense. The only reason I watched this movie in the first place was to see CHACE CRAWFORD!!! He is so hot, but in this movie his hair was kind of weird. But still hot.<br /><br />However, despite how hot CHACE is, it really did not make up for the film. I guess the plot isn't that bad but what really threw me over was the fact that they cuss in like every sentence. Is it that hard to express your anger without saying the F word every time?The cussing was annoying and the whole flashy, camera shaking thing gave me a headache.<br /><br />All in all, although the plot was OK, I found the film to be a bore and over dramatic. That's why I only cut to scenes with CHACE in it. LOL Anyways, not worth renting unless your a die-hard fan of a specific cast member like I was. Oh yeah the cast was Hot. The girls were HOT!!! But CHACE IS THE BEST!!""])
> tr_y=np.array(['pos','pos','neg'])
> te_x = np.array([""worst Movie"",""Nice one""])
> te_y = np.array(['bad','good'])
> ```
> 
> ### Expected Behavior
> ### Setup Details
> Include the details about the versions of:
> 
> * OS type and version:
> * Python: 3.7.9
> * autokeras:
> * keras-tuner:1.0.3
> * scikit-learn:0.23.2
> * numpy:1.18.5
> * pandas:1.1.5
> * tensorflow:2.3.0
> 
> ### Additional context
> I installed the following procedure for installation using anaconda prompt:
> 
> ```
> conda create -n env_autokeras
> conda activate env_autokeras
> conda install tensorflow
> pip install git+https://github.com/keras-team/keras-tuner.git
> pip install autokeras
> ```

I ran into the same error when I set the max_trials to 3.
However, it works well when I execute the code in Google Colab!.",bug description try run sample code text classifier error loading cloud system file system scheme file complete trace bug reproduction code bug import ak import data used code like adult comedy like south park nearly similar format small three teenage high given like think good leader also small going school idiotic principal nervous teacher many cast also fantastic henry smack pony doon dead mark perry blunder know came canada good good good movie basically skimmed movie enough catch watch plot tell truth kind boring make sense reason watched movie first place see hot movie hair kind weird still however despite hot really make film guess plot bad really threw fact cuss like every sentence hard express anger without saying word every time annoying whole flashy camera shaking thing gave although plot found film bore dramatic cut anyways worth unless fan specific cast member like oh yeah cast hot hot best worst movie nice one behavior setup include o type version python additional context following procedure installation anaconda prompt create activate install pip install pip install ran error set however work well execute code,issue,positive,positive,neutral,neutral,positive,positive
743792454,"
[python program.txt](https://github.com/keras-team/autokeras/files/5683501/python.program.txt)
[output1.txt](https://github.com/keras-team/autokeras/files/5683504/output1.txt)

Hi @haifeng-jin , I am not using notebook. I am using the python program shared here. I have even shared the output of the execution. I am using my own private dataset. Hence, can't share it. But, I can definitely provide few details about the dataset. It has 68,419 records. 68 features. The target feature has three classes. It is an imbalanced dataset. I have also run the pip freeze command. Its output is present in the bottom of the output file.

model = StructuredDataClassifier(max_trials = 300, project_name = ""structured_data_classifier"", objective = ""val_loss"")
model.fit(x = X_train, y = Y_train, validation_data=(X_test, Y_test), epochs = 1200, batch_size = 2770, class_weight = keras_class_weights, verbose = 2)

I have configured max-trials to 300 and epochs to 1200. After Trial 25 got completed, the next trial hit the epoch limit of 1200. Then, fit function stopped. It did not start a new trial. Hence, I feel there is a bug. This is not the expected behavior.

I have tried the same program with epoch=50 and max_trials=10, which are less than the default values, then it worked fine. This issue was not encountered. But, when I increased it to 1200, this issue occurred.",python hi notebook python program even output execution private hence ca share definitely provide target feature three class also run pip freeze command output present bottom output file model objective verbose trial got next trial hit epoch limit fit function stopped start new trial hence feel bug behavior tried program le default worked fine issue issue,issue,positive,positive,positive,positive,positive,positive
743705109,"Ok.

On Sat, Dec 12, 2020 at 1:45 AM Haifeng Jin <notifications@github.com>
wrote:

> The main factor for my decision is if we have enough people to use this
> feature. It will add maintenance burden to the team since the overall
> framework for AutoKeras is not stable yet. Any code can break as we modify
> the framework. Thank you again for your contribution. If we see many people
> request this feature, we will have it.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/keras-team/autokeras/pull/1433#issuecomment-743333100>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AEVLQ5W335BLP4EM5EXRQFTSUJLDFANCNFSM4TWC3CMQ>
> .
>
",sat wrote main factor decision enough people use feature add maintenance burden team since overall framework stable yet code break modify framework thank contribution see many people request feature reply directly view,issue,negative,positive,positive,positive,positive,positive
743333100,"The main factor for my decision is if we have enough people to use this feature. It will add maintenance burden to the team since the overall framework for AutoKeras is not stable yet. Any code can break as we modify the framework. Thank you again for your contribution. If we see many people request this feature, we will have it.",main factor decision enough people use feature add maintenance burden team since overall framework stable yet code break modify framework thank contribution see many people request feature,issue,negative,positive,positive,positive,positive,positive
743313268,"@andyDoucette Yeah, currently we have too many new features that are on going. Probably will reconsider after this batch is done.

I think your modifications to the docstrings are really good. If you don't mind, I will modify your commits and merge that part.",yeah currently many new going probably reconsider batch done think really good mind modify merge part,issue,positive,positive,positive,positive,positive,positive
743311133,May be you can try `auto_model.tuner.results_summary()`? We will have a better solution in the next few months by improving Keras Tuner.,may try better solution next improving tuner,issue,positive,positive,positive,positive,positive,positive
743302460,"Not really, but it support the same early stopping for epochs.",really support early stopping,issue,negative,positive,positive,positive,positive,positive
743301265,"Yes, but we don't have extra developers to work on it for now. This feature will be continued after object detection and time series data.",yes extra work feature continued object detection time series data,issue,negative,neutral,neutral,neutral,neutral,neutral
743047641,"I see.  You're just busy?  Don't have time to fully consider if these
changes will help or hurt the usefullness of the platform?  I just wanted
to do the pull request so others can benefit from my hard-fought path
toward a workable solution.  No one is going to find or trust my changes if
they're in a fork.  But I understand if you have limited time or energy to
consider things like this.  It's not a paid position. ;)  Take care, and
merry christmas!

On Fri, Dec 11, 2020 at 4:04 PM Haifeng Jin <notifications@github.com>
wrote:

> Thank you so much for the contribution! However, we are not aiming at
> support this feature for now since it requires some modifications to the
> framework. You are encouraged to have a fork.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/keras-team/autokeras/pull/1433#issuecomment-743040144>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AEVLQ5S22T7TASGJUF3WYNTSUHHAJANCNFSM4TWC3CMQ>
> .
>
",see busy time fully consider help hurt platform pull request benefit path toward workable solution one going find trust fork understand limited time energy consider like position take care merry wrote thank much contribution however aiming support feature since framework fork thread reply directly view,issue,positive,positive,neutral,neutral,positive,positive
743040144,"Thank you so much for the contribution! However, we are not aiming at support this feature for now since it requires some modifications to the framework. You are encouraged to have a fork. People who need this feature will use your fork for it. You can comment on the issue to direct them there.",thank much contribution however aiming support feature since framework fork people need feature use fork comment issue direct,issue,positive,positive,positive,positive,positive,positive
738701239,"Hello @haifeng-jin!

I have a problem in stuck `model.fit` execution with generators.

**Versions**
TensorFlow: 2.3.0
AutoKeras: 1.0.12
KerasTuner: 1.0.3

**Hardware**
Google Colab:
RAM 25 GB 
GPU Tesla V100-SXM2-16GB

But I would like to run it on my computer:
RAM 16 GB
GeForce GTX 1060 6GB

So generators are important for me also due to hardware restrictions.

**Data amount**
X_train.shape - (3466413, 18, 5)
X_train_steady.shape - (3466413, 1)
Y_lat_train.shape - (3466413, 10)
Y_lon_train.shape - (3466413, 10))
X_val.shape - (323931, 18, 5)
X_val_steady.shape - (323931, 1),
Y_lat_val.shape - (323931, 10)
Y_lon_val.shape - (323931, 10)

**Code**

Option 1
```
def make_gen_callable(x_data,
                      x_data_steady,
                      y_lat_data,
                      y_lon_data,
                      batch_size):
    def generator_shuffle():
        max_index = len(x_data) - 1
        while 1:
            rows = np.random.randint(0, max_index)
            x = (x_data[rows], x_data_steady[rows])
            y = (y_lat_data[rows], y_lon_data[rows])
            yield x, y
    return generator_shuffle

batch_size = 256

train_gen = make_gen_callable(X_train,
                              X_train_steady,
                              Y_lat_train,
                              Y_lon_train,
                              batch_size)

val_gen = make_gen_callable(X_val,
                             X_val_steady,
                             Y_lat_val,
                             Y_lon_val,
                             batch_size)

output_types = ((tf.float32, tf.float32), (tf.float32, tf.float32))

output_shapes = (([18, 5], [1]), ([10], [10]))

train_dataset = tf.data.Dataset.from_generator(
    train_gen,
    output_types=output_types,
    output_shapes=output_shapes,
).batch(batch_size).repeat()

val_dataset = tf.data.Dataset.from_generator(
    val_gen,
    output_types=output_types,
    output_shapes=output_shapes,
).batch(batch_size).repeat()
```
Option 2

```
def make_gen_callable(x_data,
                      x_data_steady,
                      y_lat_data,
                      y_lon_data,
                      batch_size):
    def generator_shuffle():
        max_index = len(x_data) - 1
        while 1:
            rows = np.random.randint(0, max_index)
            x = (x_data[rows], x_data_steady[rows])
            y = (y_lat_data[rows], y_lon_data[rows])
            yield x, y
    return generator_shuffle

batch_size = 256

train_gen = make_gen_callable(X_train,
                              X_train_steady,
                              Y_lat_train,
                              Y_lon_train,
                              batch_size)

val_gen = make_gen_callable(X_val,
                             X_val_steady,
                             Y_lat_val,
                             Y_lon_val,
                             batch_size)

output_types = ((tf.float32, tf.float32), (tf.float32, tf.float32))

output_shapes = (([None, 18, 5], [None, 1]), ([None, 10], [None, 10]))

train_dataset = tf.data.Dataset.from_generator(
    train_gen,
    output_types=output_types,
    output_shapes=output_shapes,
)

val_dataset = tf.data.Dataset.from_generator(
    val_gen,
    output_types=output_types,
    output_shapes=output_shapes,
)
```

In both cases I did not get the results even after 24 hours.

![image](https://user-images.githubusercontent.com/28987306/101150766-c1580280-3631-11eb-8ffd-a446d25cd4b0.png)

Without generators one can see the first results in output immediately.

Could you please help me with it?


",hello problem stuck execution hardware ram would like run computer ram important also due hardware data amount code option yield return option yield return none none none none get even image without one see first output immediately could please help,issue,positive,positive,positive,positive,positive,positive
738382624,"Hi , Can I have some help on the above please, 
Using tensorflow == 2.3.0 keras == 2.4.3
Thanks",hi help please thanks,issue,positive,positive,positive,positive,positive,positive
737527940,"This issue is not a bug in AutoKeras, but an error I made when creating my dataset. In case anyone encounters this issue, my dataset was read from a TFRecordFile and so the Tensors in it did not have an explicitly defined shape; this is fixed by calling [dataset.map](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map) and using the function [tf.ensure_shape](https://www.tensorflow.org/api_docs/python/tf/ensure_shape) in the map function to explicitly set the shape of the Tensors.",issue bug error made case anyone issue read explicitly defined shape fixed calling function map function explicitly set shape,issue,negative,positive,neutral,neutral,positive,positive
736521399,@haifeng-jin when there is a change in BertBlock it affect the BertTokenizer. Could you guide me here?,change affect could guide,issue,negative,neutral,neutral,neutral,neutral,neutral
735864901,Also interested in this issue - and is it applicable to other block types as well?,also interested issue applicable block well,issue,negative,positive,positive,positive,positive,positive
735046477,"Yes, It would be very nice if can able plot the losses and accuracies that we recorded during the training.
",yes would nice able plot training,issue,positive,positive,positive,positive,positive,positive
734694085,"@VictorReaver1999 I was also getting the ""Cannot take the length of shape with unknown rank"" error.  The issue is that autokeras.utils.data_utils.batched doesn't know what to do with the generator.  Since the generators in the example are indeed outputting batches, just monkey-patching this function to return True will get you up and running for now.

```
train_dataset = tf.data.Dataset.from_generator(lambda: callable_iterator(train_generator),output_types=(tf.float32, tf.float32))
val_dataset = tf.data.Dataset.from_generator(lambda: callable_iterator(val_generator),output_types=(tf.float32, tf.float32))

# Autokeras data_utils gets confused by the generator.
# Just let it know that the data is indeed batched.
ak.utils.data_utils.batched = lambda _: True

clf = ak.ImageRegressor(
    max_trials=args.max_trials,
    directory=args.save_model_dir)
```

**Update (above left for posterity):**

I found that there was a place downstream that was also failing in spite of the monkey-patch.  As I experimented with AutoKeras, I found a cleaner way that both clears the downstream error and avoids the ugly monkey-patching:
```
def callable_iterator(generator, expected_batch_size):
  for img_batch, targets_batch in generator:
    if img_batch.shape[0] == expected_batch_size:
      yield img_batch, targets_batch

train_dataset = tf.data.Dataset.from_generator(
    lambda: callable_iterator(train_generator, args.batch_size),
    output_types=(tf.float32, tf.float32),
    output_shapes=(tf.TensorShape([None, args.crop_size, args.crop_size, 1 if args.gray else 3]),
                   tf.TensorShape([None, 1])))
val_dataset = tf.data.Dataset.from_generator(
    lambda: callable_iterator(val_generator, args.batch_size),
    output_types=(tf.float32, tf.float32),
    output_shapes=(tf.TensorShape([None, args.crop_size, args.crop_size, 1 if args.gray else 3]),
                   tf.TensorShape([None, 1])))
```
Obviously the things starting with `args.` should be replaced with something appropriate to your code.

This surfaces the appropriate dimensions to the necessary places in AutoKeras.  AutoKeras does not behave well if you give it any incomplete batches, so I had to modify callable_iterator as above to reject incomplete batches from the iterator.",also getting take length shape unknown rank error issue know generator since example indeed function return true get running lambda lambda confused generator let know data indeed lambda true update left posterity found place downstream also failing spite experimented found cleaner way downstream error ugly generator generator yield lambda none else none lambda none else none obviously starting something appropriate code appropriate necessary behave well give incomplete modify reject incomplete,issue,negative,negative,neutral,neutral,negative,negative
731727338,"Hi @haifeng-jin  I faced the same bug in v1.0.10 and just tested with the v1.0.11 that you released 5 days ago. However, I still hit into the issue. Can you confirm that it's in the bugfix for v1.0.11?",hi faced bug tested day ago however still hit issue confirm,issue,negative,neutral,neutral,neutral,neutral,neutral
730444877,"> > > > @ciberger, this code seems to work, you can give a shot:
> > > > ```python
> > > > import tensorflow as tf
> > > > import numpy as np
> > > > import autokeras as ak
> > > > from tensorflow.keras.preprocessing import image
> > > > import pathlib
> > > > import matplotlib.pylab as plt
> > > > 
> > > > BATCH_SIZE = 32
> > > > IMG_HEIGHT = 224
> > > > IMG_WIDTH = 224
> > > > data_dir = tf.keras.utils.get_file(
> > > >   'flower_photos',
> > > >   'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',
> > > >   untar=True)
> > > > data_dir = pathlib.Path(data_dir)
> > > > #image_count = len(list(data_dir.glob('*/*.jpg')))
> > > > #STEPS_PER_EPOCH = np.ceil(image_count/BATCH_SIZE)
> > > > 
> > > > def preprocess(img):
> > > >     img = image.array_to_img(img, scale=False)
> > > >     img = img.resize((IMG_WIDTH, IMG_HEIGHT))
> > > >     img = image.img_to_array(img)
> > > >     return img / 255.0
> > > > 
> > > > image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,
> > > >                                               horizontal_flip=True,
> > > >                                               validation_split=0.2,
> > > >                                               preprocessing_function=preprocess)
> > > > 
> > > > train_generator = image_generator.flow_from_directory(
> > > >     directory=str(data_dir),
> > > >      batch_size=BATCH_SIZE,
> > > >      shuffle=True,
> > > >      #class_mode=""categorical"",
> > > >      target_size=(IMG_HEIGHT, IMG_WIDTH),
> > > >     subset='training'
> > > > )
> > > > 
> > > > val_generator = image_generator.flow_from_directory(
> > > >     directory=str(data_dir),
> > > >      batch_size=BATCH_SIZE,
> > > >      shuffle=True,
> > > >      #class_mode=""categorical"",
> > > >      target_size=(IMG_HEIGHT, IMG_WIDTH),
> > > >     subset='validation'
> > > > )
> > > > 
> > > > def callable_iterator(generator):
> > > >     for img_batch, targets_batch in generator:
> > > >         yield img_batch, targets_batch
> > > > 
> > > > train_dataset = tf.data.Dataset.from_generator(lambda: callable_iterator(train_generator),output_types=(tf.float32, tf.float32))
> > > > val_dataset = tf.data.Dataset.from_generator(lambda: callable_iterator(val_generator),output_types=(tf.float32, tf.float32))
> > > > 
> > > > for image, label in train_dataset.take(1):
> > > >   print(""Image shape: "", image.numpy().shape)
> > > >   print(""Label: "", label.numpy()[0])
> > > >   plt.imshow(image.numpy()[0].squeeze(axis=2) * 255)
> > > >   plt.show()
> > > > 
> > > > clf = ak.ImageClassifier(max_trials=10)
> > > > #Feed the tensorflow Dataset to the classifier.
> > > > clf.fit(train_dataset, epochs=60)
> > > > #Evaluate the best model.
> > > > print(clf.evaluate(val_dataset))
> > > > ```
> > > > 
> > > > 
> > > > Then you can feed your fit function with the tf.datasets
> > > 
> > > 
> > > Your example shows no output for me. I'm using google colab with GPU support and I have got it working before (albeit with bad predictive performance).
> > > UPDATE: I know the generator works when I test it using the adapted code above
> > > UPDATE: Tried on local machine and the same issue happens, TensorFlow 2.2.0, AutoKeras 1.0.2
> > > UPDATE: The problem is with AutoKeras [#1075 ](https://github.com/keras-team/autokeras/issues/1075#issuecomment-636543611)
> > 
> > 
> > Hi. I know this is several months late, but I am not getting any output just as you. What does it have to do with autokeras? The issue is with matplotlib since this is the library responsible for displaying the image. What am I missing? Thank you.
> 
> An AutoKeras contributor said so [here](https://github.com/keras-team/autokeras/issues/1075#issuecomment-649144273).
> 
> It could be what you said; it could also be something else.
> Why does it matter anyway? It works now.

Well, I am getting output now. But clf.fit isn't working (it says ValueError: Cannot take the length of shape with unknown rank. on line clf.fit(train_dataset, epochs=60) which is the same issue that abdulsam faced. What's the workaround? The link you gave doesn't really explain much, it is a base-case tutorial. ",code work give shot python import import import ak import image import import list return categorical categorical generator generator yield lambda lambda image label print image shape print label feed classifier evaluate best model print feed fit function example output support got working albeit bad predictive performance update know generator work test code update tried local machine issue update problem hi know several late getting output issue since library responsible image missing thank contributor said could said could also something else matter anyway work well getting output working take length shape unknown rank line issue faced link gave really explain much tutorial,issue,positive,negative,neutral,neutral,negative,negative
730228747,@haifeng-jin we need to re-open this one again. Also how do you feel about adding a checklist of blocks to do?,need one also feel,issue,negative,neutral,neutral,neutral,neutral,neutral
729694186,"> > > @ciberger, this code seems to work, you can give a shot:
> > > ```python
> > > import tensorflow as tf
> > > import numpy as np
> > > import autokeras as ak
> > > from tensorflow.keras.preprocessing import image
> > > import pathlib
> > > import matplotlib.pylab as plt
> > > 
> > > BATCH_SIZE = 32
> > > IMG_HEIGHT = 224
> > > IMG_WIDTH = 224
> > > data_dir = tf.keras.utils.get_file(
> > >   'flower_photos',
> > >   'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',
> > >   untar=True)
> > > data_dir = pathlib.Path(data_dir)
> > > #image_count = len(list(data_dir.glob('*/*.jpg')))
> > > #STEPS_PER_EPOCH = np.ceil(image_count/BATCH_SIZE)
> > > 
> > > def preprocess(img):
> > >     img = image.array_to_img(img, scale=False)
> > >     img = img.resize((IMG_WIDTH, IMG_HEIGHT))
> > >     img = image.img_to_array(img)
> > >     return img / 255.0
> > > 
> > > image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,
> > >                                               horizontal_flip=True,
> > >                                               validation_split=0.2,
> > >                                               preprocessing_function=preprocess)
> > > 
> > > train_generator = image_generator.flow_from_directory(
> > >     directory=str(data_dir),
> > >      batch_size=BATCH_SIZE,
> > >      shuffle=True,
> > >      #class_mode=""categorical"",
> > >      target_size=(IMG_HEIGHT, IMG_WIDTH),
> > >     subset='training'
> > > )
> > > 
> > > val_generator = image_generator.flow_from_directory(
> > >     directory=str(data_dir),
> > >      batch_size=BATCH_SIZE,
> > >      shuffle=True,
> > >      #class_mode=""categorical"",
> > >      target_size=(IMG_HEIGHT, IMG_WIDTH),
> > >     subset='validation'
> > > )
> > > 
> > > def callable_iterator(generator):
> > >     for img_batch, targets_batch in generator:
> > >         yield img_batch, targets_batch
> > > 
> > > train_dataset = tf.data.Dataset.from_generator(lambda: callable_iterator(train_generator),output_types=(tf.float32, tf.float32))
> > > val_dataset = tf.data.Dataset.from_generator(lambda: callable_iterator(val_generator),output_types=(tf.float32, tf.float32))
> > > 
> > > for image, label in train_dataset.take(1):
> > >   print(""Image shape: "", image.numpy().shape)
> > >   print(""Label: "", label.numpy()[0])
> > >   plt.imshow(image.numpy()[0].squeeze(axis=2) * 255)
> > >   plt.show()
> > > 
> > > clf = ak.ImageClassifier(max_trials=10)
> > > #Feed the tensorflow Dataset to the classifier.
> > > clf.fit(train_dataset, epochs=60)
> > > #Evaluate the best model.
> > > print(clf.evaluate(val_dataset))
> > > ```
> > > 
> > > 
> > > Then you can feed your fit function with the tf.datasets
> > 
> > 
> > Your example shows no output for me. I'm using google colab with GPU support and I have got it working before (albeit with bad predictive performance).
> > UPDATE: I know the generator works when I test it using the adapted code above
> > UPDATE: Tried on local machine and the same issue happens, TensorFlow 2.2.0, AutoKeras 1.0.2
> > UPDATE: The problem is with AutoKeras [#1075 ](https://github.com/keras-team/autokeras/issues/1075#issuecomment-636543611)
> 
> Hi. I know this is several months late, but I am not getting any output just as you. What does it have to do with autokeras? The issue is with matplotlib since this is the library responsible for displaying the image. What am I missing? Thank you.

An AutoKeras contributor said so [here](https://github.com/keras-team/autokeras/issues/1075#issuecomment-649144273).

It could be what you said; it could also be something else.
Why does it matter anyway? It works now.",code work give shot python import import import ak import image import import list return categorical categorical generator generator yield lambda lambda image label print image shape print label feed classifier evaluate best model print feed fit function example output support got working albeit bad predictive performance update know generator work test code update tried local machine issue update problem hi know several late getting output issue since library responsible image missing thank contributor said could said could also something else matter anyway work,issue,positive,positive,neutral,neutral,positive,positive
729666395,"> > @ciberger, this code seems to work, you can give a shot:
> > ```python
> > import tensorflow as tf
> > import numpy as np
> > import autokeras as ak
> > from tensorflow.keras.preprocessing import image
> > import pathlib
> > import matplotlib.pylab as plt
> > 
> > BATCH_SIZE = 32
> > IMG_HEIGHT = 224
> > IMG_WIDTH = 224
> > data_dir = tf.keras.utils.get_file(
> >   'flower_photos',
> >   'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',
> >   untar=True)
> > data_dir = pathlib.Path(data_dir)
> > #image_count = len(list(data_dir.glob('*/*.jpg')))
> > #STEPS_PER_EPOCH = np.ceil(image_count/BATCH_SIZE)
> > 
> > def preprocess(img):
> >     img = image.array_to_img(img, scale=False)
> >     img = img.resize((IMG_WIDTH, IMG_HEIGHT))
> >     img = image.img_to_array(img)
> >     return img / 255.0
> > 
> > image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,
> >                                               horizontal_flip=True,
> >                                               validation_split=0.2,
> >                                               preprocessing_function=preprocess)
> > 
> > train_generator = image_generator.flow_from_directory(
> >     directory=str(data_dir),
> >      batch_size=BATCH_SIZE,
> >      shuffle=True,
> >      #class_mode=""categorical"",
> >      target_size=(IMG_HEIGHT, IMG_WIDTH),
> >     subset='training'
> > )
> > 
> > val_generator = image_generator.flow_from_directory(
> >     directory=str(data_dir),
> >      batch_size=BATCH_SIZE,
> >      shuffle=True,
> >      #class_mode=""categorical"",
> >      target_size=(IMG_HEIGHT, IMG_WIDTH),
> >     subset='validation'
> > )
> > 
> > def callable_iterator(generator):
> >     for img_batch, targets_batch in generator:
> >         yield img_batch, targets_batch
> > 
> > train_dataset = tf.data.Dataset.from_generator(lambda: callable_iterator(train_generator),output_types=(tf.float32, tf.float32))
> > val_dataset = tf.data.Dataset.from_generator(lambda: callable_iterator(val_generator),output_types=(tf.float32, tf.float32))
> > 
> > for image, label in train_dataset.take(1):
> >   print(""Image shape: "", image.numpy().shape)
> >   print(""Label: "", label.numpy()[0])
> >   plt.imshow(image.numpy()[0].squeeze(axis=2) * 255)
> >   plt.show()
> > 
> > clf = ak.ImageClassifier(max_trials=10)
> > #Feed the tensorflow Dataset to the classifier.
> > clf.fit(train_dataset, epochs=60)
> > #Evaluate the best model.
> > print(clf.evaluate(val_dataset))
> > ```
> > 
> > 
> > Then you can feed your fit function with the tf.datasets
> 
> Your example shows no output for me. I'm using google colab with GPU support and I have got it working before (albeit with bad predictive performance).
> 
> UPDATE: I know the generator works when I test it using the adapted code above
> UPDATE: Tried on local machine and the same issue happens, TensorFlow 2.2.0, AutoKeras 1.0.2
> UPDATE: The problem is with AutoKeras [#1075 ](https://github.com/keras-team/autokeras/issues/1075#issuecomment-636543611)

Hi. I know this is several months late, but I am not getting any output just as you. What does it have to do with autokeras? The issue is with matplotlib since this is the library responsible for displaying the image. What am I missing? Thank you. ",code work give shot python import import import ak import image import import list return categorical categorical generator generator yield lambda lambda image label print image shape print label feed classifier evaluate best model print feed fit function example output support got working albeit bad predictive performance update know generator work test code update tried local machine issue update problem hi know several late getting output issue since library responsible image missing thank,issue,positive,positive,neutral,neutral,positive,positive
729658903,@lc0 Thank you. I will work on BertBlock and ConvBlock today and raise a PR in a day or 2.,thank work today raise day,issue,negative,neutral,neutral,neutral,neutral,neutral
728135764,"Is there any update on this issue ?
I'm facing the same problem as well",update issue facing problem well,issue,negative,neutral,neutral,neutral,neutral,neutral
727707802,"Looks like 3859af4a3597edc8be22a0807ba1fc858f12237b was the commit that broke it: 

ConvBlock: Adding num_filters as an option for when you need to have a certain number of channels to match an output image.

It seems that this commit somehow makes us lose a ""image_block_1/conv_block_1/filters_0_1"" hyperparameter.  That makes no sense to me yet.  The default of None should act precicely the same as the original code.  Can a dev take a look at this please?",like commit broke option need certain number match output image commit somehow u lose sense yet default none act original code dev take look please,issue,negative,positive,positive,positive,positive,positive
727553062,I honestly don't understand how anything I did could have broken tests/unit_tests/tuners/task_specific_test.py::test_img_clf_init_hp0_equals_hp_of_a_model.  Any thoughts there?,honestly understand anything could broken,issue,negative,positive,neutral,neutral,positive,positive
727542983,"There are some general improvements in here as well, and a commit that just changes commenting in the places I needed to fully understand the code.  Those comments may or may not be helpful to other people. Feel free to pick and choose which comments you think should get into the repo.",general well commit fully understand code may may helpful people feel free pick choose think get,issue,positive,positive,positive,positive,positive,positive
726414810,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1431?src=pr&el=h1) Report
> Merging [#1431](https://codecov.io/gh/keras-team/autokeras/pull/1431?src=pr&el=desc) (d22093e) into [master](https://codecov.io/gh/keras-team/autokeras/commit/d42ba3325059f93661f4f62fa841c8825edc59dd?el=desc) (d42ba33) will **not change** coverage.
> The diff coverage is `100.00%`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1431/graphs/tree.svg?width=650&height=150&src=pr&token=yDvddb2DDZ)](https://codecov.io/gh/keras-team/autokeras/pull/1431?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##            master     #1431    +/-   ##
==========================================
  Coverage   100.00%   100.00%            
==========================================
  Files           44        44            
  Lines         2777      3275   +498     
==========================================
+ Hits          2777      3275   +498     
```


| [Impacted Files](https://codecov.io/gh/keras-team/autokeras/pull/1431?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [autokeras/keras\_layers.py](https://codecov.io/gh/keras-team/autokeras/pull/1431/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2tlcmFzX2xheWVycy5weQ==) | `100.00% <100.00%> (ø)` | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1431?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1431?src=pr&el=footer). Last update [d42ba33...d22093e](https://codecov.io/gh/keras-team/autokeras/pull/1431?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",report de master change coverage coverage impacted file tree graph coverage master coverage impacted coverage continue review full report legend click learn absolute relative impact affected missing data powered last update de read comment,issue,negative,positive,neutral,neutral,positive,positive
726344101,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1430?src=pr&el=h1) Report
> Merging [#1430](https://codecov.io/gh/keras-team/autokeras/pull/1430?src=pr&el=desc) (22fa33e) into [master](https://codecov.io/gh/keras-team/autokeras/commit/0ff5e51fc622f02e1c434ad10642f03e36168433?el=desc) (0ff5e51) will **not change** coverage.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1430/graphs/tree.svg?width=650&height=150&src=pr&token=yDvddb2DDZ)](https://codecov.io/gh/keras-team/autokeras/pull/1430?src=pr&el=tree)

```diff
@@            Coverage Diff            @@
##            master     #1430   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           50        44    -6     
  Lines         2852      2777   -75     
=========================================
- Hits          2852      2777   -75     
```


| [Impacted Files](https://codecov.io/gh/keras-team/autokeras/pull/1430?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [autokeras/adapters/\_\_init\_\_.py](https://codecov.io/gh/keras-team/autokeras/pull/1430/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2FkYXB0ZXJzL19faW5pdF9fLnB5) | | |
| [autokeras/analysers/\_\_init\_\_.py](https://codecov.io/gh/keras-team/autokeras/pull/1430/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2FuYWx5c2Vycy9fX2luaXRfXy5weQ==) | | |
| [autokeras/tasks/\_\_init\_\_.py](https://codecov.io/gh/keras-team/autokeras/pull/1430/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL3Rhc2tzL19faW5pdF9fLnB5) | | |
| [autokeras/blocks/\_\_init\_\_.py](https://codecov.io/gh/keras-team/autokeras/pull/1430/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2Jsb2Nrcy9fX2luaXRfXy5weQ==) | | |
| [autokeras/tuners/\_\_init\_\_.py](https://codecov.io/gh/keras-team/autokeras/pull/1430/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL3R1bmVycy9fX2luaXRfXy5weQ==) | | |
| [autokeras/preprocessors/\_\_init\_\_.py](https://codecov.io/gh/keras-team/autokeras/pull/1430/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL3ByZXByb2Nlc3NvcnMvX19pbml0X18ucHk=) | | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1430?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1430?src=pr&el=footer). Last update [0ff5e51...157dc6c](https://codecov.io/gh/keras-team/autokeras/pull/1430?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",report fae master change coverage coverage impacted file tree graph coverage master coverage impacted coverage continue review full report legend click learn absolute relative impact affected missing data powered last update read comment,issue,negative,positive,neutral,neutral,positive,positive
726025054,"@dineshkumarsarangapani we can use this issue for coordination, so if you are taking any of the blocks, feel free to just mention it here",use issue taking feel free mention,issue,positive,positive,positive,positive,positive,positive
725591730,What else needs to be done in this pull request?,else need done pull request,issue,negative,neutral,neutral,neutral,neutral,neutral
723498797,@lc0 Great! Thank you. Let me know if you have any questions.,great thank let know,issue,positive,positive,positive,positive,positive,positive
723451420,@haifeng-jin I would be happy to take this one,would happy take one,issue,positive,positive,positive,positive,positive,positive
723204340,"This is a very important bug, I will look into this. Thanks.",important bug look thanks,issue,positive,positive,positive,positive,positive,positive
722688930,@haifeng-jin it looks like the linked PR was closed. Is this one still planned?,like linked closed one still,issue,negative,negative,neutral,neutral,negative,negative
722638936,"Also worth noting that documentation on the `docker run` command needs to be updated as well. In the new version the volumes are mounted differently. Whereas this worked with the previous image:

```
docker run -it -v ""$(pwd)"":/app --shm-size 2G garawalid/autokeras:latest python main.py
```

The new docker image...

```
docker run -it -v ""$(pwd)"":/app --shm-size 2G haifengjin/autokeras:latest python main.py
```

Fails:

```
python: can't open file './main.py': [Errno 2] No such file or directory
```",also worth documentation docker run command need well new version mounted differently whereas worked previous image docker run latest python new docker image docker run latest python python ca open file file directory,issue,negative,positive,positive,positive,positive,positive
722636587,May need to tweak some commands - only swapped the image reference thus far. ,may need tweak image reference thus far,issue,negative,positive,neutral,neutral,positive,positive
721693780,"@haifeng-jin , 
Thanks for updates.
when would retinanet be available.
Thanks in adavance!",thanks would available thanks,issue,positive,positive,positive,positive,positive,positive
721527016,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1415?src=pr&el=h1) Report
> Merging [#1415](https://codecov.io/gh/keras-team/autokeras/pull/1415?src=pr&el=desc) (538d554) into [master](https://codecov.io/gh/keras-team/autokeras/commit/cc0764cb41e40916fcda0cccc97c87fcbf6311fe?el=desc) (cc0764c) will **not change** coverage.
> The diff coverage is `100.00%`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1415/graphs/tree.svg?width=650&height=150&src=pr&token=yDvddb2DDZ)](https://codecov.io/gh/keras-team/autokeras/pull/1415?src=pr&el=tree)

```diff
@@            Coverage Diff            @@
##            master     #1415   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           50        50           
  Lines         2790      2804   +14     
=========================================
+ Hits          2790      2804   +14     
```


| [Impacted Files](https://codecov.io/gh/keras-team/autokeras/pull/1415?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [autokeras/tuners/greedy.py](https://codecov.io/gh/keras-team/autokeras/pull/1415/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL3R1bmVycy9ncmVlZHkucHk=) | `100.00% <100.00%> (ø)` | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1415?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1415?src=pr&el=footer). Last update [cc0764c...da052e8](https://codecov.io/gh/keras-team/autokeras/pull/1415?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",report master change coverage coverage impacted file tree graph coverage master coverage impacted coverage continue review full report legend click learn absolute relative impact affected missing data powered last update dae read comment,issue,negative,positive,neutral,neutral,positive,positive
721432309,"same error for me. It is quite weird as it is not always after X-epochs... sometimes the first sometimes after 30.

really looking forward to a fix if anybody has a solution",error quite weird always sometimes first sometimes really looking forward fix anybody solution,issue,negative,negative,neutral,neutral,negative,negative
721110962,@haifeng-jin This PR is ready for review. Please review.,ready review please review,issue,positive,positive,positive,positive,positive,positive
720199807,"Python generators are supported in 1.0.10 release.
Please refer to the tutorials here.
https://autokeras.com/tutorial/load/

Please let us know if it doesn't work for your case.",python release please refer please let u know work case,issue,positive,neutral,neutral,neutral,neutral,neutral
719999802,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1408?src=pr&el=h1) Report
> Merging [#1408](https://codecov.io/gh/keras-team/autokeras/pull/1408?src=pr&el=desc) into [master](https://codecov.io/gh/keras-team/autokeras/commit/6550f22d3c643715ed635b6c619442006990d8ed?el=desc) will **not change** coverage.
> The diff coverage is `100.00%`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1408/graphs/tree.svg?width=650&height=150&src=pr&token=yDvddb2DDZ)](https://codecov.io/gh/keras-team/autokeras/pull/1408?src=pr&el=tree)

```diff
@@            Coverage Diff            @@
##            master     #1408   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           50        50           
  Lines         2760      2785   +25     
=========================================
+ Hits          2760      2785   +25     
```


| [Impacted Files](https://codecov.io/gh/keras-team/autokeras/pull/1408?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [autokeras/blocks/basic.py](https://codecov.io/gh/keras-team/autokeras/pull/1408/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2Jsb2Nrcy9iYXNpYy5weQ==) | `100.00% <100.00%> (ø)` | |
| [autokeras/tuners/greedy.py](https://codecov.io/gh/keras-team/autokeras/pull/1408/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL3R1bmVycy9ncmVlZHkucHk=) | `100.00% <100.00%> (ø)` | |
| [autokeras/utils/utils.py](https://codecov.io/gh/keras-team/autokeras/pull/1408/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL3V0aWxzL3V0aWxzLnB5) | `100.00% <100.00%> (ø)` | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1408?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1408?src=pr&el=footer). Last update [6550f22...90f2e68](https://codecov.io/gh/keras-team/autokeras/pull/1408?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",report master change coverage coverage impacted file tree graph coverage master coverage impacted coverage continue review full report legend click learn absolute relative impact affected missing data powered last update fe read comment,issue,negative,positive,neutral,neutral,positive,positive
719998284,"I am closing this pr to create another pr with your commits.
You will still be recognized as a contributor.

Thanks.",create another still contributor thanks,issue,positive,positive,positive,positive,positive,positive
719381123,"> @dineshkumarsarangapani Is this PR ready for review? Thanks

@haifeng-jin yes it is ready for review.Thanks.",ready review thanks yes ready,issue,positive,positive,positive,positive,positive,positive
719111418,"yes understood now
Actually if we do prediction after exporting the model it returns probabiility

model1.fit(x,y)
model1.predict -> returns classes

model_export = model1.export_model()
model_export.predict -> return probability

Thanks",yes understood actually prediction model class return probability thanks,issue,positive,positive,neutral,neutral,positive,positive
719057067,"We won't support the `predict_proba` function directly.
The users should use the exported Keras model as an work around.",wo support function directly use model work around,issue,negative,positive,neutral,neutral,positive,positive
717914619,"> > > I really haven't seen this error before.
> > > Would you try the same code running without GPU? Just mask the GPU out using env var.
> > 
> > 
> > Sorry, I'm a total stranger and amateur, so I can't understand which file for me to manipulate. For instance, ""config.py"" in a certain folder?
> 
> Sorry again, I managed to run the codes on CPU.
> Yes, it worked only 1 epoch, but then, the error message of ""Function call stack: train_function"" appeared and stopped.

The actual cause seems in connection with KerasTuner.  The error message in detail is below:

tensorflow.python.framework.errors_impl.UnimplementedError:  Cast double to string is not supported
	 [[node functional_1/Cast (defined at C:\Users\Admin\AppData\Roaming\Python\Python37\site-packages\kerastuner\engine\tuner.py:142) ]] [Op:__inference_train_function_50491]

Function call stack:
train_function
---
All the data used are converted into float32 and there is not a string data and/or columns with string data type.  I wonder what's wrong with this.  And I guess this issue is far from what originally made me in trouble.",really seen error would try code running without mask sorry total stranger amateur ca understand file manipulate instance certain folder sorry run yes worked epoch error message function call stack stopped actual cause connection error message detail cast double string node defined function call stack data used converted float string data string data type wonder wrong guess issue far originally made trouble,issue,negative,negative,neutral,neutral,negative,negative
717323437,"@dcohron to display the architecture of the best model I found I could do the next:

```
# 1. export the model:
model = clf.export_model()

# 2. Ask for the model Sumary:
model.summary()
```

if you add this at the end of the AutoKeras code, you'll be able to see the architecture of the model in the Terminal.

I got the following message for a random trial I did:
 ```
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 84)]              0         
_________________________________________________________________
multi_category_encoding (Mul (None, 84)                0         
_________________________________________________________________
normalization (Normalization (None, 84)                169       
_________________________________________________________________
dense (Dense)                (None, 512)               43520     
_________________________________________________________________
batch_normalization (BatchNo (None, 512)               2048      
_________________________________________________________________
re_lu (ReLU)                 (None, 512)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 32)                16416     
_________________________________________________________________
batch_normalization_1 (Batch (None, 32)                128       
_________________________________________________________________
re_lu_1 (ReLU)               (None, 32)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 101)               3333      
_________________________________________________________________
classification_head_1 (Softm (None, 101)               0         
=================================================================
Total params: 65,614
Trainable params: 64,357
Non-trainable params: 1,257
_________________________________________________________________
```

This doesn't solve the problem about loading the best model but at least it gives you the opportunity to recreate the best model 
 architecture on tensorflow by yourself, which gives much less problems. I hope this is helpful :)",display architecture best model found could next export model model ask model add end code able see architecture model terminal got following message random trial layer type output shape param none none normalization normalization none dense dense none none none dense none batch none none dense none none total trainable solve problem loading best model least opportunity recreate best model architecture much le hope helpful,issue,positive,positive,positive,positive,positive,positive
717280571,"> @dcohron not related to the question, but I've also encountered the same problem when using custom metrics. I kind of solved it using an answer from another [issue](https://github.com/keras-team/autokeras/issues/1257#issuecomment-674132595).

This doesn't seem to work for me, I keep getting the same error:

Traceback (most recent call last):
  File ""/home/a/Documents/Sign_recognition/venv/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py"", line 417, in _revive_layer_from_config
    generic_utils.serialize_keras_class_and_config(class_name, config))
  File ""/home/a/Documents/Sign_recognition/venv/lib/python3.7/site-packages/tensorflow/python/keras/layers/serialization.py"", line 175, in deserialize
    printable_module_name='layer')
  File ""/home/a/Documents/Sign_recognition/venv/lib/python3.7/site-packages/tensorflow/python/keras/utils/generic_utils.py"", line 347, in deserialize_keras_object
    config, module_objects, custom_objects, printable_module_name)
  File ""/home/a/Documents/Sign_recognition/venv/lib/python3.7/site-packages/tensorflow/python/keras/utils/generic_utils.py"", line 296, in class_and_config_for_serialized_keras_object
    raise ValueError('Unknown ' + printable_module_name + ': ' + class_name)
ValueError: Unknown layer: Custom>MultiCategoryEncoding

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""ASL_recognition1.py"", line 48, in <module>
    model = tf.keras.models.load_model('/home/a/Documents/autokeras/structured_data_classifier/best_model')
  File ""/home/a/Documents/Sign_recognition/venv/lib/python3.7/site-packages/tensorflow/python/keras/saving/save.py"", line 187, in load_model
    return saved_model_load.load(filepath, compile, options)
  File ""/home/a/Documents/Sign_recognition/venv/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py"", line 121, in load
    path, options=options, loader_cls=KerasObjectLoader)
  File ""/home/a/Documents/Sign_recognition/venv/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py"", line 633, in load_internal
    ckpt_options)
  File ""/home/a/Documents/Sign_recognition/venv/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py"", line 194, in __init__
    super(KerasObjectLoader, self).__init__(*args, **kwargs)
  File ""/home/a/Documents/Sign_recognition/venv/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py"", line 130, in __init__
    self._load_all()
  File ""/home/a/Documents/Sign_recognition/venv/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py"", line 215, in _load_all
    self._layer_nodes = self._load_layers()
  File ""/home/a/Documents/Sign_recognition/venv/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py"", line 315, in _load_layers
    layers[node_id] = self._load_layer(proto.user_object, node_id)
  File ""/home/a/Documents/Sign_recognition/venv/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py"", line 341, in _load_layer
    obj, setter = self._revive_from_config(proto.identifier, metadata, node_id)
  File ""/home/a/Documents/Sign_recognition/venv/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py"", line 359, in _revive_from_config
    self._revive_layer_from_config(metadata, node_id))
  File ""/home/a/Documents/Sign_recognition/venv/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py"", line 428, in _revive_layer_from_config
    'call.'.format(cls=class_name))
RuntimeError: Unable to restore a layer of class Custom>MultiCategoryEncoding. Layers of class Custom>MultiCategoryEncoding require that the class be provided to the model loading code, either by registering the class using @keras.utils.register_keras_serializable on the class def and including that file in your program, or by passing the class in a keras.utils.CustomObjectScope that wraps this load call.",related question also problem custom metric kind answer another issue seem work keep getting error recent call last file line file line file line file line raise unknown layer custom handling exception another exception recent call last file line module model file line return compile file line load path file line file line super self file line file line file line file line setter file line file line unable restore layer class custom class custom require class provided model loading code either class class file program passing class load call,issue,positive,positive,neutral,neutral,positive,positive
717045517,"I will raise a new PR with clean branch
",raise new clean branch,issue,negative,positive,positive,positive,positive,positive
716971413,How long will it take to fix the bug? ,long take fix bug,issue,negative,negative,neutral,neutral,negative,negative
716534976,"> > I really haven't seen this error before.
> > Would you try the same code running without GPU? Just mask the GPU out using env var.
> 
> Sorry, I'm a total stranger and amateur, so I can't understand which file for me to manipulate. For instance, ""config.py"" in a certain folder?

Sorry again, I managed to run the codes on CPU.
Yes, it worked only 1 epoch, but then, the error message of ""Function call stack: train_function"" appeared and stopped.",really seen error would try code running without mask sorry total stranger amateur ca understand file manipulate instance certain folder sorry run yes worked epoch error message function call stack stopped,issue,negative,negative,negative,negative,negative,negative
716515243,"> I really haven't seen this error before.
> Would you try the same code running without GPU? Just mask the GPU out using env var.

Sorry, I'm a total stranger and amateur, so I can't understand which file for me to manipulate.  For instance, ""config.py"" in a certain folder?
",really seen error would try code running without mask sorry total stranger amateur ca understand file manipulate instance certain folder,issue,negative,negative,neutral,neutral,negative,negative
716032156,"@haifeng-jin thanks again. Unfortunately, it looks like there's still an issue kicking around. After running 

```from sklearn.datasets import load_breast_cancer

from tensorflow.keras.callbacks import Callback, EarlyStopping, ModelCheckpoint
from tensorflow.python.platform import tf_logging as logging
from sklearn import datasets, svm, metrics
from sklearn.model_selection import train_test_split, KFold, StratifiedKFold
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, cohen_kappa_score, matthews_corrcoef, log_loss
import matplotlib.pyplot as plt, pandas as pd, numpy as np, matplotlib as mpl
import requests, time, re, os, subprocess, json, sys, datetime

import autokeras as ak
import keras.backend as K

from IPython.display import clear_output
%matplotlib inline

x, y = load_breast_cancer(return_X_y=True)
xTrain, xTest, yTrain, yTest = train_test_split(x, y, random_state=0)

MAXTRIALS = 600
inputNode = ak.StructuredDataInput()
outputNode = ak.StructuredDataBlock(categorical_encoding=True)(inputNode)
outputNode = ak.ClassificationHead(num_classes=2)(outputNode)

clf = ak.AutoModel(
    inputNode, 
    outputNode, 
    overwrite=True,
    objective=""val_loss"",
    max_trials=MAXTRIALS)

clf.fit(xTrain, yTrain) #metrics=[matthewsCorrelation],
    
predictedClasses = clf.predict(xTest)

cm = confusion_matrix(yTest, predictedClasses)

print(cm)

matthew = matthews_corrcoef(yTest, predictedClasses)

print('MCC:', matthew)
```

I run 

```
models = clf.tuner.get_best_models(num_models=66) #Or whatever the actual number of trials is
len(models)
```

and this yields the error

```
WARNING:tensorflow:Layer multi_category_encoding is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.

If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.

To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.

WARNING:tensorflow:Layer multi_category_encoding is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.

If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.

To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.

WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate
WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
/usr/local/lib/python3.8/site-packages/tensorflow/python/training/py_checkpoint_reader.py in NewCheckpointReader(filepattern)
     94   try:
---> 95     return CheckpointReader(compat.as_bytes(filepattern))
     96   # TODO(b/143319754): Remove the RuntimeError casting logic once we resolve the

RuntimeError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ./auto_model/trial_3a5d4cfec8ed6d7bd8418be44da0b7af/checkpoints/epoch_5/checkpoint

During handling of the above exception, another exception occurred:

NotFoundError                             Traceback (most recent call last)
<ipython-input-4-36dfe1721b50> in <module>
----> 1 models = clf.tuner.get_best_models(num_models=10)
      2 len(models)

/usr/local/lib/python3.8/site-packages/kerastuner/engine/tuner.py in get_best_models(self, num_models)
    263         """"""
    264         # Method only exists in this class for the docstring override.
--> 265         return super(Tuner, self).get_best_models(num_models)
    266 
    267     def _deepcopy_callbacks(self, callbacks):

/usr/local/lib/python3.8/site-packages/kerastuner/engine/base_tuner.py in get_best_models(self, num_models)
    238         """"""
    239         best_trials = self.oracle.get_best_trials(num_models)
--> 240         models = [self.load_model(trial) for trial in best_trials]
    241         return models
    242 

/usr/local/lib/python3.8/site-packages/kerastuner/engine/base_tuner.py in <listcomp>(.0)
    238         """"""
    239         best_trials = self.oracle.get_best_trials(num_models)
--> 240         models = [self.load_model(trial) for trial in best_trials]
    241         return models
    242 

/usr/local/lib/python3.8/site-packages/kerastuner/engine/tuner.py in load_model(self, trial)
    188         best_epoch = trial.best_step
    189         with hm_module.maybe_distribute(self.distribution_strategy):
--> 190             model.load_weights(self._get_checkpoint_fname(
    191                 trial.trial_id, best_epoch))
    192         return model

/usr/local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py in load_weights(self, filepath, by_name, skip_mismatch, options)
   2174     else:
   2175       try:
-> 2176         py_checkpoint_reader.NewCheckpointReader(filepath)
   2177         save_format = 'tf'
   2178       except errors_impl.DataLossError:

/usr/local/lib/python3.8/site-packages/tensorflow/python/training/py_checkpoint_reader.py in NewCheckpointReader(filepattern)
     97   # issue with throwing python exceptions from C++.
     98   except RuntimeError as e:
---> 99     error_translator(e)

/usr/local/lib/python3.8/site-packages/tensorflow/python/training/py_checkpoint_reader.py in error_translator(e)
     33       'Failed to find any '
     34       'matching files for') in error_message:
---> 35     raise errors_impl.NotFoundError(None, None, error_message)
     36   elif 'Sliced checkpoints are not supported' in error_message or (
     37       'Data type '

NotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ./auto_model/trial_3a5d4cfec8ed6d7bd8418be44da0b7af/checkpoints/epoch_5/checkpoint
```

Now, I thought this was just the off-by-1 error from before, but when I looked for the file, there is an ""epoch_5"" folder, but it's strangely empty. The other folder of epochs have checkpoint files.",thanks unfortunately like still issue kicking around running import import import logging import metric import import import import import time o import ak import import print print run whatever actual number error warning layer casting input tensor float layer float new behavior layer float intended run layer float safely ignore warning doubt warning likely issue model change float default call change layer pas layer constructor author layer disable passing base layer constructor warning layer casting input tensor float layer float new behavior layer float intended run layer float safely ignore warning doubt warning likely issue model change float default call change layer pas layer constructor author layer disable passing base layer constructor warning unresolved object root warning unresolved object root warning unresolved object root warning unresolved object root warning unresolved object root warning used see specific use load status object silence use make check explicit see recent call last try return remove casting logic resolve unsuccessful constructor find matching handling exception another exception recent call last module self method class override return super tuner self self self trial trial return trial trial return self trial return model self else try except issue throwing python except find raise none none type unsuccessful constructor find matching thought error file folder strangely empty folder,issue,negative,negative,neutral,neutral,negative,negative
715887070,"@haifeng-jin i have few more patches ready. If this is fine, I can give PR's for the rest.",ready fine give rest,issue,positive,positive,positive,positive,positive,positive
715600035,"Keras predict function returns probabilities
Autokeras returning classes

Are you saying autokeras supports this or suggesting this has to be included",predict function class saying suggesting included,issue,negative,neutral,neutral,neutral,neutral,neutral
715425602,"No, the only way is to change the code in Keras Tuner by yourself. You may locate the code by searching the keyword ""Best Value So Far""",way change code tuner may locate code searching best value far,issue,positive,positive,positive,positive,positive,positive
715422887,The usage of this class is a little bit tricky. You may refer to https://github.com/keras-team/autokeras/blob/master/tests/integration_tests/task_api_test.py#L105,usage class little bit tricky may refer,issue,negative,negative,negative,negative,negative,negative
715421709,"For all advanced usages like this, we would like the users to rely on export_model and the Keras model should support everything they want.",advanced like would like rely model support everything want,issue,positive,positive,positive,positive,positive,positive
715420792,"I think I understand the bug. It is caused by the NaN value in validation loss which is the metric for evaluation.
We will need to handle it in Keras Tuner.",think understand bug nan value validation loss metric evaluation need handle tuner,issue,negative,neutral,neutral,neutral,neutral,neutral
715354840,"@haifeng-jin Thanks, it's fixed. This seems like a stupid question, but is there a simple way to change the width of the ""Hyperparameter |Value |Best Value So Far"" table so that the name of the hyperparameter doesn't get truncated?",thanks fixed like stupid question simple way change width value far table name get truncated,issue,positive,negative,neutral,neutral,negative,negative
714808703,"what are you installing with pip, just autokeras?   `pip install autokeras` ?  you get the error when running this? ",pip pip install get error running,issue,negative,neutral,neutral,neutral,neutral,neutral
714770529,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1396?src=pr&el=h1) Report
> Merging [#1396](https://codecov.io/gh/keras-team/autokeras/pull/1396?src=pr&el=desc) into [master](https://codecov.io/gh/keras-team/autokeras/commit/fa872c7f33482f046f0fe76b44b46db2faa67e04?el=desc) will **not change** coverage.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1396/graphs/tree.svg?width=650&height=150&src=pr&token=yDvddb2DDZ)](https://codecov.io/gh/keras-team/autokeras/pull/1396?src=pr&el=tree)

```diff
@@            Coverage Diff            @@
##            master     #1396   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           50        50           
  Lines         2704      2704           
=========================================
  Hits          2704      2704           
```


| [Impacted Files](https://codecov.io/gh/keras-team/autokeras/pull/1396?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [autokeras/auto\_model.py](https://codecov.io/gh/keras-team/autokeras/pull/1396/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2F1dG9fbW9kZWwucHk=) | `100.00% <ø> (ø)` | |
| [autokeras/tasks/image.py](https://codecov.io/gh/keras-team/autokeras/pull/1396/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL3Rhc2tzL2ltYWdlLnB5) | `100.00% <ø> (ø)` | |
| [autokeras/tasks/structured\_data.py](https://codecov.io/gh/keras-team/autokeras/pull/1396/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL3Rhc2tzL3N0cnVjdHVyZWRfZGF0YS5weQ==) | `100.00% <ø> (ø)` | |
| [autokeras/tasks/text.py](https://codecov.io/gh/keras-team/autokeras/pull/1396/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL3Rhc2tzL3RleHQucHk=) | `100.00% <ø> (ø)` | |
| [autokeras/tasks/time\_series\_forecaster.py](https://codecov.io/gh/keras-team/autokeras/pull/1396/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL3Rhc2tzL3RpbWVfc2VyaWVzX2ZvcmVjYXN0ZXIucHk=) | `100.00% <ø> (ø)` | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1396?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1396?src=pr&el=footer). Last update [fa872c7...03de858](https://codecov.io/gh/keras-team/autokeras/pull/1396?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",report master change coverage coverage impacted file tree graph coverage master coverage impacted coverage continue review full report legend click learn absolute relative impact affected missing data powered last update de read comment,issue,negative,positive,neutral,neutral,positive,positive
713516736,"I found this in the gpu support for tensorflow:

On systems with NVIDIA® Ampere GPUs (CUDA architecture 8.0) or newer, kernels are JIT-compiled from PTX and TensorFlow can take over 30 minutes to start up. This overhead can be limited to the first start up by increasing the default JIT cache size with: 'export CUDA_CACHE_MAXSIZE=2147483648' (see JIT Caching for details).

maybe that's the reason why it is slower in the case of the NVIDIA RTX 3080.

Anyway I'm not very experienced and I don't have a clue of what this JIT thing is or how can I change it...",found support registered ampere architecture take start overhead limited first start increasing default cache size see maybe reason case anyway experienced clue thing change,issue,negative,positive,positive,positive,positive,positive
713415894,"@haifeng-jin, it is difficult to provide a colab because it depends on the training parameters choosen by keras-tuner and autokeras. 

All I know is that the exception ""ValueError"" is catched in kerastuner/tuners/bayesians.py in _populate_space function.

Below an example of a trial JSON that causes the error (you can see that some values are NaN) :

{""trial_id"": ""5e9e66472f6f827a8a4b5b8286adb365"", ""hyperparameters"": {""space"": [{""class_name"": ""Boolean"", ""config"": {""name"": ""structured_data_block_1/normalize"", ""default"": false, ""conditions"": []}}, {""class_name"": ""Choice"", ""config"": {""name"": ""structured_data_block_1/dense_block_1/num_layers"", ""default"": 2, ""conditions"": [], ""values"": [1, 2, 3], ""ordered"": true}}, {""class_name"": ""Boolean"", ""config"": {""name"": ""structured_data_block_1/dense_block_1/use_batchnorm"", ""default"": false, ""conditions"": []}}, {""class_name"": ""Choice"", ""config"": {""name"": ""structured_data_block_1/dense_block_1/dropout"", ""default"": 0, ""conditions"": [], ""values"": [0.0, 0.25, 0.5], ""ordered"": true}}, {""class_name"": ""Choice"", ""config"": {""name"": ""structured_data_block_1/dense_block_1/units_0"", ""default"": 32, ""conditions"": [], ""values"": [16, 32, 64, 128, 256, 512, 1024], ""ordered"": true}}, {""class_name"": ""Choice"", ""config"": {""name"": ""structured_data_block_1/dense_block_1/units_1"", ""default"": 32, ""conditions"": [], ""values"": [16, 32, 64, 128, 256, 512, 1024], ""ordered"": true}}, {""class_name"": ""Choice"", ""config"": {""name"": ""regression_head_1/dropout"", ""default"": 0, ""conditions"": [], ""values"": [0.0, 0.25, 0.5], ""ordered"": true}}, {""class_name"": ""Choice"", ""config"": {""name"": ""optimizer"", ""default"": ""adam"", ""conditions"": [], ""values"": [""adam"", ""sgd"", ""adam_weight_decay""], ""ordered"": false}}, {""class_name"": ""Choice"", ""config"": {""name"": ""learning_rate"", ""default"": 0.001, ""conditions"": [], ""values"": [0.1, 0.01, 0.001, 0.0001, 2e-05, 1e-05], ""ordered"": true}}, {""class_name"": ""Choice"", ""config"": {""name"": ""structured_data_block_1/dense_block_1/units_2"", ""default"": 32, ""conditions"": [], ""values"": [16, 32, 64, 128, 256, 512, 1024], ""ordered"": true}}], ""values"": {""structured_data_block_1/normalize"": false, ""structured_data_block_1/dense_block_1/num_layers"": 3, ""structured_data_block_1/dense_block_1/use_batchnorm"": false, ""structured_data_block_1/dense_block_1/dropout"": 0.5, ""structured_data_block_1/dense_block_1/units_0"": 256, ""structured_data_block_1/dense_block_1/units_1"": 64, ""regression_head_1/dropout"": 0.25, ""optimizer"": ""sgd"", ""learning_rate"": 0.1, ""structured_data_block_1/dense_block_1/units_2"": 64}}, ""metrics"": {""metrics"": {""loss"": {""direction"": ""min"", ""observations"": [{""value"": [NaN], ""step"": 0}]}, ""mean_squared_error"": {""direction"": ""min"", ""observations"": [{""value"": [NaN], ""step"": 0}]}, ""val_loss"": {""direction"": ""min"", ""observations"": [{""value"": [NaN], ""step"": 0}]}, ""val_mean_squared_error"": {""direction"": ""min"", ""observations"": [{""value"": [NaN], ""step"": 0}]}}}, ""score"": NaN, ""best_step"": null, ""status"": ""COMPLETED""}",difficult provide training know exception function example trial error see nan space name default false choice name default ordered true name default false choice name default ordered true choice name default ordered true choice name default ordered true choice name default ordered true choice name default ordered false choice name default ordered true choice name default ordered true false false metric metric loss direction min value nan step direction min value nan step direction min value nan step direction min value nan step score nan null status,issue,positive,negative,neutral,neutral,negative,negative
713319008,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1394?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) Report
> Merging [#1394](https://codecov.io/gh/keras-team/autokeras/pull/1394?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) (258b084) into [master](https://codecov.io/gh/keras-team/autokeras/commit/0d22c6f6a611cdfc017a24c28c68e7925b7f7feb?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) (0d22c6f) will **decrease** coverage by `7.45%`.
> The diff coverage is `26.92%`.

> :exclamation: Current head 258b084 differs from pull request most recent head 0a17101. Consider uploading reports for the commit 0a17101 to get more accurate results
[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1394/graphs/tree.svg?width=650&height=150&src=pr&token=yDvddb2DDZ&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)](https://codecov.io/gh/keras-team/autokeras/pull/1394?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)

```diff
@@             Coverage Diff             @@
##            master    #1394      +/-   ##
===========================================
- Coverage   100.00%   92.54%   -7.46%     
===========================================
  Files           51       50       -1     
  Lines         3406     3070     -336     
===========================================
- Hits          3406     2841     -565     
- Misses           0      229     +229     
```


| [Impacted Files](https://codecov.io/gh/keras-team/autokeras/pull/1394?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) | Coverage Δ | |
|---|---|---|
| [autokeras/keras\_layers.py](https://codecov.io/gh/keras-team/autokeras/pull/1394/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL2tlcmFzX2xheWVycy5weQ==) | `47.86% <17.93%> (-52.14%)` | :arrow_down: |
| [autokeras/blocks/basic.py](https://codecov.io/gh/keras-team/autokeras/pull/1394/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL2Jsb2Nrcy9iYXNpYy5weQ==) | `95.91% <22.22%> (-4.09%)` | :arrow_down: |
| [autokeras/blocks/heads.py](https://codecov.io/gh/keras-team/autokeras/pull/1394/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL2Jsb2Nrcy9oZWFkcy5weQ==) | `91.03% <31.57%> (-8.97%)` | :arrow_down: |
| [autokeras/preprocessors/encoders.py](https://codecov.io/gh/keras-team/autokeras/pull/1394/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL3ByZXByb2Nlc3NvcnMvZW5jb2RlcnMucHk=) | `71.18% <39.28%> (-28.82%)` | :arrow_down: |
| [autokeras/pipeline.py](https://codecov.io/gh/keras-team/autokeras/pull/1394/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL3BpcGVsaW5lLnB5) | `99.03% <94.11%> (-0.97%)` | :arrow_down: |
| [autokeras/auto\_model.py](https://codecov.io/gh/keras-team/autokeras/pull/1394/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL2F1dG9fbW9kZWwucHk=) | `100.00% <100.00%> (ø)` | |
| [autokeras/graph.py](https://codecov.io/gh/keras-team/autokeras/pull/1394/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL2dyYXBoLnB5) | `99.47% <100.00%> (-0.53%)` | :arrow_down: |
| [autokeras/preprocessors/\_\_init\_\_.py](https://codecov.io/gh/keras-team/autokeras/pull/1394/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL3ByZXByb2Nlc3NvcnMvX19pbml0X18ucHk=) | `100.00% <100.00%> (ø)` | |
| [autokeras/nodes.py](https://codecov.io/gh/keras-team/autokeras/pull/1394/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team#diff-YXV0b2tlcmFzL25vZGVzLnB5) | `100.00% <0.00%> (ø)` | |
| ... and [15 more](https://codecov.io/gh/keras-team/autokeras/pull/1394/diff?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team) | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1394?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1394?src=pr&el=footer&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team). Last update [0d22c6f...0a17101](https://codecov.io/gh/keras-team/autokeras/pull/1394?src=pr&el=lastupdated&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=keras-team).
",report master decrease coverage coverage exclamation current head pull request recent head consider commit get accurate impacted file tree graph coverage master coverage impacted coverage continue review full report legend click learn absolute relative impact affected missing data powered last update read comment,issue,negative,positive,neutral,neutral,positive,positive
713166031,"It should have just been fixed in AutoKeras 1.0.10.
You may try again with the latest release.
Remember to update Keras Tuner.
pip3 install git+https://github.com/keras-team/keras-tuner.git@1.0.2rc3",fixed may try latest release remember update tuner pip install,issue,negative,positive,positive,positive,positive,positive
713165214,"I really haven't seen this error before.
Would you try the same code running without GPU? Just mask the GPU out using env var.",really seen error would try code running without mask,issue,negative,positive,positive,positive,positive,positive
713163608,"You don't need to create a new object. You just run the same .py file again.
If you want to create a new object, please make sure all the configs remains the same as the previous one.",need create new object run file want create new object please make sure remains previous one,issue,positive,positive,positive,positive,positive,positive
713162662,"@mklosi Thank you! you need to fork the repo and make the changes in your fork.
Then pull request the our repo.

Thanks",thank need fork make fork pull request thanks,issue,positive,positive,positive,positive,positive,positive
713161236,"Would you paste the error of how it doesn't run after load?
You can try to change the data type to string before feeding to the model.",would paste error run load try change data type string feeding model,issue,negative,neutral,neutral,neutral,neutral,neutral
713160082,"I am not sure why it cannot remove the dir.
Keras Tuner would always remove some dir to save disk space during the search.
It runs fine in my computer.",sure remove tuner would always remove save disk space search fine computer,issue,positive,positive,positive,positive,positive,positive
713159226,"It was not the last trial, it is actually the final fit.
We will always retrain the model if you specifies the epochs.

If you want to get that model, you can use `clf.tuner.get_best_models(3)`.",last trial actually final fit always retrain model want get model use,issue,negative,positive,positive,positive,positive,positive
713156633,"OK. I got why this error exists.
I have submitted a PR to keras tuner. https://github.com/keras-team/keras-tuner/pull/424
It is for fixing the no such file or directory error.

And for the error of `UnimplementedError:  Cast double to string is not supported`,
you can try AutoKeras 1.0.10.
If it still exists, please cast your data as a numpy array with dtype string before passing it to the predict function.

It should solve the problem.",got error tuner fixing file directory error error cast double string try still please cast data array string passing predict function solve problem,issue,negative,neutral,neutral,neutral,neutral,neutral
713126944,@lusob I have merged your commits in another pull request. You can check the current master for your contribution. Thank you!,another pull request check current master contribution thank,issue,negative,neutral,neutral,neutral,neutral,neutral
713108030,"> The PR looks good to me. However, it the conflicts needs to be resolved before merging. Thanks.

Hi @haifeng-jin, I can't see any conflicts, could you please let me know where I can see them? 

",good however need resolved thanks hi ca see could please let know see,issue,positive,positive,positive,positive,positive,positive
713056110,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1391?src=pr&el=h1) Report
> Merging [#1391](https://codecov.io/gh/keras-team/autokeras/pull/1391?src=pr&el=desc) into [master](https://codecov.io/gh/keras-team/autokeras/commit/d902b4f964ae0b8f42a3101b02cb7fe2a3cacc33?el=desc) will **not change** coverage.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1391/graphs/tree.svg?width=650&height=150&src=pr&token=yDvddb2DDZ)](https://codecov.io/gh/keras-team/autokeras/pull/1391?src=pr&el=tree)

```diff
@@            Coverage Diff            @@
##            master     #1391   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           50        50           
  Lines         2704      2704           
=========================================
  Hits          2704      2704           
```



------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1391?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1391?src=pr&el=footer). Last update [d902b4f...80a8bed](https://codecov.io/gh/keras-team/autokeras/pull/1391?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",report master change coverage coverage impacted file tree graph coverage master coverage continue review full report legend click learn absolute relative impact affected missing data powered last update abed read comment,issue,negative,positive,neutral,neutral,positive,positive
712535340,"The fix is in a pending pull request to keras tuner.
https://github.com/keras-team/keras-tuner/pull/424
We will have a new tag for kerastuner after this one is merged.",fix pending pull request tuner new tag one,issue,negative,positive,positive,positive,positive,positive
711090113,"> The error was as follows (I also tried on a newly prepared virtual environment):
> 
> ## Non-OK-status: GpuLaunchKernel(FillPhiloxRandomKernelLaunch, num_blocks, block_size, 0, d.stream(), gen, data, size, dist) status: Internal: no kernel image is available for execution on the device

Additional parameters here, I'm running the code on GPU:

autokeras 1.0.9
keras 2.3.1
tensorflow 2.3.0
tensorflow-gpu 2.3.1
numpy 1.19.2
pandas 1.0.5
keras-tuner 1.0.2rc2
python 3.7.8

CuDNN 7.6
CUDA v10.1
GPU: GeForce GTX 960M",error also tried newly prepared virtual environment gen data size status internal kernel image available execution device additional running code python,issue,negative,positive,positive,positive,positive,positive
710767463,"The error was as follows (I also tried on a newly prepared virtual environment):

---
 Non-OK-status: GpuLaunchKernel(FillPhiloxRandomKernelLaunch<Distribution>, num_blocks, block_size, 0, d.stream(), gen, data, size, dist) status: Internal: no kernel image is available for execution on the device
---
",error also tried newly prepared virtual environment distribution gen data size status internal kernel image available execution device,issue,negative,positive,positive,positive,positive,positive
710636687,"I have the same issue, but in my case it is very curious because it actually goes faster in a 500€ laptop than a 2000€ tower computer with i9 processor and rtx 3080 graphics card.

Any one knows why?

laptop specs:
CPU - Core i5-8300H
Graphics card - NVIDIA GeForce GTX 1050 2GB
RAM - 4GB
memory - 1T ddr

Computer tower specs:
CPU - Core i9-10900kf
Graphics card - NVIDIA GeForce RTX 3080 10GB
memory - 1T ssd
RAM - 16GB

both have cuda installed and the training is faster in the computer, but the waiting time is much faster in the laptop, which in my onpinion is super wierd because the computer is better and faster than the laptop in any possible aspect.",issue case curious actually go faster tower computer processor graphic card one spec core graphic card ram memory computer tower spec core graphic card memory ram training faster computer waiting time much faster super computer better faster possible aspect,issue,positive,positive,positive,positive,positive,positive
710318261,"@haifeng-jin , thanks so much for doing this! Is 1d image classification (with multiple channels) still supported? If so, what does the usage look like? I have been trying to get an input of shape [batch_size x channels x num_samples] to work where num_samples is the dimension of the 1d image, but the ak.ImageInput seems to treat it as 2d image (using the channels) and something like a ResNetBlock won't work with an ak.Input of that shape. Ideally, I'd like to run the input through both a ResNet and an RNN, but am having difficulties reconciling that with the documented tutorials. ",thanks much image classification multiple still usage look like trying get input shape work dimension image treat image something like wo work shape ideally like run input reconciling,issue,positive,positive,positive,positive,positive,positive
709381247,"Hello, thanks for the answer.

According to the link to the documentation you provided:

""This feature is controlled by the overwrite argument of AutoModel or any other task APIs. It is set to False by default, which means it would not overwrite the contents of the directory. In other words, it will continue the previous fit.""

That is, we just need to create a new object and just run the search again, and it will continue from the previous place ?",hello thanks answer according link documentation provided feature overwrite argument task set false default would overwrite content directory continue previous fit need create new object run search continue previous place,issue,positive,positive,neutral,neutral,positive,positive
708883284,"@haifeng-jin  I created a very small PR to address this issue, and I'd like you to take a look. I can't push the branch though, since I don't have permissions apparently. I followed all the steps in the [Contributing Guide](https://autokeras.com/contributing/) page. Is there something else I need to do to gain permissions?   I used ssh to clone the repo. ",small address issue like take look ca push branch though since apparently guide page something else need gain used clone,issue,positive,negative,neutral,neutral,negative,negative
708284493,"The documentation is very clear：
Currently, AutoKeras is only compatible with Python >= 3.5 and TensorFlow >= 2.3.0
Why can't it be installed?",documentation currently compatible python ca,issue,negative,neutral,neutral,neutral,neutral,neutral
708283874,"When I use pip install to install, the following error message is displayed: ERROR: Package'dataclasses' requires a different Python: 3.8.3 not in'>=3.6, <3.7'",use pip install install following error message displayed error different python,issue,negative,neutral,neutral,neutral,neutral,neutral
708159052,"Got exact same issue, does anyone know how to resolve this. Here is how I am saving and loading the model.
model = reg.export_model()
model.save(""model_autokeras"",  save_format='tf')

loaded_model = load_model(""model_autokeras"", custom_objects=ak.CUSTOM_OBJECTS)
loaded_model.evaluate(x_test, y_test)",got exact issue anyone know resolve saving loading model model,issue,negative,positive,positive,positive,positive,positive
708038148,"Unfortunately, we are not yet supporting python generators.
I tried your snippet. The problem is AutoKeras doesn't have a good way to tell if the dataset is batched or not.
So I change to the following one, which works.
```
import math

import numpy as np
import tensorflow as tf
from autokeras import StructuredDataRegressor
from tensorflow.data import Dataset

N_BATCHES = 3
BATCH_SIZE = 10
N_FEATURES = 3


def get_data_generator(n_batches, batch_size, n_features):
    """"""Get a generator returning n_batches random data of batch_size with n_features.""""""

    def data_generator():
        for _ in range(n_batches * batch_size):
            x = np.random.randn(n_features)
            y = x.sum(axis=0)
            yield x, y

    return data_generator


ds = Dataset.from_generator(
    get_data_generator(N_BATCHES, BATCH_SIZE, N_FEATURES),
    output_types=(tf.float32, tf.float32),
    output_shapes=((N_FEATURES,), tuple()),
).batch(BATCH_SIZE)

import autokeras as ak
print(ak.utils.data_utils.dataset_shape(ds))
print(ak.utils.data_utils.dataset_shape(tf.data.Dataset.from_tensor_slices(np.random.rand(64, 3)).batch(32)))
# assert False

reg = StructuredDataRegressor(overwrite=True)
reg.fit(x=ds, batch_size=BATCH_SIZE)
```",unfortunately yet supporting python tried snippet problem good way tell change following one work import math import import import import get generator random data range yield return import ak print print assert false reg,issue,negative,negative,neutral,neutral,negative,negative
708029477,"I don't think it is possible to replicate this case using AutoModel with 1 trial.
The main reason is the unit_1 and unit_0, and the optimizer cannot be specified directly using AutoModel.",think possible replicate case trial main reason directly,issue,negative,positive,neutral,neutral,positive,positive
708027297,"With [ClassificationHead](https://autokeras.com/block/#classificationhead), you can use a custom loss function. Please let us know if it works for you. You need to use the AutoModel API with it.",use custom loss function please let u know work need use,issue,negative,neutral,neutral,neutral,neutral,neutral
708025975,"Unfortunately, AutoKeras cannot support such training at the moment. It can be done with a custom training loop using Keras. May be Keras Tuner can support this if you need to tune the hyperparameters.",unfortunately support training moment done custom training loop may tuner support need tune,issue,negative,negative,negative,negative,negative,negative
707773096,"@dcohron not related to the question, but I've also encountered the same problem when using custom metrics. I kind of solved it using an answer from another [issue](https://github.com/keras-team/autokeras/issues/1257#issuecomment-674132595).",related question also problem custom metric kind answer another issue,issue,negative,positive,positive,positive,positive,positive
707738290,"Hello, @haifeng-jin 
I'm now trying based on your suggestion that I should explicitly set varidation_data.
(FYI, X has 30k rows * (30-100 cols * 24 groups), Y has [30k rows*4 cols, 30k list, 30k list])

It seems that the ""SPLIT #"" bug can be swept by this means, however, I encountered ""kernel died"" errors instead :<  
I'll take some more time to see it.",hello trying based suggestion explicitly set list list split bug swept however kernel instead take time see,issue,negative,neutral,neutral,neutral,neutral,neutral
707492327,"> Yes, please use a name that doesn't end with 'H5' or 'h5' when saving the model.

then it will be automatically saved tf's <class 'tensorflow.python.keras.engine.functional.Functional'>, and doesn't work after load_model.",yes please use name end saving model automatically saved class work,issue,positive,neutral,neutral,neutral,neutral,neutral
707491006,"my issue
```
print(type(m_search)) # <class 'autokeras.tasks.structured_data.StructuredDataClassifier'>
model1 = m_search.export_model()
print(type(model1)) # <class 'tensorflow.python.keras.engine.functional.Functional'>
```
after export_model(), it's changed to 'Functional', not to <class 'tensorflow.python.keras.engine.training.Model'>(commented in Export model documentation) 
with this message 'WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.' 
load_model() has also same message

after load or export, the model can't be re-fit or predict anymore with this message which wasn't when the model is StructuredDataClassifier.
`valueerror: shapes (none, 1) and (none, 3) are incompatible`
",issue print type class model print type model class class export model documentation message loaded model metric yet built empty train evaluate model also message load export model ca predict message model none none incompatible,issue,negative,negative,neutral,neutral,negative,negative
706803480,"@ciessielski @jisho-iemoto @Cariaga Would you confirm that the training data you are using has number of samples that at least 2 times the batch_size. For example, if your batch_size is 32 (default), then your data should at least contain 33 samples.",would confirm training data number least time example default data least contain,issue,negative,negative,negative,negative,negative,negative
706802534,A temporary work around can be split the data to training and validation before calling fit. Use validation_data arg to pass the validation set.,temporary work around split data training validation calling fit use pas validation set,issue,negative,positive,positive,positive,positive,positive
706784018,What is the prediction you get? Maybe it's a list with one value which is the most common...,prediction get maybe list one value common,issue,negative,negative,negative,negative,negative,negative
706548126,"Here is the colab to reproduce the error:
https://colab.research.google.com/drive/1jOzTuL26UZaISnSZkUD273yZ1cqrX1QL?usp=sharing

The error seems to appear when patience is higher than the variable self._save_n_checkpoints (hardcoded => 10) of kerastuner/engine/tuner.py:
See callbacks=[tf.keras.callbacks.EarlyStopping(training_objective, patience=50)] in the colab.

With this configuration, for an unknown reason, the best checkpoint is removed and then when autokeras is looking for it, it crashes.
It may be a problem with the function ""save_model(self, trial_id, model, step=0)"" defined in kerastuner/engine/tuner.py

A hack would be to increase self._save_n_checkpoints to patience.",reproduce error error appear patience higher variable see configuration unknown reason best removed looking may problem function self model defined hack would increase patience,issue,negative,positive,positive,positive,positive,positive
706501640,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1376?src=pr&el=h1) Report
> :exclamation: No coverage uploaded for pull request base (`master@15c64d8`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1376/graphs/tree.svg?width=650&height=150&src=pr&token=yDvddb2DDZ)](https://codecov.io/gh/keras-team/autokeras/pull/1376?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##             master     #1376   +/-   ##
==========================================
  Coverage          ?   100.00%           
==========================================
  Files             ?        48           
  Lines             ?      2935           
  Branches          ?         0           
==========================================
  Hits              ?      2935           
  Misses            ?         0           
  Partials          ?         0           
```



------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1376?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1376?src=pr&el=footer). Last update [15c64d8...1e27201](https://codecov.io/gh/keras-team/autokeras/pull/1376?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",report exclamation coverage pull request base master click learn coverage impacted file tree graph coverage master coverage continue review full report legend click learn absolute relative impact affected missing data powered last update read comment,issue,negative,negative,neutral,neutral,negative,negative
706319069,"If you take the snippet I put at the beginning and use whatever dataset you want (I used the Titanic dataset in this snippet), that should be sufficient to reproduce the error.",take snippet put beginning use whatever want used titanic snippet sufficient reproduce error,issue,negative,neutral,neutral,neutral,neutral,neutral
706271087,I really don't know. Would you provide your code in colab? So that I can reproduce the error?,really know would provide code reproduce error,issue,negative,positive,positive,positive,positive,positive
706270121,I cannot reproduce the error. Is there any colab examples that reproduces the error? Thanks.,reproduce error error thanks,issue,negative,positive,positive,positive,positive,positive
706261458,"I am not very familiar with tfjs or tf lite. I am not sure why it doesn't convert.

For the exported Keras model from AutoKeras, it is just a Keras Model.
It should convert if other Keras Models do.",familiar lite sure convert model model convert,issue,negative,positive,positive,positive,positive,positive
706261029,"Thanks a lot for the comment.
I've built up the environment by Anaconda 3 and it is already virtual.  And the errors above have been solved step by step.

Though I don't know whether it helps solve the bug or not, I tried to ""reduce the output"" (original: 3 kinds in a list, trial: a single in a list), which was also in vain due to the same error.",thanks lot comment built environment anaconda already virtual step step though know whether solve bug tried reduce output original list trial single list also vain due error,issue,negative,positive,neutral,neutral,positive,positive
706258566,I don't think it is related to the bug. But it may break other parts of the code. So I suggest you use virtualenv to install AutoKeras to separate the dependencies.,think related bug may break code suggest use install separate,issue,negative,neutral,neutral,neutral,neutral,neutral
706141445,Looks like some issue with the inputs. Setting (augment=False) solved problem. ,like issue setting problem,issue,negative,neutral,neutral,neutral,neutral,neutral
705828939,"Same problem on my side : tensorflow 2.3.1, autokeras 1.0.9, keras-tuner 1.0.2rc2.
Impossible to use autokeras... Any workaround ?",problem side impossible use,issue,negative,negative,negative,negative,negative,negative
705418868,"I am getting the same error when I use a `StructuredDataRegressor` with a `tensorflow.data.Dataset`. This seems to contradict the documentation of the `StructuredDataRegressor.fit` method which states:

> x: String, numpy.ndarray, pandas.DataFrame or **tensorflow.Dataset**. Training data x. If the data is from a csv file, it should be a string specifying the path of the csv file of the training data.

### Example Code

```python
import math

import numpy as np
import tensorflow as tf
from autokeras import StructuredDataRegressor
from tensorflow.data import Dataset

N_BATCHES = 3
BATCH_SIZE = 10
N_FEATURES = 3


def get_data_generator(n_batches, batch_size, n_features):
    """"""Get a generator returning n_batches random data of batch_size with n_features.""""""

    def data_generator():
        for _ in range(n_batches):
            x = np.random.randn(batch_size, n_features)
            y = x.sum(axis=1)
            yield x, y

    return data_generator


ds = Dataset.from_generator(
    get_data_generator(N_BATCHES, BATCH_SIZE, N_FEATURES),
    output_types=(tf.float32, tf.float32),
    output_shapes=((BATCH_SIZE, N_FEATURES), (BATCH_SIZE,)),
)

reg = StructuredDataRegressor()
reg.fit(x=ds)

```

### Expected Behaviour

The regressor is fitted on the dataset.

### Actual Behaviour

`AttributeError: 'numpy.ndarray' object has no attribute 'decode'` is raised.

### Further Information

If I use the following keras model instead of the StructuredDataRegressor everything works fine:
```python
from keras.layers import Dense
from keras.models import Sequential
reg = Sequential()
reg.add(Dense(16))
reg.add(Dense(1))

reg.compile(loss=""mean_squared_error"")

reg.fit(ds)
```",getting error use contradict documentation method string training data data file string path file training data example code python import math import import import import get generator random data range yield return reg behaviour regressor fitted actual behaviour object attribute raised information use following model instead everything work fine python import dense import sequential reg sequential dense dense,issue,negative,negative,neutral,neutral,negative,negative
705106928,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1370?src=pr&el=h1) Report
> :exclamation: No coverage uploaded for pull request base (`master@15c64d8`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).
> The diff coverage is `100.00%`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1370/graphs/tree.svg?width=650&height=150&src=pr&token=yDvddb2DDZ)](https://codecov.io/gh/keras-team/autokeras/pull/1370?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##             master     #1370   +/-   ##
==========================================
  Coverage          ?   100.00%           
==========================================
  Files             ?        48           
  Lines             ?      2630           
  Branches          ?         0           
==========================================
  Hits              ?      2630           
  Misses            ?         0           
  Partials          ?         0           
```


| [Impacted Files](https://codecov.io/gh/keras-team/autokeras/pull/1370?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [autokeras/analysers/input\_analysers.py](https://codecov.io/gh/keras-team/autokeras/pull/1370/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2FuYWx5c2Vycy9pbnB1dF9hbmFseXNlcnMucHk=) | `100.00% <ø> (ø)` | |
| [autokeras/blocks/heads.py](https://codecov.io/gh/keras-team/autokeras/pull/1370/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2Jsb2Nrcy9oZWFkcy5weQ==) | `100.00% <100.00%> (ø)` | |
| [autokeras/engine/head.py](https://codecov.io/gh/keras-team/autokeras/pull/1370/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2VuZ2luZS9oZWFkLnB5) | `100.00% <100.00%> (ø)` | |
| [autokeras/engine/io\_hypermodel.py](https://codecov.io/gh/keras-team/autokeras/pull/1370/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2VuZ2luZS9pb19oeXBlcm1vZGVsLnB5) | `100.00% <100.00%> (ø)` | |
| [autokeras/engine/node.py](https://codecov.io/gh/keras-team/autokeras/pull/1370/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2VuZ2luZS9ub2RlLnB5) | `100.00% <100.00%> (ø)` | |
| [autokeras/engine/tuner.py](https://codecov.io/gh/keras-team/autokeras/pull/1370/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2VuZ2luZS90dW5lci5weQ==) | `100.00% <100.00%> (ø)` | |
| [autokeras/graph.py](https://codecov.io/gh/keras-team/autokeras/pull/1370/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2dyYXBoLnB5) | `100.00% <100.00%> (ø)` | |
| [autokeras/keras\_layers.py](https://codecov.io/gh/keras-team/autokeras/pull/1370/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2tlcmFzX2xheWVycy5weQ==) | `100.00% <100.00%> (ø)` | |
| [autokeras/nodes.py](https://codecov.io/gh/keras-team/autokeras/pull/1370/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL25vZGVzLnB5) | `100.00% <100.00%> (ø)` | |
| [autokeras/utils/data\_utils.py](https://codecov.io/gh/keras-team/autokeras/pull/1370/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL3V0aWxzL2RhdGFfdXRpbHMucHk=) | `100.00% <100.00%> (ø)` | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1370?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1370?src=pr&el=footer). Last update [15c64d8...3827d9a](https://codecov.io/gh/keras-team/autokeras/pull/1370?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",report exclamation coverage pull request base master click learn coverage impacted file tree graph coverage master coverage impacted coverage continue review full report legend click learn absolute relative impact affected missing data powered last update da read comment,issue,negative,negative,neutral,neutral,negative,negative
704042495,"The working environment is
autokeras version : 1.0.9
tensorflow version : 2.0.3

thank you.",working environment version version thank,issue,negative,neutral,neutral,neutral,neutral,neutral
703855477,"Thanks for the information, I'll look into that! If I get any solution I will let you know for sure.",thanks information look get solution let know sure,issue,positive,positive,positive,positive,positive,positive
703833686,"I have a similar issue.  I think that if you can load the best model you could then run keras.Model.summary() (summary method in the keras Model class)  on that model to see the architecture.  Should be simple as that.

I have tried accessing the best model two ways:
1)  Via the try/except in the documentation for tf or h5 formats.  This does not work because I have a custom metric (F1 Score) which triggers a ""ValueError: Unable to restore custom object of type _tf_keras_metric currently.  Please make sure that the layer implements `get_config`and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.""
2)  Digging a bit deeper I tried loaded = tf.saved_model.load(best_model_path) from  ...model/best_model/saved_model.pb which triggers a ""ValueError: The same saveable will be restored with two names: layer_with_weights-6/encoding layers/0/_table/.ATTRIBUTES/table""

Any help here would be most appreciated.",similar issue think load best model could run summary method model class model see architecture simple tried best model two way via documentation work custom metric score unable restore custom object type currently please make sure layer saving addition please use calling digging bit tried loaded two help would,issue,positive,positive,positive,positive,positive,positive
703005896,"A GPU sitting idle just begs for more epochs, but other than that, can someone give a clear explanation of why this is needed and when it would be useful?
",sitting idle someone give clear explanation would useful,issue,positive,positive,positive,positive,positive,positive
702802447,We are working on retina net for now. May add the rest after [KerasCV](https://github.com/keras-team/governance/pull/26) is available.,working retina net may add rest available,issue,negative,positive,positive,positive,positive,positive
702791713,"We are working on to support this feature.
It is a duplicate of 
#984 ",working support feature duplicate,issue,negative,neutral,neutral,neutral,neutral,neutral
702791209,"Yes, that version is not working with the latest tf.
So please use autokeras 1.0.9 and tf 2.3.0 and keras-tuner 1.0.2rc2.
You can follow the installation instructions on our website. Thanks.",yes version working latest please use follow installation thanks,issue,positive,positive,positive,positive,positive,positive
702790353,"We will add how to constrain model size to the FAQ on our website soon. It is tracked by this issue #1341 .
However, it may not work very well. Another suggestion is to use some techniques to reduce the model size after you export it.
There should be some way to reduce the size of a tf model without sacrifice the performance.",add constrain model size soon tracked issue however may work well another suggestion use reduce model size export way reduce size model without sacrifice performance,issue,negative,neutral,neutral,neutral,neutral,neutral
702528474,"Thanks for good work.
Yes, tf format works. 
let me ask another question.
I am using autokeras for generating prediction model efficiently(StructuredData).
For portable device deployment, I have to use TensorflowLite or Tensorflowjs.
I tested various combination of format and convert tool.
Unfortunately, even keras-generated model from keras homepage example fails to convert.
(https://keras.io/examples/structured_data/structured_data_classification_from_scratch/)
conversion script: 
```
import tensorflowjs as tfjs
tfjs.converters.save_keras_model(model, 'model_test/tfjs_model')
```

BTW what I want to know clear is, autokeras-generated model would be just keras model,
so that if keras model is fine for converion to tflite or tfjs format, autokeras model would be OK also.
Am I right?

update :  comment posted below was deleted because the issue is different, sorry for that  : ).",thanks good work yes format work let ask another question generating prediction model efficiently portable device deployment use tested various combination format convert tool unfortunately even model example convert conversion script import model want know clear model would model model fine format model would also right update comment posted issue different sorry,issue,positive,positive,neutral,neutral,positive,positive
702090426,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1358?src=pr&el=h1) Report
> Merging [#1358](https://codecov.io/gh/keras-team/autokeras/pull/1358?src=pr&el=desc) into [master](https://codecov.io/gh/keras-team/autokeras/commit/59128d3153d38e200156b83efa5cc6ab2f75c8e6?el=desc) will **not change** coverage.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1358/graphs/tree.svg?width=650&height=150&src=pr&token=yDvddb2DDZ)](https://codecov.io/gh/keras-team/autokeras/pull/1358?src=pr&el=tree)

```diff
@@            Coverage Diff            @@
##            master     #1358   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           48        48           
  Lines         2589      2589           
=========================================
  Hits          2589      2589           
```


| [Impacted Files](https://codecov.io/gh/keras-team/autokeras/pull/1358?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [autokeras/tasks/image.py](https://codecov.io/gh/keras-team/autokeras/pull/1358/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL3Rhc2tzL2ltYWdlLnB5) | `100.00% <ø> (ø)` | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1358?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1358?src=pr&el=footer). Last update [59128d3...251c22a](https://codecov.io/gh/keras-team/autokeras/pull/1358?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",report master change coverage coverage impacted file tree graph coverage master coverage impacted coverage continue review full report legend click learn absolute relative impact affected missing data powered last update ca read comment,issue,negative,positive,neutral,neutral,positive,positive
701884363,"Does the tf format work?
As we tested, it should work.
The h5 may not at the moment.",format work tested work may moment,issue,negative,neutral,neutral,neutral,neutral,neutral
701882065,"There are two caveats of exporting the model.
1. save the model to tf format instead of h5 if you want to save it. Simply remove the .h5 suffix from the path would do it.
2. format the data to np.unicode type if you are using numpy arrays, and use tf.string format for tf.data.Dataset.

I believe it would solve your problem. ",two model save model format instead want save simply remove suffix path would format data type use format believe would solve problem,issue,positive,neutral,neutral,neutral,neutral,neutral
701160926,"I currently have the same issue. The model seems to work just fine when not exported, but the loaded model complains of casting involving strings and floats - neither of which are present in my training data after checking.",currently issue model work fine loaded model casting neither present training data,issue,negative,positive,positive,positive,positive,positive
701158441,"Saving model with StructruedDataRegressor example(California house ex.) produces same error..

I tried to save tf-format, keras-format, convert to sequential model and save, all results the same.
```
seq_model = tf.keras.Sequential(model.layers)
seq_model.save(""model_test/h5_california.h5"", save_format=""h5"")
```
haifeng-jin said saving model is OK, so I guess it is because of packages version difference.
Below is my test spec., different? or another package dependency?

< test spec. >
autokeras.__version =  1.0.8
tensorflow.__version =  2.3.0
python =  3.6.8 |Anaconda, Inc.| (default, Dec 30 2018, 01:22:34) 


< source - almost from autokeras example code except model.save >
```
from sklearn.datasets import fetch_california_housing
import numpy as np
import pandas as pd
import tensorflow as tf
import autokeras as ak

house_dataset = fetch_california_housing()
df = pd.DataFrame(
    np.concatenate((
        house_dataset.data, 
        house_dataset.target.reshape(-1,1)),
        axis=1),
    columns=house_dataset.feature_names + ['Price'])
train_size = int(df.shape[0] * 0.9)
df[:train_size].to_csv('train.csv', index=False)
df[train_size:].to_csv('eval.csv', index=False)
train_file_path = 'train.csv'
test_file_path = 'eval.csv'

import pandas as pd
import numpy as np
x_train = pd.read_csv('train.csv')
y_train = x_train.pop('Price')

x_test = pd.read_csv('eval.csv')
y_test = x_test.pop('Price')

reg = ak.StructuredDataRegressor(max_trials=3, overwrite=True)
reg.fit(x_train, y_train, epochs=10)

model = reg.export_model()
model.save(""model_test/h5_california.h5"", save_format=""h5"")
```
< Error Message >

--------------------------------------------------------------------------
NotImplementedError                       Traceback (most recent call last)
<ipython-input-27-b96bf92dba26> in <module>
----> 1 seq_model.save(""model_test/h5_california.h5"", save_format=""h5"")
      2 # tf.keras.models.save_model(model, ""model_test/pb_california"", save_format=""tf"")

~/miniconda3/envs/ak/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py in save(self, filepath, overwrite, include_optimizer, save_format, signatures, options)
   1977     """"""
   1978     save.save_model(self, filepath, overwrite, include_optimizer, save_format,
-> 1979                     signatures, options)
   1980 
   1981   def save_weights(self,

~/miniconda3/envs/ak/lib/python3.6/site-packages/tensorflow/python/keras/saving/save.py in save_model(model, filepath, overwrite, include_optimizer, save_format, signatures, options)
    129           'or using `save_weights`.')
    130     hdf5_format.save_model_to_hdf5(
--> 131         model, filepath, overwrite, include_optimizer)
    132   else:
    133     saved_model_save.save(model, filepath, overwrite, include_optimizer,

~/miniconda3/envs/ak/lib/python3.6/site-packages/tensorflow/python/keras/saving/hdf5_format.py in save_model_to_hdf5(model, filepath, overwrite, include_optimizer)
    117     model_weights_group = f.create_group('model_weights')
    118     model_layers = model.layers
--> 119     save_weights_to_hdf5_group(model_weights_group, model_layers)
    120 
    121     # TODO(b/128683857): Add integration tests between tf.keras and external

~/miniconda3/envs/ak/lib/python3.6/site-packages/tensorflow/python/keras/saving/hdf5_format.py in save_weights_to_hdf5_group(f, layers)
    633   for layer in sorted(layers, key=lambda x: x.name):
    634     g = f.create_group(layer.name)
--> 635     weights = _legacy_weights(layer)
    636     weight_values = K.batch_get_value(weights)
    637     weight_names = [w.name.encode('utf8') for w in weights]

~/miniconda3/envs/ak/lib/python3.6/site-packages/tensorflow/python/keras/saving/hdf5_format.py in _legacy_weights(layer)
    882         'Save or restore weights that is not an instance of `tf.Variable` is '
    883         'not supported in h5, use `save_format=\'tf\'` instead. Got a model '
--> 884         'or layer {} with weights {}'.format(layer.__class__.__name__, weights))
    885   return weights

NotImplementedError: Save or restore weights that is not an instance of `tf.Variable` is not supported in h5, use `save_format='tf'` instead. Got a model or layer MultiCategoryEncoding with weights [<tensorflow.python.keras.engine.base_layer_utils.TrackableWeightHandler object at 0x7f48fee09e80>, <tensorflow.python.keras.engine.base_layer_utils.TrackableWeightHandler object at 0x7f48fee09438>, <tensorflow.python.keras.engine.base_layer_utils.TrackableWeightHandler object at 0x7f48fc599898>]



",saving model example house ex error tried save convert sequential model save said saving model guess version difference test different another package dependency test spec python default source almost example code except import import import import import ak import import reg model error message recent call last module model save self overwrite self overwrite self model overwrite model overwrite else model overwrite model overwrite add integration external layer sorted layer layer restore instance use instead got model layer return save restore instance use instead got model layer object object object,issue,positive,neutral,neutral,neutral,neutral,neutral
699680993,"Thanks! I cloned the latest code of the branch; I agree this appears fixed by the next release (from ""Test AutoKeras update"")
https://colab.research.google.com/drive/1uwCAQLk65C0AFtR9nKS3OmI5RK-A8Wbc#scrollTo=-EU25QbuCbij",thanks latest code branch agree fixed next release test update,issue,positive,positive,positive,positive,positive,positive
699633654,"Hello.
Just after updating Auto-Keras to 1.0.9 (I guess other relating files are also updated automatically, if needed), the same issue is still found.

---
During updating Auto-Keras, I encountered the following errors.  Is anything in touch with the bug in question?


ERROR: google-api-core 1.22.2 has requirement google-auth<2.0dev,>=1.21.1, but you'll have google-auth 1.19.2 which is incompatible.
ERROR: botocore 1.17.29 has requirement docutils<0.16,>=0.10, but you'll have docutils 0.16 which is incompatible.
ERROR: awscli 1.18.106 has requirement docutils<0.16,>=0.10, but you'll have docutils 0.16 which is incompatible.
ERROR: awscli 1.18.106 has requirement rsa<=4.5.0,>=3.1.2; python_version != ""3.4"", but you'll have rsa 4.6 which is incompatible.
",hello guess also automatically issue still found following anything touch bug question error requirement incompatible error requirement incompatible error requirement incompatible error requirement incompatible,issue,negative,neutral,neutral,neutral,neutral,neutral
699589093,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1352?src=pr&el=h1) Report
> Merging [#1352](https://codecov.io/gh/keras-team/autokeras/pull/1352?src=pr&el=desc) into [master](https://codecov.io/gh/keras-team/autokeras/commit/05dba445c8bd85b25f68b827dd3bfe40263a0708?el=desc) will **not change** coverage.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1352/graphs/tree.svg?width=650&height=150&src=pr&token=yDvddb2DDZ)](https://codecov.io/gh/keras-team/autokeras/pull/1352?src=pr&el=tree)

```diff
@@            Coverage Diff            @@
##            master     #1352   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           48        48           
  Lines         2594      2592    -2     
=========================================
- Hits          2594      2592    -2     
```


| [Impacted Files](https://codecov.io/gh/keras-team/autokeras/pull/1352?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [autokeras/graph.py](https://codecov.io/gh/keras-team/autokeras/pull/1352/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2dyYXBoLnB5) | `100.00% <ø> (ø)` | |
| [autokeras/keras\_layers.py](https://codecov.io/gh/keras-team/autokeras/pull/1352/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2tlcmFzX2xheWVycy5weQ==) | `100.00% <ø> (ø)` | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1352?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1352?src=pr&el=footer). Last update [05dba44...511a33e](https://codecov.io/gh/keras-team/autokeras/pull/1352?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",report master change coverage coverage impacted file tree graph coverage master coverage impacted coverage continue review full report legend click learn absolute relative impact affected missing data powered last update ae read comment,issue,negative,positive,neutral,neutral,positive,positive
699462670,"Thanks a lot for your help!

On Sat, Sep 26, 2020, 11:12 Haifeng Jin <notifications@github.com> wrote:

> pip3 install git+https://github.com/keras-team/keras-tuner.git@1.0.2rc1
> This command works on my computer.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/keras-team/autokeras/issues/1336#issuecomment-699431968>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AIPIB72DSM4D6ZZQXYRMD6DSHV5K7ANCNFSM4RJDZ3RA>
> .
>
",thanks lot help sat wrote pip install command work computer thread reply directly view,issue,positive,positive,positive,positive,positive,positive
699432940,I also suspect this issue still exist due to some recent user's feedback. Anyone can provide a colab notebook for reproducing the issue?,also suspect issue still exist due recent user feedback anyone provide notebook issue,issue,negative,negative,neutral,neutral,negative,negative
699432708,"Yes, please use a name that doesn't end with 'H5' or 'h5' when saving the model.",yes please use name end saving model,issue,positive,neutral,neutral,neutral,neutral,neutral
699432517,"Sorry, we don't have this plan. In the near future, we may even keep based on the latest version of tensorflow since we are always using some features which only exists in the latest version of TF.",sorry plan near future may even keep based latest version since always latest version,issue,negative,positive,positive,positive,positive,positive
699432364,We have removed this feature since the performance is not good enough and it is just a pretrained model which doesn't support training.,removed feature since performance good enough model support training,issue,positive,positive,positive,positive,positive,positive
699432195,"I suspect this is supported in the master branch.
We will get to this one if it still fails in the next release (1.0.9).",suspect master branch get one still next release,issue,negative,neutral,neutral,neutral,neutral,neutral
699431968,"`pip3 install git+https://github.com/keras-team/keras-tuner.git@1.0.2rc1`
This command works on my computer.",pip install command work computer,issue,negative,neutral,neutral,neutral,neutral,neutral
699431870,Is it an error that exits the program completely? or it is keep running to the  end and you can still export the found best model?,error program completely keep running end still export found best model,issue,negative,positive,positive,positive,positive,positive
699431228,I will look into this and try to fix it in the next release. Thanks.,look try fix next release thanks,issue,negative,positive,neutral,neutral,positive,positive
699431067,Yes. The main issue is the exported model needs the data to be in strings format.,yes main issue model need data format,issue,negative,positive,positive,positive,positive,positive
698590797,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1350?src=pr&el=h1) Report
> Merging [#1350](https://codecov.io/gh/keras-team/autokeras/pull/1350?src=pr&el=desc) into [master](https://codecov.io/gh/keras-team/autokeras/commit/5b8864d1863ac0474db8b657f023341686f4b1fb?el=desc) will **not change** coverage.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1350/graphs/tree.svg?width=650&height=150&src=pr&token=yDvddb2DDZ)](https://codecov.io/gh/keras-team/autokeras/pull/1350?src=pr&el=tree)

```diff
@@            Coverage Diff            @@
##            master     #1350   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           48        48           
  Lines         2594      2594           
=========================================
  Hits          2594      2594           
```



------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1350?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1350?src=pr&el=footer). Last update [5b8864d...1d08e17](https://codecov.io/gh/keras-team/autokeras/pull/1350?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",report master change coverage coverage impacted file tree graph coverage master coverage continue review full report legend click learn absolute relative impact affected missing data powered last update de read comment,issue,negative,positive,neutral,neutral,positive,positive
696054753,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1346?src=pr&el=h1) Report
> Merging [#1346](https://codecov.io/gh/keras-team/autokeras/pull/1346?src=pr&el=desc) into [master](https://codecov.io/gh/keras-team/autokeras/commit/9b73d55ee4b328883e0a2b0eb6809fb4941f8451?el=desc) will **not change** coverage.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1346/graphs/tree.svg?width=650&height=150&src=pr&token=yDvddb2DDZ)](https://codecov.io/gh/keras-team/autokeras/pull/1346?src=pr&el=tree)

```diff
@@            Coverage Diff            @@
##            master     #1346   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           47        47           
  Lines         2458      2458           
=========================================
  Hits          2458      2458           
```



------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1346?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1346?src=pr&el=footer). Last update [9b73d55...a7976a9](https://codecov.io/gh/keras-team/autokeras/pull/1346?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",report master change coverage coverage impacted file tree graph coverage master coverage continue review full report legend click learn absolute relative impact affected missing data powered last update aa read comment,issue,negative,positive,neutral,neutral,positive,positive
695991278,"Hi 
Any updates on this object detection with custom dataset in autokeras. Any example of optimizing standard SSD?Yolo object detectors with autokeras",hi object detection custom example standard object,issue,negative,neutral,neutral,neutral,neutral,neutral
695969412,"1. Download **https://raw.githubusercontent.com/tensorflow/tensorflow/v2.3.0/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py**  to F:\Anaconda3\envs\tflow2\Lib\site-packages\tensorflow_core\python\keras\layers\preprocessing - it just doesnt exist in tf 2.0-2.1
2. Comment all the _@tf.keras.utils.register_keras_serializable(package='Text')_, that will couse an error.

After that tf object detection api works fine, as for me",doesnt exist comment error object detection work fine,issue,negative,positive,positive,positive,positive,positive
694117880,"same here, running :
pip3 install git+https://github.com/keras-team/keras-tuner.git@1.0.2rc0
pip3 install autokeras==1.0.3

 using the example for text classification : https://autokeras.com/tutorial/text_classification/

getting AttributeError: 'tuple' object has no attribute 'shape'",running pip install pip install example text classification getting object attribute,issue,negative,neutral,neutral,neutral,neutral,neutral
694040929,"Thanks for the update. I am not able to share the dataset as it is restricted. The data is a time-series of images obtained from an industrial process. Main challenges are non-stationarity and noise. I am doing some feature extraction which I can test with AK once ready.

I will look into the Keras-Tuner feature to restrict the model size. I have used Keras-Tuner separately to tune models where I can provide the range of search for each parameter. I am not sure how this works when combining with AK. Is it something I should be able to pass as kwargs to automodel?

If there is a sample code or code doc that I can refer to, that will be great. 

Thanks.",thanks update able share restricted data industrial process main noise feature extraction test ak ready look feature restrict model size used separately tune provide range search parameter sure work combining ak something able pas sample code code doc refer great thanks,issue,positive,positive,positive,positive,positive,positive
693538470,"Getting error
`ValueError: Unsuccessful TensorSliceReader constructor: Failed to get matching files on ./structured_data_regressor/trial_869518eb879f942102cf397ccdff8288/checkpoints/epoch_2/checkpoint: Not found: ./structured_data_regressor/trial_869518eb879f942102cf397ccdff8288/checkpoints/epoch_2; No such file or directory`

`ls structured_data_regressor/trial_869518eb879f942102cf397ccdff8288/checkpoints/`
`epoch_0  epoch_10  epoch_11  epoch_12  epoch_3  epoch_4  epoch_5  epoch_6  epoch_7  epoch_8  epoch_9`


>>> import autokeras as ak
>>> ak.__version__
'1.0.8'
>>> import tensorflow as tf
>>> tf.__version__
'2.3.0'
>>> import kerastuner
>>> kerastuner.__version__
'1.0.2rc1'

",getting error unsuccessful constructor get matching found file directory import ak import import,issue,negative,neutral,neutral,neutral,neutral,neutral
693536413,I believe this is fixed in the master branch. If you like to check it out.,believe fixed master branch like check,issue,negative,positive,neutral,neutral,positive,positive
693535405,"I forgot how. But there must be a solution. This is more like a Keras question. If anyone has an answer, welcome to post here.",forgot must solution like question anyone answer welcome post,issue,positive,positive,positive,positive,positive,positive
693532704,"Yes. You can set an upper bound to the number of parameters which is supported by Keras Tuner, therefore supported by AutoKeras. We may add this soon to the FAQ.

I don't think there is any configurable way to improve the performance. Are you using any public dataset? We can take a look of why it is performing poorly.

Thanks.",yes set upper bound number tuner therefore may add soon think way improve performance public take look poorly thanks,issue,positive,positive,neutral,neutral,positive,positive
693530739,"We remove the early stopping only in two cases: https://github.com/keras-team/autokeras/blob/master/autokeras/engine/tuner.py#L170.
If validation data is not provided, we will run a final fit with the entire training data provided by the user.
So we don't have extra data for validation. So we cannot do early stopping.
If you provide your own validation data and pass the early stopping in the callbacks, we won't need to run the final fit.",remove early stopping two validation data provided run final fit entire training data provided user extra data validation early stopping provide validation data pas early stopping wo need run final fit,issue,negative,positive,positive,positive,positive,positive
693390609,"I have the same issue.
It happens when the score of the trial is NaN in my case.

We need to repoen the issue.

A workaround would be to remove the trial that has a NaN score.",issue score trial nan case need issue would remove trial nan score,issue,negative,neutral,neutral,neutral,neutral,neutral
693309305,"> Issue solved in the latest version, thanks.

In `autokeras ==1.0.8`?",issue latest version thanks,issue,negative,positive,positive,positive,positive,positive
693172298,Could you please point to any tutorial / example for using this feature,could please point tutorial example feature,issue,negative,neutral,neutral,neutral,neutral,neutral
691432012,"> > import scipy in your code. It will probably solve the error.
> 
> Thank you.

I wrote `import scipy
from autokeras import ImageClassifier, load_image_dataset`
But the following error prompted `ImportError: cannot import name 'load_image_dataset' from 'autokeras'`. Please help me!",import code probably solve error thank wrote import import following error import name please help,issue,negative,neutral,neutral,neutral,neutral,neutral
691392914,"Here's a minimal reproduction for the issue.
code:
```
import autokeras as ak
import numpy as np

x = input_node = ak.Input()
x = ak.RNNBlock()(x)
x = ak.TemporalReduction()(x)
output_node = ak.RegressionHead(loss='cosine_similarity')(x)
reg = ak.AutoModel(
    inputs=input_node,
    outputs=output_node,
    overwrite=True,
    max_trials=1)
reg.fit(x=np.zeros((100, 50, 20)), y=np.ones((100, 20)), epochs=2)
```

output:
```
Trial 1 Complete [00h 00m 10s]
val_loss: -0.86031574010849

Best val_loss So Far: -0.86031574010849
Total elapsed time: 00h 00m 10s
INFO:tensorflow:Oracle triggered exit
Epoch 1/2
4/4 [==============================] - 0s 19ms/step - loss: -0.5827 - mean_squared_error: 0.9994
Epoch 2/2
4/4 [==============================] - 0s 18ms/step - loss: -0.8673 - mean_squared_error: 0.9979
```",minimal reproduction issue code import ak import reg output trial complete best far total time oracle triggered exit epoch loss epoch loss,issue,negative,positive,positive,positive,positive,positive
691391144,"<!--
/* Font Definitions */
@font-face
	{font-family:""Cambria Math"";
	panose-1:2 4 5 3 5 4 6 3 2 4;}
@font-face
	{font-family:""Yu Gothic"";
	panose-1:2 11 4 0 0 0 0 0 0 0;}
@font-face
	{font-family:""MS PGothic"";
	panose-1:2 11 6 0 7 2 5 8 2 4;}
@font-face
	{font-family:""Yu Gothic"";
	panose-1:2 11 4 0 0 0 0 0 0 0;}
@font-face
	{font-family:""MS PGothic"";}
/* Style Definitions */
p.MsoNormal, li.MsoNormal, div.MsoNormal
	{margin:0mm;
	text-align:justify;
	text-justify:inter-ideograph;
	font-size:10.5pt;
	font-family:""游ゴシック"",sans-serif;}
a:link, span.MsoHyperlink
	{mso-style-priority:99;
	color:blue;
	text-decoration:underline;}
.MsoChpDefault
	{mso-style-type:export-only;}
/* Page Definitions */
@page WordSection1
	{size:612.0pt 792.0pt;
	margin:99.25pt 30.0mm 30.0mm 30.0mm;}
div.WordSection1
	{page:WordSection1;}
-->Dear Martin-san, Sorry for my misunderstanding.  The issue in question is not in my scope.Please forget and discard the e-mail I sent you. Thanks, Jisho-Iemoto Windows 10 版のメールから送信 差出人: 上月 秀一送信日時: 2020年9月12日 11:55宛先: keras-team/autokeras件名: RE: [keras-team/autokeras] ""Oracle triggered exit"" for ak.StructuredDataClassifier (#1046) Dear Martin-san, Thanks for your input.  However, I can’t understand what you mean about “Can you please re-open this issue?”Could you kindly tell me what I shall do with the article/issue? Thanks Jisho-Iemoto Windows 10 版のメールから送信 差出人: Mike Martin送信日時: 2020年9月12日 11:50宛先: keras-team/autokerasCC: Subscribed件名: Re: [keras-team/autokeras] ""Oracle triggered exit"" for ak.StructuredDataClassifier (#1046) @utkarshgupta137 @haifeng-jin This issue is absolutely not solved in the latest version. I'm still getting this on 1.0.8. Can you please re-open this issue?—You are receiving this because you are subscribed to this thread.Reply to this email directly, view it on GitHub, or unsubscribe.  ",font math style margin justify link color blue underline page page size margin page dear sorry misunderstanding issue question forget discard sent thanks oracle triggered exit dear thanks input however understand mean please issue could kindly tell shall thanks mike oracle triggered exit issue absolutely latest version still getting please issue directly view,issue,positive,positive,positive,positive,positive,positive
691390818,"<!--
/* Font Definitions */
@font-face
	{font-family:""Cambria Math"";
	panose-1:2 4 5 3 5 4 6 3 2 4;}
@font-face
	{font-family:""Yu Gothic"";
	panose-1:2 11 4 0 0 0 0 0 0 0;}
@font-face
	{font-family:""MS PGothic"";
	panose-1:2 11 6 0 7 2 5 8 2 4;}
@font-face
	{font-family:""Yu Gothic"";
	panose-1:2 11 4 0 0 0 0 0 0 0;}
@font-face
	{font-family:""MS PGothic"";}
/* Style Definitions */
p.MsoNormal, li.MsoNormal, div.MsoNormal
	{margin:0mm;
	text-align:justify;
	text-justify:inter-ideograph;
	font-size:10.5pt;
	font-family:""游ゴシック"",sans-serif;}
a:link, span.MsoHyperlink
	{mso-style-priority:99;
	color:blue;
	text-decoration:underline;}
.MsoChpDefault
	{mso-style-type:export-only;}
/* Page Definitions */
@page WordSection1
	{size:612.0pt 792.0pt;
	margin:99.25pt 30.0mm 30.0mm 30.0mm;}
div.WordSection1
	{page:WordSection1;}
-->Dear Martin-san, Thanks for your input.  However, I can’t understand what you mean about “Can you please re-open this issue?”Could you kindly tell me what I shall do with the article/issue? Thanks Jisho-Iemoto Windows 10 版のメールから送信 差出人: Mike Martin送信日時: 2020年9月12日 11:50宛先: keras-team/autokerasCC: Subscribed件名: Re: [keras-team/autokeras] ""Oracle triggered exit"" for ak.StructuredDataClassifier (#1046) @utkarshgupta137 @haifeng-jin This issue is absolutely not solved in the latest version. I'm still getting this on 1.0.8. Can you please re-open this issue?—You are receiving this because you are subscribed to this thread.Reply to this email directly, view it on GitHub, or unsubscribe. ",font math style margin justify link color blue underline page page size margin page dear thanks input however understand mean please issue could kindly tell shall thanks mike oracle triggered exit issue absolutely latest version still getting please issue directly view,issue,positive,positive,positive,positive,positive,positive
691389816,@utkarshgupta137 @haifeng-jin This issue is absolutely not solved in the latest version. I'm still getting this on 1.0.8. Can you please re-open this issue?,issue absolutely latest version still getting please issue,issue,negative,positive,positive,positive,positive,positive
691323130,"I also have the same issue, maybe after I upgraded Auto-Keras and other packages relating to it.
Since it took somewhat a long time, I guess keras-tuner should be taken into account as well (this is just my opinion without any evidence).

When using the old version, I encountered shape mismatch error, so I updated Auto-Keras ->1.0.8.",also issue maybe since took somewhat long time guess taken account well opinion without evidence old version shape mismatch error,issue,negative,positive,neutral,neutral,positive,positive
691251615,"> @Karim-53 Thank you for the reply.
> I just tried.
> The solution is a little bit tricky.
> This code runs fine. You can use it as a reference.
> 
> ```python
> import autokeras as ak
> import numpy as np
> from sklearn.model_selection import train_test_split
> 
> 
> n_points = 100
> n_features = 6
> n_classes = 10
> X = np.random.rand(n_points, n_features)
> print(X.shape, X.dtype)# random (100, 6) shaped array
> y = np.random.randint(low=0, high=n_classes, size=n_points)
> print(y.shape, y.dtype)
> X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)
> 
> clf = ak.StructuredDataClassifier(max_trials=1)
> clf.fit(X_train, y_train, epochs=2)
> predicted_y = clf.predict(X_test)
> clf.evaluate(X_test, y_test)
> 
> model = clf.export_model()
> import tensorflow as tf
> 
> X_test = tf.data.Dataset.from_tensor_slices(X_test.astype(np.unicode)).batch(32)
> predicted_y_2 = model.predict(X_test)
> print(predicted_y_2)
> ```

Running into the same issue – so seems like the solution to wrap the data into a tfds object?",thank reply tried solution little bit tricky code fine use reference python import ak import import print random shaped array print model import print running issue like solution wrap data object,issue,positive,negative,neutral,neutral,negative,negative
688551660,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1334?src=pr&el=h1) Report
> :exclamation: No coverage uploaded for pull request base (`bert@0f1fb90`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1334/graphs/tree.svg?width=650&height=150&src=pr&token=yDvddb2DDZ)](https://codecov.io/gh/keras-team/autokeras/pull/1334?src=pr&el=tree)

```diff
@@           Coverage Diff            @@
##             bert     #1334   +/-   ##
========================================
  Coverage        ?   100.00%           
========================================
  Files           ?        41           
  Lines           ?      2336           
  Branches        ?         0           
========================================
  Hits            ?      2336           
  Misses          ?         0           
  Partials        ?         0           
```



------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1334?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1334?src=pr&el=footer). Last update [0f1fb90...e76dfa5](https://codecov.io/gh/keras-team/autokeras/pull/1334?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",report exclamation coverage pull request base click learn coverage impacted file tree graph coverage coverage continue review full report legend click learn absolute relative impact affected missing data powered last update read comment,issue,negative,negative,neutral,neutral,negative,negative
687741603,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1332?src=pr&el=h1) Report
> Merging [#1332](https://codecov.io/gh/keras-team/autokeras/pull/1332?src=pr&el=desc) into [master](https://codecov.io/gh/keras-team/autokeras/commit/8f0f02c42ef999e174b62d4a3a4434f4eacedc0b?el=desc) will **not change** coverage.
> The diff coverage is `100.00%`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1332/graphs/tree.svg?width=650&height=150&src=pr&token=yDvddb2DDZ)](https://codecov.io/gh/keras-team/autokeras/pull/1332?src=pr&el=tree)

```diff
@@            Coverage Diff            @@
##            master     #1332   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           39        39           
  Lines         2251      2258    +7     
=========================================
+ Hits          2251      2258    +7     
```


| [Impacted Files](https://codecov.io/gh/keras-team/autokeras/pull/1332?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [autokeras/blocks/basic.py](https://codecov.io/gh/keras-team/autokeras/pull/1332/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2Jsb2Nrcy9iYXNpYy5weQ==) | `100.00% <100.00%> (ø)` | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1332?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1332?src=pr&el=footer). Last update [8f0f02c...9d5a076](https://codecov.io/gh/keras-team/autokeras/pull/1332?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",report master change coverage coverage impacted file tree graph coverage master coverage impacted coverage continue review full report legend click learn absolute relative impact affected missing data powered last update da read comment,issue,negative,positive,neutral,neutral,positive,positive
687687443,@kevinkit Thank a lot for making a perfect guideline !,thank lot making perfect guideline,issue,positive,positive,positive,positive,positive,positive
687399827,"Alright, no problem. I will work on it and create pull request. 👍 ",alright problem work create pull request,issue,negative,neutral,neutral,neutral,neutral,neutral
687219287,"We didn't expect people would want to set this parameter. Currently, they are not fixed but tunable. So anyone who is interested in this feature is welcome to pull request. Thanks!",expect people would want set parameter currently fixed tunable anyone interested feature welcome pull request thanks,issue,positive,positive,positive,positive,positive,positive
687215793,This should be resolved in the latest release of AutoKeras 1.0.8. Are you using this one? Would you share the code and the full error message with us? Thanks. @lephuc2019 ,resolved latest release one would share code full error message u thanks,issue,negative,positive,positive,positive,positive,positive
686981681,I have tested this with v1.0.5 and TF 2.3.0. I can confirm that the issue is completely resolved. Also closed #1210 ,tested confirm issue completely resolved also closed,issue,negative,neutral,neutral,neutral,neutral,neutral
686981118,I can confirm that the issue is resolved in version 1.0.5 with TF 2.3.0. Thanks @haifeng-jin .,confirm issue resolved version thanks,issue,positive,positive,positive,positive,positive,positive
685752458,"Hi there,

Is there anything I can do? I've been testing this and it's really strange, a model will work on keras if I send it to the dataframe but when I take those same dataframes and pass them to autokeras, it just hangs.",hi anything testing really strange model work send take pas,issue,negative,negative,neutral,neutral,negative,negative
683637276,"Thanks @haifeng-jin. In my case, it was solved by preparing correct shapes for x_train, y_train and x_test while I was reading my data from pandas dataframe.",thanks case correct reading data,issue,negative,positive,positive,positive,positive,positive
683594945,"ImportError: cannot import name 'image_preprocessing' from 'tensorflow.python.keras.layers.preprocessing' (C:\Users\acer\miniconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\keras\layers\preprocessing\__init__.py)

Getting this error on windows 10",import name getting error,issue,negative,neutral,neutral,neutral,neutral,neutral
683230217,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1324?src=pr&el=h1) Report
> Merging [#1324](https://codecov.io/gh/keras-team/autokeras/pull/1324?src=pr&el=desc) into [master](https://codecov.io/gh/keras-team/autokeras/commit/d23d5108ac5d449501f99ce6a68b2fb1f1daad44?el=desc) will **not change** coverage.
> The diff coverage is `100.00%`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1324/graphs/tree.svg?width=650&height=150&src=pr&token=yDvddb2DDZ)](https://codecov.io/gh/keras-team/autokeras/pull/1324?src=pr&el=tree)

```diff
@@            Coverage Diff            @@
##            master     #1324   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           39        39           
  Lines         2248      2251    +3     
=========================================
+ Hits          2248      2251    +3     
```


| [Impacted Files](https://codecov.io/gh/keras-team/autokeras/pull/1324?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [autokeras/tasks/structured\_data.py](https://codecov.io/gh/keras-team/autokeras/pull/1324/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL3Rhc2tzL3N0cnVjdHVyZWRfZGF0YS5weQ==) | `100.00% <100.00%> (ø)` | |
| [autokeras/tuners/task\_specific.py](https://codecov.io/gh/keras-team/autokeras/pull/1324/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL3R1bmVycy90YXNrX3NwZWNpZmljLnB5) | `100.00% <100.00%> (ø)` | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1324?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1324?src=pr&el=footer). Last update [d23d510...0b8a195](https://codecov.io/gh/keras-team/autokeras/pull/1324?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",report master change coverage coverage impacted file tree graph coverage master coverage impacted coverage continue review full report legend click learn absolute relative impact affected missing data powered last update ba read comment,issue,negative,positive,neutral,neutral,positive,positive
683160097,"For fun, I tried to take my df and do .fillna(0)  - now autokeras start within a few seconds. Is there a way to do classification with NaN values in a dataset?",fun tried take start within way classification nan,issue,positive,positive,positive,positive,positive,positive
683156994,"I thought maybe because my data has many different types of data it would be a issue so I created a dict of column_types for the fit function but no luck.  

Also if it helps I'm running this on a GPU and a TPU. Both have the same effect, except GPU seems to crash within few min due to memory crash but TPU just keeps running.",thought maybe data many different data would issue fit function luck also running effect except crash within min due memory crash running,issue,negative,positive,positive,positive,positive,positive
683146539,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1322?src=pr&el=h1) Report
> Merging [#1322](https://codecov.io/gh/keras-team/autokeras/pull/1322?src=pr&el=desc) into [master](https://codecov.io/gh/keras-team/autokeras/commit/1744572839599be78f1f255af946d1972bd921cc?el=desc) will **not change** coverage.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1322/graphs/tree.svg?width=650&height=150&src=pr&token=yDvddb2DDZ)](https://codecov.io/gh/keras-team/autokeras/pull/1322?src=pr&el=tree)

```diff
@@            Coverage Diff            @@
##            master     #1322   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           39        39           
  Lines         2243      2273   +30     
=========================================
+ Hits          2243      2273   +30     
```


| [Impacted Files](https://codecov.io/gh/keras-team/autokeras/pull/1322?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [autokeras/tuners/task\_specific.py](https://codecov.io/gh/keras-team/autokeras/pull/1322/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL3R1bmVycy90YXNrX3NwZWNpZmljLnB5) | `100.00% <0.00%> (ø)` | |
| [autokeras/tasks/structured\_data.py](https://codecov.io/gh/keras-team/autokeras/pull/1322/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL3Rhc2tzL3N0cnVjdHVyZWRfZGF0YS5weQ==) | `100.00% <0.00%> (ø)` | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1322?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1322?src=pr&el=footer). Last update [1744572...b1ad143](https://codecov.io/gh/keras-team/autokeras/pull/1322?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",report master change coverage coverage impacted file tree graph coverage master coverage impacted coverage continue review full report legend click learn absolute relative impact affected missing data powered last update bad read comment,issue,negative,negative,neutral,neutral,negative,negative
683055121,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1321?src=pr&el=h1) Report
> Merging [#1321](https://codecov.io/gh/keras-team/autokeras/pull/1321?src=pr&el=desc) into [master](https://codecov.io/gh/keras-team/autokeras/commit/1744572839599be78f1f255af946d1972bd921cc?el=desc) will **not change** coverage.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1321/graphs/tree.svg?width=650&height=150&src=pr&token=yDvddb2DDZ)](https://codecov.io/gh/keras-team/autokeras/pull/1321?src=pr&el=tree)

```diff
@@            Coverage Diff            @@
##            master     #1321   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           39        39           
  Lines         2243      2243           
=========================================
  Hits          2243      2243           
```



------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1321?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1321?src=pr&el=footer). Last update [1744572...f11a68e](https://codecov.io/gh/keras-team/autokeras/pull/1321?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",report master change coverage coverage impacted file tree graph coverage master coverage continue review full report legend click learn absolute relative impact affected missing data powered last update fae read comment,issue,negative,positive,neutral,neutral,positive,positive
682688033,Sorry about this bug. The main problem is that currently `ak.Input()` is not very well supported. We will try to get to this. Not sure how many people is using this input node.,sorry bug main problem currently well try get sure many people input node,issue,negative,positive,positive,positive,positive,positive
682685936,"For StructuredDataClassifier or Regressor, after you export the model, you should convert your data to np.unicode first before feeding into the exported model.",regressor export model convert data first feeding model,issue,negative,positive,positive,positive,positive,positive
682187552,"If it helps, this is my code (after I normalize and encode my data):
```
df.to_csv(""./encoded.csv"")
autokerasFile = ""./encoded.csv""
import autokeras as ak
# try using autokeras for imputation
# Initialize the structured data classifier.
clf = ak.StructuredDataClassifier(
    overwrite=True,
    max_trials=3) # It tries 3 different models.
# Feed the structured data classifier with training data.
clf.fit(
    # The path to the train.csv file.
    autokerasFile,
    # The name of the label column.
    'Exchange',
    epochs=100,
    verbose=True)
# Predict with the best model.
predicted_y = clf.predict(autokerasFile)
# Evaluate the best model with testing data.
print(clf.evaluate(autokerasFile, 'Exchange'))
```

At this point is pretty much just hangs. I can see memory usage changing but no output.

Let me know if there is any other information I can provide - Thank you.

Edit - My keras model ran within a few seconds of starting it. The AK model has yet to start and it's been over 15 hours. When testing with other datasets, it seemed to work..it seems to be something with my dataset I suspect but I can't figure out why because I'm not getting any messages/errors.",code normalize encode data import ak try imputation initialize structured data classifier different feed structured data classifier training data path file name label column predict best model evaluate best model testing data print point pretty much see memory usage output let know information provide thank edit model ran within starting ak model yet start testing work something suspect ca figure getting,issue,positive,positive,positive,positive,positive,positive
682184052,"Hi Haifeng, Thank you for the reply.  I am using 1.0.8.

```
import autokeras as ak
ak.__version__
1.0.8
```

Not sure if it makes a difference but my data is large(800mb uncompressed), has mixed categorical and continuous datapoints, and has quite a few NAN values.

So far, I've encoded the data, scaled it and ran both the structured data regressor as well as the classifier. Both are having the same behaviour.",hi thank reply import ak sure difference data large uncompressed mixed categorical continuous quite nan far data scaled ran structured data regressor well classifier behaviour,issue,positive,positive,positive,positive,positive,positive
681227271,"Yes. I think 1.0.0 is compatible with TF 2.1.0.
AutoKeras is still not stable enough and under active development.
We are still pending on some future features of tensorflow.
So in the near future, we will always based on the latest TensorFlow version.

I think from 1.0.3 on AutoKeras will raise an error if your TensorFlow version is not compatible.",yes think compatible still stable enough active development still pending future near future always based latest version think raise error version compatible,issue,positive,positive,neutral,neutral,positive,positive
681216150,I have never seen this error before. We just changed the search space for structured data tasks. You may try again with 1.0.8. Le tme know if it still doesn't work.,never seen error search space structured data may try know still work,issue,negative,neutral,neutral,neutral,neutral,neutral
681208169,"```python
import autokeras as ak
import numpy as np

from keras.datasets import boston_housing
(x_train, y_train), (x_test, y_test) = boston_housing.load_data()

reg = ak.StructuredDataRegressor(max_trials=3, directory='./boston', seed=10)
reg.fit(x_train, y_train, epochs=10)

model = reg.export_model()
model.predict(x_test.astype(np.unicode))
```
This code works for me.",python import ak import import reg model code work,issue,negative,neutral,neutral,neutral,neutral,neutral
681180341,"I have the same error as @maxmarketit. @haifeng-jin do you have any idea why it happens? Might it be connected with tensorflow version?
",error idea might connected version,issue,negative,neutral,neutral,neutral,neutral,neutral
680745189,"@toohsk Yes, please. Thank you! I think it is good to try these Keras dataset first.",yes please thank think good try first,issue,positive,positive,positive,positive,positive,positive
680721570,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1314?src=pr&el=h1) Report
> Merging [#1314](https://codecov.io/gh/keras-team/autokeras/pull/1314?src=pr&el=desc) into [master](https://codecov.io/gh/keras-team/autokeras/commit/d6129a0270d2ef42f5c60c38f94e42b84f36d930?el=desc) will **not change** coverage.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1314/graphs/tree.svg?width=650&height=150&src=pr&token=yDvddb2DDZ)](https://codecov.io/gh/keras-team/autokeras/pull/1314?src=pr&el=tree)

```diff
@@            Coverage Diff            @@
##            master     #1314   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           39        39           
  Lines         2243      2243           
=========================================
  Hits          2243      2243           
```



------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1314?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1314?src=pr&el=footer). Last update [d6129a0...100f617](https://codecov.io/gh/keras-team/autokeras/pull/1314?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",report master change coverage coverage impacted file tree graph coverage master coverage continue review full report legend click learn absolute relative impact affected missing data powered last update da read comment,issue,negative,positive,neutral,neutral,positive,positive
680247625,"This bug still exists:
`clf = ak.AutoModel(inputs=ak.Input(),outputs=ak.ClassificationHead(num_classes=2),overwrite=True,max_trials=1)`
ouputs:
```
/usr/local/lib/python3.6/dist-packages/autokeras/auto_model.py in _assemble(self)
    203             output_node = blocks.Merge()(middle_nodes)
    204         else:
--> 205             output_node = middle_nodes[0]
    206 
    207         outputs = nest.flatten(

IndexError: list index out of range
```

OS type and version: Google colab
Python: 3.6
autokeras: 1.0.7
keras-tuner: 1.0.2rc1
scikit-learn: 0.22.2.post1
numpy: 1.18.5
pandas: 1.0.5
tensorflow: 2.3.0",bug still self else list index range o type version python post,issue,negative,neutral,neutral,neutral,neutral,neutral
679273430,@mandalbiswadip Would you like to take this one?,would like take one,issue,negative,neutral,neutral,neutral,neutral,neutral
679156605,"> 
> 
> Since every release is fixing important bugs. We always expect the users to use the latest version.

That would be a little bit too ambitious.

To be more specific, which version of autokeras would have no issue with TensorFlow 2.1.0? 1.0.0?",since every release fixing important always expect use latest version would little bit ambitious specific version would issue,issue,positive,positive,positive,positive,positive,positive
678891104,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1305?src=pr&el=h1) Report
> Merging [#1305](https://codecov.io/gh/keras-team/autokeras/pull/1305?src=pr&el=desc) into [master](https://codecov.io/gh/keras-team/autokeras/commit/a567a00dd26a89d98c835a06f0c107762a0e2d3b?el=desc) will **not change** coverage.
> The diff coverage is `100.00%`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1305/graphs/tree.svg?width=650&height=150&src=pr&token=yDvddb2DDZ)](https://codecov.io/gh/keras-team/autokeras/pull/1305?src=pr&el=tree)

```diff
@@            Coverage Diff            @@
##            master     #1305   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           39        39           
  Lines         2236      2236           
=========================================
  Hits          2236      2236           
```


| [Impacted Files](https://codecov.io/gh/keras-team/autokeras/pull/1305?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [autokeras/utils/utils.py](https://codecov.io/gh/keras-team/autokeras/pull/1305/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL3V0aWxzL3V0aWxzLnB5) | `100.00% <100.00%> (ø)` | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1305?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1305?src=pr&el=footer). Last update [a567a00...3c379b1](https://codecov.io/gh/keras-team/autokeras/pull/1305?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",report master change coverage coverage impacted file tree graph coverage master coverage impacted coverage continue review full report legend click learn absolute relative impact affected missing data powered last update aa read comment,issue,negative,positive,neutral,neutral,positive,positive
678718396,I just fix the bug in master branch. will have a new release soon after thorough tests,fix bug master branch new release soon thorough,issue,negative,positive,positive,positive,positive,positive
678712376,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1300?src=pr&el=h1) Report
> Merging [#1300](https://codecov.io/gh/keras-team/autokeras/pull/1300?src=pr&el=desc) into [master](https://codecov.io/gh/keras-team/autokeras/commit/736078b9ea48628f5199bb627271c265ac64b53b?el=desc) will **not change** coverage.
> The diff coverage is `100.00%`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1300/graphs/tree.svg?width=650&height=150&src=pr&token=yDvddb2DDZ)](https://codecov.io/gh/keras-team/autokeras/pull/1300?src=pr&el=tree)

```diff
@@            Coverage Diff            @@
##            master     #1300   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           39        39           
  Lines         2229      2236    +7     
=========================================
+ Hits          2229      2236    +7     
```


| [Impacted Files](https://codecov.io/gh/keras-team/autokeras/pull/1300?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [autokeras/blocks/basic.py](https://codecov.io/gh/keras-team/autokeras/pull/1300/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2Jsb2Nrcy9iYXNpYy5weQ==) | `100.00% <100.00%> (ø)` | |
| [autokeras/tuners/greedy.py](https://codecov.io/gh/keras-team/autokeras/pull/1300/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL3R1bmVycy9ncmVlZHkucHk=) | `100.00% <100.00%> (ø)` | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1300?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1300?src=pr&el=footer). Last update [736078b...2e5999a](https://codecov.io/gh/keras-team/autokeras/pull/1300?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",report master change coverage coverage impacted file tree graph coverage master coverage impacted coverage continue review full report legend click learn absolute relative impact affected missing data powered last update ea read comment,issue,negative,positive,neutral,neutral,positive,positive
678662507,"Issue maybe not related to autokeras. When I try a much smaller dataset, I get a message - 
```
/usr/local/lib/python3.6/dist-packages/kerastuner/engine/metrics_tracking.py:92: RuntimeWarning: All-NaN axis encountered
  return np.nanmin(values)

But when I use a larger datset, that message doesn't even appear. 
```",issue maybe related try much smaller get message axis return use message even appear,issue,negative,neutral,neutral,neutral,neutral,neutral
678602075,Since every release is fixing important bugs. We always expect the users to use the latest version.,since every release fixing important always expect use latest version,issue,negative,positive,positive,positive,positive,positive
678500447,"@haifeng-jin do checkout the changes. I have also created a [gist](https://gist.github.com/mandalbiswadip/3a475d53e3fc3352acac1fdf86479150) for the same. Also, there is no pre-defined evaluation/test set for the wine dataset and hence I have used a chunk (20%) of the available data as an evaluation dataset. ",also gist also set wine hence used chunk available data evaluation,issue,negative,positive,positive,positive,positive,positive
678426617,@haifeng-jin sure. I would be happy to take it up.,sure would happy take,issue,positive,positive,positive,positive,positive,positive
678413370,"@mandalbiswadip We also want to remove the titanic csv files from the repo some time in the future. If you would like to help us with it after this PR, I can give you the instructions. Thanks.",also want remove titanic time future would like help u give thanks,issue,positive,positive,neutral,neutral,positive,positive
678398103,"@ywtaccelerator @AnSmithD I have had another fix for the bug merged. I tested it with the [mnist example](https://github.com/keras-team/autokeras/blob/master/examples/mnist.py) by adding the distribution_strategy argument to it. It runs fine now.

Before this fix it also runs fine for the fit function but not for the predict and evaluate function.
I cannot reproduce the bug of failing on the second trail.

Please paste the entire stack trace if it still doesn't work.
Also please try if the mnist example works.

Thank you!",another fix bug tested example argument fine fix also fine fit function predict evaluate function reproduce bug failing second trail please paste entire stack trace still work also please try example work thank,issue,positive,positive,positive,positive,positive,positive
678388837,@haifeng-jin  The dataset isn't available in tensorflow-datasets. Is it fine if I use the dataset link from [UCI repository](https://archive.ics.uci.edu/ml/datasets/wine) to download the dataset? ,available fine use link repository,issue,negative,positive,positive,positive,positive,positive
678036037,"@haifeng-jin 
As you commented in the previous issue #1283, I created a pull request.
Would you review and merge it?
Thanks.",previous issue pull request would review merge thanks,issue,negative,positive,neutral,neutral,positive,positive
677893671,"The feature for using `git+` in setup.py is deprecated by pypi.
So I believe we have to wait until the next stable release of Keras Tuner.

For tensorflow-gpu, we actually don't need it. Now `tensorflow` package can work on GPU.

We will look into the absl-py to figure out the problem.

Thank you!",feature believe wait next stable release tuner actually need package work look figure problem thank,issue,negative,neutral,neutral,neutral,neutral,neutral
677878444,"true tf 2.3.0 is installed with pip, but not the tensorflow-gpu version


You can add these dependencies to the setup.py file by replacing your current install_requires=[ ] to


    install_requires=[
        'packaging',
        'tensorflow-gpu>=2.3.0', # Changed this to the gpu version
        'scikit-learn',
        'pandas',
        'absl-py', # Needed for something in either AutoKeras or Tensorflow

       'git+https://github.com/keras-team/keras-tuner.git@1.0.2rc1', # I think this will work. It at least works when you do pip install git+https://github.com/keras-team/keras-tuner.git@1.0.2rc1

    ],


I have also added spaces to this bit of code to align everything. This text filed doesn't allow me to put tabs. Do not copy and paste it into your setup.py file
",true pip version add file current version something either think work least work pip install also added bit code align everything text allow put copy paste file,issue,positive,positive,neutral,neutral,positive,positive
677869294,We are actually supporting it in the latest release. The ResNetBlock and XceptionBlock all have a hyperparam called pretrained to control it.,actually supporting latest release control,issue,negative,positive,positive,positive,positive,positive
677868321,"Hi @WilliamJudge94 , Thank you for the report.
I am not very familiar with conda and setup.py.
We can install it with pip fine.

I think tf 2.3 is already in setup.py.
Is there a way to add a git+https to setup.py? Thanks.",hi thank report familiar install pip fine think already way add thanks,issue,positive,positive,positive,positive,positive,positive
677726507,"Got it!
First, I'll try from adding .py file and send it as a pull request 👍 ",got first try file send pull request,issue,negative,positive,positive,positive,positive,positive
677633607,"@ywtaccelerator Have you tried uninstalling autokeras and keras-tuner first? And then reinstalling keras-tuner directly via `pip3 install git+https://github.com/keras-team/keras-tuner.git` and **only afterwards** installing autokeras from the master branch?

@haifeng-jin 's fix is working for me (after above described procedure) but unfortunately, it does not seem to result in any performance gains in terms of computing time ... ",tried first directly via pip install afterwards master branch fix working procedure unfortunately seem result performance gain time,issue,negative,negative,neutral,neutral,negative,negative
677510719,"@haifeng-jin Yes, after I installed AutoKeras from the master branch (ak.version shows its version is 1.0.7), the code snippet above works well and a previously finished (or killed) run can be resumed. Thank you very much for your effort!",yes master branch version code snippet work well previously finished run thank much effort,issue,positive,positive,neutral,neutral,positive,positive
677496310,"@haifeng-jin Thank you very much for your effort and fixing it quickly, but unfortunately it still does not work for me. I have installed AutoKeras from the master branch and ak.__version__ shows its version is 1.0.7, but neither running the Simple Example [here](https://autokeras.com/tutorial/image_classification/) directly, nor trying the ways mentioned above in this page, could make use of multiple GPUs...

Could you double check if it functions well, or briefly describe how to make it work? Thanks!",thank much effort fixing quickly unfortunately still work master branch version neither running simple example directly trying way page could make use multiple could double check well briefly describe make work thanks,issue,positive,positive,neutral,neutral,positive,positive
677446263,"@haifeng-jin May tensorflow.keras.utils.Sequence be another way to support? It's just like torch.Dataset class, and may be easy to apply in code.I used Sequence for huge numpy array which is stored in a h5py file, it just be read to RAM when __getitem__ is called.",may another way support like class may easy apply used sequence huge array file read ram,issue,positive,positive,positive,positive,positive,positive
675796786,I think this issue is already resolved as we update the greedy tuner. It is caused by loading the hypermodel. Now we don't load the hypermodel anymore when loading the oracle.,think issue already resolved update greedy tuner loading load loading oracle,issue,negative,neutral,neutral,neutral,neutral,neutral
675752274,Thanks for the reply. I got what I was looking for. ,thanks reply got looking,issue,negative,positive,positive,positive,positive,positive
675222602,@mandalbiswadip Would you help us test the Wine dataset? Thank you!,would help u test wine thank,issue,positive,neutral,neutral,neutral,neutral,neutral
675221998,"Thank you! You can just pull request to the examples folder with a .py file, which has the same content as your gist.
You can also comment on the 1219 issue with the corresponding fields. I will add it to the table.",thank pull request folder file content gist also comment issue corresponding add table,issue,negative,neutral,neutral,neutral,neutral,neutral
675168718,@FontTian @ywtaccelerator @AnSmithD This bug is fixed in master branch. Please refer to #1285 for fixing details. Thanks.,bug fixed master branch please refer fixing thanks,issue,positive,positive,positive,positive,positive,positive
675163988,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1285?src=pr&el=h1) Report
> Merging [#1285](https://codecov.io/gh/keras-team/autokeras/pull/1285?src=pr&el=desc) into [master](https://codecov.io/gh/keras-team/autokeras/commit/9b0a6a8d7143161c178fb6bba957e1d99e9944ca&el=desc) will **not change** coverage.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1285/graphs/tree.svg?width=650&height=150&src=pr&token=yDvddb2DDZ)](https://codecov.io/gh/keras-team/autokeras/pull/1285?src=pr&el=tree)

```diff
@@            Coverage Diff            @@
##            master     #1285   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           39        39           
  Lines         2223      2222    -1     
=========================================
- Hits          2223      2222    -1     
```


| [Impacted Files](https://codecov.io/gh/keras-team/autokeras/pull/1285?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [autokeras/graph.py](https://codecov.io/gh/keras-team/autokeras/pull/1285/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2dyYXBoLnB5) | `100.00% <ø> (ø)` | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1285?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1285?src=pr&el=footer). Last update [9b0a6a8...6d57038](https://codecov.io/gh/keras-team/autokeras/pull/1285?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",report master change coverage coverage impacted file tree graph coverage master coverage impacted coverage continue review full report legend click learn absolute relative impact affected missing data powered last update baa read comment,issue,negative,positive,neutral,neutral,positive,positive
674678401,@haifeng-jin Can I take up few of the datasets from the list and work on them? Let me know which ones are yet to be tested out.,take list work let know yet tested,issue,negative,neutral,neutral,neutral,neutral,neutral
674573852,"> I guess the latest commits (after the commit `e4a5dbe7e29d64c9b095d134f0ca2a5543353dda`) require `kerastuner` of version 1.0rc0:
> 
> `pip install git+https://github.com/keras-team/keras-tuner.git@1.0rc0`
> 
> You may refer to this commit:
> 
> [e4a5dbe](https://github.com/keras-team/autokeras/commit/e4a5dbe7e29d64c9b095d134f0ca2a5543353dda)

This worked for me. Thanks.",guess latest commit require version pip install may refer commit worked thanks,issue,positive,positive,positive,positive,positive,positive
674460947,"I think this example should work in 1.0.5. Which version are you using now? Thanks.
",think example work version thanks,issue,negative,positive,positive,positive,positive,positive
674460817,You need to checkout the 0.4 version and lower. There is a bayesian optimization implemented. You can find the loss there. The 1.0+ is not following the paper anymore.,need version lower optimization find loss following paper,issue,negative,neutral,neutral,neutral,neutral,neutral
674453905,The weight sharing may negatively impact the performance like using pretrained models but tuning learning rate.,weight may negatively impact performance like tuning learning rate,issue,negative,negative,negative,negative,negative,negative
674443466,"@haifeng-jin Thank you! Looking forward to the solving of this issue, I really appreciate your work in AutoKeras.",thank looking forward issue really appreciate work,issue,positive,positive,positive,positive,positive,positive
674442856,"@haifeng-jin Thank you! The multi GPU issue has been my biggest headache for days, although I know there must be some more important issues for you to solve first :)",thank issue biggest headache day although know must important solve first,issue,positive,positive,positive,positive,positive,positive
674441305,"> @haifeng-jin Sorry, I think you misunderstood my discription of the bug. I have seen [this page](https://autokeras.com/tutorial/faq/) before I filed this issue and till now there is no change in this page, with autokeras==1.0.5, following my steps for reproducing the bug, the bug can still be reproduced, and my code for reproducing the bug exactly follows the discription in the [FAQ](https://autokeras.com/tutorial/faq/).
> 
> 
> 
> My workaround here temporarily solved the bug of not being able to resume a previously finished (or killed) run when a custom objective (or to be more precise, ""metric"", and not a built-in one like 'mse') was used, by using ""custom object scope"", which is not described in the [FAQ](https://autokeras.com/tutorial/faq/).
> 
> 
> 
> So could you have a look at my discription of the bug again? The bug still exists and I hope one day it can be solved officially, thank you! I really appreciate your work in AutoKeras.

Got u! I will get to this one after the multi GPU issue solved.",sorry think misunderstood bug seen page issue till change page following bug bug still code bug exactly temporarily bug able resume previously finished run custom objective precise metric one like used custom object scope could look bug bug still hope one day officially thank really appreciate work got get one issue,issue,positive,positive,neutral,neutral,positive,positive
674441012,"@haifeng-jin Sorry, I think you misunderstood my discription of the bug. I have seen [this page](https://autokeras.com/tutorial/faq/) before I filed this issue and till now there is no change in this page, with autokeras==1.0.5, following my steps for reproducing the bug, the bug can still be reproduced, and my code for reproducing the bug exactly follows the discription in the [FAQ](https://autokeras.com/tutorial/faq/).

My workaround here temporarily solved the bug of not being able to resume a previously finished (or killed) run when a custom objective (or to be more precise, ""metric"", and not a built-in one like 'mse') was used, by using ""custom object scope"", which is not described in the [FAQ](https://autokeras.com/tutorial/faq/).

So could you have a look at my discription of the bug again? The bug still exists and I hope one day it can be solved officially, thank you! I really appreciate your work in AutoKeras.",sorry think misunderstood bug seen page issue till change page following bug bug still code bug exactly temporarily bug able resume previously finished run custom objective precise metric one like used custom object scope could look bug bug still hope one day officially thank really appreciate work,issue,positive,positive,neutral,neutral,positive,positive
674421881,"> @haifeng-jin Sorry but I did not find a solution to resuming a previously finished (or killed) run when a custom objective was used  in [the website of AutoKeras](https://autokeras.com/), my solution above is just a workaround to this problem and I have not fully tested it yet, if there is an official workaround to this bug, could you give a link to the solution you mentioned? Thanks!

The solution is here. The same as yours.
https://autokeras.com/tutorial/faq/",sorry find solution previously finished run custom objective used solution problem fully tested yet official bug could give link solution thanks solution,issue,positive,negative,negative,negative,negative,negative
674417543,"@haifeng-jin Sorry but I did not find a solution to resuming a previously finished (or killed) run when a custom objective was used  in [the website of AutoKeras](https://autokeras.com/), my solution above is just a workaround to this problem and I have not fully tested it yet, if there is an official workaround to this bug, could you give a link to the solution you mentioned? Thanks!",sorry find solution previously finished run custom objective used solution problem fully tested yet official bug could give link solution thanks,issue,positive,negative,negative,negative,negative,negative
674364044,@ywtaccelerator  I am working on another issue related to the tuner right now. Will get to this one right afterwards. Thanks,working another issue related tuner right get one right afterwards thanks,issue,negative,positive,positive,positive,positive,positive
674363756,"@ywtaccelerator Thank you! I think the solution is similar to the one in FAQ on our website, right?",thank think solution similar one right,issue,positive,positive,positive,positive,positive,positive
674132833,"Hi, is there any update on this topic? Is there currently a workaround to make use of multiple GPUs?",hi update topic currently make use multiple,issue,negative,neutral,neutral,neutral,neutral,neutral
674132595,"Hi, I have come up with a simple workaround for this bug and it seems to work well for me these days:

Using custom object scope: 
Import
`from tensorflow.keras.utils import CustomObjectScope`
and add
`with CustomObjectScope({'f1_score': f1_score}):`
before initializing the classifier, so the whole above code snippet will be:

```
from tensorflow.keras.datasets import mnist
import kerastuner

import autokeras as ak

from tensorflow.keras import backend as K
from tensorflow.keras.utils import CustomObjectScope

def recall_m(y_true, y_pred):
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))
    recall = true_positives / (possible_positives + K.epsilon())
    return recall

def precision_m(y_true, y_pred):
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))
    precision = true_positives / (predicted_positives + K.epsilon())
    return precision

def f1_score(y_true, y_pred):
    precision = precision_m(y_true, y_pred)
    recall = recall_m(y_true, y_pred)
    return 2*((precision*recall)/(precision+recall+K.epsilon()))

with CustomObjectScope({'f1_score': f1_score}):
    # Prepare the dataset.
    (x_train, y_train), (x_test, y_test) = mnist.load_data()
    print(x_train.shape)  # (60000, 28, 28)
    print(y_train.shape)  # (60000,)
    print(y_train[:3])  # array([7, 2, 1], dtype=uint8)

    # Initialize the ImageClassifier.
    clf = ak.ImageClassifier(
        max_trials=3,
        objective=kerastuner.Objective('val_f1_score', direction='max'),
        metrics=[f1_score],
    )
    # Search for the best model.
    clf.fit(x_train, y_train, epochs=10)
    # Evaluate on the testing data.
    print('Accuracy: {accuracy}'.format(
        accuracy=clf.evaluate(x_test, y_test)))
```

So after running the above code, letting ""max_trials=5"" in ImageClassifier and running the same snippet again, the NAS process will resume and the code will run for two more trials.

Hope this could help you formally solve the bug, by the way, I am more interested in how to make use of multiple GPUs, because the NAS process is too time-consuming... I have tried some ""tricks"" but none of them works :(",hi come simple bug work well day custom object scope import import add classifier whole code snippet import import import ak import import recall return recall precision return precision precision recall return precision recall prepare print print print array initialize search best model evaluate testing data print accuracy running code running snippet process resume code run two hope could help formally solve bug way interested make use multiple process tried none work,issue,positive,positive,positive,positive,positive,positive
673540396,"I had this problem and found out that my file was named autokeras.py, so when I imported the lib, I was actually importing my own file. Changing the file name solved the problem.",problem found file actually file file name problem,issue,negative,neutral,neutral,neutral,neutral,neutral
672809373,"@haifeng-jin sorry for the late response, I was on vacation. I can't update to tf 2.3.0 because I have to wait until conda updates it. I will try it once it's possible. Currently using 1.0.4 with this [workaround](https://github.com/keras-team/autokeras/issues/1210#issuecomment-654956430)",sorry late response vacation ca update wait try possible currently,issue,negative,negative,negative,negative,negative,negative
671298730,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1273?src=pr&el=h1) Report
> Merging [#1273](https://codecov.io/gh/keras-team/autokeras/pull/1273?src=pr&el=desc) into [master](https://codecov.io/gh/keras-team/autokeras/commit/2583f4857acf6dd16dfdacafcf1728f48bc13626&el=desc) will **not change** coverage.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1273/graphs/tree.svg?width=650&height=150&src=pr&token=yDvddb2DDZ)](https://codecov.io/gh/keras-team/autokeras/pull/1273?src=pr&el=tree)

```diff
@@            Coverage Diff            @@
##            master     #1273   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           39        39           
  Lines         2222      2222           
=========================================
  Hits          2222      2222           
```



------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1273?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1273?src=pr&el=footer). Last update [2583f48...11c49e0](https://codecov.io/gh/keras-team/autokeras/pull/1273?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",report master change coverage coverage impacted file tree graph coverage master coverage continue review full report legend click learn absolute relative impact affected missing data powered last update ce read comment,issue,negative,positive,neutral,neutral,positive,positive
669002141,"@haifeng-jin Apols but tried the above

> pip3 install git+https://github.com/keras-team/keras-tuner.git@1.0.2rc0
> pip3 install autokeras==1.0.3

pip3 install tensorflow==2.2.0 but still or
pip install --upgrade tensorflow

```
lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:440 _get_metric_object
        y_t_rank = len(y_t.shape.as_list())

    AttributeError: 'tuple' object has no attribute 'shape'

```
Ubuntu 20.04
",tried pip install pip install pip install still pip install upgrade object attribute,issue,negative,neutral,neutral,neutral,neutral,neutral
668858130,@AnSmithD Thank you for your report. I believe this is a very important bug we need to track down. Would you like to setup a call with us to talk about it? I believe this would be the fastest way to solve it. Please reach me on Slack if you would like to do so. Thank you!,thank report believe important bug need track would like setup call u talk believe would way solve please reach slack would like thank,issue,positive,positive,positive,positive,positive,positive
668857024,This is as expected. We try very different models in the first several trials to quickly locate the models suitable for the dataset. The second model is much larger than the first one.,try different first several quickly locate suitable second model much first one,issue,negative,positive,positive,positive,positive,positive
668856566,I believe this would be a feature in Keras Tuner. The prints are there.,believe would feature tuner,issue,negative,neutral,neutral,neutral,neutral,neutral
668276234,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1271?src=pr&el=h1) Report
> Merging [#1271](https://codecov.io/gh/keras-team/autokeras/pull/1271?src=pr&el=desc) into [master](https://codecov.io/gh/keras-team/autokeras/commit/cf85de326f75745d261b14033c031a32972ae020&el=desc) will **not change** coverage.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1271/graphs/tree.svg?width=650&height=150&src=pr&token=yDvddb2DDZ)](https://codecov.io/gh/keras-team/autokeras/pull/1271?src=pr&el=tree)

```diff
@@            Coverage Diff            @@
##            master     #1271   +/-   ##
=========================================
  Coverage   100.00%   100.00%           
=========================================
  Files           39        39           
  Lines         2222      2222           
=========================================
  Hits          2222      2222           
```



------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1271?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1271?src=pr&el=footer). Last update [cf85de3...405baa6](https://codecov.io/gh/keras-team/autokeras/pull/1271?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",report master change coverage coverage impacted file tree graph coverage master coverage continue review full report legend click learn absolute relative impact affected missing data powered last update baa read comment,issue,negative,positive,neutral,neutral,positive,positive
668203236,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1270?src=pr&el=h1) Report
> Merging [#1270](https://codecov.io/gh/keras-team/autokeras/pull/1270?src=pr&el=desc) into [master](https://codecov.io/gh/keras-team/autokeras/commit/2d922b42911068336875e59a58e4d938ac20db0a&el=desc) will **increase** coverage by `0.94%`.
> The diff coverage is `100.00%`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1270/graphs/tree.svg?width=650&height=150&src=pr&token=yDvddb2DDZ)](https://codecov.io/gh/keras-team/autokeras/pull/1270?src=pr&el=tree)

```diff
@@             Coverage Diff             @@
##           master     #1270      +/-   ##
===========================================
+ Coverage   99.05%   100.00%   +0.94%     
===========================================
  Files          39        39              
  Lines        2226      2222       -4     
===========================================
+ Hits         2205      2222      +17     
+ Misses         21         0      -21     
```


| [Impacted Files](https://codecov.io/gh/keras-team/autokeras/pull/1270?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [autokeras/auto\_model.py](https://codecov.io/gh/keras-team/autokeras/pull/1270/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2F1dG9fbW9kZWwucHk=) | `100.00% <ø> (+1.69%)` | :arrow_up: |
| [autokeras/engine/block.py](https://codecov.io/gh/keras-team/autokeras/pull/1270/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2VuZ2luZS9ibG9jay5weQ==) | `100.00% <ø> (+2.85%)` | :arrow_up: |
| [autokeras/graph.py](https://codecov.io/gh/keras-team/autokeras/pull/1270/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2dyYXBoLnB5) | `100.00% <ø> (+1.80%)` | :arrow_up: |
| [autokeras/utils/data\_utils.py](https://codecov.io/gh/keras-team/autokeras/pull/1270/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL3V0aWxzL2RhdGFfdXRpbHMucHk=) | `100.00% <ø> (+4.76%)` | :arrow_up: |
| [autokeras/encoders.py](https://codecov.io/gh/keras-team/autokeras/pull/1270/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2VuY29kZXJzLnB5) | `100.00% <100.00%> (+5.63%)` | :arrow_up: |
| [autokeras/engine/encoder.py](https://codecov.io/gh/keras-team/autokeras/pull/1270/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2VuZ2luZS9lbmNvZGVyLnB5) | `100.00% <100.00%> (ø)` | |
| [autokeras/engine/tuner.py](https://codecov.io/gh/keras-team/autokeras/pull/1270/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2VuZ2luZS90dW5lci5weQ==) | `100.00% <0.00%> (+1.00%)` | :arrow_up: |
| ... and [4 more](https://codecov.io/gh/keras-team/autokeras/pull/1270/diff?src=pr&el=tree-more) | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1270?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1270?src=pr&el=footer). Last update [2d922b4...495b925](https://codecov.io/gh/keras-team/autokeras/pull/1270?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",report master increase coverage coverage impacted file tree graph coverage master coverage impacted coverage continue review full report legend click learn absolute relative impact affected missing data powered last update read comment,issue,negative,positive,neutral,neutral,positive,positive
667628800,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1267?src=pr&el=h1) Report
> Merging [#1267](https://codecov.io/gh/keras-team/autokeras/pull/1267?src=pr&el=desc) into [master](https://codecov.io/gh/keras-team/autokeras/commit/27d78391ae43194c03213d769bfaae6fb5af4eb7&el=desc) will **increase** coverage by `0.56%`.
> The diff coverage is `100.00%`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1267/graphs/tree.svg?width=650&height=150&src=pr&token=yDvddb2DDZ)](https://codecov.io/gh/keras-team/autokeras/pull/1267?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master    #1267      +/-   ##
==========================================
+ Coverage   95.60%   96.17%   +0.56%     
==========================================
  Files          39       39              
  Lines        2254     2250       -4     
==========================================
+ Hits         2155     2164       +9     
+ Misses         99       86      -13     
```


| [Impacted Files](https://codecov.io/gh/keras-team/autokeras/pull/1267?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [autokeras/adapters/input\_adapter.py](https://codecov.io/gh/keras-team/autokeras/pull/1267/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2FkYXB0ZXJzL2lucHV0X2FkYXB0ZXIucHk=) | `100.00% <100.00%> (+7.64%)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1267?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1267?src=pr&el=footer). Last update [176d04b...a82523a](https://codecov.io/gh/keras-team/autokeras/pull/1267?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",report master increase coverage coverage impacted file tree graph coverage master coverage impacted coverage continue review full report legend click learn absolute relative impact affected missing data powered last update aa read comment,issue,negative,positive,neutral,neutral,positive,positive
667623729,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1266?src=pr&el=h1) Report
> Merging [#1266](https://codecov.io/gh/keras-team/autokeras/pull/1266?src=pr&el=desc) into [master](https://codecov.io/gh/keras-team/autokeras/commit/27d78391ae43194c03213d769bfaae6fb5af4eb7&el=desc) will **decrease** coverage by `0.13%`.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1266/graphs/tree.svg?width=650&height=150&src=pr&token=yDvddb2DDZ)](https://codecov.io/gh/keras-team/autokeras/pull/1266?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master    #1266      +/-   ##
==========================================
- Coverage   95.60%   95.47%   -0.14%     
==========================================
  Files          39       39              
  Lines        2254     2254              
==========================================
- Hits         2155     2152       -3     
- Misses         99      102       +3     
```


| [Impacted Files](https://codecov.io/gh/keras-team/autokeras/pull/1266?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [autokeras/adapters/input\_adapter.py](https://codecov.io/gh/keras-team/autokeras/pull/1266/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2FkYXB0ZXJzL2lucHV0X2FkYXB0ZXIucHk=) | `90.58% <0.00%> (-1.77%)` | :arrow_down: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1266?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1266?src=pr&el=footer). Last update [27d7839...785ca61](https://codecov.io/gh/keras-team/autokeras/pull/1266?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",report master decrease coverage coverage impacted file tree graph coverage master coverage impacted coverage continue review full report legend click learn absolute relative impact affected missing data powered last update ca read comment,issue,negative,positive,neutral,neutral,positive,positive
667609315,"In looking at a few runs of this snippet, it looks like there is an off-by-1 error somewhere in the model loading procedure. Consistently, I see that if it is epoch X that is supposed to be loaded, and there is no checkpoint at epoch X, there is a checkpoint at epoch X+1. However, after account for that issue, I encounter a different error when trying to make predictions. If my test set is `xTest`, then calling

```
models = clf.tuner.get_best_models(MAXTRIALS)

for model in models:
    model.predict(xTest)
```

yields the error

```
---------------------------------------------------------------------------
UnimplementedError                        Traceback (most recent call last)
<ipython-input-5-c18752c5786e> in <module>
      2 
      3 for model in models:
----> 4     model.predict(xTest)

/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)
    128       raise ValueError('{} is not supported in multi-worker mode.'.format(
    129           method.__name__))
--> 130     return method(self, *args, **kwargs)
    131 
    132   return tf_decorator.make_decorator(

/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in predict(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)
   1597           for step in data_handler.steps():
   1598             callbacks.on_predict_batch_begin(step)
-> 1599             tmp_batch_outputs = predict_function(iterator)
   1600             if data_handler.should_sync:
   1601               context.async_wait()

/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)
    778       else:
    779         compiler = ""nonXla""
--> 780         result = self._call(*args, **kwds)
    781 
    782       new_tracing_count = self._get_tracing_count()

/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)
    844               *args, **kwds)
    845       # If we did not create any variables the trace we have is good enough.
--> 846       return self._concrete_stateful_fn._filtered_call(canon_args, canon_kwds)  # pylint: disable=protected-access
    847 
    848     def fn_with_cond(*inner_args, **inner_kwds):

/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _filtered_call(self, args, kwargs, cancellation_manager)
   1846                            resource_variable_ops.BaseResourceVariable))],
   1847         captured_inputs=self.captured_inputs,
-> 1848         cancellation_manager=cancellation_manager)
   1849 
   1850   def _call_flat(self, args, captured_inputs, cancellation_manager=None):

/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
   1922       # No tape is watching; skip to running the function.
   1923       return self._build_call_outputs(self._inference_function.call(
-> 1924           ctx, args, cancellation_manager=cancellation_manager))
   1925     forward_backward = self._select_forward_and_backward_functions(
   1926         args,

/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/function.py in call(self, ctx, args, cancellation_manager)
    548               inputs=args,
    549               attrs=attrs,
--> 550               ctx=ctx)
    551         else:
    552           outputs = execute.execute_with_cancellation(

/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     58     ctx.ensure_initialized()
     59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
---> 60                                         inputs, attrs, num_outputs)
     61   except core._NotOkStatusException as e:
     62     if name is not None:

UnimplementedError:  Cast double to string is not supported
	 [[node functional_1/Cast (defined at <ipython-input-5-c18752c5786e>:4) ]] [Op:__inference_predict_function_9685]

Function call stack:
predict_function
```",looking snippet like error somewhere model loading procedure consistently see epoch supposed loaded epoch epoch however account issue encounter different error trying make test set calling model error recent call last module model self raise mode return method self return predict self verbose step step self else compiler result self create trace good enough return self self self tape watching skip running function return call self else name except name none cast double string node defined function call stack,issue,negative,positive,positive,positive,positive,positive
667226987,"Hello, 
got the same issue. I am specifying 4 GPUs (out of 8) to train the current model in a distributed fashion, using `tf.distribute.MirroredStrategy( )` since `tf.keras.utils.multi_gpu_model( )` is deprecated and removed since april 2020.

When doing:

```
def make_model(ckpt_path, max_try = 1):
    
    callbacks = [
    keras.callbacks.ModelCheckpoint(
        filepath=ckpt_path + '/bestMod.hdf5', verbose = 1, monitor=""val_accuracy"",
                           mode='max', save_best_only = True), 
    keras.callbacks.EarlyStopping(monitor='val_loss', patience=3,  mode='auto')]
    
    
    AutoClassifier = ak.ImageClassifier(directory= ""fruits/"", 
                   project_name = ""fruits_AutoKeras"",
                   max_trials = max_try, 
                   metrics = ['accuracy', 'top_k_categorical_accuracy'], 
                   seed = 1245,
                   overwrite = True)     
    
    model = AutoClassifier.fit(
        data_train,
        callbacks=callbacks,
        validation_data=vali_data,
        verbose=2)
    
    return model


def run_search(ckpt_path, max_try = 1):

    strat = tf.distribute.MirroredStrategy()
    with strat.scope():
        model = make_model(ckpt_path, max_try)

    return model

run_search(checkpoint, max_try = 3)

```
only one single GPU is doing all the computations, the other three remain idle. When following @FontTian and inserting `distribution_strategy=strat` into the initialisation of the image classifier, the same error `RuntimeError: Too many failed attempts to build model.` occurs. Same happens when adding `tuner='random'` to ak.ImageClassifier.

As suggested by @haifeng-jin, I ran a basic KerasTuner example on 4 GPUs which worked just fine. Furthermore, in https://github.com/keras-team/autokeras/issues/440#issuecomment-592160313 I read that the clear_session() before every run might wipe out the gpu configuration. Removing this line from the code did not change anything with respect to the errors/problems stated above.

Thanks in advance",hello got issue train current model distributed fashion since removed since verbose true metric seed overwrite true model return model model return model one single three remain idle following image classifier error many build ran basic example worked fine furthermore read every run might wipe configuration removing line code change anything respect stated thanks advance,issue,positive,positive,positive,positive,positive,positive
666027338,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1256?src=pr&el=h1) Report
> Merging [#1256](https://codecov.io/gh/keras-team/autokeras/pull/1256?src=pr&el=desc) into [tuner](https://codecov.io/gh/keras-team/autokeras/commit/1cbd0f03e18bb47a5fc33463e6039c1f8e4e9863&el=desc) will **increase** coverage by `0.53%`.
> The diff coverage is `100.00%`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1256/graphs/tree.svg?width=650&height=150&src=pr&token=yDvddb2DDZ)](https://codecov.io/gh/keras-team/autokeras/pull/1256?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##            tuner    #1256      +/-   ##
==========================================
+ Coverage   93.94%   94.47%   +0.53%     
==========================================
  Files          39       39              
  Lines        2229     2245      +16     
==========================================
+ Hits         2094     2121      +27     
+ Misses        135      124      -11     
```


| [Impacted Files](https://codecov.io/gh/keras-team/autokeras/pull/1256?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [autokeras/blocks/reduction.py](https://codecov.io/gh/keras-team/autokeras/pull/1256/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2Jsb2Nrcy9yZWR1Y3Rpb24ucHk=) | `100.00% <100.00%> (+10.11%)` | :arrow_up: |
| [autokeras/blocks/wrapper.py](https://codecov.io/gh/keras-team/autokeras/pull/1256/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2Jsb2Nrcy93cmFwcGVyLnB5) | `100.00% <100.00%> (+2.67%)` | :arrow_up: |
| [autokeras/blocks/basic.py](https://codecov.io/gh/keras-team/autokeras/pull/1256/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2Jsb2Nrcy9iYXNpYy5weQ==) | `96.30% <0.00%> (-0.34%)` | :arrow_down: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1256?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1256?src=pr&el=footer). Last update [1cbd0f0...fdccff8](https://codecov.io/gh/keras-team/autokeras/pull/1256?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",report tuner increase coverage coverage impacted file tree graph coverage tuner coverage impacted coverage continue review full report legend click learn absolute relative impact affected missing data powered last update read comment,issue,negative,positive,neutral,neutral,positive,positive
665982515,For sure! I'll try to get in touch with you! Thank you!,sure try get touch thank,issue,positive,positive,positive,positive,positive,positive
665914154,"@haifeng-jin Thank you for your reply, I have filed a separate issue https://github.com/keras-team/autokeras/issues/1257 named ""Resumption fails with custom objective"", please feel free to let me know if you need any additional information, I hope we can find a solution soon, thanks!",thank reply separate issue resumption custom objective please feel free let know need additional information hope find solution soon thanks,issue,positive,positive,positive,positive,positive,positive
665841978,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1242?src=pr&el=h1) Report
> Merging [#1242](https://codecov.io/gh/keras-team/autokeras/pull/1242?src=pr&el=desc) into [master](https://codecov.io/gh/keras-team/autokeras/commit/a567a00dd26a89d98c835a06f0c107762a0e2d3b?el=desc) will **decrease** coverage by `0.08%`.
> The diff coverage is `97.87%`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1242/graphs/tree.svg?width=650&height=150&src=pr&token=yDvddb2DDZ)](https://codecov.io/gh/keras-team/autokeras/pull/1242?src=pr&el=tree)

```diff
@@             Coverage Diff             @@
##            master    #1242      +/-   ##
===========================================
- Coverage   100.00%   99.91%   -0.09%     
===========================================
  Files           39       41       +2     
  Lines         2236     2311      +75     
===========================================
+ Hits          2236     2309      +73     
- Misses           0        2       +2     
```


| [Impacted Files](https://codecov.io/gh/keras-team/autokeras/pull/1242?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [autokeras/tuners/task\_specific.py](https://codecov.io/gh/keras-team/autokeras/pull/1242/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL3R1bmVycy90YXNrX3NwZWNpZmljLnB5) | `100.00% <ø> (ø)` | |
| [autokeras/keras\_layers.py](https://codecov.io/gh/keras-team/autokeras/pull/1242/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2tlcmFzX2xheWVycy5weQ==) | `97.56% <94.44%> (-2.44%)` | :arrow_down: |
| [autokeras/applications/\_\_init\_\_.py](https://codecov.io/gh/keras-team/autokeras/pull/1242/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2FwcGxpY2F0aW9ucy9fX2luaXRfXy5weQ==) | `100.00% <100.00%> (ø)` | |
| [autokeras/applications/bert.py](https://codecov.io/gh/keras-team/autokeras/pull/1242/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2FwcGxpY2F0aW9ucy9iZXJ0LnB5) | `100.00% <100.00%> (ø)` | |
| [autokeras/blocks/\_\_init\_\_.py](https://codecov.io/gh/keras-team/autokeras/pull/1242/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2Jsb2Nrcy9fX2luaXRfXy5weQ==) | `100.00% <100.00%> (ø)` | |
| [autokeras/blocks/basic.py](https://codecov.io/gh/keras-team/autokeras/pull/1242/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2Jsb2Nrcy9iYXNpYy5weQ==) | `100.00% <100.00%> (ø)` | |
| [autokeras/blocks/wrapper.py](https://codecov.io/gh/keras-team/autokeras/pull/1242/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2Jsb2Nrcy93cmFwcGVyLnB5) | `100.00% <100.00%> (ø)` | |
| [autokeras/graph.py](https://codecov.io/gh/keras-team/autokeras/pull/1242/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2dyYXBoLnB5) | `100.00% <100.00%> (ø)` | |
| ... and [4 more](https://codecov.io/gh/keras-team/autokeras/pull/1242/diff?src=pr&el=tree-more) | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1242?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1242?src=pr&el=footer). Last update [a567a00...a88b419](https://codecov.io/gh/keras-team/autokeras/pull/1242?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",report master decrease coverage coverage impacted file tree graph coverage master coverage impacted coverage continue review full report legend click learn absolute relative impact affected missing data powered last update aa read comment,issue,negative,positive,neutral,neutral,positive,positive
665763671,"For the first one, you got the right solution. For the second one, I think it is a big. Would you file a separate issue about it? Name it ""resume fails with custom objective"". Thank you!",first one got right solution second one think big would file separate issue name resume custom objective thank,issue,positive,positive,positive,positive,positive,positive
665690805,"@haifeng-jin Of course, I would love to help! But I found there are some other problems when using customized metrics (e.g. the way above we use f1_score) to select the best model, and I guess it would better to address them first before updating the FAQ:

(1) After the fitting process using the above code and exporting the model by:

> model = clf.export_model()
> model.save(""model_autokeras.h5"")

then there will be an error ""ValueError: Unknown metric function: f1_score"" if we would like to load the saved model by the following code directly (which is in https://autokeras.com/tutorial/export/):

> from tensorflow.keras.models import load_model
> loaded_model = load_model(""model_autokeras"", custom_objects=ak.CUSTOM_OBJECTS)

I guess that is because the .h5 file contains our customized function, so currently I found the following way can be a solution and the loaded_model works well for me:

> my_custom_objects={'f1_score': f1_score}
> my_custom_objects.update(ak.CUSTOM_OBJECTS)
> loaded_model = load_model(""model_autokeras"", custom_objects=my_custom_objects)


(2) Another problem that I would really like to find a solution soon is that the above code snippet of using f1_score as customized metric cannot resume a previously killed run by running the same code again.

For example, after finishing running the above code snippet of using f1_score as customized metric, if I would like to run for two more trails, I simply let ""max_trials=5"" in the ImageClassifier and run the same snippet again, but there will be an error ""ValueError: Unknown metric function: f1_score"". I guess the error is caused by the same problem as in (1), i.e., in the process of loading model or checkpoint we should pass {'f1_score': f1_score} to the custom_objects, so I guess the error might not be that hard to fix.

(The following is the whole traceback of the error:

Traceback (most recent call last):
  File ""<input>"", line 1, in <module>
  File ""/snap/pycharm-professional/211/plugins/python/helpers/pydev/_pydev_bundle/pydev_umd.py"", line 197, in runfile
    pydev_imports.execfile(filename, global_vars, local_vars)  # execute the script
  File ""/snap/pycharm-professional/211/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py"", line 18, in execfile
    exec(compile(contents+""\n"", file, 'exec'), glob, loc)
  File ""/home/colotu01/csi4900tf2/20200728_try/try_to_continue_fitting.py"", line 50, in <module>
    metrics=[f1_score],
  File ""/home/colotu01/anaconda3/envs/tf2/lib/python3.7/site-packages/autokeras/tasks/image.py"", line 85, in __init__
    **kwargs)
  File ""/home/colotu01/anaconda3/envs/tf2/lib/python3.7/site-packages/autokeras/tasks/image.py"", line 24, in __init__
    **kwargs)
  File ""/home/colotu01/anaconda3/envs/tf2/lib/python3.7/site-packages/autokeras/auto_model.py"", line 136, in __init__
    **kwargs)
  File ""/home/colotu01/anaconda3/envs/tf2/lib/python3.7/site-packages/autokeras/tuners/task_specific.py"", line 102, in __init__
    **kwargs)
  File ""/home/colotu01/anaconda3/envs/tf2/lib/python3.7/site-packages/autokeras/tuners/greedy.py"", line 237, in __init__
    **kwargs)
  File ""/home/colotu01/anaconda3/envs/tf2/lib/python3.7/site-packages/autokeras/engine/tuner.py"", line 40, in __init__
    super().__init__(oracle, hypermodel, **kwargs)
  File ""/home/colotu01/anaconda3/envs/tf2/lib/python3.7/site-packages/kerastuner/engine/tuner.py"", line 104, in __init__
    overwrite=overwrite)
  File ""/home/colotu01/anaconda3/envs/tf2/lib/python3.7/site-packages/kerastuner/engine/base_tuner.py"", line 71, in __init__
    self.directory, self.project_name, overwrite=overwrite)
  File ""/home/colotu01/anaconda3/envs/tf2/lib/python3.7/site-packages/kerastuner/engine/oracle.py"", line 312, in _set_project_dir
    self.reload()
  File ""/home/colotu01/anaconda3/envs/tf2/lib/python3.7/site-packages/kerastuner/engine/oracle.py"", line 337, in reload
    super(Oracle, self).reload(self._get_oracle_fname())
  File ""/home/colotu01/anaconda3/envs/tf2/lib/python3.7/site-packages/kerastuner/engine/stateful.py"", line 64, in reload
    self.set_state(state)
  File ""/home/colotu01/anaconda3/envs/tf2/lib/python3.7/site-packages/autokeras/tuners/greedy.py"", line 84, in set_state
    self.hypermodel = graph.Graph.from_config(state['hypermodel'])
  File ""/home/colotu01/anaconda3/envs/tf2/lib/python3.7/site-packages/autokeras/graph.py"", line 205, in from_config
    blocks = [blocks_module.deserialize(block) for block in config['blocks']]
  File ""/home/colotu01/anaconda3/envs/tf2/lib/python3.7/site-packages/autokeras/graph.py"", line 205, in <listcomp>
    blocks = [blocks_module.deserialize(block) for block in config['blocks']]
  File ""/home/colotu01/anaconda3/envs/tf2/lib/python3.7/site-packages/autokeras/blocks/__init__.py"", line 37, in deserialize
    printable_module_name='hypermodels')
  File ""/home/colotu01/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/utils/generic_utils.py"", line 360, in deserialize_keras_object
    return cls.from_config(cls_config)
  File ""/home/colotu01/anaconda3/envs/tf2/lib/python3.7/site-packages/autokeras/engine/head.py"", line 72, in from_config
    config['metrics'] = deserialize_metrics(config['metrics'])
  File ""/home/colotu01/anaconda3/envs/tf2/lib/python3.7/site-packages/autokeras/engine/head.py"", line 23, in deserialize_metrics
    deserialized.append(tf.keras.metrics.deserialize(metric))
  File ""/home/colotu01/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/metrics.py"", line 3443, in deserialize
    printable_module_name='metric function')
  File ""/home/colotu01/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/utils/generic_utils.py"", line 378, in deserialize_keras_object
    'Unknown ' + printable_module_name + ': ' + object_name)
ValueError: Unknown metric function: f1_score

)


Please let me know if you need any additional information, and I am happy to help!",course would love help found metric way use select best model guess would better address first fitting process code model model error unknown metric function would like load saved model following code directly import guess file function currently found following way solution work well another problem would really like find solution soon code snippet metric resume previously run running code example finishing running code snippet metric would like run two simply let run snippet error unknown metric function guess error problem process loading model pas guess error might hard fix following whole error recent call last file input line module file line execute script file line compile file file line module file line file line file line file line file line file line super oracle file line file line file line file line reload super oracle self file line reload state file line state file line block block file line block block file line file line return file line file line metric file line function file line unknown metric function please let know need additional information happy help,issue,positive,positive,positive,positive,positive,positive
665496311,"@ywtaccelerator Yes, you are right. Would you help us change the faq in this file? Thank you!
https://github.com/keras-team/autokeras/blob/master/docs/templates/tutorial/faq.md",yes right would help u change file thank,issue,positive,positive,positive,positive,positive,positive
665368190,"> This snippet works for me.
> 
> ```python
> from tensorflow.keras.datasets import mnist
> import kerastuner
> 
> import autokeras as ak
> 
> from tensorflow.keras import backend as K
> 
> 
> def recall_m(y_true, y_pred):
>     true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
>     possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))
>     recall = true_positives / (possible_positives + K.epsilon())
>     return recall
> 
> def precision_m(y_true, y_pred):
>     true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
>     predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))
>     precision = true_positives / (predicted_positives + K.epsilon())
>     return precision
> 
> def f1_score(y_true, y_pred):
>     precision = precision_m(y_true, y_pred)
>     recall = recall_m(y_true, y_pred)
>     return 2*((precision*recall)/(precision+recall+K.epsilon()))
> 
> # Prepare the dataset.
> (x_train, y_train), (x_test, y_test) = mnist.load_data()
> print(x_train.shape)  # (60000, 28, 28)
> print(y_train.shape)  # (60000,)
> print(y_train[:3])  # array([7, 2, 1], dtype=uint8)
> 
> # Initialize the ImageClassifier.
> clf = ak.ImageClassifier(
>     max_trials=3,
>     objective=kerastuner.Objective('val_f1_score', direction='min'),
>     metrics=[f1_score],
> )
> # Search for the best model.
> clf.fit(x_train, y_train, epochs=10)
> # Evaluate on the testing data.
> print('Accuracy: {accuracy}'.format(
>     accuracy=clf.evaluate(x_test, y_test)))
> ```


Hi, I guess we should let the ""direction"" be 'max', right?",snippet work python import import import ak import recall return recall precision return precision precision recall return precision recall prepare print print print array initialize search best model evaluate testing data print accuracy hi guess let direction right,issue,positive,positive,positive,positive,positive,positive
664821585,This bug is fixed with the latest release 1.0.5.,bug fixed latest release,issue,negative,positive,positive,positive,positive,positive
664820339,This problem is fixed in the latest release. 1.0.5,problem fixed latest release,issue,negative,positive,positive,positive,positive,positive
664794336,"This snippet works for me.

```python
from tensorflow.keras.datasets import mnist
import kerastuner

import autokeras as ak

from tensorflow.keras import backend as K


def recall_m(y_true, y_pred):
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))
    recall = true_positives / (possible_positives + K.epsilon())
    return recall

def precision_m(y_true, y_pred):
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))
    precision = true_positives / (predicted_positives + K.epsilon())
    return precision

def f1_score(y_true, y_pred):
    precision = precision_m(y_true, y_pred)
    recall = recall_m(y_true, y_pred)
    return 2*((precision*recall)/(precision+recall+K.epsilon()))

# Prepare the dataset.
(x_train, y_train), (x_test, y_test) = mnist.load_data()
print(x_train.shape)  # (60000, 28, 28)
print(y_train.shape)  # (60000,)
print(y_train[:3])  # array([7, 2, 1], dtype=uint8)

# Initialize the ImageClassifier.
clf = ak.ImageClassifier(
    max_trials=3,
    objective=kerastuner.Objective('val_f1_score', direction='min'),
    metrics=[f1_score],
)
# Search for the best model.
clf.fit(x_train, y_train, epochs=10)
# Evaluate on the testing data.
print('Accuracy: {accuracy}'.format(
    accuracy=clf.evaluate(x_test, y_test)))
```",snippet work python import import import ak import recall return recall precision return precision precision recall return precision recall prepare print print print array initialize search best model evaluate testing data print accuracy,issue,positive,positive,positive,positive,positive,positive
664756894,I am working on it. It seems it is a bug that it always use val_loss as objective.,working bug always use objective,issue,negative,neutral,neutral,neutral,neutral,neutral
664756293,We have just had a new release 1.0.5. I expect use it with TF 2.3.0 can fix the bug. We have fixed another bug in that might cause the problem so it should work this time.,new release expect use fix bug fixed another bug might cause problem work time,issue,negative,positive,positive,positive,positive,positive
664755751,@castrovictor We have fixed another bug that causes the checkpoint not found issue in 1.0.5. I believe the bug should be fixed. Let me know if it doesn't. remember to update to TF 2.3.0 Thanks.,fixed another bug found issue believe bug fixed let know remember update thanks,issue,negative,positive,positive,positive,positive,positive
664740142,@mreismendes Would you like to do a video call with us to help us improve AutoKeras? We are also happy to answer any questions you have. You can ping me on Slack to setup the call. Thank you.,would like video call u help u improve also happy answer ping slack setup call thank,issue,positive,positive,positive,positive,positive,positive
664318574,"> #1210
> will be helpful, now, a simply way is comment out the delete portion

Thank you for the link. Indeed, the issue discussed is the same, I didn't notice it.

Anyway, according to @haifeng-jin in that issue, it should be fixed in the last version, 1.0.4, but turns out it's not. ",helpful simply way comment delete portion thank link indeed issue notice anyway according issue fixed last version turn,issue,positive,positive,neutral,neutral,positive,positive
664302910,"> I encountered the same issue. Of course, it means that the best performance against the metric was not in the last ten epochs. Should there not be an early stopping in such a case? [Additional: I see now that the early stopping ""patience"" is set to 10 epochs, so there would not be early stopping in this case. Is there a purpose in saving any of the checkpoints except the one producing the best score (as can be found in trial.json) after completing the last epoch?]

Not sure what it is saving because they are not the last 10 epochs and I have no way to know if they are the ""10 best epochs""",issue course best performance metric last ten early stopping case additional see early stopping patience set would early stopping case purpose saving except one best score found last epoch sure saving last way know best,issue,positive,positive,positive,positive,positive,positive
664106884,"https://github.com/keras-team/autokeras/issues/1210   
will be helpful, now, a simply way is comment out the delete portion",helpful simply way comment delete portion,issue,negative,neutral,neutral,neutral,neutral,neutral
664028135,"I encountered the same issue. Of course, it means that the best performance against the metric was not in the last ten epochs. Should there not be an early stopping in such a case? [Additional: I see now that the early stopping ""patience"" is set to 10 epochs, so there would not be early stopping in this case. Is there a purpose in saving any of the checkpoints except the one producing the best score (as can be found in trial.json) after completing the last epoch?]",issue course best performance metric last ten early stopping case additional see early stopping patience set would early stopping case purpose saving except one best score found last epoch,issue,positive,positive,positive,positive,positive,positive
663858422,"> @mreismendes I have the fix in the Pull request now. I tried it works.
> You can install with the following command and your notebook runs fine.
> 
> ```
> !pip install git+https://github.com/keras-team/autokeras.git@bug_fix
> ```

Thank you! It's working flawlessly!",fix pull request tried work install following command notebook fine pip install thank working flawlessly,issue,positive,positive,positive,positive,positive,positive
663781305,"@mreismendes I have the fix in the Pull request now. I tried it works.
You can install with the following command and your notebook runs fine.
```
!pip install git+https://github.com/keras-team/autokeras.git@bug_fix
```",fix pull request tried work install following command notebook fine pip install,issue,negative,positive,positive,positive,positive,positive
663300570,"> @SoYoungCho This is a rather old issue. I believe it has been fixed already. Are you using AutoKeras 1.0.4 with Keras Tuner 1.0.2rc1? Thanks.

Problem solved. I did use AutoKeras 1.0.4 with Keras Tuner 1.0.2rc1, but the problem was overfitting. Randomly shuffling the dataset solved my issue. Thanks!",rather old issue believe fixed already tuner thanks problem use tuner problem randomly shuffling issue thanks,issue,negative,positive,neutral,neutral,positive,positive
663265711,"Thank you @haifeng-jin  for your response.
When I put np.unicode this works to me. But I believe that is important to use the original type of numpy, or perhaps, you can put this transformation within the preprocess. This is only an idea/suggestion.
Again, thank you for your help!
Bellow, I put the de model.summary()

----------------------
model.summary()
Model: ""model""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 9)]               0         
_________________________________________________________________
multi_column_categorical_enc (None, 9)                 0         
_________________________________________________________________
dense (Dense)                (None, 64)                640       
_________________________________________________________________
batch_normalization (BatchNo (None, 64)                256       
_________________________________________________________________
re_lu (ReLU)                 (None, 64)                0         
_________________________________________________________________
dropout (Dropout)            (None, 64)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 16)                1040      
_________________________________________________________________
batch_normalization_1 (Batch (None, 16)                64        
_________________________________________________________________
re_lu_1 (ReLU)               (None, 16)                0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 16)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 32)                544       
_________________________________________________________________
batch_normalization_2 (Batch (None, 32)                128       
_________________________________________________________________
re_lu_2 (ReLU)               (None, 32)                0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 32)                0         
_________________________________________________________________
regression_head_1 (Dense)    (None, 1)                 33        
=================================================================
Total params: 2,705
Trainable params: 2,481
Non-trainable params: 224
_________________________________________________________________",thank response put work believe important use original type perhaps put transformation within thank help bellow put de model model layer type output shape param none none dense dense none none none dropout dropout none dense none batch none none dropout none dense none batch none none dropout none dense none total trainable,issue,positive,positive,positive,positive,positive,positive
663237697,@mreismendes Thank you so much! will get to it right away.,thank much get right away,issue,negative,positive,positive,positive,positive,positive
663237448,"The prerprocess steps are using preprocessing layers of Keras, it should be part of the model. Would you paste your model.summary()?
I guess it might be cause of the format of the training data.
We use np.unicode for the data.",part model would paste guess might cause format training data use data,issue,negative,neutral,neutral,neutral,neutral,neutral
663235733,@SoYoungCho This is a rather old issue. I believe it has been fixed already. Are you using AutoKeras 1.0.4 with Keras Tuner 1.0.2rc1? Thanks.,rather old issue believe fixed already tuner thanks,issue,negative,positive,positive,positive,positive,positive
663092152,"Hi there,
Hope all is well. Any update on this topic?
Cheers,
Alex",hi hope well update topic,issue,positive,neutral,neutral,neutral,neutral,neutral
662967813,"> I really cannot reproduce the error. It would be great if you can share a colab notebook. Thank you!

https://colab.research.google.com/drive/1H-i0Y6QZRGyvNaprHHSUoeHRDO6z9O59?usp=sharing",really reproduce error would great share notebook thank,issue,positive,positive,positive,positive,positive,positive
662091491,"We didn't fully test this feature with AutoKeras yet. You may try pass one more arg `tuner='random'`. If the error still exists, you may try a basic example with KerasTuner to see if it is a KerasTuner issue. Thanks.",fully test feature yet may try pas one error still may try basic example see issue thanks,issue,negative,positive,neutral,neutral,positive,positive
662072825,"> Hi there,
> I installed the current version of the master with `pip install git+https://github.com/keras-team/autokeras.git@master`. However, i still get the same error.
> 
> ```
> OS type and version: Windows 10
> Python: 3.7
> autokeras: 1.0.4.dev0
> keras-tuner: 1.0.2rc0
> tensorflow: 2.2.0 no GPU used
> ```

I have the same issue as well!",hi current version master pip install however still get error o type version python dev used issue well,issue,negative,neutral,neutral,neutral,neutral,neutral
662071087,"@abdulsam Hi Abdus, it seems you have encountered a lot of issues. Can we setup a call to help you resolve the issues? You can also help us answer some of our user study questions and provide your feedback. You can reach me on slack. Thank you!",hi lot setup call help resolve also help u answer user study provide feedback reach slack thank,issue,positive,neutral,neutral,neutral,neutral,neutral
662070150,"@cibic89 Yes. Thank you! Please put it in this folder https://github.com/keras-team/autokeras/tree/master/docs/py
You may also try to run your code in colab to make sure it works.",yes thank please put folder may also try run code make sure work,issue,positive,positive,positive,positive,positive,positive
661988435,"I think This issue opened log time ago(TF=2.1.0), and I assume that it has been fixed in the new version.
The installation has been also modified and I assume you installed autokeras like
pip3 install git+https://github.com/keras-team/keras-tuner.git@1.0.2rc0
pip3 install autokeras==1.0.3

not just like
pip install autokeras
(Right now this does not work unless you install TF==2.1 instead of TF==2.2)

Thank you!
________________________________
差出人: Haifeng Jin <notifications@github.com>
送信日時: 2020年7月21日 8:51
宛先: keras-team/autokeras <autokeras@noreply.github.com>
CC: Takeo Shibata <takeofuture@hotmail.com>; Author <author@noreply.github.com>
件名: Re: [keras-team/autokeras] export_model does not work for specific image data and AutoModel (#1103)


I tried the tutorial on colab and added the line of export_model, which runs fine. Not sure how to reproduce the error.

—
You are receiving this because you authored the thread.
Reply to this email directly, view it on GitHub<https://github.com/keras-team/autokeras/issues/1103#issuecomment-661943498>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AH5KQ3D7MPJIDHJ7NKIFND3R4W2PVANCNFSM4MNYPICQ>.
",think issue log time ago assume fixed new version installation also assume like pip install pip install like pip install right work unless install instead thank author author work specific image data tried tutorial added line fine sure reproduce error thread reply directly view,issue,positive,positive,positive,positive,positive,positive
661943498,"I tried the tutorial on colab and added the line of export_model, which runs fine. Not sure how to reproduce the error.",tried tutorial added line fine sure reproduce error,issue,negative,positive,positive,positive,positive,positive
661929656,I think it mainly because of the categorical encoding? would you paste your code?,think mainly categorical would paste code,issue,negative,positive,positive,positive,positive,positive
661928365,"@Karim-53 Thank you for the reply.
I just tried.
The solution is a little bit tricky.
This code runs fine. You can use it as a reference.
```python
import autokeras as ak
import numpy as np
from sklearn.model_selection import train_test_split


n_points = 100
n_features = 6
n_classes = 10
X = np.random.rand(n_points, n_features)
print(X.shape, X.dtype)# random (100, 6) shaped array
y = np.random.randint(low=0, high=n_classes, size=n_points)
print(y.shape, y.dtype)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)

clf = ak.StructuredDataClassifier(max_trials=1)
clf.fit(X_train, y_train, epochs=2)
predicted_y = clf.predict(X_test)
clf.evaluate(X_test, y_test)

model = clf.export_model()
import tensorflow as tf

X_test = tf.data.Dataset.from_tensor_slices(X_test.astype(np.unicode)).batch(32)
predicted_y_2 = model.predict(X_test)
print(predicted_y_2)
```",thank reply tried solution little bit tricky code fine use reference python import ak import import print random shaped array print model import print,issue,positive,negative,neutral,neutral,negative,negative
661853855,"emmm,I find it

>distribution_strategy: Optional. A TensorFlow tf.distribute DistributionStrategy instance. If specified, each trial will run under this scope. For example, tf.distribute.MirroredStrategy(['/gpu:0, /'gpu:1]) will run each trial on two GPUs. Currently only single-worker strategies are supported.

and I ran the following code, but an error appeared.

```python

strategy = tf.distribute.MirroredStrategy(['/gpu:0', '/gpu:1'])
# tuner.Tuner(distribution_strategy=strategy)
import autokeras as ak
clf = ak.ImageClassifier(
    overwrite=True,
    max_trials=1,distribution_strategy=strategy)

...
RuntimeError: Too many failed attempts to build model.
```",find optional instance trial run scope example run trial two currently ran following code error python strategy import ak many build model,issue,negative,positive,positive,positive,positive,positive
661101304,"Hi there,
I installed the current version of the master with `pip install git+https://github.com/keras-team/autokeras.git@master`. However, i still get the same error.


    OS type and version: Windows 10
    Python: 3.7
    autokeras: 1.0.4.dev0
    keras-tuner: 1.0.2rc0
    tensorflow: 2.2.0 no GPU used

",hi current version master pip install however still get error o type version python dev used,issue,negative,neutral,neutral,neutral,neutral,neutral
660787936,"I think this is supported in Keras-Tuner's Tuner class. AutoKeras supports all args in Tuner class.
You can pass `distribution_strategy` to any model you use in AutoKeras.
The details you can find on this page: https://keras-team.github.io/keras-tuner/documentation/tuners/",think tuner class tuner class pas model use find page,issue,negative,neutral,neutral,neutral,neutral,neutral
660787217,"We are really trying hard to reach this feature. This will be the next one after we have time-series, and segmentation. Of course, we will focus on the performance on existing tasks and fixing important bugs even before those.",really trying hard reach feature next one segmentation course focus performance fixing important even,issue,negative,positive,neutral,neutral,positive,positive
660786869,"Yes, this will be in a future version. However, you can use it in the master branch now.",yes future version however use master branch,issue,negative,neutral,neutral,neutral,neutral,neutral
660786734,"Cool, we have a time-series in the master branch actually, but we did not expose it since we haven't fully tested the performance yet.",cool master branch actually expose since fully tested performance yet,issue,negative,positive,positive,positive,positive,positive
660786505,We still haven't got the chance to work on this feature yet. We are likely to have a `get_config()` which follows the Keras APIs.,still got chance work feature yet likely,issue,negative,neutral,neutral,neutral,neutral,neutral
660786178,We have fixed the problem in the master branch. You can use the master branch with keras-tuner 1.0.2rc1 tag.,fixed problem master branch use master branch tag,issue,negative,positive,neutral,neutral,positive,positive
660710516,"@castrovictor Sure thing. I'm running using the following Dockerfile:

```dockerfile
FROM nvidia/cuda:10.1-cudnn7-devel-ubuntu18.04

# install apt packages
RUN apt update && apt upgrade -y && apt install -y \
        curl \
        git \
        python3 \
        python3-pip \
        vim \
        wget

# install pip packages
RUN pip3 install --no-cache-dir -U pip
RUN pip3 install --no-cache-dir -U setuptools six
RUN pip3 install --no-cache-dir \
        scipy==1.4.1 \
        tensorflow-gpu==2.2.0 \
        git+https://github.com/keras-team/autokeras.git@7db2afd \
        git+https://github.com/keras-team/keras-tuner.git@fa84eb2

# clean the cache
RUN rm -rf /var/lib/apt/lists/* && rm -rf ~/.cache/pip/*
```

Running pip3 freeze inside the container gives the following:

```
$ pip3 freeze 
absl-py==0.9.0
asn1crypto==0.24.0
astunparse==1.6.3
autokeras @ git+https://github.com/keras-team/autokeras.git@7db2afde4af83ca113841a979e218d775a04eb40
backcall==0.2.0
cachetools==4.1.1
certifi==2020.6.20
chardet==3.0.4
colorama==0.4.3
cryptography==2.1.4
decorator==4.4.2
future==0.18.2
gast==0.3.3
google-auth==1.19.2
google-auth-oauthlib==0.4.1
google-pasta==0.2.0
grpcio==1.30.0
h5py==2.10.0
idna==2.6
importlib-metadata==1.7.0
ipython==7.16.1
ipython-genutils==0.2.0
jedi==0.17.2
joblib==0.16.0
Keras-Preprocessing==1.1.2
keras-tuner @ git+https://github.com/keras-team/keras-tuner.git@fa84eb29446f6234aea243a73cef85de4bbdb642
keyring==10.6.0
keyrings.alt==3.0
Markdown==3.2.2
numpy==1.19.0
oauthlib==3.1.0
opt-einsum==3.2.1
packaging==20.4
pandas==1.0.5
parso==0.7.0
pexpect==4.8.0
pickleshare==0.7.5
prompt-toolkit==3.0.5
protobuf==3.12.2
ptyprocess==0.6.0
pyasn1==0.4.8
pyasn1-modules==0.2.8
pycrypto==2.6.1
Pygments==2.6.1
pygobject==3.26.1
pyparsing==2.4.7
python-dateutil==2.8.1
pytz==2020.1
pyxdg==0.25
requests==2.24.0
requests-oauthlib==1.3.0
rsa==4.6
scikit-learn==0.23.1
scipy==1.4.1
SecretStorage==2.3.1
six==1.15.0
tabulate==0.8.7
tensorboard==2.2.2
tensorboard-plugin-wit==1.7.0
tensorflow==2.2.0
tensorflow-estimator==2.2.0
tensorflow-gpu==2.2.0
termcolor==1.1.0
terminaltables==3.1.0
threadpoolctl==2.1.0
tqdm==4.48.0
traitlets==4.3.3
urllib3==1.25.9
wcwidth==0.2.5
Werkzeug==1.0.1
wrapt==1.12.1
zipp==3.1.0
```

and python version:

```
$ python3 --version
Python 3.6.9
```",sure thing running following install apt run apt update apt upgrade apt install curl git python vim install pip run pip install pip run pip install six run pip install clean cache run running pip freeze inside container following pip freeze python version python version python,issue,positive,positive,positive,positive,positive,positive
660669324,"@dahlo would you mind posting your configuration? Installing the versions you mention I get this error:


ImportError: dlopen: cannot load any more object with static TLS
___________________________________________________________________________
Contents of /mnt/sdd/vicastro/envs/ak4/lib/python3.8/site-packages/sklearn/__check_build:
__pycache__               setup.py                  _check_build.cpython-38-x86_64-linux-gnu.so
__init__.py
___________________________________________________________________________
It seems that scikit-learn has not been built correctly.

",would mind posting configuration mention get error load object static content built correctly,issue,negative,positive,positive,positive,positive,positive
660550016,Can confirm working. Running ~30 instances i would get about 1 crash per hour with the KeyError. I have now run over 24h and not a single crash. Running autokeras 7db2afd and keras-tuner fa84eb2.,confirm working running would get crash per hour run single crash running,issue,negative,negative,neutral,neutral,negative,negative
660488373,"> 
> 
> I just discovered this one: https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_generator
> You might be able to wrap your generator into a tf.data.Dataset with it.

@haifeng-jin  Can I contribute a tutorial for using an image generator with AutoKeras?",discovered one might able wrap generator contribute tutorial image generator,issue,negative,positive,positive,positive,positive,positive
660261875,"@haifeng-jin While loading the saved models, it is giving a warning
`WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.`

I ignored this warning because I can train it again. But while using fit() method on the loaded model, it is showing this error:
`ValueError: Shapes (None, 1) and (None, 10) are incompatible`",loading saved giving warning warning error loading saved state result model starting freshly warning train fit method loaded model showing error none none incompatible,issue,negative,positive,positive,positive,positive,positive
660170123,"Meanwhile I was able to set Automodel with CNN block. Please find the code below.
Hope it can be usefull for you :)

Note: at this point I ws using autokeras: 1.0.3 and  Tensorflow: 2.2.0
```
# Library import
import pandas as pd
import numpy as np
import autokeras as ak
import tensorflow as tf
import matplotlib.pyplot as plt

# Prepare example Data - Shape 1D
num_instances = 100
num_features = 5
x_train = np.random.rand(num_instances, num_features).astype(np.float32)
y_train = np.zeros(num_instances).astype(np.float32)
y_train[0:int(num_instances/2)]=1
x_test = np.random.rand(num_instances, num_features).astype(np.float32)
y_test = np.zeros(num_instances).astype(np.float32)
y_train[0:int(num_instances/2)]=1

x_train = np.expand_dims(x_train, axis=2) #This step it's very important an CNN will only accept this data shape
print(x_train.shape)
print(y_train.shape)

# Prepare Automodel for search
input_node = ak.Input() 
output_node = ak.ConvBlock()(input_node) 
#output_node = ak.DenseBlock()(output_node) #optional
#output_node = ak.SpatialReduction()(output_node) #optional
output_node = ak.ClassificationHead(num_classes=2, multi_label=True)(output_node)

auto_model = ak.AutoModel(inputs=input_node,outputs=output_node,overwrite=True,max_trials=1)

# Search
auto_model.fit(x_train, y_train, epochs=1)
print(auto_model.evaluate(x_test, y_test))

# Export as a Keras Model
model = auto_model.export_model()
print(type(model.summary()))

# Export as a Keras Model
model = auto_model.export_model()
print(type(model.summary()))
```
",meanwhile able set block please find code hope note point library import import import import ak import import prepare example data shape step important accept data shape print print prepare search optional optional search print export model model print type export model model print type,issue,positive,positive,positive,positive,positive,positive
660024881,"I preprocess my input data with the exact same (copy paste) code as in my model calculation. I even included it in the ticket above. It used to work a few weeks ago but for some reason it has stopped working, even though I haven't touched the code.",input data exact copy paste code model calculation even included ticket used work ago reason stopped working even though touched code,issue,negative,positive,positive,positive,positive,positive
659499509,"Yes, that is the property of the hyperband tuner.
It use successive halving which only train the models for less epochs at first and select the good ones and further train.",yes property tuner use successive train le first select good train,issue,positive,positive,positive,positive,positive,positive
659498240,"It seems it is caused by an incompatible input shape.
You may need to preprocess the input data a little bit to match the shape.
To ensure you preprocess the data properly,
you can always try to convert it to a tf.data.Dataset and see its shape.
```
ak.utils.data_utils.dataset_shape(dataset)
```",incompatible input shape may need input data little bit match shape ensure data properly always try convert see shape,issue,negative,negative,neutral,neutral,negative,negative
659495789,"Currently, I can only reproduce it by not setting `overwrite` which by default is set to False.
It is caused by not properly saving the oracle and tuner.
The linked PR solves this problem.
Will be merged soon.",currently reproduce setting overwrite default set false properly saving oracle tuner linked problem soon,issue,negative,negative,negative,negative,negative,negative
659493943,"@abdulsam You can use a for loop to do so.
```python
for index, model in enumerate(AutoModel.tuner.get_best_models(3)):
  model.save('model' + str(index) + '.h5')
```",use loop python index model enumerate index,issue,negative,neutral,neutral,neutral,neutral,neutral
659351164,"> As I tested, it works now with AutoKeras 1.0.3.

I'm getting the same error while loading the model:
`WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.`

and after `model.fit(x_train, y_train, epoch=20)`
I'm getting the following error:

`ValueError: in user code:

    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:571 train_function  *
        outputs = self.distribute_strategy.run(
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica
        return fn(*args, **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:533 train_step  **
        y, y_pred, sample_weight, regularization_losses=self.losses)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:205 __call__
        loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:143 __call__
        losses = self.call(y_true, y_pred)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:246 call
        return self.fn(y_true, y_pred, **self._fn_kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:1527 categorical_crossentropy
        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py:4561 categorical_crossentropy
        target.shape.assert_is_compatible_with(output.shape)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py:1117 assert_is_compatible_with
        raise ValueError(""Shapes %s and %s are incompatible"" % (self, other))

    ValueError: Shapes (None, 1) and (None, 10) are incompatible`",tested work getting error loading model warning error loading saved state result model starting freshly getting following error user code run return return return call return return raise incompatible self none none incompatible,issue,negative,positive,neutral,neutral,positive,positive
659245801,"Yes, the bug is still there. We tried with 2 different computers.

**To reproduce the error:**
run a very basic example: https://autokeras.com/tutorial/structured_data_regression/

The error might happen (or not). If not then 

run these lines once again: 
```python
predicted_y = reg.predict(...)
print(reg.evaluate(...))
```
in the second run, the error always happen:
``Unresolved object in checkpoint``

As you can see, many people are already complaining about that (all same issue):
![image](https://user-images.githubusercontent.com/33978275/87645527-e6fd7180-c74d-11ea-8f69-1654bc6f4922.png)

",yes bug still tried different reproduce error run basic example error might happen run python print second run error always happen unresolved object see many people already issue image,issue,negative,positive,positive,positive,positive,positive
659088752,"So ObjectDetection models eventually supported, (I am not talking about pretrained_model,  I assume it is not the job for autokeras as AutoML which automatically search and find candidates for the models based on given data).    
I am assuming given training dat asimilar like COCO or so (class label + (x, y, h, w) ) * xxx, then it find the good model for object detection automatically.  Any update so far? I am looking forward to using it!  ",eventually talking assume job automatically search find based given data assuming given training like coco class label find good model object detection automatically update far looking forward,issue,positive,positive,positive,positive,positive,positive
659068423,Hmm I tried pip installing using the .git link today but it still seems to have the same issue. Is the fix coming in a future version?,tried pip link today still issue fix coming future version,issue,negative,neutral,neutral,neutral,neutral,neutral
659005647,"@I-Kryachko It seems you are experiencing multiple bugs while using AutoKeras.
We would like to schedule a video call with you to see if we can help you solve the problems.
And we also have some questions about your experience in using AutoKeras.
Would you like to do it? You can ping me on slack. https://autokeras.com/#community",multiple would like schedule video call see help solve also experience would like ping slack,issue,positive,neutral,neutral,neutral,neutral,neutral
658999060,"Sometimes I run ok too. It happens for me at ak 1.0.3 when tuner decides to make certain improvents on get started task. Two tasks which I run one by one do not run the same layers, so sometimes I have error.",sometimes run ak tuner make certain get task two run one one run sometimes error,issue,negative,positive,positive,positive,positive,positive
658996109,"Thanks everyone!
As I talked to chyt, we don't see this error any more with ak 1.0.3 and kt 1.0.2rc0.
Not sure how to reproduce it. I am running totally fine locally.",thanks everyone see error ak sure reproduce running totally fine locally,issue,positive,positive,positive,positive,positive,positive
658994421,"@Karim-53 Really? I thought I fixed it.
With autokeras==1.0.3 and keras-tuner=1.0.2rc0, there should not be this bug any more.
What error message are you getting?

Thanks.",really thought fixed bug error message getting thanks,issue,negative,positive,positive,positive,positive,positive
658893003,"> @ciberger, this code seems to work, you can give a shot:
> 
> ```python
> import tensorflow as tf
> import numpy as np
> import autokeras as ak
> from tensorflow.keras.preprocessing import image
> import pathlib
> import matplotlib.pylab as plt
> 
> BATCH_SIZE = 32
> IMG_HEIGHT = 224
> IMG_WIDTH = 224
> data_dir = ""dataset/train""
> data_dir = pathlib.Path(data_dir)
> #image_count = len(list(data_dir.glob('*/*.jpg')))
> #STEPS_PER_EPOCH = np.ceil(image_count/BATCH_SIZE)
> 
> def preprocess(img):
>     img = image.array_to_img(img, scale=False)
>     img = img.resize((IMG_WIDTH, IMG_HEIGHT))
>     img = image.img_to_array(img)
>     return img / 255.0
> 
> image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,
>                                               horizontal_flip=True,
>                                               validation_split=0.2,
>                                               preprocessing_function=preprocess)
> 
> train_generator = image_generator.flow_from_directory(
>     directory=str(data_dir),
>      batch_size=BATCH_SIZE,
>      shuffle=True,
>      #class_mode=""categorical"",
>      target_size=(IMG_HEIGHT, IMG_WIDTH),
>     subset='training'
> )
> 
> val_generator = image_generator.flow_from_directory(
>     directory=str(data_dir),
>      batch_size=BATCH_SIZE,
>      shuffle=True,
>      #class_mode=""categorical"",
>      target_size=(IMG_HEIGHT, IMG_WIDTH),
>     subset='validation'
> )
> 
> def callable_iterator(generator):
>     for img_batch, targets_batch in generator:
>         yield img_batch, targets_batch
> 
> train_dataset = tf.data.Dataset.from_generator(lambda: callable_iterator(train_generator),output_types=(tf.float32, tf.float32))
> val_dataset = tf.data.Dataset.from_generator(lambda: callable_iterator(val_generator),output_types=(tf.float32, tf.float32))
> 
> # for image, label in train_dataset.take(1):
> #   print(""Image shape: "", image.numpy().shape)
> #   print(""Label: "", label.numpy())
> #   plt.imshow(image.numpy()[0] * 255)
> #   plt.show()
> 
> 
> clf = ak.ImageClassifier(max_trials=10)
> #Feed the tensorflow Dataset to the classifier.
> clf.fit(train_dataset, epochs=60)
> #Evaluate the best model.
> print(clf.evaluate(val_dataset))
> ```
> 
> Then you can feed your fit function with the tf.datasets

Getting an error `ValueError: Cannot take the length of shape with unknown rank.` on line `clf.fit(train_dataset, epochs=60)`",code work give shot python import import import ak import image import import list return categorical categorical generator generator yield lambda lambda image label print image shape print label feed classifier evaluate best model print feed fit function getting error take length shape unknown line,issue,positive,positive,positive,positive,positive,positive
658821091,"Update: I can't even finish a trial, I get an error of running out of memory which disappears if I do not use `overwrite=True`

Update 2: two trials later I do not run out of memory (for now, it's only in the first trial). 

Sorry if you fell overwhelmed by my many comments, I am just try to give as much information as possible to contribute to Autokeras.",update ca even finish trial get error running memory use update two later run memory first trial sorry fell many try give much information possible contribute,issue,negative,positive,neutral,neutral,positive,positive
658762272,"I originally wanted to use AutoKeras for time-series data. I prepared the date to be fed into a LSTM, so the dimensions are: ```(BATCH_SIZE x WINDOW_SIZE x NUM_FEATURES)```.",originally use data prepared date fed,issue,negative,positive,positive,positive,positive,positive
658683917,"Still interested, as I need this feature for integration into Dataiku DSS.",still interested need feature integration,issue,negative,positive,positive,positive,positive,positive
658639532,Is `overwrite=True` not working yet? Any stable solution to continue the seeking/training after being stopped?,working yet stable solution continue stopped,issue,negative,neutral,neutral,neutral,neutral,neutral
658367489,"> I might because of the `overwrite=False`. Just change it to True may solve the problem.

I'll try with this, if it does not solve the issue, I will notify.

As @I-Kryachko , my issue is starting training from scratch.

And finally, I have to say that the error didn't show up in the last 3-4 trials I made, but I got a run out of memory error. So not sure what was going on with the previous issue.",might change true may solve problem try solve issue notify issue starting training scratch finally say error show last made got run memory error sure going previous issue,issue,negative,positive,positive,positive,positive,positive
658070739,"Found out that Pickiling your model will preserve the text encoding.

import joblib

#save the model
joblib.dump(model, 'model.pkl') 

#load the model
model_from_joblib = joblib.load('model.pkl')  


import numpy as np
# Use the loaded model to make predictions 
model_from_joblib.predict([np.asarray([""your X""], dtype=np.str), -1])",found model preserve text import save model model load model import use loaded model make,issue,negative,neutral,neutral,neutral,neutral,neutral
657390387,@haifeng-jin setting `overwrite=False` indeed fixed the issue. Thanks for your help!,setting indeed fixed issue thanks help,issue,positive,positive,positive,positive,positive,positive
657250515,"> You can use `AutoModel.tuner.get_best_models(3)`

This will enlist the best 3 models. I want to save these models or export them. Is there any way to do this?

",use enlist best want save export way,issue,positive,positive,positive,positive,positive,positive
657191493,"Same here but not only one epoch, I have 4 trials after resuming more than one training processes and training ends with export of a very bad model comparing to previous saved metrics (i do not use validation split and have separate validation tf.dataset).

I train 2 different models at the same time on different gpus and in different project directories. I had low disk space and my processes stopped, but I started them at different time and that is why first process stopped at trial 267 and second stopped at trial 78. After I cleared disk space and resumed processes both of them got same 4 more trials and finished training with exporting. The finished ""best_model"" was 20% worse than several models in saved checkpoints by saved metrics (compared manually).

I expected that after resuming the train process my previous best models would be compared to new ""current best"" model. And the fact that when I resumed both processes I got same low number of trials is suspicious. I had practically the same behaviour when interrupt the process by ctrl+c and resume it after - the training process does not last more than several trials not more than 4 even if I interupt at one finished trial.
Is this a bug or I missed something, @haifeng-jin ?",one epoch one training training export bad model previous saved metric use validation split separate validation train different time different different project low disk space stopped different time first process stopped trial second stopped trial disk space got finished training finished worse several saved saved metric manually train process previous best would new current best model fact got low number suspicious practically behaviour interrupt process resume training process last several even one finished trial bug something,issue,negative,positive,neutral,neutral,positive,positive
657190460,"@haifeng-jin 
For me issue happens when I start training without interrupting and resuming the process, wothout any previously saved checkpoints. That is why the result is the same with `overwrite=False` or with `overwrite=True`.",issue start training without interrupting process previously saved result,issue,positive,negative,negative,negative,negative,negative
657163519,I might because of the `overwrite=False`. Just change it to True may solve the problem.,might change true may solve problem,issue,negative,positive,positive,positive,positive,positive
657163347,"@ricwo Are you using overwrite=False? If you let overwrite=True, I think the error would gone.",let think error would gone,issue,negative,neutral,neutral,neutral,neutral,neutral
657163199,"Thanks for the report.
Why would the structured data have more than 2 dimensions?
what are the meanings of each dimension please?",thanks report would structured data dimension please,issue,positive,positive,positive,positive,positive,positive
655141913,"I have the same issue with Image Classifier. Also version is 1.0.3. My dataset is like:
```
tdataset = tf.data.Dataset.from_tensor_slices((tfilenames, tannotations))
vdataset = tf.data.Dataset.from_tensor_slices((vfilenames, vannotations))
...
tdataset = tdataset.map(BasicPreprocessor(im_size, 0))
vdataset = vdataset.map(BasicPreprocessor(im_size, 1))
```

Preprocessor is:
```
    @tf.function
    def preprocess_annotated(self, data, annotation):
        if self.pipeline == 0 or self.pipeline == 1:
            image_string = tf.io.read_file(data)
            image = tf.image.decode_image(image_string, channels=3)
            image.set_shape(shape=[None, None, 3])
            images = self.adjust_pixelwise(image)
        else:
            images = data

        images = self.resize_to(image=images, sz=self.images_size, keep_scales=self.keep_scales)

        return images, annotation
```
where `self.resize_to` is call of `tf.image.resize(images=image, size=(sz, sz))`; `self.adjust_pixelwise` is:
```
result = tf.divide(image, tf.constant(2.0))
result = tf.add(result, tf.constant(0.5))
result = tf.image.convert_image_dtype(result, tf.uint8)
return result
```
The other code is from Get Started example.
Sometimes it works well but when trials reach something with 'classification_head_1/spatial_reduction_1/reduction_type' I get the error mentioned earlier. Once i hade nearly 60 trials finished without this error and I think there was no `spatial_reduction_1` block inside any trial. And most of the times I have only nearly 3-7 trials working correctly and then an error appears.

Any workarounds or news about issue, @haifeng-jin?",issue image classifier also version like self data annotation data image none none image else data return annotation call result image result result result result return result code get example sometimes work well reach something get error hade nearly finished without error think block inside trial time nearly working correctly error news issue,issue,negative,positive,neutral,neutral,positive,positive
654966599,"Well, I had tried this first but for some reason, it did not work all the time. I still used to get an error some times. Need to figure out why.",well tried first reason work time still used get error time need figure,issue,negative,positive,positive,positive,positive,positive
654956430,"I think that you do not need to fix this by hardcoding the metric that you need in a certan task.

The problem for me was that autokeras could not get correct model checkpoint for epoch because it was looking for a deleted one and that is why i got the error when the trials finished and the final ""best model"" loop started to loop the best trials.

The deleting algo was described earlier and is in `save_model` method. Debugging this I noticed that `epoch` value differs from `step` value in console and in trial.json step value equals the epoch_value. Then I noticed that the deleted epoch is the previous to the first that was saved in my checkpoints directory. For example if i have best step=9 for trial then my best epoch number is 10 in console log and checkpoint is saved in epoch_9 directory. And the `save_model` method just delets my directory epoch_9 cause it starts to delete from the wrong epoch number.
That is why I fixed the line in the method above:
`epoch_to_delete = epoch - self._save_n_checkpoints`
to this:
`epoch_to_delete = epoch - self._save_n_checkpoints - 1`
and now my best checkpoints are stored correctly. Hope this helps you too.",think need fix metric need task problem could get correct model epoch looking one got error finished final best model loop loop best method epoch value step value console step value epoch previous first saved directory example best trial best epoch number console log saved directory method directory cause delete wrong epoch number fixed line method epoch epoch best correctly hope,issue,positive,positive,positive,positive,positive,positive
654457873,"@haifeng-jin I'm having the same issue. ak is trying to restore epoch 2, which was not persisted:

```bash
ValueError: Unsuccessful TensorSliceReader constructor: Failed to get matching files on /data/auto-clf-20-epochs-4-trials/trial_479975cd710064c8120d0f95a2c0b230/checkpoints/epoch_2/checkpoint: Not found: /data/auto-clf-20-epochs-4-trials/trial_479975cd710064c8120d0f95a2c0b230/checkpoints/epoch_2; No such file or directory
```
However epoch 2 was not persisted during training:
```bash
ls /data/auto-clf-20-epochs-4-trials/trial_479975cd710064c8120d0f95a2c0b230/checkpoints
epoch_0  epoch_10  epoch_11  epoch_12  epoch_3  epoch_4  epoch_5  epoch_6  epoch_7  epoch_8  epoch_9
```

Is there anything I can do to help fix this issue? ",issue ak trying restore epoch bash unsuccessful constructor get matching found file directory however epoch training bash anything help fix issue,issue,negative,neutral,neutral,neutral,neutral,neutral
654455622,@chyt It seems you are facing multiple bugs while using AutoKeras. It would be great if we can schedule an one hour meeting to help you debug. We can use half of the meeting to debug and half of the meeting for you to answer some of our user study questions. You can join our slack and message me your email address. Thank you!,facing multiple would great schedule one hour meeting help use half meeting half meeting answer user study join slack message address thank,issue,positive,positive,positive,positive,positive,positive
653753941,"> ```
> model = clf.export_model()
> ```
> 
> You can get a keras model in this way.
> Then refer to this one for how to visualize it. https://keras.io/api/utils/model_plotting_utils/

thanks！",model get model way refer one visualize,issue,negative,neutral,neutral,neutral,neutral,neutral
653119709,"I'm having the same issue, but with Image Classifier. My autokeras version is 1.0.3",issue image classifier version,issue,negative,neutral,neutral,neutral,neutral,neutral
652590513,The performance is almost similar to the tutorial now. ,performance almost similar tutorial,issue,negative,neutral,neutral,neutral,neutral,neutral
652559217,@zhulingchen Would you like to do a user study with us? Have a 30-minute meeting with me to talk about what do you think of AutoKeras. Your thinking is important to us. Thanks.,would like user study u meeting talk think thinking important u thanks,issue,positive,positive,positive,positive,positive,positive
651210146,"> Please refer to #984 for how to use generators.

Hi, please see above comment that the error is not due to the generators.",please refer use hi please see comment error due,issue,negative,negative,negative,negative,negative,negative
651195093,"I found the bug. When `.fit()` is called, it gets stuck when calling` _prepare_data()`, which gets stuck in`split_data()`. Then, `split_data()` gets sutck when calling `dataset.reduce().` This happens because Image data preprocessing from Keras creates an infinite generator, but according to [tensorflow docs, reduce() ](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#reduce)runs until the dataset is exhausted. The point is that as it is infinite, the dataset never gets exhausted.",found bug stuck calling stuck calling image data infinite generator according reduce exhausted point infinite never exhausted,issue,negative,negative,neutral,neutral,negative,negative
651167177,"> Originally, this error is because Keras Tuner deletes the old checkpoints saved on disk to reduce the disk usage. However, we have fixed this in a recent pull request ([keras-team/keras-tuner#318](https://github.com/keras-team/keras-tuner/pull/318)). Not sure why still exists.
> 
> @chyt Would you share a colab notebook for the reproduction? Thanks.

How would I share this notebook with you? The code is pretty straightforward, but the dataset is loaded from Google Drive.

Edit: here is a Gist of the notebook: https://gist.github.com/chyt/79e2f9de030c11e990af8595e7da631b

You can see the error near the bottom of the output:

```
ValueError: Unsuccessful TensorSliceReader constructor: Failed to get matching files on /content/drive/My Drive/image_classifier/trial_6a080628b2d822154a54edc6187850b6/checkpoints/epoch_67/checkpoint: Not found: /content/drive/My Drive/image_classifier/trial_6a080628b2d822154a54edc6187850b6/checkpoints/epoch_67; No such file or directory
```",originally error tuner old saved disk reduce disk usage however fixed recent pull request sure still would share notebook reproduction thanks would share notebook code pretty straightforward loaded drive edit gist notebook see error near bottom output unsuccessful constructor get matching found file directory,issue,positive,positive,positive,positive,positive,positive
650909765,"Originally, this error is because Keras Tuner deletes the old checkpoints saved on disk to reduce the disk usage. However, we have fixed this in a recent pull request (https://github.com/keras-team/keras-tuner/pull/318). Not sure why still exists.

@chyt Would you share a colab notebook for the reproduction? Thanks.",originally error tuner old saved disk reduce disk usage however fixed recent pull request sure still would share notebook reproduction thanks,issue,positive,positive,positive,positive,positive,positive
650854737,"I am afraid it does not work still.

The tutorial works fine in my colab,
but the code above still produces errors.

So I change the code to save data into a csv file and do the same thing as the tutorial,
but still `reg.predict()` produces an error(the below)

```
WARNING:tensorflow:Model was constructed with shape (None, 12) for input Tensor(""input_1:0"", shape=(None, 12), dtype=string), but it was called on an input with incompatible shape (None, 9).
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-35-f2177c0055ff> in <module>()
      1 # Predict with the best model.
----> 2 predicted_y = reg.predict(test_file_path)

12 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)
    966           except Exception as e:  # pylint:disable=broad-except
    967             if hasattr(e, ""ag_error_metadata""):
--> 968               raise e.ag_error_metadata.to_exception(e)
    969             else:
    970               raise

ValueError: in user code:

    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1147 predict_function  *
        outputs = self.distribute_strategy.run(
    /usr/local/lib/python3.6/dist-packages/autokeras/keras_layers.py:48 call  *
        split_inputs = tf.split(input_nodes, [1] * len(self.encoding), axis=-1)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:1962 split  **
        value=value, size_splits=size_splits, axis=axis, num_split=num, name=name)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py:9789 split_v
        num_split=num_split, name=name)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:744 _apply_op_helper
        attrs=attr_protos, op_def=op_def)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py:595 _create_op_internal
        compute_device)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:3327 _create_op_internal
        op_def=op_def)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:1817 __init__
        control_input_ops, op_def)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:1657 _create_c_op
        raise ValueError(str(e))

    ValueError: can't split axis of size 9 into pieces of size [1,1,1,1,1,1,1,1,1,1,1,1] for '{{node model/multi_column_categorical_encoding/split}} = Spl
```",afraid work still tutorial work fine code still change code save data file thing tutorial still error warning model shape none input tensor none input incompatible shape none recent call last module predict best model wrapper except exception raise else raise user code call split raise ca split axis size size node,issue,positive,positive,positive,positive,positive,positive
650779040,"Thanks, this error does not occur anymore. However, using the installation instructions at https://autokeras.com/install/, ensuring that the scipy version is 1.4.1, keras-tuner version is 1.0.2rc0, and autokeras version is 1.0.3 per autokeras requirements I now get the following error:

>Error in py_call_impl(callable, dots$args, dots$keywords) : 
> TypeError: __init__() got an unexpected keyword argument 'name' 

Maybe related to #1193 ",thanks error occur however installation version version version per get following error error callable got unexpected argument maybe related,issue,negative,positive,neutral,neutral,positive,positive
650701481,"Yes true, you need to pick the specific metric that needs to be compared to identify the best model. For me it was a regression problem so I chose val_loss (rmse).",yes true need pick specific metric need identify best model regression problem chose,issue,positive,positive,positive,positive,positive,positive
650700158,"This issue helps a lot. However, the solution doesn't work for me. I find that the best model is evaluated by the validation accuracy, not the validation loss. The best epoch should be the one with the highest accuracy. Simply replacing best loss with best accuracy works.",issue lot however solution work find best model validation accuracy validation loss best epoch one highest accuracy simply best loss best accuracy work,issue,positive,positive,positive,positive,positive,positive
650654380,"Thanks a lot.

The piece of code is running now!

On Sat, Jun 27, 2020 at 5:59 AM Sivam Pillai <notifications@github.com>
wrote:

> I have extended my hack further, to achieve the original goal in a
> non-standard way. I realized that best_step is only set at the end of the
> trial. So it is None during the trial. However, since we call save_model on
> epoch end, we can use the traditional approach of identifying best_epoch by
> comparing val_loss from logs and using this to find best_epoch and pass to
> the save model.
>
> Here are my updates to kerastuner/engine/tuner.py file (follow the
> comments CHANGE HERE):
>
> # required to set the initial loss value to infinity (very large number)
> import numpy as np
>
>
> class Tuner(base_tuner.BaseTuner):
>
>     def __init__(self,
>                  oracle,
>                  hypermodel,
>                  max_model_size=None,
>                  optimizer=None,
>                  loss=None,
>                  metrics=None,
>                  distribution_strategy=None,
>                  directory=None,
>                  project_name=None,
>                  logger=None,
>                  tuner_id=None,
>                  overwrite=False):
>
>         # Subclasses of `KerasHyperModel` are not automatically wrapped.
>        # CHANGE HERE: initialized values for best_loss and best_epoch later set after each epoch
>         self.best_loss = np.inf
>         self.best_epoch = 0
>         if not isinstance(hypermodel, hm_module.KerasHyperModel):
>             hypermodel = hm_module.KerasHyperModel(
>                 hypermodel,
>                 max_model_size=max_model_size,
>                 optimizer=optimizer,
>                 loss=loss,
>                 metrics=metrics,
>                 distribution_strategy=distribution_strategy)
>
>         super(Tuner, self).__init__(oracle=oracle,
>                                     hypermodel=hypermodel,
>                                     directory=directory,
>                                     project_name=project_name,
>                                     logger=logger,
>                                     overwrite=overwrite)
>
>         self.distribution_strategy = distribution_strategy
>
>         # Support multi-worker distribution strategies w/ distributed tuning.
>         # Only the chief worker in each cluster should report results.
>         if self.distribution_strategy is not None:
>             self.oracle.multi_worker = (
>                 self.distribution_strategy.extended._in_multi_worker_mode())
>             self.oracle.should_report = (
>                 self.distribution_strategy.extended.should_checkpoint)
>
>         # Save only the last N checkpoints.
>         self._save_n_checkpoints = 10
>
>         self.tuner_id = tuner_id or self.tuner_id
>
> # CHANGE HERE: save_model function (Original is commented out)
> #     def save_model(self, trial_id, model, step=0):
> #         epoch = step
> #         self._checkpoint_model(model, trial_id, epoch)
> #         # TODO: save the top epoch checkpoints instead of last ones.
> #         epoch_to_delete = epoch - self._save_n_checkpoints
> #         best_epoch = self.oracle.get_trial(trial_id).best_step
> #         if epoch > self._save_n_checkpoints and epoch_to_delete != best_epoch:
> #             self._delete_checkpoint(
> #                 trial_id, epoch_to_delete)
>
>     def save_model(self, trial_id, model, step=0):
>         epoch = step
>         self._checkpoint_model(model, trial_id, epoch)
>         # TODO: save the top epoch checkpoints instead of last ones.
>         epoch_to_delete = epoch - self._save_n_checkpoints
> #         best_epoch = self.oracle.get_trial(trial_id).best_step
>         print(""BEST EPOCH, DELETE EPOCH, NCHKP: "", self.best_epoch, epoch_to_delete, self._save_n_checkpoints)
>         if epoch > self._save_n_checkpoints and epoch_to_delete != self.best_epoch:
>             self._delete_checkpoint(
>                 trial_id, epoch_to_delete)
>
>     def on_epoch_end(self, trial, model, epoch, logs=None):
>         """"""A hook called at the end of every epoch.
>
>         # Arguments:
>             trial: A `Trial` instance.
>             model: A Keras `Model`.
>             epoch: The current epoch number.
>             logs: Dict. Metrics for this epoch. This should include
>               the value of the objective for this epoch.
>         """"""
>       # CHANGE HERE: check if current loss better than previous loss and set best_epoch accordingly
>         if logs['val_loss'] < self.best_loss:
>             self.best_epoch = epoch
>             self.best_loss = logs['val_loss']
>
>         print(""best: "", self.best_epoch, self.best_loss, logs['val_loss'])
>         self.save_model(trial.trial_id, model, step=epoch)
>         # Report intermediate metrics to the `Oracle`.
>         status = self.oracle.update_trial(
>             trial.trial_id, metrics=logs, step=epoch)
>         trial.status = status
>         if trial.status == ""STOPPED"":
>             model.stop_training = True
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/keras-team/autokeras/issues/1210#issuecomment-650558229>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AQBYMPDWKJTD7EXD3TH2GDTRYXUMTANCNFSM4OJA6YFA>
> .
>
",thanks lot piece code running sat wrote extended hack achieve original goal way set end trial none trial however since call epoch end use traditional approach find pas save model file follow change set initial loss value infinity large number import class tuner self oracle automatically wrapped change later set epoch super tuner self support distribution distributed tuning chief worker cluster report none save last change function original self model epoch step model epoch save top epoch instead last epoch epoch self model epoch step model epoch save top epoch instead last epoch print best epoch delete epoch epoch self trial model epoch hook end every epoch trial trial instance model model epoch current epoch number metric epoch include value objective epoch change check current loss better previous loss set accordingly epoch print best model report intermediate metric oracle status status stopped true reply directly view,issue,positive,positive,positive,positive,positive,positive
650558229,"I have extended my hack further, to achieve the original goal in a non-standard way. I realized that best_step is only set at the end of the trial. So it is None during the trial. However, since we call save_model on epoch end, we can use the traditional approach of identifying best_epoch by comparing val_loss from logs and using this to find best_epoch and pass to the save model.

Here are my updates to kerastuner/engine/tuner.py file (follow the comments CHANGE HERE):

```
# required to set the initial loss value to infinity (very large number)
import numpy as np


class Tuner(base_tuner.BaseTuner):
   
    def __init__(self,
                 oracle,
                 hypermodel,
                 max_model_size=None,
                 optimizer=None,
                 loss=None,
                 metrics=None,
                 distribution_strategy=None,
                 directory=None,
                 project_name=None,
                 logger=None,
                 tuner_id=None,
                 overwrite=False):

        # Subclasses of `KerasHyperModel` are not automatically wrapped.
       # CHANGE HERE: initialized values for best_loss and best_epoch later set after each epoch
        self.best_loss = np.inf
        self.best_epoch = 0
        if not isinstance(hypermodel, hm_module.KerasHyperModel):
            hypermodel = hm_module.KerasHyperModel(
                hypermodel,
                max_model_size=max_model_size,
                optimizer=optimizer,
                loss=loss,
                metrics=metrics,
                distribution_strategy=distribution_strategy)

        super(Tuner, self).__init__(oracle=oracle,
                                    hypermodel=hypermodel,
                                    directory=directory,
                                    project_name=project_name,
                                    logger=logger,
                                    overwrite=overwrite)

        self.distribution_strategy = distribution_strategy

        # Support multi-worker distribution strategies w/ distributed tuning.
        # Only the chief worker in each cluster should report results.
        if self.distribution_strategy is not None:
            self.oracle.multi_worker = (
                self.distribution_strategy.extended._in_multi_worker_mode())
            self.oracle.should_report = (
                self.distribution_strategy.extended.should_checkpoint)

        # Save only the last N checkpoints.
        self._save_n_checkpoints = 10

        self.tuner_id = tuner_id or self.tuner_id

# CHANGE HERE: save_model function (Original is commented out)
#     def save_model(self, trial_id, model, step=0):
#         epoch = step
#         self._checkpoint_model(model, trial_id, epoch)
#         # TODO: save the top epoch checkpoints instead of last ones.
#         epoch_to_delete = epoch - self._save_n_checkpoints
#         best_epoch = self.oracle.get_trial(trial_id).best_step
#         if epoch > self._save_n_checkpoints and epoch_to_delete != best_epoch:
#             self._delete_checkpoint(
#                 trial_id, epoch_to_delete)

    def save_model(self, trial_id, model, step=0):
        epoch = step
        self._checkpoint_model(model, trial_id, epoch)
        # TODO: save the top epoch checkpoints instead of last ones.
        epoch_to_delete = epoch - self._save_n_checkpoints
#         best_epoch = self.oracle.get_trial(trial_id).best_step
        print(""BEST EPOCH, DELETE EPOCH, NCHKP: "", self.best_epoch, epoch_to_delete, self._save_n_checkpoints)
        if epoch > self._save_n_checkpoints and epoch_to_delete != self.best_epoch:
            self._delete_checkpoint(
                trial_id, epoch_to_delete)

    def on_epoch_end(self, trial, model, epoch, logs=None):
        """"""A hook called at the end of every epoch.

        # Arguments:
            trial: A `Trial` instance.
            model: A Keras `Model`.
            epoch: The current epoch number.
            logs: Dict. Metrics for this epoch. This should include
              the value of the objective for this epoch.
        """"""
      # CHANGE HERE: check if current loss better than previous loss and set best_epoch accordingly
        if logs['val_loss'] < self.best_loss:
            self.best_epoch = epoch 
            self.best_loss = logs['val_loss']

        print(""best: "", self.best_epoch, self.best_loss, logs['val_loss'])
        self.save_model(trial.trial_id, model, step=epoch)
        # Report intermediate metrics to the `Oracle`.
        status = self.oracle.update_trial(
            trial.trial_id, metrics=logs, step=epoch)
        trial.status = status
        if trial.status == ""STOPPED"":
            model.stop_training = True

Should we create a PR for kerastuner based on this?",extended hack achieve original goal way set end trial none trial however since call epoch end use traditional approach find pas save model file follow change set initial loss value infinity large number import class tuner self oracle automatically wrapped change later set epoch super tuner self support distribution distributed tuning chief worker cluster report none save last change function original self model epoch step model epoch save top epoch instead last epoch epoch self model epoch step model epoch save top epoch instead last epoch print best epoch delete epoch epoch self trial model epoch hook end every epoch trial trial instance model model epoch current epoch number metric epoch include value objective change check current loss better previous loss set accordingly epoch print best model report intermediate metric oracle status status stopped true create based,issue,positive,positive,positive,positive,positive,positive
650546071,"OK, on further investigation, I have found that the error comes from keras-tuner in the save_model function of tuner class:

```
    def save_model(self, trial_id, model, step=0):
        epoch = step
        self._checkpoint_model(model, trial_id, epoch)
        # TODO: save the top epoch checkpoints instead of last ones.
        epoch_to_delete = epoch - self._save_n_checkpoints
        best_epoch = self.oracle.get_trial(trial_id).best_step
        if epoch > self._save_n_checkpoints and epoch_to_delete != best_epoch:
            self._delete_checkpoint(
                trial_id, epoch_to_delete)
```

Here the model checks, if the number of epochs is more than the maximum number and starts deleting older models. The if condition ensures best_model is not deleted. However, the problem comes from the fact that best_epoch is always None. As a result, that condition is useless and old models (older than self._save_n_checkpoints=10) including best model gets deleted.

Will need advice on how to make sure oracle appropriately updates best_epoch here so we can skip deleting the best model. A simple hack to make this work (if storage is not an issue) is to simply comment out the delete portion (that will save all the epochs)

```
    def save_model(self, trial_id, model, step=0):
        epoch = step
        self._checkpoint_model(model, trial_id, epoch)
        # TODO: save the top epoch checkpoints instead of last ones.
        epoch_to_delete = epoch - self._save_n_checkpoints
        best_epoch = self.oracle.get_trial(trial_id).best_step
        # if epoch > self._save_n_checkpoints and epoch_to_delete != best_epoch:
        #    self._delete_checkpoint(
        #        trial_id, epoch_to_delete)
```",investigation found error come function tuner class self model epoch step model epoch save top epoch instead last epoch epoch model number maximum number older condition however problem come fact always none result condition useless old older best model need advice make sure oracle appropriately skip best model simple hack make work storage issue simply comment delete portion save self model epoch step model epoch save top epoch instead last epoch epoch,issue,positive,positive,positive,positive,positive,positive
650524157,"I'm using autokeras on top of tensorflow docker images, which currently has tensorflow-gpu installed. When pip install autokeras is done, it tries to install tensorflow instead of detecting tensorflow-gpu.",top docker currently pip install done install instead,issue,negative,positive,positive,positive,positive,positive
650241299,"I am seeing this as well using ImageClassifier on Google Colab connected to Google Drive. Usually everything is fine with a smaller number of trials/epochs. However when I increase this number (right now I am doing 10 trials and 200 epochs) I get the error and the epoch directory does not exist. This seems to be a bit different of an error than what @pingusix is experiencing, since he seems to indicate that the epoch directory does exist. 

I was wondering if it could have something to do with getting disconnected from Google Colab, but based on the reports here it seems like it is not the case. 

I'm using autokeras 1.0.3, keras tuner 1.0.2rc0, and tensorflow 2.2.0. ",seeing well connected drive usually everything fine smaller number however increase number right get error epoch directory exist bit different error since indicate epoch directory exist wondering could something getting disconnected based like case tuner,issue,negative,positive,neutral,neutral,positive,positive
649963519,"Thank you for your reply.
Wine data is provided scikit-learn datasets.
[https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine)
It is table data for three-class classification, and all features are numerical values.",thank reply wine data provided table data classification numerical,issue,negative,neutral,neutral,neutral,neutral,neutral
649893539,"Yes, we can although I haven't tested. You can use RNNBlock to do it with AutoModel.
https://autokeras.com/block/#rnnblock-class
https://autokeras.com/tutorial/customized/",yes although tested use,issue,negative,neutral,neutral,neutral,neutral,neutral
649892853,As I tested the latest version of AutoKeras can save the structureddataregressor fine.,tested latest version save fine,issue,positive,positive,positive,positive,positive,positive
649892372,"We have released a new version, which is 1.0.3. depending on tf 2.2.0. Please see this installation guide. https://autokeras.com/#installation",new version depending please see installation guide,issue,negative,positive,positive,positive,positive,positive
649892081,We don't have enough people to work on this feature for now. But we welcome people to build a third-party package to do the job.,enough people work feature welcome people build package job,issue,negative,positive,positive,positive,positive,positive
649891646,This is fixed in 1.0.3. Please let me know if it is not.,fixed please let know,issue,negative,positive,neutral,neutral,positive,positive
649517146,"> Currently, autokeras does not support generators given by flow_from_directory. I tried to wrap them into a tf.Dataset because they are supposed to be supported, but there is a problem when fitting it. I opened an issue about that.

Thanks for replying, although flow_from_directory is not supported, it doesnt seems to be the source of my error. ive tried other datas including the examples given in the website and i still get the same error. i'm wondering if there is an issue with keras tuner?

the kernel stops at 
model= ak.ImageClassifier(
    ...)
",currently support given tried wrap supposed problem fitting issue thanks although doesnt source error tried given still get error wondering issue tuner kernel,issue,positive,positive,positive,positive,positive,positive
649499128,"By they way, I think we can close this issue.",way think close issue,issue,negative,neutral,neutral,neutral,neutral,neutral
649498562,"Currently, autokeras does not support generators given by flow_from_directory. I tried to wrap them into a tf.Dataset because they are supposed to be supported, but there is a problem when fitting it. I opened an issue about that.",currently support given tried wrap supposed problem fitting issue,issue,negative,positive,positive,positive,positive,positive
649144650,"This is because your are using a different version of Keras Tuner. Please follow this guide to install the correct version.
https://autokeras.com/#installation",different version tuner please follow guide install correct version,issue,negative,neutral,neutral,neutral,neutral,neutral
649144031,"This is already fixed. Please try our latest release 1.0.3.
https://colab.research.google.com/github/keras-team/autokeras/blob/master/docs/ipynb/image_classification.ipynb",already fixed please try latest release,issue,negative,positive,positive,positive,positive,positive
649143774,"Thank you for the report! I think it is fixed in the latest release 1.0.3. If it doesn't, please let me know. Thanks.",thank report think fixed latest release please let know thanks,issue,positive,positive,positive,positive,positive,positive
649143408,"Sorry, this is not of high priority now. We may get to it later when we have finished the tasks in progress.",sorry high priority may get later finished progress,issue,negative,negative,negative,negative,negative,negative
649143103,This is fixed in 1.0.3 release. You can also export the model with 1.0.3. Thanks.,fixed release also export model thanks,issue,negative,positive,positive,positive,positive,positive
649142908,Thank you for the bug report. I think this is fixed in our latest release 1.0.3. You may have a try.,thank bug report think fixed latest release may try,issue,negative,positive,positive,positive,positive,positive
649142682,Would you provide your dataset? I can take a look. Thank you!,would provide take look thank,issue,negative,neutral,neutral,neutral,neutral,neutral
649142409,Thank you for the issue! We may make it more flexible to have different orders of the layers as a hyperparameter. I think people are doing it in various ways.,thank issue may make flexible different think people various way,issue,positive,neutral,neutral,neutral,neutral,neutral
649141422,Would you provide your code and dataset? It would be great if they are in a colab notebook. I can take a look to see why.,would provide code would great notebook take look see,issue,positive,positive,positive,positive,positive,positive
649140750,"#925  We have this issue here. However, we are not working on it right now. Will get to it after timeseries forecasting and image segmentation.",issue however working right get forecasting image segmentation,issue,negative,positive,positive,positive,positive,positive
649139263,Let's use #984 to track this generator issue. Thanks.,let use track generator issue thanks,issue,negative,positive,positive,positive,positive,positive
649139061,"We just release the real 1.0.3. You may try this https://colab.research.google.com/github/keras-team/autokeras/blob/master/docs/ipynb/image_classification.ipynb
",release real may try,issue,negative,positive,positive,positive,positive,positive
649138748,I believe we have fixed this in the latest version 1.0.3. Please let me know if it still doesn't work. ,believe fixed latest version please let know still work,issue,negative,positive,positive,positive,positive,positive
649138516,"I think it might because the metrics are evaluated on different data. During testing, I assume you passed testing data. During fit, AutoKeras split your training data and the evaluation is done on the validation data splited from the training data.",think might metric different data testing assume testing data fit split training data evaluation done validation data training data,issue,negative,positive,positive,positive,positive,positive
649046385,"> Please uninstall it and install it with this command. `pip install git+https://github.com/keras-team/keras-tuner.git@1.0.2rc0#egg=keras-tuner-1.0.2rc0`

I tried and it worked. Thks!
",please install command pip install tried worked,issue,negative,neutral,neutral,neutral,neutral,neutral
648894965,"If you read the docs or the paper, you will find out that autokeras finds an architecture using a variation of bayesian optimization. Not sure  if you can just improve an actual model with autokeras",read paper find architecture variation optimization sure improve actual model,issue,positive,positive,positive,positive,positive,positive
648888805,Whats the status on this? Not being able to load a saved model kind of defeats the purpose of autokeras in the first place...,whats status able load saved model kind purpose first place,issue,positive,positive,positive,positive,positive,positive
648726865,"> Currently, we are short of hands. It would be great if anyone could try to give an example on TF record and tf.data. @naitslup has provided this example ([#1060 (comment)](https://github.com/keras-team/autokeras/issues/1060#issuecomment-611473658)) , which would be a good start.

Happy to do this. ",currently short would great anyone could try give example record provided example comment would good start happy,issue,positive,positive,positive,positive,positive,positive
648719805,"Thanks. Just tried and works with tf 2.2.0, but the warning persists. Anyway, I did some research and the warning states that the state of the optimizer can't be saved, i.e we could not continue the training from the same point it finished. So it's not a problem at all. ",thanks tried work warning anyway research warning state ca saved could continue training point finished problem,issue,negative,positive,positive,positive,positive,positive
648659558,I have 32 GB of memory and I'm running it on the CPUs not on the video card.,memory running video card,issue,negative,neutral,neutral,neutral,neutral,neutral
648579462,"Currently, we are short of hands. It would be great if anyone could try to give an example on TF record and tf.data. @naitslup has provided this example (https://github.com/keras-team/autokeras/issues/1060#issuecomment-611473658) , which would be a good start.",currently short would great anyone could try give example record provided example would good start,issue,positive,positive,positive,positive,positive,positive
648579058,"I have the same error.
I'm adding DenseHashTable in DNNModel, intend to save embeddings in it, this is code:

`class DNNModel(tf.keras.Model):  
    def __init__(self, xxx):
            self.table = self._create_embedding_table(vocabulary_list, embeddings)

    def _create_embedding_table(self, vocab_list, embeddings):
        dimension = embeddings.shape[1]
        table = tf.lookup.experimental.DenseHashTable(tf.string, tf.float32, [2.0]*dimension, ""empty_key"", ""deleted_key"")
        # 对比，测试到底注释前后有没有效果
        keys = tf.constant([i for i in vocab_list], tf.string)
        values = tf.convert_to_tensor(embeddings, tf.float64)
        values = tf.cast(values, tf.float32)
        table.insert(keys, values)
        return table

    def call(self, inputs, training=None, mask=None):
        fc_embeddings = self._input_layer(inputs)
        bert_embeddings = self._look_up(inputs)
        net = tf.concat([fc_embeddings, bert_embeddings], axis=1)
       ....
`
all is ok when runn it, but when i  export model with the code tf.keras.models.save_model(model, FLAGS.servable_model_dir), it will raise the same error:RuntimeError: Attempting to capture an EagerTensor without building a function.

I debug the code, it likes serialize the DenseHashTable in dnnModel will raise Exceptions:

 File ""/Users/jiananliu/work/neirongrecom/model/ctr_model/wide_n_deep/wide_n_deep_keras_main.py"", line 1021, in run
    tf.keras.models.save_model(model, FLAGS.servable_model_dir, include_optimizer=False)
  File ""/Users/jiananliu/anaconda3/envs/transformer/lib/python3.7/site-packages/tensorflow/python/keras/saving/save.py"", line 138, in save_model
    signatures, options)
  File ""/Users/jiananliu/anaconda3/envs/transformer/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/save.py"", line 78, in save
    save_lib.save(model, filepath, signatures, options)
  File ""/Users/jiananliu/anaconda3/envs/transformer/lib/python3.7/site-packages/tensorflow/python/saved_model/save.py"", line 951, in save
    obj, export_dir, signatures, options, meta_graph_def)
  File ""/Users/jiananliu/anaconda3/envs/transformer/lib/python3.7/site-packages/tensorflow/python/saved_model/save.py"", line 1027, in _build_meta_graph
    options.namespace_whitelist)
  File ""/Users/jiananliu/anaconda3/envs/transformer/lib/python3.7/site-packages/tensorflow/python/saved_model/save.py"", line 595, in _fill_meta_graph_def
    object_map, resource_map, asset_info = saveable_view.map_resources()
  File ""/Users/jiananliu/anaconda3/envs/transformer/lib/python3.7/site-packages/tensorflow/python/saved_model/save.py"", line 270, in map_resources
    new_resource = new_obj._create_resource()
  File ""/Users/jiananliu/anaconda3/envs/transformer/lib/python3.7/site-packages/tensorflow/python/ops/lookup_ops.py"", line 1945, in _create_resource
    name=self._name)
  File ""/Users/jiananliu/anaconda3/envs/transformer/lib/python3.7/site-packages/tensorflow/python/ops/gen_lookup_ops.py"", line 1113, in mutable_dense_hash_table_v2
    max_load_factor=max_load_factor, name=name)
  File ""/Users/jiananliu/anaconda3/envs/transformer/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 470, in _apply_op_helper
    preferred_dtype=default_dtype)
  File ""/Users/jiananliu/anaconda3/envs/transformer/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 1307, in convert_to_tensor
    raise RuntimeError(""Attempting to capture an EagerTensor without ""
RuntimeError: Attempting to capture an EagerTensor without building a function.",error intend save code class self self dimension table dimension return table call self net export model code model raise error capture without building function code serialize raise file line run model file line file line save model file line save file line file line file line file line file line file line file line raise capture without capture without building function,issue,positive,neutral,neutral,neutral,neutral,neutral
648578740,Let's use #984 to track all the generator related issues. Thanks.,let use track generator related thanks,issue,negative,positive,neutral,neutral,positive,positive
648578329,Let's use #984 to track all the generator related questions.,let use track generator related,issue,negative,neutral,neutral,neutral,neutral,neutral
648577679,"It does work pretty well, better than the lstm baseline in my case. I think the issue with lstm is kind of, that there is not as much to optimize. You might run into some trouble, I had to do minor changes to source code to make padding and masking work for example",work pretty well better case think issue kind much optimize might run trouble minor source code make padding work example,issue,positive,positive,positive,positive,positive,positive
648577275,"We have released a new version 1.0.3. You may use this to install:
```
pip3 install git+https://github.com/keras-team/keras-tuner.git@1.0.2rc0
pip3 install autokeras==1.0.3
```",new version may use install pip install pip install,issue,negative,positive,positive,positive,positive,positive
648559364,We just release AutoKeras 1.0.3 with tons of bugs fixed. You may give it a try with TF 2.2.0 and Keras Tuner 1.0.2rc0,release fixed may give try tuner,issue,negative,positive,neutral,neutral,positive,positive
648557998,We just open up this arg in every API. Please try AutoKeras 1.0.3. Thanks.,open every please try thanks,issue,positive,positive,neutral,neutral,positive,positive
648557806,How much is your memory please? I cannot reproduce the error on my machine.,much memory please reproduce error machine,issue,negative,positive,positive,positive,positive,positive
648557503,"Our latest tutorial on structured data regression works. It is using tf 2.2.0 ak 1.0.3.
It has no problem exporting the model. As I tested it saves too.
https://autokeras.com/tutorial/structured_data_regression/",latest tutorial structured data regression work ak problem model tested,issue,negative,positive,positive,positive,positive,positive
648556566,"We just released a new version yesterday. So you may try it with AutoKeras 1.0.3. Remember to set `overwrite=True`, it is usually the overwrite thing causes the incompatibility.",new version yesterday may try remember set usually overwrite thing incompatibility,issue,negative,negative,neutral,neutral,negative,negative
648556181,Currently AutoKeras is not supporting data generator. You may only use tf.data.Dataset with tf record as an alternative. Thanks.,currently supporting data generator may use record alternative thanks,issue,positive,positive,positive,positive,positive,positive
648555720,We have fixed this problem for the new release. Please try autokeras 1.0.3. Thanks.,fixed problem new release please try thanks,issue,negative,positive,positive,positive,positive,positive
648555220,Please uninstall it and install it with this command. `pip install git+https://github.com/keras-team/keras-tuner.git@1.0.2rc0#egg=keras-tuner-1.0.2rc0`,please install command pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
648442474,"When I install manually keras-tuner (pip install keras-tuner) the following error is thrown

>>> import autokeras
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/leandro/.local/share/virtualenvs/Moira-jyrwulee/lib/python3.7/site-packages/autokeras/__init__.py"", line 48, in <module>
    check_kt_version()
  File ""/home/leandro/.local/share/virtualenvs/Moira-jyrwulee/lib/python3.7/site-packages/autokeras/utils/utils.py"", line 67, in check_kt_version
    'ok.'.format(version=kerastuner.__version__)
ImportError: The Keras Tuner package version needs to be at least 1.0.2rc0
for AutoKeras to run. Currently, your Keras Tuner version is
1.0.1. Please upgrade with
`$ pip install git+https://github.com/keras-team/keras-tuner.git@1.0.2rc0#egg=keras-tuner-1.0.2rc0`.
You can use `pip freeze` to check afterwards that everything is ok. 



Sorry if it was boring, I just want to help.",install manually pip install following error thrown import recent call last file line module file line module file line tuner package version need least run currently tuner version please upgrade pip install use pip freeze check afterwards everything sorry boring want help,issue,negative,negative,negative,negative,negative,negative
648374825,"> I'm also struggling with this. I've seen rumours of people managing to get it to work.
> 
> [This post](https://github.com/keras-team/autokeras/issues/984#issuecomment-629828148) is the main thing I've been cribbing from.
> [#1075](https://github.com/keras-team/autokeras/issues/1075#issuecomment-636543611) is also an important read I think.
> 
> Putting them together I built myself a docker image:
> 
> ```dockerfile
> RUN apt update && apt install -y git \                                                                                                                 
>  && python3 -m pip install git+https://github.com/keras-team/keras-tuner.git@master \                                                                  
>  && python3 -m pip install git+https://github.com/keras-team/autokeras.git \                                                                               
>  && python3 -m pip install Pillow  
> ```
> 
> And I've been trying to get it working since then using code like this:
> 
> ```python
> # yes I realise my imports are a mess, leave me alone
> from os import listdir
> from os.path import isfile, join
> import tensorflow as tf
> import numpy
> import random
> import PIL
> import autokeras
> 
> BATCH_SIZE = 1
> IMG_HEIGHT = 128
> IMG_WIDTH = 128
> 
> image_generator = tf.keras.preprocessing.image.ImageDataGenerator(
>                                               horizontal_flip=True,
>                                               validation_split=0.2)
> 
> train_generator = image_generator.flow_from_directory('training-data',
>                                                       batch_size=BATCH_SIZE,
>                                                       target_size=(IMG_HEIGHT, IMG_WIDTH),
>                                                       class_mode=""categorical"",
>                                                       shuffle=True)
> test_generator = image_generator.flow_from_directory('test-data',
>                                                batch_size=BATCH_SIZE,
>                                                target_size=(IMG_HEIGHT, IMG_WIDTH),
>                                                class_mode=""categorical"",
>                                                shuffle=True)
> 
> batch_num = 0
> 
> def callable_iterator(generator):
>     global batch_num
>     for img_batch, targets_batch in generator:
>         batch_num = batch_num + 1
>         if batch_num == 20000:
>             # have to break otherwise fit will run forever???
>             break
>         yield img_batch, targets_batch
> 
> print(""Beginning set generation"")
> training_set = tf.data.Dataset.from_generator(lambda: callable_iterator(train_generator), output_types=(tf.float32, tf.float32), output_shapes=(tf.TensorShape([BATCH_SIZE, IMG_HEIGHT, IMG_WIDTH, 3]), tf.TensorShape([BATCH_SIZE, 3])))
> test_set = tf.data.Dataset.from_generator(lambda: callable_iterator(test_generator), output_types=(tf.float32, tf.float32))
> 
> classifier = autokeras.ImageClassifier(project_name='classifier',
>                                        objective='val_accuracy',
>                                        max_trials=10)
> print(""beginning fit"")
> classifier.fit(training_set,
>                steps_per_epoch=100,
>                callbacks=[
>                    tf.keras.callbacks.EarlyStopping(patience=2),
>                    tf.keras.callbacks.ModelCheckpoint(filepath=""models/{epoch:02d}-{val_loss:.2f}.h5""),
>                    tf.keras.callbacks.CSVLogger(""ak-classifier.csv""),
>                    tf.keras.callbacks.ProgbarLogger()
>                ],
>                epochs=200)
> ```
> 
> But I still haven't got it working. By tweaking various bits (tensorflow version, steps_per_epoch, batch_size, epochs) I've managed to shift the errors around, but never eradicate them. Because I'm running it in a docker container modifying tensorflow/autokeras itself is super painful. I'm currently following a lead (noticed my autokeras install line didn't have the full git URL) and if that fails my next step is going to be starting to modify tensorflow to get some debug logging in there.

I gave autokeras up and returned to keras-tuner!!!",also struggling seen people get work post main thing cribbing also important read think together built docker image run apt update apt install git python pip install python pip install python pip install pillow trying get working since code like python yes mess leave alone o import import join import import import random import import categorical categorical generator global generator break otherwise fit run forever break yield print beginning set generation lambda lambda classifier print beginning fit epoch still got working various version shift around never eradicate running docker container super painful currently following lead install line full git next step going starting modify get logging gave returned,issue,positive,positive,positive,positive,positive,positive
648364623,"I'm also struggling with this. I've seen rumours of people managing to get it to work.

[This post](https://github.com/keras-team/autokeras/issues/984#issuecomment-629828148) is the main thing I've been cribbing from.
[#1075](https://github.com/keras-team/autokeras/issues/1075#issuecomment-636543611) is also an important read I think.

Putting them together I built myself a docker image:

```dockerfile
RUN apt update && apt install -y git \                                                                                                                 
 && python3 -m pip install git+https://github.com/keras-team/keras-tuner.git@master \                                                                  
 && python3 -m pip install git+https://github.com/keras-team/autokeras.git \                                                                               
 && python3 -m pip install Pillow  
```

And I've been trying to get it working since then using code like this:
```python
# yes I realise my imports are a mess, leave me alone
from os import listdir
from os.path import isfile, join
import tensorflow as tf
import numpy
import random
import PIL
import autokeras

BATCH_SIZE = 1
IMG_HEIGHT = 128
IMG_WIDTH = 128

image_generator = tf.keras.preprocessing.image.ImageDataGenerator(
                                              horizontal_flip=True,
                                              validation_split=0.2)

train_generator = image_generator.flow_from_directory('training-data',
                                                      batch_size=BATCH_SIZE,
                                                      target_size=(IMG_HEIGHT, IMG_WIDTH),
                                                      class_mode=""categorical"",
                                                      shuffle=True)
test_generator = image_generator.flow_from_directory('test-data',
                                               batch_size=BATCH_SIZE,
                                               target_size=(IMG_HEIGHT, IMG_WIDTH),
                                               class_mode=""categorical"",
                                               shuffle=True)

batch_num = 0

def callable_iterator(generator):
    global batch_num
    for img_batch, targets_batch in generator:
        batch_num = batch_num + 1
        if batch_num == 20000:
            # have to break otherwise fit will run forever???
            break
        yield img_batch, targets_batch

print(""Beginning set generation"")
training_set = tf.data.Dataset.from_generator(lambda: callable_iterator(train_generator), output_types=(tf.float32, tf.float32), output_shapes=(tf.TensorShape([BATCH_SIZE, IMG_HEIGHT, IMG_WIDTH, 3]), tf.TensorShape([BATCH_SIZE, 3])))
test_set = tf.data.Dataset.from_generator(lambda: callable_iterator(test_generator), output_types=(tf.float32, tf.float32))

classifier = autokeras.ImageClassifier(project_name='classifier',
                                       objective='val_accuracy',
                                       max_trials=10)
print(""beginning fit"")
classifier.fit(training_set,
               steps_per_epoch=100,
               callbacks=[
                   tf.keras.callbacks.EarlyStopping(patience=2),
                   tf.keras.callbacks.ModelCheckpoint(filepath=""models/{epoch:02d}-{val_loss:.2f}.h5""),
                   tf.keras.callbacks.CSVLogger(""ak-classifier.csv""),
                   tf.keras.callbacks.ProgbarLogger()
               ],
               epochs=200)
```

But I still haven't got it working. By tweaking various bits (tensorflow version, steps_per_epoch, batch_size, epochs) I've managed to shift the errors around, but never eradicate them. Because I'm running it in a docker container modifying tensorflow/autokeras itself is super painful. I'm currently following a lead (noticed my autokeras install line didn't have the full git URL) and if that fails my next step is going to be starting to modify tensorflow to get some debug logging in there.",also struggling seen people get work post main thing cribbing also important read think together built docker image run apt update apt install git python pip install python pip install python pip install pillow trying get working since code like python yes mess leave alone o import import join import import import random import import categorical categorical generator global generator break otherwise fit run forever break yield print beginning set generation lambda lambda classifier print beginning fit epoch still got working various version shift around never eradicate running docker container super painful currently following lead install line full git next step going starting modify get logging,issue,positive,positive,positive,positive,positive,positive
648256521,"Currently, we only support this in ConvBlock. So you may need to follow this guide to connect your own space. https://autokeras.com/tutorial/customized/",currently support may need follow guide connect space,issue,negative,neutral,neutral,neutral,neutral,neutral
648254361,"You can pass the normalization layer as a custom object while you load the model.
Would you please provide your dataset? So that we can tune our algorithm to see why it doesn't perform good. Thanks.",pas normalization layer custom object load model would please provide tune algorithm see perform good thanks,issue,positive,positive,positive,positive,positive,positive
648253275,I believe this is caused by some version inconsistency. Please tryout the latest version and use export_model to get the best model. Thanks.,believe version inconsistency please tryout latest version use get best model thanks,issue,positive,positive,positive,positive,positive,positive
648252102,"@Astlaan I think this is a great use case!
If you would like to reproduce it on colab with autokeras 1.0.3, I will try to help you solve it.

Thank you!",think great use case would like reproduce try help solve thank,issue,positive,positive,positive,positive,positive,positive
648248938,"I cannot tell which one is the actual performance. We may need to clean up the output of AutoKeras later.
I think you can pass a callback function to the fit function. In that callback, you can track these metrics.

Thanks.",tell one actual performance may need clean output later think pas function fit function track metric thanks,issue,positive,positive,positive,positive,positive,positive
648246891,We just had a new release 1.0.3. It runs fine with tf 2.2.0. You may have a try. Thanks.,new release fine may try thanks,issue,positive,positive,positive,positive,positive,positive
648244832,"This is fixed in our latest release. You can try out this example on colab, which has both the export and summary.
https://autokeras.com/tutorial/structured_data_regression/",fixed latest release try example export summary,issue,negative,positive,positive,positive,positive,positive
648170957,i have same problem while the input is ok (the tuner already make several trials for the same input data),problem input tuner already make several input data,issue,negative,neutral,neutral,neutral,neutral,neutral
647155785,"hello

I thank you very much for your quick reply.

I am in a docker.

the command you indicate doesn't work if you don't upgrade pip....

RUN python3 -m pip install --upgrade pip
RUN pip3 install --no-cache-dir tensorflow==2.1.0

Now it works!!  you can close my  demand...

Adrien








Le jeu. 18 juin 2020 à 15:36, Kevin <notifications@github.com> a écrit :

> Install tensorflow 2.1.0
>
> Like :
>
> pip install tensorflow-gpu==2.1.0
>
> I have not been active in this repository for a long time so I am not
> quite sure if this is still the case
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/keras-team/autokeras/issues/1197#issuecomment-646021724>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ACL4CXUAV5HDTUO4EXINYR3RXIJ6VANCNFSM4OBSJRHA>
> .
>


-- 
Adrien BRUNO
17 Avenue CUMERO
06130  GRASSE
tél:  0633042634
",hello thank much quick reply docker command indicate work upgrade pip run python pip install upgrade pip run pip install work close demand install like pip install active repository long time quite sure still case thread reply directly view avenue,issue,positive,positive,positive,positive,positive,positive
646021724,"Install tensorflow 2.1.0 

Like :

`pip install tensorflow-gpu==2.1.0`


I have not been active in this repository for a long time so I am not quite sure if this is still the case",install like pip install active repository long time quite sure still case,issue,positive,positive,positive,positive,positive,positive
645508111,"@utkarshgupta137

##  save and load model
```
def load_pickle_model_from_file(name_file):
    with open(name_file, 'rb') as file:
        loaded_model = pickle.load(file)
    return loaded_model

```
```
def save_pickle_model_to_file(model, name_model):
    with open(Path(str(name_model)+"".pickle""), 'wb') as file:
        pickle.dump(model, file)
    print(str(Path(str(name_model)+"".pickle""))+' - model saved!')
```

##  create:   model_name - you select own name; directory - you select place for model's data 
```
model = ak.StructuredDataRegressor(max_trials=max_trials,
                                               column_names=data_cols,
                                               column_types=data_type,
                                               project_name=model_name
                                               directory='data/models_saved_data/'
                                               )
```

## save after creating:   model_name - your selected name on previouse stage
`save_pickle_model_to_file(model, model_name)`

",save load model open file file return model open path file model file print path model saved create select name directory select place model data model save selected name stage model,issue,positive,neutral,neutral,neutral,neutral,neutral
645416482,"@alexfdo I'm facing the same issue. Could you elaborate on what you've done?
I tried to provide a directory myself, but still getting the same error.",facing issue could elaborate done tried provide directory still getting error,issue,negative,positive,positive,positive,positive,positive
645237188,I am seeing this as well with structured_data_classifier after trying the various combinations of code mentioned earlier.  I get the error a lot of the time though not always and when it fails I can verify that the checkpoint  does not exist under the trials_xx/checkpoints/epoch_yy path. The directory parameter is specified as an absolute path and grep doesn't seem to show that the file has been saved somewhere else as far as I can see.,seeing well trying various code get error lot time though always verify exist path directory parameter absolute path seem show file saved somewhere else far see,issue,negative,positive,positive,positive,positive,positive
645073467,"Facing the same issue.
Get 'INFO:tensorflow:Oracle triggered exit' just after all trials complete.
My code:
> X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=0) # 116883 rows in X, y
ak = StructuredDataRegressor(max_trials=1, seed=0)
ak.fit(X_train, y_train, epochs=100)
ak.evaluate(X_test, y_test)
ak.export_model().save('ak')
 
In addition, I get the following when trying to save the exported model:

> ak.export_model().save('ak')
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate
WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate
WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.
2020-06-16 23:58:37.896026: W tensorflow/python/util/util.cc:319] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/network.py"", line 1008, in save
    signatures, options)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/save.py"", line 115, in save_model
    signatures, options)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/saved_model/save.py"", line 78, in save
    save_lib.save(model, filepath, signatures, options)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/save.py"", line 909, in save
    meta_graph_def, saveable_view, signatures, options.namespace_whitelist)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/save.py"", line 553, in _fill_meta_graph_def
    object_map, resource_map, asset_info = saveable_view.map_resources()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/save.py"", line 251, in map_resources
    new_resource = obj._create_resource()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/lookup_ops.py"", line 1932, in _create_resource
    name=self._name)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_lookup_ops.py"", line 1113, in mutable_dense_hash_table_v2
    max_load_factor=max_load_factor, name=name)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py"", line 468, in _apply_op_helper
    preferred_dtype=default_dtype)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 1280, in convert_to_tensor
    raise RuntimeError(""Attempting to capture an EagerTensor without ""
RuntimeError: Attempting to capture an EagerTensor without building a function.

I can't view the summary of the exported model either:
> model = ak.export_model()
> model.summary()
> Model: ""model""
> _________________________________________________________________
> Layer (type)                 Output Shape              Param #   
> =================================================================
> input_1 (InputLayer)         [(None, 6)]               0         
> _________________________________________________________________
> Traceback (most recent call last):
>   File ""<stdin>"", line 1, in <module>
>   File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/network.py"", line 1310, in summary
>     print_fn=print_fn)
>   File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/utils/layer_utils.py"", line 226, in print_summary
>     print_layer_summary(layers[i])
>   File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/utils/layer_utils.py"", line 184, in print_layer_summary
>     fields = [name + ' (' + cls_name + ')', output_shape, layer.count_params()]
>   File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 1607, in count_params
>     return int(sum(np.prod(w.shape.as_list()) for w in self.weights))
>   File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 1607, in <genexpr>
>     return int(sum(np.prod(w.shape.as_list()) for w in self.weights))
> AttributeError: 'TrackableWeightHandler' object has no attribute 'shape'",facing issue get oracle triggered exit complete code ak addition get following trying save model warning unresolved object root warning unresolved object root warning unresolved object root warning unresolved object root warning unresolved object root warning used see specific use load status object silence use make check explicit see warning unresolved object root warning unresolved object root warning unresolved object root warning unresolved object root warning unresolved object root warning used see specific use load status object silence use make check explicit see currently considered may change future consider warning calling constraint removed future version pas recent call last file line module file line save file line file line save model file line save file line file line file line file line file line file line raise capture without capture without building function ca view summary model either model model model layer type output shape param none recent call last file line module file line summary file line file line name file line return sum file line return sum object attribute,issue,negative,positive,neutral,neutral,positive,positive
644152908,"> Hi everyone, I am really sorry about the bugs.
> I am busy fixing them and aiming at a new stable release soon.
> If you have to get it working now, please try our master branch with the master branch of keras-tuner and tensorflow 2.2.0 as dependency.
> 
> Thanks.
> 
> ```
> pip install git+https://github.com/keras-team/autokeras.git@master
> pip install git+https://github.com/keras-team/keras-tuner.git@master
> pip install tensorflow==2.2.0
> ```

TypeError Traceback (most recent call last)

in ()
16 #outputs=[ak.ClassificationHead()],
17 max_trials=global_max_trials,
---> 18 objective = 'val_loss',
19 #overwrite=global_overwrite,
20 #tuner='bayesian'

2 frames

/usr/local/lib/python3.6/dist-packages/autokeras/engine/tuner.py in init(self, oracle, hypermodel, preprocessors, **kwargs)
36 preprocessors=None,
37 **kwargs):
---> 38 super().init(oracle, hypermodel, **kwargs)
39 self.preprocessors = nest.flatten(preprocessors)
40 self._finished = False

TypeError: init() got an unexpected keyword argument 'name'",hi everyone really sorry busy fixing aiming new stable release soon get working please try master branch master branch dependency thanks pip install pip install pip install recent call last objective self oracle super oracle false got unexpected argument,issue,positive,negative,neutral,neutral,negative,negative
644152660,"> > Hi everyone, I am really sorry about the bugs.
> > I am busy fixing them and aiming at a new stable release soon.
> > If you have to get it working now, please try our master branch with the master branch of keras-tuner and tensorflow 2.2.0 as dependency.
> > Thanks.
> > ```
> > pip install git+https://github.com/keras-team/autokeras.git@master
> > pip install git+https://github.com/keras-team/keras-tuner.git@master
> > pip install tensorflow==2.2.0
> > ```
> 
> This works for me now!!

No, it does not work for me",hi everyone really sorry busy fixing aiming new stable release soon get working please try master branch master branch dependency thanks pip install pip install pip install work work,issue,positive,negative,neutral,neutral,negative,negative
644075595,"This is still not working can someone confirm this issue is resolved in latest updates or any workaround
",still working someone confirm issue resolved latest,issue,negative,positive,positive,positive,positive,positive
643859474,This PR is temporarily closed until we find a good use case for these layers.,temporarily closed find good use case,issue,negative,positive,positive,positive,positive,positive
643699253,"> Hi everyone, I am really sorry about the bugs.
> I am busy fixing them and aiming at a new stable release soon.
> If you have to get it working now, please try our master branch with the master branch of keras-tuner and tensorflow 2.2.0 as dependency.
> 
> Thanks.
> 
> ```
> pip install git+https://github.com/keras-team/autokeras.git@master
> pip install git+https://github.com/keras-team/keras-tuner.git@master
> pip install tensorflow==2.2.0
> ```

This works for me now!!",hi everyone really sorry busy fixing aiming new stable release soon get working please try master branch master branch dependency thanks pip install pip install pip install work,issue,positive,negative,neutral,neutral,negative,negative
643661225,"I want to offer a solution that I use myself
It is based on Pickle + using the directories in the class structure at https://autokeras.com/structured_data_regressor/

```
 Class StructuredDataRegressor
 autokeras.StructuredDataRegressor (
   ...............................
      metrics = no
      project_name = ""structd_data_regressor"",
      max_trials = 100,
      directory = no,
     **kwargs
 )
```

If you do not specify your names for directories, then the system uses the default values, each time overwriting the information in the same directory ./structd_data_regressor   
I use this variant to set my own names for directories.
```
model = ak.StructuredDataRegressor(max_trials=max_trials,
                                                ....................................................
                                               project_name=model_name,
                                               directory='data/models_saved_data/'
                                               )
```
model_name - this is the name under which the model will be saved. And this same model_name I indicate to pickle which model to load. I save the model completely, without any operation such as export_model.",want offer solution use based pickle class structure class metric directory specify system default time information directory use variant set model name model saved indicate pickle model load save model completely without operation,issue,positive,positive,neutral,neutral,positive,positive
643013720,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1190?src=pr&el=h1) Report
> Merging [#1190](https://codecov.io/gh/keras-team/autokeras/pull/1190?src=pr&el=desc) into [master](https://codecov.io/gh/keras-team/autokeras/commit/faa779db089019acb6a2c707043c2c47d4ca23c9&el=desc) will **increase** coverage by `0.04%`.
> The diff coverage is `100.00%`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1190/graphs/tree.svg?width=650&height=150&src=pr&token=yDvddb2DDZ)](https://codecov.io/gh/keras-team/autokeras/pull/1190?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master    #1190      +/-   ##
==========================================
+ Coverage   93.68%   93.72%   +0.04%     
==========================================
  Files          39       39              
  Lines        2073     2088      +15     
==========================================
+ Hits         1942     1957      +15     
  Misses        131      131              
```


| [Impacted Files](https://codecov.io/gh/keras-team/autokeras/pull/1190?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [autokeras/blocks/\_\_init\_\_.py](https://codecov.io/gh/keras-team/autokeras/pull/1190/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2Jsb2Nrcy9fX2luaXRfXy5weQ==) | `100.00% <100.00%> (ø)` | |
| [autokeras/blocks/basic.py](https://codecov.io/gh/keras-team/autokeras/pull/1190/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2Jsb2Nrcy9iYXNpYy5weQ==) | `97.66% <100.00%> (+0.16%)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1190?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1190?src=pr&el=footer). Last update [faa779d...f5753e9](https://codecov.io/gh/keras-team/autokeras/pull/1190?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",report master increase coverage coverage impacted file tree graph coverage master coverage impacted coverage continue review full report legend click learn absolute relative impact affected missing data powered last update fe read comment,issue,negative,positive,neutral,neutral,positive,positive
643011416,We will improve the text task performances with transformers instead of improving rnn block.,improve text task instead improving block,issue,negative,neutral,neutral,neutral,neutral,neutral
642882910,"This is not the final commit. Just wanted to know if the direction of implementing this is okay or not. I have to add comments and unit test case. Also, for this to work for text especially, we also need Token and Position embedding as input. Any suggestions in this regard are welcome.",final commit know direction add unit test case also work text especially also need token position input regard welcome,issue,positive,positive,positive,positive,positive,positive
642861622,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1188?src=pr&el=h1) Report
> Merging [#1188](https://codecov.io/gh/keras-team/autokeras/pull/1188?src=pr&el=desc) into [master](https://codecov.io/gh/keras-team/autokeras/commit/e70d5bd8deda8386dc5f1fb266b551767a364741&el=desc) will **decrease** coverage by `3.62%`.
> The diff coverage is `14.70%`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1188/graphs/tree.svg?width=650&height=150&src=pr&token=yDvddb2DDZ)](https://codecov.io/gh/keras-team/autokeras/pull/1188?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master    #1188      +/-   ##
==========================================
- Coverage   93.60%   89.97%   -3.63%     
==========================================
  Files          39       39              
  Lines        2017     2175     +158     
==========================================
+ Hits         1888     1957      +69     
- Misses        129      218      +89     
```


| [Impacted Files](https://codecov.io/gh/keras-team/autokeras/pull/1188?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [autokeras/blocks/basic.py](https://codecov.io/gh/keras-team/autokeras/pull/1188/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2Jsb2Nrcy9iYXNpYy5weQ==) | `69.53% <14.70%> (-28.47%)` | :arrow_down: |
| [autokeras/tuners/greedy.py](https://codecov.io/gh/keras-team/autokeras/pull/1188/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL3R1bmVycy9ncmVlZHkucHk=) | `95.87% <0.00%> (-3.10%)` | :arrow_down: |
| [autokeras/blocks/heads.py](https://codecov.io/gh/keras-team/autokeras/pull/1188/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2Jsb2Nrcy9oZWFkcy5weQ==) | `96.55% <0.00%> (-1.15%)` | :arrow_down: |
| [autokeras/auto\_model.py](https://codecov.io/gh/keras-team/autokeras/pull/1188/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2F1dG9fbW9kZWwucHk=) | `93.82% <0.00%> (-1.13%)` | :arrow_down: |
| [autokeras/tasks/text.py](https://codecov.io/gh/keras-team/autokeras/pull/1188/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL3Rhc2tzL3RleHQucHk=) | `100.00% <0.00%> (ø)` | |
| [autokeras/engine/adapter.py](https://codecov.io/gh/keras-team/autokeras/pull/1188/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2VuZ2luZS9hZGFwdGVyLnB5) | `93.54% <0.00%> (ø)` | |
| [autokeras/tuners/hyperband.py](https://codecov.io/gh/keras-team/autokeras/pull/1188/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL3R1bmVycy9oeXBlcmJhbmQucHk=) | `100.00% <0.00%> (ø)` | |
| [autokeras/adapters/input\_adapter.py](https://codecov.io/gh/keras-team/autokeras/pull/1188/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2FkYXB0ZXJzL2lucHV0X2FkYXB0ZXIucHk=) | `92.35% <0.00%> (+0.09%)` | :arrow_up: |
| [autokeras/engine/tuner.py](https://codecov.io/gh/keras-team/autokeras/pull/1188/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2VuZ2luZS90dW5lci5weQ==) | `95.34% <0.00%> (+0.16%)` | :arrow_up: |
| [autokeras/tasks/structured\_data.py](https://codecov.io/gh/keras-team/autokeras/pull/1188/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL3Rhc2tzL3N0cnVjdHVyZWRfZGF0YS5weQ==) | `94.44% <0.00%> (+0.69%)` | :arrow_up: |
| ... and [5 more](https://codecov.io/gh/keras-team/autokeras/pull/1188/diff?src=pr&el=tree-more) | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1188?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1188?src=pr&el=footer). Last update [e70d5bd...2f2960e](https://codecov.io/gh/keras-team/autokeras/pull/1188?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",report master decrease coverage coverage impacted file tree graph coverage master coverage impacted coverage continue review full report legend click learn absolute relative impact affected missing data powered last update fe read comment,issue,negative,positive,neutral,neutral,positive,positive
641734470,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1186?src=pr&el=h1) Report
> Merging [#1186](https://codecov.io/gh/keras-team/autokeras/pull/1186?src=pr&el=desc) into [master](https://codecov.io/gh/keras-team/autokeras/commit/dab94de0cfffe736b95ca07d0b80507a50ab4a0b&el=desc) will **decrease** coverage by `0.05%`.
> The diff coverage is `100.00%`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1186/graphs/tree.svg?width=650&height=150&src=pr&token=yDvddb2DDZ)](https://codecov.io/gh/keras-team/autokeras/pull/1186?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master    #1186      +/-   ##
==========================================
- Coverage   93.73%   93.68%   -0.06%     
==========================================
  Files          39       39              
  Lines        2043     2073      +30     
==========================================
+ Hits         1915     1942      +27     
- Misses        128      131       +3     
```


| [Impacted Files](https://codecov.io/gh/keras-team/autokeras/pull/1186?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [autokeras/auto\_model.py](https://codecov.io/gh/keras-team/autokeras/pull/1186/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2F1dG9fbW9kZWwucHk=) | `93.82% <ø> (-1.13%)` | :arrow_down: |
| [autokeras/tuners/greedy.py](https://codecov.io/gh/keras-team/autokeras/pull/1186/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL3R1bmVycy9ncmVlZHkucHk=) | `95.87% <ø> (-3.10%)` | :arrow_down: |
| [autokeras/engine/tuner.py](https://codecov.io/gh/keras-team/autokeras/pull/1186/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2VuZ2luZS90dW5lci5weQ==) | `95.34% <100.00%> (+0.16%)` | :arrow_up: |
| [autokeras/tasks/image.py](https://codecov.io/gh/keras-team/autokeras/pull/1186/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL3Rhc2tzL2ltYWdlLnB5) | `97.36% <100.00%> (+0.70%)` | :arrow_up: |
| [autokeras/tasks/structured\_data.py](https://codecov.io/gh/keras-team/autokeras/pull/1186/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL3Rhc2tzL3N0cnVjdHVyZWRfZGF0YS5weQ==) | `94.44% <100.00%> (+0.69%)` | :arrow_up: |
| [autokeras/tasks/text.py](https://codecov.io/gh/keras-team/autokeras/pull/1186/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL3Rhc2tzL3RleHQucHk=) | `100.00% <100.00%> (ø)` | |
| [autokeras/tasks/time\_series\_forecaster.py](https://codecov.io/gh/keras-team/autokeras/pull/1186/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL3Rhc2tzL3RpbWVfc2VyaWVzX2ZvcmVjYXN0ZXIucHk=) | `84.37% <100.00%> (+1.32%)` | :arrow_up: |
| [autokeras/tuners/hyperband.py](https://codecov.io/gh/keras-team/autokeras/pull/1186/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL3R1bmVycy9oeXBlcmJhbmQucHk=) | `100.00% <100.00%> (ø)` | |
| [autokeras/blocks/heads.py](https://codecov.io/gh/keras-team/autokeras/pull/1186/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2Jsb2Nrcy9oZWFkcy5weQ==) | `96.55% <0.00%> (-1.15%)` | :arrow_down: |
| ... and [3 more](https://codecov.io/gh/keras-team/autokeras/pull/1186/diff?src=pr&el=tree-more) | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1186?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1186?src=pr&el=footer). Last update [dab94de...b277b15](https://codecov.io/gh/keras-team/autokeras/pull/1186?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",report master decrease coverage coverage impacted file tree graph coverage master coverage impacted coverage continue review full report legend click learn absolute relative impact affected missing data powered last update read comment,issue,negative,positive,neutral,neutral,positive,positive
641698367,"I have the same question coming up.
Is thee any progress?
What is self? Model object loaded from ? 
Ex.
clf = ak.ImageClassifier
clf.fit(x_train, y_train)
model = clf.export_model()
So  passing like predict_proba(model, x_test), I am a bit confused with ""self"".
Thank you!
",question coming thee progress self model object loaded ex model passing like model bit confused self thank,issue,positive,negative,negative,negative,negative,negative
641275404,"Got the exact same issue. 

```
...
network = ak.StructuredDataClassifier(max_trials=1, num_classes=2) #1 trial to speed the process up for testing purposes
network.fit(x_train, y_train, epochs=1) #1  epoch to speed the process up for testing purposes

network.evaluate(x_test, y_test) #works fine

model = network.export_model()
model.save(""model_autokeras.h5"")

loaded_model = load_model(""./model_autokeras.h5"", custom_objects=ak.CUSTOM_OBJECTS)
loaded_model.evaluate(x_test, y_test) #UnimplementedError: Cast double to string is not supported
```",got exact issue network trial speed process testing epoch speed process testing work fine model cast double string,issue,negative,positive,positive,positive,positive,positive
640811718,"@haifeng-jin Is this feature available yet? Because I'm getting an error

`ValueError: Expect the data to ImageInput to have 3 or 4 dimensions, but got input shape (5000, 3, 360, 640, 3) with 5 dimensions
`
when I have more than 1 video frame",feature available yet getting error expect data got input shape video frame,issue,negative,positive,positive,positive,positive,positive
640677800,"Change the imports to

```
from keras.optimizers import Adam
from keras.callbacks import EarlyStopping
from keras.layers import Dense
from keras.layers import Dropout
from keras import models
```
",change import import import dense import dropout import,issue,negative,neutral,neutral,neutral,neutral,neutral
640458190,"> I mean this may still be a bug. We will test it out during we write the colab notebooks. And fix it.
> 
> I guess the bug may be related to the custom preprocessing layer we implemented for coverting the numerical features to categorical ones. That custom layer will be removed. We will use the official layers provided in tf2.2 to do the trick, which are not released yet.

This is fixed now ?",mean may still bug test write fix guess bug may related custom layer numerical categorical custom layer removed use official provided trick yet fixed,issue,negative,negative,neutral,neutral,negative,negative
640288449,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1181?src=pr&el=h1) Report
> Merging [#1181](https://codecov.io/gh/keras-team/autokeras/pull/1181?src=pr&el=desc) into [metrics](https://codecov.io/gh/keras-team/autokeras/commit/3964eb01cbf5d1da6d01d733bba58bf22dc4f13d&el=desc) will **increase** coverage by `0.06%`.
> The diff coverage is `100.00%`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1181/graphs/tree.svg?width=650&height=150&src=pr&token=yDvddb2DDZ)](https://codecov.io/gh/keras-team/autokeras/pull/1181?src=pr&el=tree)

```diff
@@             Coverage Diff             @@
##           metrics    #1181      +/-   ##
===========================================
+ Coverage    93.67%   93.73%   +0.06%     
===========================================
  Files           39       39              
  Lines         2039     2043       +4     
===========================================
+ Hits          1910     1915       +5     
+ Misses         129      128       -1     
```


| [Impacted Files](https://codecov.io/gh/keras-team/autokeras/pull/1181?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [autokeras/adapters/input\_adapter.py](https://codecov.io/gh/keras-team/autokeras/pull/1181/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2FkYXB0ZXJzL2lucHV0X2FkYXB0ZXIucHk=) | `92.35% <100.00%> (+0.09%)` | :arrow_up: |
| [autokeras/engine/adapter.py](https://codecov.io/gh/keras-team/autokeras/pull/1181/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2VuZ2luZS9hZGFwdGVyLnB5) | `93.54% <100.00%> (ø)` | |
| [autokeras/utils/data\_utils.py](https://codecov.io/gh/keras-team/autokeras/pull/1181/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL3V0aWxzL2RhdGFfdXRpbHMucHk=) | `91.30% <100.00%> (+5.59%)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1181?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1181?src=pr&el=footer). Last update [3964eb0...222092b](https://codecov.io/gh/keras-team/autokeras/pull/1181?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",report metric increase coverage coverage impacted file tree graph coverage metric coverage impacted coverage continue review full report legend click learn absolute relative impact affected missing data powered last update read comment,issue,negative,positive,neutral,neutral,positive,positive
640073145,"I was able to get around this issue by overriding RegressionHead.build, by creating a `RegressionHeadSigmoid` that inherits from it and actually passes the activation parameter to the Dense layer.

```
class RegressionHeadSigmoid(ak.RegressionHead):
    def build(self, hp, inputs=None):
        if self.output_dim and self.output_shape[-1] != self.output_dim:
            raise ValueError(
                'The data doesn\'t match the output_dim. '
                'Expecting {} but got {}'.format(self.output_dim,
                                                 self.output_shape[-1]))
        inputs = tf.nest.flatten(inputs)
        ak.utils.validate_num_inputs(inputs, 1)
        input_node = inputs[0]
        output_node = input_node

        dropout_rate = self.dropout_rate or hp.Choice('dropout_rate',
                                                      [0.0, 0.25, 0.5],
                                                      default=0)

        if dropout_rate > 0:
            output_node = layers.Dropout(dropout_rate)(output_node)
        output_node = ak.Flatten().build(hp, output_node)
        output_node = tf.keras.layers.Dense(self.output_shape[-1],
                                   name=self.name, activation='sigmoid')(output_node)
        return output_node
```

However, I think it would be nice to modify RegressionHead to allow this 'activation' parameter as part of its constructor.",able get around issue actually activation parameter dense layer class build self raise data match got return however think would nice modify allow parameter part constructor,issue,positive,positive,positive,positive,positive,positive
639536489,"Update: the issue is not that the weights cannot be loaded, but the optimizer. In fact, the problem is that you get a warning saying the optimizer could not be saved whe you try to export the model to a file.",update issue loaded fact problem get warning saying could saved try export model file,issue,negative,neutral,neutral,neutral,neutral,neutral
639408022,"> 
> 
> @cibic89 Thanks for your kindly answer. I tried without the evaluation data, I failed for some reason related to #984 .

Did you resolve thisw @lsrock1 ?",thanks kindly answer tried without evaluation data reason related resolve,issue,positive,positive,positive,positive,positive,positive
639078389,"@achaar I just consulted Keras team for how to do the attentions. It is not easy to implement. So let's just do the following.

1. Address the comments for moving the docstrings.
2. Use the hp to select between the two kinds of attention layers (Attention, AdditiveAttention).

Then this PR is good to be merged.
This Attention block will be used by users who are building their own search spaces with the blocks.

We will explore other ways to improve the performance of the text tasks.

Thanks.",team easy implement let following address moving use select two attention attention good attention block used building search explore way improve performance text thanks,issue,positive,positive,positive,positive,positive,positive
639014484,"@achaar 
I think there are two kinds of attentions.
One is Attention layer.
The other on is AdditiveAttention layer.
The latter one is more commonly used.
The original implementation in another pull request is about the latter one.

So we may discuss the two attention mechanisms and decide which one to use. Or may be we can use both.
You can find the paper links of these two in https://buomsoo-kim.github.io/attention/2020/01/01/Attention-mechanism-1.md/#:~:text=Attention%20Mechanism%20in%20Neural%20Networks%20%2D%201.&text=Attention%20is%20arguably%20one%20of,a%20large%20amount%20of%20information

Thanks.",think two one attention layer layer latter one commonly used original implementation another pull request latter one may discus two attention decide one use may use find paper link two thanks,issue,positive,positive,neutral,neutral,positive,positive
639000281,"I can present the attention block in tomorrow's meeting. But for it to work with the RNN block, the RNN block also needs to be modified. Currently, it does not return the hidden state of the RNN, which is required for the attention block. ",present attention block tomorrow meeting work block block also need currently return hidden state attention block,issue,negative,negative,neutral,neutral,negative,negative
638591907,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1168?src=pr&el=h1) Report
> Merging [#1168](https://codecov.io/gh/keras-team/autokeras/pull/1168?src=pr&el=desc) into [master](https://codecov.io/gh/keras-team/autokeras/commit/48611fa95bb7f9fd0def585534fb468eb62a422f&el=desc) will **increase** coverage by `0.09%`.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1168/graphs/tree.svg?width=650&height=150&src=pr&token=yDvddb2DDZ)](https://codecov.io/gh/keras-team/autokeras/pull/1168?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master    #1168      +/-   ##
==========================================
+ Coverage   93.59%   93.69%   +0.09%     
==========================================
  Files          39       39              
  Lines        2014     2030      +16     
==========================================
+ Hits         1885     1902      +17     
+ Misses        129      128       -1     
```


| [Impacted Files](https://codecov.io/gh/keras-team/autokeras/pull/1168?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [autokeras/adapters/output\_adapter.py](https://codecov.io/gh/keras-team/autokeras/pull/1168/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2FkYXB0ZXJzL291dHB1dF9hZGFwdGVyLnB5) | `87.12% <0.00%> (+3.59%)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1168?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1168?src=pr&el=footer). Last update [48611fa...a3e1c24](https://codecov.io/gh/keras-team/autokeras/pull/1168?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",report master increase coverage coverage impacted file tree graph coverage master coverage impacted coverage continue review full report legend click learn absolute relative impact affected missing data powered last update fa read comment,issue,negative,positive,neutral,neutral,positive,positive
637915866,"> Why one-hot as opposed to probabilities or, says, lists of integers?

Our logic is output is in the same format as the user provided targets.
The targets for multi-label classification has to be one-hot encoded for now.

In the future, we will support lists of integers as training targets.
If the user provide lists of integers as training targets, we will return lists of integers as prediction results.",opposed logic output format user provided classification future support training user provide training return prediction,issue,negative,neutral,neutral,neutral,neutral,neutral
637716586,"Okay, then we'll try to resolve this and get back as soon as possible. ",try resolve get back soon possible,issue,negative,neutral,neutral,neutral,neutral,neutral
637699704,"Ah, that makes more sense.

I have installed that version of keras-tuner, am pulling from master on autokeras, and have tf 2.2.0.  Still the same error.

I also tried keras-tuner/master as described in an e-mail from Haifeng Jin earlier today.  Same error there, too.",ah sense version master still error also tried today error,issue,negative,neutral,neutral,neutral,neutral,neutral
637674236,"Yes, you can use the specific commit for the time being. The issue will be resolved in the next release. 

I was referring to the installation procedure for AutoKeras and keras-tuner. ",yes use specific commit time issue resolved next release installation procedure,issue,positive,neutral,neutral,neutral,neutral,neutral
637671706,"I'm not sure I understand what method you're referring to.   The code you linked uses an ImageRegressor and is very focused around that concept instead of a StructuredDataRegression.

Regarding updating AutoKeras-tuner, are you referring to keras-tuner (https://github.com/keras-team/keras-tuner)?  The example pulls from a specific commit which seems very unmaintainable.",sure understand method code linked around concept instead regarding example specific commit unmaintainable,issue,positive,positive,positive,positive,positive,positive
637668980,"Hi everyone, I am really sorry about the bugs.
I am busy fixing them and aiming at a new stable release soon.
If you have to get it working now, please try our master branch with the master branch of keras-tuner and tensorflow 2.2.0 as dependency.

Thanks.
```
pip install git+https://github.com/keras-team/autokeras.git@master
pip install git+https://github.com/keras-team/keras-tuner.git@master
pip install tensorflow==2.2.0
```",hi everyone really sorry busy fixing aiming new stable release soon get working please try master branch master branch dependency thanks pip install pip install pip install,issue,positive,negative,neutral,neutral,negative,negative
637660941,"Hello @KirkDCO , Can you please try again using the method mentioned in : https://github.com/achaar/autokeras/blob/img_reg_tutorial/docs/templates/tutorial/image_regression.ipynb

Please update the AutoKeras-tuner also.

Thanks.
",hello please try method please update also thanks,issue,positive,positive,positive,positive,positive,positive
637658564,"Yes, to both.  

I pulled from the master branch yesterday (20.06.01) and tf is 2.2.0 installed by pip.

Note that I'm also seeing errors with another example - issue report here:  https://github.com/keras-team/autokeras/issues/1163

",yes master branch yesterday pip note also seeing another example issue report,issue,negative,neutral,neutral,neutral,neutral,neutral
637646288,"@KirkDCO Have you tried using the master branch?
If not, install using the AutoKeras master branch. And make sure your tensorflow version is 2.2 .

Thanks.",tried master branch install master branch make sure version thanks,issue,positive,positive,positive,positive,positive,positive
637413919,"@cibic89 Thanks for your kindly answer. I tried without the evaluation data, I failed for some reason related to #984 .",thanks kindly answer tried without evaluation data reason related,issue,positive,positive,positive,positive,positive,positive
637252847,"Hi @haruiz & @cibic89,

I downloaded a little mnist images stored in local folder to try your method, but it just showed the following message and then system hang:

`Found 9 images belonging to 3 classes`

when system hang, I could see it use a lot of CPU computing resources:

CMD                   %MEM %CPU
python3 script.py    0.7       117

Could you tell me how to deal with this situation?
I used tensorflow 2.1.0 and current version of autokeras.
Thank you!",hi little local folder try method following message system found belonging class system could see use lot mem python could tell deal situation used current version thank,issue,negative,negative,neutral,neutral,negative,negative
637244851,"I agree, if fit_generator is applied, this module will become very popular. Sparse integration would also be nice.",agree applied module become popular sparse integration would also nice,issue,positive,positive,positive,positive,positive,positive
637165230,"Same problem here using official example from https://autokeras.com/tutorial/structured_data_classification/

Environment:
MacOS
Python 3.8
autokeras 1.0.2
tensorflow 2.2.0

Code (abbreviated from example above):

import autokeras as ak
import pandas as pd

x_train = pd.read_csv('train.csv')
y_train = x_train.pop('survived')

x_test = pd.read_csv('eval.csv')
y_test = x_test.pop('survived')

clf = ak.StructuredDataClassifier(max_trials=10)
clf.fit(x_train, y_train)
predicted_y = clf.predict(x_test)
print(clf.evaluate(x_test, y_test))

-------------------------------
Epoch 1/1000
Traceback (most recent call last):
  File ""ak_tutorial.py"", line 11, in <module>
    clf.fit(x_train, y_train)
  File ""/Users/kdelisle/opt/miniconda2/envs/AutoML/lib/python3.8/site-packages/autokeras/tasks/structured_data.py"", line 246, in fit
    super().fit(x=x,
  File ""/Users/kdelisle/opt/miniconda2/envs/AutoML/lib/python3.8/site-packages/autokeras/tasks/structured_data.py"", line 89, in fit
    super().fit(x=x,
  File ""/Users/kdelisle/opt/miniconda2/envs/AutoML/lib/python3.8/site-packages/autokeras/auto_model.py"", line 253, in fit
    self.tuner.search(x=dataset,
  File ""/Users/kdelisle/opt/miniconda2/envs/AutoML/lib/python3.8/site-packages/autokeras/engine/tuner.py"", line 114, in search
    super().search(callbacks=new_callbacks, **fit_kwargs)
  File ""/Users/kdelisle/opt/miniconda2/envs/AutoML/lib/python3.8/site-packages/kerastuner/engine/base_tuner.py"", line 130, in search
    self.run_trial(trial, *fit_args, **fit_kwargs)
  File ""/Users/kdelisle/opt/miniconda2/envs/AutoML/lib/python3.8/site-packages/autokeras/engine/tuner.py"", line 71, in run_trial
    history = model.fit(x, *fit_args, **copied_fit_kwargs)
  File ""/Users/kdelisle/opt/miniconda2/envs/AutoML/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py"", line 66, in _method_wrapper
    return method(self, *args, **kwargs)
  File ""/Users/kdelisle/opt/miniconda2/envs/AutoML/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py"", line 848, in fit
    tmp_logs = train_function(iterator)
  File ""/Users/kdelisle/opt/miniconda2/envs/AutoML/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 580, in __call__
    result = self._call(*args, **kwds)
  File ""/Users/kdelisle/opt/miniconda2/envs/AutoML/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 627, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File ""/Users/kdelisle/opt/miniconda2/envs/AutoML/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 505, in _initialize
    self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
  File ""/Users/kdelisle/opt/miniconda2/envs/AutoML/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 2446, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/Users/kdelisle/opt/miniconda2/envs/AutoML/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 2777, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/Users/kdelisle/opt/miniconda2/envs/AutoML/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 2657, in _create_graph_function
    func_graph_module.func_graph_from_py_func(
  File ""/Users/kdelisle/opt/miniconda2/envs/AutoML/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py"", line 981, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/Users/kdelisle/opt/miniconda2/envs/AutoML/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 441, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/Users/kdelisle/opt/miniconda2/envs/AutoML/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py"", line 968, in wrapper
    raise e.ag_error_metadata.to_exception(e)
AttributeError: in user code:

    /Users/kdelisle/opt/miniconda2/envs/AutoML/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:571 train_function  *
        outputs = self.distribute_strategy.run(
    /Users/kdelisle/opt/miniconda2/envs/AutoML/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    /Users/kdelisle/opt/miniconda2/envs/AutoML/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    /Users/kdelisle/opt/miniconda2/envs/AutoML/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica
        return fn(*args, **kwargs)
    /Users/kdelisle/opt/miniconda2/envs/AutoML/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:543 train_step  **
        self.compiled_metrics.update_state(y, y_pred, sample_weight)
    /Users/kdelisle/opt/miniconda2/envs/AutoML/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:391 update_state
        self._build(y_pred, y_true)
    /Users/kdelisle/opt/miniconda2/envs/AutoML/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:321 _build
        self._metrics = nest.map_structure_up_to(y_pred, self._get_metric_objects,
    /Users/kdelisle/opt/miniconda2/envs/AutoML/lib/python3.8/site-packages/tensorflow/python/util/nest.py:1114 map_structure_up_to
        return map_structure_with_tuple_paths_up_to(
    /Users/kdelisle/opt/miniconda2/envs/AutoML/lib/python3.8/site-packages/tensorflow/python/util/nest.py:1213 map_structure_with_tuple_paths_up_to
        results = [func(*args, **kwargs) for args in zip(flat_path_list,
    /Users/kdelisle/opt/miniconda2/envs/AutoML/lib/python3.8/site-packages/tensorflow/python/util/nest.py:1213 <listcomp>
        results = [func(*args, **kwargs) for args in zip(flat_path_list,
    /Users/kdelisle/opt/miniconda2/envs/AutoML/lib/python3.8/site-packages/tensorflow/python/util/nest.py:1116 <lambda>
        lambda _, *values: func(*values),  # Discards the path arg.
    /Users/kdelisle/opt/miniconda2/envs/AutoML/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:421 _get_metric_objects
        return [self._get_metric_object(m, y_t, y_p) for m in metrics]
    /Users/kdelisle/opt/miniconda2/envs/AutoML/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:421 <listcomp>
        return [self._get_metric_object(m, y_t, y_p) for m in metrics]
    /Users/kdelisle/opt/miniconda2/envs/AutoML/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:442 _get_metric_object
        y_t_rank = len(y_t.shape.as_list())

    AttributeError: 'tuple' object has no attribute 'shape'",problem official example environment python code example import ak import print epoch recent call last file line module file line fit super file line fit super file line fit file line search super file line search trial file line history file line return method self file line fit file line result file line file line file line file line file line file line file line return file line wrapper raise user code run return return return return zip zip lambda lambda path return metric return metric object attribute,issue,positive,positive,positive,positive,positive,positive
636794537,"this happens to me too on Google Colab and on local machine using this Keras Tuner:
`KerasTuner: pip install git+git://github.com/keras-team/keras-tuner.git@d2d69cba21a0b482a85ce2a38893e2322e139c01 --no-dependencies`

versions:
TensorFlow: default 2.2.0rc4 on current Google colab
AutoKeras: 1.0.3 master branch",local machine tuner pip install default current master branch,issue,negative,neutral,neutral,neutral,neutral,neutral
636774091,Can you include the code for generating the train and validation sets? I suspect that you are trying to unpack data from the generator prematurely (for AutoKeras),include code generating train validation suspect trying unpack data generator prematurely,issue,negative,neutral,neutral,neutral,neutral,neutral
636586166,@achaar I tried it but result was same.. Thank you for the reply. ,tried result thank reply,issue,negative,neutral,neutral,neutral,neutral,neutral
636543611,"@deepakkumar1984 Thank you for the suggestion, even I overlooked that fix is pushed to master.

I have uninstalled AutoKeras and installed the new version 1.0.3 from git using below command.

`! pip install git+https://github.com/keras-team/autokeras`

Then I started executing my code to fit the model.

```
from tensorflow.keras.datasets import mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()
print(x_train.shape) # (60000, 28, 28)
print(y_train.shape) # (60000,)
print(y_train[:3]) # array([7, 2, 1], dtype=uint8)

import autokeras as ak

# Initialize the image classifier.
clf = ak.ImageClassifier(max_trials=2) # It tries 10 different models.

# Feed the image classifier with training data.

clf.fit(x_train, y_train,epochs=3)
```

There is no ERROR but,` clf.fit(x_train, y_train,epochs=3)` running for longer time and its more than 20mins+ and still running. Any suggestions please? I am using MNIST data.",thank suggestion even fix master uninstalled new version git command pip install code fit model import print print print array import ak initialize image classifier different feed image classifier training data error running longer time still running please data,issue,positive,positive,positive,positive,positive,positive
636537895,"Sorry should have checked the comment above that its been fixed in master branch. The current solution untill 1.0.3 is released is below:

- pip uninstall autokeras
- git clone https://github.com/keras-team/autokeras
- cd autokeras
- python setup.py install",sorry checked comment fixed master branch current solution untill pip git clone python install,issue,negative,negative,negative,negative,negative,negative
636505082,"+1

Upgraded tensorflow==2.2.0rc2 but still facing same issue. Please look into this.

```
from tensorflow.keras.datasets import mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()
print(x_train.shape) # (60000, 28, 28)
print(y_train.shape) # (60000,)
print(y_train[:3]) # array([7, 2, 1], dtype=uint8)

import autokeras as ak

# Initialize the image classifier.
clf = ak.ImageClassifier(max_trials=2) # It tries 10 different models.

# Feed the image classifier with training data.

clf.fit(x_train, y_train,epochs=3)
```

```
Epoch 1/3
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-3-48320bb5e5b1> in <module>
----> 1 clf.fit(x_train, y_train,epochs=3)

~/anaconda3/lib/python3.7/site-packages/autokeras/tasks/image.py in fit(self, x, y, epochs, callbacks, validation_split, validation_data, **kwargs)
    120                     validation_split=validation_split,
    121                     validation_data=validation_data,
--> 122                     **kwargs)
    123 
    124 

~/anaconda3/lib/python3.7/site-packages/autokeras/auto_model.py in fit(self, x, y, batch_size, epochs, callbacks, validation_split, validation_data, **kwargs)
    256                           validation_data=validation_data,
    257                           fit_on_val_data=self._split_dataset,
--> 258                           **kwargs)
    259 
    260     def _process_x(self, x, fit):

~/anaconda3/lib/python3.7/site-packages/autokeras/engine/tuner.py in search(self, callbacks, fit_on_val_data, **fit_kwargs)
    112             new_callbacks.append(tf.keras.callbacks.EarlyStopping(patience=10))
    113 
--> 114         super().search(callbacks=new_callbacks, **fit_kwargs)
    115 
    116         # Fully train the best model with original callbacks.

~/anaconda3/lib/python3.7/site-packages/kerastuner/engine/base_tuner.py in search(self, *fit_args, **fit_kwargs)
    128 
    129             self.on_trial_begin(trial)
--> 130             self.run_trial(trial, *fit_args, **fit_kwargs)
    131             self.on_trial_end(trial)
    132         self.on_search_end()

~/anaconda3/lib/python3.7/site-packages/autokeras/engine/tuner.py in run_trial(self, trial, x, *fit_args, **fit_kwargs)
     69             model = self.hypermodel.build(trial.hyperparameters)
     70             utils.adapt_model(model, x)
---> 71             history = model.fit(x, *fit_args, **copied_fit_kwargs)
     72             for metric, epoch_values in history.history.items():
     73                 if self.oracle.objective.direction == 'min':

~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)
     64   def _method_wrapper(self, *args, **kwargs):
     65     if not self._in_multi_worker_mode():  # pylint: disable=protected-access
---> 66       return method(self, *args, **kwargs)
     67 
     68     # Running inside `run_distribute_coordinator` already.

~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    783                 batch_size=batch_size):
    784               callbacks.on_train_batch_begin(step)
--> 785               tmp_logs = train_function(iterator)
    786               # Catch OutOfRangeError for Datasets of unknown size.
    787               # This blocks until the batch has finished executing.

~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)
    578         xla_context.Exit()
    579     else:
--> 580       result = self._call(*args, **kwds)
    581 
    582     if tracing_count == self._get_tracing_count():

~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)
    625       # This is the first call of __call__, so we have to initialize.
    626       initializers = []
--> 627       self._initialize(args, kwds, add_initializers_to=initializers)
    628     finally:
    629       # At this point we know that the initialization is complete (or less

~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)
    504     self._concrete_stateful_fn = (
    505         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
--> 506             *args, **kwds))
    507 
    508     def invalid_creator_scope(*unused_args, **unused_kwds):

~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)
   2444       args, kwargs = None, None
   2445     with self._lock:
-> 2446       graph_function, _, _ = self._maybe_define_function(args, kwargs)
   2447     return graph_function
   2448 

~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)
   2775 
   2776       self._function_cache.missed.add(call_context_key)
-> 2777       graph_function = self._create_graph_function(args, kwargs)
   2778       self._function_cache.primary[cache_key] = graph_function
   2779       return graph_function, args, kwargs

~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
   2665             arg_names=arg_names,
   2666             override_flat_arg_shapes=override_flat_arg_shapes,
-> 2667             capture_by_value=self._capture_by_value),
   2668         self._function_attributes,
   2669         # Tell the ConcreteFunction to clean up its graph once it goes out of

~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    979         _, original_func = tf_decorator.unwrap(python_func)
    980 
--> 981       func_outputs = python_func(*func_args, **func_kwargs)
    982 
    983       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in wrapped_fn(*args, **kwds)
    439         # __wrapped__ allows AutoGraph to swap in a converted function. We give
    440         # the function a weak reference to itself to avoid a reference cycle.
--> 441         return weak_wrapped_fn().__wrapped__(*args, **kwds)
    442     weak_wrapped_fn = weakref.ref(wrapped_fn)
    443 

~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)
    966           except Exception as e:  # pylint:disable=broad-except
    967             if hasattr(e, ""ag_error_metadata""):
--> 968               raise e.ag_error_metadata.to_exception(e)
    969             else:
    970               raise

AttributeError: in user code:

    /Users/madhubandru/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:505 train_function  *
        outputs = self.distribute_strategy.run(
    /Users/madhubandru/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    /Users/madhubandru/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    /Users/madhubandru/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica
        return fn(*args, **kwargs)
    /Users/madhubandru/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:477 train_step  **
        self.compiled_metrics.update_state(y, y_pred, sample_weight)
    /Users/madhubandru/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/compile_utils.py:386 update_state
        self._build(y_pred, y_true)
    /Users/madhubandru/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/compile_utils.py:317 _build
        self._metrics, y_true, y_pred)
    /Users/madhubandru/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/nest.py:1118 map_structure_up_to
        **kwargs)
    /Users/madhubandru/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/nest.py:1214 map_structure_with_tuple_paths_up_to
        *flat_value_lists)]
    /Users/madhubandru/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/nest.py:1213 <listcomp>
        results = [func(*args, **kwargs) for args in zip(flat_path_list,
    /Users/madhubandru/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/nest.py:1116 <lambda>
        lambda _, *values: func(*values),  # Discards the path arg.
    /Users/madhubandru/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/compile_utils.py:416 _get_metric_objects
        return [self._get_metric_object(m, y_t, y_p) for m in metrics]
    /Users/madhubandru/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/compile_utils.py:416 <listcomp>
        return [self._get_metric_object(m, y_t, y_p) for m in metrics]
    /Users/madhubandru/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/compile_utils.py:437 _get_metric_object
        y_t_rank = len(y_t.shape.as_list())

    AttributeError: 'tuple' object has no attribute 'shape'

```",still facing issue please look import print print print array import ak initialize image classifier different feed image classifier training data epoch recent call last module fit self fit self self fit search self super fully train best model original search self trial trial trial self trial model model history metric self self return method self running inside already fit self verbose shuffle step catch unknown size batch finished self else result self first call initialize finally point know complete le self self none none return self return self tell clean graph go name signature autograph invariant autograph swap converted function give function weak reference avoid reference cycle return wrapper except exception raise else raise user code run return return return zip lambda lambda path return metric return metric object attribute,issue,positive,positive,positive,positive,positive,positive
636501870,"+1

Facing same error.

IDE: Juypter notebook

```
from tensorflow.keras.datasets import mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()

import autokeras as ak

clf = ak.ImageClassifier(max_trials=10) 
clf.fit(x_train, y_train,epochs=3)
```


```
Epoch 1/3
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-23-dbbd6c2b9b86> in <module>
      5 
      6 clf = ak.ImageClassifier(max_trials=10)
----> 7 clf.fit(x_train, y_train,epochs=3)

~/anaconda3/lib/python3.7/site-packages/autokeras/tasks/image.py in fit(self, x, y, epochs, callbacks, validation_split, validation_data, **kwargs)
    120                     validation_split=validation_split,
    121                     validation_data=validation_data,
--> 122                     **kwargs)
    123 
    124 

~/anaconda3/lib/python3.7/site-packages/autokeras/auto_model.py in fit(self, x, y, batch_size, epochs, callbacks, validation_split, validation_data, **kwargs)
    256                           validation_data=validation_data,
    257                           fit_on_val_data=self._split_dataset,
--> 258                           **kwargs)
    259 
    260     def _process_x(self, x, fit):

~/anaconda3/lib/python3.7/site-packages/autokeras/engine/tuner.py in search(self, callbacks, fit_on_val_data, **fit_kwargs)
    112             new_callbacks.append(tf.keras.callbacks.EarlyStopping(patience=10))
    113 
--> 114         super().search(callbacks=new_callbacks, **fit_kwargs)
    115 
    116         # Fully train the best model with original callbacks.

~/anaconda3/lib/python3.7/site-packages/kerastuner/engine/base_tuner.py in search(self, *fit_args, **fit_kwargs)
    128 
    129             self.on_trial_begin(trial)
--> 130             self.run_trial(trial, *fit_args, **fit_kwargs)
    131             self.on_trial_end(trial)
    132         self.on_search_end()

~/anaconda3/lib/python3.7/site-packages/autokeras/engine/tuner.py in run_trial(self, trial, x, *fit_args, **fit_kwargs)
     69             model = self.hypermodel.build(trial.hyperparameters)
     70             utils.adapt_model(model, x)
---> 71             history = model.fit(x, *fit_args, **copied_fit_kwargs)
     72             for metric, epoch_values in history.history.items():
     73                 if self.oracle.objective.direction == 'min':

~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)
     64   def _method_wrapper(self, *args, **kwargs):
     65     if not self._in_multi_worker_mode():  # pylint: disable=protected-access
---> 66       return method(self, *args, **kwargs)
     67 
     68     # Running inside `run_distribute_coordinator` already.

~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)
    846                 batch_size=batch_size):
    847               callbacks.on_train_batch_begin(step)
--> 848               tmp_logs = train_function(iterator)
    849               # Catch OutOfRangeError for Datasets of unknown size.
    850               # This blocks until the batch has finished executing.

~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)
    578         xla_context.Exit()
    579     else:
--> 580       result = self._call(*args, **kwds)
    581 
    582     if tracing_count == self._get_tracing_count():

~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)
    625       # This is the first call of __call__, so we have to initialize.
    626       initializers = []
--> 627       self._initialize(args, kwds, add_initializers_to=initializers)
    628     finally:
    629       # At this point we know that the initialization is complete (or less

~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)
    504     self._concrete_stateful_fn = (
    505         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
--> 506             *args, **kwds))
    507 
    508     def invalid_creator_scope(*unused_args, **unused_kwds):

~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)
   2444       args, kwargs = None, None
   2445     with self._lock:
-> 2446       graph_function, _, _ = self._maybe_define_function(args, kwargs)
   2447     return graph_function
   2448 

~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)
   2775 
   2776       self._function_cache.missed.add(call_context_key)
-> 2777       graph_function = self._create_graph_function(args, kwargs)
   2778       self._function_cache.primary[cache_key] = graph_function
   2779       return graph_function, args, kwargs

~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
   2665             arg_names=arg_names,
   2666             override_flat_arg_shapes=override_flat_arg_shapes,
-> 2667             capture_by_value=self._capture_by_value),
   2668         self._function_attributes,
   2669         # Tell the ConcreteFunction to clean up its graph once it goes out of

~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    979         _, original_func = tf_decorator.unwrap(python_func)
    980 
--> 981       func_outputs = python_func(*func_args, **func_kwargs)
    982 
    983       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in wrapped_fn(*args, **kwds)
    439         # __wrapped__ allows AutoGraph to swap in a converted function. We give
    440         # the function a weak reference to itself to avoid a reference cycle.
--> 441         return weak_wrapped_fn().__wrapped__(*args, **kwds)
    442     weak_wrapped_fn = weakref.ref(wrapped_fn)
    443 

~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)
    966           except Exception as e:  # pylint:disable=broad-except
    967             if hasattr(e, ""ag_error_metadata""):
--> 968               raise e.ag_error_metadata.to_exception(e)
    969             else:
    970               raise

AttributeError: in user code:

    /Users/madhubandru/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:571 train_function  *
        outputs = self.distribute_strategy.run(
    /Users/madhubandru/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    /Users/madhubandru/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    /Users/madhubandru/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica
        return fn(*args, **kwargs)
    /Users/madhubandru/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:543 train_step  **
        self.compiled_metrics.update_state(y, y_pred, sample_weight)
    /Users/madhubandru/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/compile_utils.py:391 update_state
        self._build(y_pred, y_true)
    /Users/madhubandru/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/compile_utils.py:322 _build
        self._metrics, y_true, y_pred)
    /Users/madhubandru/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/nest.py:1118 map_structure_up_to
        **kwargs)
    /Users/madhubandru/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/nest.py:1214 map_structure_with_tuple_paths_up_to
        *flat_value_lists)]
    /Users/madhubandru/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/nest.py:1213 <listcomp>
        results = [func(*args, **kwargs) for args in zip(flat_path_list,
    /Users/madhubandru/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/nest.py:1116 <lambda>
        lambda _, *values: func(*values),  # Discards the path arg.
    /Users/madhubandru/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/compile_utils.py:421 _get_metric_objects
        return [self._get_metric_object(m, y_t, y_p) for m in metrics]
    /Users/madhubandru/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/compile_utils.py:421 <listcomp>
        return [self._get_metric_object(m, y_t, y_p) for m in metrics]
    /Users/madhubandru/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/compile_utils.py:442 _get_metric_object
        y_t_rank = len(y_t.shape.as_list())

    AttributeError: 'tuple' object has no attribute 'shape'
```",facing error ide notebook import import ak epoch recent call last module fit self fit self self fit search self super fully train best model original search self trial trial trial self trial model model history metric self self return method self running inside already fit self verbose shuffle step catch unknown size batch finished self else result self first call initialize finally point know complete le self self none none return self return self tell clean graph go name signature autograph invariant autograph swap converted function give function weak reference avoid reference cycle return wrapper except exception raise else raise user code run return return return zip lambda lambda path return metric return metric object attribute,issue,positive,positive,positive,positive,positive,positive
636488517,"+1

On Ubuntu 20, autokeras 1.0.2, and the official example:
```python
import autokeras as ak

# Initialize the classifier.
clf = ak.StructuredDataClassifier(max_trials=30)
# x is the path to the csv file. y is the column name of the column to predict.
clf.fit(x='/home/irek/Pobrane/train.txt', y='survived')
# Evaluate the accuracy of the found model.
print('Accuracy: {accuracy}'.format(
    accuracy=clf.evaluate(x='/home/irek/Pobrane/eval.txt', y='survived')))
```

```
2020-05-31 17:41:11.061524: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-05-31 17:41:11.082875: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2494195000 Hz
2020-05-31 17:41:11.083416: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4ec6d50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-05-31 17:41:11.083442: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Epoch 1/1000
Traceback (most recent call last):
  File ""/home/irek/workspace/.../ak.py"", line 6, in <module>
    clf.fit(x='/home/irek/Pobrane/train.txt', y='survived')
  File ""/home/irek/.venv/lib/python3.8/site-packages/autokeras/tasks/structured_data.py"", line 246, in fit
    super().fit(x=x,
  File ""/home/irek/.venv/lib/python3.8/site-packages/autokeras/tasks/structured_data.py"", line 89, in fit
    super().fit(x=x,
  File ""/home/irek/.venv/lib/python3.8/site-packages/autokeras/auto_model.py"", line 253, in fit
    self.tuner.search(x=dataset,
  File ""/home/irek/.venv/lib/python3.8/site-packages/autokeras/engine/tuner.py"", line 114, in search
    super().search(callbacks=new_callbacks, **fit_kwargs)
  File ""/home/irek/.venv/lib/python3.8/site-packages/kerastuner/engine/base_tuner.py"", line 130, in search
    self.run_trial(trial, *fit_args, **fit_kwargs)
  File ""/home/irek/.venv/lib/python3.8/site-packages/autokeras/engine/tuner.py"", line 71, in run_trial
    history = model.fit(x, *fit_args, **copied_fit_kwargs)
  File ""/home/irek/.venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py"", line 66, in _method_wrapper
    return method(self, *args, **kwargs)
  File ""/home/irek/.venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py"", line 848, in fit
    tmp_logs = train_function(iterator)
  File ""/home/irek/.venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 580, in __call__
    result = self._call(*args, **kwds)
  File ""/home/irek/.venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 627, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File ""/home/irek/.venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 505, in _initialize
    self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
  File ""/home/irek/.venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 2446, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/home/irek/.venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 2777, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/home/irek/.venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 2657, in _create_graph_function
    func_graph_module.func_graph_from_py_func(
  File ""/home/irek/.venv/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py"", line 981, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/home/irek/.venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 441, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/home/irek/.venv/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py"", line 968, in wrapper
    raise e.ag_error_metadata.to_exception(e)
AttributeError: in user code:

    /home/irek/.venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:571 train_function  *
        outputs = self.distribute_strategy.run(
    /home/irek/.venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    /home/irek/.venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    /home/irek/.venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica
        return fn(*args, **kwargs)
    /home/irek/.venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:543 train_step  **
        self.compiled_metrics.update_state(y, y_pred, sample_weight)
    /home/irek/.venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:391 update_state
        self._build(y_pred, y_true)
    /home/irek/.venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:321 _build
        self._metrics = nest.map_structure_up_to(y_pred, self._get_metric_objects,
    /home/irek/.venv/lib/python3.8/site-packages/tensorflow/python/util/nest.py:1114 map_structure_up_to
        return map_structure_with_tuple_paths_up_to(
    /home/irek/.venv/lib/python3.8/site-packages/tensorflow/python/util/nest.py:1213 map_structure_with_tuple_paths_up_to
        results = [func(*args, **kwargs) for args in zip(flat_path_list,
    /home/irek/.venv/lib/python3.8/site-packages/tensorflow/python/util/nest.py:1213 <listcomp>
        results = [func(*args, **kwargs) for args in zip(flat_path_list,
    /home/irek/.venv/lib/python3.8/site-packages/tensorflow/python/util/nest.py:1116 <lambda>
        lambda _, *values: func(*values),  # Discards the path arg.
    /home/irek/.venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:421 _get_metric_objects
        return [self._get_metric_object(m, y_t, y_p) for m in metrics]
    /home/irek/.venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:421 <listcomp>
        return [self._get_metric_object(m, y_t, y_p) for m in metrics]
    /home/irek/.venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:442 _get_metric_object
        y_t_rank = len(y_t.shape.as_list())

    AttributeError: 'tuple' object has no attribute 'shape'
```",official example python import ak initialize classifier path file column name column predict evaluate accuracy found model print accuracy binary use frequency service platform host guarantee used device host default version epoch recent call last file line module file line fit super file line fit super file line fit file line search super file line search trial file line history file line return method self file line fit file line result file line file line file line file line file line file line file line return file line wrapper raise user code run return return return return zip zip lambda lambda path return metric return metric object attribute,issue,positive,positive,positive,positive,positive,positive
636467465,"I had the same issue on Python 3.8.3 and Tensorflow 2.2.0. But it works on Python 3.7.7 and Tensorflow 2.1.1.

The issue is probably in Tensorflow 2.2.0, but Python 3.8.3 doesn't support Tensorflow 2.1. So I have to use Python 3.7 to make it work.",issue python work python issue probably python support use python make work,issue,negative,neutral,neutral,neutral,neutral,neutral
636407749,"Getting same issue with tensorflow=2.2.0

C:\Python\Python37\lib\site-packages\tensorflow\python\keras\engine\training.py:571 train_function  *
        outputs = self.distribute_strategy.run(
    C:\Python\Python37\lib\site-packages\tensorflow\python\distribute\distribute_lib.py:951 run  **
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    C:\Python\Python37\lib\site-packages\tensorflow\python\distribute\distribute_lib.py:2290 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    C:\Python\Python37\lib\site-packages\tensorflow\python\distribute\distribute_lib.py:2649 _call_for_each_replica
        return fn(*args, **kwargs)
    C:\Python\Python37\lib\site-packages\tensorflow\python\keras\engine\training.py:543 train_step  **
        self.compiled_metrics.update_state(y, y_pred, sample_weight)
    C:\Python\Python37\lib\site-packages\tensorflow\python\keras\engine\compile_utils.py:391 update_state
        self._build(y_pred, y_true)
    C:\Python\Python37\lib\site-packages\tensorflow\python\keras\engine\compile_utils.py:322 _build
        self._metrics, y_true, y_pred)
    C:\Python\Python37\lib\site-packages\tensorflow\python\util\nest.py:1118 map_structure_up_to
        **kwargs)
    C:\Python\Python37\lib\site-packages\tensorflow\python\util\nest.py:1214 map_structure_with_tuple_paths_up_to
        *flat_value_lists)]
    C:\Python\Python37\lib\site-packages\tensorflow\python\util\nest.py:1213 <listcomp>
        results = [func(*args, **kwargs) for args in zip(flat_path_list,
    C:\Python\Python37\lib\site-packages\tensorflow\python\util\nest.py:1116 <lambda>
        lambda _, *values: func(*values),  # Discards the path arg.
    C:\Python\Python37\lib\site-packages\tensorflow\python\keras\engine\compile_utils.py:421 _get_metric_objects
        return [self._get_metric_object(m, y_t, y_p) for m in metrics]
    C:\Python\Python37\lib\site-packages\tensorflow\python\keras\engine\compile_utils.py:421 <listcomp>
        return [self._get_metric_object(m, y_t, y_p) for m in metrics]
    C:\Python\Python37\lib\site-packages\tensorflow\python\keras\engine\compile_utils.py:442 _get_metric_object
        y_t_rank = len(y_t.shape.as_list())

    AttributeError: 'tuple' object has no attribute 'shape'

Any update on this issue please?",getting issue run return return return zip lambda lambda path return metric return metric object attribute update issue please,issue,negative,neutral,neutral,neutral,neutral,neutral
636232821,"> 
> 
> Have a look at the last answer in this issue: #984

Thank you!",look last answer issue thank,issue,negative,neutral,neutral,neutral,neutral,neutral
636232743,"> 
> 
> @ciberger, this code seems to work, you can give a shot:
> 
> ```python
> import tensorflow as tf
> import numpy as np
> import autokeras as ak
> from tensorflow.keras.preprocessing import image
> import pathlib
> import matplotlib.pylab as plt
> 
> BATCH_SIZE = 32
> IMG_HEIGHT = 224
> IMG_WIDTH = 224
> data_dir = tf.keras.utils.get_file(
>   'flower_photos',
>   'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',
>   untar=True)
> data_dir = pathlib.Path(data_dir)
> #image_count = len(list(data_dir.glob('*/*.jpg')))
> #STEPS_PER_EPOCH = np.ceil(image_count/BATCH_SIZE)
> 
> def preprocess(img):
>     img = image.array_to_img(img, scale=False)
>     img = img.resize((IMG_WIDTH, IMG_HEIGHT))
>     img = image.img_to_array(img)
>     return img / 255.0
> 
> image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,
>                                               horizontal_flip=True,
>                                               validation_split=0.2,
>                                               preprocessing_function=preprocess)
> 
> train_generator = image_generator.flow_from_directory(
>     directory=str(data_dir),
>      batch_size=BATCH_SIZE,
>      shuffle=True,
>      #class_mode=""categorical"",
>      target_size=(IMG_HEIGHT, IMG_WIDTH),
>     subset='training'
> )
> 
> val_generator = image_generator.flow_from_directory(
>     directory=str(data_dir),
>      batch_size=BATCH_SIZE,
>      shuffle=True,
>      #class_mode=""categorical"",
>      target_size=(IMG_HEIGHT, IMG_WIDTH),
>     subset='validation'
> )
> 
> def callable_iterator(generator):
>     for img_batch, targets_batch in generator:
>         yield img_batch, targets_batch
> 
> train_dataset = tf.data.Dataset.from_generator(lambda: callable_iterator(train_generator),output_types=(tf.float32, tf.float32))
> val_dataset = tf.data.Dataset.from_generator(lambda: callable_iterator(val_generator),output_types=(tf.float32, tf.float32))
> 
> for image, label in train_dataset.take(1):
>   print(""Image shape: "", image.numpy().shape)
>   print(""Label: "", label.numpy()[0])
>   plt.imshow(image.numpy()[0].squeeze(axis=2) * 255)
>   plt.show()
> 
> clf = ak.ImageClassifier(max_trials=10)
> #Feed the tensorflow Dataset to the classifier.
> clf.fit(train_dataset, epochs=60)
> #Evaluate the best model.
> print(clf.evaluate(val_dataset))
> ```
> 
> Then you can feed your fit function with the tf.datasets

Your example shows no output for me. I'm using google colab with GPU support and I have got it working before (albeit with bad predictive performance).

UPDATE: I know the generator works when I test it using the adapted code above
UPDATE: Tried on local machine and the same issue happens, TensorFlow 2.2.0, AutoKeras 1.0.2
UPDATE: The problem is with AutoKeras [#1075 ](https://github.com/keras-team/autokeras/issues/1075#issuecomment-636543611)",code work give shot python import import import ak import image import import list return categorical categorical generator generator yield lambda lambda image label print image shape print label feed classifier evaluate best model print feed fit function example output support got working albeit bad predictive performance update know generator work test code update tried local machine issue update problem,issue,negative,positive,positive,positive,positive,positive
636202937,Have a look at the last answer in this issue: https://github.com/keras-team/autokeras/issues/984,look last answer issue,issue,negative,neutral,neutral,neutral,neutral,neutral
635776895,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1156?src=pr&el=h1) Report
> Merging [#1156](https://codecov.io/gh/keras-team/autokeras/pull/1156?src=pr&el=desc) into [master](https://codecov.io/gh/keras-team/autokeras/commit/6d57bf01f9b4df75ef49f0e621a8723bb0f071c8&el=desc) will **increase** coverage by `0.05%`.
> The diff coverage is `95.83%`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1156/graphs/tree.svg?width=650&height=150&src=pr&token=yDvddb2DDZ)](https://codecov.io/gh/keras-team/autokeras/pull/1156?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master    #1156      +/-   ##
==========================================
+ Coverage   93.48%   93.54%   +0.05%     
==========================================
  Files          39       39              
  Lines        1965     1982      +17     
==========================================
+ Hits         1837     1854      +17     
  Misses        128      128              
```


| [Impacted Files](https://codecov.io/gh/keras-team/autokeras/pull/1156?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [autokeras/engine/head.py](https://codecov.io/gh/keras-team/autokeras/pull/1156/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2VuZ2luZS9oZWFkLnB5) | `95.45% <88.88%> (-4.55%)` | :arrow_down: |
| [autokeras/graph.py](https://codecov.io/gh/keras-team/autokeras/pull/1156/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2dyYXBoLnB5) | `95.73% <93.33%> (-0.55%)` | :arrow_down: |
| [autokeras/engine/tuner.py](https://codecov.io/gh/keras-team/autokeras/pull/1156/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2VuZ2luZS90dW5lci5weQ==) | `95.18% <100.00%> (-0.06%)` | :arrow_down: |
| [autokeras/hypermodels/\_\_init\_\_.py](https://codecov.io/gh/keras-team/autokeras/pull/1156/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2h5cGVybW9kZWxzL19faW5pdF9fLnB5) | `100.00% <100.00%> (ø)` | |
| [autokeras/hypermodels/heads.py](https://codecov.io/gh/keras-team/autokeras/pull/1156/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2h5cGVybW9kZWxzL2hlYWRzLnB5) | `95.55% <100.00%> (-1.15%)` | :arrow_down: |
| [autokeras/nodes.py](https://codecov.io/gh/keras-team/autokeras/pull/1156/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL25vZGVzLnB5) | `100.00% <100.00%> (ø)` | |
| [autokeras/utils/utils.py](https://codecov.io/gh/keras-team/autokeras/pull/1156/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL3V0aWxzL3V0aWxzLnB5) | `79.41% <0.00%> (+8.82%)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1156?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1156?src=pr&el=footer). Last update [6d57bf0...4c776a2](https://codecov.io/gh/keras-team/autokeras/pull/1156?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",report master increase coverage coverage impacted file tree graph coverage master coverage impacted coverage continue review full report legend click learn absolute relative impact affected missing data powered last update ca read comment,issue,negative,positive,neutral,neutral,positive,positive
635545659,"Memory leak can be reproduced using titanic example from documentation:

```python
import autokeras as ak

# Initialize the structured data classifier.
clf = ak.StructuredDataClassifier(max_trials=1000)
# Feed the structured data classifier with training data.
clf.fit(
    # The path to the train.csv file.
    'titanic-train.csv',
    # The name of the label column.
    'survived',
    verbose=False)
# Predict with the best model.
# predicted_y = clf.predict('titanic-eval.csv')
# Evaluate the best model with testing data.
print('\n\n\n')
print(clf.evaluate('titanic-eval.csv', 'survived'))
print('\n\n\n')
```


It doesn't happen if I used keras-tuner on its own.",memory leak titanic example documentation python import ak initialize structured data classifier feed structured data classifier training data path file name label column predict best model evaluate best model testing data print print print happen used,issue,positive,positive,positive,positive,positive,positive
635478049,"Having the same problem with TF2.2.0, trying to save a model having TextVectorization as first layer.
`NotImplementedError: Save or restore weights that is not an instance of `tf.Variable` is not supported in h5, use `save_format='tf'` instead. Got a model or layer TextVectorization with weights [<tensorflow.python.keras.engine.base_layer_utils.TrackableWeightHandler object at 0x7fbcd91b2bb0>]`",problem trying save model first layer save restore instance use instead got model layer object,issue,positive,positive,positive,positive,positive,positive
635054856,"Hi, please check Customized Space Search in https://autokeras.com/tutorial/image_classification/ to see if you are defining the model correctly. 
Thanks.",hi please check space search see model correctly thanks,issue,positive,positive,positive,positive,positive,positive
635004758,"The RNN attention block has been added. The required unit test is also added. Although, I am not sure how we can prevent it from being used in Bidirectional RNNs. ",attention block added unit test also added although sure prevent used bidirectional,issue,negative,positive,positive,positive,positive,positive
635001092,AutoKeras is not usable without fit_generator I feel. It is limited to toy problems!,usable without feel limited toy,issue,negative,negative,neutral,neutral,negative,negative
634791155,"Same problem here.. what's causing the issue? I would prefer to know it rather than just copy & paste @Jim-EDU 's instructions. I am going to do my bachelor thesis using autokeras, so I need a good understanding. ",problem causing issue would prefer know rather copy paste going bachelor thesis need good understanding,issue,negative,positive,positive,positive,positive,positive
634682804,"Hey guys,

I have found an docker image - pytorch/pytorch:1.4-cuda10.1-cudnn7-devel, that can solve the above problem!
Run it and execute following command, and then you could play with the autokeras.

apt-get update
apt-get upgrade
apt-get install python3-pip
apt-get install wget
apt-get install vim
apt-get install tmux
wget https://repo.anaconda.com/archive/Anaconda3-2020.02-Linux-x86_64.sh
bash Anaconda3-2020.02-Linux-x86_64.sh
pip install --upgrade pip
pip install tensorflow==2.1.0
pip install autokeras

enjoy it!",hey found docker image solve problem run execute following command could play update upgrade install install install vim install bash pip install upgrade pip pip install pip install enjoy,issue,positive,positive,positive,positive,positive,positive
634427200,This bug is fixed in the master branch.,bug fixed master branch,issue,negative,positive,neutral,neutral,positive,positive
633820093,The same question when I run the example of MNIST..python3.7 tensorflow2.1,question run example python,issue,negative,neutral,neutral,neutral,neutral,neutral
633818639,I get the same question when I run the example of MNIST!,get question run example,issue,negative,neutral,neutral,neutral,neutral,neutral
633470206,"Same issue here. Google Colab. Tried with `%tensorflow_version 2.x` and `pip install tensorflow==2.2.0rc2`.

EDIT: `!pip install tensorflow==2.1.0`fixed it for me.",issue tried pip install edit pip install fixed,issue,negative,positive,neutral,neutral,positive,positive
632318305,"Looks okay locally. The Data Format cell has a bug which is not resolved. The Customized Search Space also had a bug, which is resolved now. ",locally data format cell bug resolved search space also bug resolved,issue,negative,neutral,neutral,neutral,neutral,neutral
631595635,"Try specifying a shallow folder for the directory, e.g.
`regressor = ak.StructuredDataRegressor(max_trials=2, column_names=column_names, column_types=data_type, directory=r'C:\hello')`

I experienced a similar issue for StructuredDataClassifier. I think this error is happening because of a Windows limitation on maximum path length. Solved it by changing the directory to a very shallow folder as suggested here: https://github.com/una-dinosauria/human-motion-prediction/issues/10#issuecomment-320480162",try shallow folder directory regressor experienced similar issue think error happening limitation maximum path length directory shallow folder,issue,negative,positive,neutral,neutral,positive,positive
629828148,"@ciberger, this code seems to work, you can give a shot:

```python
import tensorflow as tf
import numpy as np
import autokeras as ak
from tensorflow.keras.preprocessing import image
import pathlib
import matplotlib.pylab as plt

BATCH_SIZE = 32
IMG_HEIGHT = 224
IMG_WIDTH = 224
data_dir = ""dataset/train""
data_dir = pathlib.Path(data_dir)
#image_count = len(list(data_dir.glob('*/*.jpg')))
#STEPS_PER_EPOCH = np.ceil(image_count/BATCH_SIZE)

def preprocess(img):
    img = image.array_to_img(img, scale=False)
    img = img.resize((IMG_WIDTH, IMG_HEIGHT))
    img = image.img_to_array(img)
    return img / 255.0

image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,
                                              horizontal_flip=True,
                                              validation_split=0.2,
                                              preprocessing_function=preprocess)

train_generator = image_generator.flow_from_directory(
    directory=str(data_dir),
     batch_size=BATCH_SIZE,
     shuffle=True,
     #class_mode=""categorical"",
     target_size=(IMG_HEIGHT, IMG_WIDTH),
    subset='training'
)

val_generator = image_generator.flow_from_directory(
    directory=str(data_dir),
     batch_size=BATCH_SIZE,
     shuffle=True,
     #class_mode=""categorical"",
     target_size=(IMG_HEIGHT, IMG_WIDTH),
    subset='validation'
)

def callable_iterator(generator):
    for img_batch, targets_batch in generator:
        yield img_batch, targets_batch

train_dataset = tf.data.Dataset.from_generator(lambda: callable_iterator(train_generator),output_types=(tf.float32, tf.float32))
val_dataset = tf.data.Dataset.from_generator(lambda: callable_iterator(val_generator),output_types=(tf.float32, tf.float32))

# for image, label in train_dataset.take(1):
#   print(""Image shape: "", image.numpy().shape)
#   print(""Label: "", label.numpy())
#   plt.imshow(image.numpy()[0] * 255)
#   plt.show()


clf = ak.ImageClassifier(max_trials=10)
#Feed the tensorflow Dataset to the classifier.
clf.fit(train_dataset, epochs=60)
#Evaluate the best model.
print(clf.evaluate(val_dataset))
```
Then you can feed your fit function with the tf.datasets",code work give shot python import import import ak import image import import list return categorical categorical generator generator yield lambda lambda image label print image shape print label feed classifier evaluate best model print feed fit function,issue,positive,positive,positive,positive,positive,positive
629821484,"Hi @haifeng-jin. Thanks for your reply. 

are you aware if it's possible to convert `tf.data.Dataset.from_generator` to a `ndarray` to be used as a training set?

Thanks ",hi thanks reply aware possible convert used training set thanks,issue,positive,positive,positive,positive,positive,positive
629693540,"Current we don't support generators. It seems not the main stream way to do the job in the future of tf keras. We will try to support tf records, which we haven't really tested yet.",current support main stream way job future try support really tested yet,issue,positive,positive,neutral,neutral,positive,positive
629693362,You need to use AutoModel.tuner to get the tuner. Then use Keras Tuner's methods to get the models. Please refer to https://keras-team.github.io/keras-tuner/documentation/tuners/#get_best_models-method,need use get tuner use tuner get please refer,issue,negative,neutral,neutral,neutral,neutral,neutral
629693063,The Time Series Forecasting is actually in the master branch. We won't release it until we have fully tested its performance.,time series forecasting actually master branch wo release fully tested performance,issue,negative,neutral,neutral,neutral,neutral,neutral
628935102,I can save but loading gives me `ValueError: Unknown layer: CategoricalEncoding`,save loading unknown layer,issue,negative,negative,neutral,neutral,negative,negative
628658010,"You can bump it should be backward compatible. Give me a few minutes and I'll make a pull request using the latest features added, it should make the doc much prettier :)",bump backward compatible give make pull request latest added make doc much,issue,negative,positive,positive,positive,positive,positive
627734835,"I am having the same problem. I downgraded my AutoKeras from 1.0.2 to 1.0.1, set my **max_trials=10**, epochs=1 (for testing purposes) and I was still getting the Oracle error. **BUT** if I set the **max_trials=12** and I set metrics=['accuracy'] then it would complete all 12 trials without any issues. This also works without metrics=['accuracy'], but it seems to error out at iteration 20 instead of 10. **This was also with kernel restarts in-between each max_trial test**. I am unsure what this means, but hopefully, it helps in the debugging process. 

Unfortunately, there is a bug in 1.0.1 that makes it difficult to get the best model. clf.get_best_model does not choose the best one. To obtain all models found by AutoKeras one needs to do the following:

`max_trials=12

clf=ak.ImageClassifier(max_trials=max_trials, metrics=['accuracy'])

clf.fit(X_train, y_train, epochs=1, verbose=0)

found_models = clf.tuner.get_best_models(max_trials)

for model in found_models:
    print(model.evaluate(X_test, y_test))`",problem set testing still getting oracle error set set would complete without also work without error iteration instead also kernel test unsure hopefully process unfortunately bug difficult get best model choose best one obtain found one need following model print,issue,negative,positive,positive,positive,positive,positive
626342072,"Using the latest version of KerasTuner fixed the problem, thanks!",latest version fixed problem thanks,issue,negative,positive,positive,positive,positive,positive
626227543,"Thank you QQ for the tip. For now I will stick to TF 2.1.0 and AK 1.0.2, as is working so far.

I wanted to reported anyway so you guys are aware of the issue.",thank tip stick ak working far anyway aware issue,issue,negative,positive,positive,positive,positive,positive
626007850,"> When using a prior version of both tensorflow (2.1.0) an autokeras (1.0.2) this error doesn't happen

It might because of the modification of kerastuner. Please try to install a fairly latest version of kerastuner (note: the `` __version__`` attribute of this version may not be correct):
  
KerasTuner: pip install git+git://github.com/keras-team/keras-tuner.git@d2d69cba21a0b482a85ce2a38893e2322e139c01

TensorFlow: 2.2.0 (or the default 2.2.0rc4 on current Google colab)
AutoKeras: 1.0.3 master branch

Thanks.
",prior version error happen might modification please try install fairly latest version note attribute version may correct pip install default current master branch thanks,issue,negative,positive,positive,positive,positive,positive
625214999,When using a prior version of both tensorflow (2.1.0) an autokeras (1.0.2) this error doesn't happen,prior version error happen,issue,negative,neutral,neutral,neutral,neutral,neutral
624543684,"you might use

```python
CLASS_NAMES = ['roses', 'sunflowers', 'daisy', 'dandelion', 'tulips']
predict = [CLASS_NAMES[i] for i in ohe_predict.argmax(1)]
```",might use python predict,issue,negative,neutral,neutral,neutral,neutral,neutral
624028162,"## Description
Hi! I'm dealing with the same situation where I want to use a generator to read from a massive training set. If generators are not tested, can you recommend an alternative approach?

Thanks in advance! 🙌

## Expected Behavior
Expected to train the model using as a training set a _tensorflow.Dataset.generator_ object.

Alternatively, convert _tensorflow.Dataset.generator_ object to train/test set input for Autokeras.

## Reproducible code
```python
import autokeras as ak
import tensorflow as tf
import pathlib

# Define general parameters
BATCH_SIZE = 32
IMG_HEIGHT = 150
IMG_WIDTH = 150

data_dir = tf.keras.utils.get_file(
    'flower_photos',
    'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',
    untar=True)

data_dir = pathlib.Path(data_dir)

CLASS_NAMES = np.array([item.name for item in data_dir.glob('*') if item.name != ""LICENSE.txt""])
# array(['roses', 'sunflowers', 'daisy', 'dandelion', 'tulips'], dtype='<U10')


# ImageDataGenerator using Keras
train_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)

# Define the parameters
train_data_gen = train_gen.flow_from_directory(
    batch_size=BATCH_SIZE,
    directory=data_dir,
    shuffle=True,
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    class_mode='categorical'
)

# Wrapping Keras generator
train_ds = tf.data.Dataset.from_generator(
    lambda: train_data_gen,
    output_types=(tf.float32, tf.float32),
    output_shapes = ([BATCH_SIZE,IMG_HEIGHT,IMG_WIDTH,3],
                     [BATCH_SIZE,len(CLASS_NAMES)]))
# Found 3670 images belonging to 5 classes.

images, labels = next(train_data_gen)
print(images.dtype, images.shape)
print(labels.dtype, labels.shape)
# float32(32, 150, 150, 3)
# float32(32, 5)

# Initialize the image classifier.
clf = ak.ImageClassifier(max_trials=2)
# Feed the image classifier with training data.
clf.fit(train_ds, epochs=2)
```

## Error message
<details><summary>See console output (Click to expand)</summary>

```python
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
 in 
      2 clf = ak.ImageClassifier(max_trials=2)
      3 # Feed the image classifier with training data.
----> 4 clf.fit(train_ds, epochs=2)

~/.pyenv/versions/python-3.7.4/lib/python3.7/site-packages/autokeras/tasks/image.py in fit(self, x, y, epochs, callbacks, validation_split, validation_data, **kwargs)
    120                     validation_split=validation_split,
    121                     validation_data=validation_data,
--> 122                     **kwargs)
    123 
    124 

~/.pyenv/versions/python-3.7.4/lib/python3.7/site-packages/autokeras/auto_model.py in fit(self, x, y, batch_size, epochs, callbacks, validation_split, validation_data, **kwargs)
    237             y=y,
    238             validation_data=validation_data,
--> 239             validation_split=validation_split)
    240 
    241         # Process the args.

~/.pyenv/versions/python-3.7.4/lib/python3.7/site-packages/autokeras/auto_model.py in _prepare_data(self, x, y, validation_data, validation_split)
    319         if validation_data is None and validation_split:
    320             self._split_dataset = True
--> 321             dataset, validation_data = utils.split_dataset(dataset, validation_split)
    322         return dataset, validation_data
    323 

~/.pyenv/versions/python-3.7.4/lib/python3.7/site-packages/autokeras/utils.py in split_dataset(dataset, validation_split)
     79         A tuple of two tf.data.Dataset. The training set and the validation set.
     80     """"""
---> 81     num_instances = dataset.reduce(np.int64(0), lambda x, _: x + 1).numpy()
     82     if num_instances < 2:
     83         raise ValueError('The dataset should at least contain 2 '

~/.pyenv/versions/python-3.7.4/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py in reduce(self, initial_state, reduce_func)
   1932             f=reduce_func,
   1933             output_shapes=structure.get_flat_tensor_shapes(state_structure),
-> 1934             output_types=structure.get_flat_tensor_types(state_structure)))
   1935 
   1936   def unbatch(self):

~/.pyenv/versions/python-3.7.4/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_dataset_ops.py in reduce_dataset(input_dataset, initial_state, other_arguments, f, output_types, output_shapes, use_inter_op_parallelism, name)
   4659         pass  # Add nodes to the TensorFlow graph.
   4660     except _core._NotOkStatusException as e:
-> 4661       _ops.raise_from_not_ok_status(e, name)
   4662   # Add nodes to the TensorFlow graph.
   4663   if not isinstance(output_types, (list, tuple)):

~/.pyenv/versions/python-3.7.4/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py in raise_from_not_ok_status(e, name)
   6604   message = e.message + ("" name: "" + name if name is not None else """")
   6605   # pylint: disable=protected-access
-> 6606   six.raise_from(core._status_to_exception(e.code, message), None)
   6607   # pylint: enable=protected-access
   6608 

~/.pyenv/versions/python-3.7.4/lib/python3.7/site-packages/six.py in raise_from(value, from_value)

InvalidArgumentError: ValueError: `generator` yielded an element of shape (22, 150, 150, 3) where an element of shape (32, 150, 150, 3) was expected.
Traceback (most recent call last):

  File ""/Users/cristobalberger/.pyenv/versions/python-3.7.4/lib/python3.7/site-packages/tensorflow_core/python/ops/script_ops.py"", line 236, in __call__
    ret = func(*args)

  File ""/Users/cristobalberger/.pyenv/versions/python-3.7.4/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 825, in generator_py_func
    ""of shape %s was expected."" % (ret_array.shape, expected_shape))

ValueError: `generator` yielded an element of shape (22, 150, 150, 3) where an element of shape (32, 150, 150, 3) was expected.


	 [[{{node PyFunc}}]] [Op:ReduceDataset]
```
</details>

## Setup Details

- OS type and version: macOS Catalina (10.15)
- Python: 3.7.4
- autokeras: 1.0.2
- keras-tuner: 1.0.1
- scikit-learn: 0.22.2.post1
- numpy: 1.18.3
- pandas: 1.0.3
- tensorflow: 2.1.0
",description hi dealing situation want use generator read massive training set tested recommend alternative approach thanks advance behavior train model training set object alternatively convert object set input reproducible code python import ak import import define general item array define wrapping generator lambda found belonging class next print print float float initialize image classifier feed image classifier training data error message summary see console output click expand python recent call last feed image classifier training data fit self fit self process self none true return two training set validation lambda raise least contain reduce self self name pas add graph except name add graph list name message name name name none else message none value generator element shape element shape recent call last file line ret file line shape generator element shape element shape node setup o type version catalina python post,issue,positive,positive,neutral,neutral,positive,positive
622652022,"According to AutoKeras's official website, the function of Time Series Forecasting is coming soon.",according official function time series forecasting coming soon,issue,negative,neutral,neutral,neutral,neutral,neutral
622422723,I doubt it would be worth the effort. TF 1.5 was over 2 years ago and much has changed in TensorFlow since then. You may be able to get it working with TF 1.15 though.,doubt would worth effort ago much since may able get working though,issue,negative,positive,positive,positive,positive,positive
621330979,"I made another attempt. On this case using mnist [example]( https://autokeras.com/tutorial/customized/) but cutting some steps to make it simple


```
(x_train, y_train), (x_test, y_test) = mnist.load_data()

input_node = ak.ImageInput()
    #output_node = ak.Normalization()(input_node)
    #output_node = ak.ImageAugmentation()(output_node)
output_node = ak.ConvBlock()(input_node)
    #output_node2 = ak.ResNetBlock(version='v2')(output_node)
    #output_node = ak.Merge()([output_node1, output_node2])
output_node = ak.ClassificationHead()(output_node)

auto_model = ak.AutoModel(inputs=input_node, outputs=output_node, max_trials=1)
auto_model.fit(x_train, y_train,epochs=1 )

model = auto_model.export_model()
```

Still get the error `Shapes (32,) and (64,) are incompatible` at `export_model` :(

```
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-12-edf9daa2eec5> in <module>
----> 1 model = auto_model.export_model()
      2 #print(model.summary())

~\Anaconda3\envs\myenv\lib\site-packages\autokeras\auto_model.py in export_model(self)
    381             with trained weights.
    382         """"""
--> 383         return self.tuner.get_best_model()

~\Anaconda3\envs\myenv\lib\site-packages\autokeras\engine\tuner.py in get_best_model(self)
     40 
     41     def get_best_model(self):
---> 42         model = super().get_best_models()[0]
     43         model.load_weights(self.best_model_path)
     44         return model

~\Anaconda3\envs\myenv\lib\site-packages\kerastuner\engine\tuner.py in get_best_models(self, num_models)
    229         """"""
    230         # Method only exists in this class for the docstring override.
--> 231         return super(Tuner, self).get_best_models(num_models)
    232 
    233     def _deepcopy_callbacks(self, callbacks):

~\Anaconda3\envs\myenv\lib\site-packages\kerastuner\engine\base_tuner.py in get_best_models(self, num_models)
    236         """"""
    237         best_trials = self.oracle.get_best_trials(num_models)
--> 238         models = [self.load_model(trial) for trial in best_trials]
    239         return models
    240 

~\Anaconda3\envs\myenv\lib\site-packages\kerastuner\engine\base_tuner.py in <listcomp>(.0)
    236         """"""
    237         best_trials = self.oracle.get_best_trials(num_models)
--> 238         models = [self.load_model(trial) for trial in best_trials]
    239         return models
    240 

~\Anaconda3\envs\myenv\lib\site-packages\kerastuner\engine\tuner.py in load_model(self, trial)
    155         with hm_module.maybe_distribute(self.distribution_strategy):
    156             model.load_weights(self._get_checkpoint_fname(
--> 157                 trial.trial_id, best_epoch))
    158         return model
    159 

~\Anaconda3\envs\myenv\lib\site-packages\tensorflow_core\python\keras\engine\training.py in load_weights(self, filepath, by_name, skip_mismatch)
    232         raise ValueError('Load weights is not yet supported with TPUStrategy '
    233                          'with steps_per_run greater than 1.')
--> 234     return super(Model, self).load_weights(filepath, by_name, skip_mismatch)
    235 
    236   @trackable.no_automatic_dependency_tracking

~\Anaconda3\envs\myenv\lib\site-packages\tensorflow_core\python\keras\engine\network.py in load_weights(self, filepath, by_name, skip_mismatch)
   1191         save_format = 'h5'
   1192     if save_format == 'tf':
-> 1193       status = self._trackable_saver.restore(filepath)
   1194       if by_name:
   1195         raise NotImplementedError(

~\Anaconda3\envs\myenv\lib\site-packages\tensorflow_core\python\training\tracking\util.py in restore(self, save_path)
   1281         graph_view=self._graph_view)
   1282     base.CheckpointPosition(
-> 1283         checkpoint=checkpoint, proto_id=0).restore(self._graph_view.root)
   1284     load_status = CheckpointLoadStatus(
   1285         checkpoint,

~\Anaconda3\envs\myenv\lib\site-packages\tensorflow_core\python\training\tracking\base.py in restore(self, trackable)
    207         # This object's correspondence with a checkpointed object is new, so
    208         # process deferred restorations for it and its dependencies.
--> 209         restore_ops = trackable._restore_from_checkpoint_position(self)  # pylint: disable=protected-access
    210         if restore_ops:
    211           self._checkpoint.new_restore_ops(restore_ops)

~\Anaconda3\envs\myenv\lib\site-packages\tensorflow_core\python\training\tracking\base.py in _restore_from_checkpoint_position(self, checkpoint_position)
    906     restore_ops.extend(
    907         current_position.checkpoint.restore_saveables(
--> 908             tensor_saveables, python_saveables))
    909     return restore_ops
    910 

~\Anaconda3\envs\myenv\lib\site-packages\tensorflow_core\python\training\tracking\util.py in restore_saveables(self, tensor_saveables, python_saveables)
    287              ""expecting %s"") % (tensor_saveables.keys(), validated_names))
    288       new_restore_ops = functional_saver.MultiDeviceSaver(
--> 289           validated_saveables).restore(self.save_path_tensor)
    290       if not context.executing_eagerly():
    291         for name, restore_op in sorted(new_restore_ops.items()):

~\Anaconda3\envs\myenv\lib\site-packages\tensorflow_core\python\training\saving\functional_saver.py in restore(self, file_prefix)
    253     for device, saver in sorted(self._single_device_savers.items()):
    254       with ops.device(device):
--> 255         restore_ops.update(saver.restore(file_prefix))
    256     return restore_ops

~\Anaconda3\envs\myenv\lib\site-packages\tensorflow_core\python\training\saving\functional_saver.py in restore(self, file_prefix)
    100                                           structured_restored_tensors):
    101       restore_ops[saveable.name] = saveable.restore(
--> 102           restored_tensors, restored_shapes=None)
    103     return restore_ops
    104 

~\Anaconda3\envs\myenv\lib\site-packages\tensorflow_core\python\training\saving\saveable_object_util.py in restore(self, restored_tensors, restored_shapes)
    114       restored_tensor = array_ops.identity(restored_tensor)
    115       return resource_variable_ops.shape_safe_assign_variable_handle(
--> 116           self.handle_op, self._var_shape, restored_tensor)
    117 
    118 

~\Anaconda3\envs\myenv\lib\site-packages\tensorflow_core\python\ops\resource_variable_ops.py in shape_safe_assign_variable_handle(handle, shape, value, name)
    295   with _handle_graph(handle):
    296     value_tensor = ops.convert_to_tensor(value)
--> 297   shape.assert_is_compatible_with(value_tensor.shape)
    298   return gen_resource_variable_ops.assign_variable_op(handle,
    299                                                       value_tensor,

~\Anaconda3\envs\myenv\lib\site-packages\tensorflow_core\python\framework\tensor_shape.py in assert_is_compatible_with(self, other)
   1108     """"""
   1109     if not self.is_compatible_with(other):
-> 1110       raise ValueError(""Shapes %s and %s are incompatible"" % (self, other))
   1111 
   1112   def most_specific_compatible_shape(self, other):

ValueError: Shapes (32,) and (64,) are incompatible


```",made another attempt case example cutting make simple model still get error incompatible recent call last module model print self trained return self self model super return model self method class override return super tuner self self self trial trial return trial trial return self trial return model self raise yet greater return super model self self status raise restore self restore self trackable object correspondence object new process deferred self self return self name sorted restore self device saver sorted device return restore self return restore self return handle shape value name handle value return handle self raise incompatible self self incompatible,issue,positive,positive,positive,positive,positive,positive
621305142,"Same issue in here. On this case I made a ""hello world"" with Cifar 10 and export doesn't work :(

```
from tensorflow.keras.datasets import mnist, cifar10
import autokeras as ak

(x_train, y_train), (x_test, y_test) = cifar10.load_data()

input_node = ak.ImageInput()
output_node = ak.Normalization()(input_node)
output_node = ak.ImageAugmentation()(output_node)
output_node1 = ak.ConvBlock()(output_node)
output_node2 = ak.ResNetBlock(version='v2')(output_node)
output_node = ak.Merge()([output_node1, output_node2])
output_node = ak.ClassificationHead()(output_node)

auto_model = ak.AutoModel(inputs=input_node, outputs=output_node, max_trials=1)
auto_model.fit(x_train, y_train,epochs=1 )

model = auto_model.export_model()
print(model.summary())
```

Return error:
ValueError                                Traceback (most recent call last)
<ipython-input-5-6d0d37edc8f9> in <module>
----> 1 model = auto_model.export_model()
      2 print(model.summary())

~\Anaconda3\envs\myenv\lib\site-packages\autokeras\auto_model.py in export_model(self)
    381             with trained weights.
    382         """"""
--> 383         return self.tuner.get_best_model()

~\Anaconda3\envs\myenv\lib\site-packages\autokeras\engine\tuner.py in get_best_model(self)
     40 
     41     def get_best_model(self):
---> 42         model = super().get_best_models()[0]
     43         model.load_weights(self.best_model_path)
     44         return model

~\Anaconda3\envs\myenv\lib\site-packages\kerastuner\engine\tuner.py in get_best_models(self, num_models)
    229         """"""
    230         # Method only exists in this class for the docstring override.
--> 231         return super(Tuner, self).get_best_models(num_models)
    232 
    233     def _deepcopy_callbacks(self, callbacks):

~\Anaconda3\envs\myenv\lib\site-packages\kerastuner\engine\base_tuner.py in get_best_models(self, num_models)
    236         """"""
    237         best_trials = self.oracle.get_best_trials(num_models)
--> 238         models = [self.load_model(trial) for trial in best_trials]
    239         return models
    240 

~\Anaconda3\envs\myenv\lib\site-packages\kerastuner\engine\base_tuner.py in <listcomp>(.0)
    236         """"""
    237         best_trials = self.oracle.get_best_trials(num_models)
--> 238         models = [self.load_model(trial) for trial in best_trials]
    239         return models
    240 

~\Anaconda3\envs\myenv\lib\site-packages\kerastuner\engine\tuner.py in load_model(self, trial)
    155         with hm_module.maybe_distribute(self.distribution_strategy):
    156             model.load_weights(self._get_checkpoint_fname(
--> 157                 trial.trial_id, best_epoch))
    158         return model
    159 

~\Anaconda3\envs\myenv\lib\site-packages\tensorflow_core\python\keras\engine\training.py in load_weights(self, filepath, by_name, skip_mismatch)
    232         raise ValueError('Load weights is not yet supported with TPUStrategy '
    233                          'with steps_per_run greater than 1.')
--> 234     return super(Model, self).load_weights(filepath, by_name, skip_mismatch)
    235 
    236   @trackable.no_automatic_dependency_tracking

~\Anaconda3\envs\myenv\lib\site-packages\tensorflow_core\python\keras\engine\network.py in load_weights(self, filepath, by_name, skip_mismatch)
   1191         save_format = 'h5'
   1192     if save_format == 'tf':
-> 1193       status = self._trackable_saver.restore(filepath)
   1194       if by_name:
   1195         raise NotImplementedError(

~\Anaconda3\envs\myenv\lib\site-packages\tensorflow_core\python\training\tracking\util.py in restore(self, save_path)
   1281         graph_view=self._graph_view)
   1282     base.CheckpointPosition(
-> 1283         checkpoint=checkpoint, proto_id=0).restore(self._graph_view.root)
   1284     load_status = CheckpointLoadStatus(
   1285         checkpoint,

~\Anaconda3\envs\myenv\lib\site-packages\tensorflow_core\python\training\tracking\base.py in restore(self, trackable)
    207         # This object's correspondence with a checkpointed object is new, so
    208         # process deferred restorations for it and its dependencies.
--> 209         restore_ops = trackable._restore_from_checkpoint_position(self)  # pylint: disable=protected-access
    210         if restore_ops:
    211           self._checkpoint.new_restore_ops(restore_ops)

~\Anaconda3\envs\myenv\lib\site-packages\tensorflow_core\python\training\tracking\base.py in _restore_from_checkpoint_position(self, checkpoint_position)
    906     restore_ops.extend(
    907         current_position.checkpoint.restore_saveables(
--> 908             tensor_saveables, python_saveables))
    909     return restore_ops
    910 

~\Anaconda3\envs\myenv\lib\site-packages\tensorflow_core\python\training\tracking\util.py in restore_saveables(self, tensor_saveables, python_saveables)
    287              ""expecting %s"") % (tensor_saveables.keys(), validated_names))
    288       new_restore_ops = functional_saver.MultiDeviceSaver(
--> 289           validated_saveables).restore(self.save_path_tensor)
    290       if not context.executing_eagerly():
    291         for name, restore_op in sorted(new_restore_ops.items()):

~\Anaconda3\envs\myenv\lib\site-packages\tensorflow_core\python\training\saving\functional_saver.py in restore(self, file_prefix)
    253     for device, saver in sorted(self._single_device_savers.items()):
    254       with ops.device(device):
--> 255         restore_ops.update(saver.restore(file_prefix))
    256     return restore_ops

~\Anaconda3\envs\myenv\lib\site-packages\tensorflow_core\python\training\saving\functional_saver.py in restore(self, file_prefix)
    100                                           structured_restored_tensors):
    101       restore_ops[saveable.name] = saveable.restore(
--> 102           restored_tensors, restored_shapes=None)
    103     return restore_ops
    104 

~\Anaconda3\envs\myenv\lib\site-packages\tensorflow_core\python\training\saving\saveable_object_util.py in restore(self, restored_tensors, restored_shapes)
    114       restored_tensor = array_ops.identity(restored_tensor)
    115       return resource_variable_ops.shape_safe_assign_variable_handle(
--> 116           self.handle_op, self._var_shape, restored_tensor)
    117 
    118 

~\Anaconda3\envs\myenv\lib\site-packages\tensorflow_core\python\ops\resource_variable_ops.py in shape_safe_assign_variable_handle(handle, shape, value, name)
    295   with _handle_graph(handle):
    296     value_tensor = ops.convert_to_tensor(value)
--> 297   shape.assert_is_compatible_with(value_tensor.shape)
    298   return gen_resource_variable_ops.assign_variable_op(handle,
    299                                                       value_tensor,

~\Anaconda3\envs\myenv\lib\site-packages\tensorflow_core\python\framework\tensor_shape.py in assert_is_compatible_with(self, other)
   1108     """"""
   1109     if not self.is_compatible_with(other):
-> 1110       raise ValueError(""Shapes %s and %s are incompatible"" % (self, other))
   1111 
   1112   def most_specific_compatible_shape(self, other):

ValueError: Shapes (3,) and (1,) are incompatible

",issue case made hello world export work import import ak model print return error recent call last module model print self trained return self self model super return model self method class override return super tuner self self self trial trial return trial trial return self trial return model self raise yet greater return super model self self status raise restore self restore self trackable object correspondence object new process deferred self self return self name sorted restore self device saver sorted device return restore self return restore self return handle shape value name handle value return handle self raise incompatible self self incompatible,issue,positive,positive,positive,positive,positive,positive
621111482,"Same problem here, when I try to save the exported model from the StructuredDataClassifier example, I get the following error:

RuntimeError: Attempting to capture an EagerTensor without building a function.

Thank you.",problem try save model example get following error capture without building function thank,issue,negative,neutral,neutral,neutral,neutral,neutral
621066067,"@dadebulba I also met this problem，and I fixed this by adding 

> 'Normalization': tensorflow.keras.layers.experimental.preprocessing.Normalization

to CUSTOM_OBJECTS.This bug has fixed in master branch（not release now,with tf 2.2.0rc3）.",also met fixed bug fixed master release,issue,negative,positive,neutral,neutral,positive,positive
621036257,"Thanks, it looks like you only tune to Normalize or to Augment, as booleans. Not what transform to apply.",thanks like tune normalize augment transform apply,issue,positive,positive,positive,positive,positive,positive
620920428,"@haifeng-jin Thank you for your reply again.
The master branch of AutoKeras incorporating this argument for max_model_size uses tensorflow 2.2? I have been receiving errors relating to methods apparently only exists in tensorflow 2.2 nightly.
I will test this out when tensorflow 2.2 stable is released. ",thank reply master branch argument apparently nightly test stable,issue,negative,positive,neutral,neutral,positive,positive
620913128,That is as expected. AutoKeras would try to explore different models for the first several trials. The first trial is a small model. The second one is much larger.,would try explore different first several first trial small model second one much,issue,negative,positive,neutral,neutral,positive,positive
620912832,"https://github.com/keras-team/autokeras/blob/master/autokeras/tuners/greedy.py
@cbsudux The tuning algorithm is here. The search space is just defined in the build function in those blocks.",tuning algorithm search space defined build function,issue,negative,neutral,neutral,neutral,neutral,neutral
620912482,"@Pythonatheart I really don't know the answer. You may submit an issue to Keras Tuner to ask. 
Actually, I have never exceeded the memory limit with our search space.
I have around 11GB of GPU memory.
Thanks.",really know answer may submit issue tuner ask actually never memory limit search space around memory thanks,issue,negative,positive,positive,positive,positive,positive
620911712,Thank you for the report. It has been fixed in the master branch,thank report fixed master branch,issue,negative,positive,neutral,neutral,positive,positive
620218149,"I am also facing the same issue on the titanic survival problem I got from the following link. https://autokeras.com/examples/titanic/

I have also done some tweaking. 

import autokeras as ak

# Initialize the classifier.
clf = ak.StructuredDataClassifier(max_trials=30)
# x is the path to the csv file. y is the column name of the column to predict.
# clf.fit(x=train, y='survived') # @ instead of using name of the column, I have used the its original values
clf.fit(x=train, y=train[['survived']])
# Evaluate the accuracy of the found model.
print('Accuracy: {accuracy}'.format(accuracy=clf.evaluate(x=eval, y=eval[['survived']])))
",also facing issue titanic survival problem got following link also done import ak initialize classifier path file column name column predict instead name column used original evaluate accuracy found model print accuracy,issue,negative,positive,positive,positive,positive,positive
619508756,"Thank you for your help, but this didn't solve my problem. I tested it on another computer without the GPU and I got the same error.",thank help solve problem tested another computer without got error,issue,positive,neutral,neutral,neutral,neutral,neutral
619230807,"I actually can't reproduce the exact error, but a `ValueError` is raised using your dataset:

```
>>> X_train, X_test, y_train, y_test = train_test_split(corpus[text_name].values,
...                                                     labels,
...                                                     test_size=test_size,
...                                                     stratify=corpus[class_name],
...                                                     shuffle=True)
ValueError: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.
```

Looks like there are classes in the dataset with only one instance:

```
>>> counts = corpus.loc[:, ""speaker""].value_counts()
>>> counts[counts < 2]
Brigitte Sauzay         1
Roman Herzog            1
Béla Anda               1
Matthias Platzeck       1
Joachim Gauck           1
Ursula von der Leyen    1
Brigitte Zypries        1
Aydan Özoğuz            1
Peter Struck            1
Sigmar Gabriel          1
Michael Glos            1
Wolfgang Schäuble       1
Friedrich Merz          1
Ronald Pofalla          1
Herta Däubler-Gmelin    1
Waldemar Ritter         1
Hans Bernhard Beus      1
Ilse Aigner             1
Renate Schmidt          1
Werner Müller           1
Name: speaker, dtype: int64
```

After filtering those I am able to both predict and evaluate with the trained model (reaching 0.8794 accuracy).

I am on `autokeras` 1.0.2 and `tensorflow` 2.1.0. By the way, since `keras` as a standalone package is no longer under active development, I generally recommend using the `tensorflow.keras` API.",actually ca reproduce exact error raised corpus least class member minimum number class le like class one instance speaker anda peter struck name speaker filtering able predict evaluate trained model reaching accuracy way since package longer active development generally recommend,issue,positive,positive,neutral,neutral,positive,positive
617283000,"I tried to use 
import tensorflow as tf
tf.enable_eager_execution()

But autokeras is running of TF 2.0 that doesn't work that way, I think.
@jayavanth Can you please let me know how you did it?  

> @Kraks Try this and see if it works. It works for me and I can save it but I can't load it back.
> 
> https://stackoverflow.com/questions/52357542/attributeerror-tensor-object-has-no-attribute-numpy

",tried use import running work way think please let know try see work work save ca load back,issue,positive,neutral,neutral,neutral,neutral,neutral
617280836,"Hello,
I'm having the same issue :(
Does anyone was able to export a model create with StructuredDataClassifier api?? 


model3.save(""modelo3"", save_format='tf')

Traceback (most recent call last)
<ipython-input-9-e875c179c094> in <module>
      1 print(""tipo do modelo gravado"", type(model3))
      2 #tf.keras.models.save_model(model1, ""modelo1"") ##
----> 3 model3.save(""modelo3"", save_format='tf')

~\AppData\Local\conda\conda\envs\Env2\lib\site-packages\tensorflow_core\python\keras\engine\network.py in save(self, filepath, overwrite, include_optimizer, save_format, signatures, options)
   1006     """"""
   1007     save.save_model(self, filepath, overwrite, include_optimizer, save_format,
-> 1008                     signatures, options)
   1009 
   1010   def save_weights(self, filepath, overwrite=True, save_format=None):

~\AppData\Local\conda\conda\envs\Env2\lib\site-packages\tensorflow_core\python\keras\saving\save.py in save_model(model, filepath, overwrite, include_optimizer, save_format, signatures, options)
    113   else:
    114     saved_model_save.save(model, filepath, overwrite, include_optimizer,
--> 115                           signatures, options)
    116 
    117 

~\AppData\Local\conda\conda\envs\Env2\lib\site-packages\tensorflow_core\python\keras\saving\saved_model\save.py in save(model, filepath, overwrite, include_optimizer, signatures, options)
     76     # we use the default replica context here.
     77     with distribution_strategy_context._get_default_replica_context():  # pylint: disable=protected-access
---> 78       save_lib.save(model, filepath, signatures, options)
     79 
     80   if not include_optimizer:

~\AppData\Local\conda\conda\envs\Env2\lib\site-packages\tensorflow_core\python\saved_model\save.py in save(obj, export_dir, signatures, options)
    907   object_saver = util.TrackableSaver(checkpoint_graph_view)
    908   asset_info, exported_graph = _fill_meta_graph_def(
--> 909       meta_graph_def, saveable_view, signatures, options.namespace_whitelist)
    910   saved_model.saved_model_schema_version = (
    911       constants.SAVED_MODEL_SCHEMA_VERSION)

~\AppData\Local\conda\conda\envs\Env2\lib\site-packages\tensorflow_core\python\saved_model\save.py in _fill_meta_graph_def(meta_graph_def, saveable_view, signature_functions, namespace_whitelist)
    551   resource_initializer_ops = []
    552   with exported_graph.as_default():
--> 553     object_map, resource_map, asset_info = saveable_view.map_resources()
    554     for resource_initializer_function in resource_initializer_functions:
    555       asset_dependencies = []

~\AppData\Local\conda\conda\envs\Env2\lib\site-packages\tensorflow_core\python\saved_model\save.py in map_resources(self)
    249         # pylint: disable=protected-access
    250         with ops.device(obj._resource_device):
--> 251           new_resource = obj._create_resource()
    252         # pylint: enable=protected-access
    253         resource_map[obj.resource_handle] = new_resource

~\AppData\Local\conda\conda\envs\Env2\lib\site-packages\tensorflow_core\python\ops\lookup_ops.py in _create_resource(self)
   1930         value_shape=self._value_shape,
   1931         initial_num_buckets=self._initial_num_buckets,
-> 1932         name=self._name)
   1933     if context.executing_eagerly():
   1934       self._table_name = None

~\AppData\Local\conda\conda\envs\Env2\lib\site-packages\tensorflow_core\python\ops\gen_lookup_ops.py in mutable_dense_hash_table_v2(empty_key, deleted_key, value_dtype, container, shared_name, use_node_name_sharing, value_shape, initial_num_buckets, max_load_factor, name)
   1111                                    value_shape=value_shape,
   1112                                    initial_num_buckets=initial_num_buckets,
-> 1113                                    max_load_factor=max_load_factor, name=name)
   1114   _result = _outputs[:]
   1115   if _execute.must_record_gradient():

~\AppData\Local\conda\conda\envs\Env2\lib\site-packages\tensorflow_core\python\framework\op_def_library.py in _apply_op_helper(op_type_name, name, **keywords)
    466               dtype=dtype,
    467               as_ref=input_arg.is_ref,
--> 468               preferred_dtype=default_dtype)
    469         except TypeError as err:
    470           if dtype is None:

~\AppData\Local\conda\conda\envs\Env2\lib\site-packages\tensorflow_core\python\framework\ops.py in convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)
   1278       graph = get_default_graph()
   1279       if not graph.building_function:
-> 1280         raise RuntimeError(""Attempting to capture an EagerTensor without ""
   1281                            ""building a function."")
   1282       return graph.capture(value, name=name)

RuntimeError: Attempting to capture an EagerTensor without building a function.
",hello issue anyone able export model create recent call last module print type model model save self overwrite self overwrite self model overwrite else model overwrite save model overwrite use default replica context model save self self none container name name except err none value name graph raise capture without building function return value capture without building function,issue,positive,positive,positive,positive,positive,positive
616228807,"```
INFO:tensorflow:Oracle triggered exit
C:\ProgramData\Anaconda3\lib\site-packages\numpy\core\_methods.py:151: RuntimeWarning: invalid value encountered in reduce
  ret = umr_sum(arr, axis, dtype, out, keepdims)
C:\ProgramData\Anaconda3\lib\site-packages\numpy\core\_methods.py:183: RuntimeWarning: invalid value encountered in reduce
  arrmean = umr_sum(arr, axis, dtype, keepdims=True)

```

don't know whether I am facing the same issue",oracle triggered exit invalid value reduce ret axis invalid value reduce axis know whether facing issue,issue,positive,neutral,neutral,neutral,neutral,neutral
616187655,"Hello,

Is there any update regarding this topic?

I find myself in the same situation...

Thanks!

(tf 2.1)",hello update regarding topic find situation thanks,issue,negative,positive,positive,positive,positive,positive
615656798,"@Kraks Try this and see if it works. It works for me and I can save it but I can't load it back.

https://stackoverflow.com/questions/52357542/attributeerror-tensor-object-has-no-attribute-numpy",try see work work save ca load back,issue,negative,neutral,neutral,neutral,neutral,neutral
615497934,"I play with the regression example from the autokeras website and have the same issue when saving to `tf` format, but a different one to `h5` format:

```
Traceback (most recent call last):
  File ""auto_ex.py"", line 47, in <module>
    model.save(""m.h5"")
  File ""/home/kraks/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py"", line 1008, in save
    signatures, options)
  File ""/home/kraks/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py"", line 112, in save_model
    model, filepath, overwrite, include_optimizer)
  File ""/home/kraks/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py"", line 109, in save_model_to_hdf5
    save_weights_to_hdf5_group(model_weights_group, model_layers)
  File ""/home/kraks/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py"", line 627, in save_weights_to_hdf5_group
    weight_values = K.batch_get_value(weights)
  File ""/home/kraks/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py"", line 3270, in batch_get_value
    return [x.numpy() for x in tensors]
  File ""/home/kraks/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py"", line 3270, in <listcomp>
    return [x.numpy() for x in tensors]
AttributeError: 'TrackableWeightHandler' object has no attribute 'numpy'
```

Versions:
OS: Linux Mint 19.3 kernel 5.0.0-32-generic
Python 3.6.9
tensorflow: 2.1.0
pandas: 1.0.3
autokeras: 1.0.2
scikit-learn: 0.22.2.post1
bumpy: 1.18.2",play regression example issue saving format different one format recent call last file line module file line save file line model overwrite file line file line file line return file line return object attribute o mint kernel generic python post bumpy,issue,positive,neutral,neutral,neutral,neutral,neutral
615310503,"Add:
I did not wait for the second trial to finish before the test, so I came to a conclusion.
But now I have tested many times, no matter how much I set **max_trials**
No matter how much **epoch** is set, `ak` will only run **4** trials, and in the **third** trial
Will print this sentence ```INFO: tensorflow: Oracle triggered exit```
Only the **second** of these four trials is slow, and the other three are fast. What is the principle?
Is the second slowness a bug? Under what circumstances will the phrase ""Oracle triggered exit"" be triggered, leading to the end of the entire training early",add wait second trial finish test came conclusion tested many time matter much set matter much epoch set ak run third trial print sentence oracle triggered exit second four slow three fast principle second bug phrase oracle triggered exit triggered leading end entire training early,issue,negative,positive,neutral,neutral,positive,positive
614458186,"Did you figure this out? I have the same issue. I let it run overnight and the results are useless, though it worked the first time. Lost a lot of time",figure issue let run overnight useless though worked first time lost lot time,issue,negative,negative,negative,negative,negative,negative
614441041,"@haifeng-jin , Can you post a link to the script that does it? The repo is pretty big and it's hard to find out where the tuning happens.",post link script pretty big hard find tuning,issue,negative,negative,neutral,neutral,negative,negative
614431196,"@haifeng-jin  Thank you for your reply. 
It is hard to determine the total parameters for max_model_size.
If using AlexNet as an example, total params is ~62M, and GPU memory consumed is ~1.0 GB.
So for 24GB GPU memory, does that mean max_model_size = 62M x 24 = 1.5Billion?
Probably not, and I don't know whether GPU mem is freed up after each trial (i.e. clear session?). 
So, it's at best a trial and error approach until I get some idea of max_model_size? 
It is really deep...深不可测。LOL
What are your thoughts? Any good pointers? What would you set as a max_model_size for a RTX Titan? 
Thank you once again. I appreciate your time and thoughts on this. 
",thank reply hard determine total example total memory memory mean probably know whether mem freed trial clear session best trial error approach get idea really deep good would set thank appreciate time,issue,positive,positive,positive,positive,positive,positive
614411385,"@Pythonatheart I am not sure either.
This is the code I found how KT is using this max_model_size.
https://github.com/keras-team/keras-tuner/blob/d2d69cba21a0b482a85ce2a38893e2322e139c01/kerastuner/engine/hypermodel.py#L155

It seems like it is the number of values in the params.",sure either code found like number,issue,positive,positive,positive,positive,positive,positive
614410280,"In the master branch now, you can see the tuning of these two.",master branch see tuning two,issue,negative,neutral,neutral,neutral,neutral,neutral
614220496,"I'm also having this issue and seems a duplicate of #1095.

It works with tensorflow 2.1.0 but I need to use a newer version to be able to export the model.",also issue duplicate work need use version able export model,issue,negative,positive,positive,positive,positive,positive
614100440,"I have a problem with the use, the object should be **np array** object instead of **list**, which will cause the dimension error, closed!",problem use object array object instead list cause dimension error closed,issue,negative,negative,neutral,neutral,negative,negative
612564572,"@haifeng-jin  Thank you for the response. However, can you provide an example of how to specify this in AutoKeras? The documentation for keras-tuner is not very useful:

max_model_size: Int. Maximum size of weights (in floating point coefficients) for a valid models. Models larger than this are rejected.

For example, how can I limit model size to fit my GPU, in this case a RTX Titan (24 GB memory)? What would be the ""floating point coefficients"" integer value as per documentation above? An example pseudocode will be helpful e.g. model.fit(x, y, max_model_size=value) or it is model = ImageRegressor(max_model_size=value)?

Thank you once again for your time and help.  ",thank response however provide example specify documentation useful maximum size floating point valid example limit model size fit case memory would floating point integer value per documentation example helpful model thank time help,issue,positive,positive,positive,positive,positive,positive
612356054,"@Pythonatheart After #1093 is merged, you should be able to use it in the master branch. You can pass the `max_model_size` to any AutoKeras model you use.
You can find the description of `max_model_size` here:
https://keras-team.github.io/keras-tuner/documentation/tuners/#tuner-class",able use master branch pas model use find description,issue,negative,positive,positive,positive,positive,positive
612355078,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1094?src=pr&el=h1) Report
> Merging [#1094](https://codecov.io/gh/keras-team/autokeras/pull/1094?src=pr&el=desc) into [master](https://codecov.io/gh/keras-team/autokeras/commit/3d520e2eb5d0fa5c6fcec94d48f768bacf833f04&el=desc) will **increase** coverage by `0.00%`.
> The diff coverage is `94.11%`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1094/graphs/tree.svg?width=650&height=150&src=pr&token=yDvddb2DDZ)](https://codecov.io/gh/keras-team/autokeras/pull/1094?src=pr&el=tree)

```diff
@@           Coverage Diff           @@
##           master    #1094   +/-   ##
=======================================
  Coverage   92.65%   92.66%           
=======================================
  Files          38       39    +1     
  Lines        1907     1921   +14     
=======================================
+ Hits         1767     1780   +13     
- Misses        140      141    +1     
```


| [Impacted Files](https://codecov.io/gh/keras-team/autokeras/pull/1094?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [autokeras/auto\_model.py](https://codecov.io/gh/keras-team/autokeras/pull/1094/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2F1dG9fbW9kZWwucHk=) | `91.24% <75.00%> (-0.56%)` | :arrow_down: |
| [autokeras/engine/preprocessor.py](https://codecov.io/gh/keras-team/autokeras/pull/1094/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2VuZ2luZS9wcmVwcm9jZXNzb3IucHk=) | `100.00% <100.00%> (ø)` | |
| [autokeras/engine/tuner.py](https://codecov.io/gh/keras-team/autokeras/pull/1094/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2VuZ2luZS90dW5lci5weQ==) | `96.15% <100.00%> (+0.37%)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1094?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1094?src=pr&el=footer). Last update [3d520e2...f942265](https://codecov.io/gh/keras-team/autokeras/pull/1094?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",report master increase coverage coverage impacted file tree graph coverage master coverage impacted coverage continue review full report legend click learn absolute relative impact affected missing data powered last update de read comment,issue,negative,positive,neutral,neutral,positive,positive
612157729,It might be releated to tensorflow version. Would you try tf 2.1? Thanks,might version would try thanks,issue,negative,positive,positive,positive,positive,positive
611904900,"> > https://github.com/keras-team/autokeras/pull/1090/files#diff-b2a4808b666256ed34518e4234d24721R37
> 
> Have you tested this in tf-nightly? I remembered this being an issue but resolved lately. If not, please file a issue!

Here is the issue I filed.
https://github.com/tensorflow/tensorflow/issues/38419",tested issue resolved lately please file issue issue,issue,negative,negative,negative,negative,negative,negative
611863119,"> https://github.com/keras-team/autokeras/pull/1090/files#diff-b2a4808b666256ed34518e4234d24721R37

Have you tested this in tf-nightly? I remembered this being an issue but resolved lately. If not, please file a issue!",tested issue resolved lately please file issue,issue,negative,negative,negative,negative,negative,negative
611669103,"@tanzhenyu
I have implemented a layer encapsulating multiple `IndexLookup` layers inside.
https://github.com/keras-team/autokeras/pull/1090/files#diff-b2a4808b666256ed34518e4234d24721R37

I notice the `IndexLookup` layer does not support saving for now.

Would you please let me know what is the general way of implementing a saving mechanism for a preprocessing layer?
We want to implement a temporary walk around for the `IndexLookup` layer for saving it.
Currently, I tried to put `IndexLookup.get_vocabulary()` in the `get_config()` function, but it raises an error.

Thank you.",layer multiple inside notice layer support saving would please let know general way saving mechanism layer want implement temporary walk around layer saving currently tried put function error thank,issue,positive,positive,neutral,neutral,positive,positive
611473658,"Hi, is there an example how to feed TFRecord files to autokeras i tried this:

# read TFRecord file
feature_description = {
    'data_x': tf.io.FixedLenFeature([500,], tf.float32),
    'data_y': tf.io.FixedLenFeature([1], tf.float32)
    }

def _parse_function(example_proto):
    return tf.io.parse_single_example(example_proto, feature_description)

def sample(iterator):
    return next(iterator)

dataset = tf.data.TFRecordDataset(filenames=[filename])
dataset = dataset.map(_parse_function)#, num_parallel_calls=8)
dataset = dataset.repeat().shuffle(buffer_size=50).batch(2)

#feed to Structured Data Regressor
model = ak.StructuredDataRegressor(max_trials=2)
model.fit(dataset)

but that gives me an error:

File ""[...]autokeras\auto_model.py"", line 297, in _process_xy
  x = dataset.map(lambda a, b: a)

  TypeError: <lambda>() missing 1 required positional argument: 'b'",hi example feed tried read file return sample return next feed structured data regressor model error file line lambda lambda missing positional argument,issue,negative,negative,neutral,neutral,negative,negative
610886524,"Hi, is there a similar solution for the StructuredDataRegressor? I have large numerical, structured data and the StructuredDataRegressor does not seem to support tf.data.Dataset with numerical data yet.",hi similar solution large numerical structured data seem support numerical data yet,issue,positive,positive,positive,positive,positive,positive
610875265,"
# for autokeras 1.0:

## save the model
model.save('my_model') 

## load the model
import tensorflow as tf
new_model = tf.keras.models.load_model('my_model')",save model load model import,issue,negative,neutral,neutral,neutral,neutral,neutral
610763175,"> @flozi00 Thank you for the request! We are interested in pairing with third-party Softwares to provide more features to the users. Are you from the Ludwig team?
> 
> We may consider doing this after the next stable release of AutoKeras on TF 2.2.
> 
> Thanks.

I am not from Ludwig team.
Actually Ludwig is running on tf 1, but they are working on tf 2 version",thank request interested provide team may consider next stable release thanks team actually running working version,issue,positive,positive,positive,positive,positive,positive
610748008,"Thank you for your detail description.
I tested and I would like to share.
So basically you can save and load model by 
from tensorflow.keras.models import load_model, save_model

You can save tf format and load tf format (h5 format does not work for me)

```
# Export as a Keras Model.
model = clf.export_model()

print(type(model))  # <class 'tensorflow.python.keras.engine.training.Model'>
model.summary()

# https://www.tensorflow.org/api_docs/python/tf/keras/models/save_model
save_model(model, 'mymodel_tf.tf', save_format='tf')
load_tf_model = load_model('mymodel_tf.tf', custom_objects=ak.CUSTOM_OBJECTS)
load_tf_model.summary()

#save_model(model, 'mymodel_h5.h5', save_format='h5')　#Does not work
#load_h5_model = load_model('mymodel_h5.h5', custom_objects=ak.CUSTOM_OBJECTS) #Does not work

---
import autokeras as ak
from tensorflow.keras.models import load_model
load_tf_model = load_model('mymodel_tf.tf', custom_objects=ak.CUSTOM_OBJECTS)
load_tf_model.summary()
```",thank detail description tested would like share basically save load model import save format load format format work export model model print type model class model model work work import ak import,issue,positive,neutral,neutral,neutral,neutral,neutral
610717989,"haifeng-jin, any time frame this will be implemented? I really like AK and want to use it in some of my papers. Thanks. ",time frame really like ak want use thanks,issue,positive,positive,positive,positive,positive,positive
610716867,"Took me sometime to figure things out too, given the sparse documentation. But here's my take on your questions:

1. The number of models tested is determined by max_trials. In this tutorial example, max_trials = 10, meaning 10 models were tested.
2. For each model, the number of training rounds (epochs) are determined by epochs. In the tutorial, epochs=3, meaning only 3 rounds of training is attempted for the model. Normally, the more epochs, the higher chance that your model is better trained (depending on your dataset). Typically, it is normal to set epochs=200. The model will however stop training if no improvement in val_loss (lower score) is observed after 10 epochs, meaning it may stop training after 50 epochs even if epochs=200.
3. After max_trials is reached (in this tutorial, 10 trials/models), AutoKeras will pick the best model and attempt one final training using all your training data. This is the tricky bit. When you specify clf.fit(x_train, y_train, epochs=3), not all x_train are used for training because AutoKeras does a 80:20 train-validation split on your x_train data. For example, if number of x_train data/sample is 10 images, the split will results in 8 images for training, 2 images for validation. For the final training of best model, AK will use all the training data (10 images as per previous example ).
4. Is it possible to save other models? Probably, the AK team will need to provide a bit more description (which takes a long time) on the nature of the saved trials within the automodel folder. All your weights and trial details are actually stored in those folder. Just need to convert them into Keras model - which again we wait for instructions from AK team?

Hope this helps.  



",took sometime figure given sparse documentation take number tested determined tutorial example meaning tested model number training determined tutorial meaning training model normally higher chance model better trained depending typically normal set model however stop training improvement lower score meaning may stop training even tutorial pick best model attempt one final training training data tricky bit specify used training split data example number split training validation final training best model ak use training data per previous example possible save probably ak team need provide bit description long time nature saved within folder trial actually folder need convert model wait ak team hope,issue,positive,positive,positive,positive,positive,positive
610701142,"@flozi00 Thank you for the request! We are interested in pairing with third-party Softwares to provide more features to the users. Are you from the Ludwig team?

We may consider doing this after the next stable release of AutoKeras on TF 2.2.

Thanks.",thank request interested provide team may consider next stable release thanks,issue,positive,positive,positive,positive,positive,positive
610699082,"@abgese I have merged the PR. I just found that there are still 2 minor changes we need to make.

1. We should change the default value of `predict_until`. Since we can know how long the user want to predict based on how long is the training and testing `x`. We just predict until the end of the `x`.

2. I am a little bit confused about why we don't need `y` in the `predict` function. I think the previous `y`s are also part of the input to predict the next step.

Thanks.",found still minor need make change default value since know long user want predict based long training testing predict end little bit confused need predict function think previous also part input predict next step thanks,issue,positive,negative,neutral,neutral,negative,negative
609539924,I am also having this issue. Is there an alternative way to view and save the best model?,also issue alternative way view save best model,issue,positive,positive,positive,positive,positive,positive
609513838,"Good afternoon, all! I appear to be experiencing the same ""Oracle, expected: ['val_f1']"" error @alexcombessie detailed earlier, using release 1.0.2, so the problem doesn't appear to be fixed yet.
EDIT: In my case, this is for the ""StructuredDataClassifier""",good afternoon appear oracle error detailed release problem appear fixed yet edit case,issue,negative,positive,positive,positive,positive,positive
607606922,This is a known issue. We have fixed it in the master branch. You may try it with tensorflow==2.2.0rc2. Thanks,known issue fixed master branch may try thanks,issue,negative,positive,positive,positive,positive,positive
606982583,"Thank you for your reply. There is no mistake in your understanding. It would be better if you could have a convenient interface

1. The current problem is that the model export in *. H5 format of keras failed. I see in the issues that you are solving

2. Another problem is that some layers in autokeras are customized by you. They do not exist in the built-in layer of tensorflow, so they cannot be saved as *. Pb. I want to know what kind of data I should consult to solve this knowledge",thank reply mistake understanding would better could convenient interface current problem model export format see another problem exist layer saved want know kind data consult solve knowledge,issue,positive,positive,positive,positive,positive,positive
606855602,"Hi, I have the same problem. The same exception is raised when using a `tf.data.dataset`.",hi problem exception raised,issue,negative,neutral,neutral,neutral,neutral,neutral
606488970,"Heya @haifeng-jin,

Hope all is well in lockdown times...

I am answering quite late, sorry about that. I have a bit of a backlog going on at Dataiku. I can't commit, but if I find some time between now and summer I will try. But if anyone has time before that, definitely a better option.

Cheers,

Alex",hope well time quite late sorry bit backlog going ca commit find time summer try anyone time definitely better option,issue,positive,negative,negative,negative,negative,negative
606486847,"@haifeng-jin I agree, it's not difficult to code it with this trick. As it's a common requirement, I think it would be valuable to have it built-in the core library.",agree difficult code trick common requirement think would valuable core library,issue,negative,negative,negative,negative,negative,negative
605892626,It's working now. Missed the minor version of TF. Thanks for reply! ,working minor version thanks reply,issue,negative,positive,neutral,neutral,positive,positive
605828822,"I have both requirements satisfied still getting the same error.

Keras: 2.3.1
Tensorflow: 2.0.0
OS: Mac OS Mojave",satisfied still getting error o mac o,issue,negative,positive,positive,positive,positive,positive
605406124,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1037?src=pr&el=h1) Report
> Merging [#1037](https://codecov.io/gh/keras-team/autokeras/pull/1037?src=pr&el=desc) into [master](https://codecov.io/gh/keras-team/autokeras/commit/94d5b26a6ed796539ff8dba3da69c9efb8abf4c2&el=desc) will **increase** coverage by `0.20%`.
> The diff coverage is `100.00%`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1037/graphs/tree.svg?width=650&height=150&src=pr&token=yDvddb2DDZ)](https://codecov.io/gh/keras-team/autokeras/pull/1037?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master    #1037      +/-   ##
==========================================
+ Coverage   91.15%   91.36%   +0.20%     
==========================================
  Files          37       37              
  Lines        1798     1771      -27     
==========================================
- Hits         1639     1618      -21     
+ Misses        159      153       -6     
```


| [Impacted Files](https://codecov.io/gh/keras-team/autokeras/pull/1037?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [autokeras/hypermodels/preprocessing.py](https://codecov.io/gh/keras-team/autokeras/pull/1037/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2h5cGVybW9kZWxzL3ByZXByb2Nlc3NpbmcucHk=) | `98.59% <100.00%> (+5.73%)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1037?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1037?src=pr&el=footer). Last update [94d5b26...a25be6d](https://codecov.io/gh/keras-team/autokeras/pull/1037?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",report master increase coverage coverage impacted file tree graph coverage master coverage impacted coverage continue review full report legend click learn absolute relative impact affected missing data powered last update abed read comment,issue,negative,positive,neutral,neutral,positive,positive
605405585,"This is because we implemented our own preprocessing layer for feature encoding. We are soon moving to TF2.2, which has the official layers to do the task. At that time, this should be fixed.",layer feature soon moving official task time fixed,issue,negative,positive,neutral,neutral,positive,positive
605405464,"https://www.tensorflow.org/guide/data#consuming_tfrecord_data
This is a tutorial on using tf.data.Dataset to load large datasets, which doesn't fit in memory.
It is the most recommended way to load data to TF as well.",tutorial load large fit memory way load data well,issue,positive,positive,positive,positive,positive,positive
605405187,"Thank you for the clarification! If my understanding is correct, you are able to do it with the current AutoKeras, right? You can just export the model as a Keras Model and convert it to on. So what you want is a convenient interface.",thank clarification understanding correct able current right export model model convert want convenient interface,issue,negative,positive,positive,positive,positive,positive
605061971,"What was your issue? I didn't check for accuracy on mine, but I can give you a code sample

```python
import autokeras as ak
from sklearn.model_selection import train_test_split

# X and y from Pandas dataframes
X = df.drop(columns=['host_id', 'price'])
y = df['price']

# split up if you're holding onto validation data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)
y_arr = y_train.to_numpy().astype('int64') # this is now a 1D numpy array

clf = ak.StructuredDataRegressor(max_trials=10)
clf.fit(X_train, y_arr, validation_data=(X_test, y_test))
```",issue check accuracy mine give code sample python import ak import split holding onto validation data array,issue,negative,neutral,neutral,neutral,neutral,neutral
604853406,"


> I recently finished using AutoKeras on a regression task with tabular data. It worked great (thanks!!) but while working on it, I noticed the tutorial is empty ( https://autokeras.com/tutorial/structured_data_regression/ ) yet there is now an example in the documentation in this repo. Is a new release planned?
> 
> In the meantime - there's still no example for text regression or image regression. I will try to add examples for one or both to fully close this issue, if no one else is working on it.

My Structured Data Regression doesn't seem to work, how did you do it",recently finished regression task tabular data worked great thanks working tutorial empty yet example documentation new release still example text regression image regression try add one fully close issue one else working structured data regression seem work,issue,positive,positive,positive,positive,positive,positive
603610679,"Just noticed that final_fit is included in the fit method as per discussion in other issues. 
It will be good to update documentation to reflect this? ",included fit method per discussion good update documentation reflect,issue,positive,positive,positive,positive,positive,positive
603297788,"@haifeng-jin This did solved my problem, thank you. My problem was mainly not to use `AutoModel`. I had used `TextClassifier` before but this didn't work. The following code worked: 

```
max_features = 10000

input_node = ak.TextInput()
output_node = ak.TextToIntSequence(max_tokens=max_features)(input_node)
output_node = ak.ClassificationHead()(output_node)
clf = ak.AutoModel(inputs=input_node, outputs=output_node, max_trials=1)
```",problem thank problem mainly use used work following code worked,issue,negative,positive,neutral,neutral,positive,positive
602947500,"Yes, I have very big datasets that will not fit in memory. 
",yes big fit memory,issue,positive,positive,positive,positive,positive,positive
602912941,We currently are not working on these tutorials. It would be great if you can contribute any of them. Please follow the image classification tutorial style to write it. Thank you!,currently working would great contribute please follow image classification tutorial style write thank,issue,positive,positive,positive,positive,positive,positive
602895012,"@yufei-12 Is working on this. Hopefully will have some update soon. However, we don't have a timeline for when we can deliver this module for now.",working hopefully update soon however deliver module,issue,negative,neutral,neutral,neutral,neutral,neutral
602893782,We don't have an example right now. I believe there is a way to put them into a tf.data.Dataset. Do you think so?,example right believe way put think,issue,negative,positive,positive,positive,positive,positive
602426870,"The Pb format model can be deployed by tensorflow serving. Both the *. CKPT weight of tensorflow and the *. H5 of keras can be converted into Pb format files. The Pb format files are convenient for the environment configuration of the client and the server, so we hope to have a Pb format export interface
The following is an example of the directory structure of a Pb file
```
.
└── 0
    ├── saved_model.pb
    └── variables
        ├── variables.data-00000-of-00001
        └── variables.index
```",format model serving weight converted format format convenient environment configuration client server hope format export interface following example directory structure file,issue,negative,neutral,neutral,neutral,neutral,neutral
602187108,I have the same problem but with multi-class classification. Did you find any solution yet?,problem classification find solution yet,issue,negative,neutral,neutral,neutral,neutral,neutral
600425122,@haifeng-jin  when will autoKeras support object detection and prediction for custom models ??,support object detection prediction custom,issue,negative,neutral,neutral,neutral,neutral,neutral
600395855,This is because the environment recognize the ak package as the one in the tests folder. directly install autokeras instead of cloning the repo would solve the problem.,environment recognize ak package one folder directly install instead would solve problem,issue,negative,positive,neutral,neutral,positive,positive
600224713,"Ok so then how do you feed a big dataset with images without `keras.utils.Sequence`s? It's implausible to load it all in memory as you do in examples. It's fine for small Fashion-MNIST like datasets, what the huge ones? Could you show an example?",feed big without implausible load memory fine small like huge could show example,issue,positive,positive,positive,positive,positive,positive
600167498,This might because of the greedy tuning algorithms have some bugs. You can try to use the AutoModel API and use random search as tuner.,might greedy tuning try use use random search tuner,issue,negative,negative,negative,negative,negative,negative
600165237,I think this is totally doable with a small trick. Just export the model and get the output of the softmax.,think totally doable small trick export model get output,issue,negative,negative,negative,negative,negative,negative
600163810,"Currently, we did not test fort this feature. If you succeed, please let us know. Thanks",currently test fort feature succeed please let u know thanks,issue,positive,positive,neutral,neutral,positive,positive
600162621,I am not sure what is pb format. Is it possible to do it after exporting the model?,sure format possible model,issue,negative,positive,positive,positive,positive,positive
599035758,"Hi, 

I am still interested, get_params is an important method which would close the gap with the sklearn API.",hi still interested important method would close gap,issue,positive,positive,positive,positive,positive,positive
599035626,"Still interested by the way, any chance it can happen in a later version?",still interested way chance happen later version,issue,positive,positive,positive,positive,positive,positive
597979402,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1041?src=pr&el=h1) Report
> Merging [#1041](https://codecov.io/gh/keras-team/autokeras/pull/1041?src=pr&el=desc) into [master](https://codecov.io/gh/keras-team/autokeras/commit/6feed04568efd9672857eec8b457981cd6ed53f3?src=pr&el=desc) will **not change** coverage.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1041/graphs/tree.svg?width=650&token=yDvddb2DDZ&height=150&src=pr)](https://codecov.io/gh/keras-team/autokeras/pull/1041?src=pr&el=tree)

```diff
@@          Coverage Diff           @@
##           master   #1041   +/-   ##
======================================
  Coverage    92.1%   92.1%           
======================================
  Files          37      37           
  Lines        1749    1749           
======================================
  Hits         1611    1611           
  Misses        138     138
```


| [Impacted Files](https://codecov.io/gh/keras-team/autokeras/pull/1041?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [autokeras/hypermodels/heads.py](https://codecov.io/gh/keras-team/autokeras/pull/1041/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2h5cGVybW9kZWxzL2hlYWRzLnB5) | `96.42% <ø> (ø)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1041?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1041?src=pr&el=footer). Last update [6feed04...bbdc11f](https://codecov.io/gh/keras-team/autokeras/pull/1041?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",report master change coverage coverage impacted file tree graph coverage master coverage impacted coverage continue review full report legend click learn absolute relative impact affected missing data powered last update feed read comment,issue,negative,positive,neutral,neutral,positive,positive
597976603,@abgese It seems the tests are not covering the TimeSeriesInput. Would you please add a test to cover it? Thanks.,covering would please add test cover thanks,issue,positive,positive,positive,positive,positive,positive
597361641,"Currently, the is no way to limit the time. However, all the intermediate results and models are saved on disk. You may try to see what's in the folder. Those kids and models are generated by KerasTuner. Thanks.",currently way limit time however intermediate saved disk may try see folder thanks,issue,positive,positive,neutral,neutral,positive,positive
597360709,I also found the latest tf-nightly doesn't solve the issue. We will need to further investigate it. Thanks,also found latest solve issue need investigate thanks,issue,positive,positive,positive,positive,positive,positive
597360058,"Hi,
If you want to use the export model, you will need to do the one hour encoding yourself. The structured data classifier accept both raw labels and encoded labels.",hi want use export model need one hour structured data classifier accept raw,issue,negative,negative,negative,negative,negative,negative
597072775,"@haifeng-jin do you have any suggestion on how to limit the time any other way, or a way to save the state of the program every n iterations/time units?

I run my code on a HPC center where i have to book my jobs with a time limit, and jobs are terminated when the timer runs out. It would be a shame if i can't save my model before that happens.",suggestion limit time way way save state program every run code center book time limit timer would shame ca save model,issue,positive,negative,neutral,neutral,negative,negative
596716902,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1036?src=pr&el=h1) Report
> Merging [#1036](https://codecov.io/gh/keras-team/autokeras/pull/1036?src=pr&el=desc) into [master](https://codecov.io/gh/keras-team/autokeras/commit/389c82ed5952201bb3c09d33e91dd6251f35efad?src=pr&el=desc) will **not change** coverage.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1036/graphs/tree.svg?width=650&token=yDvddb2DDZ&height=150&src=pr)](https://codecov.io/gh/keras-team/autokeras/pull/1036?src=pr&el=tree)

```diff
@@          Coverage Diff           @@
##           master   #1036   +/-   ##
======================================
  Coverage    92.1%   92.1%           
======================================
  Files          37      37           
  Lines        1748    1748           
======================================
  Hits         1610    1610           
  Misses        138     138
```


| [Impacted Files](https://codecov.io/gh/keras-team/autokeras/pull/1036?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [autokeras/hypermodels/heads.py](https://codecov.io/gh/keras-team/autokeras/pull/1036/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2h5cGVybW9kZWxzL2hlYWRzLnB5) | `96.38% <ø> (ø)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1036?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1036?src=pr&el=footer). Last update [389c82e...d62c12b](https://codecov.io/gh/keras-team/autokeras/pull/1036?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",report master change coverage coverage impacted file tree graph coverage master coverage impacted coverage continue review full report legend click learn absolute relative impact affected missing data powered last update ce read comment,issue,negative,positive,neutral,neutral,positive,positive
596346671,"I have tested all dev versions of tf-nightly-gpu==2.2.0 in colab including the latest  version(tf-nightly-gpu 2.2.0.dev20200308) , error still exits.

From tf-nightly-gpu==2.2.0.dev20200226 to the latest version(tf-nightly-gpu 2.2.0.dev20200308), it will raise AttributeError: 'tuple' object has no attribute 'shape' error:
````
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:493 train_function  *
        outputs = self.distribute_strategy.experimental_run_v2(
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:856 experimental_run_v2  **
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2112 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2470 _call_for_each_replica
        return fn(*args, **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:465 _train_step  **
        self.compiled_metrics.update_state(y, y_pred, sample_weight)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:348 update_state
        self._build(y_pred, y_true)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:267 _build
        self._metrics, y_true, y_pred)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py:1118 map_structure_up_to
        **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py:1214 map_structure_with_tuple_paths_up_to
        *flat_value_lists)]
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py:1213 <listcomp>
        results = [func(*args, **kwargs) for args in zip(flat_path_list,
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py:1116 <lambda>
        lambda _, *values: func(*values),  # Discards the path arg.
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:377 _get_metric_objects
        return [self._get_metric_object(m, y_t, y_p) for m in metrics]
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:377 <listcomp>
        return [self._get_metric_object(m, y_t, y_p) for m in metrics]
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:398 _get_metric_object
        y_t_rank = len(y_t.shape.as_list())

    AttributeError: 'tuple' object has no attribute 'shape'
````
With tf-nightly-gpu==2.2.0.dev20200218 and before, it will raise AttributeError: 'TrackableWeightHandler' object has no attribute 'numpy' error:
````
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py in save(self, filepath, overwrite, include_optimizer, save_format, signatures, options)
   1002     """"""
   1003     save.save_model(self, filepath, overwrite, include_optimizer, save_format,
-> 1004                     signatures, options)
   1005 
   1006   def save_weights(self, filepath, overwrite=True, save_format=None):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py in save_model(model, filepath, overwrite, include_optimizer, save_format, signatures, options)
    133           'or using `save_weights`.')
    134     hdf5_format.save_model_to_hdf5(
--> 135         model, filepath, overwrite, include_optimizer)
    136   else:
    137     saved_model_save.save(model, filepath, overwrite, include_optimizer,

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/hdf5_format.py in save_model_to_hdf5(model, filepath, overwrite, include_optimizer)
    107     model_weights_group = f.create_group('model_weights')
    108     model_layers = model.layers
--> 109     save_weights_to_hdf5_group(model_weights_group, model_layers)
    110 
    111     # TODO(b/128683857): Add integration tests between tf.keras and external

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/hdf5_format.py in save_weights_to_hdf5_group(f, layers)
    627     g = f.create_group(layer.name)
    628     weights = _legacy_weights(layer)
--> 629     weight_values = K.batch_get_value(weights)
    630     weight_names = [w.name.encode('utf8') for w in weights]
    631     save_attributes_to_hdf5_group(g, 'weight_names', weight_names)

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py in batch_get_value(tensors)
   3325   """"""
   3326   if context.executing_eagerly():
-> 3327     return [x.numpy() for x in tensors]
   3328   elif ops.inside_function():  # pylint: disable=protected-access
   3329     raise RuntimeError('Cannot get value inside Tensorflow graph function.')

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py in <listcomp>(.0)
   3325   """"""
   3326   if context.executing_eagerly():
-> 3327     return [x.numpy() for x in tensors]
   3328   elif ops.inside_function():  # pylint: disable=protected-access
   3329     raise RuntimeError('Cannot get value inside Tensorflow graph function.')

AttributeError: 'TrackableWeightHandler' object has no attribute 'numpy'
````",tested dev latest version dev error still dev latest version dev raise object attribute error return return return zip lambda lambda path return metric return metric object attribute dev raise object attribute error save self overwrite self overwrite self model overwrite model overwrite else model overwrite model overwrite add integration external layer return raise get value inside graph function return raise get value inside graph function object attribute,issue,negative,positive,positive,positive,positive,positive
595985633,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1029?src=pr&el=h1) Report
> Merging [#1029](https://codecov.io/gh/keras-team/autokeras/pull/1029?src=pr&el=desc) into [master](https://codecov.io/gh/keras-team/autokeras/commit/28baa17f921b6a82d6f1e3995c5d7390ab7f83f7?src=pr&el=desc) will **not change** coverage.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/1029/graphs/tree.svg?width=650&token=yDvddb2DDZ&height=150&src=pr)](https://codecov.io/gh/keras-team/autokeras/pull/1029?src=pr&el=tree)

```diff
@@           Coverage Diff           @@
##           master    #1029   +/-   ##
=======================================
  Coverage   92.52%   92.52%           
=======================================
  Files          33       33           
  Lines        1673     1673           
=======================================
  Hits         1548     1548           
  Misses        125      125
```



------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1029?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/1029?src=pr&el=footer). Last update [28baa17...f11a319](https://codecov.io/gh/keras-team/autokeras/pull/1029?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",report master change coverage coverage impacted file tree graph coverage master coverage continue review full report legend click learn absolute relative impact affected missing data powered last update baa fa read comment,issue,negative,positive,neutral,neutral,positive,positive
595723366,"I updated the **Bug Reproduction** by using only tf.keras methods, but some issues persist (which are updated in **Error messages**)",bug reproduction persist error,issue,negative,neutral,neutral,neutral,neutral,neutral
595217619,"Hi, unfortunately the latest tf-nightly raises another error: 

    AttributeError: in user code:

    /home/user/tf-nightly-test/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:499 train_function  *
        outputs = self.distribute_strategy.experimental_run_v2(
    /home/user/tf-nightly-test/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:856 experimental_run_v2  **
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    /home/user/tf-nightly-test/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:2112 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    /home/user/tf-nightly-test/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:2470 _call_for_each_replica
        return fn(*args, **kwargs)
    /home/user/tf-nightly-test/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:471 train_step  **
        self.compiled_metrics.update_state(y, y_pred, sample_weight)
    /home/user/tf-nightly-test/lib/python3.6/site-packages/tensorflow/python/keras/engine/compile_utils.py:348 update_state
        self._build(y_pred, y_true)
    /home/user/tf-nightly-test/lib/python3.6/site-packages/tensorflow/python/keras/engine/compile_utils.py:267 _build
        self._metrics, y_true, y_pred)
    /home/user/tf-nightly-test/lib/python3.6/site-packages/tensorflow/python/util/nest.py:1118 map_structure_up_to
        **kwargs)
    /home/user/tf-nightly-test/lib/python3.6/site-packages/tensorflow/python/util/nest.py:1214 map_structure_with_tuple_paths_up_to
        *flat_value_lists)]
    /home/user/tf-nightly-test/lib/python3.6/site-packages/tensorflow/python/util/nest.py:1213 <listcomp>
        results = [func(*args, **kwargs) for args in zip(flat_path_list,
    /home/user/tf-nightly-test/lib/python3.6/site-packages/tensorflow/python/util/nest.py:1116 <lambda>
        lambda _, *values: func(*values),  # Discards the path arg.
    /home/user/tf-nightly-test/lib/python3.6/site-packages/tensorflow/python/keras/engine/compile_utils.py:377 _get_metric_objects
        return [self._get_metric_object(m, y_t, y_p) for m in metrics]
    /home/user/tf-nightly-test/lib/python3.6/site-packages/tensorflow/python/keras/engine/compile_utils.py:377 <listcomp>
        return [self._get_metric_object(m, y_t, y_p) for m in metrics]
    /home/user/tf-nightly-test/lib/python3.6/site-packages/tensorflow/python/keras/engine/compile_utils.py:398 _get_metric_object
        y_t_rank = len(y_t.shape.as_list())

    AttributeError: 'tuple' object has no attribute 'shape'

Within TF==2.1.0 I used pandas Dataframes as Input and everything worked fine except for saving the model after calling best_model = model.export_model(). Now I transformed these Dataframes into Numpy arrays but the error mentioned above occurs. ",hi unfortunately latest another error user code return return return zip lambda lambda path return metric return metric object attribute within used input everything worked fine except saving model calling error,issue,negative,positive,positive,positive,positive,positive
594594343,"Hi, Would you try the latest tf-nightly? It may resolve the issue. Thanks",hi would try latest may resolve issue thanks,issue,positive,positive,positive,positive,positive,positive
594592300,we are not supporting the stand alone Keras. You can only export and load the model with TF.keras. Thanks,supporting stand alone export load model thanks,issue,positive,positive,positive,positive,positive,positive
594590617,The accuracy is low for now mainly because the image data augmentation layers are not released yet. I expect the new version after tf 2.2 would be much better.,accuracy low mainly image data augmentation yet expect new version would much better,issue,negative,positive,positive,positive,positive,positive
594513047,@tik0 Have you found out anything on this one? Have you been able to use AutoKeras to create an Autoencoder or did you use something different?,found anything one able use create use something different,issue,negative,positive,positive,positive,positive,positive
594206797,"@ECEMACHINE Would you please help address Francois's comments?
Note some docstring problems may also exist in the docstrings of other classes.
Please check ImageClassifier, ImageRegressor, ImageInput for similar problems.

Thank you!",would please help address note may also exist class please check similar thank,issue,positive,neutral,neutral,neutral,neutral,neutral
593832513,"same error 
error ifo
```
  File ""/home/dy/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/generic_utils.py"", line 250, in class_and_config_for_serialized_keras_object
    raise ValueError('Unknown ' + printable_module_name + ': ' + class_name)
ValueError: Unknown layer: Normalization
```
here is my code 

```
model = tf.keras.models.load_model(self.local_path+'model.h5',custom_objects=ak.CUSTOM_OBJECTS)
```",error error file line raise unknown layer normalization code model,issue,negative,negative,neutral,neutral,negative,negative
593786643,"@picsag 
may I ask you how good of your trained model performed on cifar10?
I only achieve 74% accuracy by default `ak.ImageClassifier`... (script as belows)

```python
from tensorflow.keras.datasets import cifar10
import autokeras as ak

# Prepare the dataset.
(x_train, y_train), (x_test, y_test) = cifar10.load_data()
# Initialize the ImageClassifier.
clf = ak.ImageClassifier()
# Search for the best model.
clf.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=300, batch_size=128)
# Evaluate on the testing data.
print('Accuracy: {accuracy}'.format(
    accuracy=clf.evaluate(x_test, y_test)))
```

if it need a lot of custom config to get higher performance, I will feel this is not handy, comparing to apply resnet18 to get 94%+ accuracy.",may ask good trained model achieve accuracy default script python import import ak prepare initialize search best model evaluate testing data print accuracy need lot custom get higher performance feel handy apply get accuracy,issue,positive,positive,positive,positive,positive,positive
593094226,"Hi Haifeng,
I did try with tf-nightly and it does remove the occurence of NaN trials. Thanks for higlighting this - I guess all current development is following tf-nightly. I will go ahead and close this.",hi try remove nan thanks guess current development following go ahead close,issue,negative,positive,neutral,neutral,positive,positive
592763840,"Currently, we are not supporting JSON format, you have to write your own python program to convert JSON to a compatible format (numpy.ndarray, tf.data.Dataset).
We also do not support object detection for now.
Thanks.",currently supporting format write python program convert compatible format also support object detection thanks,issue,positive,positive,positive,positive,positive,positive
592408726,"Hi, I'm reading the code of autogluon. I'll get started soon.Thank you.




------------------&nbsp;Original&nbsp;------------------
From: ""Haifeng Jin""<notifications@github.com&gt;; 
Date: 2020年2月28日(星期五) 凌晨4:29
To: ""keras-team/autokeras""<autokeras@noreply.github.com&gt;; 
Cc: ""K""<1345997226@qq.com&gt;; ""Mention""<mention@noreply.github.com&gt;; 
Subject: Re: [keras-team/autokeras] Object Detection (#925)




@yufei-12 is designing the APIs.
 Hopefully, we will have a basic model in the next 2 months.
 Yufei, do you have any updates on this issue?
 
Thanks.
 
—
You are receiving this because you were mentioned.
Reply to this email directly, view it on GitHub, or unsubscribe.",hi reading code get original date mention mention subject object detection designing hopefully basic model next issue thanks reply directly view,issue,positive,positive,neutral,neutral,positive,positive
592248171,"> @bestpredicts Would you help us answer another question?
> In this issue, it shows you have unassigned tl-yang from the issue. You can see the log right above.
> However, I don't think you have permission to do it.
> 
> Would you please let me know how did you unassigned him?
> GitHub is trying to fix this bug.

 Thank you for your answer, in fact I did not do any unassigned operation, I don't know why this bug was triggered  :O ",would help u answer another question issue unassigned issue see log right however think permission would please let know unassigned trying fix bug thank answer fact unassigned operation know bug triggered,issue,positive,positive,positive,positive,positive,positive
592161937,"@yufei-12 is designing the APIs.
Hopefully, we will have a basic model in the next 2 months.
Yufei, do you have any updates on this issue?

Thanks.",designing hopefully basic model next issue thanks,issue,positive,positive,neutral,neutral,positive,positive
592161305,"@bestpredicts Would you help us answer another question?
In this issue, it shows you have unassigned tl-yang from the issue. You can see the log right above.
However, I don't think you have permission to do it.

Would you please let me know how did you unassigned him?
GitHub is trying to fix this bug.",would help u answer another question issue unassigned issue see log right however think permission would please let know unassigned trying fix bug,issue,positive,positive,positive,positive,positive,positive
592160313,"I believe you can use any way that supported by tensorflow or tf.keras. AutoKeras is not doing anything to configure the GPUs to use. We just directly call the APIs of TensorFlow.
The only thing we did is to do a clear_session() before every run. Not sure if that would wipe out your gpu configuration.",believe use way anything configure use directly call thing every run sure would wipe configuration,issue,negative,positive,positive,positive,positive,positive
591929437," hi, @haifeng-jin  when will Autokeras  support  object detection for a custom dataset  for training ",hi support object detection custom training,issue,negative,neutral,neutral,neutral,neutral,neutral
591712350,"> It is based on TensorFlow. So it does in a way that trains one model on multiple GPUs as distributed training.


In fact, I specified two GPUs in cuda_visible_devices in the code, but when I use the fit method,  but only one GPU is working. and we know that tf.keras use this api to do  multi gpu  
```
tf.keras.utils.multi_gpu_model(
    model, gpus, cpu_merge=True, cpu_relocation=False
)
```
but  can I use. this api. for. autokeras?",based way one model multiple distributed training fact two code use fit method one working know use model use,issue,negative,positive,positive,positive,positive,positive
591500947,It is based on TensorFlow. So it does in a way that trains one model on multiple GPUs as distributed training.,based way one model multiple distributed training,issue,negative,neutral,neutral,neutral,neutral,neutral
591500413,"I think I know why.

It might because the normalization layer has no weights when exported.
Exported model's Normalization is load from disk but its weights are not saved to disk.
If the normalization is giving invalid output, the model loss will be nan.

You can just uninstall tensorflow and install the latest tf-nightly.
It should solve the problem.",think know might normalization layer model normalization load disk saved disk normalization giving invalid output model loss nan install latest solve problem,issue,negative,positive,positive,positive,positive,positive
591252329,"here is my code 
```
#%%
import os
import math
import codecs
import random
import numpy as np
from glob import glob
from PIL import Image
import cv2
from sklearn.model_selection import train_test_split
from keras.utils import to_categorical
from tqdm import tqdm
import autokeras as ak
import time
import os
os.environ[""CUDA_VISIBLE_DEVICES""] = ""0,1""


DEBUG = True
PRINT = False
img_width = 50
img_height = 50




def data_flow(train_data_dir):  # need modify
    label_files = glob(os.path.join(train_data_dir, '*.txt'))
    random.shuffle(label_files)
    img_paths = []
    labels = []
    for index, file_path in enumerate(label_files):
        with codecs.open(file_path, 'r', 'utf-8') as f:
            line = f.readline()
        line_split = line.strip().split(', ')
        if len(line_split) != 2:
            print('%s contain error lable' % os.path.basename(file_path))
            continue
        img_name = line_split[0]
        label = int(line_split[1])
        img_paths.append(os.path.join(train_data_dir, img_name))
        labels.append(label)
    return  img_paths,labels


if DEBUG:
    img_paths,labels = data_flow(""/home/dy/autodl/garbage/garbage_classify/train_data"")
    if PRINT:
        print(img_paths[:10],labels[:10])




def prepare_data(list_of_images,labels):
    """"""
    Returns two arrays: 
        x is an array of resized images
        y is an array of labels
    """"""
    x = [] # images as arrays
    y = [] # labels
    
    for image in tqdm(list_of_images):
        x.append(cv2.resize(cv2.imread(image), (img_width,img_height), interpolation=cv2.INTER_CUBIC))

    y = labels 
    return x, y



if DEBUG:
    X,Y=  prepare_data(img_paths,labels)
    if PRINT:
        print(X)
        print(Y)

    X_train, X_val, Y_train, Y_val = train_test_split(X,Y, test_size=0.2, random_state=1)



X_train = np.array(X_train)
Y_train =  to_categorical(Y_train)

X_val = np.array(X_val)
Y_val = to_categorical(Y_val)

start = time.time()


input_node = ak.ImageInput()
output_node = ak.Normalization()(input_node)
output_node = ak.ImageAugmentation(percentage=0.3)(output_node)
output_node = ak.ResNetBlock(version='v2')(output_node)
output_node = ak.ClassificationHead()(output_node)
clf = ak.AutoModel(inputs=input_node, outputs=output_node, max_trials=10)
clf.fit(X_train, Y_train, epochs=50)
# Evaluate on the testing data.
print('Accuracy: {accuracy}'.format(
    accuracy=clf.evaluate(X_val, Y_val)))

end = time.time()

minute = (end-start)/60


print(""总共运行时间 %f min""%minute)


```",code import o import math import import random import import import image import import import import import ak import time import o true print false need modify index enumerate line print contain error continue label label return print print two array array image image return print print print start evaluate testing data print accuracy end minute print min minute,issue,negative,negative,negative,negative,negative,negative
591108741,"@sibyjackgrove It is because the version of tf-nightly. I removed it yesterday and added it back today. So If you merge master, it should pass.",version removed yesterday added back today merge master pas,issue,negative,neutral,neutral,neutral,neutral,neutral
591071866,"@abgese 
I have got a reply confirming we cannot implement a preprocessing layer doing the job. Let's take the second approach to add a TimeSeriesInput() in nodes.py and a corresponding adapter in input_adapters.py.

Let me know if you have any questions.

I will be changing the API and docs for enabling users to do the preprocessing themselves.

We may use this feature later when it is in TensorFlow's stable release.
https://github.com/keras-team/governance/blob/master/rfcs/20190729-keras-preprocessing-redesign.md#timeseriesgenerator",got reply confirming implement layer job let take second approach add corresponding adapter let know may use feature later stable release,issue,negative,neutral,neutral,neutral,neutral,neutral
591059835,"There are two possible approaches.
1. Put the preprocessing step inside the Keras model.
We need a preprocessing layer to change the shape.
The input shape to the preprocessing layer (num_instances, num_features).
The output shape of the preprocessing layer (num_instances - lookback + 1, lookback, num_features).
Is it possible to implement a preprocessing layer like this?

2. Do the preprocessing before input to the Keras model.
This can be directly done with input_adpaters.py.
The problem is when people export the Keras model, the model cannot do the preprocessing for them.
They have to do the preprocessing themselves to use the exported Keras model.
A possible solution would be to add one more argument for whether to do the preprocessing for the user in the fit.
They can choose to do preprocessing themselves when using AutoKeras.
",two possible put step inside model need layer change shape input shape layer output shape layer possible implement layer like input model directly done problem people export model model use model possible solution would add one argument whether user fit choose,issue,negative,positive,neutral,neutral,positive,positive
590877419,"Hi Haifeng,
It looks like this (on the exact same code and repeatable training set as the original log file attached):

Model: ""model""
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 18, 10, 1)]  0                                            
__________________________________________________________________________________________________
normalization (Normalization)   (None, 18, 10, 1)    3           input_1[0][0]                    
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 9, 5, 128)    1280        normalization[0][0]              
__________________________________________________________________________________________________
separable_conv2d (SeparableConv (None, 9, 5, 128)    17664       conv2d[0][0]                     
__________________________________________________________________________________________________
separable_conv2d_1 (SeparableCo (None, 9, 5, 128)    17664       separable_conv2d[0][0]           
__________________________________________________________________________________________________
add (Add)                       (None, 9, 5, 128)    0           separable_conv2d_1[0][0]         
                                                                 conv2d[0][0]                     
__________________________________________________________________________________________________
separable_conv2d_2 (SeparableCo (None, 9, 5, 128)    17664       add[0][0]                        
__________________________________________________________________________________________________
separable_conv2d_3 (SeparableCo (None, 9, 5, 128)    17664       separable_conv2d_2[0][0]         
__________________________________________________________________________________________________
add_1 (Add)                     (None, 9, 5, 128)    0           separable_conv2d_3[0][0]         
                                                                 add[0][0]                        
__________________________________________________________________________________________________
separable_conv2d_4 (SeparableCo (None, 9, 5, 128)    17664       add_1[0][0]                      
__________________________________________________________________________________________________
separable_conv2d_5 (SeparableCo (None, 9, 5, 128)    17664       separable_conv2d_4[0][0]         
__________________________________________________________________________________________________
add_2 (Add)                     (None, 9, 5, 128)    0           separable_conv2d_5[0][0]         
                                                                 add_1[0][0]                      
__________________________________________________________________________________________________
separable_conv2d_6 (SeparableCo (None, 9, 5, 128)    17664       add_2[0][0]                      
__________________________________________________________________________________________________
separable_conv2d_7 (SeparableCo (None, 9, 5, 128)    17664       separable_conv2d_6[0][0]         
__________________________________________________________________________________________________
add_3 (Add)                     (None, 9, 5, 128)    0           separable_conv2d_7[0][0]         
                                                                 add_2[0][0]                      
__________________________________________________________________________________________________
separable_conv2d_8 (SeparableCo (None, 9, 5, 128)    17664       add_3[0][0]                      
__________________________________________________________________________________________________
separable_conv2d_9 (SeparableCo (None, 9, 5, 128)    17664       separable_conv2d_8[0][0]         
__________________________________________________________________________________________________
add_4 (Add)                     (None, 9, 5, 128)    0           separable_conv2d_9[0][0]         
                                                                 add_3[0][0]                      
__________________________________________________________________________________________________
separable_conv2d_10 (SeparableC (None, 9, 5, 256)    34176       add_4[0][0]                      
__________________________________________________________________________________________________
separable_conv2d_11 (SeparableC (None, 9, 5, 256)    68096       separable_conv2d_10[0][0]        
__________________________________________________________________________________________________
max_pooling2d (MaxPooling2D)    (None, 5, 3, 256)    0           separable_conv2d_11[0][0]        
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 5, 3, 256)    33024       add_4[0][0]                      
__________________________________________________________________________________________________
add_5 (Add)                     (None, 5, 3, 256)    0           max_pooling2d[0][0]              
                                                                 conv2d_1[0][0]                   
__________________________________________________________________________________________________
flatten (Flatten)               (None, 3840)         0           add_5[0][0]                      
__________________________________________________________________________________________________
regression_head_1 (Dense)       (None, 1)            3841        flatten[0][0]                    
==================================================================================================
Total params: 317,060
Trainable params: 317,057
Non-trainable params: 3
__________________________________________________________________________________________________
Train on 3283 samples, validate on 1408 samples
Epoch 1/1000

  32/3283 [..............................] - ETA: 55s - loss: nan - mean_squared_error: nan
",hi like exact code repeatable training set original log file attached model model layer type output shape param connected none normalization normalization none none normalization none none add add none none add none add none add none none add none none none add none none none add none none none none none add none flatten flatten none dense none flatten total trainable train validate epoch eta loss nan nan,issue,positive,positive,positive,positive,positive,positive
590431253,"I have never seen this before.
To my understanding, the issue is mainly related to export_model.

The behavior is highly likely that there is an exported preprocessing layer that is not adapted, which is a known bug.
However, I don't think we include any preprocessing layer in ImageRegressor.

Would you try best_model.summary() to see what is inside?
As long as it is an OK Keras model, it should have some loss value instead of NaN.",never seen understanding issue mainly related behavior highly likely layer known bug however think include layer would try see inside long model loss value instead nan,issue,negative,negative,neutral,neutral,negative,negative
590272998,"Be careful when writing ""Resolves #949"", it's going to close the issue when merged.",careful writing going close issue,issue,negative,negative,neutral,neutral,negative,negative
590118394,"@nocluebutalotofit Thanks for the pull request. We are currently focusing on Keras models (neural networks). When comparing with tree-based models, it may have its limitations.

The dataset is good. We will include this tutorial later.

Thank you!",thanks pull request currently neural may good include tutorial later thank,issue,positive,positive,positive,positive,positive,positive
590097076,"I had same issue, when using tensorflow.keras. I had written a custom data generator using python yield instruction. My problem was that I used generator for validation data, but didn't determine the validation_steps (So the data collector was going to out of range):
```
model.fit(generate_train_data(),
          steps_per_epoch=train_size // batch_size,
          validation_data=generate_val_data(),
          epochs=epochs)
```
And fixed it by using validation steps:
```
model.fit(generate_train_data(),
          steps_per_epoch=train_size // batch_size,
          validation_data=generate_val_data(),
          validation_steps=validation_size // batch_size,
          epochs=epochs)
```",issue written custom data generator python yield instruction problem used generator validation data determine data collector going range fixed validation,issue,negative,positive,neutral,neutral,positive,positive
590033415,"Hi Haifeng, just to clarify the X number of trials (20 in this case) does finish before doing the final fit. But it cannot be the case that the last trial that gives only NaN is the best performing model when the previous models (although not with great accuracy values) gives better results? Or am I somehow missing something, or using the APIs in the wrong way? Appreciate any suggestions, thank you!",hi clarify number case finish final fit case last trial nan best model previous although great accuracy better somehow missing something wrong way appreciate thank,issue,positive,positive,positive,positive,positive,positive
590033267,"> I mean this may still be a bug. We will test it out during we write the colab notebooks. And fix it.
> 
> I guess the bug may be related to the custom preprocessing layer we implemented for coverting the numerical features to categorical ones. That custom layer will be removed. We will use the official layers provided in tf2.2 to do the trick, which are not released yet.

Awesome sounds great! It'll be amazing once that is implemented. Thank you very much.",mean may still bug test write fix guess bug may related custom layer numerical categorical custom layer removed use official provided trick yet awesome great amazing thank much,issue,positive,positive,positive,positive,positive,positive
590033205,"> I mean this may still be a bug. We will test it out during we write the colab notebooks. And fix it.
> 
> I guess the bug may be related to the custom preprocessing layer we implemented for coverting the numerical features to categorical ones. That custom layer will be removed. We will use the official layers provided in tf2.2 to do the trick, which are not released yet.

thanks for your efforts, I look forward to the progress of autokeras",mean may still bug test write fix guess bug may related custom layer numerical categorical custom layer removed use official provided trick yet thanks look forward progress,issue,positive,negative,neutral,neutral,negative,negative
590032895,"I mean this may still be a bug. We will test it out during we write the colab notebooks. And fix it.

I guess the bug may be related to the custom preprocessing layer we implemented for coverting the numerical features to categorical ones. That custom layer will be removed. We will use the official layers provided in tf2.2 to do the trick, which are not released yet.",mean may still bug test write fix guess bug may related custom layer numerical categorical custom layer removed use official provided trick yet,issue,negative,negative,negative,negative,negative,negative
590032546,"> We had a new release, autokeras 1.0.2. If you use it with the latest tf-nightly. This issue should be resolved.

I have upgraded the autokeras, but still have the same problem.",new release use latest issue resolved still problem,issue,negative,positive,positive,positive,positive,positive
590032521,"10 trials is still too few for the tuner to explore the search space. That is why the learning rate didn't change during search. Greedy is tend to explore around the tried hyper parameters. We believe that would be a good strategy for hyper parameter tuning.

We are still in a stage of make autokeras 1.0 robust. Haven't fine tune the tuning algorithms yet.",still tuner explore search space learning rate change search greedy tend explore around tried hyper believe would good strategy hyper parameter tuning still stage make robust fine tune tuning yet,issue,positive,positive,positive,positive,positive,positive
590032229,"> We are trying to convert all the tutorials to colab. Making sure all the functions have a working example.

I am not sure I understand what this means in relation to this issue. Would you like the above example/bug to be posted on colab for testing? It's still not clear to me if I am doing something wrong or if this is a bug.",trying convert making sure working example sure understand relation issue would like posted testing still clear something wrong bug,issue,positive,positive,positive,positive,positive,positive
590032104,It looks like it is returning the last. Actually it is returning the best after fully training at the end of the search.,like last actually best fully training end search,issue,positive,positive,positive,positive,positive,positive
590032039,We are trying to convert all the tutorials to colab. Making sure all the functions have a working example.,trying convert making sure working example,issue,negative,positive,positive,positive,positive,positive
589909115,"The above code snippet is still broken for me. I tested on Ubuntu and Mac OS.

Package versions:
```
autokeras==1.0.2
keras-tuner==1.0.1
tf-estimator-nightly==2.1.0.dev2020022109
tf-nightly==2.2.0.dev20200218
```

Output/error:
```
WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate
WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.
2020-02-21 18:37:51.015891: W tensorflow/core/framework/op_kernel.cc:1729] OP_REQUIRES failed at cast_op.cc:123 : Unimplemented: Cast double to string is not supported
Traceback (most recent call last):
  File "".../scratch_2.py"", line 24, in <module>
    predicted_y_2 = model.predict(X_test)
  File "".../venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py"", line 919, in predict
    use_multiprocessing=use_multiprocessing)
  File "".../venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_v2.py"", line 496, in predict
    workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)
  File "".../venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_v2.py"", line 473, in _model_iteration
    total_epochs=1)
  File "".../venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_v2.py"", line 128, in run_one_epoch
    batch_outs = execution_function(iterator)
  File "".../venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_v2_utils.py"", line 98, in execution_function
    distributed_function(input_fn))
  File "".../venv/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py"", line 576, in __call__
    result = self._call(*args, **kwds)
  File "".../venv/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py"", line 646, in _call
    return self._concrete_stateful_fn._filtered_call(canon_args, canon_kwds)  # pylint: disable=protected-access
  File "".../venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 1660, in _filtered_call
    self.captured_inputs)
  File "".../venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 1741, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File "".../venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 598, in call
    ctx=ctx)
  File "".../venv/lib/python3.7/site-packages/tensorflow/python/eager/execute.py"", line 60, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.UnimplementedError:  Cast double to string is not supported
	 [[node Cast (defined at .../scratch_2.py:24) ]] [Op:__inference_distributed_function_3792]

Function call stack:
distributed_function
```
@haifeng-jin, could you test that code snippet with the above package versions and let me know if I am doing something wrong.",code snippet still broken tested mac o package dev dev warning used see specific use load status object silence use make check explicit see warning unresolved object root warning unresolved object root warning unresolved object root warning unresolved object root warning unresolved object root warning used see specific use load status object silence use make check explicit see cast double string recent call last file line module file line predict file line predict file line file line file line file line result file line return file line file line file line call file line cast double string node cast defined function call stack could test code snippet package let know something wrong,issue,negative,negative,negative,negative,negative,negative
589904454,"Would you please paste your code? I will try to see if I can reproduce the bug.
Thanks.",would please paste code try see reproduce bug thanks,issue,positive,positive,positive,positive,positive,positive
589904342,"We had a new release, autokeras 1.0.2. If you use it with the latest tf-nightly. This issue should be resolved.",new release use latest issue resolved,issue,negative,positive,positive,positive,positive,positive
589814044,"If you use autokeras==1.0.2 and the latest tf-nightly, this issue should be fixed.",use latest issue fixed,issue,negative,positive,positive,positive,positive,positive
589813268,"If you use the latest tf-nightly, there won't be this problem anymore.",use latest wo problem,issue,negative,positive,positive,positive,positive,positive
589742048,"Yes, according to my test, it is fixed.
If it is not, then I can fix it again and release it again.",yes according test fixed fix release,issue,negative,positive,neutral,neutral,positive,positive
589741323,"That is a good point!

We can use git workflow for docs, to enable the hotfixes to the docs for the released version.
We don't need to release the bleeding edge docs, if the user really would like to read, they can generate the docs locally.
So the website should be updated automatically with each release and manually when there is a hotfix to the docs.

Thanks.",good point use git enable version need release bleeding edge user really would like read generate locally automatically release manually thanks,issue,positive,positive,positive,positive,positive,positive
589738692,"It is mainly because of the search space. Now we are able to search larger but better models. There is no way to decrease the model size in AutoKeras. There may be other libraries has this feature, that you give it a large model, it gives you a smaller one. I am not sure.

Thanks.",mainly search space able search better way decrease model size may feature give large model smaller one sure thanks,issue,positive,positive,positive,positive,positive,positive
589737920,"We really cannot reproduce this error. Which OS are you running it on? Thanks.
It is highly likely you installed new version of autokeras for one interpreter, and used another interpreter to run your program which has the older version of autokeras ",really reproduce error o running thanks highly likely new version one interpreter used another interpreter run program older version,issue,negative,positive,positive,positive,positive,positive
589538521,"Same issue:
```python3
import autokeras as ak
import numpy as np
from sklearn.model_selection import train_test_split


n_points = 100
n_features = 6
n_classes = 10
X = np.random.rand(n_points, n_features)
print(X.shape, X.dtype)# random (100, 6) shaped array
y = np.random.randint(low=0, high=n_classes, size=n_points)
print(y.shape, y.dtype)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)

clf = ak.StructuredDataClassifier(max_trials=1)
clf.fit(X_train, y_train, epochs=2)
predicted_y = clf.predict(X_test)
clf.evaluate(X_test, y_test)

model = clf.export_model()
predicted_y_2 = model.predict(X_test)
```

Could this be related to #929? It seems to me like one of the pre-processors isn't being exported correctly. @haifeng-jin [mentioned](https://github.com/keras-team/autokeras/issues/929#issuecomment-580978284) that a ""new"" version, I'm not sure which version he was referring to, I tried pulling from the master and no different.",issue python import ak import import print random shaped array print model could related like one correctly new version sure version tried master different,issue,positive,positive,neutral,neutral,positive,positive
589534436,"Well, this is actually expected. `Union[Callable, Loss] ` == `Callable` since Loss is a callable. I just added the two since I believe it'd nicer to read in the code. I don't think there is anything we can do for the docs. ",well actually union callable loss callable since loss callable added two since believe read code think anything,issue,negative,neutral,neutral,neutral,neutral,neutral
589329930,"There is a project dedicated to this: https://pypi.org/project/mknotebooks/

For the moment, I believe it's better to use it directly in the autogen.py. If we see that there is a lot of boilerplate that we need to take care of, we'll integrate it into keras-autodoc with a nicer API.",project moment believe better use directly see lot need take care integrate,issue,positive,positive,positive,positive,positive,positive
589324056,"@gabrieldemarmiesse I am thinking about use python notebooks like this and convert them into markdown in autogen.py to put the website.

I would like to use python notebooks for all the tutorials.
So that people can easily run them on Colab.

On the webpage of each tutorial, there should be a button like in this one to direct people to open in colab.
Do you think we should implement this feature in keras-autodoc or just do it in autokeras autogen.py?",thinking use python like convert markdown put would like use python people easily run tutorial button like one direct people open think implement feature,issue,positive,positive,positive,positive,positive,positive
588527718,@haifeng-jin will the new release also have a fix for the bug described here: https://github.com/keras-team/autokeras/issues/946 ? Because if not then TextClassifier will still work only on 1.0.0.,new release also fix bug still work,issue,negative,positive,positive,positive,positive,positive
588352437,"error message - AttributeError: module 'autokeras' has no attribute 'Input'

Autokeras version = 1.0.1",error message module attribute version,issue,negative,neutral,neutral,neutral,neutral,neutral
588345342,@zhulingchen It is not released. We coordinated with TF team to know what features will be there. This would save us the efforts to implement those features by ourselves.,team know would save u implement,issue,negative,neutral,neutral,neutral,neutral,neutral
588342854,"> 
> 
> @zhulingchen The resume feature is supported in 1.0.0. We haven't thoroughly tested it yet.
> Unfortunately, AutoKeras 1.0.1 and future versions will only support Tensorflow 2.2 and above.
> So it doesn't fully function will the preprocessing layers in TF 2.1.

But TF 2.2 has not released yet, right?",resume feature thoroughly tested yet unfortunately future support fully function yet right,issue,negative,positive,positive,positive,positive,positive
588335340,"@zhulingchen The resume feature is supported in 1.0.0. We haven't thoroughly tested it yet.
Unfortunately, AutoKeras 1.0.1 and future versions will only support Tensorflow 2.2 and above.
So it doesn't fully function will the preprocessing layers in TF 2.1.",resume feature thoroughly tested yet unfortunately future support fully function,issue,negative,neutral,neutral,neutral,neutral,neutral
588330639,"Would you also provide the error message and your autokeras version?

Thanks",would also provide error message version thanks,issue,negative,positive,positive,positive,positive,positive
588329879,"This is mainly because we updated the framework and didn't have enough people to implement the network morphism for the new framework.
We don't have an article for the greedy yet.
",mainly framework enough people implement network new framework article greedy yet,issue,negative,positive,positive,positive,positive,positive
588328771,"Currently, we have not tested with generators yet.
I will look into this.
It seems it detected the dataset as less than 2 instances inside.
I assume it has more.

You may try providing the validation_data yourself.
It won't have this issue but may have some other errors.",currently tested yet look le inside assume may try providing wo issue may,issue,negative,neutral,neutral,neutral,neutral,neutral
588326291,"Thank you for the report.
I am working on this recently.
Will have a new release soon.",thank report working recently new release soon,issue,negative,positive,positive,positive,positive,positive
588267340,"> 
> 
> It is in our FAQ in the tutorial, but I haven't error the answer. You can use the overwrite argument of AutoModel. Just run the code again providing the same directory, it will resume.

Thanks! Is it a feature of 1.0.0 or 1.0.1? I am using 1.0.0.

Also, does AutoKeras 1.0.1 **require** TensorFlow 2.1.0? I haven't upgraded it because otherwise I need to upgrade CUDA from 10.0 to 10.1. It would be great if AutoKeras 1.0.1 works with TensorFlow 2.0.0 as well.",tutorial error answer use overwrite argument run code providing directory resume thanks feature also require otherwise need upgrade would great work well,issue,positive,positive,positive,positive,positive,positive
588024357,"> 
> 
> Please check the 0.4 version fort the implementation. Thanks
Hi, it seems, In the current version, you are using RandomSearch, Hyperband, BayesianOptimization( from kerastuner ) and Greedy as the algorithms. I have a few questions: Why is ""network morphism"" is no longer available? Compared to the other algorithms, What are the advantages of ""Greedy "" ?  Is there an article about the""Greedy "" algorithm? Thanks.
",please check version fort implementation thanks hi current version greedy network longer available greedy article greedy algorithm thanks,issue,negative,positive,positive,positive,positive,positive
587952969,I get the same fault with models fit via StructuredDataRegressor and StructuredDataClassifier,get fault fit via,issue,negative,positive,positive,positive,positive,positive
587665786,Actually the docs aren't rendered well with this. Let's put that on hold until we can build the docs with python 3.8 (next tf release I think).,actually well let put hold build python next release think,issue,negative,neutral,neutral,neutral,neutral,neutral
587611201,"I can't change the python version yet in github because typedapi doesn't support python 3.5. For the moment let's test with python 3.6, we should be able to catch more bugs than in python 3.7.",ca change python version yet support python moment let test python able catch python,issue,negative,positive,positive,positive,positive,positive
587263734,"It is in our FAQ in the tutorial, but I haven't error the answer. You can use the overwrite argument of AutoModel. Just run the code again providing the same directory, it will resume.",tutorial error answer use overwrite argument run code providing directory resume,issue,negative,neutral,neutral,neutral,neutral,neutral
587263286,Please check the 0.4 version fort the implementation. Thanks,please check version fort implementation thanks,issue,positive,positive,positive,positive,positive,positive
586665059,"I

> Normalization is not a custom object. It's a Keras layer. You don't need to add it to the custom object as long as you use tf2.1 or later.

I try to use keras kayer, and only found keras.layers.BatchNormalization, when I use this class, then system raise error: expect 3 parameters but 4 were given.",normalization custom object layer need add custom object long use later try use found use class system raise error expect given,issue,negative,negative,neutral,neutral,negative,negative
586663401,Normalization is not a custom object. It's a Keras layer. You don't need to add it to the custom object as long as you use tf2.1 or later.,normalization custom object layer need add custom object long use later,issue,negative,negative,neutral,neutral,negative,negative
586663253,"We will see if more people are looking to use this, we will add this in the FAQ section on the website.",see people looking use add section,issue,negative,neutral,neutral,neutral,neutral,neutral
586662876,"Currently, fork and modify the codebase would be the only solution. We may support customized hyper parameter as arguments later. Now user can only pass fixed values.",currently fork modify would solution may support hyper parameter later user pas fixed,issue,positive,positive,neutral,neutral,positive,positive
586585296,"I tried to find a way to perform this custom kernel sizes by replacing the code inside basic.py from line 195 with the following:
     

>    if isinstance(self.kernel_size, int):
>               kernel_size = self.kernel_size
>         elif self.kernel_size is None:
>               kernel_size = hp.Choice('kernel_size',
>                                     [3, 5, 7],
>                                     default=self.kernel_size[0])
>         else:
>               kernel_size = hp.Choice('kernel_size',
>                                     self.kernel_size,
>                                     default=self.kernel_size[0])

Is there a better or more elegant way to do it using some other classes (HyperParameter ? )?

",tried find way perform custom kernel size code inside line following none else better elegant way class,issue,negative,positive,positive,positive,positive,positive
586577638,"Hi

Thank you for your reply. I loaded the json from the trial.json file from the trial id folder, 
path = '...path_to_trial_id...'
json_file = open(path, 'r')
loaded_model_json = json_file.read()
json_file.close()

However, I am not able to call 
loaded_model=model_from_json(loaded_model)


![image](https://user-images.githubusercontent.com/39946849/74586486-76acc180-4ff0-11ea-9da4-3130df99134a.png)

The code that you provided does not work with the path or the name of the json file or the loaded_model_json. The error is:
File ""...\kerastuner\engine\tuner.py"", line 150, in load_model
    model = self.hypermodel.build(trial.hyperparameters)
AttributeError: 'str' object has no attribute 'hyperparameters'

I would be grateful if you could provide a more detailed sample code on how to load an intermediate trial model.",hi thank reply loaded file trial id folder path open path however able call image code provided work path name file error file line model object attribute would grateful could provide detailed sample code load intermediate trial model,issue,negative,positive,positive,positive,positive,positive
586473179,"@picsag Currently, we are not providing this interface. However, I assume you are an advanced user who can dive into the source code. You can do a hacking solution like this:
```python
auto_model.tuner.load_model(trial_id)
```
The trial_id can be found somewhere in the saving directory. (The name of the json file).",currently providing interface however assume advanced user dive source code hacking solution like python found somewhere saving directory name file,issue,positive,positive,positive,positive,positive,positive
586470460,@maxmarketit This might because of a big issue. I will try it. Thanks.,might big issue try thanks,issue,negative,positive,neutral,neutral,positive,positive
585787218,"I managed to find a compromise by looking into auto_model.py and observing that the AutoModel.export_model() returns a Keras model.
However if an intermediate trial is needed, is still not clear how to load the corresponding model from the saved files (.index and checkpoint).",find compromise looking observing model however intermediate trial still clear load corresponding model saved,issue,positive,positive,positive,positive,positive,positive
585590578,"I have been trying this in colab...

    %tensorflow_version 2.x  
    import autokeras as ak

    from keras.datasets import boston_housing
    (x_train, y_train), (x_test, y_test) = boston_housing.load_data()

    reg = ak.StructuredDataRegressor(max_trials=3, directory='./boston', seed=10)
    reg.fit(x_train, y_train, epochs=10)

    model = reg.export_model()
    model.predict(x_test)

model.predict takes forever!!!

",trying import ak import reg model forever,issue,negative,neutral,neutral,neutral,neutral,neutral
585559575,@seanreynoldscs  I did not find the tutorial on wrapping ImageNet into tf.data.Dataset. I believe there is a way to do so and without loading it into memory. AutoKeras currently is not supporting tensors as training data.,find tutorial wrapping believe way without loading memory currently supporting training data,issue,negative,positive,positive,positive,positive,positive
585541232,@maxmarketit Would you please paste your code to reproduce the error? Thanks,would please paste code reproduce error thanks,issue,negative,positive,positive,positive,positive,positive
585410673,"About how this work: Typeguard has a pytest plugin. This plugin will hook into all autokeras imports and run the `typechecked` decorator. 

Meaning that during the tests, every time a function with type hints is called, the arguments are checked (as opposed to the default behavior in python, where type hints do nothing).

If the type hints are wrong, here is the result: https://github.com/keras-team/autokeras/runs/440879952",work hook run decorator meaning every time function type checked opposed default behavior python type nothing type wrong result,issue,negative,negative,negative,negative,negative,negative
585170168,"I reinstalled tensorflow and autokeras and ran it again.

Another error occurred while executing the code.

The full error log is shown below.
2020-02-12 20:43:47.329690: W tensorflow/core/framework/op_kernel.cc:1655] OP_REQUIRES failed at save_restore_v2_ops.cc:220 : Unknown: Failed to rename: .\auto_model\trial_d052e73d00eb40d2f1a00d4a472a874c\checkpoints\epoch_0\checkpoint_temp_43c9929389a54f28958954228a55ace5/part-00001-of-00002.data-00000-of-00001 to: .\auto_model\trial_d052e73d00eb40d2f1a00d4a472a874c\checkpoints\epoch_0\checkpoint.data-00001-of-00002 : �׼����� �źεǾ����ϴ�.
; Input/output error
Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\ops\gen_io_ops.py"", line 493, in merge_v2_checkpoints
    ""delete_old_dirs"", delete_old_dirs)
tensorflow.python.eager.core._FallbackException: This function does not handle the case of the path where all inputs are not already EagerTensors.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""D:/joo/Tensorflow Projects/AutoML/autokeras_customized_model.py"", line 38, in <module>
    auto_model.fit(x_train, y_train, epochs=300)
  File ""C:\ProgramData\Anaconda3\envs\tensorflow\lib\site-packages\autokeras\auto_model.py"", line 250, in fit
    **kwargs)
  File ""C:\ProgramData\Anaconda3\envs\tensorflow\lib\site-packages\autokeras\engine\tuner.py"", line 132, in search
    super().search(callbacks=new_callbacks, **fit_kwargs)
  File ""C:\ProgramData\Anaconda3\envs\tensorflow\lib\site-packages\kerastuner\engine\base_tuner.py"", line 130, in search
    self.run_trial(trial, *fit_args, **fit_kwargs)
  File ""C:\ProgramData\Anaconda3\envs\tensorflow\lib\site-packages\autokeras\engine\tuner.py"", line 91, in run_trial
    history = model.fit(x, *fit_args, **copied_fit_kwargs)
  File ""C:\ProgramData\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\keras\engine\training.py"", line 819, in fit
    use_multiprocessing=use_multiprocessing)
  File ""C:\ProgramData\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py"", line 397, in fit
    prefix='val_')
  File ""C:\ProgramData\Anaconda3\envs\tensorflow\lib\contextlib.py"", line 88, in __exit__
    next(self.gen)
  File ""C:\ProgramData\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py"", line 771, in on_epoch
    self.callbacks.on_epoch_end(epoch, epoch_logs)
  File ""C:\ProgramData\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\keras\callbacks.py"", line 302, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File ""C:\ProgramData\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\keras\callbacks.py"", line 992, in on_epoch_end
    self._save_model(epoch=epoch, logs=logs)
  File ""C:\ProgramData\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\keras\callbacks.py"", line 1027, in _save_model
    self.model.save_weights(filepath, overwrite=True)
  File ""C:\ProgramData\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\keras\engine\network.py"", line 1123, in save_weights
    self._trackable_saver.save(filepath, session=session)
  File ""C:\ProgramData\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\training\tracking\util.py"", line 1168, in save
    file_prefix=file_prefix_tensor, object_graph_tensor=object_graph_tensor)
  File ""C:\ProgramData\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\training\tracking\util.py"", line 1116, in _save_cached_when_graph_building
    save_op = saver.save(file_prefix)
  File ""C:\ProgramData\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\training\saving\functional_saver.py"", line 238, in save
    sharded_prefixes, file_prefix, delete_old_dirs=True)
  File ""C:\ProgramData\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\ops\gen_io_ops.py"", line 499, in merge_v2_checkpoints
    delete_old_dirs=delete_old_dirs, name=name, ctx=_ctx)
  File ""C:\ProgramData\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\ops\gen_io_ops.py"", line 525, in merge_v2_checkpoints_eager_fallback
    attrs=_attrs, ctx=ctx, name=name)
  File ""C:\ProgramData\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\eager\execute.py"", line 61, in quick_execute
    num_outputs)
**UnicodeDecodeError: 'utf-8' codec can't decode byte 0xbe in position 288: invalid start byte**

There seems to be a problem with storing the model.
Could you tell me where to fix it?",ran another error code full error log shown unknown rename error recent call last file line function handle case path already handling exception another exception recent call last file line module file line fit file line search super file line search trial file line history file line fit file line fit file line next file line epoch file line epoch file line file line file line file line save file line file line save file line file line file line ca decode position invalid start problem model could tell fix,issue,positive,positive,positive,positive,positive,positive
585081572,"Do not merge, I need to add a test to ensure the types are correct.",merge need add test ensure correct,issue,negative,neutral,neutral,neutral,neutral,neutral
584990758,"@dzimmerman-nci Thank you for the work solution! Hope tf would release this ""fit to adapt"" feature soon.",thank work solution hope would release fit adapt feature soon,issue,positive,positive,positive,positive,positive,positive
584989760,"@fucker007 
This is not the right data for text input. Currently, we are only supporting natural language like inputs to TextInput.
The separate character between words should be spaces.
Otherwise, it might not work.
",right data text input currently supporting natural language like separate character otherwise might work,issue,positive,positive,positive,positive,positive,positive
584812904,"@haifeng-jin it seems the only way to get it to work is if I retrain the exported Keras model after adapting the TextVectorization layer like this:

```
auto_keras_model = ak.TextClassifier(max_trials=3)
auto_keras_model.fit(x_train, y_train)
keras_model = auto_keras_model.export_model()
text_vectorization_layer = keras_model.layers[1]
text_vectorization_layer.adapt(x_train)
keras_model.fit(x_train, y_train)
print(keras_model.evaluate(x_test, y_test))
```

If I exclude the `keras_model.fit(x_train, y_train)` line, I get the same results as I do when I do not adapt the TextVectorization layer.",way get work retrain model layer like print exclude line get adapt layer,issue,negative,neutral,neutral,neutral,neutral,neutral
584726962,+10. Can't believe that there aren't any people interested in this application to time series!,ca believe people interested application time series,issue,negative,positive,positive,positive,positive,positive
584601290,"Same issue here, with some custom code, is there any way to fix it?",issue custom code way fix,issue,negative,neutral,neutral,neutral,neutral,neutral
584461673,"```python
#!/usr/bin/env python
# coding: utf-8
import autokeras as ak
from autokeras import TextClassifier
import csv
import numpy as np
import pandas as pd
import matplotlib
import os
clf = TextClassifier()#获取分类器
data_path = ""../data2/"" #数据存储的路径
data = pd.DataFrame() #数据存储的位置
csvFile = open(""data2/total.csv"",""r"",encoding='utf-8')
df_ = pd.read_csv(csvFile)
data = data.append(df_)
y_train = data[""ItemName""].values  
data['Length'],data['Depth'],data['Height'],data['Volume'],data['Surface'] = data['Length'].astype('str'),data['Depth'].astype('str'),data['Height'].astype('str'),data['Volume'].astype('str'),data['Surface'].astype('str')
x_train = data[""ElementName""].str.cat([
    data['FamilyName'],
    data['CategoryName'],
    data['Length'],
    data['Depth'],
    data['Height'],
    data['Volume'],
    data['Surface']],
    sep='_')  #行拼接
x_train = np.array(x_train ,dtype=np.str)
# print(x_train)  #array，每個元素為每行中幾個屬性拼接起來的字符串
# print(x_train[1]) #工法桩 850mm_混凝土-圆形-柱_结构柱_2.7887139107610888_2.7791890388965257_78.41207349081365_607.7220435970835_888.682356823353

# y_train[12000] #'钻孔灌注桩立柱桩'
# type(y_train[12000]) #str
y_train = np.array(y_train ,dtype=np.str)
# y_train[12000] #'钻孔灌注桩立柱桩'
# type(y_train[12000]) #numpy.str_


print(x_train.shape,y_train.shape) #(12955,) (12955, 1)
x_train,y_train = x_train.reshape(-1),y_train.reshape(-1,1)#-1是模糊控制的意思 比如人reshape（-1,2）固定2列 多少行不知道
#reshape獲取可以省略
print(x_train.shape,y_train.shape) # (12955,) (12955, 1)

#第二步将数据加入模型
import autokeras as ak
input_node = ak.TextInput()
output_node = ak.TextBlock(vectorizer='ngram')(input_node)
output_node = ak.ClassificationHead()(output_node)
clf = ak.AutoModel(inputs=input_node, outputs=output_node, max_trials=10)
clf.fit(x_train, y_train,verbose=1)
#第三步保存查看模型层次
clf.export_model()
```
@haifeng-jin this is my code",python python import ak import import import import import import o data open data data data data data data data data data data data data data data data data data data data data print print type type print print import ak code,issue,negative,neutral,neutral,neutral,neutral,neutral
584298714,So AutoKeras also does this when searching for the best model architecture? That layer is just not saved properly after the AutoKeras fit method?,also searching best model architecture layer saved properly fit method,issue,positive,positive,positive,positive,positive,positive
584236073,"@rakshanda22 Yes.
```
pip3 uninstall autokeras
pip3 install autokeras==1.0.0
```",yes pip pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
584234794,"So is there a way to drop down to autokeras 1.0.0?

Also another workaround could be to use this instead of text classification.

input_node = ak.TextInput()
output_node = ak.TextBlock(vectorizer='ngram')(input_node)
output_node = ak.ClassificationHead()(output_node)
clf = ak.AutoModel(inputs=input_node, outputs=output_node, max_trials=10)
clf.fit(x_train, y_train)",way drop also another could use instead text classification,issue,negative,neutral,neutral,neutral,neutral,neutral
584233813,"@johny-b If so, it must be the text vectorization layer.
We didn't use it in 1.0.0 and use it in 1.0.1.

It's weights cannot be saved for now.
When the tuner loads it for eval and predict, it doesn't work.

https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/keras/layers/preprocessing/text_vectorization.py#L290

Hopefully, it can be saved with TF 2.2.
I will confirm with the tensorflow team. If not, we may try to do a walk around.",must text layer use use saved tuner predict work hopefully saved confirm team may try walk around,issue,positive,neutral,neutral,neutral,neutral,neutral
584232116,"@dzimmerman-nci  No retraining is needed. You only need to adapt the preprocessing layer, i.e., text_vectorization with the training data. The `adapt` function is the `fit` function for preprocessing layers. They currently cannot be fit with the model's fit function, but need to be adapt separate.

example here:
https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/TextVectorization",need adapt layer training data adapt function fit function currently fit model fit function need adapt separate example,issue,positive,positive,positive,positive,positive,positive
584230273,@fucker007 Would you paste your code for reproducing this bug? Thanks.,would paste code bug thanks,issue,negative,positive,positive,positive,positive,positive
584163405,"Thanks for the help @haifeng-jin. To clarify, do I need to retrain the Keras model after running the Auto-Keras fit? Or do I only need to adapt the test data X values to the exported Keras model to run inference?",thanks help clarify need retrain model running fit need adapt test data model run inference,issue,positive,positive,positive,positive,positive,positive
583951123,"1

#第三步保存查看模型层次

2

clf.export_model()

WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x000001A755E62DA0> and <tensorflow.python.keras.layers.core.Dense object at 0x000001A761126940>).

WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x000001A755E62DA0> and <tensorflow.python.keras.layers.core.Dense object at 0x000001A761126940>).

WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x000001A761126940> and <tensorflow.python.keras.layers.advanced_activations.Softmax object at 0x000001A75F4DD630>).

WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x000001A761126940> and <tensorflow.python.keras.layers.advanced_activations.Softmax object at 0x000001A75F4DD630>).

---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-9-d4c056555dc8> in <module>
      1 #第三步保存查看模型层次
----> 2 clf.export_model()

D:\anaconda\envs\ak1.0\lib\site-packages\autokeras\auto_model.py in export_model(self)
    373             with trained weights.
    374         """"""
--> 375         return self.tuner.get_best_model()

D:\anaconda\envs\ak1.0\lib\site-packages\autokeras\engine\tuner.py in get_best_model(self)
     35 
     36     def get_best_model(self):
---> 37         model = super().get_best_models()[0]
     38         model.load_weights(self.best_model_path)
     39         return model

D:\anaconda\envs\ak1.0\lib\site-packages\kerastuner\engine\tuner.py in get_best_models(self, num_models)
    229         """"""
    230         # Method only exists in this class for the docstring override.
--> 231         return super(Tuner, self).get_best_models(num_models)
    232 
    233     def _deepcopy_callbacks(self, callbacks):

D:\anaconda\envs\ak1.0\lib\site-packages\kerastuner\engine\base_tuner.py in get_best_models(self, num_models)
    236         """"""
    237         best_trials = self.oracle.get_best_trials(num_models)
--> 238         models = [self.load_model(trial) for trial in best_trials]
    239         return models
    240 

D:\anaconda\envs\ak1.0\lib\site-packages\kerastuner\engine\base_tuner.py in <listcomp>(.0)
    236         """"""
    237         best_trials = self.oracle.get_best_trials(num_models)
--> 238         models = [self.load_model(trial) for trial in best_trials]
    239         return models
    240 

D:\anaconda\envs\ak1.0\lib\site-packages\kerastuner\engine\tuner.py in load_model(self, trial)
    155         with hm_module.maybe_distribute(self.distribution_strategy):
    156             model.load_weights(self._get_checkpoint_fname(
--> 157                 trial.trial_id, best_epoch))
    158         return model
    159 

D:\anaconda\envs\ak1.0\lib\site-packages\tensorflow_core\python\keras\engine\training.py in load_weights(self, filepath, by_name, skip_mismatch)
    232         raise ValueError('Load weights is not yet supported with TPUStrategy '
    233                          'with steps_per_run greater than 1.')
--> 234     return super(Model, self).load_weights(filepath, by_name, skip_mismatch)
    235 
    236   @trackable.no_automatic_dependency_tracking

D:\anaconda\envs\ak1.0\lib\site-packages\tensorflow_core\python\keras\engine\network.py in load_weights(self, filepath, by_name, skip_mismatch)
   1191         save_format = 'h5'
   1192     if save_format == 'tf':
-> 1193       status = self._trackable_saver.restore(filepath)
   1194       if by_name:
   1195         raise NotImplementedError(

D:\anaconda\envs\ak1.0\lib\site-packages\tensorflow_core\python\training\tracking\util.py in restore(self, save_path)
   1281         graph_view=self._graph_view)
   1282     base.CheckpointPosition(
-> 1283         checkpoint=checkpoint, proto_id=0).restore(self._graph_view.root)
   1284     load_status = CheckpointLoadStatus(
   1285         checkpoint,

D:\anaconda\envs\ak1.0\lib\site-packages\tensorflow_core\python\training\tracking\base.py in restore(self, trackable)
    207         # This object's correspondence with a checkpointed object is new, so
    208         # process deferred restorations for it and its dependencies.
--> 209         restore_ops = trackable._restore_from_checkpoint_position(self)  # pylint: disable=protected-access
    210         if restore_ops:
    211           self._checkpoint.new_restore_ops(restore_ops)

D:\anaconda\envs\ak1.0\lib\site-packages\tensorflow_core\python\training\tracking\base.py in _restore_from_checkpoint_position(self, checkpoint_position)
    906     restore_ops.extend(
    907         current_position.checkpoint.restore_saveables(
--> 908             tensor_saveables, python_saveables))
    909     return restore_ops
    910 

D:\anaconda\envs\ak1.0\lib\site-packages\tensorflow_core\python\training\tracking\util.py in restore_saveables(self, tensor_saveables, python_saveables)
    287              ""expecting %s"") % (tensor_saveables.keys(), validated_names))
    288       new_restore_ops = functional_saver.MultiDeviceSaver(
--> 289           validated_saveables).restore(self.save_path_tensor)
    290       if not context.executing_eagerly():
    291         for name, restore_op in sorted(new_restore_ops.items()):

D:\anaconda\envs\ak1.0\lib\site-packages\tensorflow_core\python\training\saving\functional_saver.py in restore(self, file_prefix)
    253     for device, saver in sorted(self._single_device_savers.items()):
    254       with ops.device(device):
--> 255         restore_ops.update(saver.restore(file_prefix))
    256     return restore_ops

D:\anaconda\envs\ak1.0\lib\site-packages\tensorflow_core\python\training\saving\functional_saver.py in restore(self, file_prefix)
    100                                           structured_restored_tensors):
    101       restore_ops[saveable.name] = saveable.restore(
--> 102           restored_tensors, restored_shapes=None)
    103     return restore_ops
    104 

D:\anaconda\envs\ak1.0\lib\site-packages\tensorflow_core\python\training\saving\saveable_object_util.py in restore(self, restored_tensors, restored_shapes)
    114       restored_tensor = array_ops.identity(restored_tensor)
    115       return resource_variable_ops.shape_safe_assign_variable_handle(
--> 116           self.handle_op, self._var_shape, restored_tensor)
    117 
    118 

D:\anaconda\envs\ak1.0\lib\site-packages\tensorflow_core\python\ops\resource_variable_ops.py in shape_safe_assign_variable_handle(handle, shape, value, name)
    295   with _handle_graph(handle):
    296     value_tensor = ops.convert_to_tensor(value)
--> 297   shape.assert_is_compatible_with(value_tensor.shape)
    298   return gen_resource_variable_ops.assign_variable_op(handle,
    299                                                       value_tensor,

D:\anaconda\envs\ak1.0\lib\site-packages\tensorflow_core\python\framework\tensor_shape.py in assert_is_compatible_with(self, other)
   1108     """"""
   1109     if not self.is_compatible_with(other):
-> 1110       raise ValueError(""Shapes %s and %s are incompatible"" % (self, other))
   1111 
   1112   def most_specific_compatible_shape(self, other):

ValueError: Shapes (20000, 32) and (32, 32) are incompatible

I use clf.export_model() , wrong, help @haifeng-jin ",warning inconsistent loading object graph either trackable object python program incompatible way incompatible program two resolved different object object warning inconsistent loading object graph either trackable object python program incompatible way incompatible program two resolved different object object warning inconsistent loading object graph either trackable object python program incompatible way incompatible program two resolved different object object warning inconsistent loading object graph either trackable object python program incompatible way incompatible program two resolved different object object recent call last module self trained return self self model super return model self method class override return super tuner self self self trial trial return trial trial return self trial return model self raise yet greater return super model self self status raise restore self restore self trackable object correspondence object new process deferred self self return self name sorted restore self device saver sorted device return restore self return restore self return handle shape value name handle value return handle self raise incompatible self self incompatible use wrong help,issue,positive,positive,neutral,neutral,positive,positive
583892762,"Thanks @haifeng-jin . If we start having other public modules, we just need to add them to the list of modules to check :)",thanks start public need add list check,issue,negative,positive,neutral,neutral,positive,positive
583892280,"@gabrieldemarmiesse Let's do the pre-commit docker. Thank you!

Yes, all the public APIs are in __init__.py since we don't have much.
It might change in the future if the API is becoming heavy.",let docker thank yes public since much might change future becoming heavy,issue,positive,positive,neutral,neutral,positive,positive
583891794,"> I assumed that all the functions/classes in the autokeras public API were in autokeras/__init__.py . Is that true or are them some of them somewhere else?

Ping about this question :)",assumed public true somewhere else ping question,issue,negative,positive,positive,positive,positive,positive
583891413,"Not really. You can try it out by cloning tensorflow/addons if you want. There are two steps, first it builds the image with the tools in it, then runs the container to do all the formatting.

The first step takes ~3m in my computer the first time, then 0.2 seconds the second time (because of the docker cache)
The second step takes as long as using normal tools without docker. In our case 2-3 seconds since we have bazel format, clang-format, black and flake8 (soon isort too).

Starting from the second time, it's pretty much as fast as without docker.
If you want I can make a PR, you can clone and see for yourself if you're satisfied with the speed.",really try want two first image container first step computer first time second time docker cache second step long normal without docker case since format black flake soon starting second time pretty much fast without docker want make clone see satisfied speed,issue,positive,positive,positive,positive,positive,positive
583890994,"@gabrieldemarmiesse So this pre-commit.sh will be executed before each commit, right? If it is done with docker will it be very slow to make the commits?",executed commit right done docker slow make,issue,negative,negative,neutral,neutral,negative,negative
583890481,"@haifeng-jin thanks for the answer. In tensorflow/addons, we provide a pre-commit running with docker to ensure that it will always work for our users and stay up to date. Would that be something you'd like me to work on in autokeras? See https://github.com/tensorflow/addons/blob/master/tools/pre-commit.sh ",thanks answer provide running docker ensure always work stay date would something like work see,issue,positive,positive,positive,positive,positive,positive
583889457,"@gabrieldemarmiesse To use isort locally you need to pip uninstall autokeras and add the repo path to the python path so that isort won't treat autokeras as a third party lib installed from pypi, but the local import.",use locally need pip add path python path wo treat third party local import,issue,positive,neutral,neutral,neutral,neutral,neutral
583860511,"I noticed the same.

Also:
* all is well on autokeras 1.0.0, bug is only on 1.0.1
* works just as bad on other text datasets

I'm using Ubuntu 18.04 and tensorflow 2.1.0",also well bug work bad text,issue,negative,negative,negative,negative,negative,negative
583783267,"This one is resolved for the latest version.
Please refer to the tutorial about export model for details.

https://autokeras.com/tutorial/export/",one resolved latest version please refer tutorial export model,issue,negative,positive,positive,positive,positive,positive
583780068,We're going to have a nice TODO list with https://github.com/tensorflow/addons/pull/1051 . Then we'll be able to track easily what's left and we'll avoid regressions with it.,going nice list able track easily left avoid,issue,negative,positive,positive,positive,positive,positive
583759173,"Thank you so much, that worked.
So in summary to get everything working for me we did the following:

```
input_node = ak.ImageInput()
output_node = ak.ClassificationHead()
clf = ak.AutoModel(inputs=input_node, outputs=output_node, max_trials=10)
```
to export:
```
model = clf.export_model()
model.save(modelLocation)
```

and when loading: 
`exposureModel = load_model(exposureModelPath, custom_objects=ak. CUSTOM_OBJECTS)
`",thank much worked summary get everything working following export model loading,issue,negative,positive,neutral,neutral,positive,positive
583743396,"@seanreyboldscs 
You will need the following line.
```python
load_model (custom_objects=ak. CUSTOM_OBJECTS)
```
Thanks.

Anyone would like to update it in the documentation to include the load model tutorial in
/docs/templates/tutorial/export.md

?",need following line python thanks anyone would like update documentation include load model tutorial,issue,positive,positive,neutral,neutral,positive,positive
583723695,"Okay this worked for keeping the model trained:
input_node = ak.ImageInput()
output_node = ak.ClassificationHead()
clf = ak.AutoModel(inputs=input_node, outputs=output_node, max_trials=10)

I'm still having trouble loading the model with keras, now I'm getting: 
ValueError: Unknown layer: Sigmoid

I noticed that the last two layers of my trained network are: 
dense (Dense)                (None, 1)                 33        
classification_head_1 (Sigmo (None, 1)                 0      

I thought it was a little odd that they are both size (None, 1)

",worked keeping model trained still trouble loading model getting unknown layer sigmoid last two trained network dense dense none none thought little odd size none,issue,negative,negative,negative,negative,negative,negative
583713100,"Also when I try to use this model by calling: 
keras_model = clf.export_model()
and 
keras_model.save(modelLocation)

When I try to import this model using:
exposureModel = load_model(exposureModelPath)

I get this error:
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-5-c1d97e7cc4ac> in <module>
     13 # load the trained convolutional neural network
     14 print(""[INFO] Exposure network..."")
---> 15 exposureModel = load_model(exposureModelPath)

~\Anaconda3\envs\tf2\lib\site-packages\tensorflow_core\python\keras\saving\save.py in load_model(filepath, custom_objects, compile)
    144   if (h5py is not None and (
    145       isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):
--> 146     return hdf5_format.load_model_from_hdf5(filepath, custom_objects, compile)
    147 
    148   if isinstance(filepath, six.string_types):

~\Anaconda3\envs\tf2\lib\site-packages\tensorflow_core\python\keras\saving\hdf5_format.py in load_model_from_hdf5(filepath, custom_objects, compile)
    166     model_config = json.loads(model_config.decode('utf-8'))
    167     model = model_config_lib.model_from_config(model_config,
--> 168                                                custom_objects=custom_objects)
    169 
    170     # set weights

~\Anaconda3\envs\tf2\lib\site-packages\tensorflow_core\python\keras\saving\model_config.py in model_from_config(config, custom_objects)
     53                     '`Sequential.from_config(config)`?')
     54   from tensorflow.python.keras.layers import deserialize  # pylint: disable=g-import-not-at-top
---> 55   return deserialize(config, custom_objects=custom_objects)
     56 
     57 

~\Anaconda3\envs\tf2\lib\site-packages\tensorflow_core\python\keras\layers\serialization.py in deserialize(config, custom_objects)
    104       module_objects=globs,
    105       custom_objects=custom_objects,
--> 106       printable_module_name='layer')

~\Anaconda3\envs\tf2\lib\site-packages\tensorflow_core\python\keras\utils\generic_utils.py in deserialize_keras_object(identifier, module_objects, custom_objects, printable_module_name)
    301             custom_objects=dict(
    302                 list(_GLOBAL_CUSTOM_OBJECTS.items()) +
--> 303                 list(custom_objects.items())))
    304       with CustomObjectScope(custom_objects):
    305         return cls.from_config(cls_config)

~\Anaconda3\envs\tf2\lib\site-packages\tensorflow_core\python\keras\engine\network.py in from_config(cls, config, custom_objects)
    935     """"""
    936     input_tensors, output_tensors, created_layers = reconstruct_from_config(
--> 937         config, custom_objects)
    938     model = cls(inputs=input_tensors, outputs=output_tensors,
    939                 name=config.get('name'))

~\Anaconda3\envs\tf2\lib\site-packages\tensorflow_core\python\keras\engine\network.py in reconstruct_from_config(config, custom_objects, created_layers)
   1891   # First, we create all layers and enqueue nodes to be processed
   1892   for layer_data in config['layers']:
-> 1893     process_layer(layer_data)
   1894   # Then we process nodes in order of layer depth.
   1895   # Nodes that cannot yet be processed (if the inbound node

~\Anaconda3\envs\tf2\lib\site-packages\tensorflow_core\python\keras\engine\network.py in process_layer(layer_data)
   1873       from tensorflow.python.keras.layers import deserialize as deserialize_layer  # pylint: disable=g-import-not-at-top
   1874 
-> 1875       layer = deserialize_layer(layer_data, custom_objects=custom_objects)
   1876       created_layers[layer_name] = layer
   1877 

~\Anaconda3\envs\tf2\lib\site-packages\tensorflow_core\python\keras\layers\serialization.py in deserialize(config, custom_objects)
    104       module_objects=globs,
    105       custom_objects=custom_objects,
--> 106       printable_module_name='layer')

~\Anaconda3\envs\tf2\lib\site-packages\tensorflow_core\python\keras\utils\generic_utils.py in deserialize_keras_object(identifier, module_objects, custom_objects, printable_module_name)
    290     config = identifier
    291     (cls, cls_config) = class_and_config_for_serialized_keras_object(
--> 292         config, module_objects, custom_objects, printable_module_name)
    293 
    294     if hasattr(cls, 'from_config'):

~\Anaconda3\envs\tf2\lib\site-packages\tensorflow_core\python\keras\utils\generic_utils.py in class_and_config_for_serialized_keras_object(config, module_objects, custom_objects, printable_module_name)
    248     cls = module_objects.get(class_name)
    249     if cls is None:
--> 250       raise ValueError('Unknown ' + printable_module_name + ': ' + class_name)
    251 
    252   cls_config = config['config']

ValueError: Unknown layer: Normalization
",also try use model calling try import model get error recent call last module load trained convolutional neural network print exposure network compile none return compile compile model set import return identifier list list return model first create process order layer depth yet inbound node import layer layer identifier identifier none raise unknown layer normalization,issue,negative,positive,neutral,neutral,positive,positive
583711903,"During training I see the results include a couple trials with very good results such as: 
10/10 [==============================] - ETA: 0s - loss: 0.0979 - accuracy: 0.96 - 0s 6ms/step - loss: 0.0501 - accuracy: 0.9869 - val_loss: 0.0636 - val_accuracy: 0.9868

However the last evaluated result is: Epoch 449/1000
13/13 [==============================] - ETA: 0s - loss: 0.6730 - accuracy: 0.62 - ETA: 0s - loss: 0.6965 - accuracy: 0.50 - 0s 11ms/step - loss: 0.6882 - accuracy: 0.5407 - val_loss: 0.6688 - val_accuracy: 0.6184

After calling the fit function when I evaluate the model I get the results that are much closer to the poor results at the end, and dont represent the best results during training: 
print(clf.evaluate(testX, testY))
shows:
4/4 [==============================] - ETA: 0s - loss: 0.7171 - accuracy: 0.40 - 0s 25ms/step - loss: 0.6935 - accuracy: 0.5234
[0.6934990286827087, 0.5234375]

Which seems really crappy considering there was very good convergence during training.
As an aside, the data I'm classifying converges very easy with a simple LeNet or MobileNet design. It's not MNIST, but it is a softball I was tossing AUTOKERAS so that I could evaluate the tool.",training see include couple good eta loss accuracy loss accuracy however last result epoch eta loss accuracy eta loss accuracy loss accuracy calling fit function evaluate model get much closer poor end dont represent best training print testy eta loss accuracy loss accuracy really considering good convergence training aside data easy simple design softball tossing could evaluate tool,issue,negative,positive,positive,positive,positive,positive
583697380,"Hi, it's my understanding that final_fit() has been removed and its functionality is now included in fit().  I think you can remove that final_fit() line and it should be okay.",hi understanding removed functionality included fit think remove line,issue,negative,positive,positive,positive,positive,positive
583618793,"Is there a more stable version I should be using? I'm very new to this, I've only been using Sage Maker and Google Cloud AutoML.",stable version new sage maker cloud,issue,negative,positive,positive,positive,positive,positive
583087820,"@dzimmerman-nci It seems caused by the text vectorization. It does not support saving.
https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/keras/layers/preprocessing/text_vectorization.py#L290
I believe this will be fixed by the next release of Tensorflow.
For the a walk around would be export the model and adapt the layer yourself.
```python
keras_model = auto_model.export_model()
text_vectorization_layer = keras_model.layers[1]  # may be other layers, you can print keras_model.layers to see
text_vectorization_layer.adapt(dataset)  # dataset only contain x, no y.
```
Then the `keras_model` can be used as normal.
Let me know if it doesn't work.",text support saving believe fixed next release walk around would export model adapt layer python may print see contain used normal let know work,issue,negative,positive,neutral,neutral,positive,positive
582560758,"@jcrodriguez1989 Yeah, I will add it to the documentation later today. Thx

@kevinkit We are actually using the tf.keras (Keras inside TensorFlow package) instead of the standalone Keras.
So you don't need to worry about the installation of Keras as long as you installed the correct version of TensorFlow. Thx",yeah add documentation later today actually inside package instead need worry installation long correct version,issue,negative,negative,neutral,neutral,negative,negative
582516209,"Thank you very much for that information and fast reply - is there a version requirement for Keras, too?",thank much information fast reply version requirement,issue,negative,positive,positive,positive,positive,positive
582511289,"Hi @kevinkit , the minimum tensorflow requirement is 2.1.0 .
It would be great if this requirement could be documented.",hi minimum requirement would great requirement could,issue,positive,positive,positive,positive,positive,positive
582086430,"@zhulingchen BTW, if you would like to receive all the info about AutoKeras, you can join our Slack.
https://autokeras.com/#community
I saw you are very active in helping us answering questions on GitHub. Really appreciate.
",would like receive join slack saw active helping u really appreciate,issue,positive,positive,neutral,neutral,positive,positive
582083357,"@zhulingchen Yes, but you need to use the AutoModel API, with the ImageBlock(augment=False, normalize=False). 
You can just work on 1.0.1 with this trick.

https://autokeras.com/block/#imageblock-class

https://autokeras.com/tutorial/image_classification/#customized-search-space",yes need use work trick,issue,negative,neutral,neutral,neutral,neutral,neutral
582081618,"hi @albert-92 @abhisingh007224 , I really cannot reproduce this error. Maybe it is related to the conda environment?

Would you please run the following script with the same python interpreter and paste the output here?
Thank you for your help!

```python
import sys
print(sys.version)
import pkg_resources
pkg_resources.get_distribution(""autokeras"").version
import autokeras
print(autokeras.__dict__)
```",hi really reproduce error maybe related environment would please run following script python interpreter paste output thank help python import print import import print,issue,positive,positive,neutral,neutral,positive,positive
581951470,But in Mac it is still showing error,mac still showing error,issue,negative,neutral,neutral,neutral,neutral,neutral
581929629,"I'm getting the same error `AttributeError: module 'autokeras' has no attribute 'ImageClassifier'` on Ubuntu 18.04.

On Windows 10 it works just fine.

I tried `pip3 install autokeras` and `python3 -m pip install autokeras`.
",getting error module attribute work fine tried pip install python pip install,issue,negative,positive,positive,positive,positive,positive
581624179,"Speaking of this, Haifeng, if I am comfortable with doing all preprocessing
myself like what I said above, I can still keep working on AutoKeras 1.0.0 ?

On Mon, Feb 3, 2020 at 3:35 PM Haifeng Jin <notifications@github.com> wrote:

> @jcrodriguez1989 <https://github.com/jcrodriguez1989> TF has to be at
> least 2.1.0. You may also try the latest tf-nightly. Only 2.1 and above
> support exporting the preprocessors we use. It is a new feature of tf to
> make preprocessor as part of a keras model.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/keras-team/autokeras/issues/929?email_source=notifications&email_token=AAQCDDARPS2INZBOG3L3JZ3RBB5XXA5CNFSM4KMW3HFKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEKVJTNI#issuecomment-581605813>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AAQCDDGJJD2NTRFFJ47J7HLRBB5XXANCNFSM4KMW3HFA>
> .
>
-- 
Best regards,

----------------------------------------------------------------------
Dr. Lingchen Zhu

Research Scientist
Schlumberger-Doll Research
1 Hampshire Street
Cambridge, MA 02139
----------------------------------------------------------------------
Tel: +1-617-768-2087 <%28617%29%20768-2087>
​Cell: +1-678-772-2209 <%28678%29%20772-2209>​
Email: lzhu14@slb.com
Email: ​zhulingchen@gmail.com​
",speaking comfortable like said still keep working mon wrote least may also try latest support use new feature make part model reply directly view best research scientist research street,issue,positive,positive,positive,positive,positive,positive
581605813,@jcrodriguez1989 TF has to be at least 2.1.0. You may also try the latest tf-nightly. Only 2.1 and above support exporting the preprocessors we use. It is a new feature of tf to make preprocessor as part of a keras model.,least may also try latest support use new feature make part model,issue,negative,positive,positive,positive,positive,positive
581584001,"@haifeng-jin great work!
However, I'm still getting the same error.
I have:

```python
>>> pkg_resources.get_distribution(""autokeras"").version
'1.0.1'
>>> pkg_resources.get_distribution(""tensorflow"").version
'2.1.0'
```

By the way, which is the tensorflow recommended version? I was getting other issues with tf 2.0.0
",great work however still getting error python way version getting,issue,negative,positive,positive,positive,positive,positive
580978284,"@jcrodriguez1989 We just released a new version, which is able to export all the preprocessors, e.g., normalization. You may try again with the new version. Thank you!",new version able export normalization may try new version thank,issue,negative,positive,positive,positive,positive,positive
580826782,"> 
> 
> Hi @zhulingchen ,
> expanding dimension gets another error:
> 
> ```python
> import numpy as np
> x_test_exp = np.expand_dims(x_test, 3)
> x_test.shape # (1000, 28, 28)
> x_test_exp.shape # (1000, 28, 28, 1)
> predicted_y_2 = model.predict(x_test_exp)
> ```
> 
> ```
> # TypeError: Value passed to parameter 'input' has DataType uint8 not in list of allowed values: float16, bfloat16, float32, float64
> ```
> 
> However, my intention is not to make this particular example work, I was wondering if `export_model` could get fixed.
> thanks you very much for your help! :)

I think you need to first add the last size-1 dimension to `x_train`, convert `x_train` from `uint8` to `float32`, and then normalize them to [0, 1] like `x_train = x_train / 255.0`, and do the same thing to `x_test`;

and then redo your AutoKeras train `clf.fit(x_train, y_train, epochs=3)`, and then export the best Keras model with `model = clf.export_model()`, and then do the prediction with `predicted_y_2 = model.predict(x_test)` on the normalized `x_test`.

That's all the regular operations when you work with TensorFlow/Keras.",hi expanding dimension another error python import value parameter list float float float however intention make particular example work wondering could get fixed thanks much help think need first add last dimension convert float normalize like thing redo train export best model model prediction regular work,issue,positive,positive,positive,positive,positive,positive
580819368,"Hi @zhulingchen ,
expanding dimension gets another error:

```python
import numpy as np
x_test_exp = np.expand_dims(x_test, 3)
x_test.shape # (1000, 28, 28)
x_test_exp.shape # (1000, 28, 28, 1)
predicted_y_2 = model.predict(x_test_exp)
```
    # TypeError: Value passed to parameter 'input' has DataType uint8 not in list of allowed values: float16, bfloat16, float32, float64

However, my intention is not to make this particular example work, I was wondering if `export_model` could get fixed.
thanks you very much for your help! :)",hi expanding dimension another error python import value parameter list float float float however intention make particular example work wondering could get fixed thanks much help,issue,positive,positive,positive,positive,positive,positive
580807968,"Hi, before you train on `x_train` and `y_train` and test on `x_test`, did you expand a dimension to the last dimension of `x_train` and `x_test` and make it have a shape of `(None, 28, 28, 1)`?

That's usually how people do on the datasets to train and test the CNNs with the regular TensorFlow/Keras.",hi train test expand dimension last dimension make shape none usually people train test regular,issue,negative,negative,neutral,neutral,negative,negative
580453711,@vincentluo91 I think this is normal behavior. The value recorded in the json file is the highest score through all the epochs instead of the final score.,think normal behavior value file highest score instead final score,issue,negative,positive,neutral,neutral,positive,positive
580034958,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/932?src=pr&el=h1) Report
> Merging [#932](https://codecov.io/gh/keras-team/autokeras/pull/932?src=pr&el=desc) into [preprocessing_layer](https://codecov.io/gh/keras-team/autokeras/commit/887f05c796040fd395644c8e23e87c4b228d2007?src=pr&el=desc) will **not change** coverage.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/932/graphs/tree.svg?width=650&token=yDvddb2DDZ&height=150&src=pr)](https://codecov.io/gh/keras-team/autokeras/pull/932?src=pr&el=tree)

```diff
@@                 Coverage Diff                  @@
##           preprocessing_layer     #932   +/-   ##
====================================================
  Coverage                87.43%   87.43%           
====================================================
  Files                       32       32           
  Lines                     1664     1664           
====================================================
  Hits                      1455     1455           
  Misses                     209      209
```



------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/932?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/932?src=pr&el=footer). Last update [887f05c...4a87852](https://codecov.io/gh/keras-team/autokeras/pull/932?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",report change coverage coverage impacted file tree graph coverage coverage continue review full report legend click learn absolute relative impact affected missing data powered last update read comment,issue,negative,positive,neutral,neutral,positive,positive
579825329,"@vincentluo91 Thank you for the report. We miss a line in the example.
`output_node = ak.ClassificationHead()(output_node)`.
If anyone like, please help us correct it here:
https://github.com/keras-team/autokeras/blob/master/docs/templates/tutorial/customized.md",thank report miss line example anyone like please help u correct,issue,positive,neutral,neutral,neutral,neutral,neutral
579576528,"# [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/930?src=pr&el=h1) Report
> Merging [#930](https://codecov.io/gh/keras-team/autokeras/pull/930?src=pr&el=desc) into [preprocessing_layer](https://codecov.io/gh/keras-team/autokeras/commit/29cedb4db3ea7e9706e89a22d96b9cb1c2f0ebc5?src=pr&el=desc) will **decrease** coverage by `1.15%`.
> The diff coverage is `90.59%`.

[![Impacted file tree graph](https://codecov.io/gh/keras-team/autokeras/pull/930/graphs/tree.svg?width=650&token=yDvddb2DDZ&height=150&src=pr)](https://codecov.io/gh/keras-team/autokeras/pull/930?src=pr&el=tree)

```diff
@@                   Coverage Diff                   @@
##           preprocessing_layer     #930      +/-   ##
=======================================================
- Coverage                88.53%   87.37%   -1.16%     
=======================================================
  Files                       19       28       +9     
  Lines                     1613     1656      +43     
=======================================================
+ Hits                      1428     1447      +19     
- Misses                     185      209      +24
```


| [Impacted Files](https://codecov.io/gh/keras-team/autokeras/pull/930?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [autokeras/hypermodels/wrapper.py](https://codecov.io/gh/keras-team/autokeras/pull/930/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2h5cGVybW9kZWxzL3dyYXBwZXIucHk=) | `88.04% <ø> (-0.96%)` | :arrow_down: |
| [autokeras/task.py](https://codecov.io/gh/keras-team/autokeras/pull/930/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL3Rhc2sucHk=) | `92.94% <100%> (+0.17%)` | :arrow_up: |
| [autokeras/hypermodels/heads.py](https://codecov.io/gh/keras-team/autokeras/pull/930/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2h5cGVybW9kZWxzL2hlYWRzLnB5) | `96.34% <100%> (ø)` | |
| [autokeras/adapters/\_\_init\_\_.py](https://codecov.io/gh/keras-team/autokeras/pull/930/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2FkYXB0ZXJzL19faW5pdF9fLnB5) | `100% <100%> (ø)` | |
| [autokeras/engine/node.py](https://codecov.io/gh/keras-team/autokeras/pull/930/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2VuZ2luZS9ub2RlLnB5) | `100% <100%> (ø)` | |
| [autokeras/engine/io\_hypermodel.py](https://codecov.io/gh/keras-team/autokeras/pull/930/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2VuZ2luZS9pb19oeXBlcm1vZGVsLnB5) | `100% <100%> (ø)` | |
| [autokeras/engine/block.py](https://codecov.io/gh/keras-team/autokeras/pull/930/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2VuZ2luZS9ibG9jay5weQ==) | `97.36% <100%> (+3.84%)` | :arrow_up: |
| [autokeras/tuners/\_\_init\_\_.py](https://codecov.io/gh/keras-team/autokeras/pull/930/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL3R1bmVycy9fX2luaXRfXy5weQ==) | `100% <100%> (ø)` | |
| [autokeras/hypermodels/preprocessing.py](https://codecov.io/gh/keras-team/autokeras/pull/930/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2h5cGVybW9kZWxzL3ByZXByb2Nlc3NpbmcucHk=) | `83.5% <100%> (ø)` | :arrow_up: |
| [autokeras/hypermodels/\_\_init\_\_.py](https://codecov.io/gh/keras-team/autokeras/pull/930/diff?src=pr&el=tree#diff-YXV0b2tlcmFzL2h5cGVybW9kZWxzL19faW5pdF9fLnB5) | `100% <100%> (ø)` | |
| ... and [21 more](https://codecov.io/gh/keras-team/autokeras/pull/930/diff?src=pr&el=tree-more) | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/keras-team/autokeras/pull/930?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/keras-team/autokeras/pull/930?src=pr&el=footer). Last update [29cedb4...4253289](https://codecov.io/gh/keras-team/autokeras/pull/930?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",report decrease coverage coverage impacted file tree graph coverage coverage impacted coverage continue review full report legend click learn absolute relative impact affected missing data powered last update read comment,issue,negative,positive,neutral,neutral,positive,positive
579010413,Thank you and I hope next version will be released ASAP :),thank hope next version,issue,positive,neutral,neutral,neutral,neutral,neutral
578473216,"@LAX1992 Currently, the ConvBlock does support the 3d images. The ResNetBlock and XceptionBlock does not. You can use AutoModel with ConvBlock to do it. The ResNet and XceptionNet are extending code from KerasTuner. You may submit a issue there to ask if the will support 3d. Thank you.",lax currently support use extending code may submit issue ask support thank,issue,positive,neutral,neutral,neutral,neutral,neutral
578472925,@Min-seong-song I believe this is because the processor is not exported. Tensorflow 2.1 has just released the preprocessing layers which enables a Keras model to contain preprocessors. We will support it in the next release of AutoKeras. Thank you,believe processor model contain support next release thank,issue,positive,neutral,neutral,neutral,neutral,neutral
578472735,"@ekarabulut The object detection module is only a pertained one. It doesn't support custom dataset for training. Currently, we don't have this module. This is in our plan. Will have it in the near future. Thank you.",object detection module one support custom training currently module plan near future thank,issue,positive,positive,neutral,neutral,positive,positive
578472517,"@anavanab99 This is mainly because of some of the custom layers we added to the model. Another issue is some preprocessors are not exported. We are addressing this now. will update a version support everything to be exported to Keras model. Will update the tutorial too.

Thanks",mainly custom added model another issue update version support everything model update tutorial thanks,issue,positive,positive,positive,positive,positive,positive
577342880,Thank you for the report. We will fix this bug.,thank report fix bug,issue,negative,neutral,neutral,neutral,neutral,neutral
577342380,"@mulka For the StructuredDataClassifier, the export model may not always work. This issue will be solved soon since Keras is supporting preprocessing layers from tensorflow 2.1.",export model may always work issue soon since supporting,issue,negative,positive,positive,positive,positive,positive
577282161,"@iXanthos Yes, that is correct. The `StructuredDataClassifier` call.

We will do some performance evaluation later for the new version.
It is hard to do a strict time limit, so, for now, we will not focus on this feature.",yes correct call performance evaluation later new version hard strict time limit focus feature,issue,negative,negative,neutral,neutral,negative,negative
577273276,"@gabrieldemarmiesse I have added you as a collaborator.
I think you mean an organization on DockerHub with repositories for different Keras projects.
That would be great.
We can use my account before this organization is created.
And move to it whenever it is ready.

@fchollet Do we have a Keras organization or something similar on DockerHub? Thanks.",added collaborator think mean organization different would great use account organization move whenever ready organization something similar thanks,issue,positive,positive,positive,positive,positive,positive
577206911,Does this mean that saving a model doesn't currently work? Or is there a work around? I now have a model with 0 trainable parameters which seems wrong.,mean saving model currently work work around model trainable wrong,issue,negative,negative,negative,negative,negative,negative
577050549,"@haifeng-jin so is there a way to set a strict time limit? If not, this is a step backwards in my opinion, as it makes autokeras unavailable for quantitative performance evaluation under strict time restrictions (99% of all the published works evaluate a tool or library under some time constraints).
Also, when you talk about the initializer, you mean the `StructuredDataClassifier` call, correct?

Thank you in advance.",way set strict time limit step backwards opinion unavailable quantitative performance evaluation strict time work evaluate tool library time also talk mean call correct thank advance,issue,negative,negative,negative,negative,negative,negative
576937265,"My dockerhub username is gabrieldemarmiesse

Do you tyink it would make sense for us to have a repository on dockerhub for keras projects? ",would make sense u repository,issue,negative,neutral,neutral,neutral,neutral,neutral
576935899,"@gabrieldemarmiesse 
We will use the README file in the docker folder as the documentation. Would you help us update the autogen.py to use it?

For DockerHub, I can add the secrets to the repo and let's use this action to do it:
https://github.com/marketplace/actions/publish-docker
The docker will be uploaded to https://hub.docker.com/repository/docker/haifengjin/autokeras
I can add you as a collaborator on DockerHub.
Let me know your DockerHub ID.

Thanks.",use file docker folder documentation would help u update use add let use action docker add collaborator let know id thanks,issue,positive,positive,positive,positive,positive,positive
576864907,"@iXanthos For time_limit, we changed it. We now use max_trials to control the search. It is an argument in the initializer of the classes.
`metrics` is also in the initializer. It has the same usage as the Keras metrics in the compile function.
",use control search argument class metric also usage metric compile function,issue,negative,neutral,neutral,neutral,neutral,neutral
576411431,"@Kyrill996 We don't have this error.
`Python 3.6.6 (v3.6.6:4cf1f54eb7, Jun 26 2018, 19:50:54) 
[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)] on darwin
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import autokeras as ak
>>> ak.StructuredDataClassifier.export_model
<function AutoModel.export_model at 0x13d6da598>
>>> `

You may try `python3 -m pip install --upgrade autokeras` if you are using python3 as your command for executing the python file.

We are currently not supporting export the structured data classifier unless the final found model is a neural network.
So even you can use that function it might not work as expected for now.
I will add this to the export model tutorial later.",error python compatible apple type help copyright license information import ak function may try python pip install upgrade python command python file currently supporting export structured data classifier unless final found model neural network even use function might work add export model tutorial later,issue,negative,positive,neutral,neutral,positive,positive
576407188,Sorry for that missing information. That is exactly the version that i am using.,sorry missing information exactly version,issue,negative,negative,negative,negative,negative,negative
576362042,"@Kyrill996 Would you please confirm your AutoKeras version?
The export model function only exists in the latest version. 1.0.0",would please confirm version export model function latest version,issue,negative,positive,positive,positive,positive,positive
576355799,"Ok sure thing. Beforehand, we should rewrite the Dockerfile to use the official Tensorflow image rather than the nvidia/cuda one. It's going to be less maintenance in the long run. I can work on that when I have the time.",sure thing beforehand rewrite use official image rather one going le maintenance long run work time,issue,negative,positive,positive,positive,positive,positive
576348004,"@yfq512 You can first export the model as a Keras Model. Then call the save_model function of the Keras Model.
Am I understanding your needs correctly?",first export model model call function model understanding need correctly,issue,negative,positive,positive,positive,positive,positive
576347332,@gabrieldemarmiesse Great! Then let's just use DockerHub. We may automate the push process with GitHub Actions.,great let use may push process,issue,positive,positive,positive,positive,positive,positive
576295883,"@haifeng-jin , you mean to host the produced docker image? We have the choice between GitHub package and DockerHub on this.

From [this thread](https://github.community/t5/GitHub-Actions/Use-docker-images-from-GitHub-Package-Registry/td-p/30407) it seems that dockerhub is more integrated into the docker cli than GitHub packages. (not a big surprise since it's the same company making both).

It seems that unless we have a strong reason not to, it would be preferable to push the images to DockerHub.

I hope I didn't misinterpret your question.",mean host produced docker image choice package thread docker big surprise since company making unless strong reason would preferable push hope misinterpret question,issue,positive,positive,neutral,neutral,positive,positive
576097469,We will not let the user specify the optimizer for now and just search for the best optimizer by enlarging the search space.,let user specify search best enlarging search space,issue,positive,positive,positive,positive,positive,positive
576093237,"> > However, since I am really not familiar with this mechanism there might be some cons we are not aware of.
> 
> What are some potential issues?

I don't know.
If you don't see any potential issue, then we can just do it.",however since really familiar mechanism might aware potential know see potential issue,issue,negative,positive,positive,positive,positive,positive
576091773,"Do we ever expect users to want to specify losses and metrics *otherwise* than through the Head objects?

We could add a `compile` step with only the `optimizer` argument.",ever expect want specify metric otherwise head could add compile step argument,issue,negative,neutral,neutral,neutral,neutral,neutral
576091200,"> However, since I am really not familiar with this mechanism there might be some cons we are not aware of. 

What are some potential issues?",however since really familiar mechanism might aware potential,issue,negative,positive,positive,positive,positive,positive
576044417,"This issue has been breakdown to multiple parts in the AutoKeras Project.
After adopting the preprocessing layers the issue should be resolved.",issue breakdown multiple project issue resolved,issue,negative,neutral,neutral,neutral,neutral,neutral
576044311,"@KalidindiMounika We have the function `export` in the new release now.
It can export everything except for the preprocessors.",function export new release export everything except,issue,negative,positive,positive,positive,positive,positive
576030444,"@gabrieldemarmiesse When we make sure the docker file is good, we may try the GitHub Package feature.
https://github.com/keras-team/autokeras/packages?package_type=Docker
What do you think?",make sure docker file good may try package feature think,issue,positive,positive,positive,positive,positive,positive
576030287,"@alexcombessie Thank you so much!
Maybe we can start by writing a simple tutorial on how to resume the training with the `overwrite` argument in `AutoModel`?
Or you can just try f1 score works or not, if not you can work on this issue.
I will help you in the process and give more details after you tried.",thank much maybe start writing simple tutorial resume training overwrite argument try score work work issue help process give tried,issue,negative,positive,neutral,neutral,positive,positive
576013685,"@Sette tensorflow has ready to use docker images, with gpu enable and jupyter included. Do you think we could use that to reduce the size of the Dockerfile? 

https://hub.docker.com/r/tensorflow/tensorflow",ready use docker enable included think could use reduce size,issue,negative,positive,positive,positive,positive,positive
575895357,"Thanks a lot, I will give it a try.

I am interested in contributing by the way, what would be a good way to start?",thanks lot give try interested way would good way start,issue,positive,positive,positive,positive,positive,positive
575759754,"I am merging it.
I haven't test it yet, but it definitely more complete than the previous file.
We can fix it later if anyone finds any bug.",test yet definitely complete previous file fix later anyone bug,issue,negative,negative,neutral,neutral,negative,negative
575758598,"@alexcombessie We just released the new version of AutoKeras yesterday.
It should support the f1 for now.",new version yesterday support,issue,negative,positive,positive,positive,positive,positive
575758151,"@HunbeomBak Hi, I cannot reproduce the bug on my machine.
Maybe you can try tf 2.1.0?
Let's see if there is anyone else who has this bug.",hi reproduce bug machine maybe try let see anyone else bug,issue,negative,neutral,neutral,neutral,neutral,neutral
575504623,"I can run code like this example.
But I want save model as ***.h5 file. I do not find some api about savemodel like imageclassition



发自我的iPhone


------------------ Original ------------------
From: Haifeng Jin <notifications@github.com&gt;
Date: Fri,Jan 17,2020 3:04 PM
To: keras-team/autokeras <autokeras@noreply.github.com&gt;
Cc: yfq512 <1085561337@qq.com&gt;, Mention <mention@noreply.github.com&gt;
Subject: Re: [keras-team/autokeras] Ask about version 1.0. (#794)




@yfq512
 Here is a tutorial: https://autokeras.com/tutorial/structured_data_classification/
 Let me know if it works or not.
 Thanks.
 
—
You are receiving this because you were mentioned.
Reply to this email directly, view it on GitHub, or unsubscribe.",run code like example want save model file find like original date mention mention subject ask version tutorial let know work thanks reply directly view,issue,positive,positive,positive,positive,positive,positive
575502058,"@yfq512 
Here is a tutorial: https://autokeras.com/tutorial/structured_data_classification/
Let me know if it works or not.
Thanks.
",tutorial let know work thanks,issue,negative,positive,positive,positive,positive,positive
574871063,"@DavidJBianco This is a very tough issue.
First, the saved model is may contain a custom layer `autokeras.hypermodel.head.IdentityLayer`.
You can follow http://keras.io/getting-started/faq/ the tutorial of saving and loading custom layer.
`model = load_model('my_model.h5', custom_objects={'IdentityLayer': autokeras.hypermodel.head.IdentityLayer})`

However, the keras model doesn't save all the things of a found model by AutoKeras. It may use a lightGBM model.
We will update the tutorial for handling this in the tutorial below soon.
https://autokeras.com/tutorial/export/

In the near future, we will wrap everything into the keras model and remove the custom layer. So this issue will be resovled automatically.",tough issue first saved model may contain custom layer follow tutorial saving loading custom layer model however model save found model may use model update tutorial handling tutorial soon near future wrap everything model remove custom layer issue automatically,issue,positive,negative,neutral,neutral,negative,negative
574867488,"@taylor4712 You can use the current master branch to export your model using `export_model()` of ImageClassifier. Then, you can use the exported Keras model to output the probs.",use current master branch export model use model output,issue,negative,neutral,neutral,neutral,neutral,neutral
574087253,"clf = ImageClassifier(verbose = True)
from sklearn.metrics import roc_curve,roc_auc_score
y_test_cat_prob=clf.predict(x_test)
fpr , tpr , thresholds = roc_curve( y_test , y_test_cat_prob)


i used sklearn. I have a multiclass classification, it does not support multiclass format",verbose true import used classification support format,issue,positive,positive,positive,positive,positive,positive
573944503,"@Peng-wei-Yu Yes, that should be the correct way.
How did you tell that the batch_size in fit not working?",yes correct way tell fit working,issue,positive,positive,positive,positive,positive,positive
573944289,"@taylor4712 How are you passing the roc_curve to AutoKeras?
I am not sure whether we are supporting this feature or not.
Would you please paste the code which produces the error?

Thanks.",passing sure whether supporting feature would please paste code error thanks,issue,positive,positive,positive,positive,positive,positive
573943662,"@takuya2816 We cannot reproduce the error. It might because the python interpreter you use is not the one you installed the 1.0 version of AutoKeras.
If you are running your program with command `python3`.
You can try this `python3 -m pip freeze | grep autokeras`. to see the version.",reproduce error might python interpreter use one version running program command python try python pip freeze see version,issue,negative,neutral,neutral,neutral,neutral,neutral
573942544,"https://github.com/tensorflow/tensorflow/issues/31509
It seems it is an issue of tensorflow.
We can only expect the next version of tensorflow to fix it.
Thanks.",issue expect next version fix thanks,issue,negative,positive,neutral,neutral,positive,positive
571832951,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`.

If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",wo notify release get touch new version available rather skip next major minor version let know ignore major version ignore minor version change mind resolve,issue,negative,positive,neutral,neutral,positive,positive
571786291,Sure thing. It's easy enough. I'll do it tonight/tomorrow. ,sure thing easy enough,issue,positive,positive,positive,positive,positive,positive
571782551,"@gabrieldemarmiesse Would you be willing to add a similar change / error message for keras-tuner? I just released a minor kerastuner version (1.0.1) w/o this dependency but haven't updated GH yet, and a check like this would be nice",would willing add similar change error message minor version dependency yet check like would nice,issue,negative,positive,positive,positive,positive,positive
571469503,"Hi, I also experience that issue with darknight's code, and also with my own with StructuredDataClassifier",hi also experience issue code also,issue,negative,neutral,neutral,neutral,neutral,neutral
571171406,I am facing the same issue. It migth be somehow related to **kwargs? Should we add them somewhere into our code or they are missing in autokeras package?,facing issue somehow related add somewhere code missing package,issue,negative,negative,neutral,neutral,negative,negative
570835549,@taylor4712 @sustef94 The API of AutoKeras 1.0 and 0.4 are different. Would you paste your code for reproducing the error? We currently don't have the load_image_dataset function. You may need to load the images manually to numpy.,different would paste code error currently function may need load manually,issue,negative,neutral,neutral,neutral,neutral,neutral
570730295,"Also if we decide to type the API surface and do runtime type checks, I'd be happy to implement it :) ",also decide type surface type happy implement,issue,positive,positive,positive,positive,positive,positive
570723870,"@gabrieldemarmiesse 
I think it is a good idea to do so if it can save the manual type check and error raising process. 
However, since I am really not familiar with this mechanism there might be some cons we are not aware of. Adding it to all APIs would have some workload.
I would rather wait for the reviews from @fchollet and @omalleyt12 before we proceed.
Thank you for your patience.",think good idea save manual type check error raising process however since really familiar mechanism might aware would would rather wait proceed thank patience,issue,positive,positive,positive,positive,positive,positive
570682668,"@haifeng-jin I believe that adding type hints is a safe move. It doesn't have any runtime consequences. From the pep:

> While these annotations are available at runtime through the usual `__annotations__` attribute, no type checking happens at runtime.

Adding some tool on top of it might. But this PR is focused only on type hints.

I believe it is safe to merge an doesn't necessitate a review from @fchollet or @omalleyt12 .",believe type safe move pep available usual attribute type tool top might type believe safe merge necessitate review,issue,positive,positive,positive,positive,positive,positive
570597674,"> same issue, is it fixed in 1.0.0b.0?

It is merged in the current version in the repo",issue fixed current version,issue,negative,positive,neutral,neutral,positive,positive
570548274,Same problem for me. Also could not find it in a different place,problem also could find different place,issue,negative,neutral,neutral,neutral,neutral,neutral
570450542,"Thank you very much for helping me @haifeng-jin @zhulingchen 
If it ’s just a simple upgrade with latest version autokeras==1.0.0b0 , the same file  still reports an error.
Install  keras-tuner from  source (instead of 'pip install keras-tuner' ) can really solve the problem.
Hope my mistake can help more people who are learning about AutoKeras.",thank much helping simple upgrade latest version file still error install source instead install really solve problem hope mistake help people learning,issue,positive,positive,positive,positive,positive,positive
570372740,"@taylor4712 We have the new 1.0.0 beta version released. You can install it with `pip3 install autokeras==1.0.0b0`.
You can follow this tutorial on splitting the data. https://autokeras.com/tutorial/image_classification/#validation-data
Let us know if it works or not.

Thank you!",new beta version install pip install follow tutorial splitting data let u know work thank,issue,negative,positive,positive,positive,positive,positive
570370606," @zhulingchen Thanks for the suggestion. Currently, AutoKeras is based on the 1.0.0 version of KerasTuner. If you install the master branch of KerasTuner, I am not sure it would work well since we haven't tested it yet.

@bb-1357
I suggest you install the latest version of AutoKeras with `pip3 install autokeras==1.0.0b0`.
I saw this bug once, I remembered I have fixed it before the b0 release.
Thanks.",thanks suggestion currently based version install master branch sure would work well since tested yet suggest install latest version pip install saw bug fixed release thanks,issue,positive,positive,positive,positive,positive,positive
570369131,@Kantshun It is definitely an important issue. We will include an installation tutorial on the website later. Thanks.,definitely important issue include installation tutorial later thanks,issue,positive,positive,positive,positive,positive,positive
570235960,"@gabrieldemarmiesse you are right, internet problem. I can install autokeras now, but its documentation is too brief, i don't quite understand how to use autokeras.",right problem install documentation brief quite understand use,issue,negative,positive,positive,positive,positive,positive
570221783,"> 
> 
> The version I installed is exactly 1.0.0，I‘m sad that the problem still cannot be solved

Then try the latest commit of `keras-tuner` from its source codes:

```
git clone https://github.com/keras-team/keras-tuner.git
cd keras-tuner
pip install .
```",version exactly sad problem still try latest commit source git clone pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
570145823,"No, autokeras == 1.0.0a0. My operating environment is tensorflow==2.0.0,torch=1.3.1，and all codes coming from official website,I didn't make any changes
```
`from autokeras import ImageClassifier
from tensorflow.keras.datasets import mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()
import autokeras as ak
# Initialize the image classifier.
clf = ak.ImageClassifier(max_trials=10) # It tries 10 different models.
split = 50000
x_val = x_train[split:]
y_val = y_train[split:]   
x_train = x_train[:split]  
y_train = y_train[:split]
clf.fit(
    x=x_train, y=y_train, validation_split=0.2
)`
```
**The compiler reported an error**
```
“meta_model.py in <listcomp>(.0)
     53 
     54     outputs = nest.flatten([output_blocks(output_node)
---> 55                             for output_blocks in outputs])
     56     hm = graph.HyperGraph(inputs, outputs, override_hps=hps)
     57     return hm
TypeError: 'Node' object is not callable
```
**if I change ""clt.fit""function into**
```
clf.fit(
 x=x_train, y=y_train, epochs=2000, callbacks=None, validation_split=0.2, validation_data=None
)
```
**The compiler reported an error** 
```
meta_model.py in <listcomp>(.0)
     53 
     54     outputs = nest.flatten([output_blocks(output_node)
---> 55                             for output_blocks in outputs])
     56     hm = graph.HyperGraph(inputs, outputs, override_hps=hps)
     57     return hm
 `TypeError: _build_wrapper() got an unexpected keyword argument 'inputs`' 
```
thanks a lot.
",operating environment coming official make import import import ak initialize image classifier different split split split split split compiler error return object callable change function compiler error return got unexpected argument thanks lot,issue,negative,positive,positive,positive,positive,positive
570141771,"@bb-1357 Is it autokeras==1.0.0b0 that you use? Please paste the entire notebook scripts, so that we can reproduce the error. thanks",use please paste entire notebook reproduce error thanks,issue,negative,positive,neutral,neutral,positive,positive
570140111," I use autokeras.StructuredDataClassifier, but I don't know how to save model. I try many methods ...,but it does' not work! Can you help me?",use know save model try many work help,issue,positive,positive,positive,positive,positive,positive
570139830,"@stale I use autokeras.StructuredDataClassifier, but I don't know how save model. I try many methods  ...,but it does' not work! Can you help me ",stale use know save model try many work help,issue,positive,neutral,neutral,neutral,neutral,neutral
570127930,"> Hi guys,
> I encountered this situation as well and I found autokeras use keras-tuner as part of it.
> In the master branch, keras-tuner just fixed [it](https://github.com/keras-team/keras-tuner/commit/250724d4f10244a8e6087a27eb9fac90c4d34392).
> SO you can fixed by install it from master.
> `pip install git+git://github.com/keras-team/keras-tuner@master#egg=kerastuner`
> It just a workaround if you want to run the example, it may encounter other unknown bugs so don't use in production.

solve the problem!! thanks",hi situation well found use part master branch fixed fixed install master pip install master want run example may encounter unknown use production solve problem thanks,issue,positive,positive,neutral,neutral,positive,positive
570109334,The version I installed is exactly 1.0.0，I‘m sad that the problem still cannot be solved,version exactly sad problem still,issue,negative,negative,negative,negative,negative,negative
570075080,"> 
> 
> Another tricky problem:TypeError: _build_wrapper() got an unexpected keyword argument 'inputs'

For this problem, please update your `keras-tuner` package to version 1.0.0",another tricky problem got unexpected argument problem please update package version,issue,negative,positive,neutral,neutral,positive,positive
569619814,Another tricky problem:TypeError: _build_wrapper() got an unexpected keyword argument 'inputs',another tricky problem got unexpected argument,issue,negative,positive,neutral,neutral,positive,positive
569510292,"> Addition: I did try with
> 
> ```
> clf = AutoKerasClassifier(
>     max_trials = 5,
>     epochs = 10,
>     batch_size = 1024,
>     objective = kerastuner.Objective(""val_f1"", direction=""max"")
> )
> ```
> 
> But this time I get another error after Oracle exit:
> Objective value missing in metrics reported to the Oracle, expected: ['val_f1'], found: dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])

Both the cases seem to be working in the current release",addition try objective time get another error oracle exit objective value missing metric oracle found seem working current release,issue,negative,negative,neutral,neutral,negative,negative
569484778,@darkknight9394 can you exactly provide the code you are trying to execute?,exactly provide code trying execute,issue,negative,positive,positive,positive,positive,positive
569462969,"Sure thing, let me change that.",sure thing let change,issue,negative,positive,positive,positive,positive,positive
569458768,"@iamkucuk Yes, there is. To do so, you need to create your own block. We will add this tutorial [here](https://autokeras.com/tutorial/customized/) soon.",yes need create block add tutorial soon,issue,negative,neutral,neutral,neutral,neutral,neutral
569410388,"I am facing the same issue when I am trying to compile the following code:

```
import tensorflow as tf
config = tf.compat.v1.ConfigProto()
config.gpu_options.allow_growth = True
tf.compat.v1.keras.backend.set_session(tf.compat.v1.Session(config=config))

from tensorflow.keras.datasets import mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()
print(x_train.shape) # (60000, 28, 28)
print(y_train.shape) # (60000,)
print(y_train[:3]) # array([7, 2, 1], dtype=uint8)

import autokeras as ak

clf = ak.ImageClassifier(max_trials=10) # It tries 10 different models.
clf.fit(x_train, y_train)
predicted_y = clf.predict(x_test)
print(clf.evaluate(x_test, y_test))
```

The trace is as follows:

```
Traceback (most recent call last):
  File ""demo.py"", line 17, in <module>
    clf.fit(x_train, y_train)
  File ""/home/abhinit/anaconda3/envs/keras/lib/python3.7/site-packages/autokeras/task.py"", line 116, in fit
    **kwargs)
  File ""/home/abhinit/anaconda3/envs/keras/lib/python3.7/site-packages/autokeras/auto_model.py"", line 199, in fit
    **kwargs)
  File ""/home/abhinit/anaconda3/envs/keras/lib/python3.7/site-packages/autokeras/tuner.py"", line 138, in search
    super().search(callbacks=new_callbacks, **fit_kwargs)
  File ""/home/abhinit/anaconda3/envs/keras/lib/python3.7/site-packages/kerastuner/engine/base_tuner.py"", line 122, in search
    self.run_trial(trial, *fit_args, **fit_kwargs)
  File ""/home/abhinit/anaconda3/envs/keras/lib/python3.7/site-packages/autokeras/tuner.py"", line 53, in run_trial
    trial.hyperparameters)
  File ""/home/abhinit/anaconda3/envs/keras/lib/python3.7/site-packages/autokeras/hypermodel/graph.py"", line 460, in build_graphs
    plain_graph = self.hyper_build(hp)
  File ""/home/abhinit/anaconda3/envs/keras/lib/python3.7/site-packages/autokeras/hypermodel/graph.py"", line 480, in hyper_build
    outputs = old_block.build(hp, inputs=inputs)
  File ""/home/abhinit/anaconda3/envs/keras/lib/python3.7/site-packages/autokeras/hypermodel/base.py"", line 117, in _build_wrapper
    return self._build(hp, *args, **kwargs)
  File ""/home/abhinit/anaconda3/envs/keras/lib/python3.7/site-packages/autokeras/hypermodel/hyperblock.py"", line 62, in build
    seed=self.seed)(output_node)
  File ""/home/abhinit/anaconda3/envs/keras/lib/python3.7/site-packages/autokeras/hypermodel/preprocessor.py"", line 577, in __init__
    super().__init__(**kwargs)
  File ""/home/abhinit/anaconda3/envs/keras/lib/python3.7/site-packages/autokeras/hypermodel/base.py"", line 100, in __init__
    super().__init__(**kwargs)
TypeError: __init__() got an unexpected keyword argument 'seed'
```

My setup is as follows:

- autokeras                 1.0.0b0       
- cudatoolkit               10.0.130      
- cudnn                     7.6.4             
- keras-applications        1.0.8       
- keras-base                2.2.4          
- keras-preprocessing       1.1.0    
- keras-tuner               1.0.0          
- numpy                     1.17.4         
- numpy-base                1.17.4     
- python                    3.7.5            
- tensorflow                2.0.0          
- tensorflow-gpu            2.0.0                ",facing issue trying compile following code import true import print print print array import ak different print trace recent call last file line module file line fit file line fit file line search super file line search trial file line file line file line file line return file line build file line super file line super got unexpected argument setup python,issue,positive,positive,positive,positive,positive,positive
569337067,"Addition: I did try with 
```
clf = AutoKerasClassifier(
    max_trials = 5,
    epochs = 10,
    batch_size = 1024,
    objective = kerastuner.Objective(""val_f1"", direction=""max"")
)

```

But this time I get another error after Oracle exit:
Objective value missing in metrics reported to the Oracle, expected: ['val_f1'], found: dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])",addition try objective time get another error oracle exit objective value missing metric oracle found,issue,negative,negative,neutral,neutral,negative,negative
569333673,"Sure, here you go:

```
import pandas as pd
import numpy as np

from sklearn.base import BaseEstimator, RegressorMixin, ClassifierMixin
from autokeras import StructuredDataClassifier, StructuredDataRegressor

class AutoKerasClassifier(StructuredDataClassifier, BaseEstimator, ClassifierMixin):
    def __init__(self, 
        column_names = None, 
        column_types = None,
        num_classes = None,
        multi_label = False,
        loss = None,
        metrics = None, 
        name = 'structured_data_classifier',
        max_trials = 100,
        directory = None,
        objective = 'val_accuracy',
        overwrite = True,
        seed = None,
        classes_ = None,
        epochs = None,
        batch_size = 32):
        super().__init__(
            column_names = column_names,
            column_types = column_types,
            num_classes = num_classes,
            multi_label = multi_label,
            loss = loss,
            metrics = metrics,
            name = name,
            max_trials = max_trials,
            directory = directory,
            objective = objective,
            overwrite = overwrite,
            seed = seed)
        self.classes_ = classes_
        self.epochs = epochs
        self.batch_size = batch_size
        
    def fit(self, x = None, y = None, epochs = None, callbacks = None, validation_split = 0.2, **kwargs):
        self.classes_ = [str(i) for i in np.unique(y)]
        super().fit(x = x, y = y, epochs = self.epochs, callbacks = callbacks,
                       validation_split = validation_split, batch_size = self.batch_size, **kwargs)
        
    def predict(self, x, **kwargs):
        y = pd.Series(super().predict(x = x, batch_size = self.batch_size, **kwargs).flatten())
        return(y)

from autokeras_doctor import AutoKerasClassifier

clf = AutoKerasClassifier(
    max_trials = 5,
    epochs = 10,
    batch_size = 1024,
    objective = ""val_f1""
)

```

I am using this wrapper class inside Dataiku DSS, which calls `fit` on `clf`.

Side-note: the only reason I wrote a wrapper class around StructuredDataClassifier is that I am missing the classes_ attribute, as defined in `sklearn` or `xgboost` classifiers.",sure go import import import import class self none none none false loss none metric none name directory none objective overwrite true seed none none none super loss loss metric metric name name directory directory objective objective overwrite overwrite seed seed fit self none none none none super predict self super return import objective wrapper class inside fit reason wrote wrapper class around missing attribute defined,issue,negative,positive,positive,positive,positive,positive
569330729,@andreaAnc To use the RNN block you have to reshape it to 2D per instance.,use block reshape per instance,issue,negative,neutral,neutral,neutral,neutral,neutral
569328930,"@alexcombessie Thank you for the issue! Would you please paste your code, too?",thank issue would please paste code,issue,positive,neutral,neutral,neutral,neutral,neutral
569217525,"> autokeras0.4.0
> # save the model
> 
> clf.export_autokeras_model(""keras.model"")
> # load the model
> 
> from autokeras.utils import pickle_from_file
> model = pickle_from_file(""keras.model"")
> results = model.evaluate(x_test, y_test)
> print(results)
> # according to the above code, the result is ok.



but how to use in autokeras1.0?",save model load model import model print according code result use,issue,negative,neutral,neutral,neutral,neutral,neutral
568996201,"@taylor4712
The sklearn confusion matrix function is quite straight forward. You can save the confusion matrix by assignment:
`cm = confusion_matrix(ytest,yprediction)` 
Then you add add column/row  name or whatever modification you want to the variable `cm`; then
`print(str(cm))` 
For more. Please refer to https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html",confusion matrix function quite straight forward save confusion matrix assignment add add name whatever modification want variable print please refer,issue,positive,positive,positive,positive,positive,positive
568994846,"@Kantshun   
install keras package first. Then install scikit-learn
numpy
scipy:
tensorflow (use <=1.8)
pytorch

Then install autokeras
Let me know if you still encounter any more installation problems",install package first install use install let know still encounter installation,issue,negative,positive,positive,positive,positive,positive
568992245,"> @Npccc Thank you so much for the bug report.
> It is very hard for us to reproduce this bug without the full log.
> Would you please provide the full log if it is available?
> 
> Thank you!

Still experiencing the same problem. Looking for a fix. @haifeng-jin  Do you know where the problem is at? I guess autokeras/torch seems to pass an unexpected dimension to the next conv layer while it is searching an architecture ",thank much bug report hard u reproduce bug without full log would please provide full log available thank still problem looking fix know problem guess pas unexpected dimension next layer searching architecture,issue,negative,positive,positive,positive,positive,positive
568753399,"You could install everything manually, even tensorflow with --no-deps but this is a workaround and the issue will be fixed in the future. I already opened a PR for that. 

Happy Christmas to you too!",could install everything manually even issue fixed future already happy,issue,positive,positive,positive,positive,positive,positive
568752839,"Thanks for the follow up.  I followed your suggestion, but I end up with another issue

import autocross

ModuleNotFoundError                       Traceback (most recent call last)
<ipython-input-4-43b9b5252b3c> in <module>
----> 1 import autokeras

/media/bison/xavierssd500/sandbox/my-project-env/lib/python3.6/site-packages/autokeras/__init__.py in <module>
----> 1 from autokeras.auto_model import AutoModel
      2 from autokeras.const import Constant
      3 from autokeras.hypermodel.base import Block
      4 from autokeras.hypermodel.base import Head
      5 from autokeras.hypermodel.base import HyperBlock

/media/bison/xavierssd500/sandbox/my-project-env/lib/python3.6/site-packages/autokeras/auto_model.py in <module>
----> 1 import kerastuner
      2 import tensorflow as tf
      3 from tensorflow.python.util import nest
      4 
      5 from autokeras import meta_model

ModuleNotFoundError: No module named 'kerastuner'

when I try pip install keras-tuner

ERROR: Could not find a version that satisfies the requirement tensorflow>=2.0.0-beta1 (from keras-tuner) (from versions: none)
ERROR: No matching distribution found for tensorflow>=2.0.0-beta1 (from keras-tuner)

thanks and happy holidays",thanks follow suggestion end another issue import recent call last module import module import import constant import block import head import module import import import nest import module try pip install error could find version requirement none error matching distribution found thanks happy,issue,negative,positive,positive,positive,positive,positive
568728258,"
![Codacy](https://app.codacy.com/assets/images/favicon.png) Here is an overview of what got changed by this pull request:


```diff

Issues
======
- Added 1
           
```


See the complete overview on [Codacy](https://app.codacy.com/app/jhfjhfj1/autokeras/pullRequest?prid=4678707&bid=15652099)
        ",overview got pull request added see complete overview,issue,negative,positive,neutral,neutral,positive,positive
568704101,"Thank you for your reply.

Just to be clear, right now is it possible to use 1D data (such as time-series) with autokeras? if yes, which module supports 1D data?",thank reply clear right possible use data yes module data,issue,positive,positive,positive,positive,positive,positive
568682697,"This issue is fixed in autokeras 1.0.0b0. If not, please reopen the issue. Thanks.",issue fixed please reopen issue thanks,issue,positive,positive,positive,positive,positive,positive
568682127,We are still working on this module. You can see the interface in autokeras/task.py,still working module see interface,issue,negative,neutral,neutral,neutral,neutral,neutral
568599125,"RNN block works for 1D data? 

Thanks!",block work data thanks,issue,negative,positive,positive,positive,positive,positive
568596885,"Hi,

Haven't tried, but at a quick glance, sounds like RNNBlock + multiple ClassificationHeads would fit your requirements.

Hope it helps,

Alex",hi tried quick glance like multiple would fit hope,issue,positive,positive,positive,positive,positive,positive
568319296,"import tensorflow as tf

import autokeras as ak
from keras.datasets import mnist
import numpy as numpy
print(tf.__version__)
print(ak)
#tf.executing_eagerly(True)

print(tf.executing_eagerly())


# Prepare the data.
(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train = x_train.reshape(x_train.shape + (1,))
x_test = x_test.reshape(x_test.shape + (1,))

# Search and train the classifier.
x_train =x_train[0:5]

x_test =x_test[0:5]
clf = ak.ImageClassifier(max_trials=2)
clf.fit(x_train, y_train,validation_split=0.9,epochs=2)
print(""going to predict now"")
y = clf.predict(x_test, y_test)",import import ak import import print print ak true print prepare data search train classifier print going predict,issue,negative,positive,positive,positive,positive,positive
567547813,You seem to have an internet connection problem when downloading panda. It seems unrelated to autokeras.,seem connection problem panda unrelated,issue,negative,neutral,neutral,neutral,neutral,neutral
567528293,"A quick fix is to install it without the dependencies. `pip install --no-deps git+git://github.com/keras-team/autokeras`. 

The long term fix is to remove tensorflow from the setup.py, otherwise it's going to try to install the cpu version of tensorflow everytime. I would consider that a bug. 

See https://github.com/keras-team/keras-tuner/issues/168 which has the same problem.",quick fix install without pip install long term fix remove otherwise going try install version would consider bug see problem,issue,negative,positive,positive,positive,positive,positive
567519441,"The error you got is unrelated to cuda, it seems that the install of scikit-learn is broken. I don't know what is the reason though. You can see it by doing:

```python
from sklearn import exceptions
```

And you'll see a similar error. 

I would recommend two things:

1) On windows, use anaconda as your python installation. You'll have far less issues. Use ""conda install"" to install scikit learn.
2) If the problem persist, ask your questions on stackoverflow or report a bug in the scikit-learn repo, since it's unrelated to autokeras. The core devs here (keras-team in general) have very little time overall, so let's dispatch the problems to their appropriate channels.

I hope you'll fix it quickly! Good luck!",error got unrelated install broken know reason though see python import see similar error would recommend two use anaconda python installation far le use install install problem persist ask report bug since unrelated core general little time overall let dispatch appropriate hope fix quickly good luck,issue,negative,positive,neutral,neutral,positive,positive
567329131,"Facing Same Issue, Please provide a solution.",facing issue please provide solution,issue,positive,neutral,neutral,neutral,neutral,neutral
567034754,"> @christian-steinmeyer
> Excuse me, I've downloaded the newest version of code from github, but I don't see the requirements.txt. Where is it?

Good question. I am not sure. Perhaps the development team knows more about this?",excuse version code see good question sure perhaps development team,issue,positive,positive,positive,positive,positive,positive
566898750,"@christian-steinmeyer 
Excuse me, I've downloaded the newest version of code from github, but I don't see the requirements.txt. Where is it?",excuse version code see,issue,negative,negative,neutral,neutral,negative,negative
566408938,There is no option to export/save a model in autokeras 1.0. How can we save the model for deployment ? ,option model save model deployment,issue,negative,neutral,neutral,neutral,neutral,neutral
566244925,"
![Codacy](https://app.codacy.com/assets/images/favicon.png) Here is an overview of what got changed by this pull request:


```diff

Issues
======
+ Solved 1
           
```


See the complete overview on [Codacy](https://app.codacy.com/app/jhfjhfj1/autokeras/pullRequest?prid=4644318&bid=15555409)
        ",overview got pull request see complete overview,issue,negative,positive,neutral,neutral,positive,positive
565646393,Could we just target tf.keras? It would make things much simpler. The multi-backend keras is deprecated.,could target would make much simpler,issue,negative,positive,positive,positive,positive,positive
565417438,"@jhfjhfj1 Thank you for your answers. I measured the execution times of the different blocks for 1 epoch both with and without GPU

```
inputs = autokeras.ImageInput( )
# t1 = autokeras.hypermodel.preprocessor.Normalization( )( inputs )
# t1 = autokeras.hypermodel.preprocessor.ImageAugmentation( )( inputs )
# t1 = autokeras.hypermodel.block.ConvBlock( )( inputs )
# t1 = autokeras.hypermodel.block.XceptionBlock( )( inputs )
t1 = autokeras.hypermodel.block.ResNetBlock( )( inputs )
outputs = autokeras.ClassificationHead( )( t1 )

model = autokeras.GraphAutoModel(
    inputs = inputs,
    outputs = outputs
)
```

The results are as follows

With GPU
Normalization( ): 85 s
ImageAugmentation( ): 278 s
ConvBlock( ): 11 s
ResNetBlock( ): 45 s
XceptionBlock( ): 42 s

Without GPU:
Normalization( ): 33 s
ImageAugmentation( ): 80 s
ConvBlock( ): 111 s
ResNetBlock( ): 3882 s
XceptionBlock( ): 2659 s

So on 1.0 the GPU makes ConvBlock( ), ResNetBlock( ) and XceptionBlock( ) much faster but Normalization( ) and ImageAugmentation( ) slower. However the 1.0 ConvBlock( ) with GPU is still is much slower than the 0.4 full ImageClassifier( ) that only takes 2 s.",thank measured execution time different epoch without model normalization without normalization much faster normalization however still much full,issue,negative,positive,positive,positive,positive,positive
565357675,"Hi @YongHuangSJTU 
Please report it with your environment, packages with version, and error messages.
Then others can help you.",hi please report environment version error help,issue,negative,neutral,neutral,neutral,neutral,neutral
565355218,"> Hi guys,
> I encountered this situation as well and I found autokeras use keras-tuner as part of it.
> In the master branch, keras-tuner just fixed [it](https://github.com/keras-team/keras-tuner/commit/250724d4f10244a8e6087a27eb9fac90c4d34392).
> SO you can fixed by install it from master.
> `pip install git+git://github.com/keras-team/keras-tuner@master#egg=kerastuner`
> It just a workaround if you want to run the example, it may encounter other unknown bugs so don't use in production.

>Hi @TreeKat71 , I got the same error and couldn't fix it with your workaround. I'm using tensorflow->gpu==2.0.0b1

The error was gone after reinstall kerastuner by `pip install git+git://github.com/keras-team/keras-tuner@master#egg=kerastuner` Thanks TreeKat71 for your solution.",hi situation well found use part master branch fixed fixed install master pip install master want run example may encounter unknown use production hi got error could fix error gone reinstall pip install master thanks solution,issue,negative,positive,neutral,neutral,positive,positive
565214529,@omalleyt12 Thank you for the review! Great suggestions. I will try to follow the get from config and get set state style.,thank review great try follow get get set state style,issue,positive,positive,positive,positive,positive,positive
564986863,"Can someone please answer this question

https://stackoverflow.com/questions/59301161/explanation-needed-for-autokerass-automodel-and-graphautomodel",someone please answer question,issue,negative,neutral,neutral,neutral,neutral,neutral
564986622,"Could you please answer my question

https://stackoverflow.com/questions/59301161/explanation-needed-for-autokerass-automodel-and-graphautomodel",could please answer question,issue,negative,neutral,neutral,neutral,neutral,neutral
564100042,"I am using the latest version based on the most recent commit and I can do something like:

```
_, model = automodel.get_best_model()
model.save(file_path)
```

It worked well for me.

Note that the `get_best_model` function returns two objects and only the second one is the model.
```
    def get_best_model(self):
        """"""Load the best PreprocessGraph and Keras model.

        It is mainly used by the predict and evaluate function of AutoModel.

        # Returns
            Tuple of (PreprocessGraph, tf.keras.Model).
        """"""
        preprocess_graph, keras_graph = self.hyper_graph.build_graphs(
            self.best_hp)
        preprocess_graph.reload(self.best_preprocess_graph_path)
        keras_graph.reload(self.best_keras_graph_path)
        model = keras_graph.build(self.best_hp)
        model.load_weights(self.best_model_path)
        return preprocess_graph, model
```",latest version based recent commit something like model worked well note function two second one model self load best model mainly used predict evaluate function model return model,issue,positive,positive,positive,positive,positive,positive
563322689,"@pezdorado You did it correctly. Thank you!

You can further break down the ImageBlock into [Normalization] + [ImageAugmentation] + [ConvBlock, ResNetBlock, XceptionBlock]. In this way, we can see which one is the slow one. 

I remember I tried just ConvBlock + ClassificationHead. It was fast.",correctly thank break normalization way see one slow one remember tried fast,issue,negative,negative,neutral,neutral,negative,negative
563248729,"I've tried the functional API with an ImageBlock( augment = False ) but it's as slow as the task API. I hope I applied the functional API correctly since the tutorial is quite sparse

```
!pip install git+git://github.com/keras-team/autokeras@master#egg=autokeras

import tensorflow
import autokeras

( ( x, y ), validation_data ) = tensorflow.keras.datasets.mnist.load_data( )

inputs = autokeras.ImageInput( )
blocks = autokeras.hypermodel.hyperblock.ImageBlock( augment = False )( inputs )
outputs = autokeras.ClassificationHead( )( blocks )

model = autokeras.GraphAutoModel(
    inputs = inputs,
    outputs = outputs
)

model.fit( x, y, validation_split = 0.1, batch_size = 128 )
```

Did I apply the functional API correctly and did I correctly turn off augmentation? If so, then the problem does not seem to be caused by augmentation. ",tried functional augment false slow task hope applied functional correctly since tutorial quite sparse pip install master import import augment false model apply functional correctly correctly turn augmentation problem seem augmentation,issue,negative,negative,negative,negative,negative,negative
562847906,"Traceback (most recent call last):
  File ""auto.py"", line 58, in <module>
    clf.fit(X_train, Y_train, validation_split=0.2)
  File ""/usr/local/lib/python3.6/dist-packages/autokeras/task.py"", line 111, in fit
    **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/autokeras/auto_model.py"", line 159, in fit
    **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/autokeras/tuner.py"", line 132, in search
    super().search(callbacks=new_callbacks, **fit_kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/kerastuner/engine/base_tuner.py"", line 122, in search
    self.run_trial(trial, *fit_args, **fit_kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/autokeras/tuner.py"", line 46, in run_trial
    trial.hyperparameters)
  File ""/usr/local/lib/python3.6/dist-packages/autokeras/hypermodel/graph.py"", line 435, in build_graphs
    plain_graph = self.hyper_build(hp)
  File ""/usr/local/lib/python3.6/dist-packages/autokeras/hypermodel/graph.py"", line 455, in hyper_build
    outputs = old_block.build(hp, inputs=inputs)
  File ""/usr/local/lib/python3.6/dist-packages/autokeras/hypermodel/base.py"", line 65, in _build_wrapper
    return self._build(hp, *args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/autokeras/hypermodel/hyperblock.py"", line 69, in build
    seed=self.seed)(output_node)
  File ""/usr/local/lib/python3.6/dist-packages/autokeras/hypermodel/preprocessor.py"", line 452, in __init__
    super().__init__(**kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/autokeras/hypermodel/base.py"", line 48, in __init__
    super().__init__(**kwargs)
TypeError: __init__() got an unexpected keyword argument 'seed'
",recent call last file line module file line fit file line fit file line search super file line search trial file line file line file line file line return file line build file line super file line super got unexpected argument,issue,positive,positive,positive,positive,positive,positive
562399519,"@AdityaVijayvergia Thanks for the PR!
The PR is failing on the tests.
Would you please try to fix them?",thanks failing would please try fix,issue,negative,positive,positive,positive,positive,positive
562183925,why is the issue closed? was a solution mentioned somewhere?,issue closed solution somewhere,issue,negative,negative,neutral,neutral,negative,negative
562014790,@pezdorado You can turn off the augmentation by using the functional API of 1.0. The image block has that arg. Please refer to the tutorial on the official website. Thanks,turn augmentation functional image block please refer tutorial official thanks,issue,negative,positive,positive,positive,positive,positive
562000694,"Thank you for reopening this and trying to solve this.

In #847 it was suggested that this problem has to do with data augmentation.

I'm having a hard time understanding how this could explain the fact that without GPU 0.4 and 1.0 are equally fast but with GPU 0.4 is much faster and 1.0 is still as slow as without GPU.

Also I didn't know AutoKeras did image augmentation. I tried to find more information about this, and I found that the 0.4 ImageClassifier( ) has an augment parameter that defaults to False but the 1.0 ImageClassifier( ) doesn't seem to have an augment parameter. Does 1.0 do augmentation and if so is there a way to switch it off?",thank trying solve problem data augmentation hard time understanding could explain fact without equally fast much faster still slow without also know image augmentation tried find information found augment parameter false seem augment parameter augmentation way switch,issue,negative,negative,negative,negative,negative,negative
561890798,@pezdorado I think the problem is because of the data augmentation. We will try to improve it. Thank you! I reopened the issue #834.,think problem data augmentation try improve thank issue,issue,negative,neutral,neutral,neutral,neutral,neutral
561453276,"I'm sure I have tensorflow-gpu installed now, but still can't run my autokeras scripts. could anyone help me?
![image](https://user-images.githubusercontent.com/31396222/70108551-9173c900-1684-11ea-8eca-a7da96921124.png)
",sure still ca run could anyone help image,issue,positive,positive,positive,positive,positive,positive
561393487,"@nanshihui It is `multiprocessing.queues`, not `multiprocessing.Queues`. Just tried on Python3.7 and Python2.7.

EDIT: snap NO!!! It works if you try to import it in the Python shell, but referencing it directly like the code given doesn't work.

EDIT: do this (Python2)
```
import multiprocessing
from multiprocessing.queues import Queue as mp_queue

class Queue(mp_queue):
  # ...
```

EDIT: in Python3, this code has a problem:
```
  File ""...[redacted].../shared_queue.py"", line 53, in __init__
    super(Queue, self).__init__(*args, **kwargs)
TypeError: __init__() missing 1 required keyword-only argument: 'ctx'
```
Solution: https://stackoverflow.com/questions/24941359/ctx-parameter-in-multiprocessing-queue",tried python python edit snap work try import python shell directly like code given work edit python import import queue class queue edit python code problem file line super queue self missing argument solution,issue,negative,positive,neutral,neutral,positive,positive
561190704,"I have CUDA toolkit and tensorflow installed. but not sure wethere my tensorflow is gpu version or not.
![image](https://user-images.githubusercontent.com/31396222/70058849-a61b7700-161a-11ea-9d3e-e035d5093158.png)
![image](https://user-images.githubusercontent.com/31396222/70058988-ea0e7c00-161a-11ea-8088-9c4bf8e42bbd.png)
",sure version image image,issue,negative,positive,positive,positive,positive,positive
561189455,"Adding as idea of project milestone, or something i didnt see anywhere else but seems significant for research in AutoML/NAS, and maybe is good to think in an implementation, are the Monte Carlo Tree Search models to architecture search.",idea project milestone something didnt see anywhere else significant research maybe good think implementation monte tree search architecture search,issue,positive,positive,positive,positive,positive,positive
559900548,"Hi, I have the same problem, @Fridgi did you find a solution for it ? ",hi problem find solution,issue,negative,neutral,neutral,neutral,neutral,neutral
559872068,"
![Codacy](https://app.codacy.com/assets/images/favicon.png) Here is an overview of what got changed by this pull request:


```diff

Issues
======
- Added 3
           

Complexity increasing per file
==============================
- autokeras/tuner.py  7
         
```


See the complete overview on [Codacy](https://app.codacy.com/app/autokeras/autokeras/pullRequest?prid=4365872&bid=14825639)
        ",overview got pull request added complexity increasing per file see complete overview,issue,negative,positive,neutral,neutral,positive,positive
559549382,"The code currently assumes 1-gram
Should I change it to take n-gram range as input?",code currently change take range input,issue,negative,neutral,neutral,neutral,neutral,neutral
558589362,I am using AutoModel in the new autokeras1.0.0. Have you been able to find an answer to this question? I am wondering if I use the same directory name and call AutoModel.fit() if it will resume operations. ,new able find answer question wondering use directory name call resume,issue,negative,positive,positive,positive,positive,positive
557309752,"Thanks for the PR!
It seems the suggestion from Codacy is not very relevant.
I will just close this PR.
We can have a meeting to discuss some more important features.",thanks suggestion relevant close meeting discus important,issue,positive,positive,positive,positive,positive,positive
557309216,"Thanks for the PR!
This is already addressed in this PR which would be merged soon.
https://github.com/keras-team/autokeras/pull/817",thanks already would soon,issue,negative,positive,positive,positive,positive,positive
557144435,"I am having the same issue on Windows 10 with TensorFlow 2.0.0 and Cuda 10. It sits forever on Epoch 1. There was a little GPU use at beginning, but none since then. CPU usage is continuously low but not zero for the process. Waited over 2 hours with no update, running in Jupyter notebook.",issue forever epoch little use beginning none since usage continuously low zero process update running notebook,issue,negative,negative,neutral,neutral,negative,negative
555689192,"The current dependency of kerastuner is based on rc0. You can install kerastuner with the following command.
`pip install git+https://github.com/keras-team/keras-tuner.git@1.0rc0`.
You can always check the kerastuner version we are depending on in [.travis.yml](https://github.com/keras-team/autokeras/blob/master/.travis.yml).",current dependency based install following command pip install always check version depending,issue,negative,neutral,neutral,neutral,neutral,neutral
555635550,"I've found a fix within Jupyter. I had to add this to the imports to allow for the multiprocessing of Autokeras to report on terminal  if for whatever reason Jupyter is causing issues... this anticipates both use in terminal or jupyter so I've added it

```
# Enable multiprocessing
import multiprocessing
multiprocessing.set_start_method('forkserver') 
```",found fix within add allow report terminal whatever reason causing use terminal added enable import,issue,negative,neutral,neutral,neutral,neutral,neutral
555277751,"
![Codacy](https://app.codacy.com/assets/images/favicon.png) Here is an overview of what got changed by this pull request:


```diff

Issues
======
+ Solved 16
           

Complexity decreasing per file
==============================
+ tests/autokeras/graph_test.py  -1
         

Clones added
============
- tests/autokeras/hypermodel/block_test.py  2
         
```


See the complete overview on [Codacy](https://app.codacy.com/app/autokeras/autokeras/pullRequest?prid=4522254&bid=15230114)
        ",overview got pull request complexity decreasing per file added see complete overview,issue,negative,positive,neutral,neutral,positive,positive
554612951,"auto_model is introduced in autokeras-1.0. Try this version using the following commands and please see if it works for you...

```
pip install git+git://github.com/keras-team/autokeras@master#egg=autokeras
pip install git+git://github.com/keras-team/keras-tuner@master#egg=keras-tuner
import autokeras
```

We can check the same using the following commands:

autokeras 0.4 code
```
import autokeras
print(dir(autokeras))
```
['CnnModule', 'ImageClassifier', 'ImageRegressor', 'MlpModule', 'PortableImageSupervised', 'TextClassifier', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'backend', 'bayesian', 'constant', 'custom_queue', 'image', 'net_module', 'net_transformer', 'nn', 'preprocessor', 'search', 'supervised', 'text', 'utils']

autokeras 1.0 code
```
import autokeras
print(dir(autokeras))
```
['AutoModel', 'ClassificationHead', 'Constant', 'ConvBlock', 'DenseBlock', 'EmbeddingBlock', 'FeatureEngineering', 'GraphAutoModel', 'ImageAugmentation', 'ImageBlock', 'ImageClassifier', 'ImageInput', 'ImageRegressor', 'Input', 'LightGBMBlock', 'Merge', 'Normalization', 'RNNBlock', 'RegressionHead', 'ResNetBlock', 'SpatialReduction', 'StructuredDataBlock', 'StructuredDataClassifier', 'StructuredDataInput', 'StructuredDataRegressor', 'TemporalReduction', 'TextBlock', 'TextClassifier', 'TextInput', 'TextRegressor', 'TextToIntSequence', 'TextToNgramVector', 'XceptionBlock', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'auto_model', 'const', 'encoder', 'hypermodel', 'meta_model', 'task', 'tuner', 'utils']",try version following please see work pip install master pip install master import check following code import print code import print,issue,negative,neutral,neutral,neutral,neutral,neutral
554204222,Thank you for the issue. We are trying to solve it.,thank issue trying solve,issue,positive,neutral,neutral,neutral,neutral,neutral
553875124,"> In your 1.0 code, you have validation_data, so it does make sense.
> You still need to validate it, it takes more time.

The validation_data is only a small fraction of the training data (10000 versus 60000 samples I believe) and does not explain the speed factor of > 40. When I use validation_split = 0.2 instead of validation_data the speed difference remains (I understand 0.4 also implicitly uses a validation split but I cannot find what fraction).",code make sense still need validate time small fraction training data versus believe explain speed factor use instead speed difference remains understand also implicitly validation split find fraction,issue,negative,negative,negative,negative,negative,negative
553806057,"In your 1.0 code, you have validation_data, so it does make sense.
You still need to validate it, it takes more time.",code make sense still need validate time,issue,negative,neutral,neutral,neutral,neutral,neutral
553250514,"Hi guys,
I encountered this situation as well and I found autokeras use keras-tuner as part of it.
In the master branch,  keras-tuner just fixed [it](https://github.com/keras-team/keras-tuner/commit/250724d4f10244a8e6087a27eb9fac90c4d34392).
SO you can fixed by install it from master.
`pip install git+git://github.com/keras-team/keras-tuner@master#egg=kerastuner`
It just a workaround if you want to run the example, it may encounter other unknown bugs so don't use in production.",hi situation well found use part master branch fixed fixed install master pip install master want run example may encounter unknown use production,issue,negative,positive,neutral,neutral,positive,positive
552156483,Same for running the auto keras 1.0 task api example with validation_split = True added on win10,running auto task example true added win,issue,positive,positive,positive,positive,positive,positive
551967563,I got this error too when simply running the example IO API codes here [https://autokeras.com/tutorial/](url),got error simply running example io,issue,negative,neutral,neutral,neutral,neutral,neutral
551479825,"Commenting here as this is related to Keras Tuner not being specified as a dependency as mentioned in the OP.

Installing autokeras from source (master branch) results in the following error upon import:
```python
>>> import autokeras
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/tuokri/autokeras/autokeras/__init__.py"", line 1, in <module>
    from autokeras.auto_model import AutoModel
  File ""/home/tuokri/autokeras/autokeras/auto_model.py"", line 1, in <module>
    import kerastuner
ModuleNotFoundError: No module named 'kerastuner'
```

This is fixed by manually installing Keras Tuner:
`pip install keras-tuner`",related tuner dependency source master branch following error upon import python import recent call last file line module file line module import file line module import module fixed manually tuner pip install,issue,negative,positive,neutral,neutral,positive,positive
551095759,"I can confirm this bug using 

- autokeras (from github, installed today)
- tensorflow 2.0
- kerastuner 1.0.0

additionally, I had to use `clf.fit(...)` with `validation_split` to avoid raising another exception.",confirm bug today additionally use avoid raising another exception,issue,negative,neutral,neutral,neutral,neutral,neutral
549429545,"Can you please  give any  example code. It would be great to export Auto -keras model into pure keras /tensorflow model so that it could be parsed  by  OpenCV DNN module.
Thanks ",please give example code would great export auto model pure model could module thanks,issue,positive,positive,positive,positive,positive,positive
549187252,"> Hi, @itsergiu
> Is this example?: https://raw.githubusercontent.com/keras-team/autokeras/master/examples/a_simple_example/mnist.py
> 
> I have tested this code and requires a lot of resources. You can try to increase the RAM assigned to machine, now has 2048 MB ![VBoxMemory](https://user-images.githubusercontent.com/6674996/56499155-70030a00-6505-11e9-806a-467a937df9fa.png)
> 
> However, in this situation, **is preferable real hardware than my "".ova""** because you can use all the CPU cores, memory and the GPU:
> 
> > Enable Multi-GPU Training
> > Auto-Keras support multiple GPU training in the default setting. There's no additional step needed to enable multiple GPU training. However, if multiple-GPU training is not a desirable behavior. You can disable it via environmental variable. CUDA_VISIBLE_DEVICES. For example, in your bash: export CUDA_VISIBLE_DEVICES=0. Keep in mind that when using multiple-GPU, make sure batch size is big enough that multiple-gpu context switch overhead won't effect the performance too much. Otherwise multiple-gpu training may be slower than single-GPU training.
> 
> Autokeras can be installed with pip. Useful links:
> 
> Get Python 3.6: https://www.python.org/downloads/
> 
> Download pip tutorial: https://www.liquidweb.com/kb/install-pip-windows/
> 
> pip command for Autokeras (https://autokeras.com/start/): **pip install autokeras**
> 
> Installing Jupyter (https://jupyter.org/install) and Spyder (https://docs.spyder-ide.org/installation.html) is easy without Anaconda too.
> 
> Hope this helps.

Where can I find the autokeras settings? How and where did you increase the RAM?",hi example tested code lot try increase ram assigned machine however situation preferable real hardware use memory enable training support multiple training default setting additional step enable multiple training however training desirable behavior disable via environmental variable example bash export keep mind make sure batch size big enough context switch overhead wo effect performance much otherwise training may training pip useful link get python pip tutorial pip command pip install easy without anaconda hope find increase ram,issue,positive,positive,positive,positive,positive,positive
548774931,"Ok I having hard time using 1.0 version for text classification and there is no proper documentation for it. So needed some help.
0.4 lack some functionalities I want to use.",hard time version text classification proper documentation help lack want use,issue,negative,negative,negative,negative,negative,negative
548720804,Hey have you tested autokeras for text classification,hey tested text classification,issue,negative,neutral,neutral,neutral,neutral,neutral
548657713,"@zhulingchen 
After I add kerastuner to autokeras, it also has error like below:
RuntimeError: Too many failed attempts to build model.
Have you met this problem and solved it?",add also error like many build model met problem,issue,negative,positive,positive,positive,positive,positive
546763042,"I guess the latest commits (after the commit `e4a5dbe7e29d64c9b095d134f0ca2a5543353dda`) require `kerastuner` of version 1.0rc0:

`pip install git+https://github.com/keras-team/keras-tuner.git@1.0rc0`

You may refer to this commit:

https://github.com/keras-team/autokeras/commit/e4a5dbe7e29d64c9b095d134f0ca2a5543353dda",guess latest commit require version pip install may refer commit,issue,positive,positive,positive,positive,positive,positive
545702908,"> Hi there,
> 
> I'm facing the same issue. I'm using a conda environment
> `conda create -n autokeras python=3.6 tensorflow-gpu keras nb_conda conda activate autokeras`
> If I use the latest version of pip3 and autokeras 0.4 during the installation the following error occurs:
> `ERROR: Could not find a version that satisfies the requirement torch==1.0.1.post2 (from autokeras) (from versions: 0.1.2, 0.1.2.post1, 0.1.2.post2) ERROR: No matching distribution found for torch==1.0.1.post2 (from autokeras)`
> If I use the latest version of pip3 and autokeras 1.0 the error `ValueError: Either validation_data or validation_splitshould be provided.` rises in the example of the Geeting Started Document.
> I used pip3:
> `pip 19.3.1 from C:\Users\Georg\Anaconda3\envs\autokeras\lib\site-packages\pip (python 3.6)`
> 
> If I try to provide validation_split=0.8 the exception `KeyError: 'label_to_int'` rises, as well if I provide validation_data.
> 
> I also tried different versions of pip but no one worked.
> 
> I tried the example from autokeras.com for the Task API for 1.0, I tried the example for 0.4 and I tried the MNIST exmple of this repo, but all exited with validation data should be provided or label_to_int or No module named 'autokeras.image'.
> 
> I also tried everything in this thread but nothing did work.

I got the same question with you ""error ValueError: Either validation_data or validation_splitshould be provided""",hi facing issue environment create activate use latest version pip installation following error error could find version requirement post post post error matching distribution found post use latest version pip error either example document used pip pip python try provide exception well provide also tried different pip one worked tried example task tried example tried validation data provided module also tried everything thread nothing work got question error either provided,issue,negative,positive,positive,positive,positive,positive
545701935,"you may want to install autokeras 0.4 in Windows,the error ""torch==1.0.1.post2"" shoud be installed in Linux.Try it in Ubuntu will work well",may want install error post work well,issue,negative,neutral,neutral,neutral,neutral,neutral
545277015,Same question. I'd appreciate if anyone could help.,question appreciate anyone could help,issue,positive,neutral,neutral,neutral,neutral,neutral
544754971,"Hi there,

I'm facing the same issue. I'm using a conda environment
`
conda create -n autokeras python=3.6 tensorflow-gpu keras nb_conda
conda activate autokeras
`
If I use the latest version of pip3 and autokeras 0.4 during the installation the following error occurs:
`ERROR: Could not find a version that satisfies the requirement torch==1.0.1.post2 (from autokeras) (from versions: 0.1.2, 0.1.2.post1, 0.1.2.post2)
ERROR: No matching distribution found for torch==1.0.1.post2 (from autokeras)`
If I use the latest version of pip3 and autokeras 1.0 the error `ValueError: Either validation_data or validation_splitshould be provided.` rises in the example of the Geeting Started Document. 
I used pip3:
`pip 19.3.1 from C:\Users\Georg\Anaconda3\envs\autokeras\lib\site-packages\pip (python 3.6)`

If I try to provide validation_split=0.8 the exception `KeyError: 'label_to_int'` rises, as well if I provide validation_data.

I also tried different versions of pip but no one worked.

I tried the example from autokeras.com for the Task API for 1.0, I tried the example for 0.4 and I tried the MNIST exmple of this repo, but all exited with validation data should be provided or label_to_int or No module named 'autokeras.image'.

I also tried everything in this thread but nothing did work.
",hi facing issue environment create activate use latest version pip installation following error error could find version requirement post post post error matching distribution found post use latest version pip error either example document used pip pip python try provide exception well provide also tried different pip one worked tried example task tried example tried validation data provided module also tried everything thread nothing work,issue,negative,positive,positive,positive,positive,positive
544353922,"autokeras0.4.0
# save the model
clf.export_autokeras_model(""keras.model"")
# load the model
from autokeras.utils import pickle_from_file
model = pickle_from_file(""keras.model"")
results = model.evaluate(x_test, y_test)
print(results)
# according to the above code, the result is ok.",save model load model import model print according code result,issue,negative,neutral,neutral,neutral,neutral,neutral
543489577," class Queue(multiprocessing.Queues.Queue):
AttributeError: module 'multiprocessing' has no attribute 'Queues'

I am on py3",class queue module attribute,issue,negative,neutral,neutral,neutral,neutral,neutral
543049166,"However you tried to fix this before, it's broken again.",however tried fix broken,issue,negative,negative,negative,negative,negative,negative
542372371,I have been trying to install auto keras and I'm having the same error. Can anybody help me on how to resolve the error.,trying install auto error anybody help resolve error,issue,negative,neutral,neutral,neutral,neutral,neutral
542195193,"I dug into your source code and found you are using `kerastuner` for hyperparameter optimization. Therefore the automatically-searched and trained models are compatible with `tf.keras` models, so I should be able to use all related `tf.keras` callbacks and model-saving functionalities as shown in https://www.tensorflow.org/guide/keras/save_and_serialize.",dug source code found optimization therefore trained compatible able use related shown,issue,negative,positive,positive,positive,positive,positive
540535307,"Hello
Facing the same issue with autokeras '1.0.0a0'
Did you manage to solve your issue ?",hello facing issue manage solve issue,issue,negative,neutral,neutral,neutral,neutral,neutral
539325534,"Ah ok. The README says that you need to use `pip3` to install it. Have you tried that?
```bash
pip3 install autokeras
```

Because `autokeras` is a library that can be installed using the latest version of `pip` (which is `pip3`).",ah need use pip install tried bash pip install library latest version pip pip,issue,negative,positive,positive,positive,positive,positive
538913582,"That does not work for me because when i try
pip install autokeras

it shows me

```
  ERROR: Could not find a version that satisfies the requirement torch==1.0.1.post2 (from autokeras) (from versions: 0.1.2, 0.1.2.post1, 0.1.2.post2)
ERROR: No matching distribution found for torch==1.0.1.post2 (from autokeras)
```
even though i installed torch=1.0.1. Thats why i cloned it from github repository and installed setup.py.
",work try pip install error could find version requirement post post post error matching distribution found post even though thats repository,issue,negative,neutral,neutral,neutral,neutral,neutral
538815846,"I followed the installation instructions in the README:
```bash
pip install autokeras
```
Regardless of using the `verbose=True` flag, the code `clf.fit(...)` works for me just fine.

Perhaps, you can try to uninstall it first (as in delete the repo on your local machine if you downloaded the zip) as follows:
```bash
pip uninstall -y autokeras
```
You can then try to reinstall it via `pip`.",installation bash pip install regardless flag code work fine perhaps try first delete local machine zip bash pip try reinstall via pip,issue,negative,positive,positive,positive,positive,positive
538739603,"Thank you, 

If I use it with the verbose=True flag it shows me this:

TypeError: init() got an unexpected keyword argument 'verbose'

for the line in clf = ak.ImageClassifier(verbose=True)

I did ugrade autokeras as you said, but it is already in the latest version it say ""Requirement already up-todate, skipping upgrade"" 

How did you install autokeras? Maybe my version does not work properly... i had some issues with it. 
I used: 

pip install git+git://github.com/keras-team/autokeras@master#egg=autokeras # for 1.0 version

from https://autokeras.com/

Thank you for your help!",thank use flag got unexpected argument line said already latest version say requirement already skipping upgrade install maybe version work properly used pip install master version thank help,issue,positive,positive,positive,positive,positive,positive
538709276,"Hmm, that's odd. When I try it without the `verbose=True` flag, it works just fine. When I try it with the `validation_data` parameter it throws an error that says `validation_data` is not a parameter even though the code in the repo says so. 

Maybe, it'll work if you use the `verbose=True` flag:
```python
...
clf = ak.ImageClassifier(verbose=True)
clf.fit(xtrain, ytrain)
...
```

Can you please try this? It may work with the verbose flag. Also, worse case your `autokeras` library has not been updated yet. You can try upgrading via `pip`:
```bash
pip install --upgrade autokeras
```

Then, you can try running it again and checking if it works with/without the `verbose=True` flag.

Hope this helps!",odd try without flag work fine try parameter error parameter even though code maybe work use flag python please try may work verbose flag also worse case library yet try via pip bash pip install upgrade try running work flag hope,issue,negative,negative,neutral,neutral,negative,negative
538644660,"Thank your for your help!
But now the following error:

TypeError: __init__() got an unexpected keyword argument 'verbose'
for the line in clf = ak.ImageClassifier(verbose=True)

When I leave out ""verbose=True"" in the brackets i get the following:
![Screenshot 2019-10-05 14 49 18](https://user-images.githubusercontent.com/56178548/66255062-964cf700-e77f-11e9-9ada-3d9a72c8896c.png)


",thank help following error got unexpected argument line leave get following,issue,negative,positive,neutral,neutral,positive,positive
538627643,"Hey there!

Now you can access the `ImageClassifier` directly from the `autokeras` module as follows:

```python
import autokeras as ak
from tensorflow.keras.datasets import mnist

(xtrain, ytrain), (xtest, ytest) = mnist.load_data()
xtrain = xtrain.reshape([-1, 28, 28, 1])
xtest = xtest.reshape([-1, 28, 28, 1])

clf = ak.ImageClassifier(verbose=True)
clf.fit(xtrain, ytrain)
""""""
Preprocessing the images.
Preprocessing finished.

Initializing search.
Initialization finished.

+----------------------------------------------+
|               Training model 0               |
+----------------------------------------------+

...
""""""
```

Hope this helps!",hey access directly module python import ak import finished search finished training model hope,issue,negative,positive,neutral,neutral,positive,positive
538521073,"I pinned the version. 

I believe that after the 1.0, we should only publish the docs when we release a new version of autokeras on pypi, otherwise users are going to get confused. 

Most of them will have Autokeras installed from pip and they'll look at a documentation describing the new features of the master branch.",pinned version believe publish release new version otherwise going get confused pip look documentation new master branch,issue,negative,negative,neutral,neutral,negative,negative
538516688,True. Let me pin the current version.,true let pin current version,issue,negative,positive,positive,positive,positive,positive
538515279,"@gabrieldemarmiesse Can we have a tag on the keras-autodoc and use it for the pip install in CI of AutoKeras? Since AutoKeras is automatically pushing the updates to master branch to the website, if the keras-autodoc master branch crashes, AutoKeras website would crash.",tag use pip install since automatically pushing master branch master branch would crash,issue,negative,neutral,neutral,neutral,neutral,neutral
537474583,"I actually removed all other ignores as there was no violations here. The only ignore now is ""imported but unused"" in the `__init__.py` files.",actually removed ignore unused,issue,negative,neutral,neutral,neutral,neutral,neutral
537169173,This PR is ready to be merged but let's discuss it at the meeting Friday with @fchollet to make sure it's what he wants. ,ready let discus meeting make sure,issue,positive,positive,positive,positive,positive,positive
533848528,I had the same issue. Using the official Docker image was the way to go.,issue official docker image way go,issue,negative,neutral,neutral,neutral,neutral,neutral
533400368,"I tried 

> ` For the first example, you can reform the 'clf.fit(x_train, y_train)' into 'clf.fit(x_train, y_train, validation_data=(x_test, y_test))'.`

and 

> Solved by casting the MNIST data to np.float64,

it started training for a few epochs, but it stopped with the following error:

> ~/anaconda3/envs/autokeras10/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
>      65     else:
>      66       message = e.message
> ---> 67     six.raise_from(core._status_to_exception(e.code, message), None)
>      68   except TypeError as e:
>      69     keras_symbolic_tensors = [
> 
> ~/anaconda3/envs/autokeras10/lib/python3.6/site-packages/six.py in raise_from(value, from_value)
> 
> UnknownError:  {{function_node __inference_Dataset_map_<class 'functools.partial'>_1446651}} InvalidArgumentError: input must have 3 channels but instead has 1 channels. [Op:AdjustSaturation]
> Traceback (most recent call last):",tried first example reform casting data training stopped following error name else message message none except value class input must instead recent call last,issue,negative,positive,neutral,neutral,positive,positive
533344401,The same import error happens in `examples/portable_models/portable_load.py`. It looks like this was solved with https://github.com/keras-team/autokeras/pull/719 but then the PR was closed without merging?,import error like closed without,issue,negative,negative,neutral,neutral,negative,negative
533343665,@jeanjerome I get `AttributeError: 'Graph' object has no attribute 'produce_keras_model`. I don't see `produce_keras_model` anywhere in the codebase...,get object attribute see anywhere,issue,negative,neutral,neutral,neutral,neutral,neutral
533062027,"Same Problem.

Autokeras Version: 0.4.0
Python version: 3.6.7
Tensorflow version: 1.13.1
Keras Version:2.3.0
CUDA Version: 10.1
Driver Version: 430.40
GPU: RTX 2080 Super


![image](http://cucugi.us/images/autokeras_error.gif)
",problem version python version version version version driver version super image,issue,negative,positive,positive,positive,positive,positive
532803064,"@civilinformer thank you. I get another conversion error unfortunately:

```
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-20-d3b4caceffb6> in <module>
     21         y_train,
     22         validation_data=(x_test, y_test),
---> 23         verbose=True) 
     24 y = clf.predict(x_test, y_test)

/usr/local/lib/python3.6/dist-packages/autokeras/auto_model.py in fit(self, x, y, validation_split, validation_data, **kwargs)
    121         self.tuner.search(x=dataset,
    122                           validation_data=validation_data,
--> 123                           **kwargs)
    124 
    125     def prepare_data(self, x, y, validation_data, validation_split):

/usr/local/lib/python3.6/dist-packages/kerastuner/engine/tuner.py in search(self, *fit_args, **fit_kwargs)
    221             self.trials.append(trial)
    222             self.on_trial_begin(trial)
--> 223             self.run_trial(trial, hp, fit_args, fit_kwargs)
    224             self.on_trial_end(trial)
    225         self.on_search_end()

/usr/local/lib/python3.6/dist-packages/autokeras/tuner.py in run_trial(self, trial, hp, fit_args, fit_kwargs)
     40         new_fit_kwargs['callbacks'] = self.add_earlystopping_callback(callbacks)
     41 
---> 42         super().run_trial(trial, hp, [], new_fit_kwargs)
     43 
     44     def get_best_hp(self, num_models=1):

/usr/local/lib/python3.6/dist-packages/kerastuner/engine/tuner.py in run_trial(self, trial, hp, fit_args, fit_kwargs)
    259             fit_kwargs['callbacks'] = self._inject_callbacks(
    260                 original_callbacks, trial, execution)
--> 261             model.fit(*fit_args, **fit_kwargs)
    262             self.on_execution_end(trial, execution, model)
    263 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    641         max_queue_size=max_queue_size,
    642         workers=workers,
--> 643         use_multiprocessing=use_multiprocessing)
    644 
    645   def evaluate(self,

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)
    692         shuffle=shuffle,
    693         initial_epoch=initial_epoch,
--> 694         steps_name='steps_per_epoch')
    695 
    696   def evaluate(self,

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py in model_iteration(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)
    218     step = 0
    219     while step < target_steps:
--> 220       batch_data = _get_next_batch(generator, mode)
    221       if batch_data is None:
    222         if is_dataset:

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py in _get_next_batch(generator, mode)
    360   """"""Retrieves the next batch of input data.""""""
    361   try:
--> 362     generator_output = next(generator)
    363   except (StopIteration, errors.OutOfRangeError):
    364     return None

/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py in __next__(self)
    584 
    585   def __next__(self):  # For Python 3 compatibility
--> 586     return self.next()
    587 
    588   def _next_internal(self):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py in next(self)
    621     """"""
    622     try:
--> 623       return self._next_internal()
    624     except errors.OutOfRangeError:
    625       raise StopIteration

/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py in _next_internal(self)
    613             self._iterator_resource,
    614             output_types=self._flat_output_types,
--> 615             output_shapes=self._flat_output_shapes)
    616 
    617       return self._structure._from_compatible_tensor_list(ret)  # pylint: disable=protected-access

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py in iterator_get_next_sync(iterator, output_types, output_shapes, name)
   2118       else:
   2119         message = e.message
-> 2120       _six.raise_from(_core._status_to_exception(e.code, message), None)
   2121   # Add nodes to the TensorFlow graph.
   2122   if not isinstance(output_types, (list, tuple)):

/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)

InvalidArgumentError: ValueError: Tensor conversion requested dtype float64 for Tensor with dtype float32: 'tf.Tensor(\n[[[-1.2717254   2.4169948  -2.1740365 ]\n  [-0.39899644  1.6467917  -1.0019091 ]\n  [ 0.23112531  0.3909577   0.80664694]\n  ...\n  [-0.4772491   0.07524413  1.1650144 ]\n  [ 1.3342674  -0.43896303 -1.1289805 ]\n  [ 0.9109202  -0.33863023 -0.45496833]]\n\n [[ 0.94991887 -0.93013865  0.8514788 ]\n  [ 0.09348091 -0.36770564 -1.3416209 ]\n  [ 0.05318227 -0.70337045  0.35095558]\n  ...\n  [ 0.57118213 -1.0970585   0.60063195]\n  [-0.7659061   1.0390383   1.6728557 ]\n  [ 0.15889482 -0.9244571  -0.82788104]]\n\n [[-1.7850689  -1.6536125  -0.20558591]\n  [ 0.08051167  0.91122293  1.1320447 ]\n  [-0.01140222 -0.5511768  -0.4131454 ]\n  ...\n  [-0.7884533  -0.7702382  -0.86406696]\n  [ 0.6864766   0.64581436 -1.1103286 ]\n  [-0.47958803 -0.51848376  0.72430086]]\n\n ...\n\n [[-0.64761925 -1.0660917  -1.9404725 ]\n  [ 1.682229   -0.32439038 -0.7986581 ]\n  [ 2.363566    1.3686383   1.4962013 ]\n  ...\n  [ 0.33979434  1.2607307   0.22902605]\n  [ 1.5148147  -0.32657847 -2.6823864 ]\n  [ 0.09385773  0.2971194   0.8475815 ]]\n\n [[-0.4257261  -0.4954373  -0.22250512]\n  [-1.5689013  -0.32116008  0.00719456]\n  [ 1.7424654   1.8573691   1.9624333 ]\n  ...\n  [ 1.2441821   0.6155239   0.9603718 ]\n  [-1.0619017  -1.0550648   2.1678107 ]\n  [ 2.0420384  -1.4821937  -1.5438503 ]]\n\n [[-1.1446363  -0.21962133  1.1001482 ]\n  [-0.7724971   0.7933725   0.18620113]\n  [ 1.1540568   0.5871017   1.0590978 ]\n  ...\n  [ 0.99659747  0.47944668 -0.6308534 ]\n  [-0.12846816 -0.12814523 -1.2744265 ]\n  [-0.47947478  1.315488   -0.5510188 ]]], shape=(28, 28, 3), dtype=float32)'
Traceback (most recent call last):

  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py"", line 207, in __call__
    return func(device, token, args)

  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py"", line 121, in __call__
    self._convert(ret, dtype=self._out_dtypes[0]))

  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py"", line 101, in _convert
    return ops.convert_to_tensor(value, dtype=dtype)

  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py"", line 1100, in convert_to_tensor
    return convert_to_tensor_v2(value, dtype, preferred_dtype, name)

  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py"", line 1158, in convert_to_tensor_v2
    as_ref=False)

  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py"", line 1180, in internal_convert_to_tensor
    value = _TensorTensorConversionFunction(value, dtype=dtype)

  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py"", line 1036, in _TensorTensorConversionFunction
    (dtype.name, t.dtype.name, str(t)))

ValueError: Tensor conversion requested dtype float64 for Tensor with dtype float32: 'tf.Tensor(\n[[[-1.2717254   2.4169948  -2.1740365 ]\n  [-0.39899644  1.6467917  -1.0019091 ]\n  [ 0.23112531  0.3909577   0.80664694]\n  ...\n  [-0.4772491   0.07524413  1.1650144 ]\n  [ 1.3342674  -0.43896303 -1.1289805 ]\n  [ 0.9109202  -0.33863023 -0.45496833]]\n\n [[ 0.94991887 -0.93013865  0.8514788 ]\n  [ 0.09348091 -0.36770564 -1.3416209 ]\n  [ 0.05318227 -0.70337045  0.35095558]\n  ...\n  [ 0.57118213 -1.0970585   0.60063195]\n  [-0.7659061   1.0390383   1.6728557 ]\n  [ 0.15889482 -0.9244571  -0.82788104]]\n\n [[-1.7850689  -1.6536125  -0.20558591]\n  [ 0.08051167  0.91122293  1.1320447 ]\n  [-0.01140222 -0.5511768  -0.4131454 ]\n  ...\n  [-0.7884533  -0.7702382  -0.86406696]\n  [ 0.6864766   0.64581436 -1.1103286 ]\n  [-0.47958803 -0.51848376  0.72430086]]\n\n ...\n\n [[-0.64761925 -1.0660917  -1.9404725 ]\n  [ 1.682229   -0.32439038 -0.7986581 ]\n  [ 2.363566    1.3686383   1.4962013 ]\n  ...\n  [ 0.33979434  1.2607307   0.22902605]\n  [ 1.5148147  -0.32657847 -2.6823864 ]\n  [ 0.09385773  0.2971194   0.8475815 ]]\n\n [[-0.4257261  -0.4954373  -0.22250512]\n  [-1.5689013  -0.32116008  0.00719456]\n  [ 1.7424654   1.8573691   1.9624333 ]\n  ...\n  [ 1.2441821   0.6155239   0.9603718 ]\n  [-1.0619017  -1.0550648   2.1678107 ]\n  [ 2.0420384  -1.4821937  -1.5438503 ]]\n\n [[-1.1446363  -0.21962133  1.1001482 ]\n  [-0.7724971   0.7933725   0.18620113]\n  [ 1.1540568   0.5871017   1.0590978 ]\n  ...\n  [ 0.99659747  0.47944668 -0.6308534 ]\n  [-0.12846816 -0.12814523 -1.2744265 ]\n  [-0.47947478  1.315488   -0.5510188 ]]], shape=(28, 28, 3), dtype=float32)'


	 [[{{node EagerPyFunc}}]] [Op:IteratorGetNextSync]
```",thank get another conversion error unfortunately recent call last module fit self self search self trial trial trial trial self trial super trial self self trial trial execution trial execution model fit self verbose shuffle evaluate self fit self model verbose shuffle evaluate self model data verbose shuffle mode step step generator mode none generator mode next batch input data try next generator except return none self self python compatibility return self next self try return except raise self return ret name else message message none add graph list value tensor conversion float tensor float recent call last file line return device token file line ret file line return value file line return value name file line file line value value file line tensor conversion float tensor float node,issue,positive,positive,positive,positive,positive,positive
532628554,"> For the first example, you can reform the 'clf.fit(x_train, y_train)' into 'clf.fit(x_train, y_train, validation_data=(x_test, y_test))'.

Results in a different error for me.
```python
ValueError: Tensor conversion requested dtype float64 for Tensor with dtype float32: 
<tf.Tensor: id=240045, shape=(28, 28, 1), dtype=float32, numpy=array([[[nan],
[nan],
...,
[nan],
[nan]]],
dtype=float32)>
```

edit: Solved by casting the MNIST data to `np.float64`.",first example reform different error python tensor conversion float tensor float nan nan nan nan edit casting data,issue,negative,positive,positive,positive,positive,positive
532572580,"> I also meet the same issue. I please ask ""Have you already worked out it ?""

Not yet, do you have any clue?",also meet issue please ask already worked yet clue,issue,negative,neutral,neutral,neutral,neutral,neutral
532554093,"I also meet the same issue. I please ask ""Have you already worked out it ?""",also meet issue please ask already worked,issue,negative,neutral,neutral,neutral,neutral,neutral
532321084,"I tried creating 3-channel images and the first error goes away. However, I cannot get rid of the conversion error. What do you get if you try this?:

```
import numpy as np 
import autokeras as ak 
from tensorflow.keras.datasets import mnist 
   
(x_train, y_train), (x_test, y_test) = mnist.load_data() # function is just: def load_mnist(): return mnist.load_data() 
x_train = np.asarray(x_train.reshape(x_train.shape + (1,)), dtype=np.float64) 
x_test = np.asarray(x_test.reshape(x_test.shape + (1,)), dtype=np.float64) 
train = np.empty((*x_train.shape[:3], 3), dtype=np.float64) 
test = np.empty((*x_test.shape[:3], 3), dtype=np.float64) 
for i in range(3): 
    train[:,:,:,i] = x_train[:,:,:,0] 
    test[:,:,:,i] = x_test[:,:,:,0] 
     
x_train = train 
x_test = test  
   
print(x_train.dtype, y_train.shape, x_test.shape, y_test.shape) 
   
clf = ak.ImageClassifier(max_trials=2) 
clf.fit(x_train,  
        y_train,  
        validation_data=(x_test, y_test),  
        verbose=True) 
y = clf.predict(x_test, y_test) 
```",tried first error go away however get rid conversion error get try import import ak import function return train test range train test train test print,issue,negative,positive,positive,positive,positive,positive
529715761,"> ### Bug Description
> ### Reproducing Steps
> All the examples listed in https://autokeras.com/tutorial/ fail in version 1.0.0.
> 
> **First example:**
> 
> ```
> 
> >>> import autokeras as ak
> >>> from keras.datasets import mnist
> Using TensorFlow backend.
> >>> 
> >>> # Prepare the data.
> ... (x_train, y_train), (x_test, y_test) = mnist.load_data()
> >>> x_train = x_train.reshape(x_train.shape + (1,))
> >>> x_test = x_test.reshape(x_test.shape + (1,))
> >>> 
> >>> # Search and train the classifier.
> ... clf = ak.ImageClassifier(max_trials=100)
> >>> clf.fit(x_train, y_train)
> 2019-09-03 15:17:47.250598: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
> 2019-09-03 15:17:47.271654: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1992000000 Hz
> 2019-09-03 15:17:47.272577: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4e7f8e0 executing computations on platform Host. Devices:
> 2019-09-03 15:17:47.272623: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
> Traceback (most recent call last):
>   File ""<stdin>"", line 1, in <module>
>   File ""/home/michael/MonolithApp/dpu/venv/src/autokeras/autokeras/auto_model.py"", line 101, in fit
>     validation_split=validation_split)
>   File ""/home/michael/MonolithApp/dpu/venv/src/autokeras/autokeras/auto_model.py"", line 146, in prepare_data
>     x_val, y_val = validation_data
> TypeError: 'NoneType' object is not iterable
> ```
> 
> **Second example:**
> 
> ```
> 
> >>> import numpy as np
> >>> import autokeras as ak
> >>> from keras.datasets import mnist
> >>> 
> >>> # Prepare the data.
> ... (x_train, y_classification), (x_test, y_test) = mnist.load_data()
> >>> x_image = x_train.reshape(x_train.shape + (1,))
> >>> x_test = x_test.reshape(x_test.shape + (1,))
> >>> 
> >>> x_structured = np.random.rand(x_train.shape[0], 100)
> >>> y_regression = np.random.rand(x_train.shape[0], 1)
> >>> 
> >>> # Build model and train.
> ... automodel = ak.AutoModel(
> ...    inputs=[ak.ImageInput(),
> ...            ak.StructuredDataInput()],
> ...    outputs=[ak.RegressionHead(metrics=['mae']),
> ...             ak.ClassificationHead(loss='categorical_crossentropy',
> ...                                   metrics=['accuracy'])])
> Traceback (most recent call last):
>   File ""<stdin>"", line 4, in <module>
> AttributeError: module 'autokeras' has no attribute 'StructuredDataInput'
> ```
> 
> This error can be fixed by replacing `StructuredDataInput` with `StructuredInput`, but this still fails:
> 
> ```
> 
> >>> import numpy as np
> >>> import autokeras as ak
> >>> from keras.datasets import mnist
> >>> 
> >>> # Prepare the data.
> ... (x_train, y_classification), (x_test, y_test) = mnist.load_data()
> >>> x_image = x_train.reshape(x_train.shape + (1,))
> >>> x_test = x_test.reshape(x_test.shape + (1,))
> >>> 
> >>> x_structured = np.random.rand(x_train.shape[0], 100)
> >>> y_regression = np.random.rand(x_train.shape[0], 1)
> >>> 
> >>> # Build model and train.
> ... automodel = ak.AutoModel(
> ...    inputs=[ak.ImageInput(),
> ...            ak.StructuredInput()],
> ...    outputs=[ak.RegressionHead(metrics=['mae']),
> ...             ak.ClassificationHead(loss='categorical_crossentropy',
> ...                                   metrics=['accuracy'])])
> >>> automodel.fit([x_image, x_structured],
> ...               [y_regression, y_classification])
> Traceback (most recent call last):
>   File ""<stdin>"", line 2, in <module>
>   File ""/home/michael/MonolithApp/dpu/venv/src/autokeras/autokeras/auto_model.py"", line 101, in fit
>     validation_split=validation_split)
>   File ""/home/michael/MonolithApp/dpu/venv/src/autokeras/autokeras/auto_model.py"", line 131, in prepare_data
>     y = self._label_encoding(y)
>   File ""/home/michael/MonolithApp/dpu/venv/src/autokeras/autokeras/auto_model.py"", line 182, in _label_encoding
>     label_encoder.fit_with_labels(y)
>   File ""/home/michael/MonolithApp/dpu/venv/src/autokeras/autokeras/utils.py"", line 153, in fit_with_labels
>     data = np.array(data).flatten()
> ValueError: could not broadcast input array from shape (60000,1) into shape (60000)
> ```
> 
> Finally, the third example fails:
> 
> ```
> >>> import numpy as np
> >>> import tensorflow as tf
> >>> from keras.datasets import mnist
> >>> 
> >>> # Prepare the data.
> ... (x_train, y_classification), (x_test, y_test) = mnist.load_data()
> >>> x_image = x_train.reshape(x_train.shape + (1,))
> >>> x_test = x_test.reshape(x_test.shape + (1,))
> >>> 
> >>> x_structured = np.random.rand(x_train.shape[0], 100)
> >>> y_regression = np.random.rand(x_train.shape[0], 1)
> >>> 
> >>> # Build model and train.
> ... inputs = ak.ImageInput(shape=(28, 28, 1))
> >>> outputs1 = ak.ResNetBlock(version='next')(inputs)
> >>> outputs2 = ak.XceptionBlock()(inputs)
> >>> image_outputs = ak.Merge()((outputs1, outputs2))
> >>> 
> >>> structured_inputs = ak.StructuredInput()
> >>> structured_outputs = ak.DenseBlock()(structured_inputs)
> >>> merged_outputs = ak.Merge()((image_outputs, structured_outputs))
> >>> 
> >>> classification_outputs = ak.ClassificationHead()(merged_outputs)
> >>> regression_outputs = ak.RegressionHead()(merged_outputs)
> >>> automodel = ak.GraphAutoModel(inputs=inputs,
> ...                               outputs=[regression_outputs,
> ...                                        classification_outputs])
> Traceback (most recent call last):
>   File ""<stdin>"", line 3, in <module>
>   File ""/home/michael/MonolithApp/dpu/venv/src/autokeras/autokeras/auto_model.py"", line 243, in __init__
>     self.hypermodel = graph.GraphHyperModel(self.inputs, self.outputs)
>   File ""/home/michael/MonolithApp/dpu/venv/src/autokeras/autokeras/hypermodel/graph.py"", line 33, in __init__
>     self._build_network()
>   File ""/home/michael/MonolithApp/dpu/venv/src/autokeras/autokeras/hypermodel/graph.py"", line 135, in _build_network
>     '{name}.'.format(name=block.name))
> ValueError: A required input is missing for HyperModel merge_4.
> ```
> 
> In my own example, the choice of validation data does not appear to work:
> 
> ```
> 
> >>> import pandas as pd
> >>> import autokeras as ak
> >>> import numpy as np
> >>>
> >>> automodel = ak.auto_model.AutoModel(
> ...         inputs=[ak.StructuredInput()],
> ...         outputs=[
> ...             ak.RegressionHead(metrics=['mae']),
> ...             ak.ClassificationHead(loss='categorical_crossentropy', metrics=['accuracy'])
> ...             ]
> ...         )
> >>>
> >>> df = pd.read_csv(""samples.csv"")
> >>> X = np.array(df[df.columns[:-4]])
> >>> yr = np.array(df[[""residuary_resistance"", ""doubled""]])
> >>> yc = np.array(df[[""animal"", ""colour""]])
> >>>
> >>>
> >>> automodel.fit(x=[X], y=[yr, yc])
> 2019-09-03 15:23:55.991949: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
> 2019-09-03 15:23:56.015636: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1992000000 Hz
> 2019-09-03 15:23:56.016339: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4231040 executing computations on platform Host. Devices:
> 2019-09-03 15:23:56.016375: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
> Traceback (most recent call last):
>   File ""<stdin>"", line 1, in <module>
>   File ""/home/michael/MonolithApp/dpu/venv/src/autokeras/autokeras/auto_model.py"", line 101, in fit
>     validation_split=validation_split)
>   File ""/home/michael/MonolithApp/dpu/venv/src/autokeras/autokeras/auto_model.py"", line 146, in prepare_data
>     x_val, y_val = validation_data
> TypeError: 'NoneType' object is not iterable
> ```
> 
> ### Expected Behavior
> Expected behaviour is that the examples are able to run to the end.
> 
> ### Setup Details
> Include the details about the versions of:
> 
> * OS type and version: Ubuntu 18.04.3 LTS
> * Python: 3.6.8
> * autokeras: 1.0.0 (`pip3 install git+git://github.com/keras-team/autokeras@master#egg=autokeras`)
> * scikit-learn: 0.20.2
> * numpy: 1.16.1
> * keras: 2.2.4
> * scipy: 1.2.0
> * tensorflow: 2.0.0rc0
> * pytorch: 1.0.1post2

For the first example, you can reform the 'clf.fit(x_train, y_train)' into 'clf.fit(x_train, y_train, validation_data=(x_test, y_test))'.

For the second example, you should reshape the y_classification with 'y_classification.reshape(-1, 1)'. And if you get an 'MemoryError', just slice the data to run a mini set.

For the third example, you can see we only pass 'inputs' into the GraphAutoModel, actually this 'inputs' is only the image input while we also need to input the 'structured_inputs', so change the present code to 'inputs=[inputs, structured_inputs]'. We will change the name of 'inputs' into 'image_inputs' to make it sense.

We will patch this bugs  in a few days.
Thank U and welcome the continuing issue reports!",bug description listed fail version first example import ak import prepare data search train classifier binary use frequency service platform host device host default version recent call last file line module file line fit file line object iterable second example import import ak import prepare data build model train recent call last file line module module attribute error fixed still import import ak import prepare data build model train recent call last file line module file line fit file line file line file line data data could broadcast input array shape shape finally third example import import import prepare data build model train recent call last file line module file line file line file line name input missing example choice validation data appear work import import ak import yr doubled animal colour yr binary use frequency service platform host device host default version recent call last file line module file line fit file line object iterable behavior behaviour able run end setup include o type version python pip install master post first example reform second example reshape get slice data run set third example see pas actually image input also need input change present code change name make sense patch day thank welcome issue,issue,positive,positive,neutral,neutral,positive,positive
528711259,"Actually，if we use float 32, API test will run but other parts failed.



---Original---
From: ""Haifeng Jin""<notifications@github.com&gt;
Date: Fri, Sep 6, 2019 00:11 AM
To: ""keras-team/autokeras""<autokeras@noreply.github.com&gt;;
Cc: ""Davidsirui""<1053871735@qq.com&gt;;""Mention""<mention@noreply.github.com&gt;;
Subject: Re: [keras-team/autokeras] bugs found and fixed by api-test (#762)



@Davidsirui Do we have to use float32 instead of float64? I think for all the other preprocessors requires float64.
 
—
You are receiving this because you were mentioned.
Reply to this email directly, view it on GitHub, or mute the thread.",use float test run date mention mention subject found fixed use float instead float think float reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
528710739,@Davidsirui Do we have to use float32 instead of float64? I think for all the other preprocessors requires float64.,use float instead float think float,issue,negative,neutral,neutral,neutral,neutral,neutral
523080923,"Codacy needs a private token to work. For this reason, it's impossible to use it in forks. I've added a check to avoid using codacy if we're on a fork in travis CI.",need private token work reason impossible use added check avoid fork travis,issue,negative,negative,negative,negative,negative,negative
522850253,"> ### Feature Description
> Support for RNN, specifically LSTM and/or GRU - I might be willing to help implement in autokeras
> 
> ### Reason
> Much of my work involves RNN, specifically LSTM and GRU, and I am sure that many other potential autokeras users would be interested in sequence model support also.
> 
> ### Solution
> I suggest initially just supporting LSTM since LSTM cover GRU use cases, with a slight cost in model complexity and training time.
> 
> ### Alternative Solutions
> none
> 
> ### Additional Context
> Please reach out to me if you would like help implementing this.

Seems that the support is present.
[https://github.com/keras-team/autokeras/issues/696](url)",feature description support specifically might willing help implement reason much work specifically sure many potential would interested sequence model support also solution suggest initially supporting since cover use slight cost model complexity training time alternative none additional context please reach would like help support present,issue,positive,positive,positive,positive,positive,positive
522247028,"> I think you can set the constant value
> 
> # Shuffle the data and set the settings
> from sklearn.utils import shuffle
> x_train,y_train = shuffle(x_train,y_train)
> 
> from autokeras.constant import Constant
> 
> # Constant.BACKEND = 'tensorflow'
> Constant.MAX_BATCH_SIZE = 6
> Constant.VALIDATION_SET_SIZE = 0.3
> 
> from autokeras.image.image_supervised import ImageClassifier
> 
> something like that

Thanks  for you reply  ,  I  have  solved  it",think set constant value shuffle data set import shuffle shuffle import constant import something like thanks reply,issue,positive,positive,neutral,neutral,positive,positive
521581410,"I'm experiencing the same issue, though can build and run cutting edge with my RTX 2080. Unfortunately in doing so autokeras doesn't seem to leverage the GPU at all..",issue though build run cutting edge unfortunately seem leverage,issue,negative,negative,negative,negative,negative,negative
521102469,"Do you have a setup.py for Windows? I always got into:
ERROR: Could not find a version that satisfies the requirement torch>=1.0.1.post2 (from autokeras) (from versions: 0.1.2, 0.1.2.post1, 0.1.2.post2)
ERROR: No matching distribution found for torch>=1.0.1.post2 (from autokeras)
And torch v 1.0.1.post2 is not for Windows.",always got error could find version requirement torch post post post error matching distribution found torch post torch post,issue,negative,neutral,neutral,neutral,neutral,neutral
521090576,This does not seem to work with TPU on Colab. Colab claims not being able to find autokeras.,seem work able find,issue,negative,positive,positive,positive,positive,positive
520430068,"Have you tried `export CUDA_VISIBLE_DEVICES=0,1,2` in the shell (eg bash) that you're running? I know that `os.environ`should do this but I've had this issue before.
",tried export shell bash running know issue,issue,negative,neutral,neutral,neutral,neutral,neutral
520321628,Same thing happened with me. Shutdown the kernel and try rerunning the code. Worked for me.,thing shutdown kernel try code worked,issue,negative,neutral,neutral,neutral,neutral,neutral
520166587,The location of the ImageClassifer lib is already been updated; that's why your machine cannot find the module. You can either update your keras version or find the correct location in the github. hope it helps,location already machine find module either update version find correct location hope,issue,negative,neutral,neutral,neutral,neutral,neutral
520166447,the link of bayesian searcher is broken under Documentation,link searcher broken documentation,issue,negative,negative,negative,negative,negative,negative
519543608,"I have the same problem listed above. 
And would love to export the auto keras model into a valid keras model (then a tensorflow js model), but none of the solutions seem to work as intented.

Any update on this ?",problem listed would love export auto model valid model model none seem work update,issue,negative,positive,positive,positive,positive,positive
517957850,"I have issues with input shape (?, 64, 64, 2). Seems that ak only work with 1- and 3-channel gridded inputs.",input shape ak work,issue,negative,neutral,neutral,neutral,neutral,neutral
517881756,"python3.6.5
error as follows:
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-4-d1e3316252b2> in <module>()
----> 1 clf.export_keras_model(""hezd.h5"")

~/anaconda3/lib/python3.6/site-packages/autokeras/supervised.py in export_keras_model(self, model_file_name)
    250             Save the architecture, weights, and optimizer state of the best model
    251         """"""
--> 252         self.cnn.best_model.produce_keras_model().save(model_file_name)
    253 
    254     def predict(self, x_test):

AttributeError: 'Graph' object has no attribute 'produce_keras_model'",python error recent call last deb module self save architecture state best model predict self object attribute,issue,positive,positive,positive,positive,positive,positive
517793932,@mikewlange : Interested but this doesn't get TPUs to work with autokeras?  Right?  Just curious if you had an example with the TPU integration with autokeras.,interested get work right curious example integration,issue,positive,positive,positive,positive,positive,positive
517132888,"I'm guessing this is an oldie that never got closed. But just in case. 

[https://github.com/mikewlange/autokerascolab](https://github.com/mikewlange/autokerascolab)

Oh, skip to 10 if you don't feel like battling ngrok for tensorboard ",guessing never got closed case oh skip feel like,issue,negative,negative,neutral,neutral,negative,negative
516316982,"Hi, Does auto keras support regression problem? Does it suppoert LSTM network?
Thx.",hi auto support regression problem network,issue,negative,neutral,neutral,neutral,neutral,neutral
515758949,"It seems that the BayesianOptimizer relies on a multiprocess queue to check the training status,  whose method qsize, however,  is not reliable according to the python [document.](https://docs.python.org/3/library/multiprocessing.html). So the searching loop may not be able to break properly after training. I think this might be the issuse.
",queue check training status whose method however reliable according python document searching loop may able break properly training think might,issue,negative,positive,positive,positive,positive,positive
514032508,"Attached problem with image:
![image](https://user-images.githubusercontent.com/34225874/61679124-c287d880-ad37-11e9-9680-0fe0a88eab28.png)
",attached problem image image,issue,negative,neutral,neutral,neutral,neutral,neutral
514027922,"Same Regression Problem：
Using CnnModule instead of ImageRegressor,  still stuck at 0% problem.
Thanks & Regards!
",regression instead still stuck problem thanks,issue,negative,positive,positive,positive,positive,positive
513624072,"Gives any update for this bug?

Thanks & Regards!
Momo1986",update bug thanks momo,issue,negative,positive,positive,positive,positive,positive
513623782,"Hello, @haofanwang, I cannot work with your suggestion. However, still be grateful to you.

By the way, what is your label format, is it a classification problem or a regression problem?

Thanks & Regards!
",hello work suggestion however still grateful way label format classification problem regression problem thanks,issue,negative,positive,positive,positive,positive,positive
513088513,"I met the same problem before. I just close the terminal and rerun the code, and the training process can work well surprisedly.",met problem close terminal rerun code training process work well surprisedly,issue,negative,positive,neutral,neutral,positive,positive
512819369,"@manugarri yes, [the doc](https://autokeras.com/) is confusing. Some examples, for example the [CnnModule tutorial](https://autokeras.com/start/) are not made for autokeras 0.4 = pipy autokeras.

Autokeras team should make a doc like [the PyTorch one](https://pytorch.org/docs/stable/index.html), where on the top left you can choose your lib version.",yes doc example tutorial made pipy team make doc like one top left choose version,issue,positive,positive,positive,positive,positive,positive
512796321,"Hi @tl-yang , @jhfjhfj1 

Is there any progress on this? In current version of code (0.4.0) i could only find the implementation of DCGAN for image generation, but it is not possible to use NAS for searching optimal generator architecture. 

Moreover, **NetworkModule** is currently restricted to 1D output, are you planning to implement **NetworkModule** that supports 3D output generation?

BR",hi progress current version code could find implementation image generation possible use searching optimal generator architecture moreover currently restricted output implement output generation,issue,negative,neutral,neutral,neutral,neutral,neutral
512733876,"@cdelcroix i see, that means all of the docs on autokeras docsite are for a version that doesnt exist in pipy, isnt it?",see version doesnt exist pipy,issue,negative,neutral,neutral,neutral,neutral,neutral
512697436,"@manugarri [the version available on pypi is 0.4.0](https://pypi.org/project/autokeras/). According to the [readme](https://github.com/keras-team/autokeras/blob/master/README.md) of the master branch of this repo @humzaiqbal should use 

> the legacy branch (...) to checkout the 0.4 version.",version available according master branch use legacy branch version,issue,negative,positive,positive,positive,positive,positive
512592495,"@cdelcroix  when you say 0.4 is the legacy branch, what do you mean? is the version available in pipy isnt it?",say legacy branch mean version available pipy,issue,negative,positive,neutral,neutral,positive,positive
512138282,"Hi, 

You are using the legacy branch (autokeras 0.4), you should try:

`from autokeras.backend.torch.loss_function import classification_loss`

(or `from autokeras.backend.tensorflow.loss_function import classification_loss` depending of your backend)

An example can be found [there](https://github.com/keras-team/autokeras/blob/legacy/examples/net_modules/mlp_module.py
)
",hi legacy branch try import import depending example found,issue,negative,neutral,neutral,neutral,neutral,neutral
510948654,"it's already integrated in RNNBlock:
I found the best starting point is the blocks [branch](https://github.com/keras-team/autokeras/tree/blocks
):
try test_hyper_block.py:

```
def test_rnn_block():
    x_train = np.random.rand(100, 32, 10, 10)
    y_train = np.random.randint(5, size=100)
    y_train = tf.keras.utils.to_categorical(y_train)

    input_node = ak.Input()
    output_node = input_node
    output_node = ak.RNNBlock()(output_node)
    output_node = ak.ClassificationHead()(output_node)

    input_node.shape = (32, 10, 10)
    output_node[0].shape = (5,)

    graph = ak.GraphAutoModel(input_node, output_node)
    model = graph.build(kerastuner.HyperParameters())
    model.fit(x_train, y_train, epochs=1, batch_size=100, verbose=False)
    result = model.predict(x_train)

    assert result.shape == (100, 5)


test_rnn_block()
```",already found best starting point branch try graph model result assert,issue,positive,positive,positive,positive,positive,positive
509947121,"Has solved by the following steps:

1. Install tensorflow (cpu)
2. Install autokeras
3. Uninstall tensorflow (cpu) and tensorflow-gpu
4. Reinstall tensorflow-gpu",following install install reinstall,issue,negative,neutral,neutral,neutral,neutral,neutral
509399417,"when I try in this order 
first, change apt server
and
```sudo apt-get update; sudo apt-get upgrade -y; git clone https://github.com/keras-team/autokeras.git; sudo apt-get install python3-venv -y; python3 -m venv ak; source ak/bin/activate; cd autokeras/; sudo apt-get install gcc -y; sudo apt-get install python3-dev -y; pip install wheel; pip install -r requirements.txt; python setup.py install;```

then Process finished with exit code 0 with test_auto_model, test_hyperblock, test_image, test_processor

how can I try input something ?",try order first change apt server update upgrade git clone install python ak source install install pip install wheel pip install python install process finished exit code try input something,issue,negative,positive,positive,positive,positive,positive
509391206,"all of ubuntu command and result
```
Installing, this may take a few minutes...
Please create a default UNIX user account. The username does not need to match your Windows username.
For more information visit: https://aka.ms/wslusers
Enter new UNIX username: lay
Enter new UNIX password:
Retype new UNIX password:
passwd: password updated successfully
Installation successful!
To run a command as administrator (user ""root""), use ""sudo <command>"".
See ""man sudo_root"" for details.

lay@HL_ML:~$ sudo vi /etc/apt/sources.list
[sudo] password for lay:
lay@HL_ML:~$ sudo apt-get update; sudo apt-get upgrade -y; git clone https://github.com/keras-team/autokeras.git; sudo apt-get insatll python3-venv;
Get:1 http://mirror.kakao.com/ubuntu bionic InRelease [242 kB]
Get:2 http://mirror.kakao.com/ubuntu bionic-updates InRelease [88.7 kB]
Get:3 http://mirror.kakao.com/ubuntu bionic-backports InRelease [74.6 kB]
Get:4 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]
Get:5 http://mirror.kakao.com/ubuntu bionic/main amd64 Packages [1019 kB]
Get:6 http://mirror.kakao.com/ubuntu bionic/main Translation-en [516 kB]
Get:7 http://mirror.kakao.com/ubuntu bionic/restricted amd64 Packages [9184 B]
Get:8 http://mirror.kakao.com/ubuntu bionic/restricted Translation-en [3584 B]
Get:9 http://mirror.kakao.com/ubuntu bionic/universe amd64 Packages [8570 kB]
Get:10 http://mirror.kakao.com/ubuntu bionic/universe Translation-en [4941 kB]
Get:11 http://mirror.kakao.com/ubuntu bionic/multiverse amd64 Packages [151 kB]
Get:12 http://mirror.kakao.com/ubuntu bionic/multiverse Translation-en [108 kB]
Get:13 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 Packages [680 kB]
Get:14 http://mirror.kakao.com/ubuntu bionic-updates/main Translation-en [250 kB]
Get:15 http://mirror.kakao.com/ubuntu bionic-updates/restricted amd64 Packages [6996 B]
Get:16 http://mirror.kakao.com/ubuntu bionic-updates/restricted Translation-en [3076 B]
Get:17 http://mirror.kakao.com/ubuntu bionic-updates/universe amd64 Packages [970 kB]
Get:18 http://mirror.kakao.com/ubuntu bionic-updates/universe Translation-en [293 kB]
Get:19 http://mirror.kakao.com/ubuntu bionic-updates/multiverse amd64 Packages [6644 B]
Get:20 http://mirror.kakao.com/ubuntu bionic-updates/multiverse Translation-en [3556 B]
Get:21 http://mirror.kakao.com/ubuntu bionic-backports/main amd64 Packages [2512 B]
Get:22 http://mirror.kakao.com/ubuntu bionic-backports/main Translation-en [1644 B]
Get:23 http://mirror.kakao.com/ubuntu bionic-backports/universe amd64 Packages [3736 B]
Get:24 http://mirror.kakao.com/ubuntu bionic-backports/universe Translation-en [1696 B]
Get:25 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [448 kB]
Get:26 http://security.ubuntu.com/ubuntu bionic-security/main Translation-en [156 kB]
Get:27 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [570 kB]
Get:28 http://security.ubuntu.com/ubuntu bionic-security/universe Translation-en [185 kB]
Get:29 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [4008 B]
Get:30 http://security.ubuntu.com/ubuntu bionic-security/multiverse Translation-en [2060 B]
Fetched 19.4 MB in 9s (2191 kB/s)
Reading package lists... Done
Reading package lists... Done
Building dependency tree
Reading state information... Done
Calculating upgrade... Done
The following package was automatically installed and is no longer required:
  libfreetype6
Use 'sudo apt autoremove' to remove it.
The following packages will be upgraded:
  apt apt-utils bash bind9-host bzip2 cloud-init curl dbus dmeventd dmsetup dnsutils friendly-recovery gcc-8-base
  initramfs-tools initramfs-tools-bin initramfs-tools-core libapt-inst2.0 libapt-pkg5.0 libbind9-160 libbz2-1.0
  libcurl3-gnutls libcurl4 libdb5.3 libdbus-1-3 libdevmapper-event1.02.1 libdevmapper1.02.1 libdns-export1100
  libdns1100 libdrm-common libdrm2 libelf1 libexpat1 libgcc1 libglib2.0-0 libglib2.0-data libgnutls30 libirs160
  libisc-export169 libisc169 libisccc160 libisccfg160 liblvm2app2.2 liblvm2cmd2.02 liblwres160 libnss-systemd
  libpam-systemd libpython3.6 libpython3.6-minimal libpython3.6-stdlib libseccomp2 libsqlite3-0 libssl1.1 libstdc++6
  libsystemd0 libudev1 lvm2 open-vm-tools openssl python3-cryptography python3-distupgrade python3-gdbm python3-jinja2
  python3-software-properties python3.6 python3.6-minimal snapd software-properties-common systemd systemd-sysv tzdata
  ubuntu-release-upgrader-core udev update-notifier-common vim vim-common vim-runtime vim-tiny xxd
78 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.
Need to get 46.2 MB of archives.
After this operation, 2202 kB disk space will be freed.
Get:1 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 bash amd64 4.4.18-2ubuntu1.2 [614 kB]
Get:2 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 bzip2 amd64 1.0.6-8.1ubuntu0.2 [33.9 kB]
Get:3 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 libbz2-1.0 amd64 1.0.6-8.1ubuntu0.2 [31.2 kB]
Get:4 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 gcc-8-base amd64 8.3.0-6ubuntu1~18.04.1 [18.7 kB]
Get:5 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 libgcc1 amd64 1:8.3.0-6ubuntu1~18.04.1 [40.7 kB]
Get:6 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 libstdc++6 amd64 8.3.0-6ubuntu1~18.04.1 [400 kB]
Get:7 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 libnss-systemd amd64 237-3ubuntu10.24 [105 kB]
Get:8 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 libsystemd0 amd64 237-3ubuntu10.24 [204 kB]
Get:9 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 libpam-systemd amd64 237-3ubuntu10.24 [108 kB]
Get:10 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 systemd amd64 237-3ubuntu10.24 [2903 kB]
Get:11 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 udev amd64 237-3ubuntu10.24 [1101 kB]
Get:12 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 libudev1 amd64 237-3ubuntu10.24 [53.6 kB]
Get:13 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 dbus amd64 1.12.2-1ubuntu1.1 [150 kB]
Get:14 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 libdbus-1-3 amd64 1.12.2-1ubuntu1.1 [175 kB]
Get:15 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 libexpat1 amd64 2.2.5-3ubuntu0.1 [80.5 kB]
Get:16 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 friendly-recovery all 0.2.38ubuntu1.1 [8888 B]
Get:17 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 initramfs-tools all 0.130ubuntu3.8 [9592 B]
Get:18 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 initramfs-tools-core all 0.130ubuntu3.8 [48.2 kB]
Get:19 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 initramfs-tools-bin amd64 0.130ubuntu3.8 [12.7 kB]
Get:20 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 systemd-sysv amd64 237-3ubuntu10.24 [11.4 kB]
Get:21 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 libapt-pkg5.0 amd64 1.6.11 [806 kB]
Get:22 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 snapd amd64 2.39.2+18.04 [13.1 MB]
Get:77 http://security.ubuntu.com/ubuntu bionic-security/main amd64 libglib2.0-0 amd64 2.56.4-0ubuntu0.18.04.4 [1169 kB]
Get:23 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 libapt-inst2.0 amd64 1.6.11 [55.6 kB]
Get:24 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 libdb5.3 amd64 5.3.28-13.1ubuntu1.1 [672 kB]
Get:25 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 apt amd64 1.6.11 [1166 kB]
Get:26 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 apt-utils amd64 1.6.11 [206 kB]
Get:27 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 libgnutls30 amd64 3.5.18-1ubuntu1.1 [645 kB]
Get:28 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 libseccomp2 amd64 2.4.1-0ubuntu0.18.04.2 [39.1 kB]
Get:29 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 libpython3.6 amd64 3.6.8-1~18.04.1 [1418 kB]
Get:30 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 libssl1.1 amd64 1.1.1-1ubuntu2.1~18.04.3 [1295 kB]
Get:31 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 python3.6 amd64 3.6.8-1~18.04.1 [202 kB]
Get:32 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 python3.6-minimal amd64 3.6.8-1~18.04.1 [1620 kB]
Get:33 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 libpython3.6-stdlib amd64 3.6.8-1~18.04.1 [1715 kB]
Get:34 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 libpython3.6-minimal amd64 3.6.8-1~18.04.1 [533 kB]
Get:35 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 libsqlite3-0 amd64 3.22.0-1ubuntu0.1 [497 kB]
Get:36 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 update-notifier-common all 3.192.1.7 [160 kB]
Get:37 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 libdevmapper1.02.1 amd64 2:1.02.145-4.1ubuntu3.18.04.1 [127 kB]
Get:38 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 dmsetup amd64 2:1.02.145-4.1ubuntu3.18.04.1 [74.4 kB]
Get:39 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 libisc-export169 amd64 1:9.11.3+dfsg-1ubuntu1.8 [164 kB]
Get:40 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 libdns-export1100 amd64 1:9.11.3+dfsg-1ubuntu1.8 [749 kB]
Get:41 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 libelf1 amd64 0.170-0.4ubuntu0.1 [44.8 kB]
Get:42 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 openssl amd64 1.1.1-1ubuntu2.1~18.04.3 [614 kB]
Get:43 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 tzdata all 2019b-0ubuntu0.18.04 [190 kB]
Get:44 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 xxd amd64 2:8.0.1453-1ubuntu1.1 [49.2 kB]
Get:45 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 vim amd64 2:8.0.1453-1ubuntu1.1 [1152 kB]
Get:46 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 vim-tiny amd64 2:8.0.1453-1ubuntu1.1 [475 kB]
Get:47 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 vim-runtime all 2:8.0.1453-1ubuntu1.1 [5435 kB]
Get:48 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 vim-common all 2:8.0.1453-1ubuntu1.1 [70.4 kB]
Get:49 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 libirs160 amd64 1:9.11.3+dfsg-1ubuntu1.8 [19.1 kB]
Get:50 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 bind9-host amd64 1:9.11.3+dfsg-1ubuntu1.8 [53.6 kB]
Get:51 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 dnsutils amd64 1:9.11.3+dfsg-1ubuntu1.8 [146 kB]
Get:52 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 libbind9-160 amd64 1:9.11.3+dfsg-1ubuntu1.8 [27.6 kB]
Get:53 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 libisccfg160 amd64 1:9.11.3+dfsg-1ubuntu1.8 [48.5 kB]
Get:54 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 libisccc160 amd64 1:9.11.3+dfsg-1ubuntu1.8 [17.9 kB]
Get:55 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 libdns1100 amd64 1:9.11.3+dfsg-1ubuntu1.8 [966 kB]
Get:56 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 libisc169 amd64 1:9.11.3+dfsg-1ubuntu1.8 [238 kB]
Get:57 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 liblwres160 amd64 1:9.11.3+dfsg-1ubuntu1.8 [34.8 kB]
Get:58 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 libdrm-common all 2.4.97-1ubuntu1~18.04.1 [5216 B]
Get:59 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 libdrm2 amd64 2.4.97-1ubuntu1~18.04.1 [31.3 kB]
Get:60 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 ubuntu-release-upgrader-core all 1:18.04.34 [25.2 kB]
Get:61 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 python3-distupgrade all 1:18.04.34 [107 kB]
Get:62 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 python3-gdbm amd64 3.6.8-1~18.04 [13.3 kB]
Get:63 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 curl amd64 7.58.0-2ubuntu3.7 [159 kB]
Get:64 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 libcurl4 amd64 7.58.0-2ubuntu3.7 [214 kB]
Get:65 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 libdevmapper-event1.02.1 amd64 2:1.02.145-4.1ubuntu3.18.04.1 [10.9 kB]
Get:66 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 liblvm2cmd2.02 amd64 2.02.176-4.1ubuntu3.18.04.1 [585 kB]
Get:67 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 dmeventd amd64 2:1.02.145-4.1ubuntu3.18.04.1 [30.4 kB]
Get:68 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 libcurl3-gnutls amd64 7.58.0-2ubuntu3.7 [212 kB]
Get:69 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 liblvm2app2.2 amd64 2.02.176-4.1ubuntu3.18.04.1 [432 kB]
Get:70 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 lvm2 amd64 2.02.176-4.1ubuntu3.18.04.1 [928 kB]
Get:71 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 python3-cryptography amd64 2.1.4-1ubuntu1.3 [221 kB]
Get:72 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 python3-jinja2 all 2.10-1ubuntu0.18.04.1 [95.4 kB]
Get:73 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 software-properties-common all 0.96.24.32.9 [9992 B]
Get:74 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 python3-software-properties all 0.96.24.32.9 [23.8 kB]
Get:75 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 cloud-init all 19.1-1-gbaa47854-0ubuntu1~18.04.1 [393 kB]
Get:76 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 open-vm-tools amd64 2:10.3.10-1~ubuntu0.18.04.1 [545 kB]
Get:78 http://security.ubuntu.com/ubuntu bionic-security/main amd64 libglib2.0-data all 2.56.4-0ubuntu0.18.04.4 [4496 B]
Fetched 46.2 MB in 6s (7247 kB/s)
Extracting templates from packages: 100%
Preconfiguring packages ...
(Reading database ... 28645 files and directories currently installed.)
Preparing to unpack .../bash_4.4.18-2ubuntu1.2_amd64.deb ...
Unpacking bash (4.4.18-2ubuntu1.2) over (4.4.18-2ubuntu1.1) ...
Setting up bash (4.4.18-2ubuntu1.2) ...
update-alternatives: using /usr/share/man/man7/bash-builtins.7.gz to provide /usr/share/man/man7/builtins.7.gz (builtins.7.gz) in auto mode
(Reading database ... 28645 files and directories currently installed.)
Preparing to unpack .../bzip2_1.0.6-8.1ubuntu0.2_amd64.deb ...
Unpacking bzip2 (1.0.6-8.1ubuntu0.2) over (1.0.6-8.1) ...
Preparing to unpack .../libbz2-1.0_1.0.6-8.1ubuntu0.2_amd64.deb ...
Unpacking libbz2-1.0:amd64 (1.0.6-8.1ubuntu0.2) over (1.0.6-8.1) ...
Setting up libbz2-1.0:amd64 (1.0.6-8.1ubuntu0.2) ...
(Reading database ... 28645 files and directories currently installed.)
Preparing to unpack .../gcc-8-base_8.3.0-6ubuntu1~18.04.1_amd64.deb ...
Unpacking gcc-8-base:amd64 (8.3.0-6ubuntu1~18.04.1) over (8.3.0-6ubuntu1~18.04) ...
Setting up gcc-8-base:amd64 (8.3.0-6ubuntu1~18.04.1) ...
(Reading database ... 28645 files and directories currently installed.)
Preparing to unpack .../libgcc1_1%3a8.3.0-6ubuntu1~18.04.1_amd64.deb ...
Unpacking libgcc1:amd64 (1:8.3.0-6ubuntu1~18.04.1) over (1:8.3.0-6ubuntu1~18.04) ...
Setting up libgcc1:amd64 (1:8.3.0-6ubuntu1~18.04.1) ...
(Reading database ... 28645 files and directories currently installed.)
Preparing to unpack .../libstdc++6_8.3.0-6ubuntu1~18.04.1_amd64.deb ...
Unpacking libstdc++6:amd64 (8.3.0-6ubuntu1~18.04.1) over (8.3.0-6ubuntu1~18.04) ...
Setting up libstdc++6:amd64 (8.3.0-6ubuntu1~18.04.1) ...
(Reading database ... 28645 files and directories currently installed.)
Preparing to unpack .../libnss-systemd_237-3ubuntu10.24_amd64.deb ...
Unpacking libnss-systemd:amd64 (237-3ubuntu10.24) over (237-3ubuntu10.21) ...
Preparing to unpack .../libsystemd0_237-3ubuntu10.24_amd64.deb ...
Unpacking libsystemd0:amd64 (237-3ubuntu10.24) over (237-3ubuntu10.21) ...
Setting up libsystemd0:amd64 (237-3ubuntu10.24) ...
(Reading database ... 28645 files and directories currently installed.)
Preparing to unpack .../libpam-systemd_237-3ubuntu10.24_amd64.deb ...
Unpacking libpam-systemd:amd64 (237-3ubuntu10.24) over (237-3ubuntu10.21) ...
Preparing to unpack .../systemd_237-3ubuntu10.24_amd64.deb ...
Unpacking systemd (237-3ubuntu10.24) over (237-3ubuntu10.21) ...
Preparing to unpack .../udev_237-3ubuntu10.24_amd64.deb ...
Unpacking udev (237-3ubuntu10.24) over (237-3ubuntu10.21) ...
Preparing to unpack .../libudev1_237-3ubuntu10.24_amd64.deb ...
Unpacking libudev1:amd64 (237-3ubuntu10.24) over (237-3ubuntu10.21) ...
Setting up libudev1:amd64 (237-3ubuntu10.24) ...
(Reading database ... 28645 files and directories currently installed.)
Preparing to unpack .../0-dbus_1.12.2-1ubuntu1.1_amd64.deb ...
Unpacking dbus (1.12.2-1ubuntu1.1) over (1.12.2-1ubuntu1) ...
Preparing to unpack .../1-libdbus-1-3_1.12.2-1ubuntu1.1_amd64.deb ...
Unpacking libdbus-1-3:amd64 (1.12.2-1ubuntu1.1) over (1.12.2-1ubuntu1) ...
Preparing to unpack .../2-libexpat1_2.2.5-3ubuntu0.1_amd64.deb ...
Unpacking libexpat1:amd64 (2.2.5-3ubuntu0.1) over (2.2.5-3) ...
Preparing to unpack .../3-friendly-recovery_0.2.38ubuntu1.1_all.deb ...
Unpacking friendly-recovery (0.2.38ubuntu1.1) over (0.2.38ubuntu1) ...
Preparing to unpack .../4-initramfs-tools_0.130ubuntu3.8_all.deb ...
Unpacking initramfs-tools (0.130ubuntu3.8) over (0.130ubuntu3.7) ...
Preparing to unpack .../5-initramfs-tools-core_0.130ubuntu3.8_all.deb ...
Unpacking initramfs-tools-core (0.130ubuntu3.8) over (0.130ubuntu3.7) ...
Preparing to unpack .../6-initramfs-tools-bin_0.130ubuntu3.8_amd64.deb ...
Unpacking initramfs-tools-bin (0.130ubuntu3.8) over (0.130ubuntu3.7) ...
Setting up systemd (237-3ubuntu10.24) ...
Initializing machine ID from random generator.
(Reading database ... 28645 files and directories currently installed.)
Preparing to unpack .../systemd-sysv_237-3ubuntu10.24_amd64.deb ...
Unpacking systemd-sysv (237-3ubuntu10.24) over (237-3ubuntu10.21) ...
Preparing to unpack .../libapt-pkg5.0_1.6.11_amd64.deb ...
Unpacking libapt-pkg5.0:amd64 (1.6.11) over (1.6.10) ...
Setting up libapt-pkg5.0:amd64 (1.6.11) ...
(Reading database ... 28645 files and directories currently installed.)
Preparing to unpack .../snapd_2.39.2+18.04_amd64.deb ...
Unpacking snapd (2.39.2+18.04) over (2.38+18.04) ...
Preparing to unpack .../libapt-inst2.0_1.6.11_amd64.deb ...
Unpacking libapt-inst2.0:amd64 (1.6.11) over (1.6.10) ...
Preparing to unpack .../libdb5.3_5.3.28-13.1ubuntu1.1_amd64.deb ...
Unpacking libdb5.3:amd64 (5.3.28-13.1ubuntu1.1) over (5.3.28-13.1ubuntu1) ...
Setting up libdb5.3:amd64 (5.3.28-13.1ubuntu1.1) ...
(Reading database ... 28645 files and directories currently installed.)
Preparing to unpack .../archives/apt_1.6.11_amd64.deb ...
Unpacking apt (1.6.11) over (1.6.10) ...
Setting up apt (1.6.11) ...
Installing new version of config file /etc/apt/apt.conf.d/01autoremove ...
(Reading database ... 28645 files and directories currently installed.)
Preparing to unpack .../apt-utils_1.6.11_amd64.deb ...
Unpacking apt-utils (1.6.11) over (1.6.10) ...
Preparing to unpack .../libgnutls30_3.5.18-1ubuntu1.1_amd64.deb ...
Unpacking libgnutls30:amd64 (3.5.18-1ubuntu1.1) over (3.5.18-1ubuntu1) ...
Setting up libgnutls30:amd64 (3.5.18-1ubuntu1.1) ...
(Reading database ... 28645 files and directories currently installed.)
Preparing to unpack .../libseccomp2_2.4.1-0ubuntu0.18.04.2_amd64.deb ...
Unpacking libseccomp2:amd64 (2.4.1-0ubuntu0.18.04.2) over (2.3.1-2.1ubuntu4.1) ...
Setting up libseccomp2:amd64 (2.4.1-0ubuntu0.18.04.2) ...
(Reading database ... 28645 files and directories currently installed.)
Preparing to unpack .../00-libpython3.6_3.6.8-1~18.04.1_amd64.deb ...
Unpacking libpython3.6:amd64 (3.6.8-1~18.04.1) over (3.6.7-1~18.04) ...
Preparing to unpack .../01-libssl1.1_1.1.1-1ubuntu2.1~18.04.3_amd64.deb ...
Unpacking libssl1.1:amd64 (1.1.1-1ubuntu2.1~18.04.3) over (1.1.0g-2ubuntu4.3) ...
Preparing to unpack .../02-python3.6_3.6.8-1~18.04.1_amd64.deb ...
Unpacking python3.6 (3.6.8-1~18.04.1) over (3.6.7-1~18.04) ...
Preparing to unpack .../03-python3.6-minimal_3.6.8-1~18.04.1_amd64.deb ...
Unpacking python3.6-minimal (3.6.8-1~18.04.1) over (3.6.7-1~18.04) ...
Preparing to unpack .../04-libpython3.6-stdlib_3.6.8-1~18.04.1_amd64.deb ...
Unpacking libpython3.6-stdlib:amd64 (3.6.8-1~18.04.1) over (3.6.7-1~18.04) ...
Preparing to unpack .../05-libpython3.6-minimal_3.6.8-1~18.04.1_amd64.deb ...
Unpacking libpython3.6-minimal:amd64 (3.6.8-1~18.04.1) over (3.6.7-1~18.04) ...
Preparing to unpack .../06-libsqlite3-0_3.22.0-1ubuntu0.1_amd64.deb ...
Unpacking libsqlite3-0:amd64 (3.22.0-1ubuntu0.1) over (3.22.0-1) ...
Preparing to unpack .../07-update-notifier-common_3.192.1.7_all.deb ...
Unpacking update-notifier-common (3.192.1.7) over (3.192.1.5) ...
Preparing to unpack .../08-libdevmapper1.02.1_2%3a1.02.145-4.1ubuntu3.18.04.1_amd64.deb ...
Unpacking libdevmapper1.02.1:amd64 (2:1.02.145-4.1ubuntu3.18.04.1) over (2:1.02.145-4.1ubuntu3) ...
Preparing to unpack .../09-dmsetup_2%3a1.02.145-4.1ubuntu3.18.04.1_amd64.deb ...
Unpacking dmsetup (2:1.02.145-4.1ubuntu3.18.04.1) over (2:1.02.145-4.1ubuntu3) ...
Preparing to unpack .../10-libisc-export169_1%3a9.11.3+dfsg-1ubuntu1.8_amd64.deb ...
Unpacking libisc-export169:amd64 (1:9.11.3+dfsg-1ubuntu1.8) over (1:9.11.3+dfsg-1ubuntu1.7) ...
Preparing to unpack .../11-libdns-export1100_1%3a9.11.3+dfsg-1ubuntu1.8_amd64.deb ...
Unpacking libdns-export1100 (1:9.11.3+dfsg-1ubuntu1.8) over (1:9.11.3+dfsg-1ubuntu1.7) ...
Preparing to unpack .../12-libelf1_0.170-0.4ubuntu0.1_amd64.deb ...
Unpacking libelf1:amd64 (0.170-0.4ubuntu0.1) over (0.170-0.4) ...
Preparing to unpack .../13-libglib2.0-0_2.56.4-0ubuntu0.18.04.4_amd64.deb ...
Unpacking libglib2.0-0:amd64 (2.56.4-0ubuntu0.18.04.4) over (2.56.4-0ubuntu0.18.04.2) ...
Preparing to unpack .../14-libglib2.0-data_2.56.4-0ubuntu0.18.04.4_all.deb ...
Unpacking libglib2.0-data (2.56.4-0ubuntu0.18.04.4) over (2.56.4-0ubuntu0.18.04.2) ...
Preparing to unpack .../15-openssl_1.1.1-1ubuntu2.1~18.04.3_amd64.deb ...
Unpacking openssl (1.1.1-1ubuntu2.1~18.04.3) over (1.1.0g-2ubuntu4.3) ...
Preparing to unpack .../16-tzdata_2019b-0ubuntu0.18.04_all.deb ...
Unpacking tzdata (2019b-0ubuntu0.18.04) over (2019a-0ubuntu0.18.04) ...
Preparing to unpack .../17-xxd_2%3a8.0.1453-1ubuntu1.1_amd64.deb ...
Unpacking xxd (2:8.0.1453-1ubuntu1.1) over (2:8.0.1453-1ubuntu1) ...
Preparing to unpack .../18-vim_2%3a8.0.1453-1ubuntu1.1_amd64.deb ...
Unpacking vim (2:8.0.1453-1ubuntu1.1) over (2:8.0.1453-1ubuntu1) ...
Preparing to unpack .../19-vim-tiny_2%3a8.0.1453-1ubuntu1.1_amd64.deb ...
Unpacking vim-tiny (2:8.0.1453-1ubuntu1.1) over (2:8.0.1453-1ubuntu1) ...
Preparing to unpack .../20-vim-runtime_2%3a8.0.1453-1ubuntu1.1_all.deb ...
Unpacking vim-runtime (2:8.0.1453-1ubuntu1.1) over (2:8.0.1453-1ubuntu1) ...
Preparing to unpack .../21-vim-common_2%3a8.0.1453-1ubuntu1.1_all.deb ...
Unpacking vim-common (2:8.0.1453-1ubuntu1.1) over (2:8.0.1453-1ubuntu1) ...
Preparing to unpack .../22-libirs160_1%3a9.11.3+dfsg-1ubuntu1.8_amd64.deb ...
Unpacking libirs160:amd64 (1:9.11.3+dfsg-1ubuntu1.8) over (1:9.11.3+dfsg-1ubuntu1.7) ...
Preparing to unpack .../23-bind9-host_1%3a9.11.3+dfsg-1ubuntu1.8_amd64.deb ...
Unpacking bind9-host (1:9.11.3+dfsg-1ubuntu1.8) over (1:9.11.3+dfsg-1ubuntu1.7) ...
Preparing to unpack .../24-dnsutils_1%3a9.11.3+dfsg-1ubuntu1.8_amd64.deb ...
Unpacking dnsutils (1:9.11.3+dfsg-1ubuntu1.8) over (1:9.11.3+dfsg-1ubuntu1.7) ...
Preparing to unpack .../25-libbind9-160_1%3a9.11.3+dfsg-1ubuntu1.8_amd64.deb ...
Unpacking libbind9-160:amd64 (1:9.11.3+dfsg-1ubuntu1.8) over (1:9.11.3+dfsg-1ubuntu1.7) ...
Preparing to unpack .../26-libisccfg160_1%3a9.11.3+dfsg-1ubuntu1.8_amd64.deb ...
Unpacking libisccfg160:amd64 (1:9.11.3+dfsg-1ubuntu1.8) over (1:9.11.3+dfsg-1ubuntu1.7) ...
Preparing to unpack .../27-libisccc160_1%3a9.11.3+dfsg-1ubuntu1.8_amd64.deb ...
Unpacking libisccc160:amd64 (1:9.11.3+dfsg-1ubuntu1.8) over (1:9.11.3+dfsg-1ubuntu1.7) ...
Preparing to unpack .../28-libdns1100_1%3a9.11.3+dfsg-1ubuntu1.8_amd64.deb ...
Unpacking libdns1100:amd64 (1:9.11.3+dfsg-1ubuntu1.8) over (1:9.11.3+dfsg-1ubuntu1.7) ...
Preparing to unpack .../29-libisc169_1%3a9.11.3+dfsg-1ubuntu1.8_amd64.deb ...
Unpacking libisc169:amd64 (1:9.11.3+dfsg-1ubuntu1.8) over (1:9.11.3+dfsg-1ubuntu1.7) ...
Preparing to unpack .../30-liblwres160_1%3a9.11.3+dfsg-1ubuntu1.8_amd64.deb ...
Unpacking liblwres160:amd64 (1:9.11.3+dfsg-1ubuntu1.8) over (1:9.11.3+dfsg-1ubuntu1.7) ...
Preparing to unpack .../31-libdrm-common_2.4.97-1ubuntu1~18.04.1_all.deb ...
Unpacking libdrm-common (2.4.97-1ubuntu1~18.04.1) over (2.4.95-1~18.04.1) ...
Preparing to unpack .../32-libdrm2_2.4.97-1ubuntu1~18.04.1_amd64.deb ...
Unpacking libdrm2:amd64 (2.4.97-1ubuntu1~18.04.1) over (2.4.95-1~18.04.1) ...
Preparing to unpack .../33-ubuntu-release-upgrader-core_1%3a18.04.34_all.deb ...
Unpacking ubuntu-release-upgrader-core (1:18.04.34) over (1:18.04.32) ...
Preparing to unpack .../34-python3-distupgrade_1%3a18.04.34_all.deb ...
Unpacking python3-distupgrade (1:18.04.34) over (1:18.04.32) ...
Preparing to unpack .../35-python3-gdbm_3.6.8-1~18.04_amd64.deb ...
Unpacking python3-gdbm:amd64 (3.6.8-1~18.04) over (3.6.7-1~18.04) ...
Preparing to unpack .../36-curl_7.58.0-2ubuntu3.7_amd64.deb ...
Unpacking curl (7.58.0-2ubuntu3.7) over (7.58.0-2ubuntu3.6) ...
Preparing to unpack .../37-libcurl4_7.58.0-2ubuntu3.7_amd64.deb ...
Unpacking libcurl4:amd64 (7.58.0-2ubuntu3.7) over (7.58.0-2ubuntu3.6) ...
Preparing to unpack .../38-libdevmapper-event1.02.1_2%3a1.02.145-4.1ubuntu3.18.04.1_amd64.deb ...
Unpacking libdevmapper-event1.02.1:amd64 (2:1.02.145-4.1ubuntu3.18.04.1) over (2:1.02.145-4.1ubuntu3) ...
Preparing to unpack .../39-liblvm2cmd2.02_2.02.176-4.1ubuntu3.18.04.1_amd64.deb ...
Unpacking liblvm2cmd2.02:amd64 (2.02.176-4.1ubuntu3.18.04.1) over (2.02.176-4.1ubuntu3) ...
Preparing to unpack .../40-dmeventd_2%3a1.02.145-4.1ubuntu3.18.04.1_amd64.deb ...
Unpacking dmeventd (2:1.02.145-4.1ubuntu3.18.04.1) over (2:1.02.145-4.1ubuntu3) ...
Preparing to unpack .../41-libcurl3-gnutls_7.58.0-2ubuntu3.7_amd64.deb ...
Unpacking libcurl3-gnutls:amd64 (7.58.0-2ubuntu3.7) over (7.58.0-2ubuntu3.6) ...
Preparing to unpack .../42-liblvm2app2.2_2.02.176-4.1ubuntu3.18.04.1_amd64.deb ...
Unpacking liblvm2app2.2:amd64 (2.02.176-4.1ubuntu3.18.04.1) over (2.02.176-4.1ubuntu3) ...
Preparing to unpack .../43-lvm2_2.02.176-4.1ubuntu3.18.04.1_amd64.deb ...
Unpacking lvm2 (2.02.176-4.1ubuntu3.18.04.1) over (2.02.176-4.1ubuntu3) ...
Preparing to unpack .../44-python3-cryptography_2.1.4-1ubuntu1.3_amd64.deb ...
Unpacking python3-cryptography (2.1.4-1ubuntu1.3) over (2.1.4-1ubuntu1.2) ...
Preparing to unpack .../45-python3-jinja2_2.10-1ubuntu0.18.04.1_all.deb ...
Unpacking python3-jinja2 (2.10-1ubuntu0.18.04.1) over (2.10-1) ...
Preparing to unpack .../46-software-properties-common_0.96.24.32.9_all.deb ...
Unpacking software-properties-common (0.96.24.32.9) over (0.96.24.32.7) ...
Preparing to unpack .../47-python3-software-properties_0.96.24.32.9_all.deb ...
Unpacking python3-software-properties (0.96.24.32.9) over (0.96.24.32.7) ...
Preparing to unpack .../48-cloud-init_19.1-1-gbaa47854-0ubuntu1~18.04.1_all.deb ...
Unpacking cloud-init (19.1-1-gbaa47854-0ubuntu1~18.04.1) over (18.5-45-g3554ffe8-0ubuntu1~18.04.1) ...
Preparing to unpack .../49-open-vm-tools_2%3a10.3.10-1~ubuntu0.18.04.1_amd64.deb ...
Unpacking open-vm-tools (2:10.3.10-1~ubuntu0.18.04.1) over (2:10.3.5-7~ubuntu0.18.04.1) ...
Setting up libapt-inst2.0:amd64 (1.6.11) ...
Setting up libnss-systemd:amd64 (237-3ubuntu10.24) ...
Setting up libexpat1:amd64 (2.2.5-3ubuntu0.1) ...
Processing triggers for mime-support (3.60ubuntu1) ...
Processing triggers for ureadahead (0.100.0-21) ...
Setting up update-notifier-common (3.192.1.7) ...
Setting up xxd (2:8.0.1453-1ubuntu1.1) ...
Setting up apt-utils (1.6.11) ...
Processing triggers for install-info (6.5.0.dfsg.1-2) ...
Setting up libcurl3-gnutls:amd64 (7.58.0-2ubuntu3.7) ...
Setting up tzdata (2019b-0ubuntu0.18.04) ...

Current default time zone: 'Asia/Seoul'
Local time is now:      Tue Jul  9 05:54:38 KST 2019.
Universal Time is now:  Mon Jul  8 20:54:38 UTC 2019.
Run 'dpkg-reconfigure tzdata' if you wish to change it.

Setting up systemd-sysv (237-3ubuntu10.24) ...
Setting up libelf1:amd64 (0.170-0.4ubuntu0.1) ...
Setting up libglib2.0-0:amd64 (2.56.4-0ubuntu0.18.04.4) ...
No schema files found: doing nothing.
Setting up libdevmapper1.02.1:amd64 (2:1.02.145-4.1ubuntu3.18.04.1) ...
Setting up bzip2 (1.0.6-8.1ubuntu0.2) ...
Setting up libdrm-common (2.4.97-1ubuntu1~18.04.1) ...
Setting up libdevmapper-event1.02.1:amd64 (2:1.02.145-4.1ubuntu3.18.04.1) ...
Setting up libglib2.0-data (2.56.4-0ubuntu0.18.04.4) ...
Processing triggers for libc-bin (2.27-3ubuntu1) ...
Setting up udev (237-3ubuntu10.24) ...
invoke-rc.d: could not determine current runlevel
update-initramfs: deferring update (trigger activated)
Setting up libssl1.1:amd64 (1.1.1-1ubuntu2.1~18.04.3) ...
Checking for services that may need to be restarted...done.
Checking for services that may need to be restarted...done.
Checking init scripts...

Restarting services possibly affected by the upgrade:
invoke-rc.d: could not determine current runlevel

Services restarted successfully.

Setting up python3-jinja2 (2.10-1ubuntu0.18.04.1) ...
Processing triggers for systemd (237-3ubuntu10.24) ...
Setting up openssl (1.1.1-1ubuntu2.1~18.04.3) ...
Installing new version of config file /etc/ssl/openssl.cnf ...
Setting up vim-common (2:8.0.1453-1ubuntu1.1) ...
Setting up libsqlite3-0:amd64 (3.22.0-1ubuntu0.1) ...
Setting up dmsetup (2:1.02.145-4.1ubuntu3.18.04.1) ...
update-initramfs: deferring update (trigger activated)
Setting up python3-gdbm:amd64 (3.6.8-1~18.04) ...
Setting up liblvm2app2.2:amd64 (2.02.176-4.1ubuntu3.18.04.1) ...
Processing triggers for man-db (2.8.3-2ubuntu0.1) ...
Setting up python3-software-properties (0.96.24.32.9) ...
Setting up vim-runtime (2:8.0.1453-1ubuntu1.1) ...
Setting up initramfs-tools-bin (0.130ubuntu3.8) ...
Setting up friendly-recovery (0.2.38ubuntu1.1) ...
Setting up liblwres160:amd64 (1:9.11.3+dfsg-1ubuntu1.8) ...
Processing triggers for rsyslog (8.32.0-1ubuntu4) ...
invoke-rc.d: could not determine current runlevel
Setting up libdbus-1-3:amd64 (1.12.2-1ubuntu1.1) ...
Setting up python3-distupgrade (1:18.04.34) ...
Setting up cloud-init (19.1-1-gbaa47854-0ubuntu1~18.04.1) ...
Installing new version of config file /etc/cloud/cloud.cfg ...
Setting up software-properties-common (0.96.24.32.9) ...
Setting up python3-cryptography (2.1.4-1ubuntu1.3) ...
Setting up vim-tiny (2:8.0.1453-1ubuntu1.1) ...
Setting up libisc169:amd64 (1:9.11.3+dfsg-1ubuntu1.8) ...
Setting up libisccc160:amd64 (1:9.11.3+dfsg-1ubuntu1.8) ...
Setting up initramfs-tools-core (0.130ubuntu3.8) ...
Setting up libisc-export169:amd64 (1:9.11.3+dfsg-1ubuntu1.8) ...
Setting up libcurl4:amd64 (7.58.0-2ubuntu3.7) ...
Setting up initramfs-tools (0.130ubuntu3.8) ...
update-initramfs: deferring update (trigger activated)
Setting up ubuntu-release-upgrader-core (1:18.04.34) ...
Setting up libdrm2:amd64 (2.4.97-1ubuntu1~18.04.1) ...
Setting up libpython3.6-minimal:amd64 (3.6.8-1~18.04.1) ...
Setting up snapd (2.39.2+18.04) ...
Installing new version of config file /etc/apparmor.d/usr.lib.snapd.snap-confine.real ...
md5sum: /etc/apparmor.d/usr.lib.snapd.snap-confine: No such file or directory
Setting up libdns-export1100 (1:9.11.3+dfsg-1ubuntu1.8) ...
Setting up dbus (1.12.2-1ubuntu1.1) ...
Setting up libdns1100:amd64 (1:9.11.3+dfsg-1ubuntu1.8) ...
Setting up libpython3.6-stdlib:amd64 (3.6.8-1~18.04.1) ...
Setting up libpam-systemd:amd64 (237-3ubuntu10.24) ...
Setting up curl (7.58.0-2ubuntu3.7) ...
Setting up open-vm-tools (2:10.3.10-1~ubuntu0.18.04.1) ...
invoke-rc.d: could not determine current runlevel
Setting up python3.6-minimal (3.6.8-1~18.04.1) ...
Setting up libisccfg160:amd64 (1:9.11.3+dfsg-1ubuntu1.8) ...
Setting up libpython3.6:amd64 (3.6.8-1~18.04.1) ...
Setting up python3.6 (3.6.8-1~18.04.1) ...
Setting up vim (2:8.0.1453-1ubuntu1.1) ...
Setting up libirs160:amd64 (1:9.11.3+dfsg-1ubuntu1.8) ...
Setting up libbind9-160:amd64 (1:9.11.3+dfsg-1ubuntu1.8) ...
Setting up bind9-host (1:9.11.3+dfsg-1ubuntu1.8) ...
Setting up dnsutils (1:9.11.3+dfsg-1ubuntu1.8) ...
Setting up liblvm2cmd2.02:amd64 (2.02.176-4.1ubuntu3.18.04.1) ...
Setting up dmeventd (2:1.02.145-4.1ubuntu3.18.04.1) ...
Setting up lvm2 (2.02.176-4.1ubuntu3.18.04.1) ...
invoke-rc.d: could not determine current runlevel
update-initramfs: deferring update (trigger activated)
invoke-rc.d: could not determine current runlevel
invoke-rc.d: could not determine current runlevel
Processing triggers for libc-bin (2.27-3ubuntu1) ...
Processing triggers for initramfs-tools (0.130ubuntu3.8) ...
Cloning into 'autokeras'...
remote: Enumerating objects: 282, done.
remote: Counting objects: 100% (282/282), done.
remote: Compressing objects: 100% (163/163), done.
remote: Total 9394 (delta 187), reused 167 (delta 104), pack-reused 9112
Receiving objects: 100% (9394/9394), 68.51 MiB | 14.47 MiB/s, done.
Resolving deltas: 100% (6214/6214), done.
E: Invalid operation insatll
lay@HL_ML:~$ sudo apt-get install python3-venv;
Reading package lists... Done
Building dependency tree
Reading state information... Done
The following package was automatically installed and is no longer required:
  libfreetype6
Use 'sudo apt autoremove' to remove it.
The following additional packages will be installed:
  python-pip-whl python3-distutils python3-lib2to3 python3.6-venv
The following NEW packages will be installed:
  python-pip-whl python3-distutils python3-lib2to3 python3-venv python3.6-venv
0 upgraded, 5 newly installed, 0 to remove and 0 not upgraded.
Need to get 1878 kB of archives.
After this operation, 4017 kB of additional disk space will be used.
Do you want to continue? [Y/n] y
Get:1 http://mirror.kakao.com/ubuntu bionic-updates/universe amd64 python-pip-whl all 9.0.1-2.3~ubuntu1.18.04.1 [1653 kB]
Get:2 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 python3-lib2to3 all 3.6.8-1~18.04 [76.5 kB]
Get:3 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 python3-distutils all 3.6.8-1~18.04 [141 kB]
Get:4 http://mirror.kakao.com/ubuntu bionic-updates/universe amd64 python3.6-venv amd64 3.6.8-1~18.04.1 [6184 B]
Get:5 http://mirror.kakao.com/ubuntu bionic-updates/universe amd64 python3-venv amd64 3.6.7-1~18.04 [1208 B]
Fetched 1878 kB in 0s (7364 kB/s)
Selecting previously unselected package python-pip-whl.
(Reading database ... 28657 files and directories currently installed.)
Preparing to unpack .../python-pip-whl_9.0.1-2.3~ubuntu1.18.04.1_all.deb ...
Unpacking python-pip-whl (9.0.1-2.3~ubuntu1.18.04.1) ...
Selecting previously unselected package python3-lib2to3.
Preparing to unpack .../python3-lib2to3_3.6.8-1~18.04_all.deb ...
Unpacking python3-lib2to3 (3.6.8-1~18.04) ...
Selecting previously unselected package python3-distutils.
Preparing to unpack .../python3-distutils_3.6.8-1~18.04_all.deb ...
Unpacking python3-distutils (3.6.8-1~18.04) ...
Selecting previously unselected package python3.6-venv.
Preparing to unpack .../python3.6-venv_3.6.8-1~18.04.1_amd64.deb ...
Unpacking python3.6-venv (3.6.8-1~18.04.1) ...
Selecting previously unselected package python3-venv.
Preparing to unpack .../python3-venv_3.6.7-1~18.04_amd64.deb ...
Unpacking python3-venv (3.6.7-1~18.04) ...
Setting up python-pip-whl (9.0.1-2.3~ubuntu1.18.04.1) ...
Setting up python3.6-venv (3.6.8-1~18.04.1) ...
Processing triggers for man-db (2.8.3-2ubuntu0.1) ...
Setting up python3-lib2to3 (3.6.8-1~18.04) ...
Setting up python3-distutils (3.6.8-1~18.04) ...
Setting up python3-venv (3.6.7-1~18.04) ...
lay@HL_ML:~$ python3 -m venv ak
lay@HL_ML:~$ source ak/bin/activate
(ak) lay@HL_ML:~$ cd autokeras/
(ak) lay@HL_ML:~/autokeras$ sudo apt-get install gcc; sudo apt-get install python3-dev; pip install wheel;
Reading package lists... Done
Building dependency tree
Reading state information... Done
The following package was automatically installed and is no longer required:
  libfreetype6
Use 'sudo apt autoremove' to remove it.
The following additional packages will be installed:
  binutils binutils-common binutils-x86-64-linux-gnu cpp cpp-7 gcc-7 gcc-7-base libasan4 libatomic1 libbinutils
  libc-dev-bin libc6-dev libcc1-0 libcilkrts5 libgcc-7-dev libgomp1 libisl19 libitm1 liblsan0 libmpc3 libmpx2
  libquadmath0 libtsan0 libubsan0 linux-libc-dev manpages-dev
Suggested packages:
  binutils-doc cpp-doc gcc-7-locales gcc-multilib make autoconf automake libtool flex bison gdb gcc-doc gcc-7-multilib
  gcc-7-doc libgcc1-dbg libgomp1-dbg libitm1-dbg libatomic1-dbg libasan4-dbg liblsan0-dbg libtsan0-dbg libubsan0-dbg
  libcilkrts5-dbg libmpx2-dbg libquadmath0-dbg glibc-doc
The following NEW packages will be installed:
  binutils binutils-common binutils-x86-64-linux-gnu cpp cpp-7 gcc gcc-7 gcc-7-base libasan4 libatomic1 libbinutils
  libc-dev-bin libc6-dev libcc1-0 libcilkrts5 libgcc-7-dev libgomp1 libisl19 libitm1 liblsan0 libmpc3 libmpx2
  libquadmath0 libtsan0 libubsan0 linux-libc-dev manpages-dev
0 upgraded, 27 newly installed, 0 to remove and 0 not upgraded.
Need to get 26.9 MB of archives.
After this operation, 115 MB of additional disk space will be used.
Do you want to continue? [Y/n] ^C
(ak) lay@HL_ML:~/autokeras$ sudo apt-get install gcc -y; sudo apt-get install python3-dev -y; pip install wheel;
Reading package lists... Done
Building dependency tree
Reading state information... Done
The following package was automatically installed and is no longer required:
  libfreetype6
Use 'sudo apt autoremove' to remove it.
The following additional packages will be installed:
  binutils binutils-common binutils-x86-64-linux-gnu cpp cpp-7 gcc-7 gcc-7-base libasan4 libatomic1 libbinutils
  libc-dev-bin libc6-dev libcc1-0 libcilkrts5 libgcc-7-dev libgomp1 libisl19 libitm1 liblsan0 libmpc3 libmpx2
  libquadmath0 libtsan0 libubsan0 linux-libc-dev manpages-dev
Suggested packages:
  binutils-doc cpp-doc gcc-7-locales gcc-multilib make autoconf automake libtool flex bison gdb gcc-doc gcc-7-multilib
  gcc-7-doc libgcc1-dbg libgomp1-dbg libitm1-dbg libatomic1-dbg libasan4-dbg liblsan0-dbg libtsan0-dbg libubsan0-dbg
  libcilkrts5-dbg libmpx2-dbg libquadmath0-dbg glibc-doc
The following NEW packages will be installed:
  binutils binutils-common binutils-x86-64-linux-gnu cpp cpp-7 gcc gcc-7 gcc-7-base libasan4 libatomic1 libbinutils
  libc-dev-bin libc6-dev libcc1-0 libcilkrts5 libgcc-7-dev libgomp1 libisl19 libitm1 liblsan0 libmpc3 libmpx2
  libquadmath0 libtsan0 libubsan0 linux-libc-dev manpages-dev
0 upgraded, 27 newly installed, 0 to remove and 0 not upgraded.
Need to get 26.9 MB of archives.
After this operation, 115 MB of additional disk space will be used.
Get:1 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 binutils-common amd64 2.30-21ubuntu1~18.04.2 [193 kB]
Get:2 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 libbinutils amd64 2.30-21ubuntu1~18.04.2 [503 kB]
Get:3 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 binutils-x86-64-linux-gnu amd64 2.30-21ubuntu1~18.04.2 [1856 kB]
Get:4 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 binutils amd64 2.30-21ubuntu1~18.04.2 [3396 B]
Get:5 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 gcc-7-base amd64 7.4.0-1ubuntu1~18.04.1 [18.9 kB]
Get:6 http://mirror.kakao.com/ubuntu bionic/main amd64 libisl19 amd64 0.19-1 [551 kB]
Get:7 http://mirror.kakao.com/ubuntu bionic/main amd64 libmpc3 amd64 1.1.0-1 [40.8 kB]
Get:8 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 cpp-7 amd64 7.4.0-1ubuntu1~18.04.1 [6742 kB]
Get:9 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 cpp amd64 4:7.4.0-1ubuntu2.3 [27.7 kB]
Get:10 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 libcc1-0 amd64 8.3.0-6ubuntu1~18.04.1 [47.4 kB]
Get:11 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 libgomp1 amd64 8.3.0-6ubuntu1~18.04.1 [76.4 kB]
Get:12 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 libitm1 amd64 8.3.0-6ubuntu1~18.04.1 [28.0 kB]
Get:13 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 libatomic1 amd64 8.3.0-6ubuntu1~18.04.1 [9184 B]
Get:14 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 libasan4 amd64 7.4.0-1ubuntu1~18.04.1 [359 kB]
Get:15 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 liblsan0 amd64 8.3.0-6ubuntu1~18.04.1 [133 kB]
Get:16 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 libtsan0 amd64 8.3.0-6ubuntu1~18.04.1 [288 kB]
Get:17 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 libubsan0 amd64 7.4.0-1ubuntu1~18.04.1 [126 kB]
Get:18 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 libcilkrts5 amd64 7.4.0-1ubuntu1~18.04.1 [42.5 kB]
Get:19 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 libmpx2 amd64 8.3.0-6ubuntu1~18.04.1 [11.6 kB]
Get:20 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 libquadmath0 amd64 8.3.0-6ubuntu1~18.04.1 [133 kB]
Get:21 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 libgcc-7-dev amd64 7.4.0-1ubuntu1~18.04.1 [2381 kB]
Get:22 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 gcc-7 amd64 7.4.0-1ubuntu1~18.04.1 [7463 kB]
Get:23 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 gcc amd64 4:7.4.0-1ubuntu2.3 [5184 B]
Get:24 http://mirror.kakao.com/ubuntu bionic/main amd64 libc-dev-bin amd64 2.27-3ubuntu1 [71.8 kB]
Get:25 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 linux-libc-dev amd64 4.15.0-54.58 [1004 kB]
Get:26 http://mirror.kakao.com/ubuntu bionic/main amd64 libc6-dev amd64 2.27-3ubuntu1 [2587 kB]
Get:27 http://mirror.kakao.com/ubuntu bionic/main amd64 manpages-dev all 4.15-1 [2217 kB]
Fetched 26.9 MB in 1s (31.8 MB/s)
Selecting previously unselected package binutils-common:amd64.
(Reading database ... 28965 files and directories currently installed.)
Preparing to unpack .../00-binutils-common_2.30-21ubuntu1~18.04.2_amd64.deb ...
Unpacking binutils-common:amd64 (2.30-21ubuntu1~18.04.2) ...
Selecting previously unselected package libbinutils:amd64.
Preparing to unpack .../01-libbinutils_2.30-21ubuntu1~18.04.2_amd64.deb ...
Unpacking libbinutils:amd64 (2.30-21ubuntu1~18.04.2) ...
Selecting previously unselected package binutils-x86-64-linux-gnu.
Preparing to unpack .../02-binutils-x86-64-linux-gnu_2.30-21ubuntu1~18.04.2_amd64.deb ...
Unpacking binutils-x86-64-linux-gnu (2.30-21ubuntu1~18.04.2) ...
Selecting previously unselected package binutils.
Preparing to unpack .../03-binutils_2.30-21ubuntu1~18.04.2_amd64.deb ...
Unpacking binutils (2.30-21ubuntu1~18.04.2) ...
Selecting previously unselected package gcc-7-base:amd64.
Preparing to unpack .../04-gcc-7-base_7.4.0-1ubuntu1~18.04.1_amd64.deb ...
Unpacking gcc-7-base:amd64 (7.4.0-1ubuntu1~18.04.1) ...
Selecting previously unselected package libisl19:amd64.
Preparing to unpack .../05-libisl19_0.19-1_amd64.deb ...
Unpacking libisl19:amd64 (0.19-1) ...
Selecting previously unselected package libmpc3:amd64.
Preparing to unpack .../06-libmpc3_1.1.0-1_amd64.deb ...
Unpacking libmpc3:amd64 (1.1.0-1) ...
Selecting previously unselected package cpp-7.
Preparing to unpack .../07-cpp-7_7.4.0-1ubuntu1~18.04.1_amd64.deb ...
Unpacking cpp-7 (7.4.0-1ubuntu1~18.04.1) ...
Selecting previously unselected package cpp.
Preparing to unpack .../08-cpp_4%3a7.4.0-1ubuntu2.3_amd64.deb ...
Unpacking cpp (4:7.4.0-1ubuntu2.3) ...
Selecting previously unselected package libcc1-0:amd64.
Preparing to unpack .../09-libcc1-0_8.3.0-6ubuntu1~18.04.1_amd64.deb ...
Unpacking libcc1-0:amd64 (8.3.0-6ubuntu1~18.04.1) ...
Selecting previously unselected package libgomp1:amd64.
Preparing to unpack .../10-libgomp1_8.3.0-6ubuntu1~18.04.1_amd64.deb ...
Unpacking libgomp1:amd64 (8.3.0-6ubuntu1~18.04.1) ...
Selecting previously unselected package libitm1:amd64.
Preparing to unpack .../11-libitm1_8.3.0-6ubuntu1~18.04.1_amd64.deb ...
Unpacking libitm1:amd64 (8.3.0-6ubuntu1~18.04.1) ...
Selecting previously unselected package libatomic1:amd64.
Preparing to unpack .../12-libatomic1_8.3.0-6ubuntu1~18.04.1_amd64.deb ...
Unpacking libatomic1:amd64 (8.3.0-6ubuntu1~18.04.1) ...
Selecting previously unselected package libasan4:amd64.
Preparing to unpack .../13-libasan4_7.4.0-1ubuntu1~18.04.1_amd64.deb ...
Unpacking libasan4:amd64 (7.4.0-1ubuntu1~18.04.1) ...
Selecting previously unselected package liblsan0:amd64.
Preparing to unpack .../14-liblsan0_8.3.0-6ubuntu1~18.04.1_amd64.deb ...
Unpacking liblsan0:amd64 (8.3.0-6ubuntu1~18.04.1) ...
Selecting previously unselected package libtsan0:amd64.
Preparing to unpack .../15-libtsan0_8.3.0-6ubuntu1~18.04.1_amd64.deb ...
Unpacking libtsan0:amd64 (8.3.0-6ubuntu1~18.04.1) ...
Selecting previously unselected package libubsan0:amd64.
Preparing to unpack .../16-libubsan0_7.4.0-1ubuntu1~18.04.1_amd64.deb ...
Unpacking libubsan0:amd64 (7.4.0-1ubuntu1~18.04.1) ...
Selecting previously unselected package libcilkrts5:amd64.
Preparing to unpack .../17-libcilkrts5_7.4.0-1ubuntu1~18.04.1_amd64.deb ...
Unpacking libcilkrts5:amd64 (7.4.0-1ubuntu1~18.04.1) ...
Selecting previously unselected package libmpx2:amd64.
Preparing to unpack .../18-libmpx2_8.3.0-6ubuntu1~18.04.1_amd64.deb ...
Unpacking libmpx2:amd64 (8.3.0-6ubuntu1~18.04.1) ...
Selecting previously unselected package libquadmath0:amd64.
Preparing to unpack .../19-libquadmath0_8.3.0-6ubuntu1~18.04.1_amd64.deb ...
Unpacking libquadmath0:amd64 (8.3.0-6ubuntu1~18.04.1) ...
Selecting previously unselected package libgcc-7-dev:amd64.
Preparing to unpack .../20-libgcc-7-dev_7.4.0-1ubuntu1~18.04.1_amd64.deb ...
Unpacking libgcc-7-dev:amd64 (7.4.0-1ubuntu1~18.04.1) ...
Selecting previously unselected package gcc-7.
Preparing to unpack .../21-gcc-7_7.4.0-1ubuntu1~18.04.1_amd64.deb ...
Unpacking gcc-7 (7.4.0-1ubuntu1~18.04.1) ...
Selecting previously unselected package gcc.
Preparing to unpack .../22-gcc_4%3a7.4.0-1ubuntu2.3_amd64.deb ...
Unpacking gcc (4:7.4.0-1ubuntu2.3) ...
Selecting previously unselected package libc-dev-bin.
Preparing to unpack .../23-libc-dev-bin_2.27-3ubuntu1_amd64.deb ...
Unpacking libc-dev-bin (2.27-3ubuntu1) ...
Selecting previously unselected package linux-libc-dev:amd64.
Preparing to unpack .../24-linux-libc-dev_4.15.0-54.58_amd64.deb ...
Unpacking linux-libc-dev:amd64 (4.15.0-54.58) ...
Selecting previously unselected package libc6-dev:amd64.
Preparing to unpack .../25-libc6-dev_2.27-3ubuntu1_amd64.deb ...
Unpacking libc6-dev:amd64 (2.27-3ubuntu1) ...
Selecting previously unselected package manpages-dev.
Preparing to unpack .../26-manpages-dev_4.15-1_all.deb ...
Unpacking manpages-dev (4.15-1) ...
Setting up libquadmath0:amd64 (8.3.0-6ubuntu1~18.04.1) ...
Setting up libgomp1:amd64 (8.3.0-6ubuntu1~18.04.1) ...
Setting up libatomic1:amd64 (8.3.0-6ubuntu1~18.04.1) ...
Setting up libcc1-0:amd64 (8.3.0-6ubuntu1~18.04.1) ...
Setting up libtsan0:amd64 (8.3.0-6ubuntu1~18.04.1) ...
Setting up linux-libc-dev:amd64 (4.15.0-54.58) ...
Setting up liblsan0:amd64 (8.3.0-6ubuntu1~18.04.1) ...
Setting up gcc-7-base:amd64 (7.4.0-1ubuntu1~18.04.1) ...
Setting up binutils-common:amd64 (2.30-21ubuntu1~18.04.2) ...
Setting up libmpx2:amd64 (8.3.0-6ubuntu1~18.04.1) ...
Processing triggers for libc-bin (2.27-3ubuntu1) ...
Processing triggers for man-db (2.8.3-2ubuntu0.1) ...
Setting up libmpc3:amd64 (1.1.0-1) ...
Setting up libc-dev-bin (2.27-3ubuntu1) ...
Setting up manpages-dev (4.15-1) ...
Setting up libc6-dev:amd64 (2.27-3ubuntu1) ...
Setting up libitm1:amd64 (8.3.0-6ubuntu1~18.04.1) ...
Setting up libisl19:amd64 (0.19-1) ...
Setting up libasan4:amd64 (7.4.0-1ubuntu1~18.04.1) ...
Setting up libbinutils:amd64 (2.30-21ubuntu1~18.04.2) ...
Setting up libcilkrts5:amd64 (7.4.0-1ubuntu1~18.04.1) ...
Setting up libubsan0:amd64 (7.4.0-1ubuntu1~18.04.1) ...
Setting up libgcc-7-dev:amd64 (7.4.0-1ubuntu1~18.04.1) ...
Setting up cpp-7 (7.4.0-1ubuntu1~18.04.1) ...
Setting up binutils-x86-64-linux-gnu (2.30-21ubuntu1~18.04.2) ...
Setting up cpp (4:7.4.0-1ubuntu2.3) ...
Setting up binutils (2.30-21ubuntu1~18.04.2) ...
Setting up gcc-7 (7.4.0-1ubuntu1~18.04.1) ...
Setting up gcc (4:7.4.0-1ubuntu2.3) ...
Processing triggers for libc-bin (2.27-3ubuntu1) ...
Reading package lists... Done
Building dependency tree
Reading state information... Done
The following package was automatically installed and is no longer required:
  libfreetype6
Use 'sudo apt autoremove' to remove it.
The following additional packages will be installed:
  dh-python libexpat1-dev libpython3-dev libpython3.6-dev python3.6-dev
Suggested packages:
  libdpkg-perl dpkg-dev
The following NEW packages will be installed:
  dh-python libexpat1-dev libpython3-dev libpython3.6-dev python3-dev python3.6-dev
0 upgraded, 6 newly installed, 0 to remove and 0 not upgraded.
Need to get 45.5 MB of archives.
After this operation, 78.3 MB of additional disk space will be used.
Get:1 http://mirror.kakao.com/ubuntu bionic/main amd64 dh-python all 3.20180325ubuntu2 [89.2 kB]
Get:2 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 libexpat1-dev amd64 2.2.5-3ubuntu0.1 [122 kB]
Get:3 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 libpython3.6-dev amd64 3.6.8-1~18.04.1 [44.8 MB]
Get:4 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 libpython3-dev amd64 3.6.7-1~18.04 [7328 B]
Get:5 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 python3.6-dev amd64 3.6.8-1~18.04.1 [508 kB]
Get:6 http://mirror.kakao.com/ubuntu bionic-updates/main amd64 python3-dev amd64 3.6.7-1~18.04 [1288 B]
Fetched 45.5 MB in 1s (42.0 MB/s)
Selecting previously unselected package dh-python.
(Reading database ... 33145 files and directories currently installed.)
Preparing to unpack .../0-dh-python_3.20180325ubuntu2_all.deb ...
Unpacking dh-python (3.20180325ubuntu2) ...
Selecting previously unselected package libexpat1-dev:amd64.
Preparing to unpack .../1-libexpat1-dev_2.2.5-3ubuntu0.1_amd64.deb ...
Unpacking libexpat1-dev:amd64 (2.2.5-3ubuntu0.1) ...
Selecting previously unselected package libpython3.6-dev:amd64.
Preparing to unpack .../2-libpython3.6-dev_3.6.8-1~18.04.1_amd64.deb ...
Unpacking libpython3.6-dev:amd64 (3.6.8-1~18.04.1) ...
Selecting previously unselected package libpython3-dev:amd64.
Preparing to unpack .../3-libpython3-dev_3.6.7-1~18.04_amd64.deb ...
Unpacking libpython3-dev:amd64 (3.6.7-1~18.04) ...
Selecting previously unselected package python3.6-dev.
Preparing to unpack .../4-python3.6-dev_3.6.8-1~18.04.1_amd64.deb ...
Unpacking python3.6-dev (3.6.8-1~18.04.1) ...
Selecting previously unselected package python3-dev.
Preparing to unpack .../5-python3-dev_3.6.7-1~18.04_amd64.deb ...
Unpacking python3-dev (3.6.7-1~18.04) ...
Setting up libexpat1-dev:amd64 (2.2.5-3ubuntu0.1) ...
Processing triggers for man-db (2.8.3-2ubuntu0.1) ...
Setting up dh-python (3.20180325ubuntu2) ...
Setting up libpython3.6-dev:amd64 (3.6.8-1~18.04.1) ...
Setting up python3.6-dev (3.6.8-1~18.04.1) ...
Setting up libpython3-dev:amd64 (3.6.7-1~18.04) ...
Setting up python3-dev (3.6.7-1~18.04) ...
Collecting wheel
  Downloading https://files.pythonhosted.org/packages/bb/10/44230dd6bf3563b8f227dbf344c908d412ad2ff48066476672f3a72e174e/wheel-0.33.4-py2.py3-none-any.whl
Installing collected packages: wheel
Successfully installed wheel-0.33.4
(ak) lay@HL_ML:~/autokeras$ pip install -r requirements.txt
Collecting tensorflow>=2.0.0b0 (from -r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/29/6c/2c9a5c4d095c63c2fb37d20def0e4f92685f7aee9243d6aae25862694fd1/tensorflow-2.0.0b1-cp36-cp36m-manylinux1_x86_64.whl (87.9MB)
    100% |████████████████████████████████| 87.9MB 18kB/s
Collecting scikit-learn>=0.20.2 (from -r requirements.txt (line 2))
  Downloading https://files.pythonhosted.org/packages/85/04/49633f490f726da6e454fddc8e938bbb5bfed2001681118d3814c219b723/scikit_learn-0.21.2-cp36-cp36m-manylinux1_x86_64.whl (6.7MB)
    100% |████████████████████████████████| 6.7MB 240kB/s
Collecting kerastuner from git+git://github.com/keras-team/keras-tuner@master#egg=kerastuner (from -r requirements.txt (line 3))
  Cloning git://github.com/keras-team/keras-tuner (to master) to /tmp/pip-build-3emq08hc/kerastuner
  Running setup.py (path:/tmp/pip-build-3emq08hc/kerastuner/setup.py) egg_info for package kerastuner produced metadata for project name keras-tuner. Fix your #egg=kerastuner fragments.
Collecting pytest>=4.5.0 (from -r requirements.txt (line 4))
  Downloading https://files.pythonhosted.org/packages/69/1d/2430053122a3c6106f7fd1ff0bc68eb73e27db8f951db70fcd942da52c7b/pytest-5.0.1-py3-none-any.whl (221kB)
    100% |████████████████████████████████| 225kB 4.6MB/s
Collecting pytest-pep8 (from -r requirements.txt (line 5))
  Downloading https://files.pythonhosted.org/packages/1f/1c/c834344ef39381558b047bea1e3005197fa8457c199d58219996ca07defb/pytest-pep8-1.0.6.tar.gz
Collecting pytest-xdist (from -r requirements.txt (line 6))
  Downloading https://files.pythonhosted.org/packages/9f/cc/371b2e6dfbf4e8df07b04e310dd6ea0b3f367e257d1e6cb516b25bc4af1b/pytest_xdist-1.29.0-py2.py3-none-any.whl
Collecting pytest-cov (from -r requirements.txt (line 7))
  Downloading https://files.pythonhosted.org/packages/84/7b/73f8522619d1cbb22b9a36f9c54bc5ce5e24648e53cc1bf566477d2d1f2b/pytest_cov-2.7.1-py2.py3-none-any.whl
Collecting tb-nightly<1.14.0a20190604,>=1.14.0a20190603 (from tensorflow>=2.0.0b0->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/a4/96/571b875cd81dda9d5dfa1422a4f9d749e67c0a8d4f4f0b33a4e5f5f35e27/tb_nightly-1.14.0a20190603-py3-none-any.whl (3.1MB)
    100% |████████████████████████████████| 3.1MB 546kB/s
Collecting astor>=0.6.0 (from tensorflow>=2.0.0b0->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/d1/4f/950dfae467b384fc96bc6469de25d832534f6b4441033c39f914efd13418/astor-0.8.0-py2.py3-none-any.whl
Collecting six>=1.10.0 (from tensorflow>=2.0.0b0->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl
Collecting absl-py>=0.7.0 (from tensorflow>=2.0.0b0->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/da/3f/9b0355080b81b15ba6a9ffcf1f5ea39e307a2778b2f2dc8694724e8abd5b/absl-py-0.7.1.tar.gz (99kB)
    100% |████████████████████████████████| 102kB 7.6MB/s
Collecting termcolor>=1.1.0 (from tensorflow>=2.0.0b0->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz
Requirement already satisfied: wheel>=0.26 in /home/lay/ak/lib/python3.6/site-packages (from tensorflow>=2.0.0b0->-r requirements.txt (line 1))
Collecting gast>=0.2.0 (from tensorflow>=2.0.0b0->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz
Collecting google-pasta>=0.1.6 (from tensorflow>=2.0.0b0->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/d0/33/376510eb8d6246f3c30545f416b2263eee461e40940c2a4413c711bdf62d/google_pasta-0.1.7-py3-none-any.whl (52kB)
    100% |████████████████████████████████| 61kB 5.7MB/s
Collecting keras-preprocessing>=1.0.5 (from tensorflow>=2.0.0b0->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41kB)
    100% |████████████████████████████████| 51kB 5.6MB/s
Collecting numpy<2.0,>=1.14.5 (from tensorflow>=2.0.0b0->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/87/2d/e4656149cbadd3a8a0369fcd1a9c7d61cc7b87b3903b85389c70c989a696/numpy-1.16.4-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)
    100% |████████████████████████████████| 17.3MB 98kB/s
Collecting protobuf>=3.6.1 (from tensorflow>=2.0.0b0->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/d2/fb/29de8d08967f0cce1bb10b39846d836b0f3bf6776ddc36aed7c73498ca7e/protobuf-3.8.0-cp36-cp36m-manylinux1_x86_64.whl (1.2MB)
    100% |████████████████████████████████| 1.2MB 1.4MB/s
Collecting tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501 (from tensorflow>=2.0.0b0->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/32/dd/99c47dd007dcf10d63fd895611b063732646f23059c618a373e85019eb0e/tf_estimator_nightly-1.14.0.dev2019060501-py2.py3-none-any.whl (496kB)
    100% |████████████████████████████████| 501kB 2.9MB/s
Collecting wrapt>=1.11.1 (from tensorflow>=2.0.0b0->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/23/84/323c2415280bc4fc880ac5050dddfb3c8062c2552b34c2e512eb4aa68f79/wrapt-1.11.2.tar.gz
Collecting grpcio>=1.8.6 (from tensorflow>=2.0.0b0->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/f2/5d/b434403adb2db8853a97828d3d19f2032e79d630e0d11a8e95d243103a11/grpcio-1.22.0-cp36-cp36m-manylinux1_x86_64.whl (2.2MB)
    100% |████████████████████████████████| 2.2MB 443kB/s
Collecting keras-applications>=1.0.6 (from tensorflow>=2.0.0b0->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)
    100% |████████████████████████████████| 51kB 5.3MB/s
Collecting scipy>=0.17.0 (from scikit-learn>=0.20.2->-r requirements.txt (line 2))
  Downloading https://files.pythonhosted.org/packages/72/4c/5f81e7264b0a7a8bd570810f48cd346ba36faedbd2ba255c873ad556de76/scipy-1.3.0-cp36-cp36m-manylinux1_x86_64.whl (25.2MB)
    100% |████████████████████████████████| 25.2MB 64kB/s
Collecting joblib>=0.11 (from scikit-learn>=0.20.2->-r requirements.txt (line 2))
  Downloading https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl (278kB)
    100% |████████████████████████████████| 286kB 4.1MB/s
Collecting colorama (from keras-tuner->-r requirements.txt (line 3))
  Downloading https://files.pythonhosted.org/packages/4f/a6/728666f39bfff1719fc94c481890b2106837da9318031f71a8424b662e12/colorama-0.4.1-py2.py3-none-any.whl
Collecting psutil (from keras-tuner->-r requirements.txt (line 3))
  Downloading https://files.pythonhosted.org/packages/1c/ca/5b8c1fe032a458c2c4bcbe509d1401dca9dda35c7fc46b36bb81c2834740/psutil-5.6.3.tar.gz (435kB)
    100% |████████████████████████████████| 440kB 3.0MB/s
Collecting requests (from keras-tuner->-r requirements.txt (line 3))
  Downloading https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl (57kB)
    100% |████████████████████████████████| 61kB 5.6MB/s
Collecting tabulate (from keras-tuner->-r requirements.txt (line 3))
  Downloading https://files.pythonhosted.org/packages/c2/fd/202954b3f0eb896c53b7b6f07390851b1fd2ca84aa95880d7ae4f434c4ac/tabulate-0.8.3.tar.gz (46kB)
    100% |████████████████████████████████| 51kB 5.0MB/s
Collecting terminaltables (from keras-tuner->-r requirements.txt (line 3))
  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz
Collecting tqdm (from keras-tuner->-r requirements.txt (line 3))
  Downloading https://files.pythonhosted.org/packages/9f/3d/7a6b68b631d2ab54975f3a4863f3c4e9b26445353264ef01f465dc9b0208/tqdm-4.32.2-py2.py3-none-any.whl (50kB)
    100% |████████████████████████████████| 51kB 4.9MB/s
Collecting wcwidth (from pytest>=4.5.0->-r requirements.txt (line 4))
  Downloading https://files.pythonhosted.org/packages/7e/9f/526a6947247599b084ee5232e4f9190a38f398d7300d866af3ab571a5bfe/wcwidth-0.1.7-py2.py3-none-any.whl
Collecting importlib-metadata>=0.12 (from pytest>=4.5.0->-r requirements.txt (line 4))
  Downloading https://files.pythonhosted.org/packages/bd/23/dce4879ec58acf3959580bfe769926ed8198727250c5e395e6785c764a02/importlib_metadata-0.18-py2.py3-none-any.whl
Collecting pluggy<1.0,>=0.12 (from pytest>=4.5.0->-r requirements.txt (line 4))
  Downloading https://files.pythonhosted.org/packages/06/ee/de89e0582276e3551df3110088bf20844de2b0e7df2748406876cc78e021/pluggy-0.12.0-py2.py3-none-any.whl
Collecting atomicwrites>=1.0 (from pytest>=4.5.0->-r requirements.txt (line 4))
  Downloading https://files.pythonhosted.org/packages/52/90/6155aa926f43f2b2a22b01be7241be3bfd1ceaf7d0b3267213e8127d41f4/atomicwrites-1.3.0-py2.py3-none-any.whl
Collecting more-itertools>=4.0.0 (from pytest>=4.5.0->-r requirements.txt (line 4))
  Downloading https://files.pythonhosted.org/packages/1f/9e/942df77ddde2fae3f319f2ab8b5d00d5f6b115496e2eb4bad37d1aaefeea/more_itertools-7.1.0-py3-none-any.whl (55kB)
    100% |████████████████████████████████| 61kB 5.6MB/s
Collecting packaging (from pytest>=4.5.0->-r requirements.txt (line 4))
  Downloading https://files.pythonhosted.org/packages/91/32/58bc30e646e55eab8b21abf89e353f59c0cc02c417e42929f4a9546e1b1d/packaging-19.0-py2.py3-none-any.whl
Collecting py>=1.5.0 (from pytest>=4.5.0->-r requirements.txt (line 4))
  Downloading https://files.pythonhosted.org/packages/76/bc/394ad449851729244a97857ee14d7cba61ddb268dce3db538ba2f2ba1f0f/py-1.8.0-py2.py3-none-any.whl (83kB)
    100% |████████████████████████████████| 92kB 7.0MB/s
Collecting attrs>=17.4.0 (from pytest>=4.5.0->-r requirements.txt (line 4))
  Downloading https://files.pythonhosted.org/packages/23/96/d828354fa2dbdf216eaa7b7de0db692f12c234f7ef888cc14980ef40d1d2/attrs-19.1.0-py2.py3-none-any.whl
Collecting pep8>=1.3 (from pytest-pep8->-r requirements.txt (line 5))
  Downloading https://files.pythonhosted.org/packages/42/3f/669429ce58de2c22d8d2c542752e137ec4b9885fff398d3eceb1a7f5acb4/pep8-1.7.1-py2.py3-none-any.whl (41kB)
    100% |████████████████████████████████| 51kB 5.3MB/s
Collecting pytest-cache (from pytest-pep8->-r requirements.txt (line 5))
  Downloading https://files.pythonhosted.org/packages/d1/15/082fd0428aab33d2bafa014f3beb241830427ba803a8912a5aaeaf3a5663/pytest-cache-1.0.tar.gz
Collecting execnet>=1.1 (from pytest-xdist->-r requirements.txt (line 6))
  Downloading https://files.pythonhosted.org/packages/77/1a/f69e1f73bc36f55d3273afd1c52936def71ac67d9c5215be3a4ca3a45577/execnet-1.6.0-py2.py3-none-any.whl
Collecting pytest-forked (from pytest-xdist->-r requirements.txt (line 6))
  Downloading https://files.pythonhosted.org/packages/3f/55/ef92c340e723495dbee91d749903d2b7950b49c501943296257246d7d880/pytest_forked-1.0.2-py2.py3-none-any.whl
Collecting coverage>=4.4 (from pytest-cov->-r requirements.txt (line 7))
  Downloading https://files.pythonhosted.org/packages/f8/4e/f28fc04019bac97d301512d904992791569234a06826cd420f78fba9a361/coverage-4.5.3-cp36-cp36m-manylinux1_x86_64.whl (205kB)
    100% |████████████████████████████████| 215kB 4.8MB/s
Collecting werkzeug>=0.11.15 (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow>=2.0.0b0->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/9f/57/92a497e38161ce40606c27a86759c6b92dd34fcdb33f64171ec559257c02/Werkzeug-0.15.4-py2.py3-none-any.whl (327kB)
    100% |████████████████████████████████| 327kB 3.5MB/s
Collecting markdown>=2.6.8 (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow>=2.0.0b0->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl (87kB)
    100% |████████████████████████████████| 92kB 6.8MB/s
Collecting setuptools>=41.0.0 (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow>=2.0.0b0->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/ec/51/f45cea425fd5cb0b0380f5b0f048ebc1da5b417e48d304838c02d6288a1e/setuptools-41.0.1-py2.py3-none-any.whl (575kB)
    100% |████████████████████████████████| 583kB 2.3MB/s
Collecting h5py (from keras-applications>=1.0.6->tensorflow>=2.0.0b0->-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/30/99/d7d4fbf2d02bb30fb76179911a250074b55b852d34e98dd452a9f394ac06/h5py-2.9.0-cp36-cp36m-manylinux1_x86_64.whl (2.8MB)
    100% |████████████████████████████████| 2.8MB 601kB/s
Collecting chardet<3.1.0,>=3.0.2 (from requests->keras-tuner->-r requirements.txt (line 3))
  Downloading https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl (133kB)
    100% |████████████████████████████████| 143kB 6.4MB/s
Collecting idna<2.9,>=2.5 (from requests->keras-tuner->-r requirements.txt (line 3))
  Downloading https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl (58kB)
    100% |████████████████████████████████| 61kB 5.9MB/s
Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 (from requests->keras-tuner->-r requirements.txt (line 3))
  Downloading https://files.pythonhosted.org/packages/e6/60/247f23a7121ae632d62811ba7f273d0e58972d75e58a94d329d51550a47d/urllib3-1.25.3-py2.py3-none-any.whl (150kB)
    100% |████████████████████████████████| 153kB 6.0MB/s
Collecting certifi>=2017.4.17 (from requests->keras-tuner->-r requirements.txt (line 3))
  Downloading https://files.pythonhosted.org/packages/69/1b/b853c7a9d4f6a6d00749e94eb6f3a041e342a885b87340b79c1ef73e3a78/certifi-2019.6.16-py2.py3-none-any.whl (157kB)
    100% |████████████████████████████████| 163kB 5.9MB/s
Collecting zipp>=0.5 (from importlib-metadata>=0.12->pytest>=4.5.0->-r requirements.txt (line 4))
  Downloading https://files.pythonhosted.org/packages/da/bd/1a5fdf15aa44231fd09f63ecf175b60f057ae37ec65b343bb009364923f3/zipp-0.5.2-py2.py3-none-any.whl
Collecting pyparsing>=2.0.2 (from packaging->pytest>=4.5.0->-r requirements.txt (line 4))
  Downloading https://files.pythonhosted.org/packages/dd/d9/3ec19e966301a6e25769976999bd7bbe552016f0d32b577dc9d63d2e0c49/pyparsing-2.4.0-py2.py3-none-any.whl (62kB)
    100% |████████████████████████████████| 71kB 6.3MB/s
Collecting apipkg>=1.4 (from execnet>=1.1->pytest-xdist->-r requirements.txt (line 6))
  Downloading https://files.pythonhosted.org/packages/67/08/4815a09603fc800209431bec5b8bd2acf2f95abdfb558a44a42507fb94da/apipkg-1.5-py2.py3-none-any.whl
Building wheels for collected packages: pytest-pep8, absl-py, termcolor, gast, wrapt, psutil, tabulate, terminaltables, pytest-cache
  Running setup.py bdist_wheel for pytest-pep8 ... done
  Stored in directory: /home/lay/.cache/pip/wheels/68/34/52/2a6e08e030cef8b3671898f34cecb12750cc4b96ebfe66fe67
  Running setup.py bdist_wheel for absl-py ... done
  Stored in directory: /home/lay/.cache/pip/wheels/ee/98/38/46cbcc5a93cfea5492d19c38562691ddb23b940176c14f7b48
  Running setup.py bdist_wheel for termcolor ... done
  Stored in directory: /home/lay/.cache/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6
  Running setup.py bdist_wheel for gast ... done
  Stored in directory: /home/lay/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd
  Running setup.py bdist_wheel for wrapt ... done
  Stored in directory: /home/lay/.cache/pip/wheels/d7/de/2e/efa132238792efb6459a96e85916ef8597fcb3d2ae51590dfd
  Running setup.py bdist_wheel for psutil ... done
  Stored in directory: /home/lay/.cache/pip/wheels/90/7e/74/bb640d77775e6b6a78bcc3120f9fea4d2a28b2706de1cff37d
  Running setup.py bdist_wheel for tabulate ... done
  Stored in directory: /home/lay/.cache/pip/wheels/2b/67/89/414471314a2d15de625d184d8be6d38a03ae1e983dbda91e84
  Running setup.py bdist_wheel for terminaltables ... done
  Stored in directory: /home/lay/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e
  Running setup.py bdist_wheel for pytest-cache ... done
  Stored in directory: /home/lay/.cache/pip/wheels/e4/9e/28/59d0a23800e49808f17920c5922252c661966ca4a36db5ee38
Successfully built pytest-pep8 absl-py termcolor gast wrapt psutil tabulate terminaltables pytest-cache
Installing collected packages: six, werkzeug, setuptools, markdown, grpcio, numpy, protobuf, absl-py, tb-nightly, astor, termcolor, gast, google-pasta, keras-preprocessing, tf-estimator-nightly, wrapt, h5py, keras-applications, tensorflow, scipy, joblib, scikit-learn, colorama, psutil, chardet, idna, urllib3, certifi, requests, tabulate, terminaltables, tqdm, keras-tuner, wcwidth, zipp, importlib-metadata, pluggy, atomicwrites, more-itertools, pyparsing, packaging, py, attrs, pytest, pep8, apipkg, execnet, pytest-cache, pytest-pep8, pytest-forked, pytest-xdist, coverage, pytest-cov
  Found existing installation: setuptools 39.0.1
    Uninstalling setuptools-39.0.1:
      Successfully uninstalled setuptools-39.0.1
  Running setup.py install for keras-tuner ... done
Successfully installed absl-py-0.7.1 apipkg-1.5 astor-0.8.0 atomicwrites-1.3.0 attrs-19.1.0 certifi-2019.6.16 chardet-3.0.4 colorama-0.4.1 coverage-4.5.3 execnet-1.6.0 gast-0.2.2 google-pasta-0.1.7 grpcio-1.22.0 h5py-2.9.0 idna-2.8 importlib-metadata-0.18 joblib-0.13.2 keras-applications-1.0.8 keras-preprocessing-1.1.0 keras-tuner-0.9.0.1562619727 markdown-3.1.1 more-itertools-7.1.0 numpy-1.16.4 packaging-19.0 pep8-1.7.1 pluggy-0.12.0 protobuf-3.8.0 psutil-5.6.3 py-1.8.0 pyparsing-2.4.0 pytest-5.0.1 pytest-cache-1.0 pytest-cov-2.7.1 pytest-forked-1.0.2 pytest-pep8-1.0.6 pytest-xdist-1.29.0 requests-2.22.0 scikit-learn-0.21.2 scipy-1.3.0 setuptools-41.0.1 six-1.12.0 tabulate-0.8.3 tb-nightly-1.14.0a20190603 tensorflow-2.0.0b1 termcolor-1.1.0 terminaltables-3.1.0 tf-estimator-nightly-1.14.0.dev2019060501 tqdm-4.32.2 urllib3-1.25.3 wcwidth-0.1.7 werkzeug-0.15.4 wrapt-1.11.2 zipp-0.5.2
(ak) lay@HL_ML:~/autokeras$ python setup.py install
running install
running bdist_egg
running egg_info
creating autokeras.egg-info
writing autokeras.egg-info/PKG-INFO
writing dependency_links to autokeras.egg-info/dependency_links.txt
writing requirements to autokeras.egg-info/requires.txt
writing top-level names to autokeras.egg-info/top_level.txt
writing manifest file 'autokeras.egg-info/SOURCES.txt'
reading manifest file 'autokeras.egg-info/SOURCES.txt'
writing manifest file 'autokeras.egg-info/SOURCES.txt'
installing library code to build/bdist.linux-x86_64/egg
running install_lib
running build_py
creating build
creating build/lib
creating build/lib/autokeras
copying autokeras/__init__.py -> build/lib/autokeras
copying autokeras/const.py -> build/lib/autokeras
copying autokeras/utils.py -> build/lib/autokeras
creating build/lib/autokeras/auto
copying autokeras/auto/__init__.py -> build/lib/autokeras/auto
copying autokeras/auto/auto_model.py -> build/lib/autokeras/auto
copying autokeras/auto/image.py -> build/lib/autokeras/auto
copying autokeras/auto/tuner.py -> build/lib/autokeras/auto
creating build/lib/autokeras/hypermodel
copying autokeras/hypermodel/__init__.py -> build/lib/autokeras/hypermodel
copying autokeras/hypermodel/hyper_block.py -> build/lib/autokeras/hypermodel
copying autokeras/hypermodel/hyper_head.py -> build/lib/autokeras/hypermodel
copying autokeras/hypermodel/hyper_node.py -> build/lib/autokeras/hypermodel
copying autokeras/hypermodel/processor.py -> build/lib/autokeras/hypermodel
creating build/bdist.linux-x86_64
creating build/bdist.linux-x86_64/egg
creating build/bdist.linux-x86_64/egg/autokeras
copying build/lib/autokeras/__init__.py -> build/bdist.linux-x86_64/egg/autokeras
creating build/bdist.linux-x86_64/egg/autokeras/auto
copying build/lib/autokeras/auto/__init__.py -> build/bdist.linux-x86_64/egg/autokeras/auto
copying build/lib/autokeras/auto/auto_model.py -> build/bdist.linux-x86_64/egg/autokeras/auto
copying build/lib/autokeras/auto/image.py -> build/bdist.linux-x86_64/egg/autokeras/auto
copying build/lib/autokeras/auto/tuner.py -> build/bdist.linux-x86_64/egg/autokeras/auto
copying build/lib/autokeras/const.py -> build/bdist.linux-x86_64/egg/autokeras
creating build/bdist.linux-x86_64/egg/autokeras/hypermodel
copying build/lib/autokeras/hypermodel/__init__.py -> build/bdist.linux-x86_64/egg/autokeras/hypermodel
copying build/lib/autokeras/hypermodel/hyper_block.py -> build/bdist.linux-x86_64/egg/autokeras/hypermodel
copying build/lib/autokeras/hypermodel/hyper_head.py -> build/bdist.linux-x86_64/egg/autokeras/hypermodel
copying build/lib/autokeras/hypermodel/hyper_node.py -> build/bdist.linux-x86_64/egg/autokeras/hypermodel
copying build/lib/autokeras/hypermodel/processor.py -> build/bdist.linux-x86_64/egg/autokeras/hypermodel
copying build/lib/autokeras/utils.py -> build/bdist.linux-x86_64/egg/autokeras
byte-compiling build/bdist.linux-x86_64/egg/autokeras/__init__.py to __init__.cpython-36.pyc
byte-compiling build/bdist.linux-x86_64/egg/autokeras/auto/__init__.py to __init__.cpython-36.pyc
byte-compiling build/bdist.linux-x86_64/egg/autokeras/auto/auto_model.py to auto_model.cpython-36.pyc
byte-compiling build/bdist.linux-x86_64/egg/autokeras/auto/image.py to image.cpython-36.pyc
byte-compiling build/bdist.linux-x86_64/egg/autokeras/auto/tuner.py to tuner.cpython-36.pyc
byte-compiling build/bdist.linux-x86_64/egg/autokeras/const.py to const.cpython-36.pyc
byte-compiling build/bdist.linux-x86_64/egg/autokeras/hypermodel/__init__.py to __init__.cpython-36.pyc
byte-compiling build/bdist.linux-x86_64/egg/autokeras/hypermodel/hyper_block.py to hyper_block.cpython-36.pyc
byte-compiling build/bdist.linux-x86_64/egg/autokeras/hypermodel/hyper_head.py to hyper_head.cpython-36.pyc
byte-compiling build/bdist.linux-x86_64/egg/autokeras/hypermodel/hyper_node.py to hyper_node.cpython-36.pyc
byte-compiling build/bdist.linux-x86_64/egg/autokeras/hypermodel/processor.py to processor.cpython-36.pyc
byte-compiling build/bdist.linux-x86_64/egg/autokeras/utils.py to utils.cpython-36.pyc
creating build/bdist.linux-x86_64/egg/EGG-INFO
copying autokeras.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO
copying autokeras.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO
copying autokeras.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO
copying autokeras.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO
copying autokeras.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO
zip_safe flag not set; analyzing archive contents...
creating dist
creating 'dist/autokeras-1.0.0-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it
removing 'build/bdist.linux-x86_64/egg' (and everything under it)
Processing autokeras-1.0.0-py3.6.egg
Copying autokeras-1.0.0-py3.6.egg to /home/lay/ak/lib/python3.6/site-packages
Adding autokeras 1.0.0 to easy-install.pth file

Installed /home/lay/ak/lib/python3.6/site-packages/autokeras-1.0.0-py3.6.egg
Processing dependencies for autokeras==1.0.0
Searching for scikit-learn==0.20.2
Reading https://pypi.org/simple/scikit-learn/
Downloading https://files.pythonhosted.org/packages/0d/3a/b92670f5c368c20329ecc4c255993fae7934564d485c3ed7ea7b8da7f741/scikit_learn-0.20.2-cp36-cp36m-manylinux1_x86_64.whl#sha256=eb7ddbdf33eb822fdc916819b0ab7009d954eb43c3a78e7dd2ec5455e074922a
Best match: scikit-learn 0.20.2
Processing scikit_learn-0.20.2-cp36-cp36m-manylinux1_x86_64.whl
Installing scikit_learn-0.20.2-cp36-cp36m-manylinux1_x86_64.whl to /home/lay/ak/lib/python3.6/site-packages
writing requirements to /home/lay/ak/lib/python3.6/site-packages/scikit_learn-0.20.2-py3.6-linux-x86_64.egg/EGG-INFO/requires.txt
Adding scikit-learn 0.20.2 to easy-install.pth file

Installed /home/lay/ak/lib/python3.6/site-packages/scikit_learn-0.20.2-py3.6-linux-x86_64.egg
Searching for tensorflow==2.0.0b0
Reading https://pypi.org/simple/tensorflow/
Downloading https://files.pythonhosted.org/packages/6c/19/0d0c7f240db7bcd6b83783b9a89a67f38584d100e23ad5ae93114be92232/tensorflow-2.0.0b0-cp36-cp36m-manylinux1_x86_64.whl#sha256=b75cfa72e858ebaeb9c4edbaef8a51bac5304846e92f13ff8d87b7a891629da5
Best match: tensorflow 2.0.0b0
Processing tensorflow-2.0.0b0-cp36-cp36m-manylinux1_x86_64.whl
Installing tensorflow-2.0.0b0-cp36-cp36m-manylinux1_x86_64.whl to /home/lay/ak/lib/python3.6/site-packages
writing requirements to /home/lay/ak/lib/python3.6/site-packages/tensorflow-2.0.0b0-py3.6-linux-x86_64.egg/EGG-INFO/requires.txt
Adding tensorflow 2.0.0b0 to easy-install.pth file
Installing freeze_graph script to /home/lay/ak/bin
Installing saved_model_cli script to /home/lay/ak/bin
Installing tensorboard script to /home/lay/ak/bin
Installing tf_upgrade_v2 script to /home/lay/ak/bin
Installing tflite_convert script to /home/lay/ak/bin
Installing toco script to /home/lay/ak/bin
Installing toco_from_protos script to /home/lay/ak/bin

Installed /home/lay/ak/lib/python3.6/site-packages/tensorflow-2.0.0b0-py3.6-linux-x86_64.egg
Searching for scipy==1.3.0
Best match: scipy 1.3.0
Adding scipy 1.3.0 to easy-install.pth file

Using /home/lay/ak/lib/python3.6/site-packages
Searching for numpy==1.16.4
Best match: numpy 1.16.4
Adding numpy 1.16.4 to easy-install.pth file
Installing f2py script to /home/lay/ak/bin
Installing f2py3 script to /home/lay/ak/bin
Installing f2py3.6 script to /home/lay/ak/bin

Using /home/lay/ak/lib/python3.6/site-packages
Searching for wrapt==1.11.2
Best match: wrapt 1.11.2
Adding wrapt 1.11.2 to easy-install.pth file

Using /home/lay/ak/lib/python3.6/site-packages
Searching for wheel==0.33.4
Best match: wheel 0.33.4
Adding wheel 0.33.4 to easy-install.pth file
Installing wheel script to /home/lay/ak/bin

Using /home/lay/ak/lib/python3.6/site-packages
Searching for tf-estimator-nightly==1.14.0.dev2019060501
Best match: tf-estimator-nightly 1.14.0.dev2019060501
Adding tf-estimator-nightly 1.14.0.dev2019060501 to easy-install.pth file

Using /home/lay/ak/lib/python3.6/site-packages
Searching for termcolor==1.1.0
Best match: termcolor 1.1.0
Adding termcolor 1.1.0 to easy-install.pth file

Using /home/lay/ak/lib/python3.6/site-packages
Searching for tb-nightly==1.14.0a20190603
Best match: tb-nightly 1.14.0a20190603
Adding tb-nightly 1.14.0a20190603 to easy-install.pth file
Installing tensorboard script to /home/lay/ak/bin

Using /home/lay/ak/lib/python3.6/site-packages
Searching for six==1.12.0
Best match: six 1.12.0
Adding six 1.12.0 to easy-install.pth file

Using /home/lay/ak/lib/python3.6/site-packages
Searching for protobuf==3.8.0
Best match: protobuf 3.8.0
Adding protobuf 3.8.0 to easy-install.pth file

Using /home/lay/ak/lib/python3.6/site-packages
Searching for Keras-Preprocessing==1.1.0
Best match: Keras-Preprocessing 1.1.0
Adding Keras-Preprocessing 1.1.0 to easy-install.pth file

Using /home/lay/ak/lib/python3.6/site-packages
Searching for Keras-Applications==1.0.8
Best match: Keras-Applications 1.0.8
Adding Keras-Applications 1.0.8 to easy-install.pth file

Using /home/lay/ak/lib/python3.6/site-packages
Searching for grpcio==1.22.0
Best match: grpcio 1.22.0
Adding grpcio 1.22.0 to easy-install.pth file

Using /home/lay/ak/lib/python3.6/site-packages
Searching for google-pasta==0.1.7
Best match: google-pasta 0.1.7
Adding google-pasta 0.1.7 to easy-install.pth file

Using /home/lay/ak/lib/python3.6/site-packages
Searching for gast==0.2.2
Best match: gast 0.2.2
Adding gast 0.2.2 to easy-install.pth file

Using /home/lay/ak/lib/python3.6/site-packages
Searching for astor==0.8.0
Best match: astor 0.8.0
Adding astor 0.8.0 to easy-install.pth file

Using /home/lay/ak/lib/python3.6/site-packages
Searching for absl-py==0.7.1
Best match: absl-py 0.7.1
Adding absl-py 0.7.1 to easy-install.pth file

Using /home/lay/ak/lib/python3.6/site-packages
Searching for setuptools==41.0.1
Best match: setuptools 41.0.1
Adding setuptools 41.0.1 to easy-install.pth file
Installing easy_install script to /home/lay/ak/bin
Installing easy_install-3.6 script to /home/lay/ak/bin

Using /home/lay/ak/lib/python3.6/site-packages
Searching for Markdown==3.1.1
Best match: Markdown 3.1.1
Adding Markdown 3.1.1 to easy-install.pth file
Installing markdown_py script to /home/lay/ak/bin

Using /home/lay/ak/lib/python3.6/site-packages
Searching for Werkzeug==0.15.4
Best match: Werkzeug 0.15.4
Adding Werkzeug 0.15.4 to easy-install.pth file

Using /home/lay/ak/lib/python3.6/site-packages
Searching for h5py==2.9.0
Best match: h5py 2.9.0
Adding h5py 2.9.0 to easy-install.pth file

Using /home/lay/ak/lib/python3.6/site-packages
Finished processing dependencies for autokeras==1.0.0
(ak) lay@HL_ML:~/autokeras$ history
    1  sudo vi /etc/apt/sources.list
    2  sudo apt-get update; sudo apt-get upgrade -y; git clone https://github.com/keras-team/autokeras.git; sudo apt-get insatll python3-venv;
    3  sudo apt-get install python3-venv;
    4  python3 -m venv ak
    5  source ak/bin/activate
    6  cd autokeras/
    7  sudo apt-get install gcc; sudo apt-get install python3-dev; pip install wheel;
    8  sudo apt-get install gcc -y; sudo apt-get install python3-dev -y; pip install wheel;
    9  pip install -r requirements.txt
   10  python setup.py install
   11  history
(ak) lay@HL_ML:~/autokeras$  
```",command result may take please create default user account need match information visit enter new lay enter new password retype new password password successfully installation successful run command administrator user root use command see man lay password lay lay update upgrade git clone get get get get get get get get get get get get get get get get get get get get get get get get get get get get get get fetched reading package done reading package done building dependency tree reading state information done calculating upgrade done following package automatically longer use apt remove following apt bash curl base python vim newly remove need get operation disk space freed get bash get get get base get get get get get get get get get get get get get get get get get get get get get get apt get get get get get get python get get get get get get get get get get get get get get vim get get get get get get get get get get get get get get get get get get curl get get get get get get get get get get get get get get fetched reading currently unpack bash setting bash provide auto mode reading currently unpack unpack setting reading currently unpack base setting base reading currently unpack setting reading currently unpack setting reading currently unpack unpack setting reading currently unpack unpack unpack unpack setting reading currently unpack unpack unpack unpack unpack unpack unpack setting machine id random generator reading currently unpack unpack setting reading currently unpack unpack unpack setting reading currently unpack apt setting apt new version file reading currently unpack unpack setting reading currently unpack setting reading currently unpack unpack unpack python unpack unpack unpack unpack unpack unpack unpack unpack unpack unpack unpack unpack unpack unpack unpack unpack vim unpack unpack unpack unpack unpack unpack unpack unpack unpack unpack unpack unpack unpack unpack unpack unpack unpack unpack curl unpack unpack unpack unpack unpack unpack unpack unpack unpack unpack unpack unpack unpack setting setting setting setting setting setting setting setting current default time zone local time tue universal time mon run wish change setting setting setting schema found nothing setting setting setting setting setting setting could determine current update trigger setting may need done may need done possibly affected upgrade could determine current successfully setting setting new version file setting setting setting update trigger setting setting setting setting setting setting setting could determine current setting setting setting new version file setting setting setting setting setting setting setting setting setting update trigger setting setting setting setting new version file file directory setting setting setting setting setting setting curl setting could determine current setting setting setting setting python setting vim setting setting setting setting setting setting setting could determine current update trigger could determine current could determine current remote done remote counting done remote done remote total delta delta mib done done invalid operation lay install reading package done building dependency tree reading state information done following package automatically longer use apt remove following additional following new newly remove need get operation additional disk space used want continue get get get get get fetched previously unselected package reading currently unpack previously unselected package unpack previously unselected package unpack previously unselected package unpack previously unselected package unpack setting setting setting setting setting lay python ak lay source ak lay ak lay install install pip install wheel reading package done building dependency tree reading state information done following package automatically longer use apt remove following additional base dev make flex bison doc following new base dev newly remove need get operation additional disk space used want continue ak lay install install pip install wheel reading package done building dependency tree reading state information done following package automatically longer use apt remove following additional base dev make flex bison doc following new base dev newly remove need get operation additional disk space used get get get get get base get get get get get get get get get get get get get get get get dev get get get get get get fetched previously unselected package reading currently unpack previously unselected package unpack previously unselected package unpack previously unselected package unpack previously unselected package base unpack base previously unselected package unpack previously unselected package unpack previously unselected package unpack previously unselected package unpack previously unselected package unpack previously unselected package unpack previously unselected package unpack previously unselected package unpack previously unselected package unpack previously unselected package unpack previously unselected package unpack previously unselected package unpack previously unselected package unpack previously unselected package unpack previously unselected package unpack previously unselected package dev unpack dev previously unselected package unpack previously unselected package unpack previously unselected package unpack previously unselected package unpack previously unselected package unpack previously unselected package unpack setting setting setting setting setting setting setting setting base setting setting setting setting setting setting setting setting setting setting setting setting setting dev setting setting setting setting setting setting reading package done building dependency tree reading state information done following package automatically longer use apt remove following additional following new newly remove need get operation additional disk space used get get get get get get fetched previously unselected package reading currently unpack previously unselected package unpack previously unselected package unpack previously unselected package unpack previously unselected package unpack previously unselected package unpack setting setting setting setting setting setting wheel collected wheel successfully ak lay pip install line line master line git master running path package produced project name fix line line line line line astor line six line line line requirement already satisfied wheel line gast line line line line line dev dev line line line line line line line line line tabulate line line line line line pluggy line line line line line line pep line line line line coverage line line markdown line line line line line line line line line line building collected gast tabulate running done directory running done directory running done directory running gast done directory running done directory running done directory running tabulate done directory running done directory running done directory successfully built gast tabulate collected six markdown astor gast tabulate pluggy pep coverage found installation successfully uninstalled running install done successfully dev ak lay python install running install running running writing writing writing writing writing manifest file reading manifest file writing manifest file library code running running build flag set archive content egg removing everything egg egg file egg searching reading best match writing file searching reading best match writing file script script script script script toco script script searching best match file searching best match file script script script searching best match file searching best match wheel wheel file wheel script searching dev best match dev dev file searching best match file searching best match file script searching best match six six file searching best match file searching best match file searching best match file searching best match file searching best match file searching best match gast gast file searching best match astor astor file searching best match file searching best match file script script searching best match markdown markdown file script searching best match file searching best match file finished ak lay history update upgrade git clone install python ak source install install pip install wheel install install pip install wheel pip install python install history ak lay,issue,positive,positive,positive,positive,positive,positive
509390725,"1.simply change apt server  and
2.sudo apt-get update; sudo apt-get upgrade -y; git clone https://github.com/keras-team/autokeras.git; sudo apt-get install python3-venv -y; python3 -m venv ak; source ak/bin/activate; cd autokeras/; sudo apt-get install gcc -y; sudo apt-get install python3-dev -y; pip install wheel; pip install -r requirements.txt; python setup.py install;

and when I execute pip install -r requirements.txt then
```
Collecting kerastuner from git+git://github.com/keras-team/keras-tuner@master#egg=kerastuner (from -r requirements.txt (line 3))
  Cloning git://github.com/keras-team/keras-tuner (to master) to /tmp/pip-build-3emq08hc/kerastuner
  Running setup.py (path:/tmp/pip-build-3emq08hc/kerastuner/setup.py) egg_info for package kerastuner produced metadata for project name keras-tuner. Fix your #egg=kerastuner fragments.
```
occur
and in Python display `Pakage requirement 'kerastuner' is not satisfied` is it okay?",change apt server update upgrade git clone install python ak source install install pip install wheel pip install python install execute pip install master line git master running path package produced project name fix occur python display requirement satisfied,issue,negative,positive,positive,positive,positive,positive
509204534,"@alexsiormpas 
[Conda](https://docs.conda.io/en/latest/) (or Anaconda) is a package manager for the python language. With it, you can create multiple environments, comparable to ""Virtual Machines"", in which you can install, uninstall etc. packages with certain requirements without affecting your overall system. As a result, you can install autokeras for example, without it conflicting with any other projects you might have, if you use a dedicated environment. A minimal version that you could have a look at is [Miniconda](https://docs.conda.io/en/latest/miniconda.html). You'll find plenty of documentation and materials online.

[This](https://autokeras.com/start/) is the website, I mentioned. There, you'll finde these commands that should be executed:
```
pip install -r requirements.txt
python setup.py install
```",anaconda package manager python language create multiple comparable virtual install certain without affecting overall system result install example without conflicting might use environment minimal version could look find plenty documentation executed pip install python install,issue,positive,positive,neutral,neutral,positive,positive
509117887,"@christian-steinmeyer 
- What does clean conda environment mean? No package installed?
- COuld you please share the link  to the website you're mentioning so I can read what I need to do.
Sorry very new to Python :)",clean environment mean package could please share link read need sorry new python,issue,positive,negative,neutral,neutral,negative,negative
509081452,"If you have a clean (conda) environment, clone the current state of the git project, and install all requirements from it, it should work. Details can be found on the website under ""getting started"" > without pip.",clean environment clone current state git project install work found getting without pip,issue,negative,positive,positive,positive,positive,positive
509036720,"> > Hi JJSeah, I'm new to Anaconda/Python so could you please tell me where I can find that setup.py file?
> 
> Hi Jason, you can download the setup.py file from this repo or just create a new python file and change the code accordingly above. You can run the python file by [python setup.py install] in your terminal to began the installation.
> 
> Hope this helps!
Thanks for your hint I followed your reply and still getting the following errors
Could you please help me with that?:
```
running install
running bdist_egg
running egg_info
writing autokeras.egg-info\PKG-INFO
writing dependency_links to autokeras.egg-info\dependency_links.txt
writing requirements to autokeras.egg-info\requires.txt
writing top-level names to autokeras.egg-info\top_level.txt
reading manifest file 'autokeras.egg-info\SOURCES.txt'
writing manifest file 'autokeras.egg-info\SOURCES.txt'
installing library code to build\bdist.win-amd64\egg
running install_lib
warning: install_lib: 'build\lib' does not exist -- no Python modules to install

creating build\bdist.win-amd64\egg
creating build\bdist.win-amd64\egg\EGG-INFO
copying autokeras.egg-info\PKG-INFO -> build\bdist.win-amd64\egg\EGG-INFO
copying autokeras.egg-info\SOURCES.txt -> build\bdist.win-amd64\egg\EGG-INFO
copying autokeras.egg-info\dependency_links.txt -> build\bdist.win-amd64\egg\EGG-INFO
copying autokeras.egg-info\requires.txt -> build\bdist.win-amd64\egg\EGG-INFO
copying autokeras.egg-info\top_level.txt -> build\bdist.win-amd64\egg\EGG-INFO
zip_safe flag not set; analyzing archive contents...
creating 'dist\autokeras-0.4.0-py3.7.egg' and adding 'build\bdist.win-amd64\egg' to it
removing 'build\bdist.win-amd64\egg' (and everything under it)
Processing autokeras-0.4.0-py3.7.egg
Removing c:\users\siorb\appdata\local\programs\python\python37\lib\site-packages\autokeras-0.4.0-py3.7.egg
Copying autokeras-0.4.0-py3.7.egg to c:\users\siorb\appdata\local\programs\python\python37\lib\site-packages
autokeras 0.4.0 is already the active version in easy-install.pth

Installed c:\users\siorb\appdata\local\programs\python\python37\lib\site-packages\autokeras-0.4.0-py3.7.egg
Processing dependencies for autokeras==0.4.0
Searching for torch==1.1.0
Reading https://pypi.org/simple/torch/
No local packages or working download links found for torch==1.1.0
error: Could not find suitable distribution for Requirement.parse('torch==1.1.0')
```
",hi new could please tell find file hi file create new python file change code accordingly run python file python install terminal installation hope thanks hint reply still getting following could please help running install running running writing writing writing writing reading manifest file writing manifest file library code running warning exist python install flag set archive content egg removing everything egg removing egg egg already active version egg searching reading local working link found error could find suitable distribution,issue,positive,positive,positive,positive,positive,positive
508964381,"There is no easy way to install autokeras on windows unfortunately. Easiest way is to just use ubuntu 18.04 and `pip install autokeras` will work.

Otherwise you'll have to get an old release from github, tweak the dependencies in setup.py to something compatible and install it manually using `python setup.py`. I tried it as well, ended up installing ubuntu on another ssd so I can use the GPU of my PC.",easy way install unfortunately easiest way use pip install work otherwise get old release tweak something compatible install manually python tried well ended another use,issue,positive,positive,neutral,neutral,positive,positive
508547431,"Since the only issue remains is whether the feeding data to preprocessors should be a single Dataset or multiple dataset, I will merge the pull request to not blocking other pull requests. Since it will be a big change, I will pull request separately if needed.",since issue remains whether feeding data single multiple merge pull request blocking pull since big change pull request separately,issue,negative,negative,neutral,neutral,negative,negative
508148461,"> @alokgogate I had the same error because I didn't pass the labels one-hot-encoded.

@LukasKapp-Schwoerer's suggestion should solve the problem of @alokgogate.

@huaiyizhao Could you elaborate on your reply? Perhaps have a look at #678, there, I've further explained another problem I have. In essence, the loss is undefined such that autokeras does not converge.",error pas suggestion solve problem could elaborate reply perhaps look another problem essence loss undefined converge,issue,negative,positive,positive,positive,positive,positive
507365354,"I have added the issues in https://github.com/keras-team/autokeras/projects/3#card-23314326 about 1. the AutoModelBase (#689) and when to initialize the tuner (#688) and whether we should handle validation data in AutoKeras (#690).
I will merge the pull request just not to block the rest of the development, we can continue discussion on these in the issues.",added initialize tuner whether handle validation data merge pull request block rest development continue discussion,issue,negative,neutral,neutral,neutral,neutral,neutral
507360759,"For the AutoModel and GraphAutoModel, for now, the logic is really AutoModel is a subclass of GraphAutoModel, since it needs everything in the GraphAutoModel. We can look back to it when we have the metamodel ready, to see if there are common logic to extract to the base class. @fchollet ",logic really subclass since need everything look back ready see common logic extract base class,issue,negative,negative,negative,negative,negative,negative
507297008,I am also unable to export the keras model for ImageRegressor1D - has any progress been made on solving this issue? Thanks! ,also unable export model progress made issue thanks,issue,positive,negative,negative,negative,negative,negative
507264738,Moving to a new PR after recent changes to master branch,moving new recent master branch,issue,negative,positive,neutral,neutral,positive,positive
507225098,"@josai, Same issue here, autokeras-model export works fine, however keras export model has same error. Are you on python3.6?",issue export work fine however export model error python,issue,negative,positive,positive,positive,positive,positive
505552868,"There are major changes in the master branch. Please change the pull request accordingly. If too many conflicts, you can close the pull request, start a new branch from master, copy and paste your code to it, and submit a new one. Thanks.",major master branch please change pull request accordingly many close pull request start new branch master copy paste code submit new one thanks,issue,positive,positive,positive,positive,positive,positive
505517618,"Since the master has changed too much and the new API is not the same as the current sequential, I will close this pull request and send a new one.",since master much new current sequential close pull request send new one,issue,negative,positive,neutral,neutral,positive,positive
505517105,"Since the master has changed too much, I will close this pull request and start a new branch to PR again.",since master much close pull request start new branch,issue,negative,positive,positive,positive,positive,positive
505328073,"Hi @josai 
I am also facing the same issue/error.
Were you able to export the keras model?",hi also facing able export model,issue,negative,positive,positive,positive,positive,positive
504724779,"Building from source when you have torch with cuda and TF-gpu without regular tensorflow solves this issue in my case.
`git clone` and `python setup.py install`

Edit: already have the 48th model after 24h using 4 GPUs
I modified source by adding some prints and it seems to do some heavy single thread computations here:
```
Search.train produce_model
Search.train train_model
                                                                                                    
No loss decrease after 5 epochs.

Start loading model /mnt/12TB/autokeras2/temp_model
Finished loading model /mnt/12TB/autokeras2/temp_model
return from train_model
Search.train set_weight_to_graph
Search.train DONE

# Here are those heavy computations

Saving model.
```",building source torch without regular issue case git clone python install edit already th model source heavy single thread loss decrease start loading model finished loading model return done heavy saving model,issue,negative,negative,negative,negative,negative,negative
504719250,Dr. Jin I have completed all the test. And I don't delete the ImageTuner class. Because the other class calls it. Now you can have a look at the whole function(augment_iamge) to decide where we can use it.,test delete class class look whole function decide use,issue,negative,positive,positive,positive,positive,positive
504703525,"Well if anyone runs over this issue:

`conda uninstall imageio`

so easy. took me 30 minutes to figure that out 👯‍♂ ",well anyone issue easy took figure,issue,positive,positive,positive,positive,positive,positive
504703314,"If I do that I run into the 

` ERROR: Could not find a version that satisfies the requirement torch==1.0.1 (from autokeras==0.3.7) (from versions: 0.1.2, 0.1.2.post1, 0.1.2.post2)
ERROR: No matching distribution found for torch==1.0.1 (from autokeras==0.3.7)`

Problem. Any better ideas? ^^

",run error could find version requirement post post error matching distribution found problem better,issue,negative,positive,positive,positive,positive,positive
504558728,"same here with 4 GPUs and 20 cores.
In between, it is using a single core only to do ...?

Edit: 0.4.0 from pip
Edit2: Image classification task",single core edit pip edit image classification task,issue,negative,negative,neutral,neutral,negative,negative
504413535,"Hi,
I did not find any complete example how to build MLP for simple regressions. 
I think an autokeras code for MLP Boston house price dataset, as suggested by itsergiu, could be really of great help!",hi find complete example build simple think code boston house price could really great help,issue,positive,positive,positive,positive,positive,positive
503689283,"@jhfjhfj1 
Running on Google Colab:
```
/usr/local/lib/python3.6/dist-packages/autokeras/__init__.py in <module>()
----> 1 from autokeras.image.image_supervised import ImageClassifier, ImageRegressor, PortableImageSupervised
      2 from autokeras.text.text_supervised import TextClassifier
      3 from autokeras.net_module import CnnModule, MlpModule

ImportError: cannot import name 'ImageClassifier'
```
Code:

```
# !pip install autokeras
from autokeras.image.image_supervised import ImageClassifier
from autokeras.image.image_supervised import load_image_dataset


x_train, y_train = load_image_dataset(csv_file_path=""train/label.csv"",
                                      images_path=""train"")
print(x_train.shape)
print(y_train.shape)

x_test, y_test = load_image_dataset(csv_file_path=""val/label.csv"",
                                    images_path=""val"")
print(x_test.shape)
print(y_test.shape)
```
",running module import import import import name code pip install import import train print print print print,issue,negative,neutral,neutral,neutral,neutral,neutral
503660145,"I am seeing this error on Windows Server 2016 with Python 3.6.8 when following the standard installation instructions that utilize pip instead of setup.py. 

```
C:\Windows\system32>systeminfo | findstr /B /C:""OS Name"" /C:""OS Version""
OS Name:                   Microsoft Windows Server 2016 Datacenter
OS Version:                10.0.14393 N/A Build 14393

C:\Windows\system32>python --version
Python 3.6.8

C:\Windows\system32>pip --version
pip 19.1.1 from c:\program files\python36\lib\site-packages\pip (python 3.6)

C:\Windows\system32>pip install autokeras
Collecting autokeras
  Using cached https://files.pythonhosted.org/packages/c2/32/de74bf6afd09925980340355a05aa6a19e7378ed91dac09e76a487bd136d/autokeras-0.4.0.tar.gz
Collecting scipy==1.2.0 (from autokeras)
  Using cached https://files.pythonhosted.org/packages/c4/0f/2bdeab43db2b4a75863863bf7eddda8920b031b0a70494fd2665c73c9aec/scipy-1.2.0-cp36-cp36m-win_amd64.whl
Collecting tensorflow==1.13.1 (from autokeras)
  Using cached https://files.pythonhosted.org/packages/bf/58/34bfa8fa17f86333361172b3b502e805195180f19a7496ad0f6149138d55/tensorflow-1.13.1-cp36-cp36m-win_amd64.whl
Collecting torch==1.0.1.post2 (from autokeras)
  ERROR: Could not find a version that satisfies the requirement torch==1.0.1.post2 (from autokeras) (from versions: 0.1.2, 0.1.2.post1)
ERROR: No matching distribution found for torch==1.0.1.post2 (from autokeras)

C:\Windows\system32>
```",seeing error server python following standard installation utilize pip instead o name o version o name server o version build python version python pip version pip python pip install post error could find version requirement post post error matching distribution found post,issue,negative,neutral,neutral,neutral,neutral,neutral
502978577,"The seed for the weight initialization is set randomly each time you run the model. For reproducible results, you need the set the seed at the beginning of the program.
For example,
```
import numpy as np
np.seed(2019)
```",seed weight set randomly time run model reproducible need set seed beginning program example import,issue,negative,negative,negative,negative,negative,negative
502977106,It can be very easily applied to LSTM networks. I used it for text classification tasks successfully.,easily applied used text classification successfully,issue,positive,positive,positive,positive,positive,positive
502929460,"> Hi Satya,
> The code generally looks OK. There some more things to be added.
> 
> 1. We would like the input to be raw text data (strings). So you may add embedding layer in TextBlock and connect the output of embedding to RNNblock.
> 2. You may convert the text input to numerical vectors in text tuner just like what we did for image data augmentation.
> 3. For the current version, is there any difference between the TextTuner's _run and the original one?
> 
> Thanks.

Hi Haifeng,

I initially planned to incorporate point 1 in future PRs. But, I can do it in this PR. So, I will address both points 1 and 2 in the current PR. Regarding the third point, there is a slight difference between TextTuner's _run and the original one. In the original, model.compile() is not called without the arguments loss/optimizer/metrics and when I tested this, it threw errors. So, I planned to include a separate _run function for now in this PR. From the official documentation, I see that optimizer is a mandatory argument but it is not the case in the original method. So, Is there something wrong with the code or am I missing on something?",hi code generally added would like input raw text data may add layer connect output may convert text input numerical text tuner like image data augmentation current version difference original one thanks hi initially incorporate point future address current regarding third point slight difference original one original without tested threw include separate function official documentation see mandatory argument case original method something wrong code missing something,issue,positive,positive,neutral,neutral,positive,positive
502916081,"No problem.I will have a try!


 
---Original---
From: ""Haifeng Jin""<notifications@github.com>
Date: Tue, Jun 18, 2019 10:02 AM
To: ""keras-team/autokeras""<autokeras@noreply.github.com>;
Cc: ""Davidsirui""<1053871735@qq.com>;""Mention""<mention@noreply.github.com>;
Subject: Re: [keras-team/autokeras] Use tf.data and tf.image for image augmentation (#670)



@jhfjhfj1 requested changes on this pull request.
 
I think the overall code looks good.
 Here are the things to change besides making the code to run:
  
Remove the ImageTuner but directly use SequentialRandomSearch. The augment function can return tf.data or what ever is convenient that can be passed to a keras model as input data. 

The augment should be general enough to augment any data instead of selecting from cifar. 

Rename your branch with a meaningful name like 'augment'. 
 
Thanks.
 
—
You are receiving this because you were mentioned.
Reply to this email directly, view it on GitHub, or mute the thread.",try date tue mention mention subject use image augmentation pull request think overall code good change besides making code run remove directly use augment function return ever convenient model input data augment general enough augment data instead rename branch meaningful name like thanks reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
502872254,"@Davidsirui I will look into it and get back to you soon. Please remember to change the assignee to me whenever it is pending on me, even when it is not a review request. Thanks.",look get back soon please remember change assignee whenever pending even review request thanks,issue,positive,positive,neutral,neutral,positive,positive
502414134,"having the same issue even with backend = tensorflow

Get an error whenever I try:

` clf.export_keras_model('my_model.h5')`

 Here is the error report:

`in export_keras_model
    self.cnn.best_model.produce_keras_model().save(model_file_name)
AttributeError: 'Graph' object has no attribute 'produce_keras_model'`


however 

`clf.export_autokeras_model('my_autokeras_model.h5')`

works just fine. 

REAL pain in the ass not being able to export the model...",issue even get error whenever try error report object attribute however work fine real pain as able export model,issue,negative,positive,positive,positive,positive,positive
502365250,"This is just a demo. Dr. Jin can have a look at it to see if the thought or direction is right. If it is OK to do so, I will complete this commit. If it is a wrong direction, we can discuss an alternative solution to it. ",look see thought direction right complete commit wrong direction discus alternative solution,issue,negative,negative,neutral,neutral,negative,negative
502244134,"I think you can set the constant value

# Shuffle the data and set the settings
from sklearn.utils import shuffle
x_train,y_train = shuffle(x_train,y_train)

from autokeras.constant import Constant
# Constant.BACKEND = 'tensorflow'
Constant.MAX_BATCH_SIZE = 6
Constant.VALIDATION_SET_SIZE = 0.3

from autokeras.image.image_supervised import ImageClassifier

something like that",think set constant value shuffle data set import shuffle shuffle import constant import something like,issue,positive,neutral,neutral,neutral,neutral,neutral
501686113,Can't agree more. We need more documentation and examples dealing with custom data. And  a bit more classifiers.,ca agree need documentation dealing custom data bit,issue,negative,neutral,neutral,neutral,neutral,neutral
501684615,"I'm not sure if it is the appropriate way to do classification since MlpModel's output is a float rather than {0,1}, the ""classification"" loss function may not apply here.",sure appropriate way classification since output float rather classification loss function may apply,issue,negative,positive,positive,positive,positive,positive
501488371,"Hi

I think there is a mistake in the PR :

```
if get_system() == Constant.SYS_GOOGLE_COLAB:
            # When using Google Colab, use single process for searching and training.
            self.sp_search(graph, other_info, model_id, train_data, test_data)
        else:
            # Use two processes
            self mp_search(graph, other_info, model_id, train_data, test_data)
```
Following your comment, sp and mp are inverted no ?
",hi think mistake use single process searching training graph else use two self graph following comment inverted,issue,negative,negative,neutral,neutral,negative,negative
501089553,"just use ""git reset"" command.",use git reset command,issue,negative,neutral,neutral,neutral,neutral,neutral
501089280,Would you please revert the changes you made on blocks branch and create a new branch and pull request to blocks? Thanks. @PraveenVenugopal,would please revert made branch create new branch pull request thanks,issue,positive,positive,positive,positive,positive,positive
501022490,This one is also ready for review. Thanks. @fchollet ,one also ready review thanks,issue,positive,positive,positive,positive,positive,positive
500987796,"@eustomaqua Here is an example released yesterday, you can change the the search space according to it. Thanks. https://github.com/keras-team/keras-tuner/tree/master/kerastuner/applications/tunable_xception",example yesterday change search space according thanks,issue,negative,positive,positive,positive,positive,positive
500961797,The comments are all addressed except for using tf.data. It is ready for another review. Thanks. @fchollet ,except ready another review thanks,issue,positive,positive,positive,positive,positive,positive
500942296,@Davidsirui we should continue on the original pull request instead of creating a new one. Thanks. Remember to use local IDEs for the development which would be more efficient.,continue original pull request instead new one thanks remember use local ides development would efficient,issue,positive,positive,positive,positive,positive,positive
499948481,"I'm going to attempt to explain this thread. Back in January 2019, @jhfjhfj1 pushed a ""Tabular""/""GeneralClassifier"" API (#406) but removed it soon after in February (#550). The main source code for this ""Tabular"" module was [here](https://github.com/keras-team/autokeras/blob/4ddd568b06b4045ace777bc0fb7bc18573b85a75/autokeras/tabular/tabular_supervised.py), which has now been moved by @bolkedebruin to [autokeras_tabular](https://github.com/bolkedebruin/autokeras_tabular).

The author, @jhfjhfj1, explained the rationale behind the removal as such:

> @testvinder This has been removed because Auto-Keras is focusing on deep learning tasks.
> We are moving it to a new project just focusing on tabular data, which will be completed soon.
> By the time we complete the basics, we will be open to contribution.
> Thank you!

At first, it wasn't clear what @jhfjhfj1 meant by ""focusing on deep learning tasks,"" because regressions are in fact a core deep learning task. However, upon a closer look at the removed module code, as @flamby suggests, the module used [LightGBM](https://lightgbm.readthedocs.io/en/latest/), a ""gradient boosting framework that uses tree based learning algorithms."" In other words, it is machine learning but not deep learning.

It is still not clear to me why @jhfjhfj1 did not implement this ""Tabular""/""GeneralClassifier"" with a neural network like a fully-connected net or any sort of CNN/RNN like the ""image"" and ""text"" modules. Why use machine learning in *neural* architecture search? Besides, NAS/AutoML as a paradigm should be domain- and problem-independent; otherwise, aren't we simply resorting back to manual search with bells and whistles (""search heuristics"")?

I hope this does not come across as hostile. For my thesis, I need an open-source framework for NAS but the only mature one I can find does not support my problem. Pardon my frustration.",going attempt explain thread back tabular removed soon main source code tabular module author rationale behind removal removed deep learning moving new project tabular data soon time complete open contribution thank first clear meant deep learning fact core deep learning task however upon closer look removed module code module used gradient framework tree based learning machine learning deep learning still clear implement tabular neural network like net sort like image text use machine learning neural architecture search besides paradigm otherwise simply back manual search search hope come across hostile thesis need framework mature one find support problem pardon frustration,issue,positive,positive,neutral,neutral,positive,positive
499549120,The name_scope is finished. Ready for another review. Thanks.@fchollet ,finished ready another review thanks,issue,positive,positive,positive,positive,positive,positive
499309953,"Since I appear to have not have push access to the repository, here's my proposed solution:

File: `autokeras/backend/torch/data_transformer.py`
```
    def transform_train(self, data, targets=None, batch_size=None, shuffle=True):
        data = (data - self.mean) / self.std
        data = np.nan_to_num(data)
        dataset = self._transform([], data, targets)

        if batch_size is None:
            batch_size = Constant.MAX_BATCH_SIZE
        batch_size = min(len(data), batch_size)

        return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)

    def transform_test(self, data, target=None, batch_size=None):
        return self.transform_train(data, targets=target, batch_size=batch_size, shuffle=False)
```

Please let me know how you like it @jhfjhfj1. Thanks!",since appear push access repository solution file self data data data data data data none min data return self data return data please let know like thanks,issue,positive,positive,positive,positive,positive,positive
499238837,"I was interested in using AutoKeras to create a Keras model but after enough hassle I ended up using the following code from which I can build a Keras model or visualize using some of PyTorch's visualization tools.

      
       `clf = ImageClassifier(verbose=True, augment = True)

        print(""\n--Training..."")
        clf.fit(train_x, train_y, time_limit = training_time)

        print(""\n--Finding final model..."")
        clf.final_fit(train_x, train_y, test_x, test_y, retrain = False)
                    
        best_model = clf.cnn.best_model.produce_model()
        print(best_model)
        torch.save(best_model, output + ""torch_best_model_trial_"" + str(trial))`

with the printed output being:

![image](https://user-images.githubusercontent.com/8714759/58987071-c0c87c80-87ac-11e9-87c9-82d77422643f.png)

Hope that helps, and if anyone comes across a way to export a Keras model directly using AutoKeras 0.4.0 I would eternally grateful 🙌",interested create model enough hassle ended following code build model visualize visualization augment true print training print finding final model retrain false print output trial printed output image hope anyone come across way export model directly would eternally grateful,issue,positive,positive,neutral,neutral,positive,positive
499214683,"> can't find this either, seems to be issues with GeneralRegressor, TabularClassifier etc. but nothing in the codebase or docs.



> I can not find the GeneralRegressor in the documentation, or in the code examples

AutoKeras Tabular was removed, reason for this is explained in #562 

Thankfully @bolkedebruin created a package (https://pypi.org/project/autokeras-tabular/) containing the missing functionality.",ca find either nothing find documentation code tabular removed reason thankfully package missing functionality,issue,negative,negative,negative,negative,negative,negative
498896696,"Several things to change:
1. Remove the compile() function of AutoModel.
The heads should handle the loss and metrics (use fixed value for now). The HyperModel should handle the optimizer (make it a tunable variable).

2. The handling of name_scope should be done in the base classes, i.e., HyperModel, HyperParameters.
We can delete HierarchicalHyperParameters.
Use the shadowing mechanism to wrap the build function in the HyperModel class.
In the retrieving function of HyperParameters, it should include the name_scope.

3. We let the user define ""trial"".
4. We don't let the user specify ""tuner"".",several change remove compile function handle loss metric use fixed value handle make tunable variable handling done base class delete use shadowing mechanism wrap build function class function include let user define trial let user specify tuner,issue,negative,negative,negative,negative,negative,negative
498876128,Also we need to discuss more about `HierarchicalHyperParameters` and how to handle name scopes.,also need discus handle name,issue,negative,neutral,neutral,neutral,neutral,neutral
497171729,"> 
> 
> > Yes. so if autokeras stopped supporting keras why do you call ""autokeras"" instead of ""autotorch""? It confuses me.
> 
> I'm not on the autokeras project. I just also ran into this problem and found your issue open. It didn't stop supporting keras though. Keras != tensorflow and has been able to be run with different backends for a while (theano, tensorflow, and pytorch). I'm not sure why they set the default to pytorch and don't allow you to change it.

Keras supports TensorFlow, Theano, CNTK (from Microsoft) as backends, but I do not think Keras supports PyTorch as backends.

See: https://discuss.pytorch.org/t/is-it-possible-to-use-pytorch-as-backend-for-keras/15287",yes stopped supporting call instead project also ran problem found issue open stop supporting though able run different sure set default allow change think see,issue,positive,positive,positive,positive,positive,positive
497074870,"> Yes. so if autokeras stopped supporting keras why do you call ""autokeras"" instead of ""autotorch""? It confuses me.

I'm not on the autokeras project. I just also ran into this problem and found your issue open. It didn't stop supporting keras though. Keras != tensorflow and has been able to be run with different backends for a while (theano, tensorflow, and pytorch). I'm not sure why they set the default to pytorch and don't allow you to change it.",yes stopped supporting call instead project also ran problem found issue open stop supporting though able run different sure set default allow change,issue,positive,positive,positive,positive,positive,positive
497070954,"> 
> 
> So, in [`autokeras/backend/__init__.py`](https://github.com/keras-team/autokeras/blob/master/autokeras/backend/__init__.py), I noticed this:
> 
> ```
> from autokeras.constant import Constant
> 
> class Backend:
> backend = torch if Constant.BACKEND == 'torch' else tensorflow
> ```
> 
> And if you follow that into [`autokeras/constant.py`](https://github.com/keras-team/autokeras/blob/master/autokeras/constant.py) it looks like `Constant.BACKEND` default set to `'torch'`. We just set that to `'tensorflow'` in our environment, but there should be a way to change this.
> 
> By changing `autokeras/backend/__init__.py` you can get it working now, but this should in no way close this issue haha:
> `backend = tensorflow`

Yes. so if autokeras stopped supporting keras why do you call ""autokeras"" instead of ""autotorch""? It confuses me.",import constant class torch else follow like default set set environment way change get working way close issue yes stopped supporting call instead,issue,positive,positive,positive,positive,positive,positive
497052518,"So, in [`autokeras/backend/__init__.py`](https://github.com/keras-team/autokeras/blob/master/autokeras/backend/__init__.py), I noticed this:

```
from autokeras.constant import Constant

class Backend:
backend = torch if Constant.BACKEND == 'torch' else tensorflow
```

And if you follow that into [`autokeras/constant.py`](https://github.com/keras-team/autokeras/blob/master/autokeras/constant.py) it looks like `Constant.BACKEND` default set to `'torch'`. We just set that to `'tensorflow'` in our environment, but there should be a way to change this.

By changing `autokeras/backend/__init__.py` you can get it working now, but this should in no way close this issue haha:
`backend = tensorflow`",import constant class torch else follow like default set set environment way change get working way close issue,issue,negative,neutral,neutral,neutral,neutral,neutral
496794991,"I can do up a small Colab tutorial. Only minor issue is installing autokeras requirements has a different version of PyTorch to the one on Colab. 

Workaround and working Colab notebook:

https://github.com/keras-team/autokeras/issues/624#issuecomment-495916771",small tutorial minor issue different version one working notebook,issue,negative,negative,neutral,neutral,negative,negative
496679872,"#639 brought up a good point. Not sure if switching the URL to 0.4.0 solves any of the issues discussed here, but making that correction in the setup.py file along with starting from a fresh anaconda environment (python==3.6) and doing the following:

1.) installing pytorch 1.0.1 and torchvision from [here](https://pytorch.org/get-started/previous-versions/)
2.) removing the version of numpy just installed (pip remove numpy, may be unnecessary) 
3.) installing by hand (using conda install, not pip) the rest of the dependencies
4.) completely deleting the 'install_requires' list in setup.py
5.) python setup.py install (autokeras)
6.) git cloning apex, python setup.py install

results in a working version of autokeras with the only issue being a depreciation warning from sklearn:
""Cloudpickle.py, the imp module is deprecated in favor of importlib""

Really hope that helps someone!

![image](https://user-images.githubusercontent.com/8714759/58510511-e4fddb00-8166-11e9-9aa0-2131fe3e00d6.png)
",brought good point sure switching making correction file along starting fresh anaconda environment following removing version pip remove may unnecessary hand install pip rest completely list python install git apex python install working version issue depreciation warning imp module favor really hope someone image,issue,positive,positive,positive,positive,positive,positive
496270089,"Command ""pip install autokeras --ignore-installed"" successfully worked.
Thanks!",command pip install successfully worked thanks,issue,positive,positive,positive,positive,positive,positive
495916771,"I encountered and managed to get round this error.
You must use the version of PyTorch provided by the Colab runtime.

To install a fork that does not list PyTorch as a dependency:

```
! cd /opt/ && \
  git clone --depth 1 https://github.com/NVAITC/autokeras && \
  cd autokeras && python3 setup.py install
```

You will need to restart the Colab runtime (CTRL+M) the first time you're installing this

Sample notebook that works: https://colab.research.google.com/drive/1g5N9ZPH-dDBI-VrHvWjOpNRHunIZ_oBv",get round error must use version provided install fork list dependency git clone depth python install need restart first time sample notebook work,issue,negative,positive,neutral,neutral,positive,positive
495638066,"Yes, but also added the parameter to the TextClassifier class, and assigned its value to the num_labels attribute.
Please let me know if I can help in anything else.",yes also added parameter class assigned value attribute please let know help anything else,issue,positive,neutral,neutral,neutral,neutral,neutral
495599046,"Like you, I also need to get the probability of the final prediction. My solution is as follows:
add following code to the supervised.py
```
def predict_proba(self, x_test):
        x_test = self.preprocess(x_test)
        test_loader = self.data_transformer.transform_test(x_test)
        return self.cnn.predict(test_loader)
```",like also need get probability final prediction solution add following code self return,issue,positive,neutral,neutral,neutral,neutral,neutral
495114749,"can't find this either, seems to be issues with GeneralRegressor, TabularClassifier etc. but nothing in the codebase or docs.",ca find either nothing,issue,negative,neutral,neutral,neutral,neutral,neutral
494870109,"@maystroh Try to expand the dimension of the X data as follow:

```
import numpy as np
from autokeras.image.image_supervised import ImageClassifier1D

X = np.random.normal(size=(100000,10)) # 1M examples of 1D signal with 10 samples 
Y = np.random.randint(4, size=(100000,))

model = ImageClassifier1D(verbose=True)

X_train = np.expand_dims(X, axis=2)
model.fit(X_train, Y, time_limit=1 * 60 * 60)
```",try expand dimension data follow import import signal model,issue,negative,neutral,neutral,neutral,neutral,neutral
494859775,"From my understanding Y data should be passed as a 1D array of labels, not as an one-hot-encoded 2D array.",understanding data array array,issue,negative,neutral,neutral,neutral,neutral,neutral
494662859,"Did you implement it like this ? Because I am facing an issue when i declare it like this.
clf = TextClassifier(verbose=True, path=path,num_labels=2)

Error:__init__() got an unexpected keyword argument 'num_labels'
",implement like facing issue declare like error got unexpected argument,issue,negative,positive,neutral,neutral,positive,positive
494616785,"Hi Phier77, thanks for your great workaround! It worked!!! Would you mind clarifying how you also managed to have folders autokeras.egg-info and autokeras-0.4.0-py3.6.egg in your site-packages? should I move my folder autokeras.egg-info into my site-packages directory? Is cudatoolkit for gpu laptop? Mine one is cpu only so no need to install pytorch torchvision cudatoolkit=8? Thanks",hi thanks great worked would mind also egg move folder directory mine one need install thanks,issue,positive,positive,positive,positive,positive,positive
494479143,"@JasonMDSII met the same problem with you. It showed ""No module named autokeras""when I tried to import autokeras in Jupyter Notebook.
Then I download the file named autokeras-master from github and  I put the autokeras file under the file named ""site-packages"" under created environment ""autokeras"" .
Finally,it works.Before traning models, I suggesst you use pip to install nvidia apex to speed up because autokeras 0.4 uses pytorch to train models rather than tensorflow.
![无标题](https://user-images.githubusercontent.com/17315826/58116698-84831100-7c2f-11e9-8309-2995f4f862dc.png)



> > You can switch to autokeras0.3.7 & pytorch1.0.1
> 
> I tried this but using the pip installer it still won't go through with the error. ""ERROR: Could not find a version that satisfies the requirement torch==1.0.1"" it seems the issue is it is trying to pip install torch by name which does not seem to work. I also tried installing torch 1.0.1 and then trying autokeras, but still nothing

Have you tried  conda install pytorch torchvision cudatoolkit=8 or 9 or 10.0 -c pytorch",met problem module tried import notebook file put file file environment finally use pip install apex speed train rather switch tried pip installer still wo go error error could find version requirement issue trying pip install torch name seem work also tried torch trying still nothing tried install,issue,negative,neutral,neutral,neutral,neutral,neutral
494385147,"Hi JJSeah, 
I think you're right: I see autokeras folder resides outside AppData folder which contains site-packages. I did follow the instruction of running [python setup.py installation] in the windows command prompt, so why didn't it work? Can you tell what I did wrong? Thanks
![image](https://user-images.githubusercontent.com/11934573/58098961-f8b4b900-7c1d-11e9-9b36-4617033b314c.png)
",hi think right see folder outside folder follow instruction running python installation command prompt work tell wrong thanks image,issue,negative,negative,neutral,neutral,negative,negative
494355502,it might be because you didnt install the models into conda but in your computer environment,might didnt install computer environment,issue,negative,neutral,neutral,neutral,neutral,neutral
494230130,"@yckoong, thanks for the tips as I was able to run the setup.py file and saw that autokeras installed in my anaconda base environment. I also got exactly the same error **No module named 'autokeras'** when importing it in Jupyter notebook.",thanks able run file saw anaconda base environment also got exactly error module notebook,issue,negative,positive,neutral,neutral,positive,positive
494224237,"> I solved the issue by changing the setup.py file which I have attached below. Hope this helps.
> 
> from distutils.core import setup
> from setuptools import find_packages
> 
> setup(
> name='autokeras',
> packages=find_packages(exclude=('tests',)),
> install_requires=['scipy==1.2.0',
> 'tensorflow==1.13.1',
> 'torch==1.1.0',
> 'torchvision==0.2.2.post3',
> 'numpy==1.16.1',
> 'scikit-learn==0.20.2',
> 'scikit-image==0.14.2',
> 'tqdm==4.31.0',
> 'imageio==2.5.0',
> 'requests==2.21.0'
> ],
> version='0.4.0',
> description='AutoML for deep learning',
> author='DATA Lab at Texas A&M University',
> author_email='[jhfjhfj1@gmail.com](mailto:jhfjhfj1@gmail.com)',
> url='http://autokeras.com',
> download_url='https://github.com/keras-team/autokeras/archive/0.3.7.tar.gz',
> keywords=['AutoML', 'keras'],
> classifiers=[]
> )

Successfully install using `setup.py` on terminal 
![image](https://user-images.githubusercontent.com/29967331/58065861-b3f73680-7bb9-11e9-9b5c-6d37209e3ec9.png)

but prompt error when `import autokeras`, any idea?
![image](https://user-images.githubusercontent.com/29967331/58065927-f587e180-7bb9-11e9-82f2-f5a858e6f527.png)
",issue file attached hope import setup import setup post deep learning lab university successfully install terminal image prompt error import idea image,issue,positive,positive,positive,positive,positive,positive
494219347,"Hi JJSeah, thank you for your quick response. However when I run the setup.py file in my Windows 7 command prompt, I've got this error below. It seemed python couldn't recognize the function setup(name='autokeras', ....). Do you have any ideas how to resolve this?

D:\Users\jason>python setup.py install
Traceback (most recent call last):
File ""setup.py"", line 1, in 
setup(
NameError: name 'find_packages' is not defined",hi thank quick response however run file command prompt got error python could recognize function setup resolve python install recent call last file line setup name defined,issue,negative,positive,positive,positive,positive,positive
494007401,"> Hi JJSeah, I'm new to Anaconda/Python so could you please tell me where I can find that setup.py file?

Hi Jason, you can download the setup.py file from this repo or just create a new python file and change the code accordingly above. You can run the python file by [python setup.py install] in your terminal to began the installation.

Hope this helps!",hi new could please tell find file hi file create new python file change code accordingly run python file python install terminal installation hope,issue,positive,positive,positive,positive,positive,positive
493992285," I encounter the same error, could please tell me how to solve this if you had solved the problem. Thank you ",encounter error could please tell solve problem thank,issue,negative,neutral,neutral,neutral,neutral,neutral
493977751,"Hi JJSeah, I'm new to Anaconda/Python so could you please tell me where I can find that setup.py file?",hi new could please tell find file,issue,negative,positive,positive,positive,positive,positive
493737585,"I have the same issue using R,any update?

<img width=""726"" alt=""Screen Shot 2019-05-19 at 09 28 31"" src=""https://user-images.githubusercontent.com/50400284/57979643-9ccd1300-7a18-11e9-9987-3808cf6ce5e7.png"">
",issue update screen shot,issue,negative,neutral,neutral,neutral,neutral,neutral
493724872,I also notice that AutoKeras 0.4.0 starts to use PyTorch to find the best model rather than TensorFlow. How do I specify the latest version of AutoKeras to use the TensorFlow backend instead?,also notice use find best model rather specify latest version use instead,issue,positive,positive,positive,positive,positive,positive
493470887,"Checking the error message in detail, the problem seems to be in the variable: `self.num_labels`.
Unlinke the example in `https://github.com/keras-team/autokeras/blob/master/examples/task_modules/text/text_classification.py`, in my code I'm training my model in one function, and predicting results in another.
I create the object from the class TextClassifier once for the training, and a new object in the predict function. When debbuging the predict function, I have found that self.num_labels is always `None`, and that is the value sent in the ""Prepare model"" `BertForSupervisedTasks.from_pretrained`.
I tested adding the `num_labels` parameter to the TextClassifier class, and it worked ok.
Hope this helps to solve the issue!
Regards.",error message detail problem variable example code training model one function another create object class training new object predict function predict function found always none value sent prepare model tested parameter class worked hope solve issue,issue,negative,positive,positive,positive,positive,positive
493357686,"I solved the issue by changing the setup.py file which I have attached below. Hope this helps.


from distutils.core import setup
from setuptools import find_packages

setup(
    name='autokeras',
    packages=find_packages(exclude=('tests',)),
    install_requires=['scipy==1.2.0',
                      'tensorflow==1.13.1',
                      'torch==1.1.0',
                      'torchvision==0.2.2.post3',
                      'numpy==1.16.1',
                      'scikit-learn==0.20.2',
                      'scikit-image==0.14.2',
                      'tqdm==4.31.0',
                      'imageio==2.5.0',
                      'requests==2.21.0'
                      ],
    version='0.4.0',
    description='AutoML for deep learning',
    author='DATA Lab at Texas A&M University',
    author_email='jhfjhfj1@gmail.com',
    url='http://autokeras.com',
    download_url='https://github.com/keras-team/autokeras/archive/0.3.7.tar.gz',
    keywords=['AutoML', 'keras'],
    classifiers=[]
)

",issue file attached hope import setup import setup post deep learning lab university,issue,negative,neutral,neutral,neutral,neutral,neutral
492740749,"^Above installed autokeras but reinstalled the CPU version of Tensorflow.
(If using CUD9.2) I had to uninstall tensorflow and reinstall version 1.12
",version cud reinstall version,issue,negative,neutral,neutral,neutral,neutral,neutral
492447369,"I think there are two parts of the issue.

1. You can't just do `import SearchSupervised`. SearchSupervised is a sub class of `Supervised` and is not import with `import keras`. You can check here:
https://github.com/keras-team/autokeras/blob/master/autokeras/__init__.py
As you can see the module `supervised.py` is not imported with the `init`

So in order to import SearchSupervised class, you would need to do that yourself by
`import autokeras.supervised.SearchSupervised`

But then here comes the second part

2. If you check the `supervised.py`. You would see that it's full of abstract methods for now. An abstract method is a method that is declared, but contains no implementation.
Abstract classes may not be instantiated, and require subclasses to provide implementations for the abstract methods. And I don't think any of the subclasses is fully implemented. ",think two issue ca import sub class import import check see module order import class would need import come second part check would see full abstract abstract method method declared implementation abstract class may require provide abstract think fully,issue,negative,positive,positive,positive,positive,positive
492422763,"I'm looking for an autoML that handles 1D vector data. Can ImageClassifier1D be used to classify 1D signals? If yes, what will be the  embedding size in this case? I apologize if this is a newbie question. Thanks btw for your great work. ",looking vector data used yes size case apologize question thanks great work,issue,positive,positive,positive,positive,positive,positive
491953771,"> You can switch to autokeras0.3.7 & pytorch1.0.1

I tried this but using the pip installer it still won't go through with the error. ""ERROR: Could not find a version that satisfies the requirement torch==1.0.1"" it seems the issue is it is trying to pip install torch by name which does not seem to work. I also tried installing torch 1.0.1 and then trying autokeras, but still nothing",switch tried pip installer still wo go error error could find version requirement issue trying pip install torch name seem work also tried torch trying still nothing,issue,negative,neutral,neutral,neutral,neutral,neutral
491455805,"The same problem here, I am also on windows 10 and running Python 3.6.8. Any workarounds yet? I will try switching python versions if that will do anything.",problem also running python yet try switching python anything,issue,negative,neutral,neutral,neutral,neutral,neutral
489524091,"Use the following code to loading saved ""autokeras_model"":

 ```
from autokeras.utils import pickle_from_file
 autokeras_model = pickle_from_file(""20170506mnist_autokeras_best_model.h5"")
 autokeras_score = autokeras_model.evaluate(x_test, y_test)
 print(autokeras_score)
```",use following code loading saved import print,issue,negative,neutral,neutral,neutral,neutral,neutral
489338741,"The same issue when I tried a (42839, 240, 240, 3) dataset.
I've trained for around 3 days and finally got this error when 'Training model 164'.
Running under Ubuntu 16.04 512 GB RAM, Nvidia RTX 2080Ti with CUDA10.0 and cuDNN 7.5.1.

> Traceback (most recent call last):
  File ""/usr/lib/python3.6/multiprocessing/process.py"", line 258, in _bootstrap
    self.run()
  File ""/usr/lib/python3.6/multiprocessing/process.py"", line 93, in run
    self._target(*self._args, **self._kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/autokeras/search.py"", line 363, in train
    raise e
  File ""/usr/local/lib/python3.6/dist-packages/autokeras/search.py"", line 356, in train
    verbose=verbose).train_model(**trainer_args)
  File ""/usr/local/lib/python3.6/dist-packages/autokeras/backend/torch/model_trainer.py"", line 109, in train_model
    self._train()
  File ""/usr/local/lib/python3.6/dist-packages/autokeras/backend/torch/model_trainer.py"", line 145, in _train
    outputs = self.model(inputs)
  File ""/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py"", line 489, in __call__
    result = self.forward(*input, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/autokeras/backend/torch/model.py"", line 51, in forward
    temp_tensor = torch_layer(edge_input_tensor)
  File ""/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py"", line 489, in __call__
    result = self.forward(*input, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py"", line 320, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_SUPPORTED. This error may appear if you passed in a non-contiguous input.",issue tried trained around day finally got error model running ram ti recent call last file line file line run file line train raise file line train file line file line file line result input file line forward file line result input file line forward error error may appear input,issue,negative,neutral,neutral,neutral,neutral,neutral
489332340,"I found some thing about that , the issue happens if some bad object in the query set  doesn't contain the mentioned attribute, if all objects are fine the issue doesn't happen , at least on Django 2     ",found thing issue bad object query set contain attribute fine issue happen least,issue,negative,negative,negative,negative,negative,negative
489124788,"Source link for Sentiment Analysis in the documentation is broken. Points to:

https://github.com/keras-team/autokeras/blob/master/autokeras/pretrained/text_classifier.py

404 Error",source link sentiment analysis documentation broken error,issue,negative,negative,negative,negative,negative,negative
489020036,"@christian-steinmeyer getting this error 
>Process ForkProcess-2:
Traceback (most recent call last):
  File ""/root/anaconda3/lib/python3.6/multiprocessing/process.py"", line 258, in _bootstrap
    self.run()
  File ""/root/anaconda3/lib/python3.6/multiprocessing/process.py"", line 93, in run
    self._target(*self._args, **self._kwargs)
  File ""/root/anaconda3/lib/python3.6/site-packages/autokeras/search.py"", line 351, in train
    path=path,
  File ""/root/anaconda3/lib/python3.6/site-packages/autokeras/search.py"", line 344, in train
  File ""/root/anaconda3/lib/python3.6/site-packages/autokeras/nn/model_trainer.py"", line 137, in train_model
  File ""/root/anaconda3/lib/python3.6/site-packages/autokeras/nn/model_trainer.py"", line 174, in _train
  File ""/root/anaconda3/lib/python3.6/site-packages/autokeras/backend/torch/loss_function.py"", line 5, in classification_loss
    labels = target.argmax(1)
  File ""/root/anaconda3/lib/python3.6/site-packages/torch/tensor.py"", line 240, in argmax
    return torch.argmax(self, dim, keepdim)
  File ""/root/anaconda3/lib/python3.6/site-packages/torch/functional.py"", line 544, in argmax
    retained or not. Ignored if ``dim=None``.
RuntimeError: Dimension out of range (expected to be in range of [-1, 0], but got 1)",getting error process recent call last file line file line run file line train file line train file line file line file line file line return self dim file line dimension range range got,issue,negative,positive,neutral,neutral,positive,positive
488678483,"Does [this](https://github.com/keras-team/autokeras/blob/master/examples/net_modules/mlp_module.py) help?

In essence, there, you'll find the following minimal example, assuming you have 'X_train, X_test, y_train, y_test' in the correct format.

```
from autokeras import MlpModule
from autokeras.backend.torch.loss_function import classification_loss
from autokeras.nn.metric import Accuracy
from autokeras.backend.torch import DataTransformerMlp

# ... define train and test data

mlpModule = MlpModule(loss=classification_loss, metric=Accuracy, searcher_args={}, verbose=True)
data_transformer = DataTransformerMlp(x_train)
train_data = data_transformer.transform_train(x_train, y_train)
test_data = data_transformer.transform_test(x_test, y_test)
fit_args = {
    ""n_output_node"": 2,
    ""input_shape"": x_train.shape,
    ""train_data"": train_data,
    ""test_data"": test_data
}
mlpModule.fit(n_output_node=fit_args.get(""n_output_node""),
              input_shape=fit_args.get(""input_shape""),
              train_data=fit_args.get(""train_data""),
              test_data=fit_args.get(""test_data""),
              time_limit=1 * 60 * 60)
```

Disclaimer: I've not been able to run this myself, as I have installation problems, but this is what I found and assume to work.
",help essence find following minimal example assuming correct format import import import accuracy import define train test data disclaimer able run installation found assume work,issue,negative,positive,positive,positive,positive,positive
486446375,Can I ask you exactly what docker image you are running? Ty,ask exactly docker image running,issue,negative,positive,positive,positive,positive,positive
486154902,"Any update regarding the ""'NoneType' object has no attribute 'terminate'"" bug??",update regarding object attribute bug,issue,negative,neutral,neutral,neutral,neutral,neutral
485761395,"Please provide autokeras code for MLP Boston house price dataset.

https://machinelearningmastery.com/regression-tutorial-keras-deep-learning-library-python/",please provide code boston house price,issue,negative,neutral,neutral,neutral,neutral,neutral
485433596,"I already assigned to machine 4096 MB and 4 CPU.
I will test also what you recommended.
I tested code from https://autokeras.com/start/ 
```
from keras.datasets import mnist
from autokeras.image.image_supervised import ImageClassifier

if __name__ == '__main__':
    (x_train, y_train), (x_test, y_test) = mnist.load_data()
    x_train = x_train.reshape(x_train.shape + (1,))
    x_test = x_test.reshape(x_test.shape + (1,))`

    clf = ImageClassifier(verbose=True)
    clf.fit(x_train, y_train, time_limit=12 * 60 * 60)
    clf.final_fit(x_train, y_train, x_test, y_test, retrain=True)
    y = clf.evaluate(x_test, y_test)
    print(y)
```
",already assigned machine test also tested code import import print,issue,negative,neutral,neutral,neutral,neutral,neutral
485401272,"Hi, @itsergiu 
Is this example?: https://raw.githubusercontent.com/keras-team/autokeras/master/examples/a_simple_example/mnist.py

I have tested this code and requires a lot of resources. You can try to increase the RAM assigned to machine, now has 2048 MB ![VBoxMemory](https://user-images.githubusercontent.com/6674996/56499155-70030a00-6505-11e9-806a-467a937df9fa.png) 

However, in this situation, **is preferable real hardware than my "".ova""** because you can use all the CPU cores, memory and the GPU:

> Enable Multi-GPU Training
Auto-Keras support multiple GPU training in the default setting. There's no additional step needed to enable multiple GPU training. However, if multiple-GPU training is not a desirable behavior. You can disable it via environmental variable. CUDA_VISIBLE_DEVICES. For example, in your bash: export CUDA_VISIBLE_DEVICES=0. Keep in mind that when using multiple-GPU, make sure batch size is big enough that multiple-gpu context switch overhead won't effect the performance too much. Otherwise multiple-gpu training may be slower than single-GPU training.

Autokeras can be installed with pip. Useful links:

Get Python 3.6: https://www.python.org/downloads/

Download pip tutorial: https://www.liquidweb.com/kb/install-pip-windows/ 

pip command for Autokeras (https://autokeras.com/start/): **pip install autokeras**

Installing Jupyter (https://jupyter.org/install) and Spyder (https://docs.spyder-ide.org/installation.html) is easy without Anaconda too.

Hope this helps.",hi example tested code lot try increase ram assigned machine however situation preferable real hardware use memory enable training support multiple training default setting additional step enable multiple training however training desirable behavior disable via environmental variable example bash export keep mind make sure batch size big enough context switch overhead wo effect performance much otherwise training may training pip useful link get python pip tutorial pip command pip install easy without anaconda hope,issue,positive,positive,positive,positive,positive,positive
485361810,"I encountered the same problem. I could not use fit after importing the model, but final_fit or evaluate could be used.",problem could use fit model evaluate could used,issue,negative,positive,positive,positive,positive,positive
485150521,"model is automatically exported after training to /tmp/...
To set directory i've used this method:

```
clf = TextClassifier(verbose=True)
clf.output_model_file = ""/home/user/.../model.bin""
```

if you'll run  **predict** or **evaluate** - autokeras will load model for this file.
For example:
```
    if os.path.isfile(filename):
        print(""model already exist, predicting "", filename)
        clf.num_labels = 2
        y = clf.predict(x_test)
        //analyze predictions here
        return
    //train model first
```
Regarding issues with autokeras export - 
I assume keras export doesn't seem to work, but PyTorch export works.

Here's the full version of code i'm using:
```
import numpy as np
import os
from autokeras.text.text_supervised import TextClassifier
from autokeras.utils import read_tsv_file

def convert_labels_to_one_hot(labels, num_labels):
    one_hot = np.zeros((len(labels), num_labels))
    one_hot[np.arange(len(labels)), labels] = 1
    return one_hot

dir_path = os.path.dirname(os.path.realpath(__file__))

if __name__ == '__main__':
    file_path1 = ""/home/user/train_data.tsv""
    file_path2 = ""/home/user/test_data.tsv""
    x_train, y_train = read_tsv_file(input_file=file_path1)
    x_test, y_test = read_tsv_file(input_file=file_path2)

    y_train = convert_labels_to_one_hot(y_train, num_labels=2)
    y_test = convert_labels_to_one_hot(y_test, num_labels=2)

    clf = TextClassifier(verbose=True)
    filename = dir_path + ""/model.bin""
    clf.output_model_file = filename
    print(""will save model to "", filename)
    if os.path.isfile(filename):
        print(""model already exist, predicting "", filename)
        clf.num_labels = 2
        print(""Classification accuracy of existing model is : "", 100 * clf.evaluate(x_test, y_test), ""%"")
        exit()
        
    clf.fit(x=x_train, y=y_train, time_limit=12 * 60 * 60)
    print(""Classification accuracy is : "", 100 * clf.evaluate(x_test, y_test), ""%"")
```",model automatically training set directory used method run predict evaluate load model file example print model already exist return model first regarding export assume export seem work export work full version code import import o import import return print save model print model already exist print classification accuracy model exit print classification accuracy,issue,negative,positive,positive,positive,positive,positive
484783072,"I've considered converting two-dimensional arrays into four-dimensional data, which is then processed like image classification, but I don't think there will be any good results.",considered converting data like image classification think good,issue,positive,positive,positive,positive,positive,positive
484336507,"I reshape (8160, 1, 1089, 1) to (8160, 121, 9, 1), then it works. Maybe when using ImageClassifier, the second dimension doesn't support 1.",reshape work maybe second dimension support,issue,negative,neutral,neutral,neutral,neutral,neutral
484003377,Another issue is : MlpModule object has no attribute   export_autokeras_module.   Does anybody meet the same issue with me ? my aim is to save the module ,another issue object attribute anybody meet issue aim save module,issue,negative,neutral,neutral,neutral,neutral,neutral
483924985,"from PIL import Image
import torch.nn as nn
import torch as t
from torch.autograd import Variable as V
from torchvision.transforms import ToTensor,ToPILImage
to_tensor=ToTensor() # image  -> tensor
to_pil=ToPILImage()
lena=Image.open('C:/Users/Administrator/Desktop/lena.jpg')
lena

input=to_tensor(lena).unsqueeze(0) # 输入是一个batch, batch_size=1
#锐化卷积核
kernel=t.ones(3,3)/-9
kernel[1][1]=1
conv=nn.Conv2d(1,1,(3,3),1,bias=False)
conv.weight.data=kernel.view(1,1,3,3)

out=conv(V(input))
to_pil(out.data.squeeze(0))

#它会出现错误提示
RuntimeError                              Traceback (most recent call last)
<ipython-input-32-5878c7fe2af8> in <module>
      7 conv.weight.data=kernel.view(1,1,3,3)
      8 
----> 9 out=conv(V(input))
     10 to_pil(out.data.squeeze(0))

D:\ProgramData\Anaconda3\lib\site-packages\torch\nn\modules\module.py in __call__(self, *input, **kwargs)
    487             result = self._slow_forward(*input, **kwargs)
    488         else:
--> 489             result = self.forward(*input, **kwargs)
    490         for hook in self._forward_hooks.values():
    491             hook_result = hook(self, input, result)

D:\ProgramData\Anaconda3\lib\site-packages\torch\nn\modules\conv.py in forward(self, input)
    318     def forward(self, input):
    319         return F.conv2d(input, self.weight, self.bias, self.stride,
--> 320                         self.padding, self.dilation, self.groups)
    321 
    322 

RuntimeError: Given groups=1, weight of size [1, 1, 3, 3], expected input[1, 3, 75, 121] to have 1 channels, but got 3 channels instead

#修改代码
input=to_tensor(lena).unsqueeze(0) # 输入是一个batch, batch_size=1
input=input.resize(1,75*3,121).unsqueeze(0)
#锐化卷积核
kernel=t.ones(3,3)/-9
kernel[1][1]=1
conv=nn.Conv2d(1,1,(3,3),1,bias=False)
conv.weight.data=kernel.view(1,1,3,3)

out=conv(V(input))
to_pil(out.data.squeeze(0))

#它会出来结果，它的结果应该是一张图片，但是修改后它出现三张图片，虽然它不一定是解决方案，但是希望有所帮助，当然，也希望哪位大神能解决这个问题",import image import import torch import variable import image tensor kernel input recent call last module input self input result input else result input hook hook self input result forward self input forward self input return input given weight size input got instead kernel input,issue,negative,neutral,neutral,neutral,neutral,neutral
483857401,"Hello, I updated to Mojave 10.14.4 but am still getting this error",hello still getting error,issue,negative,neutral,neutral,neutral,neutral,neutral
483597295,"I have created a pypi package (https://pypi.org/project/autokeras-tabular/) that reinstates the missing functionality. Happy to remove it when the new project is there.

Obviously it will have the same pros and cons as the original did.",package missing functionality happy remove new project obviously original,issue,positive,positive,positive,positive,positive,positive
482691961,"I also have the same error with Django, How can I apply this solution ?
OS : Ubuntu 18
Python: 3.6.7
django: 2.2.0
pip: 19.0.3 
virtualenv: 16.4.3",also error apply solution o python pip,issue,negative,neutral,neutral,neutral,neutral,neutral
481278255,"i also meet this error when i use spyder, but if i use command line to run python file, no error occur!",also meet error use use command line run python file error occur,issue,negative,neutral,neutral,neutral,neutral,neutral
480503967,"@itsergiu 
It's possible to use Docker like a virtual machine. 
First, you need to [install Docker for Windows](https://docs.docker.com/docker-for-windows/install/). 

Then download Auto-Keras docker image with devel tag. This image uses Ubuntu 18.04 as a base. 
```bash
$ docker pull garawalid/autokeras:devel
```
You need to create a volume to persist your data in the container. 
```
$ docker volume create volume-autokeras
```
This command will start Auto-Keras container
```
$ docker run -it -v volume-autokeras:/app --shm-size 2G garawalid/autokeras:devel /bin/bash
```



When you install a new package in your container, you need to save your container like this :

```
$ docker ps -a 
```
```
b52fe902f038        garawalid/autokeras:devel                  ""/bin/bash""              About a minute ago   Exited (1) 3 seconds ago                                         goofy_jackson
```
```
$ docker commit <container_id> garawalid/autokeras:devel
```
where `container_id` equals to `b52fe902f038` in this case. 

 
",possible use docker like virtual machine first need install docker docker image tag image base bash docker pull need create volume persist data container docker volume create command start container docker run install new package container need save container like docker minute ago ago docker commit case,issue,positive,negative,negative,negative,negative,negative
480136360,would be fantastic if you decided to work with Berkley's Ray team to make a distributed version of this as being able to do Neural Architecture search at scale would be awesome!,would fantastic decided work ray team make distributed version able neural architecture search scale would awesome,issue,positive,positive,positive,positive,positive,positive
479683098,"Tested and verified along with the performance. @jhfjhfj1, You may merge once your review is completed.",tested along performance may merge review,issue,negative,neutral,neutral,neutral,neutral,neutral
479521754,I'm getting the same issue. It seems to be stuck completely as the `time_limit` param is not working in this case.,getting issue stuck completely param working case,issue,negative,positive,neutral,neutral,positive,positive
479479291,"I was able to fix this. I used the latest commit from master. And built it using the git clone method using the bleeding edge (manual) instructions.

Modified the setup.py file to the following after cloning:

`from distutils.core import setup
from setuptools import find_packages

setup(
    name='autokeras',
    packages=find_packages(exclude=('tests',)),
    install_requires=['scipy==1.2.0',
                      'tensorflow-gpu==1.13.1',
                      'numpy==1.16.1',
                      'scikit-learn==0.20.2',
                      'scikit-image==0.14.2',
                      'tqdm==4.31.0',
                      'imageio==2.5.0',
                      'requests==2.21.0'
                      ],
    version='0.3.7',
    description='AutoML for deep learning',
    author='DATA Lab at Texas A&M University',
    author_email='jhfjhfj1@gmail.com',
    url='http://autokeras.com',
    download_url='https://github.com/keras-team/autokeras/archive/0.3.7.tar.gz',
    keywords=['AutoML', 'keras'],
    classifiers=[]
)`

Notice the change in install_requires

Steps to install:
1) conda create -c conda-forge -n autokeras python=3.6
2) conda install -c conda-forge cython
3) conda install pytorch torchvision cudatoolkit=10.0 -c pytorch
4) pip install -r requirements.txt
5) pip install keras
6) pip install -r requirements.txt
7) python setup.py install

Hope it helps.",able fix used latest commit master built git clone method bleeding edge manual file following import setup import setup deep learning lab university notice change install create install install pip install pip install pip install python install hope,issue,positive,positive,positive,positive,positive,positive
477797294,"> > The code looks good. Next time please remember to set assignee and request review. Thanks.
> 
> I did not request it for review since I needed some clarifications. I did not think you will review and merge it. :-\

Sorry, I forgot that you asked the question in the email. We can discuss your questions later.  : )",code good next time please remember set assignee request review thanks request review since think review merge sorry forgot question discus later,issue,positive,positive,neutral,neutral,positive,positive
477794621,"> The code looks good. Next time please remember to set assignee and request review. Thanks.

I did not request it for review since I needed some clarifications. I did not think you will review and merge it. :-\",code good next time please remember set assignee request review thanks request review since think review merge,issue,positive,positive,positive,positive,positive,positive
477705357,"Hi all, 
I updated my Operator Systems to macOS Mojave Version 10.14.4 and it works right now.  ",hi operator version work right,issue,negative,positive,positive,positive,positive,positive
477626102,"
[![Coverage Status](https://coveralls.io/builds/22456701/badge)](https://coveralls.io/builds/22456701)

Coverage decreased (-0.02%) to 93.474% when pulling **7939211670bbe3fce5e6045dd833036f5533679e on KailinXu:contribution_to_issue_427** into **8635194cabe168d37a1cac2411d9d7a3ca9b7ce8 on jhfjhfj1:master**.
",coverage status coverage master,issue,negative,neutral,neutral,neutral,neutral,neutral
477464946,"do not use 'pip install autokeras' , just download the code from the GitHub repo and run the setup commands, it can solve all problems.",use install code run setup solve,issue,negative,neutral,neutral,neutral,neutral,neutral
477133223,"Are there any updates on this? I am using a CNN in a GAN to create synthetic data sets of tabular data. Considering that 95% of the enterprise data today is in tabular format, I would think tabular data support would be in high demand.  ",gan create synthetic data tabular data considering enterprise data today tabular format would think tabular data support would high demand,issue,positive,positive,positive,positive,positive,positive
476646591,"Same issue:

```
+----------------------------------------------+
|              Training model 52               |
+----------------------------------------------+
Using TensorFlow backend.
Epoch-1, Current Metric - 0:   0%|                                       | 0/25 [00:00<?, ? batch/s]
Epoch-1, Current Metric - 0:  40%|████████████                  | 10/25 [00:00<00:01, 11.64 batch/s]
Epoch-1, Current Metric - 0:  80%|████████████████████████      | 20/25 [00:00<00:00, 15.53 batch/s]
Epoch-1, Current Metric - 0: 30 batch [00:01, 20.29 batch/s]                                        
                                                            
Epoch-1, Current Metric - 0:   0%|                                        | 0/3 [00:00<?, ? batch/s]
                                                                                                    
Epoch-2, Current Metric - 0.12488710692736871:   0%|                     | 0/25 [00:00<?, ? batch/s]
Epoch-2, Current Metric - 0.12488710692736871:  80%|████████▊  | 20/25 [00:00<00:00, 116.36 batch/s]
Epoch-2, Current Metric - 0.12488710692736871: 30 batch [00:00, 93.43 batch/s]                      
                                                                              
Epoch-2, Current Metric - 0.12488710692736871:   0%|                      | 0/3 [00:00<?, ? batch/s]
                                                                                                    
Epoch-3, Current Metric - 0.12643735560694064:   0%|                     | 0/25 [00:00<?, ? batch/s]
Epoch-3, Current Metric - 0.12643735560694064:  80%|████████▊  | 20/25 [00:00<00:00, 128.00 batch/s]
Epoch-3, Current Metric - 0.12643735560694064: 30 batch [00:00, 98.46 batch/s]                      
                                                                              
Epoch-3, Current Metric - 0.12643735560694064:   0%|                      | 0/3 [00:00<?, ? batch/s]
                                                                                                    
Epoch-4, Current Metric - 0.13139597000014777:   0%|                     | 0/25 [00:00<?, ? batch/s]
Epoch-4, Current Metric - 0.13139597000014777:  80%|████████▊  | 20/25 [00:00<00:00, 116.36 batch/s]
Epoch-4, Current Metric - 0.13139597000014777: 30 batch [00:00, 93.43 batch/s]                      
                                                                              
Epoch-4, Current Metric - 0.13139597000014777:   0%|                      | 0/3 [00:00<?, ? batch/s]
                                                                                                    
Epoch-5, Current Metric - 0.12447471108940003:   0%|                     | 0/25 [00:00<?, ? batch/s]
Epoch-5, Current Metric - 0.12447471108940003:  80%|████████▊  | 20/25 [00:00<00:00, 116.36 batch/s]
Epoch-5, Current Metric - 0.12447471108940003: 30 batch [00:00, 89.51 batch/s]                      
                                                                              
Epoch-5, Current Metric - 0.12447471108940003:   0%|                      | 0/3 [00:00<?, ? batch/s]
                                                                                                    
Epoch-6, Current Metric - 0.13351544241454447:   0%|                     | 0/25 [00:00<?, ? batch/s]
Epoch-6, Current Metric - 0.13351544241454447:  80%|████████▊  | 20/25 [00:00<00:00, 128.00 batch/s]
Epoch-6, Current Metric - 0.13351544241454447: 30 batch [00:00, 98.46 batch/s]                      
                                                                              
Epoch-6, Current Metric - 0.13351544241454447:   0%|                      | 0/3 [00:00<?, ? batch/s]
                                                                                                    
Epoch-7, Current Metric - 0.13811510653115905:   0%|                     | 0/25 [00:00<?, ? batch/s]
Epoch-7, Current Metric - 0.13811510653115905:  80%|████████▊  | 20/25 [00:00<00:00, 128.00 batch/s]
Epoch-7, Current Metric - 0.13811510653115905: 30 batch [00:00, 98.46 batch/s]                      
                                                                              
Epoch-7, Current Metric - 0.13811510653115905:   0%|                      | 0/3 [00:00<?, ? batch/s]
                                                                                                    
Epoch-8, Current Metric - 0.13811514988391316:   0%|                     | 0/25 [00:00<?, ? batch/s]
Epoch-8, Current Metric - 0.13811514988391316:  80%|████████▊  | 20/25 [00:00<00:00, 128.00 batch/s]
Epoch-8, Current Metric - 0.13811514988391316: 30 batch [00:00, 98.46 batch/s]                      
                                                                              
Epoch-8, Current Metric - 0.13811514988391316:   0%|                      | 0/3 [00:00<?, ? batch/s]
                                                                                                    
Epoch-9, Current Metric - 0.14264668616483409:   0%|                     | 0/25 [00:00<?, ? batch/s]
Epoch-9, Current Metric - 0.14264668616483409:  80%|████████▊  | 20/25 [00:00<00:00, 128.00 batch/s]
Epoch-9, Current Metric - 0.14264668616483409: 30 batch [00:00, 98.46 batch/s]                      
                                                                              
Epoch-9, Current Metric - 0.14264668616483409:   0%|                      | 0/3 [00:00<?, ? batch/s]
                                                                                                    
No loss decrease after 5 epochs.
Saving model.
+--------------------------------------------------------------------------+
|        Model ID        |          Loss          |      Metric Value      |
+--------------------------------------------------------------------------+
|           52           |   0.4131729885935783   |  0.13916135467817575   |
+--------------------------------------------------------------------------+
+----------------------------------------------+
|              Training model 53               |
+----------------------------------------------+
Using TensorFlow backend.
Epoch-1, Current Metric - 0:   0%|                                       | 0/25 [00:00<?, ? batch/s]
Epoch-1, Current Metric - 0:  40%|████████████                  | 10/25 [00:00<00:01, 11.85 batch/s]
Epoch-1, Current Metric - 0:  80%|████████████████████████      | 20/25 [00:00<00:00, 15.80 batch/s]
Epoch-1, Current Metric - 0: 30 batch [00:01, 20.41 batch/s]                                        
                                                            
Epoch-1, Current Metric - 0:   0%|                                        | 0/3 [00:00<?, ? batch/s]
                                                                                                    
Epoch-2, Current Metric - 0.12774907524608334:   0%|                     | 0/25 [00:00<?, ? batch/s]
Epoch-2, Current Metric - 0.12774907524608334:  80%|████████▊  | 20/25 [00:00<00:00, 128.00 batch/s]
Epoch-2, Current Metric - 0.12774907524608334: 30 batch [00:00, 98.46 batch/s]                      
                                                                              
Epoch-2, Current Metric - 0.12774907524608334:   0%|                      | 0/3 [00:00<?, ? batch/s]
                                                                                                    
Epoch-3, Current Metric - 0.12868593904531053:   0%|                     | 0/25 [00:00<?, ? batch/s]
Epoch-3, Current Metric - 0.12868593904531053:  80%|████████▊  | 20/25 [00:00<00:00, 128.00 batch/s]
Epoch-3, Current Metric - 0.12868593904531053: 30 batch [00:00, 98.46 batch/s]                      
                                                                              
Epoch-3, Current Metric - 0.12868593904531053:   0%|                      | 0/3 [00:00<?, ? batch/s]
                                                                                                    
Epoch-4, Current Metric - 0.14223495769984323:   0%|                     | 0/25 [00:00<?, ? batch/s]
Epoch-4, Current Metric - 0.14223495769984323:  80%|████████▊  | 20/25 [00:00<00:00, 142.22 batch/s]
Epoch-4, Current Metric - 0.14223495769984323: 30 batch [00:00, 104.07 batch/s]                     
                                                                               
Epoch-4, Current Metric - 0.14223495769984323:   0%|                      | 0/3 [00:00<?, ? batch/s]
                                                                                                    
Epoch-5, Current Metric - 0.13478653627181486:   0%|                     | 0/25 [00:00<?, ? batch/s]
Epoch-5, Current Metric - 0.13478653627181486:  80%|████████▊  | 20/25 [00:00<00:00, 116.36 batch/s]
Epoch-5, Current Metric - 0.13478653627181486: 30 batch [00:00, 93.43 batch/s]                      
                                                                              
Epoch-5, Current Metric - 0.13478653627181486:   0%|                      | 0/3 [00:00<?, ? batch/s]
                                                                                                    
Epoch-6, Current Metric - 0.1501177909360736:   0%|                      | 0/25 [00:00<?, ? batch/s]
Epoch-6, Current Metric - 0.1501177909360736:  80%|█████████▌  | 20/25 [00:00<00:00, 128.00 batch/s]
Epoch-6, Current Metric - 0.1501177909360736: 30 batch [00:00, 103.23 batch/s]                      
                                                                              
Epoch-6, Current Metric - 0.1501177909360736:   0%|                       | 0/3 [00:00<?, ? batch/s]
                                                                                                    
Epoch-7, Current Metric - 0.14959561513031183:   0%|                     | 0/25 [00:00<?, ? batch/s]
Epoch-7, Current Metric - 0.14959561513031183:  80%|████████▊  | 20/25 [00:00<00:00, 128.00 batch/s]
Epoch-7, Current Metric - 0.14959561513031183: 30 batch [00:00, 98.46 batch/s]                      
                                                                              
Epoch-7, Current Metric - 0.14959561513031183:   0%|                      | 0/3 [00:00<?, ? batch/s]
                                                                                                    
Epoch-8, Current Metric - 0.14129765416510295:   0%|                     | 0/25 [00:00<?, ? batch/s]
Epoch-8, Current Metric - 0.14129765416510295:  80%|████████▊  | 20/25 [00:00<00:00, 128.00 batch/s]
Epoch-8, Current Metric - 0.14129765416510295: 30 batch [00:00, 98.46 batch/s]                      
                                                                              
Epoch-8, Current Metric - 0.14129765416510295:   0%|                      | 0/3 [00:00<?, ? batch/s]
                                                                                                    
Epoch-9, Current Metric - 0.15909613511022466:   0%|                     | 0/25 [00:00<?, ? batch/s]
Epoch-9, Current Metric - 0.15909613511022466:  80%|████████▊  | 20/25 [00:00<00:00, 128.00 batch/s]
Epoch-9, Current Metric - 0.15909613511022466: 30 batch [00:00, 98.46 batch/s]                      
                                                                              
Epoch-9, Current Metric - 0.15909613511022466:   0%|                      | 0/3 [00:00<?, ? batch/s]
                                                                                                    
No loss decrease after 5 epochs.
Saving model.
+--------------------------------------------------------------------------+
|        Model ID        |          Loss          |      Metric Value      |
+--------------------------------------------------------------------------+
|           53           |   0.4588329613208771   |   0.1518198517130523   |
+--------------------------------------------------------------------------+
+----------------------------------------------+
|              Training model 54               |
+----------------------------------------------+
Using TensorFlow backend.
Epoch-1, Current Metric - 0:   0%|                                       | 0/25 [00:00<?, ? batch/s]Process SpawnProcess-55:
Traceback (most recent call last):
                                                                                                      File ""C:\Anaconda3\envs\neuroling_project\lib\multiprocessing\process.py"", line 258, in _bootstrap
    self.run()
  File ""C:\Anaconda3\envs\neuroling_project\lib\multiprocessing\process.py"", line 93, in run
    self._target(*self._args, **self._kwargs)
  File ""C:\Anaconda3\envs\neuroling_project\lib\site-packages\autokeras\search.py"", line 351, in train
    raise e
  File ""C:\Anaconda3\envs\neuroling_project\lib\site-packages\autokeras\search.py"", line 344, in train
    verbose=verbose).train_model(**trainer_args)
  File ""C:\Anaconda3\envs\neuroling_project\lib\site-packages\autokeras\nn\model_trainer.py"", line 137, in train_model
    self._train()
  File ""C:\Anaconda3\envs\neuroling_project\lib\site-packages\autokeras\nn\model_trainer.py"", line 173, in _train
    outputs = self.model(inputs)
  File ""C:\Anaconda3\envs\neuroling_project\lib\site-packages\torch\nn\modules\module.py"", line 489, in __call__
    result = self.forward(*input, **kwargs)
  File ""C:\Anaconda3\envs\neuroling_project\lib\site-packages\autokeras\nn\graph.py"", line 689, in forward
    temp_tensor = torch_layer(edge_input_tensor)
  File ""C:\Anaconda3\envs\neuroling_project\lib\site-packages\torch\nn\modules\module.py"", line 489, in __call__
    result = self.forward(*input, **kwargs)
  File ""C:\Anaconda3\envs\neuroling_project\lib\site-packages\torch\nn\modules\conv.py"", line 187, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: Given groups=1, weight of size [64, 192, 1], expected input[128, 256, 3] to have 192 channels, but got 256 channels instead
```

@jhfjhfj1 I'll give you access to the private repo where the code is in and upload an example of the used data (so that execution of the experiment works). I'll also put a yaml of the conda env in there

It seems that the searcher alters the layer size inadequately.

I got another error that is definitely related: 
```Epoch-1, Current Metric - 0:   0%|                                       | 0/25 [00:00<?, ? batch/s]
Epoch-1, Current Metric - 0:  40%|████████████                  | 10/25 [00:00<00:01, 11.98 batch/s]
Epoch-1, Current Metric - 0:  80%|████████████████████████      | 20/25 [00:01<00:00, 15.18 batch/s]
Epoch-1, Current Metric - 0: 30 batch [00:01, 18.43 batch/s]                                        
                                                            
Epoch-1, Current Metric - 0:   0%|                                        | 0/3 [00:00<?, ? batch/s]
                                                                                                    
Epoch-2, Current Metric - 0.12290543672313972:   0%|                     | 0/25 [00:00<?, ? batch/s]
Epoch-2, Current Metric - 0.12290543672313972:  80%|█████████▌  | 20/25 [00:00<00:00, 69.23 batch/s]
Epoch-2, Current Metric - 0.12290543672313972: 30 batch [00:00, 53.85 batch/s]                      
                                                                              
Epoch-2, Current Metric - 0.12290543672313972:   0%|                      | 0/3 [00:00<?, ? batch/s]
                                                                                                    
Epoch-3, Current Metric - 0.12383724298179866:   0%|                     | 0/25 [00:00<?, ? batch/s]
Epoch-3, Current Metric - 0.12383724298179866:  80%|█████████▌  | 20/25 [00:00<00:00, 68.75 batch/s]
Epoch-3, Current Metric - 0.12383724298179866: 30 batch [00:00, 55.90 batch/s]                      
                                                                              
Epoch-3, Current Metric - 0.12383724298179866:   0%|                      | 0/3 [00:00<?, ? batch/s]
                                                                                                    
Epoch-4, Current Metric - 0.1227938792591689:   0%|                      | 0/25 [00:00<?, ? batch/s]
Epoch-4, Current Metric - 0.1227938792591689:  80%|██████████▍  | 20/25 [00:00<00:00, 63.31 batch/s]
Epoch-4, Current Metric - 0.1227938792591689: 30 batch [00:00, 54.34 batch/s]                       
                                                                             
Epoch-4, Current Metric - 0.1227938792591689:   0%|                       | 0/3 [00:00<?, ? batch/s]
                                                                                                    
Epoch-5, Current Metric - 0.1266208110584486:   0%|                      | 0/25 [00:00<?, ? batch/s]
Epoch-5, Current Metric - 0.1266208110584486:  80%|██████████▍  | 20/25 [00:00<00:00, 71.45 batch/s]
Epoch-5, Current Metric - 0.1266208110584486: 30 batch [00:00, 57.42 batch/s]                       
                                                                             
Epoch-5, Current Metric - 0.1266208110584486:   0%|                       | 0/3 [00:00<?, ? batch/s]
                                                                                                    
Epoch-6, Current Metric - 0.12670472838612737:   0%|                     | 0/25 [00:00<?, ? batch/s]
Epoch-6, Current Metric - 0.12670472838612737:  80%|█████████▌  | 20/25 [00:00<00:00, 70.20 batch/s]
Epoch-6, Current Metric - 0.12670472838612737: 30 batch [00:00, 57.15 batch/s]                      
                                                                              
Epoch-6, Current Metric - 0.12670472838612737:   0%|                      | 0/3 [00:00<?, ? batch/s]
                                                                                                    
Epoch-7, Current Metric - 0.13579259996247325:   0%|                     | 0/25 [00:00<?, ? batch/s]
Epoch-7, Current Metric - 0.13579259996247325:  80%|█████████▌  | 20/25 [00:00<00:00, 68.05 batch/s]
Epoch-7, Current Metric - 0.13579259996247325: 30 batch [00:00, 55.76 batch/s]                      
                                                                              
Epoch-7, Current Metric - 0.13579259996247325:   0%|                      | 0/3 [00:00<?, ? batch/s]
                                                                                                    
Epoch-8, Current Metric - 0.13407541190650835:   0%|                     | 0/25 [00:00<?, ? batch/s]
Epoch-8, Current Metric - 0.13407541190650835:  80%|█████████▌  | 20/25 [00:00<00:00, 72.49 batch/s]
Epoch-8, Current Metric - 0.13407541190650835: 30 batch [00:00, 58.29 batch/s]                      
                                                                              
Epoch-8, Current Metric - 0.13407541190650835:   0%|                      | 0/3 [00:00<?, ? batch/s]
                                                                                                    
Epoch-9, Current Metric - 0.1379582250010873:   0%|                      | 0/25 [00:00<?, ? batch/s]
Epoch-9, Current Metric - 0.1379582250010873:  80%|██████████▍  | 20/25 [00:00<00:00, 70.69 batch/s]
Epoch-9, Current Metric - 0.1379582250010873: 30 batch [00:00, 55.65 batch/s]                       
                                                                             
Epoch-9, Current Metric - 0.1379582250010873:   0%|                       | 0/3 [00:00<?, ? batch/s]
                                                                                                    
Epoch-10, Current Metric - 0.13624785117471777:   0%|                    | 0/25 [00:00<?, ? batch/s]
Epoch-10, Current Metric - 0.13624785117471777:  80%|████████▊  | 20/25 [00:00<00:00, 71.97 batch/s]
Epoch-10, Current Metric - 0.13624785117471777: 30 batch [00:00, 57.16 batch/s]                     
                                                                               
Epoch-10, Current Metric - 0.13624785117471777:   0%|                     | 0/3 [00:00<?, ? batch/s]
                                                                                                    
No loss decrease after 5 epochs.
Saving model.
+--------------------------------------------------------------------------+
|        Model ID        |          Loss          |      Metric Value      |
+--------------------------------------------------------------------------+
|          358           |   0.4047888070344925   |  0.13656011946032445   |
+--------------------------------------------------------------------------+
+----------------------------------------------+
|              Training model 359              |
+----------------------------------------------+
Using TensorFlow backend.
Epoch-1, Current Metric - 0:   0%|                                       | 0/25 [00:00<?, ? batch/s]
Epoch-1, Current Metric - 0:  40%|████████████                  | 10/25 [00:00<00:01, 12.11 batch/s]
Epoch-1, Current Metric - 0:  80%|████████████████████████      | 20/25 [00:01<00:00, 15.33 batch/s]
Epoch-1, Current Metric - 0: 30 batch [00:01, 18.81 batch/s]                                        
                                                            
Epoch-1, Current Metric - 0:   0%|                                        | 0/3 [00:00<?, ? batch/s]
                                                                                                    
Epoch-2, Current Metric - 0.12355520981874844:   0%|                     | 0/25 [00:00<?, ? batch/s]
Epoch-2, Current Metric - 0.12355520981874844:  80%|█████████▌  | 20/25 [00:00<00:00, 71.96 batch/s]
Epoch-2, Current Metric - 0.12355520981874844: 30 batch [00:00, 58.26 batch/s]                      
                                                                              
Epoch-2, Current Metric - 0.12355520981874844:   0%|                      | 0/3 [00:00<?, ? batch/s]
                                                                                                    
Epoch-3, Current Metric - 0.1237318097595806:   0%|                      | 0/25 [00:00<?, ? batch/s]
Epoch-3, Current Metric - 0.1237318097595806:  80%|██████████▍  | 20/25 [00:00<00:00, 68.98 batch/s]
Epoch-3, Current Metric - 0.1237318097595806: 30 batch [00:00, 53.75 batch/s]                       
                                                                             
Epoch-3, Current Metric - 0.1237318097595806:   0%|                       | 0/3 [00:00<?, ? batch/s]
                                                                                                    
Epoch-4, Current Metric - 0.1281043480177284:   0%|                      | 0/25 [00:00<?, ? batch/s]
Epoch-4, Current Metric - 0.1281043480177284:  80%|██████████▍  | 20/25 [00:00<00:00, 68.99 batch/s]
Epoch-4, Current Metric - 0.1281043480177284: 30 batch [00:00, 57.16 batch/s]                       
                                                                             
Epoch-4, Current Metric - 0.1281043480177284:   0%|                       | 0/3 [00:00<?, ? batch/s]
                                                                                                    
Epoch-5, Current Metric - 0.12668128207560211:   0%|                     | 0/25 [00:00<?, ? batch/s]
Epoch-5, Current Metric - 0.12668128207560211:  80%|█████████▌  | 20/25 [00:00<00:00, 73.28 batch/s]
Epoch-5, Current Metric - 0.12668128207560211: 30 batch [00:00, 57.34 batch/s]                      
                                                                              
Epoch-5, Current Metric - 0.12668128207560211:   0%|                      | 0/3 [00:00<?, ? batch/s]
                                                                                                    
Epoch-6, Current Metric - 0.13132767045923463:   0%|                     | 0/25 [00:00<?, ? batch/s]
Epoch-6, Current Metric - 0.13132767045923463:  80%|█████████▌  | 20/25 [00:00<00:00, 71.20 batch/s]
Epoch-6, Current Metric - 0.13132767045923463: 30 batch [00:00, 57.41 batch/s]                      
                                                                              
Epoch-6, Current Metric - 0.13132767045923463:   0%|                      | 0/3 [00:00<?, ? batch/s]
                                                                                                    
Epoch-7, Current Metric - 0.13078966470082815:   0%|                     | 0/25 [00:00<?, ? batch/s]
Epoch-7, Current Metric - 0.13078966470082815:  80%|█████████▌  | 20/25 [00:00<00:00, 68.75 batch/s]
Epoch-7, Current Metric - 0.13078966470082815: 30 batch [00:00, 56.47 batch/s]                      
                                                                              
Epoch-7, Current Metric - 0.13078966470082815:   0%|                      | 0/3 [00:00<?, ? batch/s]
                                                                                                    
Epoch-8, Current Metric - 0.13533035701312265:   0%|                     | 0/25 [00:00<?, ? batch/s]
Epoch-8, Current Metric - 0.13533035701312265:  80%|█████████▌  | 20/25 [00:00<00:00, 70.94 batch/s]
Epoch-8, Current Metric - 0.13533035701312265: 30 batch [00:00, 57.59 batch/s]                      
                                                                              
Epoch-8, Current Metric - 0.13533035701312265:   0%|                      | 0/3 [00:00<?, ? batch/s]
                                                                                                    
No loss decrease after 5 epochs.
Saving model.
+--------------------------------------------------------------------------+
|        Model ID        |          Loss          |      Metric Value      |
+--------------------------------------------------------------------------+
|          359           |   0.4063565507531166   |  0.13456349463940695   |
+--------------------------------------------------------------------------+
+----------------------------------------------+
|              Training model 360              |
+----------------------------------------------+
Using TensorFlow backend.
Epoch-1, Current Metric - 0:   0%|                                       | 0/25 [00:00<?, ? batch/s]Process SpawnProcess-361:
                                                                                                    Traceback (most recent call last):
  File ""C:\Anaconda3\envs\neuroling_project\lib\multiprocessing\process.py"", line 258, in _bootstrap
    self.run()
  File ""C:\Anaconda3\envs\neuroling_project\lib\multiprocessing\process.py"", line 93, in run
    self._target(*self._args, **self._kwargs)
  File ""C:\Anaconda3\envs\neuroling_project\lib\site-packages\autokeras\search.py"", line 351, in train
    raise e
  File ""C:\Anaconda3\envs\neuroling_project\lib\site-packages\autokeras\search.py"", line 344, in train
    verbose=verbose).train_model(**trainer_args)
  File ""C:\Anaconda3\envs\neuroling_project\lib\site-packages\autokeras\nn\model_trainer.py"", line 137, in train_model
    self._train()
  File ""C:\Anaconda3\envs\neuroling_project\lib\site-packages\autokeras\nn\model_trainer.py"", line 173, in _train
    outputs = self.model(inputs)
  File ""C:\Anaconda3\envs\neuroling_project\lib\site-packages\torch\nn\modules\module.py"", line 489, in __call__
    result = self.forward(*input, **kwargs)
  File ""C:\Anaconda3\envs\neuroling_project\lib\site-packages\autokeras\nn\graph.py"", line 689, in forward
    temp_tensor = torch_layer(edge_input_tensor)
  File ""C:\Anaconda3\envs\neuroling_project\lib\site-packages\torch\nn\modules\module.py"", line 489, in __call__
    result = self.forward(*input, **kwargs)
  File ""C:\Anaconda3\envs\neuroling_project\lib\site-packages\torch\nn\modules\batchnorm.py"", line 76, in forward
    exponential_average_factor, self.eps)
  File ""C:\Anaconda3\envs\neuroling_project\lib\site-packages\torch\nn\functional.py"", line 1623, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: running_mean should contain 5 elements not 10```

Tried this for both regression and classification so the bug should defenitely be in the search, in the generation of a new models to be explicit on that",issue training model current metric current metric current metric current metric batch current metric current metric current metric current metric batch current metric current metric current metric current metric batch current metric current metric current metric current metric batch current metric current metric current metric current metric batch current metric current metric current metric current metric batch current metric current metric current metric current metric batch current metric current metric current metric current metric batch current metric current metric current metric current metric batch current metric loss decrease saving model model id loss metric value training model current metric current metric current metric current metric batch current metric current metric current metric current metric batch current metric current metric current metric current metric batch current metric current metric current metric current metric batch current metric current metric current metric current metric batch current metric current metric current metric current metric batch current metric current metric current metric current metric batch current metric current metric current metric current metric batch current metric current metric current metric current metric batch current metric loss decrease saving model model id loss metric value training model current metric process recent call last file line file line run file line train raise file line train file line file line file line result input file line forward file line result input file line forward given weight size input got instead give access private code example used data execution experiment work also put searcher layer size inadequately got another error definitely related current metric current metric current metric current metric batch current metric current metric current metric current metric batch current metric current metric current metric current metric batch current metric current metric current metric current metric batch current metric current metric current metric current metric batch current metric current metric current metric current metric batch current metric current metric current metric current metric batch current metric current metric current metric current metric batch current metric current metric current metric current metric batch current metric current metric current metric current metric batch current metric loss decrease saving model model id loss metric value training model current metric current metric current metric current metric batch current metric current metric current metric current metric batch current metric current metric current metric current metric batch current metric current metric current metric current metric batch current metric current metric current metric current metric batch current metric current metric current metric current metric batch current metric current metric current metric current metric batch current metric current metric current metric current metric batch current metric loss decrease saving model model id loss metric value training model current metric process recent call last file line file line run file line train raise file line train file line file line file line result input file line forward file line result input file line forward file line training momentum contain tried regression classification bug search generation new explicit,issue,negative,positive,neutral,neutral,positive,positive
476184474,"I changed to  pytorch 0.4.1, but got **'float' object cannot be interpreted as an integer** this time.",got object integer time,issue,negative,neutral,neutral,neutral,neutral,neutral
475942585,"@Santamax hello, did you solve this problem? i also meet the same problem,thx",hello solve problem also meet problem,issue,negative,neutral,neutral,neutral,neutral,neutral
473842031,"Hello, I had a similar problem and solved it by loading the model with _load()_ method on _ObjectDetector_. Try this code:

```python
from autokeras.pretrained import ObjectDetector

if __name__ == '__main__':
    detector = ObjectDetector()
    detector.load()
    results = detector.predict(""example.jpg"")

    print(results)`
```",hello similar problem loading model method try code python import detector print,issue,negative,neutral,neutral,neutral,neutral,neutral
473757348,"It go on training after 8 or 9 hour, and finished test by time out. Does searching time cost this too long?",go training hour finished test time searching time cost long,issue,negative,negative,neutral,neutral,negative,negative
473736613,"@BDANG Since we don't have any available open datasets on the NRegressor, I have concerns about the users need on this task.
So it would be great if you can just make the current Regressor capable of such multi-column regression by setting the default parameter instead of creating a new class.
In this way, we can support this functionality and add no extra maintenance burden to the project.
Thank you!",since available open need task would great make current regressor capable regression setting default parameter instead new class way support functionality add extra maintenance burden project thank,issue,positive,positive,positive,positive,positive,positive
473689759,"@jhfjhfj1 

1) It's entirely possible to modify ImageRegressor, yeah.

2) Unfortunately, I'm not aware of an open datasets that apply N-regression. But if we take [NVIDIA's research on modelling steering angle](https://arxiv.org/pdf/1604.07316v1.pdf), You could forecast multiple steering angles (immediate steering angle and future steering angle).

If you want me to proceed with modifying ImageRegressor, I'm happy to do so!",entirely possible modify unfortunately aware open apply take research steering angle could forecast multiple steering immediate steering angle future steering angle want proceed happy,issue,negative,positive,positive,positive,positive,positive
473653354,Realised that the function for loading the images already has the intended functionality.,function loading already intended functionality,issue,negative,neutral,neutral,neutral,neutral,neutral
473595830,"@BDANG Thank you very much for your contribution!
I have 2 questions for this PR.
1. Is it possible to make this class the same class as ImageRegressor, but make the regressor adaptively choose the ""N"" (may equal to 1 or not) according to the input data?
2. Would you refer us to any open dataset that has such kind of ""N Regression"" requirements?",thank much contribution possible make class class make regressor adaptively choose may equal according input data would refer u open kind regression,issue,positive,positive,positive,positive,positive,positive
473341226,"Stuck here with the same bug. To add on, hoping it might help: for me it stops with the exact same exception and it does so consistently on the third model training (""training model 2"") irrespective of the input regression data.

Just to let you know: very much looking forward to using this when fixed. Your project's very much appreciated.",stuck bug add might help exact exception consistently third model training training model irrespective input regression data let know much looking forward fixed project much,issue,negative,positive,positive,positive,positive,positive
473098161,"@maximilianley 
I'm currently working on Docker image that tracks Github repository. 


",currently working docker image repository,issue,negative,neutral,neutral,neutral,neutral,neutral
472616700,@Evan-Choo It doesn't pass the CI. Please fix it. Thanks.,pas please fix thanks,issue,positive,positive,positive,positive,positive,positive
472587102,"
[![Coverage Status](https://coveralls.io/builds/22164100/badge)](https://coveralls.io/builds/22164100)

Coverage increased (+0.2%) to 93.505% when pulling **2343a4dda9a51ede69fb60722b2453e593017314 on chengchengeasy:issue450** into **b63a1b7f628ae3b61dfcafb9be577fe7c0b149ab on jhfjhfj1:master**.
",coverage status coverage issue master,issue,negative,neutral,neutral,neutral,neutral,neutral
472154838,just saw there's a new docker image for autokeras 0.3.7 created 20h ago,saw new docker image ago,issue,negative,positive,positive,positive,positive,positive
471441007,"Thanks for your response @ghmole!
Wouldn't be a good fix to implement some kind of gradient clipping?",thanks response would good fix implement kind gradient clipping,issue,positive,positive,positive,positive,positive,positive
471313944,"after I  change the parameter retrain, I got similar error: Exception occurred at train() : 'NoneType' object has no attribute 'produce_model'.  who can help me with this issue, I'm really feeling desperate now...
",change parameter retrain got similar error exception train object attribute help issue really feeling desperate,issue,negative,negative,negative,negative,negative,negative
471313699,"After i run this code I got error like this:
Exception occurred at train() : train_model() argument after ** must be a mapping, not NoneType",run code got error like exception train argument must,issue,negative,neutral,neutral,neutral,neutral,neutral
471313637,"here is my code:

import numpy as np
from autokeras import MlpModule
from autokeras.nn.loss_function import classification_loss
from autokeras.nn.metric import Accuracy
from autokeras.preprocessor import OneHotEncoder, DataTransformerMlp

def transform_y(y_train):
    # Transform y_train.
    y_encoder = OneHotEncoder()
    y_encoder.fit(y_train)
    y_train = y_encoder.transform(y_train)
    return y_train, y_encoder

y_train, y_encoder = transform_y(Y_train)
data_transformer = DataTransformerMlp(X_train)
train_data = data_transformer.transform_train(X_train, Y_train)
test_data = data_transformer.transform_test(X_val, Y_val)

mlpModule = MlpModule(loss=classification_loss, metric=Accuracy, searcher_args={}, verbose=True)
fit_args = {
        ""n_output_node"": y_encoder.n_classes,
        ""input_shape"": X_train.shape,
        ""train_data"": train_data,
        ""test_data"": test_data}

mlpModule.fit(n_output_node=fit_args.get(""n_output_node""),
                  input_shape=fit_args.get(""input_shape""),
                  train_data=fit_args.get(""train_data""),
                  test_data=fit_args.get(""test_data""),
                  time_limit= 10 * 60)
mlpModule.final_fit(train_data, test_data, trainer_args=None, retrain=False)

",code import import import import accuracy import transform return,issue,negative,neutral,neutral,neutral,neutral,neutral
471298102,"Hey,
I got the same question... right now I'm using hyperopt and hyperas to optimize any deterministic regression model... for autoKeras, it seems to be a small leap to use tabular data... where can we find the other project?",hey got question right optimize deterministic regression model small leap use tabular data find project,issue,negative,positive,neutral,neutral,positive,positive
471247325,"@ghmole @rebouvet 
This issue is because the learning rate is too large and cause the gradient explored. I just change the learning rate in the trainer to a smaller number. It tests fine now. In the future we may add customizable training args include learning rate feature to users. ",issue learning rate large cause gradient change learning rate trainer smaller number fine future may add training include learning rate feature,issue,negative,positive,positive,positive,positive,positive
471217975,"Benchmarks would be nice, particularly w.r.t. text classification, which isn't in the original paper.",would nice particularly text classification original paper,issue,positive,positive,positive,positive,positive,positive
471079491,"I think we've also encountered some other issues with spyder @jhfjhfj1 do you think we should support spyder environment?
",think also think support environment,issue,negative,neutral,neutral,neutral,neutral,neutral
470780461,"This sounds similar to the bug I just opened #570, except that it complains that i should have at least three dimensions. Also, mine occurred at line 451 in conv.py but looks like same area.",similar bug except least three also mine line like area,issue,negative,negative,negative,negative,negative,negative
470584157,"> Have you found a solution ?
Not yet. I gave up on the `autokeras`. Ticket opened for 15 days, no one responds to it. ",found solution yet gave ticket day one,issue,negative,neutral,neutral,neutral,neutral,neutral
470340536,"I run it in anaconda spyder, the mp issue always happens



sleepmole@126.com
 
From: tl-yang
Date: 2019-03-07 01:52
To: jhfjhfj1/autokeras
CC: ghmole; Author
Subject: Re: [jhfjhfj1/autokeras] check ipython kernel variant to avoid multiprocess issue when running in ipython kernel (#569)
But I'm wondering what ipython you're running? I tried it in Jupyter notebook, it works without issue?
—
You are receiving this because you authored the thread.
Reply to this email directly, view it on GitHub, or mute the thread.
",run anaconda issue always date author subject check kernel variant avoid issue running kernel wondering running tried notebook work without issue thread reply directly view mute thread,issue,negative,negative,neutral,neutral,negative,negative
470339879,"I have the problem also,Its happend after few trainings   so confused:

+--------------------------------------------------------------------------+
|        Model ID        |          Loss          |      Metric Value      |
+--------------------------------------------------------------------------+
|           28           |   0.1570680882781744   |         0.994          |
+--------------------------------------------------------------------------+
+----------------------------------------------+
|              Training model 29               |
+----------------------------------------------+
Epoch-1, Current Metric - 0:   0%|                                      | 0/508 [00:00<?, ? batch/s]Process SpawnProcess-30:
Traceback (most recent call last):
  File ""C:\Anaconda3\envs\autokeras\lib\multiprocessing\process.py"", line 249, in _bootstrap
    self.run()
  File ""C:\Anaconda3\envs\autokeras\lib\multiprocessing\process.py"", line 93, in run
    self._target(*self._args, **self._kwargs)
  File ""C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\autokeras\search.py"", line 351, in train
    raise e
  File ""C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\autokeras\search.py"", line 344, in train
    verbose=verbose).train_model(**trainer_args)
  File ""C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\autokeras\nn\model_trainer.py"", line 137, in train_model
    self._train()
  File ""C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\autokeras\nn\model_trainer.py"", line 173, in _train
    outputs = self.model(inputs)
  File ""C:\Anaconda3\envs\autokeras\lib\site-packages\torch\nn\modules\module.py"", line 489, in __call__
    result = self.forward(*input, **kwargs)
  File ""C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\autokeras\nn\graph.py"", line 689, in forward
    temp_tensor = torch_layer(edge_input_tensor)
  File ""C:\Anaconda3\envs\autokeras\lib\site-packages\torch\nn\modules\module.py"", line 489, in __call__
    result = self.forward(*input, **kwargs)
  File ""C:\Anaconda3\envs\autokeras\lib\site-packages\torch\nn\modules\conv.py"", line 320, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: Given groups=1, weight of size [64, 384, 1, 1], expected input[128, 512, 11, 3] to have 384 channels, but got 512 channels instead

Waiting for reply
",problem also confused model id loss metric value training model current metric process recent call last file line file line run file line train raise file line train file line file line file line result input file line forward file line result input file line forward given weight size input got instead waiting reply,issue,negative,negative,neutral,neutral,negative,negative
470207982,"But I'm wondering what ipython you're running? I tried it in Jupyter notebook, it works without issue?",wondering running tried notebook work without issue,issue,negative,neutral,neutral,neutral,neutral,neutral
470185396,"I am also experiencing this error:

autokeras:0.3.7
python:3.6.7
torch:1.0.1.post2
keras:2.2.4
tensorflow:1.12.0
system:Ubuntu 18.04
numpy:1.15.4

The images are 56x56 RGB, two possible labels. Using RTX 2070 for training.

```
+----------------------------------------------+
|              Training model 67               |
+----------------------------------------------+
                                                                                                    
No loss decrease after 5 epochs.


Saving model.
+--------------------------------------------------------------------------+
|        Model ID        |          Loss          |      Metric Value      |
+--------------------------------------------------------------------------+
|           67           |   0.3128864407539368   |   0.9393939393939394   |
+--------------------------------------------------------------------------+


+----------------------------------------------+
|              Training model 68               |
+----------------------------------------------+
Epoch-1, Current Metric - 0:   0%|                                        | 0/9 [00:00<?, ? batch/s]Process ForkProcess-69:
Traceback (most recent call last):
  File ""/usr/lib/python3.6/multiprocessing/process.py"", line 258, in _bootstrap
    self.run()
  File ""/usr/lib/python3.6/multiprocessing/process.py"", line 93, in run
    self._target(*self._args, **self._kwargs)
  File ""/home/omaralv/.virtualenvs/autokeras-PX4bqcu8/lib/python3.6/site-packages/autokeras/search.py"", line 351, in train
    raise e
  File ""/home/omaralv/.virtualenvs/autokeras-PX4bqcu8/lib/python3.6/site-packages/autokeras/search.py"", line 344, in train
    verbose=verbose).train_model(**trainer_args)
  File ""/home/omaralv/.virtualenvs/autokeras-PX4bqcu8/lib/python3.6/site-packages/autokeras/nn/model_trainer.py"", line 137, in train_model
    self._train()
  File ""/home/omaralv/.virtualenvs/autokeras-PX4bqcu8/lib/python3.6/site-packages/autokeras/nn/model_trainer.py"", line 173, in _train
    outputs = self.model(inputs)
  File ""/home/omaralv/.virtualenvs/autokeras-PX4bqcu8/lib/python3.6/site-packages/torch/nn/modules/module.py"", line 489, in __call__
    result = self.forward(*input, **kwargs)
  File ""/home/omaralv/.virtualenvs/autokeras-PX4bqcu8/lib/python3.6/site-packages/autokeras/nn/graph.py"", line 689, in forward
    temp_tensor = torch_layer(edge_input_tensor)
  File ""/home/omaralv/.virtualenvs/autokeras-PX4bqcu8/lib/python3.6/site-packages/torch/nn/modules/module.py"", line 489, in __call__
    result = self.forward(*input, **kwargs)
  File ""/home/omaralv/.virtualenvs/autokeras-PX4bqcu8/lib/python3.6/site-packages/torch/nn/modules/conv.py"", line 320, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: Given groups=1, weight of size [64, 192, 1, 1], expected input[128, 256, 28, 28] to have 192 channels, but got 256 channels instead
```
",also error python torch post system two possible training training model loss decrease saving model model id loss metric value training model current metric process recent call last file line file line run file line train raise file line train file line file line file line result input file line forward file line result input file line forward given weight size input got instead,issue,negative,neutral,neutral,neutral,neutral,neutral
470027931,"When I'm trying to train the Cnn Module I have:
nr_output_nodes = 8
input_shape (2749, 1, 12)

dataloader dataset: (232, 2749, 1, 12)
dataloader labels: (232, 8)

(i also tried using the same data for the test dataloader, to not make any mistake here)

i get the error message: RuntimeError: running_mean should contain 2749 elements not 12

See also https://github.com/jhfjhfj1/autokeras/issues/475 ",trying train module also tried data test make mistake get error message contain see also,issue,negative,neutral,neutral,neutral,neutral,neutral
469940671,"
[![Coverage Status](https://coveralls.io/builds/22261394/badge)](https://coveralls.io/builds/22261394)

Coverage decreased (-0.05%) to 93.606% when pulling **3ec846fb7a42018482ab716649bfd95939305a44 on ghmole:master** into **e9dbf66b005e2ffaabe29bc366bb4e72fa79add8 on jhfjhfj1:master**.
",coverage status coverage master master,issue,negative,neutral,neutral,neutral,neutral,neutral
469326792,@boyuangong Would you please look into this bug? Thanks.,would please look bug thanks,issue,positive,positive,positive,positive,positive,positive
469222930,"
[![Coverage Status](https://coveralls.io/builds/21968321/badge)](https://coveralls.io/builds/21968321)

Coverage increased (+0.4%) to 93.407% when pulling **4e8f885b385f9216946dc997d6f1b600952a3ea7 on dependabot/pip/torchvision-0.2.2.post3** into **f7815e3bdcd9595480841e3ac1d0fb609e9c0f1a on master**.
",coverage status coverage post master,issue,negative,neutral,neutral,neutral,neutral,neutral
469169692,"I'm having the same issue on the example and on any regression I tried, even if i'm using `numpy.nan_to_num` on the inputs.",issue example regression tried even,issue,negative,neutral,neutral,neutral,neutral,neutral
468987519,Same issue as mentioned above. Anybody know how to solve it?,issue anybody know solve,issue,negative,neutral,neutral,neutral,neutral,neutral
468981802,@jmschabdach The code for generating doc is in mkdocs/autogen.py. The generated files are not kept in the master branch but the gh-pages branch. They are generated by the CI.,code generating doc kept master branch branch,issue,negative,neutral,neutral,neutral,neutral,neutral
468958553,I think this is a bug. we need to figure out a way to prevent it from calling these two functions in the MLP module.,think bug need figure way prevent calling two module,issue,negative,neutral,neutral,neutral,neutral,neutral
468924693,"@jhfjhfj1 I found odd that this module was based on lightgbm. 
I'm currently using keras (tensorflow backend) for timeseries binary classification (continuous data ; finance) using Conv1D, MaxPooling1D, Bidirectional, and finally LSTM or GRU. 
NAS support would be great for such DL architectures on tabular data.
Is the new project already on github, and planned to rely on lightgbm only?",found odd module based currently binary classification continuous data finance bidirectional finally support would great tabular data new project already rely,issue,positive,positive,positive,positive,positive,positive
468729194,"Thanks.

_________________________________________
Rajeev



On Thu, Feb 28, 2019 at 4:58 PM song3134 <notifications@github.com> wrote:

> The dataset could be downloaded through the link provided at:
>
>
> https://autokeras.com/start/#what-if-your-data-are-raw-image-files-eg-jpg-png-bmp
>
> Thanks!
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/jhfjhfj1/autokeras/issues/563#issuecomment-468473307>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABZfAhObq1jeROmtIo3HbguXXDiRmI6Eks5vSF8XgaJpZM4bXvsC>
> .
>
",thanks song wrote could link provided thanks thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
468706166,"I touched the same issue: 'RuntimeError: weight should at leat have at least two dimensions'.
When I ran my own dataset on either Latest Stable or Bleeding Edge version",touched issue weight leat least two ran either latest stable bleeding edge version,issue,negative,positive,neutral,neutral,positive,positive
468685500,"Hi, just wanted to say thanks for creating the environment. Had the same problem with dependencies when trying to install autokeras. Makes it a lot easier. 
I was just trying to run the pre-trained model object_detector.py . But it seems like the autokeras version in the image is version 0.3.1 and doesn't have some features that the newest version has, such as pre-trained models. Just wanted to ask if there's a way to include object_detector in the current docker image? Thanks",hi say thanks environment problem trying install lot easier trying run model like version image version version ask way include current docker image thanks,issue,positive,positive,positive,positive,positive,positive
468473307,"The dataset could be downloaded through the link provided at:

https://autokeras.com/start/#what-if-your-data-are-raw-image-files-eg-jpg-png-bmp

Thanks!",could link provided thanks,issue,negative,positive,positive,positive,positive,positive
468461708,@song3134 Would you add the download link to the data in the start.md? Thanks.,song would add link data thanks,issue,negative,positive,positive,positive,positive,positive
468412473,"@testvinder This has been removed because Auto-Keras is focusing on deep learning tasks.
We are moving it to a new project just focusing on tabular data, which will be completed soon.
By the time we complete the basics, we will be open to contribution.
Thank you!",removed deep learning moving new project tabular data soon time complete open contribution thank,issue,negative,positive,neutral,neutral,positive,positive
468335383,"When you run it, does it not find a solution in 12 hours? How many epochs does it get through?

Developers, what is the expected shape/size of the architecture for this example? How long should it be expected to run before it finds a solution?",run find solution many get architecture example long run solution,issue,positive,positive,positive,positive,positive,positive
468273562,"After more extensive testing, I'm able to add some information:

Each time the error is thrown, the last added operation in the log is either `to_add_skip_model` or `to_concat_skip_model`. It's also the first time they are called. 

I'm able to reproduce the bug easily with the small iris dataset in less than 5 minutes with the following code:
```python
from sklearn import datasets
from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import train_test_split
from autokeras import MlpModule
from autokeras.nn.loss_function import classification_loss
from autokeras.nn.metric import Accuracy
from autokeras.preprocessor import DataTransformerMlp

iris = datasets.load_iris()

X = iris.data
Y = iris.target.reshape(-1, 1)

encoder = OneHotEncoder(sparse=False)
encoder.fit(Y)
Y_encoded = encoder.transform(Y)
n_classes = len(Y_encoded[0])

x_train, x_test, y_train, y_test = train_test_split(
        X,
        Y_encoded,
        test_size=0.33)

data_transformer = DataTransformerMlp(x_train)
train_data = data_transformer.transform_train(x_train, y_train)
test_data = data_transformer.transform_test(x_test, y_test)

clf = MlpModule(loss=classification_loss,
                metric=Accuracy,
                searcher_args={},
                verbose=True,
                path='./result_tmp/')

clf.fit(n_output_node=n_classes,
        input_shape=train_data.dataset.dataset.shape,
        train_data=train_data,
        test_data=test_data,
        time_limit=1 * 5 * 60)

clf.final_fit(train_data,
              test_data,
              retrain=False,
              trainer_args={
                  'max_iter_num': 20,
                  'max_no_improvement_num': 5
                  })
```

Unfortunately, my knowledge on the project is too low for me to dig deeper.",extensive testing able add information time error thrown last added operation log either also first time able reproduce bug easily small iris le following code python import import import import import import accuracy import iris unfortunately knowledge project low dig,issue,negative,positive,neutral,neutral,positive,positive
468174339,"I have the exact same issue using the MlpModule. The training work for a few models and then throws an error saying `weight should have at least two dimensions`.
Any ideas will be appreciated.

Here is the traceback:
```
Traceback (most recent call last):
  File ""py36/lib/python3.6/multiprocessing/process.py"", line 258, in _bootstrap
    self.run()
  File ""py36/lib/python3.6/multiprocessing/process.py"", line 93, in run
    self._target(*self._args, **self._kwargs)
  File ""py36/lib/python3.6/site-packages/autokeras/search.py"", line 350, in train
    raise e
  File ""py36/lib/python3.6/site-packages/autokeras/search.py"", line 343, in train
    verbose=verbose).train_model(**trainer_args)
  File ""py36/lib/python3.6/site-packages/autokeras/nn/model_trainer.py"", line 137, in train_model
    self._train()
  File ""py36/lib/python3.6/site-packages/autokeras/nn/model_trainer.py"", line 173, in _train
    outputs = self.model(inputs)
  File ""py36/lib/python3.6/site-packages/torch/nn/modules/module.py"", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File ""py36/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py"", line 123, in forward
    outputs = self.parallel_apply(replicas, inputs, kwargs)
  File ""py36/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py"", line 133, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File ""py36/lib/python3.6/site-packages/torch/nn/parallel/parallel_apply.py"", line 77, in parallel_apply
    raise output
  File ""py36/lib/python3.6/site-packages/torch/nn/parallel/parallel_apply.py"", line 53, in _worker
    output = module(*input, **kwargs)
  File ""py36/lib/python3.6/site-packages/torch/nn/modules/module.py"", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File ""py36/lib/python3.6/site-packages/autokeras/nn/graph.py"", line 686, in forward
    temp_tensor = torch_layer(edge_input_tensor)
  File ""py36/lib/python3.6/site-packages/torch/nn/modules/module.py"", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File ""py36/lib/python3.6/site-packages/torch/nn/modules/conv.py"", line 421, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: weight should have at least two dimensions
```",exact issue training work error saying weight least two recent call last file line file line run file line train raise file line train file line file line file line result input file line forward file line return file line raise output file line output module input file line result input file line forward file line result input file line forward weight least two,issue,negative,negative,neutral,neutral,negative,negative
468155084,"@chengchengeasy Can you take a look to locate that at which line the code stuck?
Also #492 , I think they are the same issue.
Thanks.",take look locate line code stuck also think issue thanks,issue,negative,positive,positive,positive,positive,positive
468043976,"Try to install like this:
`pip install autokeras --ignore-installed`",try install like pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
467972628,I'm getting the same issue. It got stuck at training model 37.,getting issue got stuck training model,issue,negative,neutral,neutral,neutral,neutral,neutral
467186401,"> Hi Satya, please follow my comments to add all the empty lines. I didn't comment all the part that need an empty line, but you see my point, just use empty lines to separate the sections. Only in this way, the autogen.py can collect those docs correctly to generate the website.
> 
> Thanks

I think I understood what you said. I have made the changes. Please let me know if you think anything else needs to be changed.",hi please follow add empty comment part need empty line see point use empty separate way collect correctly generate thanks think understood said made please let know think anything else need,issue,negative,negative,neutral,neutral,negative,negative
466981856,"> I would try `clf.export_keras_model(MODEL_DIR)`

I have trouble loading the saved function using keras load_model function.
It said OSError: Unable to open file (file signature not found)",would try trouble loading saved function function said unable open file file signature found,issue,negative,negative,negative,negative,negative,negative
466837788,Thanks. I got the tensorflow docker for GPU execution and installed the autokeras. Now it works.,thanks got docker execution work,issue,negative,positive,positive,positive,positive,positive
466691831,"I had the same problem with the input: (5561, 512, 512,6).
I read here in another issue that is a problem of autokeras: generate very complex models.
",problem input read another issue problem generate complex,issue,negative,negative,negative,negative,negative,negative
466628375,"
[![Coverage Status](https://coveralls.io/builds/21806146/badge)](https://coveralls.io/builds/21806146)

Coverage increased (+0.2%) to 92.813% when pulling **0e9d59b69b7d98e40abd91885d6570eb308795fc on tabular** into **4ddd568b06b4045ace777bc0fb7bc18573b85a75 on master**.
",coverage status coverage tabular master,issue,negative,neutral,neutral,neutral,neutral,neutral
466554046,@droidadroit Would you please take a look into this issue? Thanks.,would please take look issue thanks,issue,positive,positive,positive,positive,positive,positive
466553475,"Same question. After final_fit the MLP module, I'm wondering how to evaluate it performace since it doess't support 'evaluate' or 'predict'. ",question module wondering evaluate since support,issue,negative,neutral,neutral,neutral,neutral,neutral
465498064,"> You are we welcome!
> (I have to say, the fix was found not by me, but by my manager)
> 
> The code is exactly what we did. Just FYI, you can do this instead:
> keras_model.layers[:-1].activation = keras.activations.softmax
> 
> The result would be the same.

the colon "":"" is a typo ?. To revise the last layer's activation function, it should be `keras_model.layers[-1].activation = keras.activations.softmax` ? @AShyshkov 
",welcome say fix found manager code exactly instead result would colon typo revise last layer activation function,issue,negative,positive,positive,positive,positive,positive
465458313,"I changed some code in  autokeras.nn.layers.LayerType and autokeras.nn.layers.to_real_keras_layer. Now it satisfied my requirements to export keras model for  the case of ImageRegressor1D.
",code satisfied export model case,issue,negative,positive,positive,positive,positive,positive
465443073,"ImageRegressor1D has the same error. Although the model can be fitted in autokeras, however, when export_keras_model, similar error is raised:
```
Traceback (most recent call last):
  File ""src/squtils/tmp.py"", line 113, in <module>
    clf.export_keras_model('mybest.graph')
  File ""/home/qsong/.conda/envs/py36/lib/python3.6/site-packages/autokeras/supervised.py"", line 196, in export_keras_model
    self.cnn.best_model.produce_keras_model().save(model_file_name)
  File ""/home/qsong/.conda/envs/py36/lib/python3.6/site-packages/autokeras/nn/graph.py"", line 577, in produce_keras_model
    return KerasModel(self).model
  File ""/home/qsong/.conda/envs/py36/lib/python3.6/site-packages/autokeras/nn/graph.py"", line 728, in __init__
    temp_tensor = keras_layer(edge_input_tensor)
  File ""/home/qsong/.conda/envs/py36/lib/python3.6/site-packages/keras/engine/base_layer.py"", line 414, in __call__
    self.assert_input_compatibility(inputs)
  File ""/home/qsong/.conda/envs/py36/lib/python3.6/site-packages/keras/engine/base_layer.py"", line 311, in assert_input_compatibility
    str(K.ndim(x)))
ValueError: Input 0 is incompatible with layer conv2d_1: expected ndim=4, found ndim=3

```
conv1d is used in the model(this can be confirmed by the output info. ).  
However , when exporting to keras model, it uses conv2d.
It seems like the export_keras_model method only supports ImageClassifier/ImageRegressor.
@jhfjhfj1 ",error although model fitted however similar error raised recent call last file line module file line file line return self file line file line file line input incompatible layer found used model confirmed output however model like method,issue,negative,positive,neutral,neutral,positive,positive
465421944,"> We will be supporting any size image in the future.
> Currently, we don't have an upper limit.
> Only a lower limit which is image still larger than 1 after three pooling layers with stride 2.

the statement ""larger than 1 after three pooling layers with stride 2"" means the low limit of image dimension is 16 ?  Is there a exact number for this question ? or the low limit setting could be changed somewhere in the source code ? @jhfjhfj1 ",supporting size image future currently upper limit lower limit image still three stride statement three stride low limit image dimension exact number question low limit setting could somewhere source code,issue,negative,positive,neutral,neutral,positive,positive
465420712,"when I change the autokeras version to 0.2.13,  the similar error is raised at the fitting stage:
```
Using TensorFlow backend.
get feature done ......
.......................................

Initializing search.
Initialization finished.


╒==============================================╕
|               Training model 0               |
╘==============================================╛
Using TensorFlow backend.
                                                                           /home/qsong/.conda/envs/py36/lib/python3.6/multiprocessing/semaphore_tracker.py:143: UserWarning: semaphore_tracker: There appear to be 1 leaked semaphores to clean up at shutdown
  len(cache))
multiprocessing.pool.RemoteTraceback: 
""""""
Traceback (most recent call last):
  File ""/home/qsong/.conda/envs/py36/lib/python3.6/multiprocessing/pool.py"", line 119, in worker
    result = (True, func(*args, **kwds))
  File ""/home/qsong/.conda/envs/py36/lib/python3.6/multiprocessing/pool.py"", line 44, in mapstar
    return list(map(*args))
  File ""/home/qsong/.conda/envs/py36/lib/python3.6/site-packages/autokeras/search.py"", line 280, in train
    verbose).train_model(**trainer_args)
  File ""/home/qsong/.conda/envs/py36/lib/python3.6/site-packages/autokeras/utils.py"", line 126, in train_model
    self._train()
  File ""/home/qsong/.conda/envs/py36/lib/python3.6/site-packages/autokeras/utils.py"", line 170, in _train
    outputs = self.model(inputs)
  File ""/home/qsong/.conda/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py"", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File ""/home/qsong/.conda/envs/py36/lib/python3.6/site-packages/autokeras/graph.py"", line 610, in forward
    temp_tensor = torch_layer(edge_input_tensor)
  File ""/home/qsong/.conda/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py"", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File ""/home/qsong/.conda/envs/py36/lib/python3.6/site-packages/torch/nn/modules/pooling.py"", line 142, in forward
    self.return_indices)
  File ""/home/qsong/.conda/envs/py36/lib/python3.6/site-packages/torch/nn/functional.py"", line 396, in max_pool2d
    ret = torch._C._nn.max_pool2d_with_indices(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Given input size: (64x1x1). Calculated output size: (64x0x0). Output size is too small at /pytorch/aten/src/THCUNN/generic/SpatialDilatedMaxPooling.cu:69
""""""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""src/squtils/tmp.py"", line 102, in <module>
    clf.fit(feature_is, label_is, time_limit= 5 * 60)
  File ""/home/qsong/.conda/envs/py36/lib/python3.6/site-packages/autokeras/image_supervised.py"", line 239, in fit
    run_searcher_once(train_data, test_data, self.path, int(time_remain))
  File ""/home/qsong/.conda/envs/py36/lib/python3.6/site-packages/autokeras/image_supervised.py"", line 40, in run_searcher_once
    searcher.search(train_data, test_data, timeout)
  File ""/home/qsong/.conda/envs/py36/lib/python3.6/site-packages/autokeras/search.py"", line 210, in search
    metric_value, loss, graph = train_results.get(timeout=remaining_time)[0]
  File ""/home/qsong/.conda/envs/py36/lib/python3.6/multiprocessing/pool.py"", line 644, in get
    raise self._value
RuntimeError: Given input size: (64x1x1). Calculated output size: (64x0x0). Output size is too small at /pytorch/aten/src/THCUNN/generic/SpatialDilatedMaxPooling.cu:69

```
it seems like there is a lower limit of image dimension,  (as stated in this issue by [jhfjhfj1](/jhfjhfj1) https://github.com/jhfjhfj1/autokeras/issues/310#issuecomment-455797664).
",change version similar error raised fitting stage get feature done search finished training model appear clean shutdown cache recent call last file line worker result true file line return list map file line train verbose file line file line file line result input file line forward file line result input file line forward file line ret input stride padding dilation given input size calculated output size output size small exception direct cause following exception recent call last file line module file line fit file line file line search loss graph file line get raise given input size calculated output size output size small like lower limit image dimension stated issue,issue,positive,positive,neutral,neutral,positive,positive
465418384,any idea ? I ran into the same problem as stated in this issue[545](https://github.com/jhfjhfj1/autokeras/issues/545),idea ran problem stated issue,issue,negative,neutral,neutral,neutral,neutral,neutral
465386278,"You don't have to merge the rest. Because you have already merged the rest in my last pull request. 
And you mean we should ignore that kind of issues in net_transformer.py detected by Codacy?
",merge rest already rest last pull request mean ignore kind,issue,negative,positive,neutral,neutral,positive,positive
465384333,@Davidsirui Just remove the changes on net_transformer. I will merge the rest. The issues on that file is not correctly detected by Codacy. We don't need to change. Thanks.,remove merge rest file correctly need change thanks,issue,negative,positive,positive,positive,positive,positive
465226793,"> > The coverall seems broke. I cannot see the test coverage. What is the coverage now?
> 
> Around 90.3% when I last saw. There is a decrease of 3%. Is that fine? It's heavily experimental to see how to mock BERT functionality at lower level to improve on the coverage but not sure what gain we might get. I will follow upon that as well for a later PR, if that's okay?

A decrease of 3% is too much. It usually means a large part of the code is not covered. You need to look into the coverage report locally, to see which part is missing. We can schedule a meeting to review the code together.",broke see test coverage coverage around last saw decrease fine heavily experimental see mock functionality lower level improve coverage sure gain might get follow upon well later decrease much usually large part code covered need look coverage report locally see part missing schedule meeting review code together,issue,negative,positive,positive,positive,positive,positive
465067485,"I suspect whether the autokeras only support the data with the same width and high  for  ImageRegressor/ImageClassifier ?   (NO, I checked that if my input is [?, 5 * 5, 1] , similar error is stilled raised.  `ValueError: Negative dimension size caused by subtracting 2 from 1 for 'max_pooling2d_3/MaxPool' (op: 'MaxPool') with input shapes: [?,1,1,64].`)",suspect whether support data width high checked input similar error raised negative dimension size input,issue,negative,negative,neutral,neutral,negative,negative
465066402,"Maybe not the problem of data_format parameter. I found some graphs also raise the same error with the input the shape of [? , x, 1, x]. The third value should not the be the channel neither in 'th' nor in 'tf' style. 

what messed me up is  why the network is valid in autokeras, but not valid in keras or tensorflow.

really appreciate for the help.",maybe problem parameter found also raise error input shape third value channel neither style network valid valid really appreciate help,issue,negative,positive,neutral,neutral,positive,positive
464977548,"> The coverall seems broke. I cannot see the test coverage. What is the coverage now?

Around 90.3% when I last saw. There is a decrease of 3%. Is that fine? It's heavily experimental to see how to mock BERT functionality at lower level to improve on the coverage but not sure what gain we might get. I will follow upon that as well for a later PR, if that's okay?",broke see test coverage coverage around last saw decrease fine heavily experimental see mock functionality lower level improve coverage sure gain might get follow upon well later,issue,positive,positive,positive,positive,positive,positive
464943104,"I was able to run the test examples from autokeras using GPU through tensorflow. Did you check if your environment has properly installed the CUDA drivers and tensorflow-gpu is loaded?

One way the check if the tensorflow is using GPU or not, run the following codes:
   import tensorflow as tf
   sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))

You should see the output referencing the GPU if it's successful.",able run test check environment properly loaded one way check run following import sess see output successful,issue,positive,positive,positive,positive,positive,positive
464564963,"Thanks. My purpose is for academia also. But my main concern is by getting the final models via default optimization method ( as you mentioned that is Baysian searcher ), the outcome of Mlpmodule fit will be 👍 


+----------------------------------------------+
|               Training model 4               |
+----------------------------------------------+
Using TensorFlow backend.

No loss decrease after 5 epochs.


Saving model.
+--------------------------------------------------------------------------+
|        Model ID        |          Loss          |      Metric Value      |
+--------------------------------------------------------------------------+
|           4            |   0.2726407766342163   |   0.8833333333333334   |
+--------------------------------------------------------------------------+


+----------------------------------------------+
|               Training model 5               |
+----------------------------------------------+
Using TensorFlow backend.

No loss decrease after 5 epochs.


Saving model.
+--------------------------------------------------------------------------+
|        Model ID        |          Loss          |      Metric Value      |
+--------------------------------------------------------------------------+
|           5            |  0.27542130947113036   |   0.8910256410256411   |
+--------------------------------------------------------------------------+


+----------------------------------------------+
|               Training model 6               |
+----------------------------------------------+
Using TensorFlow backend.

No loss decrease after 5 epochs.


Saving model.
+--------------------------------------------------------------------------+
|        Model ID        |          Loss          |      Metric Value      |
+--------------------------------------------------------------------------+
|           6            |  0.27543354630470274   |   0.8782051282051281   |
+--------------------------------------------------------------------------+


+----------------------------------------------+
|               Training model 7               |
+----------------------------------------------+
Using TensorFlow backend.
Time is out.

No loss decrease after 5 epochs.


Then I put this code as the final_fit and nothing appears. I also trained it with several arguments and noting appeared,

 
mlpModule.final_fit(train_data, test_data, trainer_args={'max_iter_num': 6}, retrain=False)





",thanks purpose also main concern getting final via default optimization method searcher outcome fit training model loss decrease saving model model id loss metric value training model loss decrease saving model model id loss metric value training model loss decrease saving model model id loss metric value training model time loss decrease put code nothing also trained several,issue,negative,positive,positive,positive,positive,positive
464527833,"Hi,
   I was actually looking into autokeras code for academic puprpose.  I am not a contributer to the project. Can't comment authentically. MLP module use BayesianSearcher now. Find the code below. If the BayesianSearcher is enough for your purpose remove the parameter.

```
`class MlpModule(NetworkModule):
    """""" Class to create an MLP module.""""""
    def __init__(self, loss, metric, searcher_args=None, path=None, verbose=False):
        super(MlpModule, self).__init__(loss, metric, searcher_args, path, verbose)
        self.generators.extend([MlpGenerator] * 2)`
```


Init for the NetworkModule
`def __init__(self, loss, metric, searcher_args=None, path=None, verbose=False, search_type=BayesianSearcher):`
",hi actually looking code academic project ca comment authentically module use find code enough purpose remove parameter class class create module self loss metric super self loss metric path verbose self loss metric,issue,negative,positive,neutral,neutral,positive,positive
464091748,"Adding my voice to this - I am also running into this issue on 0.3.7 on python 3.6.7, Ubuntu 18.04.1 on a fresh amazon box, only autokeras + dependencies installed, running text classifier as follows:

```
from autokeras import TextClassifier

import csv
rows = []
labels = []
with open('labeled_data.csv', 'r') as f:
    reader = csv.reader(f)
    for row in reader:
        rows.append(row[0])
        labels.append(int(row[1]))

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(rows, labels, test_size=0.33, random_state=42)
clf = TextClassifier(verbose=True)
clf.fit(x=X_train, y=y_train, time_limit=12*60*60)
clf.final_fit(X_train, y_train, X_test, y_test, retrain=True)
y_out = clf.evaluate(X_test, y_test)
```

It gets stuck during fit like so:

```
Saving model.
+--------------------------------------------------------------------------+
|        Model ID        |          Loss          |      Metric Value      |
+--------------------------------------------------------------------------+
|           31           |   2.545453941822052    |   0.6641509433962264   |
+--------------------------------------------------------------------------+


+----------------------------------------------+
|              Training model 32               |
+----------------------------------------------+

No loss decrease after 5 epochs.


Saving model.
+--------------------------------------------------------------------------+
|        Model ID        |          Loss          |      Metric Value      |
+--------------------------------------------------------------------------+
|           32           |   5.955252933502197    |  0.43018867924528303   |
+--------------------------------------------------------------------------+


+----------------------------------------------+
|              Training model 33               |
+----------------------------------------------+
Epoch-1, Current Metric - 0:   0%|                                        | 0/5 [00:00<?, ? batch/s]
```

happy to provide the CSV I'm using off-list.",voice also running issue python fresh box running text classifier import import open reader row reader row row import stuck fit like saving model model id loss metric value training model loss decrease saving model model id loss metric value training model current metric happy provide,issue,positive,positive,positive,positive,positive,positive
463989362,"Hey ai-high,

yeah I fixed that. Just go and clone my forked repo (https://github.com/SharifElfouly/autokeras). That should work now...",hey yeah fixed go clone forked work,issue,negative,positive,neutral,neutral,positive,positive
463988565,Hey I fixed the CI. I'm glad I could help!,hey fixed glad could help,issue,positive,positive,positive,positive,positive,positive
463983984,"Code Climate has analyzed commit 7558bda8 and detected **0 issues** on this pull request.

View more on [Code Climate](https://codeclimate.com/github/jhfjhfj1/autokeras/pull/536).
",code climate commit pull request view code climate,issue,negative,neutral,neutral,neutral,neutral,neutral
463903016,"Code Climate has analyzed commit 410d0e40 and detected **5 issues** on this pull request.

Here's the issue category breakdown:

| Category | Count |
|:---:|:---:|
| Complexity | 5 |


View more on [Code Climate](https://codeclimate.com/github/jhfjhfj1/autokeras/pull/535).
",code climate commit de pull request issue category breakdown category count complexity view code climate,issue,negative,neutral,neutral,neutral,neutral,neutral
463836651,"@SharifElfouly Thank you for your contribution! Would you fix the CI before I can merge?

<sub>Sent with <a href=""http://githawk.com"">GitHawk</a></sub>",thank contribution would fix merge sub sent,issue,negative,neutral,neutral,neutral,neutral,neutral
463831055,"Hi Sharif, Im getting an error on the line

`from . import connection`

in the custom_queue.py file",hi getting error line import connection file,issue,negative,neutral,neutral,neutral,neutral,neutral
463667373,"Hey,
just clone my branch and reference autokeras locally from it. That worked for me....",hey clone branch reference locally worked,issue,negative,neutral,neutral,neutral,neutral,neutral
463618310,"Hi Sharif, 
Trying to run setup.py of your package and its not installing properly the .egg
python doesn't recognize the autokeras or the custom_queue class
I am working on python 3.6 virt_env
Thank you
Keren",hi trying run package properly python recognize class working python thank,issue,negative,neutral,neutral,neutral,neutral,neutral
463282579,"@chengchengeasy 
Hi Cheng,
In nas.md
Could you submit another pull request to add links to the baseline methods mentioned?
Also make the cifar10_tutorial.py can be click.
Thanks.",hi cheng could submit another pull request add link also make click thanks,issue,negative,positive,positive,positive,positive,positive
463275336,"Does anyone knows if the second code of @Anindita-Pani  should work?
according to this [thread](https://github.com/jhfjhfj1/autokeras/issues/186), we need to add activation layer and training.

",anyone second code work according thread need add activation layer training,issue,negative,neutral,neutral,neutral,neutral,neutral
463069295,"> This pull request looks good.
> However, I prefer to merge it after you finish this module.
> According to github-flow, the master branch should always be deployable.
> If I merge now, it will prevent us from releasing any new versions during your development of this module.
> 
> If we don't merge for now, I don't think anyone else would change the code of this module to create any conflict with yours.
> 
> Thanks.

Ok. I preferred to do it in multiple commits since the changes are very big and it will be easy for both code review and pushing the code. But, as you pointed about the rule, I will address the complete changes in this branch. ",pull request good however prefer merge finish module according master branch always merge prevent u new development module merge think anyone else would change code module create conflict thanks preferred multiple since big easy code review pushing code pointed rule address complete branch,issue,positive,positive,positive,positive,positive,positive
462959776,Can anyone help me with implementation of this fix? not really sure what to do,anyone help implementation fix really sure,issue,positive,positive,positive,positive,positive,positive
462822733,"I'm have windows 10 and used python 3.6 in an Anaconda environment.
1.  pip install torchvision=0.2.1
2.  pip install numpy==1.14.5
3.  pip install keras
4.  pip install scikit-learn==0.19.1
5.  pip install tensorflow
6.  pip install autokeras

This worked for me!",used python anaconda environment pip install pip install pip install pip install pip install pip install worked,issue,negative,neutral,neutral,neutral,neutral,neutral
462743616,Would you kindly make a Pull Request?,would kindly make pull request,issue,negative,positive,positive,positive,positive,positive
462741702,I did modify autokeras and just used the Queue class mentioned above instead of the multiprocessing.queues.Queue class.,modify used queue class instead class,issue,negative,neutral,neutral,neutral,neutral,neutral
462736133,"Glad it helped!
Did you modified autokeras or subclassed the Queue class in any other way? Maybe the best option would be to PR autokeras.",glad queue class way maybe best option would,issue,positive,positive,positive,positive,positive,positive
462707123,"> Since this is an old problem, I've found a posible solution that other project (lemon) has taken: to subclass the Queue class in order to make it portable. This is the code (comes from [vterron/lemon@9ca6b4b](https://github.com/vterron/lemon/commit/9ca6b4b1212228dbd4f69b88aaf88b12952d7d6f)):
> 
> ```
> class SharedCounter(object):
>     """""" A synchronized shared counter.
> 
>     The locking done by multiprocessing.Value ensures that only a single
>     process or thread may read or write the in-memory ctypes object. However,
>     in order to do n += 1, Python performs a read followed by a write, so a
>     second process may read the old value before the new one is written by the
>     first process. The solution is to use a multiprocessing.Lock to guarantee
>     the atomicity of the modifications to Value.
> 
>     This class comes almost entirely from Eli Bendersky's blog:
>     http://eli.thegreenplace.net/2012/01/04/shared-counter-with-pythons-multiprocessing/
> 
>     """"""
> 
>     def __init__(self, n = 0):
>         self.count = multiprocessing.Value('i', n)
> 
>     def increment(self, n = 1):
>         """""" Increment the counter by n (default = 1) """"""
>         with self.count.get_lock():
>             self.count.value += n
> 
>     @property
>     def value(self):
>         """""" Return the value of the counter """"""
>         return self.count.value
> 
> 
> class Queue(multiprocessing.queues.Queue):
>     """""" A portable implementation of multiprocessing.Queue.
> 
>     Because of multithreading / multiprocessing semantics, Queue.qsize() may
>     raise the NotImplementedError exception on Unix platforms like Mac OS X
>     where sem_getvalue() is not implemented. This subclass addresses this
>     problem by using a synchronized shared counter (initialized to zero) and
>     increasing / decreasing its value every time the put() and get() methods
>     are called, respectively. This not only prevents NotImplementedError from
>     being raised, but also allows us to implement a reliable version of both
>     qsize() and empty().
> 
>     """"""
> 
>     def __init__(self, *args, **kwargs):
>         super(Queue, self).__init__(*args, **kwargs)
>         self.size = SharedCounter(0)
> 
>     def put(self, *args, **kwargs):
>         self.size.increment(1)
>         super(Queue, self).put(*args, **kwargs)
> 
>     def get(self, *args, **kwargs):
>         self.size.increment(-1)
>         return super(Queue, self).get(*args, **kwargs)
> 
>     def qsize(self):
>         """""" Reliable implementation of multiprocessing.Queue.qsize() """"""
>         return self.size.value
> 
>     def empty(self):
>         """""" Reliable implementation of multiprocessing.Queue.empty() """"""
>         return not self.qsize()
> ```

This worked for me...
Thanks!",since old problem found solution project lemon taken subclass queue class order make portable code come class object synchronized counter locking done single process thread may read write object however order python read write second process may read old value new one written first process solution use guarantee atomicity value class come almost entirely self increment self increment counter default property value self return value counter return class queue portable implementation semantics may raise exception like mac o subclass problem synchronized counter zero increasing decreasing value every time put get respectively raised also u implement reliable version empty self super queue self put self super queue self get self return super queue self self reliable implementation return empty self reliable implementation return worked thanks,issue,positive,positive,positive,positive,positive,positive
462678311,"I tried the same command: 
`pip install autokeras`
I am getting this error:
`Cannot uninstall 'imageio'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.`

 (using an Anaconda-Jupyter notebook on OS: Ubuntu)",tried command pip install getting error project thus accurately determine belong would lead partial notebook o,issue,negative,positive,positive,positive,positive,positive
462626000,"> Same error.
> It seems to be an issue with multiprocessing and macOS.
> `multiprocessing/queues.py in qsize(self)`
> `def qsize(self):`
> ` # Raises NotImplementedError on Mac OSX because of broken sem_getvalue()`
> `--> self._maxsize - self._sem._semlock._get_value()`
> `def empty(self):`
> ![captura de pantalla 2019-02-07 a las 17 59 16](https://user-images.githubusercontent.com/2808425/52428381-1d1ed680-2b02-11e9-9076-5fb0bd4e03f2.png)

I'm having same problem",error issue self self mac broken empty self de la problem,issue,negative,negative,negative,negative,negative,negative
462355314,"Code Climate has analyzed commit da39d507 and detected **0 issues** on this pull request.

View more on [Code Climate](https://codeclimate.com/github/jhfjhfj1/autokeras/pull/501).
",code climate commit dad pull request view code climate,issue,negative,neutral,neutral,neutral,neutral,neutral
462234604,"Code Climate has analyzed commit df206c69 and detected **1 issue** on this pull request.

Here's the issue category breakdown:

| Category | Count |
|:---:|:---:|
| Complexity | 1 |


View more on [Code Climate](https://codeclimate.com/github/jhfjhfj1/autokeras/pull/526).
",code climate commit issue pull request issue category breakdown category count complexity view code climate,issue,negative,neutral,neutral,neutral,neutral,neutral
462216479,"Code Climate has analyzed commit c2e7b90f and detected **2 issues** on this pull request.

Here's the issue category breakdown:

| Category | Count |
|:---:|:---:|
| Duplication | 2 |


View more on [Code Climate](https://codeclimate.com/github/jhfjhfj1/autokeras/pull/527).
",code climate commit pull request issue category breakdown category count duplication view code climate,issue,negative,neutral,neutral,neutral,neutral,neutral
462108332,"I don't understand what the status of this feature request is. The functionality does not seem to be there, why has it been closed?",understand status feature request functionality seem closed,issue,negative,negative,neutral,neutral,negative,negative
461866415,"
[![Coverage Status](https://coveralls.io/builds/21535817/badge)](https://coveralls.io/builds/21535817)

Coverage decreased (-0.01%) to 93.658% when pulling **50d4365b14ffe7b782ba66fe4a1a745e74b31d17 on smell** into **5e65669dd4739a5a2e79881b426d2d15890f0c54 on master**.
",coverage status coverage smell master,issue,negative,neutral,neutral,neutral,neutral,neutral
461811029,"I get the same error. The text show the error on the console, after that I provide the full log by the file *run_08_02_2019 : _00_49.log* like requested by @jhfjhfj1.

Using TensorFlow backend.
(70000, 100, 100, 1)
(70000,)
(25596, 100, 100, 1)
(25596,)
Saving Directory: /tmp/autokeras_UZMGTI
Preprocessing the images.
Preprocessing finished.

Initializing search.
Initialization finished.


+----------------------------------------------+
|               Training model 0               |
+----------------------------------------------+
                                                                                                    
No loss decrease after 5 epochs.


Saving model.
+--------------------------------------------------------------------------+
|        Model ID        |          Loss          |      Metric Value      |
+--------------------------------------------------------------------------+
|           0            |   2.633747911453247    |   0.6235999999999999   |
+--------------------------------------------------------------------------+


+----------------------------------------------+
|               Training model 1               |
+----------------------------------------------+
Epoch-1, Current Metric - 0:   0%|                                      | 0/543 [00:00<?, ? batch/s]
Current model size is too big. Discontinuing training this model to search for other models.
                                                                                                    

+----------------------------------------------+
|               Training model 2               |
+----------------------------------------------+
Epoch-1, Current Metric - 0:   0%|                                      | 0/543 [00:00<?, ? batch/s]
Current model size is too big. Discontinuing training this model to search for other models.
                                                                                                    

+----------------------------------------------+
|               Training model 3               |
+----------------------------------------------+
                                                                                                    
No loss decrease after 5 epochs.


Saving model.
+--------------------------------------------------------------------------+
|        Model ID        |          Loss          |      Metric Value      |
+--------------------------------------------------------------------------+
|           3            |   2.481710124015808    |   0.6628000000000001   |
+--------------------------------------------------------------------------+


+----------------------------------------------+
|               Training model 4               |
+----------------------------------------------+
                                                                                                    
No loss decrease after 5 epochs.


Saving model.
+--------------------------------------------------------------------------+
|        Model ID        |          Loss          |      Metric Value      |
+--------------------------------------------------------------------------+
|           4            |   2.513569700717926    |          0.66          |
+--------------------------------------------------------------------------+


+----------------------------------------------+
|               Training model 5               |
+----------------------------------------------+
                                                                                                    
No loss decrease after 5 epochs.


Saving model.
+--------------------------------------------------------------------------+
|        Model ID        |          Loss          |      Metric Value      |
+--------------------------------------------------------------------------+
|           5            |   2.5458521485328673   |         0.6388         |
+--------------------------------------------------------------------------+


+----------------------------------------------+
|               Training model 6               |
+----------------------------------------------+
                                                                                                    
No loss decrease after 5 epochs.


Saving model.
+--------------------------------------------------------------------------+
|        Model ID        |          Loss          |      Metric Value      |
+--------------------------------------------------------------------------+
|           6            |   2.5482874870300294   |   0.6416000000000001   |
+--------------------------------------------------------------------------+


+----------------------------------------------+
|               Training model 7               |
+----------------------------------------------+
                                                                                                    
No loss decrease after 5 epochs.


Saving model.
+--------------------------------------------------------------------------+
|        Model ID        |          Loss          |      Metric Value      |
+--------------------------------------------------------------------------+
|           7            |   2.4640462756156922   |         0.6608         |
+--------------------------------------------------------------------------+


+----------------------------------------------+
|               Training model 8               |
+----------------------------------------------+
                                                                                                    
No loss decrease after 5 epochs.


Saving model.
+--------------------------------------------------------------------------+
|        Model ID        |          Loss          |      Metric Value      |
+--------------------------------------------------------------------------+
|           8            |   2.539222741127014    |         0.6452         |
+--------------------------------------------------------------------------+


+----------------------------------------------+
|               Training model 9               |
+----------------------------------------------+
                                                                                                    
No loss decrease after 5 epochs.


Saving model.
+--------------------------------------------------------------------------+
|        Model ID        |          Loss          |      Metric Value      |
+--------------------------------------------------------------------------+
|           9            |   2.5334874629974364   |         0.6532         |
+--------------------------------------------------------------------------+


+----------------------------------------------+
|              Training model 10               |
+----------------------------------------------+
                                                                                                    
No loss decrease after 5 epochs.


Saving model.
+--------------------------------------------------------------------------+
|        Model ID        |          Loss          |      Metric Value      |
+--------------------------------------------------------------------------+
|           10           |   2.5555039286613463   |         0.6468         |
+--------------------------------------------------------------------------+


+----------------------------------------------+
|              Training model 11               |
+----------------------------------------------+
                                                                                                    
No loss decrease after 5 epochs.


Saving model.
+--------------------------------------------------------------------------+
|        Model ID        |          Loss          |      Metric Value      |
+--------------------------------------------------------------------------+
|           11           |   2.5215076923370363   |         0.648          |
+--------------------------------------------------------------------------+


+----------------------------------------------+
|              Training model 12               |
+----------------------------------------------+
                                                                                                    
No loss decrease after 5 epochs.


Saving model.
+--------------------------------------------------------------------------+
|        Model ID        |          Loss          |      Metric Value      |
+--------------------------------------------------------------------------+
|           12           |   2.527649772167206    |   0.6464000000000001   |
+--------------------------------------------------------------------------+


+----------------------------------------------+
|              Training model 13               |
+----------------------------------------------+
                                                                                                    
No loss decrease after 5 epochs.


Saving model.
+--------------------------------------------------------------------------+
|        Model ID        |          Loss          |      Metric Value      |
+--------------------------------------------------------------------------+
|           13           |   2.548809218406677    |   0.6456000000000001   |
+--------------------------------------------------------------------------+


+----------------------------------------------+
|              Training model 14               |
+----------------------------------------------+
                                                                                                    
No loss decrease after 5 epochs.


Saving model.
+--------------------------------------------------------------------------+
|        Model ID        |          Loss          |      Metric Value      |
+--------------------------------------------------------------------------+
|           14           |   2.6139551758766175   |         0.6408         |
+--------------------------------------------------------------------------+


+----------------------------------------------+
|              Training model 15               |
+----------------------------------------------+
                                                                                                    
No loss decrease after 5 epochs.


Saving model.
+--------------------------------------------------------------------------+
|        Model ID        |          Loss          |      Metric Value      |
+--------------------------------------------------------------------------+
|           15           |   2.493605923652649    |         0.6588         |
+--------------------------------------------------------------------------+


+----------------------------------------------+
|              Training model 16               |
+----------------------------------------------+
Epoch-1, Current Metric - 0:   0%|                                      | 0/543 [00:00<?, ? batch/s]Process ForkProcess-25:
Traceback (most recent call last):
  File ""/usr/lib/python3.6/multiprocessing/process.py"", line 258, in _bootstrap
    self.run()
  File ""/usr/lib/python3.6/multiprocessing/process.py"", line 93, in run
    self._target(*self._args, **self._kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/autokeras/search.py"", line 351, in train
    raise e
  File ""/usr/local/lib/python3.6/dist-packages/autokeras/search.py"", line 344, in train
    verbose=verbose).train_model(**trainer_args)
  File ""/usr/local/lib/python3.6/dist-packages/autokeras/nn/model_trainer.py"", line 137, in train_model
    self._train()
  File ""/usr/local/lib/python3.6/dist-packages/autokeras/nn/model_trainer.py"", line 173, in _train
    outputs = self.model(inputs)
  File ""/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py"", line 489, in __call__
    result = self.forward(*input, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/autokeras/nn/graph.py"", line 689, in forward
    temp_tensor = torch_layer(edge_input_tensor)
  File ""/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py"", line 489, in __call__
    result = self.forward(*input, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py"", line 320, in forward
    self.padding, self.dilation, self.groups)
**RuntimeError: Given groups=1, weight of size [512, 192, 1, 1], expected input[128, 256, 25, 25] to have 192 channels, but got 256 channels instead**


2019-02-08 00:55:12,034 - utils.py - New Model Id - 3
2019-02-08 00:55:12,034 - utils.py - 
+--------------------------------------------------------------------------+
2019-02-08 00:55:12,034 - utils.py - |    Father Model ID     |                 Added Operation                 |
2019-02-08 00:55:12,034 - utils.py - +--------------------------------------------------------------------------+
2019-02-08 00:55:12,034 - utils.py - |           0            |               to_wider_model 2 64               |
2019-02-08 00:55:12,034 - utils.py - +--------------------------------------------------------------------------+
2019-02-08 01:09:16,365 - utils.py - New Model Id - 4
2019-02-08 01:09:16,365 - utils.py - 
+--------------------------------------------------------------------------+
2019-02-08 01:09:16,365 - utils.py - |    Father Model ID     |                 Added Operation                 |
2019-02-08 01:09:16,365 - utils.py - +--------------------------------------------------------------------------+
2019-02-08 01:09:16,365 - utils.py - |           0            |       to_deeper_model 0 Conv2d(1, 1, 3, 1)      |
2019-02-08 01:09:16,365 - utils.py - +--------------------------------------------------------------------------+
2019-02-08 01:20:59,017 - utils.py - New Model Id - 5
2019-02-08 01:20:59,017 - utils.py - 
+--------------------------------------------------------------------------+
2019-02-08 01:20:59,017 - utils.py - |    Father Model ID     |                 Added Operation                 |
2019-02-08 01:20:59,017 - utils.py - +--------------------------------------------------------------------------+
2019-02-08 01:20:59,017 - utils.py - |           3            |              to_add_skip_model 3 9              |
2019-02-08 01:20:59,017 - utils.py - +--------------------------------------------------------------------------+
2019-02-08 01:26:58,800 - utils.py - New Model Id - 6
2019-02-08 01:26:58,800 - utils.py - 
+--------------------------------------------------------------------------+
2019-02-08 01:26:58,800 - utils.py - |    Father Model ID     |                 Added Operation                 |
2019-02-08 01:26:58,800 - utils.py - +--------------------------------------------------------------------------+
2019-02-08 01:26:58,801 - utils.py - |           3            |              to_add_skip_model 3 8              |
2019-02-08 01:26:58,801 - utils.py - +--------------------------------------------------------------------------+
2019-02-08 01:38:15,857 - utils.py - New Model Id - 7
2019-02-08 01:38:15,857 - utils.py - 
+--------------------------------------------------------------------------+
2019-02-08 01:38:15,857 - utils.py - |    Father Model ID     |                 Added Operation                 |
2019-02-08 01:38:15,857 - utils.py - +--------------------------------------------------------------------------+
2019-02-08 01:38:15,857 - utils.py - |                        |              to_add_skip_model 4 8              |
2019-02-08 01:38:15,858 - utils.py - |           3            |               to_wider_model 6 64               |
2019-02-08 01:38:15,858 - utils.py - |                        |      to_deeper_model 8 BatchNormalization2d     |
2019-02-08 01:38:15,858 - utils.py - +--------------------------------------------------------------------------+
2019-02-08 01:47:12,485 - utils.py - New Model Id - 8
2019-02-08 01:47:12,485 - utils.py - 
+--------------------------------------------------------------------------+
2019-02-08 01:47:12,485 - utils.py - |    Father Model ID     |                 Added Operation                 |
2019-02-08 01:47:12,485 - utils.py - +--------------------------------------------------------------------------+
2019-02-08 01:47:12,485 - utils.py - |           3            |              to_add_skip_model 0 3              |
2019-02-08 01:47:12,485 - utils.py - +--------------------------------------------------------------------------+
2019-02-08 01:54:36,586 - utils.py - New Model Id - 9
2019-02-08 01:54:36,586 - utils.py - 
+--------------------------------------------------------------------------+
2019-02-08 01:54:36,586 - utils.py - |    Father Model ID     |                 Added Operation                 |
2019-02-08 01:54:36,586 - utils.py - +--------------------------------------------------------------------------+
2019-02-08 01:54:36,586 - utils.py - |           3            |              to_add_skip_model 2 6              |
2019-02-08 01:54:36,586 - utils.py - +--------------------------------------------------------------------------+
2019-02-08 02:08:38,497 - utils.py - New Model Id - 10
2019-02-08 02:08:38,497 - utils.py - 
+--------------------------------------------------------------------------+
2019-02-08 02:08:38,497 - utils.py - |    Father Model ID     |                 Added Operation                 |
2019-02-08 02:08:38,497 - utils.py - +--------------------------------------------------------------------------+
2019-02-08 02:08:38,497 - utils.py - |           3            |            to_concat_skip_model 0 10            |
2019-02-08 02:08:38,497 - utils.py - +--------------------------------------------------------------------------+
2019-02-08 02:17:25,902 - utils.py - New Model Id - 11
2019-02-08 02:17:25,903 - utils.py - 
+--------------------------------------------------------------------------+
2019-02-08 02:17:25,903 - utils.py - |    Father Model ID     |                 Added Operation                 |
2019-02-08 02:17:25,903 - utils.py - +--------------------------------------------------------------------------+
2019-02-08 02:17:25,903 - utils.py - |           3            |              to_add_skip_model 4 6              |
2019-02-08 02:17:25,903 - utils.py - +--------------------------------------------------------------------------+
2019-02-08 02:37:57,623 - utils.py - New Model Id - 12
2019-02-08 02:37:57,623 - utils.py - 
+--------------------------------------------------------------------------+
2019-02-08 02:37:57,623 - utils.py - |    Father Model ID     |                 Added Operation                 |
2019-02-08 02:37:57,623 - utils.py - +--------------------------------------------------------------------------+
2019-02-08 02:37:57,623 - utils.py - |                        |              to_add_skip_model 5 7              |
2019-02-08 02:37:57,623 - utils.py - |           3            |            to_concat_skip_model 4 10            |
2019-02-08 02:37:57,623 - utils.py - +--------------------------------------------------------------------------+
2019-02-08 02:47:27,498 - utils.py - New Model Id - 13
2019-02-08 02:47:27,498 - utils.py - 
+--------------------------------------------------------------------------+
2019-02-08 02:47:27,498 - utils.py - |    Father Model ID     |                 Added Operation                 |
2019-02-08 02:47:27,498 - utils.py - +--------------------------------------------------------------------------+
2019-02-08 02:47:27,498 - utils.py - |           3            |              to_add_skip_model 2 10             |
2019-02-08 02:47:27,498 - utils.py - +--------------------------------------------------------------------------+
2019-02-08 02:57:34,812 - utils.py - New Model Id - 14
2019-02-08 02:57:34,812 - utils.py - 
+--------------------------------------------------------------------------+
2019-02-08 02:57:34,812 - utils.py - |    Father Model ID     |                 Added Operation                 |
2019-02-08 02:57:34,812 - utils.py - +--------------------------------------------------------------------------+
2019-02-08 02:57:34,812 - utils.py - |           3            |              to_add_skip_model 2 3              |
2019-02-08 02:57:34,812 - utils.py - +--------------------------------------------------------------------------+
2019-02-08 03:06:12,639 - utils.py - New Model Id - 15
2019-02-08 03:06:12,640 - utils.py - 
+--------------------------------------------------------------------------+
2019-02-08 03:06:12,640 - utils.py - |    Father Model ID     |                 Added Operation                 |
2019-02-08 03:06:12,640 - utils.py - +--------------------------------------------------------------------------+
2019-02-08 03:06:12,640 - utils.py - |           3            |              to_add_skip_model 8 9              |
2019-02-08 03:06:12,640 - utils.py - +--------------------------------------------------------------------------+
2019-02-08 03:14:23,431 - utils.py - New Model Id - 16
2019-02-08 03:14:23,432 - utils.py - 
+--------------------------------------------------------------------------+
2019-02-08 03:14:23,432 - utils.py - |    Father Model ID     |                 Added Operation                 |
2019-02-08 03:14:23,432 - utils.py - +--------------------------------------------------------------------------+
2019-02-08 03:14:23,432 - utils.py - |                        |             to_concat_skip_model 6 9            |
2019-02-08 03:14:23,432 - utils.py - |                        |               to_wider_model 6 64               |
2019-02-08 03:14:23,432 - utils.py - |                        |               to_wider_model 20 64              |
2019-02-08 03:14:23,432 - utils.py - |           3            |              to_wider_model 20 128              |
2019-02-08 03:14:23,432 - utils.py - |                        |              to_wider_model 20 256              |
2019-02-08 03:14:23,432 - utils.py - |                        |               to_wider_model 2 128              |
2019-02-08 03:14:23,432 - utils.py - |                        |     to_deeper_model 9 Conv2d(128, 128, 3, 1)    |
2019-02-08 03:14:23,432 - utils.py - +--------------------------------------------------------------------------+",get error text show error console provide full log file like saving directory finished search finished training model loss decrease saving model model id loss metric value training model current metric current model size big training model search training model current metric current model size big training model search training model loss decrease saving model model id loss metric value training model loss decrease saving model model id loss metric value training model loss decrease saving model model id loss metric value training model loss decrease saving model model id loss metric value training model loss decrease saving model model id loss metric value training model loss decrease saving model model id loss metric value training model loss decrease saving model model id loss metric value training model loss decrease saving model model id loss metric value training model loss decrease saving model model id loss metric value training model loss decrease saving model model id loss metric value training model loss decrease saving model model id loss metric value training model loss decrease saving model model id loss metric value training model loss decrease saving model model id loss metric value training model current metric process recent call last file line file line run file line train raise file line train file line file line file line result input file line forward file line result input file line forward given weight size input got instead new model id father model id added operation new model id father model id added operation new model id father model id added operation new model id father model id added operation new model id father model id added operation new model id father model id added operation new model id father model id added operation new model id father model id added operation new model id father model id added operation new model id father model id added operation new model id father model id added operation new model id father model id added operation new model id father model id added operation new model id father model id added operation,issue,negative,positive,neutral,neutral,positive,positive
461670506,"Okay bro...

On Fri, Feb 8, 2019, 1:27 AM Drew Bollinger <notifications@github.com>
wrote:

> @hemangjoshi37a <https://github.com/hemangjoshi37a> Feel free to ignore
> my earlier issue. I think the docker image I mentioned is both a bit out of
> date and not compiled to use the GPU. I was able to get things running
> using agnz/autokeras <https://hub.docker.com/r/agnz/autokeras> which is
> built from nvidia/cuda:10.0-runtime-ubuntu18.04
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/jhfjhfj1/autokeras/issues/468#issuecomment-461574036>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL0XmXpq_yiw-R7j_YhrcPnmZQfcWMjPks5vLIVHgaJpZM4aJBwv>
> .
>
-- 

Regards,
Hemang Joshi
",drew wrote feel free ignore issue think docker image bit date use able get running built reply directly view mute thread joshi,issue,negative,positive,positive,positive,positive,positive
461625748,"Since this is an old problem, I've found a posible solution that other project (lemon) has taken: to subclass the Queue class in order to make it portable. This is the code (comes from https://github.com/vterron/lemon/commit/9ca6b4b1212228dbd4f69b88aaf88b12952d7d6f):

    class SharedCounter(object):
	    """""" A synchronized shared counter.
	
	    The locking done by multiprocessing.Value ensures that only a single
	    process or thread may read or write the in-memory ctypes object. However,
	    in order to do n += 1, Python performs a read followed by a write, so a
	    second process may read the old value before the new one is written by the
	    first process. The solution is to use a multiprocessing.Lock to guarantee
	    the atomicity of the modifications to Value.
	
	    This class comes almost entirely from Eli Bendersky's blog:
	    http://eli.thegreenplace.net/2012/01/04/shared-counter-with-pythons-multiprocessing/
	
	    """"""
	
	    def __init__(self, n = 0):
	        self.count = multiprocessing.Value('i', n)
	
	    def increment(self, n = 1):
	        """""" Increment the counter by n (default = 1) """"""
	        with self.count.get_lock():
	            self.count.value += n
	
	    @property
	    def value(self):
	        """""" Return the value of the counter """"""
	        return self.count.value
	
	
	class Queue(multiprocessing.queues.Queue):
	    """""" A portable implementation of multiprocessing.Queue.
	
	    Because of multithreading / multiprocessing semantics, Queue.qsize() may
	    raise the NotImplementedError exception on Unix platforms like Mac OS X
	    where sem_getvalue() is not implemented. This subclass addresses this
	    problem by using a synchronized shared counter (initialized to zero) and
	    increasing / decreasing its value every time the put() and get() methods
	    are called, respectively. This not only prevents NotImplementedError from
	    being raised, but also allows us to implement a reliable version of both
	    qsize() and empty().
	
	    """"""
	
	    def __init__(self, *args, **kwargs):
	        super(Queue, self).__init__(*args, **kwargs)
	        self.size = SharedCounter(0)
	
	    def put(self, *args, **kwargs):
	        self.size.increment(1)
	        super(Queue, self).put(*args, **kwargs)
	
	    def get(self, *args, **kwargs):
	        self.size.increment(-1)
	        return super(Queue, self).get(*args, **kwargs)
	
	    def qsize(self):
	        """""" Reliable implementation of multiprocessing.Queue.qsize() """"""
	        return self.size.value
	
	    def empty(self):
	        """""" Reliable implementation of multiprocessing.Queue.empty() """"""
	        return not self.qsize()",since old problem found solution project lemon taken subclass queue class order make portable code come class object synchronized counter locking done single process thread may read write object however order python read write second process may read old value new one written first process solution use guarantee atomicity value class come almost entirely self increment self increment counter default property value self return value counter return class queue portable implementation semantics may raise exception like mac o subclass problem synchronized counter zero increasing decreasing value every time put get respectively raised also u implement reliable version empty self super queue self put self super queue self get self return super queue self self reliable implementation return empty self reliable implementation return,issue,positive,positive,positive,positive,positive,positive
461615544,Sorry for the misnomer. We are currently planning to only add a simple architecture at the end of BERT. It's not easy for us to implement NAS on BERT model with GPUs.,sorry misnomer currently add simple architecture end easy u implement model,issue,negative,negative,neutral,neutral,negative,negative
461585787,"@boyuangong can you take look into this issue? Thanks

<sub>Sent with <a href=""http://githawk.com"">GitHawk</a></sub>",take look issue thanks sub sent,issue,negative,positive,positive,positive,positive,positive
461574036,@hemangjoshi37a Feel free to ignore my earlier issue. I think the docker image I mentioned is both a bit out of date and not compiled to use the GPU. I was able to get things running using [`agnz/autokeras`](https://hub.docker.com/r/agnz/autokeras) which is built from nvidia/cuda:10.0-runtime-ubuntu18.04,feel free ignore issue think docker image bit date use able get running built,issue,negative,positive,positive,positive,positive,positive
461561939,"@hemangjoshi37a I tried using the docker container with the following command:
```sh
docker run --runtime=nvidia --rm -it --entrypoint bash -v $PWD/data:/app --shm-size 16G garawalid/autokeras
```

and was able to start an image classifier but there is no GPU utilization (checked via `nvidia-smi`). I'm running this on a specifically built AMI which should connect to the GPU from docker (and has on other projects). Do you know how to get this to run on GPU + docker?",tried docker container following command sh docker run bash able start image classifier utilization checked via running specifically built ami connect docker know get run docker,issue,negative,positive,positive,positive,positive,positive
461510888,"Same error.
It seems to be an issue with multiprocessing and macOS.
`multiprocessing/queues.py in qsize(self)`
`def qsize(self):`
`    # Raises NotImplementedError on Mac OSX because of broken sem_getvalue()`
`--> self._maxsize - self._sem._semlock._get_value()`
`def empty(self):`
![captura de pantalla 2019-02-07 a las 17 59 16](https://user-images.githubusercontent.com/2808425/52428381-1d1ed680-2b02-11e9-9076-5fb0bd4e03f2.png)
",error issue self self mac broken empty self de la,issue,negative,negative,negative,negative,negative,negative
461307806,"I am also interested in this. I am not sure how complicated it would be to implement something similar to BERT, but what about 1D convolutional nets? Something akin to Yoon Kim's CNN (https://arxiv.org/abs/1408.5882)?",also interested sure complicated would implement something similar convolutional something akin kim,issue,positive,positive,neutral,neutral,positive,positive
460078092,issue is still there can you tell me when it will be fixed??,issue still tell fixed,issue,negative,positive,neutral,neutral,positive,positive
459983718,"Hi,
Thanks to @t-wtnb ,  reading again its answer I think what I was missing is the re-train (fit) again.",hi thanks reading answer think missing fit,issue,negative,positive,positive,positive,positive,positive
459776264,"Hi, 
I have the same issue, I tried @t-wtnb  solution but it stills give me different values:

My Code:

```
x_test, y_test = load_image_dataset(csv_file_path=""test/label.csv"", images_path=""test"")

model = pickle_from_file('my_autokeras_model.h5ak')
results = model.evaluate(x_test, y_test)
print(results)

keras_model = load_model('model.h5')
x = keras_model.output
x = Activation('softmax', name='activation_add')(x)
new_model = Model(keras_model.input, x)
new_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
y_test = to_categorical(y_test)
score = new_model.evaluate(x_test, y_test)
print(score)
```

result:
0.7238095238095238
[8.135800362768627, 0.49523809523809526]

which is different .

I will appropriate any help. 
thank you!",hi issue tried solution give different code test model print activation model score print score result different appropriate help thank,issue,positive,positive,positive,positive,positive,positive
459474058,"> @satyakesav You need to solve the conflicts before I merge. Just merge master into your branch, and solve the conflicts, then push to your branch. Thanks.

Done",need solve merge merge master branch solve push branch thanks done,issue,positive,positive,positive,positive,positive,positive
459423155,I'm getting the same issue; it might be a bug.,getting issue might bug,issue,negative,neutral,neutral,neutral,neutral,neutral
459385534,"I am also have this issue, anyone know how to fix it ?

+----------------------------------------------+
|              Training model 23               |
+----------------------------------------------+

No loss decrease after 5 epochs.


Saving model.
+--------------------------------------------------------------------------+
|        Model ID        |          Loss          |      Metric Value      |
+--------------------------------------------------------------------------+
|           23           |   0.8022831022739411   |   0.6621621621621621   |
+--------------------------------------------------------------------------+


+----------------------------------------------+
|              Training model 24               |
+----------------------------------------------+
Epoch-1, Current Metric - 0:   0%|                                        | 0/7 [00:00<?, ? batch/s]Process ForkProcess-25:
Traceback (most recent call last):
  File ""/home/ec2-user/anaconda3/lib/python3.6/multiprocessing/process.py"", line 258, in _bootstrap
    self.run()
  File ""/home/ec2-user/anaconda3/lib/python3.6/multiprocessing/process.py"", line 93, in run
    self._target(*self._args, **self._kwargs)
  File ""/home/ec2-user/anaconda3/lib/python3.6/site-packages/autokeras/search.py"", line 350, in train
    raise e
  File ""/home/ec2-user/anaconda3/lib/python3.6/site-packages/autokeras/search.py"", line 343, in train
    verbose=verbose).train_model(**trainer_args)
  File ""/home/ec2-user/anaconda3/lib/python3.6/site-packages/autokeras/nn/model_trainer.py"", line 137, in train_model
    self._train()
  File ""/home/ec2-user/anaconda3/lib/python3.6/site-packages/autokeras/nn/model_trainer.py"", line 173, in _train
    outputs = self.model(inputs)
  File ""/home/ec2-user/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py"", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File ""/home/ec2-user/anaconda3/lib/python3.6/site-packages/autokeras/nn/graph.py"", line 686, in forward
    temp_tensor = torch_layer(edge_input_tensor)
  File ""/home/ec2-user/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py"", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File ""/home/ec2-user/anaconda3/lib/python3.6/site-packages/torch/nn/modules/conv.py"", line 301, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: Given groups=1, weight of size [1024, 192, 1, 1], expected input[128, 256, 44, 23] to have 192 channels, but got 256 channels instead",also issue anyone know fix training model loss decrease saving model model id loss metric value training model current metric process recent call last file line file line run file line train raise file line train file line file line file line result input file line forward file line result input file line forward given weight size input got instead,issue,negative,neutral,neutral,neutral,neutral,neutral
459230576,"Hi @Hsiny , I hope it could be done before this weekend ;)
Just wait for few moments!",hi hope could done weekend wait,issue,negative,neutral,neutral,neutral,neutral,neutral
459183928,"I really hope resize_image_data() can be parallelized. It tasks a long time to preprocessing.I have 10 cpu cores,while the cpu usage is only 10%.  
",really hope long time usage,issue,negative,positive,neutral,neutral,positive,positive
458788060,"@jhfjhfj1 Requirement already satisfied: autokeras in /usr/local/lib/python3.6/dist-packages (0.3.6)
Requirement already satisfied: nltk==3.3 in /usr/local/lib/python3.6/dist-packages (from autokeras) (3.3)
Requirement already satisfied: requests==2.20.1 in /usr/local/lib/python3.6/dist-packages (from autokeras) (2.20.1)
Requirement already satisfied: scikit-image==0.14.1 in /usr/local/lib/python3.6/dist-packages (from autokeras) (0.14.1)
Requirement already satisfied: tensorflow==1.10.0 in /usr/local/lib/python3.6/dist-packages (from autokeras) (1.10.0)
Requirement already satisfied: librosa==0.6.2 in /usr/local/lib/python3.6/dist-packages (from autokeras) (0.6.2)
Requirement already satisfied: torch==0.4.1 in /usr/local/lib/python3.6/dist-packages (from autokeras) (0.4.1)
Requirement already satisfied: opencv-python==4.0.0.21 in /usr/local/lib/python3.6/dist-packages (from autokeras) (4.0.0.21)
Requirement already satisfied: pandas==0.23.4 in /usr/local/lib/python3.6/dist-packages (from autokeras) (0.23.4)
Requirement already satisfied: imageio==2.4.1 in /usr/local/lib/python3.6/dist-packages (from autokeras) (2.4.1)
Requirement already satisfied: unidecode in /usr/local/lib/python3.6/dist-packages (from autokeras) (1.0.23)
Requirement already satisfied: scipy==1.1.0 in /usr/local/lib/python3.6/dist-packages (from autokeras) (1.1.0)
Requirement already satisfied: numpy==1.15.4 in /usr/local/lib/python3.6/dist-packages (from autokeras) (1.15.4)
Requirement already satisfied: torchvision==0.2.1 in /usr/local/lib/python3.6/dist-packages (from autokeras) (0.2.1)
Requirement already satisfied: lws==1.2 in /usr/local/lib/python3.6/dist-packages (from autokeras) (1.2)
Requirement already satisfied: tqdm==4.29.0 in /usr/local/lib/python3.6/dist-packages (from autokeras) (4.29.0)
Requirement already satisfied: inflect in /usr/local/lib/python3.6/dist-packages (from autokeras) (2.1.0)
Requirement already satisfied: lightgbm==2.2.2 in /usr/local/lib/python3.6/dist-packages (from autokeras) (2.2.2)
Requirement already satisfied: numba in /usr/local/lib/python3.6/dist-packages (from autokeras) (0.40.1)
Requirement already satisfied: scikit-learn==0.20.1 in /usr/local/lib/python3.6/dist-packages (from autokeras) (0.20.1)
Requirement already satisfied: keras==2.2.4 in /usr/local/lib/python3.6/dist-packages (from autokeras) (2.2.4)
Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk==3.3->autokeras) (1.11.0)
Requirement already satisfied: idna<2.8,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests==2.20.1->autokeras) (2.6)
Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.20.1->autokeras) (1.22)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.20.1->autokeras) (3.0.4)
Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.20.1->autokeras) (2018.11.29)
Requirement already satisfied: networkx>=1.8 in /usr/local/lib/python3.6/dist-packages (from scikit-image==0.14.1->autokeras) (2.2)
Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image==0.14.1->autokeras) (3.0.2)
Requirement already satisfied: dask[array]>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image==0.14.1->autokeras) (0.20.2)
Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image==0.14.1->autokeras) (1.0.1)
Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image==0.14.1->autokeras) (5.4.1)
Requirement already satisfied: cloudpickle>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image==0.14.1->autokeras) (0.6.1)
Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0->autokeras) (1.1.0)
Requirement already satisfied: setuptools<=39.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0->autokeras) (39.1.0)
Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0->autokeras) (0.7.1)
Requirement already satisfied: tensorboard<1.11.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0->autokeras) (1.10.0)
Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0->autokeras) (1.15.0)
Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0->autokeras) (0.2.2)
Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0->autokeras) (0.32.3)
Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0->autokeras) (0.7.0)
Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0->autokeras) (3.6.1)
Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.6.2->autokeras) (2.1.6)
Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa==0.6.2->autokeras) (0.13.1)
Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.6.2->autokeras) (4.3.2)
Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.6.2->autokeras) (0.2.1)
Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas==0.23.4->autokeras) (2.5.3)
Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas==0.23.4->autokeras) (2018.9)
Requirement already satisfied: llvmlite>=0.25.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba->autokeras) (0.27.0)
Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->autokeras) (3.13)
Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->autokeras) (1.0.6)
Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->autokeras) (1.0.5)
Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->autokeras) (2.8.0)
Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->scikit-image==0.14.1->autokeras) (0.10.0)
Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->scikit-image==0.14.1->autokeras) (2.3.1)
Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->scikit-image==0.14.1->autokeras) (1.0.1)
Requirement already satisfied: toolz>=0.7.3; extra == ""array"" in /usr/local/lib/python3.6/dist-packages (from dask[array]>=0.9.0->scikit-image==0.14.1->autokeras) (0.9.0)
Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.11.0,>=1.10.0->tensorflow==1.10.0->autokeras) (0.14.1)
Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.11.0,>=1.10.0->tensorflow==1.10.0->autokeras) (3.0.1)

Saving Directory: /tmp/autokeras_FPRYV5
tokenlizing texts...
data readed and convert to 400 length sequences
generating preprocessing model...
loading pretrain weights...
try downloading pre train weights from link http://nlp.stanford.edu/data/glove.6B.zip
file already extracted in the path /tmp/autokeras_store/glove/
Total 400000 word vectors embedded.
generating preprocessing model...
converting text to vector...

Initializing search.
Initialization finished.


+----------------------------------------------+
|               Training model 0               |
+----------------------------------------------+
                                                                                                    
No loss decrease after 5 epochs.


Saving model.
+--------------------------------------------------------------------------+
|        Model ID        |          Loss          |      Metric Value      |
+--------------------------------------------------------------------------+
|           0            |   0.6255926847457886   |          0.7           |
+--------------------------------------------------------------------------+


+----------------------------------------------+
|               Training model 1               |
+----------------------------------------------+
                                                               
No loss decrease after 5 epochs.


Saving model.
+--------------------------------------------------------------------------+
|        Model ID        |          Loss          |      Metric Value      |
+--------------------------------------------------------------------------+
|           1            |   0.6155815839767456   |          0.7           |
+--------------------------------------------------------------------------+


+----------------------------------------------+
|               Training model 2               |
+----------------------------------------------+
                                                               
No loss decrease after 5 epochs.


Saving model.
+--------------------------------------------------------------------------+
|        Model ID        |          Loss          |      Metric Value      |
+--------------------------------------------------------------------------+
|           2            |   0.6602308273315429   |          0.7           |
+--------------------------------------------------------------------------+


+----------------------------------------------+
|               Training model 3               |
+----------------------------------------------+
                                                                                                    
No loss decrease after 5 epochs.


Saving model.
+--------------------------------------------------------------------------+
|        Model ID        |          Loss          |      Metric Value      |
+--------------------------------------------------------------------------+
|           3            |   0.6266433477401734   |          0.7           |
+--------------------------------------------------------------------------+


+----------------------------------------------+
|               Training model 4               |
+----------------------------------------------+
                                                                                                    
No loss decrease after 5 epochs.


Saving model.
+--------------------------------------------------------------------------+
|        Model ID        |          Loss          |      Metric Value      |
+--------------------------------------------------------------------------+
|           4            |   0.6265841841697692   |          0.7           |
+--------------------------------------------------------------------------+


+----------------------------------------------+
|               Training model 5               |
+----------------------------------------------+
                                                                                                    
No loss decrease after 5 epochs.


Saving model.
+--------------------------------------------------------------------------+
|        Model ID        |          Loss          |      Metric Value      |
+--------------------------------------------------------------------------+
|           5            |    0.62655268907547    |          0.7           |
+--------------------------------------------------------------------------+


+----------------------------------------------+
|               Training model 6               |
+----------------------------------------------+
                                                                                                    
No loss decrease after 5 epochs.


Saving model.
+--------------------------------------------------------------------------+
|        Model ID        |          Loss          |      Metric Value      |
+--------------------------------------------------------------------------+
|           6            |   0.6266003966331481   |          0.7           |
+--------------------------------------------------------------------------+


+----------------------------------------------+
|               Training model 7               |
+----------------------------------------------+
                                                                                                    
No loss decrease after 5 epochs.


Saving model.
+--------------------------------------------------------------------------+
|        Model ID        |          Loss          |      Metric Value      |
+--------------------------------------------------------------------------+
|           7            |    0.62654128074646    |          0.7           |
+--------------------------------------------------------------------------+


+----------------------------------------------+
|               Training model 8               |
+----------------------------------------------+
                                                                                                    
No loss decrease after 5 epochs.


Saving model.
+--------------------------------------------------------------------------+
|        Model ID        |          Loss          |      Metric Value      |
+--------------------------------------------------------------------------+
|           8            |   0.6323509812355042   |          0.7           |
+--------------------------------------------------------------------------+


+----------------------------------------------+
|               Training model 9               |
+----------------------------------------------+
                                                                                                    
No loss decrease after 5 epochs.


Saving model.
+--------------------------------------------------------------------------+
|        Model ID        |          Loss          |      Metric Value      |
+--------------------------------------------------------------------------+
|           9            |   0.6324479937553406   |          0.7           |
+--------------------------------------------------------------------------+


+----------------------------------------------+
|              Training model 10               |
+----------------------------------------------+
                                                                                                    
No loss decrease after 5 epochs.


Saving model.
+--------------------------------------------------------------------------+
|        Model ID        |          Loss          |      Metric Value      |
+--------------------------------------------------------------------------+
|           10           |   0.6266794085502625   |          0.7           |
+--------------------------------------------------------------------------+


+----------------------------------------------+
|              Training model 11               |
+----------------------------------------------+
                                                                                                    
No loss decrease after 5 epochs.


Saving model.
+--------------------------------------------------------------------------+
|        Model ID        |          Loss          |      Metric Value      |
+--------------------------------------------------------------------------+
|           11           |   0.6265178203582764   |          0.7           |
+--------------------------------------------------------------------------+


+----------------------------------------------+
|              Training model 12               |
+----------------------------------------------+
                                                                                                    
No loss decrease after 5 epochs.


Saving model.
+--------------------------------------------------------------------------+
|        Model ID        |          Loss          |      Metric Value      |
+--------------------------------------------------------------------------+
|           12           |   0.6275265574455261   |          0.7           |
+--------------------------------------------------------------------------+


+----------------------------------------------+
|              Training model 13               |
+----------------------------------------------+
Epoch-1, Current Metric - 0:   0%|                                        | 0/1 [00:00<?, ? batch/s]

---------------------------------------------------------------------------

RuntimeError                              Traceback (most recent call last)

<ipython-input-8-912e41d7d26f> in <module>()
     36 
     37     clf = TextClassifier(verbose=True)
---> 38 clf.fit(x=x_train, y=y_train, time_limit=6 * 60 * 60)

/usr/local/lib/python3.6/dist-packages/autokeras/text/text_supervised.py in fit(self, x, y, time_limit)
     54         y = np.array(y).flatten()
     55 
---> 56         super().fit(x, y, time_limit)
     57 
     58     def init_transformer(self, x):

/usr/local/lib/python3.6/dist-packages/autokeras/supervised.py in fit(self, x, y, time_limit)
    133             time_limit = 24 * 60 * 60
    134 
--> 135         self.cnn.fit(self.get_n_output_node(), x_train.shape, train_data, test_data, time_limit)
    136 
    137     def final_fit(self, x_train, y_train, x_test, y_test, trainer_args=None, retrain=False):

/usr/local/lib/python3.6/dist-packages/autokeras/net_module.py in fit(self, n_output_node, input_shape, train_data, test_data, time_limit)
     70         try:
     71             while time_remain > 0:
---> 72                 self.searcher.search(train_data, test_data, int(time_remain))
     73                 pickle_to_file(self, os.path.join(self.path, 'module'))
     74                 if len(self.searcher.history) >= Constant.MAX_MODEL_NUM:

/usr/local/lib/python3.6/dist-packages/autokeras/search.py in search(self, train_data, test_data, timeout)
    156         if get_system() == Constant.SYS_GOOGLE_COLAB:
    157             # When using Google Colab, use single process for searching and training.
--> 158             self.sp_search(graph, other_info, model_id, train_data, test_data)
    159         else:
    160             # Use two processes

/usr/local/lib/python3.6/dist-packages/autokeras/search.py in sp_search(self, graph, other_info, model_id, train_data, test_data)
    190         try:
    191             metric_value, loss, graph = train(None, graph, train_data, test_data, self.trainer_args,
--> 192                                               self.metric, self.loss, self.verbose, self.path)
    193             # Do the search in current thread.
    194             search_results = self._search_common()

/usr/local/lib/python3.6/dist-packages/autokeras/search.py in train(q, graph, train_data, test_data, trainer_args, metric, loss, verbose, path)
    348     except RuntimeError as e:
    349         if not re.search('out of memory', str(e)):
--> 350             raise e
    351         if verbose:
    352             print('\nCurrent model size is too big. Discontinuing training this model to search for other models.')

/usr/local/lib/python3.6/dist-packages/autokeras/search.py in train(q, graph, train_data, test_data, trainer_args, metric, loss, verbose, path)
    341                                           metric=metric,
    342                                           loss_function=loss,
--> 343                                           verbose=verbose).train_model(**trainer_args)
    344         model.set_weight_to_graph()
    345         if q:

/usr/local/lib/python3.6/dist-packages/autokeras/nn/model_trainer.py in train_model(self, max_iter_num, max_no_improvement_num, timeout)
    135         for epoch in range(max_iter_num):
    136             self.scheduler.step()
--> 137             self._train()
    138             test_loss, metric_value = self._test()
    139             self.current_metric_value = metric_value

/usr/local/lib/python3.6/dist-packages/autokeras/nn/model_trainer.py in _train(self)
    171             inputs, targets = inputs.to(self.device), targets.to(self.device)
    172             self.optimizer.zero_grad()
--> 173             outputs = self.model(inputs)
    174             loss = self.loss_function(outputs, targets)
    175             loss.backward()

/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    475             result = self._slow_forward(*input, **kwargs)
    476         else:
--> 477             result = self.forward(*input, **kwargs)
    478         for hook in self._forward_hooks.values():
    479             hook_result = hook(self, input, result)

/usr/local/lib/python3.6/dist-packages/autokeras/nn/graph.py in forward(self, input_tensor)
    684                 else:
    685                     edge_input_tensor = node_list[u]
--> 686                 temp_tensor = torch_layer(edge_input_tensor)
    687                 node_list[v] = temp_tensor
    688         return node_list[output_id]

/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    475             result = self._slow_forward(*input, **kwargs)
    476         else:
--> 477             result = self.forward(*input, **kwargs)
    478         for hook in self._forward_hooks.values():
    479             hook_result = hook(self, input, result)

/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py in forward(self, input)
    174     def forward(self, input):
    175         return F.conv1d(input, self.weight, self.bias, self.stride,
--> 176                         self.padding, self.dilation, self.groups)
    177 
    178 

RuntimeError: Given groups=1, weight of size [512, 768, 1], expected input[118, 1024, 100] to have 768 channels, but got 1024 channels instead",requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied inflect requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied six requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied array requirement already satisfied requirement already satisfied pillow requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied astor requirement already satisfied requirement already satisfied requirement already satisfied gast requirement already satisfied wheel requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied decorator requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied dev requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied cycler requirement already satisfied requirement already satisfied requirement already satisfied extra array array requirement already satisfied requirement already satisfied markdown saving directory data convert length generating model loading pretrain try train link file already extracted path total word generating model converting text vector search finished training model loss decrease saving model model id loss metric value training model loss decrease saving model model id loss metric value training model loss decrease saving model model id loss metric value training model loss decrease saving model model id loss metric value training model loss decrease saving model model id loss metric value training model loss decrease saving model model id loss metric value training model loss decrease saving model model id loss metric value training model loss decrease saving model model id loss metric value training model loss decrease saving model model id loss metric value training model loss decrease saving model model id loss metric value training model loss decrease saving model model id loss metric value training model loss decrease saving model model id loss metric value training model loss decrease saving model model id loss metric value training model current metric recent call last module fit self super self fit self self fit self try self search self use single process searching training graph else use two self graph try loss graph train none graph search current thread train graph metric loss verbose path except memory raise verbose print model size big training model search train graph metric loss verbose path self epoch range self loss self input result input else result input hook hook self input result forward self else return self input result input else result input hook hook self input result forward self input forward self input return input given weight size input got instead,issue,positive,positive,positive,positive,positive,positive
458736254,"@satyakesav You need to solve the conflicts before I merge. Just merge master into your branch, and solve the conflicts, then push to your branch. Thanks.",need solve merge merge master branch solve push branch thanks,issue,positive,positive,positive,positive,positive,positive
458735663,@hemanthsavasere This is a duplicated issue of #448 . Should be closed. sorry for the confusion. @boyuangong is working on this.,issue closed sorry confusion working,issue,negative,negative,negative,negative,negative,negative
458719735,"Hi all,

I get a similar error: 

  File ""/home/me/anaconda3/envs/autokeras/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py"", line 156, in _check_input_dim
    .format(input.dim()))
ValueError: expected 2D or 3D input (got 4D input).

I've posted a new thread about this issue, giving more details about the code I used [(here)](https://github.com/jhfjhfj1/autokeras/issues/500)",hi get similar error file line input got input posted new thread issue giving code used,issue,negative,positive,neutral,neutral,positive,positive
458430006,"Hi @jhfjhfj1, I would like to contribute. Is this issue assigned to someone?",hi would like contribute issue assigned someone,issue,negative,neutral,neutral,neutral,neutral,neutral
458376960,"@boyuangong After this pull request is merged, please change all the google drive related constants in constant.py into another format.
First, create a namedtuple (https://pymotw.com/2/collections/namedtuple.html) as GoogleDriveFile(google_id, local_file_name).
Change each pretrained model related constants into a list of GoogleDriveFile.

Reply to this message to confirm you received.
Let me know if you have any questions.

Thanks.",pull request please change drive related another format first create change model related list reply message confirm received let know thanks,issue,positive,positive,positive,positive,positive,positive
457678855,@boyuangong Since we have created the team drive. Please move all the models there. Thanks.,since team drive please move thanks,issue,positive,positive,positive,positive,positive,positive
457581605,"Had same problem when used existing TF conda environment. 
Just create new empty conda environment with python 3.6 :
`conda create -n AutoKeras python=3.6`
and after activating environment use:
 `pip install autokeras`
Everything works after this",problem used environment create new empty environment python create environment use pip install everything work,issue,negative,positive,neutral,neutral,positive,positive
457392807,"I am having the same issue as sj84jozo while attempting to install autokeras on a Mac virtual machine, using Python 3.6.8rc1.  Without having any packages installed before calling ""pip install autokeras"", I am getting the following dependency conflict:

Collecting autokeras
Collecting numpy==1.15.4 (from autokeras)
  Using cached https://files.pythonhosted.org/packages/74/68/2b00ba3c7390354db2a1706291750b6b7e911f6f79c0bd2184ae04f3c6fd/numpy-1.15.4-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl
Collecting tensorflow==1.10.0 (from autokeras)
  Using cached https://files.pythonhosted.org/packages/9d/68/48b43857933875ae0a7a149d1e66dbdbef62a4a571da4c0c88c1311fdb5b/tensorflow-1.10.0-cp36-cp36m-macosx_10_11_x86_64.whl
Collecting lws==1.2 (from autokeras)
  Using cached https://files.pythonhosted.org/packages/3a/c7/856af2e1202e7a4c5102406196aa661edb402256e7ce2334be0c0d8afa2e/lws-1.2.tar.gz
    Complete output from command python setup.py egg_info:
    Traceback (most recent call last):
      File ""<string>"", line 1, in <module>
      File ""/private/var/folders/gr/cv55yf7150sgph146qxjm1nh0000gn/T/pip-install-4vqch6_d/lws/setup.py"", line 2, in <module>
        import numpy as np
    ModuleNotFoundError: No module named 'numpy'
    
    ----------------------------------------
Command ""python setup.py egg_info"" failed with error code 1 in /private/var/folders/gr/cv55yf7150sgph146qxjm1nh0000gn/T/pip-install-4vqch6_d/lws/
(AutoKeras) Joes-MacBook-Pro:AutoKeras joecipolla$ 


Would appreciate any assistance you could give.  Thanks!",issue install mac virtual machine python without calling pip install getting following dependency conflict complete output command python recent call last file string line module file line module import module command python error code would appreciate assistance could give thanks,issue,negative,positive,neutral,neutral,positive,positive
457124314,"Got it. I made the `parallel` argument as an optional one.
And I just found there are other functions that could be parallelized, `compute_image_resize_params` and `resize_image_data`.
@jhfjhfj1, How do you think about parallelizing those functions ?",got made parallel argument optional one found could think,issue,negative,neutral,neutral,neutral,neutral,neutral
456885776,"@Beomi Thank you for your contribution. This is a very nice feature!
However, you need to add one more thing.
A default parameter in the function call to disable the parallel.
def read_images(img_file_names, images_dir_path, parallel=True).
Since many platforms don't support multiprocessing, the program would crash.
Remember to change the docstrings, too.

Thank you!",thank contribution nice feature however need add one thing default parameter function call disable parallel since many support program would crash remember change thank,issue,positive,positive,positive,positive,positive,positive
456839409,"Hi Haifeng,

I have addressed all the comments. Please let me know If you have anymore questions.",hi please let know,issue,negative,neutral,neutral,neutral,neutral,neutral
456832952,"@Mainak431 It is a feature of Python3 instead of a syntax error.
Thanks.",feature python instead syntax error thanks,issue,negative,positive,positive,positive,positive,positive
456831632,"Another pull request is needed for changing all the download into this format, including all the pretrained models. You may ""find usage"" of the original download function to see where to make the changes. Thanks. @boyuangong ",another pull request format may find usage original function see make thanks,issue,positive,positive,positive,positive,positive,positive
456743373,"> import scipy in your code. It will probably solve the error.

Thank you.",import code probably solve error thank,issue,negative,neutral,neutral,neutral,neutral,neutral
456525700,"I also have the same issue.



+----------------------------------------------+
|              Training model 29               |
+----------------------------------------------+
Epoch-1, Current Metric - 0:   0%|                                       | 0/22 [00:00<?, ? batch/s]
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-13-ada35e4aa1db> in <module>()
      1 clf = ImageClassifier(verbose=True, augment=False)
----> 2 clf.fit(X_train, y_train, time_limit = 12 * 60 * 60)
      3 clf.final_fit(X_train, y_train, X_test, y_test, retrain=True)
      4 y = clf.evaluate(X_test, y_test)
      5 

/usr/local/lib/python3.6/dist-packages/autokeras/image/image_supervised.py in fit(self, x, y, time_limit)
    109             print(""Preprocessing finished."")
    110 
--> 111         super().fit(x, y, time_limit)
    112 
    113     def init_transformer(self, x):

/usr/local/lib/python3.6/dist-packages/autokeras/supervised.py in fit(self, x, y, time_limit)
    133             time_limit = 24 * 60 * 60
    134 
--> 135         self.cnn.fit(self.get_n_output_node(), x_train.shape, train_data, test_data, time_limit)
    136 
    137     def final_fit(self, x_train, y_train, x_test, y_test, trainer_args=None, retrain=False):

/usr/local/lib/python3.6/dist-packages/autokeras/net_module.py in fit(self, n_output_node, input_shape, train_data, test_data, time_limit)
     70         try:
     71             while time_remain > 0:
---> 72                 self.searcher.search(train_data, test_data, int(time_remain))
     73                 pickle_to_file(self, os.path.join(self.path, 'module'))
     74                 if len(self.searcher.history) >= Constant.MAX_MODEL_NUM:

/usr/local/lib/python3.6/dist-packages/autokeras/search.py in search(self, train_data, test_data, timeout)
    156         if get_system() == Constant.SYS_GOOGLE_COLAB:
    157             # When using Google Colab, use single process for searching and training.
--> 158             self.sp_search(graph, other_info, model_id, train_data, test_data)
    159         else:
    160             # Use two processes

/usr/local/lib/python3.6/dist-packages/autokeras/search.py in sp_search(self, graph, other_info, model_id, train_data, test_data)
    190         try:
    191             metric_value, loss, graph = train(None, graph, train_data, test_data, self.trainer_args,
--> 192                                               self.metric, self.loss, self.verbose, self.path)
    193             # Do the search in current thread.
    194             search_results = self._search_common()

/usr/local/lib/python3.6/dist-packages/autokeras/search.py in train(q, graph, train_data, test_data, trainer_args, metric, loss, verbose, path)
    348     except RuntimeError as e:
    349         if not re.search('out of memory', str(e)):
--> 350             raise e
    351         if verbose:
    352             print('\nCurrent model size is too big. Discontinuing training this model to search for other models.')

/usr/local/lib/python3.6/dist-packages/autokeras/search.py in train(q, graph, train_data, test_data, trainer_args, metric, loss, verbose, path)
    341                                           metric=metric,
    342                                           loss_function=loss,
--> 343                                           verbose=verbose).train_model(**trainer_args)
    344         model.set_weight_to_graph()
    345         if q:

/usr/local/lib/python3.6/dist-packages/autokeras/nn/model_trainer.py in train_model(self, max_iter_num, max_no_improvement_num, timeout)
    135         for epoch in range(max_iter_num):
    136             self.scheduler.step()
--> 137             self._train()
    138             test_loss, metric_value = self._test()
    139             self.current_metric_value = metric_value

/usr/local/lib/python3.6/dist-packages/autokeras/nn/model_trainer.py in _train(self)
    171             inputs, targets = inputs.to(self.device), targets.to(self.device)
    172             self.optimizer.zero_grad()
--> 173             outputs = self.model(inputs)
    174             loss = self.loss_function(outputs, targets)
    175             loss.backward()

/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    475             result = self._slow_forward(*input, **kwargs)
    476         else:
--> 477             result = self.forward(*input, **kwargs)
    478         for hook in self._forward_hooks.values():
    479             hook_result = hook(self, input, result)

/usr/local/lib/python3.6/dist-packages/autokeras/nn/graph.py in forward(self, input_tensor)
    684                 else:
    685                     edge_input_tensor = node_list[u]
--> 686                 temp_tensor = torch_layer(edge_input_tensor)
    687                 node_list[v] = temp_tensor
    688         return node_list[output_id]

/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    475             result = self._slow_forward(*input, **kwargs)
    476         else:
--> 477             result = self.forward(*input, **kwargs)
    478         for hook in self._forward_hooks.values():
    479             hook_result = hook(self, input, result)

/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py in forward(self, input)
    299     def forward(self, input):
    300         return F.conv2d(input, self.weight, self.bias, self.stride,
--> 301                         self.padding, self.dilation, self.groups)
    302 
    303 

RuntimeError: Given groups=1, weight of size [64, 76, 1, 1], expected input[128, 80, 26, 26] to have 76 channels, but got 80 channels instead",also issue training model current metric recent call last module fit self print finished super self fit self self fit self try self search self use single process searching training graph else use two self graph try loss graph train none graph search current thread train graph metric loss verbose path except memory raise verbose print model size big training model search train graph metric loss verbose path self epoch range self loss self input result input else result input hook hook self input result forward self else return self input result input else result input hook hook self input result forward self input forward self input return input given weight size input got instead,issue,negative,positive,positive,positive,positive,positive
456159944,"Try brew install libomp.
Install the latest version of Auto-Keras.
If it still doesn't work, please reopen the issue.",try brew install install latest version still work please reopen issue,issue,negative,positive,positive,positive,positive,positive
455872151,"I believe this is solved. If you still have this bug, please reopen this issue. Thanks.",believe still bug please reopen issue thanks,issue,positive,positive,positive,positive,positive,positive
455872007,"@francotheengineer Yes, we are happy to see them made into Jupyter Notebooks. We would appreciate if you can help us do it. Thanks.",yes happy see made would appreciate help u thanks,issue,positive,positive,positive,positive,positive,positive
455871193,"@jhfjhfj1  Hi, maybe some of the more basic tutorials can be made into Jupyter Notebooks as it might help new users? - I'm happy to write some in the style TF does (https://www.tensorflow.org/hub/tutorials/image_retraining) Thanks",hi maybe basic made might help new happy write style thanks,issue,positive,positive,positive,positive,positive,positive
455821951,I don't see this functionality in the latest version. Was it taken out again for some reason? @jhfjhfj1 ,see functionality latest version taken reason,issue,negative,positive,positive,positive,positive,positive
455813511,import scipy in your code. It will probably solve the error.,import code probably solve error,issue,negative,neutral,neutral,neutral,neutral,neutral
455813317,Try to directly install Autokeras container in docker in your AWS instance. It will automatically handle all the requirements.,try directly install container docker instance automatically handle,issue,negative,positive,neutral,neutral,positive,positive
455813279,100Mb is not big. Your phone will handle it fine. By the way which mobile do you have??,big phone handle fine way mobile,issue,negative,positive,positive,positive,positive,positive
455813195,Upgrade all pip packages will solve the problem.,upgrade pip solve problem,issue,negative,neutral,neutral,neutral,neutral,neutral
455797780,"It will be added in the future.
GAN is very hard to train for non-experts.
We are trying to automate it as much as possible.
Finally, it would only require the data to train a GAN.
Thanks.",added future gan hard train trying much possible finally would require data train gan thanks,issue,negative,negative,neutral,neutral,negative,negative
455797664,"We will be supporting any size image in the future.
Currently, we don't have an upper limit.
Only a lower limit which is image still larger than 1 after three pooling layers with stride 2.",supporting size image future currently upper limit lower limit image still three stride,issue,negative,positive,neutral,neutral,positive,positive
455797421,"It is not possible to export the entire data pipeline to a Keras model.
Only the neural network is exported.
Without the data preprocessing, the Keras model won't perform well.",possible export entire data pipeline model neural network without data model wo perform well,issue,negative,neutral,neutral,neutral,neutral,neutral
455797183,"I think this is fixed in the latest version.
Feel free to reopen if it is not.

Thanks.",think fixed latest version feel free reopen thanks,issue,positive,positive,positive,positive,positive,positive
455797012,"Currently, it is not supported.
However, you can implement your own loss function and pass it to the CnnModule.
Thanks.",currently however implement loss function pas thanks,issue,negative,positive,neutral,neutral,positive,positive
455796930,This issue is fixed in the latest version. Thanks.,issue fixed latest version thanks,issue,negative,positive,positive,positive,positive,positive
455796891,"This issue is fixed with the latest version.
Please refer tot he tutorial.
https://autokeras.com/start/#automated-text-classifier-tutorial",issue fixed latest version please refer tot tutorial,issue,negative,positive,positive,positive,positive,positive
455796769,@tl-yang I think we also need a tutorial just for selecting single and multiple GPUs in additional to the colab tutorial.,think also need tutorial single multiple additional tutorial,issue,negative,negative,neutral,neutral,negative,negative
455581135,We set different limits of epochs to the search phase and the final training phase. Thanks.,set different search phase final training phase thanks,issue,negative,positive,neutral,neutral,positive,positive
455580687,We are getting rid of GPUtil now. It should work find now. Thanks.,getting rid work find thanks,issue,negative,positive,positive,positive,positive,positive
455580384,This is fixed in the latest version. Thanks.,fixed latest version thanks,issue,negative,positive,positive,positive,positive,positive
455579803,This is resolved in the current version. Thanks.,resolved current version thanks,issue,positive,positive,neutral,neutral,positive,positive
455579115,We are not aiming to support it in short term. Thanks.,aiming support short term thanks,issue,positive,positive,neutral,neutral,positive,positive
455578853,"> Having a same problem
> 
> Is this error cause by #26 ?

That issue is already fixed, it won't cause a bus error.
Were you using the latest version?

Thanks.",problem error cause issue already fixed wo cause bus error latest version thanks,issue,negative,positive,positive,positive,positive,positive
455576355,"If you want to use this feature, you need to preprocess your data and call the CnnModule instead of ImageClassifier. During you pack your pytorch datasets, you need to implement the batch loading. Thanks.",want use feature need data call instead pack need implement batch loading thanks,issue,negative,positive,positive,positive,positive,positive
455575710,@tl-yang Is there a colab tutorial or example now? Can we put it on start.md? Thanks.,tutorial example put thanks,issue,negative,positive,positive,positive,positive,positive
455574916,I believe this issue is solved. Feel free to reopen if still exists.,believe issue feel free reopen still,issue,positive,positive,positive,positive,positive,positive
455518674,"## Pull Request Test Coverage Report for [Build 1394](https://coveralls.io/builds/21149871)

* **0** of **0**   changed or added relevant lines in **0** files are covered.
* **1** unchanged line in **1** file lost coverage.
* Overall coverage remained the same at **94.746%**

---


|  Files with Coverage Reduction | New Missed Lines | % |
| :-----|--------------|--: |
| [autokeras/nn/model_trainer.py](https://coveralls.io/builds/21149871/source?filename=autokeras%2Fnn%2Fmodel_trainer.py#L413) | 1 | 91.94% |
<!-- | **Total:** | **1** |  | -->

|  Totals | [![Coverage Status](https://coveralls.io/builds/21149871/badge)](https://coveralls.io/builds/21149871) |
| :-- | --: |
| Change from base [Build 1392](https://coveralls.io/builds/21145375): |  0.0% |
| Covered Lines: | 4382 |
| Relevant Lines: | 4625 |

---
##### 💛  - [Coveralls](https://coveralls.io)
",pull request test coverage report build added relevant covered unchanged line file lost coverage overall coverage coverage reduction new total coverage status change base build covered relevant coverall,issue,negative,positive,neutral,neutral,positive,positive
455321183,"## Pull Request Test Coverage Report for [Build 1391](https://coveralls.io/builds/21137205)

* **2** of **10**   **(20.0%)**  changed or added relevant lines in **1** file are covered.
* **7** unchanged lines in **3** files lost coverage.
* Overall coverage decreased (**-0.3%**) to **94.455%**

---

|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |
| :-----|--------------|--------|---: |
| [autokeras/search.py](https://coveralls.io/builds/21137205/source?filename=autokeras%2Fsearch.py#L189) | 2 | 10 | 20.0%
<!-- | **Total:** | **2** | **10** | **20.0%** | -->

|  Files with Coverage Reduction | New Missed Lines | % |
| :-----|--------------|--: |
| [autokeras/net_transformer.py](https://coveralls.io/builds/21137205/source?filename=autokeras%2Fnet_transformer.py#L68) | 1 | 96.43% |
| [autokeras/nn/graph.py](https://coveralls.io/builds/21137205/source?filename=autokeras%2Fnn%2Fgraph.py#L361) | 2 | 97.45% |
| [autokeras/nn/layer_transformer.py](https://coveralls.io/builds/21137205/source?filename=autokeras%2Fnn%2Flayer_transformer.py#L135) | 4 | 96.08% |
<!-- | **Total:** | **7** |  | -->

|  Totals | [![Coverage Status](https://coveralls.io/builds/21137205/badge)](https://coveralls.io/builds/21137205) |
| :-- | --: |
| Change from base [Build 1387](https://coveralls.io/builds/21112562): |  -0.3% |
| Covered Lines: | 4378 |
| Relevant Lines: | 4635 |

---
##### 💛  - [Coveralls](https://coveralls.io)
",pull request test coverage report build added relevant file covered unchanged lost coverage overall coverage missing coverage covered total coverage reduction new total coverage status change base build covered relevant coverall,issue,negative,negative,neutral,neutral,negative,negative
455278050,"## Pull Request Test Coverage Report for [Build 1389](https://coveralls.io/builds/21135098)

* **0** of **0**   changed or added relevant lines in **0** files are covered.
* **5** unchanged lines in **3** files lost coverage.
* Overall coverage decreased (**-0.1%**) to **94.659%**

---


|  Files with Coverage Reduction | New Missed Lines | % |
| :-----|--------------|--: |
| [autokeras/nn/graph.py](https://coveralls.io/builds/21135098/source?filename=autokeras%2Fnn%2Fgraph.py#L361) | 1 | 97.66% |
| [autokeras/nn/layers.py](https://coveralls.io/builds/21135098/source?filename=autokeras%2Fnn%2Flayers.py#L88) | 2 | 95.0% |
| [autokeras/net_transformer.py](https://coveralls.io/builds/21135098/source?filename=autokeras%2Fnet_transformer.py#L56) | 2 | 95.24% |
<!-- | **Total:** | **5** |  | -->

|  Totals | [![Coverage Status](https://coveralls.io/builds/21135098/badge)](https://coveralls.io/builds/21135098) |
| :-- | --: |
| Change from base [Build 1387](https://coveralls.io/builds/21112562): |  -0.1% |
| Covered Lines: | 4378 |
| Relevant Lines: | 4625 |

---
##### 💛  - [Coveralls](https://coveralls.io)
",pull request test coverage report build added relevant covered unchanged lost coverage overall coverage coverage reduction new total coverage status change base build covered relevant coverall,issue,negative,positive,neutral,neutral,positive,positive
455114136,"linux cpu:2 memory:2g 
python file:![image](https://user-images.githubusercontent.com/6300447/51310594-f67cfb00-1a81-11e9-9747-4acce76d42dc.png)
voice file:[test_0 (2).zip](https://github.com/jhfjhfj1/autokeras/files/2768083/test_0.2.zip)

",memory python file image voice file,issue,negative,neutral,neutral,neutral,neutral,neutral
455064278,"Please specify your environment and your script so that we can repeat. Also, we cannot make sure that every text can be converted to 100% accurate and clear. That's the limitation of the current model [deep voice  3](https://arxiv.org/pdf/1710.07654.pdf). Please feel free to let me know if you have any questions. ",please specify environment script repeat also make sure every text converted accurate clear limitation current model deep voice please feel free let know,issue,positive,positive,positive,positive,positive,positive
455060047,"Hi there, thanks for your interest to our package! We are currently working on the voice to text model. The voice generation model is only for text to voice(.wav file). ",hi thanks interest package currently working voice text model voice generation model text voice file,issue,positive,positive,neutral,neutral,positive,positive
455024041,"> @PeterHuang2015 Thank you for your contribution.
> It seems the CI is not passed.
> Please fix it before I can merge.
> Thanks.

THX for the correction!",thank contribution please fix merge thanks correction,issue,positive,positive,positive,positive,positive,positive
454868275,"## Pull Request Test Coverage Report for [Build 1386](https://coveralls.io/builds/21110690)

* **9** of **9**   **(100.0%)**  changed or added relevant lines in **1** file are covered.
* **13** unchanged lines in **6** files lost coverage.
* Overall coverage decreased (**-0.2%**) to **94.53%**

---


|  Files with Coverage Reduction | New Missed Lines | % |
| :-----|--------------|--: |
| [autokeras/nn/layers.py](https://coveralls.io/builds/21110690/source?filename=autokeras%2Fnn%2Flayers.py#L205) | 1 | 95.31% |
| [autokeras/pretrained/voice_generator/deepvoice3_pytorch/modules.py](https://coveralls.io/builds/21110690/source?filename=autokeras%2Fpretrained%2Fvoice_generator%2Fdeepvoice3_pytorch%2Fmodules.py#L105) | 1 | 98.72% |
| [autokeras/nn/graph.py](https://coveralls.io/builds/21110690/source?filename=autokeras%2Fnn%2Fgraph.py#L375) | 1 | 97.45% |
| [autokeras/pretrained/voice_generator/voice_generator.py](https://coveralls.io/builds/21110690/source?filename=autokeras%2Fpretrained%2Fvoice_generator%2Fvoice_generator.py#L194) | 3 | 98.09% |
| [autokeras/net_transformer.py](https://coveralls.io/builds/21110690/source?filename=autokeras%2Fnet_transformer.py#L56) | 3 | 92.86% |
| [autokeras/nn/layer_transformer.py](https://coveralls.io/builds/21110690/source?filename=autokeras%2Fnn%2Flayer_transformer.py#L135) | 4 | 96.08% |
<!-- | **Total:** | **13** |  | -->

|  Totals | [![Coverage Status](https://coveralls.io/builds/21110690/badge)](https://coveralls.io/builds/21110690) |
| :-- | --: |
| Change from base [Build 1375](https://coveralls.io/builds/21090395): |  -0.2% |
| Covered Lines: | 4372 |
| Relevant Lines: | 4625 |

---
##### 💛  - [Coveralls](https://coveralls.io)
",pull request test coverage report build added relevant file covered unchanged lost coverage overall coverage coverage reduction new total coverage status change base build covered relevant coverall,issue,negative,positive,neutral,neutral,positive,positive
454852258,"Q2: 
In my experience, `export CUDA_VISIBLE_DEVICES=0` is the best way to prevent your terminal from seeing the other GPUs. 
This code also has some functionality to do the same within python:
```
os.environ[""CUDA_DEVICE_ORDER""]=""PCI_BUS_ID""   # see issue #152
os.environ[""CUDA_VISIBLE_DEVICES""]=str(<gpu number>)
```
You could parse <gpu number> from arg parse or alike. ",experience export best way prevent terminal seeing code also functionality within python see issue number could parse number parse alike,issue,positive,positive,positive,positive,positive,positive
454819822,"@minda163 You are using the latest release instead of the latest master.
We are drafting a new release now.
You may use pip install tomorrow to try again.
In this version, we fixed some bugs in the MLP module.

Thanks.",latest release instead latest master drafting new release may use pip install tomorrow try version fixed module thanks,issue,negative,positive,positive,positive,positive,positive
454819345,"## Pull Request Test Coverage Report for [Build 1380](https://coveralls.io/builds/21107952)

* **183** of **185**   **(98.92%)**  changed or added relevant lines in **5** files are covered.
* **8** unchanged lines in **5** files lost coverage.
* Overall coverage decreased (**-0.2%**) to **94.573%**

---

|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |
| :-----|--------------|--------|---: |
| [autokeras/pretrained/voice_generator/deepvoice3_pytorch/modules.py](https://coveralls.io/builds/21107952/source?filename=autokeras%2Fpretrained%2Fvoice_generator%2Fdeepvoice3_pytorch%2Fmodules.py#L105) | 12 | 13 | 92.31%
| [autokeras/pretrained/voice_generator/voice_generator.py](https://coveralls.io/builds/21107952/source?filename=autokeras%2Fpretrained%2Fvoice_generator%2Fvoice_generator.py#L194) | 129 | 130 | 99.23%
<!-- | **Total:** | **183** | **185** | **98.92%** | -->

|  Files with Coverage Reduction | New Missed Lines | % |
| :-----|--------------|--: |
| [autokeras/nn/layers.py](https://coveralls.io/builds/21107952/source?filename=autokeras%2Fnn%2Flayers.py#L205) | 1 | 95.31% |
| [autokeras/nn/model_trainer.py](https://coveralls.io/builds/21107952/source?filename=autokeras%2Fnn%2Fmodel_trainer.py#L199) | 1 | 91.94% |
| [autokeras/net_transformer.py](https://coveralls.io/builds/21107952/source?filename=autokeras%2Fnet_transformer.py#L68) | 1 | 95.24% |
| [autokeras/nn/graph.py](https://coveralls.io/builds/21107952/source?filename=autokeras%2Fnn%2Fgraph.py#L375) | 1 | 97.45% |
| [autokeras/nn/layer_transformer.py](https://coveralls.io/builds/21107952/source?filename=autokeras%2Fnn%2Flayer_transformer.py#L135) | 4 | 96.08% |
<!-- | **Total:** | **8** |  | -->

|  Totals | [![Coverage Status](https://coveralls.io/builds/21107952/badge)](https://coveralls.io/builds/21107952) |
| :-- | --: |
| Change from base [Build 1375](https://coveralls.io/builds/21090395): |  -0.2% |
| Covered Lines: | 4374 |
| Relevant Lines: | 4625 |

---
##### 💛  - [Coveralls](https://coveralls.io)
",pull request test coverage report build added relevant covered unchanged lost coverage overall coverage missing coverage covered total coverage reduction new total coverage status change base build covered relevant coverall,issue,negative,negative,neutral,neutral,negative,negative
454810470,"Inspiration: Microsoft's [nni](https://github.com/Microsoft/nni), an AutoML toolkit for neural architecture search, already supports [sequential](https://github.com/Microsoft/nni/search?q=sequential&unscoped_q=sequential) models. ",inspiration neural architecture search already sequential,issue,positive,neutral,neutral,neutral,neutral,neutral
454804983,"@PeterHuang2015 Thank you for your contribution.
It seems the CI is not passed.
Please fix it before I can merge.
Thanks.",thank contribution please fix merge thanks,issue,positive,positive,positive,positive,positive,positive
454788165,"Hey i have the same Problem. @JasonKitty  how should I call the enviroment variable

",hey problem call variable,issue,negative,neutral,neutral,neutral,neutral,neutral
454645583,"Thank you man.

On Tue, Jan 15, 2019, 11:34 PM Franco <notifications@github.com> wrote:

> No released yet.
> https://medium.com/tensorflow/standardizing-on-keras-guidance-on-high-level-apis-in-tensorflow-2-0-bad2b04c819a
>
> —
> You are receiving this because you authored the thread.
>
>
> Reply to this email directly, view it on GitHub
> <https://github.com/jhfjhfj1/autokeras/issues/377#issuecomment-454491044>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL0Xme-VG9n_JwyT6xheCTI0aXlCPlCLks5vDhgdgaJpZM4ZU2Wh>
> .
>
-- 

Regards,
Hemang Joshi
",thank man tue franco wrote yet thread reply directly view mute thread joshi,issue,negative,positive,neutral,neutral,positive,positive
454643343,"@jhfjhfj1 
I installed autokeras yesterday , used ""pip install autokeras'',it shoud be the latest master branch.
![image](https://user-images.githubusercontent.com/33540791/51225288-d0256580-1984-11e9-8b89-1738a1210e7d.png)
",yesterday used pip install latest master branch image,issue,negative,positive,positive,positive,positive,positive
454637399,"Can you try with the latest master branch? If it still fails, we will look into it. Thank you!",try latest master branch still look thank,issue,negative,positive,positive,positive,positive,positive
454481744,"Ohh okay. Can you please give me any link to TF2.0??

On Tue, Jan 15, 2019, 10:55 PM Franco <notifications@github.com> wrote:

> I can only assume this is because TF Slim is being deprecated in TF2.0 in
> favour of Keras.
>
> —
> You are receiving this because you authored the thread.
>
>
> Reply to this email directly, view it on GitHub
> <https://github.com/jhfjhfj1/autokeras/issues/377#issuecomment-454477606>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL0XmYDK-Erh-uIek7MpzGsdnwhCtM2Gks5vDg8bgaJpZM4ZU2Wh>
> .
>
-- 

Regards,
Hemang Joshi
",please give link tue franco wrote assume slim thread reply directly view mute thread joshi,issue,negative,positive,neutral,neutral,positive,positive
454238917,"@jhfjhfj1 The reason behind this bug is that we were trying to normalize the input tensor using the `Normalize()` transform which expects the input tensor to be an image in the form of `CxHxW` (three dimensional). But in MLP, the input tensor is 1D - so we have to rethink the way we normalize the tensor. I have normalized the input numpy array using numpy's functions and then converted it into a tensor. ",reason behind bug trying normalize input tensor normalize transform input tensor image form three dimensional input tensor rethink way normalize tensor input array converted tensor,issue,negative,negative,negative,negative,negative,negative
454220146,"I am also experiencing this issue.
```
+----------------------------------------------+
|              Training model 163              |
+----------------------------------------------+
Epoch-1, Current Metric - 0:   0%|                                        | 0/6 [00:00<?, ? batch/s]Process SpawnProcess-1:
Traceback (most recent call last):
  File ""/usr/lib/python3.6/multiprocessing/process.py"", line 258, in _bootstrap
    self.run()
  File ""/usr/lib/python3.6/multiprocessing/process.py"", line 93, in run
    self._target(*self._args, **self._kwargs)
  File ""/home/zane/workspace/prediction/lib/python3.6/site-packages/autokeras/search.py"", line 277, in train
    raise e
  File ""/home/zane/workspace/prediction/lib/python3.6/site-packages/autokeras/search.py"", line 270, in train
    verbose=verbose).train_model(**trainer_args)
  File ""/home/zane/workspace/prediction/lib/python3.6/site-packages/autokeras/nn/model_trainer.py"", line 126, in train_model
    self._train()
  File ""/home/zane/workspace/prediction/lib/python3.6/site-packages/autokeras/nn/model_trainer.py"", line 160, in _train
    outputs = self.model(inputs)
  File ""/home/zane/workspace/prediction/lib/python3.6/site-packages/torch/nn/modules/module.py"", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File ""/home/zane/workspace/prediction/lib/python3.6/site-packages/autokeras/nn/graph.py"", line 681, in forward
    temp_tensor = torch_layer(edge_input_tensor)
  File ""/home/zane/workspace/prediction/lib/python3.6/site-packages/torch/nn/modules/module.py"", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File ""/home/zane/workspace/prediction/lib/python3.6/site-packages/torch/nn/modules/conv.py"", line 176, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: Given groups=1, weight of size [64, 192, 1], expected input[256, 256, 8] to have 192 channels, but got 256 channels instead
```",also issue training model current metric process recent call last file line file line run file line train raise file line train file line file line file line result input file line forward file line result input file line forward given weight size input got instead,issue,negative,neutral,neutral,neutral,neutral,neutral
453897025,"This is already supported. Simply specify output path parameter when instantiating the classifier and set resume parameter to true, e.g. `ak.ImageClassifier(path='output',verbose=True,augment=True,resume=True)`

Training will restart from last model where it was interrupted.",already simply specify output path parameter classifier set resume parameter true training restart last model interrupted,issue,negative,positive,positive,positive,positive,positive
453810585,"I have the same issue. 

This is my code. Almost same as example.

`from keras.datasets import mnist
from autokeras import ImageClassifier

if __name__ == '__main__':
    (x_train, y_train), (x_test, y_test) = mnist.load_data()
    x_train = x_train.reshape(x_train.shape + (1,))
    x_test = x_test.reshape(x_test.shape + (1,))

    clf = ImageClassifier(verbose=True, augment=False)
    clf.fit(x_train, y_train, time_limit=12 * 60 * 60)
    clf.final_fit(x_train, y_train, x_test, y_test, retrain=True)
    y = clf.evaluate(x_test, y_test)
    print(y * 100)`

Error message:

> Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz
11493376/11490434 [==============================] - 15s 1us/stepETA: 15s - ETA: 12s - ETA: 10s - ETA: 10s 4243456/11490434 [==========>...................] - ETA: 9s 5046272/11490434 [============>.................] - ETA: 8s - ETA: 8s - ETA: 7s - ETA: 7s - ETA: 5s 7831552/11490434 [===================>..........] - ETA: 4s - ETA: 3s - ETA: 2s 9658368/11490434 [========================>.....] - ETA: 2s - ETA: 2s - ETA: 1s - ETA: 1s - ETA: 1s - ETA: 0s
Preprocessing the images.
Preprocessing finished.

Initializing search.
Initialization finished.


+----------------------------------------------+
|               Training model 0               |
+----------------------------------------------+
Traceback (most recent call last):

  File ""<ipython-input-4-462cd77ad5a2>"", line 1, in <module>
    runfile('E:/tm/mutlu_tm/tm_scrape/MNIST_autokeras.py', wdir='E:/tm/mutlu_tm/tm_scrape')

  File ""C:\Anaconda\envs\tf_gpu\lib\site-packages\spyder_kernels\customize\spydercustomize.py"", line 704, in runfile
    execfile(filename, namespace)

  File ""C:\Anaconda\envs\tf_gpu\lib\site-packages\spyder_kernels\customize\spydercustomize.py"", line 108, in execfile
    exec(compile(f.read(), filename, 'exec'), namespace)

  File ""E:/tm/mutlu_tm/tm_scrape/MNIST_autokeras.py"", line 17, in <module>
    clf.fit(x_train, y_train, time_limit=12 * 60 * 60)

  File ""C:\Anaconda\envs\tf_gpu\lib\site-packages\autokeras\image\image_supervised.py"", line 114, in fit
    super().fit(x, y, time_limit)

  File ""C:\Anaconda\envs\tf_gpu\lib\site-packages\autokeras\supervised.py"", line 129, in fit
    self.cnn.fit(self.get_n_output_node(), x_train.shape, train_data, test_data, time_limit)

  File ""C:\Anaconda\envs\tf_gpu\lib\site-packages\autokeras\net_module.py"", line 65, in fit
    self.searcher.search(train_data, test_data, int(time_remain))

  File ""C:\Anaconda\envs\tf_gpu\lib\site-packages\autokeras\search.py"", line 222, in search
    p.terminate()

  File ""C:\Anaconda\envs\tf_gpu\lib\multiprocessing\process.py"", line 116, in terminate
    self._popen.terminate()

AttributeError: 'NoneType' object has no attribute 'terminate'


Setup Details

OS type and version: Windows 8.1 Pro
Python: 3.6.8
autokeras: 0.3.5
scikit-learn: 0.20.1
numpy: 1.14.5 <pip>, 1.15.4 py36h19fb1c0_0
keras: 2.2.4 <0>, 2.2.2 <pip>
scipy: 1.1.0
tensorflow: 1.10.0
pytorch: 0.4.1

I am using conda virtual env and spyder to run the code.",issue code almost example import import print error message data eta eta eta eta eta eta eta eta eta eta eta eta eta eta eta eta eta eta finished search finished training model recent call last file line module file line file line compile file line module file line fit super file line fit file line fit file line search file line terminate object attribute setup o type version pro python pip pip virtual run code,issue,positive,positive,positive,positive,positive,positive
453809556,"## Pull Request Test Coverage Report for [Build 1361](https://coveralls.io/builds/21045438)

* **1** of **1**   **(100.0%)**  changed or added relevant line in **1** file are covered.
* **5** unchanged lines in **3** files lost coverage.
* Overall coverage decreased (**-0.06%**) to **94.524%**

---


|  Files with Coverage Reduction | New Missed Lines | % |
| :-----|--------------|--: |
| [autokeras/nn/model_trainer.py](https://coveralls.io/builds/21045438/source?filename=autokeras%2Fnn%2Fmodel_trainer.py#L199) | 1 | 92.42% |
| [autokeras/nn/graph.py](https://coveralls.io/builds/21045438/source?filename=autokeras%2Fnn%2Fgraph.py#L379) | 1 | 97.23% |
| [autokeras/nn/layer_transformer.py](https://coveralls.io/builds/21045438/source?filename=autokeras%2Fnn%2Flayer_transformer.py#L158) | 3 | 93.14% |
<!-- | **Total:** | **5** |  | -->

|  Totals | [![Coverage Status](https://coveralls.io/builds/21045438/badge)](https://coveralls.io/builds/21045438) |
| :-- | --: |
| Change from base [Build 1360](https://coveralls.io/builds/21037934): |  -0.06% |
| Covered Lines: | 4402 |
| Relevant Lines: | 4657 |

---
##### 💛  - [Coveralls](https://coveralls.io)
",pull request test coverage report build added relevant line file covered unchanged lost coverage overall coverage coverage reduction new total coverage status change base build covered relevant coverall,issue,negative,positive,neutral,neutral,positive,positive
453753998,Maybe you can try to create a virtual enviorment or use anaconda to get a pure enviorment.,maybe try create virtual use anaconda get pure,issue,negative,positive,positive,positive,positive,positive
452755440,"Sorry, I am confused about the final resolution. Is it changing the Google Colab Notes to single process or was there a change in the source code. Also, can you please post steps to disable multi-processing?",sorry confused final resolution single process change source code also please post disable,issue,negative,negative,negative,negative,negative,negative
452669756,"I have similar errors.
`+----------------------------------------------+
|               Training model 1               |
+----------------------------------------------+
/Users/liuuuche/.virtualenv3/lib/python3.6/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.1) compiler.
This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.
Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.
You can install the OpenMP library by the following command: ``brew install libomp``.
  ""You can install the OpenMP library by the following command: ``brew install libomp``."", UserWarning)
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/Users/liuuuche/.virtualenv3/lib/python3.6/site-packages/autokeras/image/image_supervised.py"", line 114, in fit
    super().fit(x, y, time_limit)
  File ""/Users/liuuuche/.virtualenv3/lib/python3.6/site-packages/autokeras/supervised.py"", line 129, in fit
    self.cnn.fit(self.get_n_output_node(), x_train.shape, train_data, test_data, time_limit)
  File ""/Users/liuuuche/.virtualenv3/lib/python3.6/site-packages/autokeras/net_module.py"", line 65, in fit
    self.searcher.search(train_data, test_data, int(time_remain))
  File ""/Users/liuuuche/.virtualenv3/lib/python3.6/site-packages/autokeras/search.py"", line 200, in search
    generated_other_info, generated_graph = self.generate(remaining_time, q)
  File ""/Users/liuuuche/.virtualenv3/lib/python3.6/site-packages/autokeras/search.py"", line 251, in generate
    remaining_time, multiprocessing_queue)
  File ""/Users/liuuuche/.virtualenv3/lib/python3.6/site-packages/autokeras/bayesian.py"", line 350, in generate
    if multiprocessing_queue.qsize() != 0:
  File ""/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py"", line 117, in qsize
    return self._maxsize - self._sem._semlock._get_value()
NotImplementedError`",similar training model starting version library file distribution built apple clang compiler case via pip install command need install compiler instead need install library running system apple clang compiler install library following command brew install install library following command brew install recent call last file line module file line fit super file line fit file line fit file line search file line generate file line generate file line return,issue,positive,positive,positive,positive,positive,positive
452666529,"## Pull Request Test Coverage Report for [Build 1314](https://coveralls.io/builds/20979239)

* **0** of **0**   changed or added relevant lines in **0** files are covered.
* No unchanged relevant lines lost coverage.
* Overall coverage remained the same at **94.553%**

---



|  Totals | [![Coverage Status](https://coveralls.io/builds/20979239/badge)](https://coveralls.io/builds/20979239) |
| :-- | --: |
| Change from base [Build 1308](https://coveralls.io/builds/20976308): |  0.0% |
| Covered Lines: | 4340 |
| Relevant Lines: | 4590 |

---
##### 💛  - [Coveralls](https://coveralls.io)
",pull request test coverage report build added relevant covered unchanged relevant lost coverage overall coverage coverage status change base build covered relevant coverall,issue,negative,positive,neutral,neutral,positive,positive
452607376,"## Pull Request Test Coverage Report for [Build 1301](https://coveralls.io/builds/20976119)

* **0** of **0**   changed or added relevant lines in **0** files are covered.
* **3** unchanged lines in **1** file lost coverage.
* Overall coverage increased (+**0.04%**) to **94.641%**

---


|  Files with Coverage Reduction | New Missed Lines | % |
| :-----|--------------|--: |
| [autokeras/nn/graph.py](https://coveralls.io/builds/20976119/source?filename=autokeras%2Fnn%2Fgraph.py#L286) | 3 | 97.02% |
<!-- | **Total:** | **3** |  | -->

|  Totals | [![Coverage Status](https://coveralls.io/builds/20976119/badge)](https://coveralls.io/builds/20976119) |
| :-- | --: |
| Change from base [Build 1294](https://coveralls.io/builds/20975844): |  0.04% |
| Covered Lines: | 4344 |
| Relevant Lines: | 4590 |

---
##### 💛  - [Coveralls](https://coveralls.io)
",pull request test coverage report build added relevant covered unchanged file lost coverage overall coverage coverage reduction new total coverage status change base build covered relevant coverall,issue,negative,positive,neutral,neutral,positive,positive
452584040,"> I figured it out for myself. The docker container I was using was 2G memory. I increased it to 16G and restarted the docker image by adding `--shm-size 16G` when running `docker run`. It solved my problems. Hope it helps.

It helps !  Thanks",figured docker container memory docker image running docker run hope thanks,issue,positive,positive,positive,positive,positive,positive
452562926,"Thank you for the contribution, but we are not planning to put all these information in the README yet.",thank contribution put information yet,issue,negative,neutral,neutral,neutral,neutral,neutral
451944991,"I'm experiencing the same issue with version 0.3.5. I've set MAX_IMAGE_SIZE to 224 * 224.

It already occurred two times with identical settings:

```console
Using TensorFlow backend.
{'dataPath': '/Data/', 'imageBaseDir': '/Datasets/224x224/', 'trainDataFile': 'train.csv', 'valDataFile': 'val.csv', 'testDataFile': 'test.csv', 'augmentData': False, 'timeLimit': 24.0, 'max_iter_num': 100, 'max_iter_num_eval': 50, 'max_no_improvement_num': 20, 'modelPath': '224x224', 'modelName': 'model'}
Loading data...
Training data shape:  (44830, 224, 224, 3)
Validation data shape:  (4760, 224, 224, 3)
Test data shape:  (5510, 224, 224, 3)
Start architecture search...
Saving Directory: /tmp/autokeras_4G7EAB
Preprocessing the images.
Preprocessing finished.

Initializing search.
Initialization finished.

+----------------------------------------------+
|               Training model 0               |
+----------------------------------------------+

.
.
.
.
.
.

Epoch-43, Current Metric - 0.212:   0%|                                   | 0/4 [00:00<?, ? batch/s]
Epoch-43, Current Metric - 0.212: 10 batch [00:00, 91.13 batch/s]                                   
                                                                 
No loss decrease after 20 epochs.


Saving model.
+--------------------------------------------------------------------------+
|        Model ID        |          Loss          |      Metric Value      |
+--------------------------------------------------------------------------+
|           26           |   11.985831153392791   |  0.20940000000000003   |
+--------------------------------------------------------------------------+


+----------------------------------------------+
|              Training model 27               |
+----------------------------------------------+

Epoch-1, Current Metric - 0:   0%|                                      | 0/347 [00:00<?, ? batch/s]
                                                                                                    
Process ForkProcess-28:
Traceback (most recent call last):
  File ""/home/lucieri/anaconda3/envs/project/lib/python3.6/multiprocessing/process.py"", line 258, in _bootstrap
    self.run()
  File ""/home/lucieri/anaconda3/envs/project/lib/python3.6/multiprocessing/process.py"", line 93, in run
    self._target(*self._args, **self._kwargs)
  File ""/home/lucieri/anaconda3/envs/project/lib/python3.6/site-packages/autokeras/search.py"", line 473, in train
    raise e
  File ""/home/lucieri/anaconda3/envs/project/lib/python3.6/site-packages/autokeras/search.py"", line 466, in train
    verbose=verbose).train_model(**trainer_args)
  File ""/home/lucieri/anaconda3/envs/project/lib/python3.6/site-packages/autokeras/nn/model_trainer.py"", line 137, in train_model
    self._train()
  File ""/home/lucieri/anaconda3/envs/project/lib/python3.6/site-packages/autokeras/nn/model_trainer.py"", line 173, in _train
    outputs = self.model(inputs)
  File ""/home/lucieri/anaconda3/envs/project/lib/python3.6/site-packages/torch/nn/modules/module.py"", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File ""/home/lucieri/anaconda3/envs/project/lib/python3.6/site-packages/autokeras/nn/graph.py"", line 685, in forward
    temp_tensor = torch_layer(edge_input_tensor)
  File ""/home/lucieri/anaconda3/envs/project/lib/python3.6/site-packages/torch/nn/modules/module.py"", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File ""/home/lucieri/anaconda3/envs/project/lib/python3.6/site-packages/torch/nn/modules/conv.py"", line 301, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: Given groups=1, weight of size [128, 384, 1, 1], expected input[128, 512, 64, 64] to have 384 channels, but got 512 channels instead
```

```console
Process ForkProcess-17:
Traceback (most recent call last):
  File ""/home/lucieri/anaconda3/envs/project/lib/python3.6/multiprocessing/process.py"", line 258, in _bootstrap
    self.run()
  File ""/home/lucieri/anaconda3/envs/project/lib/python3.6/multiprocessing/process.py"", line 93, in run
    self._target(*self._args, **self._kwargs)
  File ""/home/lucieri/anaconda3/envs/project/lib/python3.6/site-packages/autokeras/search.py"", line 473, in train
    raise e
  File ""/home/lucieri/anaconda3/envs/project/lib/python3.6/site-packages/autokeras/search.py"", line 466, in train
    verbose=verbose).train_model(**trainer_args)
  File ""/home/lucieri/anaconda3/envs/project/lib/python3.6/site-packages/autokeras/nn/model_trainer.py"", line 137, in train_model
    self._train()
  File ""/home/lucieri/anaconda3/envs/project/lib/python3.6/site-packages/autokeras/nn/model_trainer.py"", line 173, in _train
    outputs = self.model(inputs)
  File ""/home/lucieri/anaconda3/envs/project/lib/python3.6/site-packages/torch/nn/modules/module.py"", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File ""/home/lucieri/anaconda3/envs/project/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py"", line 123, in forward
    outputs = self.parallel_apply(replicas, inputs, kwargs)
  File ""/home/lucieri/anaconda3/envs/project/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py"", line 133, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File ""/home/lucieri/anaconda3/envs/project/lib/python3.6/site-packages/torch/nn/parallel/parallel_apply.py"", line 77, in parallel_apply
    raise output
  File ""/home/lucieri/anaconda3/envs/project/lib/python3.6/site-packages/torch/nn/parallel/parallel_apply.py"", line 53, in _worker
    output = module(*input, **kwargs)
  File ""/home/lucieri/anaconda3/envs/project/lib/python3.6/site-packages/torch/nn/modules/module.py"", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File ""/home/lucieri/anaconda3/envs/project/lib/python3.6/site-packages/autokeras/nn/graph.py"", line 685, in forward
    temp_tensor = torch_layer(edge_input_tensor)
  File ""/home/lucieri/anaconda3/envs/project/lib/python3.6/site-packages/torch/nn/modules/module.py"", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File ""/home/lucieri/anaconda3/envs/project/lib/python3.6/site-packages/torch/nn/modules/conv.py"", line 301, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: Given groups=1, weight of size [1024, 384, 1, 1], expected input[64, 512, 32, 32] to have 384 channels, but got 512 channels instead
```",issue version set already two time identical console false loading data training data shape validation data shape test data shape start architecture search saving directory finished search finished training model current metric current metric batch loss decrease saving model model id loss metric value training model current metric process recent call last file line file line run file line train raise file line train file line file line file line result input file line forward file line result input file line forward given weight size input got instead console process recent call last file line file line run file line train raise file line train file line file line file line result input file line forward file line return file line raise output file line output module input file line result input file line forward file line result input file line forward given weight size input got instead,issue,negative,negative,neutral,neutral,negative,negative
451689921,"This issue is solved by removing the GPUtil.
The user can specify the GPU by setting the environmental variable.",issue removing user specify setting environmental variable,issue,negative,neutral,neutral,neutral,neutral,neutral
451689810,"@tl-yang I think this issue is solved. If so, please close the issue. Thanks.",think issue please close issue thanks,issue,positive,positive,positive,positive,positive,positive
451689724,This issue is solved. Please see the code in the examples directory.,issue please see code directory,issue,negative,neutral,neutral,neutral,neutral,neutral
451548529,"## Pull Request Test Coverage Report for [Build 1247](https://coveralls.io/builds/20910915)

* **3** of **92**   **(3.26%)**  changed or added relevant lines in **2** files are covered.
* **1** unchanged line in **1** file lost coverage.
* Overall coverage decreased (**-2.03%**) to **91.738%**

---

|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |
| :-----|--------------|--------|---: |
| [autokeras/utils.py](https://coveralls.io/builds/20910915/source?filename=autokeras%2Futils.py#L310) | 3 | 23 | 13.04%
| [autokeras/pretrained/text_sentiment.py](https://coveralls.io/builds/20910915/source?filename=autokeras%2Fpretrained%2Ftext_sentiment.py#L1) | 0 | 69 | 0.0%
<!-- | **Total:** | **3** | **92** | **3.26%** | -->

|  Files with Coverage Reduction | New Missed Lines | % |
| :-----|--------------|--: |
| [autokeras/nn/model_trainer.py](https://coveralls.io/builds/20910915/source?filename=autokeras%2Fnn%2Fmodel_trainer.py#L413) | 1 | 91.94% |
<!-- | **Total:** | **1** |  | -->

|  Totals | [![Coverage Status](https://coveralls.io/builds/20910915/badge)](https://coveralls.io/builds/20910915) |
| :-- | --: |
| Change from base [Build 1243](https://coveralls.io/builds/20910726): |  -2.03% |
| Covered Lines: | 3664 |
| Relevant Lines: | 3994 |

---
##### 💛  - [Coveralls](https://coveralls.io)
",pull request test coverage report build added relevant covered unchanged line file lost coverage overall coverage missing coverage covered total coverage reduction new total coverage status change base build covered relevant coverall,issue,negative,negative,neutral,neutral,negative,negative
451534598,@boyuangong Please try to pass the tests. Thanks.,please try pas thanks,issue,positive,positive,positive,positive,positive,positive
451300990,Or may be we can prompt user at the time of installation of autokeras which GPU they have. ,may prompt user time installation,issue,negative,neutral,neutral,neutral,neutral,neutral
451299939,Download .whl package of torch 0.4.1 from any website and install it manually. It works fine. ,package torch install manually work fine,issue,negative,positive,positive,positive,positive,positive
451167804,"Hey, I believe the arguments for the fit function need to be numpy arrays and I believe you are passing in pandas DataFrames - try classifier.fit(x_train.values, y_train.values, time_limit=60)",hey believe fit function need believe passing try,issue,negative,positive,positive,positive,positive,positive
451012926,"I too had similar issues. Running on MacOS X. Using python3.6 virtual environment.
It looks like a problem with OpenMP (which is probably not installed on your MacOS machine)

Try installing it with brew:
```bash
brew install libomp
```",similar running python virtual environment like problem probably machine try brew bash brew install,issue,negative,neutral,neutral,neutral,neutral,neutral
450715712,The test case and example will cause weird error. ,test case example cause weird error,issue,negative,negative,negative,negative,negative,negative
450540779,"If exporting as PyTorch model, I could do that like this.

```python
import torch

model_filename = 'models/text_model.h5'

model = classifier.cnn.best_model.produce_model()
torch.save(model, model_filename)
```",model could like python import torch model model,issue,negative,neutral,neutral,neutral,neutral,neutral
450464652,"> Can I implement it using FCN?

We are currently following the implementation from the [ADE20K dataset](https://github.com/CSAILVision/semantic-segmentation-pytorch)",implement currently following implementation,issue,negative,neutral,neutral,neutral,neutral,neutral
450420807,@tl-yang I will merge this pull request. We can discuss with Boyuan later. Thanks.,merge pull request discus later thanks,issue,negative,positive,neutral,neutral,positive,positive
450305237,@jhfjhfj1 GPUtil is used in text_preprocessed.py. Not by utils.py. So I think we need to confirm with @boyuangong ?,used think need confirm,issue,negative,neutral,neutral,neutral,neutral,neutral
450287819,"@tl-yang I think it is fine to use multi-gpu by default. So does using env variable means we don't use GPUtil anymore? If we still use GPUtil, how and why should we use it?

I think it would be a good idea that we don't use GPUtil, but let the users to use GPUtil to set the env var to constrain the GPU usage of autokeras.",think fine use default variable use still use use think would good idea use let use set constrain usage,issue,positive,positive,positive,positive,positive,positive
450280434,@jhfjhfj1 I think this function is ready to merge. Could you please comment on whether you like the idea of using multi_gpu as a default behavior (can be constraint by CUDA_VISIBLE_DEVICE environment variable) or adding one more parameter to the ModelTrainer is more preferable?  ,think function ready merge could please comment whether like idea default behavior constraint environment variable one parameter preferable,issue,positive,positive,positive,positive,positive,positive
450063741,"> I had the same issue, running in Colab
> 
> Using:
> 
> ```
> import autokeras as ak 
> .....
> clf = ak.ImageClassifier(verbose=True, augment=False)
> ```
> Instead of:
> 
> `from autokeras.classifier import ImageClassifier`
> 
> Seems to fix the issue, but then when I execute the code block, the kernel dies.

@SkanderHn Have you found a fix?",issue running import ak instead import fix issue execute code block kernel found fix,issue,negative,neutral,neutral,neutral,neutral,neutral
449898459,"## Pull Request Test Coverage Report for [Build 1176](https://coveralls.io/builds/20797341)

* **335** of **355**   **(94.37%)**  changed or added relevant lines in **5** files are covered.
* **3** unchanged lines in **1** file lost coverage.
* Overall coverage increased (+**0.02%**) to **93.74%**

---

|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |
| :-----|--------------|--------|---: |
| [autokeras/pretrained/face_detector.py](https://coveralls.io/builds/20797341/source?filename=autokeras%2Fpretrained%2Fface_detector.py#L638) | 15 | 16 | 93.75%
| [autokeras/pretrained/base.py](https://coveralls.io/builds/20797341/source?filename=autokeras%2Fpretrained%2Fbase.py#L19) | 4 | 6 | 66.67%
| [autokeras/pretrained/object_detector.py](https://coveralls.io/builds/20797341/source?filename=autokeras%2Fpretrained%2Fobject_detector.py#L181) | 312 | 329 | 94.83%
<!-- | **Total:** | **335** | **355** | **94.37%** | -->

|  Files with Coverage Reduction | New Missed Lines | % |
| :-----|--------------|--: |
| [autokeras/nn/graph.py](https://coveralls.io/builds/20797341/source?filename=autokeras%2Fnn%2Fgraph.py#L285) | 3 | 97.02% |
<!-- | **Total:** | **3** |  | -->

|  Totals | [![Coverage Status](https://coveralls.io/builds/20797341/badge)](https://coveralls.io/builds/20797341) |
| :-- | --: |
| Change from base [Build 1173](https://coveralls.io/builds/20796123): |  0.02% |
| Covered Lines: | 3684 |
| Relevant Lines: | 3930 |

---
##### 💛  - [Coveralls](https://coveralls.io)
",pull request test coverage report build added relevant covered unchanged file lost coverage overall coverage missing coverage covered total coverage reduction new total coverage status change base build covered relevant coverall,issue,negative,negative,neutral,neutral,negative,negative
449881082,"@JY00002 Thanks for you advice, unfortunately `TextClassifier` did not have `export_autokeras_model`(`export_keras_model` only) unlike `ImageClassifier`(`export_autokeras_model` is defined in `ImageSupervised` not `DeepSupervised`).",thanks advice unfortunately unlike defined,issue,negative,negative,negative,negative,negative,negative
449865628,"@jhfjhfj1 
I have merged changes from upstream, with you suggestions implemented. The mnist code is running now for both Bayesian and Grid. 

Let me know if any more code re-usage is needed in grid_search.py ",upstream code running grid let know code,issue,negative,neutral,neutral,neutral,neutral,neutral
449852444,"@lhideki you can refer the 'portable_load.py' in the dir""autokeras-master/examples"", and i use solve my problem. hope the code can help you .
    MODEL_DIR = 'The_best_model.h5'
    clf.export_autokeras_model(MODEL_DIR)
    model = pickle_from_file(MODEL_DIR)",refer use solve problem hope code help model,issue,positive,neutral,neutral,neutral,neutral,neutral
449796461,"@JasonKitty @kctoayo88  Exactly, you'll have to let nvidia-smi command work to use gpu on AutoKeras because we'll use the command to determine which gpu to use. In the future, we may add a custom parameter to let user specify the device id.",exactly let command work use use command determine use future may add custom parameter let user specify device id,issue,negative,positive,positive,positive,positive,positive
449547883,"@PraveenVenugopal 
I briefly read your code.
I think you don't need to override the search() function. 
The test for gird_search.py is not covering enough lines of code in that file.
We can discuss tomorrow on how to change.

Thanks.",briefly read code think need override search function test covering enough code file discus tomorrow change thanks,issue,negative,positive,neutral,neutral,positive,positive
449534580,"👌👍👌

On Fri, Dec 21, 2018, 8:13 PM Haifeng Jin <notifications@github.com> wrote:

> Merged #383 <https://github.com/jhfjhfj1/autokeras/pull/383> into master.
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/jhfjhfj1/autokeras/pull/383#event-2040968946>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/AL0Xmfi2mZTJEb3w1zqDFGvMp6oWe1Mdks5u7POXgaJpZM4ZV3y1>
> .
>
-- 

Regards,
Hemang Joshi
",wrote master thread reply directly view mute thread joshi,issue,negative,positive,neutral,neutral,positive,positive
449534526,"You can try tensor board.

On Fri, Dec 21, 2018, 7:42 PM JasonKitty <notifications@github.com> wrote:

> Feature
>
> I would like to see how does the model change in a visual way ,but i
> didn't find any interface for this. Would you please add this interface to
> make the training more visible?
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/jhfjhfj1/autokeras/issues/392>, or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL0XmZ-vOEMQQ6tJbfMMmLEAyIAp3tODks5u7OxngaJpZM4ZeCwt>
> .
>
-- 

Regards,
Hemang Joshi
",try tensor board wrote feature would like see model change visual way find interface would please add interface make training visible thread reply directly view mute thread joshi,issue,positive,positive,neutral,neutral,positive,positive
449446146,"Actually this is the link to some of the best pre trained models : [TensorFlow-Slim image classification model library](https://github.com/tensorflow/models/tree/master/research/slim)
I hope you will use it as well.",actually link best trained image classification model library hope use well,issue,positive,positive,positive,positive,positive,positive
449441938,Resolved the conflicts found in files. @jhfjhfj1 @song3134 @boyuangong Kindly review the changes ,resolved found song kindly review,issue,positive,positive,positive,positive,positive,positive
449391148,"I met the same problem as you.
My solution is to add this path C:\Program Files\NVIDIA Corporation\NVSMI to System environment variable.

",met problem solution add path system environment variable,issue,negative,neutral,neutral,neutral,neutral,neutral
449114263,"> @jhfjhfj1 I found several bug in this pr, might postpone a little bit. Sorry

@jhfjhfj1 I think this version should be better, please let me know if there's any issue.",found several bug might postpone little bit sorry think version better please let know issue,issue,positive,negative,neutral,neutral,negative,negative
448808343,"@jhfjhfj1  I found several bug in this pr, might postpone a little bit. Sorry",found several bug might postpone little bit sorry,issue,negative,negative,negative,negative,negative,negative
448430811,"Sorry about the delay.

1. That does not seem to be enough. I would look at [this blog post](http://benanne.github.io/2015/03/17/plankton.html) for inspiration on data augmentation techniques. Or many other posts on the topic. The code for this project currently has static data augmentation, but you could pretty easily modify it to do more.
2. Are you saying that your alternative technique was using resnet15 without autokeras? That makes sense. Resnet15 is thoroughly trained to recognize a large number of important features. You should not expect autokeras to be able to beat that with the amount of data you have. For the number of classes in the Stanford dog dataset (unless you aren't using all of them) that seems like pretty good performance.
4. Whether you need to be augmented while building the dataset? What do you mean? You should be able to tell the classifier to do augmentation with an argument. See [this](https://github.com/jhfjhfj1/autokeras/blob/a0efd9b22aae8cf6340977a36ec798a00ae86804/autokeras/image/image_supervised.py), check ImageSupervised for documentation.",sorry delay seem enough would look post inspiration data augmentation many topic code project currently static data augmentation could pretty easily modify saying alternative technique without sense thoroughly trained recognize large number important expect able beat amount data number class dog unless like pretty good performance whether need augmented building mean able tell classifier augmentation argument see check documentation,issue,positive,positive,positive,positive,positive,positive
448079352,"I have replaced the glove vector file in the /tem/autokeras_store/glove floder, and it works fine.",glove vector file work fine,issue,negative,positive,positive,positive,positive,positive
447751806,"Hi @codecrack3 , thanks for your interesting in our package. I test the code on Google Colab and I didn't get any errors. 

As for your errors, it seems to be a pytorch problem which has something to do with `torch.manual_seed`, and it was fixed in pytorch [issue 2571](https://github.com/pytorch/pytorch/issues/2517 ), please take a look if you are interested. So my suggestion is try to make sure the torch version is the latest. 

Also, I have added the example of export and load keras model in example folder.

If you still get this problem, please feel free to let us know. And please add your settings such that we can repeated the bug. 

Thanks,
Boyuan",hi thanks interesting package test code get problem something fixed issue please take look interested suggestion try make sure torch version latest also added example export load model example folder still get problem please feel free let u know please add repeated bug thanks,issue,positive,positive,positive,positive,positive,positive
447594096,"Actually I right now figured out that new version of python 3.7 is
installed with upgrade in my anaconda upgrade which j didn't knew, so I
downgraded it to 3.6 and it works fine now
But thanks for the help.

On Sun, Dec 16, 2018, 1:11 AM beepmaster <notifications@github.com> wrote:

> Did you use the pytorch link generator ? Did you try a pip installation ?
> If so, what is your Python version ?
> Did you check your Python environment and pip ?
>
> —
> You are receiving this because you commented.
>
>
> Reply to this email directly, view it on GitHub
> <https://github.com/jhfjhfj1/autokeras/issues/41#issuecomment-447592946>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL0XmY-WFVAIeUiNsewYCEtwCVwH_6Gxks5u5VBvgaJpZM4Vumb8>
> .
>
-- 

Regards,
Hemang Joshi
",actually right figured new version python upgrade anaconda upgrade knew work fine thanks help sun wrote use link generator try pip installation python version check python environment pip reply directly view mute thread joshi,issue,positive,positive,positive,positive,positive,positive
447592946,"Did you use the pytorch link generator ? Did  you try a pip installation ? If so, what is your Python version ? 
Did you check your Python environment and pip ?
",use link generator try pip installation python version check python environment pip,issue,negative,neutral,neutral,neutral,neutral,neutral
447560110,"> I just start from a fresh Python 3.6 install.
> Just need to install PyTorch from their website recommandation
> IE : For A python, windows, pip configuration :
> 
> pip3 install http://download.pytorch.org/whl/cu90/torch-0.4.1-cp36-cp36m-win_amd64.whl
> pip3 install torchvision
> 
> then a simple
> 
> pip install autokeras
> 
> works fine

Error : 
`torch-0.4.1-cp36-cp36m-win_amd64.whl is not supported wheel on this platform`

_Please help_",start fresh python install need install ie python pip configuration pip install pip install simple pip install work fine error wheel platform,issue,negative,positive,positive,positive,positive,positive
447533647,"This pull request is ready to be merged.

The details of this pull request are:
1. Added face detection based on the pre-trained model.
2. Added a test.

",pull request ready pull request added face detection based model added test,issue,negative,positive,positive,positive,positive,positive
446728299,"Hi @tl-yang, I will assign this issue to @chengchengeasy.
He has already implemented a greedy algorithm.
You can focus on other issues.",hi assign issue already greedy algorithm focus,issue,negative,neutral,neutral,neutral,neutral,neutral
445704511,"Answer the questions:
1、I extracted five categories from the “Stanford dog” dataset.There are about 100 images in each category
2、I use it finetune pre-training resnet15, and the final classification accuracy is close to 98%.However, the final model generated by autokeras has a classification accuracy of only 78%
3、Autokeras generates a model with nearly 150 layers
4、In constant.py, DATA_AUGMENTATION = True, and whether I need to be augmented while building the dataset??
@isaac-gs thank you",answer extracted five dog category use final classification accuracy close final model classification accuracy model nearly true whether need augmented building thank,issue,positive,positive,positive,positive,positive,positive
445686500,"1. Your experiments should be robust to random variable change. I would recommend running several times and averaging the results to get a ""realistic"" estimation of performance.
2. This does not seem to be supported (see link). You could run each of several iterations of this experiment on each of your GPUs.

https://github.com/jhfjhfj1/autokeras/issues/60 (the feature seems to be planned for AutoKeras 0.4)",robust random variable change would recommend running several time get realistic estimation performance seem see link could run several experiment feature,issue,positive,negative,neutral,neutral,negative,negative
445684701,"A few questions,
- How small of a dataset are you talking about?
- Have you created your own network to solve this?
- If so, what was the difference in performance?
- What architecture did autokeras create?

Some datasets are just plain too small. I would recommend looking into data augmentation.",small talking network solve difference performance architecture create plain small would recommend looking data augmentation,issue,positive,negative,negative,negative,negative,negative
445578524,@jhfjhfj1 added the steps to visualize model graph,added visualize model graph,issue,negative,neutral,neutral,neutral,neutral,neutral
445338623,@locys The exception actually may not have anything to do with the actual error. Could you provide me with the full console log?,exception actually may anything actual error could provide full console log,issue,negative,positive,positive,positive,positive,positive
445337131,"Support GPU on Google Colab

###Solution
-  Disable multiprocessing
### Reason
-  Google Colab doesn't support multiprocessing ""spwan"" start method. However, cuda only support ""spawn"" start method. Thus, to enable GPU accelaration on Google Colab, we must run autokeras in sigle process.",support solution disable reason support start method however support spawn start method thus enable must run process,issue,positive,neutral,neutral,neutral,neutral,neutral
445135923,"When I put 46000 224 * 224 images for training ,I ran into this problem. 
After I reduce the size to 96 * 96 , it works well
Then I tryed 128 * 128, problem occured again
I think It is something about resouces.   my enviroment is win10, gtx1080ti, i7-8700k, 32g memory",put training ran problem reduce size work well problem think something win memory,issue,negative,positive,positive,positive,positive,positive
444854230,"Hi @jhfjhfj1 

I would like to work on this .Could you guide me how may I start and contribute? 
I have worked on video classification problems before using python and openCV .

https://www.linkedin.com/in/umang-sharma-321b4483/",hi would like work guide may start contribute worked video classification python,issue,negative,neutral,neutral,neutral,neutral,neutral
443575453,"> @tl-yang Is it ready to merge?

yes, sorry i forgot to put that in the title",ready merge yes sorry forgot put title,issue,positive,negative,negative,negative,negative,negative
443473305,"@satyakesav Would you please fix this issue?

I think it can be solved by moving this line https://github.com/jhfjhfj1/autokeras/blob/master/autokeras/image/image_supervised.py#L279
to the predict() function.",would please fix issue think moving line predict function,issue,negative,neutral,neutral,neutral,neutral,neutral
443396228,@codecrack3 Thank you for the bug report. I think we need the entire log to reproduce the error.,thank bug report think need entire log reproduce error,issue,negative,neutral,neutral,neutral,neutral,neutral
443396033,"i get same exception (ver 0.3.4 , ImageClassifier)
+----------------------------------------------+
|              Training model 22               |
+----------------------------------------------+
Epoch-1, Current Metric - 0:   0%|                                        | 0/4 [00:00<?, ? batch/s]Process ForkProcess-25:
Traceback (most recent call last):
  File ""/usr/lib/python3.6/multiprocessing/process.py"", line 258, in _bootstrap
    self.run()
  File ""/usr/lib/python3.6/multiprocessing/process.py"", line 93, in run
    self._target(*self._args, **self._kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/autokeras/search.py"", line 277, in train
    raise e
  File ""/usr/local/lib/python3.6/dist-packages/autokeras/search.py"", line 270, in train
    verbose=verbose).train_model(**trainer_args)
  File ""/usr/local/lib/python3.6/dist-packages/autokeras/nn/model_trainer.py"", line 122, in train_model
    self._train()
  File ""/usr/local/lib/python3.6/dist-packages/autokeras/nn/model_trainer.py"", line 156, in _train
    outputs = self.model(inputs)
  File ""/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py"", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/autokeras/nn/graph.py"", line 681, in forward
    temp_tensor = torch_layer(edge_input_tensor)
  File ""/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py"", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py"", line 301, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: Given groups=1, weight of size [64, 192, 1, 1], expected input[128, 256, 32, 32] to have 192 channels, but got 256 channels instead",get exception training model current metric process recent call last file line file line run file line train raise file line train file line file line file line result input file line forward file line result input file line forward given weight size input got instead,issue,negative,neutral,neutral,neutral,neutral,neutral
443085760,"@boyuangong would you please look into this issue and try to solve it and include in the tutorial for export models? Thank you!

<sub>Sent with <a href=""http://githawk.com"">GitHawk</a></sub>",would please look issue try solve include tutorial export thank sub sent,issue,positive,neutral,neutral,neutral,neutral,neutral
442916655,"@Npccc Thank you so much for the bug report.
It is very hard for us to reproduce this bug without the full log.
Would you please provide the full log if it is available?

Thank you!",thank much bug report hard u reproduce bug without full log would please provide full log available thank,issue,positive,positive,positive,positive,positive,positive
442672872,"@tl-yang 
**My enviroment：**
autokeras：'0.3.3'
python：3.6.6
torch:0.4.1
keras:2.2.4
tensorflow:1.12.0
system:Ubuntu16.04
numpy:1.15.2

**My code:**
I'm running on my own dataset

`from autokeras.image.image_supervised import load_image_dataset, ImageClassifier
from keras.models import load_model
from keras.utils import plot_model
from keras.preprocessing.image import load_img, img_to_array
import numpy as np
import torch
TRAIN_CSV_DIR = '/home/guost/Datasets/Dog/C5/NewAg128/train_labels.csv'
TRAIN_IMG_DIR = '/home/guost/Datasets/Dog/C5/NewAg128/train'
TEST_CSV_DIR = '/home/guost/Datasets/Dog/C5/NewAg128/test_labels.csv'
TEST_IMG_DIR = '/home/guost/Datasets/Dog/C5/NewAg128/test'

if __name__ == '__main__':
    train_data, train_labels = load_image_dataset(csv_file_path=TRAIN_CSV_DIR, images_path=TRAIN_IMG_DIR)
    test_data, test_labels = load_image_dataset(csv_file_path=TEST_CSV_DIR, images_path=TEST_IMG_DIR)
    train_data = train_data.astype('float32') / 255.
    test_data = test_data.astype('float32') / 255.
    clf = ImageClassifier(verbose=True,path='/home/guost/autokeras/Newversion/1128/modelPath',resume=False)
    clf.fit(train_data, train_labels,x_test=test_data,y_test=test_labels, time_limit=30 * 60)
    clf.final_fit(train_data, train_labels, test_data, test_labels, retrain=True)
    y = clf.evaluate(test_data, test_labels)
    print(""evaluate:"", y)`

Thank  you@tl-yang 

",torch system code running import import import import import import torch print evaluate thank,issue,negative,neutral,neutral,neutral,neutral,neutral
442651624,@Npccc We have just fixed a bug that might cause this problem. You can try with the latest version 0.3.4. Thanks.,fixed bug might cause problem try latest version thanks,issue,negative,positive,positive,positive,positive,positive
442651402,"@codecrack3 I think the bug is fixed. You can try with 0.3.4. If it still has this error, please reopen the issue. Thank you!",think bug fixed try still error please reopen issue thank,issue,negative,positive,neutral,neutral,positive,positive
442642894,"@shyamalschandra  The latest version should work on Colab. If you encounter any problem using Google Colab with the latest Autokeras, please let us know!",latest version work encounter problem latest please let u know,issue,negative,positive,positive,positive,positive,positive
442642312,Hi @lhwcv . Thank you so much for the report. We're trying to figure out a good solution for this issue. If you have any thought please let us know!   ,hi thank much report trying figure good solution issue thought please let u know,issue,positive,positive,positive,positive,positive,positive
442633466,I think this is related to #311 . @Npccc  Can you provide more detail? what version are you using? Are you running mnist example or?  What is your environment setting?,think related provide detail version running example environment setting,issue,negative,neutral,neutral,neutral,neutral,neutral
442619540,"@renaudham Hi, thanks for your interesting in our work. We are preparing the tutorial documents for some modules including the textClassifier. You can directly check this in the new [pull request 341](https://github.com/jhfjhfj1/autokeras/pull/341/files). The text tutorial are in text.md. 

Also, if you want to try the textClassifier. You can go and check the example in examples/text_cnn.  

Please feel free to let me know if you have further questions.",hi thanks interesting work tutorial directly check new pull request text tutorial also want try go check example please feel free let know,issue,positive,positive,positive,positive,positive,positive
442542859,@codecrack3 Thanks for the bug report. May I know which version are you using and what code are you running? Thanks.,thanks bug report may know version code running thanks,issue,positive,positive,positive,positive,positive,positive
442380678,"Hi.
Great, what is the status?

Some questions
-What is the max length of each texts we want to classify? For example can, we proceed an average email ?
-How many classes can we feed in the engine, so it could stay relatively average with not too much false positive ? 20, 50?
I know many old classifier drop a lot in accuracy if there is too many classes.
But recent one like the openSource from Facebook can stand really more. But I don't want to use anything from facebook.

-What is the format to feed for training and then testing ? I didn't see any docs and tutorials yet, is there?

Thanks, great job.",hi great status length want example proceed average many class feed engine could stay relatively average much false positive know many old classifier drop lot accuracy many class recent one like stand really want use anything format feed training testing see yet thanks great job,issue,positive,positive,positive,positive,positive,positive
442315471,@codecrack3 Thanks for the issue. I am trying to fix this bug.,thanks issue trying fix bug,issue,negative,positive,positive,positive,positive,positive
442278496,"@tl-yang  i use spyder to run my code 
>My enviroment

windows 10
python 3.6
autokeras 0.3.1
tensorflow 1.7.0
keras 2.2.2
torch 0.4.1
spyder 3.2.6
tensorflow-gpu 1.9.0

",use run code python torch,issue,negative,neutral,neutral,neutral,neutral,neutral
442205113,@EverKnows Are you using notebook to run the code?  Can you provide some more detail about your environment?,notebook run code provide detail environment,issue,negative,neutral,neutral,neutral,neutral,neutral
442060720,"@tl-yang 
here is my code
from keras.datasets import mnist
from autokeras import ImageClassifier
import tensorflow
from fashion_mnist_load import fashion_mnist_load 




def f():
    (x_train, y_train), (x_test, y_test) = mnist.load_data(r'F:/Ranly_Obj/AdcancedTech/mnist/mnist.npz')
    x_train = x_train.reshape(x_train.shape + (1,))
    x_test = x_test.reshape(x_test.shape + (1,))
        
        
    clf = ImageClassifier(verbose=True)
        
    clf.fit(x_train, y_train, time_limit=12 * 60 * 60)
    print('Done')
    clf.final_fit(x_train, y_train, x_test, y_test, retrain=True)
    y = clf.evaluate(x_test, y_test)
    print(y * 100)
if __name__=='__main__':
    f()

and here is my error info
runfile('F:/Ranly_Obj/AdcancedTech/auto_example.py', wdir='F:/Ranly_Obj/AdcancedTech')
Using TensorFlow backend.
C:\Users\lenovo\AppData\Roaming\Python\Python36\site-packages\tqdm\autonotebook\__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)
  "" (e.g. in jupyter console)"", TqdmExperimentalWarning)
Preprocessing the images.
x is  (60000, 28, 28, 1)
Preprocessing finished.

Initializing search.
Initialization finished.


+----------------------------------------------+
|               Training model 0               |
+----------------------------------------------+
Traceback (most recent call last):

  File ""<ipython-input-1-f8faa807d086>"", line 1, in <module>
    runfile('F:/Ranly_Obj/AdcancedTech/auto_example.py', wdir='F:/Ranly_Obj/AdcancedTech')

  File ""E:\anaconda\lib\site-packages\spyder\utils\site\sitecustomize.py"", line 705, in runfile
    execfile(filename, namespace)

  File ""E:\anaconda\lib\site-packages\spyder\utils\site\sitecustomize.py"", line 102, in execfile
    exec(compile(f.read(), filename, 'exec'), namespace)

  File ""F:/Ranly_Obj/AdcancedTech/auto_example.py"", line 32, in <module>
    f()

  File ""F:/Ranly_Obj/AdcancedTech/auto_example.py"", line 26, in f
    clf.fit(x_train, y_train, time_limit=12 * 60 * 60)

  File ""C:\Users\lenovo\AppData\Roaming\Python\Python36\site-packages\autokeras\image\image_supervised.py"", line 123, in fit
    super().fit(x, y, x_test, y_test, time_limit)

  File ""C:\Users\lenovo\AppData\Roaming\Python\Python36\site-packages\autokeras\supervised.py"", line 140, in fit
    self.cnn.fit(self.get_n_output_node(), x_train.shape, train_data, test_data, time_limit)

  File ""C:\Users\lenovo\AppData\Roaming\Python\Python36\site-packages\autokeras\net_module.py"", line 60, in fit
    self.searcher.search(train_data, test_data, int(time_remain))

  File ""C:\Users\lenovo\AppData\Roaming\Python\Python36\site-packages\autokeras\search.py"", line 238, in search
    p.terminate()

  File ""E:\anaconda\lib\multiprocessing\process.py"", line 116, in terminate
    self._popen.terminate()

AttributeError: 'NoneType' object has no attribute 'terminate'",code import import import import print print error notebook mode use instead force console mode console console finished search finished training model recent call last file line module file line file line compile file line module file line file line fit super file line fit file line fit file line search file line terminate object attribute,issue,positive,positive,positive,positive,positive,positive
441877883,"My question is, does then autokeras use the training accuracy as the main metric, instead of the validation one?",question use training accuracy main metric instead validation one,issue,negative,positive,positive,positive,positive,positive
441876946,"OK, think it works now:
``` python
import numpy as np
import autokeras as ak
def f():
        x_train = np.random.rand(100, 30, 30, 1)
        x_val  = np.random.rand(70, 30, 30, 1)
        y_train = np.ceil(np.random.rand(100))
        y_val = np.ceil(np.random.rand(70))
        clf = ak.ImageClassifier(verbose=True)
        clf.fit(x_train, y_train)
if __name__ == '__main__':
        f()
```",think work python import import ak,issue,negative,neutral,neutral,neutral,neutral,neutral
441874708,"@tl-yang It seems that it gives the same error as before.

Code:
```python

import numpy as np
import autokeras as ak
from tensorflow import set_random_seed
seed = 0
np.random.seed(seed)
set_random_seed(0)


x_train = np.random.rand(100, 30, 30, 1)
x_val  = np.random.rand(70, 30, 30, 1)
y_train = np.ceil(np.random.rand(100))
y_val = np.ceil(np.random.rand(70))
clf = ak.ImageClassifier(verbose=True)
clf.fit(x_train, y_train) #, x_val, y_val)
```

```
Using TensorFlow backend.
Preprocessing the images.
x is  (100, 30, 30, 1)
Preprocessing finished.
Initializing search.
Initialization finished.
+----------------------------------------------+
|               Training model 0               |
+----------------------------------------------+
Using TensorFlow backend.
Preprocessing the images.
x is  (100, 30, 30, 1)
Preprocessing finished.
Initializing search.
Initialization finished.
+----------------------------------------------+
|               Training model 0               |
+----------------------------------------------+
Traceback (most recent call last):
  File ""/home/s1881460/.local/lib/python3.6/site-packages/autokeras/search.py"", line 231, in search
    raise e
  File ""/home/s1881460/.local/lib/python3.6/site-packages/autokeras/search.py"", line 199, in search
    p.start()
  File ""/usr/lib/python3.6/multiprocessing/process.py"", line 105, in start
    self._popen = self._Popen(self)
  File ""/usr/lib/python3.6/multiprocessing/context.py"", line 284, in _Popen
    return Popen(process_obj)
  File ""/usr/lib/python3.6/multiprocessing/popen_spawn_posix.py"", line 32, in __init__
    super().__init__(process_obj)
  File ""/usr/lib/python3.6/multiprocessing/popen_fork.py"", line 19, in __init__
    self._launch(process_obj)
  File ""/usr/lib/python3.6/multiprocessing/popen_spawn_posix.py"", line 42, in _launch
    prep_data = spawn.get_preparation_data(process_obj._name)
  File ""/usr/lib/python3.6/multiprocessing/spawn.py"", line 143, in get_preparation_data
    _check_not_importing_main()
  File ""/usr/lib/python3.6/multiprocessing/spawn.py"", line 136, in _check_not_importing_main
    is not going to be frozen to produce an executable.''')
RuntimeError: 
        An attempt has been made to start a new process before the
        current process has finished its bootstrapping phase.
        This probably means that you are not using fork to start your
        child processes and you have forgotten to use the proper idiom
        in the main module:
            if __name__ == '__main__':
                freeze_support()
                ...
        The ""freeze_support()"" line can be omitted if the program
        is not going to be frozen to produce an executable.
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""/usr/lib/python3.6/multiprocessing/spawn.py"", line 105, in spawn_main
    exitcode = _main(fd)
  File ""/usr/lib/python3.6/multiprocessing/spawn.py"", line 114, in _main
    prepare(preparation_data)
  File ""/usr/lib/python3.6/multiprocessing/spawn.py"", line 225, in prepare
    _fixup_main_from_path(data['init_main_from_path'])
  File ""/usr/lib/python3.6/multiprocessing/spawn.py"", line 277, in _fixup_main_from_path
    run_name=""__mp_main__"")
  File ""/usr/lib/python3.6/runpy.py"", line 263, in run_path
    pkg_name=pkg_name, script_name=fname)
  File ""/usr/lib/python3.6/runpy.py"", line 96, in _run_module_code
    mod_name, mod_spec, pkg_name, script_name)
  File ""/usr/lib/python3.6/runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""/home/s1881460/train.py"", line 41, in <module>
    clf.fit(x_train, y_train) #, x_val, y_val)
  File ""/home/s1881460/.local/lib/python3.6/site-packages/autokeras/image/image_supervised.py"", line 123, in fit
    super().fit(x, y, x_test, y_test, time_limit)
  File ""/home/s1881460/.local/lib/python3.6/site-packages/autokeras/supervised.py"", line 140, in fit
    self.cnn.fit(self.get_n_output_node(), x_train.shape, train_data, test_data, time_limit)
  File ""/home/s1881460/.local/lib/python3.6/site-packages/autokeras/net_module.py"", line 60, in fit
    self.searcher.search(train_data, test_data, int(time_remain))
  File ""/home/s1881460/.local/lib/python3.6/site-packages/autokeras/search.py"", line 238, in search
    p.terminate()
  File ""/usr/lib/python3.6/multiprocessing/process.py"", line 116, in terminate
    self._popen.terminate()
AttributeError: 'NoneType' object has no attribute 'terminate'
```
Ctrl-C, 
```
^CTraceback (most recent call last):
  File ""train.py"", line 41, in <module>
    clf.fit(x_train, y_train) #, x_val, y_val)
  File ""/home/s1881460/.local/lib/python3.6/site-packages/autokeras/image/image_supervised.py"", line 123, in fit
    super().fit(x, y, x_test, y_test, time_limit)
  File ""/home/s1881460/.local/lib/python3.6/site-packages/autokeras/supervised.py"", line 140, in fit
    self.cnn.fit(self.get_n_output_node(), x_train.shape, train_data, test_data, time_limit)
  File ""/home/s1881460/.local/lib/python3.6/site-packages/autokeras/net_module.py"", line 60, in fit
    self.searcher.search(train_data, test_data, int(time_remain))
  File ""/home/s1881460/.local/lib/python3.6/site-packages/autokeras/search.py"", line 217, in search
    metric_value, loss, graph = q.get(timeout=remaining_time)
  File ""/usr/lib/python3.6/multiprocessing/queues.py"", line 104, in get
    if not self._poll(timeout):
  File ""/usr/lib/python3.6/multiprocessing/connection.py"", line 257, in poll
    return self._poll(timeout)
  File ""/usr/lib/python3.6/multiprocessing/connection.py"", line 414, in _poll
    r = wait([self], timeout)
  File ""/usr/lib/python3.6/multiprocessing/connection.py"", line 911, in wait
    ready = selector.select(timeout)
  File ""/usr/lib/python3.6/selectors.py"", line 376, in select
    fd_event_list = self._poll.poll(timeout)
```

",error code python import import ak import seed seed finished search finished training model finished search finished training model recent call last file line search raise file line search file line start self file line return file line super file line file line file line file line going frozen produce executable attempt made start new process current process finished phase probably fork start child forgotten use proper idiom main module line program going frozen produce executable handling exception another exception recent call last file string line module file line file line prepare file line prepare data file line file line file line file line code file line module file line fit super file line fit file line fit file line search file line terminate object attribute recent call last file line module file line fit super file line fit file line fit file line search loss graph file line get file line poll return file line wait self file line wait ready file line select,issue,positive,positive,positive,positive,positive,positive
441870809,"@Ivorra I mean remove the last two parameters: `clf.fit(x_train, y_train)`  it seems that x_test and y_test parameters have some problem now.",mean remove last two problem,issue,negative,negative,negative,negative,negative,negative
441870605,"@tl-yang It seems to give the same error, I just set the line to ""clf.fit(x_train, y_train, x_val, y_val)"". Is that what I should change?",give error set line change,issue,negative,neutral,neutral,neutral,neutral,neutral
441867413,@Ivorra I think you just found another issue. Try to remove the x_test y_test parameter in the .fit function. It should work.,think found another issue try remove parameter function work,issue,negative,neutral,neutral,neutral,neutral,neutral
441864248,"Add pytest. Put the image in tests/resources/object_detection/...
Follow the contributing guide to see the coverage.",add put image follow guide see coverage,issue,negative,neutral,neutral,neutral,neutral,neutral
441862554,"load() to download the model.
Put the download link in the constant.py.
The path to save the downloaded model should be temp_path_generator() + '_object_detection_pretrained'.

predict(img_path, output_file_path=None)
Returns:
   List of tuples. Each tuple is like ((x1, y1), (h, w), category, confidence).
   ",load model put link path save model predict list like category confidence,issue,positive,neutral,neutral,neutral,neutral,neutral
441860353,"@tl-yang Could you clarify how to do the wrapping? I am doing the following, but it just gives another error:
```python
import numpy as np
import autokeras as ak

from tensorflow import set_random_seed

def f():
    seed = 0
     np.random.seed(seed)
     set_random_seed(seed)

    x_train = np.random.rand(100, 30, 30, 1)
    x_val  = np.random.rand(70, 30, 30, 1)
    y_train = np.random.rand(100)
    y_val = np.random.rand(70)

    clf = ak.ImageClassifier(verbose=True)

    clf.fit(x_train, y_train, x_test=x_val, y_test=y_val)
        
if __name__ == '__main__':
    f()
```

And the error:
```

Using TensorFlow backend.
Preprocessing the images.
x is  (100, 30, 30, 1)
Preprocessing finished.
Initializing search.
Initialization finished.

+----------------------------------------------+
|               Training model 0               |
+----------------------------------------------+
Using TensorFlow backend.
Process SpawnProcess-1:                                                                             
Traceback (most recent call last):
  File ""/usr/lib/python3.6/multiprocessing/process.py"", line 258, in _bootstrap
    self.run()
  File ""/usr/lib/python3.6/multiprocessing/process.py"", line 93, in run
    self._target(*self._args, **self._kwargs)
  File ""/home/s1881460/.local/lib/python3.6/site-packages/autokeras/search.py"", line 301, in train
    verbose=verbose).train_model(**trainer_args)
  File ""/home/s1881460/.local/lib/python3.6/site-packages/autokeras/nn/model_trainer.py"", line 115, in train_model
    test_loss, metric_value = self._test()
  File ""/home/s1881460/.local/lib/python3.6/site-packages/autokeras/nn/model_trainer.py"", line 179, in _test
    test_loss += float(self.loss_function(outputs, targets))
  File ""/home/s1881460/.local/lib/python3.6/site-packages/autokeras/nn/loss_function.py"", line 5, in classification_loss
    labels = target.argmax(1)
  File ""/home/s1881460/.local/lib/python3.6/site-packages/torch/tensor.py"", line 231, in argmax
    return torch.argmax(self, dim, keepdim)
  File ""/home/s1881460/.local/lib/python3.6/site-packages/torch/functional.py"", line 374, in argmax
    return torch._argmax(input, dim, keepdim)
RuntimeError: Dimension out of range (expected to be in range of [-1, 0], but got 1)
Exception ignored in: <bound method StorageRef.__del__ of <torch.multiprocessing.reductions.StorageRef object at 0x7fa24c3ff940>>
Traceback (most recent call last):
  File ""/home/s1881460/.local/lib/python3.6/site-packages/torch/multiprocessing/reductions.py"", line 26, in __del__
AttributeError: 'NoneType' object has no attribute '_free_weak_ref'
Exception ignored in: <bound method StorageRef.__del__ of <torch.multiprocessing.reductions.StorageRef object at 0x7fa24c3ffac8>>
Traceback (most recent call last):
  File ""/home/s1881460/.local/lib/python3.6/site-packages/torch/multiprocessing/reductions.py"", line 26, in __del__
AttributeError: 'NoneType' object has no attribute '_free_weak_ref'
Exception ignored in: <bound method StorageRef.__del__ of <torch.multiprocessing.reductions.StorageRef object at 0x7fa24c3ffbe0>>
Traceback (most recent call last):
  File ""/home/s1881460/.local/lib/python3.6/site-packages/torch/multiprocessing/reductions.py"", line 26, in __del__
AttributeError: 'NoneType' object has no attribute '_free_weak_ref'
Exception ignored in: <bound method StorageRef.__del__ of <torch.multiprocessing.reductions.StorageRef object at 0x7fa24c3ff080>>
Traceback (most recent call last):
  File ""/home/s1881460/.local/lib/python3.6/site-packages/torch/multiprocessing/reductions.py"", line 26, in __del__
AttributeError: 'NoneType' object has no attribute '_free_weak_ref'
Exception ignored in: <bound method StorageRef.__del__ of <torch.multiprocessing.reductions.StorageRef object at 0x7fa24c3ff470>>
Traceback (most recent call last):
  File ""/home/s1881460/.local/lib/python3.6/site-packages/torch/multiprocessing/reductions.py"", line 26, in __del__
AttributeError: 'NoneType' object has no attribute '_free_weak_ref'
Exception ignored in: <bound method StorageRef.__del__ of <torch.multiprocessing.reductions.StorageRef object at 0x7fa24c3ff5f8>>
Traceback (most recent call last):
  File ""/home/s1881460/.local/lib/python3.6/site-packages/torch/multiprocessing/reductions.py"", line 26, in __del__
AttributeError: 'NoneType' object has no attribute '_free_weak_ref'
```
After Ctrl-C:

```
^CTraceback (most recent call last):
  File ""run.py"", line 56, in <module>
    f()
  File ""run.py"", line 40, in f
    x_test=x_val, y_test=y_val)
  File ""/home/s1881460/.local/lib/python3.6/site-packages/autokeras/image/image_supervised.py"", line 123, in fit
    super().fit(x, y, x_test, y_test, time_limit)
  File ""/home/s1881460/.local/lib/python3.6/site-packages/autokeras/supervised.py"", line 140, in fit
    self.cnn.fit(self.get_n_output_node(), x_train.shape, train_data, test_data, time_limit)
  File ""/home/s1881460/.local/lib/python3.6/site-packages/autokeras/net_module.py"", line 60, in fit
    self.searcher.search(train_data, test_data, int(time_remain))
  File ""/home/s1881460/.local/lib/python3.6/site-packages/autokeras/search.py"", line 217, in search
    metric_value, loss, graph = q.get(timeout=remaining_time)
  File ""/usr/lib/python3.6/multiprocessing/queues.py"", line 104, in get
    if not self._poll(timeout):
  File ""/usr/lib/python3.6/multiprocessing/connection.py"", line 257, in poll
    return self._poll(timeout)
  File ""/usr/lib/python3.6/multiprocessing/connection.py"", line 414, in _poll
    r = wait([self], timeout)
  File ""/usr/lib/python3.6/multiprocessing/connection.py"", line 911, in wait
    ready = selector.select(timeout)
  File ""/usr/lib/python3.6/selectors.py"", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt

```
",could clarify wrapping following another error python import import ak import seed seed seed error finished search finished training model process recent call last file line file line run file line train file line file line float file line file line return self dim file line return input dim dimension range range got exception bound method object recent call last file line object attribute exception bound method object recent call last file line object attribute exception bound method object recent call last file line object attribute exception bound method object recent call last file line object attribute exception bound method object recent call last file line object attribute exception bound method object recent call last file line object attribute recent call last file line module file line file line fit super file line fit file line fit file line search loss graph file line get file line poll return file line wait self file line wait ready file line select,issue,positive,positive,neutral,neutral,positive,positive
441856869,"hi @Ivorra . I think you need to wrap your code in a` if __name__ = '__main__':` block. Cause in linux, we're using the spawn method to start a process. 
",hi think need wrap code block cause spawn method start process,issue,negative,neutral,neutral,neutral,neutral,neutral
441708384,"Hi,

It also happens to me (Ubuntu 16.04.5 LTS), I am using a random generated dataset (np.random.rand), this is the code:

```python
# train.py file, run with ""python3.6 train.py"" 
import numpy as np
import autokeras as ak
from tensorflow import set_random_seed
seed = 0
np.random.seed(seed)
set_random_seed(0)

x_train = np.random.rand(100, 30, 30, 1)
x_val  = np.random.rand(70, 30, 30, 1)
y_train = np.random.rand(100)
y_val = np.random.rand(70)
clf = ak.ImageClassifier(verbose=True)
clf.fit(x_train, y_train,  x_test=x_val, y_test=y_val)
```
This is the error:

```
Using TensorFlow backend.
Preprocessing the images.
x is  (100, 30, 30, 1)
Preprocessing finished.
Initializing search.
Initialization finished.
+----------------------------------------------+
|               Training model 0               |
+----------------------------------------------+
Using TensorFlow backend.
Preprocessing the images.
x is  (100, 30, 30, 1)
Preprocessing finished.
Initializing search.
Initialization finished.
+----------------------------------------------+
|               Training model 0               |
+----------------------------------------------+
Traceback (most recent call last):
  File ""/home/s1881460/.local/lib/python3.6/site-packages/autokeras/search.py"", line 231, in search
    raise e
  File ""/home/s1881460/.local/lib/python3.6/site-packages/autokeras/search.py"", line 199, in search
    p.start()
  File ""/usr/lib/python3.6/multiprocessing/process.py"", line 105, in start
    self._popen = self._Popen(self)
  File ""/usr/lib/python3.6/multiprocessing/context.py"", line 284, in _Popen
	return Popen(process_obj)
  File ""/usr/lib/python3.6/multiprocessing/popen_spawn_posix.py"", line 32, in __init__
    super().__init__(process_obj)
  File ""/usr/lib/python3.6/multiprocessing/popen_fork.py"", line 19, in __init__
    self._launch(process_obj)
  File ""/usr/lib/python3.6/multiprocessing/popen_spawn_posix.py"", line 42, in _launch
    prep_data = spawn.get_preparation_data(process_obj._name)
  File ""/usr/lib/python3.6/multiprocessing/spawn.py"", line 143, in get_preparation_data
    _check_not_importing_main()
  File ""/usr/lib/python3.6/multiprocessing/spawn.py"", line 136, in _check_not_importing_main
    is not going to be frozen to produce an executable.''')
RuntimeError: 
        An attempt has been made to start a new process before the
        current process has finished its bootstrapping phase.
        This probably means that you are not using fork to start your
        child processes and you have forgotten to use the proper idiom
        in the main module:
            if __name__ == '__main__':
                freeze_support()
                ...
        The ""freeze_support()"" line can be omitted if the program
        is not going to be frozen to produce an executable.
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""/usr/lib/python3.6/multiprocessing/spawn.py"", line 105, in spawn_main
    exitcode = _main(fd)
  File ""/usr/lib/python3.6/multiprocessing/spawn.py"", line 114, in _main
    prepare(preparation_data)
  File ""/usr/lib/python3.6/multiprocessing/spawn.py"", line 225, in prepare
    _fixup_main_from_path(data['init_main_from_path'])
  File ""/usr/lib/python3.6/multiprocessing/spawn.py"", line 277, in _fixup_main_from_path
    run_name=""__mp_main__"")
  File ""/usr/lib/python3.6/runpy.py"", line 263, in run_path
    pkg_name=pkg_name, script_name=fname)
  File ""/usr/lib/python3.6/runpy.py"", line 96, in _run_module_code
    mod_name, mod_spec, pkg_name, script_name)
  File ""/usr/lib/python3.6/runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""/home/s1881460/train.py"", line 42, in <module>
    x_test=x_val, y_test=y_val)
  File ""/home/s1881460/.local/lib/python3.6/site-packages/autokeras/image/image_supervised.py"", line 123, in fit
    super().fit(x, y, x_test, y_test, time_limit)
  File ""/home/s1881460/.local/lib/python3.6/site-packages/autokeras/supervised.py"", line 140, in fit
    self.cnn.fit(self.get_n_output_node(), x_train.shape, train_data, test_data, time_limit)
  File ""/home/s1881460/.local/lib/python3.6/site-packages/autokeras/net_module.py"", line 60, in fit
    self.searcher.search(train_data, test_data, int(time_remain))
  File ""/home/s1881460/.local/lib/python3.6/site-packages/autokeras/search.py"", line 238, in search
    p.terminate()
  File ""/usr/lib/python3.6/multiprocessing/process.py"", line 116, in terminate
    self._popen.terminate()
AttributeError: 'NoneType' object has no attribute 'terminate'
```

Then, I have to Ctrl-C for stopping the execution, which outputs:

```
^CTraceback (most recent call last):
  File ""/home/s1881460/.local/lib/python3.6/site-packages/autokeras/search.py"", line 199, in search
    p.start()
  File ""/usr/lib/python3.6/multiprocessing/process.py"", line 105, in start
    self._popen = self._Popen(self)
  File ""/usr/lib/python3.6/multiprocessing/context.py"", line 284, in _Popen
    return Popen(process_obj)
  File ""/usr/lib/python3.6/multiprocessing/popen_spawn_posix.py"", line 32, in __init__
    super().__init__(process_obj)
  File ""/usr/lib/python3.6/multiprocessing/popen_fork.py"", line 19, in __init__
    self._launch(process_obj)
  File ""/usr/lib/python3.6/multiprocessing/popen_spawn_posix.py"", line 62, in _launch
    f.write(fp.getbuffer())
KeyboardInterrupt
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File ""train.py"", line 42, in <module>
    x_test=x_val, y_test=y_val)
  File ""/home/s1881460/.local/lib/python3.6/site-packages/autokeras/image/image_supervised.py"", line 123, in fit
    super().fit(x, y, x_test, y_test, time_limit)
  File ""/home/s1881460/.local/lib/python3.6/site-packages/autokeras/supervised.py"", line 140, in fit
    self.cnn.fit(self.get_n_output_node(), x_train.shape, train_data, test_data, time_limit)
  File ""/home/s1881460/.local/lib/python3.6/site-packages/autokeras/net_module.py"", line 60, in fit
    self.searcher.search(train_data, test_data, int(time_remain))
  File ""/home/s1881460/.local/lib/python3.6/site-packages/autokeras/search.py"", line 238, in search
    p.terminate()
  File ""/usr/lib/python3.6/multiprocessing/process.py"", line 116, in terminate
    self._popen.terminate()
AttributeError: 'NoneType' object has no attribute 'terminate'
```

Hope it helps!


",hi also random code python file run python import import ak import seed seed error finished search finished training model finished search finished training model recent call last file line search raise file line search file line start self file line return file line super file line file line file line file line going frozen produce executable attempt made start new process current process finished phase probably fork start child forgotten use proper idiom main module line program going frozen produce executable handling exception another exception recent call last file string line module file line file line prepare file line prepare data file line file line file line file line code file line module file line fit super file line fit file line fit file line search file line terminate object attribute stopping execution recent call last file line search file line start self file line return file line super file line file line handling exception another exception recent call last file line module file line fit super file line fit file line fit file line search file line terminate object attribute hope,issue,positive,positive,positive,positive,positive,positive
441694475,"## Pull Request Test Coverage Report for [Build 1041](https://coveralls.io/builds/20293213)

* **1** of **1**   **(100.0%)**  changed or added relevant line in **1** file are covered.
* No unchanged relevant lines lost coverage.
* Overall coverage increased (+**0.08%**) to **94.735%**

---



|  Totals | [![Coverage Status](https://coveralls.io/builds/20293213/badge)](https://coveralls.io/builds/20293213) |
| :-- | --: |
| Change from base [Build 1027](https://coveralls.io/builds/20279435): |  0.08% |
| Covered Lines: | 2411 |
| Relevant Lines: | 2545 |

---
##### 💛  - [Coveralls](https://coveralls.io)
",pull request test coverage report build added relevant line file covered unchanged relevant lost coverage overall coverage coverage status change base build covered relevant coverall,issue,negative,positive,neutral,neutral,positive,positive
441524485,"@Timmmeyyy @EverKnows @cutechestnut  I'm having a hard time reproducing the bug. Can you provide me with some more detail? Like how long do you run the mnist example until the error occurred? what is the console ouput(before the error)

I think it might be a race condition. But I can't tell under what circumstances the error will occur.  ",hard time bug provide detail like long run example error console error think might race condition ca tell error occur,issue,negative,negative,negative,negative,negative,negative
440894855,"It use pytorch DataSet api to load data, you may try implement a pytorch Dataset to fix it.",use load data may try implement fix,issue,negative,neutral,neutral,neutral,neutral,neutral
440851728,"I implement the basic function. Please see the demo here. https://colab.research.google.com/drive/12QXaI5ZAiQJfK-19HVl8fyjyh79B-TMf

The PR is waiting for review yet, so I think it may take weeks until my PR is merged into master. ",implement basic function please see waiting review yet think may take master,issue,negative,neutral,neutral,neutral,neutral,neutral
440647815,"Hi, i got the same issue 5 minutes ago. May @tl-yang  you have an solution ?",hi got issue ago may solution,issue,negative,neutral,neutral,neutral,neutral,neutral
440607276,"i got this problem too，here is my error information.（autokeras0.3.1 windows10 py36） 
Traceback (most recent call last):

  File ""<ipython-input-1-f8faa807d086>"", line 1, in <module>
    runfile('F:/Ranly_Obj/AdcancedTech/auto_example.py', wdir='F:/Ranly_Obj/AdcancedTech')

  File ""E:\anaconda\lib\site-packages\spyder\utils\site\sitecustomize.py"", line 705, in runfile
    execfile(filename, namespace)

  File ""E:\anaconda\lib\site-packages\spyder\utils\site\sitecustomize.py"", line 102, in execfile
    exec(compile(f.read(), filename, 'exec'), namespace)

  File ""F:/Ranly_Obj/AdcancedTech/auto_example.py"", line 27, in <module>
    clf.fit(x_train, y_train, time_limit=12 * 60 * 60)

  File ""C:\Users\lenovo\AppData\Roaming\Python\Python36\site-packages\autokeras\image\image_supervised.py"", line 123, in fit
    super().fit(x, y, x_test, y_test, time_limit)

  File ""C:\Users\lenovo\AppData\Roaming\Python\Python36\site-packages\autokeras\supervised.py"", line 140, in fit
    self.cnn.fit(self.get_n_output_node(), x_train.shape, train_data, test_data, time_limit)

  File ""C:\Users\lenovo\AppData\Roaming\Python\Python36\site-packages\autokeras\net_module.py"", line 60, in fit
    self.searcher.search(train_data, test_data, int(time_remain))

  File ""C:\Users\lenovo\AppData\Roaming\Python\Python36\site-packages\autokeras\search.py"", line 238, in search
    p.terminate()

  File ""E:\anaconda\lib\multiprocessing\process.py"", line 116, in terminate
    self._popen.terminate()

AttributeError: 'NoneType' object has no attribute 'terminate'",got problem error recent call last file line module file line file line compile file line module file line fit super file line fit file line fit file line search file line terminate object attribute,issue,positive,positive,positive,positive,positive,positive
440599023,"Direct operation：
```
import autokeras as ak
clf = ak.ImageClassifier(verbose=True)
```

or
```
from autokeras.image.image_supervised  import ImageClassifier
clf = ImageClassifier(verbose=True)
```",direct import ak import,issue,negative,positive,neutral,neutral,positive,positive
440343057,"Which I mean is that if I use a pic with shape 28\*28, autokeras may normal, but when I take a pic with shape 28\*1, it will error and show the output size is too small, so I wonder what is the max or min pic shape for autokeras, thank you.",mean use pic shape may normal take pic shape error show output size small wonder min pic shape thank,issue,negative,negative,negative,negative,negative,negative
439933177,"If you use PyTorch the input to a ConvNet should be shaped like [batch, channels, height, width].

Keras offers two modes: ""channels_last"" corresponds to inputs with shape (batch, height, width, channels) while ""channels_first"" corresponds to inputs with shape (batch, channels, height, width)"" https://keras.io/layers/convolutional/

My take on what sets the max size of an image is that your batch of images should fit into your RAM. ",use input shaped like batch height width two shape batch height width shape batch height width take size image batch fit ram,issue,positive,positive,positive,positive,positive,positive
439596498,I pulled and installed this repo 2 days ago. So bleeding edge? I am at the moment unable to check the exact version as this is installed at work.,day ago bleeding edge moment unable check exact version work,issue,negative,negative,negative,negative,negative,negative
439561028,"Hi @cutechestnut. Thank you for the bug report, I'll be looking into this issue.
",hi thank bug report looking issue,issue,negative,neutral,neutral,neutral,neutral,neutral
439560782,"Hi @JaspervDalen , thank you for the bug report. Could you please specify the version of autokeras?",hi thank bug report could please specify version,issue,positive,neutral,neutral,neutral,neutral,neutral
439525514,"## Pull Request Test Coverage Report for [Build 998](https://coveralls.io/builds/20152332)

* **24** of **25**   **(96.0%)**  changed or added relevant lines in **6** files are covered.
* No unchanged relevant lines lost coverage.
* Overall coverage decreased (**-0.02%**) to **94.954%**

---

|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |
| :-----|--------------|--------|---: |
| [autokeras/text/text_preprocessor.py](https://coveralls.io/builds/20152332/source?filename=autokeras%2Ftext%2Ftext_preprocessor.py#L182) | 6 | 7 | 85.71%
<!-- | **Total:** | **24** | **25** | **96.0%** | -->


|  Totals | [![Coverage Status](https://coveralls.io/builds/20152332/badge)](https://coveralls.io/builds/20152332) |
| :-- | --: |
| Change from base [Build 990](https://coveralls.io/builds/20150035): |  -0.02% |
| Covered Lines: | 2390 |
| Relevant Lines: | 2517 |

---
##### 💛  - [Coveralls](https://coveralls.io)
",pull request test coverage report build added relevant covered unchanged relevant lost coverage overall coverage missing coverage covered total coverage status change base build covered relevant coverall,issue,negative,positive,neutral,neutral,positive,positive
439455366,"## Pull Request Test Coverage Report for [Build 980](https://coveralls.io/builds/20147899)

* **6** of **6**   **(100.0%)**  changed or added relevant lines in **1** file are covered.
* No unchanged relevant lines lost coverage.
* Overall coverage increased (+**0.01%**) to **94.916%**

---



|  Totals | [![Coverage Status](https://coveralls.io/builds/20147899/badge)](https://coveralls.io/builds/20147899) |
| :-- | --: |
| Change from base [Build 977](https://coveralls.io/builds/20147446): |  0.01% |
| Covered Lines: | 2371 |
| Relevant Lines: | 2498 |

---
##### 💛  - [Coveralls](https://coveralls.io)
",pull request test coverage report build added relevant file covered unchanged relevant lost coverage overall coverage coverage status change base build covered relevant coverall,issue,negative,positive,neutral,neutral,positive,positive
439418366,Please can you help me I find the same error when I fine tune Unet architecture.,please help find error fine tune architecture,issue,negative,positive,positive,positive,positive,positive
439389452,"> @csteel45 I got the same error, could you please explain how to fix this error?

@Bjoux2  Sorry, I was on travel this week.

In search.py change the line: ctx = mp.get_context('fork')
to
ctx = mp.get_context('spawn')

I added some extra code to address running in a virtualenv so I don't have the exact line number.",got error could please explain fix error sorry travel week change line added extra code address running exact line number,issue,negative,negative,neutral,neutral,negative,negative
439234791,@jhfjhfj1 it's mid-November and I still seem to have this issue when I try to install with `pip3`,still seem issue try install pip,issue,negative,neutral,neutral,neutral,neutral,neutral
439072161,"You mean clf.export_autokeras_model?
How can I transform this to a keras model after the export?
I can't load the autokeras model.

Unfortunately there is no alternative to
clf.load_searcher().load_best_model().produce_keras_model().save('my_model.h5')
with produce autokeras model.",mean transform model export ca load model unfortunately alternative produce model,issue,negative,negative,negative,negative,negative,negative
438616822,I believe this has to do with data transformation issues. Try using `export_autokeras_model` instead.,believe data transformation try instead,issue,negative,neutral,neutral,neutral,neutral,neutral
438537110,"@csteel45 I got the same error, could you please explain how to fix this error? ",got error could please explain fix error,issue,negative,neutral,neutral,neutral,neutral,neutral
438432050,"@tl-yang Yes, although it is hard to implement ALL the tqdm features since there is no ipywidgets support, my plan is to implement a ugly but workable progressbar without the support of ipywidgets.

I will check your case and try to make it work.",yes although hard implement since support plan implement ugly workable without support check case try make work,issue,positive,negative,negative,negative,negative,negative
438403132,"Hi @chengs, thanks for the great work. With the patch, tqdm should be able to support tqdm.notebook on Google Colab, Is my understanding correct?  
I've tried our original usage of tqdm:
```python
from tqdm.autonotebook import tqdm
progress_bar = tqdm(total=len(
    desc='Epoch-'
    + str(self.current_epoch)
    + ', Current Metric - '
    + str(self.current_metric_value),
    file=sys.stdout,
    leave=False,
    ncols=100,
    position=0,
    unit=' batch')
``` 
Still I got the same error code.
",hi thanks great work patch able support understanding correct tried original usage python import current metric batch still got error code,issue,positive,positive,positive,positive,positive,positive
438227435,"Hi, I am a tqdm developer and am trying to address this problem.
I have a PR which has minimal function https://github.com/tqdm/tqdm/pull/640
Could you please try it and give me some feedbacks? (eg. If it is enough for you).",hi developer trying address problem minimal function could please try give enough,issue,negative,negative,neutral,neutral,negative,negative
438183447,"Thx for your answer chris, can you give me the changes i have to do, to get it working under windows? 

Greetz Tim ",answer give get working,issue,negative,neutral,neutral,neutral,neutral,neutral
438020040,"Hi @shyamalschandra , thank you for the suggestion. There are two things I would like to discuss with you before we start.

1. You mentioned that tdqm doesn't work on Google CoLab and you use pyprind to address the issue. I would prefer to change from 
```python  
from tqdm.autonotebook import tqdm
``` 

to 

```python
from tqdm import tqdm
```  
which can also resolve the issue without having to change the dependency.
I'll open up another issue for this problem.

2. Could you please explain how you are going to make Autokeras run distributely? 
    Providing some code snippets will be very helpful. 

Thanks a lot!
",hi thank suggestion two would like discus start work use address issue would prefer change python import python import also resolve issue without change dependency open another issue problem could please explain going make run providing code helpful thanks lot,issue,positive,positive,neutral,neutral,positive,positive
437953778,"Correct. It doesn’t work under Windows which doesn’t support fork. Instead, you need to change the fork to a spawn so that it is cross-platform. The alternative is to check the OS and call fork for Unix-based systems and Spawn for Windows-based systems.

 

-Chris

 

From: Timmmeyyy <notifications@github.com>
Reply-To: jhfjhfj1/autokeras <reply@reply.github.com>
Date: Monday, November 12, 2018 at 11:12 AM
To: jhfjhfj1/autokeras <autokeras@noreply.github.com>
Cc: Christopher Steel <csteel@fortmoon.com>, Mention <mention@noreply.github.com>
Subject: Re: [jhfjhfj1/autokeras] Autokeras does not work on Windows due to fork (#300)

 

So I got i right, under Ubuntu it will work and i didnt get the fork error?

—
You are receiving this because you were mentioned.
Reply to this email directly, view it on GitHub, or mute the thread.

",correct work support fork instead need change fork spawn alternative check o call fork spawn reply date steel mention mention subject work due fork got right work didnt get fork error reply directly view mute thread,issue,positive,positive,neutral,neutral,positive,positive
437937275,"So I got i right, under Ubuntu it will work and i didnt get the fork error?",got right work didnt get fork error,issue,negative,positive,positive,positive,positive,positive
437916777,"@boyuangong Please add the tutorial for the image, text and the cnn_module, MLP module (In progress) to the documentation, with example code. Thanks.",please add tutorial image text module progress documentation example code thanks,issue,positive,positive,positive,positive,positive,positive
437638778,"It will crash

 

From: tl-yang <notifications@github.com>
Reply-To: jhfjhfj1/autokeras <reply@reply.github.com>
Date: Saturday, November 10, 2018 at 4:54 PM
To: jhfjhfj1/autokeras <autokeras@noreply.github.com>
Cc: Christopher Steel <csteel@fortmoon.com>, Mention <mention@noreply.github.com>
Subject: Re: [jhfjhfj1/autokeras] Autokeras does not work on Windows due to fork (#300)

 

Hi @csteel45 , will the error cause Autokeras to crash? Or it just appear on the terminal?

—
You are receiving this because you were mentioned.
Reply to this email directly, view it on GitHub, or mute the thread.

",crash reply date steel mention mention subject work due fork hi error cause crash appear terminal reply directly view mute thread,issue,negative,negative,neutral,neutral,negative,negative
437624249,"Hi @csteel45 , will the error cause Autokeras to crash? Or it just appear on the terminal?",hi error cause crash appear terminal,issue,negative,neutral,neutral,neutral,neutral,neutral
436888150,"win10.
autokeras:0.2.18
but the code get the new Bug:

Traceback (most recent call last):

  File ""<ipython-input-7-68b06ee81421>"", line 1, in <module>
    runfile('C:/Users/75129/Desktop/mypy/my model.py', wdir='C:/Users/75129/Desktop/mypy')

  File ""C:\Users\75129\AppData\Local\conda\conda\envs\keras1\lib\site-packages\spyder_kernels\customize\spydercustomize.py"", line 678, in runfile
    execfile(filename, namespace)

  File ""C:\Users\75129\AppData\Local\conda\conda\envs\keras1\lib\site-packages\spyder_kernels\customize\spydercustomize.py"", line 106, in execfile
    exec(compile(f.read(), filename, 'exec'), namespace)

  File ""C:/Users/75129/Desktop/mypy/my model.py"", line 156, in <module>
    clf.fit(train_x,train_y,time_limit=1*60)

  File ""C:\Users\75129\AppData\Local\conda\conda\envs\keras1\lib\site-packages\autokeras\image_supervised.py"", line 239, in fit
    run_searcher_once(train_data, test_data, self.path, int(time_remain))

  File ""C:\Users\75129\AppData\Local\conda\conda\envs\keras1\lib\site-packages\autokeras\image_supervised.py"", line 40, in run_searcher_once
    searcher.search(train_data, test_data, timeout)

  File ""C:\Users\75129\AppData\Local\conda\conda\envs\keras1\lib\site-packages\autokeras\search.py"", line 178, in search
    pool = mp.Pool(1)

  File ""C:\Users\75129\AppData\Local\conda\conda\envs\keras1\lib\multiprocessing\context.py"", line 119, in Pool
    context=self.get_context())

  File ""C:\Users\75129\AppData\Local\conda\conda\envs\keras1\lib\multiprocessing\pool.py"", line 174, in __init__
    self._repopulate_pool()

  File ""C:\Users\75129\AppData\Local\conda\conda\envs\keras1\lib\multiprocessing\pool.py"", line 239, in _repopulate_pool
    w.start()

  File ""C:\Users\75129\AppData\Local\conda\conda\envs\keras1\lib\multiprocessing\process.py"", line 105, in start
    self._popen = self._Popen(self)

  File ""C:\Users\75129\AppData\Local\conda\conda\envs\keras1\lib\multiprocessing\context.py"", line 322, in _Popen
    return Popen(process_obj)

  File ""C:\Users\75129\AppData\Local\conda\conda\envs\keras1\lib\multiprocessing\popen_spawn_win32.py"", line 33, in __init__
    prep_data = spawn.get_preparation_data(process_obj._name)

  File ""C:\Users\75129\AppData\Local\conda\conda\envs\keras1\lib\multiprocessing\spawn.py"", line 173, in get_preparation_data
    main_mod_name = getattr(main_module.__spec__, ""name"", None)

AttributeError: module '__main__' has no attribute '__spec__'",win code get new bug recent call last file bee line module file line file line compile file line module file line fit file line file line search pool file line pool file line file line file line start self file line return file line file line name none module attribute,issue,positive,positive,positive,positive,positive,positive
436886777,"Finally got it working after I copied some code from a post showing how to copy the environment info over. Also, when I first ran it, I kept getting an access denied error. I found a different post that suggested that I change to the directory of the process (my virtualenv). That fixed the issue. Lastly, you need to add the NVDIA-SMI directory to your path or you get:
'nvidia-smi' is not recognized as an internal or external command",finally got working copied code post showing copy environment also first ran kept getting access error found different post change directory process fixed issue lastly need add directory path get internal external command,issue,negative,positive,neutral,neutral,positive,positive
436875938,Great. Please also ensure that you address the use of virtual environments. I changed my local copy to use spawn instead of fork but I am having issues that I believe may be related to my virtualenv for tensorflow.,great please also ensure address use virtual local copy use spawn instead fork believe may related,issue,positive,positive,positive,positive,positive,positive
436833042,"@zhoukaisheng Hi, thank you for reporting to us. Do you mind tell us what's your OS platform and which version of autokeras you're now using? ",hi thank u mind tell u o platform version,issue,negative,neutral,neutral,neutral,neutral,neutral
436831858,"@csteel45 Yes, you're right, Windows doesn't support **fork**. The recent why we use **fork** is just to be able to run it on Google Colab. So I think this issue can be easily addressed by detecting the current structure. I'll take care of it ASAP!",yes right support fork recent use fork able run think issue easily current structure take care,issue,positive,positive,positive,positive,positive,positive
436649141,"@tl-yang Would you please look into this issue?
Thanks.",would please look issue thanks,issue,positive,positive,positive,positive,positive,positive
436339557,#130 Thanks for the request. I'm currently working on these two issues.,thanks request currently working two,issue,negative,positive,neutral,neutral,positive,positive
435773822,"Since this issue is already solve, I will just close the pr.",since issue already solve close,issue,negative,neutral,neutral,neutral,neutral,neutral
435772540,"Since we have found a more thorogh solution for this task, we close the pr.
Thank you so much for your contribution.",since found solution task close thank much contribution,issue,positive,positive,positive,positive,positive,positive
435717975,"I made a new section called Getting Started with Docker. 
You are welcome",made new section getting docker welcome,issue,negative,positive,positive,positive,positive,positive
435652259,"How is one supposed to use [`autokeras.constant.Constant`](https://github.com/jhfjhfj1/autokeras/blob/master/autokeras/constant.py)? Is it enough to make

```
import autokeras
autokeras.constant.Constant.MAX_BATCH_SIZE = 64
autokeras.constant.Constant.MAX_LAYERS = 5
```

before fitting?",one supposed use enough make import fitting,issue,negative,positive,positive,positive,positive,positive
435628858,"@garawalid Thank you very much for creating the docker file!

Instead of changing the readme.md, would you please add a new file called docker.md in mkdocs/docs ? And remember to modify the mkdocs.yml as well.
Please do not put the latest version number in the md file.
We don't want to manually updated it every time we have a new release.

Thanks.",thank much docker file instead would please add new file remember modify well please put latest version number file want manually every time new release thanks,issue,positive,positive,positive,positive,positive,positive
435585611,"thanks @mlaradji  

I will try to manually compile TensorFlow.
",thanks try manually compile,issue,negative,positive,positive,positive,positive,positive
435520012,"I am facing the same problem and it seems to be an infinite loop. In 'search.py' (line 219), we have the following:
```
        except RuntimeError as e:
            if not re.search('out of memory', str(e)):
                raise e
            if self.verbose:
                print('\nCurrent model size is too big. Discontinuing training this model to search for other models.')
            Constant.MAX_MODEL_SIZE = graph.size() - 1
            print(Constant.MAX_MODEL_SIZE) # Not in original file.
            return
```
As shown above, I have added a `print(Constant.MAX_MODEL_SIZE)`, which showed that `Constant.MAX_MODEL_SIZE` stays constant (because `graph.size()` does not change) after each iteration of `Current model size is too big. Discontinuing training this model to search for other models.`. 

I'm unsure whether it's a mistake in the code or a misunderstanding on my part, but it seems that `Constant.MAX_MODEL_SIZE` should be reduced everytime there was not enough memory to load a model, for example by having `Constant.MAX_MODEL_SIZE = max(1, round(Constant.MAX_MODEL_SIZE/2))` instead of `Constant.MAX_MODEL_SIZE = graph.size() - 1`.

### Update
Using `Constant.MAX_MODEL_SIZE = max(1, round(Constant.MAX_MODEL_SIZE/2))` does not work for me. Though the model is (seemingly) successfully loaded in memory, it is not being trained (GPU usage: Mem: 1908/2002 MB; Util: 0%). The output from autokeras shows that it is stuck:
```
Initializing search.
Initialization finished.


+----------------------------------------------+
|               Training model 0               |
+----------------------------------------------+

Saving model.
+--------------------------------------------------------------------------+
|        Model ID        |          Loss          |      Metric Value      |
+--------------------------------------------------------------------------+
|           0            |   24.642928409576417   |         0.2808         |
+--------------------------------------------------------------------------+


+----------------------------------------------+
|               Training model 1               |
+----------------------------------------------+

Current model size is too big. Discontinuing training this model to search for other models.

Reduced Constant.MAX_MODEL_SIZE down to 16777216.


+----------------------------------------------+
|               Training model 1               |
+----------------------------------------------+

Current model size is too big. Discontinuing training this model to search for other models.

Reduced Constant.MAX_MODEL_SIZE down to 8388608.


+----------------------------------------------+
|               Training model 1               |
+----------------------------------------------+

Current model size is too big. Discontinuing training this model to search for other models.

Reduced Constant.MAX_MODEL_SIZE down to 4194304.


+----------------------------------------------+
|               Training model 1               |
+----------------------------------------------+

Current model size is too big. Discontinuing training this model to search for other models.

Reduced Constant.MAX_MODEL_SIZE down to 2097152.


+----------------------------------------------+
|               Training model 1               |
+----------------------------------------------+

Current model size is too big. Discontinuing training this model to search for other models.

Reduced Constant.MAX_MODEL_SIZE down to 1048576.


+----------------------------------------------+
|               Training model 1               |
+----------------------------------------------+

Current model size is too big. Discontinuing training this model to search for other models.

Reduced Constant.MAX_MODEL_SIZE down to 524288.


+----------------------------------------------+
|               Training model 1               |
+----------------------------------------------+

Current model size is too big. Discontinuing training this model to search for other models.

Reduced Constant.MAX_MODEL_SIZE down to 262144.


+----------------------------------------------+
|               Training model 1               |
+----------------------------------------------+
#Model is stuck at this point.#
```",facing problem infinite loop line following except memory raise print model size big training model search print original file return shown added print stay constant change iteration current model size big training model search unsure whether mistake code misunderstanding part reduced enough memory load model example round instead update round work though model seemingly successfully loaded memory trained usage mem output stuck search finished training model saving model model id loss metric value training model current model size big training model search reduced training model current model size big training model search reduced training model current model size big training model search reduced training model current model size big training model search reduced training model current model size big training model search reduced training model current model size big training model search reduced training model current model size big training model search reduced training model model stuck,issue,negative,positive,neutral,neutral,positive,positive
435232353,I put the installation and the example in the same folder as `autokeras-docker` in the `readme.md`. Do I have to add it to `mkdocs/start.md` instead?,put installation example folder add instead,issue,negative,neutral,neutral,neutral,neutral,neutral
434823809,"Hi @ronykroy,

I believe the problem occurs because the `text` module, along with the `nn` or `image` modules, don't get installed with `pip install autokeras`, which is my case as well. As a temporary solution, you can clone the repository and either use autokeras from there, or copy the submodules you need to your Python's autokeras ($PYTHON_DIR/lib/python3.6/site-packages/autokeras).

As for why the submodules don't get installed, my (unexpert) intuition is that there's something wrong with the `setup.py` file and/or the pip package.
",hi believe problem text module along image get pip install case well temporary solution clone repository either use copy need python get unexpert intuition something wrong file pip package,issue,negative,negative,negative,negative,negative,negative
434515325,"It seems to me that this problem would be solved if we implemented a model size constraint on A* search i.e. do not expand the nodes that represent too big models.

I think it could be implemented somewhere here:
autokeras/search.py, line 187:
```python
  if not self.training_queue:
                searched = True

                while new_father_id is None:
                    remaining_time = timeout - (time.time() - start_time)
                    new_graph, new_father_id = self.bo.optimize_acq(self.search_tree.adj_list.keys(),
                                                                    self.descriptors,
                                                                    remaining_time)
                new_model_id = self.model_count
                self.model_count += 1
                self.training_queue.append((new_graph, new_father_id, new_model_id))
                self.descriptors.append(new_graph.extract_descriptor())
```
Is this a reasonable idea ?",problem would model size constraint search expand represent big think could somewhere line python true none reasonable idea,issue,negative,positive,positive,positive,positive,positive
434506755,"So I've tested that code on my setup and it worked fine (apart from some irrelevant dependency issues in `tqdm`). I think it is probably a problem with your CUDA setup. I have previously ran into trouble getting CUDA to work, which only resolved when I compiled TensorFlow with my CUDA.

Note that my setup is different from yours:
OS : Ubuntu 18.04.1
CUDA 10.0.134
CUDNN 7.3.1
TensorFlow 1.11.0 (manually compiled)
AutoKeras 0.2.18
Keras 2.2.2",tested code setup worked fine apart irrelevant dependency think probably problem setup previously ran trouble getting work resolved note setup different o manually,issue,negative,negative,neutral,neutral,negative,negative
434485376,"I'm interested in working on this. Perhaps we could integrate `hyperopt`, `Chocolate`, or `Advisor` (which combines `hyperopt` and `Chocolate` in its own API) into `autokeras`.",interested working perhaps could integrate chocolate advisor chocolate,issue,negative,positive,positive,positive,positive,positive
434117489,"@aojue1109 
I was trying to reproduce the error that you reported using the following scenario but unable to do that.
My training set has 2000 images (1000 each of cat and dog images from Cat vs Dog image classification task). The images have arbitrary sizes in the training set and hence I resized all of them to 324 x 324 x 3 since you have mentioned that the images in your scenario are the same. I have verified that I am training my network on a CPU not GPU. 

The following is the code that I used
```
x_train, y_train = load_image_dataset(csv_file_path=""labels.csv"", images_path=""data"")

x_temp = []
for x in x_train:
    x_temp.append(scipy.misc.imresize(x, [324, 324, 3]))
x_train = numpy.array(x_temp)

if __name__ == '__main__':
    clf = ImageClassifier(verbose=True, augment=False)
    clf.fit(x_train, y_train, time_limit=12 * 60 * 60)

```
Despite the scenario, my model is training without any failure but it is insanely slow because of the obvious reasons. 

Can you please let me know the exact steps to reproduce the issue. Before doing that, it will be good If you can verify whether the issue is reproducible in your environment with the latest pull request. Please let me know.

Thanks,
Satya",trying reproduce error following scenario unable training set cat dog cat dog image classification task arbitrary size training set hence since scenario training network following code used data despite scenario model training without failure insanely slow obvious please let know exact reproduce issue good verify whether issue reproducible environment latest pull request please let know thanks,issue,positive,positive,neutral,neutral,positive,positive
433712844,"Hi Mlaradji,

Here is my samlpe of code

```
from autokeras.image_supervised import ImageClassifier

if __name__ == '__main__':

   # get image data from factory......
  
   x_train = # get training data 
   y_train = # get label of training data
   x_test = # get test data 
   y_test = # get label of test data

    x_train = x_train.reshape(x_train.shape + (1,))
    x_test = x_test.reshape(x_test.shape + (1,))

    clf = ImageClassifier(verbose=True)
    clf.fit(x_train, y_train, time_limit=12 * 60 * 60)
    clf.final_fit(x_train, y_train, x_test, y_test, retrain=True)
    y = clf.evaluate(x_test, y_test)
    print(y)
```

Sample code just like example of autokeras official website.

Thank you.",hi code import get image data factory get training data get label training data get test data get label test data print sample code like example official thank,issue,positive,neutral,neutral,neutral,neutral,neutral
433527184,"I believe I misunderstood your build process, seeing the version branch for 0.2.18",believe misunderstood build process seeing version branch,issue,negative,neutral,neutral,neutral,neutral,neutral
433524443,"Hi Eton,

Could you post a sample of the code with `ImageClassifier` that failed for you? I would like to test it on my system.",hi could post sample code would like test system,issue,negative,neutral,neutral,neutral,neutral,neutral
432874213,"@xuean009  Would you please provide the code for how you saved the model? Thanks.
",would please provide code saved model thanks,issue,positive,positive,positive,positive,positive,positive
432577889,"sadly not. I have this problem using a couple of datasets but cifar10 is the most basic example, that's why I gave it. (It also works for the developing team according to the paper)",sadly problem couple basic example gave also work team according paper,issue,negative,negative,negative,negative,negative,negative
432400490,"## Pull Request Test Coverage Report for [Build 800](https://coveralls.io/builds/19679458)

* **2** of **2**   **(100.0%)**  changed or added relevant lines in **1** file are covered.
* **2** unchanged lines in **1** file lost coverage.
* Overall coverage decreased (**-0.04%**) to **94.699%**

---


|  Files with Coverage Reduction | New Missed Lines | % |
| :-----|--------------|--: |
| [autokeras/bayesian.py](https://coveralls.io/builds/19679458/source?filename=autokeras%2Fbayesian.py#L103) | 2 | 95.88% |
<!-- | **Total:** | **2** |  | -->

|  Totals | [![Coverage Status](https://coveralls.io/builds/19679458/badge)](https://coveralls.io/builds/19679458) |
| :-- | --: |
| Change from base [Build 798](https://coveralls.io/builds/19649120): |  -0.04% |
| Covered Lines: | 2108 |
| Relevant Lines: | 2226 |

---
##### 💛  - [Coveralls](https://coveralls.io)
",pull request test coverage report build added relevant file covered unchanged file lost coverage overall coverage coverage reduction new total coverage status change base build covered relevant coverall,issue,negative,positive,neutral,neutral,positive,positive
432276194,@malizheng Thank you! This is an important issue we need to solve.,thank important issue need solve,issue,positive,positive,positive,positive,positive,positive
432275748,"@Npccc Please refer to this issue #186 .
We will try to make it easier to use in the future. Thanks.",please refer issue try make easier use future thanks,issue,positive,positive,neutral,neutral,positive,positive
432274683,"@vincent-hui Yes, we are working on this issue.
Please refer to #105 .
Thanks.",yes working issue please refer thanks,issue,positive,positive,positive,positive,positive,positive
432274430,"@woj-i The concept of autokeras is to hide all the preprocessing details from the user. If you want to pass the customized processed data to it, you need to use the CnnModule class to directly do the neural architecture search. Thanks.

Sorry for the confusing documentation. We will update it soon.",concept hide user want pas data need use class directly neural architecture search thanks sorry documentation update soon,issue,negative,negative,neutral,neutral,negative,negative
432273366,Currently we only support python3.6. Thanks. @VictorZhang2014 ,currently support python thanks,issue,positive,positive,neutral,neutral,positive,positive
432273119,"@moon412 Yes, it is totally possible. You need to write a new class extending the ImageClassifier and override the metric function part. Thanks.",moon yes totally possible need write new class extending override metric function part thanks,issue,positive,positive,positive,positive,positive,positive
432272684,"Currently, you cannot customize it with the API. You can only customize it by forking and changing the code yourself, which is not very easy to do. Thanks.",currently code easy thanks,issue,positive,positive,positive,positive,positive,positive
432272216,@LeoWang We are focusing on the functionality part now. Will consider supporting multiple platforms in the future. Thanks,functionality part consider supporting multiple future thanks,issue,positive,positive,positive,positive,positive,positive
432218493,"Bug Description
when I predict the data after training model, the result :
array(['0'], dtype='<U1')
when I save and reload the model, the result:
array([[ 2.2954037, -1.2626443]], dtype=float32)

So I try to add softmax after whole model, but it also  does not work.
Any ideas will be appreciated.
",bug description predict data training model result array save reload model result array try add whole model also work,issue,negative,positive,positive,positive,positive,positive
431733229,"I have the same problem.I used the keras model output from autokera to predict the image and found that the accuracy was very low.I added the solution you provided, but still did not solve the problem",used model output predict image found accuracy added solution provided still solve problem,issue,negative,neutral,neutral,neutral,neutral,neutral
431660017,"Same issue here. But how long will autokeras terminate on MNIST training? It's training on my mac in 8 hours. As screenshot below.

<img width=""1035"" alt=""wx20181021-191028 2x"" src=""https://user-images.githubusercontent.com/6853884/47266158-3efd4900-d565-11e8-8a0f-d93aaa3037be.png"">

How to get the resulted model? Which path does these models save? ",issue long terminate training training mac get model path save,issue,negative,negative,neutral,neutral,negative,negative
431553904,"Hi @jhfjhfj1!
In the docs the parametr augments is defined like:`
```
augment: A boolean value indicating whether the data needs augmentation. If not define, then it
                will use the value of Constant.DATA_AUGMENTATION which is True by default.
```
I think this is the first point, that needs to be clarify. I interpret the current definition like any kind of preprocessing.
However, I would still need a way to provide preprocessed text. E.g. there is IMDB set from Keras, that has list of numbers for features (indices of words) and a sentiment as the class. Currently it's impossible to apply it to the TextClassifier. What would you recommend?",hi defined like augment value whether data need augmentation define use value true default think first point need clarify interpret current definition like kind however would still need way provide text set list index sentiment class currently impossible apply would recommend,issue,positive,positive,positive,positive,positive,positive
431424363,"@woj-i Thank you for your contribution.
The augment has a different meaning than the preprocessing of the text.
Augment should mean increase the number of training examples by generating some new ones.

Maybe we should just delete this default parameter of augment.

Thanks.",thank contribution augment different meaning text augment mean increase number training generating new maybe delete default parameter augment thanks,issue,positive,positive,neutral,neutral,positive,positive
431307768,"## Pull Request Test Coverage Report for [Build 783](https://coveralls.io/builds/19612364)

* **3** of **7**   **(42.86%)**  changed or added relevant lines in **1** file are covered.
* No unchanged relevant lines lost coverage.
* Overall coverage decreased (**-0.04%**) to **94.684%**

---

|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |
| :-----|--------------|--------|---: |
| [autokeras/text/text_supervised.py](https://coveralls.io/builds/19612364/source?filename=autokeras%2Ftext%2Ftext_supervised.py#L62) | 3 | 7 | 42.86%
<!-- | **Total:** | **3** | **7** | **42.86%** | -->


|  Totals | [![Coverage Status](https://coveralls.io/builds/19612364/badge)](https://coveralls.io/builds/19612364) |
| :-- | --: |
| Change from base [Build 774](https://coveralls.io/builds/19493559): |  -0.04% |
| Covered Lines: | 2084 |
| Relevant Lines: | 2201 |

---
##### 💛  - [Coveralls](https://coveralls.io)
",pull request test coverage report build added relevant file covered unchanged relevant lost coverage overall coverage missing coverage covered total coverage status change base build covered relevant coverall,issue,negative,positive,neutral,neutral,positive,positive
430902234,"In addition to reinstalling `autokeras`, my Python version is the latest version of 3.7 that is not suitable for `autokeras` and `tensorflow==1.11.0`.  

Because when I ran tensorflow, it gave me the Runtime Error message, shown that: `RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.7`.

So my solution for the issue that is uninstalled python3.7 and reinstalled 3.6.6, `tensorflow` and `autokeras`, finally, everything worked well. ",addition python version latest version suitable ran gave error message shown version module match version solution issue uninstalled python finally everything worked well,issue,negative,positive,positive,positive,positive,positive
430481679,"I think @eagleoflqj comment is right but we need put code in the main function as follow.

```
import autokeras as ak

from keras.datasets import mnist
def main():
    (X_train, Y_train), (X_test, Y_test) = mnist.load_data()
    X_train = X_train.reshape(X_train.shape + (1,))
    X_test = X_test.reshape(X_test.shape + (1,))
    clf = ak.ImageClassifier(verbose=True, augment=False)
    clf.fit(X_train, Y_train)

if __name__ == ""__main__"":
    main()
```

Ref: https://stackoverflow.com/questions/24374288/where-to-put-freeze-support-in-a-python-script",think comment right need put code main function follow import ak import main main ref,issue,negative,positive,positive,positive,positive,positive
430467198,"@jhfjhfj1 
 Training model 60    
Using TensorFlow backend.
Current model size is too big. Discontinuing training this model to search for other models.
Search  stuck in one model(model 60) , always in this problem.(Data:cifar10).
",training model current model size big training model search search stuck one model model always problem data,issue,negative,neutral,neutral,neutral,neutral,neutral
430219419,"> Help needed.
> Does anyone know why it cannot work with Google Collaboratory and how to fix it?
> Thanks

@jhfjhfj1 In my case, it seems that lack of memory was the problem when I use google Colab. 
So I think that, some kind of batch generator such as fit_generator something could be useful to handle with the problem.
Do you have any plan to implement this idea?

By the way, autokeras is really easy, and powerful for me to do NAS for image classification!
Thank you so much for your kindness and effort for this :)

Now I'm gonna also try to use autokeras for other data types, such as time-series neuronal / behavior data - convert them into kind of 2-d array or text data. 
I saw that module for audio data is also being considered, and it will be really nice for them too!


",help anyone know work fix thanks case lack memory problem use think kind batch generator something could useful handle problem plan implement idea way really easy powerful image classification thank much kindness effort gon na also try use data neuronal behavior data convert kind array text data saw module audio data also considered really nice,issue,positive,positive,positive,positive,positive,positive
429618815,"Faced a similar problem:

After training the model using `clf.fit()` function, calling `clf.final_fit()` does not make any difference. The best model remains the same and does not get updated. So:
```
clf = ak.ImageClassifier(verbose=True, resume=True, path='autokeras-run')	
clf.final_fit(x_train, y_train, x_dev, y_dev, retrain=True)
y_test_pred = clf.predict(x_test)
```
leads to exactly the same results as:
```
clf = ak.ImageClassifier(verbose=True, resume=True, path='autokeras-run')
y_test_pred = clf.predict(x_test)
```",faced similar problem training model function calling make difference best model remains get exactly,issue,negative,positive,positive,positive,positive,positive
429422374,"@droidadroit Thanks.
You can try to follow our code review video last time to get familiar with the code, and we can have a meeting next Monday after the code review to see how to integrate your part into the code base.",thanks try follow code review video last time get familiar code meeting next code review see integrate part code base,issue,negative,negative,neutral,neutral,negative,negative
429386617,"Hi! Yes, I am working on it. It seems to be failing on trying to load
scripts from the text folder. I'll figure out whats going on. Thanks!

On Fri, Oct 12, 2018 at 11:28 AM Haifeng Jin <notifications@github.com>
wrote:

> @raijinspecial <https://github.com/raijinspecial> Would you please try to
> resolve the conflicts with the master branch and fix the failed unit tests?
> Thanks.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/jhfjhfj1/autokeras/pull/252#issuecomment-429383809>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ACxQ9P3z2hAMde1NhxLa-y6b0cXctTMLks5ukMM5gaJpZM4XURo5>
> .
>
",hi yes working failing trying load text folder figure whats going thanks wrote would please try resolve master branch fix unit thanks reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
429383809,@raijinspecial Would you please try to resolve the conflicts with the master branch and fix the failed unit tests? Thanks.,would please try resolve master branch fix unit thanks,issue,positive,positive,positive,positive,positive,positive
429383322,"@raijinspecial  Thank you for your contribution!
You can pull the latest master and directly edit on the original file instead of creating one in the root directory.
I think your solution is valid.
https://github.com/jhfjhfj1/autokeras/issues/226#issuecomment-428316462
",thank contribution pull latest master directly edit original file instead one root directory think solution valid,issue,positive,positive,positive,positive,positive,positive
429223402,"this issue solved.
after loaded model, i add it
x = keras_model.output 
x = Activation('softmax', name='activation_add')(x)  
keras_model = Model(keras_model.input, x)    

I refer to another Issue.
Thanks.",issue loaded model add activation model refer another issue thanks,issue,negative,positive,positive,positive,positive,positive
429192766,"autokeras==0.2.18

i used 3 ways that
clf.load_searcher().load_best_model().produce_keras_model().save()
and 
export_keras_model() & export_autokeras_model() 


I tried reload model after exported model function
and than
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.fit

result that accuracy is low and no more training even mnist data set and custom dataset. 
it's same situation

",used way tried reload model model function result accuracy low training even data set custom situation,issue,negative,neutral,neutral,neutral,neutral,neutral
429106337,"@jhfjhfj1 I have implemented audio classification using a two-layered neural network for UrbanSound on the sample dataset containing 10 training and 10 testing examples (all examples in each case belong to the 10 different classes).
1. Anything to report? FYI, its performance is bad. This is expected because it was trained on small data.
2. Should I implement this on the whole dataset?",audio classification neural network sample training testing case belong different class anything report performance bad trained small data implement whole,issue,negative,negative,negative,negative,negative,negative
429008581,"We don't have this problem.
Can you confirm the version number you use? Which is the latest version?
Thanks.",problem confirm version number use latest version thanks,issue,negative,positive,positive,positive,positive,positive
429007285,"@bersbersbers We will improve the documentations right after we finished some of our features. Thank you for your suggestion.

1. It can do regression.
2. It use pytorch. tensorflow and keras are for exporting keras model.
3. Currently we do not support it.",improve right finished thank suggestion regression use model currently support,issue,positive,positive,positive,positive,positive,positive
429006169,This might be a bug. I will investigate it. @twprinston Thanks.,might bug investigate thanks,issue,negative,positive,positive,positive,positive,positive
428625676,"@jhfjhfj1 Could you elaborate, please?

Your statement implies ""this error is generated by autokeras"", which is obvious. Your statement does not imply that this error is good or bad.

Does this mean that the model is not finding a good search criterion and that we should stop the algorithm / modify our data?  

Or does it mean that the algorithm is working as expected and we should continue.

thank you",could elaborate please statement error obvious statement imply error good bad mean model finding good search criterion stop algorithm modify data mean algorithm working continue thank,issue,negative,positive,neutral,neutral,positive,positive
428316462,"The following changes to image_supervised.py worked for me. Used imageio.imread to bring in images and skimage.transform.resize to make all images the same dimension by giving (x, y, z) where z=channels.

I tried to make a PR but I'm a noob and I think I did it in the wrong place.

```
def read_images(img_file_names, images_dir_path, normalized_size=None):
    """"""Read the images from the path and return their numpy.ndarray instance.
        Return a numpy.ndarray instance containing the training data.

    Args:
        img_file_names: List containing images names.
        images_dir_path: Path to the directory containing images.
        normalized_size: tuple specifying resize shape (x, y, z), z = channels
    """"""
    x_train = []
    if os.path.isdir(images_dir_path):
        for img_file in img_file_names:
            img_path = os.path.join(images_dir_path, img_file)
            if os.path.exists(img_path):
                # img = ndimage.imread(fname=img_path)
                img = imageio.imread(img_path)
                img = resize(img, output_shape=normalized_size, anti_aliasing=True)
                if len(img.shape) < 3:
                    img = img[..., np.newaxis]
                x_train.append(img)
            else:
                raise ValueError(""%s image does not exist"" % img_file)
    else:
        raise ValueError(""Directory containing images does not exist"")
    return np.asanyarray(x_train)
```",following worked used bring make dimension giving tried make think wrong place read path return instance return instance training data list path directory resize shape resize else raise image exist else raise directory exist return,issue,negative,negative,negative,negative,negative,negative
428056081,"same with @Lincoln-Jiang  
maybe the multiprocessing of searcher need more shm-size than default",maybe searcher need default,issue,negative,neutral,neutral,neutral,neutral,neutral
427979363,"@chencc6566193 Since this issue is kind of urgent, @jhfjhfj1 reassigned it to me as well. Please feel free to let me know if you had any progress, then we two can co-work on this one. Thanks!",since issue kind urgent well please feel free let know progress two one thanks,issue,positive,positive,positive,positive,positive,positive
427932595,"@dhlee-jubilee @rafaelmarconiramos 
This is a expected behavior. It should not affect the search.
Thanks.",behavior affect search thanks,issue,negative,positive,positive,positive,positive,positive
427597284,"@uditjuneja1 Thank you for your contribution.
However, we already have someone working on this, which is @satyakesav .
The solution is not that straightforward.
So I will just shut this down. Please specify the details of your contribution in the description of the pull request if you really think it is important to be merged.",thank contribution however already someone working solution straightforward shut please specify contribution description pull request really think important,issue,positive,positive,positive,positive,positive,positive
427529540,Searching for Efficient Multi-Scale Architectures for Dense Image Prediction code just released https://github.com/tensorflow/models/pull/5430,searching efficient dense image prediction code,issue,negative,neutral,neutral,neutral,neutral,neutral
427425832,"@jhfjhfj1 @boyuangong 
I am interested in contributing to the autokeras project, and think this would be a good task module to start with. What would be a good benchmark dataset to use?
As far as I can tell, ImageClassifier (in image_supervised.py) is the only task module that is currently fully implemented. Is this correct? I would want to use this for guidance in implementing the GeneralClassifier module. ",interested project think would good task module start would good use far tell task module currently fully correct would want use guidance module,issue,positive,positive,positive,positive,positive,positive
427288624,"This (unresolved) issue may be relevant:
https://github.com/tensorflow/tensorflow/issues/7166",unresolved issue may relevant,issue,negative,positive,positive,positive,positive,positive
427180646,"I had the same problem.
This error is ""out of memory problem.""
The searcher creates a very complex model, and don´t get to put to execute on GPU.
I didn't find a solution. If you find, share with us.",problem error memory problem searcher complex model get put execute find solution find share u,issue,negative,negative,negative,negative,negative,negative
426978353,The code maybe is trying to import Searcher form autokeras/search.,code maybe trying import searcher form,issue,negative,neutral,neutral,neutral,neutral,neutral
426760150,"@jhfjhfj1 I got the same error in my custom dataset, saying out of memory in the second model and stop searching. Any suggestion for this?

> Saving model.
+--------------------------------------------------------------------------+
|        Model ID        |          Loss          |      Metric Value      |
+--------------------------------------------------------------------------+
|           0            |   4.703066980093718    |   0.9453525641025642   |
+--------------------------------------------------------------------------+
                                                                           
                                                                           

> out of memory
> 
> 
> ╒==============================================╕
> |               Training model 1               |
> ╘==============================================╛
> Using TensorFlow backend.
> 
>                                                                            
>                                                                            out of memory
> 
> 
> ╒==============================================╕
> |               Training model 1               |
> ╘==============================================╛
> Using TensorFlow backend.
> 

",got error custom saying memory second model stop searching suggestion saving model model id loss metric value memory training model memory training model,issue,negative,neutral,neutral,neutral,neutral,neutral
426518883,"@jhfjhfj1 I just want to reload and compute the precision again, it's not a big deal. ",want reload compute precision big deal,issue,negative,neutral,neutral,neutral,neutral,neutral
426289360,"@satyakesav 
First, you may examine whether the data is loaded to GPU memory batch by batch, or all together.
If is loaded all together, try to change it to load batch by batch.
https://github.com/jhfjhfj1/autokeras/blob/master/autokeras/model_trainer.py#L219

Second, if the image is oversize (the total size is larger than 64*64*3), resize the image before feed into the NN, according to their original length/width ratio. Keep the size just right.

Thanks.",first may examine whether data loaded memory batch batch together loaded together try change load batch batch second image oversize total size resize image feed according original ratio keep size right thanks,issue,positive,positive,positive,positive,positive,positive
426012427,"> @boyuangong is this live yet? Is there a branch where the code lives currently? Very excited to see your work!

Thanks for your attention to our package! Now it’s moved to [WIP] textClassifier WIP #199. You can switch the branch to textClassifier for the latest code. It’s working now. But may need carefully choose the size of the input(you can customize the input length in the constant.py) to prevent the out of memory issue. I am currently waiting for code review and also working on the test coverage before merge it into the master branch.

Best,
Boyuan
",live yet branch code currently excited see work thanks attention package switch branch latest code working may need carefully choose size input input length prevent memory issue currently waiting code review also working test coverage merge master branch best,issue,positive,positive,positive,positive,positive,positive
425936864,@boyuangong is this live yet? Is there a branch where the code lives currently? Very excited to see your work!,live yet branch code currently excited see work,issue,negative,positive,positive,positive,positive,positive
425765063,"@satyakesav The code is good to merge.
There are some minor comments on how to create the pull request for you to follow next time.
1. Start the pull request the first day you start to write code and mark it [WIP].
2. Please change [WIP] to [MRG] when done.
3. For most of the pull request should be checked out from and request to develop branch, unless it is a very urgent bug fix.

Thank you for your work.",code good merge minor create pull request follow next time start pull request first day start write code mark please change done pull request checked request develop branch unless urgent bug fix thank work,issue,positive,positive,positive,positive,positive,positive
425757176,"It should not be one-hot-encoded when feed to autokeras.

I assume this issue is resolved.
Thank you all for the contribution.",feed assume issue resolved thank contribution,issue,negative,neutral,neutral,neutral,neutral,neutral
425757052,"@zuoxiang95 It would be solved together with issue #221 .
Thanks.",would together issue thanks,issue,negative,positive,positive,positive,positive,positive
425756410,"@wernergkrebs 

Thank you for the contribution and suggestions!
You are right! It works now.

I will improve on how I manage these pull requests, and hope to see more comments and contributions from you in the future.

Would you please increase the test coverage a little bit for your code?
https://coveralls.io/builds/19272393/source?filename=autokeras%2Fimage1D_supervised.py#L139
Then I will merge it.

Thanks.
",thank contribution right work improve manage pull hope see future would please increase test coverage little bit code merge thanks,issue,positive,positive,neutral,neutral,positive,positive
425754157,"> @wernergkrebs Usually for our unit test, it can finish within 1 or two minutes.
> There must be something wrong with your test code.
> Might because of the mock is not correct.

HI @jhfjhfj1 , I'm not going to argue with you on this. As project owner, you will often be called upon to diagnose issues with your code, and should not expect others to do this for you.

In my tests, your code passed tests but did so slowly, and the output from the GitHub build in fact shows it timing out in your existing code sections, which were not touched. You are using a random number generator to generate test cases, so variable build and test times are to be expected with such a setup.

My assertion is that the tests pass, they just sometimes take slightly then the allowed GitHub timeout, and the length of time for the tests to pass is variable due to the use of random number generator to generate test cases. I believe the issue can be mitigated by following Github's own suggestion to either increase test timeout length or request GitHub retry the build. 

In any event, if new tests are added, one would expect test builds to take longer, so running into a timeout as code grows is not unexpected. It doesn't seem like you've investigated whether this is possible, or tried to run the tests in your own build environment to get timings on how long the tests take to pass on average, but simply have asserted without evidence the problem ""must be"" in the newly checked in code, without examining the issue at all or trying to do your own test builds, which only takes a few minutes.",usually unit test finish within two must something wrong test code might mock correct hi going argue project owner often upon diagnose code expect code slowly output build fact timing code touched random number generator generate test variable build test time setup assertion pas sometimes take slightly length time pas variable due use random number generator generate test believe issue following suggestion either increase test length request retry build event new added one would expect test take longer running code unexpected seem like whether possible tried run build environment get long take pas average simply without evidence problem must newly checked code without examining issue trying test,issue,negative,negative,negative,negative,negative,negative
425752548,"Awesome, great work! I figured it was probably due to the different resolutions. I used this code:
def proc_images():
    """"""
    Returns two arrays: 
        x is an array of resized images
        y is an array of labels
    """"""
    
    drone=""yes""

    x = [] # images as arrays
    y = [] # labels Infiltration or Not_infiltration
    WIDTH = 128
    HEIGHT = 128

    for img in images:
        base = os.path.basename(img)
        finding = labels[""Label""][labels[""File Name""] == base].values[0]

        # Read and resize image
        full_size_image = cv2.imread(img)
        x.append(cv2.resize(full_size_image, (WIDTH,HEIGHT), interpolation=cv2.INTER_CUBIC))

        # Labels
        if drone in finding:
            #finding = str(disease)
            finding = 1
            y.append(finding)

        else:
            #finding = ""Not_"" + str(disease)
            finding = 0
            y.append(finding)

    return x,y

which I borrowed from a kaggle kernel: https://www.kaggle.com/crawford/resize-and-save-images-as-numpy-arrays-128x128

to resize the images, and this worked for autokeras. It made me think if there is any automated, or in principle method to find the optimal resizing parameters for any arbitrary set of images, as you rightly point out that resizing can result in information loss or distortion. I don't have a solution for that yet but if I find one I will report it.",awesome great work figured probably due different used code two array array yes infiltration width height base finding label file name base read resize image width height drone finding finding disease finding finding else finding disease finding finding return kernel resize worked made think principle method find optimal arbitrary set rightly point result information loss distortion solution yet find one report,issue,positive,positive,neutral,neutral,positive,positive
425747520,"@wernergkrebs Usually for our unit test, it can finish within 1 or two minutes.
There must be something wrong with your test code.
Might because of the mock is not correct.",usually unit test finish within two must something wrong test code might mock correct,issue,negative,negative,negative,negative,negative,negative
425747182,@jhfjhfj1  I'll test this a little bit more. I found something unexpected process closing error.,test little bit found something unexpected process error,issue,negative,negative,neutral,neutral,negative,negative
425746688,"@tl-yang Is this one ready to merge?
If so, please request code review, change assignee, and, change the [WIP] to [MRG].",one ready merge please request code review change assignee change,issue,positive,positive,positive,positive,positive,positive
425744109,"I think I've figured out why I was running into problems. The problem was that my `jpg` images were not of the same resolution. 

### Fix?
I normalized my images to the same resolution by adding the following lines, and a new option `normalized_size`, to `autokeras.image_supervised.read_images`:
```
import cv2
...
                img = cv2.imread(img_path)
                img = cv2.resize(img, dsize=normalized_size, interpolation=cv2.INTER_CUBIC)
```

Executing the following lines results in the desired output:
```
x_train, y_train = load_image_dataset(csv_file_path=""data/train/labels.csv"",
                                      images_path=""data/train"", normalized_size = (100,100))
print(x_train.shape)
print(y_train.shape)
```
Output:
```
(13750, 100, 100, 3)
(13750,)
``` 

Running the training then proceeds without error.

### Pull Request

I think requiring that the images be of the same resolution is good behavior, as I've read that usually speeds up the training. I think at least one of the following functionality could be added to autokeras:
1. I think it is useful having an option in `autokeras.image_supervised.load_image_dataset`, or perhaps a separate function, to normalize an image dataset to the same resolution. However, there are possible problems that could occur. Reducing an image's resolution could cause data loss, and, depending on the way the resolution is changed, the images might be changed too much and it might throw off the training. Note that my knowledge in this area is very limited.
2. `help(autokeras.image_supervised.load_image_dataset)` could include a line indicating that images need to be of the same size.
3. Allow image datasets that have multiple resolutions. This is probably the most desirable, but I foresee that it would require changes to functions outside of `image_supervised.py`.

If one (or more) of the options seems desirable, I could code in the relevant sections and submit a pull request.

### Changed Functions

For reference, the following are the changed functions in `image_supervised.py`:
```
def read_images(img_file_names, images_dir_path, normalized_size = None):
    """"""Read the images from the path and return their numpy.ndarray instance.
        Return a numpy.ndarray instance containing the training data.

    Args:
        img_file_names: List containing images names.
        images_dir_path: Path to the directory containing images.
    """"""
    x_train = []
    if os.path.isdir(images_dir_path):
        for img_file in img_file_names:
            img_path = os.path.join(images_dir_path, img_file)
            if os.path.exists(img_path):
                #img = ndimage.imread(fname=img_path)
                img = cv2.imread(img_path)
                img = cv2.resize(img, dsize=normalized_size, interpolation=cv2.INTER_CUBIC)
                if len(img.shape) < 3:
                    img = img[..., np.newaxis]
                x_train.append(img)
            else:
                raise ValueError(""%s image does not exist"" % img_file)
    else:
        raise ValueError(""Directory containing images does not exist"")
    return np.asanyarray(x_train)


def load_image_dataset(csv_file_path, images_path, normalized_size = None):
    """"""Load images from the files and labels from a csv file.

    Second, the dataset is a set of images and the labels are in a CSV file.
    The CSV file should contain two columns whose names are 'File Name' and 'Label'.
    The file names in the first column should match the file names of the images with extensions,
    e.g., .jpg, .png.
    The path to the CSV file should be passed through the `csv_file_path`.
    The path to the directory containing all the images should be passed through `image_path`.

    Args:
        csv_file_path: CSV file path.
        images_path: Path where images exist.

    Returns:
        x: Four dimensional numpy.ndarray. The channel dimension is the last dimension.
        y: The labels.
    """"""
    img_file_name, y = read_csv_file(csv_file_path)
    x = read_images(img_file_name, images_path, normalized_size = normalized_size)
    return np.array(x), np.array(y)
```

",think figured running problem resolution fix resolution following new option import following desired output print print output running training proceeds without error pull request think resolution good behavior read usually training think least one following functionality could added think useful option perhaps separate function normalize image resolution however possible could occur reducing image resolution could cause data loss depending way resolution might much might throw training note knowledge area limited help could include line need size allow image multiple probably desirable foresee would require outside one desirable could code relevant submit pull request reference following none read path return instance return instance training data list path directory else raise image exist else raise directory exist return none load file second set file file contain two whose name file first column match file path file path directory file path path exist four dimensional channel dimension last dimension return,issue,positive,positive,neutral,neutral,positive,positive
425719220,"I got the warning 3 which @wufaxiang said. thanks!

OS: Win 10 x64 - v1803
Terminal: git version 2.19.0.windows.1
Python: Anaconda Python 3.6

tensorflow-gpu==1.11.0
autokeras==0.2.15
pytorch==0.4.1

I run the original example code:
```
from keras.datasets import mnist
from autokeras.image_supervised import ImageClassifier

if __name__ == '__main__':
    (x_train, y_train), (x_test, y_test) = mnist.load_data()
    x_train = x_train.reshape(x_train.shape + (1,))
    x_test = x_test.reshape(x_test.shape + (1,))

    clf = ImageClassifier(verbose=True)
    clf.fit(x_train, y_train, time_limit=12 * 60 * 60)
    clf.final_fit(x_train, y_train, x_test, y_test, retrain=True)
    y = clf.evaluate(x_test, y_test)
    print(y)
```

_Problem_: Why?
```
C:\ProgramData\Anaconda3\lib\site-packages\autokeras\bayesian.py:151: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.
  warnings.warn(""Predicted variances smaller than 0. ""
```",got warning said thanks o win terminal git version python anaconda python run original example code import import print smaller setting smaller,issue,positive,positive,positive,positive,positive,positive
425675298,"@wenyawei Thank you for your report.
It is an expected behavior.
It would affect the search too much.

Thanks.",thank report behavior would affect search much thanks,issue,positive,positive,positive,positive,positive,positive
425675185,"@bersbersbers 
Installing tensorflow is needed for autokeras.
But there is no need to install it if tensorflow-gpu is installed.
We don't know how to determine whether tensorflow-gpu is installed in setup.py, so we just install tensorflow in all the situations.",need install know determine whether install,issue,negative,neutral,neutral,neutral,neutral,neutral
425675018,"Hi @marooncn 
I don't think we have this feature yet.
Would you please describe why you need to loaded with autokeras instead of directly use Keras?

Thanks.",hi think feature yet would please describe need loaded instead directly use thanks,issue,positive,positive,positive,positive,positive,positive
425674933,"@rafaelmarconiramos @zuoxiang95 
This is an expected behavior.
It would affect the search too much, but continue to search smaller models.",behavior would affect search much continue search smaller,issue,negative,positive,neutral,neutral,positive,positive
425674719,"The solution would be to load the data from disk batch by batch, which can be done by pytorch dataloader.
",solution would load data disk batch batch done,issue,negative,neutral,neutral,neutral,neutral,neutral
425674559,"@rafaelmarconiramos Thank you so much for your work.
However, @chenwydj is also working on this one.
You may check with him on Gitter.

Thanks.",thank much work however also working one may check thanks,issue,positive,positive,positive,positive,positive,positive
425631686,"I'm getting the same problem using autokeras on colab. 
When I brought in the mnist example, after the reshape x_train was (60000, 28, 28, 1), but using load_image_dataset on jpgs is also giving me a 1D array of arrays. I'm unsure how to reshape it properly.",getting problem brought example reshape also giving array unsure reshape properly,issue,negative,neutral,neutral,neutral,neutral,neutral
425192028,"I suspect you're using a different version of scipy (1.0.0 or greater) than the one autokeras actually uses. Do you import from`imread` from `imageio`?

Autokeras actually uses the deprecated `scipy.misc.imread` instead of the current `imageio.imread`. Going forward I think it's best to upgrade.

The dirty fix I proposed was also based on the deprecated version `scipy.misc.imread`.",suspect different version greater one actually import actually instead current going forward think best upgrade dirty fix also based version,issue,negative,positive,positive,positive,positive,positive
425071711,"I met the same error
```
Traceback (most recent call last):
  File ""ak_aoi_img.py"", line 23, in <module>
    clf.fit(x_train, y_train, time_limit=2 * 60 * 60)
  File ""/home/adt/wen/ak_aoi/autokeras/image_supervised.py"", line 239, in fit
    run_searcher_once(train_data, test_data, self.path, int(time_remain))
  File ""/home/adt/wen/ak_aoi/autokeras/image_supervised.py"", line 40, in run_searcher_once
    searcher.search(train_data, test_data, timeout)
  File ""/home/adt/wen/ak_aoi/autokeras/search.py"", line 193, in search
    remaining_time)
  File ""/home/adt/wen/ak_aoi/autokeras/bayesian.py"", line 256, in optimize_acq
    for temp_graph in transform(elem.graph):
  File ""/home/adt/wen/ak_aoi/autokeras/net_transformer.py"", line 83, in transform
    temp_graph = to_deeper_graph(deepcopy(graph))
  File ""/home/adt/wen/ak_aoi/autokeras/net_transformer.py"", line 63, in to_deeper_graph
    graph.to_conv_deeper_model(layer_id, 3)
  File ""/home/adt/wen/ak_aoi/autokeras/graph.py"", line 313, in to_conv_deeper_model
    new_layers = deeper_conv_block(target, kernel_size, self.weighted)
  File ""/home/adt/wen/ak_aoi/autokeras/layer_transformer.py"", line 11, in deeper_conv_block
    weight = np.zeros((n_filters, n_filters) + filter_shape)
MemoryError
```",met error recent call last file line module file line fit file line file line search file line transform file line transform graph file line file line target file line weight,issue,negative,positive,positive,positive,positive,positive
425032140,"i get the same error too, it seems the bug is not fixed.",get error bug fixed,issue,negative,positive,neutral,neutral,positive,positive
425011245,"hello @dietercastel , I have tried your solution, use scipy imresize to resize all images, but i have got a error:

  File ""train.py"", line 54, in read_images
    return np.asanyarray(x_train)
  File ""/home/zuoxiang/anaconda3/envs/tensorflow/lib/python3.6/site-packages/numpy/core/numeric.py"", line 544, in asanyarray
    return array(a, dtype, copy=False, order=order, subok=True)
ValueError: could not broadcast input array from shape (416,416,3) into shape (416,416)

here is my code:
```
def read_images(img_file_names, images_dir_path):
    """"""Read the images from the path and return their numpy.ndarray instance.
        Return a numpy.ndarray instance containing the training data.
    Args:
        img_file_names: List containing images names.
        images_dir_path: Path to the directory containing images.
    """"""
    x_train = []
    if os.path.isdir(images_dir_path):
        for img_file in img_file_names:
            img_path = os.path.join(images_dir_path, img_file)
            if os.path.exists(img_path):
                img = ndimage.imread(fname=img_path)
                img = imresize(img, (416,416))
                if len(img.shape) < 3:
                    img = img[..., np.newaxis]
                x_train.append(img)
            else:
                raise ValueError(""%s image does not exist"" % img_file)
    else:
        raise ValueError(""Directory containing images does not exist"")
    return np.asanyarray(x_train)
```",hello tried solution use resize got error file line return file line return array could broadcast input array shape shape code read path return instance return instance training data list path directory else raise image exist else raise directory exist return,issue,negative,neutral,neutral,neutral,neutral,neutral
424840726,"I see, thanks. Isn't PyTorch an alternative to TensorFlow? Do both need to be installed at the same time?
Furthermore, it is unfortunate that autokeras installes tensorflow, even though tensorflow-gpu is installed. Is this intended?",see thanks alternative need time furthermore unfortunate even though intended,issue,negative,negative,negative,negative,negative,negative
424758987,"I received the same error, but on Model 1. I never reach more than two models. 
I read here that maybe the problem is the autokeras generates heavy models to try.",received error model never reach two read maybe problem heavy try,issue,negative,negative,negative,negative,negative,negative
424754299,"Install first the torch.
In my environment I installed ./torch-0.4.1-cp36-cp36m-manylinux1_x86_64.whl",install first torch environment,issue,negative,positive,positive,positive,positive,positive
424736201,"@soerface Thank you, your solution is correct. After three days run the final result is about 82% on my dataset. It's much higher than a simple neural network I designed which the precision is[ 68.75%](https://github.com/marooncn/Defect-Detection-Classifier). ",thank solution correct three day run final result much higher simple neural network designed precision,issue,positive,positive,neutral,neutral,positive,positive
424663459,"Searching for Efficient Multi-Scale Architectures for Dense Image Prediction:

https://arxiv.org/abs/1809.04184",searching efficient dense image prediction,issue,negative,neutral,neutral,neutral,neutral,neutral
424509514,"Hi @Zvezdin,
    Thanks for the idea. It's indeed needed for maximum flexibility. However, we're trying to refactor the whole structure now, so we may have to wait a little bit.  ",hi thanks idea indeed maximum flexibility however trying whole structure may wait little bit,issue,positive,positive,neutral,neutral,positive,positive
424287917,"I got the same issue. And I have 24 GB memory for my docker container to use. There is only one GTX 1080 GPU. 
My configuration has no problem running the [Keras mnist example](https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py)",got issue memory docker container use one configuration problem running example,issue,negative,neutral,neutral,neutral,neutral,neutral
424246342,"Tried (14967, 224, 224, 3) with 1080ti 12GB and 32Gb ram and Failed
Output:
UserWarning: semaphore_tracker: There appear to be 1 leaked semaphores to clean up at shutdown
  len(cache))",tried ti ram output appear clean shutdown cache,issue,negative,positive,positive,positive,positive,positive
424198622,"I experienced the same warning. 
 UserWarning: semaphore_tracker: There appear to be 1 leaked semaphores to clean up at shutdown
  len(cache))",experienced warning appear clean shutdown cache,issue,negative,positive,positive,positive,positive,positive
424080756,"I think 1. is related to #200   
2. How much longer did it take?  The time_limit is not 100% accurate. However, it shouldn't be too far away from 10 min.
4.   Pytorch itself uses tensorflow backend. It's a normal behavior I believe.",think related much longer take accurate however far away min normal behavior believe,issue,negative,positive,positive,positive,positive,positive
424039820,"I'm working with image segmentation, and I have a considerable interest in this task. ",working image segmentation considerable interest task,issue,negative,positive,neutral,neutral,positive,positive
423785862,"Hello, I have the same problem.
Was this problem fixed in the repository?
I am using a small dataset to try, but I have the same error: out of memory.

What is the recommendation? Update autokeras to a specific branch?

Thanks",hello problem problem fixed repository small try error memory recommendation update specific branch thanks,issue,negative,positive,neutral,neutral,positive,positive
423770183,"@marooncn @mariolys07 The problem seems to occur when you have black and white images. With `np.repeat` I could work around the issue, copying the last channel two times. See my commit above, not sure if this is the way to go. I think we should look forward to fixing #204 instead of tinkering with this function.",problem occur black white could work around issue last channel two time see commit sure way go think look forward fixing instead function,issue,negative,positive,neutral,neutral,positive,positive
423597091,"@Zvezdin Thank you for the report.
I think this has been fixed in the develop branch.
Will be released soon.",thank report think fixed develop branch soon,issue,negative,positive,neutral,neutral,positive,positive
423581630,"I tried making the change @compassNS suggested but I got this error:
`local variable 'pool' referenced before assignment`",tried making change got error local variable assignment,issue,negative,neutral,neutral,neutral,neutral,neutral
423566095,"Hi @compassNS ,

Would you mind telling me how to run autokeras with Google Colaboratory ?

Thank a lot.
",hi would mind telling run thank lot,issue,negative,neutral,neutral,neutral,neutral,neutral
423284954,"@jhfjhfj1 I was not using the latest version. It gives score of 99% with the latest version(0.2.14)
Thanks ! ",latest version score latest version thanks,issue,negative,positive,positive,positive,positive,positive
423282160,@satyakesav Would you please try to run the examples/mnist.py with the latest version of autokeras and post the final accuracy here?,would please try run latest version post final accuracy,issue,negative,positive,positive,positive,positive,positive
423208670,Should u squeezed your image? Try this method to remove single dimension in image. https://docs.scipy.org/doc/numpy/reference/generated/numpy.squeeze.html,image try method remove single dimension image,issue,negative,negative,neutral,neutral,negative,negative
422895182,Thanks for the comment. Please refer to #195.,thanks comment please refer,issue,positive,positive,positive,positive,positive,positive
422582248,"## Pull Request Test Coverage Report for [Build 666](https://coveralls.io/builds/19069392)

* **1** of **1**   **(100.0%)**  changed or added relevant line in **1** file are covered.
* **2** unchanged lines in **1** file lost coverage.
* Overall coverage decreased (**-0.1%**) to **95.838%**

---


|  Files with Coverage Reduction | New Missed Lines | % |
| :-----|--------------|--: |
| [autokeras/graph.py](https://coveralls.io/builds/19069392/source?filename=autokeras%2Fgraph.py#L271) | 2 | 97.22% |
<!-- | **Total:** | **2** |  | -->

|  Totals | [![Coverage Status](https://coveralls.io/builds/19069392/badge)](https://coveralls.io/builds/19069392) |
| :-- | --: |
| Change from base [Build 664](https://coveralls.io/builds/19065144): |  -0.1% |
| Covered Lines: | 1888 |
| Relevant Lines: | 1970 |

---
##### 💛  - [Coveralls](https://coveralls.io)
",pull request test coverage report build added relevant line file covered unchanged file lost coverage overall coverage coverage reduction new total coverage status change base build covered relevant coverall,issue,negative,positive,neutral,neutral,positive,positive
422497493,"Hi @jhfjhfj1,

I am not sure exactly what you are asking, but i think you are referring to:

""tests/test_image_supervised.py .....
No output has been received in the last 10m0s, this potentially indicates a stalled build or something wrong with the build itself.""

This is actually do the tests working but timing out. (Taking longer than 10 minutes).

However, if you will the tests for my contributed code, tests/test_image1D_supervised.py"" already successful completed in the GitHub test build.

As my tests run relatively quickly on my machine, they may have added to the total time required slightly, but I don't think are the cause of the timeout. The next test (where GitHub aborts) does take a long time on my machine (tests/test_image_supervised.py), and I can easily imagine this taking longer than 10 minutes (it is the test were it reads from the CSV file that takes a long time.)

Also many of the classification tests are based on random data, so build testing times may fluctuate if random number seeding is not working properly. (In earlier versions of SciPy the random seed was ignored. I believe this is long fixed, but the numpy/scipy seeds are not the global random number seeds for all packages, and i don't know if the pytests are seeded. Thus you can have build times greatly varying depending on the randomly generated classification problem.

So i believe the build is timing out, but I believe it just timed out because test/test_image_supervised.py (not affected by my changes) either normally takes a very long time to test out-of-the-box with the current master build, or the randomly-generated tests sometimes take a long time. I was able to confirm on my machine that test/test_image_supervised.py (not affected by my checkin) does take a long time to test sometimes with the existing base master, although I can't verify if this is due to random variation (or lack of random seeding) or if that is just normal. GitHub also notes that there is normal time variation in GitHub builds (due to network load issues, etc.) that affects some projects, and suggests the timeout be increased for these projects.

The build results reference a URL with suggests for either adding a retry parameter (so if it times out it will retry 3 times, which may be helpful if the timeout is caused due to random number generation) or increasing the timeout, to say 20 minutes instead of the default 10 minutes.

My build passes all checks on my machine, and that is identical to what is checked in, it just sometimes takes longer than 10 minutes, and the long tests are in the existing code (with my own tests running quickly generally in my tests, although they also use the random number generator).

So I'm not sure I can fix. I believe you will need to increase the time out or the retry on the build.

If you increase the time out I believe the build will pass all checks.",hi sure exactly think output received last potentially build something wrong build actually working timing taking longer however code already successful test build run relatively quickly machine may added total time slightly think cause next test take long time machine easily imagine taking longer test file long time also many classification based random data build testing time may fluctuate random number working properly random seed believe long fixed global random number know seeded thus build time greatly depending randomly classification problem believe build timing believe timed affected either normally long time test current master build sometimes take long time able confirm machine affected take long time test sometimes base master although ca verify due random variation lack random normal also normal time variation due network load build reference either retry parameter time retry time may helpful due random number generation increasing say instead default build machine identical checked sometimes longer long code running quickly generally although also use random number generator sure fix believe need increase time retry build increase time believe build pas,issue,positive,negative,neutral,neutral,negative,negative
422485027,"@wernergkrebs Thank you so much for the contribution!
Would you please fix the CI so that we can start a code review?",thank much contribution would please fix start code review,issue,positive,positive,positive,positive,positive,positive
422483948,"@mariolys07 Please follow #193 to continue the discussion on the custom datasets.
Thank you for your feedback!",please follow continue discussion custom thank feedback,issue,positive,neutral,neutral,neutral,neutral,neutral
422455440,"I believe you are replying to my other post, no ?
https://github.com/jhfjhfj1/autokeras/issues/198

I can resize my images, what is the maximum size you recommend ?
And do you have any feed-back on my questions above ?

thanks",believe post resize maximum size recommend thanks,issue,positive,positive,positive,positive,positive,positive
422423282,"@Anindita-Pani may I know which version of auto keras are u using? The previous version had a bug in the prediction and evaluation.

Our current local test results are over 98% or 99% on the latest version 0.2.14.
Thanks.",may know version auto previous version bug prediction evaluation current local test latest version thanks,issue,negative,positive,positive,positive,positive,positive
422405164,I had the same issue with a custom dataset. I haven't been able to reach 20% accuracy on any set.,issue custom able reach accuracy set,issue,negative,positive,positive,positive,positive,positive
422403900,I'm also interested in learning how to solve this issue. Pretty much any other model trained for a similar amount of time will produce better accuracy.,also interested learning solve issue pretty much model trained similar amount time produce better accuracy,issue,positive,positive,positive,positive,positive,positive
422216266,"I think it is because the size of image is too large.
You may want to try compress it first.
We may implement this compression feature in the future.
Thanks.",think size image large may want try compress first may implement compression feature future thanks,issue,negative,positive,positive,positive,positive,positive
422216000,"@hiepph This one is fixed in the develop version. Will be in the next release.
Thanks.",one fixed develop version next release thanks,issue,negative,positive,positive,positive,positive,positive
421977529,"Add google colab check to @PositronBeam 

search.py line175 - 180

BEFORE==============================================================
```
        mp.set_start_method('spawn', force=True)
        pool = mp.Pool(1)
        try:
            train_results = pool.map_async(train, [(graph, train_data, test_data, self.trainer_args,
                                                    		os.path.join(self.path, str(model_id) + '.png'),
self.metric, self.loss, self.verbose)])
```

AFTER===============================================================
```
        import sys
        if ""google.colab"" in sys.modules:
          gcolab = True
        else:
          gcolab = False
          mp.set_start_method('spawn', force=True)
          pool = mp.Pool(1)

        try:
           if gcolab:
              train_results = train((graph, train_data, test_data, self.trainer_args,
                                              os.path.join(self.path, str(model_id) + '.png'),
                                              self.metric, self.loss, self.verbose))
           else:
              train_results = pool.map_async(train, [(graph, train_data, test_data, self.trainer_args,
                                                    	          os.path.join(self.path, str(model_id) + '.png'),
                                                                          self.metric, self.loss, self.verbose)])

```",add check line pool try train graph import true else false pool try train graph else train graph,issue,negative,negative,neutral,neutral,negative,negative
421914920,Strongly looking forward to this feature!,strongly looking forward feature,issue,negative,positive,positive,positive,positive,positive
421910776,This problem has been well solved and I think this issue can be closed. Thanks again @jhfjhfj1 @eagleoflqj ,problem well think issue closed thanks,issue,negative,positive,neutral,neutral,positive,positive
421909288,"> try this command:
> PYTHONIOENCODING=utf-8 python minist_example.py

Thanks for your reply!  Yes, this is the right solution. But I encounter another problem with respect to ""Bus error"" can be solved by [#118](https://github.com/jhfjhfj1/autokeras/issues/118)",try command python thanks reply yes right solution encounter another problem respect bus error,issue,positive,positive,positive,positive,positive,positive
421744091,"Thanks for your reply! @jhfjhfj1 

But I got exactly the same error as:
""root@91686962c4c1:/data/autokeras# python minist_example.py
Using TensorFlow backend.
Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz
11493376/11490434 [==============================] - 8s 1us/step

Initializing search.
Initialization finished.


Traceback (most recent call last):
  File ""minist_example.py"", line 10, in <module>
    clf.fit(x_train, y_train, time_limit=12 * 60 * 60)
  File ""/usr/local/lib/python3.6/dist-packages/autokeras/image_supervised.py"", line 239, in fit
    run_searcher_once(train_data, test_data, self.path, int(time_remain))
  File ""/usr/local/lib/python3.6/dist-packages/autokeras/image_supervised.py"", line 40, in run_searcher_once
    searcher.search(train_data, test_data, timeout)
  File ""/usr/local/lib/python3.6/dist-packages/autokeras/search.py"", line 172, in search
    print('\u2552' + '=' * 46 + '\u2555')
UnicodeEncodeError: 'ascii' codec can't encode character '\u2552' in position 0: ordinal not in range(128)""

By the way, I run my code in a **Docker** instance.

All requirements by autokeras are installed by command 'pip install autokeras' in a new Docker container.

Some info on my Docker environment:
chuanming@Galadriel:~$ nvidia-docker version
NVIDIA Docker: 2.0.3
Client:
 Version:      18.03.1-ce
 API version:  1.37
 Go version:   go1.9.5
 Git commit:   9ee9f40
 Built:        Thu Apr 26 07:17:20 2018
 OS/Arch:      linux/amd64
 Experimental: false
 Orchestrator: swarm

Server:
 Engine:
  Version:      18.03.1-ce
  API version:  1.37 (minimum version 1.12)
  Go version:   go1.9.5
  Git commit:   9ee9f40
  Built:        Thu Apr 26 07:15:30 2018
  OS/Arch:      linux/amd64
  Experimental: false",thanks reply got exactly error root python data search finished recent call last file line module file line fit file line file line search print ca encode character position ordinal range way run code docker instance command install new docker container docker environment version docker client version version go version go git commit built experimental false orchestrator swarm server engine version version minimum version go version go git commit built experimental false,issue,positive,positive,neutral,neutral,positive,positive
421643119,"I tried to find that out by looking at the pipenv docs, but I couldn't figure it out. ",tried find looking could figure,issue,negative,neutral,neutral,neutral,neutral,neutral
421619602,"      
  

 Hi there,   
  

  
Thanks a lot. I will send the pull request of the newst version tonight when I come back home. The model is pretty much complete now. Only   have some run out of memory problem. It would be great to receive help from you.   
  
  
  
  
 -- Best Boyuan Gong  
      
  

  
  
>   
> On Sep 15, 2018 at 1:56 PM,  <Muhammad (mailto:notifications@github.com)>  wrote:
>   
>   
>   
>
> @boyuangong (https://github.com/boyuangong)  I can help you out with that module if that's okay.
>
>   
>
> —
>  You are receiving this because you were mentioned.
>  Reply to this email directly,   view it on GitHub (https://github.com/jhfjhfj1/autokeras/issues/35#issuecomment-421616659), or   mute the thread (https://github.com/notifications/unsubscribe-auth/AV8DUPG7diI91B-wkADAb3aMMEJJB4w5ks5ubU1ogaJpZM4VtU_w).
>
>     
>   
  
  
     ",hi thanks lot send pull request version tonight come back home model pretty much complete run memory problem would great receive help best gong wrote help module reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
421585774,"@jhfjhfj1 
Sorry for my stupid question. In Additional context of the first post of @@PositronBeam , is it a workaround for running autokeras on Google Collaboratory?
",sorry stupid question additional context first post running,issue,negative,negative,negative,negative,negative,negative
421522834,"@chuanmingliu Thanks for trying out.
Are you able to run the mnist example?",thanks trying able run example,issue,negative,positive,positive,positive,positive,positive
421522746,"@theprodev 
Thank you for your interest.
We will update the tutorial later.
",thank interest update tutorial later,issue,positive,neutral,neutral,neutral,neutral,neutral
421522592,"@aojue1109 
Please use the standard template to formulate your bug report.

Thanks.",please use standard template formulate bug report thanks,issue,positive,positive,neutral,neutral,positive,positive
421522538,"@jcpeterson Thanks.
Currently, we only opened task-specific interfaces.
We will be extracting the network-type level interfaces soon.
",thanks currently level soon,issue,negative,positive,neutral,neutral,positive,positive
421522466,"@paulgureghian 
Thank you for the issue.
Would you please check what is the latest tensorflow version possible on pipenv?

Thanks",thank issue would please check latest version possible thanks,issue,positive,positive,positive,positive,positive,positive
421015462,"@swenkel Thanks. This is the expected behavior. Whenever it is out of memory, it would never search such large models, but smaller ones.

<sub>Sent with <a href=""http://githawk.com"">GitHawk</a></sub>",thanks behavior whenever memory would never search large smaller sub sent,issue,negative,positive,positive,positive,positive,positive
421014443,"Please follow the instructions on our website, autokeras.com

<sub>Sent with <a href=""http://githawk.com"">GitHawk</a></sub>",please follow sub sent,issue,negative,neutral,neutral,neutral,neutral,neutral
420938852,"I just start from a fresh Python 3.6 install. 
Just need to install PyTorch from their website recommandation
IE : For A python, windows, pip configuration :

pip3 install http://download.pytorch.org/whl/cu90/torch-0.4.1-cp36-cp36m-win_amd64.whl
pip3 install torchvision

then a simple 

pip install autokeras

works fine",start fresh python install need install ie python pip configuration pip install pip install simple pip install work fine,issue,negative,positive,positive,positive,positive,positive
420748469,"Check you have no ""autokeras.py"" file in your current folder.",check file current folder,issue,negative,neutral,neutral,neutral,neutral,neutral
420718703,"You are we welcome!
(I have to say, the fix was found not by me, but by my manager)

The code is exactly what we did. Just FYI, you can do this instead:
keras_model.layers[:-1].activation = keras.activations.softmax

The result would be the same.

",welcome say fix found manager code exactly instead result would,issue,negative,positive,positive,positive,positive,positive
420692330,"@AShyshkov Thank you for your great advice! Your comment is very helpful for me.
After loading the model generated by Auto-Keras, I added Activation('softmax') layer at the final output Dense layer, and compiled it.
```
keras_model = load_model('my_model.h5')

x = keras_model.output
x = Activation('softmax', name='activation_add')(x)
keras_model = Model(keras_model.input, x)

keras_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
```
Then, I retrained the model using `fit` function. Through the retraining, both loss and accuracy successfully improved.

Thank you again!",thank great advice comment helpful loading model added activation layer final output dense layer activation model model fit function loss accuracy successfully thank,issue,positive,positive,positive,positive,positive,positive
420676140,"Hey, I think we found the issue.
Seem like a defect in AutoKeras. The last layer in the best model for MNIST classifier is a Dense layer with linear activation function. Training such model ends up with exploding gradients issue. Change it to softmax (or top it off with layer Activation('softmax') ), retrain your model and you should be fine.",hey think found issue seem like defect last layer best model classifier dense layer linear activation function training model issue change top layer activation retrain model fine,issue,positive,positive,positive,positive,positive,positive
420664750,"@jhfjhfj1 Thank you for your comment.
I'm sorry I missed the note on `README.md`:
```
Note: currently, Auto-Keras is only compatible with: Python 3.6.
```
Then, I tried the following:
- Using Python 3.6
- Input MNIST x (data): devided by 255.0 for normalization
- Input MNIST y (label): one-hot-vectored using `keras.utils.to_categorical`

However, this issue still existed, that is, the performance of the model is poor in a pure keras code.

Fortunately, the network structure of the model generated by Auto-Keras can be plotted into PNG file using `keras.utils.plot_model`.
I will try to construct the same network using pure keras code (functional API).

In addition, until this issue will be fixed, I try to conclude the whole process (searching model, final-fitting model, and predicting using the model) in an Auto-Keras code.

Thank you again for your kindness.",thank comment sorry note note currently compatible python tried following python input data normalization input label however issue still performance model poor pure code fortunately network structure model plotted file try construct network pure code functional addition issue fixed try conclude whole process searching model model model code thank kindness,issue,positive,positive,neutral,neutral,positive,positive
420658627,"@t-wtnb @AShyshkov Thank you for the issue.
The Keras model itself is hard to have the same behavior as the Auto-Keras. Since it doesn't contain the steps of preprocessing the data and the labels.
Sometimes the data should be normalized. The labels should be one-hot encoded.
We are very open to any suggestions that would fix this.

Thanks.",thank issue model hard behavior since contain data sometimes data open would fix thanks,issue,positive,negative,neutral,neutral,negative,negative
420657484,"@tl-yang Would you change the auto GPU selection to only select from the CUDA_VISIBLE_DEVICES pool?
Thanks.",would change auto selection select pool thanks,issue,negative,positive,positive,positive,positive,positive
419967646,"Help needed.
Does anyone know why it cannot work with Google Collaboratory and how to fix it?
Thanks",help anyone know work fix thanks,issue,positive,positive,positive,positive,positive,positive
419709490,"Nope, Autokeras is a Python library without any graphical user interface. If you want to expose your model as an API, you have to build it in Python yourself. I am not sure what exactly you built in your pipeline but it seems to go in a similar direction as AutoML. I wrote a [blog post about Google AutoML](https://www.statworx.com/de/blog/a-performance-benchmark-of-google-automl-vision-using-fashion-mnist/) that you might find useful understanding the functionalities.",nope python library without graphical user interface want expose model build python sure exactly built pipeline go similar direction wrote post might find useful understanding,issue,positive,positive,positive,positive,positive,positive
419667361,@tl-yang I am not sure the selection of GPU part would crash in some special cases. And we need to support manual selection of GPU as well. Thanks.,sure selection part would crash special need support manual selection well thanks,issue,positive,positive,positive,positive,positive,positive
419585520,"I had the same issue, running in Colab

Using:

```
import autokeras as ak 
.....
clf = ak.ImageClassifier(verbose=True, augment=False)

```
Instead of: 

`from autokeras.classifier import ImageClassifier`


Seems to fix the issue, but then when I execute the code block, the kernel dies. 


",issue running import ak instead import fix issue execute code block kernel,issue,negative,neutral,neutral,neutral,neutral,neutral
419585387,"@tl-yang 
Please fix the CI.
Then I will merge.

Thanks.",please fix merge thanks,issue,positive,positive,positive,positive,positive,positive
418846793,"This would be really neat to have working. As Google Colab gives free GPUs, this would let a lot more people try out Autokeras...",would really neat working free would let lot people try,issue,positive,positive,positive,positive,positive,positive
418787063,"Right now `mkdocs/docs/index.md` is dynamically generated. It's not actually placed in the repository.

MkDocs's [official repository](https://github.com/mkdocs/mkdocs/) is a good demonstration. Maybe we should just put all the docs in one place.",right dynamically actually repository official repository good demonstration maybe put one place,issue,positive,positive,positive,positive,positive,positive
418728816,"@swenkel thank you for letting us know. That line should not be changed since it is for the model trainer mainly. We are investigating the issue. Thanks.

<sub>Sent with <a href=""http://githawk.com"">GitHawk</a></sub>",thank u know line since model trainer mainly investigating issue thanks sub sent,issue,positive,positive,positive,positive,positive,positive
418728047,"help needed. Does anyone know how to fix it? Thanks

<sub>Sent with <a href=""http://githawk.com"">GitHawk</a></sub>",help anyone know fix thanks sub sent,issue,positive,positive,positive,positive,positive,positive
418542886,"More general question:
Can we run autokeras models (e.g., ImageClassifier) on a cluster of distributed machines with each having multiple GPUs? 
I tried to run it in this fashion, but, was not successful. It seems like it only runs on one GPU in a single cluster node. 

More clarification on this feature would be appreciated a lot.
Thanks a lot ",general question run cluster distributed multiple tried run fashion successful like one single cluster node clarification feature would lot thanks lot,issue,positive,positive,positive,positive,positive,positive
418359790,"@jquach12 

First, as you said, 
```
if x_train.shape[0] != y_train.shape[0]:
raise ValueError('x_train and y_train should have the same number of instances.')
```
, I think, it has nothing to do with the second dimension. 

Second, I use this command in my code 
`y_train = np_utils.to_categorical(y_train,10)`. What does  

> my y_train has no second dimension 

 mean?  I should **not** pass the label  in the one-hot format? Or you use the  **Sigmoid** at the end?
",first said raise number think nothing second dimension second use command code second dimension mean pas label format use sigmoid end,issue,negative,negative,neutral,neutral,negative,negative
418256086,"Hmm, when working with MNIST and my own dataset, the shape of my x_train is similar to yours (number of samples, height, width, colorChannels), but my y_train has no second dimension.",working shape similar number height width second dimension,issue,negative,neutral,neutral,neutral,neutral,neutral
418244683,"@jquach12 

> #######
> shape of x_train : (900, 720, 720, 1)
> shape of y_train : (900, 10)
> #######

if 
the output of `np.shape(x_train)` is (900, 720, 720, 1)
and
the output of `np.shape(y_train)` is  (900, 10), 

x_train.shape[0] = 900
y_train.shape[0] = 900

right?
",shape shape output output right,issue,negative,positive,positive,positive,positive,positive
418211025,"@fliessen We released a new version.
You may try it.
Thanks.",new version may try thanks,issue,negative,positive,positive,positive,positive,positive
418180045,"@swenkel 
Thank you for your report!
The bug is fixed in the new release.",thank report bug fixed new release,issue,negative,positive,positive,positive,positive,positive
418159595,"Have you checked if you have a 1:1 labeling of your training data?

if x_train.shape[0] != y_train.shape[0]:
        raise ValueError('x_train and y_train should have the same number of instances.')",checked training data raise number,issue,negative,neutral,neutral,neutral,neutral,neutral
417841864,"@jhfjhfj1 

Just remembered you asked about open-source-exclusive platforms for recurring crowd funding.

There is https://salt.bountysource.com, which is also open source and only used by open source projects.

",recurring crowd also open source used open source,issue,negative,neutral,neutral,neutral,neutral,neutral
417832831,"@jhfjhfj1 sir,
As you said that you are running this project from a university which i didn't knew, and if so that you would be getting good financial aid from the university itself. I thought that you are a Ph.D. student LOL.
But anyway still you want some financial aid then you can try KickStarter and Indigogo crowd funding websites.
And I have sent my resume if there is any recruitment or something like that. Please let me know if there is any.",sir said running project university knew would getting good financial aid university thought student anyway still want financial aid try crowd sent resume recruitment something like please let know,issue,positive,positive,positive,positive,positive,positive
417795468,"@hemangjoshi37a 
Thank you for your suggestions!
This project is currently running in our university.
I am not sure whether we would hire anyone at the current stage.

We are very open to any financial suggestions.
What do you think of opencollective?
Or is there any crowdfunding websites just for open source projects?",thank project currently running university sure whether would hire anyone current stage open financial think open source,issue,positive,positive,neutral,neutral,positive,positive
417791373,"Thank you so much! @swenkel 
This is a very important bug.
I have just fixed it in the develop branch, which will be used for the next release.",thank much important bug fixed develop branch used next release,issue,positive,positive,positive,positive,positive,positive
417668742,I figured it out for myself. The docker container I was using was 2G memory. I increased it to 16G and restarted the docker image by adding `--shm-size 16G` when running `docker run`. It solved my problems. Hope it helps.,figured docker container memory docker image running docker run hope,issue,negative,neutral,neutral,neutral,neutral,neutral
417571505,"Here's what I get from nvidia-smi:

Fri Aug 31 10:03:59 2018
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 396.54                 Driver Version: 396.54                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 108...  Off  | 00000000:05:00.0  On |                  N/A |
| 21%   34C    P8    18W / 250W |   1121MiB / 11170MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  GeForce GTX 108...  Off  | 00000000:06:00.0 Off |                  N/A |
| 21%   33C    P8    17W / 250W |   7012MiB / 11178MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   2  GeForce GTX 108...  Off  | 00000000:09:00.0 Off |                  N/A |
| 21%   33C    P8    16W / 250W |   1244MiB / 11178MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   3  GeForce GTX 108...  Off  | 00000000:0A:00.0 Off |                  N/A |
| 21%   32C    P8    18W / 250W |    227MiB / 11178MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    1       430      C   /opt/conda/bin/python                       6785MiB |
+-----------------------------------------------------------------------------+",get driver version name volatile fan temp compute mib mib default mib mib default mib mib default mib mib default memory type process name usage mib,issue,negative,neutral,neutral,neutral,neutral,neutral
417569825,"This looks more like a memory allocation/deallocation problem.
I am running out of memory on a regular basis. Using max_model_width and depth does not help. Neither does limiting 'max_iter_num'. It simply delays the problem.

The good thing is that you build autokeras with snapshots that allow to continue training after an error. In such a case all memory is deallocated and if I restart/continue training, then I am able to train the model for quite some time again before it happens again.

I am not so sure if this problem can be solved by PyTorchs cuda management (https://pytorch.org/docs/stable/notes/cuda.html). Compared to tensorflows GPU management it is still quite poor. 

I would suggest to implement full GPU memory deallocation after each model or after a defineable threshold of GPU memory.",like memory problem running memory regular basis depth help neither limiting simply problem good thing build allow continue training error case memory training able train model quite time sure problem management management still quite poor would suggest implement full memory model threshold memory,issue,negative,positive,positive,positive,positive,positive
417566133,"Any advice on how this could be done, please? You don't mean physical dismounting, do you?",advice could done please mean physical,issue,negative,negative,negative,negative,negative,negative
417555776,"@jhfjhfj1 I just tried autokeras-0.2.11 with the Google Colaboratory
Google Colaboratory runtime dies when I use autokeras-0.2.11
Here is the output message
```
Using TensorFlow backend.
/usr/local/lib/python3.6/dist-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)
  "" (e.g. in jupyter console)"", TqdmExperimentalWarning)


Initializing search.
Initialization finished.


╒==============================================╕
|               Training model 0               |
╘==============================================╛
```",tried use output message notebook mode use instead force console mode console console search finished training model,issue,negative,neutral,neutral,neutral,neutral,neutral
417518269,"@dietercastel  thank you . i have defined a function to instead of the load_image_dataset function, looks like your comment.",thank defined function instead function like comment,issue,positive,neutral,neutral,neutral,neutral,neutral
417476608,"I noticed this too. As a temporary quick and dirty solution you can patch read_images in image_supervised.py as follows:

```python
#In images_supervised.py of your autokeras lib
# Add the necessary import to the top of the file:
from scipy.misc import imresize
#...
def read_images(...): 
#...
# after this line:
     img = ndimage.imread(fname=img_path)
# add this with (299,299) the size to resize too.
     img = imresize(img,(299,299)) # use scipy imresize to resize all images
# rest of the read_images function
     if len(img.shape) <3:
#...
```

I'm wondering what a more general way of solving this issue would look like though. Looking for the smallest image in the images and scaling all other to that size maybe?",temporary quick dirty solution patch python add necessary import top file import line add size resize use resize rest function wondering general way issue would look like though looking image scaling size maybe,issue,negative,positive,neutral,neutral,positive,positive
417399243,"@MattVil @fliessen 
You can import autokeras.constant.Constant. Then change the value of Constant.MAX_MODEL_WIDTH and Constant.MAX_MODEL_DEPTH to limit the memory usage.

We are trying to find more complicated ways to limit the memory.
Will close this issue afterward.

thanks.",import change value limit memory usage trying find complicated way limit memory close issue afterward thanks,issue,positive,negative,negative,negative,negative,negative
417312595,Same problem even with the new release,problem even new release,issue,negative,positive,positive,positive,positive,positive
416801300,"      
  

 Hi,   
  

  
The model is expected to be released around next week. I am in a vacation now back to my country. Sorry for any inconvenience.
  
  
  
  
 -- Best Boyuan Gong  
      
  

  
  
>   
> On Aug 29, 2018 at 7:26 AM,  <ziyadi (mailto:notifications@github.com)>  wrote:
>   
>   
>   
>
> When do you expect to release the initial TextClassifier model?
>
>   
>
> —
>  You are receiving this because you were mentioned.
>  Reply to this email directly,   view it on GitHub (https://github.com/jhfjhfj1/autokeras/issues/35#issuecomment-416772617), or   mute the thread (https://github.com/notifications/unsubscribe-auth/AV8DUJCF3XBzv6TUhnV81kYGnVNPWb7Nks5uVdGagaJpZM4VtU_w).
>
>     
>   
  
  
     ",hi model around next week vacation back country sorry inconvenience best gong wrote expect release initial model reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
416772617,When do you expect to release the initial TextClassifier model? ,expect release initial model,issue,negative,neutral,neutral,neutral,neutral,neutral
416637656,"Having a similar problem:
>>>
Initializing search.
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43]
Initialization finished.
Training model  0
Bus error (core dumped)
root@autokeras-v2-jupyter-56787d65fb-lbkpn:/notebooks# Using TensorFlow backend.
/opt/conda/lib/python3.6/multiprocessing/semaphore_tracker.py:143: UserWarning: semaphore_tracker: There appear to be 4 leaked semaphores to clean up at shutdown
  len(cache))
",similar problem search finished training model bus error core root appear clean shutdown cache,issue,negative,positive,positive,positive,positive,positive
416628755,"I will release a new version of autokeras using tensorflow 1.10.0 instead.
Thanks.
@cpoptic ",release new version instead thanks,issue,negative,positive,positive,positive,positive,positive
416628150,"@supermanhuyu 
Thank you for the feedback.
Currently, we do not support images of different sizes.
Will consider support it later.",thank feedback currently support different size consider support later,issue,positive,neutral,neutral,neutral,neutral,neutral
416627721,"@dietercastel Thank you so much!
You can go ahead a fix it.",thank much go ahead fix,issue,negative,positive,positive,positive,positive,positive
416526675,"when i change the sie of the function data_load_user_defined  out size to 32x32 , i can train it .maybe my GPU memory is too small .",change sie function size train memory small,issue,negative,negative,negative,negative,negative,negative
416361007,I might fix this myself tomorrow if you agree with my proposed solution or provide a better suggestion.,might fix tomorrow agree solution provide better suggestion,issue,positive,positive,positive,positive,positive,positive
416267520,">  Could not find a version that satisfies the requirement tensorflow>=1.10.1 (from autokeras) (from versions: 1.2.0rc2, 1.2.0, 1.2.1, 1.3.0rc0, 1.3.0rc1, 1.3.0rc2, 1.3.0, 1.4.0rc0, 1.4.0rc1, 1.4.0, 1.5.0rc0, 1.5.0rc1, 1.5.0, 1.5.1, 1.6.0rc0, 1.6.0rc1, 1.6.0, 1.7.0rc0, 1.7.0rc1, 1.7.0, 1.7.1, 1.8.0rc0, 1.8.0rc1, 1.8.0, 1.9.0rc0, 1.9.0rc1, 1.9.0rc2, 1.9.0, 1.10.0rc0, 1.10.0rc1, 1.10.0)
No matching distribution found for tensorflow>=1.10.1 (from autokeras)",could find version requirement matching distribution found,issue,negative,neutral,neutral,neutral,neutral,neutral
416115797,"@cpoptic @HunbeomBak Thank you for the feedback.
It has just been solved in the new release of 0.2.10.

Thanks.",thank feedback new release thanks,issue,positive,positive,positive,positive,positive,positive
416111324,"Same error on Google Colab.

In Colab, run '!pip install autokeras'. 

Then, 
Complete output from command python setup.py egg_info:
    error in autokeras setup command: 'install_requires' must be a string or list of strings containing valid project/version requirement specifiers; Invalid requirement, parse error at ""'=4.25.0'""
",error run pip install complete output command python error setup command must string list valid requirement invalid requirement parse error,issue,negative,positive,neutral,neutral,positive,positive
416099524,Fixed in the new release. Please reopen the issue if it remains unsolved. Thx.,fixed new release please reopen issue remains unsolved,issue,negative,positive,positive,positive,positive,positive
416010284,"@auvipy Thank you for you contribution!
Would you please change the setup.py as well?",thank contribution would please change well,issue,positive,neutral,neutral,neutral,neutral,neutral
416006310,"I am not sure.
As long as the tensorflow version is compatible with the Keras version,
I think it would work fine.

Thanks. @AvinoamK ",sure long version compatible version think would work fine thanks,issue,positive,positive,positive,positive,positive,positive
415928574,"@GagaLeung I think this issue is fixed in the new release of Auto Keras.
Please repoen the issue if it is not.

Thank you for your report.",think issue fixed new release auto please issue thank report,issue,positive,positive,positive,positive,positive,positive
415787366,"@jhfjhfj1 I just tried autokeras-0.2.7 with the Google Colaboratory
Google Colaboratory runtime dies when I run
```
from keras.datasets import mnist
from autokeras import ImageClassifier

if __name__ == '__main__':
    (x_train, y_train), (x_test, y_test) = mnist.load_data()
    x_train = x_train.reshape(x_train.shape + (1,))
    x_test = x_test.reshape(x_test.shape + (1,))

    clf = ImageClassifier(verbose=True, augment=False)
    clf.fit(x_train, y_train, time_limit=12 * 60 * 60)
    clf.final_fit(x_train, y_train, x_test, y_test, retrain=True)
    y = clf.evaluate(x_test, y_test)
    print(y * 100)
```
Here is the output message
```
Using TensorFlow backend.

Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz
11493376/11490434 [==============================] - 2s 0us/step
Initializing search.
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43]
Initialization finished.
Training model  0
```
 ",tried run import import print output message data search finished training model,issue,negative,neutral,neutral,neutral,neutral,neutral
415785117,"@ankapale Thank you for your work.
To enable export the model in ImageRegressor, and correctly do the evaluate() function,
the metric function should be dynamically got according to it is classification or regression.
First, change the following line to get the function by calling another member function.
https://github.com/jhfjhfj1/autokeras/blob/master/autokeras/image_supervised.py#L287
Second, add the member function as an abstract method to ImageSupervised.
Third, override the function in ImageRegressor and ImageClassifier to return mean_square_error and accuracy_score, respectively.

Let me know if you have any questions. Thanks.
",thank work enable export model correctly evaluate function metric function dynamically got according classification regression first change following line get function calling another member function second add member function abstract method third override function return respectively let know thanks,issue,positive,positive,neutral,neutral,positive,positive
415779635,"@vincent-hui , Thank you for your follow up.
We have changed the multiprocessing into torch.multiprocessing.
But we haven't tested with the Google Colaboratory yet.",thank follow tested yet,issue,negative,neutral,neutral,neutral,neutral,neutral
415769814,"Hi @jhfjhfj1 , would you mind telling us whether you tested with Google Collaboratory?

Thank a lot
",hi would mind telling u whether tested thank lot,issue,negative,neutral,neutral,neutral,neutral,neutral
415645562,"Thank you @eagleoflqj !
We have changed the multiprocessing to torch.multiprocessing.
@kmbmjn @xialulu826 Would you like to try again with our latest release to see if it works?",thank would like try latest release see work,issue,positive,positive,positive,positive,positive,positive
415619248,"This is fixed in the latest release.
Thanks.",fixed latest release thanks,issue,negative,positive,positive,positive,positive,positive
415619080,"This issue is fixed in the new release.
Thank you all for the contribution.",issue fixed new release thank contribution,issue,negative,positive,positive,positive,positive,positive
415475027,"Check the Github's CI
Please fix mixed tab/space indentation in your code, u should use 4 spaces instead of tab

```python
TabError: inconsistent use of tabs and spaces in indentation
```",check please fix mixed indentation code use instead tab python inconsistent use indentation,issue,negative,neutral,neutral,neutral,neutral,neutral
415341046,Tried it. Still keep getting the error.,tried still keep getting error,issue,negative,neutral,neutral,neutral,neutral,neutral
415307750,"@jhfjhfj1 Thanks, the problem has been sloved,next time ,I will use the bug report to give my problem.",thanks problem next time use bug report give problem,issue,negative,positive,neutral,neutral,positive,positive
415285758,"@jhfjhfj1 I appreciate your interests. I checked I am using autokeras 0.2.4.
@eagleoflqj That's exactly the same situation. This error appears occasionally.",appreciate checked exactly situation error occasionally,issue,negative,positive,positive,positive,positive,positive
415268775,"I think it's not an autokeras error.
Try to put your code into `if __name__=='__main__':`
like this
```python
if __name__=='__main__':
    (X_train, Y_train), (X_test, Y_test) = mnist.load_data()
    X_train = X_train.reshape(X_train.shape + (1,))
    X_test = X_test.reshape(X_test.shape + (1,))
    clf = ak.ImageClassifier(verbose=True, augment=False)
    clf.fit(X_train, Y_train)
```",think error try put code like python,issue,negative,neutral,neutral,neutral,neutral,neutral
415267786,"I met the same error once with autokeras 0.2.4.
But what is strange is that when I re-run the program, the error disappeared, then memory overflow appeared...",met error strange program error memory overflow,issue,negative,negative,neutral,neutral,negative,negative
415152364,Any updates here? I think it'd be good to add some rough performance numbers to the README so people can see expected results for debugging/comparison purposes.,think good add rough performance people see,issue,negative,positive,positive,positive,positive,positive
415060265,"@xialulu826 Please use the bug report template to specify the needed information.
Thanks.",please use bug report template specify information thanks,issue,positive,positive,positive,positive,positive,positive
415059006,"@kmbmjn Please specify which version of autokeras are you using.
Thanks.",please specify version thanks,issue,positive,positive,positive,positive,positive,positive
415025564,I could conduct some experiments after applying eagleoflqj's comment. I think it solved my problem. Thanks!,could conduct comment think problem thanks,issue,negative,positive,positive,positive,positive,positive
414981260,"More code examples would be appreciated.

Thanks for your work !",code would thanks work,issue,negative,positive,positive,positive,positive,positive
414980565,"Ok,

Think I have understood the Autokeras way. This code is loading the best saved model.
1. Get the autokeras graph
2. Generate a keras model from the graph

```
import os
from autokeras.utils import pickle_from_file

if __name__ == '__main__':
	path = 'XXX/app-autokeras/model'
	searcher = pickle_from_file(os.path.join(path, 'searcher'))
	graph = searcher.load_best_model()
	best_model = graph.produce_keras_model()
	best_model.summary()
```",think understood way code loading best saved model get graph generate model graph import o import path searcher path graph,issue,positive,positive,positive,positive,positive,positive
414938326,"Re: TextClassifier benchmarks:
I would suggest starting with a document/sentence leve lclassification model (not word level/many to many). e.g. IMDB sentiment. (Common benchmark for sentiment classification of short documents. Used to benchmark ULMFit amongst others).
https://github.com/keras-team/keras/blob/master/keras/datasets/imdb.py
http://nlp.fast.ai/classification/2018/05/15/introducting-ulmfit.html",would suggest starting model word many sentiment common sentiment classification short used amongst,issue,negative,positive,neutral,neutral,positive,positive
414938093,+1 . Search for a given 1D discrete or continous sequence would be amazing. ,search given discrete sequence would amazing,issue,positive,positive,positive,positive,positive,positive
414877752,"@tl-yang you can try the torch.multiprocessing.
I will be set the search space.

Thanks.",try set search space thanks,issue,negative,positive,positive,positive,positive,positive
414855645,"I think that is a normal behavior.
Thank you for your feedback! @Jules-Diez ",think normal behavior thank feedback,issue,negative,positive,positive,positive,positive,positive
414853366,"Ok the TimeoutError is gone. 

With version 0.2.5, when the time is up, the model that you are building stop and a message TimeOut appears but just after that a new model start but without prompting its parameters. And most of the time this model is quite light but need 30 iterations without improvement (not the usual 5) of the loss to stop itself. If I have time I will try to look at the code tomorrow to see what happens.
",gone version time model building stop message new model start without time model quite light need without improvement usual loss stop time try look code tomorrow see,issue,negative,positive,neutral,neutral,positive,positive
414828352,"@tl-yang 
Please see the file of net_transformer.py. It is where we can add if clause to limit the depth and width of the model.
Currently, we will put two more constants MAX_MODEL_WIDTH, MAX_MODEL_DEPTH in the Constant class instead of passing them through the parameters.

We will change it later if necessary.
Let me know if you have any questions.

Remember to branch out from develop branch.

Thanks.",please see file add clause limit depth width model currently put two constant class instead passing change later necessary let know remember branch develop branch thanks,issue,positive,positive,neutral,neutral,positive,positive
414826284,"@aa18514 Thank you so much for your help!
We are trying hard to fix all the issues.
Do you think replacing `multiprocessing` by `torch.multiprocessing` would solve the problem of not working well in windows?
I mean if not considering the problem of training to large models.

Thanks.",aa thank much help trying hard fix think would solve problem working well mean considering problem training large thanks,issue,positive,positive,neutral,neutral,positive,positive
414794216,"I've encountered the same bug running:

Debian 9.5
TensorFlow 1.10
Python 3.6.6
keras 2.2.2

The error is not always reproducible. Sometimes running mnist.py results in no errors and a graceful exit after the 20th model converges. This is using Nvidia K80 on Google Cloud.",bug running python error always reproducible sometimes running graceful exit th model cloud,issue,negative,neutral,neutral,neutral,neutral,neutral
414790249,"#Replicating the save-file code from commit a3ca627 :

    from autokeras import ImageClassifier
    clf = ImageClassifier(verbose=True, augment=False)
    clf.load_searcher().load_best_model().produce_keras_model().save('test_save.h5')

This appears successful. Returns null, but a new 7.3MB file 'test_save.h5' is generated from /tmp/autokeras/12.h5 which was originally 7.0MB.

Using Keras to plot the newly-saved model:

    from keras.models import load_model
    model = load_model('test_save.h5')
    from keras.utils import plot_model
    plot_model(model, to_file='model.png')

The result of this is successful, the architecture is plotted to an image.


Can also output just the architecture:

    from autokeras import ImageClassifier
    clf = ImageClassifier(verbose=True, augment=False)
    clf.load_searcher().load_best_model().produce_keras_model().to_json()
",code commit import successful null new file originally plot model import model import model result successful architecture plotted image also output architecture import,issue,positive,positive,positive,positive,positive,positive
414760828,"@Jules-Diez Thank you for your report.

I have solved it in the current master branch.",thank report current master branch,issue,negative,neutral,neutral,neutral,neutral,neutral
414565823,"Well I just saw issues #76 , aa18514's method seems better, since there is only one item in the list.",well saw aa method better since one item list,issue,positive,positive,positive,positive,positive,positive
414560856,"Same error.
My solution:
remove
```python
pool = multiprocessing.Pool(1)
```
and
```python
finally:
        # terminate and join the subprocess to prevent any resource leak
        pool.terminate()
        pool.join()
```
then change
```python
train_results = pool.map_async(train, [(graph, train_data, test_data, self.trainer_args,
                                                 os.path.join(self.path, str(model_id) + '.png'),
                                                 self.metric, self.loss, self.verbose)])
```
to
```python
train_results = list(map(train, [(graph, train_data, test_data, self.trainer_args,
                                                os.path.join(self.path, str(model_id) + '.png'),
                                                self.metric, self.loss, self.verbose)]))
```
and
```python
metric_value, loss, graph = train_results.get(timeout=remaining_time)[0]
```
to
```python
metric_value, loss, graph = train_results[0]
```",error solution remove python pool python finally terminate join prevent resource leak change python train graph python list map train graph python loss graph python loss graph,issue,negative,neutral,neutral,neutral,neutral,neutral
414473855,"@tl-yang
Add some code in the second last line in train() function in search.py.
to remove the model from the GPU memory.

Be careful about the import weights in layers.py and the loss returned by train_model() function in utils.py should be a float instead of a tensor.",add code second last line train function remove model memory careful import loss returned function float instead tensor,issue,negative,negative,neutral,neutral,negative,negative
414463392,"@parinaya-007 Thank you for your contribution.
However, our Markdown files are generated by executing mkdocs/autogen.py.
So it is the file that should be changed. You may change it in another merge request.

I will remove the duplication to avoid this in the future.
Thanks.",thank contribution however markdown file may change another merge request remove duplication avoid future thanks,issue,negative,positive,neutral,neutral,positive,positive
414382092,"@ManuelLevi Thank you so much!
Please change it.
Appreciate your help.

@ankapale you can focus on the other issues.
Thanks.",thank much please change appreciate help focus thanks,issue,positive,positive,positive,positive,positive,positive
414365950,"@boyuangong Please write a baseline for the TextClassifier.
It needs to extend from the supervised.py.
And reuse the class of ModelTrainer in utils.py.
Currently, it doesn't need to search for multiple architectures.
Just use a default architecture for now.

We can have a meeting to discuss if you have questions.
Thanks.",please write need extend reuse class currently need search multiple use default architecture meeting discus thanks,issue,positive,positive,neutral,neutral,positive,positive
414175716,"@blitu12345 Thank you for you interest.
@chenwydj is the one who is working on this issue.
You may talk to him via our gitter Lobby.
You can find it on our website badges.

Thanks.",thank interest one working issue may talk via lobby find thanks,issue,positive,positive,positive,positive,positive,positive
414175427,"@jrenouard 
Thank you for your report but we really cannot reproduce the error.
Would you use ""python3 -m pip install autokeras"" to install, and use ""python3"" to run the mnist.py?
So that it can make sure the package is installed for the same interpreter you use to run the script.
Thanks.",thank report really reproduce error would use python pip install install use python run make sure package interpreter use run script thanks,issue,positive,positive,positive,positive,positive,positive
414161941,"@PositronBeam Thank you for your report.
We haven't tested with Google Collaboratory yet.
Will come back to this soon.

Thanks.",thank report tested yet come back soon thanks,issue,positive,positive,neutral,neutral,positive,positive
414161851,"@ankapale Would you please help change it in the start.md file?
Thanks.",would please help change file thanks,issue,positive,positive,positive,positive,positive,positive
414107452,I'm also interested if anyone can guide me how to contribute and work on this?,also interested anyone guide contribute work,issue,negative,positive,positive,positive,positive,positive
414090541,"> In future, we plan to incorporate more operations and optimizations into our search space, and apply it to more mobile vision tasks such as semantic segmentation.

https://ai.googleblog.com/2018/08/mnasnet-towards-automating-design-of.html

",future plan incorporate search space apply mobile vision semantic segmentation,issue,negative,neutral,neutral,neutral,neutral,neutral
414090368,"I think that we could not limit this to single image if we have a video source.

A reference dataset:
https://davischallenge.org

Related:
https://github.com/jhfjhfj1/autokeras/issues/84",think could limit single image video source reference related,issue,negative,negative,neutral,neutral,negative,negative
414090326,It could also be interesting to explore separable convolution. See https://github.com/tensorflow/hub/issues/49.,could also interesting explore separable convolution see,issue,negative,positive,positive,positive,positive,positive
414076532,"Hey, 
I get pretty much the same issue with the first example on MacOSX 10.12
I installed autokeras via a ``pip3 install autokeras``and my python version is a fresh 3.6 from python.org

When I try to run the very first example I get this error:
```
Traceback (most recent call last):
  File ""autokeras.py"", line 1, in <module>
    import autokeras as ak
  File ""/Users/julien/travail/python/autokeras.py"", line 3, in <module>
    clf = ak.ImageClassifier()
AttributeError: module 'autokeras' has no attribute 'ImageClassifier'
```",hey get pretty much issue first example via pip install python version fresh try run first example get error recent call last file line module import ak file line module module attribute,issue,negative,positive,positive,positive,positive,positive
413748529,"Sorry for my late reply.
This is the shape of x_train.shape 
(1348, 480, 640, 4)
and x_test.shape
(1348, 480, 640, 4)

",sorry late reply shape,issue,negative,negative,negative,negative,negative,negative
413667171,"Can you look to export using onnx standard? 

So models are interoperable and deployable to production environments.

[https://onnx.ai](https://onnx.ai) 
",look export standard production,issue,negative,neutral,neutral,neutral,neutral,neutral
413640283,"@gael-reinaudi I am working on it.
Hopefully, it will be finished in several days.

Thank you.",working hopefully finished several day thank,issue,positive,neutral,neutral,neutral,neutral,neutral
413608333,"This seems to address #73 but there is no Regressor class.
How may we use this functionality? thx",address regressor class may use functionality,issue,negative,neutral,neutral,neutral,neutral,neutral
413507047,"MNIST works perfectly. The data I am trying is my own dataset.

Here's my PR.

```
from autokeras.classifier import ImageClassifier
from autokeras.classifier import load_image_dataset
import argparse

if __name__ == '__main__':
  parser = argparse.ArgumentParser(description=""parameters for the input program"")
  parser.add_argument('--train_csv', type=str, help=""training csv data directory"")
  parser.add_argument('--train_images', type=str, help=""training images directory"")
  parser.add_argument('--test_csv', type=str, help=""test csv directory"")
  parser.add_argument('--test_images', type=str, help=""test images directory"")
  #parser.add_argument('--dev', type=str, help=""dev directory"")

  args = parser.parse_args()

  x_train, y_train = load_image_dataset(csv_file_path=args.train_csv, images_path=args.train_images)
  print(x_train.shape)
  print(y_train.shape)

  x_test, y_test = load_image_dataset(csv_file_path=args.test_csv, images_path=args.test_images)
  print(x_train.shape)
  print(y_train.shape)

  clf = ImageClassifier(verbose=True)
  clf.fit(x_train, y_train, time_limit=10)
  clf.final_fit(x_train, y_train, x_test, y_test, retrain=True)
  y = clf.evaluate(x_test, y_test)
  print(y)
```

and my script : 
`python trainalutokeras_raw.py --train_csv ./train.csv --train_images ./images/train --test_csv ./test.csv --test_images ./images/test`",work perfectly data trying import import import parser input program training data directory training directory test directory test directory dev dev directory print print print print print script python,issue,positive,positive,positive,positive,positive,positive
413499218,"AutoKeras is poorly maintained at the minute, I had a similar issue

In ""/home/maybe/anaconda3/envs/asr/lib/python3.6/site-packages/torch/nn/modules/conv.py"" line 301 explicitly cast values in the tuple with the name 'self.padding' as int (before calling the function F.conv2d with appropiate parameters), one way you could do this by is adding the line:

```python
self.padding = (int(self.padding[0]), int(self.padding[1]))
```

before line 301:

```python
return F.conv2d(input, self.weight, self.bias, self.stride,
                           self.padding, self.dilation, self.groups)
```",poorly minute similar issue line explicitly cast name calling function one way could line python line python return input,issue,negative,negative,negative,negative,negative,negative
413494445,"yup, It's wrapped in `if __name__ == ""__main__""` function

yet, there's another error but similar. The stack trace is shown below

```
Using TensorFlow backend.
THCudaCheck FAIL file=/pytorch/aten/src/THC/generic/THCStorage.cu line=58 error=2 : out of memory
Traceback (most recent call last):
  File ""trainalutokeras_raw.py"", line 26, in <module>
    clf.fit(x_train, y_train, time_limit=10)
  File ""/home/maybe/anaconda3/envs/asr/lib/python3.6/site-packages/autokeras/classifier.py"", line 225, in fit
    run_searcher_once(train_data, test_data, self.path)
  File ""/home/maybe/anaconda3/envs/asr/lib/python3.6/site-packages/autokeras/classifier.py"", line 40, in run_searcher_once
    searcher.search(train_data, test_data)
  File ""/home/maybe/anaconda3/envs/asr/lib/python3.6/site-packages/autokeras/search.py"", line 178, in search
    train_results = train((graph, train_data, test_data, self.trainer_args, os.path.join(self.path, str(model_id) + '.png'), self.verbose))
  File ""/home/maybe/anaconda3/envs/asr/lib/python3.6/site-packages/autokeras/search.py"", line 326, in train
    verbose).train_model(**trainer_args)
  File ""/home/maybe/anaconda3/envs/asr/lib/python3.6/site-packages/autokeras/utils.py"", line 122, in train_model
    self._train(train_loader, epoch)
  File ""/home/maybe/anaconda3/envs/asr/lib/python3.6/site-packages/autokeras/utils.py"", line 143, in _train
    outputs = self.model(inputs)
  File ""/home/maybe/anaconda3/envs/asr/lib/python3.6/site-packages/torch/nn/modules/module.py"", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File ""/home/maybe/anaconda3/envs/asr/lib/python3.6/site-packages/autokeras/graph.py"", line 603, in forward
    temp_tensor = torch_layer(edge_input_tensor)
  File ""/home/maybe/anaconda3/envs/asr/lib/python3.6/site-packages/torch/nn/modules/module.py"", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File ""/home/maybe/anaconda3/envs/asr/lib/python3.6/site-packages/torch/nn/modules/conv.py"", line 301, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: cuda runtime error (2) : out of memory at /pytorch/aten/src/THC/generic/THCStorage.cu:58
/home/maybe/anaconda3/envs/asr/lib/python3.6/multiprocessing/semaphore_tracker.py:129: UserWarning: semaphore_tracker: There appear to be 1 leaked semaphores to clean up at shutdown
  len(cache))
```

Thanks for the quick response.",wrapped function yet another error similar stack trace shown fail memory recent call last file line module file line fit file line file line search train graph file line train verbose file line epoch file line file line result input file line forward file line result input file line forward error memory appear clean shutdown cache thanks quick response,issue,negative,positive,neutral,neutral,positive,positive
413488396,"Yes, this is another bug 
try to replace line 178 in (home/maybe/anaconda3/envs/asr/lib/python3.6/site-packages/autokeras/search.py): <br>
```terminal
""train_results = pool.map_async(train, [(graph, train_data, test_data, self.trainer_args, <br>
                                                os.path.join(self.path, str(model_id) + '.png'), self.verbose)])"" <br>
```

with: <br>

```terminal
train_results = train((graph, train_data, test_data, self.trainer_args, os.path.join(self.path, str(model_id) + '.png'), self.verbose)) <br>
```

and replace line 190 <br>

```terminal
accuracy, loss, graph = train_results.get()[0] <br>
```

with: <br>
```terminal
accuracy, loss, graph = train_results <br>
```

if you are on windows, torch with CUDA and multiprocessing do not seem to work well together.

Also please try to wrap your code in trainalutokeras_raw.py in:

```terminal
if __name__ == ""__main__""
```",yes another bug try replace line terminal train graph terminal train graph replace line terminal accuracy loss graph terminal accuracy loss graph torch seem work well together also please try wrap code terminal,issue,negative,neutral,neutral,neutral,neutral,neutral
413442873,"I came across the same issue:

```
Traceback (most recent call last):
  File ""trainalutokeras_raw.py"", line 25, in <module>
    clf.fit(x_train, y_train, time_limit=5 *60 *60)
  File ""/home/maybe/anaconda3/envs/asr/lib/python3.6/site-packages/autokeras/classifier.py"", line 225, in fit
    run_searcher_once(train_data, test_data, self.path)
  File ""/home/maybe/anaconda3/envs/asr/lib/python3.6/site-packages/autokeras/classifier.py"", line 40, in run_searcher_once
    searcher.search(train_data, test_data)
  File ""/home/maybe/anaconda3/envs/asr/lib/python3.6/site-packages/autokeras/search.py"", line 190, in search
    accuracy, loss, graph = train_results.get()[0]
  File ""/home/maybe/anaconda3/envs/asr/lib/python3.6/multiprocessing/pool.py"", line 608, in get
    raise self._value
RuntimeError: cuda runtime error (2) : out of memory at /pytorch/aten/src/THC/generic/THCStorage.cu:58
/home/maybe/anaconda3/envs/asr/lib/python3.6/multiprocessing/semaphore_tracker.py:129: UserWarning: semaphore_tracker: There appear to be 1 leaked semaphores to clean up at shutdown
  len(cache))
```
Also, I tried to reduce the time limit with 
`clf.fit(x_train, y_train, time_limit=10)`
doesn't solve the problem. I bet its a bug.",came across issue recent call last file line module file line fit file line file line search accuracy loss graph file line get raise error memory appear clean shutdown cache also tried reduce time limit solve problem bet bug,issue,negative,positive,positive,positive,positive,positive
413416035,"yes this is a bug, you could get around this by specifying the time_limit to a reasonably small value such as 10 seconds to ensure the run_searcher_once method runs only once.

if you check the following:

```terminal
user@ubuntu:~$ vim C:\Users\user\AppData\Local\Programs\Python36\lib\site-packages\autokeras\classifier.py
``` 
you will find the following piece of code on line 223

```terminal

if time_limit is None:
    time_limit = 24 * 60 * 60

start_time = time.time()
while time.time() - start_time <= time_limit:
    run_searcher_once(train_data, test_data, self.path)
    if len(self.load_searcher().history) >= Constant.MAX_MODEL_NUM:
        break

```

you could see the flaw in this piece of code, if time_limit parameter is not specified it defaults to 24 * 60 minutes, the default value of Constant.MAX_MODEL_NUM is 1000, so you keep on looping in the while loop until len(self.load_searcher().history) >= Constant.MAX_MODEL_NUM, also after the train process is complete self.load_searcher().history stores the new trained model which means its length only increases by one...you could get around this by maybe replacing Constant.MAX_MODEL_NUM to a sane value like 1 (or choose the time limit to be low like 10 seonds), I hope this helps....

I banged my head over this for a few hours, there a number of other problematic things in the code, I think?",yes bug could get around reasonably small value ensure method check following terminal user vim find following piece code line terminal none break could see flaw piece code parameter default value keep looping loop also train process complete new trained model length one could get around maybe sane value like choose time limit low like hope head number problematic code think,issue,positive,negative,neutral,neutral,negative,negative
413390852,"@WXB506 
i also meet this question.
but i m not using python3.
how to solved it? 
thanks.
@jhfjhfj1 
",also meet question python thanks,issue,negative,positive,positive,positive,positive,positive
413324936,"@tl-yang Please fix the code to pass the CI test.

Thanks.",please fix code pas test thanks,issue,positive,positive,positive,positive,positive,positive
413295330,"@Zvezdin Return 0 is not a good solution. It will seriously impact the performance of the GaussianProcessRegressor. 
If it could return some special value and not update the GaussianProcessRegressor with such value, it would be better.",return good solution seriously impact performance could return special value update value would better,issue,positive,positive,positive,positive,positive,positive
413268966,"@Sungtae-Lee 
You can first install autokeras, then upgrade the tensorflow.
This is a temporary solution.

I tried with mine. It works well with tensorflow 1.8.0.
I suggest you use virtualenvwrapper to just install autokeras and try.",first install upgrade temporary solution tried mine work well suggest use install try,issue,positive,positive,positive,positive,positive,positive
413267328,"Thank you all for the report.
The current version is using pytorch.
I am not sure it can support selecting GPU or not.

If really in need of selecting GPU, please submit a new issue with feature request template.
Thank you.",thank report current version sure support really need please submit new issue feature request template thank,issue,positive,positive,positive,positive,positive,positive
413266128,"Thank you for the question.
Currently, we do not support loading batch by batch.
We may implement it later.

If really in need, you can submit an issue with the feature request template for it.
Thanks.",thank question currently support loading batch batch may implement later really need submit issue feature request template thanks,issue,positive,positive,neutral,neutral,positive,positive
413265064,"Thank you for your request.
This will be supported together with the 3D input.",thank request together input,issue,negative,neutral,neutral,neutral,neutral,neutral
413203060,"If I install tensorflow without autokeras, it installs tensorflow 1.10.0 and it works well.
However if i install autokeras with tensorflow, tensorflow version gets fixed to 1.8.0 and it gives errors.
Even if I specify the version of tensorflow while installing after installing autokeras, tensorflow version is fixed to 1.8.0.
Do you know how to upgrade tensorflow version to 1.10.0 after installing autokeras? @jhfjhfj1 Thanks",install without work well however install version fixed even specify version version fixed know upgrade version thanks,issue,negative,positive,positive,positive,positive,positive
413160728,sorry currently I have no time to confirm these so I’d like to close it temporarily,sorry currently time confirm like close temporarily,issue,negative,negative,negative,negative,negative,negative
413103702,"[autokeras_bugcode.txt](https://github.com/jhfjhfj1/autokeras/files/2289362/autokeras_bugcode.txt)
Here's the text file version of the code, since the format was changed by the message board.
Thanks!",text file version code since format message board thanks,issue,negative,positive,positive,positive,positive,positive
413103184,"Here's my code: 
----------------------------------------------------------------------
from autokeras.classifier import ImageClassifier
import argparse
import numpy as np

parser = argparse.ArgumentParser()
parser.add_argument('-path', dest='path', type=str, help='/path/to/save/model')

args = parser.parse_args()
path = args.path

if __name__ == '__main__':
    x_train = np.load('x_train.npy')
    y_train = np.load('y_train.npy')
    clf = ImageClassifier(verbose=True, path=path, resume=True, augment=False)
    clf.fit(x_train, y_train, time_limit=12*60*60)


",code import import import parser path,issue,negative,neutral,neutral,neutral,neutral,neutral
413015025,"## Pull Request Test Coverage Report for [Build 418](https://coveralls.io/builds/18485735)

* **2** of **2**   **(100.0%)**  changed or added relevant lines in **1** file are covered.
* **1** unchanged line in **1** file lost coverage.
* Overall coverage increased (+**0.06%**) to **94.538%**

---


|  Files with Coverage Reduction | New Missed Lines | % |
| :-----|--------------|--: |
| [autokeras/utils.py](https://coveralls.io/builds/18485735/source?filename=autokeras%2Futils.py#L55) | 1 | 81.54% |
<!-- | **Total:** | **1** |  | -->

|  Totals | [![Coverage Status](https://coveralls.io/builds/18485735/badge)](https://coveralls.io/builds/18485735) |
| :-- | --: |
| Change from base [Build 416](https://coveralls.io/builds/18480948): |  0.06% |
| Covered Lines: | 1523 |
| Relevant Lines: | 1611 |

---
##### 💛  - [Coveralls](https://coveralls.io)
",pull request test coverage report build added relevant file covered unchanged line file lost coverage overall coverage coverage reduction new total coverage status change base build covered relevant coverall,issue,negative,positive,neutral,neutral,positive,positive
413003667,"When I first ran this with about 550 128x128 grayscale images using a Quadro P4000 with 8 GB of memory, it immediately crashed due to insufficient memory.  I adjusted the constant.MAX_BATCH_SIZE parameter from the default of 128 down to 32, and then it worked for about an hour until crashing  again.  The error message was:
RuntimeError: cuda runtime error (2) : out of memory at /pytorch/aten/src/THC/generic/THCStorage.cu:58

 I was watching the GPU memory usage before it crashed, and it fluctuated in cycles as expected for a ""grid search"" sort of activity.  Unfortunately, it looks like the peak memory usage corresponding to the more memory-intensive models progressively increase until overwhelming the GPU memory. 

 Maybe it would be good, upon initialization of the program, to quantify the available memory and then cap the model search to models that fit within that limit.  If the program determines that it cannot identify an optimal model within that constraint, and may require more memory, it could output such a message and hints as to how to accomplish this (i.e., smaller batches, smaller images, larger GPU memory, etc...).  It might also help to offer a grayscale option in the load_image_dataset method that reduces a color image from three color channels to one grayscale channel.

also, what is the LIMIT_MEMORY parameter?",first ran memory immediately due insufficient memory parameter default worked hour error message error memory watching memory usage grid search sort activity unfortunately like peak memory usage corresponding progressively increase overwhelming memory maybe would good upon program quantify available memory cap model search fit within limit program identify optimal model within constraint may require memory could output message accomplish smaller smaller memory might also help offer option method color image three color one channel also parameter,issue,positive,positive,positive,positive,positive,positive
412967798,"@jhfjhfj1 Thanks for the reply.

I start getting out of memory errors after many successfully trained models. I don't think that it's a memory leak or a dataset error. I'm using a custom dataset and one input sample (without batch) is a 80x90x24 matrix. In my case, I think that AutoKeras decides to create too large models for my 6GB GPU after many successful iterations. In such a case, would you consider my proposed solution as optimal (giving negative or zero feedback if it fails), or else how would you tackle such an issue?",thanks reply start getting memory many successfully trained think memory leak error custom one input sample without batch matrix case think create large many successful case would consider solution optimal giving negative zero feedback else would tackle issue,issue,positive,positive,positive,positive,positive,positive
412942425,"@Jangol @Zvezdin 
Thank you for your help.

I think the memory is usually big enough to handle most of the datasets.
I am not sure how to clean up the GPU memory usage of a model in pytorch.
I think we should clean the GPU memory on the main process.
Then see if it still crashes or not.

If it still crashes, we will try to feed the data really in batches.",thank help think memory usually big enough handle sure clean memory usage model think clean memory main process see still still try feed data really,issue,positive,positive,positive,positive,positive,positive
412941084,"Thank you for your interest.

I think it can.
Did you try the load_raw_data example?
@X-YI ",thank interest think try example,issue,positive,neutral,neutral,neutral,neutral,neutral
412940505,"Thank you for your interest in our project.
Currently, we do not support distributed mode.

We might support it in the future.
If you really in need of this feature, you can submit a new issue using the feature request template.
Thanks.",thank interest project currently support distributed mode might support future really need feature submit new issue feature request template thanks,issue,positive,positive,positive,positive,positive,positive
412939861,"@GagaLeung Would you please share your code as well?

Thank you!",would please share code well thank,issue,positive,neutral,neutral,neutral,neutral,neutral
412800740,"I also keep getting these errors on a GTX 1060. I managed to fix it the following way. If training a network crashes, I updated the train function to return 0.0 as accuracy and the maximum possible loss as loss. This way the Bayesian optimization algorithm understands that this path is unreliable (for the current hardware) and tries to find an alternative. If @jhfjhfj1 wants, I can make a pull request with the change.",also keep getting fix following way training network train function return accuracy maximum possible loss loss way optimization algorithm path unreliable current hardware find alternative make pull request change,issue,negative,neutral,neutral,neutral,neutral,neutral
412764469,"Hi:
You can try to adjust the "" constant.MAX_BATCH_SIZE"" parameter，the default value is 32 .",hi try adjust default value,issue,negative,neutral,neutral,neutral,neutral,neutral
412731543,"Please try to upgrade your tensorflow to the required version.
@Sungtae-Lee ",please try upgrade version,issue,negative,neutral,neutral,neutral,neutral,neutral
412729651,"I installed autokeras by ""pip3 install autokeras""
ran ""python3""
then, used import autokeras

=====================================================
I have succeeded in changing the error message and it persists even after using
""python -m pip install autokeras""
I did it by installing pytorch manually other than the one installed while installing autokeras.
It seems like tensorflow also need to be installed manually.

Now the error is
=====================================================
>>> import autokeras
Using TensorFlow backend.
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/mnt/hkim/deepcas9/autokeras.py"", line 1, in <module>
    from keras.datasets import mnist
  File ""/home/hkim/.local/lib/python3.6/site-packages/keras/__init__.py"", line 3, in <module>
    from . import utils
  File ""/home/hkim/.local/lib/python3.6/site-packages/keras/utils/__init__.py"", line 6, in <module>
    from . import conv_utils
  File ""/home/hkim/.local/lib/python3.6/site-packages/keras/utils/conv_utils.py"", line 9, in <module>
    from .. import backend as K
  File ""/home/hkim/.local/lib/python3.6/site-packages/keras/backend/__init__.py"", line 89, in <module>
    from .tensorflow_backend import *
  File ""/home/hkim/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py"", line 5, in <module>
    import tensorflow as tf
  File ""/home/hkim/.local/lib/python3.6/site-packages/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
  File ""/home/hkim/.local/lib/python3.6/site-packages/tensorflow/python/__init__.py"", line 63, in <module>
    from tensorflow.python.framework.framework_lib import *  # pylint: disable=redefined-builtin
  File ""/home/hkim/.local/lib/python3.6/site-packages/tensorflow/python/framework/framework_lib.py"", line 104, in <module>
    from tensorflow.python.framework.importer import import_graph_def
  File ""/home/hkim/.local/lib/python3.6/site-packages/tensorflow/python/framework/importer.py"", line 32, in <module>
    from tensorflow.python.framework import function
  File ""/home/hkim/.local/lib/python3.6/site-packages/tensorflow/python/framework/function.py"", line 36, in <module>
    from tensorflow.python.ops import resource_variable_ops
  File ""/home/hkim/.local/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py"", line 35, in <module>
    from tensorflow.python.ops import variables
  File ""/home/hkim/.local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py"", line 40, in <module>
    class Variable(checkpointable.CheckpointableBase):
AttributeError: module 'tensorflow.python.training.checkpointable' has no attribute 'CheckpointableBase'
=============================================

About pip and python library
$ pip3 --version
pip 8.1.1 from /usr/lib/python3/dist-packages (python 3.6)

>>> import site; site.getsitepackages()
['/usr/local/lib/python3.6/dist-packages', '/usr/lib/python3/dist-packages', '/usr/lib/python3.6/dist-packages']

Thank you for helping @jhfjhfj1 ",pip install ran python used import error message even python pip install manually one like also need manually error import recent call last file line module file line module import file line module import file line module import file line module import file line module import file line module import file line module import file line module import file line module import file line module import function file line module import file line module import file line module class variable module attribute pip python library pip version pip python import site thank helping,issue,negative,neutral,neutral,neutral,neutral,neutral
412728494,"Thank you for your interest in our project.

Currently, we do not support this feature, but you can submit an issue of ""feature request"" if you really in need.",thank interest project currently support feature submit issue feature request really need,issue,positive,positive,neutral,neutral,positive,positive
412728196,"Thank you for your interest in our project.

Currently, we do not support tabular data.
If you really in need you can submit an issue of ""new task module"".",thank interest project currently support tabular data really need submit issue new task module,issue,positive,positive,positive,positive,positive,positive
412727801,"This is fixed in the latest release.
Please reopen the issue if it is not.

Thank you.",fixed latest release please reopen issue thank,issue,positive,positive,positive,positive,positive,positive
412727632,"Thank you for your report.
This is fixed in the latest release.

Please reopen the issue if it is not.",thank report fixed latest release please reopen issue,issue,positive,positive,positive,positive,positive,positive
412727495,"Thank you for your report.
This bug is fixed in the latest release.

If you find it is not, please reopen the issue.",thank report bug fixed latest release find please reopen issue,issue,positive,positive,positive,positive,positive,positive
412726853,"I really don't have this error. The only reason I can guess is your pip and python not using the same library. Please use `python -m pip install autokeras`. I don't know which command you use to run python, but just use it in this way to run pip. @Sungtae-Lee  Thanks.

<sub>Sent with <a href=""http://githawk.com"">GitHawk</a></sub>",really error reason guess pip python library please use python pip install know command use run python use way run pip thanks sub sent,issue,negative,positive,positive,positive,positive,positive
412713383,"We currently do not support tabular data for now.
Currently, we only support Image classification.
But more functions will be added soon.

Thank you for the question.",currently support tabular data currently support image classification added soon thank question,issue,positive,neutral,neutral,neutral,neutral,neutral
412676157,"<!---
Please label your issue with `new_task_module`.
-->

### Suggested Name
<!---
Give a suggested name of the new task module, e.g. TextClassifier, ImageClassifier.
-->
TextClassifier
### Task Description
<!---
A clear and concise description of the machine learning task to be added, its problem statement and learning outcome.
-->
Text classification. The input is some strings. Each string is an article, a sentence, a paragraph in English. The output is a single class label for each string.

### Evaluation Metrics
<!---
e.g. Mean Square Error, F1-score, Accuracy, AUC.
-->
Accuracy

### Benchmark Datasets
<!---
Any public available datasets you know for the task,
please provide the name and link.
-->
Penn Treebank
### Reason
<!---
A clear and concise description of why this feature would be useful for the project.
-->
NA
### Solution
<!---
A clear and concise description of what you want to happen.
-->
NA
### Additional Context
<!---
Add any other context or screenshots about the feature request here.
-->
NA",please label issue name give name new task module task description clear concise description machine learning task added problem statement learning outcome text classification input string article sentence paragraph output single class label string evaluation metric mean square error accuracy accuracy public available know task please provide name link reason clear concise description feature would useful project na solution clear concise description want happen na additional context add context feature request na,issue,positive,positive,neutral,neutral,positive,positive
412655477,"Sorry for the late reply.
Auto Keras will encode the labels in y for you.
Y should be a one-dimensional array which has the same length as x.

Thanks.",sorry late reply auto encode array length thanks,issue,negative,negative,negative,negative,negative,negative
412654560,"Thank you all for the help.
We haven't really tested on Windows, yet.
We will move to torch 0.4.1 in the next release.
",thank help really tested yet move torch next release,issue,positive,positive,neutral,neutral,positive,positive
412653293,"This issue has been fixed in the new release.
The parameter of the __init__() function has changed.

Thank you for your contribution.",issue fixed new release parameter function thank contribution,issue,negative,positive,positive,positive,positive,positive
412652868,"I think this is a Keras related issue.
Since it is not calling the autokeras code yet before it crashes.

If you feel it is not, you can reopen the issue.

Thank you for your contribution.",think related issue since calling code yet feel reopen issue thank contribution,issue,negative,neutral,neutral,neutral,neutral,neutral
412651679,"This issue has been fixed.
Thank you for the contribution.",issue fixed thank contribution,issue,negative,positive,neutral,neutral,positive,positive
412623148,"Thank you for the suggestion.
We are working on this feature now.
It would be online soon.

Thanks.",thank suggestion working feature would soon thanks,issue,positive,positive,positive,positive,positive,positive
412620106,"Thank you for the bug report.
I just fixed it by changing the examples.
You can reopen the issue if it still fails.

Thanks.",thank bug report fixed reopen issue still thanks,issue,positive,positive,positive,positive,positive,positive
412583412,"Thank @paindefender for the help.

@ankapale 
Please add a function of export keras_model() to the ImageClassifier
by clf.load_searcher().load_best_model().produce_keras_model() here.
https://github.com/jhfjhfj1/autokeras/blob/master/autokeras/graph.py#L542

Thanks.

We also need to find a way to export our own model instead of the Keras model.
I will open an issue on that.",thank help please add function export thanks also need find way export model instead model open issue,issue,positive,positive,neutral,neutral,positive,positive
412386017,"The classifier.md is automatically generated from the docstrings in the code.
You may want to modify the docstrings instead.

Thank you for your contribution.",automatically code may want modify instead thank contribution,issue,negative,neutral,neutral,neutral,neutral,neutral
412386011,I also interested in text classifier.,also interested text classifier,issue,negative,positive,positive,positive,positive,positive
412385167,"The classifier.md is automatically generated from the docstrings in the code.
You may modify the docstrings instead.

Thank you for the contribution.",automatically code may modify instead thank contribution,issue,negative,neutral,neutral,neutral,neutral,neutral
412384969,"Thank you for the contribution but the docs have been largely changed recently.
The typo has been fixed during the process.",thank contribution largely recently typo fixed process,issue,negative,positive,neutral,neutral,positive,positive
412382657,"Auto Keras may figure out a better default path.
It would be better if it is OS aware.",auto may figure better default path would better o aware,issue,positive,positive,positive,positive,positive,positive
412293474,@jagesh I got to know that I you have to define the time limit in the step before that ,got know define time limit step,issue,negative,neutral,neutral,neutral,neutral,neutral
412258359,"+1.

Only running on one GPU despite having four GPU on my server.

",running one despite four server,issue,negative,neutral,neutral,neutral,neutral,neutral
412258085,"same issue +1.
I expect  
`clf.fit(x_train, y_train, time_limit=2 *60 *60 )`

to execute about 2 hours, but didn't stop regardless of 2 hrs pass by.",issue expect execute stop regardless pas,issue,negative,neutral,neutral,neutral,neutral,neutral
411959145,"A hint, just specifies a new approachable path when creating the classifier is ok. You can check it by referring docstring by help() method.",hint new approachable path classifier check help method,issue,negative,positive,positive,positive,positive,positive
411954062,"Having the same problem here. Couldn't install with 'pip install autokeras', so I installed with --no-dependencies. Then installed the dependencies manually (wrong versions). Could be that. But I am having the same problem on windows. Under Linux Subsystem it worked perfectly.",problem could install install manually wrong could problem subsystem worked perfectly,issue,negative,positive,positive,positive,positive,positive
411818723,"thanks for the answer, but how to write you by another way 
what is your email?",thanks answer write another way,issue,negative,positive,positive,positive,positive,positive
411797013,"Hey @rodrigob I just had the same problem where simple uninstall and reinstall didn't help. I fixed it by:

1. Uninstalling everything installed with pip.

`pip freeze | xargs pip uninstall -y
`

2. Deleting all my site-packages directories (found by doing `python -m site`)
3. Reinstalling tensorflow using pip with the --no-cache-dir option. Reinstalling without the --no-cache-dir didn't resolve the problem. `pip install tensorflow==1.9 --no-cache-dir`.

Step (2) is probably not needed due to step (1), but I haven't checked that.

HTH,

Owen.",hey problem simple reinstall help fixed everything pip pip freeze pip found python site pip option without resolve problem pip install step probably due step checked,issue,negative,negative,neutral,neutral,negative,negative
411322983,"Same for me. The working solution was:
1. pip install pytorch  (from their homepage)
2. download autokeras from https://pypi.org/project/autokeras/0.2.1/#history
3. unpack, edit setup.py and change from torch==0.4.0 to torch==0.4.1 (line 6) and pack back to tar.gz
4. pip install autokeras-0.2.1.tar.gz",working solution pip install unpack edit change line pack back pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
410919196,"Those are just some random files we created.
They have been deleted.
The only example we provide currently is the examples/mnist.py

Sorry for the confusion.",random example provide currently sorry confusion,issue,negative,negative,negative,negative,negative,negative
410820166,@song3134 Please add some pytest to make sure the coverage from coveralls doesn't drop.,song please add make sure coverage coverall drop,issue,negative,positive,positive,positive,positive,positive
410815722,"Thank you so much!
I just fixed the problem.",thank much fixed problem,issue,negative,positive,neutral,neutral,positive,positive
410706459,"This is an simple bug fix for python 3 users.
This bug happened because of ""float padding"" value.
To fix this issue, cast padding value to int.
#42 #46 ",simple bug fix python bug float padding value fix issue cast padding value,issue,positive,neutral,neutral,neutral,neutral,neutral
410514937,"In Cifar10.py , 

Traceback (most recent call last):
  File ""autok2.py"", line 7, in <module>
    clf = ImageClassifier(verbose=True, augment=True)
TypeError: __init__() got an unexpected keyword argument 'augment'

this is the error, tried in both python3 and python2",recent call last file line module got unexpected argument error tried python python,issue,negative,positive,neutral,neutral,positive,positive
410463379,"@hiteshn97 yes, this worked. I also managed to install it by simply installing torch by myself. Unfortunately it still seems to have problems. The examples aren't working. ",yes worked also install simply torch unfortunately still working,issue,negative,negative,negative,negative,negative,negative
410447582,"Not sure about the Memory requirement of AutoML but this Memory error depends on your dataset size as well.
Since you are using a few thousand RGB images, it will take up a huge space and eventually may fail on VRAM/RAM in execution.
And ""Batch size"" is not yet configurable from the user side, so you will not be even able to trim down data flowing per batch.
I suggest to try with just a few hundred images and monitor the Memory used up!",sure memory requirement memory error size well since thousand take huge space eventually may fail execution batch size yet user side even able trim data flowing per batch suggest try hundred monitor memory used,issue,negative,positive,positive,positive,positive,positive
410439745,"I followed this blog https://github.com/tensorflow/probability/issues/46 and it solved the issue.
Although it's a new error now, ImportError: cannot import name Constant
Should I open another issue for this?",issue although new error import name constant open another issue,issue,negative,positive,neutral,neutral,positive,positive
410437088,"I have forked the original library here https://github.com/hiteshn97/autokeras/
Clone it, then python setup.py install 
Worked.
",forked original library clone python install worked,issue,negative,positive,positive,positive,positive,positive
410435823,"You can try the lower version of tf，and after uninstalled the tf remove the residual folder in the python site-packages.
My version：
Keras：2.1.5
tf：1.6.0",try lower version uninstalled remove residual folder python,issue,negative,neutral,neutral,neutral,neutral,neutral
410431652,"I have forked the original library here https://github.com/hiteshn97/autokeras/blob/master/requirements.txt
Can you provide an example on how to build this from setup.py ? 
Much thanx.",forked original library provide example build much,issue,negative,positive,positive,positive,positive,positive
410428493,"Tried. Uninstalled protobuf, tf and reinstalled them. Still same error.",tried uninstalled still error,issue,negative,neutral,neutral,neutral,neutral,neutral
410390972,"Same problem here windows 10 
python 3.6.2
is it an issue with torch on windows ?",problem python issue torch,issue,negative,neutral,neutral,neutral,neutral,neutral
410386826,"Even I included GPUtil, I still can not select my GPU. ",even included still select,issue,negative,neutral,neutral,neutral,neutral,neutral
410310715,"Hi

Unlikely...i am just learning how to use github.... 😉

cheers!



Manuel Boissiere





________________________________
From: Karan Dwivedi <notifications@github.com>
Sent: 03 August 2018 17:38
To: jhfjhfj1/autokeras
Cc: Subscribed
Subject: Re: [jhfjhfj1/autokeras] Performance (#10)


@jhfjhfj1<https://github.com/jhfjhfj1> any updates?

Thanks :)

—
You are receiving this because you are subscribed to this thread.
Reply to this email directly, view it on GitHub<https://github.com/jhfjhfj1/autokeras/issues/10#issuecomment-410309135>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AoHxvAtIR5ZRflgLn4YCaYmpWgfUXWC5ks5uNHyCgaJpZM4TahgY>.
",hi unlikely learning use sent august subject performance thanks thread reply directly view mute thread,issue,negative,negative,neutral,neutral,negative,negative
410243056,+1 would also be interested in auto text classifier,would also interested auto text classifier,issue,negative,positive,positive,positive,positive,positive
410226095,"On the same topic,
What types of ML problems are supported? There are only examples of image classification tasks.
In my specific case, I'm interested in multi-target regression with continuous and categorical inputs. Does Auto-Keras handle categorical variables for example with support for embeddings?",topic image classification specific case interested regression continuous categorical handle categorical example support,issue,positive,positive,positive,positive,positive,positive
410148814,"python2 does not have queue， I try python3, the problem solved.",python try python problem,issue,negative,neutral,neutral,neutral,neutral,neutral
409563994,"Thank you for your careful reading.
It has been patched in the new version which would be released soon.
It should be changed to ""return f[len_a-1][len_b-1].""",thank careful reading new version would soon return,issue,negative,positive,neutral,neutral,positive,positive
402718001,Ignore my question about the accuracy results. I see now it is scored on the test set. So my only question is about parallelism.,ignore question accuracy see scored test set question parallelism,issue,negative,neutral,neutral,neutral,neutral,neutral
382478830,"@touching-foots-huskie Currently not, but we might start to implement RNN after the image classifier is ready.",currently might start implement image classifier ready,issue,negative,positive,neutral,neutral,positive,positive
382478391,@bkj We are fine tuning and running the experiments on several benchmark datasets. The results should be ready in one month.,fine tuning running several ready one month,issue,positive,positive,positive,positive,positive,positive
381937571,"## Pull Request Test Coverage Report for [Build 117](https://coveralls.io/builds/16554448)

* **0** of **0**  **(NaN%)** changed or added relevant lines in **0** files are covered.
* No unchanged relevant lines lost coverage.
* Overall coverage remained the same at **96.266%**

---



|  Totals | [![Coverage Status](https://coveralls.io/builds/16554448/badge)](https://coveralls.io/builds/16554448) |
| :-- | --: |
| Change from base [Build 111](https://coveralls.io/builds/16519780): |  0.0% |
| Covered Lines: | 1289 |
| Relevant Lines: | 1339 |

---
##### 💛  - [Coveralls](https://coveralls.io)
",pull request test coverage report build nan added relevant covered unchanged relevant lost coverage overall coverage coverage status change base build covered relevant coverall,issue,negative,positive,neutral,neutral,positive,positive
381819722,"Thank you for the contribution.
Could you change this file as well?
https://github.com/jhfjhfj1/autokeras/blob/master/mkdocs/docs/index.md
Thanks.
@lusob ",thank contribution could change file well thanks,issue,positive,positive,positive,positive,positive,positive
381558511,"## Pull Request Test Coverage Report for [Build 115](https://coveralls.io/builds/16534580)

* **0** of **0**  **(NaN%)** changed or added relevant lines in **0** files are covered.
* **4** unchanged lines in **1** file lost coverage.
* Overall coverage decreased (**-0.3%**) to **95.967%**

---


|  Files with Coverage Reduction | New Missed Lines | % |
| :-----|--------------|--: |
| [autokeras/net_transformer.py](https://coveralls.io/builds/16534580/source?filename=autokeras%2Fnet_transformer.py#L47) | 4 | 90.2% |
<!-- | **Total:** | **4** |  | -->

|  Totals | [![Coverage Status](https://coveralls.io/builds/16534580/badge)](https://coveralls.io/builds/16534580) |
| :-- | --: |
| Change from base [Build 111](https://coveralls.io/builds/16519780): |  -0.3% |
| Covered Lines: | 1285 |
| Relevant Lines: | 1339 |

---
##### 💛  - [Coveralls](https://coveralls.io)
",pull request test coverage report build nan added relevant covered unchanged file lost coverage overall coverage coverage reduction new total coverage status change base build covered relevant coverall,issue,negative,positive,neutral,neutral,positive,positive
375913728,"## Pull Request Test Coverage Report for [Build 95](https://coveralls.io/builds/16160606)

* **30** of **39**  **(76.92%)** changed or added relevant lines in **1** file are covered.
* **1** unchanged line in **1** file lost coverage.
* Overall coverage decreased (**-0.5%**) to **94.235%**

---

|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |
| :-----|--------------|--------|---: |
| [autokeras/classifier.py](https://coveralls.io/builds/16160606/source?filename=autokeras%2Fclassifier.py#L107) | 30 | 39 | 76.92%
<!-- | **Total:** | **30** | **39** | **76.92%** | -->

|  Files with Coverage Reduction | New Missed Lines | % |
| :-----|--------------|--: |
| [autokeras/net_transformer.py](https://coveralls.io/builds/16160606/source?filename=autokeras%2Fnet_transformer.py#L72) | 1 | 86.89% |
<!-- | **Total:** | **1** |  | -->

|  Totals | [![Coverage Status](https://coveralls.io/builds/16160606/badge)](https://coveralls.io/builds/16160606) |
| :-- | --: |
| Change from base [Build 87](https://coveralls.io/builds/16061436): |  -0.5% |
| Covered Lines: | 1226 |
| Relevant Lines: | 1301 |

---
##### 💛  - [Coveralls](https://coveralls.io)
",pull request test coverage report build added relevant file covered unchanged line file lost coverage overall coverage missing coverage covered total coverage reduction new total coverage status change base build covered relevant coverall,issue,negative,negative,neutral,neutral,negative,negative
375316615,"@amraw Please fix the failed test by looking at the logs in ""continuous-integration/travis-ci/push"" by clicking ""Details"" button after it.
Thanks.",please fix test looking button thanks,issue,positive,positive,positive,positive,positive,positive
