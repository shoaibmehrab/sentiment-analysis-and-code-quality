comment,sentiment
hi find solution problem get decrease loss open meta like unmasked loss much better,positive
problem new model text extended wondering new model input specific tried work previous model also even found another issue problem find,positive
ran problem ran last batch dev interestingly enough error choose skip batch solve problem,neutral
via issue need doc read contributor guideline make sure update write new necessary issue review anyone community free review discus high chance fun make sure fun owner private account side show individual ego,positive
issue version right python code version work fine,positive
hi thank pull request welcome community action order merge pull request code require sign contributor license agreement seem one file process order u review merge please sign behalf someone else employer individual may sufficient employer may need sign corporate tooling perform afterwards pull request tagged process may take hour please give time u received error please contact u thanks,positive
also experience running python attempt make local link spending day work end,neutral
suggest looking alongside voice used successfully gender regarding emotion bark promising tested yet,positive
upgrade probably fix error present version,neutral
thank contributor license agreement accept code meta open source project thanks,positive
hope resolve soon several use limited accent,negative
ever able find solution,positive
seeing performance main paper guess correct nevertheless warning correct model newly seen definitely used put newly,positive
yes important iso specification brazil category totally different come pronunciation issue urgent,positive
series able get infer could probably work also file missing error due thrown first suggest replace line following print enable see whats causing error also provide full model audio like python model audio code error message output python dev complete log,positive
thanks immediately clear whole thing via command pop full output getting added print command well python model audio tur manifest python tur dev loading model running inference recent call last file line module process file line process open file directory need said first comment output process error message file found actual never ran produced output hello output error message according comment printed following error python dev complete log,positive
thanks suggestion looking forward use use,positive
also faced problem pas fine use mono stereo,positive
error fixed hi find error already problem,positive
could address issue yet,neutral
hello error generating text summary resolve,neutral
issue trying install pip several ended failure finally found solution worked python install version either zip specific release directly file command prompt administrator extracted directory install method proved successful please note version python version ensure met prior installation hope anyone else facing challenge,positive
wondering code working thanks pointing,positive
removing argument audio pretraining solve issue,neutral
found error training model machine course pretty absurd plain another machine ironically enough convert model work fine paradoxically use trained model almost unbelievable,negative
pro solution worked hope,neutral
comment successfully trying import code module found,positive
also problem building model please help range got unexpected argument,positive
installation successful unable import import module,positive
hi thank available model list available please get information mean looking try different could find information,positive
excuse done still dealing making new module,positive
hi also working problem like one subclass use directly video use text,positive
hi higher version two,positive
hi problem following applied fix,neutral
check section input output entirely used,neutral
hey got news issue within auxiliary script model specifically forward function link similar issue raised git led problem related,neutral
mismatch size initialize model want initialize common,negative
hi code actively recipe new language implementation might relevant,positive
hi find code load one access even model already solution,neutral
machine translation first setup machine model default everything machine cache copied cache machine cache typically one need copy two hub machine cache instead path given path local machine cache import torch run got recent call last file line module file line load model model file line model entry file line file line data file line join object model path line model working import torch print welt matte loading read file world cat sitting mat blocking use every anyone solution,positive
still one getting used image command path model task translation train beam,neutral
consider base model architecture also problem wonder whether could please give advice sincerely appreciate,negative
issue need attention ca use python mutable default class field common use,negative
think problem text variable longer live run although hard say sure really familiar try de en indeed text variable longer available running command text value text worked fine also running code translation example,positive
share worked tried tutorial got error additionally certain necessary kernel time worked kernel worked,positive
hi able find data example data please help,positive
following worked mac install use environment variable pointing perhaps run python code export,neutral
better way resample audio wo make forward pas much le efficient use model,positive
long time faced issue found solution add love well,positive
definitely bug found problem,neutral
issue fixed latest main branch,positive
link used broken place find found way data,negative
link excuse link training new model still broken tell link thank much,negative
screwed added back worked fine,positive
try install caution always use python pip instead pip otherwise install globally instead inside environment create activate environment python version example create name activate caution always use python pip instead pip inside environment otherwise install globally instead inside environment install support python pip install torch version example version require based clone repository install git clone python pip install upgrade python pip install upgrade ignore running related show work fine install flashlight python python pip install,positive
many thanks code review ready merge side could please help merge,positive
hey think also looking script pretraining luck finding anything,neutral
already used successfully last year tried generate translation current version however get size mismatch size mismatch weight param shape shape current model older version thought could work got another error line epoch key could help met issue solve,positive
bash pip list print export,neutral
need specify launch command otherwise seem understand trying train conformer build regular instead wrong outdated like command use launch conformer training notice get error recognize certain passing also need add extra argument line,negative
since dealing exact problem,positive
alternately use fork python knowledge distillation interesting,positive
solution environment shell pip install shell pip environment local use shell pip install shell pip little tip best use,positive
yes used page meet trouble send ready script template,neutral
hello issue closed problem really,positive
also facing problem solution,neutral
hi sure relevant situation providing static providing path locally text,positive
question run command null resulting wer problem help thanks lot,positive
removing file worked something,neutral
like pretraining consult doc drop manually loading code model know would negative impact inference since new area import torch import fixed problem method thank,negative
check see version issue occur version training model different version translation,neutral
also contain name audio inside check audio format used manifest file well modify worked fine problem file audio name problem still,positive
looking code change task code task model task,neutral
hi wonder used training machine translation model trained model would like know use machine translation task thanks advance,positive
solve problem could please share,neutral
fixed issue could help,positive
target target provided always covered dictionary used train model model data make sure target properly used train model thanks much got stupid mistake point corrected found complex search found architecture may simple procedure difficult transfer suggestion must use found missing get file thanks looking forward reply,negative
please consider official based well see tutorial suspect quote unlikely see substantial thanks reference tried work error positional argument given sure whether file model distinguish original,positive
please consider official based well see tutorial suspect quote unlikely see substantial,negative
check link thanks much immediately reply whether latest fit latest replacement flashlight import name dont want use want use infer,positive
check link thanks much immediately reply whether latest fit latest replacement flashlight import name,positive
got link believe click link broken luckily script generate going try see work problem find code set validation set,negative
still little research direction,negative
found need indicate token segment,neutral
target target provided always covered dictionary used train model model data make sure target properly used train model,positive
facing issue sure setup file,positive
want use unseen language pair solve vocabulary problem,neutral
luck getting answer friend,neutral
error data suddenly model may speech module problem,neutral
figured implement detailed approach,positive
figured map token formula used following symbol returned field number loaded audio file corresponding transcript acoustic model inference zero length loaded audio file batch number emission matrix returned acoustic model inference audio file inference number audio file case loaded audio length audio file batch sample rate loaded audio usually,negative
figured get added following code usually understood model emission already method extended functionality function class also method python self list list frame corresponding every token list blank list emission matrix list frame corresponding every enumerate continue return self list list corresponding every token list list character corresponding every return slightly code decode method ensure character corresponding symbol list returned object new decode method python decode self none else range token corresponding token score frame letter transcript list return new decode method python decode self range token corresponding token score frame transcript list empty result local variable list return new decode method python decode self return else return result hypo token score hypo transcript list hypo hypo corresponding token hypo frame return hypo range result result return custom script get time hypothesis beam use following function process result decode python process object union list list list list audio file returned object number hypothesis return list best hypothesis list audio file best hypothesis emission matrix acoustic model trained list original audio batch measured number number best hypothesis return per audio file bool flag used specify whether calculate time alignment hypothesis union list list list list audio file list best hypothesis list audio file best hypothesis hypothesis following transcript hypothesis list list word one word transcript following word start time word corresponding audio file end time word corresponding audio range use maximum original audio length batch audio length else hyp hyp field empty lexicon transcript hyp else field convert instead hyp transcript transcript hyp hyp add hypothesis else append phrase list prediction first beam likely transcript field empty lexicon transcript else field convert instead transcript transcript add hypothesis return use following code process result decode python range use maximum original audio length batch audio length else append phrase list prediction first beam likely transcript transcript transcript add hypothesis return importantly calculate time python get word time information hypothesis transcript input converting length audio file number number acoustic model emission matrix sample rate loaded audio file list list corresponding returned list frame corresponding list float float list word list time corresponding audio file get corresponding token note algorithm work first last add case symbol index frame offset word start stop index get index range create word index start symbol end symbol tup first word start character word end character index loop index find index start end word try tup start index end index yet end index found tup word composed one character add index token end character index word else word composed one character add end character index word add complete word list word start end index tup tup reset continue onto next statement token may boundary two start character new word add start character index word except continue create start stop time word return utility function create time alignment information word python get word time information word hypothesis transcript list list transcript list float float list word transcript list list following word float start time word corresponding audio file float end time word corresponding audio word zip word return formula use calculate time corresponding audio symbol transcript following symbol returned field number loaded audio file corresponding transcript acoustic model inference zero length loaded audio file batch number emission matrix returned acoustic model inference audio file inference number audio file case loaded audio length audio file batch sample rate loaded audio usually,positive
simpler solution skip setting false generate look good,positive
sorry think optimal fix problem version like problem higher version torch solution problem,negative
question audio important role paper false default official code,negative
confused still fixed break backwards compatibility,negative
repository allow transformer compatibility feel free check,positive
also set false large,negative
like case commit model around time,neutral
hi could anyone please explain get ca find anywhere maybe need search elsewhere,neutral
problem also happen different different lead different model case,neutral
trying use got error would anyone give advice update someone else provided solution,neutral
trained translation model flores want generate translation per tutorial loading custom model ca find file pas argument fix problem,neutral
due version incompatibility fix pip pip install work,negative
model trained torch also situation torch version reduced model still need,neutral
thanks update actually look specific pretrain scratch initialize adapter pretraining setup way along id route specific adapter could actual script launch pretraining,positive
hi found pretraining code hope,neutral
painful process install none header file available every time run getting one error header file missing variable declared installation process going solid full independent installation process available,positive
change half becomes whole,positive
team lot effort write instruction working trivial useless job big corporation reputation issue,negative
error python switched python work,neutral
sweep package pip function biological module could find similar package function mistake something else,neutral
edit close issue store file supposed manually change current working directory python file,neutral
python main type help copyright license information import recent call last file line module file line module import file line module import file line module import file line module import file line module file line return wrap file line wrap return order file line name type file line raise default type field mutable default class field common use,negative
finished working since training long extending length position led index error however setting truncate able solve problem,positive
solve option default one get,neutral
minimal let compatible based provided option whole word strategy could help,positive
additionally like old model lid bin much better old model new model assuming language coming flores simplified traditional officially like serious bug model assume particular,positive
late anyone interested assuming model could use library python import array,negative
following create totally new environment however work put folder move folder another path training go think problem probably due path resolution,positive
checked fixed code issue command main branch find import metric le result code afraid reviewer hope,negative
pretraining script given author python data mask task arch dropout criterion seed rotate insert,neutral
try pip install upgrade,neutral
ran exact issue pip install upgrade issue exactly update new version,positive
sure related problem went away confirm working,positive
hello runt problem update guess fix add flag,neutral
label dictionary class added four detail refer,neutral
yet sorry late tu got problem inference solve reply directly view id,negative
sorry go lot pretty new error version compatible python fix change code like import parent optional none union try type raise input class structured forget decorate add missing type return else raise object unsupported type type like need improve compatibility first,negative
switching operator good idea general known first place anyways still issue get error running command common object recent call last file line module import file line module import file line module file line file line store node file line structured return parent file line create return file line file line ex cause file line raise set full trace file line raise object unsupported type,positive
fix dependency anyone use python install git clone pip install,neutral
hi location export hope tried still get error,neutral
python use string loaded model,neutral
able resolve also facing issue thanks,positive
official change python meaning higher wo work need get dependent exact python version,positive
similar issue code portable,neutral
also error linker error code fatal error resolved external development,neutral
problem higher torch version thank,positive
figured solve problem issue thank,neutral
sorry bother unable run transcribe python facing range found object attribute going landing except lot already tried solution lead error posted solution way many transcribe working posted one set installation actually work somewhere great error prefix infer user micro model audio manifest loading model running inference parameter please specify version level none assume version infer recent call last file line module file line file line file line file line raise ex file line return file line lambda lambda file line file line file line file line scheme file line object attribute,positive
stopping update could anyone please help,neutral
apparently support support either possible solution system anyone else solution share,positive
hey news new release currently unable use dependency fix alias taken care,negative
got problem inference solve,neutral
hello could kindly share directly way rebuild model comfortable way difficult want express gratitude,positive
issue still official release python error python,neutral
error install package conflicting,neutral
hi also audio getting correct audio truncated attached drive link original audio someone issue please help thanks link,positive
running building extension error visual greater get build install,positive
neither worked python least gave running building extension error visual greater get build,positive
hi able sort possibly similar memory issue trying use inference kernel unknown think ram consumption,positive
install problem resolved pip pip install thanks also work,positive
hi want replicate translation result transformer base model paper attention need following last data trained model python arch criterion last translation test python path model beam however got generate test got generate test far away result attention need think thanks lot hello also want reproduce result transformer paper could please tell employ generate thank,negative
issue still official release python,neutral
met problem function passing positional parameter therefore gave default value none change line layer flatten train model model got work well,neutral
simply downgrade version think issue came fixed,positive
pipeline still old language code import pipeline model pipeline print hello hello print hello,positive
directly support example usage given multilingual translation example particular script script encode data prior hi model want use import get know come difference object format found glad give advance fixing right script suggestion thank,positive
hi think bug come function file python self word word dictionary word overwrite word return else word word return condition word overwrite otherwise even overwrite indeed set true case dictionary duplicate special normally loading file dictionary start special pad order file file already special overwrite saved meant skip first overwrite pull request bug,positive
hi would rebuild machine support order thanks share guide rebuild,positive
hi would rebuild machine support order,neutral
add state model state task normalize false change line none none code run temporarily,negative
hello error model order support thanks,positive
issue helpful start tool either post something similar linked added file,neutral
issue still resolved documentation reproduce billion word paper,neutral
hi three later getting error manage work around think bug come function file python self word word dictionary word overwrite word return else word word return condition word overwrite otherwise even overwrite indeed set true case trained wrong dimension generally special dictionary loaded file try create pull request fix note solution fix duplicate problem order problem dictionary always pad order potentially special,positive
hi know something add link another please need help,neutral
last tell first number accuracy second accuracy single match target prediction question tho,positive
please update training functionality,neutral
nonmetal hi problem met problem,neutral
thanks fine tune already want fine tune guinea document python file help data thank help,positive
repurpose language within model select language example one least amount data initial training prepare new chosen language model inference simply use language token worked decently well quality translation best good starting point,positive
hello scope particular see moreover dictionary also language set fixed since language special included model dictionary lot library important thing along form model matrix soon add new library get model error inconsistency amount matrix shape main hypothesis impossible new language included model,positive
seven seen error may want check file attribute defined case set interesting seeing error inference training step also file problem file training give well training go well also compare file difference anyway thanks look forward new update,positive
seven seen error may want check file attribute defined case set interesting seeing error inference training step also file problem file training give well,positive
issue portion data causing model produce output thanks help,positive
please see model run error file image,neutral
please see model run,neutral
problem please let know already,neutral
like limit model share link soon exciting hear thanks lot convenient share example use model multiple loop loading model way instead one audio loading,positive
like limit model share link soon,neutral
ah like change local branch fixed,positive
odd share audio file check end mean time could use running inference,negative
install problem resolved pip pip install thank work,neutral
issue fixed ca see,positive
hi thanks reply portal python work fine bad transcript happen utility,negative
hi would recommend run language model get better accuracy thanks found mean need train,positive
fixed issue thanks sending,positive
could try running inference audio see still see output,neutral
hi would recommend run language model get better accuracy,positive
hi please double check everything make sure data preparation token dictionary training done correctly would expect work language without could possibly start making sure able run tutorial language modify data try run also training loss going also able see validation going well,positive
hi notebook could try see work,neutral
filtering reason filter specific based religious found noisy wo audio corresponding text match,neutral
exact post reference also tried,positive
hi able decode min audio memory decode longer audio would recommend splitting audio based decode audio,positive
hi please check tutorial,neutral
release setup git sync git update recursive pip install update also try release soon sorry bother ca even git clone one one please check version thank much,negative
simple fix install check,neutral
found solution memory consumption issue server server shut audio le minute idea solution greatly,positive
case reinstall driver problem,neutral
available last week chance get version source thanks,positive
sorry bumping question anything else need provide help,negative
problem torch corresponding platform tried came could get good bash pip install torch use export build could get python,positive
find different mean wanting understand thing thanks,negative
figured wrong directory reason,negative
hi could share issue able model,positive
sorry still issue training gan issue file line forward object attribute although issue closed due period inactivity still clear clue fix error find forward pas causing error still get resolution,negative
maybe found think problem already part might led job use launcher everything added work,neutral
mind could elaborate explanation issue clear exactly change argument prepare audio,positive
hello issue everything accordingly error first thing used pip install based comment getting recent call last file string line module file line module import file line module import file line module import file line module import file line module import missing module,positive
anyone know fix key still clue fix issue ask,neutral
try visual studio select first development option,positive
past issue also problem post code python model en de text text,negative
pip install instead pip install fixed issue found solution version work none nightly seem work either must error working sigh,positive
resolved version might say version ignore working fine related please feel free reopen issue,positive
hi problem know fix one please,neutral
still getting error even suggestion error get building extension fatal error file directory compilation error command exit status problem update bash apt install,positive
hey everyone sorry finally open early version along project also till today note documentation training yet gradually next check directory sonar get sense modeling work also pretty advanced based data pipeline already landed initial release documentation also follow pretty soon obviously feedback would greatly following day share repository please hesitate reach well specific,positive
hello check issue already thanks linked however find solution one solve problem,positive
case still use made short tutorial run directly,positive
update git model solve issue issue commit,neutral
following python code work import import import import audio import write import import display audio import torch task false model model generator model generator model text sample task text sample sample sample sample sample speaker sample speaker rate task model generator sample rate,negative
tried python issue recent call last file line file line file line file line file line file line file line raise ex cause file line raise ex set end full file line file line self file line file line self file line file line self file line key key file line file line file line ex cause file line raise ex set end full omega key,positive
hello check issue already,neutral
think wrong previous attempt previous attempt set correct setting still dealing key,negative
think set somehow able read correctly another error message recent call last file line module import file line module import file line module import file line module import module however tried python worked fine interpret error,positive
part issue think working,neutral
oh actually wrong original paper also removed silence,negative
install problem resolved pip pip install,neutral
official fix slow made fix version install following command simple test found pip install,negative
sorry still tried various number looking forward good outlook author reproduce result abstractive issue help follow step work well ca get result paper set hi issue solve strictly instruction train got original paper reply directly view comment id hi successfully training script training script got score last time forgot use multiple small python task translation source target arch criterion dropout,positive
sorry still tried various number looking forward good outlook author reproduce result abstractive issue help follow step work well ca get result paper set hi issue solve strictly instruction train got original paper reply directly view id,positive
hi got problem want know average length model,negative
issue python arch task criterion dropout seed simple pretrain please install pip install none none false none none none none none false true false false false false false false none false none false none none none false false false false none none none false none none none false false false false false false none false none none none none none none false false false false false false false false none false none none none false none false none none false false false none false false false false none none none true true true true false true false false false false false none false false none false false false false none false false false none none false none false false false false none none false none none false false none false false false false false none none none none false none false none dictionary dictionary linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear task model criterion model trained expert model trained loaded loaded valid parameter parameter training per device per device none load loaded epoch loading train data epoch loaded loaded train true true false new epoch begin validation valid subset true true false new epoch grouped begin training epoch start,negative
hi sorry late reply use import assert must different assert must smaller assert path exist command command command command copy copy panic status command status print status,negative
help follow step work well ca get result paper set hi issue solve strictly instruction train got original paper,positive
hello really interested paper plan release model code thank advance,positive
know relevant anyway think need set second iteration,positive
met problem stop symbol sentence,neutral
hello inference time around per core processor second per sentence translation easiest solution distill knowledge smaller faster architecture instance currently building mobile friendly version model knowledge distillation train smaller architecture transformer smaller layer width improve latency expense accuracy note tried received inadequate also exploring architecture natural language inference glue lower latency phone involved solution port model framework inference latency framework used many suspect model size might still need reduced though depending among hardware model second per sentence translation bad see post said surprisingly faster often time le second,positive
give sense slow inference keep mind translation via addition inference data noticeably left image time function call right image code running machine thought local would much faster could capture capture,positive
hello may know sample size training many train model getting good case afraid sample size may small running enough sample size training ran training thanks,positive
code level folder move code new folder,positive
agree broken multiple point,negative
thanks reply great point tutorial script work provided command actually problem simple model registry code went error error related example broken multiple good general documentation provide think man command even simple documentation help user modify default argument faulty baked example script,positive
error message script trying register model architecture name already model architecture name registered causing raised one possible solution issue check model architecture name already registered trying register conditional statement registration code architecture already registered skip registration step function used register new model architecture two argument name model argument name architecture go function first given already registered raised next function given already registered raised prevent duplicate registered pas architecture registered function also architecture configuration function dictionary implement solution modify function add conditional statement second check one duplicate example raise register model architecture unknown model type raise register duplicate model architecture return callable raise model architecture must callable return return,positive
please read error try module need install missing one need print error output install need specify directory setup run make root probably container change image error ran,negative
thanks reply according suggestion installation path running python task path subset criterion letter still error showing name defined checked code found line source found line import flashlight successfully date author subject module issue case could fix import error pip install python build develop echo export reply directly view id,positive
case could fix import error pip install python build develop echo export,neutral
memory training problem set overcome problem,neutral
thanks lot worked well,positive
pip install instead pip install fixed issue found solution,positive
facing issue found solution issue thanks,positive
hi solve problem occur issue rather tensor use number output different image,neutral
like added latest release would possible new release would like package officially version rather latest master would great thank,positive
used brute force method check training set zero far training sure method affect performance model hope explain negative approach might self model param none continue print nan print nan set grad zero return,positive
prepared create activate pip install,neutral
thank reply according suggestion installation path run python task path subset criterion letter decode model error name defined checked code found line source found line import flashlight successfully date author subject module issue flashlight installation install wrong way path case ca import want decode model greedy mode require installation flashlight reply directly view id,positive
nope longer involved either,neutral
simple use see scaling speech technology add attention adapter project perfect want know use voice translate,positive
get server export still receive import name fall back version,neutral
flashlight installation install wrong path case ca import want decode model greedy mode require installation flashlight,negative
could please confirm work,neutral
text neatly new would recommend library automatically perform sentence segmentation various without headache language identification,positive
people wonder code wrote found,neutral
able fix error case case sample matching exactly sample data split corrected sample file data training successfully,positive
got exact error way actively trying post able figure answer,positive
half successfully problem way start following mac o terminal command precision full special thank worked,positive
excuse added data training step get like id token token token token token token like token frequency token frequency token frequency got error recent call last file line module file line main file line main file line main file line file line file line return file line file line file line size else file line index dimension size anyone idea,positive
fix issue add open line,neutral
think overlap check variable code see number,neutral
hi need good luck,positive
hi chaos thank pull request welcome community action order merge pull request code require sign contributor license agreement seem one file process order u review merge please sign behalf someone else employer individual may sufficient employer may need sign corporate tooling perform afterwards pull request tagged process may take hour please give time u received error please contact u thanks,positive
well get working torch got unblocked thanks tip got work around pip install since found probably however rigorous test yet thank much tried suggestion worked,positive
may ask create dictionary,neutral
think another issue problem fully case add option still work order pip install,neutral
half successfully problem way start following mac o terminal command precision full special thank,positive
hi see vocabulary list mean also difference vocabulary thanks,negative
first library add training functionality second step ca wait,positive
first library add training functionality second step,positive
missing one need print error output yes right smaller model working,positive
error raised get source file object function instance module module hello could sure add path thanks,positive
utilize method divide text one sentence time python paragraph sentence output translator sentence output print print,neutral
hi also working problem far consistent finding get audio prediction without data still trying figure part,positive
discussion issue said override method,neutral
keep backwards yes buffer upon construction object need loaded matter whether,neutral
issue fixed exactly still get error,positive
evaluation stage use python script python task path test criterion getting error recent call last file line module file line main file line main file line super split file line none file line file line file line ex cause file line raise ex set end full file line return file line node file line key file line file line file line ex cause file line raise ex set end full key,positive
excuse long time could ask kind problem yet,positive
found given state could example try generate hello name hello name,neutral
hi anybody resolve issue also run speech normalizer,neutral
need data want load model similar question think least need file data folder,negative
idea open new issue maybe one help since used,positive
find default value see distributed training default value training distributed fashion thanks,positive
added new get sample please check,positive
issue pretraining script applied train set split train valid issue train model train validation set valid train completely different complete mismatch validation loss train validation compute train set use train validation training loss,positive
try pip install see work certified,neutral
still getting error even suggestion error get building extension fatal error file directory compilation error command exit status problem update,neutral
also found error another machine problem actually error file directory size may indicate binary incompatibility header got error gone output shown bottom,neutral
use case note large character vocabulary otherwise raw slightly better performance,positive
thanks reply find error wrapper full model yes tested yesterday audio pure noise however work model hint,positive
sure would work one example voice conversion,positive
controllable generation change gender emotion yet could consider model voice model achieve could please name one voice achieve find directly model bad,negative
controllable generation change gender emotion yet could consider model voice model achieve,neutral
full model generator discriminator kor format,positive
sampling rate thing tune little higher voice lower number give thinner voice faster,positive
find solution yet yes share,neutral
guide language thinking language id code remains unchanged need define vocabulary new language list used new language use model working random discriminator however met error kor model line state state find two ai behave way main difference perspective whether,negative
hi could please also discriminator also met error model random discriminator line state state,negative
execute following python type layer layer manifest get following error missing argument looking code error legit error acoustic recent call last file line module main logger file line main missing positional argument reason included running thanks,positive
thanks would appreciate someone team look,positive
got error model error come due apex version mismatch three work git clone apex pip install,negative
hello may share file public,neutral
dictionary please check work thank,neutral
thanks pointing criterion name mismatch criterion model,positive
dictionary please check work,neutral
guide language thinking language id code remains unchanged need define vocabulary new language list used new language use,positive
guide language thinking language id,neutral
issue running python resolve issue like module based please advise,neutral
turn dumb model sample rate run following command change sample rate process like audio audio audio audio array,negative
hi clone feel free use face want open pull request merge,positive
make progress excited see launch support fine tune model add support let know,positive
gender controllable user yet gender voice determined training speaker thus vary across plan make easily controllable next release,positive
still getting python pip void able run pip install yes also work python,positive
simple use see scaling speech technology add attention adapter following guide,neutral
le code snippet easily run give try good know even line supposed stuff ran ram audio file even long le long way yet try notebook trouble running,positive
le code snippet easily run give try,positive
hello question met two visual studio installer finally error install one throw new exception information user,positive
much really take run model anyways running system ram really second audio input,positive
working making easy check stay tuned make nice post soon,positive
working making easy check stay tuned,positive
working making easy check,positive
pull latest master branch change torch version got run successfully wrong model,neutral
pull latest master branch version,positive
anyone still file directory error want test inference really error inference folder need write file error line open write open see defined open method defined give python right write read file open see code process print manifest path open audio audio audio open audio open open dummy python dev print loading model running inference open hypo enumerate hypo hypo print hypo python already folder want check simply change path static folder instance user directory like path see file like line might fail writing inference log file like file directory problem write next file folder property run sweep user prefix write folder root level simply change folder folder user folder instance run sweep user prefix script access log folder result ran get output information ram basically throughout found error model probably big run free,positive
pull latest master branch,positive
like resolved close issue,neutral
probably due mismatch vocabulary original code vocabulary hard used get use different vocabulary per language use get text use instead,negative
moment plan release multilingual model,neutral
thanks looking yesterday issue fixed,positive
get result first comment comment make work explain please try entering directory use pip install,positive
related take look comment,neutral
get result first comment make work explain please,positive
working fine long time situation image,positive
model think wrong model one link right one yes right model could please submit issue project issue together,positive
model think wrong model one link right one,negative
model think wrong model,negative
hi someone still struggling run code tried create python package easily use project instead calling dealing hope useful get following error following recent call last file try import import module handling exception another exception recent call last file try import import module handling exception another exception recent call last cell line import file import import import import logger file import path import import import module project included yet version need install source shell pip pip install installation accordingly let know issue following error recent call last file line file line module file line transcribe file line return file line file line none file line main file line file line line file line optional override model file line file line return super strict file line raise loading error loading unexpected key handling exception another exception recent call last file line file line return file line return file line evalue file line record file line color file line return file line value file line file line value file line file line value file line return file line raise one value found one value found,positive
hi someone still struggling run code tried create python package easily use project instead calling dealing hope useful get following error following recent call last file try import import module handling exception another exception recent call last file try import import module handling exception another exception recent call last cell line import file import import import import logger file import path import import import module project included yet version need install source shell pip pip install installation accordingly let know issue,positive
hi someone still struggling run code tried create python package easily use project instead calling dealing hope useful get following error following recent call last file try import import module handling exception another exception recent call last file try import import module handling exception another exception recent call last cell line import file import import import import logger file import path import import import module,positive
hi someone still struggling run code tried create python package easily use project instead calling dealing hope useful,positive
hosting space would control,neutral
hi think share data understand ca provide data see issue providing code also wondering combine multiple pretraining thanks,positive
sure running ran error error maybe quick permission issue work docker regularly manifest loading model running inference recent call last file line self mode file directory handling exception another exception script working image tested note added also work run update install git curl run git clone pip install pip pip install pip install pip install torch pip install pip install pip install pip install pip install pip install python run echo root root echo echo run user python building shell docker build dev running shell docker run dev python model fra audio worked thanks proficient docker make sure create directory docker file directory place model audio directory line current directory present working directory volume inside container path,positive
hi would suggest use o ran similar error trying install library machine library trying install different though installation library lot smoother short video install doubt video helpful specific error please feel free check would like thanks,positive
try following instruction last line tried last line worked,neutral
sure running ran error error maybe quick permission issue work docker regularly manifest loading model running inference recent call last file line self mode file directory handling exception another exception script working image tested note added also work run update install git curl run git clone pip install pip pip install pip install pip install torch pip install pip install pip install pip install pip install pip install python run echo root root echo echo run user python building bash docker build dev running bash docker run dev python model fra audio,positive
problem model replacement model problem,neutral
root pip install root pip install root pip install root pip install,neutral
unfortunately fix problem case recent call last file line module import file line module import file line module file line return name level package level file line module import file line module import file line module unpack object problem exception note full exception trace shown execution file directory file line process open file line module file line code file line current frame return code none file directory trying run,negative
would say catch error rather error handling call done call run inference reason file thus open call fail throw error dig backwards command find got open sense rough contribute back yeah mean anything within reason going get error likely way issue many possible way fail trying extra verbose potentially help edit bad thought message printing command output running command error look like failing lack good news open source could change another character run run docker thanks lot eventually rewrite whole block like python import o prefix infer user micro python even command execute something fail outright pretty sure made still get unpack error change string copied entire string maybe missing something running scuffed,negative
model probabilistic model thus get different audio time run suppose random seed controllable generation generate utterance particular type emotion yet incorporate next release,negative
general installation basically need install find guide notebook,positive
hi transformer layer additional adapter module used original see would make appropriate conversion script,positive
anyone still file directory error want test inference really error inference folder need write file error line open write open see defined open method defined give python right write read file open see code process print manifest path open audio audio audio open audio open open dummy python dev print loading model running inference open hypo enumerate hypo hypo print hypo python already folder want check simply change path static folder instance user directory like path see file like line might fail writing inference log file like file directory problem write next file folder property run sweep user prefix write folder root level simply change folder folder user folder instance run sweep user prefix script access log folder result,positive
free user memory process use model instead,positive
error anyone problem unpack object shell python model audio manifest loading model running inference recent call last file line module import file line module import file line module file line return name level package level file line module import file line module import file line module unpack object recent call last file line module process file line process open file directory,neutral
try use short audio length see error still like saying couple tried file error still update fix,neutral
try use short audio length see error still like saying couple tried file error still,neutral
reach looking collaborate test mandarin audio data model may best model yes,positive
sure run pip install pip install also make sure audio sample appropriate sure run audio file try recreate working notebook step error might get hello thank response indeed executed code python pip install pip install original sample code provided correctly produce text content however mandarin file already format still error precautionary measure tried command convert file error still try use short audio length see error still like saying couple,positive
reach looking collaborate test mandarin audio data model may best model,positive
sure run pip install pip install also make sure audio sample appropriate sure run audio file try recreate working notebook step error might get hello thank response indeed executed code python pip install pip install original sample code provided correctly produce text content however mandarin file already format still error precautionary measure tried command convert file error still,positive
try different see work experimental process reach looking collaborate,positive
test mandarin audio data recognition result relatively poor know python model audio,negative
print system sample language mandarin code block python import o prefix infer user micro python model audio error message binary use available enable following rebuild appropriate compiler warning could find recent call last file line module file line file line file line file line raise ex file line return file line lambda lambda file line return file line sweep batch file line launch ret file line file line main file line main file line main processor file line assert adapter recent call last file line module process file line process file line run raise command python dev returned exit status sure run pip install pip install also make sure audio sample appropriate sure run audio file try recreate working notebook step error might get,positive
first error vague way source,negative
print system sample language mandarin code block python import o prefix infer user micro python model audio error message binary use available enable following rebuild appropriate compiler warning could find recent call last file line module file line file line file line file line raise ex file line return file line lambda lambda file line return file line sweep batch file line launch ret file line file line main file line main file line main processor file line assert adapter recent call last file line module process file line process file line run raise command python dev returned exit status,positive
get strange folder root directory mandarin user administrator mandarin create root directory recent call last file line self mode file directory handling exception another exception recent call last file line self mode file directory handling exception another exception recent call last file line self mode file directory handling exception another exception recent call last file line module file line file line file line file line raise ex file line return file line lambda lambda file line return file line sweep file line file line file line file line self mode permission recent call last file line module process file line process open file directory,negative
inference please try installation guide,neutral
working put notebook soon,neutral
got target code share code community looking implement coverage penalty similar al sure correct place extend already example similar penalty,positive
working right release soon,positive
hi bug pas multiple audio command,neutral
series able get infer could probably work also file missing error due thrown first suggest replace line following print enable see whats causing error also provide full model audio like python model audio,positive
able inference one audio time tried load audio tried job always got due manifest loading model running inference please install pip install locally dev main main loading adapter loaded true true true rebuilt epoch new epoch line python dev may task result limit may memory usage limit may usage limit may usage limit may memory cache swap may name may bash may python may sh may python may memory memory kill process python score sacrifice child may process python tried set help job around memory first usage suddenly limit best way infer many audio update one audio large min would also kill job inference support long audio large size try split audio possible avoid check comment,positive
sure related problem went away confirmed error resolved,positive
tried load last got error error unrecognized load continue pretraining,neutral
latest way run model tried docker solution notebook gave try problem,positive
added dictionary previous current model multiple please follow dictionary based want thanks kind reply wear cape,positive
able inference one audio time tried load audio tried job always got due manifest loading model running inference please install pip install locally dev loading adapter loaded true true true rebuilt epoch new epoch line python dev may task result limit may memory usage limit may usage limit may usage limit may memory cache swap may name may bash may python may sh may python may memory memory kill process python score sacrifice child may process python tried set help job around memory first usage suddenly limit best way infer many audio update one audio large min would also kill job inference support long audio,positive
like middle dot included punctuation indeed try fix next release,neutral
pinto thank comment worked without however sampling rate must docker build dev run docker run dev python model audio input output got insurance company yesterday markdown command ran docker run dev python model audio sure running ran error error maybe quick permission issue work docker regularly markdown version warning driver functionality available use container start container support see manifest loading model running inference recent call last file line self mode file directory handling exception another exception recent call last file line self mode file directory handling exception another exception recent call last file line self mode file directory handling exception another exception recent call last file line module file line file line file line file line raise ex file line return file line lambda lambda file line return file line sweep file line file line file line file line self mode permission recent call last file line module process file line process open file directory hopefully spot something thank advance,positive
lid language identification given speech input lid predict language check section run lid lid,neutral
inference added see chip inference added,neutral
possibly problem input text tried sentence working fine raw command python problem bit saw reading file also sent problem solution pull request image,positive
latest way run model tried docker solution notebook gave check,positive
latest way run model tried docker solution notebook gave,positive
small audio test try bigger one would definition long work min would good enough hour would even better accommodate longer sentence change calculation sample per per size however would recommend split long audio shorter audio large cause run much,positive
run code based docker manifest loading model running inference recent call last file line module file line file line file line file line raise ex file line return file line lambda lambda file line return file line sweep batch file line launch ret file line file line main file line main file line main processor file line file line super split file line none file line file line file line ex cause file line raise ex set end full file line return file line node file line key file line file line file line ex cause file line raise ex set end full key recent call last file line module process file line process open file directory issue key edit file something found problem need use model part,positive
currently support automatic language detection given speech could use lid detect language put language code inference script check support table thanks comment could elaborate use lid,positive
currently support automatic language detection given speech could use lid detect language put language code inference script check support table,neutral
small audio test try bigger one would definition long work min would good enough hour would even better,positive
small audio test try bigger one would definition long work,negative
manage run long audio,negative
run machine thanks useful check environment default use full make sure correctly namely path need update well might missing pip install check audio format since resample find python script used run hope,positive
want support plan due technical could train model code public speech,negative
mandarin support check table,neutral
model supporting check list filtering letter like image see thread,positive
possibly problem input text tried sentence working fine raw command python,positive
added dictionary previous current model multiple please follow dictionary based want,negative
issue fixed please try training use original code filtering language letter like image image,positive
model supporting check list filtering letter like image,positive
run code based docker manifest loading model running inference recent call last file line module file line file line file line file line raise ex file line return file line lambda lambda file line return file line sweep batch file line launch ret file line file line main file line main file line main processor file line file line super split file line none file line file line file line ex cause file line raise ex set end full file line return file line node file line key file line file line file line ex cause file line raise ex set end full key recent call last file line module process file line process open file directory issue key edit file something,positive
model supporting check list,positive
working iso text file image iso code image,neutral
sorry want try one use,negative
issue fixed please try training use original code,positive
dictionary model used without explicitly get error message thanks answer want convert model use looking dictionary run directly great work,positive
please make sure python,positive
thank much version torch nightly version everything work fine thanks help,positive
see thanks function nightly version far try stable version install nightly pip install torch,positive
output connected request sent response length saving saved environment information version build false used build used build o version clang version version version version python version main python platform available true version set lazy configuration driver version version probably one following hip version version available true architecture order little address size physical virtual list thread per core core per socket socket node vendor id family model model name stepping vendor type full cache li cache cache mib cache mib node vulnerability affected vulnerability affected vulnerability vulnerable host state unknown vulnerability affected vulnerability stale data vulnerable vulnerability vulnerable vulnerability spec store bypass vulnerable vulnerability vulnerable pointer vulnerability vulnerable disabled disabled vulnerable vulnerability affected vulnerability abort vulnerable de pat aes relevant pip pip pip pip pip pip pip pip could collect,negative
billion company file simply unacceptable install use speech text audio best export transcription subtile improve transcription quality install use text speech model best train voice none file transcribe audio text version step clone git import o git clone get current working directory create directory create exist change current working directory step install build patient pip install step install tensor board pip install step preferred model pro use smaller model avoid memory outrage model step audio create folder path audio need transcribe note need make sure audio data sample rate easily like example file fixing audio sample rate step run inference transcribe audio time long import o prefix infer user micro python model audio get transcription example thanks lot great tutorial discovered bad pas wonder text speech,positive
hi share environment use running alignment script get via command bash security please check content running python,neutral
dictionary model used without explicitly get error message,neutral
could try install python solve issue,neutral
thanks notebook everything audio error exceed support long audio audio full error manifest loading model running inference binary use available enable following rebuild appropriate compiler warning could find recent call last file line module file line file line file line file line raise ex file line return file line lambda lambda file line return file line sweep batch file line launch ret file line file line main file line main file line main processor file line file line file line return file line file line file line epoch file line file line file line file line file line return file line return file line file line list file line return index file line assert exceed recent call last file line module process file line process open file directory,positive
yes error message step list show torch,neutral
please install nightly build see step,neutral
fixed dimension issue issue file line path module attribute,positive
worked without however sampling rate must run update install git curl git clone git pip install pip pip install pip install pip install torch pip install pip install pip install pip install pip install pip install python apt update apt install true run echo root root echo echo user python build docker build dev run docker run dev python model audio input output got insurance company yesterday used read audio error error opening system error,positive
billion company file simply unacceptable install use speech text audio best export transcription subtile improve transcription quality install use text speech model best train voice none file transcribe audio text version step clone git import o git clone get current working directory create directory create exist change current working directory step install build patient pip install step install tensor board pip install step preferred model pro use smaller model avoid memory outrage model step audio create folder path audio need transcribe note need make sure audio data sample rate easily like example file fixing audio sample rate step run inference transcribe audio time long import o prefix infer user micro python model audio get transcription example,positive
transcribe audio text version step clone git import o git clone get current working directory create directory create exist change current working directory step install build patient pip install step install tensor board pip install step preferred model pro use smaller model avoid memory outrage model step audio create folder path audio need transcribe note need make sure audio data sample rate easily like example file fixing audio sample rate step run inference transcribe audio time long import o prefix infer user micro python model audio get transcription example,positive
hi landed fix please use code,neutral
issue change fix issue,neutral
hi also release language identification translation language support translation moment,neutral
hi please use language code,neutral
someone share working notebook think might help facing,neutral
error may related python switching back python may resolve problem run inference fixing path also find model specify absolute path model file relative path like may cause extra error,positive
issue automatic least way give multiple language hin,negative
worked without however sampling rate must run update install git curl git clone git pip install pip pip install pip install pip install torch pip install pip install pip install pip install pip install pip install python apt update apt install true run echo root root echo echo user python build docker build dev run docker run dev python model audio input output got insurance company yesterday,positive
hi thanks discussion learned lot trying make work python copy run pip install pip install pip install torch pip install pip install pip install pip install pip install pip install python apt update apt install true python built image docker build dev run docker run dev python model audio could please run code starting git clone many thanks git clone model docker build dev docker run dev python model audio,positive
hello everyone done done printing output error unpack object full log manifest loading model running inference recent call last file line module import file line module import file line module file line return name level package level file line module import file line module import file line module unpack object python hin dev recent call last file line module process file line process open hypo word running,positive
issue python model audio manifest loading model running inference recent call last file line module import file line module import file line module import file line module import file line module import file line module import file line module file location line return wrap file location line wrap return order file location line name type file location line raise default type field mutable default class field common use recent call last file line module process file line process open file directory,negative
error bash python model audio manifest loading model running inference recent call last file line module import file line module import file line module file line return name level package level file line module import file line module import file line module unpack object recent call last file line module process file line process open file directory,neutral
hi thanks discussion learned lot trying make work python copy run pip install pip install pip install torch pip install pip install pip install pip install pip install pip install python apt update apt install true python built image docker build dev run docker run dev python model audio run code based docker manifest loading model running inference recent call last file line module file line file line file line file line raise ex file line return file line lambda lambda file line return file line sweep batch file line launch ret file line file line main file line main file line main processor file line file line super split file line none file line file line file line ex cause file line raise ex set end full file line return file line node file line key file line file line file line ex cause file line raise ex set end full key recent call last file line module process file line process open file directory,positive
hi output error visual greater get build please also indicate tried know suggest suggest depending tried thank,positive
kept tracing error met error file line return name level package level file frozen line file frozen line file frozen line file frozen line file frozen line file frozen line file frozen line undefined symbol recent call last anyone know solution,neutral
error unrecognized tried continue pretraining,neutral
hi thanks discussion learned lot trying make work python copy run pip install pip install pip install torch pip install pip install pip install pip install pip install pip install python apt update apt install true python built image docker build dev run docker run dev python model audio,positive
use thus raw raise push fix conversion soon,negative
hi change file send fix code soon,neutral
open source mean provide support simply source code open anyone read sure would like make usable get rid attitude decent person,positive
made open source could done obligation standard better id take away hostile language ask nicely people faceless corporation choosing open source provide documentation purpose making open source people compare simpler use whisper,positive
would say catch error rather error handling call done call run inference reason file thus open call fail throw error dig backwards command find got open sense rough contribute back yeah mean anything within reason going get error likely way issue many possible way fail trying extra verbose potentially help edit bad thought message printing command output running command error look like failing lack good news open source could change another character run run docker thanks lot eventually rewrite whole block like import o prefix infer user micro python even command execute something fail outright,negative
run pip install worked chip,neutral
made open source could done obligation standard better id take away hostile language ask nicely people faceless corporation choosing open source provide documentation,positive
would say catch error rather error handling call done call run inference reason file thus open call fail throw error dig backwards command find got open sense rough contribute back edit bad thought message printing command output running command error look like failing lack good news open source could change another character run run docker,negative
getting error also documentation run sample horrible,negative
error error manifest python dev loading model running inference warning could find locally dev recent call last file line module process file line process open file directory turn following location looking ram status believe crash lack memory image feel perhaps increasing memory solve problem hope investigation,neutral
got model finally load run apparently allow directory code dev directory name pas tur like try create directory dev inside per also change seem anything think full inference ran process got stuck went impressive error catch error many could go wrong hopefully clean currently staring error pretty sure due removing name file line main processor file line file line super split file line key enough unpack got,positive
sigh command loading model running inference python tur dev recent call last file line module process file line process open file directory however go back recreate temp run command manually seem get reason via way install many way partial list case anyone pip install pip install pip install pip install pip install pip install pip install pip install pip install still getting nowhere running command even printing output status code,positive
thanks could also add extra support like following else,positive
thanks immediately clear whole thing via command pop full output getting added print command well python model audio tur manifest python tur dev loading model running inference recent call last file line module process file line process open file directory need said first comment output process error message file found actual never ran produced output,positive
hi new error manifest loading model running inference binary use available enable following rebuild appropriate compiler warning could find recent call last file line module import file line module import file line module file line return name level package level file line module import file line module import file line module unpack object python dev recent call last file line module process file line process open file directory,positive
thanks immediately clear whole thing via command pop full output getting added print command well python model audio tur manifest python tur dev loading model running inference recent call last file line module process file line process open file directory,positive
please read error try module need install missing one need print error output install need specify directory setup run make root probably container change image,negative
got error want try manifest loading model running inference recent call last file line module import file line module import file line module file line return name level package level file line module import file line module import file line module import file line module import file line module import file line module import missing module python dev recent call last file line module process file line process open file directory,negative
getting pretty much used right letter language code waiting seem effect error showing,positive
got time manifest loading model running inference error incompatible version buggy upgrade import name recent call last file line self mode file directory handling exception another exception recent call last file line self mode file directory handling exception another exception recent call last file line self mode file directory handling exception another exception recent call last file line module file line file line file line file line raise ex file line return file line lambda lambda file line return file line sweep file line file line file line file line self mode permission recent call last file line module process file line process open file directory,neutral
module need install used,neutral
module install missing module,negative
expect language code see section file model example use,neutral
sure full log mine base python model hin audio manifest loading model running inference recent call last file line module import module recent call last file line module process file line process open file directory,positive
though sure wrong sure right say standard tried en far image,positive
need check error change print see error pas file new top level key common true common true,positive
hi share entire log tested code work fine end,positive
hi way coin action segmentation task think method video true may bit inflated coin file structure video region interest understanding used code data neither feature extraction method issue official script coin also cut consider region interest example first video testing subset coin region interest go second second actually around considering video class considered thus correctly metric since predict belonging class maybe missing something,positive
raw via official script official official script strongly recommend use since slow hi thank guidance may ask know split video several clip found long video short clip clip caption,negative
hi thank help want reproduce paper think need video could find official link know find hi finished facing problem may ask know split video several clip found long video short clip clip caption,negative
replace generator model generator model,neutral
even though aware still feel comfortable obviously intention meta developer hinder people commercial thus would like follow use commercial lot people would great apache,positive
looking forward saw licensed look see general legally impossible copyright law give say use output people make data program user program enter convert data copyright output generally program input form copyright status output input still would appreciate developer meta would allow u use model pursue idea answer question would nice thank,positive
update able resolve problem also issue,positive
massively helpful routinely source output messy easy accept,positive
unfortunately becomes incompatible know fix problem also python image exception file image,negative
added missing field file python import torch model model false sure whether false true would happy someone could give feedback concerning,positive
leave logging like able suppress,positive
able resolve first issue error training model saved key name uncompiled one model key name uncompiled one first removed model key name second made code file function line able execute training last someone resolve second one kindly help,positive
yes lot warning triton random expect difference eager whenever graph break one step done tracing graph break,negative
hi use get bunch logging tried way terminal flooded,neutral
install torch python precision full use run use solution work thank much,positive
current path may contain file remove rename,neutral
solution downgrade package float throughout,neutral
hi problem could know fix one please,neutral
also facing issue way resolve,neutral
progress initial thought pas appropriate data type call file image sure would anywhere else presume underlying handle rest,positive
dumb question training transformer model want use enough install library environment start training need pas additional,negative
someone else get working issue error running following added git pull git clone git pull pip install pip install import torch list available load ensemble running python anyone still running issue desperately trying solve issue would fix python,negative
solve issue loading normalizer model function state model path model without head state task normalize false note model without layer class line model repeated multiple time code,negative
also looking notebook since installation clear help would,positive
hi possible missing file thanks advance,neutral
said please try python kernel see different output,neutral
hi see error making change class none none none error configuration best barry,positive
try pip install see work worked like charm,neutral
hi final loss value data looking forward reply thank,neutral
share worked tried tutorial got error additionally certain necessary kernel time worked,positive
saw let get model think right way use without main code seen code bit older latest may may let support feature may need update thanks finally think got right direction use implementation currently time tense hope future support properly find used unify learning param default value problem,positive
struggling problem solution use composite used unsupervised composite generator null false fixed discriminator null false fixed create generator discriminator best know use composite command line question problem,positive
thanks method bit tricky know affect let say model want let part get let share following given method view could make python forward self let say part part time part scale based part scale based set global part understanding right trying modify let support need test whether looking forward official think crucial network module hi want know get output add output want increase learning rate use thanks forward self else return,positive
accuracy pretraining performance downstream task necessarily correlated especially across different model could example change mask length get close accuracy downstream task performance bad remember correctly base model around large model around accuracy base model paper following training accuracy correct latent audio representation switching continuous like line paper pretraining accuracy also validation set training set,negative
kind late interested well would possible obtain pseudo used train iteration,positive
hello working low resource language translation anyone please provide would much helpful get code,positive
hi would appreciate get code model,neutral
image task false model generator model text sample task text rate task generator sample,negative
spent several day found modal could generate multiple made upset state clearly documentation file think general considering,positive
getting error running following code trying convert align model please tell went wrong create instance desired create instance model load saved load state model set model evaluation mode convert model format print example print model result input file line forward object attribute,negative
real nice advance bug,positive
hi met error solve problem,neutral
problem already still trying test older version run please let know problem,positive
raw via official script official official script strongly recommend use since slow,negative
hi thank help want reproduce paper think need video could find official link know find,neutral
extract python python also written far remember validation training took le think combine python,positive
hi found enter python evaluation still missing know find,negative
problem used model test data result also would like ask transfer hugging face model model many thanks,positive
facing issue case maybe issue resolved setting task translation task translation maybe could work case task task,neutral
risk sounding bit pointed reason development happening like project instead one many u would love help make better get quarterly internal development hard believe anything going change regarding governance,positive
hey thanks lot interest still actively working next version based internal beta release summer likely sometime end june beginning august keep posted finalize,positive
interesting problem like formulation would appropriate wonder possible account cost padding example quadratic complexity might cause padding long sequence result additional computation amount padding applied short sequence,positive
assume something like class common common field,negative
really looking forward new framework user,positive
hi thank pull request require sign contributor license agreement need attention currently record system longer valid need process order u review merge please sign behalf someone else employer individual may sufficient employer may need sign corporate tooling perform afterwards pull request tagged process may take hour please give time u received error please contact u thanks,positive
issue mode branch notebook rune following installation installation guide git clone pip install git pip install python git clone git pip install apply fix path import o try import get error recent call last cell line import module import import import import name unknown location note import failing due missing package manually install either pip apt view common click open button,negative
would found otherwise thank,neutral
hi might want check stoa,neutral
hello still looking code update even older version would great,positive
could code file import path import root path en task task root task,neutral
got error python kernel revealed missing well new pip package got unpack object restart kernel missing dependency kernel problem resolved,negative
need upgrade version pip package pip install upgrade pip work,neutral
thank used model focus model far know model,positive
command python split rank replace directory input split name split train dev test path saved file model number typically number used rank rank current process directory want save extracted get error trying,negative
maybe somehow related way,neutral
ever solve issue facing similar issue validation training model,neutral
ever find solution tried following exact setup getting error match assuming need extra code like sure already working implementation somewhere,positive
working version include sure missing,positive
self criterion super criterion,positive
another environment python face error,neutral
nonmetal hello problem model trained working either data basically related default value training addition following image,neutral
second error problem apex saying one empty go line add print print terminal throwing error solve problem accordingly problem one data missing file one folder,negative
please tell resolve issue,neutral
tried use script find worked,neutral
still wondering extract model check script,neutral
train get verbose like following tackling step done forward graph step done compiler function step start tracing forward step done tracing forward step calling compiler function step forward graph triton random expect difference eager step done forward graph step done compiler function step start tracing graph break forward step start tracing forward step start tracing step start tracing step calling compiler function step forward graph triton random expect difference eager step done forward graph step done compiler function step start tracing graph break step done tracing graph break step calling compiler function step forward graph triton random expect difference eager step done forward graph step done compiler function step start tracing graph break forward step done tracing graph break forward step calling compiler function step forward graph step done forward graph step done compiler function step backwards graph step done backwards graph step backwards graph step done backwards graph step backwards graph step done backwards graph step backwards graph step done backwards graph step backwards graph step done backwards graph,negative
similar flax take look welcome,positive
hi thanks great script made however script working fine model given trying use model throwing error code ran python error getting recent call last file line main file line main model file line model file line file line false object attribute please look possible mistake side running issue trying run inference model trained hi thanks great script made however script working fine model given trying use model throwing error code ran python error getting recent call last file line main file line main model file line model file line file line false object attribute please look possible mistake side running issue trying run inference model trained able solve issue help running issue,positive
loading register model false false false true false false true none false,negative
hello situation solve problem,neutral
ah sure thanks get following error dummy file line state guess still saved key also find way,positive
use may help also could answer training precision memory time another,neutral
default type optional file may solve issue fix similar removing wrapper well,neutral
support yes specifically support,neutral
need upgrade version pip package pip install upgrade pip,neutral
hi problem know modify please tell thank much,positive
normal mode work pip install resolve,positive
hi thank providing code looking right script reproduce result paper run code encounter many fix found format abnormal strange blank head large margin sentence example line image forgot reproduction result reply trying thank help lot forgot reproduction experience,positive
anyone still evaluate might want check reproduction repository,neutral
also getting issue python,neutral
reference hi code function add state according error maybe remove call function file also work state helper old model state state state state epoch add state state state reduce history memory usage keep last state state state state state record class name state state move state state best state state keep track number state state use stateful training data state state epoch state epoch,positive
represent dictionary source language text represent target language text token frequency token frequency token frequency,neutral
doc said transformer data transformer data data,neutral
ah could still fix kind stuff,positive
added data training step use trained model inference step got different still exactly audio hope help,positive
thank much inference tried train translation almost even long silent sound end,positive
solve issue yet also facing issue,neutral
avoid bug mode resolve issue,neutral
hope help way may inference step,neutral
hey anyone loading struggling deal please help tried useless load base task normalize false task false load normalizer model model model none model model run following command python unit got message maybe error file line ensemble file line model file line model self file line file line non optional field assigned none,negative
fixed one successfully actually idea issue hope anyone explain ah actually could file,positive
fixed one successfully actually idea issue,positive
drop beginning command try launch execute rest example get following output error append unbuffered python launch following run without python notice drop beginning python also drop,neutral
hi de de sure work loading due vocabulary mismatch last,positive
find git repository unfortunately data command python task try command python task arch getting error exception load model please ensure match getting error data instead trained model model different number,negative
hello abstract method pretty simple de de worked however try load model get also trying fine tune trying model vocabulary instead vocabulary trained anyone solution problem,positive
implement code novice many understand,positive
problem think problem found almost little impact model transfer,negative
able install mac hint basically building source clone git clone folder build source pip install,positive
hello problem found problem might like error report abstract method perhaps correspond may previous method program run normally hope help,negative
could let know fixed error successfully still fix,positive
hi fine tune model use command python configuration image image meant,positive
still case support inference,neutral
pro vim export interrogate precision full,positive
copy file folder example work win wow,positive
hi model model also error message trying save model best validation result model also tried solution avail instead saving entire model save load model work model model reference hope might helpful trying save model similar motivation training single,positive
tell system configuration number memory system memory ram mem would please provide running thanks,positive
hello anyone please share possible,neutral
file add code directly change source code novice want ask advice,positive
code loading model work,neutral
thanks look resolved good go,positive
checked pending good two minor merge resolved happy merge right away,positive
issue still fixed curious thanks,positive
number number matter mode image,neutral
tell system configuration number memory system memory ram,neutral
hey got error new version think compatible new version problem old version new error old version right install new version solve error confused end end solution best,positive
hey got error new version think compatible new version problem old version,positive
training code add change change,neutral
request share reading material preferred furthermore take mean loss heavily first iteration,negative
sum divide instead dividing first second,positive
good idea say training take mean pas instead passing loss sum,positive
think good idea later among avoid,positive
find git repository unfortunately data command python task try command python task arch getting error exception load model please ensure match would please share whole thanks,negative
yes hard label distillation,negative
similar issue running python got name defined unwrapped file try except close worked naming use rather manually change,neutral
sorry since good understanding criterion return loss return divide loss pas place,positive
directly related question possible use technique model correct way,neutral
problem apex install another therefore solution create different,neutral
need change line score,neutral
sorry slow reply actually first time someone pointed issue command set original training run though tested recent may need fiddle bit python data mask task arch dropout criterion seed rotate insert hope command many may suspected arch exist might good alternative apparently ca invalid value instead unrecognized final command shell python data mask task arch dropout criterion seed rotate insert thank also run successfully like know pretrain pretrain training,positive
hello anyone able find solution facing issue recent call last module module unpack object,positive
actually even remember faced problem thank answer hope help people,neutral
model used decode step come step model use model decode step successfully,positive
ended writing solution script model well piece model new average although would easy enough change work model sure work anything else difficult change people working problem place start want thing,positive
hi think got solution problem missing first token inference output set tell model take first output token,positive
way run python try run command pip install python get error error pip dependency resolver currently take account behaviour source following dependency pillow decorator torch incompatible torch torch incompatible,neutral
expand data problem think might similar issue,neutral
currently running issue anyone found resolution,neutral
hi everyone final year student trying run train model scratch getting error someone please tell order train model scratch follow would really help,positive
hi task kind classification preliminary train model produce text source two simplicity first second token typically calculated target typically like run training exactly like difference model size following change note training scratch tried went back task problem inference output one token instead two task token prediction trivial however much variance target always first token always second token always running inference beam model token one understand manually like tensor make sense even checked token correct still even multiple token force token model repeat token generate one missing something guess hi encounter problem output also ignore first token solve problem thank,positive
anyone know terminal command used kill running distributed running python image top list running image kill via kill,positive
since found answer import model,neutral
hello save problem environment torch python install pip pip install base root git branch arch dropout criterion beam scoring evaluate path beam use obtain however load problem error error loading unexpected key since use tensor trained param weird want help like become like trained,negative
found fix following removed anomaly detection set false found better handling loss scale quite bit issue,positive
pip error following self parser sure basic command interface command raise command class must subclass command command class class must subclass command,positive
problem still happening happening loading model also import torch error message module unpack object,neutral
yet man sorry facing problem figured solution reply directly view id best,positive
facing problem figured solution,neutral
problem code shown following picture use freeze parameter version use,neutral
failure reliably failing commit reliably passing commit behind idea loading crash task definition since sure would break test also add variation task without,negative
find git repository unfortunately data command python task try command python task arch getting error exception load model please ensure match,negative
file tar file extract create folder lot inside think one expert file rest,neutral
break test main passing idea,positive
pip install attempt connect resolve maybe slow connection try add flag specify specific pip channel pip install alternatively sure well try use python develop install install automatically thanks solve use python develop,positive
thanks solve use python develop,positive
looking additional related translation project might need citation forming consistency rest public site,neutral
hi model explicit trivial way reducing want smaller model use german train smaller translation model training data combination well find,neutral
sure related problem went away,positive
use reference nice wrapper think lack data preparation,positive
use shelf model easier downstream task want fine tune task without classification head another want fine tune base model showing train base model configuration used base model trained paper train scratch find proceed would,negative
problem got problem training loss fixed saved also invalid result zero downstream inference,positive
high school student speech recognition possible fine tune fine tuned model please tell,positive
getting error training data learning rate default error,neutral
pip install attempt connect resolve maybe slow connection try add flag specify specific pip channel pip install alternatively sure well try use python develop install install automatically,positive
meet problem ca find useful information,positive
convert use image work model saved still want get model need save,neutral
want run set default floating point float code running stable diffusion model facing error issue fixed set floating point float,positive
task arch complete dropout simple training model getting following note gradient overflow gradient setting loss scale note gradient overflow gradient setting loss scale note gradient overflow gradient setting loss scale note gradient overflow gradient setting loss scale get solution instance o,positive
hi bug little ago well fixed significant accuracy fixed submit fix,positive
know could possible update continue training might fixed,positive
meet problem waiting solution,neutral
hi also met problem could please tell specific operation thanks,positive
model reproduce found label mean predict nothing,negative
hello met problem want solve problem option get good result thank much,positive
also contain name audio inside check audio format used manifest file well modify worked fine,positive
hey sorry late reply making good progress internally well initial going release beta version first half year exact timing set yet post thread soon date,positive
find solution little bit odd issue via strange path try use directory inference training directory wrapping model running python interpreter instead never seen bug know reason maybe someone help accurate cause,negative
hi maybe step step tutorial data model really helpful could share project via git repository,positive
able get error since translation default translation task two dictionary language pair hence error task single file error,positive
want set argument filter invalid maybe modify line line hope help,neutral
perform forced following script python python import torch import import hello world welt model scorer ensure match reference target score print prob print score score,negative
also facing issue please help create,neutral
reference tried setup told least memory per parameter model could successfully fine tune parameter model like param model one may enough memory fine tune model know sure someone confirm memory would great actually,positive
try command use notebook python pip install torch python precision full,positive
none none false none none false false false false false true true false none false none false none none none false false false false false false none none none false none false false none none false false false false false false none false none none none none none none true true false false false false false false none none true none none none false none false none none false false false none false false false none none false false false false false false false false false false false false false false false false none none false false none false false false false none false false false none none false none false false false false none none false none false false none none none false false false true false false none none none false none false,negative
used default path also tried smaller number fix error,neutral
thanks lot ran following based feedback resolve error let know anything otherwise close issue fine tuning task arch,positive
task need monolingual corpus training want use task add remove example bash additionally also change make run well please make sure file path valid,positive
hello wonder progress really expect hear news,positive
thanks source code tip explanation sense run script prompt completion get two shown previous image sense run training script arch task get error saying file directory hence thought need use order create single file sorry long amble ultimately brought,negative
translation task file source dictionary target dictionary respectively please refer source code remove rename dictionary like need modify source code make code run well,neutral
oh yeah identical could remove duplicate rename,neutral
although two identical joint dictionary use command check example bash,neutral
thanks quick response without return dictionary screen shot may missing something since getting similar unrecognized problem issue,positive
please try remove true true example bash prompt completion,positive
could make sure passing flag inference time error unrecognized option available branch thus need branch run inference,positive
struggling problem solution use composite used unsupervised composite generator null false fixed discriminator null false fixed create generator discriminator best know use composite command line,positive
anyone problem composite parameter command line,neutral
increase instead usage image,neutral
functionality available trying model getting error following task ar ast ba ca da de el en e fa fi ga ha hi id ka ko lo ne pa si ta th ur wo yo temperature criterion dropout seed simple patience arch getting following error error unrecognized mine system information version torch goal use early stopping metric unable please guide thanks,positive
getting error unrecognized anyone suggest solve,neutral
error gave shock piece code touched since,neutral
hi single pair provided command python drop want multiple language time list point command list data want skip line together,negative
update tried loading model buffer error instead import io import torch open buffer buffer recent call last file line module file line load return file line invalid load key working ram machine case,neutral
second way modify code reorder according beam index current code try mask old beam beam order however bug rarely effect test set false hard trigger play role beam search require beam size appear top beam size one step agree bug rarely effect always full false bug,positive
oh see latest issue trying another train know value another great try train thank lot good day,positive
think bug fixed latest version see line originally data loader output list tensor like convert list tensor tensor simply code also implement code python type list enumerate,positive
really possible tell model sufficiently trained without downstream task could implement periodic evaluation instance however still great tend use learning rate improve significantly exposed lower learning best advice train various see improving good starting set example,positive
load wrong task probably split remedy update task pointed try update point future,negative
available pretraining task override task like task,positive
try following pip install pip install issue problem new version torch previous version torch issue,negative
try grade previous version,negative
apparently need use latest version module need latest compatible dictionary version,positive
test seem unrelated could connect socket,neutral
trying install also getting linker error unresolved external symbol internal error unresolved external symbol internal possibly related,neutral
hi would mind share trained direction thanks much,positive
problem know arch task use closer seem get trying different arch transformer task arch task cat temperature still get missing key unexpected key load model please ensure match met error kindly tell solve error,positive
hi use end persisting wrote pipeline scratch suggest try,neutral
hi found wrong think document param per batch suppose batch size average per sample set however mean part abandoned another word incomplete batch leading worse,negative
thank response turned missing one cause error fine man think data check step whether time also tracing change sample object code model sample key none first may data reply directly view id,positive
think data check step whether time also tracing change sample object code model sample key none first may data,positive
hi came across similar issue think difference file file saved variable state file hugging face variable key file hugging face file match code really model,positive
hi found solution issue found personal fork unfortunately help worked thesis almost ago,negative
hi mike little confused sentence permutation token rather full stop token,negative
want dual translation built two like following model reverse direction fetch backward translation well fed two like self sample model criterion criterion model sample criterion sample however nan precisely getting nan process nan clearly get especially task model give advice dual translation thank hello also trying implement dual translation based progress issue,positive
hi wondering problem since faced situation share progression dual learning based hello would like ask made progress question want implement dual machine translation willing ask fee,positive
hello issue get working,neutral
try running set precision full,positive
looking model need sent device issue model sent device python class self none false self text sample text sample sample device sample sample device sample sample device sample none else device rate device sample return text rate self text text text text rate text return text rate,negative
could run python root directory build worked faced similar issue,neutral
see divide mask span length consistent,positive
hi issue flag scoring likely generate default gap large case regarding give add generation like beam match great thanks flag scoring mismatch,positive
way run normally mean,negative
similar issue think could related installation work fine primary machine tried different machine threw error replicated python visual eventually enough error went away new one building extension many appear finally throwing error exit code visual studio tool due unresolved external week thought one,positive
similar issue command pip install,neutral
hi question solve problem thanks help,positive
done since top mostly improving accuracy would similar ablation follow,positive
issue someone help please,neutral
hi figure show model still converge well trained much smaller amount data wondering whether done similar ablation see similar ablation study scale paper towards unsupervised speech thanks,positive
argument none carefully check,negative
issue please update found solution hello problem problem think setting gan training greater impact true setting tricky,positive
try one much faster,positive
install torch python precision full,positive
update worked moving user directory reason like user outside chance could fixed,positive
hello anybody help issue since like forward function right need given forward process exist moreover source code find shift right operation forward self return run inference model use previous token input python self run normalize model assert range model need normalize else break return,positive
simple solution inspired shell python,neutral
train need check prepared data,neutral
anyone figure fix facing issue completely stuck,positive
hi thank much reply think great,positive
understanding none input feeding supposed version feeding previous output next step guess ca happen target also none target supposed contain none mean made mistake somewhere instance passing wrong input,negative
sorry slow reply actually first time someone pointed issue command set original training run though tested recent may need fiddle bit python data mask task arch dropout criterion seed rotate insert hope command many may suspected arch exist might good alternative apparently ca invalid value instead unrecognized final command shell python data mask task arch dropout criterion seed rotate insert thank also run successfully,positive
hi get error specify anywhere checked dictionary forward none guess chance could spot passing something could cause use python simple seed criterion task arch dropout patience,neutral
model generator model next sample task text sample sample sample sample sample speaker sample speaker rate task model generator sample,neutral
issue resolved yet found much le likely still long run,negative
solve issue case anyone else problem future thought post let u say want use calculating need training format ranged however contain information script exactly one file name shard secondly rename remove part new temp directory running script worked perfectly bash export based train script python print create temporary model directory create find echo rev cut rev extract full path done find echo rev cut rev set python path none output command something like running command lot ram case peak memory around process limited ram found total expert current distributed world size stitching able load current world size number time float loss base float perplexity float,positive
issue version following discussion fixed inconsistency version tested everything worked fine minor update follow semantic theory problem update,positive
problem facing choose ignore use list instead brave cool use however found making list inside direct simple though little bit dirty view set list new input add like inside list holding new scalar none index may need condition incase loading original example index return example last line access collate like none none incase loading original merge source none else none long batch go criterion model well done anything,positive
believe model one node train multiple parallel data distribution would say model correct way train several hundred model sorry ignorance advantage data parallel,negative
could make sure passing flag inference time error unrecognized,positive
latest version met similar,positive
thank much date version seemingly closed gap posting run completeness valid epoch valid subset loss valid epoch valid subset loss valid epoch valid subset loss valid epoch valid subset loss valid epoch valid subset loss train epoch loss clip wall train epoch loss clip wall train epoch loss clip wall train epoch loss clip wall train epoch loss clip wall train epoch loss clip wall le match,positive
could slightly old take full advantage ampere perhaps try upgrade recent build recent also keep eye version old could run recent ampere optimal speed,positive
main branch resolved issue,positive
still could need help sorry confusion brought implementation indeed weird added new raw target text file guess normal way would send new new inside know create kind target raw text file new new need,negative
know still need help sorry pretty poor understanding implementation target training along side target part understand target got loss function name new input something else would done maybe mean want new input applied training case need training subset right,negative
guess solution bad though understand mean target first glance would new argument forward default want make collate inside align need change transformer main implementation part new input something raw guess nothing build inside test run sufficient want million new input may write another way loading extending cool thank kind reply new associated every target token every time step amount easier extract rather extra target however calculating loss target include mind hacking inside collate delete extra target sample know whether something considered happening implementation strategy many time hacky messy elegant way might use entire size target extra instead target think would bring lot code,positive
exactly otherwise error thanks lot,positive
trying execute training getting error error unrecognized recent call last file line module main file line main file line file line raise command returned exit status,positive
guess solution bad though understand mean target first glance would new argument forward default want make collate inside align need change transformer main implementation part new input something raw guess nothing build inside test run sufficient want million new input may write another way loading extending cool,negative
hey could quick look,positive
hi may ask would suggest want add new every time step use different one text target current solution target may better sent model via however change code place example scalar part want use dictionary encode want use different dictionary,positive
second also interested add new language model,positive
update like actually successfully error thrown somewhere middle upon target side empty might problem aware possible use clause discriminatory restriction president commissioner lady like congratulate report president commissioner lady like congratulate report case would much like know council position president commissioner lady like congratulate report president commissioner lady like congratulate report,positive
follow prepare training data manifest shall get file need,neutral
thank much thought conformer ready like mention,positive
great news point important point currently somewhat code documentation something get used spent multiple working although still many quite grasp due lack code documentation find big problem new joining lab,positive
hi clumsy reinstall environment use command,negative
hi think task general task use different different also choose share task use prefix distinguish different language default different according different trained task,positive
thanks investigating shall open another issue test breakage reference sure open issue,positive
thanks investigating shall open another issue test breakage reference,positive
environment version o pip source build command used source pip install python version python version configuration ti anyone problem try pip flag see situation due environment setting pip install exactly system environment system environment ca find build take long time,positive
still failing investigation build version release install version locally rerun gone irrelevant could connect socket guess could proceed fix separately,negative
unfortunately never able figure fix longer relevant ended setup experiment version require internal state hope fix work,positive
think fix compilation error meanwhile test run addition,neutral
failing change variable type tensor assigned value type bool file line compute padding mask tensor since file line return looking issue try send fix real quick,positive
install however run python build error running build running running building extension file included function char char unsigned warning format argument type unsigned argument type aka long unsigned read unique text total long unsigned aka long long unsigned warning format argument type unsigned argument type char unsigned aka read unique text total long unsigned char unsigned aka unsigned function char char char char warning format argument type unsigned argument type aka could truncate output file size long unsigned aka unsigned warning format argument type unsigned argument type long unsigned text long unsigned long long unsigned function char char unsigned warning format argument type unsigned argument type aka long unsigned read unique vocabulary total long unsigned aka long long unsigned warning format argument type unsigned argument type char unsigned aka read unique vocabulary total long unsigned char unsigned aka unsigned function char char char unsigned char char char warning format argument type unsigned argument type char char unsigned aka read long unsigned char char unsigned aka unsigned writing ut unhandled machine type import library format archive error file format error returned exit status error command exit code fix,positive
failing change variable type tensor assigned value type bool file line compute padding mask tensor since file line return,neutral
sent added validation defined,neutral
well found note licensed available model license file,positive
sorry revive old thread tested trick got odd posted,negative
issue went away setting file sure parameter used original paper sure default,positive
python task path train criterion letter lexicon,neutral
found issue passing string instead fix falsely string running,negative
suppose since trying extract work around end used package loaded model hugging face worked fine without error warning,positive
great code also issue manage figure whether dropping negative impact model performance,positive
wondering update ust branch internally,neutral
ah translation task rather probably mismatch hub interface beginning sentence token need remove token hi thanks replay yes translation task however removing token work think problem force none solve issue hello also problem none could solve solve thank,positive
question train get normal blue may ask use vocabulary size rather attention need try two vocabulary size better little vocabulary size also achieve blue attention need,positive
question train get normal blue may ask use vocabulary size rather attention need,positive
thank reply tried still get error python sample sample sample sample sample sample output tensor tensor none none tensor believe could generator task return object shown object object way place onto device,neutral
may reason norm code python,neutral
hello ran problem following famous issue script came implementation actually worked without script python run inference model single audio file used loaded key key import torch import import import import dictionary import import import unpack base create taken key exist otherwise default field field field field return assert return return model model model sample input define additional generator feature input source input source false input sample input list model hypo sample hypo used torch version version flashlight version version compilation release run inside docker container,negative
meet problem model saving produce one use model run import torch model model error message like recent call last file line file line module model file line save file line ca pickle attribute anyone solution,neutral
solve problem problem well thanks,positive
sorry misunderstanding output defined negative sample set defined shape one positive sample true future negative loss function calculated model maybe objective function like python sigmoid true result result loss sigmoid true sigmoid would nice someone check function code,positive
also basically pretraining fail existence field quick fix change file line python else none python else none pas argument relevant recall correctly addition line mask add field import optional optional field help set use mask whole use command line,positive
totally depend corpus portion corpus loss function need time capture contextual representation loss function tend higher high portion also increase loss score also worth loss score nothing performance downstream example loss score low performance downstream poor need least similar enough capture contextual representation effective transfer learning approach portion loss score tend,positive
yes sure curious far model could go loss function due hardware per epoch training far based paper thanks answer,positive
think another issue problem fully case,neutral
little meaningful compare across strongly data,positive
average loss end could someone share loss target language would like know average loss around,negative
thanks issue question find answer hi dont know understanding correct think first extraction used original open source code thank understood,positive
given access tried load model code state model task,neutral
tried load use lid model error could infer task type true false false false false false false available available,negative
hi find model nan silent output fixed issue try remove hope help method completely work thanks lot problem,positive
thanks issue question find answer hi dont know understanding correct think first extraction used original open source code,positive
hi guess large going fit memory couple might try try base rather large model mention input output sequence size batch size reduce try training loop trainer try free anaconda cache server machine know weird worked know exact reason access multiple allocate multiple parallelize model hope help,positive
thanks issue question find answer,positive
probably input sample default may try print sample see inside probably inside found inside likely used model put onto batch,neutral
hi give higher wer score trying train different language facing issue,positive
could circumvent running train loop specify specify new work many used training case would nice way use script instead able run one node also another issue calculating extremely slow took calculate loss contrast one train batch approximately two training would take look like done loading fused epoch update loss wall begin validation subset rank got valid subset rank begin looping validation subset length inside handler epoch epoch update loss wall script used bash export batch size per gradient accumulation launch job adjust port python task arch criterion sum linear dropout,negative
hi root directory meant error guessing root directory file root directory hi thanks reply yes enter root next step installation,positive
refer answer however long time still ca get paper unlabeled data data language model best result got paper reproduce given model provide guidance really spent long time tried reproduce open source configuration performance rather poor public model found import torch state print print state get output like none none false none none false false false false false true false false none false none false none none none false false false false none none none false none none true false false false false none false none none none none none none true false false false false false false none true none none none false none true none none none false false none none none false false false false false true false false false false false none false false none false false false false none false false false none none false none false false false false none none false none false false none false false false false true false true false false false false true false false false false false false none false false false true false true false true false false true false false false false false true false none true none false false true false false false false false false false false false false false true false false false false none false true true false false false false false false none none false none none false none false false false none false true false false false none none none none none false none false name message false true addition parameter could found code model state give configuration reproduce paper thanks answer,negative
hi sorry late reply mine despite close still gap reproduce yes far setting right update frequency according batch size script use evaluate model,negative
hi sorry late reply mine despite close still gap reproduce yes far setting right update frequency according batch size,negative
hi sorry late reply mine despite close still gap reproduce,negative
hello want knowledge distillation train standard transformer model original data translate train data set get distilled data based original data finally use distilled data train student model enable simple knowledge distillation,positive
similar question following language model example attempt train basic message ca decode position invalid start able fine data train valid test along dictionary help,positive
hi facing issue repeated random together one case generate,negative
hi find model nan silent output fixed issue try remove hope help,positive
hi met question question error task file file error function core error one line code function si terminal print lot exception object iterable solution main reason error version si precision seen change version change code si input input hope helpful,positive
yes code bring memory decided back later,neutral
yeah release mark let sync internally,neutral
basically change made need torch install already case since assume torch directly build need run python use dependency another project important avoid needing everyone commit research experiment inside problem approach torch build time sometime new version instead one current call build isolation think feature match code compile torch torch get currently way saying want version build install see lengthy discussion conclusion thread pip ca fix alternative build support best found far disable build isolation sure reuse thing get ca reproduce issue machine install torch git clone pip install python install torch pip install always figured feel like need upgrade think net win library let know feel strongly,positive
investigate please need cut new release prevent people working broken,negative
pip install working far throw away made extra added seem part model training different architecture also supporting built later going work,positive
help search search need help process data correctly train model question code data used according training neural machine translation apply terminology constrained neural machine translation transformer train validation data already according train validation dev data model en de trained model task criterion arch noise dropout tried already tried data source target respectively worked idea solve error hi resolved issue,neutral
hi right loading also release indeed right action kind,positive
aha th see backed second time th ended release,neutral
hey everyone sorry delay thanks lot feedback far hope new version address raised plan early release end year likely start gathering concrete feedback also start external see reason supporting external quite contrary believe critical project open possible want succeed similar new version proper model open anyone willing commit project get touch get close first public release,positive
thanks response going try since expert either might require bit training quant noise used noise block size trained architecture sentence trained around got model sensible hypothesis around th epoch training command data folder handled quantize freshly build model load state exactly clear mean write training loop quantization make would nice share snippet gist profile would help try together zoom thanks update train quant noise well quantize model without severe loss metric share shortly also tried quant noise model worse unused model model lost share experience thanks,positive
meet problem check source code finally find one step iterate data check function message,neutral
hi could please help review,neutral
hey found training detail squad,neutral
hi sorry hard time create activate pip install pip install could someone share detailed script new error guess issue isolated build feature isolated build create new building version one system please also try pip install ran build building docker run git clone pip install python pip install pip install work however running following command another error building extension building extension recent call last file string line module file line module file line module file line setup file line setup return file line setup return file line file line file line super command file line file line run file line file line command file line super command file line file line run self file line run self file line run file line self file line self file line file line file line self file line file line file line file line list index range end output resolved pip install idea version maybe fix know reason,positive
hi sorry hard time create activate pip install pip install could someone share detailed script new error guess issue isolated build feature isolated build create new building version one system please also try pip install,negative
read try change article pipeline translation sent text print sent sent output good day please add file exclusion attached ability change set,positive
hi root directory meant error guessing root directory file root directory,neutral
basic implementation based implementation much older version tried integrate version sample bash script distill model smaller model thanks detail way sample bash script random paper fixed issue,negative
met problem change would influence final training,neutral
basic implementation based implementation much older version tried integrate version sample bash script distill model smaller model thanks detail way sample bash script random paper,negative
one quite useful bug report thanks,positive
hi version name torch version summary dynamic neural python strong acceleration author team license location name pip version summary tool python author pip license location message strange torch indeed import torch tried commit right,positive
use custom model architecture defined file directory parent student defined library wo need parameter,neutral
hey like collapse may want lower learning rate dont variance wasnt logging trained loss curve image couple example reduced speech setup variance look somewhat similar exactly also learning rate peak rate training loss image image target image hi curve different speech curve like converge actually audio modality training curve similar curve predict target seem check audio model image image image,positive
hi could report pip version torch pip show torch pip also error message pretty clear related commit,positive
could please give little used opt,negative
please use latest version code find example folder work progress make multiple bug please stay date code,positive
hello tried run code pip install error unrecognized temperature none,neutral
nice work might even better could use distillation would try thanks,positive
address bug encounter error task try train model scratch fine,positive
look file see field set script looking data directory character recognition way looking training know turn validation create set way training set put data directory validation set something else like change value file field thank,neutral
update working issue relative path hi still getting issue used following command,neutral
commit error pip install check commit installation fine exactly environment already cause update error pip install building collected building building finished status error building run successfully exit code output running writing writing writing entry writing writing writing manifest file recent call last file line module import module use could find falling back slow could find reading manifest file reading manifest template license file writing manifest file license file license pattern install use build pip running running recent call last file line run file line unpacked file line file line name file line command file line super command file line file line run self file line run self file line run file line file line raise version version used compile please make sure use error support via pep recently seeing error please report,positive
try via pip install ran issue tried pip install version reinstall command,neutral
mean two run one rather two useful thanks,positive
basic implementation based implementation much older version tried integrate latest version repository dynamic try include new relevant much possible may occasionally see broken stuff please raise open repository contain enough documentation run training please feel free reach,positive
mean one merge one generate time may try use script question,negative
want suggest copy edit assume used use command line batch sent model change whatever want following handle id also shuffling generation find written batch,neutral
oh sorry checked log directory,negative
share wer model seem weird since accuracy masked improving,negative
solution special model would learn predict need one script replace order maybe,positive
use give alignment alignment replace token format change thanks,positive
commit tried add feature sure go back version,positive
hi would also like know solution issue also transformer model bit working transformer model might helpful somehow update task spelling correction trying skip special used alternative way achieve replace special paired data maybe also work train model replace back order,positive
read documentation feature folder,neutral
hi would also like know solution issue,neutral
original input used replace translation hi may ask fixed issue still working task original input used replace,positive
hi knew long time ago may ask solve problem,negative
replace original string add replacement,positive
thank assistance normalizer available convenience would please provide information met problem,positive
also trying implement modification,neutral
sure talking sorted right guess see assume shuffling happening inside disable sort get original order wish change original code recommend need make copy alter copy use make recognize new task conduct searching find go find tiny piece advice conduct searching whole repository though wo tell shuffle data may tell use task data handled always ask anyway,positive
run recent release also make run apex version work need investigate recent version apex work whether actually tested,neutral
thanks response checked version also checked version also currently listen trained model code part script import,positive
probably due different version used training loading probably older version locally please check two please share specific command reproduce,positive
please use python use help get help use,neutral
information happening python python via able get older work fine,positive
met problem think essence problem win compile guess however program code correct guess problem compilation send graphical report error however original file directly work normally,positive
thank try shortly much obliged,positive
hi got exactly issue maybe found solution since setup,positive
issue add code around line atomic save add line add line,neutral
note reproduce please install pip install recent call last file string line module file line module import file line module file line return name level package level file line module import file line module file line file line return name level package level file line module import file line module import file line module file line file line return name level package level file line module import file line module import file line module import file line module import file line module import module error process exit code pip install pip install another directory part path hope new catch installation upstream,positive
also looking distill prune,neutral
instead git repository pip install without,neutral
hi still release evaluation squad,neutral
wont much effect match feature extractor normalization setting normalize layer norm feature extractor normalization group norm first block feature extractor feature extractor,positive
look good general like previous implementation integrate create one many redundant code,positive
confirm error anyone python path like following import repository kept note path repository kept may differ use different way different python version time append path becomes must,neutral
thank notebook able run notebook without error,positive
hi please notebook reproduce issue,neutral
hi thank issue tried reproduce could also confirm,neutral
hi root cause ca import fix please guess missing file,negative
good would suggest also ann making,positive
someone code originally trained task latest version task load model try use load model error projection head contrastive learning follow firstly model bash try load task python import torch import model task got familiar error recent call last file line module file line model file line model super file line model self file line return task file line object type need load model like code need dictionary file look like python import o import torch import path task task data path task model need get easily follow training guide bash root bash successfully loaded model try inference toy net input python source none return return model,positive
task task name project defined task class reason import python find task class two way import new stated new defined corresponding folder data task automatically way directory hold extension issue task class need import see know directory structure use task class instead would recommend use first hope,positive
actually run must twice mean issue command node script look like,negative
hi yes think correct notice also pas blocking function look relevant,positive
hi met issue use set,neutral
found everything need sample said need correctly whole methodics lot thanks,positive
hi array fixed commit,positive
try pretrain speech model total however use support upgrade use command socket issue someone help figure issue thanks advance,positive
similar issue figure perhaps,neutral
expert merely want share point view actual question make judge language sentence written must id token front sentence en like tell language exhaustive program identify reading actually load need first switch sentence language previous sentence well actually also collect written language form batch make multilingual batch way believe,negative
instance batch line since line id like en whole line written language en batch made multiple batch contain multiple believe line like en love apple la used general mean model learn task simply difficult go around splitting,negative
may help sort cut sort cut sort cut,neutral
question pretraining code sorely missing help would great respect,positive
link getting error trying initialize model saying file directory large number loaded default infrastructure code looking language specific tar file also sample code showing use flores python thank,positive
hi know freeze used false working train sorry tried freeze project dont know much,negative
may know root cause thanks,positive
facing error training phase idea fix please model trained another task another architecture model model model expect exactly identical model model class input upstream saved class take list weighted sum train python use functionality please install python use functionality please install recent call last file line module main file line main runner runner file line file line file line file line return dictionary file line super file line name defined,positive
thanks confirmed added final documentation,positive
occur problem validation process setting validation part work still strange bug know,negative
hi know freeze used false working train,negative
similar question know freeze model training used false working,negative
made create new sure,positive
unfortunately guess may easy fix,negative
problem similar problem freezing transformer,neutral
would please provide code question,neutral
hi code look good able verify able reproduce vanilla noise also would good verify like work well pushing code,positive
total vocabulary size must wrote model input feature size output feature size determined given vocabulary size size different get error mismatch loaded alter already found end probably le frequent would alter first edit prune distill recent issue model interest would need read till end,positive
thanks replay data preparation quick test data moment another question vocabulary contain data add new based new,positive
modify like python torch,neutral
nice tell work hope solve issue afterwards,positive
code defined pruning function model proportion import prune import module module module module module return model call building model main function build model criterion model model model module want prune prop ready prune use command start make sense working,positive
code defined pruning function model proportion import prune import module module module module module return model call building model main function build model criterion model model model module want prune prop ready prune use command start make sense,positive
help plan use start training two use configure use please help thanks much solution hope useful,positive
hi thank much keeping order important work yes sample id would work thanks,positive
use data model one two vocabulary line special determine model input feature size output feature size data made model need use vocabulary prepare data command may like data well suggest read page,positive
sorry confidence since tried yet guess would need try later however time weekend may take time want solve would suggest implementation make model freeze believe method method freeze,negative
found working model freeze used reset saved model used still implementation,neutral
hi trying train model still find doc get yet know format train could please share training could please list detailed,positive
sorry slow reply actually first time someone pointed issue command set original training run though tested recent may need fiddle bit python data mask task arch dropout criterion seed rotate insert hope command many may suspected arch exist might good alternative apparently ca invalid value instead unrecognized final command sh python data mask task arch dropout criterion seed rotate insert,positive
still relevant issue today,positive
final loop naively following desired effect python ignore start ignore start index enumerate else remove last pad last sentence loop last sentence else sentence add padding token original last sentence sentence sentence result index index sentence index add,positive
test set automatically sort length flag keep sentence order despite extract input output regular expression produced reorder sample id already keep order,neutral
solve issue align folder name work think suffix pas like case suffix align think reason file way,neutral
want freeze slice single weight tensor short answer difficult need modify previous link,negative
may try freeze model reload whether saving frozen state similar pruning mechanism model directly apply use load model prune new use get new model assign new use save new model use retrain model prune method freeze tensor reload,positive
checked weight freezing freeze whole module rather case want freeze zero pruning whole module right,positive
want freeze tensor guess simple way freeze code directly example copy implementation freeze method method use import custom model arch tell use custom model class may try freeze model reload whether saving frozen state,positive
thanks fix see due could please address,positive
sorry reply work time also actually read wrote phrasing bad understand nonetheless may need know literally dummy batch data model python single tensor class model used model batch model transformer tensor sentence length element inside bigger size tensor given sentence length tensor sentence length element inside bigger size need find forward need kind batch model accept tried method prune model successfully set le important save question need load retrain model use load model prune new use get new model assign new use save new model use retrain model prune freeze avoid process,positive
thing try load locally python import model output loading archive file en dictionary de dictionary recent call last file line module file line file line task file line file line return super strict file line raise loading error loading missing key size mismatch param shape shape current model size mismatch param shape shape current model size mismatch param shape shape current model size mismatch param shape shape current model size mismatch param shape shape current model size mismatch param shape shape current model size mismatch param shape shape current model size mismatch param shape shape current model size mismatch param shape shape current model size mismatch param shape shape current model size mismatch param shape shape current model size mismatch param shape shape current model size mismatch param shape shape current model size mismatch param shape shape current model size mismatch param shape shape current model loading work without,positive
nice icon nice small fix guess send pull request,positive
sorry reply work time also actually read wrote phrasing bad understand nonetheless may need know literally dummy batch data model python single tensor class model used model batch model transformer tensor sentence length element inside bigger size tensor given sentence length tensor sentence length element inside bigger size need find forward need kind batch model accept,negative
similar question found suitable method prune distill pruning torch sure,positive
mean support framework yet,negative
tried assign random input error model error recent call last module model self model confidence confidence model object save auto model model return model self model self super model set self model model none none model model else raise exception self model version greater strict option false model training trace optimize strict strict optimize strict strict self input input result result input else result input self input false try result input finally self input registered latter silently raise,negative
example acceptable input model like wrote property self return accepted forward transformer need data forward forward probably need tensor sentence length element inside bigger size tensor given sentence length tensor sentence length element inside bigger size prune probably simple run like evaluation need provide data wish also new field let know work may able reply soon know whether sentence length batch size serious recommend try different input one actually taken data one random,negative
try prune model code import torch torch import import torch import import import summary import import random import import import import import import model pruner model model checked document know input size model ref,negative
every resolved getting exact error stack trace post except triple checked exact file calling also base model training command,negative
used give language file problem thanks,positive
used method issue worked comment cool thanks familiar use prune model sorry familiar sure work,positive
distilled provide prune module believe cast method upon model weight might need load model prune save torch load weight according saved pruning would grateful share,neutral
used method issue worked comment cool thanks familiar use prune model,positive
used method issue worked comment similar question found suitable method prune distill found yet,positive
thanks work know pruning pruning,positive
gave code please least tell happen tried see something first need understand import torch print know look model find print model obviously access tensor model edit inside need create model instance done save load later exit python import torch print used hope understand wrote please give error log encounter something,negative
guess point load model load thanks reply going new model load train could please provide code load old model get alter initialize new model save new model reload new model,positive
try make load import import torch print get true true true false false false false false false recent call last module print task return self self must string code object problem,negative
guess point load model load old model print something like model inside model edit model downside treat model instance adjustment new,positive
guess happen since model state found use instead flow load old model import torch import directory new model file path note model initialize instance whose structure instead loading long time tell python create structure model annoying well pick best shall tell successfully well one idea write new original new load method may reduce loading time well good luck great save load method,positive
target guess forbid mean generate ideal target well need target way used force default error raised collate anyway usage,positive
guess happen since model state found use instead flow load old model import torch import directory new model file path note model initialize instance whose structure instead loading long time tell python create structure model annoying well pick best shall tell successfully well one idea write new original new load method may reduce loading time well good luck,positive
thanks yes think tried error model state none think could missing save model import reload new model,positive
used method issue worked,neutral
thanks help really appreciate,positive
may try import print finished saving relative trainer need,neutral
error like wrong structure input target transformer normal translation task definition see structure target addition transformer forward look target guess may change key target one last thing already tensor dictionary see forward better check take need may use merge model transformer different basic flow find data make proper batch good luck find relative example may call method loss entropy want finally,positive
found error double around key help,neutral
similar question found suitable method prune distill,positive
bug bug error loading reproduce remove argument strict function call circumvent python compose rum python import torch see error recent call last file line module file line load model model file line model entry file line file line task file line state file line state state file line state state file line none file line file line file line ex cause file line raise set end full file line file line key value file line key value file line key value file line child key file line key file line file line file line ex cause file line raise set end full key environment version master version o pip python version hi bug solve,positive
hey thanks information version found significant bug tone pronunciation problem also transcription result wrong tone mandarin example import jing print jing print print jing jing jing print see result second character new vowel tone none character respectively jing jing converted pronunciation according seem right checked use correct print print system correctly vowel accurately distinguished tone think problem conversion script transcription also test version found still remain bug thanks lot,positive
similar solution use removing code issue,neutral
able pull branch confirm error without model,positive
also thanks side huge amount work made available u one question understand technology ca make available commercial though making small available similar license like bloom considering limited small wide availability might net positive research community move would allow work since,positive
freely first model trained model input size determined afterwards result mismatch model new size different previous trained model loaded yes necessary fact pad awkward,negative
like invalid optional value error environment like anyway change optional maybe try also would nice create dummy text like repeated time train get multiple length time know valid maximum length delete long actual data late reply thank much worked training,positive
met problem guess error exactly already file corresponding path need create different one delete one already worked worked thank,positive
hi line could right also requirement satisfy requirement,positive
hi anyone issue apparently support external wonder anyone restriction thanks advance,positive
thanks lot super useful,positive
facing issue would mind telling problem ended resolved,neutral
chance could get pretty small parallel like right thing,positive
problem lot confusion regarding model speech normalizer get inference script,neutral
tried advice like wrong logic resulting forever loop need delete declare origin instead comment retrieve,negative
also problem end found made mistake trained separate model generate based validation set training set mismatch training set validation set although affect final effect model pick last saved model problem still need,neutral
hi used used mandarin example import print print print,neutral
hi problem fix bug thanks look version call calculate norm,positive
exact problem generate find one line file example used something different calling,positive
like invalid optional value error environment like anyway change optional maybe try also would nice create dummy text like repeated time train get multiple length time know valid maximum length delete long actual data,positive
also know question already many time always get error reducing token size help already still think may meaningful go warning recover pas recent call last file line module file line main file line file line spawn return join daemon file line file line join raise process following error recent call last file line file line main file line main train trainer task file line inner return file line train file line inner return file line raise file line file line step closure file line step closure file line wrapper return file line step group memory tried allocate gib gib total capacity gib already gib free gib reserved total,positive
yes affect see small disadvantage trained literally decided data like literally like vocabulary create banana cake thus decided vocabulary also use make comparison wrote recommend look used appear registered chain lot registered declare sense want know valid search starting clue,negative
may ask need space,neutral
thanks ton nevertheless found would generate specify case guess need find one right one contain inside,positive
actually repository search find nothing yet search whole find used put feature said inside inside import use coming else personally used know change might better search finally training scratch need satisfying vocabulary inside vocabulary run correctly good vocabulary enough frequent written top actually satisfaction matter count interaction normal simply put inside done matter whether put top last line middle mostly get come data make correct guess say make correct important part,positive
found solution facing issue,neutral
hi problem fix bug thanks,positive
input like result normal input platform truck used transporting transport transport airplane transport airplane output,positive
trained model also problem input platform truck used transporting transport transport airplane transport airplane output unusual sometimes recurring,positive
also problem give advice please,neutral
also train scratch instead model would anything need take care instead dictionary low count previously special dictionary class,positive
thank much answer still wonder way tell split special previous attempt modify issue pointed although training scratch work call directory perform could give detailed easily thank advance,positive
hi training different model ran error saving turn disk space full,positive
multilingual model model absolute reason believe lot model,positive
hi short fix data contain custom correctly add custom appear input appear output delete many need keep size unchanged first always data already example want fact question two custom raw input fact question fact question may become fact question fact question fact want word write python script read fix wrongly custom case fact fact question example text editor fact question fact question fact one token fact listed fact switch last custom want use custom model,positive
dense dense distilled dense,neutral
hello previous answer new special preserve procedure seem right add new special german transformer example novice gone relevant found result really appreciate help,positive
brilliant thanks model correctly loaded,positive
hi still open question tracing would anyway still hit bug,neutral
look like valid output might want restart something like shell cat model file thank much finding problem command work,positive
look like valid output might want restart something like sh cat model file,neutral
data actually contain list like per row head show data like burg led hi thanks pointing data contain list like head command show image could problem thought data look like process might know reliable way remove,positive
use hell lot memory still able figure reduce memory usage anyone,positive
better solution use service,positive
solve like much elegant solution thanks,positive
could make sure passing flag inference time,positive
data actually contain list like per row head show data like burg led,neutral
familiar multilingual model multilingual right may provide also would nice include multilingual something close issue title provided training process think also include command arch task criterion dropout seed simple yeah multilingual task thanks reminder include tag next time,positive
train model might want try task path task test scoring please check thanks suggestion definitely try model training process link also last reply,positive
data like neither source target probably model learn anything useful command data data train data valid name running also like process link basically also task train translation model low recourse case training use parallel data short first pretrain model parallel data use model generate back translation data finally use data train model,positive
train model might want try task path task test scoring please check,neutral
familiar multilingual model multilingual right may provide also would nice include multilingual something close issue title,positive
data like neither source target probably model learn anything useful,positive
correct pad weight pad weight training model result relationship training loss,neutral
expect zero vector unless gradient descent explicitly happening network suspect causing training even native pad row matrix,neutral
believe weight randomly least confirm pad weight change training since pad set zero pad contribute loss,negative
load see inside import model print,neutral
hi dictionary distilled load model due inconsistent vocabulary size dictionary model thus extra language total number however matrix file size making model structure built evaluation time number divisible extra also dummy wondering cause problem message got error loading size mismatch param shape shape current model size mismatch param shape shape current model size mismatch param shape shape current model solve problem,negative
thanks issue quick fix worked fix service default currently pip install upgrade could confirm issue resolved version thanks advance,positive
hello inference time around per core processor second per sentence translation easiest solution distill knowledge smaller faster architecture instance currently building mobile friendly version model knowledge distillation train smaller architecture transformer smaller layer width improve latency expense accuracy note tried received inadequate also exploring architecture natural language inference glue lower latency phone involved solution port model framework inference latency framework used many suspect model size might still need reduced though hello want ask knowledge distillation choose teacher model student model,positive
leaving note anyone else may encounter apex someone might able help issue pip support available yet pip install work get support run install however try install apex running pip install work get stuck getting following error message warning use due use pip python running command python recent call last file string line module file line module file line module import torch file line module raise err procedure could found error loading one error python run successfully exit code see output note error likely problem pip full command compile caller pip run enable directly import work clear error message underlying think script following warning standard file found shim handling import o try import except error print error execute since available build environment else caller import setup setup compile error error error generating package see output note issue package pip hint see checked folder file tried continue get error message file could causing anyone suggestion may causing error,positive
also contain many think back translation data supposed use training model contain many like idea prevent model generating like hospital informed police advice really work,positive
fix issue still issue,neutral
hi sure open request review thanks lot advance,positive
well get working torch got unblocked thanks tip got work around pip install since found probably however rigorous test yet,positive
regular pip behavior question pointed u may require upgrade version obey currently especially problematic since version pinned therefore something dumb like built different version short definitively bug documentation emphasis mine project pip already via built necessary,negative
issue regular pip behaviour see,neutral
well get working torch got unblocked,neutral
match original paper use dropout since memory available probably improve training speed increasing decreasing try keep training log around hey got question tell id appreciate help thanks lot,positive
hi yes output feature dimension size correct argument original model setting path none avoid work please let know encounter thanks,positive
hi thanks help fixed issue loading model confirm run model correctly model path left unchanged output default dim summary summary state sequential dropout sequential sequential dropout sequential linear dropout dropout none none sequential linear linear dropout dropout dropout dropout activation dropout linear linear linear linear dropout dropout linear activation dropout dropout linear linear dropout dropout dropout dropout activation linear linear dropout dropout dropout dropout activation dropout linear linear linear linear dropout dropout linear activation dropout dropout linear linear dropout dropout dropout dropout activation none dropout adaptor linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear,positive
hi suppose language identification model used paper please tell lid model link take anywhere,neutral
looking forward eta release,neutral
hi thanks issue fixing,positive
hey thanks getting back actually went cover ground erroneous path issue resolved load given size big machine let know,negative
error latest none flattening may none type propagation edit permission reopen,positive
thanks help look new model way target think perhaps model therefore better,positive
hi thanks patience could try state original model instead like import torch import import model state model model none none model please let know work case update end,positive
gave trying make run could tried test different find time play source target language could explain work better note least new model town could worth exploring,positive
problem output model data,neutral
met problem guess error exactly already file corresponding path need create different one delete one already worked,positive
script thank however like case also able model pipeline set see model load however error error getting error override getting better performance trying run model able model thanks help,positive
hello getting error large model pipeline set error getting error override option train suggestion thank,positive
import type added checked giving following error recent call last file line module file line main file line main file line state file line module attribute also used new directory showing following error recent call last file line return file line lambda file line return file line sweep path file line file line file line ex cause file line raise ex set end full file line return file line file line file line file line file line file line ex cause file line raise ex set end full environment variable found,positive
find efficient working massive tensor saved file read directly,positive
thanks taking look error indeed following line alongside loading model alleviate issue running work even without line said slow fix used slowdown per epoch step slowdown per epoch still pretty bad going go back loading file indexed decided pickle practice big work according thread one could save individual tensor file define retrieve tensor loading file still result individual,negative
share first decided try remove check unsupported language modeling target exception mostly thus model used adaptive model found documentation part model future target default setup setting past self future impact end result deterministic could check one target somewhere said bidirectional ought self default causal future target typically bidirectional used since discovered believe white lead practical use day might try different might give dead instead try solve problem route oh wait like bidirectional paper due known bug latex author anonymous probably fixed soon also maybe need wait one year,positive
answer best tell forked information far assume create tensor inside way around may either spawn probably keeping skip,positive
thanks true way go,positive
found set false model whole transformer position setting better one paper share position thanks lot come answer refer,positive
cool thanks swift reply give try see come think would also need make beam make think paper idea know already idea instead translation language modeling task,positive
found set false model whole transformer position setting better one paper share position thanks lot come answer,positive
thanks also path local path getting loading model python process execution able load would mind code even direct copy paste absolute,positive
hi keep vocabulary method flag first epoch u learn example first epoch use later also use note code template expand method work update task bit better use,positive
sorry knowledge field find short model change method return future past self add command line may job specifically add past self future wished utilize search two know determined see also find built comment talking future self past check find know target target handled comment find sense everything ready go however interactive may work hope guess somebody,negative
thank actually looking location know thank,neutral
change model even exist believe program load,neutral
original command default meant used lot see used day delete run fine environment automatically,positive
hi come fix regarding error,neutral
hi thanks prompt response confirm set local path one load model tried python import torch import model model model model model none model task data task error file directory thank help much,positive
hello currently trying train trying find successfully trained scratch like successful since done scratch prior speech translation trouble wer additional addition,positive
either problem trying convert form many parameter code import model library library many included anyway like know transfer deal like,positive
hi thanks reaching like issue missing quick fix update update local path set none something like model state model model none,positive
hi thanks lot unfortunately case code built new name trying call forward function original one process understanding training process easily get beginning stage set large,positive
hi yes value close training evaluation problem related fact said check paper link paper mandatory step give necessary importance article link see reason necessary tried found train sure issue thanks mainly try optimize get better,positive
directory trained model use beam search,neutral
thanks reply working course took advice away instead load directly function within implementation far working,positive
hi got problem today anyone found solution,neutral
dealing problem language pair problem following shell added training work perfectly check learning rate hi encounter issue prediction evaluation getting training trick solve issue increasing thank,positive
unblock additional need fixed,positive
basic template training different find time test yet flow hope find useful hi regarding epoch batch apply different mean new vocabulary epoch yes deal,positive
memory one problem memory necessary transfer strange handle wonder log say error actual model size written log long running determine whether model large sentence long also example used run believe sentence pretty long,positive
thank help make work code thanks,positive
hi use model simple command like one sentence per line information use available,positive
basically missing inconsistency guess dropping may solve problem find key reference locate drop make sure package pip install load file convert ordinary ease iteration import convert ordinary object iterate find wrong key continue key key print break result drop save new,negative
hi thank reply tried suggestion however model use excluding third proposal result last time allocate error error optimization irrecoverable recent call last file line module file line main file line file line spawn return join daemon file line file line join raise process following error recent call last file line file line main file line main train trainer task file line inner return file line train file line inner return file line raise file line file line file line step closure file line step closure file line wrapper return file line step group memory tried allocate gib gib total capacity gib already gib free gib reserved total reserved memory memory try setting avoid fragmentation see documentation memory management,positive
suggest try vanilla instead arch may need remove adjust according error log please paste error log problem run vanilla training might give big arch,neutral
assume copy modify copy origin data numerical used please calm bit believe wise choice mess mostly meant save memory speed actually one step back really need use require loading huge amount data via use script load binary data well use well case read implementation format follow though guess want start minimal way raw pad length matter proof use list instead fancy may take time loading loading seldom bottle neck training belive,positive
hi tested note install latest dev version instruction order use pip install test python import pipeline available model source target translator pipeline text nice meet output translator text output print language code update made space,positive
awesome code key issue however encounter new one able solve dropping key,positive
character base may similar,negative
would believe new feature fast path applied false method string true,positive
sorry know nothing nothing would mind something else help please also share finding sincere,neutral
hi could please help many thanks,positive
update issue similar issue though trying run model fine tuned issue like key issue manually dropping see,positive
like pretraining consult doc drop manually loading code model know would negative impact inference since new area import torch import,negative
tried several time found configuration work,neutral
met issue loading multilingual used sample code documentation import torch import model task model model show key,neutral
try add self work thank also work,neutral
hear getting think great idea keep core library separate current state quite overwhelming one suggest perhaps library built one individual full model easily command line search lot fun think new,positive
hi thanks detailed explanation really resolved still end explanation would get something like interpret last guess represent instead since decreasing sure one line last starting probably ich help help help stand beam search highly thanks,positive
hi thank reply made according reply work,neutral
problem moderate nan quite close across rank rank confirmed solve still would like figure use acceleration work issue reason ran memory solution reduce issue issue reason solution change nag could take look would highly thanks taking time,negative
question train get normal blue,positive
update issue similar issue though trying run model fine tuned issue like key,positive
hi wish better suggestion ended manually rather tedious probably ideal worked well enough use method like calculate grid learning rate dropout uniform train configuration small number wrote bash script launch one another log performance end run use best configuration,positive
hi also trying perform tuning model trained figured efficient way would helpful could share thank,neutral
guess work amount data,neutral
hi may ask data generating back translation like command could please share command also trying generate back translation monolingual data could figure think refer tutorial addition slow translation,negative
could also update link quick description,positive
yes breaking test unrelated fixing separately could make sure use hook run flake black yes,positive
yes breaking test unrelated fixing separately could make sure use hook run flake black,positive
hi thank prompt reply method would certainly useful particularly crossed soon becomes part thanks,positive
hi facing issue comment also set various well,neutral
hi high level dot product vector label vector normalize character since character several character right public explain method possible publish point ca commit specific date thank u know could useful community,positive
hello thanks lot answer really sense like know model working flawlessly indeed coincide said really get decided train mission difference exactly make sense add data also issue training yes come would interesting know added think would change anything answer really assumption length understand difference nice day close issue,positive
hi thank prompt response one question open lid inspection interface could give could right understand correctly support querying right thanks,positive
oh bad notice thank check code,negative
thank actually language although many share en normalization hood hi fixed might want latest version,positive
correct would modify model set used entry point look unsupervised example,neutral
yes seen think generally used custom,positive
thanks made video based giving code,positive
hi plan publish data used training lid model regarding training code used regular training plan refer section paper filtering training data script detection used code,neutral
thanks mean used model,negative
like composite used jointly generator discriminator,neutral
used composite passing dictionary format value neither way composite determine parameter discriminator whose parameter give one part discriminator different discriminator,neutral
sorry wrong composite use set different different parameter,negative
doubt support feature believe hyper weight mean people wish good luck sorry wrong specify learning rate yes every class decoration proper command line tool invoke custom lot thanks code thanks reply close issue since,negative
sorry wrong specify learning rate yes every class decoration proper command line tool invoke custom,negative
possible used like new mode task criterion,positive
would wonder deal like huge hole would case expanded overwrite least used missing put unknown char string setup count kept probably minimum done model would disaster least used want however time may yes model case without worrying unknown,negative
use composite feature well see example,neutral
think used commercially may special agreement research team,positive
right lexicon format go segmentation fault core help thanks,positive
hi sorry take consideration assuming list running script,negative
thanks much greater beginner usability inference capability know capable tool especially training many however familiar handful people really add barrier entry one modification make code branch order run shell script add command line interface leaving issue,positive
thank helpful reply extracted coin training however found give significantly worse paper wondering whether thank,negative
thank nice explanation mean model may need extended vocabulary missing fix problem,positive
confirmed actually lot considered original dictionary inside well wrote expansion code dictionary support char original found since found transfer equivalent char string found equivalent char string tensor converted two appear tensor char exist inside well sum missing use tensor find corresponding inside open first element line number id pad go line go line almost dictionary well instantly fix problem since model input dim already decided need write new convert unknown char string finishing,positive
hi check convenient script run model inference command line without dealing,neutral
thought wrong since dictionary actual inside meant back normal later think chance yes use model translation model dictionary translation output flores total source language across,negative
thought wrong since dictionary actual inside meant back normal later think chance,negative
figure process data process data go wrong process whole training data go well process whole training data thank,negative
really appreciate explanation clear,positive
post wrote wrong dictionary pad simply loaded result wrong input link probably normal see great success,positive
hi know wrong way easy way use train generate interactive used necessary special treatment well absolutely intended work flawlessly detailed story task call load look prepare notice special token like thus making input dim line count pad part actually regardless would input stated error log written error add well pas exact inside total random would never appear use case fine actually found tiny model like error except tiny due read error log confirmed truth thought last time thats compare written assumption last time fault,positive
could help revert thanks,positive
three additional vocabulary add training response related comment specifically additional data source add thank work response extra vocabulary rather still mistake besides internal dictionary link provided inaccessible ca check implementation,neutral
three additional vocabulary add training response related specifically additional data source add,neutral
addition hard data instance likely could find please add accessible documentation simple example also learning curve setting additional support useful experienced setup,positive
agree need easy way try translation feature given would like see something nature hello world welt,positive
manage get example working decided give someone something accessible,positive
manage get example working,neutral
assuming normal translation task fed almost target except task class check definition well interactive use default search find used inside,positive
make generation target prefix given length default argument stated generator may understand question generate right instead forward answer directly well like alternative validation used translation,positive
also face issue find solution,neutral
thanks sync code head main,positive
plan support external possibility external maintainer time ago sorted many go unmerged current discouraging hurt adoption happy continue conversation appropriate hopeful going forward regular cut well backwards compatibility iffy current since regular cut often tote around commit proxy bit headache,positive
linked look probably hard find link broken section least found header little difficult think get translation something plain spoken suppose anyway try follow,negative
hi could take look generation command example thanks hi took look see training see one might inference get translation see use load call translate something similar maybe something,positive
hi could take look generation command example thanks,positive
used inside one node used communication submit job platform node run use command like command experienced used call slow directly node acceptable speed fast also faster case different point use instead basically wrote ring bell sorry would recommend ask platform use test code,positive
latter first first consistency different model small thought monolingual use also working,positive
problem interactive switch right well yes switch calling always copy part write new method well made one sorry multilingual also look start search basic flow create generator generator prepare data translate list sample size inside list python generate output like tensor score float attention tensor put numerical output back normal hypo list hard identify useful redundant one give need hope,negative
unfortunately share project impossible better repeat simpler way every query specify input wait time data file read memory known mode empty input user opportunity specify input perform fly without need full model memory model multilingual supporting several strong desire specify input also order produce fly without spending time reading data every query feasible,positive
replicate paper ran recipe got test paper,neutral
hello team based trained multilingual model run service docker container according following scheme input provide source text language pair get text output everything alright every single request additional load model read data model file model file experimented various finally accepted fact without run command read data file appear message know language set also remove o terminal run path task text provide via random language besides far suppose quality lost automatic source language identification question related technical opportunity firstly read data trained multilingual model order load model thereafter provide additional currently care transferred via request share project,negative
thanks everyone longer use forget issue maybe try time future,positive
hey thanks proposal already touch early release definitely consider lightning check announcement organizational side recently fair right leading modernization effort also pretty much involved project unfortunately meta obviously welcome contribute project,positive
need create language model use one tutorial help need text train model,neutral
fixed issue try one port,positive
progress also trying train summarization task one,neutral
according experience question environment version match version follow command line sometimes pip install would produce problem try,neutral
bug usually use old version process data use version train thank spent time trying find solution found comment issue version,negative
think get unit model use char unit build,neutral
hello facing issue training task ar ast ba ca da de el en e fa fi ga ha hi id ka ko lo ne pa si ta th ur wo yo temperature criterion dropout seed simple patience arch tried solution still error thank lot advance,neutral
hi sorry could look missing could also share necessary,negative
still happening audio infer,neutral
hey like collapse may want lower learning rate dont variance wasnt logging trained loss curve image couple example reduced speech setup variance look somewhat similar exactly also learning rate peak rate training loss image image target image thank behavior loss going related bootstrap latent demonstrate importance predictor collapse,positive
hello problem able fix thanks,positive
please keep eye torch export today exportable,neutral
hello thanks lot help worry time answer first really know data given also model assumed need use train model unlike written seen line last model like number mean line right found yes exactly mean number found data mean training one data right right inside strange yes yoi understand correctly thanks command python sent think problem come length given try say since believe really help thanks case thanks lot let know manage make work properly last comment available work well add data work tried two option fixed dictionary work data instead work sure thats right manner thanks nice day,positive
great see effort made direction together felt like release please make accessible globally avoid piping multiple inheritance one consistent way setting one annoying currently current version mix argument setting recent throughout accessible everywhere also remain way concise currently also generally argue le inheritance functionality often beneficial avoid multiple standpoint probably would make sense like dropout attention even like transformer also consider specific machine translation language modeling speech would allow contribute mostly respective make little bit maintainable perspective please add general consistent feel free reach case want feedback current architecture happy help heavy user,positive
hi also tried got problem model run also tried torch encounter lot wondering got good quantization method run,positive
script one step since cloud service computation submit job link work together like slows direct communication keep speed yes platform run training deep learning need set many memory need give start script like like rank set platform mean slow,negative
think reasonable please submit,positive
one minor fix would python none instead python none think could prepare,negative
sorry busy help directly little confused well lined path one first weird thing two number looking log see en dictionary seem right number mean line right found exact match size mean training one data right right inside strange understand correctly assume right opinion may better direct approach repository may clue write python code two dictionary first open one use python record one per line add key check recording key index open line key delete key else print key print tell extra print python tell extra found inside st,positive
hello first thanks lot quick answer lined know model trained dont understand data given data work want training two number looking log see en dictionary seem right seen problem always modify given would like use exact used training reproduce find weird model start understand work ca get working exact match size extend data work weird last precision know added wondering thats need used training instead data thanks lot let know need precision,positive
hint would really like convert library test downstream help highly,positive
shape line count arch better verify many inside error log model trained trained careful path actually inside path checked two exactly look carefully log information size written inside verify well find anything weird please give,positive
script one step since cloud service computation submit job link work together like slows direct communication keep speed,positive
hi may ask data generating back translation like command could please share command also trying generate back translation monolingual data could figure,neutral
third party package install work,neutral
conduct parallel sure speed thanks reply rank data task temperature arch transformer dropout criterion seed change use,negative
mess code follow paper,negative
consider running transformer inference see guide convert disclaimer author,neutral
conduct parallel sure speed,positive
think method split data several translate multiple work parallel way one moment try said,neutral
think method split data several translate multiple work parallel way,neutral
someone else get working issue error running following added git pull git clone git pull pip install pip install import torch list available load ensemble running python,positive
hi thanks yesterday path beam train python ratio output en de ran generate distillation good go hi use command tried many avail,positive
like different use previous memory anyway case per epoch way much would say per epoch already much well yes use link data together need split data right,positive
like different use previous memory anyway case per epoch way much would say per epoch already much well,positive
instead one folder like like chat chat chat make sure folder load one folder among time point validation first training folder valid bin used put inside chat example chat chat random folder since want multilingual model may want every chat folder every language data given order example chat chat folder shuffle done hi split size shard try train model memory node almost memory load one shard data loading next shard memory used first one error need much memory split smaller size,positive
sure code provided data also work coin coin update,positive
problem please let know case run,neutral
would also want know way speeding inference guess may also parallel script great multiple next thing try though may want identify bottleneck ask inspect usage percentage another interesting post maybe something done,positive
yes need original vocabulary used author share publicly way find understand case used generate right converted,positive
need vocabulary associated grateful wo bother course could point direction find,neutral
difference training new one one need add,positive
utilize script inside work generate interactive generate decode interactive encode decode doubt commit search find nothing find knowing used,neutral
intended training model one,neutral
make raw text like original file name name translation file name name anyway one sentence per line line source text file target text file path source path target may want add emit emit path train one based data way prepare data original always write however see go one directory find example purpose,positive
sure given saved file running inference test set work following command path beam task test generate hypothesis test set need score something like work generate metric note use use,positive
dear robin thanks help successfully finished training process could kindly provide test script,positive
hi provide inference script command want test trained model audio help testing,neutral
hi please help testing saved model facing issue testing code error import name please help,neutral
create new release fix let know still,positive
ended cut sandwich encode decode bread awful hack unblocked,negative
use python following command line need also finish reading learnt,neutral
pull request differential revision,neutral
hi could please share solution issue thanks lot,positive
pull request meta employee view,neutral
hi thanks reply belong use model teacher distill original knowledge want test much model student improve distilled knowledge tested add data add extra knowledge student model definitely improve reason wo add extra data confuse whether improvement due distilled knowledge added extra knowledge teacher generate next try different,positive
knowledge looping believe need actually path base model usually base model class class assume get base model get hope problem added path necessary right command line make,negative
get question valid loss come criterion time cross entropy calculated giving target input model generation given valid use create calculating inference create well difference model generation difference score calculation sorry ask big blue gap valid evaluate train little,negative
added added path file override get error message however code running code found loop calling function keep calling resulting state loaded many time memory filled program know think,positive
hello wondering whether able get output provided trying model getting lot,positive
get question valid loss come criterion time cross entropy calculated giving target input model generation given valid use create calculating inference create well difference model generation difference score calculation,neutral
thanks telling may look difference score though pace end week decide much training best higher score always appealing well evaluation training result without reason problem ask difference valid evaluate train success time known normal guess key problem classmate tell valid low thank,positive
thanks telling may look difference score though pace end week decide much training best higher score always appealing well evaluation training result without reason problem,positive
first probably wo helpful feel free ignore time would mind knowledge understand teacher model trained data lot unlabeled data one use teacher model create student model trained data student model meant distilled version teacher model believe student supposed get data otherwise need teacher since estimation may close enough original quality student achieve score original validation data understand data defeat purpose one improve student model although possible extra data approach assume data teacher model good teacher model compare student bad student model human sense come right learning size noise different original one let alone data critically different different telling one good would say resource time try different see best,positive
situation tried following search find give one one run generation fix need well tried change guess get valid blue low evaluate may get little low valid blue train model better key problem train valid get evaluate blue thank,positive
trying local extract file strange certain work,positive
hi forgive making clear picture loss student model save loss figure teacher model figure red line train loss blue line valid loss orange line important teacher model loss figure model fitted train loss valid loss close student model use learning teacher model train model like think would defeat purpose method extra distillation data,positive
believe current normal provide feature command line sure implementation data huge size decided much memory data total one way write custom class read new result write custom task class utilize class import custom code use also need search use append every one file take line new obtain like line data get fine training write collate method create batch training order make sure batch contain correct ratio data among different region also want add two new command line argument line ratio among custom task add new hand written data huge mix data split multiple option sample write outside may also use language data mixture correct ratio training provide multiple data folder train fashion use command like train valid model get first epoch form second epoch run next epoch must first folder must rest need folder order current switched midway valid also mixture first one lot extension also done inside command line second one extension lot outside advance may also think third way write utilize multiple data folder first also good way understanding create thank try let know go hi experiment going,positive
repository used generate either edit method tested code anything wrong please tell self note wrong truncate fix though impact inference used compute loss print length truncation may wrong print length truncation source return copy make new class new class name new class class new use class method need edit corrupt local import new task class another option conveniently enough token count sentence change length add break big enough downside command line write length,negative
situation tried following search find give one one run generation fix need well,neutral
error log saved inside believe implementation problem path whereabout may try command line tried please tell result meaning may edit like input path model important distinguish string attribute copy put model use directory file name need instead make program run given,positive
different console anaconda create new virtual environment still use git clone install truth told error different issue like complex environment said visual error said found,negative
use specific version hardware source install making sure beforehand,positive
bug explicitly require forward self class forward self perhaps print type understand forward,neutral
folder added still get error ca figure file name attached whole message image,positive
tried run command prompt administrator faced different error pasting last portion long message error code running building extension error visual greater get build end output note error likely problem pip error building wheel building wheel done wheel directory successfully built build error could build install also getting similar trying install older version like also latest visual problem either also pip wheel causing issue well assuming,positive
like requirement administration right click run prompt administrator fix problem,positive
decide make sure copy see fine,positive
comment better worse performance chosen personal preference stable control training well memory usage,positive
glad know coming currently familiar rookie find easy extend little bit hard personal perspective detailed thorough document code decomposability want,positive
hi familiar teacher student model teacher loss red curve represent teacher validation loss also several half transparent mean aside would like say quite common see validation loss blue one drop first several go slightly later case guess learning rate increasing distill data make student validation loss drop little,negative
time since look code remember typical meaning one reduce run,negative
facing similar install pip install pip install error pip install deprecation future pip version change local built without first temporary directory recommend use test new behavior becomes default pip remove support functionality find discussion regarding build done getting build wheel error error command exit status command complete output recent call last file line module main file line main hook file line return hook file line return file line file line compile code file line module privilege client warning file command exit status check full command output error command exit status check full command output warning pip version however version available consider via pip install upgrade pip command help o python,positive
hey understand use could mind explain,neutral
making easily nowadays always,positive
thank issue taking look,neutral
hi facing issue find solution,neutral
hi sorry bother provide training used unlabeled data,negative
would solution work almost old time maybe better way one perhaps,positive
thanks reply want lexicon free,positive
hi following provided super helpful thank much model trained many stopped following error mean model training error need fix recent call last file line module file line main file line main file line main train trainer task file line inner return file line train file line inner return file line raise command specify criterion stop training right know model complete training arch task criterion dropout seed simple list like trained bit epoch stopped think normal used much data parallel data million sentence may ask one final result training maybe,positive
class post calling method call constructor whenever call path beam task could resolve,neutral
thank much help found older version branch work model work,positive
hi tried reproduce nat small data teacher model nat around tell performance poor script task criterion arch noise dropout seed seed en test task path beam know appropriate give advice something wrong,negative
need specify lexicon file within command lexicon case python task path subset criterion letter lexicon used model like every word label transcription file write like,neutral
hi good know coming think integrate train could useful,positive
similar question dictionary dictionary used paper size model size please confirm right dictionary padding empty dictionary end never used furthermore running inference code error dictionary size size directly dictionary convenient way fix,positive
hi merely beginner efficiency use like open loading data well know guess still one model case may also want run multiple also believe high much memory slows would mind telling way,negative
addition question target translation language taken option lot,neutral
flow creation could separate landed first create flow file met error refusing allow personal access token create update without scope could help create flow new file current line run pip install dev,positive
find solution need delete set number,neutral
finally problem sure used relative path solve hi also met problem could please tell specific operation thanks,positive
honest tested side guess give following task command used generate switch generate interactive add anyway case believe default task read data correctly reason got random language model special token identify language pair used normal translation task need,positive
issue file normalizer model,neutral
leave alone meant used document way give get error raw text,negative
leave alone meant used document way,neutral
would mind test guess found reason find around line end fortunately comment line default unknown string instead use somewhat verbose alternative unlikely appear real reference get split multiple alternative hand scoring replacement code found either want test argument test may work code flow search find give one one run generation please let know work way upon change mean number still fit unlikely different total add en de raw text found test exception could infer language pair please provide explicitly en de found test image dont know test prepare data command sorry change far thank,negative
wait something remote pip find package use may tell environment go one find like found folder open use editor replace use vim use python test whether work know nothing sending pull request guess issue like work public library would nice teach future matter run believe best install option git clone repository current directory open pip install install local want upgrade git pull update till main branch famous found,positive
hi thank much reply could explain bit fix command pip install use,positive
would mind test guess found reason find around line end fortunately comment line default unknown string instead use somewhat verbose alternative unlikely appear real reference get split multiple alternative hand scoring replacement code found either want test argument test may work code flow search find give one one run generation please let know work way upon change mean number still fit unlikely different,negative
guess give around given train generate addition used slightly different like one exact valid one thank try get change second also try best last get change,positive
generator interface high interface probably exportable least today exportable transformer back see,negative
hello question answer question,neutral
could feed smaller recombine,neutral
found way lower infer latency thanks ahead,positive
available change result vary option input truncation always place around exactly sentence boundary boundary next sentence already th like default input length set model different value opportunity translate longer input,positive
thank one question guess one learning give open many see last since working may still better increase fully utilize memory luck may keep wait enough time respond time yes guess may improve inference speed efficiency generating one sentence quite low way already sufficient might vary different usual number see,positive
hi model think utilization high suspect setting trying use though know importantly want use sake setting beam size high useful easily slow inference large margin think increasing batch size may reasonable approach think bound batch size going address,positive
yes instead fix enjoy replace,positive
quite beginner yet big model utilization probably model size guess like never watched utilization guess high due communication data one batch transferred want use raise beam improve increase speed believe provided function make one simulate multiple probably wo beam quite eats lot memory,positive
guess give around given train generate addition used slightly different like one exact valid one,positive
probably wrong given error log size however new data size mismatch param shape shape current model size mismatch param shape shape current model size mismatch param shape shape current model run path path en even raw data dealt possibility give different frankly speaking believe yet work would another trial identify reason create several make tiny learning one load,negative
input need use quotation mark wrap work thank much quick reply,positive
input need use quotation mark wrap,neutral
show detailed log profile criterion model space composite lamb nag cosine fixed manual step triangular scoring meteor wer task task raw lazy curriculum curriculum none bucket none o path path quiet beam beam sampling ordered unordered temperature temperature hard soft ensemble vote patience patience arch arch default tanh linear transformer conformer dropout dropout static uniform normal static uniform normal random tail none char data error unrecognized,positive
thanks pointing one line input missing please add inference code update soon arise another error error unrecognized,neutral
thank much nice try said,positive
general given train model specify maximum source sequence length handleable model check model,positive
note technically breaking change,neutral
meant regular text course separate besides represent source text even long independent total satisfy network truncation st text position long sentence boundary position maybe specify upper limit translate,negative
say mean easily surpass token might get truncated,positive
thanks pointing one line input missing please add inference code update soon,neutral
exactly ca find section,positive
copy paste transformer model use may get publicly officially actually model easy long afraid auto may copy adjust forward support new class deal inside forward well nothing say stage really want handle feel free ask detailed answer long help,positive
yes wrote new trainer used model training said need set new model know tutorial model really dont want set model scratch one tiny change position model,positive
sorry misunderstanding case write new model also come train model write new copy write new everything need still use trainer write new task maybe new well use let notice directory written import import folder folder inside directory import import o file sorted name file directory name folder name name way mostly make directory new module saw someone said linear instead still,positive
find install apex completely reinstall check version,positive
like instance python dictionary type case added python none else import type get type instance python dictionary recommend use new directory almost directory latest version distributed inference faster enough try,positive
due fact trained one sentence time cut translate one one make work,negative
hi get segmentation fault core run python use default setting still got error cry,neutral
hi may ask solve problem python got segmentation fault core,neutral
thanks reply back translation project need feed output first model second model convert output first model vector want use vector input second model training use convert index wondering whether possible pas vector input model,positive
may make data binary save like cut especially want share well script helpful exact data structure official support implementation different usage also increase complexity inside like people different implementation philosophy may find evaluation vary,positive
input exact turn first create zero assign given efficiently however believe actual waste much knowing alone sufficient wish progress,positive
honest may get said environment time beginner help suggest take question already great way need reply since helpful noble report issue finished say must least one difference assume used console used sure environment also successful command command look different data know since add may help understand situation data run environment yet got success failure must something,positive
need maintainer approve running,neutral
sure written main flag enable glancing sampling given ran data correctly set folder able run training run python simple arch criterion dropout noise task similarly vanilla python simple arch criterion dropout noise task see main enable also combined given code added stated python simple arch criterion dropout noise task please see paper course little specific setup number batch size might need tuning effectively available guess would need reduce since train multiple result batch size quite large let know case run strip internal hopefully miss anything,positive
hi thanks great integration nat could please provide example show train model,positive
python valid thank already finished,neutral
issue tried reinstall work way solve thanks,positive
thank effort help solve issue apologize already issue possibility nothing work log first part try log running code prepare following example speech translation take logged run console environment ca understand different piece code environment apologize question data piece image image image tree directory image,positive
hi facing issue found way fix yet,neutral
better way resample audio,positive
hi figure run image classification task,neutral
ran problem fixed line,positive
also problem lead problem later solve,neutral
determine raise issue always good start read error log last line said directly search general want post question offense freedom ask around found may help author last long due default length check whether data written one one line raise acceptable length site help still better ask done basic searching effort deserve help offensive rude tell would first wrote factor data first got log surprising felt kind sad well also checked log different one one default best might happen environment different,positive
show log run code logged log running command log training input pad name log log loading corpus log loaded log log pad log log log recent call last file line module main file line main process file line process file line file line train return file line return internal run code printed console output follow log running command log training input pad name log log loading corpus log loaded log log pad log log log log log alphabet log final character log done log making suffix array log frequent sub log seed log input log done log em training log em log em log saving model log saving think really issue,positive
thanks explanation guess know well part get know nothing special sinusoidal embed weight parameter guess simple find embed found,positive
given definition sinusoidal al page matrix dimension depend maximum input length total number reflected implementation one case static method within forward model input whose length maximum input length special case built although first yet explain trainer move sinusoidal line since registered buffer model see ca command,positive
change made export transformer model could share code lot,neutral
hi thanks code explanation project bit special like iteration model generate sentence model learn model iteration said need call generate function frequently case guess create beginning use batch,positive
might already case problem loaded need default designate one file path argument everything fine,positive
get complain generator provide user model following one generate method generate sample generator note every task copy little adjustment take batch input given model forward sample one batch data model big size may cause model work generator whole used may improve generation speed generator none task build one task optional force begin optional force include list optional beginning sentence token default list sample size list inside list generate output tensor score float attention tensor alignment tensor tensor use tensor convert actual generator none return sample use make back normal give correct dictionary like return list data according return load create one best official example read handle user,positive
welcome shame expert implementation especially around efficiency opinion first apologize use fixed sinusoidal change value according input length unlike embed change start forward case every forward good embed embed must forward onto,positive
consider given information really scarce following gave got error data given console got place different may swap data run code difference command difference succeed one may use editor compare even might go ask really want solve one help read file repository like start searching log follow flow first aim load got,positive
thank reply even fixed sinusoidal need like every buffer used model forward indeed explain previous message question done manually,negative
got error someone please look,neutral
piece code give two different,neutral
found solution facing issue tried many way still ca solve training turn,positive
found solution meet error,neutral
able resolve issue yes,positive
believe current normal provide feature command line sure implementation data huge size decided much memory data total one way write custom class read new result write custom task class utilize class import custom code use also need search use append every one file take line new obtain like line data get fine training write collate method create batch training order make sure batch contain correct ratio data among different region also want add two new command line argument line ratio among custom task add new hand written data huge mix data split multiple option sample write outside may also use language data mixture correct ratio training provide multiple data folder train fashion use command like train valid model get first epoch form second epoch run next epoch must first folder must rest need folder order current switched midway valid also mixture first one lot extension also done inside command line second one extension lot outside advance may also think third way write utilize multiple data folder first also good way understanding create thank try let know go,positive
inspect around find console sentence point might problem might data gotten corrupted,neutral
program work console following log loading corpus log loaded log saving model log saving printed,neutral
fixed value input length input tensor embed like constant function since trainer never touch guess necessary put onto,positive
check pip list use console tell,neutral
believe current normal provide feature command line sure implementation data huge size decided much memory data total one way write custom class read new result write custom task class utilize class import custom code use also need search use append every one file take line new obtain like line data get fine training write collate method create batch training order make sure batch contain correct ratio data among different region also want add two new command line argument line ratio among custom task add new hand written data huge mix data split multiple option sample write outside may also use language data mixture correct ratio training provide multiple data folder train fashion use command like train valid model get first epoch form second epoch run next epoch must first folder must rest need folder order current switched midway valid also mixture first one lot extension also done inside command line second one extension lot outside advance may also think third way write utilize multiple data folder first also good way understanding create,positive
sorry help since never speech translation training believe used editor feature program program work console say following log loaded add log inspect may also want see wish progress,negative
actual reason actually see raw data thus understand structure also require run run tiny size model order produce data assuming reading translation running bash obtain folder open shall see data german data find every line one data corresponding line also find folder original data fact data format raw data written way must first either line must one entry data line data file must correspond line distinguished turn data binary reduce file size read correctly also turn binary data first example provide multilingual translation section reuse specify create given data actual big project run want program progress pip install remember add running like command line run people want train generate work use editor set easily check break run small size model like dimension even smaller,positive
rate limited u commit status success rate limit user id like click,positive
master today install python pip install successfully,positive
thanks run fail unrelated like flaky job code nothing o would able kick another run,positive
would recommend might require slight code know need help please show increase take input,negative
note need maintainer approve running learn moment would help run,neutral
always meant temporary solution thing course maybe soon,neutral
would able try fix,positive
also resolve issue still dont see except one doc,neutral
way fixed error primitive type thing monkey allow set object value must wrong version different type error valid bet name thing fixing get past enter exit general agree gon na stuff like monkey private need script work install,negative
way fixed error primitive type thing monkey allow set object value must wrong version different type,negative
believe ran script pip install working found running fixing next error strict flag compose raise set full trace file line wrapped file line return file line node file line super file line value file line value file line return value file line raise value primitive type task,positive
ah sorry mean torch,negative
hum file main find,positive
thanks facing blocking issue running simple torch hub file line module attribute requirement already satisfied test catch regression,positive
posterity create static dictionary strategy way always,positive
running issue ever find solution,neutral
hi may know support added model appreciate,neutral
install error fatal error file directory include,neutral
thanks work meet could show full command model hi eventually manage model without error luck well issue generation though,positive
facing issue default python version version python version via command python afterward install pip via command apt install python pip install upgrade pip following error facing pip install error warning command exit status python check full command output error could find version requirement error matching distribution found surprisingly error resolved via command pip install upgrade solution originally,positive
hi luck model much difficulty well thank much,positive
also problem tried solve problem use load model,neutral
also problem tried solve,neutral
facing issue text summarization text multifocal patchy homogeneous ground glass attenuation septal thickening lung multifocal patchy homogeneous ground glass attenuation septal thickening lung,neutral
think problem incompatible elastic launch necessary use launch could please elaborate able resolve issue torch getting waiting store based barrier,positive
still getting python pip void able run pip install,positive
finally problem sure used relative path solve,positive
training process large machine try use parameter like thread utilization instead,positive
work version solution follow git clone activate pip install reference,neutral
came problem number set match python,neutral
also forgot put space vocabulary,neutral
help model translation task custom training given work well specific hi question solve,neutral
problem example unclear would much better see toy simple format could agree,positive
tried add decrease warning still exist warning ran memory exception memory tried allocate mib gib total capacity gib already mib free gib reserved total warning recover pas,positive
issue anyone share utilization,neutral
official documentation still include information logged,neutral
another question provide training split long short assume used split purpose training validation right mind performance model,positive
hi update want use metric best validation step seem end implement already one,positive
hi update see model sentence prediction task summarization well ca find similar script summarization,neutral
thanks filing issue fix try merge soon,positive
still know extract however make work example following add hub replace feat feat array torch tensor run,neutral
hello tried fine tune issue command size added script data make work problem loss decreasing converging wondering could data file extended data make training work thanks lot,positive
issue period inactivity issue still present latest release please create new issue information thank,positive
pull request automatically marked stale pull request still relevant please leave comment example bump keep open sorry able yet contribution much,positive
first command actually worked correctly also implementation,positive
issue automatically marked stale issue still affecting please leave comment example bump keep open sorry able yet new additional information please include comment,negative
hey sorry like question fell could maybe try use forum instead,negative
think issue still worth handling training inference different due issue,positive
function guess would cumbersome work case transformer first make sure place train data word behind vocabulary original change original order vocabulary second add code beginning transformer function starting point third set flag reach vocabulary process would rather cumbersome work,positive
like driver problem tried run point work train problem work normally solve,positive
hyper transformer model still default set model think default hyper parser parser,neutral
hey post command worked thanks,positive
would please close issue problem thanks,positive
recently ran issue case problem data older version version training script fixed problem,positive
facing issue anyone help fix,neutral
hi got anyways thank kindly help really appreciate thank,positive
tried scratch turn loss normal scale yes tried scratch many different clip norm work set based description paper know said better performance always set section author said effective batch size around think set hi thank least try second one regarding training tried scratch turn loss normal scale set based description paper know said better performance always set thank advance,positive
running issue install instructed current,neutral
pull request period inactivity issue still present latest release please ask pull request thank,positive
hey thanks used wrong work,negative
hi thank least try second one regarding training tried scratch turn loss normal scale set based description paper know said better performance always set thank advance,positive
hi yes actually two think detect overflow operation address pretrain model reload training please reset load model setting second one somehow tricky work,neutral
hi found solution facing problem,neutral
hi find mismatch multilingual input source however multilingual model style seem different well however multilingual setting source code hi mismatch,neutral
flag detail recommend see think flag work alone,neutral
never tried use think easily implement guess good ca use audio use audio,positive
dictionary file official dictionary file used paper letter dictionary make dictionary data dictionary char letter word,neutral
idea ran today anybody may help future code worked python version torch version,neutral
hi issue loading lot found following solution feasible hope help pip install git clone pip install quiet pip install quiet best,positive
hi command use language model still work correctly used dictionary open run single audio file format data format run command,negative
issue still open work issue thanks,positive
know dictionary used model,neutral
hey sorry access possible run command possible would great could post command model good single audio file without language model would super helpful community use could maybe check see without language model work correctly,positive
think output word thus empty string bunch inverted,negative
hi tried model following command good could please recheck setup thanks python task path subset criterion letter,positive
use latest version instead pip package,positive
pip work thing differently ended successfully,positive
found source multiple choice reason,neutral
hello similar problem output text transformer almost input however use another test set work well find solve problem,neutral
received error install git clone recursive fatal reference tree unable path recurse path,negative
data every thing go smoothly get data directory forget command absolute path data directory,positive
please try base model match al differently particular adjust learning rate automatically based require peak given explicitly hi could please share choosing small attention need thanks much oh see,negative
hi also got error solution information put log handling exception another exception recent call last file line module file line return task file line super task model file line file line return builder file line file line return file line partial file line return file line head return request file line request return file line request resp prep file line send request file line send raise wrong version number,negative
thanks ping look get back,positive
bump really checked many time blank,positive
second slightly different git clone remove include add include include include include include include define static err err return implement return err static protect return protect protect else protect return protect static return return void void handle void map warning push warning disable protect warning pop unsupported flag protection return handle return null protect null null return map map null return return map void return return void return return void return return void return return void return return define allow use specific later define change appropriate value target include file include include extern define define define define define define define define define define define define void define define define void void void void void void void go back python install user yes annoying really globally used package fully untested hello solution still error fatal error open include file file directory error command visual exit code suggest action please,positive
please try base model match al differently particular adjust learning rate automatically based require peak given explicitly hi could please share choosing small attention need thanks much,negative
thanks help work thank,positive
machine answer either use project environment ex run administrator thanks confirm running following command git bash administrator worked pip install,positive
hi thank helping question add new word language model model need train need learn map,positive
use high version could change two add two code include define change must tensor must tensor successfully build kernel hope successful experience help well environment version main version o python version version compilation release build,positive
different projecting class evaluation check paper,neutral
perfectly understand meant finally solve problem wrapper model load model inner code load hub based mismatch model could totally load local model could encode sentence well thank guideline though question idiot really helpful solve one close issue could please explain bit issue,positive
hi model trained separate branch bunch experimental model loaded code please use official get close model,positive
hi ca find talking anywhere also may ask find false set true either,negative
able monkey patch use method log metric get data plotted code code extra environment variable base progress bar used progress bar main trunk would really helpful python class self self return iter log self step print self step self optional none optional none epoch optional none prefix optional none optional none optional none optional none optional none optional none optional none optional bool false none none handler handler simple bar epoch prefix none bar epoch prefix simple bar epoch prefix bool bar epoch prefix bar bar bar epoch prefix else raise unknown log format bar bar return bar,negative
thanks lot advice rest great discussion prune model actually fine tune german translation task complex text simple text work however actual text one dot one comma experience similar usual translation pruning,positive
choice layer gar module second layer indeed layer used see unlike choice layer paper sense explicitly note layer thanks feedback,positive
suggest instead default value way want set far overcome issue still work instead,positive
thing paper used intermediate layer predictor however far tell layer neither convolutional gar top layer argument number latter understand correctly seem dimensionality however correspond provided model paper definitely wrong check file speech space also layer detailed paper entropy across time rough metric quantify whether output across class found across time highly similar across different result get something like choose layer entropy lower pretty much always class decrease gar layer argument making think default get layer none definitely used downstream course higher available give nonsense plot layer output straight convolutional best shot would thus layer would still cool know whether correct,positive
need add argument script note different accept different,neutral
write resolved facing error,neutral
maybe use following file use tool first convert format file format one advance command python train dev test zip range split list split progress enumerate text progress path path apart section remain still however could test training procedure yet could guarantee process could still reproduce correct result,positive
training automatically end addition way set training complete,positive
news regarding error problem downgrade python moment python pip install o red hat enterprise,neutral
need memory loading training scratch,neutral
update initial question could run used however result lower paper score reproduce paper score properly,neutral
thanks lot reply trying something class built fork would better work see put code also somewhere inside fork train model,positive
ca reproduce accuracy paper following script bash python model drop final accuracy got provided sanity check provide run evaluation,neutral
add report problem image,neutral
could also please consider fix,neutral
facing issue beam multiple,neutral
problem tried upgrade torch version respectively help,neutral
official code code briefly verify conform implementation go deeply resolve missing,negative
code nothing guess answer yes raw input line split clear dividing line split sentence two part hard implement,negative
struggling problem solution use composite used unsupervised composite generator null false fixed discriminator null false fixed create generator discriminator best,positive
resolved latest main branch,positive
thank much finally calculate finished advisable publish depend unlikely reproducible paper consistent across research instead use standard still used internal consistent thank friend,neutral
right apologize see send thanks right lucky command lucky learn thank much yes right got python output,positive
forgot ran code part apology know use try add help feel lucky case run python help might tell something little hard read also write new python want get familiar new best way read explanation second add print code never used sorry wo try time guess run like python output point epoch rename help set try find input average last many set try find path input average last many,positive
wonder rest part translation normal one show first open normal print content translation different edit maybe custom model add detailed calculation progress actually transformer rough way last information get translation believe get,positive
right find python import import import torch import o import model iterable string load string various key returned correspond string parameter torch none none state lambda first none state state model list none raise list found note clone case parameter else model return assert path else path none none raise exception found need least print last none sorted entry entry last entry return path sorted else return path sorted else return path sorted main parser tool average input produce new file output new path set try find path input average last many set try find path input average last many set upper bound use would print none false none true none assert none none assert none none combine none last last else last none none print print print print print finished writing main,positive
run directly environment go step step one last step error ran use dual system mean write script last step written python ran code first time know use compiler like yet write program command line need configure first try later copied data model flash drive put let show,positive
exaggerate mean sometimes expression suitable first small group like share interest new python recommend add lot print variable show progress program since repository edit add print line actually need line notice get one string back line see help file guess program like directory model alone also use code editor like well example tell defined run python click run button add ask program stop line decide check little bit tricky though little advice new,positive
thank letter mean people express several addition new question next step want ask whether know relevant next step influence evaluate model following command export average last python output generate translation python data path beam false cut cut sort cut command python output made first step following recent call last file line module main file line main file line found need least exception need least five model theoretically calculate average value five know ca run ca find relevant information day matter matter much fill seem work know finally thank reply,positive
apologize advance helpful enough test always search repository find case may need point already data right know raw data split train valid test python split split done code assume know basic bash python data contain like write python program split program error may solve post clarify error open check finally done,positive
equation talking satisfied two different relationship relationship established sorry understand part talking feature dimension know equation explain relationship merely talking decided multilingual translation general people use multilingual use think useful new language born multiple propose one multilingual may prefer mixture different rather switching two new language,positive
question actually original pretraining able pretrain according ca find,positive
first thank reply trying add code turned wrong said would right add secondly german translation piece open source code run author left command join dictionary trying upset thank much help yesterday finally would like ask equation talking satisfied two different relationship relationship established one said suitable multilingual fact quite clear implement think discus together nice communicate thank,positive
long original final data line final format pretty simple case according check raw data file data next encode thus first may try split file see anything wrong may need write python program adjust data end need make sure final data text one data per line token space dictionary case want use original care give procedure similar write deal interactive utilize type like path add new type wrong check log carefully find unusual new,positive
sorry wo helpful curious much loss loss actually get model also tried official example well know one,negative
well correct error unequal length strange idea want handle different language share input dimension german input feature pad feature dimension german dictionary copy paste one text thus target size create one data faster meant multilingual task guess,negative
need pas like try official way get exist official link nothing,neutral
already used successfully last year tried generate translation current version however get size mismatch size mismatch weight param shape shape current model older version thought could work got another error line epoch key could help,positive
found set false model whole transformer position setting better one paper share position thanks lot,positive
fix change maybe work well,neutral
try like right thank get architecture model write,positive
try basically path common like remember transformer ago faint memory regret left happen succeed please let know well note generation cross entropy loss exist length different cross entropy need two sequence length compute loss nature,negative
perfectly understand meant finally solve problem wrapper model load model inner code load hub based mismatch model could totally load local model could encode sentence well thank guideline though question idiot really helpful solve one close issue,positive
apologize misunderstanding believe encode nothing pretraining point return model inside class see encode decode another question due consistency input never get maybe something wrong also verify add comment involve team word generator guess used inference entropy loss call use actual compute thus never used also check class confirm,negative
first sincerely thank really familiar said trained use building exactly shown also many replacement saw log saw used model true embarrassed well know convert form actually problem port model load model worried procedure whether training well look log problem gradient loss mean kind non business pretraining thanks,positive
python probably bad luck need,negative
need run another round test notice lint error fixed main yes thanks branch rerun,positive
need run another round test notice lint error fixed main,positive
also share log see lot may also check work find decide written may want change learning rate way initial loss also need automatically append,neutral
though never utilize model encode decode kind confused want tell foolish deal raw text data see never language token id train another language train different embed dimension allow training first text following example speak like difference space like line frequency though matter obviously space data example get tensor tensor last appear finished log also many want search level finally use,positive
first tried model might already find answer case check official example even older may also find lot search multilingual advanced editor like may also help find direction every task implementation found every implementation inside advanced editor like grasp task model work,positive
hello output log meaning wall wall thank,neutral
thanks take look would able resolve conflict,positive
thanks perhaps would make sense move directory instead,positive
thanks reply think current description shown make type float pretraining support decimal label rate otherwise give label rate want change title description,positive
thanks reply think current description shown make type float pretraining support decimal label rate otherwise give label rate want change,positive
everything merge chance could update description,neutral
hello question already got appreciate,neutral
find new want learn please read necessary really tell main flow work lot useful class embarrassing read know way add special normal case want add raw data must already inside like ate apple regret since automatically already add top one line pas special want output write another python get rid,positive
instead one folder like like chat chat chat make sure folder load one folder among time point validation first training folder valid bin used put inside chat example chat chat random folder since want multilingual model may want every chat folder every language data given order example chat chat folder shuffle done,positive
used sharded model might however believe add like make support class make notice,neutral
model architecture posted command model million run version confirm around million believe parameter size decrease please copy normal version version find strange work fine small big transformer like encounter error flatten param single param guess seen able continue last see make feel continue training add make continue way install right,positive
context internal research project fair use aim given logging functionality available either aim team quickly sent,positive
pip install solve question,neutral
alright wrong need masked fed network vision implementation might minor left apply later main body work done,negative
model different case actual model size model size log said may confirm also model size even multiply model size match total mode continue training last,neutral
also issue object attribute update solution,neutral
thanks answer code local manner operating run according documentation work fine mean multiple sub setup following one single experiment training time transformer global manner time training transformer would call problem also opinion code would also store run object call end training would keep secluded outside library,positive
hello third problem also want modify loss function,neutral
python issue turned pip version pip work fine pip error,positive
hey work around internally today although worked today run per process however could today multiple sub feeling adventurous,positive
class inside causing error new attribute missing showing error key used pas create class attribute,negative
found nice implementation exclusively worked vision part,positive
finally worked problem related liking variable device image,neutral
making progress much image,positive
code snippet get following error input type weight type input tensor weight dense tensor code used python import import import task false model generator text un test sample task text rate task model generator sample,negative
revert work fine add change later mar eric liang wrote alignment version working fine think confirm revert git whole reply directly view triage go mobile android id,positive
git clone activate pip install working operating mac specially yes tested,positive
git clone activate pip install working operating mac specially,positive
install develop locally git clone activate pip install,neutral
currently working review implementation according paper think vision loss calculation method two one masked image second visual smaller image discrete variational auto like task model predict based masked based understand paper one image model hypothesis method would transform input image according paper random crop horizontal color split image size image convert visual flatten tensor apply rest like dealing discrete glad know hypothesis correct addition would mask token id suppose reserved image manually set random number boundary best,positive
hello inference time around per core processor second per sentence translation easiest solution distill knowledge smaller faster architecture instance currently building mobile friendly version model knowledge distillation train smaller architecture transformer smaller layer width improve latency expense accuracy note tried received inadequate also exploring architecture natural language inference glue lower latency phone involved solution port model framework inference latency framework used many suspect model size might still need reduced though,positive
open aiming fixing particular one work get accepted use dependency environment,positive
hi thank much appreciate help mar sultan wrote sorry slow reply actually first time someone pointed issue command set original training run though tested recent may need fiddle bit python data mask task arch dropout criterion seed rotate insert hope think remove cause training finish even also omit also batch size batch world size length also think mask value base reply directly view triage go mobile android id,negative
hi yes trying reproduce far good poor performance hello wrong wo generate result poor found solution alignment version working fine way many train training st might different training good already note batch size important batch size given enough definitely use directly increase batch also gradient unstable use lower something,positive
sorry slow reply actually first time someone pointed issue command set original training run though tested recent may need fiddle bit python data mask task arch dropout criterion seed rotate insert hope thank mike u code think remove cause training finish even also omit also batch size batch world size length also think mask value base,negative
met problem follow try step data en de problem came recent call last file line worker result true file line file line line summary file line file line else exception direct cause following exception recent call last file line module file line main file line main file line file line file line file line file line get raise problem python tried avoid still meet problem solve problem,positive
guess similar problem size mismatch issue see whole thread anyway similar case add round multiple efficiency dictionary size multiple get probably able move manually add language dictionary extra according code,positive
path beam task test command fine tune model getting size mismatch error error loading size mismatch param shape shape current model size mismatch param shape shape current model size mismatch param shape shape current model size model size matrix size matrix could please help running issue able figure problem,positive
place file current directory example root root cat import import train root task arch,neutral
training code found reason example mode alpha beta something like see context frame weighted sum total context length equal length implementation many context near tail may reason poor performance,positive
currently possible use comet,neutral
trying reproduce attention low fixed bug still thanks advance hello found solution,positive
also gradient overflow note gradient overflow gradient setting loss scale,neutral
two indeed lot handed,neutral
hi yes trying reproduce far good poor performance hello wrong wo generate result poor found solution,negative
hi noa thank pull request welcome community action order merge pull request code require sign contributor license agreement seem one file process order u review merge please sign behalf someone else employer individual may sufficient employer may need sign corporate tooling perform afterwards pull request tagged process may take hour please give time u received error please contact u thanks,positive
sorry slow reply actually first time someone pointed issue command set original training run though tested recent may need fiddle bit python data mask task arch dropout criterion seed rotate insert hope,negative
hi could find request review could please tell need would extremely useful idea thank time,positive
problem pretrain model error unrecognized command python could give advice use train extremely grateful problem also faced problem,negative
pip install yep working doubt work like,neutral
issue code maybe path correct,neutral
got link believe click link broken luckily script generate going try see work,negative
hello slow may take broken,negative
update torch version try command,neutral
show support please thank,neutral
data fixed length pretty fast per second change fixed length,positive
hi problem yet met one,neutral
think idea example help u,neutral
hero struggling dynamic shape issue really turn linked variable provided training addition bucket cap argument another option consider accelerate training try smaller number like see,positive
used following code python import flask import flask request import pickle flask home return predict rendering return salary output direct request print call data data data generate print call return import logging import import math import o import import import indent import iterable list optional import torch import import import import import import import import import import time import name message logger model none main global model reduce per sample context window size loading model false rank rank true making work sized across true else false initialize task current task load ensemble model optimize ensemble generation set source model scorer want enable padding layer calling assert model sum generate text print based text global model text print model output print model print output print text print print return print call main main print call main parser parser port print port make python import import import time session data resp result await return result main session number range port number data love session data await print main print,negative
find used wrong model model used one,negative
sorry mess change branch name fork,negative
maybe option remember clearly sorry aware error individual access reply directly view triage go mobile android id,negative
aware error individual access,positive
thanks quick response interesting showing memory utilization job go rest like already latest version length extremely long one many could cause one node could check node believe latest version output somewhere find node,positive
thanks quick response interesting showing memory utilization job go rest like already latest version length,positive
able solve issue could try latest kind hanging causing problem hanging one like long output version mechanism stop one hanging power consumption stuck kernel mode something like waiting respond,positive
find reason use actually use python self queue server accept therefore need merge word find first merge prior remove queue send server merge sub word full word segment send return force finish segment none none hyp none hyp hyp return hyp index token index segment segment else range segment segment return else segment return none,positive
model different case actual model size model size log said may confirm also model size,neutral
flatten param single param like guess least explain,negative
facing similar issue want load model directly instead worked eventually,positive
hello tried use evaluate finally get result however bad reproduce first prepare data example trained model epoch evaluate tried use raw data part evaluate model index prediction da die fa as die land ger reference da e da die source however committee allow order shut instrument low visibility metric latency al dal score also poor al strange know happen quality latency al dal question standard data preparation predict reference right thank,negative
even worse following train full trained model epoch shut slow st model epoch stop early also slow evaluation use split use evaluation connection testing set large result poor anyone thank evaluation quality latency al dal,negative
identical branch instead main,positive
unable perform evaluation inference model still facing issue tried several major listed installation setup done following link setup python binding code import transcriber transcriber transcriber dictionary print error python use functionality please install python use functionality please install recent call last file line module transcriber transcriber dictionary file line file line transcribe generator file line return file line super file line name defined comment flashlight modification binding similar script received installation code import torch import model task model model error recent call last module self name return name raise object attribute type self name self name value union tensor none object attribute comment ca figure solve error installation done properly script executed inside main directory code python task path criterion letter comment various able figure exact task task defined evaluation argument need raw ca understand exactly format data prepared error need file didnt got information file consist,positive
hello could please show u training script,neutral
want add condition take place version,neutral
hi getting error trying translation running command de en hi location export hope,neutral
compatible version later many u still possible revert,positive
hi getting error trying translation running command de en,neutral
one need install solve could nice thanks,positive
try run pip install,neutral
thanks sent march author subject restore pretraining issue think add one line train always reply directly view triage go mobile android id,positive
think add one line train always,neutral
able get generate text,positive
eta update try modify code request anyone suggestion rather reproduce work,neutral
hi yes trying reproduce far good poor performance first suggest looking made breaking current code assume working need agent next target language example german de need update self method merge routine python self queue server accept therefore need merge word find first merge prior remove queue send merge sub word full word segment send return force finish segment none none hyp none hyp hyp return hyp index token index segment segment else range segment segment return else segment return none may also need set would matter also use setting agent guide evaluate bash source target word agent output output,positive
reproduce met problem could please give help discus package model al following guide trained model know evaluate another guide know prepare guess following guide know evaluate,neutral
found problem one branch latest torch locally built source one,positive
also applied reduced speech setup,neutral
hi solve problem please,neutral
believe issue set apex set everywhere trying everywhere,neutral
thanks yes known issue current conformer implementation definitive solution work turning slow another alternative try increase effective batch size increasing value,positive
hello made prior could take look verify,neutral
hi think got copied meant one question frame size case found nowhere thank lot,neutral
solve missing audio audio pretraining get included,negative
solve missing audio audio pretraining,negative
met problem python problem tackled yet,neutral
still getting error key running code import torch import model task model model package version location decorator pip six tabulate torch tornado wheel problem,neutral
hi conformer layer linear linear dropout dropout dropout dropout activation dropout linear linear linear linear dropout dropout linear activation dropout dropout linear linear dropout dropout dropout dropout activation hyper parameter common true true task data normalize false true criterion true temp optimization model true conformer turning training speed three time solve problem,positive
hi migrate st eventually,neutral
hi turning another alternative might reduce training speed lot attention mechanism could also share hyper parameter corresponding run,neutral
please help pull request,neutral
found post issue link could one although reduced log still issue trying set environment variable warning get warning ran memory exception memory tried allocate mib gib total capacity gib already mib free gib reserved total reserved memory memory try setting avoid fragmentation see documentation memory management would like know valid limit memory usage device use code per case used training,positive
problem generate hypothesis yes please use encode decode function recover,neutral
image know training large model reduced memory usage reducing default training device assuming could issue running command,positive
hi welcome cluster mechanism issue two way also try try run server client separately user docker run evaluation feel free let know question sorry interrupt got stuck speech source target number evaluation server process id listening port warning scorer output start data writer process id process id dictionary size ran success tried run docker still problem change log level log like jump endless loop like starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection put starting new connection yeah see still could anyone help,positive
hi actually working implementation thanks ton actually main code found code tested worked like charm,positive
thought share issue step add following python import import path path build step file replace line python alpha alpha import else alpha import alpha alpha compile extension first import hope,positive
anyone able implement based suggestion,positive
order trained model still ca load,neutral
hi know long since raise issue solve modify according,negative
going issue found solution,neutral
expect someone like help,neutral
hi someone still actively working one would also like implementation,negative
training data ensure punctuation apart adjacent word resolve problem face another problem disappointed much worse,negative
hi like indeed problem omega version still need figure way need structured even inference error issue thank,neutral
anyone get chance review model task challenge would really nice share code official rather fork,positive
according paper need use temperature paper learning rate important avoid collapse cosine learning rate put also sure whether learning rate actually used range value starting value cosine schedule python whether fixed value would say fixed value since say opposite also stochastic depth may important avoid collapse repository default applied student,positive
seem generate text issue,neutral
problem ran completeness bash python python python python path valid none,neutral
still getting error key running code import torch import model task model model package version location decorator pip six tabulate torch tornado wheel,neutral
trouble evaluate due missing solve,negative
recently propose unified multimodal model code based new performance coco image cider without detector addition also performance series vision language generation visual grounding implementation provided plan release interesting near future,positive
different branch bunch better remove option new wont ported hugging face already end week delay process really,positive
hello trying load model issue trying notebook one help please week trying solve import torch import import import import import loading model error recent call last module try import except module handling exception another exception recent call last yield saved yield except code compile script code module finally setup setup return setup try except self parser none user help got self parser self parser self parser command raise command class must subclass command command class class must subclass command handling exception another exception recent call last module import loading model load model source verbose verbose model model return model model entry model name path module spec assert loader module return module self module module import sandbox except raise normal exit return self type value value type try type value except suppress unless exception ensure available yield self type value value type try type value except suppress unless exception resume self type map raise saved yield saved saved ensure available yield except code compile script code module finally setup setup return setup suppress try except raise self return parser none user help got return self parser command self parser handle want consume self parser sure basic command interface command raise command class must subclass command command class class must subclass command,positive
hi came across profile searching see first repository unable request reviewer add usually sorry ask would really great could guide exactly since believe help working internal project change really looking forward reply thanks,positive
different branch bunch better remove option new wont,positive
found problem provided file name like instead problem close issue comment perhaps vocabulary archive avoid behaviour,neutral
exactly data key value dictionary,positive
change use vanishing somewhere try divide zero hope problem,neutral
use pattern one need upgrade remove requirement constraint,neutral
solve problem exact situation output output quantization mel output tensor audio output tensor nan nan nan nan nan nan,positive
install suitable torch version command recommend work,positive
robust otherwise also hub interested,positive
sorted could please advise regarding,neutral
following also want use arch speech translation task idea,neutral
thank trying use however result poor even st wer st accuracy surpass early stopping patience tuning learning rate default like accuracy would worse smaller like loss accuracy convergence finally accuracy surpass tried also result needle say also terribly bad score even also confused result sorry could help found anything would suggest,negative
thank assistance normalizer available convenience would please provide information,positive
bump got similar error make sense audio pretraining pretraining use text someone found solution key,neutral
error unrecognized type error easy according error log image compare code older version code find reason former version option current version option become change training code may fix problem,positive
purpose remap id dictionary,neutral
hi issue unfortunately python solve issue issue notebook happen even though python identical,negative
fix added line fixed optional field help number source sequence,positive
thanks lot quick reply according loss plot training right also check variance plot image however target flat end still dropping actual meaning relation read source code standard variance network,positive
hey like collapse may want lower learning rate dont variance wasnt logging trained loss curve image couple example reduced speech setup variance look somewhat similar exactly also learning rate peak rate training loss image image target image,positive
plotted teacher student two test small student variance converge teacher variance specific point loss quickly relatively constant gab two sure interpret maybe desired behaviour since teacher always better order lead student hello found reasonable explanation follow strange loss plot image hey unfortunately loss though sure correct loss function look like strange loss two magnitude smaller would also great see training plot could tell used batch size thanks change except since memory error could share training plot u help u figure thanks much,positive
thanks quick also mention upgrade local system get example work maybe,positive
resolved problem file getting,neutral
able solve issue tried token size latest implementation still error,positive
unfortunately trial error try first maybe also lower learning rate without setting would give exactly one setting work whatever reason basically lower learning rate converge,neutral
thank helpful wonder enough replicate reducing learning rate critical,neutral
hi solve reduce learning rate also introduce gradient accumulation multiple specifically optimization part base model optimization able train base model successfully one think default learning rate,negative
plotted teacher student two test small student variance converge teacher variance specific point loss quickly relatively constant gab two sure interpret maybe desired behaviour since teacher always better order lead student hello found reasonable explanation follow strange loss plot image hey unfortunately loss though sure correct loss function look like strange loss two magnitude smaller would also great see training plot could tell used batch size,positive
hi know old issue solve reduced learning rate replicated time,positive
maybe extracted feature suitable default simultaneous st issue result feature extracted st setting global main branch time global feature following branch train however feature almost ca believe different different check detail time anyway could reproduce result thank hi firstly trained global utterance performance poor use global evaluate average best development set result remains poor training set data whose st totally irrelevant audio think maybe learning rate small increase keep unchanged result worse proper task also notice task script different matter actually confused reproduce result used small,negative
change model want change model right loading model model easier method change,positive
think documentation said soon used instead plus use support argument distributed training,neutral
hi quite getting always around official issue discovered average know closed gap official mine may seem obvious know following leave comment anyway case someone forgotten step,negative
plotted teacher student two test small student variance converge teacher variance specific point loss quickly relatively constant gab two sure interpret maybe desired behaviour since teacher always better order lead student hello found reasonable explanation follow strange loss plot image,positive
guess would omega version got error two worked,neutral
alright around code reading paper carefully figured put anyone wondering pretraining text done language modeling task file task masked version original unmasked audio original input fed model done within forward method care tensor detailed table paper gain least error rate practice task actually model provide reason use like either loss instead cross entropy loss provided better calculated inside forward method assumption correct model done projection classification possible follow implementation,positive
solve problem change version try,neutral
could please put agent code thank much,positive
sorry way used know write,negative
thank empirical advice training maybe efficient try st implement yes maybe extracted feature suitable default simultaneous st issue result feature extracted st setting global main branch time global feature following branch train however feature almost ca believe different different check detail time anyway could reproduce result thank,positive
yep right sorry think,negative
may add path root input shell script export python find execute,neutral
trying reproduce closely follow implementation paper loss early epoch check training log see patch loss related experience situation thanks help,positive
hello solve problem met similar problem like error argument choice added find arch cause following recent call last file line module file line parser file line parser trainer file line file line file line return name level package level file frozen line file frozen line file frozen line file frozen line file frozen line file frozen line file line module import file line module file line return name level package level file line module import file line module file line return name level package level file line module import file line module import module install pip install version torch compatible use version quite long time work fine task know version torch proper,positive
turn continuous recompilation happening feeding model dynamic continuous recompilation fixed padding sequence length base successful posterity sake issue used determine happening nearly every training step example step saw following profiler output frequent used save graph different revealed input shape lastly confirmed shape input iteration following patch fixed issue successful training git index close ticket since original issue hanging training fixed,positive
use share use detail exist much difference,positive
hi thanks clarification also use weight decay,positive
affecting able train large model model simply change feature extractor could provide detail make current guess help convolutional feature extraction dim stride change dim,positive
great also looking vision part model,positive
without phone recently pipeline audio text data got something like per sure correctly text data worse similar getting hi make significant training model amount data,positive
finally found solution problem came side one pas retrieve first element resulting second one,positive
yes implementation got small improvement sure mistake mismatch training data evaluation data,positive
yes projection head single linear layer bias need use normalization model doesnt learn favor particular layer,positive
hey able reproduce error could maybe rollback version see root try,positive
yes working problem different need port want get could try taking code replace loss describe paper following able get good quickly,positive
could please let know update,neutral
hi wondering whether code vision part recently,neutral
hi thanks explanation look example sure hope see related model soon best hello finished evaluation could please share thank,positive
unsupervised work clustering also work someone else different probably relevant,positive
work discus transformer capture different speech model may want try extract various transformer last one example found middle correspond like opposed last layer thank,neutral
found happening copy new object copy without calling constructor object based dot operator fallback find attribute name thus dot operator infinitely recurse line attribute set,positive
change line model task model task,neutral
good choice additionally aka greedy doesnt rely flashlight used dont need fuse,positive
recently ported flashlight currently lexicon constrained beam search try nightly build documentation found,neutral
handwriting text recognition architecture model specifically architecture like speech recognition run model wondering way infer model without flashlight,neutral
useful tried try install old version need module install cub module try change branch,positive
indeed get thing character,neutral
fan available side awesome finding,positive
found git reset hard could solve problem instead git reset git better git git main go back main branch,positive
thanks response part label test model provided helpful verify st iteration base model help obtain provided base model label still st iteration base may make st iteration base randomness model base model st iteration permitted could provide iteration base model label performance st iteration base model provided table paper language model something helpful verify st iteration base model base iteration tested model performance pipeline provided st iteration base wer used paper language model applied process metric label similar result hi unfortunately st iteration base removed accident however large extra large model trained iteration base model label one provided also model used quantization hope,negative
pip install worked try change day ca get pip install work build develop,neutral
hi added line received new error input output index must current device line tried use function well generator unfortunately please advise shall thanks,negative
getting issue new mac book pro build done getting build wheel error error getting build wheel run successfully exit code output recent call last file line module file line setup file line setup file line file line raise handling exception another exception recent call last file line module main file line main hook file line return hook file line return file line file line compile code file line module operation permitted end output note error likely problem pip error getting build wheel run successfully exit code see output note error likely problem pip,positive
current branch commit fix bug load loading several recent miss,neutral
several recent miss current branch commit work fine,positive
pip install worked try,neutral
hi could use script generate label suppose one audio file transcript like number audio file get like,neutral
hi unfortunately st iteration base removed accident however large extra large model trained iteration base model label one provided also model used quantization hope,negative
instead version red hat copyright free foundation free see source warranty even fitness particular purpose version copyright free foundation free see source warranty even fitness particular purpose pip install file requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied torch requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied collected running develop successfully install win fix problem fix found yet,positive
plotted teacher student two test small student variance converge teacher variance specific point loss quickly relatively constant gab two sure interpret maybe desired behaviour since teacher always better order lead student,positive
hi able find solution requirement,positive
exact issue also working,positive
hi add import sample sample else sample move input generator right one sorry confusion update code snippet accordingly,negative
new one way communication sent,positive
know exactly differently however following pip install git pip last installation work without,neutral
thanks much issue take look shortly,positive
right model complete output base jilt python infer usage package header package see information list missing see information schema name behavior removed see migration recent call last file line return file line lambda lambda file line run file line file line return file line file line key value file line update assert unexpected type root internal process thanks help advance,negative
curious able resolve recursion error facing similar problem,positive
stack trace pretty generic share entire output run command make sure one model right,positive
documentation dear team thanks opening source code however link broken would much could update link thanks hi thanks much issue please use link instead,positive
issue happening test interesting issue come recent time issue point issue raised,positive
hi thanks answer stack trace recent call last file line return file line lambda lambda file line run file line file line return file line file line key value file line update assert unexpected type root set path set also directory error still showing data class field,positive
found git reset hard could solve problem,negative
whats stack trace assume correctly set path right,positive
done please bear little regarding,negative
good thanks sign merge,positive
thanks much relevant pointed bug include fix next batch bug coming next,positive
may bug st example speech translation st run command python task latest version got fetching split train log mel filter bank recent call last file line module main file line main process file line process file line file line file line file line channel size many index tensor dimension simply commit error disappear environment install source install found following none code function commit use may work guess anyone recheck commit test two please,positive
thanks format train validation split run following still get error python infer instance file missing something folder outside,neutral
name manifest file subset wish evaluate subset would specify,neutral
hi include dictionary prevent model loading dictionary disk please make sure use latest commit thanks still work loading error log false none true false none none none true false false current directory false true false none false true false recent call last file line module task file line model file line model self file line return task file line file line model file line model self file line return task file line model file line return file line name name file line label file line label file line load file line raise file line open file directory loading log file line model file line model self file line return task file line model file line file line file line file line file line ex cause file line raise ex set end full file line return file line node file line key file line file line file line ex cause file line raise ex set end full key,positive
need write code convert work import torch import output world print output output model disable dropout print model model output true checker error image,positive
thank much response try look,positive
similar note exactly run inference custom audio per evaluate model data field since evaluation mandatory field unspecified python infer output error unexpected type root since guess help really,positive
sorry dont get question talking audio model based example assume follow largely still except head since dont predict input yes model thanks take look straightforward specific,positive
someone recently task need switch,neutral
sorry dont get question talking audio model based example assume follow largely still except head since dont predict input,negative
paper shortly please cite paper like title improving language understanding generative author alec year,neutral
hi tao thanks reaching discus compare work next revision paper best,positive
thank clarification turned without parameter already output parameter still face warning,neutral
hi sure solution working sure install correct indentation new code ensure proper attribute really understand still error pasted code right place ensure run script indeed attribute know error missing attribute help solution worked working best luck,positive
figure passing wrong argument sorry disturb,negative
hi want model custom new present trained model training base model hence present vocabulary list well dictionary add new well dictionary initialize,negative
sorry put question wrong position manager delete thanks,negative
follow possible solution still met error key thrown error following root python train module import logging call current directory false none false false none false true false model default false false false false static false static false false false false key model,negative
quick question apart wer mean begin validation test subset test epoch language model setup flashlight must oracle wer,positive
problem set one work,neutral
problem pretrain model error unrecognized command python could give advice use train extremely grateful problem,negative
already one thing add set case may also want first make sure device actually running may actually faster case setting device supporting removing get error,positive
example two file audio file line right format,positive
hi could provide information training example python tried following command training however architecture seem match though paper used architecture base task translation de arch criterion dropout beam log output task translation model criterion model trained parameter rank total memory name ti training per per loading model reset recent call last file line file line return super strict file line raise loading error loading size mismatch param shape shape current model size mismatch param shape shape current model size mismatch param shape shape current model handling exception another exception recent call last file line module file line main file line main file line main file line file line raise exception exception load model please ensure match might gone wrong differently would much,negative
dear thank much kind reply really appreciate great hear unfortunately find train split test split maybe something,positive
hey late response use split available specifically short version yes need apply let know need help,positive
put file proper path,neutral
news available might considerable put effort compatibility side,positive
also got issue find,neutral
also trying reproduce check trained successfully metric model dev loss thanks,positive
hi could help elaborate fix problem thanks lot,positive
normal mode work pip install,positive
met question ran example version,neutral
oh god met question please get fixed give,positive
like something environment problem went away still quite make sense seeing error,neutral
met similar question use detailed torch recent call last file line module file line main file line main return file line file line file line state file line state state file line state state branch trained model criterion arch dropout,positive
also basically pretraining fail existence field quick fix change file line python else none python else none pas argument relevant recall correctly,positive
hi try finish pull request could ask main,positive
problem solution modify source code,neutral
definitely real issue like part original change original commit necessary bit control logging change never applied file,positive
hi exactly problem hint decode training set produce distillation,positive
remove add none loop,neutral
sorry bother also use rouge evaluate public model got strange like directly use evaluate question use evaluation package obtain result whether miss something,negative
also curious sure update suggestion ladler thanks lot,positive
found issue passing string instead fix,neutral
install version solve problem pip pip install,neutral
fix use absolute path,positive
hi tried convert model model following comment facing issue removed future version currently toward like function incorrect rounding negative keep current behavior use actual floor division use triggered internally return self converting tensor python might cause trace incorrect ca record data flow python value constant future trace might generalize assert converting tensor python might cause trace incorrect ca record data flow python value constant future trace might generalize assert list converting tensor python might cause trace incorrect ca record data flow python value constant future trace might generalize assert converting tensor python might cause trace incorrect ca record data flow python value constant future trace might generalize assert model forward function model forward function recent call last file line module model run file line export return model verbose training file line export model verbose training file line model verbose file line graph graph file line graph graph file line return file line return file line wrapper return file line transpose raise export transpose tensor unsupported export transpose tensor unknown rank please help couple trace assert like assert fine warning forward method model forward function show even wrapper forward method run time error raise export transpose tensor thanks advance,negative
problem trying train monotonic git clone cub get lot cub warning previous syntax error error class qualified name error qualified name error warning previous syntax error error class qualified name error qualified name error warning previous syntax error error class qualified name error qualified name error warning previous syntax error error class qualified name error qualified name error warning previous syntax error compilation solve cub found error cub module,negative
trying reproduce attention low fixed bug still thanks advance,positive
problem trying train monotonic git clone cub get lot cub warning previous syntax error error class qualified name error qualified name error warning previous syntax error error class qualified name error qualified name error warning previous syntax error error class qualified name error qualified name error warning previous syntax error error class qualified name error qualified name error warning previous syntax error compilation,negative
according sockeye currently compatible,neutral
generate already load file directory,neutral
met problem recently reproduce number eventually,neutral
useful leave contact information thanks attention familiar interested way use unsupervised learning make discus,positive
added language space end dictionary launch command add language bash cat cut echo mask directory extracted file,neutral
useful leave contact information,positive
hello problem experiment mandarin data set guess may related gan training many time reasonable new progress please share,positive
used different task decided manually add extra dictionary hi add extra dictionary,neutral
question convert sockeye model model,neutral
due version incompatibility fix pip pip install,negative
possible conclude trained model trained well guess least model assumed generate random loss graph,negative
addition tried load run import o import torch import import task model output model model loaded forward pas done without error however output none none none tensor,neutral
target variable sample yes pas target got error recent call last file line module file line file line file line file line raise ex file line return file line lambda lambda file line run return file line file line main file line main file line main sample file line file line return file line generate sample target file line model file line return input file line forward file line min file line min dimension range range got,positive
note also error recent call last file line module file line file line file line file line raise ex file line return file line lambda lambda file line run file line file line return file line file line raise could override append use,neutral
get sorted natural order run command bash sort cut sort cut sort cut,positive
tried paper process language replicate must mean something wrong process failing progress left issue alone touched,negative
yes right line current,positive
issue please update found solution hello problem problem think setting gan training greater impact,positive
hello problem problem think setting gan training greater impact,positive
hi commit small bug following line line commit,negative
problem one thanks solution,positive
thanks fix reason pin version like become difficult support ago currently version want keep flexibility deprecate future move,negative
thanks fix reason pin version like become difficult support,negative
thanks issue please pull latest code fix commit,positive
use file original dictionary special training work data already add parameter,positive
thank add training inference sure training tho,positive
sure happening double checked extension dictionary file added end dictionary,positive
issue provided one therefore need extend dictionary language padding note language slightly different case instead example find append dictionary also need file list find well note already carefully check default explicitly added usual first train dev test train valid test python model python model done test set plain model path beam task test adapt model language pair interest adapt need task cat patience loss criterion dropout temperature criterion multilingual seed simple arch dropout tee finally note model may require small fix,negative
hi keep getting find language token dictionary inference know,neutral
also want use streaming thanks,positive
remember code part exactly part part training part model used inference,positive
found answer thanks anyway,positive
hi idea causing issue,neutral
sorry understand issue fix landed master mismatch talking error getting,negative
hi may know closed fact dependency mismatch depend older version really want keep latest would helpful fix issue,positive
nat usually need long time converge,negative
reproduce use source work left see poor comment use large batch size multiple setting set thanks also another question set large batch size reproduce experimental,positive
tried audio work well model almost wrong oh well guess scratch way go want inference audio,negative
think problem incompatible elastic launch necessary use launch,neutral
hello still plan release code thanks lot,positive
bug run extract run st got low previous found different also different,negative
load model code model task data got error could load dynamic library found ignore set machine recent call last file line module file line model task file line state model file line return super strict file line error loading size mismatch param shape shape current model size mismatch param shape shape current model find case like anyone know thanks,positive
error please help git clone pip install arch task criterion raw dropout seed simple please install pip install none none false none none none false false false false false false false false none false none false none none none false false false false none none none false none none none false false false false false false none false none none none none none none false false false false false false false false none false none none false none false none none false false false none false false false none none true true true true false true false false false false false none false false none false false false false none false false false none none false none false false false false none none false none false false none false false false false false none none none none false none false dictionary dictionary linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear task model criterion model trained expert model trained loaded valid parameter parameter rank total memory name training per device per device none load large large note device may support faster training loaded epoch loading train data epoch loaded train grouped begin training epoch start recent call last file line module file line main file line main file line main train trainer task file line inner return file line train file line inner return file line file line loss criterion model sample file line return input file line forward model sample file line return input forward missing positional argument,negative
hi thank providing code looking right script reproduce result paper run code encounter many fix found format abnormal strange blank head large margin sentence example line image forgot reproduction result reply trying thank help lot,positive
hi thank providing code looking right script reproduce result paper run code encounter many fix found format abnormal strange blank head large margin sentence example line image forgot reproduction result reply trying,positive
hi thank providing code looking right script reproduce result paper run code encounter many fix found format abnormal strange blank head large margin sentence example line image,positive
problem python even tried python error going python precise successful install python run update run install run pip install run pip install,positive
related translation find full documentation following page enable task argument need set,positive
hi partially closed however think solution propose cleaner also merge day thank thanks internal code review,positive
closed already yes good,positive
hi partially closed however think solution propose cleaner also merge day thank,negative
thanks suggestion use initial model also need data script model,positive
problem could temporal solution line import import line comment line,neutral
convert successfully also torch class self super forward self source source source source return return task original model original model model run model input multiple save model file object store trained parameter inside model file version export model whether execute constant folding optimization model input model output variable length ax,positive
sorry good merge soon thanks,positive
found model giving similar better theb interest decided source target language may worth trying,positive
please suggest run inference model model provided possible also train model,neutral
tried like similar problem much help,positive
hi good question definitely help work simply recognition feel free try,positive
fixed problem thanks lot,positive
actually line bool field help recompute save memory extra compute,neutral
forget commit issue change file,neutral
hi still issue code error latest could elaborate bit solution read figure environment except version python version version configuration,positive
think similar problem python version may solve,neutral
function target sequence naming used match also exist also sense iterative inference time,neutral
thank written script one sentence per line similar top ten sample file,positive
thanks mille super useful one last question regarding said note predict word splitting character since also dictionary added token dictionary token would make sense train model easier later map phoneme sequence word sequence since would allow one know belong word think leaving dictionary phoneme error rate thanks lot,positive
example model hub easily via python import model,positive
hi tried look file ca seem find would probably need write script separate input label one sentence per line,neutral
use instead get mistake either get must specify batch size either,neutral
could please also share file,neutral
despite fact fact link provided glue issue solve link still forbidden python glue cola recent call last file line raise code error forbidden,neutral
problem ran trained translation model tried use model paper open source code loading object attribute,neutral
really problem reproducible loading specific model new load encounter problem recently take much care guess forced model save whereas normally saved one entire epoch maybe left epoch thus resulting one empty batch explain full instead,positive
may similar empty batch phenomenon see clear relation instead kernel version,positive
hi many thanks helpful discussion extract recently maximum length error error raised according example discrete however longer produce least longer however know without wondering normal encounter error though minimum sequence length would long enough extract entire since please let know wrong anything thanks,positive
thank contributor license agreement accept code open source project thanks,positive
pull request employee view,neutral
hi yes command correct option enough different usually use separate order manual afterwards per phoneme may contain need parse correctly training data output model correctly well yes phoneme word lexicon use directly,negative
hey right find well running,positive
use hugging face maybe try hugging face version work,neutral
hi able figure problem thank,positive
flask serving rest multiple hello also use flask build rest low much reach help,positive
hello use flask build rest low help ti,neutral
found bug another error load anyone meet problem,neutral
hi similar idea additional input word tag entity single input give custom task implement hi similar purpose like modify add additional maybe easy way found mostly concentrated yeah end solution modify try create word every single word together use change concatenation order find detail idea based paper improving neural translation linguistic thanks kind reply figure,positive
hi similar idea additional input word tag entity single input give custom task implement hi similar purpose like modify add additional maybe easy way found mostly concentrated yeah end solution modify try create word every single word together use change concatenation order find detail idea based paper improving neural translation linguistic,positive
hi similar idea additional input word tag entity single input give custom task implement hi similar purpose like modify add additional maybe easy way found mostly concentrated,positive
trying generate bin path en beam task test getting error recent call last file line module file line main file line main return file line file line ensemble file line state model file line return super strict file line return super strict file line raise loading error loading size mismatch weight param shape shape current model size mismatch weight param shape shape current model size mismatch weight param shape shape current model size mismatch weight param shape shape current model size mismatch weight param shape shape current model size mismatch weight param shape shape current model issue combination training work switching version pip install instead current master version able run following path de beam task test output de dictionary dictionary loading data test mem usage test main loaded loaded test loading model start batch sampler mem usage test order index time mem usage test time mem usage test time test per epoch time mem usage un bon de de,positive
thanks filing issue could add attribute false happy review,positive
problem pretrain model error unrecognized command python could give advice use train extremely grateful,negative
otherwise question know data prepare follow need follow first second second shell en de en de method use end thank,positive
show complete script transformer seem problem thank much thanks,positive
bump wondering faster training time,neutral
hi could take look much,positive
also problem solve trying reproduce except run command shell path beam en de task translation raw tee get python large en dictionary de dictionary loaded loaded test loading model recent call last file line module file line main file line main generator sample file line return sample file line return file line generate return model sample file line return file line step file line step integer division div longer future release div perform true division python use python instead change file get python large en dictionary de dictionary loaded loaded test loading model recent call last file line module file line main file line main generator sample file line return sample file line return file line generate return model sample file line return file line step file line step result type float ca cast desired output type long anyone know resolve issue python torch also problem solve,positive
hey correct documentation new community want contribute open source,positive
bug python compatibility work,neutral
beginner facing issue anyone guide resolve,neutral
think simple fix swap two python tested fix,neutral
hello still receive error saying missing,negative
second way modify code reorder according beam index current code try mask old beam beam order however bug rarely effect test set false hard trigger play role beam search require beam size appear top beam size one step hi think possible step one beam really need please correct wrong thank,negative
unrelated memory something latest revision broken ability load older sure issue would checked older revision model perfectly,positive
private fork inherit change able export,positive
successfully transformer model could share code,positive
try add self work,neutral
found empty line end file one removed empty line working,negative
refer example link thank reply training model used place speech resynthesis,neutral
really checked many time blank problem please kindly check whether blank exist validation file especially,positive
hi found closed issue solve thank,negative
agree would preferable behavior rather terminate enter infinite loop would great,positive
problem please kindly check whether blank exist validation file especially,positive
far remember training code open help thank update looking forward input,positive
stereo instead mono converted file mono fixed issue,positive
issue distributed change job hit thought correct behavior handle gracefully continue training understand correct behavior properly,neutral
hi advice large scale label data hour seem hard example got hour data data get hour data include data data first continue hour got slightly better advice thanks,positive
sure help error message different model transformer case fixed model input,positive
would appear particular bug documentation issue model need three removing model still train looking missing would good proper set training still need removed documentation issue missing mistake added argument feature,positive
thanks pointing bug answer question need path need dictionary determine output size many though prediction head used stage fix make load dictionary meanwhile want quick fix following create dummy directory say modify running import torch state state state work,positive
looking old related see also help issue would appreciate greatly let know need done order perform proper training,positive
export folder run see line saying built thanks hi solve problem,positive
different version available pip remember version quite bit date last release pip,positive
solve via rather via pip install different version available pip,positive
solve via rather via pip install,neutral
progress case took repository model loaded following key point library written state none would state none,neutral
related work another train phoneme recognition model per around,neutral
tried use model error recent call last file line module file line main file line main return file line generator sample file line return sample file line return file line generate file line type self name object attribute,positive
problem find fix thanks crista facing issue figure solution,positive
far remember training code open help,positive
according author provided link used distribution one provided author apply additional applied exact hey man thank issue want know data link operation process write script divide data use data thank,positive
reproduce result still confused,negative
hey man meet problem tell solve problem suggestion great appreciate,positive
like state dictionary saved properly loaded would appreciate help load trying modify file state dictionary state point correct data dictionary keep running,neutral
someone please help thanks,positive
think need install flashlight python inference even raw option flashlight python warning install,negative
would appreciate greatly let know need done order perform proper training thanks advance,positive
hi took part development release model humble researcher tried occasionally discussion said see paper section stated layer total size model section introduction involve size match deduce dense sparsity considered,negative
notice must stick dictionary used pretraining neural model vocabulary use make link dictionary single file multilingual setting along model basically mean simply create binary representation corpus create new use provided use generation completely sure one training dictionary file vocabulary large table system reduced number significant part never used read issue find couple allow trim table influence size depend size model smaller noticeable,positive
got note simulate command line,neutral
problem trying train base model scratch also loss exactly think kind degenerate solution accuracy close train try lower learning rate training single maybe making difference,negative
use change batch size,neutral
like longer memory clean already see comment would try clean long although sure would solve issue since many,positive
per halved yep tried halve also work would appreciate would suggest first check memory usage running already memory use top kill trainer argument set false default try recover case never dead result got likely encounter long clear dead process manually anyway suggest setting argument true save lot trouble,positive
behavior select refer batch size per logically capacity therefore process batch size observing simply try lowering batch size setting fact tried work might long sequence even sequence batch check case set large set report error sentence length exceed,positive
behavior select refer batch size per logically capacity therefore process batch size observing simply try lowering batch size setting fact tried work might long sequence even sequence batch check case,positive
suggest work gib thanks reply setting maybe work work,positive
behavior select refer batch size per logically capacity therefore process batch size observing simply try lowering batch size setting fact tried work,positive
please see average transformer apply top work simply convolutional make prone,positive
thanks review wait going ahead,positive
hi issue also install search pip install build done getting build wheel error error command exit status command complete output supply build pep recent call last file line module file line setup file line setup file line file line raise handling exception another exception recent call last file line module main file line main hook file line return hook file line return file line file line compile code file line module directory warning command exit status check full command output error could find version requirement error matching distribution found,positive
hi trying use following code evaluate saved model found value output task need multiply output model issue also found import import gold open fin index line enumerate fin sent sent target float sent sent target print gold hello original problem range see line label evaluation step need multiply output model compute original correctly,positive
need multiply output model hello original problem range see line label evaluation step need multiply output model compute original correctly,positive
mixed due like would affect quality model missing something residual connection definitely going ultimately empirical question end result transpose fix sense update code also tried rotary nope,negative
already maybe warning work well,neutral
need evaluate suffice refer install flashlight python previously use language model install due version curious wer tested training phase must inference phase thanks,negative
exactly train model becomes training process wo stop keep training normal exit train training finished thanks lot monologue,positive
problem following line speech none like format data set wrong recent call last file line module speech none checked found indeed array sleeping instead conquering lovely rose princess become fiddle without bow poor shaggy cooing dove anyone know type data receive audio file path reading file whether thanks lot,positive
hi thanks interest yes working let know available thanks much,positive
could please help thank,neutral
much stable typically similar performance default make sure set train beyond without mode accurate post layer norm train longer outperform post layer norm effective need significantly increase learning rate post layer norm model,positive
want ask get output every unsing beam search try add generate sence,neutral
provided manually work unfortunately good model used paper decided support case unit sorry confusion thanks help,positive
thanks bug report file,positive
hi thanks interest yes working let know available,positive
hi thanks interest included yet one original working paper code let know available,positive
getting please refer documentation could also train fa data documentation,neutral
best solution apply dynamic quantization date guess either convert apply supporting dynamic quantization model conversion also run inference could please share thanks advance,positive
import torch import import model model path print hi check model script find model language specific sparse layer paper could kindly verify please,positive
behavior select refer batch size per logically capacity therefore process batch size observing simply try lowering batch size setting,positive
hi important like true one training example finding loss significantly higher value use,positive
per halved yep tried halve also work would appreciate,neutral
also similar gon na try increasing value thanks,positive
yeah normal could reduce lowering beam,positive
work thank let know get fixed one interested,positive
oh great work thanks verify rest,positive
work great spent week futile reproduce newly sample like heavenly music ca stop listening tried problem generating gibberish could please double check likely well thanks lot impressive piece work,positive
thanks helping issue due different layer seem something else please give try corresponding layer confirm use end use main corresponding commit id input file tensor tensor,positive
thank response irrelevant mixed due like would affect quality model missing something also tried rotary,negative
hello also model translation obtain translation successfully case repeat one word translation file translation model also file model problem thank advance,positive
triage actually duplicate issue,neutral
beat thank input unfortunately code either file provided gibberish reduced one end comment nicely add also original model clearly index error block thread assertion sense since padding sound look like tensor,positive
register duplicate model error register model already try change register name decorator name,neutral
luck use error tell file plus pad token end sentence token remove one number either beginning end crash get gibberish make even file one symbol work file file also empty end causing crash sure intentional remove get gibberish certain correct following acoustic exact command python layer,positive
question transpose probably mistake irrelevant without transpose within,negative
way make use lower program use one use two confused,negative
hello thanks interest work please use layer believe assume confirm text file inclusive included code file resynthesis output input example model please let know issue,positive
missing list rather something meaningful getting gibberish,positive
ran problem curious training phase inference phase,negative
import issue main module rather downstream one,positive
really roughly thing try import dictionary import dictionary recent call last file line yield body offset file line file line list file line text offset file line file line file line text offset file line got unexpected argument handling exception another exception recent call last file line module file line return file line file line start file line file line interact code file line file line prompt file line run file line return file line return await file line await file line await task file line await file line document file line document file line item document file line file line file line return file line extract file line yield object attribute suspect bug please report send list print detailed right use via use python work problem python default type help copyright license information import dictionary dictionary dictionary,positive
error generator object attribute translate,neutral
great tried explain end section end page move head scaling self attention get little without performance language modeling answer specific mathematically equivalent happy share code page math reference useful default bias modify behavior update post answer tomorrow,positive
error use single environment version version source python version version configuration ti,negative
thanks information weird glue neither without work sure specific task would mind example command used,positive
hi know wrote either pretraining right work work without would also like pretraining please let know figure,positive
thanks answer really one doubt prepare suppose need create file store data folder folder think need combine content folder single folder say bin pas folder data path training command right doubt since en would folder folder combining single en dictionary right correct way missing something,positive
hi ask time cost one epoch use cost,neutral
hi add argument command end error unrecognized without change output location,neutral
thanks lynx double checked issue fixed commit,positive
hi use since feature yet closed really need feature token level classification thesis target based sentiment analysis,positive
gibberish tried model definitely seem working,neutral
tried smaller layer amount respective strange since one symbol padding one bigger one size still gibberish use dictionary,negative
thank posting issue ran like missing file magic index,positive
glad see useful train multilingual setting also find task activate language token source input sentence another token target language input model trained must use well looking code task see basically following loop stated range epoch batch loss criterion batch,positive
sorry hijack thread anyone succeed speech resynthesis matter try keep getting gibberish help,negative
issue may main branch old version change line file solve problem target main branch master main,positive
hello update regarding exact problem trying continue pretraining new data doubt might solve problem wonder impact performance final model,positive
hello please guide one need unable find good reason use aggregator think thanks,positive
able help another query want model set language pair instead single pair following form combine directly please help,positive
fix version running single machine multiple raise error process following error recent call last file line file line main file line main train trainer task file line train file line assert norm norm file line assert norm norm file line wrapped return device found least two shell script python nag momentum seed seed missing anything python version version version version think problem might version met problem downgrade problem,negative
running similar dug little torch file model fix generate range print check torch file working,negative
confirming bug however fix solve large batch size default value line,positive
small model already used still data trained ignore run well result thanks,negative
thanks reply inference time critical stability important question thousand enough draw problem mean incompatible result fully incorrect saw trained update,positive
sorry remember inference time access right could rerun tell probably slow smaller maybe fast enough interactive translation remember thought extremely slow give simply run evaluate thousand find stability,negative
reset get sure approach correct optimal pretrain data execution epoch instead epoch training without command line get lot gradient overflow know right task model criterion model trained expert model trained loaded rank total memory name ti training per device per device load note device support faster training please switch likely faster loaded epoch loading train data epoch loaded begin training epoch start note gradient overflow gradient setting loss scale note gradient overflow gradient setting loss scale note gradient overflow gradient setting loss scale note gradient overflow gradient setting loss scale note gradient overflow gradient setting loss scale note gradient overflow gradient setting loss scale note gradient overflow gradient setting loss scale,negative
hello possible release model one opinion repository considered fully partially compatible two unstable work fully incorrect speed inference sentence translation use mig technology split use best choice inference thanks,positive
try load language model get following error assert task none could infer task type available could infer task type get false false false false none false false none none none false false available,negative
please tell long testing inference translation without model two maybe large number around clock opinion model repository considered fully compatible two fully incorrect speed inference sentence translation,positive
suggest try small model configuration first,neutral
instead running pip install could try source following instruction tested latest commit work fine,positive
still getting error even author code anyone else face issue getting error ran following command python layer false another error file line module main logger file line main file line predict file line file line file line none else input nan infinity value large tried model although throw error output file contain audio please help u thanks,positive
found pas beam parameter translate well,neutral
getting error object type loading model model task,neutral
manage make data point follow original point batch could please let know trying something similar well,positive
handled inside also way change way example mechanism custom function decide go batch,neutral
still getting error even author code anyone else face issue,neutral
like big beam fixed thanks ignore,positive
hey meet problem finished issue,neutral
commit history tried past could load ea issue might change update python environment information version dev build false used build none used build o version could collect clang version version version version python version default clang python platform available false version configuration driver version version hip version version relevant pip pip pip dev pip blas dev torch dev develop could share error message use latest branch load,positive
hi include dictionary prevent model loading dictionary disk please make sure use latest commit thanks,positive
sorry forgot update issue found way extract model library instead see,negative
equivalent many long due smaller value please check much data show reduce many suitable need anything else change,positive
might gotten lost see rebase merge,neutral
well indeed one common use need,negative
hi used code made one per line layer getting error could please help recent call last file line module main logger file line main mel file line mel lab file line inference file line inference file line return input file line forward result input error,positive
anyone please tell valid value layer python layer default giving error,neutral
able add reviewer please review change thanks,positive
fixed file resynthesis tool file text file one per line file submit,positive
hi think raised important question believe community start thinking seriously many breaking happen everyone custom code basically derive branch otherwise spend time code work behavior change although anything true follow cite really understand hard even harder part work case documentation notice anything similar regarding breaking behavior good engineering practice avoid kind make easy people build upon code breaking major old adapt new status understand may small group people following strict engineering practice may seem excessive overhead believe term would much higher community would grow many people also outside would find easy build code keeping version date branch hence able happy contribute active maintenance library course topic see great potential fully hope community consider reflecting considering adoption engineering code maintenance seen importance success open source see apache project instance marco,positive
hi also interested reducing inference time however code time spent function explicitly according documentation beam batch sentence generate list previous,negative
also facing problem solution much,positive
thank script work fine,positive
hello news front thanks advance,positive
yes agree running either added argument parser function additionally take argument use different min,neutral
equivalent many long due smaller value please check much data,positive
reduced added get similar,neutral
choose bigger number assume audio sampling rate shift window feature frame corresponding,neutral
since space target language calculated based please refer section paper trying set train st model always show warning try reduce time need change might hurt performance reduce number choose,neutral
hi issue would love hear python,positive
similar returned library indicate frame number corresponding suppose start time duration audio segment one simple way convert think work file duration le file greater,positive
second way modify code reorder according beam index current code try mask old beam beam order however bug rarely effect test set false hard trigger play role beam search require beam size appear top beam size one step,positive
different nag instead point know bug weird way saying chose model correct,negative
hi wondering problem since faced situation share progression dual learning based,neutral
hi really appreciate work however really appreciate pushing uncomfortable way pretty offensive main maintainer code responsible regretful inconvenience stated work moment update code future afraid would fit tight schedule thanks patience follow update,positive
hi steven finished question maybe solution help error version use git clone install install pip error code work new version,positive
hi see issue trying replicate like let know code working properly since forever even sure worked without error even trying fix assigned responsive helpful unfortunately see many,positive
setting following line would job,neutral
dealing problem language pair problem following bash added training work perfectly check learning rate,positive
next problem one dictionary dictionary loading model none none none train sh none recent call last file line module file line main file line main return file line file line file line return file line generate return sample file line file line return model file line return model file line return file line return file line forward file line return input file line forward none,positive
problem issue step audio instead new script latest commit issue resolved,positive
hello anybody help issue since like forward function right need given forward process exist moreover source code find shift right operation forward self return run inference model,positive
get reduce batch size maybe increase gradient accumulation compensate,neutral
since space target language calculated based please refer section paper trying set thanks reply used evaluation around train time figure gap,positive
implement integrate one instead use guide get model pull welcome also support use instead beam search standard machinery used machine translation use scoring wer get wer instead may play around architecture hyper question use model trained cross entropy loss get error missing positional argument thanks,positive
know problem good consistently worse train st model always show warning try reduce time need change,positive
since space target language calculated based please refer section paper trying set train st model always show warning try reduce time need change,neutral
since space target language calculated based please refer section paper trying set,neutral
ran st training corpus tested test split could reproduce result paper either result generate ratio translation copper also tested three char paper ca reproduce result told train command used en model task criterion arch seed test command task path beam scoring,neutral
know problem good consistently worse many,positive
know problem good consistently worse,positive
hello sorry help used different task idea mention,negative
model check data include dev part train well show correct,neutral
trained got terrible know,negative
could try add main end first parameter like main,positive
hi fix guessing additional set edit saw discussion,neutral
getting error try use simultaneous translation code example ref repository work enormous amount ram memory leak especially multiple used ram end second epoch python criterion arch dropout check lazy would solve problem course data appropriate flag well python criterion arch dropout lazy triggered following error message file line module file line main file line file line spawn return join daemon file line file line join raise process following error recent call last file line file line main file line main train trainer task file line inner return file line train enumerate progress file line enumerate file line next file line file line next file line raise item file line run item file line return file line return self file line file line start self file line return file line return file line super file line file line file line dump file protocol serialize object idea getting error,positive
hi looking commit variable function variable still used inside mean basically nothing miss something let u know think request general well used policy pas used change nothing,negative
well script really fix problem thank,positive
hi looking commit variable function variable still used inside mean basically nothing miss something let u know think request general,negative
training process frequent impacted train warning ran memory exception,positive
thanks little weird since work way work environment know restrict option check correctness,negative
following found removing restrict option option issue,neutral
facing issue find solution task thanks,positive
hello want know sentence like various copy modify file,neutral
confirm getting warning trying train simultaneous translation model scratch node criterion arch dropout since warning like training something worry,neutral
next error dictionary dictionary loading model none none none train sh none recent call last file line module file line main file line main return file line file line file line return file line generate return sample file line file line return model file line return model file line return file line return file line forward file line return input file line forward file line forward file line source file line forward source file line return input file line forward file line return input file line forward input module input file line return input file line forward return input file line input weight got input size instead,positive
also look please guess bug related inference time,neutral
also day faced similar issue fine tuned translation following snippet used task sh file list new path model another trained multilingual model arch task temperature criterion dropout seed simple disown tail copied tried fine tune text simplification source language complex form target language simple form tried perform task following code snippet sh arch task complex simple criterion dropout seed simple disown tail try fine tune text simplification part get following error similar one error loading size mismatch param shape shape current model size mismatch param shape shape current model size mismatch param shape shape current model difference tried issue like issue mask token task mask token automatically relevant section special implementation like task idea suggestion regarding use task work also great explain little bit regarding two use thanks advance,positive
mixed precision training maintain copy model latter used thus see memory usage model alone le memory usage pas rid model copy momentum thus see memory usage model memory usage memory usage relative amazing argument would load command line import use half make know make,positive
hey thanks know update want implement also need implement function target side two need guess self return none return none unit item return unit however sure correct think also gone,positive
recently run st got terrible result met problem issue,negative
found also need input order work properly inference update fix python self query key return query key already linked,neutral
happy hear also think way last question file provide source target command trying replicate paper apply preserve casing apply pair jointly source target construct vocabulary result raw text learn apply source target raw output get applied think correct one question going apply inside agent function also going translation inside agent function would really useful also explain handled part edit applied given source target think source file similar done file instead must way could figure translation topic input want implement,positive
reproduce result example st example link default error would occur specifically error,neutral
reproduce result example st,neutral
hi wondering thing manage get multilingual working thanks hi put gist script used paper data ignore particular data focus logic script hope share full code find time project hopefully soon,positive
happy hear also think way last question file provide source target command trying replicate paper apply preserve casing apply pair jointly source target construct vocabulary result raw text learn apply source target raw output get applied think correct one question going apply inside agent function also going translation inside agent function would really useful also explain handled part edit applied given source target think source file similar done file instead must way could figure translation,positive
thanks reply also confirm beta error one question handle predict function model right predict function example one thing return line predict function make sure stop point exactly predict function think require specific think yeah think aside one,positive
thanks reply also confirm beta error one question handle predict function model right predict function example one thing return line predict function make sure stop point exactly predict function think require specific think,positive
thanks pointing issue trying figure problem two quick change line shown able evaluate model even code still getting error getting tensor got tensor argument also get tested provided agent far see agent model repository wrong yes also get additional error added following line sure need confirmation python beta simultaneous use agent st since output execute policy understand simultaneous code due change might coming edit error line fix added line,positive
hi thanks reaching sorry document yet error please add option training,negative
thanks pointing issue trying figure problem two quick change line shown able evaluate model even code still getting error getting tensor got tensor argument also get tested provided agent far see agent model repository wrong,positive
following old code understand sort contact person think error triggered bug implementation get error couple pas look,positive
problem since path add line code script model,neutral
one possible guess remove compiler option like use faster instruction get similar precise result,positive
quite sure check script compatible tried latest branch macro setting environment variable switch,positive
thanks much tried branch passing simple correctness check wrote comment define go dig share minimum reproducer wonder guess,positive
previous issue next one dictionary dictionary loading model recent call last file line module file line main file line main return file line file line state file line model file line return super self file line model self file line return task file line task file line file line raise model file found model file found looking available mention one load generating need model,positive
loop code issue task first call second time duplication task registry case could solve line model registry need comment line,positive
firstly thanks lot novel work code implementation would nice give advice could provide training script task could point difference setting multilingual setting confused loss weighted sparsity loss weighted bilingual setting still necessary add sparsity loss well share loss weighted therefore exclusively find error guess right bilingual setting omit setting write line function treat sparsity loss loss excuse clear especially first one,positive
good suggestion fact first version based initially soon find le optimization limited create temporary branch interested install source see whether example little compilation setting environment variable default set kernel one advantage compiler longer create temp disk course file conflicting support see noticeable kernel regression create version default,positive
thanks awesome curious considered instead environment access run quickly tried gating minor tweak associated seem wonder experience,positive
hi please tag future please understand huge project like extension follow time apologize inconvenience actively working,positive
would something like layer enumerate else layer else,neutral
may ask command use launch model way want see way would help u come gentle fix thanks,positive
make sense format different avoid different child like launch deal multiple child launch writing file target quick try change line different avoid conflict also smaller work root cause found think fix gentle way,positive
distributed launch script work also saying way work please share used test integration trace cause bunch print code tried without still see also dont load,neutral
thanks issue team also use launch test pull running well mostly likely environmental issue see assertion failure compiler get source code content format may ask whether change source install source may suitable break following procedure change anything install via pip install help show standard output following shell environment sh command,positive
breaking running multiple file line forward file line result input file line forward return file line mask file line return data file line file line key internal assert please report bug think could due weird interaction custom maybe tried example also launch script work one difference think launch script new maybe thats problem also spawn version example even doesnt work share helpful,negative
hi fix issue feel free let know,positive
hi thanks explanation look example sure hope see related model soon best,positive
hi thanks feedback need use instead sequence generator since sequence generator static even new sequence generator tricky latency evaluation sorry document could take look example working bug fixing document,positive
also issue meant support simultaneous translation default full context beam search much like translation task need new class want evaluation run instructed documentation meanwhile hope simultaneous translation new class order make work,positive
thanks think might better add check layer drop used save user time lot since easy,positive
also run result run result bad similar question trained model result extremely bad possibly quite small model large also replace model arch improvement like could produce single word reference test sentence curious train model instead follow update,negative
run run still follow result train epoch loss total accuracy clip wall set yes instruction task criterion arch seed tee model well,neutral
run still follow result train epoch loss total accuracy clip wall set,neutral
run still follow result train epoch loss total accuracy clip wall,neutral
hey wondering progress issue official code still broken use,negative
hi new option added data preparation please update prepare file option,positive
thanks bug please pull latest code fix,positive
thanks issue fixed transformer please pull latest code fix supposed argument included task however recently added argument transformer hence duplication transformer time,positive
quick substitute unusual unused vocabulary model unfortunately got chance submit pull request hope somebody someday,positive
hi add simplicity without additional word segmentation wo work normally hence low difference acceptable given randomness model training,positive
first line got right loader example loaded model torch path file fine python import torch import path file model task,positive
issue would love hear solution,positive
use add part orignal code make start,neutral
thanks try alternatively try glue classification tutorial work machine,positive
true false none dropout false structural original transformer true true true false tanh false adaptive input false none quantization noise false advise use manually add param use except need make,negative
hi thanks much help providing work model training successfully perhaps documentation yes little unreliable time output presence training new line anyway thanks help,positive
thanks modify like many need add like would able share complete version,positive
also confused number also add,negative
think right point pas arch task temperature criterion dropout seed simple recent call last file line file line return super strict file line raise loading error loading size mismatch param shape shape current model size mismatch param shape shape current model size mismatch param shape shape current model like size issue add work correctly think remember working many ago issue command original later found another quirk file according really trailing file,positive
know testing whether install might problem issue resolved reinstall fixed,positive
hi think faced similar issue beginning like come plus special pad however trained extra special mask size table used different task decided manually add extra dictionary however original task use give path hope,positive
thank much going effort huge binary file running verify yes ran pip install user namely script finally still facing error previous reply could try,positive
modify like true false none use instead,negative
successfully problem train long time without interrupted loading new currently experiment data set parameter paper training process loss upward trend difficult converge resulting final wer high regard would like give,positive
please make pull request thanks,positive
confirmed still run script also double checked model ran completely sure wonder two back commit remember pip install reprocess data code active old commit,positive
best communicate someone else might benefit linked issue properly describe problem little bit sweeper running multiple series within one process global look written see correspond data valid train problem sweeper running next configuration since used every training procedure location write file name corresponding old configuration new place hence error look file previous configuration notice name trying write new configuration general take place,positive
thank much providing tried replicate exactly commit issue got resolved got new error error loading size mismatch param shape shape current model size mismatch param shape shape current model size mismatch param shape shape current model matrix version model link could share link version used even better tell update model configuration thanks,positive
hi solve version pip install,neutral
faced issue even setup torch pip master version although irrelevant tested problem however check type line cast wo face problem python none else minor error would like make pull request,negative
thank advice hope smaller conformer model could reduce time,neutral
insert code block head dropout,neutral
sure help commit used git log head commit code git git index import none none git index class self super snippet script arch task temperature criterion dropout seed simple,positive
tried thread none work still get dimension mismatch sort param shape shape current model similar anything else could try help would greatly thanks,positive
right quantization working point development best land mix precision,positive
quantization work used work tried use model directly import ruen ruen file line converted python object,positive
yet please feel free update issue case find answer,positive
also run result run result bad,negative
like good begin validation subset epoch valid subset loss total accuracy begin validation subset epoch valid subset loss total accuracy used model,positive
train custom data got much better result try change learning rate,positive
another issue reproduce example everything result sad run example result train epoch loss total accuracy clip wall epoch epoch epoch,negative
misunderstanding punctuation ellipsis real comment line,positive
normal single training take,positive
also issue simple fix replace,neutral
also problem use answer work instead function parser replace arch transformer architecture rely parser main,positive
solve problem meet bug pretraining custom data,neutral
according equation image correct implementation however difference,neutral
hi met problem solution thank run code model got error key,neutral
hello ran problem gan training sorry understand solution send thank much help possible contact,negative
update problem everyone issue please try,neutral
problem thanks currently reduce learning rate avoid degenerate solution,positive
able work around issue commit building according pip install,positive
replace python replace python solve problem,neutral
hi push version code soon maybe next week worked old version need merge current master branch would great release current code separate master branch difficult thanks,positive
issue please update found solution,neutral
thanks update data preparation part accordingly,positive
hello realization project entire process docker environment currently wer high find difficult converge docker environment training good,positive
commit history tried past could load issue note might change update python environment information version dev build false used build none used build o version could collect clang version version version version python version default clang python platform available false version configuration driver version version hip version version relevant pip pip pip dev pip blas dev torch dev develop,negative
hey trying train model model language starting around,neutral
believe anyone tried feel free report back experience,positive
could please look issue,neutral
able reproduce similar result far,positive
yes sorry clear looking code make clear see next day hear competition,negative
yes prepared according see structure way since prepare training code give warning mixed open source common voice speech text mono channel setup pretraining data well understand training loss decrease meaning somewhere somewhere happy place validation data also tried use common voice data training validation make sure train validation data come distribution effective either record finally figured wrong neither data installation pretraining model disaster got almost accuracy validation data pretraining however sound long validation split good evaluation material tried large model multilingual like got pretty good much thanks time though,positive
arent printing time beginning range output extractor print one would expect time increase since effectively cumulative sum right,positive
major implementation transformer recently might cause,positive
found parser default given matter arch change change,neutral
think worth training convergence seeing model learned anything via doesnt look like completely continue run pretrain reasonable code perplexity accuracy range pretrain,positive
think worth training convergence seeing model learned anything via doesnt look like completely,positive
accuracy purple curve training red validation think drop loss necessarily bad thing tried training convergence thanks quick response observation code perplexity well high around update also validation loss become higher guess probably something wrong stopped training tried suggesting continue train model thanks,negative
accuracy think drop loss necessarily bad thing tried training convergence,negative
added model model seen ideally differ get may count indication model printed model instead linear everywhere correct variable get used gone code also flag removed run error think recent commit quantization intended compatible torch release since listed experimental torch maybe dong know better late comment issue reference quantization support point,positive
see taken layer calculate twice subtle like one script task normalization taken account,negative
could post issue instead feel free ping sure already posted close issue,positive
thanks quick response problem,positive
figure also wondering ugly way would use,negative
also wondering far see differ model use standard transformer model use use different different glad know though,positive
bug code change work fine,positive
ask whether plan add open source code thanks lot,positive
could post issue instead feel free ping,positive
hi correct way formulate copa task create two first sequence premise choice dimension second sequence premise choice dimension sequence dimension pad length generally concatenate therefore input transformer becomes pas tensor directly transformer network see example reference,positive
temporary parser replace arch transformer architecture rely parser main file month ago st working well annotation point,positive
touched forever probably really date zip relevant,positive
ran notebook see behavior,neutral
also curious default hop size,negative
issue deal need add end need create file directory latter need put number used step,neutral
interest someone throw messy branch somewhere feel free reach similar running inference module know since issue still messy branch hand would great could share,positive
hi also problem use feature extractor plus classifier build model classification task training set inference sure mask value set,positive
search search question part finish example constrained want use instead achieve constrained translation found error loading unexpected key size mismatch param shape shape current model size mismatch param shape shape current model size mismatch param shape shape current model code echo python python path en beam tried guess question might related class file environment version master version o pip source pip build command used source python version version configuration relevant information,positive
hi could please tell many train model intuitively require training surpass similar dropout could find implementation detail either documentation tried training model without day thank advance reply,positive
also meet issue run script method found added set default like may use arch model use example register model method repeat default value used method reset model transformer arch script worked think violent method wait solve problem may also also model need use could please show u change detail,negative
thanks try let know also build server around model clear documentation unlike externally training train model trained test please elaborate point source externally training,positive
please let know suggest following ca seem able solve problem,positive
use branch screen shot tested recently may longer work latest code unfortunately direction time ca provide much support,positive
latest version seem work command kept please ensure match wonder something new specifically kept architecture transformer transformer,positive
yes train capitalization punctuation apply example punctuation raw data model output punctuation long remove punctuation train data thanks answer explanation link provided refer getting page code example provided inference pipeline thanks,positive
thanks awesome contribution could share working code example trying work code speech recognition page realize head particular sure need entire corpus run inference tiny file could share running inference small file really helpful thanks much,positive
maybe try issue working thanks lot close issue,positive
trying generate bin path en beam task test getting error recent call last file line module file line main file line main return file line file line ensemble file line state model file line return super strict file line return super strict file line raise loading error loading size mismatch weight param shape shape current model size mismatch weight param shape shape current model size mismatch weight param shape shape current model size mismatch weight param shape shape current model size mismatch weight param shape shape current model size mismatch weight param shape shape current model issue combination training work may mistake doc instead work setup detailed script sh path beam task test generation extremely slow memory per,positive
notebook working example also removed,neutral
like use initial instead probably something like,neutral
hi wondering thing manage get multilingual working thanks,positive
otherwise question know data prepare follow need follow first second second sh en de en de,positive
quick question different apart still use learnt joint vocabulary induce still moment trying different multilingual translation trouble joint dictionary multiple,positive
still got problem see,neutral
help question wonder someone help understand infilling algorithm particular understand rough scheme sampling following sample span span length drawn distribution uniformly choose index starting position replace span mask token understand algorithm handle merge span code think relevant code unfortunately function easy understand tried stepped code current best hypothesis code merge certain environment na yes code without,positive
hi thanks implementation trying code following reproduce found work well single following error distributed training training per device none per device load found loading train data epoch loaded begin training epoch start recent call last file string line module file line file line self file line name name file line name name file line name name previous line repeated time maximum recursion depth calling python object recent call last file string line module file line file line self file line name name file line name name file line name name previous line repeated time maximum recursion depth calling python object could please take look would much appreciate could provide like text,negative
think version causing pip pip install,neutral
think fixed master branch install line pip install,positive
file speech text recognition system large size audio length min session even ram hence way get rid making file audio audio library,positive
get word time stamp,neutral
thanks quick response sure whether loss pretraining directly related downstream case actually model overflow several epoch,positive
tried training layer performance drop lot image grey loss plot model trained data light orange faced nan problem much smaller loss yellow loss plot layer nan model performance comparatively worse also behind base model light blue loss plot layer better yellow still training,negative
add non affine layer norm output change used train fine cost accuracy guess make added non trainable could find think meant also also add another non affine layer norm output guessing useful need currently false case hi facing problem pretrain model audio initialize model may know work test thank,positive
reappear fine pip later first error,positive
note work trying install first two,positive
latest module import setup import remove code module import,positive
added property self return dummy like,neutral
also meet issue run script method found added set default like may use arch model use example register model method repeat default value used method reset model transformer arch script worked think violent method wait solve problem may also also model need use,negative
sorry late reply please refer,negative
yes right catch robust part yet,positive
hi also faced issue manually work loaded path saved path would great someone could update,positive
robust model hugging face task task based regular robust version,neutral
use like get smaller maybe use longer,neutral
find guess mean test could try start,negative
run inference concept sort since trained purely audio data need either use one inference work language model,positive
hi question pretraining model reproduce table table contain separator whether delimiter calculated counting table seem calculate separator similar thank advance reply image,neutral
ran issue want train one model share need single dictionary generate dictionary two time three setup end choosing multilingual multidirectional translation,negative
hi question pretraining model reproduce table table contain separator whether delimiter calculated counting thank advance reply image,neutral
problem need find location need change location modify file line choice none change choice none choice registry registry save workable example model task model model,neutral
side work model great,positive
tried layer norm yet week update soon look forward good news,positive
hi someone working still yet,neutral
able stabilize free experiment please share,positive
add non affine layer norm output change used train fine cost accuracy guess make added non trainable could find think meant also also add another non affine layer norm output guessing useful need currently false case,positive
tried layer norm yet week update soon,neutral
hello progress meet problem,neutral
input tensor different given operator limit input tensor shape number,neutral
found may cause problem shape tensor different batch according sentence length dynamically therefore different different batch size solution pad tensor shape number batch divided number solution also padding make sure shape fine may finish still running running waiting communication since group finished solution let finished dummy translation finished operator limit input tensor shape number,positive
problem master branch command line transformer architecture seem override default think bug commit,neutral
flag even put function hit even specify,neutral
anyone else come across happen model one set task,neutral
hi got issue resolve move like item alpha item item alpha item hi thanks method worked met another problem code right padding met problem thanks advance,positive
process source code state argument instead default value use former one output,neutral
wit drive store data found script fixed,positive
try splitting input file call time specify data see data argument hi like said step create multiple suggestion problem,neutral
loss scale even maybe mean large value,negative
add non affine layer norm output change used train fine cost accuracy guess make,positive
thanks suggestion try would behavior change,positive
yet tried switching training smaller batch size slow,negative
meet problem fix come model side large gradient tensor value overflow,positive
issue find could let know,neutral
facing issue python leeway torch ah unfortunately different situation anyways thank help,neutral
facing issue python leeway problem alpine image docker torch image,neutral
say use class see nonetheless procedure undocumented unclear use data could help u please,neutral
facing issue python leeway,neutral
worked trying make run last day finally see one thing solution run inference,neutral
facing problem training default configuration time training accuracy would zero validation accuracy increase image code perplexity look right either image image try load best see feature extracted see output full python model output tensor try get validation feature across time python model output tensor environment version master version o pip source source build command used source pip install python version version configuration relevant information training average audio around,positive
hi case issue data split rather model know following tutorial get set time ended splitting data splitting code used import import open line open hope mon wrote hello issue solve thanks thread reply directly view,positive
problem element python handle length constraint step python handle length constraint step,neutral
way avoid example kind modification,positive
hello issue solve thanks,positive
thank anyway continue try solve problem,neutral
hey fact solve problem yet switched old version avoid problem,positive
problem got similar error like worker unexpectedly model set avoid process block help,positive
found may cause problem shape tensor different batch according sentence length dynamically therefore different different batch size solution pad tensor shape number batch divided number solution also padding make sure shape fine may finish still running running waiting communication since group finished solution let finished dummy translation finished,positive
would interesting train unseen language possible add extra train model convert back,positive
continue interested centric model thank stale bot issue automatically marked stale issue still affecting please leave comment example bump keep open sorry able yet new additional information please include comment thread reply directly view,negative
removed yet like issue someone try install master note officially support right,positive
like removed strict flag awhile added back,neutral
builder option builder model single tensor option,negative
version still getting error missing something else,negative
recent call last file line file line run file line target file line run file line return file line serve file line load file line raise none file line module file line return name level package level file frozen line file frozen line file frozen line file frozen line file frozen line file frozen line file line module import module,neutral
help question similar short provide detail result table data used train valid test many used fine tuning batch size token size update frequency set section paper tried image table paper able achieve score trying reproduce result since difficulty getting sentence trying expect score bit lower paper however got training valid testing data following command shell arch task criterion dropout seed simple tee generate compute following command shell model task test cat file sort cut cat file sort cut ratio environment version master master version o pip source source build command used source git clone pip install python version version configuration long,positive
could also comment well,neutral
hi please try first fresh,positive
pip install although longer see access error running import python script module,neutral
install main channel instead something like install ran work create nat activate nat git clone install pip install torch pip install python python import print finishing step get following error step recent call last file line map segment figured solution due permission problem mounted disk git clone inside mounted disk pip install get error git clone inside system disk pip install error gone solution according question check fix disk permission mount change mount location disk location respectively work great work easily solution careful solution wipe data mounted disk please backup proceed case problem mounted disk need following command mount following comment mount,positive
install main channel instead something like install ran work create nat activate nat git clone install pip install torch pip install python python import print finishing step get following error step recent call last file string line module map segment,positive
multiple keep order similar original file,positive
fixed master branch following commit release made afterwards fade also fixed,positive
fixed master branch following commit release made afterwards,positive
hi everybody problem try run pip install thanks,positive
know exactly like building model error try previous lot,positive
hi thanks ran one following command python task path criterion letter got following error message recent call last file line module file line main file line main file line state file line state file line state state file line state state file line compose compose got unexpected argument would know issue,positive
update also set higher give better convergence scaling neural machine translation custom made speech think though,positive
hi thank response mind used low set success besides,positive
get solution solve issue facing problem want file,neutral
hi think speed although search,neutral
hi recently faced issue investigation say update frequency lowering going solve freezing loss going give best loss,positive
hi feel like model one could try use one,neutral
trained small transformer model data want transfer learning different language pair say language obviously vocabulary need new language therefore would need word source side reference linked issue issue hand different load model currently problem would like know solution posted comment tried approach learning suggest try use dictionary model training use dictionary de word reuse training well,negative
could try freezing learning new know work learning adapter tried freeze create new self also frozen,positive
hi solve issue issue please let know thanks,positive
anything super low generally range,positive
hi facing issue resolution assuming source code directory source code directory run following step step pip install pip install way solve problem good luck hi thanks solution run pip install error error command exit status io o open else import setup setup code compile code develop check full command output,positive
provide script use keep pretraining example want pretraining one language add new language thank hello got hello got progress,positive
anyone find proper solution,neutral
checked expression similar token every frame approach work,neutral
dictionary get right inference,positive
manage reproduce also tried setting following score ratio,neutral
worked hi struggling trained translation model please clarify define dummy input,neutral
worked mask mask hi struggling trained translation model please clarify assuming original input text,positive
sentence string twice example applied based twice inference script simply set none set,neutral
hello also facing similar issue able resolve thanks advance,positive
hey generate method used interpret also,neutral
hi still feel way interesting discussion subscribe receive,positive
found catch interrupt clean import o import import try run except print try except kill print let know whether work work one click trigger destroy second click want wait,positive
issue resolved recent close,neutral
issue solve seed arch task cosine criterion perhaps need check already tell program training finished know,neutral
issue solve seed arch task cosine criterion perhaps need check already tell program training finished,neutral
issue solve seed arch task cosine criterion,neutral
minimal one able check easily,positive
bump please need solution issue wed stale bot wrote issue automatically marked stale issue still affecting please leave comment example bump keep open sorry able yet new additional information please include comment thread reply directly view,negative
anyone figured use recipe,neutral
like reinstall modification code,neutral
false false work please see,negative
find useful link create file like first column occur second column count label work pretrain,positive
hi anyone please help interpret output generate given beam size generating german large scale consumption large scale consumption,positive
second slightly different git clone remove include add include include include include include include define static err err return implement return err static protect return protect protect else protect return protect static return return void void handle void map warning push warning disable protect warning pop unsupported flag protection return handle return null protect null null return map map null return return map void return return void return return void return return void return return void return return define allow use specific later define change appropriate value target include file include include extern define define define define define define define define define define define define void define define define void void void void void void void go back python install user yes annoying really globally used package fully untested,positive
assumed replace model definitively work tried model gave trying base model like model deal one error one decode self input final decode input taking buffer account data input result data final keep input next call data ca decode position invalid start,negative
currently stuck error error read line section missing empty presume come fact empty til learned flag specify much memory use specify running whose memory limited process might output file blank also redirect somehow see ran line outside manually sure solution within ought perhaps specify relatively low number add comment,positive
hi facing similar pretraining tested running case,neutral
good thanks also reinstall pip pip install sure added though least work way,positive
common issue try run default hardware setup different adjust hardware setup use simulate setup otherwise gradient happen pretraining,negative
might wrong number one control update frequency optimization part one higher training would amount time,negative
every see bring printed increasing time,neutral
experienced problem also work found added latest commit commit old one work well like git,positive
ah seen guess approach maybe could tell,neutral
hi got issue resolve move like item alpha item item alpha item none sure correct answer work,positive
work generally work pretraining model unlabeled data data way around see paper supplement help reinforce model also improve performance,positive
work generally work pretraining model unlabeled data data way around,positive
similar returned library indicate frame number corresponding suppose start time duration audio segment one simple way convert think,neutral
work along pipeline used generation time let know work end also removed size added work associated pipeline used generation time look generation well hello model removed,neutral
check paper ablation section value correct weight word insertion penalty beam beam small guess used transformer matching correct help extra improve performance case addition powerful something wrong valid epoch question wer measure value wer,negative
reason code use argument instead inside additionally add line copy file data model folder run,neutral
hi ran error able resolve commit sure exactly give error picked early enough commit,positive
update minimal working example anyone trying run unsupervised stuck building environment made docker file example,negative
need evaluate suffice refer,neutral
please explain little bit copy code understand thanks advance help,positive
get error switching commit may st current master,neutral
miss still current doc,neutral
temporarily worked around moving task data,neutral
reduced worked bin might working small iterate fast make work lot missing information file,negative
hi solution issue also facing issue currently given anyone solution,neutral
currently stuck error error read line section missing empty presume come fact empty,negative
latest install script running following get halfway clean docker image docker set set set home run activate hook apt update install festival create pip yes activate pip install install yes later install yes pip install install git clone pip install echo export git clone echo export git clone official install build build make bin echo export need go thrice get back base folder apt install subversion make patch git clone echo export make make depend make pip install,positive
something discovered seem like give local path output following command language set output got error file error message looking without portion specifically error line python sil,neutral
something discovered seem like give local path output following command language set output got error file error message looking without portion,neutral
hello also problem trying large small technical domain model get valid wer raw valid wer decrease go consistently like also following set tried cosine improvement learning rate update improvement printed model mostly eventually training word tried various parameter change also audio quieter setting audacity sampling rate set contrast original audio set stereo mono channel new data use pro setup also built pip install python used following training training log note validation interval set conserve memory prone one train model stuck word delimiter improvement made like low beginning make sure incorrectly data everything good perspective sample sample sample alright time approximately sample going know step one remove agree confusion regarding decrease training loss possibility imagine behind model training loss accuracy learned single word cost le longer sense le leading seeing training theory could wrong merely need data quality sampling rate number check audio data already know unusual match audio problem set validation feel like missing one small detail causing problem ca find thank advance help provide struggling awhile long example dont need update probably fit entire training set single example sure order audio file tried work box loss one would expect start except going model learning anything example also got ran data set still ah misunderstood function update thank clarification yes make sure order file try week got think figured problem though believe several dependency installation flashlight python previously training actually sure python successfully due environment set keep trying apologize wasting time unrelated problem thank help,positive
would also happy know,positive
hi everyone solution issue currently facing problem well,neutral
post actual error log setup,neutral
got error object attribute need solution import import import torch import import import open line data line line data line hypothesis print text print text hypothesis,neutral
end complete reinstall across,positive
somehow adjust hardware setup,neutral
work well close issue,neutral
simply gave decide use would go instead search mostly trained also remember read somewhere potential language since later ago actually maybe fixed however note available time smaller carbon footprint smaller well table paper involved model probably one section paper figure paper language sadly able model except use extremely small batch size guess need minimum use even smaller model,positive
concern argument order evaluation use,neutral
found change line recent solve problem,neutral
hi issue flag scoring likely generate default gap large case regarding give add generation like beam match,positive
run program latest version torch error compiler side know fix yeah issue lower version,positive
faced issue pretraining task temporally switched fa,neutral
faced issue solution yet,neutral
thanks posting issue also run issue trying replicate translation example tried flag issue still persist,positive
additional context issue one use exact paper need likely use exact number used paper want use exact paper,positive
solve issue weird modify file manually fix,negative
mistaken iterative product quantization model size within weight matrix result decrease number weight matrix size needing store copy block hence think effect inference time fact probably increase inference time overhead decrease inference time probably look either scalar quantization increase inference speed structured pruning,neutral
found problem like really matter sure exactly work like charm,positive
code used paper cognate prediction machine translation task,neutral
thanks work meet could show full command model,positive
know exactly something temporarily fixed temporarily added commit let know work,positive
hi follow paper reasonable set also learning rate found severe experiment far help lot,positive
hello thanks problem partially linked loading file crash log like log bash file line module main file line main generator file line reader file line file line state file line state state file line state found link state meta information training process didnt help skip process,positive
could please provide reproduction please refer comment provide command reproduce help check correct lexicon directly lexicon set transformer lexicon transformer dictionary name set hi detailed process data run inference bit specific lexicon letter dictionary transformer dictionary appendix paper table model run command line python task path subset criterion letter lexicon transformer python task path subset criterion letter lexicon,positive
one set state set state,neutral
went added print see right return statement load model look state task see none true false false none false false false false none false false false none false none false false false false none none false none false whereas get false false false none none false none false false false false none false false false none none false none false false false false none none false none false false none true look similar one succeed fail,negative
tried tracing back loading actually following pair within whereas,neutral
tried get length model definitely small,negative
ala try step recent call last file line module main file line main generator file line reader file line file line model file line model super file line model self file line return task file line file line return file line name name file line return file line load file line raise file line open file directory,positive
another thing ran across list index range think fact may simply script print length relevant print length print get output like length recent call last file line module main file line main file line iterable file line iterate file line list index range gon na try model,positive
found quite low diversity weight diversity weight please tell value percentage normal range total,positive
figured typo code pasted instead model work correctly extra extra tensor thanks lot help,positive
thanks code however working try loading read file test extra recent call last file line module file line result input file line forward return file line result input file line forward file line file line none file line result input file line forward index dimension size could causing error thanks,positive
hi decrease learning rate help suggestion got previous,negative
use almost anything thanks try,positive
training translation task instead got error related corner case multilingual translation still unfixed,neutral
roger still going taking think might able contribute stuff new note discovered also used,positive
great would like submit improve welcome otherwise keep mind next touch code,positive
thank look much finally gotten around looking ran suggest suggestion add code block create manifest file set original audio python python python python think middle two could include well like python python suggestion clarify command may misleading actually want path new path new python gave path directory directory hand gave path directory inside ended suggestion add around often helpful avoid wrap bash think might help even easier people follow along,positive
diversity loss value enough ensure large portion used try monitor see percentage used value latent latent actual loss value diversity loss doesnt matter ensure sufficient use promote exploration early training phase matter large diversity loss make sure used monitor percentage used latent latent yes high coefficient also hurt main objective,positive
diversity loss value enough ensure large portion used try monitor see percentage used value latent latent actual loss value diversity loss doesnt matter ensure sufficient use promote exploration early training phase matter large diversity loss make sure used monitor percentage used latent latent,positive
diversity loss value enough ensure large portion used try monitor see percentage used value latent latent actual loss value diversity loss doesnt matter ensure sufficient use promote exploration early training phase,positive
like driver problem tried run point work train,neutral
well support version inference version since version,neutral
run training support inference flashlight also tried tried master branch found inference run training,neutral
getting error validation pretraining phase,neutral
access underlying hub interface following looking python import torch test batch extra first model ensemble extra give last layer,positive
think one example maybe done,neutral
thanks address compatibility address problem mention,positive
work confirm talking error unrecognized lexicon,neutral
convert string nope need use lexicon,neutral
path binary language model built contain character space number normally frequency typically descending order frequency hey actually got work like keep getting convert string tried pretty much every iteration single double also like thought path home even pointing file work,positive
could please provide reproduction please refer comment provide command reproduce help check correct lexicon directly lexicon set transformer lexicon transformer dictionary name set,positive
please refer comment thanks reply provide command reproduce help check correct lexicon directly lexicon set transformer lexicon transformer dictionary name set,positive
provide reproduction code version master test paper python task path criterion letter paper python task lexicon path criterion letter transformer none encounter error reach paper tried many different,positive
hi problem setting code smoothly bug team aware fixing huge amount tried line set still got error,positive
used file thank reduce learning rate check performance,neutral
training paper case need reduce learning rate dealing first thing always try lower learning rate,positive
finally understood model properly trained time observing many people struggling overcome issue need modify overcome problem move instead following command provide one trained model successfully data set please provide,positive
hello also problem trying large small technical domain model get valid wer raw valid wer decrease go consistently like also following set tried cosine improvement learning rate update improvement printed model mostly eventually training word tried various parameter change also audio quieter setting audacity sampling rate set contrast original audio set stereo mono channel new data use pro setup also built pip install python used following training training log note validation interval set conserve memory prone one train model stuck word delimiter improvement made like low beginning make sure incorrectly data everything good perspective sample sample sample alright time approximately sample going know step one remove agree confusion regarding decrease training loss possibility imagine behind model training loss accuracy learned single word cost le longer sense le leading seeing training theory could wrong merely need data quality sampling rate number check audio data already know unusual match audio problem set validation feel like missing one small detail causing problem ca find thank advance help provide struggling awhile long example dont need update probably fit entire training set single example sure order audio file tried work box loss one would expect start except going model learning anything,positive
yes prepared according see structure way since prepare training code give warning mixed open source common voice speech text mono channel setup pretraining data well understand training loss decrease meaning somewhere somewhere happy place validation data also tried use common voice data training validation make sure train validation data come distribution effective either best advice offer try carefully examine setup maybe print something wrong loss super low much higher like everything single token like thats thing model sure match case wise,positive
hello also problem trying large small technical domain model get valid wer raw valid wer decrease go consistently like also following set tried cosine improvement learning rate update improvement printed model mostly eventually training word tried various parameter change also audio quieter setting audacity sampling rate set contrast original audio set stereo mono channel new data use pro setup also built pip install python used following training training log note validation interval set conserve memory prone one train model stuck word delimiter improvement made like low beginning make sure incorrectly data everything good perspective sample sample sample alright time approximately sample going know step one remove agree confusion regarding decrease training loss possibility imagine behind model training loss accuracy learned single word cost le longer sense le leading seeing training theory could wrong merely need data quality sampling rate number check audio data already know unusual match audio problem set validation feel like missing one small detail causing problem ca find thank advance help provide struggling awhile,positive
one test prove wrong loss train go right valid loss becomes almost valid accuracy go anyone else something like,negative
thanks worked one trying find import module tell well,positive
assumed replace model definitively work,neutral
get bottom generate file training transcript give error experienced encounter word lexicon found transcript better generate corpus instead avoid problem,positive
find marked legacy though,positive
hi thanks quick reply looking forward,positive
hi push version code soon maybe next week worked old version need merge current master branch,positive
time close specific issue lot time born thanks new audio inference simple work like charm example plus hi work model one,positive
went checked stable version process loss training phase although validation quite nice validation loss go low well accuracy someone explain strange thing use like valid set original,positive
hi first sorry answer lag switching top mind recall could help longer learning rate order first input,positive
thank used exact file used paper used instead file pretraining field removed one stride get thousand speech trained lack also lack think increasing number may converge try thank update wo get output please suggest feel,positive
suspect model like dictionary file list missing,negative
probably train file used training refer paper,neutral
discovered reason wrong model used previously model repository transformer model successfully paper official model site transformer model increasing beam change made get wer right,positive
hi around used model used pretraining discussion used think model training log begin validation subset epoch somewhere made mistake suggest information need share analyze error pretraining used lack model training giving information regarding pretraining exactly used command without parameter except used instead epoch update loss temp accuracy wall epoch update loss temp accuracy wall,positive
see validation wer loss many data train,positive
hi mind model trained thanks,positive
yeah definitely make faster split ran cluster another option also port use end please contribute back,neutral
think actual problem loading model python default may anaconda type help copyright license information import task recent call last file line module file line model file line model self file line return task file line model file line return file line name name file line label label file line label label file line load file line raise file line open file directory know path,neutral
yes prepared according see structure way since prepare training code give warning mixed open source common voice speech text mono channel setup pretraining data well understand training loss decrease meaning somewhere somewhere happy place validation data also tried use common voice data training validation make sure train validation data come distribution effective either,positive
might numerical error think source problem one notice missing sentence oh believe appear one alignment alignment alignment,negative
hi also problem trying base model custom matter wer decrease already set tried cosine learning rate update tried model blank token tried different parameter model dropout mask mask tried different custom see issue data related setup used version build pip install python o find training train log one many please share idea going need information ask provide thanks consideration something wrong extremely low loss token right beginning usually loss high letter based start getting around split word boundary,negative
chapter paper beam add beam transformer add beam thanks wer improve beam even still high could last log output wer generate,positive
chapter paper beam add beam transformer add beam,neutral
hi also problem trying base model custom matter wer decrease already set tried cosine learning rate update tried model blank token tried different parameter model dropout mask mask tried different custom see issue data related setup used version build pip install python o find training train log one many please share idea going need information ask provide thanks consideration,negative
minimum python version discussion minimum python version,neutral
update working training script,neutral
bump mon stale bot wrote pull request automatically marked stale pull request still relevant please leave comment example bump keep open sorry able yet contribution much thread reply directly view,negative
took model part working fine model instructed model file think model made mistake one suggest mistake model linear layer output,positive
looking quick fix trying extract like add return line since variable line disclaimer sure safe want perform,positive
similar trying load model following simple code import task loading error following stack recent call last file line module task file line model file line model self file line return task file line model file line return file line name name file line label label file line label label file line load file line raise file line open file directory like code load dictionary wrong path error occur model,negative
possible pin example lexicon lexicon mean like hello world mean traverse file generate lexicon file format like word letter word corresponding,negative
generate counting number transcription text yes,neutral
possible pin example lexicon lexicon mean like hello world,negative
ex wer wer try reduce wer bit see try thanks answer really appreciate,positive
path binary language model built contain character space number normally frequency typically descending order frequency lexicon confused line format individual space last sorry quite catch build generate counting number transcription text possible pin example lexicon lexicon mean like thanks,negative
path binary language model built contain character space number normally frequency typically descending order frequency lexicon confused line format word tab individual space last letter,negative
unfortunately code written feature since deliver fluent gon na try give search try hopefully help need encode target dictionary need pack method first one pas thing inference took trial error find final solution worked eventually sorry find implementation update best,positive
given every validation process yes wer use,neutral
ex wer wer try reduce wer bit,neutral
sorry topic curious got result valid epoch question wer measure value,negative
transformer step token source done interactive mode hence difference token source interactive mode issue hello add token source source code thanks,positive
unable open memory object mode pickle holding error pickle internally caller worker serialize convert list also problem may slow training slightly,negative
hi problem setting code smoothly bug team aware fixing huge amount,positive
self none else label label return else file label training stage generate kind file pretraining stage need load file,positive
unfamiliar unable add new support work recent success commit,negative
issue calling constrained python would really help lot maybe,positive
one would recommend entire model downstream ie layer input small model downstream,negative
hi thanks seeing similar issue model code snippet reproduce issue import en perhaps went print print print tensor output went went post missing perhaps assigned unknown id cause silent especially true skip output would great team could take look issue thanks,positive
yes would really great documentation comprehensive,positive
thanks also tried uncommenting port value worked well maybe single node training bit better documentation u train distributed cluster,positive
mean unnecessary provide value parameter default value single node multiple,negative
redundant mean removed somehow succeed training single node,negative
maybe found solution issue option give dictionary via change argument model generation time use reset path also example last code line citation personally work translation change argument interactive generating loading model setup hacky job know whether tried already work model maybe also people problem find easily,positive
mean audio one person voice another person wo find looking something like use one another say input audio output text,negative
mean audio one person voice another person wo find looking something like use,negative
unfortunately really keep copy model around path host trained find real solution update,positive
facing similar issue like found solution,neutral
see thanks kind reply close issue,positive
saw line work thus manual absent text know exact reason situation intermediate may get error seeing working prepared step would great create lexicon got zero division error maybe corpus small need use smaller phone cutoff threshold example suitable medium large small tried even threshold error size corpus,positive
mine got accuracy epoch dont know overfit want ask aswell mine normal note overflow setting loss scale epoch update loss temp accuracy wall epoch update loss temp accuracy wall epoch update loss temp accuracy wall,positive
normalize model trained input true check explicitly raise error doesnt match otherwise code like work there extract script unsupervised model,positive
honest might painful dig think model probably also work model maybe exactly close enough run ax tuning day,positive
saw line work thus manual absent text know exact reason situation intermediate may get error seeing working prepared step would great create lexicon got zero division error maybe corpus small need use smaller phone cutoff threshold example suitable medium large small,positive
probably ran memory big change script prune create gram phone instead gram use,neutral
hello ca run script get error error err recent call last file line file line file line file line run raise command idea,neutral
set torch version worked fine please try lowering torch version run program latest version torch error compiler side know fix,positive
getting error like error building wheel suggestion exactly getting,positive
saw line work thus manual absent text know exact reason situation intermediate may get error seeing working prepared step would great create lexicon got zero division error,positive
getting error like error building wheel suggestion,neutral
meet problem training start like confused know solve,negative
done way added think approach would work yes work,neutral
line script paste maybe intermediate step sorry dont understand language question exactly want,negative
seeing error sh compose got unexpected argument able resolve issue version suggestion sh pip install pip install,positive
hi thank much solution still work code insert line function look like python true return right way use training custom task multiple similar error found thanks,positive
hello problem file use supposed another question mine language language,neutral
base pip install building collected building wheel error error command exit status command open compile code complete output running running build running build running directive set change later release file tree error file return result raise class pas undeclared name error file return self char file char line file undeclared name file building extension error use file result compilation error use file result compilation error error command exit status error building wheel running clean build collected found installation successfully uninstalled running install error error command exit status command open compile code install record compile complete output running install running build running build running directive set change later release file tree error file return result raise class pas undeclared name error file return self char file char line file undeclared name file building extension error use file result compilation error use file result compilation error error command exit status rolling back moving moving moving moving error command exit status open compile code install record compile check full command output getting error getting,positive
done way added think approach would work,neutral
problem version module try following sh pip install pip install version torch hope work,neutral
hi thanks trying unsupervised model speech accuracy performance really bad really confused reasonable model unsupervised way similar used static way work well unsupervised target thanks help,positive
thank prepared may something used seed training around clean tested got per,positive
bump issue still sun stale bot wrote issue automatically marked stale issue still affecting please leave comment example bump keep open sorry able yet new additional information please include comment state reply directly view,negative
validation set overcome error kept random text unsupervised wo depend valid set right training completely checked original phoneme sequence made mistake think validation set though unsupervised finally able map given wer paper generate file ca get wer far,positive
yes random sampling work better training tried leaving false,negative
without phone recently pipeline audio text data got something like per sure correctly text data worse similar getting gan model gram word used via dont forget want use step mean adjacent yes yes folder suffix used training dev set dev gan training usually pretty reliable proxy model quality getting getting around without per two provided increase decrease effective batch size training still also following false true understood code mean instead random sampling,negative
already model already performance likely significantly improve corpus unlabeled audio data use pipeline delta wont huge see get couple,positive
without phone recently pipeline audio text data got something like per sure correctly text data worse similar getting gan model gram word used via dont forget want use step mean adjacent tune tuner ax sometimes blank weight close sometimes scale model learned nothing wrong blank weight might get optimal probably wont big good catch line incorrect task right unnecessary normalize important thing block disable segmentation update code soon dev set dev gan training usually pretty reliable proxy model quality getting,positive
time close specific issue lot time born thanks new audio inference simple work like charm example plus,positive
thanks could also add soon replace old,positive
hi log final epoch train log epoch valid validation set overcome error kept random text unsupervised wo depend valid set right training completely checked original phoneme sequence made mistake model th layer text used ah er eh aa ae ow ey ay sh th aw discussion remove symbol later finally able map given wer paper,positive
working next week get work little audio depending use text may need adjust threshold building phone,negative
yes good regarding building binary self rewrite instead may take time meanwhile probably need build script believe,positive
hi training speech data text data got following ref pleasure understanding said ref ay ae aa ah eh er ah ah er ae eh hyp ay ae ah ah aa th ah er ah ah ae ref said shivering passion ref eh ah sh er ow er th ae sh ah hyp er ah sh ah ow ah eh ah eh ow getting wrong number sequence matching approximately original phoneme sequence need change seed training get many run log get lower training past took additional achieve lower maybe check reference match order within running new directory audio may rearrange utterance new,positive
trying understand question like offset one tried something like instead well guess running basic issue getting different exact input python feat feat print true print true print feat feat tensor false supposed,positive
got problem trying use model pretraining environment except pip install,neutral
yes training mixed precision notice ignore long see scale get small scale probably fine thanks answer got warning training however actually happening overflow,positive
towards second question found helpful even ray training,neutral
trying understand question like offset one tried something like instead,neutral
hi training speech data text data got following ref pleasure understanding said ref ay ae aa ah eh er ah ah er ae eh hyp ay ae ah ah aa th ah er ah ah ae ref said shivering passion ref eh ah sh er ow er th ae sh ah hyp er ah sh ah ow ah eh ah eh ow getting wrong number sequence matching approximately original phoneme sequence need change seed training get,negative
hi able fix particular issue,positive
also facing issue particular single ca train getting train default batch size also usage quite low tried increase batch size set give speed training still slow speed usage something wrong bug tried different batch size lesser command python arch task cosine criterion,negative
order output based size audio file example fake value frame order get order output order input,negative
working comprehensive run pipeline something next week stay tuned meanwhile answer need finished,neutral
building latest version git git clone pip install instruction run comment instruction import torch import model task model model worked problem installation install pip get latest version,positive
git clone pip install data saw comment run saw comment import torch import model task data model model got recent call last module self self similar forward return return self self self input result input else result input hook forward positional argument given,neutral
also trying reproduce score model able script use data data echo echo ref git clone set echo data cat echo echo converting binary form split split data echo dictionary echo generating hypothesis path split beam tee cut sort cut cat ratio see get score similar paper score could point wrong get close score thanks,positive
thanks suggestion also feel buggy erroneous explore,negative
hi news new pip version fixing compatibility python get python compatibility,positive
question difficult answer would train model make sure exploring hi trying train model scratch audio found training set,neutral
please use new language pair still bit confused,negative
thanks input make training script work however problem facing loss barely converging despite small size language pair common tiny transformer would perform better right think,positive
install via pip tried following installation git clone pip install,neutral
model yes test performance testing pretty simple clear quite accurate new require data maybe able perform bit better best knowledge training unsupervised model first step actual frozen second stage pseudo trained pseudo unsupervised model first step involved least original sense unless view entire process one,positive
following error model anyone similar recent call last file line file line main file line main train trainer task file line inner return file line train file line inner return file line file line loss criterion model sample file line result input file line forward bad operand type unary default used port environment version master master version o pip source pip build command used source pip install python version version configuration relevant information following error model anyone similar recent call last file line file line main file line main train trainer task file line inner return file line train file line inner return file line file line loss criterion model sample file line result input file line forward bad operand type unary default used port environment version master master version o pip source pip build command used source pip install python version version configuration relevant information problem please help thanks,positive
model yes test performance testing pretty simple clear quite accurate new require data maybe able perform bit better,positive
hi tried use found reason final successfully built running kept getting following error last function within file included note candidate class class class operator note template argument note derived writing output version latest compatible fork however code running long remove regarding really think affect anything logging though,positive
version still error else,neutral
seed set try thanks,positive
use experiment completely unsupervised many tried one random within range got much higher perplexity score much higher well update yesterday still local could try,positive
tried new pipeline seem bit better per valid set test set per train faster use text data subset audio data also change gan training sure whether amount data main reason bad ever tried smaller performance besides meet another problem generating generator include nan fine would output none nan use obtain met fixed remove silence test set seem right prepare test data per test great per directly also around per get clean many different tried far yes per directly use audio text original except change valid set time experiment poor performance per test idea,positive
version think might due older version,positive
code still get following error try experiment epoch begin training epoch start recent call last file line module file line main file line main file line main train trainer task file line inner return file line train file line inner return file line file line module attribute,positive
tried new pipeline seem bit better per valid set test set per train faster use text data subset audio data also change gan training sure whether amount data main reason bad ever tried smaller performance besides meet another problem generating generator include nan fine would output none nan use obtain met fixed remove silence test set seem right prepare test data per test great per directly also around per get clean many different tried far,positive
got problem today document already version error log dictionary dictionary loading model loading model recent call last file line module file line main file line main return file line file line state file line model file line model super file line model self file line return task file line file line state file line state model file line return super strict file line error loading size mismatch param shape shape current model size mismatch param shape shape current model size mismatch param shape shape current model model fusion model data instruction said,positive
tried new pipeline seem bit better per valid set test set per train faster use text data subset audio data also change gan training sure whether amount data main reason bad ever tried smaller performance besides meet another problem generating generator include nan fine would output none nan use obtain met fixed remove silence test set seem right prepare test data per test,positive
work fully sharded also doesnt support dynamic code may take different different thats limitation,neutral
end heavy buggy need would recommend model writing wrapper since would faster easier fair really need put lot work library heavy actual use,positive
trying generate bin path en beam task test getting error recent call last file line module file line main file line main return file line file line ensemble file line state model file line return super strict file line return super strict file line raise loading error loading size mismatch weight param shape shape current model size mismatch weight param shape shape current model size mismatch weight param shape shape current model size mismatch weight param shape shape current model size mismatch weight param shape shape current model size mismatch weight param shape shape current model issue combination training work,positive
hi also similar type sequence sequence task file two input output please share code guide data model need done get also explain tried possible,neutral
ah turn two result nonsense show file likely speech properly normalization step defined model tell find file generate single file perform inference via trying use model provided,negative
hi test also overload use set clustering index single dictionary letter loss worried store may loading dictionary used stage due reason may want distinguish dictionary explicitly change,negative
hi confused whole point unsupervised text right missing please help pardon ignorance still didnt understand since create file understanding correct also help creation please still please help seem new general first thing say question going unanswered could number could example came time got lost could issue question way guarantee question go unanswered following saying something like still waiting answer maybe read something like see rephrase question whole point unsupervised text right see one word change question whole point unsupervised text right answer sure made whole process yet seen far used expect training exist added anyway could try empty see going forward find maybe take look maybe next question already least specific starting point another question sincere thank constructive feedback,positive
hi confused whole point unsupervised text right missing please help pardon ignorance still didnt understand since create file understanding correct also help creation please still please help seem new general first thing say question going unanswered could number could example came time got lost could issue question way guarantee question go unanswered following saying something like still waiting answer maybe read something like see rephrase question whole point unsupervised text right see one word change question whole point unsupervised text right answer sure made whole process yet seen far used expect training exist added anyway could try empty see going forward find maybe take look maybe next question already least specific starting point another question,positive
thanks explanation could see currently model support new,positive
via pip install also seen different error various version latest master could load new,positive
tried new pipeline seem bit better per valid set test set per train faster use text data subset audio data also change gan training sure whether amount data main reason bad ever tried smaller performance besides meet another problem generating generator include nan fine would output none nan use obtain met,positive
independently base large ca load new version without making use version get bunch unexpected use version unexpected assume error loading missing key unexpected key case seem impossible load without hacking around,negative
actually use case wo general found error message originate line,positive
prepare case punctuation removed prepared like open open line print list used see script audio number format open hi confused whole point unsupervised text right missing please help pardon ignorance still didnt understand since create file understanding correct also help creation please still please help,negative
need create transformer also way get output,neutral
large post transformer setting usually start transformer block though extra end transformer,negative
python bit easier install,neutral
yes typo file absolute audio corresponding transcription error format number number absolute file case problem seeing reading file reading got thank much,positive
prepare case punctuation removed prepared like open open line print list used see script audio number format open hi confused whole point unsupervised text right missing please help pardon ignorance still didnt understand since create file understanding correct also help creation please,negative
yes typo file absolute audio corresponding transcription error format number number absolute file case problem seeing reading file reading,positive
help search relevant question search question want train model error code arch recent call last file line file line main file line main file line main file line file line file line file line return file line raise tried tried pip install work tried command python got message warning imply consider explicitly error void function return type void note see declaration error redefinition different type note see declaration error argument convert note operator available perform conversion operator error argument convert fatal error error count stopping compilation error command visual studio exit status environment version master version o win bit pip source source build command used source pip install python version version configuration relevant information hi error,positive
appear please show example make command python valid produce non zero,neutral
appear please show example,neutral
hi team getting error first step python reason take first row data please help image please see folder like think contain null string please check file make sure file missing value dont see null string file still facing issue,positive
hi team getting error first step python reason take first row data please help image please see folder like file contain also showing file folder script typo yes typo file absolute audio corresponding transcription,positive
great still stuck like first number line included file note line know generate corresponding use training gan model nearly empty could give advice thanks lot sil used package reference footnote paper converting text phoneme removed numerical stress additional symbol get following set original paper ah er eh aa ae ow ey ay sh th aw sil use following code generate one provided remove additional lexical stress train gan may need parallel text need sort text simply used corpus believe also used regarding file selected avoid even partial overlap training development based corpus fairly large cause computational burden generating though likely gan training used whole corpus anyway yet figure model though,positive
great still stuck like first number line included file note line know generate corresponding use training gan model nearly empty could give advice thanks lot sil,positive
update result look fine phone error rate like one order evaluation,positive
future reference issue sure issue however issue like multiple possible issue could underlying problem,positive
converting model able export quite grad hear new feature please test resulting model accuracy best test numerical compatibility one sure,positive
converting model able export quite,positive
great could please add test may useful example added test,positive
hi team getting error first step python reason take first row data please help image please see folder like file contain also showing file folder script typo,positive
end end tutorial train see,neutral
prepare case punctuation removed prepared like open open line print list used see script audio number format open hi confused whole point unsupervised text right missing please help,negative
hi team getting error first step python reason take first row data please help image please see folder like think contain null string please check file make sure file missing value,positive
hi team getting error first step python directory file present along audio reason take first row data please help image please see folder like,positive
end end tutorial train interested knowing please reference found,positive
end end tutorial train,neutral
thank got get proper inform,neutral
hi kept code data got previously posted error ur suggestion data getting following error file line file line main file line main task file line assert task none could infer task type available could infer task type false false none false bin available,negative
log still figure wrong made,negative
thank tried run code data data get clearly exact folder copy file added one import folder copy file folder copy added import import already import trying training week place could give thank,positive
met perhaps file path correct copy data data,neutral
hi tried data preparation language later put code data corresponding able solve error please give extra run code file line module import import name partially module likely due circular import,positive
hello another problem although,neutral
sorry issue assumed people involved discussion would interested least go anyone successfully trained gan model corpus used original paper somewhere close error rate currently code achieve le successful past week half figure edit work mistake forgetting check alignment removing issue still however,positive
corpus even worse nearly got nothing decode one phone line result know fix experienced issue output certain pattern probably completely acoustic sil sil eh sil ah ah ah sil sil ah sil aa sil aa sil sil sil er sil er sil eh ae sil ah sil sil eh sil eh eh sil sil sil sil sil ay ae sil sil sil aa ah sil ah sil sil eh ah ah sil sil ah sil er sil sil aa ae sil sil ah sil sil sil sil ah sil aa eh sil sil sil er ey sil sil aa sil ah sil ay er aa er sil aa eh sil sil ow sil er sil ah ay aa ah aa er sil ah sil sil sil aa ah er sil er sil er ae sil ah sil aa sil sil aw sil eh er sil er sil sil ay sil eh sil ah sil aa sil eh er er ah sil sil sil eh sil,positive
corpus even worse nearly got nothing decode one phone line result know fix,negative
may luck convert model format,neutral
news find trying fix issue luck,neutral
really give semantic information speech looking acoustic use vector together feed classifier input like everyone carry semantic information add feature given sound sample,positive
also get error use lazy try train line dump file protocol serialize object version python o,negative
far look right pip pip install git clone pip install apt install festival official install got ta build shown copy built need first,positive
likely ran memory try prune bit building,neutral
also getting error well primary directory found check directory readable empty directory bypass test ran python sil python tried actually completely shrug think celebrated early running two quit middle finishing building final graph text corpus corpus feeding first line error err recent call last file line file line file line file line run command second line error err recent call last file line file line file line file line run command idea would case also stage built used thanks,positive
warning error critical call automatically defined root logger function nothing root logger already unless argument force set true,positive
working comprehensive run pipeline something next week stay tuned meanwhile answer need,neutral
also getting error well primary directory found check directory readable empty directory bypass test ran python sil python tried actually completely,positive
tried one example got error listed,neutral
also getting error well primary directory found check directory readable empty directory bypass test ran python sil python,positive
also getting error well primary directory found check directory readable,positive
even threshold every instance still getting divide zero,neutral
note already threshold param perhaps supposed change,neutral
specifically added threshold line,neutral
added threshold still getting still curious sure empty python line seem empty sil plenty stuff,positive
specifically happening line something wrong think getting thing input fine later happening threshold set high going assume happening,positive
specifically happening line something wrong think,negative
something went wrong output ar meith give try note interest output empty particularly base total base total reply directly view,negative
perhaps input file line empty,negative
give try note interest output empty particularly base total base total,negative
try something similarly low use making phone data setting threshold later ar meith got figured one left recent call last file line module file line main file line main file line train file line file line sum division zero come line python reply directly view,positive
got figured one left recent call last file line module file line main file line main file line train file line file line sum division zero come line python,positive
also use another think paper use default option section also removed numerical stress output,neutral
also use another see code another one directory long output format make difference use one based get whole way test run,positive
sorry hijack issue following issue two building word recent call last file line file line missing mandatory value union argument guess code building graph latter however see latter used,negative
install mention need take resulting copy oh yeah intended sort install mechanism,neutral
fixed trying figure fatal error found executable file warning return object similar fatal error found executable file fatal error found executable file one,positive
install mention need take resulting copy,neutral
yeah need also install running make sure strictly necessary maybe running enough,positive
install git version also command found command found missing first bit worked fine pip navigate top level pip install sure install tried pip install error try building make,positive
install git version also command found command found missing,negative
model link run script lid bin,neutral
gave error loading model lid bin loading error also use another,neutral
exist use got point yet used assuming format word er word space space list,neutral
also getting error later figure apex package try import command running successfully system also please let know know predict model,positive
since model chance know predict model,neutral
hi running gave notice found path,neutral
added command measure memory appear change course loop,neutral
problem removing looking code twice,neutral
text input think used text language model,neutral
oh also fake number really want give snippet thank file whose format little question file text corpus besides know content file,negative
long ago old dev branch tried working except issue fixing,positive
thats interesting see memory growing time,positive
good point work new older fix soon,positive
oh also fake number really want give snippet,negative
prepare case punctuation removed prepared like open open line print list used see script audio number format open,neutral
sorry still provide much information best guess data provide flag script language type material,positive
applied removed python script course different script gave file empty train although tried apply script supposed prepare first,positive
please describe detail done give information beginning quite new detailed stuff yet,positive
nice script prepare general main example site see yes know gave empty give file script,positive
nice script prepare general main example site see,positive
update load model call get dictionary come since derived implicit default,neutral
tried loading model setting none saving model inference got error non optional field assigned none quite annoying always keep two model around inference surely must way fix,negative
try validation data think failing find,neutral
assuming example python import model data path file line need data want load model,neutral
think anything wrong tried worked fine tried mask got following maybe mask sentence trained well order get probability target word think maybe need revise function line prob prob dictionary may need encode target word dictionary first get probability index hope help,positive
maybe solution elaborate experienced problem install pip use block following message displayed model training module try install manually pip install following displayed fatal error file directory include fixed running python reason also change path relative path worked build,positive
getting error trying fine tuning model pair command like attached within issue arch transformer task temperature criterion dropout seed simple test task anybody issue possible solution suggestion may need make sure inside train valid,positive
facing issue however need create step split way create different think problem data size create proper maybe first create data idea thanks,positive
hi trying loading well length default setting add special token size layer size add extra special token like mask building model append end,positive
please proceed merge really minor change ai project bug fix link people fork fix ideal may trouble,positive
reference find error following commit training via consequence additional task model give actual see argument however case used,neutral
think found version error gone,neutral
yes dependent language work signal level,neutral
resolved order use git clone,neutral
know whether train another model,neutral
met problem waiting staff provide documentation explain load,neutral
thanks reply code linked allow load base however still first assuming model work standard torch loading standard torch loading standard approach used library working approach work correctly change use already link documentation provided link second new code several think also difference within difference versus ask direction best modern way use feature extractor speech vector role task able omit code still work finally new approach still compatible python default type help copyright license information import torch import content content recent call last file line module file line none arch none file line file line file line ex cause file line raise ex set end full missing mandatory value model model union content none true content recent call last file line module file line file line file line value registry type import content recent call last file line module file line return file line file line file line file line ex cause file line raise ex set end full file line return file line node file line key file line file line file line ex cause file line raise ex set end full key union content recent call last file line module file line return file line object attribute content recent call last file line module file line return file line object attribute met problem,positive
question manage find answer elsewhere,neutral
sorry thanks regression test done,negative
know right way think issue function error path difference making tensor process instead got code import torch import optional import random shape float static float bool false none random mask given shape shape shape compute size first element batch size optional padding mask size shape prevent probability token chosen start span masked number divided length mask span mask approximately percentage however due actual number smaller unless true size mask minimum number masked shape mask false add random number probabilistic rounding float return mask none else none range none add random number probabilistic rounding float else sum min min else sample replacement range offset range offset range min enumerate mask true mask true return mask error another one problem return dictionary model like class self super self false forward self return model task model model print model model model remember end code like model except one done well enough function index given long type however type long type different terminate throwing instance following operation interpreter code recent call last file line forward forward self tensor tensor false false none return file line forward annotate list optional tensor false index mask index index original code recent call last forward forward trace module index put source destination match got long destination bool source aborted core think close solution,negative
interesting problem also script error exactly model task model model model error note load save problem arise,positive
need large batch size maybe,positive
learning context torch really meant context create context current device avoid change default device via problem default device new fallback unless call new thread creation context,positive
model found additionally need use arch command task current say use arch transformer failure load recent call last file line file line return super strict file line raise loading error loading missing key unexpected key size mismatch param shape shape current model size mismatch param shape shape current model exception load model please ensure match,negative
bug side problem custom gradient synchronization fact sometimes none,neutral
check paper ablation section value correct weight word insertion penalty beam beam small guess used transformer matching correct,negative
hi recreate weight word insertion penalty beam size also play important role used variety based data set please refer paper section used different base model transformer got weight word insertion penalty getting around,negative
also issue solution variable error trying export model format issue inserted following code got issue file line module file line main file line main file line export return model verbose training file line export model verbose training file line model verbose file line graph model file line graph model file line model file line strict file line result input file line forward graph file line wrapper file line result input file line result input file line forward file line file line file line module file line main file line main file line export return model verbose training file line export model verbose training file line model verbose file line graph model file line graph model file line model file line strict file line result input file line forward graph file line wrapper file line result input file line result input file line forward file line file line anyone help wrong,positive
bug bug robot lab python recent call last file line module file line forward source file line result input file line forward file line result input file line forward input module input file line result input file line forward return input file line input weight got input size instead reproduce python content import torch import model print behavior text converted input audio file name environment version master version o pip source source file build command used source pip install python version face issue use sure use input dimension expanded automatically,positive
like freeze freeze available add therefore code way people much flexibility stage sometimes want tune classification head last make training faster,positive
hi thanks however think provided model question corpus used model publicly,positive
think section paper pertinent pasted markdown data pretraining crucially large text al demonstrate increasing data size result performance several trained diverse original yang unfortunately additional publicly study focus gathering much data possible experimentation u match overall quality quantity data appropriate comparison consider five corpus size uncompressed text use following text corpus plus original data used train collected portion news data million news filtering footnote use collect extract similar al recreation corpus al text web content extracted least three subset data match style,positive
facing issue done evaluation would like generate solution yet,neutral
float got long get self input false try result input finally forward positional argument given,negative
turn server virus could included,neutral
easy could load simply create model function could change get model,positive
hi wondering someone tried pretraining,neutral
probably bug folder outside purview included package check level anything inside importable importable,neutral
easy way reduce size model leave information wo good could reduce pretraining lead smaller model try searching pruning bit usually someone find way,positive
self train first want get pseudo running raw pseudo need short audio correct transcription want training infer model run use raw may noise silence would work check common voice project need input like regular silence check common voice please close issue,negative
path beam task test command fine tune model getting size mismatch error error loading size mismatch param shape shape current model size mismatch param shape shape current model size mismatch param shape shape current model size model size matrix size matrix could please help,positive
hi release help reproducibility rely heavily data ca looking description please check paper please message concrete,negative
try mon may ping wrote problem thread reply directly view,positive
hi way work model architecture share trying train architecture multilingual translation task follow example train architecture flag get following error dictionary source dictionary target dictionary joint source target believe would need create dictionary based reply wo work would get new dictionary could please suggest achieve dictionary train architecture multilingual translation task,positive
offer intuitive example use tried use run could find example thanks,positive
like milestone currently broken recourse yet try install clone fixed branch mess later edit work,negative
would please report sort,neutral
use script kill zombie kill print run following command use python spawn main function kill print hello better way kill training code want kill manually also two training one user figure one task killing,positive
investigation removing label avoid code path understand label switch might provide bunch training need assert sense inference really removing though another bug task path criterion letter criterion lexicon connected build criterion loading model recent call last file line file execute script file line compile file file line module file line main file line main file line state model file line return super strict file line error loading unexpected key loss understand would think unnecessary,positive
thanks reply code linked allow load base however still first assuming model work standard torch loading standard torch loading standard approach used library working approach work correctly change use already link documentation provided link second new code several think also difference within difference versus ask direction best modern way use feature extractor speech vector role task able omit code still work finally new approach still compatible python default type help copyright license information import torch import content content recent call last file line module file line none arch none file line file line file line ex cause file line raise ex set end full missing mandatory value model model union content none true content recent call last file line module file line file line file line value registry type import content recent call last file line module file line return file line file line file line file line ex cause file line raise ex set end full file line return file line node file line key file line file line file line ex cause file line raise ex set end full key union content recent call last file line module file line return file line object attribute content recent call last file line module file line return file line object attribute,positive
issue though latest version,positive
problem come different data process old version latest therefore reprocess data run,positive
yeah thanks actually last commit worked fine,positive
issue python error occur python probably due python,negative
thank response let try,neutral
something happening even though trying train transformer,neutral
apparently script work removing,positive
hi please try commit think working something large previous commit work fine,positive
would possible share setup know setup model,neutral
model load check two model path model want load model try setting none code pick,neutral
go manually set line import,neutral
hi yes used worked,neutral
hi able train multilingual model scratch,positive
hi able train multilingual model,positive
mean get found file need run tried far please follow issue,negative
assuming model work standard torch loading however bunch code backward compatibility load following example file,neutral
successful base python default type help copyright license information import torch import content content content successfully model work correctly base python default type help copyright license information import torch import content content recent call last file line module file line return file line object attribute content class organization substantially unsurprising model python default type help copyright license information import torch import content content recent call last file line module file line file line default object attribute content content none true content none false none none false false false false true false false none none none none false none none none false none none true false false false false none false none none none none none none false none true none none none false none none false false none none false false false false false true false false false none false false none false false false false none false false false none false none false false false false none none false none false false none true true true false false false false false false none true false false none false false false false none false false false none false none false false false false none none false none false temp false false temp none none content recent call last file line module file line file line default file line raise file line key value file line key value file line key value file line key value file line target key file line key file line file line file line ex cause file line raise ex set end full key union see content none configuration content different structure tot python default type help copyright license information import torch import content content recent call last file line module file line return file line object attribute content recent call last file line module file line return file line file line file line file line ex cause file line raise ex set end full file line return file line node file line key file line file line file line ex cause file line raise ex set end full key union,negative
data augmented yes may extend valid step function module essentially model given input produced like model sample may substitute target input part sample whatever sequence need get desired model sample sample gather specific target token may best way though,positive
say fail initialize based installation mean actual error,negative
year later also struggling replicate anyone figure generation configuration perplexity loss seem reasonable however rouge lower across board,positive
tried far please follow issue,positive
hey epsilon sure issue already potential resolution case anyone else future probably target could loaded data folder regression task data loaded different way specifically label present split instance training data label folder file target new line raw format format please refer line hope,positive
hello think reasonably recent like last training branch done lot pretty sure evaluation go code twice loading file pretraining file derived rate move original pretraining file location loading file script model file one go moving around see find way share pretty large,positive
new one trained different normalization order transformer avoid instability higher,positive
model loaded first start store trying load model afterwards might bug latest version code share example maybe trained update whatever,positive
use different paper tried make simpler present prob mask probability individual start span code actually use parameter approximately percentage total number mask compute number sample starting mask prob,negative
take look use make,neutral
yeah base model please copy model part update get chance,negative
nope back anyone regarding,neutral
half year ago one received load usually one worker another exception worker distributed communication load however case available load load selected except one,negative
search open pull documentation,neutral
also would like thread news,neutral
receive error training model multiple single work,negative
half year ago one received load,negative
advice date current version current example use mean see multilingual translation still use,negative
provide context please follow issue share command ran,neutral
please fill issue template,neutral
yep thank pointing relevant,positive
hello part question lot think start solution script work u may make many specific case hand tested python python convert file model file function without reference base model author van import import torch import import logging message parser file saved output transportable monolithic model file main loading loading model else save space intending training saving portable model main,positive
actually issue error code worked quick fix old new trained code working,positive
script designed work model linked tried guessing different internal structure,neutral
note run original transformer model run transformer base model extra attention layer model custom model run function got error like error loading unexpected key try run model like also change transformer unfortunately got trouble define task,negative
return loss work step call update parameter right find control code like many return loss without normalization,positive
sorry sure understand question return loss,neutral
call use criterion calculate loss get loss way know general code like reset enumerate model forward pas loss compute loss function loss loss normalize loss backward pas wait several backward step,positive
assuming learn input apply text already common way need specify dictionary create dictionary thank much last reply little bit vocabulary size provide dictionary different would also different run different already obtain exact joint dictionary difference provide provide due format issue mean text already common first learn common language previous different language different size content different dictionary get hand let previous equal understand automatically creat dictionary language problem different size provide,negative
assuming learn input apply text already common way need specify dictionary create dictionary,negative
however bash script multilingual translation reference either file mention train apply model raw data trained text applied text file individually script new text get clarify basically need train input text apply text file thank problem learning model however still understand use previous experiment use obtain file learn dictionary provide file also token token frequency format way always get unified joint dictionary setting way dictionary different copy important multilingual translation model however learned different learned like en er e ti second column actually negative id index instead frequency provided input wondering get unified dictionary like provide language dictionary vocabulary number provide dictionary different would also different run different already obtain exact joint dictionary difference provide provide due format issue similar issue wonder remove dictionary would negative effect let frequency equal dummy number probably regenerate dictionary get exact number otherwise model wo trained want reuse dictionary easily convert format main format token frequency space whereas token tab frequency column filtering simply create new dictionary dummy count something also need remove dictionary cut tail also commit shortly option output generation posted,positive
hey sorry typo link correct link correct,negative
yep confirm link broken fix soon thanks,negative
however bash script multilingual translation reference either file mention train apply model raw data trained text applied text file individually script new text get clarify basically need train input text apply text file,negative
include exact code ran,positive
create iteration pas batch group step batch group,neutral
thanks awesome trim low resource run script trim model python output got error please help,positive
add following code line,neutral
hi please let know code need added file line confirmed fix add code line thanks,positive
solve problem also run,neutral
want implement got error loading model error error invalid value one,neutral
run function load custom model got error error message error loading unexpected key handle error,positive
issue specific spacy fix go line change work,neutral
next release install master pip install,neutral
input contain many one per line batch together way another alternative load model torch hub feed without model,positive
guess need train model version shown need write script extract vocabulary version extracted used vocabulary used train model see improvement hope somehow,neutral
hi probably late answer might help somebody output output sort cut output sort cut,negative
hi new python anyone explain would place,positive
base model data without language model know make prediction used following code load model import import torch import model task model model got following error object attribute understand method longer know run inference tested predict predict model get following error forward positional argument given please help,negative
work update fixed incompatibility version install could share update simple pip pip install two instance latest version work,positive
language model trained model,neutral
hi happen remember modify script output probability sentence thanks lot,positive
facing problem anyone solve,neutral
hi meet issue check file fixed already solve problem,positive
also getting error source,neutral
see pip package going happen soon,neutral
facing issue problem thanks,positive
hi exact issue problem come training well evaluation phase chance update code perform comparative evaluation thank much advance begin training epoch start recent call last file line module file line main file line main file line main train trainer task file line inner return file line train file line inner return file line loss file line loss criterion model sample file line result input file line forward model sample file line result input file line forward file line result input file line forward extra file line layer file line result input file line forward file line result input file line forward file line file line file line raise object attribute object attribute,positive
lot different make training hard mode unexpected thank think try find part regularization ca dropout batch norm used,negative
could tell u per able achieve approach note directly comparable phone different still would useful know also would awesome put model,positive
add criterion order translate,neutral
also able run inference provided st model due use see current build training scratch running inference work,positive
line dim essentially greedy algorithm model always taking id assigned highest probability want feed language model instead feed second model apply model added model take input could something like otherwise could try converting input text directly edit page description seen language used training,positive
addition wondering option used content look like simply output alignment attention based model option used replace original source sentence,positive
lot different make training hard mode unexpected,negative
yes even load model via,neutral
effective batch size training command one sorry reply could share plot training accuracy recall correctly directory generate viewable used though,positive
got error get use example without error go away right ran command without error gone issue something related together,positive
problem find fix thanks,positive
hi problem even though present correct format trying generate recent call last file line module file line main file line main file line raise found split found test could causing thanks,positive
get error although test find solution,neutral
effective batch size training command one sorry reply could share plot training accuracy,positive
getting translation result different reading local path loading,neutral
got error get use example without error go away,neutral
write solution error becomes multiple instead one token model predict input code comment finally add algorithm policy agent,neutral
thank make sense made local instance positional attention layer see score without able get around score able replicate score paper,positive
anyone problem quick solution fixed python new object,positive
complete example reproduce insert following line loading python import pickle execute command tutorial bash receive following error bash recent call last file line file line main file line main task file line ca pickle attribute,positive
anyone know short mean,negative
library would great equip,positive
try setting variable worked running code docker,neutral
run model use inefficient want efficient help path en beam task test,neutral
found error path hi faced problem figure,neutral
hi problem also meet issue hi share training log thanks,positive
issue solve command python,neutral
hi met problem reinstall would work either find,neutral
anyone team address question point appropriate code thanks opinion position attention paper al actually sequential tackle issue position attention solve,positive
hi main loss weighting see logic added support secondary agree messy working logging get rid entirely hi could explain validation loss training loss curious calculated different way,negative
reproduce use source work left see use large batch size multiple setting set,positive
got error trying run float around stride line slightly different solution,neutral
hi issue anyone solve problem,neutral
hi right set another model trained make sure model used model model good luck object attribute like true wer model true hi nick corpus wonder thought also path could please explain reply directly view,positive
thank much detailed explanation one thing find different learning paradigm paper implementation pas corrupted version target forward function paper say randomly use one corrupted version original target case would general see implementation adversary random construct policy,negative
first error got finding train st provide path file name think data directory path file path silently file find training successfully commit hi also meet issue following suggestion check commit still error addition issue date mar bit confused commit solve issue even thanks advance,positive
problem following command bash path test task beam,neutral
thank much pull request change,positive
run model large make sure break smaller voice activity detection run model smaller finally concatenate output end,positive
hi added please check run list see work would appreciate see several currently use one constraint list would output garbage text second consequent thanks help,positive
hey get response question unfortunately however think sort answer related idea rather actual implementation ape pas anything model evaluate original sentence given triplet calculate trained feed sentence initialize empty string let fill sentence hopefully create target sentence evaluation ape still feed initialize essentially give model head start giving possible output sentence already systematic ape model fix task start empty string sort last couple assuming initial sentence model train ape task training thing talking case initialize let model learn behavior fix given sentence instead generating scratch sure really code ape task tried code could get performance,positive
think issue somehow fixed recent sure exact commit use latest ran another error think better track another issue,positive
unfortunately dont trained older branch able reconstruct pretty easily looking,positive
would like contribute issue possible place look error,neutral
thanks lot commit able train,positive
like true wer model true hi nick corpus wonder thought also path could please explain,positive
hi got answer question understand experiment setting used paper,neutral
issue please reopen help,neutral
figure problem implementation model python version used code version one provided one different token vocabulary got version parameter ground truth text comparison local size local size size difference difference,neutral
would nice see file thank,positive
running single machine multiple raise error process following error recent call last file line file line main file line main train trainer task file line train file line assert norm norm file line assert norm norm file line wrapped return device found least two shell script python nag momentum seed seed missing anything python version version version version think problem might version met problem downgrade problem,negative
train inside file used fine tuning script working,positive
hi thank much bug fix recent update could please pull master try,positive
hi glad work could please share inference log could look output directory thanks,positive
look file see field set script looking data directory character recognition way looking training know turn validation create set way training set put data directory validation set something else like change value file field,neutral
hi complete evaluation tst set configuration tutorial page obtain following worse blue public quality latency al dal possible wrong thanks,negative
yes would start data replace span single mask token fact one experiment data augmentation transformer refer code,negative
hi documentation left comment may help,neutral
first error got finding train st provide path file name think data directory path file path silently file find training successfully commit,positive
hello able train first place facing issue follow process train model,positive
use data process best model batch size used linearly decayed also input document truncation position min length length beam size length penalty used achieve best result could please clarify similar thank,positive
hi meet question solve problem use totally different dictionary corpus error size mismatch param shape shape current model size mismatch param shape shape current model model know initiate command find problem met mismatch task translation blame therefore close issue idea issue could provide,neutral
hi meet question solve problem use totally different dictionary corpus error size mismatch param shape shape current model size mismatch param shape shape current model model know initiate command,neutral
found issue reason command hamper normal generation,positive
sorry found solution case single node redundant,negative
try pip install yes source code install suggestion command pip install still got error report import name,neutral
hey honestly tested got lot else rent server test efficiency model huge load hardware equipment,positive
run successfully tell efficient going buy eight,positive
well bit tricky provide working example say custom transformer library stripe lot basically initialize like constraint input seed parse feeling attraction input parse love constrained beam search seed run rest code add seed output input without seed output nice long sentence,positive
post minimal working example input command take look,negative
mean token end one constrain output constrain beam size help produce rich without let know reproduce,positive
quite sure mean assumed meant hard answer without knowing exactly input command invocation,positive
add would output setting help say custom transformer model maybe something else affecting different behavior,neutral
since conversation continued original thread,positive
force applied end sentence curious understand better glad working found bug constraint constraint interrupted instead starting beginning constraint entirely effect multiple fix soon,positive
hi suspect properly target provide detail invocation command output provide sample input,neutral
setting reason default value understand small value would cause chosen think something done right,positive
yes good per able phoneme recognition good per per close research paper see thread,positive
point clarification thread training ended thread training different set,neutral
able approximately recreate phoneme recognition training validation different used research paper used split model per validation set close paper given phoneme recognition evaluation command ran python task path valid criterion summary end evaluation output hypo sil ah aa sil ae sil er sil target sil ay er sil ae sil er sil hypo sil eh ah ay ey er sil target sil eh ah ay ey er sil hypo sil ay sh sil sil ow sil target sil ay sh sil sil ow sil hypo sil ey ah ay sil target sil ey ah ay sil wer generate valid may notice different research paper used different equivalent original outlined training command ran reduce similar time avoid error subsequent training value sure redundant work summary final file begin training epoch start epoch update loss wall stopping training due begin validation valid subset valid epoch making save epoch saving finished saving saved epoch score writing took end epoch average epoch train epoch previous high around end training run training job ran training unchanged original file file took roughly train thanks help,positive
machine translation first setup machine model default everything machine cache copied cache machine cache typically one need copy two hub machine cache instead path given path local machine cache import torch run got recent call last file line module file line load model model file line model entry file line file line data file line join object model path line model working import torch print welt matte loading read file world cat sitting mat,positive
hi trying adopt transformer model level seem work well beginning sequence token regardless input work well word level though rich correct think problem thanks,positive
news ai project bug fix link people fork fix ideal,positive
beam size always equal,neutral
though error message log slightly different tried latest master branch current state file line apply return self type ignore file line backward file line backward file line return file line file line recent call last file line module file line main file line file line spawn return join daemon file line file line join raise process following error recent call last file line file line main file line main train trainer task file line inner return file line train file line inner return file line loss file line loss file line backward file line backward self gradient file line backward file line apply return self type ignore file line backward file line backward file line return file line file line raise current state appear semaphore clean shutdown appear build command bash install git clone git clone pip install pip install apt update install screen pip install pip install python pip install pip install version,positive
confirmed got similar result removing copy without copy however little different paper especially first one think help lot people make clearer,positive
update also got error try,neutral
issue causing default process group value training single node multiple instead remove value command go onto next calling method,negative
thanks start training gotten good per yet,positive
initialize null proper value,neutral
anyone team address question point appropriate code thanks,positive
single node running command default process group summary full recent call last file line module file line file line file line file line raise ex file line return file line lambda lambda file line run return file line file line file line main file line main trainer trainer task model criterion file line file line return file line return file line return file line file line assert none default process group full train log saw reply comment though give set distributed world size based default bit around help searching error,positive
see thank paper see large large notation since large model assume still use even though large rather base model right would get best phoneme large model best wer though expect paper large reason find large model produced better large model mind effective model see get good model pretraining across fact get similar predictive pretraining really power architecture wow thanks help,positive
model different base large model due different normalization data base model use yes always version model,negative
see thank understand similarity issue may helpful yet gotten model effectively predict code training longer recreate paper phoneme,positive
thanks quick response noted loss great thank tip expectation start seeing good exactly looking double checked alignment find error going start training run training set tonight see evaluation flashlight annoying big deal two question phoneme paper hour subset file training model large model,positive
allow clarify yes trained predict trained predict transliteration imitate choose phonetic string instead,neutral
something change file specify valid value loss important thing look per token loss small size like want start getting good loss basically random chance cant improve something wrong setup maybe data evaluation yes know annoying install flashlight even strictly code require flashlight get chance,negative
thanks confirming going close issue following missing length check,neutral
thanks following issue recent update problematic modify none assert got modification confirm st reproduce score,positive
thank much able merge authorized could please merge,positive
issue line dictionary file provided documentation working previous model working properly,negative
solve model criterion model trained training per per none recent call last file line module file line main file line main trainer file line file line state file line state state file line state state,positive
format sound almost certainly use kind think saw something similar implement different data loader,positive
simple code didnt get around without depending flashlight wer unless provide case fact use flashlight,neutral
set bold total number training learning rate many peak learning rate adjust sequence length positional usually number per batch batch size increase batch size,positive
full log command task criterion arch complete dropout simple none none false none none false false false false false true false false none none none none false false false false none none none false none none none false false false false false none false none none none none none none true false false false false false none false none none none false none none none false false none none false false false false false false false false false false false none false false none false false false false none false false false none none false none false false false false none none false none false false none false false none none none none dictionary linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear dense linear task model criterion model trained expert model trained loaded loaded parameter rank total memory name training per device none per device load found loading train data epoch loaded loaded warning invalid size first sample begin training epoch start exception thread recent call last file line file line run file line range file line mask signal number range,negative
thank resolved problem one question would like work text instead speech convert format code train model,neutral
use still need install flashlight copy code adapt something like use instead flashlight question default setup calculated without flashlight log thanks,positive
use still need install flashlight copy code adapt something like use instead flashlight,neutral
example trying dont currently example pretty easy adapt code make work,positive
trying hugging face implementation would great start super nice trained actually took model one downside dont think use language model added top get working,positive
shouldnt happening version please get latest master reopen issue,positive
parameter mostly stabilize model default extractor mode prevent late training little effect final accuracy new recommend true set penalty weight parameter disable,positive
there problem python code need iterate obtain sample use model,neutral
hi welcome cluster mechanism issue two way also try try run server client separately user docker run evaluation feel free let know question,positive
inside folder folder equal gave doc indeed,neutral
hello solve issue also facing issue,neutral
wonder problem come nearly problem yes could please tell solution best,positive
good logging level problem getting stuck right message evaluation server process id listening port one logging logging level every talk even sometimes simply message job said complete evaluation know whether server rather cluster eventually carry evaluation bit impractical sudden one automatically carry evaluation one talk without check every time evaluation process still ongoing stopped message thank help,positive
hi daily mail token work fine thanks lot hi read line ca figure original proper way add think source example source target example target line code need keep right thanks,positive
thank helping trying recognize phoneme alphabet trouble resolved,negative
found parameter forward function error,neutral
ah fix concurrent seeing one thank close since fixed master already,positive
yet issue suspect lot code model loading configuration load old commit model loading probably work,positive
issue built together torch seem without pip issue,neutral
hugging face feel free try think comment may bit misleading clarify understanding reading thread title thread content phoneme recognition recreate research paper understanding predict predict correct start thread hugging face phoneme recognition post link thread also interested phoneme recognition working thread see get implementation work phoneme recognition,positive
hi rerun evaluation able reproduce issue evaluate one could change logging level see detailed logging sorry hack make logger level soon,positive
hi solve error also facing error python manifest model arch task cosine command training model custom wave installation give,neutral
thanks report could try solution follow installation able run import,positive
thanks issue please pull latest master branch,positive
also tried passing one model path task test criterion get error loading model recent call last file line module file line main file line main file line main file line model file line model super file line model self file line return task file line install please install git update ran git update already showing error,positive
also would like know,neutral
also interested multilingual model news luck,positive
try make load import import torch print get true true true false false false false false false recent call last module print task return self self must string code object,negative
tried option script still step evaluation warning root module speech source target number evaluation server process id listening port hence problem persist thanks help,positive
figure process data process data go wrong process whole training data go well,negative
think move conversation hugging face said understand getting size,neutral
hi phoneme recognition even though encode phoneme multiple difficult instance gave phoneme text aa actual hope get though pad idea encode token multiple addition already tried pas list,negative
thanks split audio talk sentence based file meant could try option,positive
thanks know mean segmentation split audio talk sentence based file checked segmentation carried properly listening produced audio first making sure division,positive
trying another asset work without tag close issue thank,neutral
thank report input segmentation prior running,neutral
sorry interrupt process pretraining right special special like mask example token mask done mask would something like separate sure whether think right thank,positive
hi following recent implementation model mean mean would mean every model saved also drive full issue step training loss validation loss wer per second training loss marginally decreasing wer still done improve faster training better accuracy also tried higher learning rate training loss still poor model converging,negative
think randomness beyond random seed see,negative
right sorry miss case version train validate maybe version also binary architecture related,negative
work update fixed incompatibility,positive
faced similar issue recent call last file line module file line main file line main file line main task file line return file line file line dictionary file line load file line raise file line open file directory ca run training,positive
written post built master branch week ago least right try check different,negative
seen binary incompatibility error sure however training succeed validation problem saw running,positive
maybe size large trying convert mandarin char size give result later hi encounter problem reason perhaps related hyper parameter wer decrease another question use model process audio result many repeated character know related format treat every character word split first train model result share epoch update loss wall,positive
hi end tried fresh reinstall another machine worked either machine something case thanks,positive
one case anyone give direction look,neutral
someone help question trouble paper wondering cause,negative
previous error one bash recent call last file line module file line main file line file line return join daemon file line file line process signal,neutral
hard custom flow ended create multiple word together single one use single input,negative
hi new requirement use address,positive
error message get number initial model match corresponding value loaded model said carefully ensure match case however number wrong size parameter number vocabulary size maybe missing parameter automatically vocabulary one extra token language language necessary indicate language process actually assume need provide argument could find manually extend file model file original become turn automatically extra end sentence unknown word vocabulary note could go wrong example list lexicographical order order considered index corresponding indicate would match used case generate system generating working still memory trying model though last point knew language form well append different say form ask generate complain index found token give hint dictionary incomplete missing something tell progress,negative
first epoch epoch epoch epoch data loading buffer empty nearly empty may indicate data loading bottleneck increasing number may help data loading buffer empty nearly empty may indicate data loading bottleneck increasing number may help epoch epoch epoch data loading buffer empty nearly empty may indicate data loading bottleneck increasing number may help data loading buffer empty nearly empty may indicate data loading bottleneck increasing number may help epoch note overflow setting loss scale epoch epoch begin validation valid subset valid epoch valid subset loss begin save saved epoch score writing took end epoch average epoch train epoch loss wall begin training epoch data loading buffer empty nearly empty may indicate data loading bottleneck increasing number may help data loading buffer empty nearly empty may indicate data loading bottleneck increasing number may help epoch begin validation valid subset valid epoch valid subset loss begin save saved epoch score writing took epoch epoch data loading buffer empty nearly empty may indicate data loading bottleneck increasing number may help data loading buffer empty nearly empty may indicate data loading bottleneck increasing number may help epoch epoch epoch epoch data loading buffer empty nearly empty may indicate data loading bottleneck increasing number may help data loading buffer empty nearly empty may indicate data loading bottleneck increasing number may help note overflow setting loss scale epoch epoch begin validation valid subset valid epoch valid subset loss begin save saved epoch score writing took end epoch average epoch train epoch loss wall begin training epoch,negative
simple pull request show issue starting work sure patch good enough,positive
hello finally manage make work solution work yes could explain tested said trained one transliteration work fine,positive
hello finally manage make work solution work yes could explain,neutral
common voice good start possible find better material maybe use suitable language model,positive
hey aware claim wer word error rate german voice corpus test set know trained,positive
yep got still really slow process lot different yet archive training speed original paper,positive
hello update issue unable model thanks,negative
hi thanks detailed answer tried run provided issue resolved getting size mismatch error error loading size mismatch param shape shape current model suggest could wrong trying model file script file de en en de except trained model instead used trained model,positive
thanks help issue resolved,positive
please replace done may work word score spelling list word print word spelling,neutral
three different number currently indicate model size number whose default match actually used architecture model loading already model see script list first initial model architecture arch loaded model initial model architectural difference model wo loaded carefully review model use script copy relevant command line used initial model trial error following see worked notice include define architecture staff may particular task related model architecture arch also change file name necessary although sadly however model spite memory training start still working let know progress model successfully loaded question task ar ast ba ca da de el en e fa fi ga ha hi id ka ko lo ne pa si ta th ur wo yo temperature criterion dropout seed simple patience arch task ar ast ba ca da de el en e fa fi ga ha hi id ka ko lo ne pa si ta th ur wo yo temperature criterion dropout seed simple patience arch task ar ast ba ca da de el en e fa fi ga ha hi id ka ko lo ne pa si ta th ur wo yo temperature criterion dropout seed simple patience arch hope,positive
found could solve problem curious reason behind,negative
problem got solution issue echo import o path echo,neutral
sorry curious number per batch training process view think average might lead unexpected saved middle one epoch,negative
discussion author directly loaded st trained assuming trained single since,positive
hi find solution facing issue,neutral
thanks recommend following end end running step think looking bug fix,positive
decode test set got log file model,neutral
thanks could also check score getting make sure data setup correct addition also try obtain training finally see training log could give step,positive
thank response training test commit,neutral
thanks report could paste training could also send git commit,positive
hi please help correct getting following error missing key,negative
thank mush answer hi sorry late reply previous issue evaluate model segmented audio rather entire talk segmentation file come along must moment data preparation actual audio segmented audio plan update script generate file soon,negative
tried follow new still one question consider input file entire ted talk fragment one sentence case used latter code used divide file single case considered entire talk manage get get used saved folder thank much advance help,positive
hi getting error running command python path beam tee,neutral
welcome training actually used thanks bring add tutorial also trained one,positive
getting problem object attribute even tried solution environment master python import import torch import model task model model,neutral
conduct validation every training step error come training conduct validation every train step error come later training fix problem,neutral
try work however regular pip install repository error stop might helpful running locally solve problem,neutral
working file loaded normally like thanks lot quick response really appreciate another minor doubt train st tutorial single,positive
error ugly fix work sure use either code run problem however training multiple training done process wo quit sit manually process abruptly bunch integer clean shut warning message recent call last file line module process file line main file line file line spawn internal process internal process return join daemon file line file line join ready file line wait ready file line select recent call last internal process file line file line file line join file line wait return else file line poll flag appear semaphore clean shutdown annoying process wo quit even training done single bug issue well meet problem like,positive
thanks detailed information run command model file provided model file successfully loaded error got mainly bug agent update fixed new evaluate model could please follow new instruction thank much feedback sorry inconvenience,positive
st provided doc seem provided st following error find raise found found rename poor output sample index prediction ich bin reference robin hood bin ich ich source duration format subtype bit metric latency al dal al dal index prediction ich bin reference sie ich sie sind ich also die sind ich sie source duration format subtype bit metric latency al dal al dal,negative
hi compress zip file link doc binary could directly load training evaluation issue load could please provide,positive
run actually forgot put description fix,neutral
hey make sure wrap code memory snippet work python import import import torch import model model text,positive
could find documentation provide help regarding load format,neutral
argument issue provide get error even,neutral
argument removed error refer unfortunately argument model,negative
inference built upon great know whether compatible though,positive
would please share snippet inference thanks,positive
ah sorry made clearer use implementation pure guess something within code,negative
thanks help would please tell hugging face model,positive
issue ran example model server except output german model good,positive
recent update clarity refer guide source file list audio assuming audio look like line target file translation audio file input,neutral
argument removed error refer,neutral
maybe size large trying convert mandarin char size give result later hi encounter problem reason perhaps related hyper parameter wer decrease another question use model process audio result many repeated character know related format treat every character word split first train model result share param set maybe model underfitting data lack training slow log valid epoch save epoch finished saving saved epoch score writing took end epoch average epoch train epoch begin training epoch epoch update loss wall epoch update loss wall epoch update loss wall note gradient overflow gradient setting loss scale,positive
manually set work path backward compatibility open path state state state none none state state state none none state state manually set state state return state,neutral
error ugly fix work sure use either code run problem however training multiple training done process wo quit sit manually process abruptly bunch integer clean shut warning message recent call last file line module process file line main file line file line spawn internal process internal process return join daemon file line file line join ready file line wait ready file line select recent call last internal process file line file line file line join file line wait return else file line poll flag appear semaphore clean shutdown annoying process wo quit even training done single bug issue well,positive
hi also getting valid wer also checked data see getting single character boxer engine boost blind spot noon lunch bed liner base model base zeta zeta sigma delta delta alpha alpha backup camera thanks hi latest python version decreasing also also trained loss start older version wer problem problem version problem parameter please read,negative
hi also getting valid wer also checked data see getting single character boxer engine boost blind spot noon lunch bed liner base model base zeta zeta sigma delta delta alpha alpha backup camera thanks hi latest python version decreasing also also trained loss start older version,negative
maybe size large trying convert mandarin char size give result later hi encounter problem reason perhaps related hyper parameter wer decrease another question use model process audio result many repeated character know related format treat every character word split first train model result share,positive
hi thanks response went answer tried still getting error architecture match please help tried following task arch criterion dropout,positive
give much information small hard give advice language work degree loss sound bad need golden check wo give much indication sort task wer still keep training,negative
hi able steal right modify base script added true true true done trick still unsure successful training look like best loss came early training subsequent went away growing training validation eventually getting stuck place got training scratch another experiment public test set broadcast news specifically far validation broken think might get time would mean loss would go zero small experience could please give intuition expect training going well also satisfied pretraining way see model actually come way hear otherwise see discovered downstream task see,positive
hi also getting valid wer also checked data see getting single character boxer engine boost blind spot noon lunch bed liner base model base zeta zeta sigma delta delta alpha alpha backup camera thanks,negative
facing problem trying decode simple code import torch import import model task data model model print loaded model sample data result data print result error name defined put data appreciate help thanks,positive
maybe size large trying convert mandarin char size give result later,positive
maybe holding wrong fix,negative
work sadly end third stage run python install another error fatal error open include file file directory error command visual studio exit status solve finally,negative
hi could tell use unsupervised translation,neutral
hi unfortunately yet possible could indicate seen meaningful different transformer multilingual model,neutral
please let u know,neutral
hello wondering whether multilingual able extract meaningful,positive
able find set still trying figure tried still architecture match task arch criterion dropout,positive
sure happen different get different behaviour task get going go school spacing whereas spacing correct task get say right right right apt spacing,positive
thanks yes right removing directly example e e favorable use supposed version would remove leave space version latest fixed example get wide acceptance received extensive approval received extensive approval thus issue,positive
taking fix problem issue,neutral
got error solve probably due properly error back,negative
think reason could different version current version could try reinstall see,neutral
get small set hour audio clip roughly work get stuff going start tweak change stuff work material change many hard like currently either go use working setup long would stick working setup,negative
try pretty good get going share information hard give advice hi never got yet stuck getting pretraining done successfully made base file batch ti also turned true false set speech bit experimented cutting audio clip batch size experiment bigger really seem make difference though loss break min per epoch ran loss got stuck epoch also try suggestion really appreciate help say remove although already tried training silence removed subset data seem make difference experiment try remove silence data train according see,positive
scoring instead fixed issue,positive
hello also met problem fix try install flashlight run test script met problem,neutral
hi improving slowdown thanks,positive
sorry writing book check somewhere easy start last time checked maybe data,negative
try pretty good get going share information hard give advice,positive
used model together base first data testing anything different augmentation data noisy maybe clean advance tried,negative
please share model used base set many audio whether augmentation used want train model language noise audio,negative
thank appreciate turned could use method anyway model different unless configuration used train model probably luck try another framework hopefully find one work problem,neutral
also ca reproduce result setting best accuracy achieve almost le accuracy found set reproduce result,positive
hugging face feel free try,positive
try state manually python import torch modify alternatively update function responsible handling,positive
hi change setting outside default also set proper,neutral
hi sorry thread late think buggy major reason default left padding disable side similar standard performance,negative
thanks explanation model architecture model follow instruction pretrain model trained use initialize working file,positive
sorry late reply main difference slightly different compare load use initialize prepare recommend following,negative
hi could share data script thanks,positive
wondering reverse text transcript file use since language project would really helpful could share,positive
try clean environment help isolate conflicting,positive
currently sure case could find documentation function also show example conjunction inference new,positive
good thank much maybe author mention code,positive
reason may use different powerful nat implementation original version model architecture optimization leading different original nat must use attention positional attention obtain performance based powerful source may useful stated,positive
hi scan thank pull request welcome community action order merge pull request code require sign contributor license agreement seem one file process order u review merge please sign behalf someone else employer individual may sufficient employer may need sign corporate tooling perform afterwards pull request tagged process may take hour please give time u received error please contact u thanks,positive
able solve simple pip install afterwards issue,positive
tried get without really weird first nat paper neural machine translation copy source model fail training code also mention use copy source paper understanding knowledge distillation machine translation problem,negative
hi thanks response still unable try assumption might incompatible machine thanks anyway,negative
try correspond translation task,neutral
thanks issue discrepancy common voice audio format new script former slightly longer padding result update fix inconsistency let know available,positive
hello related also project need use ray tune find way deal two together,neutral
also getting error please let know solution,neutral
kindly inspect model obtain training architecture order know parameter different one run import torch import import model model path print,positive
yep trained couple different written reference use thanks begin adapt need always gold gold,positive
hi nice see need model good german material use useful good overview hi nice meet experience german language,positive
give link model example model simultaneous example slightly different would possible also make available hi thanks reply seen recently particular part would helpful link previously difference presence attention,positive
give link model example model simultaneous example slightly different would possible also make available,positive
like true wer model true,positive
thanks issue rolling bug fix let know available main branch,positive
argument right allow reduce size dictionary none simple seed seed profile criterion space lamb nag cosine fixed triangular scoring wer task task target align format set limit produce dictionary size tell wrong,negative
issue mention transforming audio mono effect anyone know get mono output would substitute line,neutral
bug usually use old version process data use version train,negative
latest code seeing training right direction loss decreasing,positive
try work however regular pip install repository error stop might helpful,neutral
work fine single add even work,positive
thanks information useful keeping thread open future post,positive
could proceed ahead approach tried thread also could solve issue ran time tue mar wrote setup environment execute training prepare step went fine launch training python task arch criterion get following error right outset model criterion model trained training per per none found loading train data epoch recent call last file line file line file line spawn file line join name exception process signal unable proceed ahead absence might causing please help distributed rank distributed rank distributed rank distributed rank host rank host rank host rank host rank true true true true true dictionary ever figure wrong solve issue reply directly view,negative
setup environment execute training prepare step went fine launch training python task arch criterion get following error right outset model criterion model trained training per per none found loading train data epoch recent call last file line file line file line spawn file line join name exception process signal unable proceed ahead absence might causing please help distributed rank distributed rank distributed rank distributed rank host rank host rank host rank host rank true true true true true dictionary ever figure wrong solve issue,negative
would suggest try example text allow set flag limit size dictionary,neutral
try trying git pull pip install unable reproduce current commit,negative
try pip install unable reproduce side,negative
try python point custom,neutral
think easiest well tool enable flag give helpful logging also support specify flag like add infrastructure create file,neutral
share update version go callable list provided function beam search step provided constraint applied function batch id unidimensional tensor token return list next generation step conditioned previously batch id argument useful constrained generation conditioned prefix entity retrieval,positive
thanks reply wondering information around training general share overall around would great,positive
might want open issue,neutral
try printing output see unfortunately difficult help since dont know setup,negative
training sentence corrector model four text file multiple generate bin file wondering parameter pas reduce size dictionary worked dictionary size big thank,neutral
ah think see issue self read similar self import model self model model return model working right far keep posted happy open later bit quantization,positive
thank much detailed answer used layer norm feeding model work well,positive
already done default would use measure character error rate instead word error rate,neutral
hello normalization different originally group norm first layer feature extractor normalization u worked well scaling model size later model unstable trained long time one group norm based normalization stability group norm layer norm feature extractor input normalization data loader general new probably train even smaller kept consistent describe paper update get new use normalization scheme used otherwise notice significant accuracy normalize way normalize true take look,positive
trained trained unsupervised model top base audio file transcript trying infer command python task path test criterion getting error recent call last file line module file line state file line state state file line state translation object attribute please look thank,negative
try running see common,negative
think good sense seem documentation search one somewhat le straightforward since got unless think throwing beneath would great,positive
interested seeing land curious would possible also include bit documentation callable ca seem find anything supposed shape supposed tensor list right think best place write signature function,positive
interested seeing land curious would possible also include bit documentation callable ca seem find anything supposed shape supposed tensor list,positive
try reducing size dictionary reduce dictionary size number model also try reducing size model,neutral
like task control batch size,neutral
resolve problem mind issue thanks,positive
know anyone internally leave open open source community comment experience,neutral
far understand fix worked base base really give padding think,negative
check paper see material used use case want transcribe phone would take spotless training,neutral
thank answer new training,positive
uninstalled code still apply fix issue fix resolve,neutral
fix resolve issue code snippet affected fix sure run code import import torch import model model transcription print transcription print pad audio model transcription print print padding transcription,positive
hello found param tried word level result much worse letter level miss something,negative
seem order letter symbol role,neutral
ah turn two result nonsense show file likely speech properly normalization step defined model,neutral
without would need material,neutral
still large batch size need,positive
solve problem also try reproduce vanilla nat however result significantly lower understanding knowledge distillation machine translation,positive
hey great point model,positive
anyone proceed issue valid wer stay,neutral
ah turn two result nonsense,neutral
trying get interactive work get following error file name default removed please migrate please refer detail segmentation fault core,neutral
think extracted actually output,neutral
possible use need fine tuning hard,positive
imagine data wo used could bypass pretraining also sure use language model think seen use simple linear classifier top trained small could wrong like much simpler given,positive
problem know arch task use closer seem get trying different arch transformer task arch task cat temperature still get missing key unexpected key load model please ensure match,negative
believe important point address build extraction top amazing work simply use,positive
issue file line module file line main file line main task got unexpected argument,positive
update link still broken thanks,negative
second thrust question duplicate going close feel free reopen size issue tag still struggling,positive
different size yes seen easiest fix usually compare two manually resize code part related issue different size associated mask token difference,negative
tried issue slow accuracy pretty good comparable even without,positive
work latest code issue,positive
ran latest following git log commit author date wed issue get error loading size mismatch param shape shape current model size mismatch param shape shape current model size mismatch param shape shape current model issue becomes resolved different available trained different vocabulary size possible task right,positive
thanks response thanks recommendation,positive
thanks yes universal transformer basic transformer result used parameter size,positive
see mean solve issue able replicate paper would cool spent much time without success,positive
copy instead copy instead whole opinion,positive
model definition though right would initialize different training would destroy,positive
hi nice see need model good german material use useful good overview,positive
since head attention computational result previous time step buffer understanding score poor even model achieve good validation loss copy instead layer class code use unexpected time harm training thus difficult u fix,negative
difference saw evaluation without also affect training reason good validation loss score poor idea,positive
sorry indent code broken,negative
various code hard share code directly add function copy none none none none return addition layer construction following range else,negative
getting valid loss around score german data training done data model around would willing share code model copy basic transformer layer repeated would normal transformer solve problem,positive
issue since happen master,neutral
error gone current master,neutral
could tell parameter size valid loss value valid loss achieve score train model whose performance competitive valid loss good buffer harm generation step head attention computational result previous time step buffer understanding implementation thus use computational generation step way train model universal transformer use basic transformer generation step otherwise modify code copy instead,positive
hello able get comparative universal paper sure could elaborate part particular affect universal transformer bad way opinion would super helpful,positive
fixed would able update retry,positive
facing problem faced many compatibility turn reason pip source tried install develop locally everything working properly,positive
hi notice issue thread solve problem universal think good due head part universal way trouble part,positive
use script kill zombie kill print run following command use python spawn main function kill print,positive
dictionary model carry information already somewhat way build smaller model le information neural net might way pruning would loose information especially unsure whether another way anybody,negative
cutting audio quite hassle try past,negative
hi support speech longer speech supposed segmentation first cut silence feed shorter segmented clip,positive
problem anyone idea fix used received lot,neutral
hi problem export translation model successfully thanks,positive
ca replicate master verify git log fix,neutral
find file linked default change via command line file many likely differ want track get consistent two,positive
thanks learning rate saw considerably large learning whereas find learning around,positive
anything need optimization procedure based description ut although familiar paper know anything special repository going set universal know set opposed setup particular batch size learning rate find batch size two way batch contain number vary fixed number batch,positive
thank anything need optimization procedure repository going set universal set opposed setup particular batch size learning rate thank much prompt response,positive
yes need share across,neutral
check issue might day commit seem reload older day problem,positive
find model defined essentially change make model definition main found basically repeat layer number time,positive
please open new issue still,positive
assume need specify parameter right correct,positive
thanks lot clarification doubt example translator use library library documentation given possible assume need specify parameter right thanks lot time,positive
far know release smaller model could try training smaller model scratch following methodology paper,positive
enough context please follow issue template,neutral
sure even visible seem meant use torch hub interface maybe context clarify apply prior calling,positive
hi everybody new field understand provide example useful order train audio classifier right someone give insight difference latent used feature extractor thanks advance,positive
yeah supposed use model web page script even data thank tried got surprisingly good result strict flag removed next version see generate ratio execute st however tried result got result following instruction sure step made wrong could please thank,positive
thats problem order default recompile specific enable sure exactly get work,positive
currently revert commit file rebuild good work git pip install,positive
change error like material,neutral
anyone found solution problem get segmentation fault core character based language model,neutral
also met problem solve,neutral
thanks issue likely due inconsistency model data prep script fixed former trained latter original latter version consistency pull latest code data prep script approach convert target text manifest column version thank reply latest data script got correct wer result,positive
thanks issue likely due inconsistency model data prep script fixed former trained latter original latter version consistency pull latest code data prep script approach convert target text manifest column version,positive
yeah supposed use model web page script even data,neutral
information interested universal would great addition,positive
version may need install latest version source,positive
issue previous commit issue temporarily previous,negative
solve pip install make sure environment,positive
anyone fix go command path new model,positive
also version ca get file like even set,neutral
thanks making great made small code style,positive
thanks guy advice run mange run,positive
still issue unable infer criterion please implement also getting error unrecognized,negative
hello thanks response sure wrong see help hardware ram machine yes doubled billion sliding window step hour go one epoch update epoch currently epoch increasing update epoch faster epoch loss function almost perplexity training scratch downstream improving slowly pretraining still worse total number training learning rate many peak learning rate adjust sequence length positional usually number per batch batch size increase batch size python task criterion arch complete dropout simple image,negative
need help example exact training command one another kind important since effective may actually older see much probably couple hundred thousand sufficient also quite high actually per update achieve desired batch size practice found batch size comparably see table version paper,positive
thank work however result correct got generate ratio execute status success think difference might model used script provided command line task path beam scoring quiet could provide thank,positive
well different cluster yes hundred new chip made close compute performance memory deep learning nicely except big bummer,positive
thanks explanation think might possible augment data stick high resource translation,positive
correct function use simple solution would register forward hook since forward module forward hook weight matrix way use gradient actually used forward calculated usual could make think right,positive
thanks quick reply correct link move sample also error,positive
thanks interesting someone kind use guess based,positive
could please provide exact command translate new text file target text file trained getting various trying,positive
also copy transformer implementation work good something like conformer time clean different welcome,positive
unfortunately acknowledge many require significant work see discussion section focus particularly saw improvement majority require attention low resource large variety language identification require improvement used trained monolingual data correct language mining laser trained little data low resource poor generalization general necessity improve understanding model even example original model high quality around specific agree human quite generous given consider fluent either language ga look identify many appropriate filter would guess challenge language identification well low resource paper greater update essentially tried follow million training monolingual data monolingual data decided treat monolingual data similar data given mining noisy data considered anything le training low resource however list far far even low overall view important area progress table highlight many important language different also relevant indicate clearly need work hope improve much careful work soon,positive
resolve error link got error python task criterion train arch dropout seed simple distributed rank distributed rank distributed rank distributed rank recent call last file line module file line main file line file line spawn return join daemon file line file line join raise exception exception process following error recent call last file line file line file line file line barrier file line barrier work error internal error version,negative
wondering thing specific input format whole document essentially put single line,positive
faced problem sentence prediction task setting got training work slow per epoch epoch input raw format token length speed normal would appreciate speed training environment version master forked master version o pip source source build command used source git clone pip install python version version configuration relevant information pip install summary training configuration training script bash number batch size regression task peak polynomial batch size percent number loss task arch arch criterion dropout raw training log bash distributed rank distributed rank distributed rank host rank distributed rank host rank host rank host rank none none false none none false false false false false false false false none none none none false false false none none none false none none false false true false false none false none none none none none none false none false none false none false false none none true false true true false false false false false false none false false none false false false false none false false false none none false none false false false false none none false none false false none false false none none none input dictionary loaded loaded valid classification head linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear dense linear dropout dropout linear task model criterion model trained parameter parameter rank total memory name rank total memory name rank total memory name rank total memory name training per batch size per load found loading train data epoch warning invalid size first sample warning invalid size first sample loaded loaded train warning invalid size first sample warning invalid size first sample epoch currently logged begin training epoch fused unavailable may get better performance apex library fused unavailable may get better performance apex library fused unavailable may get better performance apex library fused unavailable may get better performance apex library epoch,negative
implementation relative positional get slowdown use,neutral
somehow manage make work yet could please share script mine posted first post actually work even regular get following error size mismatch param shape shape current model size mismatch param shape shape current model,positive
hey finally figure efficiently get based function following efficiently awesome self true optional callable none none parser parser task model criterion state state model strict true list filter lambda chain sum offset offset offset offset return,positive
thats right suggest sampling distribution skewed immediately higher chance chosen rest move everything positive selection still uniform,positive
investigation found flatten basically function create copy flatten false false sum list set device sum device device else device offset device offset offset offset device device device device return else return script whether flatten following bool flatten false tried use similar way flatten reading found following line quite slow curious efficiently list filter lambda chain self list chain filter lambda thanks,negative
question function following class important note variant weight decay behavior closely analogous self data type list flatten vector list wonder whether parameter u determine one thanks,positive
see anything obviously wrong try see get different stack trace,negative
hi thank answer also reason one data prep last odd yes designed exactly original implementation,positive
think found solution fact need remove parameter whole command line look like python task translation source target arch criterion dropout,positive
hey already found solution part let copy future need may help well great thanks help import logging import math import collection import field import import import torch import import import import import import import import import chain import import import optional list callable logger self true task model something similar print optional callable none none parser parser task task task model criterion state state model strict true list filter lambda chain self return wrote signature self model need call like thread reply directly view,positive
namely condition use half,negative
hey encounter problem well follow suggestion comment data still working sure select use half,positive
hi thank answer also reason one data prep last odd,negative
biggest problem must initial token token properly output model learned way token put output weird profound effect performance used lid loss one epoch output good loss stayed output weird used language id originally solve problem work project currently working team thanks great investigative effort make progress since currently trying use variety downstream always source source would like multilingual training already good source language label target language guess downstream never generate full would still like try right applied tag generating test set guess best also code false imply tag actually automatically added data fact ca see dag gold translation generating test set guess without drastically code best could manually append input data set right unfortunately would still mean missing proper side also lid actually like shown paper en like,positive
hi also always however range conversion still,neutral
hi successfully load model following step got error try get model snippet code speech none model task data model model model,positive
tried second python via pip however python found driver system please check driver triggered internally return found running warning compiler may please use compiler see see install higher warning compiler building extension warning compiler compatible compiler built platform please use compile extension alternatively may compile source also use compile extension see help source warning build file set default number setting environment variable warning command line option valid default warning command line option valid default building extension warning compiler compatible compiler built platform please use compile extension alternatively may compile source also use compile extension see help source warning build file set default number setting environment variable warning command line option valid default file included warning warning disable define warning disable building extension warning compiler compatible compiler built platform please use compile extension alternatively may compile source also use compile extension see help source warning build file set default number setting environment variable warning command line option valid default file included warning warning disable define warning disable function warning comparison unsigned integer warning comparison unsigned integer building extension warning compiler compatible compiler built platform please use compile extension alternatively may compile source also use compile extension see help source warning build file set default number setting environment variable error unrecognized command line option build stopped recent call last file line file line run raise command returned exit status exception direct cause following exception recent call last file line module file line setup file line setup return file line setup file line file line file line run self file line run self file line run file line self file line self file line file line file line self file line file line file line file line raise message error extension,positive
try latest version python import model task task object,positive
try following instruction last line,neutral
simple due extension work fine thanks,positive
trying load multilingual model get following error recent call last module model task model model state default translation task state task state translation state false object attribute code python import torch import import model task model model,negative
another error python task criterion train arch dropout seed simple found driver system please check driver triggered internally return none none false none none false false false false false true false false none none none none false false false none none none false none none none false false false false false none false none none none none none none false none true none none none false none none false false none none false false false false false false false false false false none false false none false false false false none false false false none none false none false false false false none none false none false false none false false none none none dictionary loaded recent call last file line import module handling exception another exception recent call last file line module file line main file line main file line main file line file line raise please build pip install python,negative
doesnt model field actually sure try doesnt work share,positive
still issue tried model load fine,positive
would either data testing used training use raw point text file would still use dictionary training,negative
run inference concept sort since trained purely audio data need either use one inference,positive
could try model via might better,positive
open since seem fixed,positive
havent seen maybe try latest version,positive
unfortunately actual beam search flashlight train model though use generate fusion check believe flashlight team working python binding package make much easier,positive
please reopen still issue,neutral
one potential way forward subclass translation task add would call appropriate,positive
need language need pointing data course exactly used model trained,positive
model anything dictionary would create whatever create example running language modeling taking possibly,neutral
might better person help,positive
signature python self model need call like,neutral
work sure latest version try master running something like checked shell python,positive
like good idea welcome,positive
probably need change feature extractor representation encode approximately amount audio would sure best configuration would experiment would model large amount unlabeled audio another option use often simply audio something like use official recipe pretraining want model audio probably first audio annotate higher final quality domain lot accuracy may great though,positive
fixed time ago saved get point might case past though,negative
might enough memory save getting similar error low space,neutral
thanks suggestion however different transformer help problem similar distance matrix audio provided different transformer meaningful monolingual model multilingual model layer top layer shown monolingual model layer multilingual model layer monolingual model layer multilingual model layer monolingual model layer multilingual model layer top layer monolingual model top layer multilingual model could indicate seen meaningful different transformer multilingual model,positive
yes work large well think none work latest,positive
met error tried use validation data loaded large,positive
frozen suggest probe different rather top layer probably need modify code return,positive
right thats bug though prob wont change much proposal fix,positive
need set add check,neutral
tried current code language model error code update soon progress,neutral
hey problem right strategy define function use running model load model self true something similar print task model state state model strict true list filter lambda chain self return however encounter problem super type must instance subtype type order fix error thanks,positive
predict print model none none item print loop sample item else item sample continue none sample target sample print sum enumerate sample id speaker none id id sample target sample else sample process top print generating result result none speaker id result print result return result image stuck code work calling terminal,positive
issue previous commit issue temporarily,negative
thanks nice answer yet still sure handle directly load model found loaded match running sure call function make loaded consistent running following load model import para shape list shape total length running may give guidance thanks lot read running full dictionary easily would great,positive
tried pip install user pip install user ran separately first one work second one error people three top pip install user worked python pip fresh server also try,positive
try would mark group name model something like python set composite different something like composite default fixed fixed,positive
yep checked new integration nice fine tuning german though add tool list,positive
took ur company think going help lot test seven ago brought continent new nation men case take day training transfer learn think good model,positive
best result also accomplished pretrain case approach let running day single wer reduced stopped training still unable run idea,positive
version installation pip list see try latest one pip install upgrade work fine thanks,positive
generally solution normally comment,positive
version installation pip list see try latest one pip install upgrade,positive
version installation pip list,neutral
solution faced similar error,neutral
also issue training code worked ago work,neutral
actually made work simply loading saving storage storage loading work perfectly,positive
try criss model architecture check,neutral
hi got error found go well model nonetheless information difference model,neutral
got load error resolved,neutral
also facing issue fine tuning model data wer stuck epoch loss decreasing log also tried parameter zero help,positive
thanks size output layer around sure context different algorithm take remove repeated blank,positive
git master head file change hopefully first comment model transformer look reasonable transformer layer somehow smoothing everything output near constant comment time flowing vertically final practically constant across time lower monolingual model thank giving reference paper first author like thorough analysis issue trying get kind representation unchanged model code work funky recently perhaps something gone adrift,positive
think necessary put argument indicate directory however important thing feed argument directory point check mass superb example,positive
thank version know error fixed release source fixed issue working,positive
update please see example usage,neutral
hi thanks great script made however script working fine model given trying use model throwing error code ran python error getting recent call last file line main file line main model file line model file line file line false object attribute please look possible mistake side running issue trying run inference model trained,positive
hi first check recent version model preliminary multilingual model lower monolingual model task would suggest try layer extraction code monolingual model see different,positive
size output layer many experienced becomes slow number large around language like fast number small faster,positive
hi got issue day fix problem downgrade version setup must le good luck,positive
landing fix general issue shouldnt happen since landed another fix default saved new assert work best data normalization please check normalize set unset remove check param missing make sure normalization actually used way see still work accuracy degradation,positive
mind separate go internal unit take easier,neutral
got similar error since package version follow suggestion upgrade although work well five day ago work successfully hope,positive
getting error simple trial run task model criterion model trained parameter rank total memory name rank total memory name training per batch size per none load found loading train data epoch loaded loaded train internal process recent call last file line module file line main file line file line spawn return join daemon file line file line join raise exception exception process following error recent call last file line file line main file line main file line file line file line file line return file line import file line size may indicate binary incompatibility header got perfectly working code written since latest version getting error running older version everything work fine version master version o source python version python,positive
similar issue answer case problem,neutral
yes see thank much return really help,positive
hello also want train spell correction model result,neutral
added comment mainly help issue might result couple ago fixing code anyway encourage look underlying issue code first one function like giving decent stage transformer could probably return transformer picked later function particularly later date underlying issue whole would work whole would work could use second example someone claim technically proficient digging inside definitely going deep end happy use get briefly untested code model type list access core model need within overall wrapper directly first code example page hope,positive
mean following python class unfortunately verbose due list field,negative
thanks technically proficient digging inside tried extraction code colleague mine see original code code load model python model model model feature extraction use python model model transformer return quite get going produce reasonable note time axis screen shot screen shot distance matrix two feature matrix note diagonal band screen shot time ca seem get work colleague layer extraction code found middle layer model better pronunciation output layer suspected better original training task case trying code model python none model model transformer none none else layer enumerate layer break return presumably none return final layer output code since condition never satisfied ala screen shot screen shot distance matrix screen shot gather model internals may different might need play code bit get aspect work approach big help hope first part,positive
sorry actually much context maybe clarify,negative
thanks lot specify completely different combining right,positive
machine answer either use project environment ex run administrator,neutral
yep feel free follow run going close task,positive
change corporas along language,neutral
need write script fetch data able script linked need change find parallel data,positive
model side clear data side following script german example similar script available specify language pair pair,positive
dig inside stage seeing like image transformer getting getting unless model intentionally left state precisely,positive
training data feel stopped prematurely loss still improving start another training run resume latest path flag see model still training metric improving kill training job,positive
yes still used sampling see additional far optimal go need experiment easy sweep done inference time wo need retrain model time,positive
need registered see example,neutral
thing really differ different use something like specify language instead de far training model depend training data start use training german model experiment,positive
yep correct format dictionary specifically like symbol count symbol count symbol token count number time care anything like use weighted sampling put dummy,neutral
perhaps look getting similar problem specifically rather slightly rep rep image subtract representation image however dig corresponding layer one access module directly get something much like would expect audio code image also previously tried loading approach exactly please let know discover something work since like pretraining idealistic point view would like use possible,positive
hi favor line add step else let know rouge data line thanks lot hi trying reproduce tried code indeed rouge confused work tried raw multiple concatenate one single line apply use generation get tested code get better result tested code find work influence however already force prefix token understand setting score make difference observation generation shorter could help work,negative
facing problem anyone help,neutral
thank saw realize bigger also increase learning rate training one right yes know take forever want make sure everything working start,positive
likely small batch size looking original model trained batch size per since total batch size would typically bit le due padding train need accumulate multiple achieve total batch size done via option training would training could,negative
comment could take another look thanks,positive
hey thanks quick detailed answer like case observe maybe smaller since train already,positive
sure simplified default good please keep wrapped version way match original paper,positive
smoothing sentence correctly think need initialize somewhere might explain sentence might also take look branch tried update code work recent version actually line pretty nicely main logic new task combine criterion tested smaller got never write merge,positive
percent faster get single machine command python task arch simple without apex note gradient overflow gradient setting loss scale epoch epoch epoch epoch apex note gradient overflow gradient setting loss scale epoch epoch epoch epoch epoch epoch,negative
little strange like exactly suggest like self,positive
hi run related switching nightly build fixed,positive
also wonder big gap paper paper,neutral
tried model data already work reasonably well,positive
wouldnt difficult would recommend run long time,negative
file get integration like instead,neutral
sorry issue try command fix coming soon find specific parameter trial error found specific model based guess model might possibly although way testing,negative
remember exact got would satisfied,positive
sorry ping interested well recent issue along similar heading road check chance support internal branch outline approach took implement assuming different thanks,negative
got rid error making sure torch,positive
hi looking forward work,neutral
problem model code data loading paper soon dan,neutral
try setting see progress,neutral
sure possible take look running flag set training log empty issue recently grab latest code properly log file,positive
support able easily extract attention returned visualize,positive
good going close issue please still,positive
facing problem unfortunately model well wer,negative
fantastic thank kindly help one last quick question somewhat unrelated topic may note following following directory structure everything run way manually specify directory everything saved something like better yet add something file create top level directory time particular file also notice whenever zero size logger output way make work capture output,positive
progress either work need model sorry,negative
hello anybody help issue since like forward function right need given forward process exist moreover source code find shift right operation forward self return,positive
see great thanks try instruction,positive
thanks work command line machine yes able input audio path get text prediction output screen make update week notify thanks patience,positive
actually set true print mask tensor tensor false false false false false false false false false true true true true true true true true true,negative
use whatever put lexicon file look say word first column lexicon file also say second column model,positive
way padding mask set false true work way true false otherwise,negative
much help since idea exactly architecture besides new still audio,positive
great worked thanks lot help git pip install upgrade running command git clone running command git update recursive build done getting build wheel done done wheel done requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade torch requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade future requirement already satisfied skipping upgrade building collected building wheel pep done wheel directory successfully built collected found installation successfully uninstalled successfully got version pip show name version summary ai research author none none license unknown location torch able load model function,positive
working example would really helpful since spent major part day trying figure unsuccessfully,positive
tried command get error en dropout criterion tee,neutral
thank kindly although based said still bit hazy please elaborate understand general format line lexicon file representation representation model used training model trained format write could write wry basically identity function write write part still confused though exist label look like used example create sort incompatibility building everything said already would go lexicon file order use instead model used letter dictionary separator however word based model dictionary looking code also lexicon make lexicon look like successfully use model guess would look like lexicon since overdraft papistry,positive
thank time tested help lot people,neutral
try running following command en dropout criterion tee note environment flag,neutral
see try building master able pip install upgrade,positive
try different beam size path beam test bash like used believe copied beam al paper translation,neutral
thanks reply yes score calculated get following,positive
unfortunately inference speed large indeed slow interested making faster alternative compression thanks interest,negative
thanks due recent necessary update thanks opening task,positive
hello feature please consider making pull request,neutral
hello thanks opening task compound splitting unfortunately original transformer paper used comparable ideally report probably,positive
thanks help ad tried previous last version tried load model nothing still get version last version,positive
bug model trained around summer see internal task,neutral
list lexicon unfortunately separate segmentation fault found method file segmentation fault section python false word enumerate word score spelling token token spelling assert spelling score work know wrong solution problem one,negative
lexicon exist allow map one representation another example provide word boundary token also map since several way pronounce word many many could multiple pronunciation multiple word two lexicon file representation onto word listed twice line without boundary token also try lexicon free thats used unit flag able get good investigate otherwise lexicon based language model would use model final output discussion finally likely problematic normalization large prohibitive beam search large space prohibitive acoustic unit probably closer due stride,positive
try pip install upgrade whatever preferred installation method think old version recent update,positive
find file instead also saw language actually trained,neutral
file linked see file need list ex,neutral
think good example task translation basically need implement new task want use specify one composed task task task choose user different different,positive
enough context help please follow issue reproducible example issue,neutral
source file believe additional documentation,neutral
full command ran posted seem match command example false set true also like none,positive
hi get score paper script latest best score got,positive
command dictionary file default faster load sometimes make take le space disk highly data prefer instead use raw text passing still need run use raw text thank explanation every time use error like file directory dictionary used successfully may request solution problem,positive
also highly interested update,positive
unit error rate error rate whatever model whatever opposed word error rate composed error rate usually unit error rate significantly lower also appropriate space problematic many,positive
certainly mix much like long consistent fine tuning however model accuracy probably wo good mixed case since case audio,positive
latest commit new model least multilingual one ended working,positive
could please tell ca mix upper lower case need exist contribute language meaning idea thanks,positive
many thanks model revert issue problem fixed,positive
problem even set normal single get stuck valid period recent call last file line module file line main file line file line spawn return join daemon file line file line join file line wait ready file line select recent call last file line poll flag,positive
hello solve problem issue,neutral
close issue feel free still unsolved,positive
error recent call last file line module output input file line predict file line sample return file line sample beam verbose file line generate generator batch file line sample file line return file line generate return sample file line file line step invalid multinomial distribution sum,neutral
similar problem ran ended minute python task path valid criterion letter however ran data model super slow memory seem utilize sure something problem data vocabulary size python task path valid criterion letter,positive
similar issue model fixed day ago consider model trying work comment issue,positive
set would use model parallel,neutral
hi thanks model great see training working would possible provide information data combination could also give used training would interested ram usage think need keep corpus memory contrast approach used would like set kind input would helpful,positive
following tip import site import user posted,neutral
thing need specify appear incorrect,neutral
really tested use interface find fix happy accept,positive
thanks work command line machine,positive
hello example intuitive fix however language pair possible scenario pretext,neutral
sorry sure follow load model one method specify data path path dictionary loaded think default current working directory going loaded used,neutral
think really important could flag would check whether loaded model extend matrix accordingly,positive
make update shortly allow use case,neutral
hi question model right dictionary use come compressed file different use method valid however use obtain seem outside vocabulary getting index error use get running could let know correct method use loading model like import model thank,positive
hi met issue guide valid wer always progress,neutral
anyone please provide example use pipeline real time medium stream rather static file looking everywhere see pitch programmatically loaded signal understand correctly sort help much,positive
bug sorry wrong label,negative
looking forward update test commit work get result hub test may also work related,neutral
thanks try use framework library,positive
switch use library easier use framework library,neutral
hi want know finally achieve successfully recently use sequence generation would could tell replace,neutral
issue encode function text one contiguous string following issue resolved encode print open open count line enumerate line print wrote count,neutral
great send copy weight,positive
thanks issue make fix shortly,positive
false alarm far tell quietly accepted still work though,negative
new error would appreciate warning invalid size first sample recent call last file line module file line main file line main file line main train file line file line file line file line file line file line list file line assert file internals line file line file line return axis array reduction operation maximum identity,positive
hello issue due improper saving instead saving model encode print open open count line enumerate line print wrote count data train data train encode,negative
thanks reply confirm say performance gap training speed downstream task accuracy mean downstream task accuracy object detection based transformer architecture slightly different weight fact difference tried study performance still finding performance based implementation worse also find official zero implementation set directly self else none different none none,negative
actually see solution use model forward method case,neutral
guess letter dictionary many future release end issue,positive
error related model loading model attribute model extract use method via model forward,neutral
try running help see provided option,neutral
oh right thank way found bit different instead converting suggestion worked perfectly thanks,positive
example first gen let call want extract suggest way import import torch audio audio note code tested method may vary different occur always look inside kind dictionary,positive
thanks lot sense fix naming confusion work,positive
know issue closed ago memory problem setting false true file perhaps help,negative
face similar problem trying load model loading import torch import model task model model recent call last file line module file line raise object attribute object attribute,neutral
latest update found training problem related memory issue reduced number training successful,positive
issue use flag training got another issue even use flag recent call last file line raise handling exception another exception recent call last file line file line main file line main train trainer task file line inner return file line train file line inner return file line file line loss criterion model sample file line result input file line forward model sample file line result input file line forward file line next,positive
probably want use general training default synchronous distributed training distributed data parallel something different filtering generally prefer default use run inconsistent gradient seem solve issue checked problem single task criterion arch seed process following error recent call last file line file line fatal error inconsistent try different generation training across rank nan rank nan rank nan rank nan rank nan rank nan rank nan rank nan handling exception another exception recent call last file line file line main file line main train trainer task file line inner return file line train file line inner return file line file line loss criterion model sample file line result input file line forward model sample file line result input file line forward return super file line forward return file line result input file line forward file line next,negative
hi fixed yet hi according recommendation way class self super model task model model model forward self return prediction class prediction lightweight wrapper around model self self padding return return mean many thanks advance,positive
please install reduce memory usage pip install recommend many data sufficient ignore data loading buffer empty warning triggered reduce time share data multiple pas like split data make true share dictionary,positive
transformer step token source done interactive mode hence difference token source interactive mode issue,neutral
hey thanks spotting late fix model address following quick fix tried fixed please comment still issue thank,positive
solve problem add file task data false model get file,negative
paper create take public available model extend randomly extra set language dont think need modify code model may need code extend layer dimension call,positive
hypothesis score hypothesis always negative number could also theoretically probably happen probability hypothesis number hypothesis highest probability returned log base case probability since log number negative hypothesis score thus negative number note log function strictly increasing function probability bigger better ex probability hypothesis score score probability,negative
guess version successfully done master branch inconsistence error version,positive
guessing talking setting following set used paper batch size effective run validation epoch epoch data randomly training set select best validation set result quite important run training early stopping stop validation accuracy epoch defined hi would please let u know found sensitive correct large nothing thanks,positive
bug fix release include next release pull latest master branch install via pip install root,positive
hi well really solve problem tried giving model still quite different code padding mask basically create segment pad go convolutional padding mask go context network mask show output different previous experiment padding size mask half input actual speech pad mask padding mask must model print thing difference context network predictor case think possible solve issue short utterance,negative
hi still getting error error override please explain solve thanks,positive
suggestion construct padding mask sample code line wan na forward use model input,negative
hey try get soon could please refer hi wondering find example command reproduce would please point already,neutral
note base model already model quick fix following file comment assert work best data normalization please check normalize set unset line change,positive
think since add example function parameter move beginning set true still think elegant add start remove end,positive
found issue argument made fail,negative
hypothesis score negative score setting default maybe loss,negative
bad got confused data root language root,negative
supposed use instead see also,neutral
similar issue run get error begin training epoch recent call last file line module file line main file line main file line main train trainer task file line inner return file line train file line inner return file line raise file line loss file line loss criterion model sample file line result input file line forward model file line result input file line forward extra file line result input file line forward extra file line file line result input file line forward file line result input file line forward return file line return input weight bias run get begin training epoch block thread assertion block thread assertion fail assert triggered recent call last file line module file line main file line main file line main train trainer task file line inner return file line train file line inner return file line raise file line loss file line loss criterion model sample file line result input file line forward loss sum file line ret input target weight reduction error assert triggered,positive
would make sense input input leaving output separate wondering whether would use problem monolingual language response,neutral
like pretraining lot form paper large bath size someone confirm usage sure got speed boost found ampere arch training also really understand large batch size feel like parameter maximum number batch,positive
thank detailed reply question want prepare distilled following correct bash bash path beam train tee cut obtain distilled simply original,positive
would also interested resolved instance issue,positive
think answer code sorry interesting question,neutral
want load need override data import torch import model task data thank want check link right,positive
via pip install version recently package time issue,neutral
pretraining part look valid based validation yet similar structure pretraining valid basically want validation loss decrease time go ca tell loss value good many,positive
directory like file valid test right default exactly link broke,positive
thanks help tried two data epoch update loss temp accuracy wall begin validation valid subset valid epoch epoch update loss temp accuracy wall begin validation valid subset valid epoch training accuracy quite opposite pay attention confirm whether training tried epoch update loss wall similarly value focus,positive
make different version master branch hi think anything please check issue posted comment code used see recently back dictionary however still return type need well thank much change return return list none none thanks make different version master branch hi think anything please check issue posted comment code used see recently back dictionary however still return type need well thank much change return return list none none hi issue code one get error epoch begin training epoch recent call last file line module file line main file line main file line main train trainer task file line inner return file line train file line inner return file line loss file line loss criterion model sample file line result input file line forward model sample file line result input file line forward file line result input file line forward extra file line file line layer file line result input file line forward file line result input file line forward assert somewhat related thanks try latest master branch close issue please feel free open new one still resolved thank,positive
yes run half probably best condition use half running,positive
setting wer still greater wer suggest,positive
make different version master branch hi think anything please check issue posted comment code used see recently back dictionary however still return type need well thank much change return return list none none thanks make different version master branch hi think anything please check issue posted comment code used see recently back dictionary however still return type need well thank much change return return list none none hi issue code one get error epoch begin training epoch recent call last file line module file line main file line main file line main train trainer task file line inner return file line train file line inner return file line loss file line loss criterion model sample file line result input file line forward model sample file line result input file line forward file line result input file line forward extra file line file line layer file line result input file line forward file line result input file line forward assert somewhat related thanks try latest master branch close issue please feel free open new one still resolved,positive
may try save memory training trying lower find one,neutral
thanks issue corrupted please remove old via either script link manually,positive
tried everything fine also tried compress everything trained model accuracy still great,positive
backup original data archive update new link,positive
use pip install error help fix error version corporation reserved pip install building collected building wheel error error command exit status command open compile code complete output running running build running package file found regular file running building extension build visual visual visual command line warning command line warning unknown option command line warning unknown option command line warning unknown option command line warning unknown option fatal error open include file file directory error command visual exit status error building wheel running clean build collected running install error error command exit status command open compile code install record compile complete output running install running build running package file found regular file running building extension build visual visual visual command line warning command line warning unknown option command line warning unknown option command line warning unknown option command line warning unknown option fatal error open include file file directory error command visual exit status error command exit status open compile code install record compile check full command output warning pip version however version available consider via pip install upgrade pip command,positive
could specify trying pretraining,neutral
could specify version use use pip install master branch,neutral
pretraining code remains thing file need prepare basically simply add path instance single file multiple time language instance bit hacky make change code simply modify data data sign something get exactly done character output file instance training language would suggest data recently perfect need filter fit domain spoken language still good resource,positive
hey sorry find model update paper pretraining similar pretraining model setting lower learning rate except way like paper model find hour depending size choose pick right script,negative
try since likely bug,neutral
thanks providing alternative although found train ex language looking least language entire identical available previously training valid test sure checked also new link provided organized differently,positive
seen posted lot content know sorry troubling,negative
try criterion task maybe directory option key,neutral
thanks try looking forward next version close issue,positive
training successful could reproduce original example wer en idea training command evaluation thanks issue bug latest configuration system wer scorer properly higher wer without punctuation removal make fix shortly let know please pull latest master branch bug fix,positive
successfully model tried follow use generate well valid first still got weird python found driver system please check driver triggered internally return python found driver system please check driver triggered internally return see empty line predict empty string may train enough work either may something trying run old command line argument new see nothing special new information source python summary train end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch epoch update loss wall end epoch average epoch train epoch begin training epoch note overflow setting loss scale end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch begin validation valid subset valid epoch save epoch finished saving saved epoch score writing took end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch epoch update loss wall end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch epoch update loss wall begin validation valid subset valid epoch save epoch finished saving saved epoch score writing took end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch epoch update loss wall end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch begin validation valid subset valid epoch save epoch finished saving saved epoch score writing took end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch epoch update loss wall end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch epoch update loss wall end epoch average epoch train epoch begin training epoch begin validation valid subset valid epoch save epoch finished saving saved epoch score writing took end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch epoch update loss wall end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch begin validation valid subset valid epoch save epoch finished saving saved epoch score writing took end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch epoch update loss wall end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch epoch update loss wall end epoch average epoch train epoch begin training epoch begin validation valid subset valid epoch save epoch finished saving saved epoch score writing took end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch epoch update loss wall end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch begin validation valid subset valid epoch save epoch finished saving saved epoch score writing took end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch epoch update loss wall end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch epoch update loss wall end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch begin validation valid subset valid epoch save epoch finished saving saved epoch score writing took end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch epoch update loss wall end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch begin validation valid subset valid epoch save epoch finished saving saved epoch score writing took end epoch average epoch train epoch begin training epoch epoch update loss wall end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch epoch update loss wall end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch begin validation valid subset valid epoch save epoch finished saving saved epoch score writing took end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch epoch update loss wall end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch epoch update loss wall begin validation valid subset valid epoch save epoch finished saving saved epoch score writing took end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch epoch update loss wall end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch end epoch average epoch train epoch begin training epoch begin validation valid subset valid epoch save epoch finished saving saved epoch score writing took end epoch average epoch train epoch begin training epoch,negative
yes use word score silence score sure used evaluation command python task path test criterion letter think according appendix yes hypothesis really unreadable also tried another trained high wer,positive
previously build following specifically command building simplified little bit used work build command,negative
yes train capitalization punctuation apply example punctuation raw data model output punctuation long remove punctuation train data,negative
bug fix latest master branch thanks issue,positive
thanks providing alternative although found train ex,positive
training successful could reproduce original example wer en idea training command evaluation thanks issue bug latest configuration system wer scorer properly higher wer without punctuation removal make fix shortly let know,positive
may installation culprit see,neutral
thank share overcome corrupted list segmentation fault core remove build option,neutral
hey make sure chance take look model ago hope useful considering expect additional future best,positive
hey unfortunately trained model base architecture understand constraint definitely consider base model well next version would suggest increasing parameter reducing number also potentially consider reducing number model frozen beginning usually set best,negative
model difficult fine tune essentially model paper minus fine tuning,positive
yes transformer evaluation token quite expensive realistic approach emit multiple hypothesis rerank transformer much usually pretty similar accuracy fused transformer accuracy drop use word score silence score transformer appendix paper upper case also hypothesis anything look strange,negative
hi could provide configuration well recently model follow instruction like work wer remains matter tried valid epoch use language model like train found history equivalence old command line argument provided,positive
ah sense glad working apex indeed optional confirm apex build fine good know may starting,positive
got working today advice mix pip fresh machine apt install git install set activate test install git clone pip install pip install could get work apex install via git pip following apex either due clash optional left apex moment made wonder due version,positive
sense going check transformer code many thanks reply,positive
hi thanks issue bug later different pull request unexpectedly st affected push fix today could also fix quickly following,positive
generally modify test set fine make want set course train set cause mismatch balance carefully train set may make model also mismatch may hurt test performance,positive
confirm say performance gap training speed downstream task accuracy assuming mean downstream task accuracy guess due slightly different weight history behind previously used single input projection layer go thus independent later three independent kept old weight consistency previous slightly better performance although suspect,negative
key step time would,neutral
suspect due model padding rather beam search particularly order truly independent batch size need zero padding every layer otherwise may get slightly different different batch size due padding correct convolutional model think transformer model correction since slows usually influence much anyway note value pad symbol always become due bias,negative
good catch please submit fix thank,positive
directly modify model code freeze setting directly applicable example paper froze work,positive
possible bug case install assuming support working true based post like following error correct python model encode beam share model example work fine model python model lo world,positive
solution git clone pip install python build develop,neutral
unfortunately robust since alignment procedure simplistic one issue seen past important remove input,negative
trying use dictionary trained,neutral
like difference perhaps improvement training faster without run impossible say sure,negative
export currently tested please share able get working,positive
currently support python recently may like leave issue open please python,neutral
good catch broken model migration fix patch commit release fix shortly,positive
checked note install behavior error message need add list check,neutral
problem problem may cause install command install command apt install git clone build build make export install additional atlas accelerate install install git clone pip install,positive
face similar problem trying load model loading recent call last file line module model task file line state file line state state file line state translation object attribute loading recent call last file line module model task file line state model file line return super strict file line error loading size mismatch param shape shape current model size mismatch param shape shape current model version,positive
want load need override data import torch import model task data,neutral
set false inference without use python task path criterion letter,negative
afraid cant help might better ask unblock try making look criterion example maybe try integrate want welcome,positive
hi actually trying use model use listen audio give transcript output suggest proceed thanks advance hi think simply run command get raw number without language model complete command task path criterion letter please make sure python binding need prepare following take subset example need binding even use base worked well running similar command binding python task path criterion letter getting following error main file line main file line file line file line file line ex cause file line raise ex set end full file line return file line node file line key file line file line file line ex cause file line raise ex set end full key,positive
also experienced inference script manifest split split manifest none normalize fix also upgrade old task therefore set code later fix removing condition hi base model got similar thank pointing solve however removing statement part get key running following command inference without model python task path criterion letter also use model inference without,positive
hello interested well particular like able translate longer understand quality could negatively impacted since training limit would interesting investigate behavior anyway thanks,positive
getting different similar error running following brand new notebook python import torch disable dropout leave train mode recent call last module import torch disable dropout leave train mode module import missing module note import failing due missing package manually install either pip apt view common click open button running pip install first problem though familiar torch hub know new default normal behaviour,positive
work define model way python store source target,neutral
also face issue removing text problem solve,neutral
question reproduce wer improvement transformer instead tried used letter dictionary model transformer directory head command used python task path criterion wer wer lexicon file argument lexicon get wer environment latest stable release branch python patch issue otherwise fail due missing know wrong thank fro answer get solution,negative
hey anybody able rectify segmentation fault error yet hi make language model use installation use without setting unable train way use character level directly need write scratch flashlight base solution problem see paper used gram character seem possible current setup,negative
hey thanks answer intention use like make script looking clean way otherwise go hacky honestly want,positive
hi try command try think work may also need replace following see,neutral
think default gram need recompile support issue though might helpful hello compile get segmentation default core corrupted size error running model level corresponding lexicon please help would kind reply,positive
happy new year issue memory error used translate bulk text checked last appear extremely long understand error would occur would appreciate could shed light possible cause thank much,positive
try integrate version code quite complex thanks response,negative
work use feature feed separate downstream,neutral
trying load model also target dictionary used fine tuning model trying load try load get change target path save rerun code,positive
still stuck new available note link still need extract specific language want extract everything else fixed similar issue reference,positive
try leave succeed code high probability work version,positive
added language model inference pipeline,neutral
great closed though red rather purple,positive
hi thank reply feasible solution code available openly please share possible,positive
hi solve problem actually new model find problem though similar,positive
issue running error different model code recent call last file line module file line main file line main generator file line return file line model file line return super strict file line error loading size mismatch param shape shape current model,positive
provide another ram issue wrapped got following error worker signal segmentation fault pickle data truncated probably data used class enough time look tried option data worked speed clearly see fully saturated command mount link smoothly speed fairly acceptable,positive
loading model malformed node string object,neutral
hi facing similar problem suggestion solve problem thank,neutral
testing model prescription get error file directory could please clarify pas letter dictionary model loading sequence run python import torch import model task faced problem loading model file directory,neutral
code loading data need create custom task define data loader function custom criterion binary cross entropy loss register class following set definition custom task self split load given split train valid test split input none input input input shuffle open file line file line line label line label label label pad label label label label label label label assert print split split following code snippet loss classification need added forward definition custom criterion class loss,neutral
thank reply help successfully load model extract feature,positive
manually parameter saved model false need parameter saved experience could please share solve tried following model model hard model still work got right idea need find saved model change four mistaken code hand unfortunately change saved model loaded sure mean without model,negative
manually parameter saved model false need parameter saved experience could please share solve tried following model model hard model still work got right idea need find saved model change four mistaken code hand unfortunately,negative
manually parameter saved model false need parameter saved experience could please share solve tried following model model hard model still work,negative
want use get anyone help point starting point,neutral
figured put folder hi could please shed light modify model thanks,positive
manually parameter saved model false need parameter saved experience,negative
manage solve problem stuck,neutral
facing issue able solve,positive
try pip install work thanks,positive
hi facing problem mean folder thank much,negative
hi facing problem mean folder,negative
check another recent commit commit problem,neutral
problem write solution answer send tipped ran command normal installation know whether helpful git clone pip install,positive
also tried change train model score still,neutral
hi trained transformer base result help figure wrong export export export export arch python port data seed arch transformer dropout criterion python output data path beam bash result,negative
making progress getting compile,neutral
relevant issue extension window system,positive
able share training procedure transformer without loss metric seem work much original model,positive
related issue install due missing,negative
please add window label,neutral
hi thanks solution really,positive
training successful could reproduce original example wer en idea summary training command div task criterion arch seed summary evaluation div python output task path beam scoring wer summary div,positive
yes example en output like fire burned fox fire burned fox explanation output found generation script three line prefixed copy original source sentence hypothesis along average positional score per token position marker text output might see hypothesis reference target alignment history generation,positive
sure let dig would post soon,positive
chance might willing share gist loaded data,positive
yep classification jump function difference,neutral
hi facing problem solve fine tune need use model,positive
hi facing problem solve,neutral
hi running problem sample following fine tuning recipe latest version data one sentence per line source target without special added example line could simply cat sat please elaborate mean setting none string change call sample directly thank mean set variable none instance add none loop,positive
hi running problem sample following fine tuning recipe latest version data one sentence per line source target without special added example line could simply cat sat please elaborate mean setting none string change call sample directly thank,positive
hi sorry long time problem,negative
like discrete latent discrete output thus rightly need cut extractor add specific task top aggregator training model way optimize contrastive loss function example want perform binary classification use extractor embed audio lower feature space pas extractor output classifier thanks reply sense use usually language pretraining like thought could also useful case although training objective different,positive
like use return list returned wrapped,neutral
since associated please feel free reopen,positive
still something one git clone easily instead back,positive
hi uninstalled previous version work fine thank much,positive
full error pip install,positive
thanks use valid set sequence level probability beam beam,positive
think default gram need recompile support issue though might helpful hello compile get segmentation default core corrupted size error running model level corresponding lexicon please help,neutral
hi thank get able get error matching distribution found,positive
ah yes like bug error never seen try model archive case got corrupted somehow,neutral
able reproduce environment could issue version report python print get,positive
make sense completely cut transformer though specifically would learned useful masked pretraining,positive
error getting run python load model model task model model check model input model export model model model run model input multiple save model file object store trained parameter inside model file version export model whether execute constant folding optimization model input model output variable ax float got long tried casting float luck,negative
testing model prescription get error file directory could please clarify pas letter dictionary model loading sequence run python import torch import model task,neutral
also interested load model follow written python import torch import model task get error object attribute looking documentation model class definition anyone know find model class get error object attribute solve,positive
met similar situation make sure used infer,positive
think negative constrained direct effective latent variable method diverse language generation,positive
able figure issue running problem,positive
hey anybody able rectify segmentation fault error yet hi make language model use installation use without setting unable train way use character level directly need write scratch flashlight base,negative
resolved following import torch import torch import model task model model,neutral
like discrete latent discrete output thus rightly need cut extractor add specific task top aggregator training model way optimize contrastive loss function example want perform binary classification use extractor embed audio lower feature space pas extractor output classifier wrong context,positive
issue model removed folder help command python arch task fixed activation offset auto criterion seed,positive
hello face problem use default complete everything fine decreasing slowly around always tried modify lot way never succeed get reason clue threshold,positive
honest like reasonable thing clean add directory end every,positive
unfortunately access code general like cat python import torch import import import dictionary open model generator generator,negative
make different version master branch hi think anything please check issue posted comment code used see recently back dictionary however still return type need well thank much change return return list none none thanks make different version master branch hi think anything please check issue posted comment code used see recently back dictionary however still return type need well thank much change return return list none none hi issue code one get error epoch begin training epoch recent call last file line module file line main file line main file line main train trainer task file line inner return file line train file line inner return file line loss file line loss criterion model sample file line result input file line forward model sample file line result input file line forward file line result input file line forward extra file line file line layer file line result input file line forward file line result input file line forward assert somewhat related thanks,positive
know answer excited learn,positive
great question went back time thankful turn correct model validation set used training set however also correct closer find model validation set since model file old small change able load model put branch bash git python path beam valid cumulative prob tensor note hypothesis token output base generate valid,positive
hi currently cut extractor added layer trained loss different found,neutral
different get model sentence model translate example could mon reference gold sentence provided source one want compare example official human version hello name possible run without target case line wo appear system translation model along score model work ex line even model work whole punctuation example might obtain something like hypothesis score hi name alb st word reverse example would hi name example number letter ex id sample understand simply index test set might sequentially use id reorder seem valid argument though translation task might used training calculate score validation set output file could calculate score like first keep target output file ex separate two cut cut run see ref would get something like,positive
since lost interest going assume hope landing,neutral
provide source sample serialize model,neutral
maybe something might know,neutral
got following recent call last file line module file line main file line main return file line name defined main function generation successful thank,positive
hi thank pull request welcome community require sign contributor license agreement seem file order u review merge code please sign behalf someone else employer individual may sufficient employer may need sign corporate received error please contact u thanks,positive
related issue error output prediction segmentation example segmentation worse provided would tell u wer example two output raw output output scorer latter need scoring wer need scoring wer train without punctuation removal allow learning applied evaluation phase see also share command line file path defined actually like dictionary size loading model loaded none note hypothesis token output base generate ratio file average python output generate result task path beam scoring extract ref hyp result head cut head cut scoring see later mistake replace two following,negative
related issue error output prediction segmentation example segmentation worse provided would tell u wer example two output raw output output scorer latter need scoring wer need scoring wer train without punctuation removal allow learning applied evaluation phase see also share command line file path defined actually like summary div none none false none none none false false false false false false false none none none none false true none none false none none none false false false false false none false none none none none none none false none false none none none false none none false false none none false false false false false false false false false none false false none false false false false none false false false none false false none false false false false none none false none false false none none false none none false false none none dictionary size loading model loaded none note hypothesis token output base generate ratio file summary div average python output generate result task path beam scoring extract ref hyp result head cut head cut scoring summary div,negative
make different version master branch hi think anything please check issue posted comment code used see recently back dictionary however still return type need well thank much change return return list none none thanks,positive
make different version master branch hi think anything please check issue posted comment code used see recently back dictionary however still return type need well thank much change return return list none none,positive
related issue error output prediction segmentation example segmentation worse provided would tell u wer example two output raw output output scorer latter need scoring wer need scoring wer train without punctuation removal allow learning applied evaluation phase see also share command line file path defined,negative
make different version master branch hi think anything please check issue posted comment code used see recently back dictionary however still return type need well thank much change return,positive
make different version master branch hi think anything please check issue posted comment code used see recently back dictionary however still return type need well,neutral
related issue error output prediction segmentation example segmentation worse provided would tell u wer,negative
make different version master branch hi think anything please check issue posted code used,neutral
make different version master branch,neutral
thanks update code shortly,positive
thanks issue yes due empty common voice skip filtering update code shortly thanks script,negative
problem empty clip used script remove empty clip hope helpful,negative
maybe right person direct question seen lot inspection model well thanks,positive
anyone know whether anything particular need done account written corpus written need need thanks,positive
thanks reply model get object attribute used model use model think model used version compatible previous version method could try use,positive
thanks chose proceed dictionary page file error coming file line object attribute dont use language model use tried output getting absurd ca understand file name file cat cat cat cat mary kind understanding happening wonder step correct directly name thank,positive
thing could find way classification task hand tried contextual got simply forward method hopefully correct way result pretty bad contextual got method much better job wonder correct thanks,positive
yes sun wrote hey thank reply talking file reply directly view,positive
thanks reply model get object attribute,positive
hey thank reply talking file,neutral
hi share solution pretraining meet question thank hi ca language model facing problem even without language model without language model loss decreasing wer value always try python letter valid wer task arch static static dropout criterion seed thank try explain impact wer value eventually issue appropriate specification used know also used problem tried work loss train low test still high used two help hi try one provided trained data set check input data lexicon,positive
faced problem therefore temporarily use previous version import torch import model,negative
main file sat wrote hi file facing problem reply directly view,positive
hi file facing problem,neutral
close issue let u know get later,neutral
historical convention since lot originally defined base whereas implement base section briefly,negative
try made recent loading seem problematic flag revert old behavior,positive
thanks ended since way defined new version,positive
error master version run python work,neutral
hi share solution pretraining meet question thank hi ca language model facing problem even without language model without language model loss decreasing wer value always try python letter valid wer task arch static static dropout criterion seed thank try explain impact wer value eventually issue appropriate specification used know also used problem tried work loss train low test still high used two help,positive
set let run overnight thank much help hi meet question,positive
related translation system might able convert following similar,positive
script removed master found file sure still work several related would great converting model format,positive
thanks example able figure issue attention mask instead,positive
seeing problem example use,neutral
also interested load model follow written python import torch import model task get error object attribute looking documentation model class definition anyone know find model class,positive
yes error file empty looking data one solve many occur,positive
hey anybody able rectify segmentation fault error yet hi make language model use installation use worked thanks lot think close issue,positive
problem configuration file task data normalize true model true dropout,positive
hi code task exactly check whether help,positive
yes perfect work like charm actually casting downstream foo work submit,positive
hey anybody able rectify segmentation fault error yet hi make language model use installation use,positive
also experienced inference script manifest split split manifest none normalize fix also upgrade old task therefore set code later fix removing condition,positive
experimented bit found work better command following however script generation output remains problematic reverse entirely action used upstream practical example echo transform input sentence instead go problem space around symbol know whether problem trying investigate issue,positive
added used training base model model true dropout taken pretraining directory entry new saved used code work though default ran restart hoped afford default seem,negative
hey anybody able rectify segmentation fault error yet,positive
hi share solution pretraining meet question thank hi ca language model facing problem even without language model without language model loss decreasing wer value always try python letter valid wer task arch static static dropout criterion seed thank try explain impact wer value eventually issue appropriate specification used know also used problem,positive
read link worked thank,neutral
actually master recently commit would disappear exact problem small base model trained scratch due configuration mismatch exactly missing case,negative
copied inside docker code part saw guy wrote check provided link issue find,neutral
hi totally agree reference also somewhat doubt real performance model training data successfully reproduce score command cat noted text evaluation fully official result indeed previous confirming effectiveness hi could share script,positive
hi share solution pretraining meet question thank hi ca language model facing problem even without language model without language model loss decreasing wer value always try python letter valid wer task arch static static dropout criterion seed thank try explain impact wer value,positive
seen code written model saw code file line assert work best data normalization please check normalize set unset normalize introduce file line introduce file,positive
training compute raw wer aka inside criterion optionally provide also ken see strange happening wer computation might want print instance think default set letter word boundary,negative
sorry late reply mean command line training many also printed case training procedure said guess correct group used guess setting also effect case model validation step parameter inside criterion ask find training model fixed steady wer value weird training,negative
tried new version version still got similar error idea happening,positive
hi share solution pretraining meet question thank hi ca language model facing problem even without language model without language model loss decreasing wer value always try python letter valid wer task arch static static dropout criterion seed,positive
hi share solution pretraining meet question thank hi ca language model facing problem even without language model without language model loss decreasing wer value always,neutral
hi share solution pretraining meet question thank hi ca language model facing problem even without language model,neutral
thanks getting back quickly,positive
need check whether path correct input input data,neutral
getting error mention solve,neutral
hi share solution pretraining meet question thank,neutral
besides share running pretraining,neutral
tried according python tried combination got every file line file line state model file line return super strict file line error loading size mismatch param shape shape current model size mismatch param shape shape current model pointed accidentally loaded model see probably write python script,positive
getting issue unable solve yet,negative
getting issue unable solve,negative
think use process fail close process waiting data read connection object closed raise doc python main main writer code maybe miss one,negative
hi tried translation speed without solution,neutral
ah translation task rather probably mismatch hub interface beginning sentence token need remove token hi thanks replay yes translation task however removing token work think problem force none solve issue,positive
would something like shell split train valid test cat split split done shell generate dictionary hi case want use specific dictionary create hand right generate dictionary looking unique training case original dictionary appear train set want reserve special may use future added add case one would manually concatenate frequency,positive
correct need apply calling model use input pas,neutral
tried run going far tried running command python task path test criterion letter lexicon beam gave error recent call last file line module file line main file line main generator file line return file line task file line return file line dictionary file line dictionary file line load file line raise file line open file directory tried taking file folder data folder ran python task path test criterion letter lexicon beam got error dictionary recent call last file line module file line main file line main generator file line return file line model file line model super file line model self file line return task file line file line specify cutoff size tried file listed next transformer model file ran command python task path test criterion letter lexicon beam got error dictionary recent call last file line module file line main file line main generator file line return file line model file line file line return lambda device file line file line file line previous line repeated time file line param file line lambda return lambda device file line found driver system please check driver error fact proper mistake made one way run already setting command believe driver sure one reason guess seeing screen shot whole bunch area hairy get rather run,positive
figured original paper added code set true translation task enhance result hi specify place try fix,positive
line already present however double found style entry resolved thank looking fast,positive
better load like model task trying transformer last one modify code,positive
correct ended feeling confused model model load without strict model make sense sorry issue curious one pitch found model actually similar small,negative
ah sorry right try soon actual language model,negative
need use model model,neutral
ran first test getting surprisingly poor believe audio file lecture noise wer used command ran python task path test criterion letter lexicon beam anybody know get least use transformer language model instead getting warning python use functionality please install python use functionality please install however run either way could word error rate high due,negative
hi actually also met problem one place line problem sample,neutral
could point fixing case try version look maybe able confirm,positive
hi like phase understand well mask padding goal fact added id label input label padding added label considered initial task like algorithm work well know already taking care anyway working fine sorry trouble thank help hello please fix facing similar issue wherein model class entire exact version work perfectly model text class,positive
ah translation task rather probably mismatch hub interface beginning sentence token need remove token hi thanks replay yes translation task however removing token work,positive
look default see criterion actually optimization default code used yet sure mean getting automatically,positive
right check although set still get exact configuration need set example set twice two different match output letter criterion letter true optimization true still configuration think critical part getting automatically something wrong,positive
command line specify configuration check printed start training,neutral
hi issue training working correctly command line training set trial one audio repeated many time python begin training epoch recent call last file string line module file line file line self pickle data truncated recent call last file string line module file line file line self pickle data truncated recent call last file string line module file line file line self pickle data truncated recent call last file line module file line file line file line file line raise ex file line return file line lambda lambda file line run return file line file line file line file line spawn return join daemon file line file line join raise exception exception process following error recent call last file line file line main file line main train trainer task file line inner return file line train file line inner return file line raise file line loss file line loss criterion model sample file line result input file line forward model sample file line result input file line forward return file line result input file line forward file line result input file line forward file line source file line forward source file line result input file line forward file line result input file line forward input module input file line result input file line forward return input calculated input size per channel kernel size kernel size ca greater actual input size recent call last file string line module file line file line self pickle data truncated appear semaphore clean shutdown appear,positive
think similar issue running error connection timed handling exception another exception recent call last object establish new connection connection timed handling exception another exception recent call last object establish new connection connection timed handling exception another exception recent call last send self request stream verify raise raise except object establish new connection connection timed,positive
sorry keep fair bit mental effort keep branch date fix resulting upstream eventually merge abandon,positive
hi bug say fixed however check actually fixed,positive
knowledge way use quantization transformer latest version correct found alternative way,positive
sorry able run dynamically transformer try latest version alternate way dynamic quantization transformer model please try model might get improvement,positive
time ago able run inference dynamically transformer code tried something similar could please share code thanks advance,positive
ran command speech recognition also got index error task criterion arch seed recent call last file line module file line main file line main file line main train trainer task file line inner return file line train file line inner return file line file line loss criterion model sample file line result input file line forward model sample file line result input file line forward file line result input file line forward file line file line none index must,positive
facing issue able get around docker configure docker container use either install additional pip example torch install proceed inference normally show python ignore worked reason investigate wer get high container related locale python try execute following container update install reinstall export export export also experienced python resolve try infer parameter initially trying build python work sure made mistake building following could cause error made modification order work also use building locally,positive
hi one problem glue,neutral
bug turned fault something wrong path removed bug issue hope bug removed future version thank,negative
overfit le epoch best perplexity epoch epoch normal,positive
also got saying normalize simple comment,neutral
hello know get vocabulary confused index symbol easily get simple loop count descending order,positive
load like instead import model task model model extract feature way tried transformer model forward may also want try different model need make return layer also model forward thanks issue,positive
current error evaluate model used bash python task path subset criterion letter error loading unexpected key,positive
sorry clear mean support loading word want use positional need modify code support probably bit lower file want train sequence model different position domain specific learned position sinusoidal way either pack binary need somehow read,negative
python dropout dropout dropout linear linear linear linear linear linear dropout dropout dropout dropout dropout dropout linear linear linear linear linear linear dropout dropout dropout dropout dropout dropout linear linear none dropout linear,neutral
post output print model,neutral
thanks work let go back original point address problem model package common true false wer task data normalize false true criterion true optimization true model true,positive
ah problem trying load model state load model like instead model task model model,neutral
state right let share python print none none false none none false false false false true false false none none none none false true none none none false none none none false false false false false none false none none none none none none false none true none none none false none none true false none none false false false false false false false false false none false false none false false false false none false false false none false false none false false false false none none false none false false none true false true none none none python print none,negative
also since might wan na change function starting,negative
binary cross entropy criterion got use criterion one zero final prediction layer branch trained different architecture wasnt trivial migrate think one version try validate model see loss get,neutral
ran issue due blank run pip install pip install user pip running root user installation normal writeable somehow supposed user instead system error empty fixed problem pip install work correctly need reason presumably python see something particular file unfortunately sure would,positive
accuracy pretraining performance downstream task necessarily correlated especially across different model could example change mask length get close accuracy downstream task performance bad remember correctly base model around large model around,negative
short convolution feature fail since padding also since contrastive training sample utterance need least feature extractor need least pretty arbitrary could go shorter well wish long longer,negative
short set something reasonable like sample rate filter short need change code also skip loading since get error change code pad instead skipping look guard,positive
load model like import model task model model update script soon,neutral
really moment try add code check since alternatively try implement straight forward since easily get please contribute back get,positive
load like instead import model task model model extract feature way tried transformer model forward may also want try different model need make return layer also model forward,neutral
havent tried theory work bunch vanilla transformer,neutral
model dictionary upper case linked,neutral
add print state print state show,neutral
ah translation task rather probably mismatch hub interface beginning sentence token need remove token,neutral
similar current master surprising get different,positive
support somewhat experimental currently command running big note load data system memory store model device memory,positive
able add brief section use pipeline parallel training,positive
sorry clear mean support loading word want use positional need modify code support probably bit lower file,negative
yes look see package various outside source directory several directory also rely,neutral
big model file also state model size due removed ing key,negative
please let know transformer model tried get paper,neutral
latest master model however met error python import torch import model model log shell recent call last beef module model model task build new model instance return self self self key return except exception self key union self key value cause cause assert false node key value cause ex cause ex cause optional type ex cause else none raise ex set end full self key raise return except exception self key self key union try node except self key key value node key self key value key key self key value cause cause assert false node key value cause ex cause ex cause else none raise ex set end full key,positive
commit fine tune model latest master wont instead model,positive
comment model work well model work python import torch import import model shell successfully python import torch import import model shell recent call last module model none arch none import self key return except exception self key union self key value cause cause assert false node key value cause ex cause ex cause else none raise ex set end full missing mandatory value model model union,positive
got running evaluation shell valid use model made python log snippet shell begin training epoch epoch update loss wall begin save save finished saving evaluate shell subset valid python task path subset criterion letter log shell criterion loading model recent call last file line module file line main file line main file line state file line state model file line return super strict file line error loading unexpected key,positive
let share progress said error file avoid error related regarding error found dictionary result model label work gon na rerun evaluation model trained,neutral
sorry wrong path corrected ran command module pip install generation successfully finished en part still bug appear st part,negative
yes latest master yesterday since provided point like run python said error file avoid error related summary sh th em en el eh ey ae aa aw ay ah ow er ax space summary ey ow sh ay ey aa ah er ay en ow ay ae aa ae el ey el ax ey ow ey ah ey ah eh th ae el er ae sh en ax ah er ae ae el summary aa el ah ow ey eh eh er ey sh ah ae eh ae ay ae sh ae aa aa sh ax aa sh ey ae er er sh ax shell tree summary package common true false wer task data normalize false true criterion true optimization true model true run code python valid use model made work well related python,positive
also run path model de beam task test,neutral
somebody run need ram inference see,neutral
confirmed fine tuning found confirmation document,positive
hi find successfully run configuration process due thanks use provided generate command given,positive
latest master anyway reason probably dont target since provided probably phone instead something like,positive
trying load model model trying load model try model instead import torch import import model successfully,positive
hi thanks could finally tried evaluate model language model however met another problem shell subset valid python task path subset criterion letter error shell criterion loading model recent call last file line module file line main file line main file line state file line state model file line return super strict file line error loading unexpected key loading model may relate issue thanks advance,positive
problem forgot add answer,neutral
found problem fine tuned different commit used evaluation used commit version everything working like charm,positive
file line particular example order file,positive
please explain format file step convert sphere something like build manifest create parallel call corresponding line line create dictionary create file every unique phoneme space per line count run command something like script,positive
master might try look see help port anyway later find time thanks quick answer,positive
code lot change version use version refer issue information,neutral
awesome way chance could merge master update looking forward instance longer module thanks,positive
typically set similar negative value example,negative
set environment use able get run face lot share set simply follow official installation also follow run summarization task something wrong code python recent call last module count hypothesis size match dimension index smaller apart dimension use official trained model try train scratch following instruction get wrong inference test data trained code provided latest version code previous read issue code version fixed bug code version python fused unavailable may get better performance apex library device device else device device mistake may happen somewhere else,positive
set environment use able get run face lot share set simply follow official installation also follow run summarization task something wrong code python recent call last module count hypothesis size match dimension index smaller apart dimension use official trained model try train scratch following instruction get wrong inference test data trained code provided latest version code previous thanks lot check,positive
involved approval anything idea interested one thing unfortunate though entirely new set never going used class possible use constrained even slightly extend,negative
submit fix thanks flagging,positive
let know still master count yes thats supposed currently used put whatever youd like count,neutral
behavior fixed implementation well overall implementation still probability low,positive
set environment use able get run face lot share set simply follow official installation also follow run summarization task something wrong code python recent call last module count hypothesis size match dimension index smaller apart dimension use official trained model try train scratch following instruction get wrong inference test data trained code provided latest version code previous,negative
return copy gradient line return,neutral
tried also pip issue tried issue,neutral
hi yes working handwriting recognition meant fork work sorry send proper issue work,negative
oh gosh sorry try fork careful,negative
hi trying run provided still get error machine remains following line memory crash loading model hint could look extra thanks,positive
set environment use able get run face lot share set simply follow official installation also follow run summarization task something wrong code python recent call last module count hypothesis size match dimension index smaller apart dimension use official trained model try train scratch following instruction get wrong inference test data trained code provided,negative
met error old version repository question step create dictionary create file every unique phoneme space per line count count statistical information right instance phoneme aa twice file corresponding line aa,positive
ah thanks know must issue install,positive
like cant import tried python like error message suggesting,neutral
tried model data several finally got good enough result first key must tune according data maybe disable first second key must set ex think enough data maybe need data result better hi interesting read comment hope use could share u best,positive
hi figure also working problem need sweep need stripped away configuration ray making look like code way search thank awesome library work,positive
hi thanks step would elaborate step could run,positive
command use path beam en de version uninstalled master version work fine error,positive
tried model data several finally got good enough result first key must tune according data maybe disable first second key must set ex think enough data maybe need data result better,positive
command use path beam en de version,neutral
got error follow document tutorial follow error,neutral
thank try implement following,neutral
possible share size book corpus corpus trained,neutral
still error recent commit built via git following command python path lexicon task criterion letter beam stack trace criterion loading model loaded python use functionality please install python use functionality please install recent call last file line module file line main file line main generator file line return file line super file line,positive
hi thanks issue try absolute path,positive
image tried following configuration process luck yet,neutral
sorry issue try command fix coming soon find specific parameter,negative
connection completely separate unfortunately taken link unfortunately able share directly due looking large language modeling recommend,positive
question batch document batch need perform want utilize idea question document batch candidate critical part total batch size final objective need executed question document across know criterion individual coming underlying model architecture task criterion task defined concern loss use global batch rather locally highly familiar distributed stuff hope suggest easy way tackle need,positive
come posted import either made local code please revert code like code like,neutral
set environment use able get run face lot share set simply follow official installation also follow run summarization task something wrong code python recent call last module count hypothesis size match dimension index smaller apart dimension use official trained model,neutral
hi thanks interest yes release soon week send release notification provide many thanks,positive
set environment use able get run face lot share set simply follow official installation also follow run summarization task something wrong code python recent call last module count hypothesis size match dimension index smaller apart dimension,neutral
tried use version version problem,neutral
set environment use able get run face lot share set simply follow official installation,positive
still issue able reproduce master latest stable release try one reopen still problem,positive
work create dummy use instead add something like bash bin,neutral
right true per must number used also compute effective batch size,positive
companion paper multilingual might find interesting release paper possibly trained data well,positive
guess fixed last condition something like python,positive
python python default anaconda type help copyright license information import import float float float float float float type class recent call last file line module must class import inspect false,negative
different python python python default may type help copyright license information import import float float float float float float type class false,negative
hi thanks interest yes release soon week send release notification provide,positive
believe actually loading combine large could make everything explode update discovered number loaded per really misleading care must taken value loaded first one spread,positive
quite clear trying achieve tried work like want append extra target training case need modify sample target reference loss sample target left one position teacher forcing easiest way create criterion start criterion modify sample calling model thanks reply think thinking already create criterion modify sample modify sample extra keep real target feed function modify work well match target well please notify anything think appropriate another issue sample size small feed one sample difficulty example two augmented sample length fed model time target however different one need modify cutting extra teacher forcing right cut extra pad shorter one sample target one appreciate help figure,positive
like may fixed please reopen still thanks,positive
able reproduce try latest stable release pip install upgrade,positive
please install latest version common,positive
quite clear trying achieve tried work like want append extra target training case need modify sample target reference loss sample target left one position teacher forcing easiest way create criterion start criterion modify sample calling model,positive
tried could look constrained,neutral
clear version since look like current master recent call last file line import module current code master clarify commit,positive
yep like module compatible immediate add support would welcome get chance make work,positive
clarify bit loss particular unlikely work properly box loss multiple probably need implement custom kind forward backward example output vocabulary loss across multiple model parallel,positive
follow share exact command ran also mention version master,positive
thanks help running unsupervised flag pointing model resolved issue report running unsupervised polish data ti day roughly imagine considerable performance boost resulting model around better relative base model one share unsupervised model still considerably worse polish normally use think still lot potential hope unsupervised pretraining outperform still remains open question whether better system trained scratch target language audio suggestion could try multilingual base model common voice like great candidate,negative
tried slice new batch size result different slice solution limit batch size solve problem,positive
far concerned might useful also slice function extra know hurt model performance looking forward kindly reply,positive
hi error would also appreciate help thanks,positive
sorry late reply issue deeply taking account mention inserted code line python key type type type type got output sh key field float float float object latent variable sampling start end decay float float float type class float float float false recent call last file line module file line file line file line file line raise ex file line return file line lambda lambda file line run return file line file line file line file line spawn return join daemon file line file line join raise exception exception process following error recent call last file line file line main file line main model file line model super file line model self file line return task file line file line state file line state state file line state state file line file line model file line must class understand entering sentence exception happening line converted list reproduce error python import import float float float float float float type class recent call last file line module must class,negative
set environment use able get run face lot share set,positive
bug validation correctly submit fix meanwhile provide set thing,neutral
hi issue case reason first communication code line state none broadcast global state later broadcast sharded rank avoid memory o state state sharded else none state none group none else state state none recent call last file line module file line main file line main file line main file line main train file line file line file line file line file line file line copier memo file line key memo value memo file line copier memo file line key memo value memo file line copier memo file line key memo value memo file line copier memo file line memo file line file line clone return type self self file line return super memory tried allocate gib gib total capacity gib already gib free gib reserved total state current rank send buffer received buffer however check loaded buffer find none know shown exception therefore solution simple avoid communication load disk process state none state none broadcast global state later broadcast sharded rank avoid memory o state state sharded else none state none group none else state state none self,negative
similar please see comment,neutral
sorry sure understand going like handwriting recognition pretty cool please first open issue discus large new case likely want keep implementation directory similar ideally implementation would reproduce paper excited open bit,positive
ah likely dictionary match provided one old model data made dictionary creation totally deterministic get correct manually specify dictionary,positive
default use visible setup distributed training across combine try case currently support distributed training likely add support distributed training soon although mostly would expect particularly good training throughput,positive
directly support since reference selected setting candidate might try instead following code sample instead gather,positive
thanks test time transformer complete sequence conditioned model far want model generate complete sequence conditioned gold target gold partial sequence exactly behavior model training time hope model still generate way even test time want use sampling method since probability distribution entire vocabulary sample one token distribution treat model generation current time step token fed input next time step,positive
work thanks quick help close issue,positive
found issue two actually single option become python field help use usually automatically thought fixed quite right,positive
thanks could kindly point fix issue tested two docker version version pull code master run still see issue,positive
archive correct note fixed couple back see issue context,positive
thanks update well small training size something really weird configuration training size dev size batch size output believe configuration get log sample training set validation step output finally instead get log line training step validation step line parameter equal sh per none batch size per found loading train data epoch loaded begin training epoch epoch update loss wall begin validation dev subset dev epoch begin save saved epoch score writing took end epoch average epoch train epoch begin training epoch believe actually loading combine large could make everything explode dig yet code understand maybe explain going,negative
convert sphere something like build manifest create parallel call corresponding line line create dictionary create file every unique phoneme space per line count run command something like script,positive
yeah tried reduce model worked try fit thank much,positive
relevant code could plug call,positive
oh think test runner discover python test import something strict dependency apex like bug master currently,neutral
use environment variable run also specify multiple via,neutral
input problem long input size probably running memory input long please try input smaller smaller model trying efficient architecture lightweight dynamic convolution may memory efficient,negative
fixed master release plan release soon include fix error master make lot sense though difference tested master error line simple dummy operation test working,positive
also able try see work otherwise please try reopen still issue,positive
able python import torch ist learning great,positive
use first reference translation set basically whole reference get reference quite clear trying achieve behavior,positive
snippet code trying beginner judgment data index probability row return data import model model sample data result data import result range result,neutral
failure somewhat mysterious idea apex would fail found,negative
update memory increase number fist try make sure wo unfreezing maybe data size information enable distributed process also increase memory usage filter audio duration le prevent many one share affordable audio duration,positive
hi new want ask used pas,positive
beginning sentence token use blank token want decode output collapse consecutive remove word boundary token defined data nothing special code wise except,positive
think default gram need recompile support issue though might helpful,neutral
yeah sorry efficient shard multiple get bigger transformer,negative
never tried language model different lexicon domain also need upper case entire want chance working model capital,neutral
look example doesnt require language model,neutral
dont use id store target supposed unique add another key like overwrite stack assuming code correctly would also maybe experiment model add token beginning sequence use classification also act applied linear classifier clear extract model without whole quantization step parameter pas believe may also want disable like output feature look probably mean something wrong data feeding also probably want keep otherwise sample random data,negative
small question getting error python corrupted list attached full text tried one without see tell wrong suggest possible fix already investigate script execute line iteration lexicon word index spelling index scorer script order input command score error script execute word spelling please read understood clear lexicon something else time spelling time already try refresh still double error sometimes segmentation fault core dump time corrupted list memory problem,negative
sorry much may would like know semantically difference tag tag dumping raw model like old model ie likely output relevant end utterance would like two iteration model much often old model like apply transcription reference word six new model however wave would produce following output apply transcription retarded single even valid word polish lexicon spelling,negative
use pip install target wo work,neutral
error order write use build custom must add self already write script answer help people similar problem stuck process word already explain already open waiting dev giving clue solve maybe waiting,neutral
yes bug found command still clue solve try ask issue maybe solution,neutral
model polish try issue seem improve situation maybe try master run unsupervised maybe something got fixed say however unsupervised domain data work quite well available data around better output data model unsupervised trained need fix issue,positive
solve issue also searching way,neutral
provide exact command used well gist hi command python task path valid criterion attached,positive
valid train set still see every file size best way never put large audio manifest file first idea studied memory grow difference sequence size update still validate phase set safety,positive
pip install thank guy work case,neutral
used latest master something like work,positive
cool recreate close soon fixed side thanks lot help,positive
got thanks lot curiosity used,positive
try work try opening issue,neutral
use provide drive get error see problem,neutral
thanks lot help yes seem like correct fourth line bash file create wo use output directly use gave understand able encode file difference way use code package python copied script python could reason try python see whether still get,positive
unable reproduce ran following copied content drive directory bash python corpus python way end without produced file number file correct reproduce problem try based thread linked bug fixed point,negative
thanks prompt reaction indeed current version file master different one version update post particular part time since could please tell used verify behaviour could check see stuff correctly version,positive
able share reproducible example original text file maybe via folder information received let know need anything else thanks help,positive
yeah good actually bit since bit risky right instead action produce easily manually example assuming work similarly great build process build similar way,positive
thank detailed report believe issue must gotten fixed last day reproduction get following set attention dropout possible model please let know still problem also change line print print since converted model loaded,positive
far yet today tomorrow training work,positive
thank much comment working although still confused loading documentation mention valid thinking written another loading class audio estimate much memory occupy matter trial error documentation old bad order succeed running almost anything need dig every issue tracing back function min size know used,negative
someone provide command discussion issue another thread recent code,neutral
language model target language might retune language model model one particular word insertion penalty may help get better,positive
hi thanks reply sure prepare one share via drive,positive
error trying file directory try apt install,positive
able share reproducible example original text file maybe via,positive
actually strict requirement try removing necessary,neutral
try pip install see work,neutral
release setup git sync git update recursive pip install update also try release soon,neutral
try running git sync git update recursive thanks worked wrong dependency,negative
would entertain also package artifact new sure exact process channel,positive
mixed precision training maintain copy model latter used thus see memory usage model alone le memory usage pas rid model copy momentum thus see memory usage model memory usage memory usage relative,neutral
question please follow issue,neutral
thank much working visible ran command run command path de beam task test,positive
hello error error override problem definition used string execution model defined old definition full type ca backward compatibility keep correct type string since handle union fix fork ca would break configuration anyone idea patch correctly glad implement,positive
think worth try open research question pointing model dont forget various want reset well probably want define training budget set number use learning rate decay initial value course training unless change probably want use lower starting cant say good value experiment make sure data single channel trained old branch code different actually flag relevant stuff sorry may better source information going code looking bug ran roughly python task criterion arch temp default static dropout let call model let run around run training model following metric sure accuracy initial around validation set suppose learned valid epoch valid subset loss temp accuracy begin save saved epoch score writing took tried run model however problem training contain broke second time ran train script model worked reason perhaps set saved ran training like model work better raw loss raw model without additional unsupervised promising however reason model stopped working language model looking transcription used lot random seen target ever something like working model provide,positive
error error override sha segmentation fault name defined even though criterion,neutral
sorry hear know maybe environment problem,negative
error following error unrecognized,neutral
want identify longer say following command space space,neutral
aware support one still non real performance benefit may even like series issue raising memory utilization,positive
doc written mixed precision training architecture dont think super support,positive
used try value slightly higher without problem sure whether try even higher zero activation,positive
device default device suggest default device,neutral
already taken care declared something else end value doesnt understand convert list,neutral
please follow issue tried far,positive
try running git sync git update recursive,neutral
understand correctly update save every said need make code argument add command,neutral
hey may used fine tuning,positive
one first one ran command reproduce except without work also ran without still failing cant newly trained model master shouldnt happen error thrown line reaching line mention file line state little error throw section python try key value except ex raise could override append use ex except ex print print key key value raise error override ex confirm error different invalid value assigned subclass list model value string variable value list list,positive
thanks getting another error running run command path de beam task test error recent call last file line module file line main file line main return file line file line return file line return file line generate return sample file line file line file line input output index must current device,positive
training going fine also similar system,positive
long audio file might change cause every epoch try even smaller make sure issue due long audio sample occur skip long audio file according capability train large model hardware afford audio without notice still training step cost much memory valid,positive
thanks response close issue,positive
output like error file directory warning last input file effect fatal error input compilation,neutral
forward method output tensor well extra python output extra model sample extra give want may ask difference code give code sample according model use get output hidden state,negative
sorry meant run following command post output command,negative
output mean move path install tried turn directory version export export path executed pip install user still get error elaborate need thanks help building wheel pep error error command exit status command complete output running running build running build running building extension building extension file included warning warning disable define warning disable building extension file included warning warning disable define warning disable function warning comparison unsigned integer warning comparison unsigned integer building extension file included warning warning please include warning building extension fatal error file directory compilation error command exit status error building wheel build error could build use pep directly,positive
one ran command reproduce except without work,neutral
neither confused sh python python default type help copyright license information import torch,negative
yes scratch try model tried didnt help also didnt run many setup might question finding right hyper,positive
forward method output tensor well extra python output extra model sample extra give want,neutral
provide exact command used well gist,positive
model trained migration sure copy mine import torch,positive
never case none think set model right,positive
wer edit distance target length target length incorrect wer,neutral
wer provide one via otherwise wer really since sorry question place wer le equal possible,negative
cant newly trained model master shouldnt happen however hit error well trying load model different script without going one something like python state task model getting fixed later today,positive
wer provide one via otherwise wer really since,positive
solution problem training wer,neutral
like run similar problem model pretraining phase latent temp string loading string recent call last file line module file line main file line main file line main model file line model super file line model self file line return task file line file line model file line model super file line model self file line return task file line return file line file line assert temp temp,positive
thanks apply let know training went obviously kind model provide need keep data format however train new model data better telephone speech guess adjust convolutional network effective window length resolution roughly match model also would happy could tell metric differ,positive
hi need add since part code need path discover register task new implementation speech recognition speech translation merge example one soon yes thanks could please advise could run think able let know get,positive
thank reply think understand input sequence length output length include ax,neutral
version since first run command,positive
hi need add since part code need path discover register task new implementation speech recognition speech translation merge example one soon yes thanks could please advise could run,positive
command used correct hope starting used correct format try add data chance might enough know help similar scenario wer stayed wer around different depending language thanks try hi converge wer specify additional trouble running inference getting maximum recursion depth method chance similar issue model work fine,positive
finally change much smaller surface area,neutral
reduced usage memory faster feature extraction well feature extraction,neutral
current strategy quite hacky basically temp directory cleanup point like task,neutral
check code line like used calculation include,neutral
hi work well done also look speech try fine tune pretraining audio mistaken know annotation text done fine tuning,positive
hi speed text field curious optimize data loading issue share thanks,positive
include padding set feed got output none confused way code thank,negative
view model train faster language model give rather hi thanks comment future intention use everything moment hardware get first want learn mechanic information paper learn model large tagged know configuration adequate work interested need little help get work thank advance thanks message unfortunately also merely starting might able help much configuration trying get hold best luck anyway,positive
sorry issue try command fix coming soon thanks specific version tested version ended error loading missing key certainly got closer generation though actually filling,negative
still work give another look later causing lot,neutral
sorry issue try command fix coming soon,negative
know share black part plan provide possibly even commit later think standard black fine temp multilingual transformer static data directory like data directory per pair need give thought ah move new test class,positive
found problem experiment used error set default decode maximum index believe bug may want fix least give informative error message,negative
work around particular error add simple option checked copy cant guarantee wont crash elsewhere later update replace one simple work next error error override,positive
view model train faster language model give rather hi thanks comment future intention use everything moment hardware get first want learn mechanic information paper learn model large tagged know configuration adequate work interested need little help get work thank advance,positive
yes track state penalize last word also take care reset state generate part phrase finish interface sufficient though thought see think would make sister class modify appropriate considerably easier positive straightforward,positive
aside might also good opportunity gradually add type code catching linter generate better,positive
one example first read trying semantics ambiguous could refer hidden relative certain way fairly common like logically used extensively filter certain throughout path object lot flexibility way expressive semantics happy spin draft see actually look like,positive
hey tutorial useful thank start actually encounter loading maybe try according documentation state,positive
like trying model already meant provide path model want continue model use case use,neutral
thank prompt response log believe log meant output printed console log,neutral
view model train faster language model give rather,neutral
running error ti python o source docker image transformer model file line module file line main file line main generator file line return file line model file line model super file line model self file line return task file line file line specify cutoff size,positive
negative constraint easy avoid word setting probability phrase little confused setting probability last word phrase,negative
hi ran issue code sample error went check documentation whether name used open file second time temporary file still open across used later common issue python fixed check way fix,negative
never seen familiar based compose show output pip freeze try run one standard example see run,positive
set simple one support support loading come work around particular error add simple option checked copy cant guarantee wont crash elsewhere later update replace one,positive
think worth try open research question pointing model dont forget various want reset well probably want define training budget set number use learning rate decay initial value course training unless change probably want use lower starting cant say good value experiment make sure data single channel trained old branch code different,positive
good make code much clearer example,positive
share full log also print type following forward method forward self source like calling model forward method different,positive
temp multilingual transformer static data directory like data directory per pair need give thought,positive
know share black part,negative
hello get chance push manage somewhere,neutral
clever happy rework like ah thanks would helpful basically revert original everywhere new teardown pattern,positive
think work something like instead clever happy rework like longer term set worry support continue break undoubtedly yes hope begin increase coverage point confidence parity hope due diligence compatibility much like every aspect fail land,positive
zero loss criterion special token like padding token,positive
figured source bug hack fix bug prefix calculated whereas inference input list causing mismatch size prefix size input batch hack calculate prefix batch loop fix sure ideal fix,positive
able resolve future reference command given tutorial need include flag save information saving model flag set hence able load trained would suggest flag tutorial avoid similar issue future,positive
sorry delay thanks quick status update like avoid test one another probably merge simplified version get working bit problem delete temporary open technically context manager garbage collected think work something like instead python class setup self teardown self everything else use instead context manager along path seem working need find time get finish line try merge later week longer term set worry support continue break since think production research use case coverage helpful,positive
way put everything place working inference training maybe put pull request relevant would help future one new thing directory also inference hour inference directory file compatible previous version model one testing order wrong first inference code search file path directory directory also copied model save directory right beginning training inherently part model wo work correctly unless label file second thing case count really matter think would intuitive provide dictionary way stay different instead order different new researcher field would great put everything one place struggle couple thank advance hey think guy answer got lot right especially come proper think could try starting,positive
try best submit maybe need take time understand code first,positive
semaphore thing come load data thats message get kill process somehow example answer add decrease,neutral
command used correct hope starting used correct format try add data chance might enough know help similar scenario wer stayed wer around different depending language thanks try,positive
issue come wrong error fixed commit fix issue class self task super task,negative
command used correct hope starting used correct format try add data chance might enough know help similar scenario wer stayed wer around different depending language,neutral
yep task far rest migrate translation task love,positive
thank worked get error,neutral
hi anyone issue unable infer criterion please implement thank,negative
model another yes certainly create new dictionary used also create hand like one symbol per line doesnt also work sentence prefer something like python bin column count symbol actually used put number youd like first column order associated probability occurrence one example alphabet,positive
code based fork transformer library tue wrote hi news thank reply directly view benjamin muller data science deep learning applied benjamin muller data science deep learning applied,positive
good catch thanks update script sure related though,positive
hi solve issue yet loading ask another question know training language tried without success hi able model got decrease wer working different apart different paper wer sure peaked thanks also working non alphabet would mind guidance regarding used trying original observe slight decrease wer remains also size data set training training share exact command used got last wer hi everything guidance letter valid wer task arch static static dropout criterion seed,positive
never clean reinstall thanks,positive
found problem saving best,positive
code little organized main difference used python,negative
hey ran batch however loader work base model try load large model error recent call last file line main file line main model file line model file line file line file line open path file directory little bit see separate load specifically load line load line fixed like new work current version way everything also running process show although true problem running thats bad trained version code didnt correctly populate fixed model please let know successfully commit id run latest code error must class error error override,positive
semaphore thing come load data thats message get kill process somehow example,neutral
input tensor might work know signal print problem use get shape like whereas model something like work,neutral
way put everything place working inference training maybe put pull request relevant would help future one new thing directory also inference hour inference directory file compatible previous version model one testing order wrong first inference code search file path directory directory also copied model save directory right beginning training inherently part model wo work correctly unless label file second thing case count really matter think would intuitive provide dictionary way stay different instead order different new researcher field would great put everything one place struggle couple thank advance,positive
seen tried root access since run code server difficult another error warning recover pas appear clean shutdown cache know code mistaken may related driver problem,negative
thanks understand correctly training instead used change,positive
issue think occasionally unpredictably due weird wonder like overflow exception simply drop current batch thank,negative
chance could handful time without review keep fixing upstream,neutral
faced problem figure holy moly everywhere,neutral
would much appreciate anybody share nat implementation code,positive
check get error commit master branch,neutral
also facing model server seem saying memory left use model model reduce task model criterion model trained rank total memory name ti rank total memory name ti rank total memory name ti rank total memory name ti rank total memory name ti rank total memory name ti rank total memory name ti rank total memory name ti rank total memory name ti rank total memory name ti training per batch size per found loading train data epoch loaded begin training epoch note overflow setting loss scale note overflow setting loss scale note overflow setting loss scale note overflow setting loss scale warning ran memory exception memory tried allocate mib gib total capacity gib already mib gib reserved total warning memory summary device id metric cur usage peak usage tot tot freed memory large pool small pool active memory large pool small pool reserved memory large pool small pool memory large pool small pool large pool small pool active large pool small pool reserved large pool small pool large pool small pool training python ignore letter dev wer task arch static static dropout criterion seed normalize environment version master version o python version version configuration use ti git clone pip install,negative
hello also trying deploy use model also tried instance deep learning ami version version also git running virtual environment run following command path de beam task test get following error strict flag removed next version see recent call last file line key value file line update value file line file line file line ex cause file line raise ex set end full invalid value one exception direct cause following exception recent call last file line module file line main file line main return file line file line file line state file line state state file line state state file line compose file line compose file line file line file line file line ex error override see problem coming invalid value one anyone similar error suggestion resolve,positive
tried following suggestion tried command upper problem another problem training code warning recover pas appear clean shutdown cache besides even shut use unable determine device handle lost system recover computer become normal ever seen kind,positive
got even uninstalled apex,neutral
hi solve issue yet loading ask another question know training language tried without success hi able model got decrease wer working different apart different paper wer sure peaked thanks also working non alphabet would mind guidance regarding used trying original observe slight decrease wer remains also size data set training training share exact command used got last wer,positive
hello still trying find reason give similar error file find solution post similar issue building older revision took rev maybe need go far trick could try,positive
hi solve issue yet loading ask another question know training language tried without success hi able model got decrease wer working different apart different paper wer sure peaked thanks also working non alphabet would mind guidance regarding used trying original observe slight decrease wer remains also size data set training,positive
hi solve issue yet loading ask another question know training language tried without success hi able model got decrease wer working different apart different paper wer sure peaked,positive
hi see sure thing need could tell use train need sampler iterative multiple need way join thanks,positive
hi solve issue yet loading ask another question know training language tried without success,positive
ti command line task translation source target arch criterion dropout,neutral
hi thanks coming back want train model considering want train multiple question data pipeline since large want define multiple iterative one task train need distributed sampler iterative like return return could assist possible implement join multiple iterative way sample smaller often distributed sampler multiple iterative really appreciate help best sat wrote describe specific use case bunch decent describe support handle large data thread reply directly view,positive
describe specific use case bunch decent describe support handle large data,positive
maintainer happy start working,positive
hi faced another problem training model first even train entirely epoch however become epoch around tried change like several time help idea problem middle part training give looking forward kindly help log like warning ran memory exception memory tried allocate mib gib total capacity gib already mib free gib reserved total warning recover pas recent call last file line module file line main file line file line spawn file line join raise exception exception process following error recent call last file line stack underflow handling exception another exception recent call last file line file line main file line main train trainer task file line inner return file line train file line inner return file line file line file line file line data exception unable data enter function together error usually fallen sync somehow fall sync one memory training script cause one worker finish epoch still data try see,positive
log log loading corpus log loaded log pad log log log log log alphabet log final character log done log making suffix array log frequent sub,positive
thanks see attached line,positive
ah yeah python populate underscore add alias thanks answer,positive
hi training pretty quick say within min share full script version,positive
ah yeah python populate underscore add alias,neutral
believe audio data also normalize currently doesnt around something like,neutral
yeah think try later late thanks,negative
looking good could please move augment functionality wrapper like previous comment choose wrap wrap task based flag something like manifest split split manifest none false split split split wrapping make normalize sure whether affect model training normalize,positive
way put everything place working inference training maybe put pull request relevant would help future one new thing directory also inference hour inference directory file compatible previous version model one testing order wrong first inference code search file path directory directory also copied model save directory right beginning training inherently part model wo work correctly unless label file second thing case count really matter think would intuitive provide dictionary way stay different instead order different,positive
right train mode remove command nothing else right train mode ca delete command training mode le memory mode still keep mode need reduce batch size thanks quick answer lot,positive
use trained model inference bigger beam correct stopped wer thought language give good,positive
tried specify command line python task translation source target arch criterion dropout error log error unrecognized recent call last file line file line code file line module main file line main command,positive
thats strange wer stay raw wer decreasing something wrong setup whether use loss raw wer early stopping criterion would probably go raw wer,negative
great glad worked used actually mode whereas used word level language model dictionary thats good idea try add get around,positive
hey ran batch however loader work base model try load large model error recent call last file line main file line main model file line model file line file line file line open path file directory little bit see separate load specifically load line load line fixed like new work current version way everything also running process show although true problem running thats bad trained version code didnt correctly populate fixed model please let know,negative
thanks response try said reason wer always stay around wondering phenomenon considered choose wer due increase loss,positive
thanks suggestion worked amusingly situation bash head error thrown found wrong casing switched round bash head resolved issue output much better python tensor side could close issue couple related suggestion may worth considering page refer file correct one sure ever used full evaluation fact silently case may ideal perhaps assert could help catch thanks,positive
think rest working possibly fixed yesterday let know still doesnt work look,positive
fact pas proper dont specify anything get like training well see whole section translation task validation space use space see building instead blue scoring beam sample validation,positive
use need dictionary data also need use whereas used letter lexicon prefer,neutral
tried increasing error longer either source target side,neutral
seen wer even small beam give better later powerful bigger beam one hypothesis training model hard fix easily fixed harder fix choosing based raw wer work reasonably well slightly worse wer also play around see train bit longer seeing phenomenon observing,negative
right train mode remove command nothing else right train mode ca delete command training mode le memory mode still keep mode need reduce batch size,positive
fixed note recovery pretty fragile may better reducing batch size activation transformer,positive
afraid definitive answer tried access training,negative
hi facing issue anything environment version master master version o pip source source build command used source clone git repository python version version configuration ti sh task model criterion model trained rank total memory name ti rank total memory name ti training per batch size per none found loading train data epoch loaded begin training epoch warning ran memory exception memory tried allocate gib gib total capacity gib already gib free gib reserved total warning memory summary device id metric cur usage peak usage tot tot freed memory large pool small pool active memory large pool small pool reserved memory large pool small pool memory large pool small pool large pool small pool active large pool small pool reserved large pool small pool large pool small pool warning memory summary device id metric cur usage peak usage tot tot freed memory large pool small pool active memory large pool small pool reserved memory large pool small pool memory large pool small pool large pool small pool active large pool small pool reserved large pool small pool large pool small pool warning recover pas warning ran memory exception memory tried allocate gib gib total capacity gib already gib free gib reserved total warning memory summary device id metric cur usage peak usage tot tot freed memory large pool small pool active memory large pool small pool reserved memory large pool small pool memory large pool small pool large pool small pool active large pool small pool reserved large pool small pool large pool small pool warning memory summary device id metric cur usage peak usage tot tot freed memory large pool small pool active memory large pool small pool reserved memory large pool small pool memory large pool small pool large pool small pool active large pool small pool reserved large pool small pool large pool small pool warning recover pas note overflow setting loss scale,negative
hello still issue follow procedure generate task translation path beam tee score cut cut python ref tee finally scoring bash tee scoring ratio scoring ratio think might due fact removing remains even although un instead instead concrete example paste ref head tail return coup de de saut en de un de la de la de la altitude de plus de de pour observer son exploitation plus de de pour observer son exploit pour argent la mise en place un en panne solution petite correspond tableau de bord de mal pour en solution forme petite se tableau de bord de un de recherche la commission un de recherche de de serum de de en serum la la gestion un la un de en la recherche sur inclusion social sur social way fix,positive
hi thanks able first train model unsupervised data base model data lexicon file trying infer model facing error please look code python task path valid lexicon criterion error getting loading model recent call last file line module file line main file line main file line model file line model self file line return task object attribute,positive
another question generate multiple hypothesis score mean average different hypothesis thanks,negative
hi issue may help,neutral
hi thanks great script made however script working fine model given trying use model throwing error code ran python error getting recent call last file line module main file line main model file line model file line file line false object attribute please look possible mistake side,positive
also need script opposite direction,neutral
hi would like ask since fit mode want try right train mode remove command nothing else faced train mode ca delete command,positive
hey ran batch however loader work base model try load large model error recent call last file line main file line main model file line model file line file line file line open path file directory little bit see separate load specifically load line load line fixed like new work current version way everything also running process show although true problem running,positive
thanks maybe try model instead really slow thanks check open st would great,positive
guess relevant part code take look see create feature,positive
hi sorry late notice used snippet old side project really remember much moment probably mistake old version snippet actually used moment ca find ping,negative
like issue override saved saved specify run training perfectly fine since necessary argument calling load error saved argument value,positive
try best submit break often currently review past gone without review aged sure possibility opening amount ownership community would look like might make possible engagement,positive
think thats great idea made sure public also large amount internal integration pas push unfortunately remain certain find break often suggest possible contribute,positive
hi thank pull request require sign contributor license agreement need attention currently record system signature file order u review merge code please sign behalf someone else employer individual may sufficient employer may need sign corporate received error please contact u thanks,positive
yes dont specify lexicon build version build bridge like take look train language,neutral
hi leverage apex tensor hopefully get also recommend try transformer since model train model soon use directly least use speed st training,negative
right old version take first say going upgrade also even support series yet anyway even could get work need convince really bad idea stick alone,negative
sorry much context based issue description based year old please provide detailed preferably directly new version,positive
actually seeing somewhat different error likely due different building like within common none global model always default obviously loaded,negative
hi tried st sure whether go well situation maybe try make training faster,positive
hi found update since,neutral
hi find mismatch multilingual input source however multilingual model,neutral
would great introduce framework even augment,positive
thanks model whole day used one shall control make faster also didnt apex work much time would save thank task criterion arch seed,positive
hi run multilingual setting update per epoch different mine anyway following final training step forced epoch still took achieve epoch,negative
hi could please tell many run final stop long taken run whole day run loss also run st without pretraining thanks epoch,positive
tried current master still get error full console output false none none false false false false false false false none none none none false none false false false false false none false none none none none none none false false none none none false none none false false false false false false false false false false false none false false false none false none false false false false none true false false none false false none false false false false none none false false false none none none de dictionary en dictionary loaded loaded test loading model strict flag removed next version see recent call last file line return file line file line raise missing mandatory value missing mandatory value exception direct cause following exception recent call last file line module file line main file line main return file line file line file line state file line state file line file line file line file line file line ex cause file line raise ex set end full missing mandatory value,negative
mind want use instead source code,neutral
problem latest release downgrade unblock pip install alternatively merge fix shortly,positive
need specify original run find correct model load,positive
believe install see post pip install add new directory work around two way first could restart reload python path alternatively add path directly via note simply path appear work,positive
command running actually python task criterion arch wer seed getting recent call last file line state model file line return super strict file line error loading unexpected key weight size mismatch weight param shape shape current model size mismatch weight param shape shape current model size mismatch weight param shape shape current model size mismatch weight param shape shape current model size mismatch weight param shape shape current model size mismatch param shape shape current model size mismatch param shape shape current model size mismatch param shape shape current model size mismatch param shape shape current model handling exception another exception recent call last file line module file line main file line main file line main train file line file line please ensure match exception load model please ensure match please look,positive
yes thats exactly mean,negative
hi thanks quick response actually trying training audio already provided,positive
mean continue different yes sure reset appropriate,positive
guard make sure data normalization newly data group norm whereas still old forward pas therefore without normalize,positive
internal based believe also additive noise used wrap around audio add noise like copyright source code licensed license found license file root directory source tree import import torch import class object instance self chain chain self length must number length sequence precision sampling rate size sample might misbehave sometimes giving short silent effect chain pitch return return class self super import augment self return self return self index item index item item source item source item source return item think sense rework use kind approach instead,positive
follow documentation may want adjust smaller trained scratch model much faster enough,positive
thanks try later one minor question need adjust training model,positive
yes model please refer documentation training loading,neutral
also another question tried command train model test set much lower result current result alright result thank look forward reply,positive
tried also work well,neutral
thank interest plan release eta yet,neutral
new implementation speech recognition speech translation issue merge example one soon,positive
hi need add since part code need path discover register task new implementation speech recognition speech translation merge example one soon,positive
thanks issue know version,positive
hi thanks looking backward compatibility issue gather wonder tried,positive
sorry worked sometime still find maybe wait author response,negative
thanks could please check still need play server support,positive
local toy version without version build source version o pip source source python version version pip think version thanks information tried version work,positive
local toy version without version build source version o pip source source python version version pip think version,neutral
error reproduce version version o pip source source python version version,neutral
yep ca command instruction need assign st different name path case closed,negative
could physically run following,neutral
sorry problem yet use valid function validate model,negative
already answer problem know save model argument use build case use command python task criterion arch temp default static dropout temp make first must save command build model like like mention import torch logging o import manual splitting list base command build model task criterion arch temp dropout name message logger parser parser load problem solve,negative
oh sorry may tested mono work like give model like test well frequency tried set parameter model able transcribe anything,neutral
another note try change sample rate setting command given give file get error recent call last file line module file line main file line main sample file line iterable file line file line raise item file line run item file line data file line return data file line file line reraise raise exception caught exception worker process original recent call last file line data index file line fetch data file line data file line item index file line file line raise exception sample rate need exception sample rate need sure limitation model mistake end change forget make channel many module use search like module example,positive
getting error import torch import import rank size initialize distributed train rank rank print rank rank process rest training script go train error recent call last file string line module file line file line prepare file line prepare data file line file line file line file line code file line module file line spawn return join daemon file line file line start self file line return file line super file line file line file line file line going frozen produce executable attempt made start new process current process finished phase probably fork start child forgotten use proper idiom main module line program going frozen produce executable recent call last file line module file line spawn return join daemon file line file line join exception process exit code,negative
another note try change sample rate setting command given give file get error recent call last file line module file line main file line main sample file line iterable file line file line raise item file line run item file line data file line return data file line file line reraise raise exception caught exception worker process original recent call last file line data index file line fetch data file line data file line item index file line file line raise exception sample rate need exception sample rate need sure limitation model mistake end,positive
inference command docker environment python task path test criterion letter lexicon beam think got idea share curious simply generate file segmented audio audio file file size right column making sure include directory audio top file copy text first transcript transcript correct actually testing getting inference obviously result poor wer measured later reference full hypothesis transcript could anything copy like every file run,positive
please install reduce memory usage pip install recommend many data sufficient ignore data loading buffer empty warning triggered reduce time share data multiple pas like thank much recommendation think share data best way,positive
core file handler fixing,neutral
ah right option please add nag particular example update documentation,positive
please install reduce memory usage pip install recommend many data sufficient ignore data loading buffer empty warning triggered reduce time share data multiple pas like,positive
finally got test providing however possible get inference model without reference testing inference something need change command,neutral
wondering run example gave,neutral
think figured sorry bother although gotten model anything yet ca sure anyone curious conversion go page see link extract folder see folder follow page first instruction follow complete go page inside folder find folder place file build folder follow page binary file go saving memory speed approach first run command assuming check much memory method use enough memory go go sure one give better first get folder move folder data folder docker,positive
open similar issue investigate read model file answer happen think base name function run maybe maybe error train meanwhile try open stranger model use finish best mode continue train make model matter train every must set new virtual machine train right prepare set next step try test next step step matter use base model model load model already follow instruction given problem model create result model none start fine tuning process import torch print none print false false false false false false false true false false false none false false temp false false none none false none false false false false none false false false none false false none false false false false none none false false false none none temp temp temp must use option create model make must please need advice edit already got answer get problem like refer model know content model follow process pipeline train know create model model create similar command like model command inside model giving trouble continue next step process solve must record command use model example mine use command python task criterion arch temp default static dropout use python reproduce process model get command script import torch logging math o random import create argument manually base command create model task criterion arch temp dropout several process get pipeline order name message logger parser model parser note understand similar model step already model inside save model already create save use fine tuning use step show put model run script model error error resulting result torch reading process try model get result none prevent error next step process apex installation method make sure install apex pip install use command install apex pip install,negative
hi docker script model base model speed build self letter lexicon lexicon command even tried model still worked difference used infer command mounted shell docker environment python task path test criterion letter lexicon beam addition content test flew reaching half yard fugitive head terrible disadvantage instant sank came closer quite within grasping reach reading thread thoroughly grateful well plan trying well wondering mean specifically model speed build self conversion process way build file exactly sure go making,negative
wow update helpful problem previous version use task file train multiple raise module,negative
hi also facing similar issue segmentation fault method class start memory till loading part still trying find reason give similar error file find solution post,neutral
even pretraining seeing transcript file audio like available audio transcript possible train model audio whose transcript file present step create model need transcription make sure file format channel already splitting base suggest experience maximum super computer spec really consume memory make file train memory audio data chunk base silence setting make sure maximum audio fit memory convert set channel create model step put already spec like mention specific directory create new directory save manifest create new directory save result run inside directory command base python create directory start train make model use command choose used base model command python task criterion arch temp default static dropout choose number worker train use home reduce base processor number processor number reduce worker little warning make really quite slow want use working something else use something similar like reduce number worker create model experience stop reach result train use account used exceed maximum used still use something else without model create next step train fine tuning method fine tuning use start must prepare audio number condition base work audio yes want make audio benefit need audio much research paper used audio create model use audio data use fine tuning assumption data already data understanding speech enough map label much data another language think data percentage raised use use model already share step prepare make sure audio data format channel put label file folder file transcription file format hi sample transcription format build save transcription format illustration save file folder directory name transcription file content file like example use lower case letter use pick one type run produce file audio data python run twice file directory python train python valid command resulting file error run key dictionary match key used open already fix code ago better file error run replace script import import o main parser open open open root next print root line line line path root assert path open path part line assert part print part print list part main edit file make sure file character use letter character use lower case letter space character create new file open text editor use find text editor use sublime text search character use letter text editor show number character record write thing character count mean character character write base number character ascending base number example save remember file create file use make script use write self import o sentence sentence sentence sentence sentence word sentence word lexicon range word word temp result temp result lexicon create file format something like every word label transcription file write like use lower case letter transcription make lower case become every word use need file create follow instruction follow instruction ready command base command python port letter wer task arch static static dropout criterion seed want resulting error run number error file line module file line main file line main file line main model file line model self file line return task file line file line file line object attribute command use python letter valid wer task arch static static dropout criterion seed folder folder empty save model resulting process folder file resulting process try process step step found error call file edit found error solve problem error happen file line function try reproduce step report line path function call line command reproduce variable variable false false path come set option function path define variable path open path line file call read file define variable error state line file error report said ca decode position invalid start meaning torch load suggestion somebody help fix tutorial edit problem model file error root error script save model process custom yes script use build custom model custom save use train model must add self make model read run script import torch logging math o random import base command use create model example last command use run like python task criterion arch temp default static dropout copy argument convert line argument task criterion arch temp dropout name message logger parser argument parser file file file error file line iteration command score try print value print word success input add script word enumerate word score spelling token token spelling assert spelling print word score score print result success success success success success success success success success channel success success success success success success success success success success success success success success success success success success success success premier success success success success success success success success darat success success success success success success success success success success success success success hey success success success success success success success success success success success success corrupted list clue error make error already character something else found word found funny run result found success success success success success success success success success channel success success success success success success success success success success success success success success success success success success success success premier success success success success success success success success darat success success success success success success success success success success success success success hey success success success success success success success success success success success success success success success success success success success segmentation fault core funny make see word first attempt report show success success second time run command found make error print report print segmentation fault core wow use language language clue maybe help already ask right,positive
anybody know language model temporarily,neutral
tried large model second file transcribe getting unusual wonder anybody clue going try show kind process involved yo welt able night togt able get enough able answer away useful,positive
note people trying model seem get awful example ha ha file audio perform well sure sample rate go,negative
might onto something memory thing expanding get transcription large model still getting though question essentially tendency within civilization question get working second,positive
would poor result got maybe something language model something else wonder,negative
wondering memory allocation problem checked docker found assigned ram believe tried increasing order make restart docker edit never mind believe simply directory need read going test really memory problem trouble able run container since know nothing docker idea link external data directory back container command believe command docker run name something run folder get error unable get absolute bin path file directory,positive
tried model tried still actually say time provide transcript bad error rate unfortunately o tenancy withen nat yo reference question essentially tendency within civilization use wonder model anything edit file tried long tried minute file small model try second file large model also,negative
temp solution might make fixed model resume training drop training make independent forget backup one fix inference code better idea,positive
try temp solution copy workable model like,neutral
command letter word python task path subset criterion letter,neutral
interesting note different loaded differently wonder might source error although getting error getting model loading although loading though could wrong,neutral
able resolve issue object attribute still stuck thanks,positive
hey refer page lexicon note page yeah need file train valid create format used model start model refer thank never know way road still way go ask got problem step make issue section full hard find problem similar minimize question make step step tutorial example already short time file number explain anything number number get number number character number character file number character mean something else little question need time investigate kind,positive
open new bug link,positive
previous bug request link,negative
thanks code aware approach fine tuning search fruitless far still run code though,positive
hey ran batch however loader work base model try load large model error recent call last file line module main file line main model file line model file line file line file line open path file directory little bit see separate load specifically load line load line fixed like new work current version way everything also running process show although true,positive
mean talking instead read whole script made automatic generation necessary specific work provide scatter across relevant correct got format wrong cause still everything working correctly yet run audio pretraining prepare use script get arbitrary run prepare following check example link train valid train valid file contain corresponding train valid order file contain file divided space divided end sentence example file know knew read said girl voice behind knock something extremely suspicious information brain come brain work example file decode check,negative
got error missing mandatory value situation change got ca expression thanks obviously working latest version,positive
thank much really really appreciate,positive
really want see soon,positive
welcome feel like way hustle inspiring keep hot,positive
hi pretrain support found origin repository pretrain example,neutral
hey refer page lexicon note page yeah need file train valid create format used model start model refer,neutral
hi think problem come since segmentation fault initialize validation set would mind listing used building package check,neutral
get error get error message missing mandatory value two loading model translate something execute path beam thought put flag recognize code worked pull thanks,neutral
think use case think,neutral
go build similar lexicon one letter word tab space word boundary token end hello tab,neutral
facing issue trying model base trying replicate experiment paper wer stay python letter valid wer task arch static static dropout criterion seed let know see something wrong thank help create lexicon file use,negative
reproduce end yet latest master added new model also make code ensure everything worked correctly top new recently added note argument latest master,positive
yes true hard create similar process clue reproduce similar process another already two learn still figure process know create new many file channel mono use language use python convert chunk base silence set add common voice speech convert channel speech still clear many make good result someone hobby like fun think create one hard work resulting use create file direction file point file exist train create model step problem start got clue create another file still tutorial train language model still unclear module still get clue create binary file must use several file like letter dictionary make language language lexicon file make lexicon file like similar lexicon think use create lexicon file option base use know start stuck step step tutorial reproduce file format data like said,positive
thanks tried torch bash file line main file line main return file line file line file line state model got unexpected argument different version something,positive
python path beam get recent call last file line module file line main file line main return file line file line return builder file line file line raise file found file found able read parameter,positive
let try figure issue tested work docker host sure cache clean fresh docker install stay tuned,positive
please reopen issue following template particular need know command ran environment,positive
thank new update yesterday issue,positive
also facing problem solve issue code path use new update yesterday issue,positive
set number thread file,neutral
root cause structure model different official model like beginning inference framework automatically training according model structure inspection temp solution python import torch official print none print official temporary solve imitate official model official,neutral
taking main provided trying run inside running command pip install get error unfortunately file collected running develop error command exit status open compile code develop check full command output try search help would much,positive
solution reduce set bigger keep batch size know real reason problem,positive
hey think would cool set notebook everyone run trying run docker image graciously provided thank everyone amazing step forward running system see think notebook would avoid since would need worry working different although think able run local machine well install docker mixed try give shot able make work update help whatsoever would much though,positive
people already trying figure good know one bit complexity setting already set docker image know know either think something like virtual environment know know like instead computer install certain folder mess main pip install running docker outlined bottom first step would docker docker run bottom page see running running issue might either mistake end probably something else would much preferable deal unexpected get different already great step forward keep,positive
yes torch hub interface also something plan soon within next,neutral
hopefully easier review let know need anything else,neutral
cant latest master issue awhile ago fixed day try,positive
sure problem fix lexicon free landing shortly tested similar setup working end perhaps lexicon free fix help dictionary need put data per,positive
yeah import work warning code able import used think wo reason error right,positive
fix added comment crash see warning printed top install go python type import work,positive
command saving really good upside logging actual search particular plot legend one main personally use compare interface logged even specify explicitly may help lot default change plus need look code figure need illustrate would possible without logging tuning screen shot legend screen shot,positive
resolution facing issue even number training even th epoch immediately seed seed batch big handle even seed set differently according epoch number right,positive
command opinion enough image,neutral
small question getting error python corrupted list attached full text tried one without see tell wrong suggest possible fix,negative
sure also faced reaching stage somehow dont think lead error error due import error object attribute child loading dictionary got error object type path import dictionary python train task path criterion lexicon image give feedback,positive
thank support would great find way log super important reproducibility opinion essential part initially via optional parameter function constructor think good idea figure way maybe via train loop also latest logging probably figure universal implementation,positive
yes suspect state model correct since recently configuration instead please submit fix,neutral
share command also since related,neutral
hi option allow score reference translation instead hypothesis,neutral
hi also possible translate python interface like case please let u know running example,neutral
issue probably structure folder something like previously pointing directory one version code able import module current master import module directory actual module directory one highest current master seem import module register successfully pattern example posted,positive
thanks sorry took long review used way testing let merge like recent configuration work add git commit,negative
chance make sure broken anything review wait bit,positive
please refer latest version pipeline use different hardware great point support yet loading model try add soon,positive
able reproduce fix issue end please pull latest version code refer latest version pipeline different hardware let u know continue facing,positive
work along pipeline used generation time let know work end also removed size added work associated pipeline used generation time look generation well,neutral
try past confirmed working master something like bash python task arch criterion,positive
yes exactly usage found,positive
general model dictionary use case archive correct use,positive
code exact task hope thanks code aware approach fine tuning search fruitless far,positive
thanks reply may please include specific model parallel data like data thank much best,positive
example code like wrap done want load model hugging face thank,neutral
slow training specially data feeding part tue wrote necessary go use output hugging face raw text like input output model input import model print got tensor tensor tensor reply directly view,negative
yeah know way different language require well inference time,neutral
necessary go use output hugging face raw text like input output model input import model print got tensor tensor tensor thank,negative
thought first think something wrong produce error think state shall architecture well,negative
right currently model define architecture layer model arch need inference,positive
hi reproduce error mind diagnosis,neutral
found issue different training loading model,neutral
thank unaware idiom assumed extension would loaded per able read access model code per original issue,positive
pretty cool would love see work ca think anything incorrect approach moment need give thought get back think something could differently,positive
note current always provide,neutral
issue git pull get error use missing mandatory value,negative
already except clause around import problem except clause namely statement line object result import used start function plain object causing following line fail object outstate,negative
thanks finding root cause ill put around import,negative
note example audio corpus short second long minimal example showing still none longer use script work git clone pip install torch pip install import import import import python python port python task criterion arch temp default static dropout import o import torch import model none recent call last module print model none task make sure present return default object attribute,positive
confirm used evaluation training data model applied raw text sanity model want make sure important detail right confirm used hypothesis training validation data apply ref,positive
present model work memory soon release work memory,neutral
object attribute fix issue import python currently support causing top script treat plain object attribute child according rebuild python see issue personally import statement top instead going use anyway hope help,positive
typo paper trained total batch size per,neutral
awesome work thank much,positive
hi monologue able resolve facing issue given everything go well,positive
able yet unfortunately time try carefully try update code simple like mostly lost next like quite learning curve someone python could wrong see make make gigantic super function enter audio get text back quite clear audio file custom one try figure,positive
help reference trying get use model problem error worked step came similar step order fix specific bit version previous support problem error error message file type order fix use specific bit version file step fix hopefully problem error number error along undefined reference error message bad address section error returned exit status currently trying fix update shortly update problem error findable linker detail force compiler use outlined spec undefined reference error part static library linker work around update given run causing discover fix post expect anything best luck,positive
hey facing similar issue module get error module trying run python following installation git clone pip install please let u know found solution problem thanks,positive
sorry get solution hugging face,negative
use efficient data format le disk space see,neutral
hi monologue able resolve facing issue,positive
one run model also another without flag yes would proper configuration quite get element list adapt configuration case alternatively one run model flag trying run still get error,neutral
trying work done create data set audio vector way kernel size way linear end still clean wondering missing make really fully,positive
oh thanks filter longer strange,positive
actually know real reason triggered error used smaller nearly one triggered error everything working guess may unexpected original,positive
hello met error adjust cause error,neutral
welcome single thread worked fine sentence usually faster passing neural network admittedly mostly used method call fast also via single need easy enough,positive
fixed issue switched everything like minor think good hopefully final review whenever,positive
also seem like causing fatal cache,neutral
case reason limit docker disk size,neutral
thanks reproduce error firstly need fix another bug parameter run script get error,positive
hi train model multiple work data parallel regime model replicated across data split effective batch size bigger utilization quite understand would want decrease utilization slow training keeping overhead data parallelism decreasing model size decreasing batch size reduce want keep would much better train instead keep fully one free since remove cost data parallelism communication synchronization thank much answer current model large insufficient video memory want use mib video memory add two video ca,positive
confirm used evaluation training data model applied raw text sanity model want make sure important detail right,positive
confirm work removing script reduced model,neutral
training single pipe module transformer model need set training command instead two pipe one one since separately generation case need set instead,negative
yes indeed generating different reproduce error two dig get resolved within next week update thread fix,neutral
hi train model multiple work data parallel regime model replicated across data split effective batch size bigger utilization quite understand would want decrease utilization slow training keeping overhead data parallelism decreasing model size decreasing batch size reduce want keep would much better train instead keep fully one free since remove cost data parallelism communication synchronization,positive
install used docker image everything right nightmare maybe inspect history image realize install bash docker pull inspect history building docker history extract docker history format,positive
like issue let see related issue,neutral
thank check share installation command,neutral
thank much single thread suffice necessary extend,negative
inference everything fine wer maybe problem program instead command,positive
basic template training different find time test yet flow hope find useful,positive
also file would awesome could remove think work without,positive
problem solution work python torch,neutral
also problem one could help lexicon command run subset python task path test criterion lexicon letter beam get wer run get wer could gone wrong example output get hyp ester day ere atremble health hat dear te day fear morrow ill anxiety money day morrow die ribe slanderer day hat te misfortune friend hen heather something hath broken lost ten pleasure reread calm reproach course public ref yesterday trembling health dear day fear morrow anxiety money day morrow diatribe slanderer day misfortune friend weather something broken lost pleasure conscience vertebral column reproach course public,negative
happen clone branch instead master branch case work,neutral
hi keep issue per issue arise installation done locally git clone pip install case keep getting argument conflicting option string install pip install work version git log commit head master author date wed fix latent depth summary registered model rather pull request resolved differential revision error,neutral
thank send manifest additionally decode work well,neutral
error fixed removing exist maybe send manifest file like help check integrity,positive
list lexicon unfortunately separate segmentation fault found method file segmentation fault section python false word enumerate word score spelling token token spelling assert spelling score work know wrong,negative
try get end week early next week,positive
dont know either whats error try official people usually output official,negative
sure still issue please reopen,positive
tried run exactly command latest version see issue could fixed still see issue please get exact version ticket git log,positive
mean would like inference work across yes possible,negative
possible release model across inference model need two mean would like inference work across would awesome let know,positive
would possible add command scheme work compute platform also think hardware rent far know thinking model would somewhat le ca run commodity hardware,positive
thanks explain purpose ca seem find corresponding seem really anything would responsible handling want make sure understanding motivation,positive
thanks looking forward regular,positive
correct link update accordingly sorry confusion,negative
sorry command actually need two model also need fix ensure work instead update soon reflect except reside let know going forward,negative
issue python recent call last file line module file line main file line main return file line file line file line model file line return super file line model self file line return task file line file line file line module balance file line device file line return convert file line file line file line param file line convert return device else none memory tried allocate mib gib total capacity gib already mib free gib reserved total,positive
thanks useful various check opus project corpus believe based witness work mainly corpus data mining indeed future human various wat well would useful check section paper also list low resource like various community,positive
thanks like link valid update soon,positive
yes problem much better,positive
learning rate schedule assuming currently set try increasing thanks reply use currently try increase,positive
learning rate schedule assuming currently set try increasing,neutral
able reproduce try version master see issue,positive
able reproduce like maybe trained model version trying load older version try latest master version see issue still,positive
hello know get vocabulary confused index symbol,negative
thanks suggestion work specific project similar often used kind work also included opus project team sometimes low resource one mindful style writing quite bit different say news social medium typically one train style domain writing system eventually applied,positive
thanks reply could create bilingual model another language dictionary,positive
certainly code replace loader layer new one optionally part old layer would want,positive
number per batch typically dynamic meaning batch size determined total length sequence opposed number also use traditional see due recent making arch first one fixed replace fix tomorrow,positive
oh actually like delta single linter advice single test warning maybe big effort,negative
ca peer black box see help land happy,positive
python version know got error message built docker file hi thanks answer could error fact working root running user server tried solve docker file still run error code used docker file use may cause dynamic loading run update install run pip install upgrade pip pip install pip install run git clone run data copy run pip install python help python help thanks advance,positive
awesome import review bit,positive
disabled follow author test,negative
sorry case paper smaller scale would comparable,negative
trained way begin different random weight seed flag multiple like typically performance,negative
ah due recent change script work fix thanks opening issue,positive
anyone got exact wer data like getting high wer range subset weird get exact subset,positive
hi docker script model base model speed build self letter lexicon lexicon command even tried model still worked difference used infer command mounted bash docker environment python task path test criterion letter lexicon beam addition content test flew reaching half yard fugitive head terrible disadvantage instant sank came closer quite within grasping reach,negative
hi help difficulty issue give lexicon command line help help lot mail address sh thank,neutral
get exception even running find solution,neutral
use beam size infer wer also beam size wer also tried training corpus however wer know configure wer,neutral
code found forward function variable several forward function several different need modify need official support,neutral
found way load substituting name however since different architecture standard transformer method work scenario suggest use modify arch transformer load excuse may ask load model want use trained hi solution self super true output key print key key word key position key type key none else key attention key print key query key print key key print value key print key print else print dense key pooler key key print intermediate key print else print key print key key print print else none none print model key print key print key assert transformer contain load transformer key size key size key else assert key key return thanks let try,positive
also ca state interface several due external specific task mind considering vocabulary theoretically understanding possible add new concatenate newly randomly however implement feature instead function like figure best practice happy implement idea,positive
got error find solution,neutral
think got something place hacky solution,neutral
need pas task dictionary,neutral
still getting issue function object attribute,neutral
time look deeply enough solve may incorrect believe problem use token language tag tag following set actually set prefix decode token force predict target language token first token set complicated index data optionally initialize trying paraphrase example use dummy language code source sentence since need target also uncertain unadapted model way train additional layer without model clear effect removing since pretraining made use short think modify code able use model way certain technical model course trying test reason issue hi tried feed target first input token however could make even extremely low probability lower uniform distribution,positive
carefully case note necessary well though would hard tell due flag due new version though since however notice drastic change performance positive negative version code base,negative
anyone got exact wer data like,positive
hi met problem mean used model specify model anything else watermelon,negative
yes plan release near future thereafter provide regular,positive
probably split input separate translate one one maximum length support due number positional present training time feed arbitrarily long,negative
think data way related somehow result high time would really appreciate could take glance maybe find detail might daily mail run python comment code lower case add space remove run count open source open sline sline sline source count hypothesis hypothesis count hypothesis hypothesis run export jar hypothesis target cat cat one ask convenient could please share would really want know data score gap address thanks,positive
also ca state interface several due external specific task mind,negative
friendly common usage wondering integrate framework,positive
problem wrong environment variable code exactly wrong version used try check moon wrote hi solution tried replace nothing message look like functional torch self module attribute directly view context type type target comment comment name view issue description view issue publisher type organization name try define class locally torch import tensor import class forward self input tensor tensor return input replace original code,negative
tried add function model also please note official notebook calling translate function doubt inconsistent could please issue thanks,positive
could underlying framework could explain specifically provide minimal,negative
thanks reply think install apex influence set flag work load epoch immediately even tried use train scratch still epoch size normal thanks confused show batch size big first epoch today try increase small model also met problem epoch load resume show stage recover pas small random seed resume train,negative
related raw work specifically seem like language get read see think maybe responsibility accept language code append least invasive,negative
tested like clear happy put skip around,positive
yeah something weird think stuff going skip test seen flakiness perhaps disable,negative
need call loading otherwise dropout applied thus causing,neutral
flaky test like see context need necessarily wait since broken already address hacky stuff make pas raw hopefully,negative
second thought likely due translation data generation process could case data numerically unstable process pipeline odd flaky test since everything sequence,negative
something interesting becomes tensor completely full,positive
use example usage script default error message,neutral
option clear cache cost speed assuming apex well size,positive
last hurdle flaky assertion sequence generator,neutral
yes set confused ca find code searching solve problem yet code problem clone several day ago follow evaluate model command meeting many parser successfully small model,negative
bug recognize path mark form use recognize path python language one form similar path recognize python command run python false command python python train correction may add clue use doubt may developer make anybody understood python language,negative
sorry ask stupid question control batch size training evaluate model according met error like option string remove one met unrecognized letter error remove met error object attribute miss something besides change occur error default process group found set,negative
apparently inefficiency toy write task next epoch would training later used successfully full without delaying training improve task though share code next week get back work main flow create task translation task create new argument directory raw data create second directory data need run disk override train set loaded one directory data second directory another thread use first directory think also make sure done safe remember right though,positive
garbage collected eventually context manager temp end test permission task still end main collected end see sticking print,positive
fix good please submit,positive
interesting whole task instance get garbage collected end test case,positive
run full error message stack trace,positive
hello trying already base model base model fine tuned however trying different language therefore different final output layer would course different want layer new new letter wish starting already model done also facing error even error loading size mismatch param shape shape current model size mismatch param shape shape current model please help solve two issue,negative
great know alternate letter maybe documentation explaining however probably different issue,positive
found way load substituting name however since different architecture standard transformer method work scenario suggest use modify arch transformer load excuse may ask load model want use trained hi solution self super true output key print key key word key position key type key none else key attention key print key query key print key key print value key print key print else print dense key pooler key key print intermediate key print else print key print key key print print else none none print model key print key print key assert transformer contain load transformer key size key size key else assert key key return,positive
encounter segmentation fault use following command python task path criterion letter lexicon anything wrong think problem related try watch video kemp show u step step procedural reproduce language model build look start even video talk use language model think try build related use mean procedure kemp show hope help,negative
python import believe module come folder find clue call folder module sub module folder file share file share script inside edit sorry understood use predict form well thinking like double process first use detect locate speech treat vector calculate possibility similar speech make condition without label want make similar thing understanding working working important speech use guarantee speech even different like noise existence detect make similar opinion method time focus one representation speech work calculate word speech easy way like speech show example word mommy go market word go clear method lock minimize prediction make raise become true guess missing data go base data recognize mommy market make idea like hope,positive
getting following error running python script recent call last file line module import file line module import undefined symbol someone help error studied answer call different way import import criterion import common,negative
investigation think normalization line code still unsure modify get,neutral
python version know got error message built docker file,neutral
version given believe release cadence going forward regular defer actual maintainer provide,neutral
tell specific train model command training recognize code,neutral
tested case docker work prepare data model shell example model file want test forget resample prepare put prepare build script use may cause dynamic loading run pip install upgrade pip pip install pip install run git clone run data copy run pip install python help python help go build docker shell build docker build run docker docker run name go container docker bash run recognize python hi everyone try build docker file get error error file found directory mode file definitely anyone else issue thanks advance,positive
dont training resource right smaller size also want model learn well trying implement model bilingual data,positive
nearly data model make multilingual,positive
many data target language,positive
batch size super small many model model trained,positive
met issue epoch one ti strange previous epoch everything load saved resume epoch get error immediately reduced work,negative
try setting option alternatively reduce ram fragmentation issue,neutral
wonder feature would like implement similar feature may know cause inefficiency whether resolved thanks,positive
running docker kept failing problem running local machine environment work nicely thank,positive
sure see need prepare training data accordingly ae eh probably use something else instead letter stage point view lexicon used training actual,positive
sure well meant use phonetic lexicon instead syntactically correct look like following ae eh ae eh ah abdicate ae ah ey ae ah ey ah ae ah ey ae ey abdication ae ey sh ah ae er ae ow ae aa ah abdomen ae ow ah wrote correctly understood question could ax talking example specific based look training data like prepared understand point corresponding lexicon one hided somewhere probably source confusion example trained sentence instead lexicon sentence thread reply directly view,positive
correctly understood question could ax talking example specific based look training data like prepared understand point corresponding lexicon one hidden somewhere probably source confusion example trained sentence instead lexicon sentence,negative
thank guessing end word marker anywhere else individual like could also like ax correct wrote guess lexicon anything far training data model trained example lexicon look like example thread reply directly view,positive
guess lexicon anything far training data model trained example lexicon look like example,positive
got wonderful understanding correct lexicon could phonetic wrote probably warning missing though add manually like assertion error coming probably incorrect lexicon related missing class binding thread reply directly view,positive
try otherwise use base architecture instead large one also use avoid exceeding limit error thanks reply used model train successfully two ti memory hope good training,positive
probably warning missing though add manually like assertion error coming probably incorrect lexicon related missing class binding,negative
try otherwise use base architecture instead large one also use avoid exceeding limit error,negative
actually memory leak problem work thank,neutral
always call whatever specify addition program language model argument come saved model instead console,neutral
hi docker environment warning message language model issue file import module try import import import support python right except python use functionality please install object object default module exception must triggered import unless file comment line warning message disappear use must specify lexicon program call,positive
infer trained succeed model able unable path set give command training please also give command inference,neutral
thanks able use script example found way pas proceed approach path text summary beam parser,positive
able use without issue standard python virtual environment environment python build use branch follow please ignore response like early without reading entire error message,positive
couple pip install automatically kick improve memory utilization master version known memory leak fixed back,positive
pull request employee view employee see taking care,neutral
pull request employee view employee see,neutral
author wrong check found version instead pip version support install latest pip still error,neutral
issue anybody able fix find solution,positive
guideline work use latest practice like extra iteration model,positive
hi error loading model tried load stage looking error conflict one present one defined current model error loading size mismatch param shape shape current model size mismatch param shape shape current model last random layer added model top unsupervised stage mismatch versus dictionary used letter one plus word boundary char right model let try fix,positive
real arise difference garbage collection specifically appropriately due strong big offender every test fail anything file,positive
confirm side effect performance,neutral
work use code model none model model found correct could code work,neutral
sorry taking long reply tried suggestion command work trying another command python raw triangular dropout arch transformer criterion beam reach,negative
ca tell related error like similarly small change somehow doubt failure related currently passing side main branch,negative
course since wo use full limit would likely worse better use,positive
thank novel comment however currently facing new issue image input list format output hub translate function weird one string shown figure note comma german translation work fine running local machine however running docker output weird shown figure repository building pip install bug something wrong,negative
yeah code work without flag,neutral
yes good point next release hopefully soon originally intended variety kept getting bump breaking detailed together ultimately since long ago expect people master,positive
would suggest model instead one already however trying modify code load mode either modify create alternative flag example add strict argument true change path state,positive
local file path directory want load name file full path name path directory additionally want provide type used specific choice,positive
hello trying already base model base model fine tuned however trying different language therefore different final output layer would course different want layer new new letter wish starting already model done also facing error even error loading size mismatch param shape shape current model size mismatch param shape shape current model please help solve two,negative
used tab know ended reopen ticket,neutral
tried task master branch,neutral
spell result nothing task right,positive
please provide argument going forward possible implicit argument open though perhaps split argument removing post removal default,neutral
check seem depend behavior actually intentional example repeat loss scale correct translation,neutral
batch size super small many model,positive
merge one fix well thanks,positive
try master instead anyway likely dependent try bit later see going confirm kind,positive
really want apply happen outside feed resulting text might start raw text training data use apply get back text file feed step generate,negative
yep exactly right text input example linked manually specify dictionary provide one generate,positive
generation via interface anything large use take look note typically monolingual data target side need,positive
tried code python path model beam beam task python valid path model beam beam task model result different,neutral
excuse could favor please,negative
issue line none none else given value since false,negative
hi one argument try dimension seem change anything get error self attention layer size mismatch param shape shape current model size mismatch param shape shape current model size mismatch param shape shape current model size mismatch param shape shape current model size mismatch param shape shape current model size mismatch param shape shape current model size mismatch param shape shape current model size mismatch param shape shape current model size mismatch param shape shape current model size mismatch param shape shape current model size mismatch param shape shape current model size mismatch param shape shape current model size mismatch param shape shape current model size mismatch param shape shape current model size mismatch param shape shape current model,neutral
actually guess someone added relevant maybe try model,positive
manage solve problem tried reset still get error,neutral
hi following import import receive following error module however recognize anyone problem solution also sure relevant file written import import,positive
yes removed since used another use case missing,negative
work fine single problem related reduction posterior probability output data parallel training,positive
case would dictionary use,neutral
input already need encode corpus normal work recommend specific issue,positive
think code really better ping working ca use note like seem available think want close feature entirely,positive
properly solve issue seem issue work,neutral
infer trained succeed model,neutral
use trained file infer audio work modify script use model thanks,positive
method model inference character level model inference,neutral
also got memory error even small batch size error original sure,positive
checked issue solution yet coming back hope find solution make sure let know,positive
would really nice see,positive
plan release engineer maybe someone community could help since many big breaking would nice discrete point right much moving target,positive
custom vocabulary model dictionary fixed want generate new vocabulary model case make format frequency frequency frequency hi thanks response custom vocabulary want identify custom let say name word like dictionary make requirement,positive
custom vocabulary model dictionary fixed want generate new vocabulary model case make format frequency frequency frequency,positive
solution merge produce language modeling format,neutral
hi suggest way add custom vocabulary model thanks advance,positive
hi issue regarding output inference done script would possible get sort character time information find discussion,neutral
hi would also like know,neutral
according way use feel like need specially change data function understand create,positive
hey tried tool brief article hope,neutral
far see problem build python look strongly suggest use provided avoid,positive
docker repository tell wrong,negative
getting following error running python script recent call last file line module import file line module import undefined symbol someone help,neutral
end writing code conversion opposite direction would great could share,positive
yes confirm issue exactly clear underlying cause though,positive
error kept everything issue everything worked must something training going differently every time random making crash maybe timing,negative
encounter warning message work well worry,neutral
different kind model use model backbone add linear import model load,positive
cool thanks command sure thanks,positive
like people issue saw added main author paper know happening,positive
cause probably group normalization probably ex,neutral
installation running python get following python use functionality please install used installation structure encounter warning message,neutral
pretraining code taken need data interested code data task,positive
hi great please share training script pretraining thanks,positive
able pretrain model pretraining done,positive
fixed code install apex properly work able pas speed show improvement epoch would idea,positive
fixed please use note need pip install already,positive
image part training log till,neutral
usually recommend interface translation advanced example task manually,positive
need use interface try something like python en hello world en output,neutral
believe due code random number state upcoming code make manage state fix issue also enable u support model parallel,negative
sorry ca help share command ran system setup please open new issue following provided,negative
looking log trained see job restart load file corrupted clear going try loading manually see work bash python import torch,positive
yes known problem fix shortly,neutral
actually totally fix clarify dependency usage going forward idea gon na land patch already available also eta make torch dependency take effect immediately need,positive
hi thank response use flag use get following error recent call last file line module file line main file line main return file line alignment object iterable,positive
thanks fix idea gon na land patch already available also eta make torch dependency,positive
used commit however work latest version master well lexicon theory current integration would modify code use instead pretraining little better strategy use whole cap number iterate quickly would train least least get meaningful although may enough depending,positive
use think finally end lot code folder instance based tutorial,neutral
help may help formulate plan move forward around time team used python start binding start fine tuning part lexicon case right pair character space train scratch small set get otherwise use whole,positive
set let run overnight thank much help,positive
see sure doesnt work paper work well afraid cant help much would require particular would also try figure training doesnt work specific setup,positive
trained log one set default train linear layer top model lead meaningful rest used entire network practice freezing accurate also set right away may lower bit train way set otherwise every epoch take day train,positive
yes single channel format length sec used original till exact next saved point know point train training meanwhile used one trained original without used code ended without specific error might able find correct failure fine tuning clue wer going,positive
look please find log stopped increasing thank much help,positive
wait make pretraining task easier taking run yet unlikely work maybe try pretraining original hyper also audio single channel right,positive
share entire training log take look quickly also get python dictionary look key,positive
used following still issue small set,negative
stuck range time idea would reach long time increasing till fine tuning data reason batch size le amount data param tried accuracy wer always,positive
yes still doesnt work try printing,neutral
fine tuning small one retry following correct,positive
accuracy reaching suspicious get around best biggest moment unless maybe something wrong pretraining,positive
large model based need similar need set smaller model use batch size bigger need,positive
problem believe problem current branch taking time previously set solution set bit higher model reduce number per epoch train model reasonable time,positive
open different issue since issue different fine tuning,positive
problem wrong environment variable code exactly wrong version used try check moon wrote hi solution tried replace nothing message look like functional torch self module attribute directly view context type type target name view issue description view issue publisher type organization name,negative
type error type converting problem,neutral
set get code work model train training extremely slow epoch iteration like half minute clearly used fully suggest fix,negative
tell number think work,neutral
python guess typo worked well anyways thanks ton awesome work need convert audio mono stereo would yes confirm issue tried converting worked,positive
actually fixed change assert return,positive
python guess typo worked well anyways thanks ton awesome work need convert audio mono stereo would,positive
clearing unneeded dependency cortex recommend take look anyway consider,neutral
hi whether try distilled try train nar model freshly could please make distilled available,positive
trained model language used already trained model base training model language gave boost learning loss stopped decreasing accuracy around trained model scratch problem share lexicon text file used create made sure like also correctly space word ending,negative
python guess typo worked well anyways thanks ton awesome work,positive
wait language model audio surprising work well,positive
sorry sure help trying model already model need reset bunch well importantly maybe also fine tuning model scratch model without lexicon everything put upper case already wer remain possible training language whose ascii far higher causing model case approach shall try still explain failure language model,positive
something wrong lexicon upper cased example,negative
add line print somewhere code see,neutral
facing issue trying model base trying replicate experiment paper wer stay python letter valid wer task arch static static dropout criterion seed let know see something wrong thank help,negative
thanks lot quick resolution case complete process environment still necessary,positive
unfortunately idea experienced fortunately maybe could memory issue model fit failing loading work single file went first obvious anyway sorry ca help,positive
encounter segmentation fault use following command python task path criterion letter lexicon anything wrong,negative
sure one need build folder,positive
facing similar issue getting system support warning switched removing flag training loss nun end epoch average epoch warning root nan found input tensor warning root nan found input tensor warning root nan found input tensor train epoch nan nan nan null begin training epoch begin validation valid subset warning root nan found input tensor warning root nan found input tensor valid epoch nan nan solve issue,negative
thank understand explain specifically,neutral
like lexicon correct model finally use lexicon standard one need convert binary launch lexicon hopefully stated clear one day,positive
removing following error prediction class included source code writing recent call last file line module file line file line return object attribute class prediction lightweight wrapper around model self self return,neutral
try without part model input shape batch signal,neutral
add print forward self included source code get,neutral
shape model may want try extract various transformer last one example found middle correspond like opposed last layer,neutral
kept simple work probably get right trying pas speech language training new model apparently necessary adapt script able code really familiar error case give advice thanks self super model none model model forward self return input weight got input size instead,positive
problem resolved branch model quickly comparable memory version calling whole remove use single model directly combine incremental state getting forward method forward pasting code search object directly call varied general hard sure yet problem people similar try put something together could prod right breaking would need sorted interest someone throw messy branch somewhere feel free reach,positive
dont need manually extract going pas result anyway suppose one dimensional vector audio return,neutral
thanks spotted root thought might case,positive
thanks flagging mechanism need add,positive
try hub interface instead alternatively might try,neutral
hi tried raw option sure experience really would suggest following add dropout training argument right default unless sure many think another post update close training either double double inference experience work bit better also need compound splitting trick generation usually boost close see let know,positive
stack trace version show complete create environment say clean environment,positive
task made following based thread get error posted please give orientation solve much experience python language thanks self super model none model none model model model forward self return input weight got input size instead,positive
great interest would nice could help,positive
definitively meanwhile everything docker two one thanks one thank slightly starting stripped python work docker different size bash latest ago latest ago thank help collaboration keep posted,positive
ah added documentation recently forgot rebuild able chunk multiple train,positive
know wrong add one audio inference,negative
ah glad clearing cache maybe issue original corrupted please reopen,positive
let know succeed issue succeed write issue,neutral
yet definitively something going,neutral
glad found tried model transformer,positive
gosh checked ten time,neutral
thank much getting python use functionality please install python use functionality please install usage error unrecognized within container command used python issue,positive
error running python torch inside lab server might clearing cache folder though,neutral
thanks able access correct link,positive
closed issue fixed issue,neutral
hi issue fixed link work case correct link,positive
tested case docker work prepare data model bash example model file want test forget resample prepare put prepare build script use may cause dynamic loading run pip install upgrade pip pip install pip install run git clone run data copy run pip install python help python help go build docker bash build docker build run docker docker run name go container docker bash run recognize python,neutral
found solution issue getting similar issue epoch showing,neutral
sorry sure help trying model already model need reset bunch well importantly maybe also,positive
define new model base architecture via command line file support coming soon dont built architecture word,negative
get used first split instead,positive
model use work remove part also recommend based looking file model archive,neutral
sorry access machine test hopefully someone community help figure please share solution back,negative
length model since positional two reserved one padding unused work python,neutral
straightforward wrap corresponding done language model implementation great add model also generalize load arbitrary welcome,positive
code generating per target want every source word try following use produce de en source de name use option score en source given de reverse direction something like test de en path let know work,neutral
automatic upgrade path old please let u know work also internal confirm run although please let u know something add,positive
hi also able find link idea correct link,positive
version git clone today,neutral
torch version error could give file line module attribute,neutral
paper stated section apply additional data un corpus news commentary language id file classified en bash en cut en cut corpus removed either source target missing corpus together run corpus,negative
currently also working translation task wan na know prepare process training,negative
ended powerful machine longer ran,positive
oh sorry know issue,negative
sure command used install python pip install pip install pip install update install update upgrade install install install apt install git clone build build make export install additional atlas accelerate install install git clone pip install thanks trying build case get error message build criterion call stack recent call first include see script build python include disable,positive
made one independent without touching,positive
code python import torch import import import import import import import import dictionary import import import parser recognize wave file model target class self super self name super name return build new model instance return self get log net output return else return forward self return class object self else none generate self sample unused generate batch normally separately directly sample return self run normalize return self normalize handling blank filter lambda return list class self super decode self list none else return score range sentence symbol symbol sentence symbol sentence symbol sentence symbol sentence symbol none symbol sentence sentence symbol return sentence assert return return model model return model main sample feature model model generator source source false sample hypo model sample hypo print main,positive
create pull request create directory usage simple command python output love thee freely men strive right love thee purely turn praise,positive
made used folder make code deduce latest please wait little,positive
thanks getting import error module module exist though add somewhere else issue,positive
manifest path dictionary tell look function return,neutral
could please specify inside file path link,neutral
thanks getting import error module module exist though add somewhere else,positive
sure command used install python pip install pip install pip install update install update upgrade install install install apt install git clone build build make export install additional atlas accelerate install install git clone pip install,positive
amazing use latest version,positive
version took code applied hope help improve code send pull request code python import o import math import import torch import import import import import import import dictionary import import import import import import torch import import import import sentence symbol symbol sentence symbol sentence symbol sentence symbol sentence symbol none symbol sentence sentence symbol return sentence class self dropout none none state state else state none assert work best data normalization task model state none state model super model none linear linear else none self set number super forward self source source source mask else return self none none return self maximum input length return none self name return return linear bias bias return false false dropout static false static false class object self else none generate self sample unused generate batch normally separately directly sample return self run normalize return self normalize handling blank filter lambda return list class self super decode self list none else return score range class parser add parser parser self super self name super name return build new model instance return self get log net output return else return forward self return assert return return return state state import model model return model main sample input feature model model generator input source input source false input sample input hypo model sample hypo print main output came conclusion need education much better understanding exclusive learning motivation perspective psychological,positive
success wrapping code put,positive
awesome could share training min extract,positive
found way load substituting name however since different architecture standard transformer method work scenario suggest use modify arch transformer load excuse may ask load model want use trained,negative
use generate new sentence give raw input file instead,negative
similar issue sort dump dug least actually hanging running sample actually eventually single thread eventually working guess something lazy loading entirely sure time substantially ran whole main problem amount memory substantially higher version network need per inference hard use sequence target longer load time big problem though saving model already loaded per instance anyone know way get memory usage beam search stay memory could clear basic transformer,positive
could anyone give train translation task thanks,positive
sample none batch one device fixed,positive
anyone making brief inference would appreciate could leave succeed leave code,neutral
ca wait model part thanks would provide concrete training script toy think idea awesome hope documentation little better thanks added page detailed run task,positive
exactly change could share code,positive
yes default used worked,neutral
might related issue time ago,neutral
difference latest first second mainly,positive
inference script need simple inference pipeline,neutral
model different size likely hidden dimension try setting parameter size,negative
transformer model linear make whole even dynamic quantization high speed make path get speed model run path beam quiet profiler result name self total self total total total time number detach self time total,positive
hi link attached getting error page please provide,neutral
dont use training downstream model model directly task one tested classification havent actually tried extract use unlike previously want feature aggregator let know work better,positive
hi trained fine model trying load extract train downstream task order following import command command like support loading model flag use flag always get following message error loading following able get however training downstream task really bad please know wrong,negative
like pip install one instance way multiple going need manage multiple likely entirely redundant switch better approach build like shell python build develop run like shell python second run pip install major hassle multiple laying around try different everyone willing virtual environment project,positive
like pip install one instance way multiple going need manage multiple likely entirely redundant switch better approach build like bash python build develop run like bash python,positive
test something part pull request,neutral
case somebody still problem training increasing file limit help problem reducing number allocate job,neutral
got bug setting true,positive
fixed issue good luck,positive
data combined train model different news crawl single provided list,negative
agree please open separate issue indicate new release,positive
thanks working though already done someone else via pip install like think people install via pip install update would great,positive
alternatively continually working want git clone pip install code python run whenever git pull folder automatically get latest source need anything else,positive
already fixed master however via pip still old one,positive
use send fixed u thank,positive
trying reproduce except run command bash path beam en de task translation raw tee get python large en dictionary de dictionary loaded loaded test loading model recent call last file line module file line main file line main generator sample file line return sample file line return file line generate return model sample file line return file line step file line step integer division div longer future release div perform true division python use python instead change file get python large en dictionary de dictionary loaded loaded test loading model recent call last file line module file line main file line main generator sample file line return sample file line return file line generate return model sample file line return file line step file line step result type float ca cast desired output type long anyone know resolve issue python torch,positive
contain text use python generate folder,neutral
ca wait model part thanks would provide concrete training script toy think idea awesome hope documentation little better,positive
push glue split master yeah line break issue might need thinking take look also,neutral
join model maybe one could try like make sure copy well might loose normalization otherwise,positive
could check still tag,neutral
used old commit install set,positive
yeah problem use run without error,neutral
new model following tried infer version still getting stuck,positive
besides try error recent call last file line module print file line return path file line missing positional argument,negative
anyone example stitching model together approach work generate text,neutral
idea wondering whether incompatibility issue model would able retrain transformer model couple retry,positive
could open separate issue model training error,neutral
gist please tell use getting stuck python generator model sample generator sample working generator sample working,neutral
yes supposed similar fate resolved problem think mismatch pip version unsupported correct version even though showing properly know tried torch pip tried install torch via resolve environment problem new pip thank anyway,positive
supposed please try one,neutral
please check torch python environment check python import torch,neutral
hi totally agree reference also somewhat doubt real performance model training data successfully reproduce score command cat noted text evaluation fully official result indeed previous confirming effectiveness mean,positive
hi response like couple please ensure latest paper trained page look tutorial used following batch size run validation epoch epoch data randomly training set select best validation set result quite important run training use without decay select model best result validation set pick final number test set hi thanks multilingual model training set transfer table also select best model setup use validation set language,positive
hi question question model sentence level monolingual data choose set vocabulary size related number size training data use tool data use framework model long take ti ti model,negative
export model following code,neutral
exact problem running model resolve setting however another question dynamic shape new issue,positive
hi thanks done original test distillation train,positive
need create epoch set shuffle false reach want beginning epoch new cal however know achieve,negative
output got ran wer stay tried go come never go behaviour infer train execution without error share lexicon file made instructed previous loaded valid criterion loading model,negative
task translation model criterion model trained parameter rank total memory name training per per none loaded epoch loading train data epoch loaded loaded train begin training epoch recent call last file line module file line main file line main file line main train trainer task file line inner return file line train file line inner return file line raise file line file line step closure file line step closure file line step beta grad beta size tensor must match size tensor dimension,negative
hi know export model still ca find solution,neutral
oh batch size big impact,neutral
yes since model say contain format name name name prefix passing generate like ideally best situation use model generation task generate set next generate way somehow could generate worked single utterance source prefix lot time make work hope inference code import torch import import o import time import extract data count print done open source open line sline sline sline source count hypothesis count print hypothesis would need change inside well sample self list list beam verbose bool false input sentence sentence prefix sentence sentence input prefix beam verbose return generate self list prefix list beam verbose bool false sample prefix build generator current well beam generator generator sample verbose print name default return name name default process top sorted zip sample return,positive
find way use generate next set like,neutral
error warning root successfully version warning root successfully version exception recent call last file line index file line file line file line assert recent call last file line module file line main file line use file line spawn file line file line join exception process exit code,positive
read example trained model,neutral
tried use following command arch dropout criterion addition memory also gave error file line module file line main file line main file line main train trainer task file line inner return file line train file line inner return file line file line step closure file line step closure file line step beta beta group many unpack,positive
version today error went away case somebody strange error,negative
like ca load model get train model,neutral
another question reproduce base model paper consider setup fixed size word input standard word either dimension input output valid test train time different paper register new model anyone provide help,negative
need explicitly pas work equal number,neutral
hey unfortunately bit use particular code need update code support,negative
thank step still get error though size tensor must match size tensor dimension ran entire stuff following time edit arch criterion dropout space simple en de seed en de task translation train valid,neutral
hello similar error command virtual environment trying run university access system error command exit status command open compile code develop user complete output running develop warning user directory disabled file support error ca create remove install directory following error trying add remove installation directory permission installation directory via prefix default setting perhaps account write access directory installation directory directory may need sign administrator root account administrative access machine may wish choose different installation directory preferably one listed environment variable information may wish consult documentation please make appropriate system try error command exit status open compile code develop user check full command output environment o python version pip version,positive
report used would misleading model one model likely,neutral
hi sorry dumb question training nat paper distilled training set evaluate distilled test set original test set done distilled test set,negative
try previous even wer gram example see better error,positive
hi used subset extracted train validation set setup fairly common practice back script written right nowadays use validation instead like feel free add option script use valid send pull request thanks,positive
check hope solve issue,neutral
never mind install python pip install pip install pip install update install update upgrade install install install apt install git clone build build make export install additional atlas accelerate install install git clone pip install run install prepare inference python python run python task path criterion letter,positive
provide full command ran,positive
thanks lot resolve except one start training everything following error message task translation model criterion model trained training per per none recent call last file line state model file line return super strict file line error loading missing key handling exception another exception recent call last file line module file line main file line main file line main train file line file line please ensure match exception load model please ensure match possible due data en dictionary en en dictionary en en dictionary en de dictionary de de dictionary de de dictionary de wrote data,positive
please follow issue provide exact error reproducible example,positive
good catch model also maybe incorrect,positive
tried multiple way split way work thanks,positive
implement integrate one instead use guide get model pull welcome also support use instead beam search standard machinery used machine translation use scoring wer get wer instead may play around architecture hyper,positive
hard say without access custom model make sure specify task training generating add extra dictionary would simply set loaded training generation see different used default task consistent training generating model use class output dimension map final output size documentation used handle text think size constant somehow look data loading code think default loading problem size thank checked source code generator task found issue end pinpoint source bug line code produce output dimension second batch really weird trained model everything fine output always way produce custom model somehow output,positive
instead separate source target one dictionary source target,neutral
finally took whole thinking bug get infinite loop since took much time previous run got done sized someone spare time address last query use flag flag,positive
hard say without access custom model make sure specify task training generating add extra dictionary would simply set loaded training generation see different,positive
model simply smaller le,neutral
rebase pas however lot displayed request already smile known issue target branch brought back master branch target one tab everything,positive
biggest problem must initial token token properly output model learned way token put output weird profound effect performance used lid loss one epoch output good loss stayed output weird used language id originally solve problem work project currently working team,positive
right see mean yes therefore far ideal wondering much performance considering also lid token used stop think simple dirty trick define maximum number stop threshold another solution would lid source target remember correctly check allow easily however sure choice general problem,positive
yesterday studied problem day learned must receive output must receive output learned receive source must receive source document receive source must receive source document image however set something like language token see code returned language dictionary extension file must language monolingual file name must extension must made name source must also target must also although made training thought flexible design monolingual fine tuning impossible language set returned problem problem language token like solve problem task share done,negative
sure mean add languaged code token long language included think need worry remember correctly vocabulary language id case would simply,positive
thank issue added print print print model location next print sample location sample print sample location sample print sample location sample print sample location sample print sample location sample print inference function generator sample got following true model location sample location sample location sample location sample location sample location attached parameter,positive
hello encounter issue solve,neutral
think might lint error got somehow fixed want rebase,positive
modify print diagnostics particular verify true make sure inside sample line sample sample else sample fact,positive
question kept null training training log log see printing done validation make training reasonably quick training guess working mandarin much sure much data small amount may work big might want use something like instead decode later also try arch instead tune hyper use bigger,positive
ran issue install machine,neutral
update support still error,neutral
sorry late response sure see python torch like image also see memory allocation made inference process second screen shot attached problem image pretraining perfect ca inference could let know information provide tackle problem thanks,positive
thank clarification turned without parameter already output,neutral
run train code case language id work like training add languaged code token,neutral
thanks see problem truncate ensure example token block create size entry long leave exactly leave token onto sequence cause extended get want ensure get modify task truncate sure much benefit actually give feel free give go hope,positive
hi read work model low resource news multilingual near future thanks,positive
close one thing script script reproduce script want make following change cut cut system reference hope,neutral
thank pas none second element optional output problem,neutral
looking type annotation correspond first batch entire output tensor second optional element extra model specific example transformer model attention inner addition hope,positive
thanks quick response really content could get file manifest able know content file also trying get text raw audio file could help sample command file,positive
probably composed think problem,neutral
yes tried default face warning bit worried model would le performant warning think capture,neutral
try default instead model manually providing full path warning problem think bias head random problem going data,negative
question kept null training training log,neutral
help following trained model like extract model apply use back previously trained model please tell achieve hi also want extract model extracted successfully could please share script whit,positive
reproduce example simply add shorten reduce setting total number training learning rate many peak learning rate adjust sequence length number per batch batch size increase batch size task criterion arch complete dropout simple truncate output task model criterion model trained parameter rank total memory name rank total memory name rank total memory name rank total memory name training per none per found loading train data epoch loaded loaded warning invalid size first sample warning invalid size first sample warning invalid size first sample warning invalid size first sample,negative
use truncate shorten warning invalid size first sample without shorten warning invalid size first sample task set test,positive
take one decode see model also ca predict also hack criterion print validation also share entire training log take look real quick,positive
thanks try get back work let u keep issue open,positive
try splitting input file call time specify data see data argument,neutral
please provide reproducible example full command ran,positive
unable reproduce ran following code python import torch import import import o model post reproducible example throw exception match properly,negative
like still please open new issue thanks,positive
course tried process tried multiple time reopen issue people help,neutral
try get memory error far know think need read entire file,positive
language token added end sequence fly need anything special specify used via flag hope,positive
reason run pull request,neutral
also fixed couple error,positive
model way python furthermore inspect used printing printing model architecture used hope,neutral
method truncate properly adjust size property avoid filtering provide log example seeing,neutral
provide gist full get please run environment variable,positive
need use option running,neutral
please include full command ran,positive
nice catch definitely agree fix feel free submit thanks,positive
memory quite small try smaller model architecture like instead also make sure verify still wo fit try trim model size reducing number,positive
hi try use model order fine tune data facing issue folder following line error telling missing went git found file found following link got model find file went link found convert file missing available done could launch previous code faced warning model newly probably train model task able use please thanks advance,positive
mind one question find besides derived paper use example paper length penalty could find final search used currently use penalty behind final score custom would extremely useful u edit section paper think dynamically calculate length penalty generation run time depending assemble basically accessible u implement model assembly get correctly time around way could improve score provided model thank,positive
full script update release git clone git clone git clone git fast get model curl output tar export export get evaluation data pair echo pair echo ref normalize data cat en en cat temporary waiting fixed include right otherwise use apply specific one export export generate model ensemble path beam en task translation raw tee cat sort cut pair output version revision language en ratio,positive
fantastic thank much explicit extra getting said slightly currently model pair one set need work hope complete update much trouble may consider removing state model make end user much faster much trouble good,positive
line number piece ie line used id reckon model indeed used splitting two model written new class one piece id instead model directly work probably loading try instead one like,positive
hi sorry notice message first time several missing command data need cat en en cat need apply case used also file correct temporary put correct fix week git clone git apply run generate way path beam en task translation raw tee finally evaluation need cat sort cut pair give everything except score still little short one matrix cumbersome run release working better approach,negative
would possible give u hand please final transformer since latter currently support model ensemble trying get best single model able reproduce score would helpful u thank need command line used get thank,positive
issue standard first script multilingual translation example used command file simply trained able load model encode text unable use method base converted successfully sorry solution thought add command used,negative
worth fix change sure though,positive
hello use language model could tell method relative code,neutral
hi ca find information plan release,neutral
got error notebook notebook,neutral
pretraining section image second audio get hope,neutral
cant reproduce ran see image sure see,positive
yeah probably get fully added,neutral
good point add dictionary use dictionary missing difference output,positive
sense clear reduced dimensionality,positive
raw sample rate sample rate lose bit valid padding opposed add,negative
thanks catch must bug code dev branch fix,positive
due stochastic nature often difference output actual output find train model probably little longer time result would different reproduce exact involve case would advised either experiment contact paper,negative
thanks ton put flag step since give warning error thought must used argument path appreciate help,positive
apparently error also resolved problem may causing work since please understand large take lot power multiple start become prohibitive support highly critical run code may help somehow warning root waiting start version warning root waiting start version warning root waiting start version warning root successfully version warning root successfully version exception recent call last file line file line file line assert recent call last file line module file line main file line use file line spawn file line file line join exception process exit code edit tried code removing flag since understand behind sure whether would helpful still subsequent error input dictionary output dictionary loaded loaded valid recent call last file line module file line main file line main file line main model file line model super file line model self file line return task file line raise dictionary dictionary,positive
making longer code path problem unfortunately provide recent master branch thought might bug either check,negative
currently inference one pas run generate interactive multiple wo automatically run multiple,neutral
error message latest version,positive
question difficult answer would train model make sure exploring,neutral
need run looking model trying validate find generate like train,neutral
thanks suggestion model scratch without argument perplexity quite normal still get sudden hike perplexity first place,positive
pretraining log maybe sorry,negative
hi let know loss accuracy value got starting fine tuning would really help,positive
memory course run could definitely better memory even current batch size clear io image memory graph imply maybe probably image,positive
need adjust training script,neutral
model unsupervised running keep ran model running finally got similarity little le result model training got proportionally used module,negative
would make sense add new directory could also clarify usage implementation good idea added documentation example also pull request tag assume fixed git commit amend author like may rerun bot,positive
oh wow pretty cool love hear training scratch work please keep u posted,positive
good point reason training scratch want know training model scratch model yield result change also training model top model parallel stagnation quite sure completely different language learn correct latent audio representation say running experiment learning starting model give complete solution give boost still need train audio set till point start,positive
start model assume vector audio similar enough across use downstream task least think supposed work,negative
goo model starting entirely scratch,neutral
use audio crop small model big model example smaller crop length example batch use version segmented since contain entire book,negative
similar question use train downstream task specifically raw audio want convert want use downstream task would accomplish,negative
would make sense add new directory could also clarify usage implementation,positive
getting error path recent call last file line module file line main file line main generator sample file line return sample file line return file line generate return model sample file line return file line step file line step integer division div longer future release div perform true division python use python instead,positive
mean input would share,negative
pointing yes would continue automatically,neutral
thanks lot help worked well got without much le overall code note together gave better least hello use,positive
help lot thank still wonder share thanks lot,positive
hello thanks comment used training code without change use argument training resume automatically need specify,positive
thank work added able run git clone python pip install echo import o echo,positive
mon wrote paper thread reply directly view weekly,positive
thank explanation able figure reading code appendix training schedule would suggest providing explanation relevant command line example reference appendix guide size,positive
thats right specify matrix input input output specify matrix input output help,positive
there table appendix paper various general would adjust adjust decay use respectively need update prob would number table use example example see mask prob set channel mask prob set set change adjust example following procedure think would valuable add every split even though make much longer,positive
right totally forgot context still like good opportunity manage issue automatically since generation really usually care overall speed could somehow catch shrink batch accordingly shifting cut data onto next flag like,positive
say training exactly general need reset run command originally make sure latest saved,positive
theory property model smaller value work bigger value would probably positional would seen training probably good ca override command line easily,positive
use instead give dynamic per batch shorter together bigger longer also reverse order batch reversing order function something like return order go first presumably right away,positive
point working pip install typo error logging older version somewhere path,positive
loss matrix word million really slow impossible meaningfully train matrix like also mostly useless near zero basically lot sense small letter token small model sense large word large,negative
thank work pip able execute code pip install code test new approach run python instead git clone pip install python still working solution,positive
might helpful always tricky performance reduce dramatically kind dynamic dummy task random token source token target get principle comparable python task arch dropout simple python task arch dropout simple real translation data input size variable aggressively bucket avoid many real data bit python task translation arch dropout simple peak stop python task translation arch dropout simple take look might improve since seem like dramatic slowdown think mostly problem padding inefficiency since batch bucket length size dominated probably speed throwing data,positive
checked installation pip work could please previously,negative
think problem tried install pip another error recent call last file line module import module think something wrong setting path,negative
hi way evaluate generation different meteor,neutral
ran similar problem untill yesterday everything running fine moreover update guess problem tried pip source,positive
tried get super hacky basically need go take attention forward function,positive
actually evaluation instead bash path like working,neutral
use python python latter approach bit reliable killing since propagate general spot zombie usually kill kill kill kill work,negative
need transformer page specify specific link getting confused many language model issue fixed tried step getting error dictionary recent call last file line module file line main file line main generator file line return file line score file line score outstate object attribute,positive
even pretraining seeing transcript file audio like available audio transcript possible train model audio whose transcript file present,positive
model trying model probably want model instead want continue training model already use dont forget set various well,neutral
thanks interesting try data scratch find training unstable loss often need decrease learning rate explode find become large check weight find range indeed,positive
yes machine ram node,neutral
like either didnt work well dictionary input audio different format trained language model issue fixed,positive
experience ca help error get try export,neutral
install pip install might improve memory situation also big much ram many ram,positive
interesting clip pretraining model trained exact way,positive
also would love advice make either command faster might train soon lot,positive
zone guess shocking better command removed added command bash dropout,negative
think case stopping save begin save trainer,neutral
update use specify different learning rate min start learning rate like warming number dont want training stop immediately,neutral
hi please look issue really stuck sorry trying run model constantly facing always,negative
thanks insight try one thing need ask possible train unsupervised model model like audio without suggest use model train scratch data,positive
finally figured silly mistake value training training whereas example issue,negative
help question thanks much,positive
use build manifest audio data create parallel file see example format particular need word ending token use end every word symbol space modify example command suitable use example command file modify used paper,positive
optimization proceeds lot model architecture task trying solve batch size many looking graph loss working well possible model already learned good test trying use something like otherwise try train higher learning rate use train train longer,positive
also curious model possible load,negative
hello want extend bidirectional translation two follow based multilingual example fix target side case one target language possible way enable,neutral
python import import import lambda label label open fin index line enumerate fin sent target sent prediction prediction target target target target print accuracy float print,neutral
thanks chose proceed dictionary page file error coming file line object attribute dont use language model use tried output getting absurd ca understand file name file cat pad cat pad cat cat mary kind understanding happening,positive
hi still issue manually removing extra seem like happening though supposed hidden saved,negative
strange still get error close one open another issue,negative
force also document silence warning although honest ought first alert anyway,positive
need transformer page dont forget dictionary use use need specify model official model use link need read dont use language model use,neutral
tried way tried python task path valid criterion letter getting error file line open file directory file model looking model python task path valid criterion letter getting error line incompatible constructor following argument path something thank,neutral
work perfectly thanks much,positive
tried environment like permission,neutral
cant actually anything interesting know model except use there sample command showing,positive
score kind inference general combination emission log prob particular weighted language model score theory could use relative confidence measure probability tried score,positive
think must since different error another issue right,positive
sample number individual common practice input single forward backward pas inside sample see dictionary likely first dimension usually batch dimension model single entity,negative
model another yes certainly create new dictionary used also create hand like one symbol per line doesnt also work sentence prefer something like python bin column count symbol actually used put number youd like,positive
like error maybe open issue everything work use,neutral
want use transformer need set type,neutral
tracked issue default causing issue included patch happy submit someone else take like git index faff class self return ordered list index based order return self return self property self git index class return ordered list index based order index self index self else index self index self none sort target length source length none,positive
ton help one last starting training phase link plenty model advise try first want like architecture particularly good finding model basically one text,positive
running like stray default somewhere code causing issue,neutral
basically error training reducing solve issue,neutral
anyone explain command solve problem facing problem stable release explain bit problem fix many,positive
thanks quick response really,positive
command actually use need specify right added parameter trained without parameter code model one kept locally separately sure work training time like printed model removed think removed since final model smaller full model parameter training seem correct right way prune full model finally try seem work error,positive
yeah would vert useful,positive
got even anyone solve,neutral
yes fine put arbitrary,positive
error bug recently push fix meanwhile copy code commit change signature generate generate self sample unused,neutral
disk space machine also resolved problem,neutral
thanks lot quick response seeing used training example also suffix presumably used recognize input file target one since custom problem involve change language alright put arbitrary language name suffix file since translation pose output file language training specify random suffix target language something like would still acceptable language type,negative
hi python task path criterion letter getting error recent call last file line module file line main file line main generator sample file line return sample generate got unexpected argument also tried faced similar issue top model,positive
error reason test file empty,negative
wondering provide u training comment gist good would good process,positive
command actually use need specify separately sure work training time like printed model removed finally try,positive
please take look paper sense long take train corresponding reproduce paper look data format see need kind must done step support experimental done much yet welcome try fast,positive
meaningless way work actually real computation building graph slow infrequent factor getting per second slow batch size try setting recommend ever setting environment variable make loss essentially meaningless flag mixed precision much better like hit bug look,negative
thanks response python already see pip install user installation normal writeable file collected running develop successfully exact issue running code code giving,positive
trying help issue running unblocked might use though make make install set export export pip install,neutral
perfect hope finished soon put schedule ready soon side,positive
believe added older version currently,positive
need rework way handle state since right converge poorly open new better shape,positive
branch something wrong way state since converge poorly similar dig discrepancy next couple,negative
please possible solution hook proper solution stuck progress model,neutral
file work long audio readable library thanks response getting saying command python task path criterion letter seeing column add raw audio text want model create text audio,negative
file work long audio readable library,negative
progress know get exact closer get object attribute without export without slow slow maybe normal many compilation epoch compilation epoch compilation step epoch best give way use faster training hardware optimization get wall closer,positive
one advantage grad norm use clipping already overflow check cheaply pointed produce false assuming overflow relatively rare first check grad norm overflow see overflow check norm,positive
thanks run default without reason ram also used case assumption directly load device set,positive
similar issue loss decreasing stuck around without quantization noise le epoch please share would like use quantization version version command used train arch transformer task translation thanks,positive
fixed still recommend use since latter really intended generative may produce correct,positive
bit late party easily missing method task translation task hacked source code without,negative
thanks response try may help command add raw audio file without model create transcript manifest command model,negative
hi meet problem train transformer model within mode,neutral
work script able modify original one build new model extract relatively easily need change model built also model want call,positive
lexicon link soon regarding language used provided team think trained time ago since still work master branch double check,neutral
hi meet problem train transformer model within mode finally solve problem,neutral
problem still locally git reset hard head git clean git pull result output remote done remote counting done remote done remote total delta delta done local master forced update new branch new branch create mode create mode create mode create mode create mode create mode create mode create mode reinstall pip install command de en train model latest version ask input add parameter recent call last file line module file line main file line main file line main trainer file line file line file line file line raise final dropout arch error recent call last file line module file line main file line main file line main trainer file line file line return file line file line return file line return file line buffer mismatch got addition try command anaconda console terminal tried latest stable version everything satisfied frist trained result oh maybe time drop,positive
thank see author author training language model help either specify large thus may easier configure thread reply directly view,positive
hi actually trying use model use listen audio give transcript output suggest proceed thanks advance hi think simply run command get raw number without language model complete command task path criterion letter please make sure python binding need prepare following take subset example,positive
use master something like bash task translation use le efficient order minimize number unique thereby avoid,positive
worked python apt install,positive
thanks quick reply really waiting need schedule train project,positive
working model parallel support almost ready,positive
loss number case may still want loss log extra key,neutral
thanks lot reference try thanks help,positive
fixed please reopen still issue,positive
logic used default bring good point large consider different solution norm reasonable solution,positive
hi actually trying use model use listen audio give transcript output suggest proceed thanks advance,positive
ah sorry error thanks,negative
either specify large thus may easier configure,positive
would helpful could suggest certain scaling used vary function batch size unfortunately precise since model said nice paper scaling find appendix page learning rate make little difference total summed learning rate training keeping fixed perhaps aggressive may get better performance keeping fixed longer period example tried specifically,positive
think still need call since need know device use,neutral
raise unable infer criterion error manually modify line master branch fix attribute error order make work bug current tool argument way pas command line,negative
thank much suggestion yes try distributed training,positive
oh also commit master problem still,neutral
yes tried run problem probably appear also tried run o work perfectly,positive
thanks reply use peak used compare approach plus since batch size around reducing hamper performance approach would helpful could suggest certain scaling used vary function batch size agree threshold loss scale argument may cause training cease though worth shot thanks suggestion,positive
thanks made following locally add param python python task python line ensemble task strict suffix line state python line path backward compatibility path loading model state storage else loading model state see two strange although model also ram case running alone see pic image ram consumption running image run still run image command model image look like missing something thanks,positive
task arch dropout none official script parameter according script wo stop automatically,neutral
expand positional dynamically based input shape guess set size raise exception input yep work sorry prior,negative
also export extremely limited export beam search quite hard may possible via tracing beam search manual construction graph via easy,positive
mixed incremental state also problem dictionary picked either tracing positional may worth supporting explicit constructor avoid forward time think default user pas argument user control positional think,positive
able reproduce confirm still issue latest version also think need set explicitly set automatically,positive
yep definitely plan move direction related incremental state right expand positional dynamically based input shape guess set size raise exception input,positive
yeah sorry rename respectively use letter update script get chance,negative
file split like describe generally like splitting generation output rest log file though inevitably someday end output file idea model data run stuff get summary output simple bash script could accomplish want could useful directory something like untested bash shift sort output match original welcome,positive
model incremental state friendly explicitly always return state,positive
loss scale going getting lot large overflow range happening many row training one option set something loss scale stay worst case could mean training indefinitely constantly throwing away overflow never model stay constant course solution lower learning rate something le aggressive might try see stable,negative
standard interconnect quite slow due transfer similar speed node thereafter get example faster might want try interface much faster back similar translation,negative
unfortunately somewhat load could potentially modify function support loading another device happy merge pull request optional flag,positive
determine loading model attribute python import torch model model parameter main change,positive
work script meant language want measure masked language modeling perplexity use,neutral
correct training still word piece mask multiple word necessary mask whole word example suppose sentence testing whole split word mask whole train replace mask ing together get mask mask whole,positive
ah think know issue though submit fix shortly,neutral
support support bit flaky also,neutral
happen get language pair work fine model see discrepancy guessing general say note two model one direction en e e en source target command,positive
one thing file manifest file file able model although know correct,positive
also want solve question,neutral
hi able get text yes please give sample code command thanks,positive
think parameter mention else model keep running,neutral
problem work well short please help,neutral
hi wonder would mind inference code achieve accuracy accuracy code import import lambda label label open fin index line enumerate fin sent target sent prediction prediction target target print print print accuracy float,neutral
solve problem issue thanks,positive
object attribute saved language modeling task latest version pas error unrecognized latest doc,positive
grade torch worked work,neutral
hello issue simply increase problem used,neutral
want model custom audio data fine given implement ca proceed need model recognition,positive
added example use constrained listed think set,neutral
plan support rest uniform near future,positive
support sampling method temperature sampling moment,neutral
case use anyone trained model based following scaling reversing translation direction model particularly great score test set sufficiently case anyone use available,positive
hi could share code test model unseen language pair tried modify code getting error generate function dear sorry delay specific version method worked copied something like model assert model model please note quick dirt code hello thanks code snippet tried zero shot inference version however score even original original method used,positive
resolved model attribute thus simply see,neutral
hi would release thank much,positive
thank much response link,positive
ah probably old version please update pip install upgrade merge backward compatible fix soon,positive
loading dictionary necessary directory actually contain training data,neutral
add variable false base class currently check done generate since defined batch,negative
would great something like world size parameter could set automatically set appropriately automatically output remove look versed could take,positive
replace function another one work refer self step beam batch sentence generate list previous range range zip range next token prevent already step step return step yet range return still know correct error occur range anyone idea please tell,negative
awesome thanks python script version python task path subset criterion letter,positive
anyone code give audio sample text example provided back vector one follow example model get text output,neutral
anyone code give audio sample text example provided back vector,neutral
sorry option probably meet need however one thing completely sure looking example want alter model attribute inference clear know pas sure work loaded see use bad hope comprehensive example,negative
sorry option probably meet need however one thing completely sure looking example want alter model attribute inference clear know pas sure work loaded,positive
interesting actually seem make difference since agree intuitive also update file talking tutorial,positive
flexible simply pas list one separate epoch first epoch loop second epoch third epoch fourth epoch,positive
hypothesis system output first number average log probability output hypothesis provided log probability token hypothesis,positive
yes generally dictionary order therefore matrix order correspond token frequency training set,positive
evaluation time first training job resumption evaluation loaded live yes exactly bit context commit function,positive
line syntax python likely need upgrade python installation,neutral
already allow new added via kind,positive
based original code linear decay via polynomial schedule,positive
use manually rename model file used script work well,neutral
large trace suggesting issue memory result python likely bogus since error resulting deep within native code,positive
like issue driver code handling left true thus overrunning dimension looking handled like something like seen close think user error,positive
like inconsistency around error depending input trying like issue dimension confirmed handled fine,positive
joining without space like image give anything correct image command used python task path e en en e input reason splitting hypothesis correctly thanks observer similar output language,positive
addition current attribute function,neutral
update hi side unfortunately,negative
additionally get python tried passing parameter help version work fine image thanks,positive
getting error running training instance getting error unless removing option training data single instance raise exception,negative
joining without space like image give anything correct image command used python task path e en en e input reason splitting hypothesis correctly thanks,positive
another option could although instance model class specific handler process input,neutral
even facing issue via poetry bash git poetry add lock file warning lock file date latest may getting outdated run update update match every version match dag version tried set commit bash git poetry add writing lock file package install update removal removing decorator able successfully anyone temporary work around,positive
hi module accuracy wise issue still module large getting issue share,positive
anyone confirm contiguous single space hacky code successfully generating seem understand line little disappointing since lot way perhaps code used training would seem easy solution still appreciate making biggest public model release,positive
find issue fix broken,negative
used pip release revisit master version thank,neutral
although size file reduce lot memory usage training significantly smaller able model memory model unaltered would probably need memory maybe reduce batch size use mixed precision training used would assume would run similar call would interpret source sentence target sentence reference best hypothesis score beam search removed hypothesis score beam search used token hypothesis score end output look line like generate test,positive
probably regenerate dictionary get exact number otherwise model wo trained want reuse dictionary easily convert format main format token frequency space whereas token tab frequency column filtering simply create new dictionary dummy count something also need remove dictionary cut tail also commit shortly option output generation hi another question order dictionary matrix done basis frequency well extract matrix first special rest correspond dictionary already sorted frequency order,positive
thanks able understand result file file could please help understanding got like something related translation dont know two could please help understanding da ist small thing little little,positive
solve end also problem,neutral
amazing actually also taken initial still sure percentage need use different pretext let,positive
thank interest along description key new repeated temperature based sampling unbalancing different translation automatically add source target language data prepared way training none specify whether add source target language source binary option specify whether add target language target multilingual translation specify path load model use transformer consume batch data structure translation task however drawback currently across however difficulty modify support different per direction,positive
think post stack overflow solution need add loading,neutral
export folder run see line saying built thanks hey add export line added still getting error,positive
need also specify task,neutral
clone latest source master pip release support available master currently,positive
agree current approach bit cumbersome added order get test pas one counterargument constrained also transformer reason could made work multilingual could add might equally messy follow suggestion course already applicable one task thats fine keep maybe add error throwing somewhere else example add property base task class false overwrite single check property throw set task support,negative
oh see sense added throwing end make test pas right sense call instead statement lot,positive
issue base search class sense something considered originally went way thought would easier merge afterwards split argument add quite bit complication get way seeing nice simplicity current search implementation,positive
instead bunch throw set add argument translation task one moment agree current approach bit cumbersome added order get test pas one counterargument constrained also transformer reason could made work multilingual could add might equally messy follow suggestion course instead code class sprinkling around general solution introduce class like call certain noop default various hook constraint stuff would also make sense implement noop base class issue see general nature pretty specific might end kind fake generality,negative
thanks kind help support able execute command used run interactive command path task test command path beam error received error loading size mismatch param shape shape current model size mismatch param shape shape current model size mismatch param shape shape current model kindly let know something wrong,positive
ah thanks fix issue think rather validation skip check intended safety check anybody trainer really need check,positive
access machine test sure unit show failure think something related installation please feel free try let u know go,positive
yes training mixed precision notice ignore long see scale get small scale probably fine,positive
model run without line size mismatch param shape shape current model shape size model shape current model size model based command like model got one parameter instead missing dont think need add mask token dictionary manually coz loading translation task language mask token added dictionary,negative
thanks help path task test error received dictionary dictionary loaded loaded test loading model extra language found model continued pretraining new set recent call last file line module file line main file line main return file line file line task strict suffix file line state model file line return super strict file line error loading unexpected key size mismatch param shape shape current model gone added language code code still one parameter missing seen code mask echo code done give work know wrong,positive
problem would great one,positive
thanks reply said vocabulary used script get model still size new model reduce much size actual model around new model around way reducing model size much size min size could get ever finally kind help guidance able small de en test run also working run still working command used run path beam could please share command executed ran epoch check work time translation poor present file ascending order respect number per sentence th sentence test file taken first sentence understand source target sure three could please explain significance associated one actually telling wir sind,positive
reducing size model wo affect size model size vocabulary size model original vocabulary vocabulary u remove unused word model greatly reduce amount memory training delete delimit need parameter causing size mismatch guessing path parameter incorrectly pointing training run model specify directory save training parameter save information long took train single expect several training use calculate score compute score specify parameter call use shell path task test,positive
module attribute module attribute solve problem used torch,neutral
good see new multilingual translation task like dont need use multilingual transformer run task experience multilingual transformer much much single transformer even explain difference original multilingual translation task new task,positive
instead version red hat copyright free foundation free see source warranty even fitness particular purpose version copyright free foundation free see source warranty even fitness particular purpose pip install file requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied torch requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied collected running develop successfully install win fix problem,positive
model without pruning always use said code given model language keep language specify command trying generate translation model author said model model copy never learned translation insist run translation model may refer script add missing state model,negative
ca confirm everything trying correct think together procedure possibly new happy proved also appreciate fair endorsed guidance data mostly come made training let know helpful,positive
thanks reply hey got since huge size please explain aware pruning model model size model could reduced see sentence corpus like try bring attention two delete extra corpus stated whether correct way delete used generate text sure correct one received error except gave error whether command additional information addition command see understanding path task test en de error received recent call last file line module file line main file line main return file line file line task strict suffix file line state model file line return super strict file line error loading unexpected key path task test en de error received got path task test en de error stated time additional information got execution error loading unexpected key size mismatch param shape shape current model size mismatch param shape shape current model size mismatch param shape shape current model help understanding issue rectify one amongst used generate translate test set error run check code work found working fine interrupted model training middle think might stopping execution middle make sense understanding size current model throughout model training kindly clarify wrong many model ran many training validation set need know access one want estimate model training time well calculate score get idea thank,positive
found way load substituting name however since different architecture standard transformer method work scenario suggest use modify arch transformer load,neutral
everything correct definitely want use model used model data dictionary file good regarding model size correct around size got similar vocabulary size call fine number worker perform make sure use path output call parameter use old distributed data parallel implementation sure used training think implementation certain may case,positive
hi new machine translation need help understand process model machine translation task make sure whether understanding correct order goal create corpus de en let say update sentence corpus version done help say corpus name example sentence corpus saw girl telescope corpus look like telescope please clarify correct kept particular directory say file python script need provide parameter corpus corpus data take care step attached please look fine file go pruning model python script generate lighter version model language pair till step model got dont know something wrong command de en could let know use parameter access train model command arch task criterion dropout seed simple pretrain please explain work parameter well generate translation command path task test model one come model right thanks advance helping kindly correct wrong somewhere thanks patience,positive
image another problem joy,positive
temporary solution found clone pip install restart kernel server copy git replace cache directory look like though solution work existence problem obvious think problem come version hope found problem test tried pip install error another error module previous code image image image restart kernel gone image another test however solution still ca help solve previous similar problem server situation server use normally python however run python bash line fail test environment run python enhanced interactive python type help python torch version starting load german translation model cache found error missing run pip install recent call last file line module file line load file line module file frozen line file frozen line file line module import file line module import file line module module file line return name level package level file line module import file line module import file line module import scoring file line module module file line return name level package level file line module raise file line module import import name however run line without problem directly import import torch cache found cache found server install pip install master branch notice separatedly copy git replace cache problem gone thanks problem,negative
hi running issue would able share attention,positive
temporary solution found clone pip install restart kernel server copy git replace cache directory look like though solution work existence problem obvious think problem come version hope found problem test tried pip install error another error module previous code image image image restart kernel gone image another test however solution still ca help solve previous similar problem server situation server use normally python however run python bash line fail test environment run python enhanced interactive python type help python torch version starting load german translation model cache found error missing run pip install recent call last file line module file line load file line module file frozen line file frozen line file line module import file line module import file line module module file line return name level package level file line module import file line module import file line module import scoring file line module module file line return name level package level file line module raise file line module import import name however run line without problem directly import import torch cache found cache found server install pip install master branch notice separatedly copy git replace cache problem gone,negative
tried running pip install like error message run pip install successfully still get error,positive
tried running pip install like error message,neutral
thanks look point also welcome,positive
might bug really use aggregator thanks flagging fix point also welcome,positive
run data setting memory getting memory error able run,positive
problem warning ran memory exception memory tried allocate mib gib total capacity gib already mib free gib reserved total,positive
marking draft straighten test giving trouble part due fact get different running locally,negative
hi met problem please help,neutral
thank much kind feedback,positive
unfortunately weird since recently look find solution thanks also telling post come across anything new,negative
hi problem compatible instead use replace line hope help,neutral
pad input output output exactly input keep padding output pretraining time longer,positive
got problem handle issue work fine another clue work fine multiply ti,positive
new multilingual task following training language trained set data path file list new arch transformer task temperature criterion dropout seed simple generate bash multilingual model language target language path evaluation cat path model task test cat cat,positive
export folder run see line saying built hi got problem trying set install install wondering could suggest find path setting thanks,positive
need run pip install install executable even running successfully found,positive
also looking forward try ca wait see whether approach useful also music information retrieval,positive
excuse know approach used model ensemble average vote way specify ensemble thanks,neutral
tested installation everything worked good close,positive
case found limit hack change somewhere else,neutral
return file code include include getting error declared scope min thread full stack trace tired search issue able get could please assist python build running build running running building extension file included error declared scope min thread note defined header thread forget include thread include include thread include vector function char char unsigned warning format argument type unsigned argument type aka long unsigned read unique text total long unsigned aka long long unsigned warning format argument type unsigned argument type char unsigned aka read unique text total long unsigned char unsigned aka unsigned function char char char char error declared scope mean warning format argument type unsigned argument type aka could truncate output file size long unsigned aka unsigned warning format argument type unsigned argument type long unsigned text long unsigned long long unsigned function char char unsigned warning format argument type unsigned argument type aka long unsigned read unique vocabulary total long unsigned aka long long unsigned warning format argument type unsigned argument type char unsigned aka read unique vocabulary total long unsigned char unsigned aka unsigned function char char char unsigned char char char warning format argument type unsigned argument type char char unsigned aka read long unsigned char char unsigned aka unsigned function char char char char error size array integral string string error declared scope vector thread note defined header thread forget include thread error template argument invalid vector thread error template argument invalid error request member type error invalid aka unsigned array subscript error command exit status,positive
resolved side wrong sha,negative
think able use train parameter added end command provided documentation true set value like total number training learning rate many peak learning rate adjust sequence length positional usually number per batch batch size increase batch size task criterion arch complete dropout simple true,positive
still want model metric way without altogether wondering install depend,neutral
problem launch per node want additionally launch infer automatically though require user specify flag submit fix,neutral
two corpus finally got,neutral
anyone link data tried rerun new machine got file line assert sentence index size limit,positive
lot full command bash export arch dropout task translation criterion tee,positive
thanks could share final command second row recent long took train data know score model row trained scratch,positive
metric epoch best bash valid epoch loss train epoch loss wall valid epoch loss train epoch loss wall valid epoch loss train epoch loss wall update trained get much better trying add,positive
hello tried total able reach score still lower say could replicate result find anything please let know thanks,positive
awesome work ca wait try,positive
thanks answer want use language model generate text batch evaluate,positive
bug bug language model example reproduce follow use generate command task path sampling beam temperature recent call last file line module file line main file line main return file line file line file line exception size sample invalid since skip example add command recent call last file line module file line main file line main return file line division zero use generate language model sentence code sample behavior generate environment version master master version o pip source pip build command used source python version version configuration ti relevant information additional context facing issue abstractive summarization model please help,positive
hi thank reply switched module working data size limit need consider raw text data format task older version replicate approach given research paper number actually upgrade version whether new version providing accuracy link issue thanks,positive
one even longer available providing description manually would also great,positive
ah shoot included unclear also causing,neutral
never mind realize supposed use,neutral
hello maintainer sorry trouble package like installation recent upgrade broke package fix yet work unless user already prep ready probably fine comment relevant time,positive
thanks already really helpful could provide little bit applied,positive
trying work problem somehow related dependency specifically since installation pip install work fault part script running command trying see since tell u file missing since pip temp run install script flag pip install verbose run part build import compile code install record compile whatever breaking line python error next line line output python clue go sure supposed supposed since exist command line also library specifically interest support,positive
hi mind replicate quantization could evaluate difference best,positive
despite installation successful ticket thank,positive
according link page around corpus aware distributed nice bit bigger also like,positive
corpus oh bad good know already saw original version available though least refer original paper would great thank much,positive
recommend following first translation easier replace data data train new system,positive
sorry access machine reproduce able figure please share people may run issue,neutral
ah right architecture added later latest version fix,positive
incremental support accumulate multiple update mean,negative
yes legacy data format original version used indexing flag work version indexing,positive
training language model primarily translation want evaluate perplexity need use,positive
maybe raw text data format format scalable really suitable small recommend data also old version please try latest version master,positive
option specific may may equal global option number training,neutral
unfortunately almost impossible reproduce exact used corpus likely different try get dump share back,negative
general specifically please see,positive
griff luck getting work,neutral
met problem answer problem history apply solve,neutral
thanks suggestion try update,positive
trying new soon update resolve issue,positive
sure try appreciate give example stitch model one,positive
able avoid bug case anyone future,positive
hi completely sure relevant basically token target sequence one first token always normal translation task,positive
hello thank reply yes indeed first step give performance around score however second step quantization could reach around score significantly lower besides accuracy able get compression ratio around smaller replication loosely command provided actually provide since current file runnable modify basically revise correct number product quantization default linear key value key value block size product quantization suggest linear key value key value quantize sequentially suggest first quantization run one tried tune also try first step model would still reach similar performance around score let know pretty see compression ratio best,positive
anything like use encode data calling need get vocabulary probably something like load dictionary class use encode sentence convert array space string call string get,neutral
hello guess hypothesis according line length thus original line number order want know option generate hypothesis original line sequence output sequence,positive
would great way specify output file command line currently facing console printing necessary,positive
think never got around fixing generate script look yet reasonable size model stitch model part back single model maybe give try,positive
point en reverse course beat en time time,neutral
raw match well task issue delta average whole whereas take last step,negative
awesome great job yes definitely appreciate feel free create one assign reviewer,positive
cool trying trim make work well think need prune take text produce new either done model able support text python import file original un chief military solution,positive
code used generate vocabulary file import import import dictionary import dictionary none symbol symbol main none parser build vocabulary corpus data path pattern corpus train test model output vocabulary file dictionary main example run saved script sh python output look good,positive
use default corpus following pruning fast lightweight also found small label help pruning increase simple try know small trick help,negative
seem work either get error process following error recent call last file line state model file line return super strict file line error loading size mismatch param shape shape current model size mismatch param shape shape current model command execute criterion task none arch dropout edit think issue might model loading originally thought error different one looking update find cause edit listed evaluation section page work thinking quick rename provided restrict loading work correctly basically loading code suffix suffix else one provide model argument train script get work correctly,positive
comparison bucket still match well,neutral
one one device bucket getting similar raw loss see full notice effect pointed previous comment gist smoother belong last step command python en de criterion task translation dropout seed simple command python en de criterion task translation dropout seed simple,negative
still work add suffix might tested continued pretraining although almost thing please try naming let know go,neutral
hi thanks lot reaching paper golden use kind distillation loss therefore command output good accuracy could give u thanks,positive
issue unaware indicate line number sorted output file,neutral
code create provide identical,neutral
similar problem used custom converting raw data reading different see link solution convert data method instead,negative
append token like text yep exactly meant,positive
create unique token append token like text,positive
author wrong check found version instead pip version support,negative
add command well get similar epoch,neutral
use speech recognition check adapt accept input instead feed model used paper wait coming next able speech recognition one model,positive
applied following patch took peek raw loss cat git index ad class self task super task forward self model sample forward self model sample compute loss given sample three class model sample loss model sample sample else sample report report print sample epoch comment running command may raw look like tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor tensor pretty different probably due input preparation full loss schedule cut cut cut cut,positive
two tested way valid data set training trained load saved model similar guess something incorrect gradient aggregation,neutral
unfortunately seem work uneven though run node master python second node set equal starting global rank node case node set node docker python,negative
sorry delay change made output start instead broke scoring script fix python ref pairwise covered average python ref pairwise covered average,negative
could related issue across maybe loss side effect,neutral
sorry directly think related,negative
thanks also quantization process model loading model architecture elegant solution work,positive
use downstream emotion recognition speaker recognition thank much,positive
distributed rank host node server rank distributed rank host node server rank distributed rank host node server rank distributed rank host node server rank distributed rank host node server rank distributed rank host node server rank distributed rank host node server rank distributed rank host node server rank node server bootstrap docker node server found node server warn open node server docker version node server bootstrap docker node server found node server warn open node server docker node server setting affinity node server setting affinity node server bootstrap docker node server found node server warn open node server docker node server bootstrap docker node server found node server warn open node server docker node server setting affinity node server setting affinity node server bootstrap docker node server found node server warn open node server docker node server bootstrap docker node server found node server warn open node server docker node server bootstrap docker node server found node server warn open node server docker node server setting affinity node server setting affinity node server bootstrap docker node server found node server warn open node server docker node server setting affinity node server setting affinity node server channel node server channel node server channel node server channel node server channel node server channel node server channel node server channel node server channel node server channel node server channel node server channel node server ring via node server ring via node server min cap disabled node server rank complete node server rank complete node server rank complete node server rank complete node server rank complete node server rank complete node server rank complete node server rank complete node server launch mode parallel model transformer criterion model trained training per per none according log think training done single node distributed training question problem execution script thank,negative
one important question reproduction number useful help community improve accuracy would make script available soon thanks,positive
please take look similar train following thanks comment,positive
make sure comparison thanks,positive
please take look similar train following,neutral
something seen possible empty file please double check data reopen issue like bug,negative
somewhat orthogonal curious format think best found beneficial use keeping fed data,positive
currently use particularly case training usually need set automatically data format nothing specifically,negative
never tried one observation seem like two really comparable log log learning also seem different,positive
tried without command python arch task criterion dropout seed simple mask rotate complete en home,positive
model vocabulary need first apply example python try encode raw text get hello world first apply hello world work world remove calling world,positive
yep get first token unless model wo mean anything trained next sentence prediction objective token meaningless representation,negative
currently require use launch training working project make trainer work component like library ready yet,positive
training command run chance highly recommend trying without,positive
seem right training log line training see different number,positive
sure happening one solution unblock list data directory epoch shard data data shell robust good try since related plasma issue gon na close issue thanks help,positive
thanks hard work exciting news,positive
currently use particularly case training,positive
looking release code around end though,neutral
trained model look example extract look something like return,neutral
sure happening one solution unblock list data directory epoch shard data data bash robust,positive
also tried master branch used experimentation latest one thrown error test latest master branch available edit comment thank,positive
data fixed length pretty fast per second,positive
source code see none item assert list map code nonzero loop didnt make anything hint,neutral
plasma use memory avoid redundant suspect running memory please try particularly unlimited suggestion thanks response tried work besides added code following self none none return assert none assert none plasma sever path property client self none assert none plasma client path return training model log start plasma sever path connect plasma client path start plasma sever path connect plasma client path start plasma sever path connect plasma client path got stuck three idea configuration might related,positive
every time log loss context switch strongly log much le frequently certainly better choice example see specifically bit item operation explicitly evaluate result use unless,positive
tried similar command complete mode logging every update extremely low anything missing thanks root note compilation many lead slow training expect beginning epoch root note compilation many lead slow training expect beginning epoch,positive
double check run complete mode dont need since length correct thanks lot,positive
seen error try latest master branch,positive
like something going come back fix maybe temporarily multiply get better approximation,positive
probably input example long length add option similar set train,negative
plasma use memory avoid redundant suspect running memory please try particularly unlimited suggestion,negative
used script used script work well make compatible converted format expect convert tried please report back try work,neutral
would recommend removing flag flag performance lot much smaller better start generally value make training faster done also make training first since lot used past probably fine,positive
still working proper documentation support generally struggle dynamic may want set use full amount sent single core paper mention batch size achieve original context length typically batch size per device many per core set per core sentence block instead set would equivalent finally total batch size across typically paper used total batch size training total batch size could simulate batch size setting would accumulate per core update giving total batch size,positive
thanks much two command look right anything hint setting thank advance,positive
attached issue per second lower factor case need multiply assuming default,neutral
need use latest version master wo work unfortunately please follow reopen task still work,neutral
thanks much promising definitely try,positive
try linearize tue wrote hi model source language tree course ca feed normal model expect know handle tried construct model take generate string output target language unfortunately learning access knowledge reading still left confused ask see support tree model anyone could help model would much thread reply directly view,negative
curiosity need disable shuffle test data,neutral
thanks since let rename make change,positive
hi shorter avoid work properly added single instance length target source bit shorter task trained system loss converted nan long sequence taken training know single training instance causing problem open nothing strange well formed used source rest training data training set repeated target sequence representation code give problem source sequence wearing like apron huge think see apron first know important tree ail basket basket full one floor kerchief basket full fell first place um back ladder ladder let see ladder um anyway guy come leading goat goat talk think even look guy watch goat disappearing way back man tree tree definitely come bicycle direction goat man left um bicycle way big giving know want um reason giving cause know point movie maybe see something um come bicycle bike um movie color movie sound track important mo whole movie cock crowing see anyway anyway um bicycle bicycle think front see riding next scene see like distance pan shot riding lane riding bicycle cro know cross kind go watching turn around hat rock spray place see fall brush go know see three age like maybe ten something twelve know look see come without saying anything speech whole movie without saying anything um help put back basket wipe first pick pour get bike one rock side road set upright know say thank walk three walk road see hat one bike turn around hat guy bike hat three share hat everything um another detail girl one bumpy road little dirt road one whatever um see bike three walking one call little um know ball walking along brush start eating walk man like important um ge getting tree ladder one full basket empty basket full basket gone target sequence anyone find something suspicious data may something else cause issue,positive
update get text wave file audio,neutral
yes extract first token,positive
hi prepare data training validation,neutral
thanks bit unsettled yesterday code lack block added block like example instead also match vocabulary size number divisible running translation script relevant change criterion see working evaluation step look fine guess working case something wrong please comment amazing work,positive
source target language id instead en size mismatch param shape shape current model line loading model command construct dictionary plus special dictionary plus language id mask token total thinking part missing would prefer also provide first line log starting line command actually may provide community resolve issue,positive
tried still get error,neutral
yes work example please try let u know go,neutral
yes update well thanks amazing work,positive
interested trying news available thanks franco,positive
done mean load model doubt done properly worked look,negative
advice date current version current example use,neutral
issue resolved bash script apply test data generate index python en e align apply trained model generate result python path test also moving file machine machine use tar command archive extract file tar tar,neutral
see current effort convert sequence generation pure torch script implementation wait next release merge,positive
need cat python path beam tee,neutral
flask serving rest multiple,neutral
case error hub able model corporate proxy silently logger attached anyway find solution set export variable export python,positive
commit head master data warning still increasing script fine otherwise every warning could solely data loading perhaps something else following base command shell arch dropout criterion patience also verify warning release,negative
thanks clarification also found,positive
eventually get divided case number masked,neutral
hopefully soon pip install install master via pip,neutral
hi publish new pip version package since package still problem,positive
correct might also need add optionally use,neutral
like hanging near end epoch big validation set also please pull latest master fixed another data loader,positive
sorry considerable delay make related internal code make everything work bit please review confirm hi thank also rerun everything good getting like idea module method set everything much cleaner thanks,positive
reasonable feel free submit,positive
sorry considerable delay make related internal code make everything work bit please review confirm,negative
thank still curious label smooth result guess would bring additional performance boost try future please share result thank much,positive
thank advice find setting higher update performance tried use label smoothing concerning inference didnt see hypothesis didnt put command far without problem havent yet tried language perhaps need open issue issue,positive
set bash think need list used pretraining said source code,neutral
usually include state number model thus file size usually strip since state going continue pretraining set flag able resume later,neutral
bash script used command apply test data generate index python en e align apply trained model generate result python path test,neutral
hi regarding longer get error however loading last printing anything find strange loading train data epoch loaded loaded train sure though still running model nothing printed problem old work well although best solution oh thank information,positive
hi regarding longer get error however loading last printing anything find strange loading train data epoch loaded loaded train sure though still running model nothing printed problem old work well although best solution,positive
hi regarding longer get error however loading last printing anything find strange loading train data epoch loaded loaded train sure though still running model nothing printed,positive
going use hugging face library also possible compatible also looking solution already tried result like found file word like two work code,neutral
observing similar issue bigger provided also inference time provided idea come fix,neutral
try following custom classification example enough context u help,neutral
load inspect used train example python import torch gist dump used train,neutral
thanks reply let clarify question section based section use combination text infilling sentence permutation therefore see used objective train yet state clearly file checked task trained file default,positive
section paper trained corrupting reconstruction output original document unlike specific u apply type document corruption extreme case information source lost equivalent language model task,positive
hi issue came across trying run script got following error module attribute resolved issue basically old version script considering version script smoothly issue reopen encounter training future thanks,positive
hi response like couple please ensure latest paper trained page look tutorial used following batch size run validation epoch epoch data randomly training set select best validation set result quite important run training use without decay select model best result validation set pick final number test set thanks reply find latest,positive
package posted result get data bash tar,neutral
hi would like ask pretraining objective model find pretraining objective file paper grateful answer question best lin,positive
hello question implementation rewrite thanks,positive
hi hope run machine source folder met problem import name fall back version solve thanks,positive
correct without average however score paper applied average magically acceptable,positive
also trying torch apex master getting issue running fixed,positive
option input truncated instead skipping,neutral
hi still running yet like said giving post update training complete,positive
sorry made mistake issue actually source addition model work well manually removed,negative
need adjust might try following example starting point guessing way high default since specify whereas example,positive
specific example following please provide original data source data kind data prior calling,positive
unable reproduce ran following without bash data following task translation arch transformer dropout criterion beam python python import,negative
latest version unfortunately problem still,neutral
try latest version master like provide fix see context,positive
solve issue got issue whenever tried load train training loop long time load train,negative
hi working option solve problem call display interface showing validation loss amongst found way store information file format something similar though,neutral
trained model data found data already still use yield score,neutral
sure follow please follow issue,positive
agree parameter odd think error getting actually number class try python equivalently python,negative
update anyone reproduce provided,neutral
hi thank help please go following example understand issue input sentence people saying mind blowing face ending worst history cinematography left whole world ended mention character idiot whole time got everyone right whole time non would people giving stupid cause make rain admit movie whole concept fascinating lot one another anybody else get feeling lot like lord stupid almost character development honestly ask good four left world pointless stupid one ever seen thank god turning creative way done like hundred time movie really stupid go see movie worth watching like star trek inglorious good get running output get training phase print sample tensor assign dictionary,negative
probably need try alternatively may need clone source run pip install thanks try,positive
probably need try alternatively may need clone source run pip install,neutral
understand right pointing correct,positive
reproduce alone something like python import torch happening trying use install want use think need explicitly specify install thank quick reply yes definitely work error surprisingly even work well wondering function fixed call installation since exist system,positive
want following environment variable give informative error message void unnamed long long float float block thread assertion sum fail assert triggered recent call last file line module file line main file line main return file line generator sample file line return sample file line return file line generate return sample file line step file line step error assert triggered,negative
reproduce alone something like python import torch happening trying use install want use think need explicitly specify install,neutral
hi thanks detailed answer everything possible could maybe tell option better language model downstream performance language model would probably better one empty without one without one clean without ask specifically much influence model blank clean sentence splitting everything,positive
really issue try running python mine ha,positive
particular model looking language ex yes format model like official example form model like want use shall transfer model firstly format run script thank much,positive
yes like line added feel free submit new fix thanks,positive
could also take look thank much another great work analysis attention paper paper code,positive
want following environment variable give informative error message,neutral
particular model looking language ex,positive
could also take look,neutral
sure understand want compute blue ca apply reference call script,positive
need specify include task try running exact command listed example task method arch dropout criterion,positive
think must one sentence per row necessarily sentence per row put amount text line aware model may impose ex need empty want use yes otherwise necessary shuffle text line line need shuffle specify whether data,positive
yes would follow advice,neutral
think easiest way would build vocabulary example find unique token ex special beginning end calling,positive
hi totally agree reference also somewhat doubt real performance model training data successfully reproduce score command cat noted text evaluation fully official result indeed previous confirming effectiveness,positive
thank interest basically want feed class label source text thinking whether feed class label feeding source target text similar text generation translation task training time,neutral
issue parameter anywhere code get supposed running code example provided error removing get error recent call last file line module file line file line main file line main criterion file line return self file line return builder file line raise unable infer criterion please implement change since code running master version,negative
also interested pretraining script update,positive
think found great tool visualize recommendation please leave link many thanks,positive
found mistake also loss summed loss got notebook fixed code,positive
yes used input shown notebook think mistake looking equivalent loss,neutral
thank reply yes size train language model take word input unit rather character use word input better performance former sorry unclear description set effect thus set training corpus document paragraph information setting none also worse performance former use model thank deal well overflow also note epoch first epoch frequent note overflow setting loss scale also print norm gradient clipping overflow change nag work well momentum gradient also note nag nag memory consumption,negative
several vocabulary size quite large model suspect partly large table large context size model many try even smaller could fine use instead slightly aggressive version mixed precision training save memory typically large batch size may produce slightly worse end another idea use model parallel training support,positive
tried train already got problem next check data see source problem thanks,positive
please share procedure transfer learning open fine tuning,positive
thanks lot way large model use hyper parameter base model,negative
hey perhaps load entire model think would difficult load since model play key part complexity involved,negative
thanks experiment data augmentation data point added training set hoped data point immediately follow original data point make life easier however figured order within batch training data file still good know content specific batch change across,positive
sorry brush take look training support,negative
ran locally mostly used al time time average translate comparison different arch tested image comparison different number image,positive
setup filtering release paper,neutral
hi able successfully model please explain,positive
brief update still running figure best way implement performance speed without compound al normalize throughout architecture comparison image layer comparison image,positive
many model going trained paper,positive
amazing work thanks lot,positive
exciting news thanks incredible work,positive
apologize reply able obtain model replicate bug working fix,positive
update release code model hopefully next,neutral
look actual input target see make sense everything work working increase likely data problem,neutral
clarify order within given batch across reconstruct epoch could potentially look note like translation fill efficiently sort length need consider want introduce randomness,neutral
believe prepared data able share preparation,positive
yes completely agree active effort migrate away instead use hope share soon,negative
hi training suggest use update label smoothing generation text short set length penalty much value forgetting remove found use setting also work language fail use task,negative
previously printing frequently fixed confirm commit recent older version believe since ago current system,positive
previously printing frequently fixed confirm commit recent,negative
met error case short utterance variable min negative thus end short think maybe bug code,negative
sorry delay working getting,negative
hi know gave trying exactly recreate,positive
also large used work latest code master also large model seeing error would check head name,positive
sorry directory shall run pip install,negative
large give error think error associated classification head probably head name,positive
thank reply model obtain score paper start model share new,positive
script tried reproduce paper get close quite good certainly could pruning training different setup single might got batch size learning rate schedule quite right reproduce paper also kind tricky might gotten correct,positive
landed please reopen issue still encounter,neutral
thanks response going try since expert either might require bit training quant noise used noise block size trained architecture sentence trained around got model sensible hypothesis around th epoch training command data folder handled quantize freshly build model load state exactly clear mean write training loop quantization make would nice share snippet gist profile would help try together zoom thanks update train quant noise well quantize model without severe loss metric share shortly,positive
exactly error manage successfully run training see problem model sate training quant noise similar problem running training also lading previously built new model freshly built model different trained quant noise case handled quantize freshly build model load state suppose could try something similar freshly build model train training quant noise expert know advice good could tell run quant noise model train model output sensible hypothesis,positive
recent call last file line module file line file line spawn file line join raise exception exception process following error recent call last file line state model file line return super strict file line error loading unexpected key handling exception another exception recent call last file line file line main file line main trainer file line file line please ensure match exception load model please ensure match tried original file seem work,positive
interesting confirm instead work well believe detach preferred way,positive
far figured fix problem waiting assign someone fix code used work ago,positive
hi way try would export model,neutral
quantize trained model run additional training argument modify file little bit regular finding add similar quantize important add argument quantization training epoch multiple,positive
facing related problem unlike however able train working model noise different size kept transformer used lower model work still quantize training noise facing issue would try hack see make progress also facing issue,positive
script wrote reduce size model pruning word python import import o import list import torch import dictionary list path dictionary path mask return main none parser model model directory model dictionary model output model data model data model list range word word name model name enumerate model name data main example run saved script python output hi thank much wonderful code final translation performance pruning technique concern numerical stability pruning denominator final layer becomes much smaller maybe easy thing dealt opinion concern thank code best,positive
script wrote reduce size model pruning word python import import o import list import torch import dictionary list path dictionary path mask return main none parser model model directory model dictionary model output model data model data model list range word word name model name enumerate model name data main example run saved script python output,positive
hi thanks fast reply understand heading model yet tested tried replicate trying practice parameter training go well accuracy well inception architecture error problem calculated input size per channel kind error calculated input size per channel kernel size kernel size ca greater actual input size original code part mask mask since majority inception removing linear bug training process working well minority basically code still broken guidance problem tried train linear progress made hope available soon possible looking forward work,positive
get error running model get fix,neutral
note pretraining model sure generate training data binary format new vocabulary hello thank experience really lot pruning method intuitively appealing would much better could make freely available best,positive
example code available please share,positive
name provide performance comparison performance comparison transformer machine translation refer paper based,neutral
expect would make different running exact command shell set file ref cat file file done cat none none ref run shell attached first one output hi thank script really lot following reproduce score still score lower paper lower result three issue also normalize testing input text file test successfully result score could share key thanks,positive
hi facing issue resolution assuming source code directory source code directory run following step step pip install pip install way solve problem good luck,positive
hi facing issue resolution,neutral
rank rank case python setting yes understand multiple multiple use number,negative
rank rank case python setting,negative
update code release thanks,positive
hi worked apply trigger use one,neutral
problem want know solution separate script use matric sari instead thank smiling,neutral
previous comment mistake instead line line,negative
possible solution file replace code line following code,neutral
hi thanks interest work release code various vision soon stay tuned,positive
hi thanks interest work thanks reaching inception specify appendix paper valid sanity check could confirm training go well experience necessarily need since already redundant along spatial dimension see previous paper would recommend large enough except first layer instance could also try slowly increasing fro say training working new cleaner aim open vision code various soon possible let know,positive
help first thanks model run question could provide pertaining script used hope train model language course aware support target task believe training language data might better although could figure base paper prone miss important training training like would highly beneficial thanks lot advance hello also interested training got,positive
provide script use keep pretraining example want pretraining one language add new language thank hello got,positive
think shall set right use refinement ever use irrelevant every iteration input would copied source,negative
maybe degrade torch version work,neutral
unable cast instance holder compile mode type information getting error anyone solve,negative
ah yes thank update link,neutral
thanks raising issue looking,positive
thanks interest investigating possibility integration code section,positive
trying large gave error error loading unexpected key need help please,positive
hi daily mail token work fine thanks lot,positive
please try report back,neutral
currently remember correctly welcome option shuffle,positive
far tell done default interpolation mode maybe ultimately matter le ideal switching one interpolation would probably better best would use maybe,positive
want initialize parameter parameter actually transformer model hyper size number equivalent,neutral
could build service based like,neutral
change parameter basically number maximum consist batch training data default remember dynamic select different sequence,neutral
know since commit internal broken,negative
model sentence level model fact translate one sentence already surprising never trained translate need split input individual translate separately,positive
maybe leave efficiency gain,neutral
hey yes extra dummy making matrix efficient delete adjust matrix manually,neutral
reason speed vary without flag hence unnoticed might tried lower due time taken move extract computation made thanks reply drop generation speed noticeable moving well even smaller like speed lower option however right difference generation speed flag,positive
thanks link sent via superhuman sat wrote hi response like couple please ensure latest paper trained page look tutorial used following batch size run validation epoch epoch data randomly training set select best validation set result quite important run training use without decay select model best result validation set pick final number test set reply directly view,positive
hi response like couple please ensure latest paper trained page look tutorial used following batch size run validation epoch epoch data randomly training set select best validation set result quite important run training use without decay select model best result validation set pick final number test set,positive
even without work may excessive reason dynamic range precision,negative
question added accurate faster used approximation original paper approximate formula nice observation actually use kept backward compatibility question added accurate faster used approximation original paper approximate formula yeah poorly part based original accurate sigmoid still approximation calling would better,positive
thing recent call last file line module file line file line spawn return join daemon file line file line join raise exception exception process following error recent call last file line import module,neutral
hi issue also trouble running,negative
reason speed vary without flag hence unnoticed might tried lower due time taken move extract computation made,negative
thanks quick fix really original author another fix internally another related bug hopefully fixed,positive
thing recent call last file line module import rerank import name unfortunately could get noisy channel example work older release issue file see code looking like something like step score model step language modeling none dictionary recent call last file line module file line file line file line rerank file line file line file line main file line train file line file line file line open file directory generic job sun status code finished sun decided update give another go yet check code see issue official thanks,positive
despite fact yet manage train model quant noise model trained without noise running generate script model problem loading state model hack pretty one model built none import import ugly line step range model step step step model model work time quantize something argument simply argument generate work generate like argument,negative
numerous expect type list list logging variable log value sum raising unexpectedly put list like unless something obvious missing current internal agree one another multiple aggregation try aggregate different metric logging particular metric one log structure different aggregation function list metric,positive
someone verify correct output python un chief military solution nu source language code either side language code start target language code even though end target language code read sure verdict legendary may insight,positive
actually example idea train two german translation task train used script based document python task arch dropout criterion seed tee train translation task python arch task dropout criterion documentation translation task however,neutral
example want reproduce training different want pretrain bilingual translation would consider pretraining mass available,positive
thanks making sure issue sort knowing everything likely working good definitely moving version soon,positive
suspect slow train even getting first log output please try simple unfortunately training really practical unit reason support training,negative
found empty list print checked like made sure list list filter end worked still problem training quant noise,positive
hi trying quantize model translation example facing train model argument train something like tried block size result similar tried quantize model training without change found see quantize anything found quantize argument divisible learned quite well quantize anything model size size indexing compression ratio wrong,negative
yes output ca evaluate,neutral
mean training include python task arch dropout criterion seed tee,negative
result model result thank,neutral
en dictionary de dictionary loaded loaded valid linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear model criterion model trained training per per none found loading train data epoch loaded loaded train note device may support faster training epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch epoch valid epoch valid subset loss posterior saved epoch score writing took train epoch loss posterior wall epoch training log,neutral
hi figure got score follow example also got wondering share script give advice thank,neutral
include copy paste create one local folder,neutral
able share generation training,positive
idea honest tested different implementation never tried biggest model since single small experience distributed training,positive
ah ignore build always thank someone testing get back feedback one early piece feedback really great could support model size model parallelism know possible currently implementation,positive
take see count take entry replace special token also add line token split image please guide build language,positive
facing problem find glue image python path beam know excepting,neutral
observation th step iterative initial amount generating starting sentence different task sentence correction let start question good language model able predict sequence length direct correlation length linguistical content sentence could perhaps improve training strategy removing need model predict initial length,positive
code method cutting model thank,negative
hi update matter thanks,positive
would documentation update detail content enough get mistaken count word training presume word corresponding format please guide build language,neutral
thanks interested array similar done right theoretically able use array standardize space example something missing,positive
something else specific file get data please guide create language,neutral
used method python state model,neutral
hi made lot related passing module fail passing forward method module sure exactly unfortunately also please let know like rebase recent master,negative
per second per second per batch,neutral
increase docker container refer also try use protocol dump work,neutral
ca remember detailed quite long time ago since ran one maybe set token without fixed batch size want large batch size recommend option,positive
thanks reply directly run command line provided originally think face mistake get wer well paper whats used expand thanks lot,positive
used modify model example code problem mistake missing positional model,negative
also see might reason,neutral
hello currently grammatical correction translation could run translation like transformer switched gaming problem training currently run script python arch dropout error image image know overflowing get run somebody help help would thanks advance,positive
provided path tried however never reach wer original paper said,positive
correct default training data valid set test set hi sorry want ask according rapid corpus eu press thank,negative
thanks worked think next release,positive
ah right probably forgot add look soon meanwhile try add forget multiple something like decide mask mask false add random number probabilistic rounding float round offset range offset range else range,negative
hi find solution issue inference use got similar exception greater good fixed really slow almost cost half hour computer finished test corpus,positive
hi also issue get want reproduce result paper however achieve wer base transformer structure achieve really wired since valid almost get thanks lot response,negative
saw let get model think right way use without main code seen code bit older latest may may let support feature may need update thanks finally think got right direction use implementation currently time tense hope future support properly,positive
install master long ago issue linked reason,negative
know seem facing problem,neutral
want let part get let share following given method view could make understanding right yep right trying modify let support need test whether looking forward official think crucial network module someone actually added functionality part getting search see tested yet,positive
thank example run training call saying exist find reference anywhere could,neutral
cording position previous step get smaller related thanks much kind,positive
thanks method bit tricky know affect let say model want let part get let share following given method view could make python forward self let say part part time part scale based part scale based set global part understanding right trying modify let support need test whether looking forward official think crucial network module,positive
got problem case nan sure happening unfortunately could reproduce investigate better since caught previous nan problem may division sure possible,positive
thanks lot maybe bug use greater exception raised follow error illegal memory access however fine use really slow predict,positive
fixed use need move,positive
model use new dictionary one produced master available,positive
hi team version facing issue running script inference anyone resolved issue,neutral
thanks question thing training automatically stopped case version little bit faster fast issue came across trying run script got following error module attribute belong raise issue,positive
unfortunately well right look support another option modify magnitude gradient module example use lower effective learning rate convolutional model,positive
got fatal error inconsistent try even added command training script would please give advice,neutral
like need export fallback see also try project,neutral
vision paper done see section aware immediate,positive
yes default normalize number even specify batch size,neutral
think ideal solution found generate dummy target file use instead get really bad model change long dummy data,positive
thanks detailed fix merge shortly,positive
yes also ended custom task criterion finding right class loading data tricky ended one hot fixed length,positive
yes right sorry think need custom task task simply probably want classification probably want loss,negative
good point extend instead submit fix,positive
linked solution one label per sample problem situation multiple per sample sentence difference,neutral
right guess need add,positive
hi wondering much memory acquire case according issue result failure exception process signal memory could specify another directory instead use case thank,negative
hi yes definitely agree analysis please see issue check function used please notice current way skip normalization thanks,positive
python path task get unable infer criterion please implement,negative
like nan normalization guess unbiased variance estimation mean naturally nan confirm could please point,negative
maybe enough space try setting temporary directory location enough storage space something like bash,neutral
hi thank pull request welcome require sign contributor license agreement seem file order u review merge code please sign behalf someone else employer individual may sufficient employer may need sign corporate received error please contact u thanks,positive
good point generally need validation loss saving order set properly old behavior get whenever validation run revert old behavior,positive
sure create model going assume translation pair considered source target respectively,positive
problem driver update driver look,neutral
error nothing size training data used root cause vocabulary used model large thus many loaded ordinary ti ti three choose use training speed slow use machine large memory like cut model best choice large vocabulary used original model actually used process part redundant information removed model matrix actually proportion cutting work mainly reducing matrix model next introduce cut model get new vocabulary based data generally speaking size vocabulary much smaller model find corresponding position old vocabulary according new vocabulary obtain part matrix according position previous step get smaller related data keep unchanged replace matrix new matrix previous step save model generally speaking new model much smaller original model enough loaded onto normal training note pretraining model sure generate training data binary format new vocabulary,positive
unfortunately could recall correctly error operation included however might fixed one error gave model sure fixed still got error bother went straight tested two version identical mine could without error,positive
comment build model criterion however raise another error object attribute similar issue bug,neutral
get error doubt override function since never seen module use loss,neutral
instead line model please pas model,neutral
hi sorry question think related issue raised training transformer base single batch size length source target please idea possible appropriate value initialize learning rate based batch size update frequency note average,negative
thanks lot yet setup training,positive
hi please update link alike broken really interested,negative
thank like idea dropout module instead would mean right confirm yep exactly,positive
ask bug also effect language dictionary order made deterministic issue scratch dictionary compatible model data dictionary provided model archive language since release data scratch really issue always going use provided dictionary file since option available,positive
thanks helping method necessarily successfully loaded fine tuned model also tried several always error phase recommend approach loading fine tuned model would happy use,positive
thanks opening issue look issue previously use method load model likely incompatibility state seeing,positive
hello specific detailed reason update frequency want reset model may change,positive
thanks interest specifically necessary thought simpler robustly test activation quantization,positive
hi show install show following error wondering notice space use space specify location space use computer outer storage large model criterion model trained parameter training per per none found loading train data epoch loaded warning logging written connection socket time warning logging written plasma store use memory starting object store directory huge page support disabled connection socket time warning logging written plasma store use memory starting object store directory huge page support disabled connection socket time warning logging written plasma store use memory starting object store directory huge page support disabled system memory request memory available request amount available may able free space inside docker container may need pas argument flag run exception function recent call last file line file line object attribute exception function recent call last file line file line object attribute exception function recent call last file line file line object attribute exception function recent call last file line file line object attribute client client client warning logging written connection socket time warning logging written plasma store use memory starting object store directory huge page support disabled system memory request memory available request amount available may able free space inside docker container may need pas argument flag run client recent call last file line module file line file line spawn file line join raise exception exception process following error recent call last file line file line main file line main train trainer task file line inner return file line train progress file line enumerate file line file line file line file line return self file line file line queue return queue file line file line lock return lock file line self semaphore file line space left device change another loaded warning logging written connection socket time warning logging written plasma store use memory starting object store directory huge page support disabled warning logging written connection socket time warning logging written plasma store use memory starting object store directory huge page support disabled connection socket time connection socket time warning logging written warning logging written plasma store use memory plasma store use memory starting object store directory huge page support disabled starting object store directory huge page support disabled warning logging written connection socket time warning logging written plasma store use memory starting object store directory huge page support disabled system memory request memory available request amount available may able free space inside docker container may need pas argument flag run aborted time try date gnu date unknown received tid stack trace unknown plasma plasma plasma main unknown connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time exception function recent call last file line file line object attribute client client client client warning logging written connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time warning logging written connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time exception function recent call last file line file line object attribute warning logging written connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time connection socket time recent call last file line module file line file line spawn file line join name exception process signal,positive
ask bug also effect language dictionary order made deterministic,neutral
artifact large apply automatically try pip install rerun enable avoid thank glad know work around cool try update work also found error python package also discussion listed although try think method better modify python source code,positive
yes number dictionary dimension main vocabulary everything first special use map raw python embed range note always traditional sense use may even full example python print also first four pad unknown access via need python print range pad,positive
please provide feature request,neutral
custom criterion need log loss scalar like add helpful error message case though,neutral
artifact large apply automatically try pip install rerun enable avoid,positive
release model previous work shown bigger model size help deal issue interference training multiple deal recommend looking gradient trade compute memory yet generalization abstraction look getting future recommend trying get gradient working fitting model memory give u suggestion limit usage need use u,positive
thanks reply format train data file sentence line similar removing blank line sentence rather title article,positive
line data sentence understand correctly single line corpus document error could occur crop longer size thats reason error think right might something else,positive
implementation bit also model architecture gradient logger output training fork also hope find useful,positive
present multiple create general valid create new one also cause,positive
hi thanks discussion wondering would example like want score gold model like something like thanks much advance,positive
hi issue model large trained interested want pretrain data please provide thanks,positive
hi left try per maybe even memory would reduced easier load library try gradient issue,neutral
help thanks basically close paper therefore use data model although got good absolute quality still relatively low due vocabulary large model large hope provide tutorial pretrain data question model sentence level monolingual data choose set vocabulary size related number size training data use tool data use framework model long take ti ti model hey sorry bother model always running memory memory tried allocate mib gib total capacity gib already mib free gib reserved total would give help even single since large kind used thanks,positive
hi support training provide output also train command need en variable order properly since particular hi trying language size million use command still unable train due memory error trained even single ti ram please confirm ram would sufficient training data size see across two even inform memory training thanks hey sorry bother met error memory single ram error far thanks,negative
could also add smaller de en,neutral
thanks detailed need separate model like python,positive
later custom python interface used custom well import,neutral
training command run share added early stopping based validation loss recent version early stopped training either,positive
thanks nice left also bit uneasy abstraction since seem flexible another option would switch dropout instead functional model add flag functionality would entirely driven model depend something like python class self super forward self return else return think thank like idea dropout module instead would mean right confirm,positive
thanks actually need already defined code let remove,positive
hi thanks much getting back issue providing suggestion master version defiantly try see training exist get back thread mean training version model converge around version model converging around version training automatically stopped validation loss decreasing case manually stop training based training log validation loss soon provide training log team look issue effect accuracy observe decrement accuracy compare exploring translation task type,positive
ah shoot figured dictionary used model one today particular dictionary order made deterministic one model slightly different dictionary dictionary provided model archive also going retrain model latest stable dictionary release,positive
initial support coming add support translation currently hopefully support model parallel,neutral
like something could wrong since custom make sure attribute correct since use populate progress bar turn progress bar wrong appear finishing epoch early either way likely logging issue still full able share code somewhere,positive
hi training model based task facing similar problem nan first nan moment skipping problematic real solution tried learning rate weight decay luck solve problem yes,positive
able use version latest version actually quite behind master ideally could use master similarly latest version said looking speed convergence need information ran training,positive
like something wrong environment directly related show actual exception general recommend setting fresh environment anaconda setup install subsequently pip install directory,negative
hi question thanks advance help,positive
example trying use model find score input get work translation task however sure correct first clean model paper extra likely architecture paragraph section paper also include additional layer top found training precision likely dropping easy remove following script python import torch extra extra model dell model extra next manually add language dictionary shell code mask echo code done model work translation task suppose would like use model find score sentence one append language start end like shell miss miss miss low vocabulary quite large would prediction first token high removing language entirely much higher shell miss miss miss hard know right call perhaps language used case one would adapt task around quite bit one take care since task permit scoring box two distinct work would helpful technical guidance exactly model perhaps would easy question answer think fact probability token low might related know model trained based implementation master token used input,positive
thanks tried adapt pipeline currently able go would worth step step guide thank much,positive
fault issue one encounter problem refer,neutral
train model share training saving save three model think better save one parameter share,positive
bug cause trained currently share,neutral
thank removing certainly reduce model size try cut original dictionary,positive
wish use full bag want convert well see sure whether used compound splitting used several since facilitate accurate markedly lower without adjustment personal suggestion would report fully without compound splitting pas signature addition nonstandard scoring,positive
hi handle want plot loss curve thank,neutral
ca access code right think ca access need find author also write try,positive
thanks get similar raw also wondering use following piece code provided author boost rouge step else defined code,negative
yes apply raw given author,negative
maybe worth somewhere another edit maybe good idea since custom module relative instead name module,positive
trying reproduce apply data use generation got following bit lower image add data step wondering missing lead score think issue someone know find detailed explanation hi say without mean even without text also try reproduce rouge lower,negative
custom criterion share training command yes custom criterion applied command line training command master branch build python task arch criterion dropout beam defined python import meanwhile following alternative command could work smoothly bash python task arch criterion dropout beam,positive
custom criterion share training command,neutral
training model task training form first epoch think issue first epoch get found reason random usually wrong size,negative
anyone better advice version rather command line thanks,positive
hi source pip install following code model error error loading unexpected key weight bias weight bias,positive
ah never mind calling encode work get weird thing string multiple based whether space front reason presume need use space work fine,negative
regarding first point likely large contain remove script,positive
problem merge inside collate function single flag used task batch token target sequence problematic batch might contain mixture many set token used set correct bash print list sample de nach er men um en de un ami ar en en hold er ged de un er em,positive
operation previous convolution still sure everything correctly,positive
master right also run python root directory build hi yes perfectly work appreciate response,positive
occur issue image log train epoch finish yet epoch start command line write,neutral
thanks reply python task arch criterion dropout use command line time epoch finish yet valid start go epoch time find memory like image train stop time log output error time log output thanks guide,positive
update something like option specify additional area look way add,neutral
hi version keep posted thanks,positive
share full command ran tried dummy model worked bash python task arch simple,positive
master right also run python root directory build,positive
even wo work batch mixture many way work batch bash print list sample de de de de de,positive
hi issue switching fixed though,positive
thank much reply tried fix get perplexity however perplexity score pretty higher sure mine way higher got path dictionary loading model dictionary loaded test model loss base perplexity thanks,positive
thank line source target raw still set source target index word dictionary,negative
hi favor line add step else let know rouge data line thanks lot hi tried add code give error exist add manually,positive
update condition satisfied image notice dimension suddenly error image output still sure,positive
able reproduce error tried recently saw different running command need update command match pas use,positive
command dictionary file default faster load sometimes make take le space disk highly data prefer instead use raw text passing still need run use raw text,negative
sure try could confirm correct branch working,positive
match size pod typically bash python python note synchronize logging end logging interval smaller slow bit recommend log interval greater also note counter factor multiply counter get correct value,positive
hi let know find could related branch moment sure find cause issue first try training simpler task,positive
need call disable dropout first otherwise return slightly different work python import torch dropout world assert,positive
like used export compatibility project team plan use instead remove migration complete let leave open reminder,positive
sure latest version stack trace see line line master submit,positive
trying branch custom sequence task running error internal assert help would want paste lengthy log unless relevant issue thanks advance,positive
thanks issue adaptive recent broke backward compatibility submit fix shortly fix get bash path loss base perplexity,negative
install main channel instead something like install ran work create nat activate nat git clone install pip install torch pip install python python import print great work,positive
training interface see language modeling example,neutral
trying put code list,neutral
thank much main branch like value select plan train pod,positive
use branch relevant master soon basically work good training work translation since like dynamic need modify approach limit number unique batch,positive
ah right due recent change submit fix,positive
practice sure whether important even latest paper massively multilingual target language token every source sequence said definitely discrepancy current implementation master paper text figure would nice get definitive answer someone involved project,positive
would really glad found solution issue,positive
write true tensor tensor got error change line worked,positive
yes get batch total pas sum update,neutral
believe tensor calling fine get error,positive
think indeed inconsistency paper however token source token correctly inserted end sample special added every sample generic token maybe issue fixed since however issue input tested task two small german corpus also add flag specifically example small batch note vocabulary size last bash print de en mask input bash print sample batch sample mask mask de mask mask en mask de mask mask de mask mask de pad mask mask en pad mask mask de pad mask mask de pad pad input see added input unlike paper bash print sample batch sample paper said token also included input please clarify whether mistake paper bug implementation,negative
uninstalled source code used command pip install install server used pip install command install source code however running training command model error still,neutral
think meant training nat add plot evaluation metric issue well trained nat model following script python arch criterion task noise dropout beam trained regular transformer similar get plot plot case nat still get loss plot version python let know essential thanks advance,positive
figured fix support merge soon,neutral
would love see feature added although maybe logging extension interface might appropriate would avoid core many logging progress,positive
addition might interested original paper clearly found use inconsistent training development data removed source side synthetic training data found best single system ensemble last dev thus best single system primary system removal en experiment check output,positive
want sound critical paper great however statement wrong example language far transformer look official en ran translate en en en legit would far language well say used nobody right reference whatever want training data output system end need score output submit scorer comparable reference well aware may confirm,positive
got problem fixed python index index return list filter large index index index index thanks,positive
got problem fixed python index index return list filter large index index index index,positive
following output get know official completion however many process data dig related take time however view fair way comparison training thanks,positive
example unsupervised mass many work,positive
mind previous work thanks,positive
hi previous work people compute thanks,positive
suggest target side data different number source side share log command correct different size manually made error fixed training got error saving output end training training command exact master model criterion model trained training per per none found loading train data epoch loaded loaded train loaded loaded train epoch overload number alpha tensor consider one following instead tensor number alpha epoch loss clip wall loss loss epoch valid subset loss loss loss saved epoch writing took done training output task path dictionary dictionary loaded loaded test loaded loaded test loading model note hypothesis token output base recent call last file line module file line main file line main return file line division zero able resume training training master fixing size error resolved issue able data full script would create set generate error correct way translation anything make easier thanks far,positive
could know option included latest version,positive
suggest target side data different number source side share log command,neutral
know external link posted,neutral
simply use import world replace path model file name accordingly make file,neutral
possible please share python code thanks,positive
thank try port python,neutral
hi model trained also docker image trying run python hope,neutral
version target used teacher forcing directly give target model include sample criterion use compute loss discussion,positive
unfortunately secondary dictionary special try python world import dictionary tensor,positive
able reproduce master master try latest master mistaken master tried master training saving command first post new end model criterion model trained training per per none found loading train data epoch loaded loaded train loaded loaded train epoch recent call last file line module file line main file line main train trainer task file line inner return file line train trainer task file line validate trainer task file line validate file line index file line key file line key file line index index index index axis size training size error instead error training size,positive
hi think might still issue run argument file line module file line main file line main main positional argument given,positive
share large small model per epoch total time taken memory usage share training large small model thanks,positive
seem answer bunch clarify ought,neutral
hi like test still facing issue recent call last file line module dictionary en dictionary file line main file line main file line file line raise found split found test point something,positive
hi many use train model train model batch size many use reach accuracy many thanks,positive
hi note used last version block run got error distributed rank distributed rank host rank distributed rank host rank distributed rank host rank host rank e dictionary ar dictionary loaded loaded valid linear none none none none none none none none none none none none none none none none none none none none linear linear none none none none none none none none none none none none none none none none none none none none attention linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear model criterion model trained training per per none found loading train data epoch loaded loaded train notice device may support faster training epoch epoch warning overflow result range recent call last file line module file line file line spawn file line join raise exception exception process following error recent call last file line file line main file line main train trainer task file line train file line inner return file line file line key weight,negative
see point big regression basically model needing additional input wo usable generate maybe consider two method one pas additional used opposite switch among either new flag input new user decide think,positive
hi thanks reply try recommendation keep posted,positive
think issue making work import internal run see work,neutral
real exception numerical result range issue kind numerical underflow really clear happening unfortunately training stack trace caught lost try block posting real stack trace version error corner fixed master,positive
able reproduce master master try latest master,positive
thank try hopefully get result,neutral
need change line rather make loading working current time,neutral
thanks great work wonder code could,positive
problem trained code get exception conclusion,neutral
hi batch size total batch size use single either case trained vanilla nat training script bash task criterion arch noise dropout,negative
hi met issue batch size mean train multiple use train one use could provide training script many thanks,positive
found issue rather stupid issue sorry,negative
reproduction problem following roughly first training result,positive
think automatically convert without obvious issue set,neutral
bug due interaction submit fix,negative
ah found mistake assumed enough register model basic setup additional model thanks help,positive
bug well like line parser,neutral
measured performance still typical script output input shape upstream apex upstream half apex half example observe drop training speed per second,negative
right yes still used different setup regular summarization setup got slightly better performance positional last rather last used took look start assume start confirmed took look variable start padding sure index tensor,positive
could please synthesize discussion update,neutral
thanks lot help worked well got without much le overall code note together gave better least,positive
worth got error completely unrelated code due setting made error message go away code worked know side effect may performance related bug,positive
due upstream change fix,negative
correct multilingual translation task need calculate share two one language single model yes fine since use example important prefer namely need add generate command task en de,positive
ah somewhat legacy behavior use everywhere originally later added used everywhere yet unfortunately bit hard change since lot expect first token would nice make default language modeling task could manually set backward compatibility,positive
note missing equal sign update use able reproduce issue,positive
really easiest way would use python load separate model instance reason work need feed batch work call forward calling see,positive
yes understand pipeline language modeling beginning sequence counter intuitive wrong better add token,neutral
language modeling want predict next word conditioned previous word first word input token condition pretend source,positive
hello confirm following correct first time multilingual training currently python de en raw tee training python task arch dropout criterion raw tee work multilingual training result unable check validation training sure able calculate generation test set sure maybe wrong use multilingual translation said enough bidirectional system example done direction used training enough bidirectional system need perform twice like example also need use evaluation use generate sure bidirectional evaluation generate command,positive
thanks question try regression would expect quantization method work quantization particular used various regression method straightforward modification simulate training time model robust effect quantization testing thanks reply interesting talking quantization classification rather regression paper quantization done regression would great help,positive
work one like issue environment rather try running also distributed,neutral
good call intend based number validation rather update patience,positive
probably need use instead see future give custom name head,neutral
like bug specific submit fix shortly thank,neutral
hi fan thanks work story generation release code paper,positive
like bug specific submit fix shortly,neutral
probably want use general training default synchronous distributed training distributed data parallel something different filtering generally prefer default use run inconsistent gradient edit worked local private cloud sorry probably unrelated recommend running whenever working new environment ensure able communicate properly,positive
probably want use general training default synchronous distributed training distributed data parallel something different filtering generally prefer default use run inconsistent gradient,positive
problem install mode sure mean fine pip install directory user directory elsewhere outside,positive
thanks fast reply problem install mode example able resolve model tried path well arch import class,positive
example point still trouble share directory structure,negative
yes sure use come,positive
hi may ask script thanks,positive
got open like test unrelated,neutral
thanks lot try let know work,positive
thanks question try regression would expect quantization method work quantization particular used various regression method straightforward modification simulate training time model robust effect quantization testing,positive
yep exactly please let u know go open new issue run,positive
code write input sentence temporary file read back kind hacky issue temporary file written though relevant piece code try environment bit figure read back file even try something independent python open line print line,positive
thanks quick reply see mean data use make bidirectional,positive
tried regression intuition work similarly classification,neutral
multilingual translation code train simultaneously share example,neutral
normalize move beginning transformer block often model learn poor without could try decreasing learning rate gradient clipping learning rate keep index assignment like bug take look,negative
understand trying replicate score paper paper comparable output reference top normalization reference paper apply special normalization following wrong bottom line comparable score except prefer normalize remove output reference edit introduction paper improve setting new flores test later end section moreover combining additional gain resulting new translation really scored might doubt,positive
thanks reply use following compound splitting script able get question understanding following script compound splitting equivalent report final paper sufficient saw additional thanks path beam test gen cut gen cut ref python ref ref,positive
thanks reply also right realize gain trick modeling long quick,positive
line added following code state state,neutral
thanks saw always start copied random second half got better specific application random thanks would please share exact made model new longer sequence appreciate,positive
neither generate distillation set work student model always get validation,neutral
feature designed sample rate model data may want change feature architecture receptive field remains would try thank,neutral
inference longer document wo work summarization model model longer custom training data fact similar fine tuning use raise let say would need adjust positional either learning start copy first positional would recommend might require slight code know need help hi would please point code copy need task similar abstractive longer thanks,positive
feature designed sample rate model data may want change feature architecture receptive field remains would,neutral
need resample audio use model something tested clear well work though let u know use data train model audio feature work well reason bad performance give advisement model data audio data case use data way model work well data appreciate work thanks,negative
error hopefully see help narrow issue bit two one work one machine work initially setup machine error setup past week however work overwrite cache machine cache cause since machine work overwrite cache machine copy mar likely something perhaps mar today copy working machine unsure commit machine error version master master version o pip source cache showing version mar python version version machine error version master master version o pip source version python version version temporary fix wait use like try overwrite copy mar test content zip file practice use risk machine received environment update driver reinstall past week also machine cache identical,negative
getting error try generate score test set code error getting test set sentence,neutral
mean even manually seem sensible,negative
thanks response getting loss validation set,positive
would recommend training scratch speech,neutral
yes train dev test file independent overlap actually got train dev accuracy got accuracy test ideal situation accuracy test opposite guess exist swap label quite wired,positive
hello running issue afford try recent version anyone know exactly problem come thank,positive
thanks found issue really useful model however question remains reproduce translation meaning training base model data,negative
thanks fast answer plan release fixed,positive
tuned incorrectly add double check think current code option,neutral
thanks answer see used already evaluation modify evaluation script,positive
ran exact test script validation set get sure overlap train test set,positive
provide gist training log one,neutral
possible need number language either,neutral
model validation set give better sense whether model bad domain,negative
try example task path sampling beam type command generate rest even supply,neutral
ever solve problem exact problem sure wrong usage blowing batch clearing,positive
hard comment branch integration excited,positive
thanks feature actually list unfortunately waiting finish old code latest pointed main ape source class initiate instead empty please feel free make pull request implementation let u know need clarification implementation thanks add,positive
source truth open source internal almost everything well aware current user file address future version discus ready,positive
awesome keep eye new try help,positive
getting plan try push build opposed landing one giant commit first next couple,positive
ah presumably working sure substantive way help branch sure though hopefully gaining access slack soon discussion necessary,positive
yeah problem believe thinking address hack around meanwhile happy work well working side,positive
working would happy start making want make sure going die vine one caveat mechanism support semantics,positive
currently working latest version stay tuned,positive
paper target data follow example data python train python train task criterion arch dropout seed extract feed input favorite model also model directly loss effectiveness paper code currently relatively straight forward want try add code coming,positive
thanks got thing work,positive
figured original paper added code set true translation task enhance result,positive
find useful nice documentation,positive
new release major ecosystem circle back plan new release,positive
probably curious think encapsulation flexible library experience,negative
believe anyone gotten around trying feel free try report back,positive
version like commit added need use master latest release able pip install install latest master version,positive
algorithm section appendix paper like initial sequence involved calculation used evaluate loss sure existence difference theory implementation maybe extra data,positive
possible use prediction train model sure would model work task box usually kind,positive
please correct wrong understood paper modification actually much simpler modification thing change instead empty sequence output refined would amazing someone could though,positive
also want know thing,neutral
request well include capability could provided one could modify code achieve modify loss function,neutral
hi want use fake news detection possible use prediction train model case model recommend whether text fake news,negative
hello train new model example page code page include manifest python arch task cosine activation offset auto temp criterion seed get following error error unrecognized temp know fix problem missing something obvious new python thank,positive
need resample audio use model something tested clear well work though let u know,positive
ran dummy epoch save model code work completely wrong mean also getting insane perplexity like issue think fixed issue last night look forward soon issue start leaving randomly turn relatively extreme always sure next token would one,negative
time look deeply enough solve may incorrect believe problem use token language tag tag following set actually set prefix decode token force predict target language token first token set complicated index data optionally initialize trying paraphrase example use dummy language code source sentence since need target also uncertain unadapted model way train additional layer without model clear effect removing since pretraining made use short think modify code able use model way certain technical model course trying test reason issue,positive
data line line root directory prepare data change added printing run language modeling task task arch get fear anger pad pad pad pad luke father pad pad pad always pas learned pad fear path dark side fear anger pad pad pad pad luke father pad pad pad always pas learned pad fear path dark side left token weird padding token,negative
feel free submit said get temporary file copied actual path successfully complete think problem,positive
thanks still something understand pretraining procedure procedure different time still hub interface always add text since evaluation downstream done interface discrepancy however tried modify behavior consistent remove testing time almost actually bit believe impact minimal finally solve problem mean fine tune without token change test procedure remove token result perform well,positive
funnily done procedure use giving token id ran dummy epoch save model code work completely wrong put pause maybe support given,negative
pull request fixed issue,positive
time python arch dropout criterion beam model criterion model trained training per per none found loading train data epoch loaded loaded train epoch loss clip wall epoch valid subset example hypothesis know see example reference big recent call last file line module file line main file line main validate trainer task file line validate sample file line inner return file line sample file line sample model file line else module attribute,positive
available already thank great work,positive
trying adapt small model several done get work use order index index train one dummy epoch gain access file special use arch load model use code adapt need skip first four reserved pad need skip first positional due padding name param name param name param param else print name nevertheless still working getting starting like clearly something want anyone able load,positive
use command train want load language model path,neutral
command use train also please provide full trace error seeing,positive
hi trying reproduce work done find score import torch extra extra model model extra dictionary code mask echo code done source target finally model path model task translation train target source however getting weird output example name name home missing something,negative
hi like phase understand well mask padding goal fact added id label input label padding added label considered initial task like algorithm work well know already taking care anyway working fine sorry trouble thank help,negative
hi like phase understand well mask padding goal fact added label label label input know taking care already anyway working fine,positive
smaller available would helpful development even poorly,neutral
confirmed reproduce end specifically anything parameter forward method,positive
great thread come want pretrain scratch convert want inference convert right directly convert model thanks,positive
yes load revert thanks,positive
yeah got found problem directory command main directory thanks think issue documentation know thanks lot fast job,positive
clear running de en still seeing error file directory,positive
issue would text variable would enough replace everywhere text written type instead full directory yes tried still issue,positive
error seeing file directory calling command correctly see text variable empty getting lost call issue,negative
yeah sir command finished without listed sure issue,positive
command finish without listed last comment,neutral
yeah right second log come thought command whole previously problem command unfortunately,negative
confused problem command first error posted come second log posted come successfully following code,negative
tried substitute text variable everywhere still issue thing command run time come stage error issue file know version language en number version language en number train valid test,neutral
think problem text variable longer live run although hard say sure really familiar try de en,positive
yes sort fact based prefix order generate sort length minimize padding increase efficiency case interactive since front sort,neutral
merge master remove change avoid file frequently keep make transformer model aware beam search provide memory saving gain speed,positive
open remove argument option used model train correctly,neutral
mean work please follow issue template provide complete command full error,positive
correct method provide reproducible example,neutral
wall total start training point message logged time spent training,negative
resolved please open new issue still,positive
add specify temperature parameter call set get sequence generator calling sample,neutral
generating model proper like new york time actually present input text way control model output randomness mostly abstractive part like temperature parameter typical prediction code given import torch import open source open sline sline sline source print print sline count hypothesis hypothesis every th sample write hypothesis batch empty batch prediction done fill batch print count count hypothesis hypothesis,positive
contain well apply model text use provided,neutral
right fact seem unused also ca find use searching commit history maybe either way probably removed,positive
resolved confirm pull master,neutral
example paper training done trained assume effect batch size want get closer performance possible set update frequency yes understanding correct training would affect performance affect performance affect quality,neutral
specific command running output seeing please follow issue,neutral
also want translate single sentence time significantly,positive
yes get could translate sec test beam size could train used training,negative
share deal problem model work well thanks lot,positive
able bypass one commit issue understand fixed,positive
thanks revert besides breaking backwards compatibility also tie properly,positive
open issue regarding seg proper solution get resolved rather update telling people specific commit,neutral
thank problem spent day small issue,negative
sure pip different one instead pip install local run pip install ensure version install version,positive
since notebook following import drive pip install git clone folder folder drive thanks,positive
install python import print ensure directory new task,positive
hopefully new information enough,positive
find issue official issue ti ti python anaconda apex issue,neutral
yes said add dummy pad dictionary even multiple confirm looking last dictionary,neutral
please follow issue template specifically include tutorial following command ran paste full error seeing,positive
run error probably throw correct line course nothing wrong dropout,negative
following pad dictionary size multiple default added dictionary size multiple look bottom dictionary,neutral
able bypass one commit,positive
result met question trained distilled data got,neutral
yes pretraining included input data know document pretraining used mode wo cross document boundary,neutral
suppose since spoken many across world order differentiate language spoken region region code might mean spoken every region code ar would mean unsure part might mean source,negative
hi thank feedback worked git clone pip install one last question en sure language could kindly explain mean context variable thanks,positive
please install master check since last version commit,neutral
hi know fine tuning similar,positive
require install cause error build remove unblock build project remove line,neutral
yes think fine similar monolingual except change task translation translation,positive
interesting ran initially thought command line used loading maybe fact intended way use dictionary anyways,positive
sure need different able run code simply naming source target language argument reality language input output,positive
issue could achieve ideal result distillation afraid something wrong generation process could guide little bit running get lot meaningless image teacher model could achieve student model could even reach tried run,negative
hi trying fine tune work impressive appreciate help thank much,positive
hi trying fine tune would possible convenient would helpful thank much,positive
author repository tell language model definition perplexity really apply would get creative people tried also language model might good starting point search,positive
tried reduce set however still problem,neutral
also setup beam search size,neutral
calculate total multiplication addition number transformer test think reasonable,positive
found bug code probably thus,neutral
dear many thanks response question bad performance mean evaluate performance task performance performance worse loss look like pretraining loss good install source loss loss minimum pretraining official data sec length speech topic open topic script format audio original format little linear use convert original format use training number various result similar arch task cosine criterion arch task cosine criterion source ca training initial odd likely result epoch loss clip wall epoch valid subset loss also token ca arch task cosine activation offset auto temp criterion seed two result experiment train epoch loss clip wall valid epoch valid subset loss train epoch loss clip wall valid epoch valid subset loss,positive
yeah must issue like whatever gone good thanks though,positive
recent commit removed assertion line address core issue set incorrectly example vocabulary size two vocabulary index language call prior setting see example believe setting wrong commit understanding correct,negative
probably right case many read generation set fine read construct size,positive
recommend measuring source target sequence,neutral
use script underlying data already compound splitting score output directly score,positive
wherever directory need put code directory file see part,neutral
file get output otherwise way get cut cut,neutral
specify part facing error ca find part file must exist certain directory,positive
maybe could try used paper take part part could also create simple dummy synthetic check training procedure work well instance label number something like,neutral
sorry may key use uncased use cased wondering use cased,negative
export folder run see line saying built thanks,positive
indeed one label way present remove model another one time thanks anyway,positive
export folder run see line saying built,neutral
sure set set still work set,positive
bad performance mean loss look like pretraining format audio use training number,negative
paper keep model frozen actually extract dump disk model python see one follow directly obtain better,positive
bash use compound split,neutral
include paper report compound splitting compound splitting script also report without compound splitting use,neutral
take look wo time weekend,neutral
language model model support attention line mention correct disable option use,neutral
yes original though use different,positive
agree advice like command work fix look learning rate dropout different size please open another issue trouble thanks,neutral
provide detail please command running,neutral
put data looking like none,neutral
hello provide additional detail assertion error hit,neutral
original used example pointer generator paper uncased version cased realistic uncased reduce vocabulary size,positive
hi thanks yesterday path beam train python ratio output en de ran generate distillation good go,positive
think might related training data way feed ca help make sure always feed label training maybe one label way frequent could investigate remove label training,positive
confirm exactly beginning training end training yes converge towards positive value one class negative class si,positive
thread instead opening new one think two might related training enter print work batch size know affecting translation quality could wrong,negative
try follow path input output try see different output different,neutral
confirm exactly beginning training end training,positive
error import name run python already find file,neutral
source like build source folder source get find anything wrong,negative
hi worry actually training loss decreasing untill certain point,positive
small original work model evaluate translation however please feel free submit review merge hi task trained model according based corpus according repository work transformer contain could please give hint obtain model loaded task tried find repository work either know thank advance code sample data used translation like train train script like criterion dropout arch task run training script following trace recent call last file line file line main file line main model file line return super file line return self file line return task file line return super task file line file line return file line file line key transformer contain load transformer,positive
source like build source folder,neutral
hi sorry delay check model change training see training loss decreasing constant,negative
dont think particular reason please feel free submit change behavior,positive
remove reduce weight decay switch cosine sweep size,neutral
thank response want know define sequence generation problem sequence generation sequence higher longer sentence,positive
went bit latest version running get error half running bash number training linearly increase many peak polynomial batch size random seed use option load task directory accuracy task arch dropout criterion simple seed seed,positive
yes could verify error sorry iteration part,negative
huh good catch fixed model please try,positive
used original data reproduce found,positive
trained large batch size final train perplexity valid perplexity like may trained bit longer share training log default use compound splitting need apply manually,positive
ah thanks flagging mistakenly broke submit fix shortly,positive
unfortunately think difficult general way wo able support native feature said used work great downside pain setup also need define manually attention,positive
thanks much know work shortly model supposed work better one paper actually,positive
release model previous work shown bigger model size help deal issue interference training multiple deal recommend looking gradient trade compute memory yet generalization abstraction look getting future recommend trying get gradient working fitting model memory,positive
thank clarification tried initially ran evaluation model exactly score float model may suggest model replace one model new variable model iteration try model range believe get error quantization sure current version able run inference mainly great someone add support quantization happy help,positive
thanks quite sense direction tuning tried fix batch size faster training speed got random well direction setting many thanks,positive
unfortunately current solution improvement please make pull request,neutral
please follow issue provide additional detail,neutral
compound splitting please follow,neutral
really important suggest tuning,positive
thanks yes usually data separate script though link together training script also data believe,negative
currently nice inbuilt way handle would really interested feature,positive
hello source special dictionary start sentence order always beginning see added check file,positive
like code allow input output language need different since used differentiate input output data code leaf wondering reason done normal translation script anyways got work following file allow input output language,positive
hi also received issue sample phase worked appreciate,neutral
according author provided link used distribution one provided author apply additional applied exact,positive
tried path beam train result file anywhere found generate distillation,neutral
hi reduced error script still result could help sure actually,positive
could please share generate new distillation training teacher tried path beam train end told memory result anywhere,positive
pull request need tested,neutral
yes pull request tested would like test locally could firstly run bash python start server bash python text speech port,positive
yeah different coming something like like thanks much clearing,positive
necessary good performance data perform something convenient way experiment like,positive
like least issue specifically think property correct stack trace missing bias term file line module model file line file line file line state model file line return super strict file line error loading missing key edit original projection bias way default safe add newly added linear since ca push git index cab class else dictionary dictionary self class name name name name name,positive
like might backwards compatibility tried loading model test script cat python import torch import import import dictionary open model generator generator error recent call last file line module model file line file line file line state model file line return super strict file line error loading missing key,positive
hi thanks already tried running docker inside without file pip install work fine seem work user solution fact pip install working option thanks,positive
like right try pip install user pip install user,positive
consider base model architecture,negative
added model model seen ideally differ get may count indication model printed model instead linear everywhere correct variable get used gone code also flag removed run error think recent commit quantization intended compatible torch release since listed experimental torch maybe dong know better,positive
hi currently part maybe new,positive
got similar issue copied code template wo generate longer sentence except,neutral
thanks update mind code change example make sure model original one make change related like new commit yesterday related quantization tried still stuck error tensor element argument got method great let u know right way quantization thanks,positive
looking source lid token end source sentence correct need use language code python none none presume lid token serve set context properly,neutral
example trying use model find score input get work translation task however sure correct first clean model paper extra likely architecture paragraph section paper also include additional layer top found training precision likely dropping easy remove following script python import torch extra extra model dell model extra next manually add language dictionary bash code mask echo code done model work translation task suppose would like use model find score sentence one append language start end like bash miss miss miss low vocabulary quite large would prediction first token high removing language entirely much higher bash miss miss miss hard know right call perhaps language used actual case one would adapt task around quite bit one take care since task permit scoring box two distinct work would helpful technical guidance exactly model perhaps would easy question answer,positive
look beginning project would great benefit avoid lost thank much help,positive
tried package reticulate call python stuff find web page,neutral
though generate one token time token generation side time would decrease regressive supposed decrease overall time since made linear also linear got error ran transformer model ran could run available fine without error,positive
master added test anything else make,neutral
master want add separate function make clearer support sequence classification separate,neutral
could please help review reduce memory size used attention original size enable increasing batch size get generation speed,positive
thank let u see author,neutral
think bug code rouge work side currently help try see result add line add let know go,neutral
thanks mention score point higher great still point paper raw update issue receive author respond yet idea point difference might come,positive
ah create object interface work need use,neutral
hi copied error error command exit status command open compile code develop user complete output running develop warning user directory disabled error ca create remove install directory following error trying add remove installation directory permission installation directory via prefix default setting perhaps account write access directory installation directory directory may need sign administrator root account administrative access machine may wish choose different installation directory preferably one listed environment variable information may wish consult documentation please make appropriate system try,positive
certainly try many learn audio would good starting point look,positive
add profile result one transformer layer change batch size cost per layer first part computation sparse image change batch size cost per layer computation dense compare use small batch size image,neutral
generate command designed translation model original question principle reason able decode model original question ask model used,positive
argument training trying model work instead trying use model flag,neutral
hi favor line add step else let know rouge data line thanks lot,positive
got raw text one get one get better number sure revert data raw text,positive
thanks yeah understand point path avoid architecture error however none saved part still getting missing key error thanks continue,positive
wonder paper get work even get work,neutral
hi explanation gave file happening case different process generating list written file,neutral
use text similar used language modeling text code use get appropriate instance,positive
yes training often contain noise want help tackle problem task filtering parallel,neutral
hi since used yes far remember sending change make order missing key go away believe point default model different need pas,negative
happy give shot data work perhaps,positive
dont think try train another network audio would interested see whether work tried,positive
passing fine command better use generate command designed translation model,positive
hi validation score know use tried add command like work error like attribute,neutral
yes understand least able run gave example switch still tell model true argument internal model creation parameter model similar source confusion come pas list language instead model dictionary,positive
need true solve sorry dont quite understand tried tried run generation model model model copy never learned translation,negative
hi issue pointing change issue understand problem model state,neutral
quite resolved particularly seem change main model one share insight change,positive
thanks much help finally got everything set,positive
run virtual environment trying install globally,neutral
leaving open long decided go got error building wheel build eventually work wondering run line,negative
like original contain language,positive
want issue understanding default ensemble list need change individual transformer evaluation model however ran inference model error forward method tensor element argument got method documentation like trainable layer wrapped via file properly access got error output could run available mean quantization yet run quantization simulation transformer thanks advance,positive
state would resize copy trying fine tune modification start training convinced sense python state state state related setting,positive
thank much great fix,positive
yes generate example remove continuation would give incorrect score,neutral
seem find solution link worth try working set training accuracy going first epoch loss gradient descent training validation result end average training accuracy average validation accuracy epoch loss clip wall accuracy epoch valid subset loss accuracy saved epoch writing took done training test result end average test accuracy valid subset loss accuracy valid subset loss accuracy valid subset loss accuracy valid subset loss accuracy,positive
hi try use model speed quite fast final result like random selection seemly find solution link,negative
true even speed unable convert module format please feel free share,positive
mismatch one inference none included model see probably lost key error loading saved simple fix setting calling better,positive
someone else problem however none point solve issue owner work still get error missing part print contain make sense however model built need loaded get model get somewhere please let know thanks,neutral
obvious namely file must exist sorry,negative
thought would easy comparison project working could figure time respond point second paragraph,positive
expect lack either obvious step one ever likely,neutral
python file command line file,neutral
tried used following snippet print current memory calling import o humanize define function print ram free enumerate print mem free utilization execute function,positive
understand ca thus could train get benefit right,positive
thanks ever get bottom difference,positive
fix random seed beginning script python import torch import count open source open sline sline sline source count hypothesis hypothesis count hypothesis hypothesis,negative
see use sampling beam reproduce code,neutral
matter reproducibility standpoint junk data,neutral
thanks reply either change stage combined dictionary generate individual dictionary,positive
lot activity end exciting transformer though misremember might try next,positive
thanks flagging look internally actively working full transformer code path still missing,positive
model model able reproduce model sh cat hello name sh cat import torch count open source open sline sline sline source count hypothesis hypothesis count hypothesis hypothesis sh,positive
worked basically major issue whereas run inference code generation wrapping problem idea intentional think instead training may coming different set use perhaps clear explicit flag though le important reduce model size though would still good know way,positive
import torch import nothing yes get different hypothesis run count open source open sline sline sline source count hypothesis hypothesis count hypothesis hypothesis,neutral
bit confused code saying run script twice output file different hypothesis,negative
yes put count print done open source open hypo sline sline sline source count hypothesis count hypothesis,neutral
anaconda prompt anaconda need set environment variable another way,neutral
run command prompt internal external command operable program batch file probably tedious never really dealt,negative
work try pip install install master git,neutral
yes compile code default personally use regularly fixed installation process work master,positive
also may ask even compatible probably stupid question ask booted virtual machine trouble setting,negative
thanks posted error message spotted give go come back trouble,neutral
error need visual work pip install,neutral
well unclear since reverse direction work perfectly identical obvious,positive
e en dropout arch path beam,neutral
run first training mode dropout still leading,positive
got problem training variant transformer big model hard reproduce since running multiple yet one got error timer since tried used ensure first line hit even error two seem serve finishing current training original code felt like hardware bug,positive
learning rate often need depending current batch size even bit original one good different seed work went lower peak learning rate still running seem great lower learning rate fine want fairly large,positive
small memory could even fit batch size memory sample size reducing length le space memory fit batch size reduce expect score decrease,positive
thank reply may ask one question reduced average length reduce,negative
think since model trained generate instead,neutral
configuration task translation source target true true true true true true arch criterion dropout true true true true create new model kept first position import torch model print model model print model model model model model model model model model model model,positive
show entire script used train,neutral
check good luck tue mar wrote long time ago remember exact problem clearly might need wait respond alternatively could post code let examine go wrong reply directly view,positive
long time ago remember exact problem clearly might need wait respond alternatively could post code let examine go wrong,negative
believe model cat cut never score close,neutral
hello could tell issue thank,neutral
could use output generate see sample translate input,neutral
criterion define default metric example want maximize,neutral
hi support training provide output also train command need en variable order properly since particular,positive
different seed work went lower peak learning rate still running seem,neutral
many thanks code running total memory replace cutting half one issue speed running quite slow suggestion appreciate lot,negative
found solution run python source folder built besides use need set path take time first python pip install index second must set path order put export path export export driver path final source,positive
see make large possible without blowing memory training model replace training step,positive
think data one direction follow naming create symbolic link direction avoid data,neutral
single ti also memory,negative
found solution run python source folder built besides use need set path,neutral
kicking road use instead sure much also try cutting half though sure actually memory usage worst case scenario could clear cache regularly slow training,negative
hi thank much feedback exactly agree full training command number training peak fixed batch size per accumulate simulate training accuracy task arch dropout criterion fixed,positive
please post full training command good chance need decrease batch size tremendously small memory allowance,positive
hi trying language size million use command still unable train due memory error trained even single ti ram please confirm ram would sufficient training data size see across two even inform memory training thanks,negative
seem like input see training example,neutral
like trying run python cell add beginning command command accuracy task arch dropout criterion fixed,positive
issue making source code,neutral
helpful trouble following final solution ended original script intermediate result thanks,positive
yes need data want translate look,neutral
hi trying use translation doc said decode training set produce distillation could give hint obtain distillation train model,neutral
based stack trace like trouble loading model architecture state match put check misalignment could thanks reply beginning previous log probably loading maybe initialize added component fusion model missing related log process recent call last file line module file line file line spawn file line join file line wait recent call last recent call last file line state model file line state model file line return super strict file line return super strict file line file line error loading missing key weight bias weight bias weight bias weight bias weight bias weight weight bias weight bias weight bias weight bias weight bias weight bias weight bias bias bias bias bias weigh bias bias bias bias bias de bias decode bias tention ion bias bias,positive
based stack trace like trouble loading model architecture state match put check misalignment could,negative
per try model different seed however similar problem associated modest batch size limited reasonable see loss bigger well perhaps something else going,positive
left pretraining running overnight also added flag sure enough halfway epoch start increasing eventually get error message process following error recent call last file line file line main file line main train trainer task file line train file line file line minimum loss scale loss probably try lowering learning rate gradient clipping increasing batch size training output stack trace epoch warning overflow setting loss scale epoch note batch size learning rate well peak learning rate original paper really need gradient clipping right,positive
please kindly help stuck thanks,positive
please help u stuck,neutral
think right thanks pointing function never yet since model able translate anything,positive
thanks yes understand also reason solution yet need custom multilingual order achieve least need pas something function like prefix proper subset logging new feel confident breaking change hence comment think language level let know help anyhow thanks,positive
thanks quick response currently training removed know loss increase issue sometime tomorrow,positive
hi thanks deprecation little bit hard get language pair level information function look better add functionality back,positive
facing issue trace forum discussion torch help edit worked local private cloud used following help export export export export please suggest way help possible like connection issue right place ask thanks,positive
another clue import task python file directory suggesting something like need figure data help much,positive
also tried create new environment fresh install redo model fusion command try interrupt program ever anything like problem loading note exactly previous step log trying manually interrupt program weight bias weight weight bias weight bias weight bias weight bias weight bias weight bias weight bias weight bias weight bias ing weight bias weight bias weight bias weight bias weigh bias weight bias weight bias handling exception another exception ready recent call last file line file line select file line file line main file line main file line main trainer file line main trainer file line file line please ensure match file line file line please ensure match exception load model please ensure match handling exception another exception recent call last exception load model please ensure match handling exception another exception recent call last file line file line run file line file line put file line offset offset size file line file line file line write file line run file line file line put file line offset offset size file line file line write would appreciate thought,positive
yep glad resolved get would need specify easily good point track,positive
hi guess open issue see error staring right face used much copy paste learn new tool get would need specify easily,positive
kind model trying quantize like trying speed translation since lot due overhead beam search since generating one token time issue since whole input entire output thus generally see bigger translation language modeling try implementation see get,positive
right previous version master branch fix sorry wasting time thanks,negative
fixed use indexing everywhere see wrong value printed master,negative
remove flag filtering want may also total batch size small also remove faster default value find strange output low assuming output batch size counter cumulative batch size across may wrong,negative
thank help able get comparable first working loss scale get smaller train epoch loss clip wall valid epoch valid subset loss saved epoch score writing took note overflow setting loss scale train epoch train epoch train epoch note overflow setting loss scale train epoch loss clip wall valid epoch valid subset loss saved epoch score writing took note overflow setting loss scale train epoch note overflow setting loss scale train epoch train epoch note overflow setting loss scale train epoch loss clip wall valid epoch valid subset loss saved epoch score writing took test solution worked fine,positive
sorry understanding change fix also regression logged language level something done purpose thanks,negative
see instead right multiplier batch size ah good point exactly loss overflow mean causing overflow consequence happening refer big overflow range use dynamic loss scaler scale keep reasonable range avoid overflow loss overflow indicate dynamic loss scaler working sometimes get bunch row usually loss perhaps due high learning rate small batch size dynamic loss scaler scale loss compensate ultimately raise exception scale minimum threshold default case training pretty large high update frequency well thus likely hit cause loss scaler get small think may fine case adjust minimum threshold also loss le mine first training log please make sure get comparable train epoch valid epoch train epoch valid epoch train epoch valid epoch train epoch valid epoch train epoch valid epoch train epoch valid epoch train epoch valid epoch train epoch valid epoch train epoch valid epoch train epoch valid epoch,positive
could perhaps clarify exactly loss overflow mean causing overflow consequence,negative
ah sense able adjust alignment accordingly thanks lot,positive
hi see instead right multiplier batch size,positive
code case want reuse speech curve import import import data plotting al fig ax al al,neutral
original paper pretty widely used day machine translation represent much vocabulary without training separate every word variant example instead learning learned might one learn common ing symbol token token safely removed alignment might look paper jointly learning align translate transformer reference implementation one thing paper section write used work learn joint source target al merge observe even statistical alignment beneficial convert back consider target word source word alignment target source,positive
please would really appreciate,positive
looking ever potentially fact member constant perform single step merge end adjust alignment accordingly sorry question code dictionary completely new far code like raw text sequence sequence dictionary index sequence model interfere dictionary paper would interested,negative
hi thanks quick answer help awesome added similar local installation also original hypo honest useful would like use alignment text problem text still weird readable possible get alignment version read code far see completely independent anything alignment related maybe way get kind tracing token becoming version,positive
someone recently transformation class structure one quick dirty way make work adapt model load model instead loading file example,negative
able test statement run command fix,positive
believe work since different class structure nonetheless verify got recent call last module task task strict raise model file found state state path state none,neutral
see problematic line instead hypo,neutral
removing target side printing comment line get bird tree bird tree un submit fix,neutral
sorry exact duplicate issue,negative
easier way reproduce execute following terminal curl tar path beam en example enter bird tree curiously hacky code version different contain range given,negative
browsing made rewrite last line sample method like sample self list beam verbose bool false list return sentence sentence beam verbose return list zip return translation alignment line code please note though still work pas one,negative
huh upon exact problem would like use get found like printed verbose set true tried following sample code import torch world error message object attribute,positive
file must directory first argument import print path file,positive
turned ram issue ram got full much ram,positive
may please help thanks,positive
take see count take entry replace special token also add line token split image,positive
infrequent frequent used show multiple part word example may split single long word bunch anti dis note end word,negative
fix please reopen still issue,neutral
generally need set something like work task arch,positive
good question long time ago found slightly reduced peak memory usage since sometime reuse memory instead new memory said soon removing manual buffer management sequence generator code bit play nicely,positive
thanks learning rate low learning rate result good announce,positive
sorry directly could please comment want feature accept,negative
thank think made mistake trying,neutral
error say please build pip install python,neutral
like projection vector gradient become setting little better since prob perplexity longer straight still ca get loss,positive
anything need help recall one le controversial open,positive
see already probably issue favor thanks,positive
could please help review,neutral
thousand right master half tag weird know yet many code since,positive
best maybe result best code number group,positive
hi tried training shown example pretraining scratch error command run dummy test run fine several though idea error might tried adjust batch size error always occur last batch epoch thanks train epoch train epoch train epoch train epoch train epoch train epoch check begin stack trace end stack trace recent call last file line file line main file line main train trainer task file line inner return file line train file line inner return file line multiply preserve device check,positive
good question currently exploration training noisy data somewhat complex specially low resource exploring direction unfortunately ca give many find direction fruitful definitely code model like,positive
need set otherwise default given file control length generate input output length size source input,neutral
use another language similar hyper tried also author used,neutral
think definition scoring compute overlap word may good metric longer maybe used task case true positive would word hypothesis reference regardless position use check membership either reference hypothesis member instead even sure scorer basically stripped implementation left completeness one could implement full rouge scorer instead prepared pull request need run translation example see everything work currently running might take little,positive
thank hope somebody find feature useful,positive
yeah think issue system run successfully local machine ran run running,neutral
thank offering help test failing documentation problem one,neutral
set reference set hypothesis token hypothesis token else rather unsure calculate based set operation position token also relevant end true positive model predict correct token given position,positive
running loss task criterion task criterion get huge difference validation accuracy best guess learning rate need,positive
great also set exclude short crop longer automatically,positive
understand problem issue problem set true default false hence update issue description problem difference related try find fix next day familiar part code anyone else come solution please go ahead may take time sure would come possible solution think problem support switching back label bug think evident bug change,positive
thanks answer work criterion without criterion underlying criterion issue rest normal translation task transformer model command python en arch transformer dropout task translation criterion command issue description problem consistently custom part criterion actually similar expect affected issue hence confident bug question extend unfortunately yet able understand root cause anything investigate open suggestion thanks,positive
sorry really know going instead model file directly untar load python import,negative
small original work model evaluate translation however please feel free submit review merge,positive
far remember difference given task binary classification task give second task much harder first one think matter task definition mismatch paper,positive
custom usually code pinned memory causing initialize work use criterion without rest,negative
code snippet good see training stop like default keep training indefinitely add train alternatively could set early stopping patience patience terminate validate loss go consecutive,positive
send data data model time especially following line idea use loop check whether present sending network,neutral
thank right documentation sec many many lesser duration file exclude audio duration lesser greater training without error modification,positive
sorry saw worked commit may know thanks,negative
general interface gotten messy working cleaner one soon time get thanks,positive
think maybe go route might promising route something like python import class class pas class self pas intentionally object structure without coupling tightly,positive
problem wo way use go route basically work together,neutral
another option defined present one line code self must explicitly parser,neutral
update combination flag got training thinking something might still weird work right,negative
still ca install user flag think code getting following error process following error line input match target however training distributedly across two get fatal error inconsistent try already flag set removing seem end dead situation original post ca use solution get object attribute problem also ran across two collective work also gradient inconsistent error thank,positive
like error recent call last file line module file line load model entry file line file line file line file line return file line first file line file line next file line seek return offset whence file line seek data min offset file line read data size invalid data stream,positive
original criterion design already add specific sure current change necessary bug please ignore shown actual commit different shown notably end also backward compatibility,positive
sorry catching agree need careful several currently everywhere need careful break code base class replacement make code continue single helpful continue support hope make easier use library motivation let people initialize use rather supporting usage,negative
wish way make stuff bit easier mostly full suite take right slow iterate working internal making faster may take done,positive
unfortunately able install source work pip install user,positive
great idea would mind,positive
yeah error strange able reproduce try share entire log see run,positive
thanks feedback bring next meeting share discussion back object doubt make rigid declaration either way number small sense enumerate added flexibility passing around single configuration object helpful rapidly trying new idea like leave decision task author note also support similar probably want support sense better totally agree beyond scope hopefully highlight better though translation inevitably function definitely provide fallback option require,positive
thanks review anything else push forward thanks advance guidance,positive
getting issue place also ahead echo echo source,neutral
personally like object number unmanageable apply begging better abstraction think conversation useful believe thinking constructor possible constructor refined would useful,positive
automatic like last option mean inevitably function every time make new task instance current translation task never used work many specific,positive
work mask last position matter,neutral
ah due recent change need load fresh copy,positive
hey ca enough pull new one one easier review,positive
awesome look log failing everything looking good also kind integration require find,positive
thanks agree way much current task read modify iterate motivation support library currently difficult around clear used component one way handling huge downside approach form added evident eventually original motivation everywhere make fast add experiment new configuration crucial research productivity one might add dozen configuration new idea need strike balance two describe would love feel approach work well like functionality thus example automatic argument require code add new argument criterion two complicated like uncommon current implementation automatic argument time twice reduce let consider code add new argument task current system one line code parser current four code self self parser return return automatic three code self self parser automatically map automatically reconstruct two code self self parser automatically map would defined base class self automatically populate used return people think last option,positive
observing message single dropout option dropout last recurrent layer dropout greater got dropout library found check please use instead meter,positive
also interested know token valid approach loading also mask token position,positive
use following method extract way dictionary special three usual task add pad,positive
yes loaded dictionary class,neutral
hi thanks answer mean yes exactly try simpler training command start need install source try something like unfortunately able install source could however use script tutorial trained across communicating also tried set export still get similar behaviour trying use instead,positive
answer load given directly use following method extract way dictionary special three usual task add pad,positive
unless actively find take care code foreseeable future,negative
think unnecessary everything hard read change maintain previous especially,negative
yes understand think super unnecessary everything hard read change maintain previous especially,negative
interest go training first need run following script convert python split train valid test extension follow first part answer,positive
giving example every component well see,neutral
make exceeding clear someone interesting want use code currently way unless mock argument care argument much like loss component outside main function,positive
share full stack trace think file part thank quick response attached import torch cache found cache found recent call last file line module file line load model entry file line file line file line file line return file line first file line file line next file line seek return offset whence file line seek data min offset file line read data size invalid data stream,positive
anyway still think good idea remove build current may lot need input otherwise easily get complicated model clear since already accepted left,positive
share full stack trace think file part,positive
difficult read maybe consider something difficult work think agree,negative
two able communicate properly say across mean try simpler training command start need install source try something like python task arch criterion,positive
also function also difficult read work,negative
ca pas constructor directly,positive
think much easier pas might defined outside,positive
think one ready wish way make stuff bit easier,positive
dramatic appear basically code toward best lot benefit downstream testing consuming,positive
basically class criterion self nothing criterion code nasty code hard test hard use production brittle,negative
sure mean need one create criterion think design freedom add different,positive
original criterion design instance variable need one create criterion inconvenient eventually add proper configuration,negative
understand original criterion design already add specific sure current change necessary felt made code even,positive
purpose change divorce want use outside basically interface minimal change keep compatibility previous interface offer perfect backwards compatibility yet subject change small amount,positive
hi purpose change might cause user defined criterion broken,negative
able reproduce confirm output python import logging pip show location first command exception probably instead master make sure clone source run pip install,positive
sorry thought question train use omit specify full file name python get specify train model following providing path data path load model iterate text file something like,negative
thank prompt reply possible negative positive selected sampling happening think per epoch mean given example positive negative selected example example two positive two negative namely example independent training training,negative
thanks could update function like based return map interest go training,positive
still something like following context answer candidate answer candidate extra model sample extra model sample sample loss possible negative positive selected sampling happening think per use also use let know unclear,negative
right one use chance probably need adjust locale try,positive
tried train base feeding following pipeline saw beginning sentence end sentence similar perfectly pipeline pine line add begging end,positive
run following command python train two order extract,neutral
extract text file run regular text file specify point file tar otherwise construct new wont match trained extracted corresponding file dont use python train valid,positive
sorry saw spectrogram extract shown doc feed system youd like work tried also,negative
specify different sample rate argument audio via simple interpolation dont expect great sample rate certainly use want might want adjust architecture keep rate else see different rate work well,positive
error odd check data make sure dont super short,positive
sorry size bad ill update soon,negative
shrink size lose like thank reply aim experiment compress model quarter original size done model training model scratch however effect exceed method full version experiment encode layer drop rate decode layer drop rate encode full decode full encode full decode encode decode encode decode encode decode encode full decode encode full decode encode full decode encode decode,positive
please let know able extract audio wed mar wrote closed reply directly view,positive
excellent work thank much,positive
first remove pip installation emotion source folder work,positive
thanks reply tried clone error,positive
get exactly following error ca decode,neutral
oh said originally score produce model give yes figured accordingly thank much,positive
idea open new issue new issue please,positive
oh said originally score produce model give,positive
need use model please see,neutral
note section run run thus training effective batch size time parameter would correct course action increasing use yes exactly train use,positive
turn pip install torch bad incomplete installation instead issue install,negative
awesome continue legacy thank fire,positive
yes exactly pick working next couple day,positive
thanks looking complete reproduce scratch create name source activate pip install torch torch successfully git clone pip install successfully python help recent call last file line code file line file line module import file line module import file line module import file line module import metric file line module import torch file line module import file line module import file line module import file line module import file line module class file line forward self input file line file line module attribute,positive
torch able reproduce try torch try bash python help,positive
pip version behind run,negative
try keep full size shrink size found important shrink size lose like encouraging want better model try something like doubling size keeping size fixed,positive
large training training time strong regularization effect apply small much would expect reduced performance tested large scale recommend training smaller may also turn amount normal dropout regularization well recommend reducing least large training another model arch report result soon hi tested recent result thanks result experiment affect effect model say original model model also training however layer effect decrease significantly encode full decode encode decode encode decode encode decode encode full decode encode full decode encode full decode encode decode,positive
also checked model use similar small architecture,negative
also following pipeline used first pipeline extract send though given clarify also use dictionary given inside folder also architectural information given,positive
hi solve issue previously successfully built source check local setting see possible cause thanks,positive
yes exactly patch fix handle,positive
may still solve problem difficult differentiate start training end epoch since initial epoch rather training due similar,negative
last link exactly looking thanks thought would capable well,positive
unfortunately really masked language like making classification sentence sentiment could try something like feeling hungry mask mask mask mask need search various mask think looking standard masked language model,positive
large training training time strong regularization effect apply small much would expect reduced performance tested large scale recommend training smaller may also turn amount normal dropout regularization well recommend reducing least large training another model arch report result soon hi tested recent result thanks,positive
like issue installation since import please reinstall,neutral
want try branch hopefully experiment run,neutral
trained classification head first want classification head though want sentence prediction like able complete sentence example input feeling hungry output shall eat banana understood correctly first link tell train classification head would mean would whole vocabulary class next word second one sentence pair classification class think related sentence prediction looking like mask replacement except instead mask one word replace whole sentence,positive
trained classification head first try model head,positive
like quick fix want take,positive
thanks bug recent depend submit fix,positive
thanks good catch remove option way dictionary generate new dictionary update,positive
operation cause identical minor thing replace work expect,negative
added detailed understanding scale paper,positive
switched single suggestion still getting error warning ran memory exception guess default model regard first used around number tried still getting stuck error suggestion also would please elaborate note input reasonably long introduction part scientific,positive
model longer custom training data fact similar fine tuning use raise let say like quite different domain average sequence length input support order handle,positive
yes perfect merge update well thank,positive
issue actually regarding folder full change another location enough empty space worked build source done successfully,positive
issue related use validation task translation loading different consistently get lower validation training get run task validation idea open new issue,positive
line first sample batch logged printed could print log everything specific file point,positive
command working pretraining multilingual model could post,neutral
thanks script loop valid multiple valid need run like also update want make sure think de en,positive
technically add would filter number,neutral
found somehow hacking way import torch foo translation task world work,neutral
added legacy interface sort mind,neutral
got error trying reproduce default task initialize able solve problem model manually model following import torch import get error set,positive
failure unrelated know anyone help thanks,negative
hi find incredibly high log probability every summarization confused score model generation reference believe actually probability model generation compute also variable sort generation reference used target purpose whole inference code snippet see text summarization seem source gold reference input sign task differently missing something evaluation code snippet count open source open sline sline sline source count hypothesis hypothesis count hypothesis hypothesis essentially wondering gold reference instead model,negative
hi thank really enjoy working logging decided add currently testing hope find feature valuable,positive
task ca adjust since used initialize positional manually tell batch generator generate smaller change line something smaller generate smaller token,neutral
mind fix think idea produce separate validation rather combining one probably need change loop validation set,neutral
assuming underlying setup almost definitely one causing let discus,neutral
really related failure happening immediately distributed probably need reinstall,negative
every training flag model usually access see training mode example look use functional form dropout,negative
one implementation option issue certainly sense probably better think interface first,positive
going use hugging face library also possible compatible,neutral
filter long warning seeing bout filter chop length way still learn something meaningful could le gave size since large probably dimension homogeneity explicitly hard code integer le work case without breaking explicitly,positive
awesome happy like light lift hard decision making made front also make tandem like associated commit given impression translate going merge eventually suspect need keep lock step,positive
model criterion model trained training per per none,neutral
accumulate multiple affect memory usage batch size per lowering avoid also control maximum sequence length default adjust probably help long fit filter long warning seeing curious running memory though many model logged right model printed,positive
recently added hope around various added first love guess would need add model wrapper modify task,positive
hi added thanks help resolve however constantly get ran memory exception memory tried allocate mib gib total capacity gib already mib free mib warning recover pas still issue way bypass understand batch size give invalid size whats best way handle,positive
thanks pointer really appreciate try soon quick question time estimate like long take step epoch based test run node would great could test see match,positive
script following change git index ce echo valid data seg done done,neutral
yeah thanks work getting first one took bit longer discussion right way maintain backward compatibility key providing legacy version base class example super helpful add general hope next easier merge,positive
thank guess lucky way,positive
historically running average epoch thus drop epoch recently behavior average recent log interval instead right commit still average whole epoch,positive
jump loss function every epoch screen shot,neutral
woo glad see land thanks see lot work anything want push back please hesitate,positive
cool thanks testing please try latest version get use task make sure working fake data bash python task criterion arch later try real training run python task none criterion arch dropout note need set pas flag proper mixed precision training currently set none batch exactly every batch otherwise get lot slow significantly might reason set value since lower slow note shrunk amount multiply get real figure setting higher good lastly still much broken get good example recently discovered bug gradient calculation giving bad latest version could,positive
working export solution simplified sequence generator work like transformer still testing,neutral
file chop source target greater note append symbol need truncate anyway still limit size either exceed option work source side could extend work target side,positive
yes bug fix correct submit shortly,neutral
hi really interesting although still decided give try cloud pretraining model please let know could help testing thanks set per node give try following script export export export note optional total number training learning rate many peak learning rate adjust sequence length positional usually increase batch size python task criterion arch complete dropout simple however forever like following model criterion model trained warning invalid size first sample warning invalid size first sample warning invalid size first sample warning invalid size first sample warning invalid size first sample warning invalid size first sample training per device none per device found loading train data epoch loaded loaded warning invalid size first sample warning invalid size first sample warning rank warning rank warning rank warning rank warning rank warning rank warning rank warning rank warning rank start warning rank start warning rank start warning rank start warning rank start warning rank start warning rank start warning rank start data type floating point data type floating point data type floating point data type floating point data type floating point data type floating point data type floating point data type floating point overload number alpha tensor consider one following instead tensor number alpha overload number alpha tensor consider one following instead tensor number alpha overload number alpha tensor consider one following instead tensor number alpha overload number alpha tensor consider one following instead tensor number alpha overload number alpha tensor consider one following instead tensor number alpha overload number alpha tensor consider one following instead tensor number alpha train epoch warning rank start warning rank start warning rank start warning rank start warning rank start warning rank start warning rank start warning rank start train epoch warning rank start warning rank start warning rank start warning rank start warning rank start warning rank start warning rank start warning rank start,negative
yes exactly thank good feature,positive
often get stuck failure one rest still get stuck use single lower batch size,negative
however paper state see section paper table result adaptive achieve perplexity result partition training data contiguous instead believe model multiple per get split across per two effectively double loading model saved arch mostly ignore arch value since configuration elsewhere look directly,positive
sorry delay still soon,negative
way export completely like,positive
working probably want adapt function got thanks lot,positive
used trained model also,neutral
em see problem another trick make number higher add two force first token force second token,positive
follow data linked issue,neutral
added example made realize might tricky use sequence since provide label input token hope enough also added convenience used classification way name task instead since already,neutral
sorry keep since tend hot see anything need order merge prevent reimport loop,negative
like bit hazy wrote sorry,negative
working probably want adapt function,neutral
