id,original_comment,processed_comment,source,sentiment_VADER,sentiment_textblob,sentiment_pattern,sentiment_bert,sentiment_spacy,max_voted_sentiment
2039778044,"<!-- documentation preview -->


Documentation preview for 17197882c12db5e0c8cfa29d1cac2070657432cc will be available when [this CircleCI job](https://circleci.com/gh/mlflow/mlflow/99036)
completes successfully.

- [Top page](https://output.circle-artifacts.com/output/job/3ad204f2-5f68-4e69-bc75-a4262d81b338/artifacts/0/docs/build/html/index.html)
- [Changed pages](https://output.circle-artifacts.com/output/job/3ad204f2-5f68-4e69-bc75-a4262d81b338/artifacts/0/docs/build/html/diff.html)

<details>
<summary>More info</summary>

- Ignore this comment if this PR does not change the documentation.
- It takes a few minutes for the preview to be available.
- The preview is updated when a new commit is pushed to this PR.
- This comment was created by https://github.com/mlflow/mlflow/actions/runs/8570926556.

</details>
",documentation preview documentation preview available job successfully top page summary ignore comment change documentation preview available preview new commit comment,issue,positive,positive,positive,positive,positive,positive
2039419875,I applied the above changes locally and it solved the issue mentioned in #11049 for me. When is this likely to be merged please?,applied locally issue likely please,issue,negative,neutral,neutral,neutral,neutral,neutral
2039254574,I imagined that. If it is possible that would be of great help. Thought of reporting just because version 1.7.2 to my knowledge is the last version that supports python2 and therefore is not compatible with newer versions and you could consider of keeping just that.,possible would great help thought version knowledge last version python therefore compatible could consider keeping,issue,positive,positive,positive,positive,positive,positive
2039246811,@Stefano97 We've removed the old docs for faster website rebuild and save the storage costs. I can send you the 1.7.2 docs if necessary.,removed old faster rebuild save storage send necessary,issue,negative,positive,neutral,neutral,positive,positive
2039139940,would love to have the official helm chart. We're just waiting on that now to start fully using mlflow as the current community provided chart does not support basic-auth and is pretty badly documented overall,would love official helm chart waiting start fully current community provided chart support pretty badly overall,issue,positive,positive,positive,positive,positive,positive
2039002907,@TejjeT sure. Let me know if you need any guidelines for that.,sure let know need,issue,negative,positive,positive,positive,positive,positive
2038482264,"@konstantin-frolov  Thanks for raising the issue! It shouldn't be the case if you are using Keras `model.fit()`, for which graph mode is turned on by default, and we are explicitly supporting it. I suspect you are wrapping your whole training loop by `tf.function`, in which case you cannot get the numerics during training. Checking Keras code for how the compilation works as a reference: [link](https://github.com/keras-team/keras/blob/42a1535ed7d3d75711a11d295f58a2dc9a59fdae/keras/backend/tensorflow/trainer.py#L325)

Could you share a reproducible github gist? We can take a closer look. ",thanks raising issue case graph mode turned default explicitly supporting suspect wrapping whole training loop case get training code compilation work reference link could share reproducible gist take closer look,issue,positive,positive,positive,positive,positive,positive
2038482114,"<!-- assign-maintainer -->
@mlflow/mlflow-team Please assign a maintainer and start triaging this issue.",please assign maintainer start issue,issue,negative,neutral,neutral,neutral,neutral,neutral
2038472373,"No response for a long time. I will close it for now. If you have update , feel free to reopen it  :)",response long time close update feel free reopen,issue,positive,positive,positive,positive,positive,positive
2038433940,"Hello ,
I am interested in working on this issue. Could you assign this to me.

",hello interested working issue could assign,issue,negative,positive,positive,positive,positive,positive
2038343438,"Hi all! I have this error when I run ""copy-model-version"" in a bash script:

mlflow.exceptions.RestException: RESOURCE_DOES_NOT_EXIST: Run '_<ID>_' not found.

I'm able to copy the model, but I have this error, have we got a workaround to solve this issue?",hi error run bash script run id found able copy model error got solve issue,issue,negative,positive,positive,positive,positive,positive
2037553763,"Hey @B-Step62 ,

Thank you so much for the review! 

I just run the pre-commit hook to the files I have modified in PR. ",hey thank much review run hook,issue,negative,positive,positive,positive,positive,positive
2037298652,"Bringing this back again, are there any developments? I agree with the previous comments, it would be very useful to have a delete and a replace option in the API, for tags, metrics and parameters... Thanks :)",back agree previous would useful delete replace option metric thanks,issue,positive,positive,neutral,neutral,positive,positive
2036782762,"@WeichenXu123 @BenWilson2 

There is an reranking endpoint: https://www.mixedbread.ai/api-reference/endpoints/reranking#rerank-documents

Would be care to include this as a new endpoints?",would care include new,issue,negative,positive,positive,positive,positive,positive
2036364680,"Hi @B-Step62, I've addressed your comments, added a test that addresses prediction with a `RunnableWithMessageHistory` while passing configurables as `params`, and restructured my changes to `call_api()` so that the previous behavior (base types like `Retriever`, `Chain`, etc. being invoked with `return_only_outputs=True`) is preserved. Let me know if this looks good — thanks!",hi added test prediction passing previous behavior base like retriever chain let know good thanks,issue,positive,negative,neutral,neutral,negative,negative
2036190776,"@subbiah-cape Could you share what is the error shown when loading the `pth` file, and any code to reproduce the issue""?

The extension should do nothing ([ref](https://discuss.pytorch.org/t/difference-between-saving-a-tensor-via-pt-and-pth/30780/4)) for the saving format, so if model is saved normally, you should be able to load the model (or by just renaming to `.pt` if YOLO validates extension).

> the parameters that I have been using in yolov8x-seg.pt are not supported here

What parameter is not supported?",could share error shown loading file code reproduce issue extension nothing ref saving format model saved normally able load model extension parameter,issue,negative,positive,positive,positive,positive,positive
2035894835,"@artjen Thank you for the contribution! Could you fix the following issue(s)?

#### &#x26a0; DCO check

The DCO check failed. Please sign off your commit(s) by following the instructions [here](https://github.com/mlflow/mlflow/runs/23420199580). See https://github.com/mlflow/mlflow/blob/master/CONTRIBUTING.md#sign-your-work for more details.",thank contribution could fix following issue check check please sign commit following see,issue,positive,neutral,neutral,neutral,neutral,neutral
2035848467,This issue has since been fixed. I was trying to directly log my DDP model without unwrapping it. I unwrap it using the ```.module()``` attribute and now its being logged as expected.,issue since fixed trying directly log model without unwrapping unwrap attribute logged,issue,negative,positive,neutral,neutral,positive,positive
2035611806,"I've had the exact same issue. The problem arises when the mlflow server shuts down during a metric log session (electrical problems for me). As a result, some of the metric files turn out to be corrupt. In some cases, the file ends with a trail of '\00' bytes. In other cases, the last row of the metric file is malformed. In both cases, the remedy would be to remove the corrupt line from the end of the file.

In my case, I had more than 1000 corrupt metric files. I had to write a script to find the corrupt files and fix the last line.

Finally, I believe it would be a good option if the mlflow server could keep track of the files that are opened and being written. This way, we can find the files that might be corrupt.",exact issue problem server metric log session electrical result metric turn corrupt file trail last row metric file malformed remedy would remove corrupt line end file case corrupt metric write script find corrupt fix last line finally believe would good option server could keep track written way find might corrupt,issue,negative,negative,negative,negative,negative,negative
2035053872,"No I am not talking about removing permission using admin, in the source code you can do it to make it permanent clone the repo checkout the latest version
In mlflow/mlflow/server/auth/permission.py file Manage permission change can_delete to false and compile the package again.",talking removing permission source code make permanent clone latest version file manage permission change false compile package,issue,negative,positive,neutral,neutral,positive,positive
2034941424,"> But is it possible json is not a dictionary here?

With the linked fix, I think no. You can test. related code

```
    def __reduce__(self):
        """"""
        Overriding `__reduce__` to make `RestException` instance pickle-able.
        """"""
        return RestException, (self.json,)
```",possible dictionary linked fix think test related code self make instance return,issue,negative,neutral,neutral,neutral,neutral,neutral
2034828928,@BenWilson2 Would you mind taking another look? Thanks!,would mind taking another look thanks,issue,negative,positive,positive,positive,positive,positive
2034584230,"I invented a new MLFlow plugin here: https://github.com/data-platform-hq/mlflow-oidc-auth, this plugin is based on the basic-auth MLFlow plugin, but supports OIDC/OAuth2 for GUI Auth and utilizes tokens (just basic auth) for non-GUI access (from notebook, pipeline, etc) at the same time.

@BenWilson2  please let me know if you like this idea and want to have something inside of MLFlow instead of 3rd party plugin  ",new based basic access notebook pipeline time please let know like idea want something inside instead party,issue,positive,positive,neutral,neutral,positive,positive
2034551480,"@j-arpit It is not a desired workflow on the organization level to have people register the model, and then inform the admin about the registered model, and then the admins keep banning people. It is inefficient and cumbersome.

",desired organization level people register model inform registered model keep banning people inefficient cumbersome,issue,negative,neutral,neutral,neutral,neutral,neutral
2034522211,"> Hold on... this error is triggered by unpickling...
> 
> maybe it has been fixed by #10936
> 
> @serena-ruan Could you check which MLflow version the user uses ?

Ah looks like so. But is it possible json is not a dictionary here?",hold error triggered maybe fixed could check version user ah like possible dictionary,issue,negative,positive,neutral,neutral,positive,positive
2034329918,"Hold on... this error is triggered by unpickling...

maybe it has been fixed by https://github.com/mlflow/mlflow/pull/10936

@serena-ruan Could you check which MLflow version the user uses ?",hold error triggered maybe fixed could check version user,issue,negative,positive,neutral,neutral,positive,positive
2034273452,"> Curious how or where `RestException` is instantiated with a string.

I'm not sure, the SparkTrials ticket stacktrace contains this error",curious string sure ticket error,issue,negative,positive,positive,positive,positive,positive
2033938682,@thesuperzapper would you like to contribute the fix?,would like contribute fix,issue,negative,neutral,neutral,neutral,neutral,neutral
2033903165,"So far, I have been using YOLOv8x-seg for segmentation. Once the training is completed, the framework itself saves the best model in a .pt extension. However, when registering the model in MLflow, it saves it with a .pth extension, and I was unable to load that model in YOLO. Is there any other feature to save the model in a .pt extension? Additionally, I have separately loaded the registered model, but I was unable to load it, and the parameters that I have been using in yolov8x-seg.pt are not supported here.",far segmentation training framework best model extension however model extension unable load model feature save model extension additionally separately loaded registered model unable load,issue,positive,positive,neutral,neutral,positive,positive
2033865146,User can simply change can_delete to false in manage permission in permissions file that will do the job ,user simply change false manage permission file job,issue,negative,negative,negative,negative,negative,negative
2033826030,"@cmohamma can you provide more details (version, env variables values, how do you start the deployments server)",provide version start server,issue,negative,neutral,neutral,neutral,neutral,neutral
2033785756,"@daniellok-db oh interesting, we had to miss this one 🤔 

> I'm guessing the best fix would be to migrate these old `<table>`s to `<Table>` from `@databricks/design-system`

Yes, that would be the best fix! However, we can also get a much quicker/makeshift solution if we relax colors in [CompareRunView.css](https://github.com/mlflow/mlflow/blob/master/mlflow/server/js/src/experiment-tracking/components/CompareRunView.css) which is a super old style file, still not migrated to emotion CSS. ",oh interesting miss one guessing best fix would migrate old table table yes would best fix however also get much solution relax color super old style file still emotion,issue,positive,positive,positive,positive,positive,positive
2033478946,Found a few more `docker-compose` in README. I'll fix them later. I want to make CI healthy first.,found fix later want make healthy first,issue,negative,positive,positive,positive,positive,positive
2033421349,@B-Step62 you are correct that this only seems to happen when you try and use light mode in MLFlow with dark mode set on your system settings.,correct happen try use light mode dark mode set system,issue,negative,positive,positive,positive,positive,positive
2033405133,"@thesuperzapper Understood, thank you for the description! Yes that seems to be a bug, I will investigate and file a patch.",understood thank description yes bug investigate file patch,issue,positive,neutral,neutral,neutral,neutral,neutral
2033391652,"@ishaan-mehta Thank you so much for the explanation! I've overlooked that the condition check is in prediction function, and that makes sense to remove the limitation then🙂",thank much explanation condition check prediction function sense remove limitation,issue,negative,positive,positive,positive,positive,positive
2033386867,"@B-Step62 I am using PostgreSQL `16.1.0`, but I think the issue is that `registered_model_permissions` is not getting cleaned up when you delete a model. 

So, databases that actually enforce ""unique constraints"" will fail when recreating a model and will be unable to INSERT a new row to `registered_model_permissions` (because one with that key already exists). Clearly the semantics should be UPSERT (or we should remove the permission row when deleting the model).

I am not sure if SQLite is used the same as more traditional DBs in MLFlow.",think issue getting delete model actually enforce unique fail model unable insert new row one key already clearly semantics remove permission row model sure used traditional,issue,negative,positive,neutral,neutral,positive,positive
2033378198,@JoelTrulin-capestart MLflow currently only supports local file system or local/remote database for saving the run metadata in S3. ,currently local file system saving run,issue,negative,neutral,neutral,neutral,neutral,neutral
2033375287,"@thesuperzapper Could you share more about the database, and also check if there is any configuration that prevent the hard delete of a row? I could delete and re-register the model on my end with MLflow 2.11.1 with SQLite.
",could share also check configuration prevent hard delete row could delete model end,issue,negative,negative,negative,negative,negative,negative
2033374711,"Ah i think we might have missed this in the original dark theme implementation, cc @hubertzub-db is there an easy way to fix this? I'm guessing the best fix would be to migrate these old `<table>`s to `<Table>` from `@databricks/design-system` 

",ah think might original dark theme implementation easy way fix guessing best fix would migrate old table table,issue,positive,positive,positive,positive,positive,positive
2033307041,"Thanks @thesuperzapper 

> Make sure your computer is set to dark mode (in system settings), and then toggle the UI to light mode before refreshing, it should flip back to dark.

I can confirm this, while the opposite is not (the dark mode preserves even when system default is light). Are you seeing the latter case as well?",thanks make sure computer set dark mode system toggle light mode refreshing flip back dark confirm opposite dark mode even system default light seeing latter case well,issue,positive,positive,positive,positive,positive,positive
2033303611,"@B-Step62 I am using MacOS, but I just tested and this happens on both Brave (Chrome fork) and Safari, so I imagine it's not related to the browser.

Make sure your computer is set to dark mode (in system settings), and then toggle the UI to light mode before refreshing, it should flip back to dark.",tested brave chrome fork safari imagine related browser make sure computer set dark mode system toggle light mode refreshing flip back dark,issue,positive,positive,positive,positive,positive,positive
2033302818,Oh I applied the same in https://github.com/mlflow/mlflow/pull/11565 to unblock tests. Maybe we can just merge it.,oh applied unblock maybe merge,issue,negative,neutral,neutral,neutral,neutral,neutral
2033298849,"@subbiah-cape What blocks you from loading the model saved with `.pth` in your `score.py`? As far as I know, there is no difference between `.pt` and `.pth` extension, Pytorch uses a single serialization format.",loading model saved far know difference extension single serialization format,issue,negative,positive,neutral,neutral,positive,positive
2033295054,"@thesuperzapper Thank you for reaching out to us! I could reproduce the issue.

cc: @daniellok-db Is this issue already tracked somewhere?",thank reaching u could reproduce issue issue already tracked somewhere,issue,positive,neutral,neutral,neutral,neutral,neutral
2033292182,"@thesuperzapper Thank you for reporting the issue, however, I cannot reproduce the issue. Could you share more about your environment, particularly OS and browser?",thank issue however reproduce issue could share environment particularly o browser,issue,positive,positive,positive,positive,positive,positive
2033165408,"> Are we going to update the Client APIs end_trace and end_span to accept str in a follow-up PR, or were you going to add that to this PR?

They just call `set_status` of the wrapper so already accept `str`, but I haven't updated the docstring. Will do in this PR.",going update client accept going add call wrapper already accept,issue,positive,neutral,neutral,neutral,neutral,neutral
2033163852,"Hi @QAM @harupy @dogeplusplus 

I'm using the serverless inference configuration in the below way using the latest mlflow version

```
from mlflow.deployments import get_deploy_client

config = dict(
    assume_role_arn=""assume_role_arn"",
    execution_role_arn=""execution_role_arn"",
    bucket_name=""bucket_name"",
    image_url=""image_url"",
    region_name=""us-east-1"",
    vpc_config=vpc_config,
    serverless_config = {""MemorySizeInMB"": 6144,""MaxConcurrency"": 20},
    tags=tags,
)

client = get_deploy_client(""sagemaker"")
client.create_deployment(
    ""name"",
    model_uri=""runs/runid/model"",
    flavor=""python_function"",
    config=config,
)
```

and getting the below error - 

`botocore.exceptions.ClientError: An error occurred (ValidationException) when calling the CreateEndpoint operation: One or more endpoint features are not supported using this configuration`

can you suggest me if I'm doing something incorrect here?

",hi inference configuration way latest version import client name getting error error calling operation one configuration suggest something incorrect,issue,negative,positive,positive,positive,positive,positive
2032553891,">I don't think we should expose credentials like that.

For the actual production usage, we can allow users to use templating and read the credentials from the env variables as the Spring property does.
```
auth:
  basic:
    - username: ${USER_NAME_TOMU}
      password: ${USER_PASS_TOMU}
    - username: ${USER_NAME_HARU}
      password: ${USER_PASS_HARU}
```

>It's inconvenient to edit the config file every time a new user needs to be added.

That's a good point. I didn't expect the arbitrary number of users would be added to the Basic Authentication user list. In this case, it would be better to persist the users in a DB and provide an API for the server admin to add a new user. Since there is [a similar feature for tracking](https://mlflow.org/docs/latest/auth/index.html?highlight=admin), can I ask if we want to share the server admin and user list between ""tracking"" and ""deployment""?


",think expose like actual production usage allow use read spring property basic password password inconvenient edit file every time new user need added good point expect arbitrary number would added basic authentication user list case would better persist provide server add new user since similar feature ask want share server user list deployment,issue,positive,positive,neutral,neutral,positive,positive
2032442845,"Are we going to update the Client APIs `end_trace` and `end_span` to accept `str` in a follow-up PR, or were you going to add that to this PR?",going update client accept going add,issue,negative,neutral,neutral,neutral,neutral,neutral
2031714713,"Hey @WeichenXu123 @BenWilson2,

I added all the available endpoints in the PR for TogetherAI. I think this would be a good time to review it!  

",hey added available think would good time review,issue,negative,positive,positive,positive,positive,positive
2031687677,"@TomeHirata Sorry for being late to send this, but this is what our design doc template looks like:
[Design doc template (2).pdf](https://github.com/mlflow/mlflow/files/14835451/Design.doc.template.2.pdf)
",sorry late send design doc template like design doc template,issue,negative,negative,negative,negative,negative,negative
2031414805,"> sudo apt-get update && sudo apt-get upgrade -y && sudo apt-get install -y git

these command fixed my issues. 
thank you so much, My system is ubuntu22.04",update upgrade install git command fixed thank much system,issue,negative,positive,positive,positive,positive,positive
2031203808,"@hubertzub-db Hi, I am interested in doing so, but may not have enough time (e.g. I need to squeeze time to maintain my open source libs like https://github.com/fzyzcjy/flutter_rust_bridge) at least recently.",hi interested may enough time need squeeze time maintain open source like least recently,issue,positive,negative,neutral,neutral,negative,negative
2031201680,@fzyzcjy great! Let us know if you're willing to provide even a minimal implementation (unformatted text in the column hidden by default) and if you need any guidelines for that :),great let u know willing provide even minimal implementation text column hidden default need,issue,positive,positive,positive,positive,positive,positive
2031081196,"> By the way, what if we consider number of rows when computing the digest? That will fix this specific case at least.

That sounds like a great idea! Indeed the hash function itself considers the length of dataset ([code](https://github.com/mlflow/mlflow/blame/1ad9148fb828a2f7beaad8394967a0691344ff81/mlflow/data/digest_utils.py#L35)), it's just that the passed dataset is always truncated to 10k rows so it is no-op for HF dataset ([code](https://github.com/mlflow/mlflow/blob/1ad9148fb828a2f7beaad8394967a0691344ff81/mlflow/data/huggingface_dataset.py#L63-L68)). If we can make it to consider the original length of the dataset, that would be awesome:)",way consider number digest fix specific case least like great idea indeed hash function length code always truncated code make consider original length would awesome,issue,positive,positive,positive,positive,positive,positive
2031014114,"By the way, what if we consider number of rows when computing the digest? That will fix this specific case at least.",way consider number digest fix specific case least,issue,negative,negative,negative,negative,negative,negative
2031011934,"Yes, and the best value for the number of rows for digesting depends on datasets. 10k doesn't work for this case, but if a dataset contains many number of columns, even lesser number may be ideal. I agree that the UX can be confusing sometimes, but since there is no single number satisfies every use case, I would simply make it configurable.",yes best value number work case many number even lesser number may ideal agree sometimes since single number every use case would simply make,issue,positive,positive,positive,positive,positive,positive
2030962994,"@manuelgilm Thank you so much for bringing this issue to our attention! 

This seems to be a regression introduced in MLflow 2.6.0. I've filed a patch PR and the issue should be fixed in the next release. For the meantime, you can invoke the `predict_log_proba` by directly accessing the underyling sklearn model

```
model = mlflow.sklearn.load_model(model_uri)
model.predict_log_proba(x)
```

",thank much issue attention regression patch issue fixed next release invoke directly model model,issue,negative,positive,neutral,neutral,positive,positive
2030957648,"I see, however the git commit hash is computed for the whole commit IIRC, thus it is really unique (up to collision), while mlflow is not. On the other hand, I do agree we cannot compute for the whole dataset, which is too slow...",see however git commit hash whole commit thus really unique collision hand agree compute whole slow,issue,positive,positive,positive,positive,positive,positive
2030943686,"@fzyzcjy The digest is designed to be an unique identifier for a dataset combined with a name, so we shouldn't create two different dataset for a same digest, similarly to Git commit hash.",digest designed unique identifier combined name create two different digest similarly git commit hash,issue,positive,positive,positive,positive,positive,positive
2030861788,@0tist Thank you so much for bringing this issue to our attention! We have filed a fix^ and it should be released in the next release.,thank much issue attention next release,issue,negative,positive,neutral,neutral,positive,positive
2030848942,"Oops, I think this was a regression, let me file a quick fix",think regression let file quick fix,issue,negative,positive,positive,positive,positive,positive
2030833750,"@B-Step62 Thanks for the reply. I am not sure whether it is the best solution, because I will not realize I need to change this argument unless I realize it is mlflow's bug (instead of my code's bug).

PS. I guess another solution is that, even if two datasets have the same digest, mlflow can store both of them (instead of only storing one). ",thanks reply sure whether best solution realize need change argument unless realize bug instead code bug guess another solution even two digest store instead one,issue,positive,positive,positive,positive,positive,positive
2030818847,@lababidi Thank you so much for bringing this issue up and filing a quick fix!! We are reviewing the PR now.,thank much issue filing quick fix,issue,negative,positive,positive,positive,positive,positive
2030815715,"@fzyzcjy Thank you for bringing the issue to our attention! Yes the dataset digest is computed with the first 10k rows for now. We need some limit to avoid hanging when calculating a digest for a huge dataset, but I think it's possible to make it configurable via a constructor argument. Will it be helpful for your use case?",thank issue attention yes digest first need limit avoid hanging calculating digest huge think possible make via constructor argument helpful use case,issue,positive,positive,positive,positive,positive,positive
2030710862,"@dbczumar / @sebastiaanboer-db 
Can you please tell me if anyone is working on the Bug fix? Else I will be happy to contribute fix for the issue. Thanks ",please tell anyone working bug fix else happy contribute fix issue thanks,issue,positive,positive,positive,positive,positive,positive
2030603710,"@ddluke  : I was trying to reproduce the issue in 2.11.4 , but seems here the issue is in your `Code to reproduce issue` script. 
 
Can you try changing `response.version` to `response.status` to check `READY` status and see if issue is still reproducible in 2.11 ?
 
`assert response.version == ""READY""` => `assert response.status == ""READY""`  
",trying reproduce issue issue code reproduce issue script try check ready status see issue still reproducible assert ready assert ready,issue,positive,positive,positive,positive,positive,positive
2030191932,@WeichenXu123 we need to set an entry in the MLModel file for langchain models that support streamable returns `streamable`: Boolean so that Model Serving will know whether to expose the streamable API logic for a given model. ,need set entry file support model serving know whether expose logic given model,issue,negative,neutral,neutral,neutral,neutral,neutral
2030038541,"I'd like to see the experiment IDs again, can view them for MLFlow UI 2.11.1

![Screenshot 2024-04-01 at 6 51 05 PM](https://github.com/mlflow/mlflow/assets/42416623/75d65413-1dbf-4804-8b15-82660a61699d)
",like see experiment view,issue,negative,neutral,neutral,neutral,neutral,neutral
2029939415,"Hi @B-Step62 — glad to help, and thanks for taking a look here!

A couple thoughts:

1. Given that this check takes place in the prediction function where the model has already been saved and is now being loaded, does it matter which types are pickleable since we have already saved and loaded back the model? Any checks for whether the model is savable should take place in the `save_model()` function itself, no?
2. Also, with https://github.com/mlflow/mlflow/pull/11370, we are now able to log arbitrary LangChain model types as code (including ones we weren't previously able to save, such as `RunnableWithMessageHistory`), so I am not sure it makes sense to limit prediction to a select few types.",hi glad help thanks taking look couple given check place prediction function model already saved loaded matter since already saved loaded back model whether model savable take place function also able log arbitrary model code previously able save sure sense limit prediction select,issue,positive,positive,positive,positive,positive,positive
2029935782,@hubertzub-db apologies for the delayed reply! we're using 2.10.1 so a few behind. Let me check the latest version resolves this on our end.,reply behind let check latest version end,issue,negative,positive,neutral,neutral,positive,positive
2029624002,"any update on this? because i am facing same issue
mlflow version 2.11.1 same version on both client and server",update facing issue version version client server,issue,negative,neutral,neutral,neutral,neutral,neutral
2029514832,"Sorry for the churn because of many updates in the main branch. Overall LGTM, a few comments, but mostly related to those updates!",sorry churn many main branch overall mostly related,issue,negative,positive,neutral,neutral,positive,positive
2029469240,"> cc @B-Step62 I'm still getting Invalid type dict for attribute 'invocation_params' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types Invalid type dict for attribute 'options' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types for attributes

Now it's fixed in the `tracing` branch. You have to rebase and include [this PR](https://github.com/mlflow/mlflow/pull/11547).
",still getting invalid type attribute value one sequence invalid type attribute value one sequence fixed tracing branch rebase include,issue,positive,positive,neutral,neutral,positive,positive
2029420390,"cc @B-Step62 I'm still getting `Invalid type dict for attribute 'invocation_params' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types
Invalid type dict for attribute 'options' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types` for attributes",still getting invalid type attribute value one sequence invalid type attribute value one sequence,issue,positive,neutral,neutral,neutral,neutral,neutral
2029397487,"> Do we also need to rename MLflowSpanExporter

True, updated!",also need rename true,issue,negative,positive,positive,positive,positive,positive
2029390366,Do we also need to rename `MLflowSpanExporter` which violates the rule added by #11563?,also need rename rule added,issue,negative,neutral,neutral,neutral,neutral,neutral
2029295084,"Your PR includes commits from other persons, could you remove unrelated commit history in the PR ?",could remove unrelated commit history,issue,negative,neutral,neutral,neutral,neutral,neutral
2029038917,"> > Refere
> 
> Couldn't find it. When I press on the Edit it only opens the title edit.

I help you edited it. Could you fix all failed tests ?",could find press edit title edit help could fix,issue,negative,neutral,neutral,neutral,neutral,neutral
2028581151,"> Refere

Couldn't find it. When I press on the Edit it only opens the title edit.",could find press edit title edit,issue,negative,neutral,neutral,neutral,neutral,neutral
2027290468,"My bad, my environment variable was not set properly and the communication to the deployments server could not be established :)",bad environment variable set properly communication server could established,issue,negative,negative,negative,negative,negative,negative
2027275199,Has there been a progress with this yet? I am still experiencing the issue on the latest (2.11.3) mlflow version and there are no errors shown in the browser's console.,progress yet still issue latest version shown browser console,issue,negative,positive,positive,positive,positive,positive
2026395356,"@ishaan-mehta Thank you so much for your contribution!!

Adding `configurable` parameter makes sense to me. However, accepting all Runnable types need to be a bit carefully done, because some types are not pickelable and need special saving logic. We have a list of current supported types [here](https://github.com/mlflow/mlflow/blob/2248511d5d86bbd751a0fea4241f78be7bc8f3c8/mlflow/langchain/utils.py#L143-L149), so would you mind testing other types you'd like to support and add them as test cases in [test_langchain_model_export.py](https://github.com/mlflow/mlflow/blob/2248511d5d86bbd751a0fea4241f78be7bc8f3c8/tests/langchain/test_langchain_model_export.py)? ",thank much contribution parameter sense however runnable need bit carefully done need special saving logic list current would mind testing like support add test,issue,positive,positive,positive,positive,positive,positive
2026252213,"> We'll need to ensure that the span event is properly closed. Within the exception catch logic, can we end the span with the Exception information attached to a failed Span event? cc @B-Step62 there is a mechanism for handling this within OTeL, correct?

The `mlflow.start_span()` has another try-catch and the span is ended at `finally` clause, so it should be guaranteed the span to be closed.

I think what happened here in the failed test is that the exception raised from the child span is eaten by the new `try-catch`, then the function is simply retried in the `except` block without decorating, resulted in a new trace (with single span) is created. What happens here is kinda complex.

TLDR: we shouldn't wrap the entire function call with try-catch cuz it will eat the valid exception from the original function and retry.

1. `predict` is called and a parent span is created.
2. `some_operation_raise_error` is called and the child span is created.
3. `some_operation_raise_error` raises exception. It closes the both spans and a trace is **logged**.
4. The exception is caught by the new try-catch.
5. It retries the `some_operation_raise_error` in `except` block, but without creating span.
6. It raises error again, which bubbles up to the parent `predict` call.
7. The new `try-catch` catches the exception, retries `predict` call without creating a span.
8. `some_operation_raise_error` executed again (with span), creates a new trace with itself alone (**<- This is what is shown in the test finally**)
9. The `predict` function is halted with the exception raised from `some_operation_raise_error`.",need ensure span event properly closed within exception catch logic end span exception information attached span event mechanism handling within correct another span ended finally clause span closed think test exception raised child span eaten new function simply except block without new trace single span complex wrap entire function call eat valid exception original function retry predict parent span child span exception trace logged exception caught new except block without span error parent predict call new exception predict call without span executed span new trace alone shown test finally predict function exception raised,issue,negative,positive,neutral,neutral,positive,positive
2025561413,"@FotiosBistas yes, a separate PR for each (including docs updates and examples for each) would be preferable due to the size of each PR. Thanks!",yes separate would preferable due size thanks,issue,positive,positive,neutral,neutral,positive,positive
2025169687,"cc @ankit-db are there any considerations that need to be accounted for on the Inference side for this change? If we're applying this dtype specification directly to the model (and not the pipeline), is this going to prove incompatible to the means that you're loading these models within the serving container during the build process? ",need inference side change specification directly model pipeline going prove incompatible loading within serving container build process,issue,negative,positive,neutral,neutral,positive,positive
2025158323,"We'll need to ensure that the span event is properly closed. Within the exception catch logic, can we end the span with the Exception information attached to a failed Span event? cc @B-Step62 there is a mechanism for handling this within OTeL, correct?",need ensure span event properly closed within exception catch logic end span exception information attached span event mechanism handling within correct,issue,negative,negative,neutral,neutral,negative,negative
2025076512,"Hey @WeichenXu123 I will try to add the following providers in this order: 

- [ ] TogetherAI
- [ ] Mixedbread
- [ ] Anyscale

Shall I open a seperate PR for each one? I believe this would be more appropriate. ",hey try add following order shall open one believe would appropriate,issue,negative,positive,positive,positive,positive,positive
2024738369,"it's a real pain in the ass, it's like the fact you can't easily delete an experiment fully, but only set as a deleted status from UI/ Python.

At work we always have to be building features on top of what is missing in mlflow, as it feels like many of the thing they just left them halfway done...",real pain as like fact ca easily delete experiment fully set status python work always building top missing like many thing left halfway done,issue,negative,positive,positive,positive,positive,positive
2024629627,I don't think we should expose credentials like that. It's inconvenient to edit the config file every time a new user needs to be added.,think expose like inconvenient edit file every time new user need added,issue,negative,negative,negative,negative,negative,negative
2024472864,@WeichenXu123 can you add a minimum streaming example in `examples/langchain`?,add minimum streaming example,issue,negative,neutral,neutral,neutral,neutral,neutral
2024263832,"Just ran into this thread and wanted to share what I found.
Model stages seems to be [deprecated](https://mlflow.org/docs/2.10.0/model-registry.html#deprecated-using-model-stages). It seems that it is suggested to [use Model Version Tags and Aliases instead](https://mlflow.org/docs/2.10.0/model-registry.html#migrating-from-stages). See [this link](https://mlflow.org/docs/2.10.0/model-registry.html#ui-workflow) for UI workflow.
",ran thread share found model use model version instead see link,issue,negative,neutral,neutral,neutral,neutral,neutral
2024149977,"> LGTM! Would be great if you test this in E2 as well before merging.

tested and seems to work!",would great test well tested work,issue,positive,positive,positive,positive,positive,positive
2023887344,"Hello, i'm using 2.11.3 version and still the warning is there.",hello version still warning,issue,negative,neutral,neutral,neutral,neutral,neutral
2023582982,"> Thanks for your contribution, but I think we need discuss and do some design for this feature . Could you create an issue for this so that we can discuss there ?

We have had a discussion for this already, the design can be accessed at go/computervision - its an urgent change for unblocking CV teams.",thanks contribution think need discus design feature could create issue discus discussion already design urgent change,issue,positive,positive,positive,positive,positive,positive
2022288954,"> Thanks for confirming. @WeichenXu123 `autolog` should be batching requests so I'm wondering why it's getting a 429 error. @sagarsumant can you help us take a look too about why asynchronous metrics logging is not helping here?

Maybe the 429 error is caused by server side issue, not triggered by MLFlow requests. You can count MLflow requests number to confirm.",thanks confirming wondering getting error help u take look asynchronous metric logging helping maybe error server side issue triggered count number confirm,issue,negative,positive,positive,positive,positive,positive
2022264275,"Thanks for your contribution, but I think we need discuss and do some design for this feature . Could you create an issue for this so that we can discuss there ?",thanks contribution think need discus design feature could create issue discus,issue,positive,positive,positive,positive,positive,positive
2022135198,">What if you have multiple users? The YAML file would look like this?

Yes, if we want to support multiple user cases, then the yaml will look like it.",multiple file would look like yes want support multiple user look like,issue,positive,neutral,neutral,neutral,neutral,neutral
2022003065,"@sagarsumant 

We are considering to make mlflow log_artifact supporting async, after it is supported, you can start work for addressing this ticket :)",considering make supporting start work ticket,issue,negative,positive,positive,positive,positive,positive
2021919022,"@serena-ruan merging the PR now to unblock other stacked PRs, but let me know if there are any remaining concerns! I will address them in follow-up.",unblock let know address,issue,negative,neutral,neutral,neutral,neutral,neutral
2021827074,"@TomeHirata Sorry for the delay.

1. Yes, I'll send you the template.
2. What if you have multiple users? The YAML file would look like this?

```yml
auth:
  basic:
    - username: tomehirata
      password: mypassword
    - username: haru
      password: haru
```

3. Sorry, we can only assign collaborators or mlflow org members.
",sorry delay yes send template multiple file would look like basic password password sorry assign,issue,negative,negative,negative,negative,negative,negative
2021762911,"@FotiosBistas 

I talked with our team folks, supporting custom provider is lots of work. For now, we agree to add TogetherAI and mixedbread.ai into MLflow.

You can refer to this PR: https://github.com/mlflow/mlflow/pull/11195 and https://github.com/mlflow/mlflow/pull/11020 for adding new provider ",team supporting custom provider lot work agree add refer new provider,issue,positive,positive,positive,positive,positive,positive
2021682071,"also, can we add an unit test to cover this?",also add unit test cover,issue,negative,neutral,neutral,neutral,neutral,neutral
2021671184,Looking forward to the next release!,looking forward next release,issue,negative,neutral,neutral,neutral,neutral,neutral
2021668875,"> > Hi all, I discussed with our team folks, we decided to **not** do this , because in many user-cases user wants to delete model that is created by themselves. If we disallow this, it might cause many complaints.
> 
> I think there should be a way for the admin while creating a user to allow such MANAGE permissions upon registering models or not. Some organizations have strict requirements like mine and this feature is insecure. We don't want to lose important models.

We can consider to add a config for this, but it should not be turned on by default.",hi team decided many user delete model disallow might cause many think way user allow manage upon strict like mine feature insecure want lose important consider add turned default,issue,negative,positive,positive,positive,positive,positive
2021526994,"> Sounds great! I think the implementation looks fantastic!

@BenWilson2 Thanks! Could you approve the PR if it looks good to you? ",great think implementation fantastic thanks could approve good,issue,positive,positive,positive,positive,positive,positive
2021497758,"Some quick thoughts regarding the design considerations:

> 1. Which kinds of langchain model support streaming output ?
> Only lc_runnables_types models. For other models like BaseRetriever , streaming is not supported. For langchain.chains.base.Chain types, although they have 'stream' method, but in my test it doesn't work too. So they are also not supported in this PR.

Yup that's fine per LangChain streaming docs: https://python.langchain.com/docs/modules/model_io/llms/streaming_llm. Note: we only really need the last chain step to be streaming (as intermediate streams doesn't provide any UX benefit)


> 2. What's the input type of model.predict_stream ?
> It only accepts one single input. Batch input is not supported.

Also sgtm. Model serving will be restricting streaming to only unified LLM inputs as well (e.g. DataFrame inputs will not be supported for now)

> 3. What's the output type of model.predict_stream ?
> It outputs an iterator. The iterator is composed of chunks. Each chunk might be chat chunk format (See _ChatChunkResponse type) if the input is recognized as chat model input, or other original chunk type generated by langchain_model.stream.

Sgtm, we'll call `chunk.to_json()` as planned get the response to return over HTTP.

> 4. Shall we add callbacks as a langchain model inference param ? it is widely used.

We need callbacks for trace logging and retrieval (similar to experimental method `_predict_with_callbacks`). It's fine to keep this hidden for now though",quick regarding design model support streaming output like streaming although method test work also fine per streaming note really need last chain step streaming intermediate provide benefit input type one single input batch input also model serving streaming unified well output type composed chunk might chat chunk format see type input chat model input original chunk type call get response return shall add model inference param widely used need trace logging retrieval similar experimental method fine keep hidden though,issue,positive,positive,positive,positive,positive,positive
2021475385,Sounds great! I think the implementation looks fantastic! ,great think implementation fantastic,issue,positive,positive,positive,positive,positive,positive
2021457751,"> Is there any need to support the chunked and chunk-based retry logic for multi-part downloads and uploads for large models within this artifact store implementation? Is that future work that is planned, or has that been deemed to be not needed for UC?

@BenWilson2 chunked and chunk-based retry logic for multi-part downloads and uploads for large models files will be needed and is planned as future work.",need support retry logic large within artifact store implementation future work retry logic large future work,issue,negative,positive,positive,positive,positive,positive
2021394169,"Is there any need to support the chunked and chunk-based retry logic for multi-part downloads and uploads for large models within this artifact store implementation? 
Is that future work that is planned, or has that been deemed to be not needed for UC? ",need support retry logic large within artifact store implementation future work,issue,negative,positive,positive,positive,positive,positive
2021222527,Overall LGTM but let's get someone from OSS team to take a look at it as well.,overall let get someone team take look well,issue,negative,neutral,neutral,neutral,neutral,neutral
2020820785,"Would be interesting to check if creating a custom provider would help with these methods (maybe this is outside the scope of this issue): 

https://github.com/mlflow/mlflow/blob/da9fafba99336efc4d625ff1b1307618a01c4f69/mlflow/deployments/mlflow/__init__.py#L63

Meaning that creating custom providers and adding them dynamically to the ``deployments server`` would be neat. ",would interesting check custom provider would help maybe outside scope issue meaning custom dynamically server would neat,issue,positive,positive,positive,positive,positive,positive
2020806516,"Hi everyone!
Is there any plan for this feature?
I'm looking into mlflow, and IMO when this feature is missing it really makes the UI unusable. A standard ML ecosystem deployment will have thousands of experiments which will already make the UI overloaded.
Also there's no way to see experiment creation date, sort by date etc.
",hi everyone plan feature looking feature missing really unusable standard ecosystem deployment already make also way see experiment creation date sort date,issue,negative,neutral,neutral,neutral,neutral,neutral
2020327194,"@WeichenXu123 I would suggest adding something like `overwrite=True` and `dont_recompute=True` to `mlflow.evaluate`. The problem is similar to [evaluate metrics inside a prompt engineering UI run](https://github.com/mlflow/mlflow/issues/10937).

Currently, are we supposed to create new runs each time we add a row and prompt? (We won't be able to use the prompt engineering UI with runs added programmatically.)",would suggest something like problem similar evaluate metric inside prompt engineering run currently supposed create new time add row prompt wo able use prompt engineering added programmatically,issue,negative,positive,positive,positive,positive,positive
2020098018,"> I am not familiar with namespaces in MLflow

MLflow experiments don't have namespace currently. It needs some design. My prefered design is like:

- Create namespace and grant permission, e.g. each  specific product or modality has its namespace.
- User can create experiment and runs in corresponding namespace with granted permission.

",familiar currently need design design like create grant permission specific product modality user create experiment corresponding permission,issue,positive,positive,positive,positive,positive,positive
2020080452,"> Artefacts pickled with cloudpickle == 3 can't be read with coudpickle < 3, and I was wondering if there was a migration guide for upgrading/downgrading artefacts.

No way... we have to install cloudpickle==3 to address it :)",ca read wondering migration guide way install address,issue,negative,neutral,neutral,neutral,neutral,neutral
2020052802,"Thanks! I need to discuss with our team folks. I think one issue is how to maintain more and more providers while mlflow maintainers have limited bandwidth. Can we add a plugin interface so that mlflow can load custom provider? e.g. we can modify https://github.com/mlflow/mlflow/blob/83b6c5fe826a741300855b640b705c33294c7b44/mlflow/gateway/providers/__init__.py#L8 to allow it load a custom provider

@BenWilson2 Thoughts ?",thanks need discus team think one issue maintain limited add interface load custom provider modify allow load custom provider,issue,negative,positive,neutral,neutral,positive,positive
2020033406,@edwardfeng-db Could you help taking a look ? I am not familiar with GraphQL,could help taking look familiar,issue,negative,positive,positive,positive,positive,positive
2019962222,"> > could you attach a demo notebook ?

could you merge front-end code and show a demo ?",could attach notebook could merge code show,issue,negative,neutral,neutral,neutral,neutral,neutral
2019961038,"I think the issue isn't mlflow but rather cloudpickle. Artefacts pickled with cloudpickle == 3 can't be read with coudpickle < 3, and I was wondering if there was a migration guide for upgrading/downgrading artefacts.

Thanks for pointing out that mlflow>2.9 is compatible with cloudpickle 3! It's weird I thought I had checked that...!

Happy to close this issue but just to confirm, there is no guide for moving artefacts due to change in cloudpickle version right?",think issue rather ca read wondering migration guide thanks pointing compatible weird thought checked happy close issue confirm guide moving due change version right,issue,positive,positive,positive,positive,positive,positive
2019790126,"> Maybe we could just display n few first words with no line breaks and use ellipsis (...) at the end?

Yes I think so! And maybe just render as pure text. For example, suppose someone has `## This is title\n\nThis is content`, we may just render as something like `This is title This is content`, instead of the huge title font.",maybe could display first line use ellipsis end yes think maybe render pure text example suppose someone content may render something like title content instead huge title font,issue,positive,positive,positive,positive,positive,positive
2019511142,"@fzyzcjy thanks for filing this FR! I think that if there's a use case for that, we definitely can add the description column. However what concerns me is not the adding the column by itself, but the approach to render its content. Run descriptions can contain a lot of rich content (markdown) and multi-line text. If we were to attempt displaying it as on the run details page, we might inadvertently hinder table readability. Maybe we could just display `n` few first words with no line breaks and use ellipsis (`...`) at the end? 🤔  Does it help with your use case @fzyzcjy ?
CC @WeichenXu123 also @AbeOmor ",thanks filing think use case definitely add description column however column approach render content run contain lot rich content markdown text attempt run page might inadvertently hinder table readability maybe could display first line use ellipsis end help use case also,issue,positive,positive,positive,positive,positive,positive
2019360805,"@ai-learner-00 
if you need to see something fast, I did the following in the model function:
```python
def model(input_df):
    answer = []
    for index, row in input_df.iterrows():
        # mine was ConversationalRetrievalChain, but you can keep yours as is
        answer.append(qa({""question"":row[""questions""], ""chat_history"": row[""chat_history""]}))
        answer[-1]['source_documents'] = list(map(lambda x: x.json(), answer[-1]['source_documents']))
    
    return answer
```",need see something fast following model function python model answer index row mine keep question row row answer list map lambda answer return answer,issue,negative,positive,neutral,neutral,positive,positive
2019357010,"We confirmed the latest commit resolves the issue, thank you so much for the quick fix @brynn-code! 

> And for the new changes afterwards, would you mind open issues here https://github.com/microsoft/promptflow/issues so that we won't miss it?

Absolutely! I will contact by filing an issue in the promptflow repo next time.",confirmed latest commit issue thank much quick fix new afterwards would mind open wo miss absolutely contact filing issue next time,issue,negative,positive,positive,positive,positive,positive
2019316426,"@B-Step62 We have fix the issue, to ensure backward compatibility, thanks for your time, really appreciate it.",fix issue ensure backward compatibility thanks time really appreciate,issue,positive,positive,positive,positive,positive,positive
2019304546,Please add unit tests for filestore / SQL alchemy / reststore backends.,please add unit alchemy,issue,negative,neutral,neutral,neutral,neutral,neutral
2019281200,"Ran rag studio tests, all passed. Thanks @serena-ruan !",ran rag studio thanks,issue,negative,positive,positive,positive,positive,positive
2019248439,"> Hi all, I discussed with our team folks, we decided to **not** do this , because in many user-cases user wants to delete model that is created by themselves. If we disallow this, it might cause many complaints.

I think there should be a way for the admin while creating a user to allow such MANAGE permissions upon registering models or not. Some organizations have strict requirements like mine and this feature is insecure. We don't want to lose important models.",hi team decided many user delete model disallow might cause many think way user allow manage upon strict like mine feature insecure want lose important,issue,negative,positive,positive,positive,positive,positive
2019245439,"> > @WeichenXu123 It is more like we want to define experiments on the organization level. Each experiment will represent one specific product or modality, and no one should delete or modify those. Users should only limit themselves to Runs and Model Registry, and not the Experiements.
> 
> In this case,
> 
> I think we'd better design a experiment namespace ""organisation"", the administrator grants ""organisation"" permission. And each user create their own experiment in organization which they have permission.

I am not familiar with namespaces in MLflow. Am I missing something?",like want define organization level experiment represent one specific product modality one delete modify limit model registry case think better design experiment administrator permission user create experiment organization permission familiar missing something,issue,positive,positive,positive,positive,positive,positive
2019200549,"Hi all, I discussed with our team folks, we decided to **not** do this , because in many user-cases user wants to delete model that is created by themselves. If we disallow this, it might cause many complaints.",hi team decided many user delete model disallow might cause many,issue,negative,positive,positive,positive,positive,positive
2019183357,"> Instead, can we extend start_span() and end_span() to take those attributes & inputs / outputs? I don't think we need to introduce separate APIs for this yet.

Oh sorry I took your comment wrong:) Yeah 100%, I didn't respond to that regard ^ but definitely agreed on adding those arguments.",instead extend take think need introduce separate yet oh sorry took comment wrong yeah respond regard definitely agreed,issue,positive,negative,negative,negative,negative,negative
2019141159,"@B-Step62 

> Yeah that's doable, I can add APIs like `client.set_attributes(trace_id, span_id, attributes)`. 

Instead, can we extend `start_span()` and `end_span()` to take those attributes & inputs / outputs? I don't think we need to introduce separate APIs for this yet.",yeah doable add like instead extend take think need introduce separate yet,issue,positive,neutral,neutral,neutral,neutral,neutral
2019125068,"Yeah that's doable, I can add APIs like `client.set_attributes(trace_id, span_id, attributes)`. ",yeah doable add like,issue,positive,neutral,neutral,neutral,neutral,neutral
2019119862,"> Also returning the object is consistent with existing run APIs, like [client.create_run()](https://mlflow.org/docs/latest/python_api/mlflow.client.html#mlflow.client.MlflowClient.create_run) returns Run object not Id alone. [Langfuse APIs](https://langfuse.com/docs/sdk/python/low-level-sdk) follows same approach as well.

Returning an object from `start_span()` is fine, but I agree with @BenWilson2 that the client APIs for mutating span data should be structured the same way as the client APIs for creating & ending traces / spans: `client.do_something(<id>, data)`. Can we take that approach?",also object consistent run like run object id alone approach well object fine agree client span data structured way client ending id data take approach,issue,positive,positive,positive,positive,positive,positive
2019115152,"Would this be related to an issue that I have with running evaluate on an XGBoost model? Getting the error:

File ""C:\Python310\lib\site-packages\mlflow\models\utils.py"", line 577, in _enforce_named_col_schema
    new_pf_input[x] = _enforce_mlflow_datatype(x, pf_input[x], input_types[x])
  File ""C:\Python310\lib\site-packages\mlflow\models\utils.py"", line 554, in _enforce_mlflow_datatype
    raise MlflowException(
mlflow.exceptions.MlflowException: Incompatible input types for column Feature_RecruiterState. Can not safely convert category to <U0.",would related issue running evaluate model getting error file line file line raise incompatible input column safely convert category,issue,negative,positive,positive,positive,positive,positive
2019065245,"Also returning the object is consistent with existing run APIs, like [client.create_run()](https://mlflow.org/docs/latest/python_api/mlflow.client.html#mlflow.client.MlflowClient.create_run) returns Run object not Id alone. [Langfuse APIs](https://langfuse.com/docs/sdk/python/low-level-sdk) follows same approach as well.",also object consistent run like run object id alone approach well,issue,negative,positive,positive,positive,positive,positive
2019060253,"@BenWilson2 

> keep track of which returned span wrapper object is which, leading to a confusing developer experience, which the client API is designed to avoid.

Hmm there is no difference between what users need to keep track between whether we return id or span object. If user doesn't keep track of span_id, how users propagate it to where `end_span() is called?

> restrict the use of the client API to atomic operations like this (only permitting the explicit start and the explicit end of spans and traces) 

What do you mean by 'atomic' here? There is no stateful operation in current API as well. 

One problem of returning span id is that it cause difference between `with mlflow.start_span()` and `client.start_span()` which is confusing.",keep track returned span wrapper object leading developer experience client designed avoid difference need keep track whether return id span object user keep track propagate restrict use client atomic like explicit start explicit end mean stateful operation current well one problem span id cause difference,issue,negative,negative,negative,negative,negative,negative
2019015650,"@prithvikannan Thanks! Yes, I have done the manual testing (logging from my laptop and check the UI):
<img width=""790"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/22925031/e31e945a-cec0-4613-b9aa-96067bb1b10f"">
",thanks yes done manual testing logging check image,issue,positive,positive,positive,positive,positive,positive
2018929118,"For the return types for the `start_` APIs, we could return `context` information (containing the required trace_id, span_id, and parent_span_id) instead of the span objects themselves to facilitate creation of child spans and for closure of spans that have been created. ",return could return context information instead span facilitate creation child closure,issue,negative,neutral,neutral,neutral,neutral,neutral
2018923238,"To maintain parity with the behavior of the client APIs, we should look at changing the implementation such that `start_span` has arguments that allow for the creation of the ""pre-call"":
```
def start_span(self, name: str, trace_id: str, parent_span_id: str, span_type: Optional[str], inputs, attributes: Optional[Dict[str,Any]]):
```
returning the span_id from the call, not the `MLflowSpanWrapper` instance. 

For the complementary `end_span` client API:

```
def end_span(self, span_id: str, outputs, attributes: Optional[Dict[str, Any]], events: List[Dict[str, Any]]) -> None
```

The return of the wrapper exposes a mutable object that creates, for simple use cases, an inviting API, but blurs the boundary between the context manager-based fluent API. For more complex use cases, this will likely prove frustrating to users to keep track of which returned span wrapper object is which, leading to a confusing developer experience, which the client API is designed to avoid. 

Could we pare down the implementation to restrict the use of the client API to atomic operations like this (only permitting the explicit start and the explicit end of spans and traces) so that users can manage all of the state locality from within their logic, calling the client APIs explicitly around their logic for starting and ending?",maintain parity behavior client look implementation allow creation self name optional optional call instance complementary client self optional list none return wrapper mutable object simple use inviting boundary context fluent complex use likely prove keep track returned span wrapper object leading developer experience client designed avoid could pare implementation restrict use client atomic like explicit start explicit end manage state locality within logic calling client explicitly around logic starting ending,issue,negative,negative,neutral,neutral,negative,negative
2018553400,We can remove can delete permission from Manage user that way manage users will be able to grant permission and only admin users will be able to delete. ,remove delete permission manage user way manage able grant permission able delete,issue,negative,positive,positive,positive,positive,positive
2018542822,"Hi, I can work on this, but after code change only the admin user will be able to grant permission to Registered Models since manage permission is required to grant permissions.",hi work code change user able grant permission registered since manage permission grant,issue,positive,positive,positive,positive,positive,positive
2018388532,"@WeichenXu123 Oh, you are right. By ""appending"", I meant appending the column ""answer_similarity_score"" to existing rows. I didn't think about the new rows. I was going to pass the entire dataframe, even though it is inefficient to recompute the results. ",oh right meant column think new going pas entire even though inefficient recompute,issue,negative,positive,positive,positive,positive,positive
2018367562,"emm, I think current `mlflow.evaluate` doesn't support this patten. for each `mlflow.evalute` invocation, you have to prepare the whole dataset you want to evaluate",think current support patten invocation prepare whole want evaluate,issue,negative,positive,neutral,neutral,positive,positive
2018342357,"@WeichenXu123 To avoid duplicates. Let's say I add a new row in the prompt engineering ui, generate metrics (by iterating over runs, which use a different prompt, in experiment), add another row and generate metrics again. This will create many duplicates over time, so I am thinking of appending to or overwriting ""eval_results_table.json"". Plus I am not sure what will happen to the aggregate metrics (e.g. average).",avoid let say add new row prompt engineering generate metric use different prompt experiment add another row generate metric create many time thinking plus sure happen aggregate metric average,issue,negative,positive,positive,positive,positive,positive
2018324266,"oh, got it, but why you need to append metric ? why not generate them in one `evalaute` call` ?",oh got need append metric generate one call,issue,negative,neutral,neutral,neutral,neutral,neutral
2018219564,"I think mlflow should be compatible with cloudpickle>=3, even if it says contraint cloudpckle<3, can you force reinstall cloudpickle >=3 and try your artifacts again ?",think compatible even force reinstall try,issue,negative,neutral,neutral,neutral,neutral,neutral
2018213090,"@WeichenXu123 I meant [LLM evaluation metrics](https://mlflow.org/docs/latest/llms/llm-evaluate/index.html#metrics-with-llm-as-the-judge) such as correctness for each row/input. (`mlflow.evaluate` also creates ""global"" metrics such as average answer correctness score)

Since the prompt engineering UI doesn't add metrics, they need to be ""appended"" programmatically. ",meant evaluation metric correctness also global metric average answer correctness score since prompt engineering add metric need programmatically,issue,negative,negative,neutral,neutral,negative,negative
2018184480,"You can use

```
with mlflow.start_run(run_id='an existing run id'):
  mlflow.log_metric(...)
```

to add any metric value to existing run.",use run id add metric value run,issue,negative,neutral,neutral,neutral,neutral,neutral
2017892776,"`.pick` returns a `RunnablePick` object, it's not supported as well. Seems `dict()` can exist in lots of the runnables but there're no existing way of loading them back in langchain, we should improve the logic to raise exception when saving (instead of loading) if the type is not supported.",object well exist lot way loading back improve logic raise exception saving instead loading type,issue,positive,neutral,neutral,neutral,neutral,neutral
2017783122,"> @serena-ruan I used:
> 
> ```
> conda_env = {
>     ""channels"": [""defaults"", ""conda-forge""],
>     ""dependencies"": [f""python={3.11}"", ""pip"", ""git""],
>     ""pip"": [
>         ""git+https://github.com/serena-ruan/mlflow.git@fix_lc"", 
>         ""mlflow"",
>         ""databricks"",
>         ""databricks-vectorsearch"",
>         ""langchain"",
>         ""langchain_core"",
>         ""langchain_community"",
>         ""cloudpickle"",
>         ""tiktoken"",
>         ""pydantic==2.6.3""
>     ],
>     ""name"": ""mlflow-env"",
> }
> ```
> 
> and now I invoke the model got the error:
> 
> ```
> MlflowException: Unsupported type None for loading.
> File <command-409646169956364>, line 7
>       1 dialog_example = {
>       2     ""messages"": [
>       3         {""role"": ""user"", ""content"": ""o que indicar para dor de cabeça?""}
>       4     ]
>       5 }
> ----> 7 model = mlflow.langchain.load_model(model_info.model_uri)
>       9 model.invoke(dialog_example)
> File /local_disk0/.ephemeral_nfs/envs/pythonEnv-4a0f43f1-9b27-49a2-a6a0-577c0fda3c61/lib/python3.10/site-packages/mlflow/langchain/__init__.py:732, in load_model(model_uri, dst_path)
>     710 """"""
>     711 Load a LangChain model from a local file or a run.
>     712 
>    (...)
>     729     A LangChain model instance.
>     730 """"""
>     731 local_model_path = _download_artifact_from_uri(artifact_uri=model_uri, output_path=dst_path)
> --> 732 return _load_model_from_local_fs(local_model_path)
> File /local_disk0/.ephemeral_nfs/envs/pythonEnv-4a0f43f1-9b27-49a2-a6a0-577c0fda3c61/lib/python3.10/site-packages/mlflow/langchain/__init__.py:705, in _load_model_from_local_fs(local_model_path)
>     703 flavor_conf = _get_flavor_configuration(model_path=local_model_path, flavor_name=FLAVOR_NAME)
>     704 _add_code_from_conf_to_system_path(local_model_path, flavor_conf)
> --> 705 return _load_model(local_model_path, flavor_conf)
> File /local_disk0/.ephemeral_nfs/envs/pythonEnv-4a0f43f1-9b27-49a2-a6a0-577c0fda3c61/lib/python3.10/site-packages/mlflow/langchain/__init__.py:515, in _load_model(local_model_path, flavor_conf)
>     513 with register_pydantic_v1_serializer_cm():
>     514     if model_load_fn == _RUNNABLE_LOAD_KEY:
> --> 515         model = _load_runnables(local_model_path, flavor_conf)
>     516     elif model_load_fn == _BASE_LOAD_KEY:
>     517         model = _load_base_lcs(local_model_path, flavor_conf)
> File /local_disk0/.ephemeral_nfs/envs/pythonEnv-4a0f43f1-9b27-49a2-a6a0-577c0fda3c61/lib/python3.10/site-packages/mlflow/langchain/runnables.py:428, in _load_runnables(path, conf)
>     426 model_data = conf.get(_MODEL_DATA_KEY, _MODEL_DATA_YAML_FILE_NAME)
>     427 if model_type in (x.__name__ for x in lc_runnable_with_steps_types()):
> --> 428     return _load_runnable_with_steps(os.path.join(path, model_data), model_type)
>     429 if (
>     430     model_type in (x.__name__ for x in picklable_runnable_types())
>     431     or model_data == _MODEL_DATA_PKL_FILE_NAME
>     432 ):
>     433     return _load_from_pickle(os.path.join(path, model_data))
> File /local_disk0/.ephemeral_nfs/envs/pythonEnv-4a0f43f1-9b27-49a2-a6a0-577c0fda3c61/lib/python3.10/site-packages/mlflow/langchain/runnables.py:126, in _load_runnable_with_steps(file_path, model_type)
>     124     config = steps_conf.get(step)
>     125     # load model from the folder of the step
> --> 126     runnable = _load_model_from_path(os.path.join(steps_path, step), config)
>     127     steps[step] = runnable
>     129 if model_type == RunnableSequence.__name__:
> File /local_disk0/.ephemeral_nfs/envs/pythonEnv-4a0f43f1-9b27-49a2-a6a0-577c0fda3c61/lib/python3.10/site-packages/mlflow/langchain/runnables.py:87, in _load_model_from_path(path, model_config)
>      85     return _load_base_lcs(path, model_config)
>      86 if model_load_fn == _CONFIG_LOAD_KEY:
> ---> 87     return _load_model_from_config(path, model_config)
>      88 raise MlflowException(f""Unsupported model load key {model_load_fn}"")
> File /local_disk0/.ephemeral_nfs/envs/pythonEnv-4a0f43f1-9b27-49a2-a6a0-577c0fda3c61/lib/python3.10/site-packages/mlflow/langchain/runnables.py:77, in _load_model_from_config(path, model_config)
>      75 elif _type in custom_type_to_loader_dict():
>      76     return custom_type_to_loader_dict()[_type](config)
> ---> 77 raise MlflowException(f""Unsupported type {_type} for loading."")
> ```

I'm getting this issue now as well when I added a  RunnablePassthrough .assign answer

```question_without_history_chain = (
  RunnableParallel(
    # itemgetter returns the values of a dictionary key
    context = itemgetter(""messages"") | RunnableLambda(extract_question) | retriever_from_llm,
    question = itemgetter(""messages"") | RunnableLambda(extract_question)
  ) #.assign(answer=rag_sources)
  | RunnablePassthrough.assign(sources=(lambda x: get_doc_metadata(x[""context""])))
  # | question_without_history_prompt
  # | chat_model
  # | StrOutputParser()
).assign(answer=(RunnablePassthrough.assign(sources=(lambda x: x['sources']))
  | question_without_history_prompt
  | chat_model
  | StrOutputParser()
)).pick(['answer','sources'])```",used pip git pip name invoke model got error unsupported type none loading file line role user content para dor de model file load model local file run model instance return file return file model model file path return path return path file step load model folder step runnable step step runnable file path return path return path raise unsupported model load key file path return raise unsupported type loading getting issue well added answer dictionary key context question lambda context lambda,issue,negative,neutral,neutral,neutral,neutral,neutral
2017152781,"emm, interesting, did you do  some profiling to confirm which function causes it ? e.g. it might trigger some I/O such as writing data to database.

btw, seemingly this is not a bug but a performance issue.",interesting confirm function might trigger writing data seemingly bug performance issue,issue,negative,positive,positive,positive,positive,positive
2017124580,"> @WeichenXu123 It is more like we want to define experiments on the organization level. Each experiment will represent one specific product or modality, and no one should delete or modify those. Users should only limit themselves to Runs and Model Registry, and not the Experiements.

In this case,

I think we'd better design a experiment namespace ""organisation"", the administrator grants ""organisation"" permission. And each user create their own experiment in organization which they have permission.",like want define organization level experiment represent one specific product modality one delete modify limit model registry case think better design experiment administrator permission user create experiment organization permission,issue,positive,positive,positive,positive,positive,positive
2017122473,"> @WeichenXu123 I would like to but my schedule is busy these days. Also, it will take me more time since I am not familiar with the codebase. Is it possible to assign it to someone else (if someone is willing)?

I added this with help wanted label to see whether we get volunteers for this.",would like schedule busy day also take time since familiar possible assign someone else someone willing added help label see whether get,issue,positive,positive,positive,positive,positive,positive
2017069570,"In 2.11.*, line chart data is sub-sampled. This makes MLFlow unuseable for me. Had to downgrade to 2.10. I couldn't find a setting to change sub-sampling setting (or if that is possible at all?).

2.11.3 - Uneven sampling rate, very low sampling rate. For some data, only the last data point is shown
![image](https://github.com/mlflow/mlflow/assets/26946864/6189a387-f1aa-435b-871b-37cf25a701c8)

2.10.2 - Showing the same data as above
![image](https://github.com/mlflow/mlflow/assets/26946864/8b530e4e-304e-4e15-ae6a-87d0a268c675)
",line chart data downgrade could find setting change setting possible uneven sampling rate low sampling rate data last data point shown image showing data image,issue,negative,negative,neutral,neutral,negative,negative
2017041124,"@harupy This PR is missing a release-note label, adding `rn/none`. If this label is incorrect, please replace it with the correct label.",missing label label incorrect please replace correct label,issue,negative,negative,negative,negative,negative,negative
2016784856,"@WeichenXu123 I would like to but my schedule is busy these days. Also, it will take me more time since I am not familiar with the codebase. Is it possible to assign it to someone else (if someone is willing)?",would like schedule busy day also take time since familiar possible assign someone else someone willing,issue,negative,positive,positive,positive,positive,positive
2016782555,"@WeichenXu123 It is more like we want to define experiments on the organization level. Each experiment will represent one specific product or modality, and no one should delete or modify those. Users should only limit themselves to Runs and Model Registry, and not the Experiements.",like want define organization level experiment represent one specific product modality one delete modify limit model registry,issue,negative,neutral,neutral,neutral,neutral,neutral
2016782048,"@WeichenXu123 It is hard for me to work on this due to my busy schedule. Is it possible to assign someone else?
If not then you can reassign me, but I am not sure if when I might be able to do so.

I spent some time locating the trigger that grants these permissions upon model registration, but I couldn't find it.",hard work due busy schedule possible assign someone else reassign sure might able spent time trigger upon model registration could find,issue,negative,positive,neutral,neutral,positive,positive
2016568321,"I understand the reasoning and the change due to the changes with Keras 3.

However, I could not figure out from the docs that with Keras 3, I was supposed to use `mlflow.keras` instead of `mlflow.tensorflow`. I think it would be good to add a general remark at the top of [this page](https://mlflow.org/docs/latest/python_api/mlflow.tensorflow.html). The page already mentions a number of tensorflow version requirements, but it would be good to explicitly mention to use `mlflow.keras` for Keras >= 3.

Since we can still use `tensorflow.keras` I expect more users to continue trying to use `mlflow.tensorflow` as before.",understand reasoning change due however could figure supposed use instead think would good add general remark top page page already number version would good explicitly mention use since still use expect continue trying use,issue,positive,positive,positive,positive,positive,positive
2016239711,Make sense to me. I will talk with our team folks later for this FR.,make sense talk team later,issue,negative,neutral,neutral,neutral,neutral,neutral
2016185147,Yes you are right. I said that in the title and made a silly typo in the content!,yes right said title made silly typo content,issue,negative,negative,negative,negative,negative,negative
2015728190,"I'd like to piggyback on this task a bit though perhaps I should make an alternative issue. Please advise. 

I'd suggest there should be a way to disable signups. Perhaps in: https://github.com/mlflow/mlflow/blob/master/mlflow/server/auth/routes.py 

Perhaps with a new ini setting disable_signup in https://github.com/mlflow/mlflow/blob/master/mlflow/server/auth/basic_auth.ini + https://github.com/mlflow/mlflow/blob/master/mlflow/server/auth/config.py#L22.

It seems unintuitive to me that anyone can create a user when `default_permission = READ` is the default. This is explained in https://mlflow.org/docs/latest/auth/index.html#how-it-works but I ended up making my few users is_admin=t via editing the auth DB and then setting `default_permission = NO_PERMISSIONS`. I'd prefer to make them normal users and set the defaults to `default_permission = MANAGE`. ",like task bit though perhaps make alternative issue please advise suggest way disable perhaps perhaps new setting unintuitive anyone create user read default ended making via setting prefer make normal set manage,issue,positive,positive,positive,positive,positive,positive
2015438191,Thanks for confirming. @WeichenXu123 `autolog` should be batching requests so I'm wondering why it's getting a 429 error. @sagarsumant can you help us take a look too about why asynchronous metrics logging is not helping here?,thanks confirming wondering getting error help u take look asynchronous metric logging helping,issue,positive,positive,positive,positive,positive,positive
2015255120,"oh got it, thank you.

Then I think you mean to add a 'description' column (not row ) in the table to show the description of the Run ?",oh got thank think mean add column row table show description run,issue,negative,negative,negative,negative,negative,negative
2015238789,"@WeichenXu123 Hi, IMHO mlflow has a good feature that we can add descriptions to a run:

![image](https://github.com/mlflow/mlflow/assets/5236035/4ca08db3-8851-4090-adf2-95c4ea8caabc)

This is the ""description"" I mean. For different people it can be different thing, and I guess you (mlflow devs) must know much more scenarios to use it than I know! As for my own case, I want to write down a sentence to remind me of this run's special thing, e.g. ""fixed bug xxx"", ""let's try blahblah thing"".",hi good feature add run image description mean different people different thing guess must know much use know case want write sentence remind run special thing fixed bug let try thing,issue,positive,positive,positive,positive,positive,positive
2015230299,"> if there could be one more row - (run) description - in this page. Then it is easy to glance through all runs with descriptions.

Could you elaborate it ? What's the content in the description ? do you have an example ? Thanks!",could one row run description page easy glance could elaborate content description example thanks,issue,positive,positive,positive,positive,positive,positive
2015226205,"What if you allow user to create their own experiment, and user can only create / edit run in experiment created by him ? 

Or does your case require one user to edit run created by another user ?",allow user create experiment user create edit run experiment case require one user edit run another user,issue,positive,neutral,neutral,neutral,neutral,neutral
2014987630,"@daniellok-db By the way, I also see weird things in the ""model metrics"" panel as below, which I guess is the same bug thus I post here. If it is not the same cause, I will create another issue.

![image](https://github.com/mlflow/mlflow/assets/5236035/f9de0afc-18f9-4894-a29a-9f06c0987a60)
",way also see weird model metric panel guess bug thus post cause create another issue image,issue,negative,negative,negative,negative,negative,negative
2014793741,got it. the root cause is still `too many 429 error responses` which seemingly indicates that the server is overloaded,got root cause still many error seemingly server,issue,negative,positive,positive,positive,positive,positive
2014458940,"I've already fixed the issue, the command line to start the server should add `--serve-artifacts` argument.",already fixed issue command line start server add argument,issue,negative,positive,neutral,neutral,positive,positive
2014287341,"@B-Step62 The FlowInvoker change caused by our recently separating packages activities, we will discussion if we need to make 1.7.0 compatible with the old version, or update promptflow flavor code and promptflow version in ml-package-versions.yml to fit those changes after promptflow 1.7.0 release (we scheduled to release it today), I'll reply here as soon.

And for the new changes afterwards, would you mind open issues here https://github.com/microsoft/promptflow/issues so that we won't miss it? We will triage the github issue daily, I'm afraid I'll miss the PR notification, issue may be more visible, thank you!",change recently separating discussion need make compatible old version update flavor code version fit release release today reply soon new afterwards would mind open wo miss triage issue daily afraid miss notification issue may visible thank,issue,negative,positive,neutral,neutral,positive,positive
2014198413,"Make sense, happy to see your contribution PR!",make sense happy see contribution,issue,positive,positive,positive,positive,positive,positive
2014178369,"@mlflow-automation Thank you for the contribution! Could you fix the following issue(s)?

#### &#x26a0; Invalid PR template

This PR does not appear to have been filed using the MLflow PR template. Please copy the PR template from [here](https://raw.githubusercontent.com/mlflow/mlflow/master/.github/pull_request_template.md) and fill it out.",thank contribution could fix following issue invalid template appear template please copy template fill,issue,positive,neutral,neutral,neutral,neutral,neutral
2014117535,"One first step may be that, we additionally store type as a column in addition to the (string) value. For example, we store `42` as `""42"" with type int`. This does not work for lists or deeply nested types, but works for a large number of cases, such as learning rate, number of heads, etc, which are int/floats.",one first step may additionally store type column addition string value example store type work deeply work large number learning rate number,issue,positive,positive,positive,positive,positive,positive
2014097282,"I think this feature makes sense, but unfortunately it doesn't seem super straightforward to implement. I don't have the best context on this, but it looks like we always save params as strings:

https://github.com/mlflow/mlflow/blob/94c503f6609116c9e6c3246be3a6724511556651/mlflow/store/tracking/file_store.py#L954-L956

There seem to be some downstream things that depend on this (e.g. column types in DBs), so it won't be super easy to change.",think feature sense unfortunately seem super straightforward implement best context like always save seem downstream depend column wo super easy change,issue,positive,positive,positive,positive,positive,positive
2013292268,"@BenWilson2  I had  a similar issue with random password ""(f]#o*Ej:3Il_|lyO:4N%_5JtH3H"" provided by AWS RDS. 

Yes, as a solution this password can be percent-encoded manually before usage, but it doesn't work with automatic password rotation. 

Is there a way to add percent-encoded to password before it was consumed and put into db connection url.
",similar issue random password provided yes solution password manually usage work automatic password rotation way add password put connection,issue,positive,negative,negative,negative,negative,negative
2013070008,Hi @harupy would you have any estimates on when it will be fixed either here in open-source version or inside Databricks? Thanks in advance.,hi would fixed either version inside thanks advance,issue,negative,positive,positive,positive,positive,positive
2012704892,I would like to express my interest for this feature as well. @nlgranger I would like to contribute to it if you're still interested you could look at it together?,would like express interest feature well would like contribute still interested could look together,issue,positive,positive,positive,positive,positive,positive
2012646917,@harupy can you approve CI action again (I guess after successful finish merge will be automatic)? It failed probably due to unset RN flag which you set up after the first approval.,approve action guess successful finish merge automatic probably due unset flag set first approval,issue,positive,positive,positive,positive,positive,positive
2012510111,"You can read doc: https://mlflow.org/docs/latest/tracking/tracking-api.html

""mlflow.source.git.commit"" tag will be automatically logged if in a git repository. This tag is only logged when the code is executed as a Python script like python train.py or as a project. If the code is executed in a notebook, this tag is not logged.",read doc tag automatically logged git repository tag logged code executed python script like python project code executed notebook tag logged,issue,negative,neutral,neutral,neutral,neutral,neutral
2012503425,"I think the version column is to show the ""mlflow.source.git.commit"" tag value. e.g., if you do:

```
with mlflow.start_run(tags={""mlflow.source.git.commit"": ""aabbcc""}):
    pass
```

The version column will show ""aabbcc"" for this run.",think version column show tag value pas version column show run,issue,negative,neutral,neutral,neutral,neutral,neutral
2012342587,"That said, it might be nice to support both. There are probably use cases to set environment variables at the time `mlflow models build-docker` is called.",said might nice support probably use set environment time,issue,positive,positive,positive,positive,positive,positive
2012326333,"Unfortunately not -- if we'd pass such a token in as an ENV then it would persist in the image (and anyone with access to the image could retrieve the token, which is a security risk). However, if we pass the token as an ARG, it is only present while the image is building.",unfortunately pas token would persist image anyone access image could retrieve token security risk however pas token present image building,issue,negative,negative,negative,negative,negative,negative
2012312626,Can we specify the docker image environment variable instead ?,specify docker image environment variable instead,issue,negative,neutral,neutral,neutral,neutral,neutral
2012173388,"@brynn-code It seems [a recent change](https://github.com/microsoft/promptflow/pull/2383) in PromptFlow master branch (will) breaks the flavor logic. The linked PR introduced two positional argument `flow_path` and `working_dir` to FlowInvoker, but they are not passed in the flavor when saving and loading a flow.

```
    def __init__(self, model, model_config: Optional[Dict[str, Any]] = None):
        from promptflow._sdk._mlflow import FlowInvoker
    
        self.model = model
        # TODO: Improve this if we have more configs afterwards
        model_config = model_config or {}
        connection_provider = model_config.get(_CONNECTION_PROVIDER_CONFIG_KEY, ""local"")
        _logger.info(""Using connection provider: %s"", connection_provider)
        connection_overrides = model_config.get(_CONNECTION_OVERRIDES_CONFIG_KEY, None)
        _logger.info(""Using connection overrides: %s"", connection_overrides)
>       self.model_invoker = FlowInvoker(
            self.model,
            connection_provider=connection_provider,
            connections_name_overrides=connection_overrides,
        )
E       TypeError: __init__() missing 2 required keyword-only arguments: 'flow_path' and 'working_dir'
```

Would you mind looking into this change and solve the issue (on either side) before the above change is released as a new PromptFlow version? Otherwise the flavor won't work with the new version. I tried to fix but not sure what we should pass to those parameters. Thank you for your support in advance!

(btw I use this thread as a contact point as it's easier to discover and share than e-mail, but let me know if you prefer different channel.) ",recent change master branch flavor logic linked two positional argument flavor saving loading flow self model optional none import model improve afterwards local connection provider none connection missing would mind looking change solve issue either side change new version otherwise flavor wo work new version tried fix sure pas thank support advance use thread contact point easier discover share let know prefer different channel,issue,positive,positive,neutral,neutral,positive,positive
2012130646,"Hi @WeichenXu123 , thanks to that, I got the whole stack trace indeed, I added it to the original post so please refer there. Here a picture of the envvars to show the envvars (`'MLFLOW_ENABLE_ASYNC_LOGGING'` and `'MLFLOW_AUTOLOGGING_TESTING'`) are set:

![image](https://github.com/mlflow/mlflow/assets/9294778/c2112fda-b56b-4d27-ac27-d352b792daba)",hi thanks got whole stack trace indeed added original post please refer picture show set image,issue,positive,positive,positive,positive,positive,positive
2011923745,"> This is a great idea! I'm very excited about the way that model cards will help ML practitioners present biases inherent to models in an easy-to-digest way for different stakeholders. I'll bring this up with the team, and I've added a priority label so that we can collect more community feedback

Was this feature implemented ?",great idea excited way model help present inherent way different bring team added priority label collect community feedback feature,issue,positive,positive,positive,positive,positive,positive
2011882438,"Could you send the error stack trace ?

You can add `os.environ[""MLFLOW_AUTOLOGGING_TESTING""] = ""true""` before running the programe, so that the autologging full stack trace will be outputed.",could send error stack trace add true running full stack trace,issue,negative,positive,positive,positive,positive,positive
2011859020,"Check, that's the one I'm executing before the `start_run()`. Unfortunately, that did not fix the warning and delay.

",check one unfortunately fix warning delay,issue,negative,negative,negative,negative,negative,negative
2011268791,Thanks @WeichenXu123 This looks correct! Could we add some tests? ,thanks correct could add,issue,negative,positive,positive,positive,positive,positive
2011027602,"Since this seems to be a duplicate of an already addressed issue, I will close this issue.",since duplicate already issue close issue,issue,negative,neutral,neutral,neutral,neutral,neutral
2011025662,"No, they are indeed not logged every single step, since the metrics are computed over one epoch. Meanwhile, I also log the train and test loss, which is logged every step. This might actually be related to the cause, since the same problem is not observed for the loss charts.",indeed logged every single step since metric one epoch meanwhile also log train test loss logged every step might actually related cause since problem loss,issue,negative,negative,neutral,neutral,negative,negative
2010896035,"I this is related to #11444. Are you logging your metrics at every single step, or only at some intervals?",related logging metric every single step,issue,negative,negative,neutral,neutral,negative,negative
2010893935,I'm not sure if I understand the question—could you maybe provide some code examples that show what you're describing? If you have an example of expected vs actual outputs that would be super helpful!,sure understand maybe provide code show example actual would super helpful,issue,positive,positive,positive,positive,positive,positive
2010427235,I found similar bug is there any update on this.,found similar bug update,issue,negative,neutral,neutral,neutral,neutral,neutral
2009531423,"Hmm, what version should that be then? I have mlflow 2.11.2 and azureml-mlflow 1.55.0, which are the latest versions on pypi. 
See picture from a debug run in PyCharm, I still get the Attribute error.
![image](https://github.com/mlflow/mlflow/assets/9294778/41918136-ffc8-4e7a-a26c-2a2a640a8b3b)

Is there a dev version of mlflow or azureml-mlflow package that I'm missing?",version latest see picture run still get attribute error image dev version package missing,issue,negative,positive,positive,positive,positive,positive
2009490222,"No, I meant `mlflow.enable_async_logging(enable=True)`. If the method is not there you are probably not running the latest version of MLflow and plugin as I mentioned.",meant method probably running latest version,issue,negative,positive,positive,positive,positive,positive
2009444872,"Sorry @daniellok-db just to clarify why 21 and not 20.1? (assuming it's a typo?)
Happy to do this, will create an MR later today",sorry clarify assuming typo happy create later today,issue,positive,positive,positive,positive,positive,positive
2009233898,"An especially annoying bug, since it's not immediately (i.e. after 5 minutes of Googling) clear how to silence this.",especially annoying bug since immediately clear silence,issue,negative,negative,negative,negative,negative,negative
2009026868,@sunishsheth2009 would you happen to know what's going on in the screenshot? I'm not super familiar with recipes so am having a tough time debugging this one,would happen know going super familiar tough time one,issue,positive,positive,positive,positive,positive,positive
2009019977,Filed #11475 to fix! The issue is with the sampling logic in the MLflow backend when metrics aren't logged for every single step.,fix issue sampling logic metric logged every single step,issue,negative,negative,neutral,neutral,negative,negative
2008927550,"Hi @santiagxf , thanks for your reply. I assume you mean `mlflow.config.enable_async_logging(enable=True)`, as in, add `.config`? If I don't, I get `AttributeError: module 'mlflow' has no attribute 'enable_async_logging'`.

Unfortunately, I still get the warning:

```
from azure.ai.ml import MLClient
from azure.identity import DefaultAzureCredential
import mlflow
import pandas as pd
import numpy as np
import xgboost


ml_client = MLClient(
    credential=DefaultAzureCredential(),
    subscription_id=""<MY_SUBSCRIPTION_ID>"",
    resource_group_name=""<MY_RESOURCE_GROUP>"",
    workspace_name=""<MY_WORKSPACE>""
)
ws = ml_client.workspaces.get(""<MY_WORKSPACE>"")
mlflow.set_tracking_uri(ws.mlflow_tracking_uri)
mlflow.config.enable_async_logging(enable=True) # <-- added before mlflow.start_run()

data = pd.DataFrame({'a': np.arange(10000), 'b': np.arange(10000) * 10, 'c': np.arange(10000) * 100})
X = data[['a', 'b']]
y = data['c']

mlflow.start_run()
mlflow.xgboost.autolog()
reg = xgboost.XGBRegressor(n_estimators=700)
reg.fit(X, y, eval_set=[(X, y)])
mlflow.end_run()
```",hi thanks reply assume mean add get module attribute unfortunately still get warning import import import import import import added data data data reg,issue,negative,negative,negative,negative,negative,negative
2008738419,"@daniellok-db  I think I see a different issue here 🤔 
Looking at the screenshots, I can see that certain aliases (""challenger"" for version 11 in this case) are displayed on the models list page but are missing on the model details page. This could be a bug and is possibly related to [this fix](https://github.com/mlflow/mlflow/pull/11223) - @kylegallatin is my assessment correct and if so, can you confirm that you're using the latest version that includes the fix above?",think see different issue looking see certain challenger version case displayed list page missing model page could bug possibly related fix assessment correct confirm latest version fix,issue,negative,positive,positive,positive,positive,positive
2008722265,"This makes sense, thanks for the report! If you'd like to contribute the fix, you can add `minimum: ""21.0.0""` to the YAML file here:

https://github.com/mlflow/mlflow/blob/2692f35ee18b6d06dee0de3d413d154af3c97576/requirements/core-requirements.yaml#L43-L46

Then run `python dev/generate_requirements.py` to update `core-requirements.txt`. I'll be happy to review the PR! If you don't have time for it, let me know and I can do it as well 😄 ",sense thanks report like contribute fix add minimum file run python update happy review time let know well,issue,positive,positive,positive,positive,positive,positive
2008590787,"@BenWilson2 Could you review this PR? I am willing to contribute a helm chart to community, and now  this helm chart supports:

- Tracking server:  can run with `--serve-artifacts`, `--no-serve-artifacts` and `artifacts-only` flags, supports basic authentication
- Artifact store: supports AWS S3, Google Cloud Storage(GCS), Azure Blob Storage, Alibaba Cloud OSS

In addition, it supports:

- all credentials will be stored in secrets and mount into the container as environment variables
- custom mlflow server arguments
- run `mlflow db upgrade` in init containers when `trackingServer.databaseUpgrade` is set to true
- custom extra init containers and containres
- custom extra environment variables
- custom extra volumes and volumemounts

Any advice is appreciated, thanks!
",could review willing contribute helm chart community helm chart server run basic authentication artifact store cloud storage azure blob storage cloud addition mount container environment custom server run upgrade set true custom extra custom extra environment custom extra advice thanks,issue,positive,positive,positive,positive,positive,positive
2008459307,"Thanks @BenWilson2 for sharing this. @matthiasschuurmans you may being throttled by the service due to a high volume of calls of `log_metric` method being done by `autolog()`. We have recently introduced asynchronous logging of metrics which allows sending a very high volume of metrics without having this issue.

To enable it, run the following before starting your run:

```python
import mlflow

mlflow.enable_async_logging(enable=True)
``` 

Please notice that asynchronous logging of metrics is available in the latest version of MLflow and `azureml-mlflow` plugin so it check for the latest versions installed. Please notice that this functionality is on preview.",thanks may service due high volume method done recently asynchronous logging metric sending high volume metric without issue enable run following starting run python import please notice asynchronous logging metric available latest version check latest please notice functionality preview,issue,positive,positive,positive,positive,positive,positive
2008381371,@santiagxf @akshaya-a would either of you have a chance to help them out? This is definitely not something we can help with :) ,would either chance help definitely something help,issue,positive,neutral,neutral,neutral,neutral,neutral
2008362290,cc @hubertzub-db is this intentional? my read on this is that it may be an intended separation of tags on the model-level and on the version-level.,intentional read may intended separation,issue,negative,neutral,neutral,neutral,neutral,neutral
2007504406,"![image](https://github.com/mlflow/mlflow/assets/98920963/5748a8d2-16f6-4e7b-b72e-da1e7ac21557)
I removed the last line, the problem has been solved!",image removed last line problem,issue,negative,neutral,neutral,neutral,neutral,neutral
2006376724,@serena-ruan I added a Issue to langchain for adding the deployment_name param to runnables.dict(). Hopefully the will implement it. https://github.com/langchain-ai/langchain/issues/19255,added issue param hopefully implement,issue,negative,neutral,neutral,neutral,neutral,neutral
2006344624,"Hi @harupy, this behavior is very difficult to understand from a user perspective. Even worst, the fact that the behavior is not stable depending on the backend led to a production issue on our side when switching from Stage to Aliases.
would it be possible to force aliases population when calling search_model_versions ? 

""The fix here is to just rely on the overall list of aliases attached to the parent registered model""",hi behavior difficult understand user perspective even worst fact behavior stable depending led production issue side switching stage would possible force population calling fix rely overall list attached parent registered model,issue,negative,negative,negative,negative,negative,negative
2006242996,"Experiencing the same problem

Edit: The running experiment has this problem:
A picture of an active experiment:
![Screenshot 2024-03-19 at 10 25 28 AM](https://github.com/mlflow/mlflow/assets/42416623/97b3ab2a-6303-4032-a6c5-57fd3077974d)

My previous recorded runs seem fine:
![Screenshot 2024-03-19 at 10 25 40 AM](https://github.com/mlflow/mlflow/assets/42416623/76cf9c92-53c5-4f19-8d0d-08eced15920d)
",problem edit running experiment problem picture active experiment previous seem fine,issue,negative,positive,neutral,neutral,positive,positive
2006188907,"@serena-ruan  I think using env vars would be undesirable behaviour, because mlflow should track from my point of view the deployment name as well (because its part of the Model). I can file a merge request, but the question is really if they want to change it especially if the runnable.json() method returns all variables that you need, that's why I addressed the issue here
",think would undesirable behaviour track point view deployment name well part model file merge request question really want change especially method need issue,issue,negative,positive,neutral,neutral,positive,positive
2006024502,"@daniellok-db @Cogniveon Unfortunately the current roadmap does not prioritize increasing usability on mobile devices 😞. We might focus in this a bit more when implementing report pages etc. in next major version, but I don't think there will be much more since there are other areas to focus on.
Despite that, if we consider users relying on mobile devices for monitoring experiments as a significant use case, we will be more than happy to see any improvements in that area. I strongly encourage to provide any contributions here + I believe we will be able to review pull requests when necessary. Similarly to what @daniellok-db said, I believe that the complex ""fix-all"" solution would be a huge undertaking - I'd rather see a plan with improving this aspect in one UI element/area at a time (e.g. focus separately on experiments list sidebar, experiments table, run details page etc.). This way, we can straighten up most painful areas as soon as possible.
@Cogniveon what are your thoughts? I'll happily discuss more if necessary",unfortunately current increasing usability mobile might focus bit report next major version think much since focus despite consider mobile significant use case happy see area strongly encourage provide believe able review pull necessary similarly said believe complex solution would huge undertaking rather see plan improving aspect one time focus separately list table run page way straighten painful soon possible happily discus necessary,issue,positive,positive,positive,positive,positive,positive
2005655388,"@SimonStanley1 For further clarification, you said 'azure_deployment' is not captured as part of the model's `dict()` function? In that case I think it should be fixed by Langchain side instead (Please raise an issue in Langchain repo), or you could use environment variables.",clarification said part model function case think fixed side instead please raise issue could use environment,issue,negative,positive,neutral,neutral,positive,positive
2005593371,"@daniellok-db Hi, just run

```
import mlflow
import random

with mlflow.start_run():
    for i in range(0, 300000, 1000):
        mlflow.log_metrics(dict(accuracy=random.random()), step=i)
```

(this range of step is realistic, since IMHO it is common to record per some steps instead of per epoch)

and see:

![image](https://github.com/mlflow/mlflow/assets/5236035/1635dbcd-6266-417d-9cc5-d15cfb8d1087)

execute that a few more times and see:

![image](https://github.com/mlflow/mlflow/assets/5236035/2f0e871c-7bc8-4dd2-8c0d-41230ac8baaf)

at the same time, another mlflow page works pretty well:

![image](https://github.com/mlflow/mlflow/assets/5236035/b919f8d7-d72e-4d04-b9f0-c6f3e2f10912)
",hi run import import random range range step realistic since common record per instead per epoch see image execute time see image time another page work pretty well image,issue,positive,negative,neutral,neutral,negative,negative
2005383938,"Sure, I will make a minimal reproducible sample later.",sure make minimal reproducible sample later,issue,negative,positive,positive,positive,positive,positive
2005225673,Could you share the code that generates the data in the charts?,could share code data,issue,negative,neutral,neutral,neutral,neutral,neutral
2005016793,"We've been hitting this for a while now on python 3.12. Gotten around it by adding setuptools as an explicit install dependency to projects using mlflow.

This is the only place it's used in the code base:

https://github.com/mlflow/mlflow/blob/79db4bc0ba7d147f168d5194ec0f91a5f7a8e442/mlflow/utils/requirements_utils.py#L165

I tried replacing `pkg_resources` with calls to `importlib_metadata` but that was causing tests to fail. Still haven't gotten to the bottom of it but `pkg_resources` was known to be buggy (that's part of why its deprecated).

I tried the below patch out but think someone more familiar with how this code is being used may need to take a look in to the test failure after applying it. `pytest` gets removed from the list of dependencies in `tests/utils/test_requirements_utils.py::test_infer_requirements_excludes_mlflow`.

```patch
git diff upstream/master
diff --git a/mlflow/utils/requirements_utils.py b/mlflow/utils/requirements_utils.py
index 57cb4ab92..3ec8f558a 100644
--- a/mlflow/utils/requirements_utils.py
+++ b/mlflow/utils/requirements_utils.py
@@ -17,7 +17,6 @@ from threading import Timer
 from typing import List, NamedTuple, Optional

 import importlib_metadata
-import pkg_resources  # noqa: TID251
 from packaging.requirements import Requirement
 from packaging.version import InvalidVersion, Version

@@ -162,10 +161,17 @@ def _normalize_package_name(pkg_name):

 def _get_requires(pkg_name):
     norm_pkg_name = _normalize_package_name(pkg_name)
-    if package := pkg_resources.working_set.by_key.get(norm_pkg_name):
-        for req in package.requires():
-            yield _normalize_package_name(req.name)
+    # Try to look up the distribution, if it is not installed, don't require it.
+    # Ex. Package is part of an uninstalled extra or installed with --no-deps.
+    requires = None
+    try:
+        requires = importlib_metadata.requires(norm_pkg_name)
+    except importlib_metadata.PackageNotFoundError:
+        _logger.debug(""Package %s not found in environment"", norm_pkg_name)

+    if requires is not None:
+        for req in requires:
+            yield _normalize_package_name(Requirement(req).name)

```

`importlib.metadata.distributions()` has been pretty much a drop in replacement for the working set in other projects. Maybe the code could be a bit simplified down if we're just looking for everything that's installed?

```python

def _get_pip_deps() -> list[str]:
    excluded = {
        ""pip"",
        ""setuptools"",
    }
    packages = [
        f""{dist.metadata['Name']}=={dist.version}""
        for dist in importlib.metadata.distributions()
        if dist.metadata[""Name""] not in excluded
    ]
    return packages

```",python gotten around explicit install dependency place used code base tried causing fail still gotten bottom known buggy part tried patch think someone familiar code used may need take look test failure removed list patch git git index import timer import list optional import tid import requirement import version package yield try look distribution require ex package part uninstalled extra none try except package found environment none yield requirement pretty much drop replacement working set maybe code could bit simplified looking everything python list pip name return,issue,negative,negative,negative,negative,negative,negative
2004993744,"Side note, I tried enabling all the `DTZ*` checks but there's quite a few places using non-timezone aware objects in the code base. It would be a much bigger PR to get all of them.",side note tried quite aware code base would much bigger get,issue,negative,negative,negative,negative,negative,negative
2004991198,"> Thanks for the PR! Can we enable https://docs.astral.sh/ruff/rules/call-datetime-utcnow/?

Sure can. Based on enabling a linter to check for datetime aware objects, it sounds like we want to keep these as aware objects vs. convert them back to naïve objects?

See https://github.com/mlflow/mlflow/issues/11414#issuecomment-1999740573",thanks enable sure based linter check aware like want keep aware convert back see,issue,positive,positive,positive,positive,positive,positive
2004595372,"hi folks, yea this makes a lot of sense. we have retry with exponential backoff logic in the LLM-as-judge part of `mlflow.evaluate()`, so it seems reasonable to also use this in the prediction path. 
",hi yea lot sense retry exponential logic part reasonable also use prediction path,issue,negative,positive,positive,positive,positive,positive
2004211572,Would it be possible to get an autologging function for metrics like there is in python? ,would possible get function metric like python,issue,negative,neutral,neutral,neutral,neutral,neutral
2003851057,"I see, then the error message looks misleading. And yes it should work for both workspace registry and UC registry, I ran the demo myself again on UC and it works fine so will need more information to debug on your case.
Please make sure your Databricks support raise an ES ticket and ping me so that I can log into your workspace and debug further :)",see error message misleading yes work registry registry ran work fine need information case please make sure support raise e ticket ping log,issue,positive,positive,positive,positive,positive,positive
2003844694,"@reslleygabriel Sorry by ES ticket I mean if you're using Databricks then you could file an ES ticket internally, but if you're just using MLflow OSS then pls ignore this comment :)
For further clarification: Is this `configurable_fields` introduced in your loader_fn or it's part of the chain itself? If it's part of the chain itself, then I think currently we do not support `RunnableConfigurableFields` class type (the output type of configurable_fields) saving/loading. It needs extra handling, you could test it by direct saving `vs_retriever.dict()` to a yaml file, I had a simple test and the output looks like this:
<img width=""735"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/82044803/443a1d00-8838-4f2d-8eed-5351f158437f"">
So this type of `ConfigurableFields` is not supported for saving/loading in Langchain yet, we'll add this to the roadmap but consider the complexity & urgency then decide when to support this :)",sorry e ticket mean could file e ticket internally ignore comment clarification part chain part chain think currently support class type output type need extra handling could test direct saving file simple test output like image type yet add consider complexity urgency decide support,issue,positive,negative,negative,negative,negative,negative
2003639243,@DouglasKrouth Thanks for the changes! Could you also update https://github.com/mlflow/mlflow/blob/79db4bc0ba7d147f168d5194ec0f91a5f7a8e442/mlflow/ml-package-versions.yml#L56-L61 to use lightning instead? We can trigger the workflow after this change :) ,thanks could also update use lightning instead trigger change,issue,negative,positive,positive,positive,positive,positive
2003154816,"thought that as well, the question is if you want to have more control over _type variable if yes another solution would be to hard code it when saving the model and picking it up like in the proposal I did. Overall integration in langchains get_type_to_cls_dict() would be possible the best way for now, from my point of view. 

The only problem with that could be that in the newer release langchain_openai needs to be installed and imported. AzureChatOpenAI is only in langchain_openai present",thought well question want control variable yes another solution would hard code saving model like proposal overall integration would possible best way point view problem could release need present,issue,positive,positive,positive,positive,positive,positive
2002963654,"Hi, is there any updates? The tensorboard histogram is quite useful and I really miss it when using mlflow!",hi histogram quite useful really miss,issue,negative,positive,positive,positive,positive,positive
2002959476,"> I'm not sure if get_deployments_target should throw. Returning None when the target hasn't been set seems fine. The caller can decide what do if get_deployments_target returns None.

Returning `None` itself is ok, but the issue is none of the consuming code in MLflow does null-check for it and raise NPE with confusing stack trace. We can add check every place, but I'm wondering the nullability is really an intended behavior.

@dbczumar You were in [the original PR](https://github.com/mlflow/mlflow/pull/10528), do you happen to remember any context behind this decision? ",sure throw none target set fine caller decide none none issue none consuming code raise stack trace add check every place wondering really intended behavior original happen remember context behind decision,issue,positive,positive,positive,positive,positive,positive
2002951426,I'm not sure if `get_deployments_target` should throw. Returning None when the target hasn't been set seems fine. The caller can decide what do if `get_deployments_target` returns None. ,sure throw none target set fine caller decide none,issue,negative,positive,positive,positive,positive,positive
2002863310,I met this error and very tired to fix it. My way is change `database_uri` in `basic_auth.ini` to `sqlite:///basic_auth.db` instead `mysql+mysqldb://mlflow_admin:my_pass@my_host:3306/mlflow`. I accept risky when store auth to sqlite.,met error tired fix way change instead accept risky store,issue,negative,negative,negative,negative,negative,negative
2002747951,"If you'd like to use Keras 3 with MLflow, you can call `mlflow.keras.save_model()` or `log_model()` instead of `mlflow.tensorflow`! Note that this requires mlflow>=2.11.0.

The `mlflow.tensorflow` flavor is for Keras < 3, since prior to that it was bundled into the tensorflow package. I think this is all intended behavior, but please let us know if there are areas in the docs that were unclear about this.",like use call instead note flavor since prior package think intended behavior please let u know unclear,issue,negative,neutral,neutral,neutral,neutral,neutral
2002724386,"> The code makes sense to me, but in the PR description, could you add more details on what bug this fixes?
> 
> A code example of failure vs. expected behavior would be super helpful as well for future people referencing this PR!

updated PR description. I think full code example might be really long as there's a lot of setup involved, is it still worth adding or is it suffice to link a notebook in dogfood. (obviously not everyone will have access to this is the main problem) I think this problem exists for any LC vector search model using Databricks managed embeddings. ",code sense description could add bug code example failure behavior would super helpful well future people description think full code example might really long lot setup involved still worth suffice link notebook obviously everyone access main problem think problem vector search model,issue,negative,positive,neutral,neutral,positive,positive
2002681694,cc @serena-ruan would you mind taking a look at this proposal for Azure OpenAI?,would mind taking look proposal azure,issue,negative,neutral,neutral,neutral,neutral,neutral
1999740573,"After reading into why it was deprecated, it seemed best to add the offset to the timestamp so the datetimes are aware of their timezone being utc. We could remove that offset and make them back into ""naïve"" datetime objects.  so they end up exactly the same if that's a better course of action.

Just let me know and I can make changes to the PR.

```python
import datetime

# This never truly did what one would think it does because it's missing an offset 
# A ""naive"" datetime object
print(datetime.datetime.utcnow())
2024-03-15 14:00:43.654328

# Puts a proper offset in the timezone
print(datetime.datetime.now(datetime.timezone.utc))
2024-03-15 14:00:43.654328+00:00

# This one is exactly the same as current. But it makes the object naive again.
print(datetime.datetime.now(datetime.timezone.utc).replace(tzinfo=None))
2024-03-15 14:00:43.655328

```",reading best add offset aware could remove offset make back end exactly better course action let know make python import never truly one would think missing offset naive object print proper offset print one exactly current object naive print,issue,negative,positive,positive,positive,positive,positive
1999689450,"@serena-ruan  No worries. 

Yes I had to add the environment variable for that CLI error.

For the original problem, yes if I just locally load the model from MLflow it works.",yes add environment variable error original problem yes locally load model work,issue,negative,positive,positive,positive,positive,positive
1999421791,"Hi, @BenWilson2 @harupy @B-Step62. Sorry for the broad mention here, could any of you take a look at my previous comment? Thank you.",hi sorry broad mention could take look previous comment thank,issue,negative,negative,negative,negative,negative,negative
1999413661,Ended up stuck here while following this example: https://mlflow.org/docs/latest/llms/prompt-engineering/index.html,ended stuck following example,issue,negative,neutral,neutral,neutral,neutral,neutral
1999125460,"Indeed, tf 2.15 is supposed to go with keras 2.15 normally. But it works with keras 3.0.x in general. Kaggle actually now uses keras 3 by default. [See announcement.](https://www.kaggle.com/discussions/product-feedback/480821) 

The env variable resolves it, as well as downgrading keras to 2.15.",indeed supposed go normally work general actually default see announcement variable well,issue,negative,positive,neutral,neutral,positive,positive
1999027687,"I think this might be caused by TF 2.15 being incompatible with Keras 3: https://keras.io/getting_started/#tensorflow--keras-2-backwards-compatibility (which explains why setting `os.environ[""TF_USE_LEGACY_KERAS""] = ""1""` fixes the issue)",think might incompatible setting issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1999024248,"While I think this change is a good idea in principle, I'm worried about this potentially breaking stuff, especially since the two objects don't seem to be exactly the same. I agree that the timezone shouldn't matter here, but it might be difficult to verify if anyone/anything was relying on it, etc.",think change good idea principle worried potentially breaking stuff especially since two seem exactly agree matter might difficult verify,issue,negative,positive,neutral,neutral,positive,positive
1999008426,"Thanks for bringing this up! Feel free to file a PR to contribute, the guide for docs is here: https://github.com/mlflow/mlflow/blob/master/CONTRIBUTING.md#writing-docs

Let me know if you have any trouble getting set up.",thanks feel free file contribute guide let know trouble getting set,issue,positive,positive,positive,positive,positive,positive
1999002679,"Ah, I see your point now. cc @prithvikannan what's required for the prompt engineering UI to show up in the evaluate tab? Is it possible for the user to construct the artifacts manually?",ah see point prompt engineering show evaluate tab possible user construct manually,issue,negative,neutral,neutral,neutral,neutral,neutral
1998819453,"@daniellok-db thanks for getting back. Yes I log manually info as well, but the problem is that it's not logged the same way as when the run is created on the UI.
For example in the attached image we see the variables like max_tokens and prompt as variables of the run, we don't see that when the run is created programmatically. ![image](https://github.com/mlflow/mlflow/assets/23370317/a6875d17-4a4d-4372-8f9f-e5d18431683a)",thanks getting back yes log manually well problem logged way run example attached image see like prompt run see run programmatically image,issue,positive,positive,neutral,neutral,positive,positive
1998738637,"@serena-ruan thank you very much for you help so far.

I load the model with:

```
with mlflow.start_run(run_name=""test"") as run:
    input_example = dialog_example
    output = final_rag_chain.invoke(dialog_example)
    signature = infer_signature(input_example, output)
    model_info = mlflow.langchain.log_model(
        final_rag_chain,
        loader_fn=get_vector_search_retriever,
        artifact_path=""chain"",
        registered_model_name=model_name,
        conda_env=conda_env, #instead of pip_requirements
        input_example=input_example,
        example_no_conversion=True,
        signature=signature,
    )
```

At some point in the chain, I get as output from a router function a config that I want to apply to the retriever in runtime.

Its an object like: 

`config = {""configurable"": {""search_kwargs_vectorstore"": {""k"": 10, 'filters': {'field_x': False}}}}`

Then I call the next chain with this new config:

`chain.with_config(config=config)`

This chain, then apply the retriever that was previously created containing the configurable_fields

```
chain = (
    RunnablePassthrough()
    | {
        ""relevant_docs"": prompt
        | chat
        | StrOutputParser()
        | vs_retriever
    }
```

The vs_retriever is a variable that contains the retriever with the configurable_fields already set up

```
return vectorstore.as_retriever(search_kwargs={""k"": 30}).configurable_fields(
        search_kwargs=ConfigurableField(
            id=""search_kwargs_vectorstore"",
            name=""Search Kwargs"",
            description=""The search kwargs to use"",
        )
    )
```

This error does not occur when I return the retriever without using configurable_fields:

`return vectorstore.as_retriever(search_kwargs={""k"": 10})`

For reference, here's the documentation on ConfigurableField: [Langchain ConfigurableField Documentation](https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.utils.ConfigurableField.html#langchain_core.runnables.utils.ConfigurableField)

At last, how do I file an ES ticket so you can dig into my notebook and debug faster?",thank much help far load model test run output signature output chain instead point chain get output router function want apply retriever object like false call next chain new chain apply retriever previously chain prompt chat variable retriever already set return search search use error occur return retriever without return reference documentation documentation last file e ticket dig notebook faster,issue,positive,negative,neutral,neutral,negative,negative
1998712753,"I see, this means the config file doesn't contain a key named `_type`. Could you provide a screenshot to the internal config files saved for your model? My guess is that some component's `save` or `dict` function doesn't correctly create a config file with `_type` key (this is inside langchain) and we depends on the `_type` to see if we could load it back or not. 
**Could you file an ES ticket so we can dig into your notebook and debug faster?**
It's also possible that the component just does not support save/load, as what we're doing in MLflow  is trying our best to save and load components Langchain doesn't support.",see file contain key could provide internal saved model guess component save function correctly create file key inside see could load back could file e ticket dig notebook faster also possible component support trying best save load support,issue,positive,positive,positive,positive,positive,positive
1998695720,"The prompt engineering UI has a lot of stuff logged automatically, but it should be fully possible to log all of those things manually as well. 

cc @serena-ruan, does the langchain autologging feature support logging stuff like max tokens, temperature, template, etc?",prompt engineering lot stuff logged automatically fully possible log manually well feature support logging stuff like temperature template,issue,positive,neutral,neutral,neutral,neutral,neutral
1998691890,"Thanks for the report, I'll try to dig into what's going wrong here.",thanks report try dig going wrong,issue,negative,negative,negative,negative,negative,negative
1998668208,"@CarlosLabrado Sorry for the late reply. `invalidConfigurationError(\""You haven\\'t configured the CLI yet!` usually happens when there're environment variables missing during endpoint creation.

The original problem looks weird... because you definitely have that folder. If you load the model locally does it work?",sorry late reply yet usually environment missing creation original problem weird definitely folder load model locally work,issue,negative,negative,negative,negative,negative,negative
1998416888,"@serena-ruan I used:


```
conda_env = {
    ""channels"": [""defaults"", ""conda-forge""],
    ""dependencies"": [f""python={3.11}"", ""pip"", ""git""],
    ""pip"": [
        ""git+https://github.com/serena-ruan/mlflow.git@fix_lc"", 
        ""mlflow"",
        ""databricks"",
        ""databricks-vectorsearch"",
        ""langchain"",
        ""langchain_core"",
        ""langchain_community"",
        ""cloudpickle"",
        ""tiktoken"",
        ""pydantic==2.6.3""
    ],
    ""name"": ""mlflow-env"",
}
```

and now I invoke the model got the error:

```
MlflowException: Unsupported type None for loading.
File <command-409646169956364>, line 7
      1 dialog_example = {
      2     ""messages"": [
      3         {""role"": ""user"", ""content"": ""o que indicar para dor de cabeça?""}
      4     ]
      5 }
----> 7 model = mlflow.langchain.load_model(model_info.model_uri)
      9 model.invoke(dialog_example)
File /local_disk0/.ephemeral_nfs/envs/pythonEnv-4a0f43f1-9b27-49a2-a6a0-577c0fda3c61/lib/python3.10/site-packages/mlflow/langchain/__init__.py:732, in load_model(model_uri, dst_path)
    710 """"""
    711 Load a LangChain model from a local file or a run.
    712 
   (...)
    729     A LangChain model instance.
    730 """"""
    731 local_model_path = _download_artifact_from_uri(artifact_uri=model_uri, output_path=dst_path)
--> 732 return _load_model_from_local_fs(local_model_path)
File /local_disk0/.ephemeral_nfs/envs/pythonEnv-4a0f43f1-9b27-49a2-a6a0-577c0fda3c61/lib/python3.10/site-packages/mlflow/langchain/__init__.py:705, in _load_model_from_local_fs(local_model_path)
    703 flavor_conf = _get_flavor_configuration(model_path=local_model_path, flavor_name=FLAVOR_NAME)
    704 _add_code_from_conf_to_system_path(local_model_path, flavor_conf)
--> 705 return _load_model(local_model_path, flavor_conf)
File /local_disk0/.ephemeral_nfs/envs/pythonEnv-4a0f43f1-9b27-49a2-a6a0-577c0fda3c61/lib/python3.10/site-packages/mlflow/langchain/__init__.py:515, in _load_model(local_model_path, flavor_conf)
    513 with register_pydantic_v1_serializer_cm():
    514     if model_load_fn == _RUNNABLE_LOAD_KEY:
--> 515         model = _load_runnables(local_model_path, flavor_conf)
    516     elif model_load_fn == _BASE_LOAD_KEY:
    517         model = _load_base_lcs(local_model_path, flavor_conf)
File /local_disk0/.ephemeral_nfs/envs/pythonEnv-4a0f43f1-9b27-49a2-a6a0-577c0fda3c61/lib/python3.10/site-packages/mlflow/langchain/runnables.py:428, in _load_runnables(path, conf)
    426 model_data = conf.get(_MODEL_DATA_KEY, _MODEL_DATA_YAML_FILE_NAME)
    427 if model_type in (x.__name__ for x in lc_runnable_with_steps_types()):
--> 428     return _load_runnable_with_steps(os.path.join(path, model_data), model_type)
    429 if (
    430     model_type in (x.__name__ for x in picklable_runnable_types())
    431     or model_data == _MODEL_DATA_PKL_FILE_NAME
    432 ):
    433     return _load_from_pickle(os.path.join(path, model_data))
File /local_disk0/.ephemeral_nfs/envs/pythonEnv-4a0f43f1-9b27-49a2-a6a0-577c0fda3c61/lib/python3.10/site-packages/mlflow/langchain/runnables.py:126, in _load_runnable_with_steps(file_path, model_type)
    124     config = steps_conf.get(step)
    125     # load model from the folder of the step
--> 126     runnable = _load_model_from_path(os.path.join(steps_path, step), config)
    127     steps[step] = runnable
    129 if model_type == RunnableSequence.__name__:
File /local_disk0/.ephemeral_nfs/envs/pythonEnv-4a0f43f1-9b27-49a2-a6a0-577c0fda3c61/lib/python3.10/site-packages/mlflow/langchain/runnables.py:87, in _load_model_from_path(path, model_config)
     85     return _load_base_lcs(path, model_config)
     86 if model_load_fn == _CONFIG_LOAD_KEY:
---> 87     return _load_model_from_config(path, model_config)
     88 raise MlflowException(f""Unsupported model load key {model_load_fn}"")
File /local_disk0/.ephemeral_nfs/envs/pythonEnv-4a0f43f1-9b27-49a2-a6a0-577c0fda3c61/lib/python3.10/site-packages/mlflow/langchain/runnables.py:77, in _load_model_from_config(path, model_config)
     75 elif _type in custom_type_to_loader_dict():
     76     return custom_type_to_loader_dict()[_type](config)
---> 77 raise MlflowException(f""Unsupported type {_type} for loading."")
```",used pip git pip name invoke model got error unsupported type none loading file line role user content para dor de model file load model local file run model return file return file model model file path return path return path file step load model folder step runnable step step runnable file path return path return path raise unsupported model load key file path return raise unsupported type loading,issue,negative,neutral,neutral,neutral,neutral,neutral
1997942744,"I was able to bypass this last error by modifying the get_retriever function based on[ this post](https://community.databricks.com/t5/machine-learning/problem-when-serving-a-langchain-model-on-databricks/td-p/59506/page/2) from ""DataWrangler"" 

```python
def get_retriever(persist_dir: str = None):
    import gunicorn

    import logging

    import traceback
    logging.basicConfig(filename='error.log', level=logging.DEBUG)

    os.environ[""DATABRICKS_HOST""] = host
    # Get the vector search index
    vsc = VectorSearchClient(workspace_url=os.environ[""DATABRICKS_HOST""],
                             personal_access_token=os.environ[""DATABRICKS_TOKEN""],
                             disable_notice=True)

    print('initialized VectorSearchClient')

    vs_index = vsc.get_index(
        endpoint_name=VECTOR_SEARCH_ENDPOINT_NAME,
        index_name=index_name
    )

    # Create the retriever
    try:
        print('trying to initialize vectorstore')
        vectorstore = DatabricksVectorSearch(
            vs_index, text_column=""content"", embedding=embedding_model, columns=[""url""]
        )

        retriever = vectorstore.as_retriever(search_kwargs={'k': 4})

        print('initialized vectorstore')

        return retriever
    except BaseException as e:
        print(""An error occurred:"", str(e))
        traceback.print_exc()


retriever = get_retriever()
```",able bypass last error function based post python none import import logging import host get vector search index print create retriever try print initialize content retriever print return retriever except print error retriever,issue,negative,positive,positive,positive,positive,positive
1997517308,"I can get past a bit further by not using a RunnableBranch:

```python
branch_node = RunnableBranch(
    (lambda x: ""yes"" in x[""question_is_relevant""].lower(), relevant_question_chain),
    (lambda x: ""no"" in x[""question_is_relevant""].lower(), irrelevant_question_chain),
    irrelevant_question_chain
)

full_chain = (
        {
            ""question_is_relevant"": is_about_databricks_chain,
            ""question"": itemgetter(""messages"") | RunnableLambda(extract_question),
            ""chat_history"": itemgetter(""messages"") | RunnableLambda(extract_history),
        }
        | branch_node 
)
```

to use a function instead:
```python
def route(info):
    if ""yes"" in info[""question_is_relevant""].lower():
        return relevant_question_chain
    elif ""no"" in info[""question_is_relevant""].lower():
        return irrelevant_question_chain
    else:
        return irrelevant_question_chain


full_chain = (
        {
            ""question_is_relevant"": is_about_databricks_chain,
            ""question"": itemgetter(""messages"") | RunnableLambda(extract_question),
            ""chat_history"": itemgetter(""messages"") | RunnableLambda(extract_history),
        }
        | RunnableLambda(route)
)

```

The endpoint is now created successfully, but when you make a call you get:
`{""error_code"": ""BAD_REQUEST"", ""message"": ""1 tasks failed. Errors: {0: 'error: InvalidConfigurationError(\""You haven\\'t configured the CLI yet! Please configure by entering `/opt/conda/envs/mlflow-env/bin/gunicorn configure`\"") Traceback (most recent call last):\\n  File \""/opt/conda/envs/mlflow-env/lib/python3.10/site-packages/mlflow/langchain/api_request_parallel_processor.py\"", line 206, in call_api\\n    response = self.lc_model.invoke(\\n  File \""/opt/conda/envs/mlflow-env/lib/python3.10/site-packages/langchain_core/runnables/base.py\"", line 2053, in invoke\\n    input = step.invoke(\\n  File \""/opt/conda/envs/mlflow-env/lib/python3.10/site-packages/langchain_core/runnables/base.py\"", line 2692, in invoke\\n    output = {key: future.result() for key, future in zip(steps, futures)}\\n  File \""/opt/conda/envs/mlflow-env/lib/python3.10/site-packages/langchain_core/runnables/base.py\"", line 2692, in <dictcomp>\\n    output = {key: future.result() for key, future in zip(steps, futures)}\\n  File \""/opt/conda/envs/mlflow-env/lib/python3.10/concurrent/futures/_base.py\"", line 458, in result\\n    return self.__get_result()\\n  File \""/opt/conda/envs/mlflow-env/lib/python3.10/concurrent/futures/_base.py\"", line 403, in __get_result\\n    raise self._exception\\n  File \""/opt/conda/envs/mlflow-env/lib/python3.10/concurrent/futures/thread.py\"", line 58, in run\\n    result = self.fn(*self.args, **self.kwargs)\\n  File \""/opt/conda/envs/mlflow-env/lib/python3.10/site-packages/langchain_core/runnables/base.py\"", line 2053, in invoke\\n    input = step.invoke(\\n  File \""/opt/conda/envs/mlflow-env/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\"", line 166, in invoke\\n    self.generate_prompt(\\n  File \""/opt/conda/envs/mlflow-env/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\"", line 544, in generate_prompt\\n    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\\n  File \""/opt/conda/envs/mlflow-env/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\"", line 408, in generate\\n    raise e\\n  File \""/opt/conda/envs/mlflow-env/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\"", line 398, in generate\\n    self._generate_with_cache(\\n  File \""/opt/conda/envs/mlflow-env/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\"", line 577, in _generate_with_cache\\n    return self._generate(\\n  File \""/opt/conda/envs/mlflow-env/lib/python3.10/site-packages/langchain_community/chat_models/mlflow.py\"", line 122, in _generate\\n    resp = self._client.predict(endpoint=self.endpoint, inputs=data)\\n  File \""/opt/conda/envs/mlflow-env/lib/python3.10/site-packages/mlflow/deployments/databricks/__init__.py\"", line 201, in predict\\n    return self._call_endpoint(\\n  File \""/opt/conda/envs/mlflow-env/lib/python3.10/site-packages/mlflow/deployments/databricks/__init__.py\"", line 138, in _call_endpoint\\n    host_creds=get_databricks_host_creds(self.target_uri),\\n  File \""/opt/conda/envs/mlflow-env/lib/python3.10/site-packages/mlflow/utils/databricks_utils.py\"", line 445, in get_databricks_host_creds\\n    config = provider.get_config()\\n  File \""/opt/conda/envs/mlflow-env/lib/python3.10/site-packages/databricks_cli/configure/provider.py\"", line 134, in get_config\\n    raise InvalidConfigurationError.for_profile(None)\\ndatabricks_cli.utils.InvalidConfigurationError: You haven\\'t configured the CLI yet! Please configure by entering `/opt/conda/envs/mlflow-env/bin/gunicorn configure`\\n\\n request payload: {\\'messages\\': [{\\'role\\': \\'user\\', \\'content\\': \\'What is Apache Spark?\\'}, {\\'role\\': \\'assistant\\', \\'content\\': \\'Apache Spark is an open-source data processing engine that is widely used in big data analytics.\\'}, {\\'role\\': \\'user\\', \\'content\\': \\'Does it support streaming?\\'}]}'}""}`
",get past bit python lambda yes lambda question use function instead python route yes return return else return question route successfully make call get message yet please configure entering configure recent call last file line response file line input file line output key key future zip file line output key key future zip file line return file line raise file line result file line input file line file line return file line raise file line file line return file line resp file line return file line file line file line raise none yet please configure entering configure request apache spark spark data engine widely used big data support streaming,issue,positive,positive,neutral,neutral,positive,positive
1997413149,"The difference between these two below. The utc aware timestamp has an offset of `+00:00`.  I believe that is ok. It wouldn't make a ton of sense to use the local timezone. 

```python
import datetime

print(datetime.datetime.utcnow())
2024-03-14 13:00:13.023986

print(datetime.datetime.now(datetime.timezone.utc))
2024-03-14 13:00:13.023986+00:00
```",difference two aware offset believe would make ton sense use local python import print print,issue,negative,positive,positive,positive,positive,positive
1997049341,"unsure whether this is the same issue, but i also can't run my test-project using `automl/flaml`.

```
❯ pdm run mlflow recipes clean --profile space-titanic && pdm run mlflow recipes run --profile space-titanic
2024/03/14 10:12:09 INFO mlflow.recipes.recipe: Creating MLflow Recipe 'mlflow-recipes' with profile: 'space-titanic'
2024/03/14 10:12:11 INFO mlflow.recipes.recipe: Creating MLflow Recipe 'mlflow-recipes' with profile: 'space-titanic'
Run MLflow Recipe step: ingest
2024/03/14 10:12:12 INFO mlflow.recipes.step: Running step ingest...
Run MLflow Recipe step: split
2024/03/14 10:12:13 INFO mlflow.recipes.step: Running step split...
/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.
  return bound(*args, **kwds)
/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/mlflow/recipes/steps/split.py:133: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.
  return data_subset.applymap(func)
/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/mlflow/recipes/steps/split.py:133: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.
  return data_subset.applymap(func)
/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/mlflow/recipes/steps/split.py:133: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.
  return data_subset.applymap(func)
/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/mlflow/recipes/steps/split.py:133: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.
  return data_subset.applymap(func)
Run MLflow Recipe step: transform
2024/03/14 10:12:14 INFO mlflow.recipes.step: Running step transform...
Run MLflow Recipe step: train
2024/03/14 10:12:15 INFO mlflow.recipes.step: Running step train...
2024/03/14 10:12:16 INFO mlflow.recipes.steps.train: Training data has less than 5000 rows, skipping rebalancing.
[flaml.automl.logger: 03-14 10:12:16] {1680} INFO - task = classification
[flaml.automl.logger: 03-14 10:12:16] {1691} INFO - Evaluation method: cv
[flaml.automl.logger: 03-14 10:12:16] {1789} INFO - Minimizing error metric: customized metric
[flaml.automl.logger: 03-14 10:12:16] {1901} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'lrl1']
[flaml.automl.logger: 03-14 10:12:16] {2219} INFO - iteration 0, current learner lgbm
2024/03/14 10:12:16 WARNING mlflow.recipes.steps.automl.flaml: 'NoneType' object is not callable
Traceback (most recent call last):
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/mlflow/recipes/steps/automl/flaml.py"", line 166, in _create_model_automl
    automl.fit(X, y, **automl_settings)
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/flaml/automl/automl.py"", line 1929, in fit
    self._search()
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/flaml/automl/automl.py"", line 2483, in _search
    self._search_sequential()
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/flaml/automl/automl.py"", line 2319, in _search_sequential
    analysis = tune.run(
               ^^^^^^^^^
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/flaml/tune/tune.py"", line 814, in run
    result = evaluation_function(trial_to_run.config)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/flaml/automl/state.py"", line 304, in _compute_with_config_base
    ) = compute_estimator(
        ^^^^^^^^^^^^^^^^^^
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/flaml/automl/ml.py"", line 369, in compute_estimator
    val_loss, metric_for_logging, train_time, pred_time = task.evaluate_model_CV(
                                                          ^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/flaml/automl/task/generic_task.py"", line 740, in evaluate_model_CV
    val_loss_i, metric_i, train_time_i, pred_time_i = get_val_loss(
                                                      ^^^^^^^^^^^^^
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/flaml/automl/ml.py"", line 494, in get_val_loss
    estimator.fit(X_train, y_train, budget=budget, free_mem_ratio=free_mem_ratio, **fit_kwargs)
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/flaml/automl/model.py"", line 1413, in fit
    self._fit(
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/flaml/automl/model.py"", line 220, in _fit
    model = self.estimator_class(**self.params)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: 'NoneType' object is not callable
Stack (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/mlflow/recipes/step.py"", line 132, in run
    self.step_card = self._run(output_directory=output_directory)
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/mlflow/recipes/steps/train.py"", line 369, in _run
    estimator = self._resolve_estimator(
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/mlflow/recipes/steps/train.py"", line 702, in _resolve_estimator
    return self._resolve_estimator_plugin(using_plugin, X_train, y_train, output_directory)
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/mlflow/recipes/steps/train.py"", line 677, in _resolve_estimator_plugin
    estimator, best_parameters = estimator_fn(
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/mlflow/recipes/steps/automl/flaml.py"", line 52, in get_estimator_and_best_params
    return _create_model_automl(
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/mlflow/recipes/steps/automl/flaml.py"", line 176, in _create_model_automl
    _logger.warning(e, exc_info=e, stack_info=True)
Traceback (most recent call last):
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/mlflow/recipes/steps/automl/flaml.py"", line 166, in _create_model_automl
    automl.fit(X, y, **automl_settings)
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/flaml/automl/automl.py"", line 1929, in fit
    self._search()
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/flaml/automl/automl.py"", line 2483, in _search
    self._search_sequential()
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/flaml/automl/automl.py"", line 2319, in _search_sequential
    analysis = tune.run(
               ^^^^^^^^^
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/flaml/tune/tune.py"", line 814, in run
    result = evaluation_function(trial_to_run.config)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/flaml/automl/state.py"", line 304, in _compute_with_config_base
    ) = compute_estimator(
        ^^^^^^^^^^^^^^^^^^
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/flaml/automl/ml.py"", line 369, in compute_estimator
    val_loss, metric_for_logging, train_time, pred_time = task.evaluate_model_CV(
                                                          ^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/flaml/automl/task/generic_task.py"", line 740, in evaluate_model_CV
    val_loss_i, metric_i, train_time_i, pred_time_i = get_val_loss(
                                                      ^^^^^^^^^^^^^
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/flaml/automl/ml.py"", line 494, in get_val_loss
    estimator.fit(X_train, y_train, budget=budget, free_mem_ratio=free_mem_ratio, **fit_kwargs)
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/flaml/automl/model.py"", line 1413, in fit
    self._fit(
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/flaml/automl/model.py"", line 220, in _fit
    model = self.estimator_class(**self.params)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: 'NoneType' object is not callable

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/mlflow/recipes/step.py"", line 132, in run
    self.step_card = self._run(output_directory=output_directory)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/mlflow/recipes/steps/train.py"", line 369, in _run
    estimator = self._resolve_estimator(
                ^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/mlflow/recipes/steps/train.py"", line 702, in _resolve_estimator
    return self._resolve_estimator_plugin(using_plugin, X_train, y_train, output_directory)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/mlflow/recipes/steps/train.py"", line 677, in _resolve_estimator_plugin
    estimator, best_parameters = estimator_fn(
                                 ^^^^^^^^^^^^^
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/mlflow/recipes/steps/automl/flaml.py"", line 52, in get_estimator_and_best_params
    return _create_model_automl(
           ^^^^^^^^^^^^^^^^^^^^^
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/mlflow/recipes/steps/automl/flaml.py"", line 177, in _create_model_automl
    raise MlflowException(
mlflow.exceptions.MlflowException: Error has occurred during training of AutoML model using FLAML: TypeError(""'NoneType' object is not callable"")
make: *** [Makefile:40: steps/train/outputs/run_id] Error 1
2024/03/14 10:12:16 INFO mlflow.recipes.utils.step: Opening HTML file at: '/home/johannesrave/.mlflow/recipes/4017c17da008f790842d057848e03dabf1f2c837c6f6beee05118abec7520772/steps/train/outputs/card.html'
Traceback (most recent call last):
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/bin/mlflow"", line 8, in <module>
    sys.exit(cli())
             ^^^^^
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/click/core.py"", line 1157, in __call__
    return self.main(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/click/core.py"", line 1078, in main
    rv = self.invoke(ctx)
         ^^^^^^^^^^^^^^^^
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/click/core.py"", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/click/core.py"", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/click/core.py"", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/click/core.py"", line 783, in invoke
    return __callback(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/mlflow/recipes/cli.py"", line 44, in run
    Recipe(profile=profile).run(step)
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/mlflow/recipes/classification/v1/recipe.py"", line 266, in run
    return super().run(step=step)
           ^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/mlflow/recipes/recipe.py"", line 111, in run
    raise MlflowException(
mlflow.exceptions.MlflowException: Failed to run recipe 'mlflow-recipes':
The following error occurred while running step 'Step:train':
Traceback (most recent call last):
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/mlflow/recipes/steps/automl/flaml.py"", line 166, in _create_model_automl
    automl.fit(X, y, **automl_settings)
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/flaml/automl/automl.py"", line 1929, in fit
    self._search()
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/flaml/automl/automl.py"", line 2483, in _search
    self._search_sequential()
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/flaml/automl/automl.py"", line 2319, in _search_sequential
    analysis = tune.run(
               ^^^^^^^^^
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/flaml/tune/tune.py"", line 814, in run
    result = evaluation_function(trial_to_run.config)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/flaml/automl/state.py"", line 304, in _compute_with_config_base
    ) = compute_estimator(
        ^^^^^^^^^^^^^^^^^^
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/flaml/automl/ml.py"", line 369, in compute_estimator
    val_loss, metric_for_logging, train_time, pred_time = task.evaluate_model_CV(
                                                          ^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/flaml/automl/task/generic_task.py"", line 740, in evaluate_model_CV
    val_loss_i, metric_i, train_time_i, pred_time_i = get_val_loss(
                                                      ^^^^^^^^^^^^^
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/flaml/automl/ml.py"", line 494, in get_val_loss
    estimator.fit(X_train, y_train, budget=budget, free_mem_ratio=free_mem_ratio, **fit_kwargs)
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/flaml/automl/model.py"", line 1413, in fit
    self._fit(
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/flaml/automl/model.py"", line 220, in _fit
    model = self.estimator_class(**self.params)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: 'NoneType' object is not callable

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/mlflow/recipes/step.py"", line 132, in run
    self.step_card = self._run(output_directory=output_directory)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/mlflow/recipes/steps/train.py"", line 369, in _run
    estimator = self._resolve_estimator(
                ^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/mlflow/recipes/steps/train.py"", line 702, in _resolve_estimator
    return self._resolve_estimator_plugin(using_plugin, X_train, y_train, output_directory)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/mlflow/recipes/steps/train.py"", line 677, in _resolve_estimator_plugin
    estimator, best_parameters = estimator_fn(
                                 ^^^^^^^^^^^^^
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/mlflow/recipes/steps/automl/flaml.py"", line 52, in get_estimator_and_best_params
    return _create_model_automl(
           ^^^^^^^^^^^^^^^^^^^^^
  File ""/home/johannesrave/dev/kaggle/mlflow-recipes/.venv/lib/python3.11/site-packages/mlflow/recipes/steps/automl/flaml.py"", line 177, in _create_model_automl
    raise MlflowException(
mlflow.exceptions.MlflowException: Error has occurred during training of AutoML model using FLAML: TypeError(""'NoneType' object is not callable"")

Last step status: 'StepStatus.FAILED'
```
the space-titanic.yaml:

```
recipe: ""classification/v1""
# FIXME::REQUIRED: Specifies the target column name for model training and evaluation.
target_col: ""Transported""
# FIXME::REQUIRED: Specifies the value of `target_col` that is considered the positive class.
positive_class: ""True""
# FIXME::REQUIRED: Sets the primary metric to use to evaluate model performance. This primary
#                  metric is used to select best performing models in MLflow UI as well as in
#                  train and evaluation step.
#                  Built-in primary metrics are: recall_score, precision_score, f1_score, accuracy_score.
primary_metric: ""precision_score""
steps:
  # Specifies the dataset to use for model development
  ingest: {{INGEST_CONFIG}}
  split:
    #
    # FIXME::OPTIONAL: Adjust the train/validation/test split ratios below.
    #
    split_ratios: [0.75, 0.125, 0.125]
    #
    #  FIXME::OPTIONAL: Specifies the method to use to ""post-process"" the split datasets. Note that
    #                   arbitrary transformations should go into the transform step.
    post_split_filter_method: create_dataset_filter
  transform:
    using: ""custom""
    #
    #  FIXME::OPTIONAL: Specifies the method that defines an sklearn-compatible transformer, which
    #                   applies input feature transformation during model training and inference.
    transformer_method: transformer_fn
  train:
    #
    # FIXME::REQUIRED: Specifies the method to use for training. Options are ""automl/flaml"" for
    #                  AutoML training or ""custom"" for user-defined estimators.
    using: ""automl/flaml""
    time_budget_secs: 30
  evaluate:
    #
    # FIXME::OPTIONAL: Sets performance thresholds that a trained model must meet in order to be
    #                  eligible for registration to the MLflow Model Registry.
    #
    # validation_criteria:
    #   - metric: root_mean_squared_error
    #     threshold: 10
  register:
    # Indicates whether or not a model that fails to meet performance thresholds should still
    # be registered to the MLflow Model Registry
    allow_non_validated_model: false
```",unsure whether issue also ca run run clean profile run run profile recipe profile recipe profile run recipe step ingest running step ingest run recipe step split running step split removed future version please use instead return bound use instead return use instead return use instead return use instead return run recipe step transform running step transform run recipe step train running step train training data le skipping task classification evaluation method error metric metric list run iteration current learner warning object callable recent call last file line file line fit file line file line analysis file line run result file line file line file line file line file line fit file line model object callable stack recent call last file string line module file line run file line estimator file line return file line estimator file line return file line recent call last file line file line fit file line file line analysis file line run result file line file line file line file line file line fit file line model object callable handling exception another exception recent call last file string line module file line run file line estimator file line return file line estimator file line return file line raise error training model object callable make error opening file recent call last file line module file line return file line main file line invoke return file line invoke return file line invoke return file line invoke return file line run recipe step file line run return super file line run raise run recipe following error running step train recent call last file line file line fit file line file line analysis file line run result file line file line file line file line file line fit file line model object callable handling exception another exception recent call last file line run file line estimator file line return file line estimator file line return file line raise error training model object callable last step status recipe target column name model training evaluation transported value considered positive class true primary metric use evaluate model performance primary metric used select best well train evaluation step primary metric use model development ingest split adjust split method use split note arbitrary go transform step transform custom method transformer input feature transformation model training inference train method use training training custom evaluate performance trained model must meet order eligible registration model registry metric threshold register whether model meet performance still registered model registry false,issue,positive,positive,positive,positive,positive,positive
1996814800,"Merging this to unblock first preview and some stacked changes e.g. client, pretty-print, etc. All the comments so far should have been addressed, except ones require design decision. Feel free to leave comments here or directly lmk, I will address in a follow-up. 
cc: @BenWilson2 @serena-ruan ",unblock first preview client far except require design decision feel free leave directly address,issue,negative,positive,positive,positive,positive,positive
1996322195,"Hi @B-Step62 , sorry to disturb, could you please help merge this small change? Thanks in advance! (I put a wrong dev url and forgot to update it before QAQ",hi sorry disturb could please help merge small change thanks advance put wrong dev forgot update,issue,negative,negative,negative,negative,negative,negative
1996011418,"Will do, thanks again for your help!

Best,
Josh

On Tue, Mar 12, 2024 at 6:44 PM Serena Ruan ***@***.***>
wrote:

> Thanks, please reopen this issue if you encounter it again.
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/mlflow/mlflow/issues/11388#issuecomment-1993058320>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/BG4ECBVGTR7QXY5QJWDA6T3YX6VPDAVCNFSM6AAAAABERIL57CVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTSOJTGA2TQMZSGA>
> .
> You are receiving this because you authored the thread.Message ID:
> ***@***.***>
>
",thanks help best josh tue mar wrote thanks please reopen issue encounter reply directly view id,issue,positive,positive,positive,positive,positive,positive
1994534028,"test failures *might* be unrelated, tried reproing locally and got an error just with this (no mlflow code)

```
architecture = ""lordtt13/emo-mobilebert""
tokenizer = AutoTokenizer.from_pretrained(architecture)
model = TFAutoModelForSequenceClassification.from_pretrained(architecture)
pipe = pipeline(task=""text-classification"", model=model, tokenizer=tokenizer)
```

will investigate tomorrow",test might unrelated tried locally got error code architecture architecture model architecture pipe pipeline investigate tomorrow,issue,negative,neutral,neutral,neutral,neutral,neutral
1994464187,"@serena-ruan I don't know if it ""only"" happens with workspace registry because when I try to use the ""databricks-uc"" I get a firewall error (already contacted support about it), but I assume it should work with workspace registry right?

Meanwhile, screenshots of the model artifacts folders:

![image](https://github.com/mlflow/mlflow/assets/4044758/50b7aa2b-bed7-41f5-81a3-0d0dd2b2faa9)


![image](https://github.com/mlflow/mlflow/assets/4044758/5c26f475-a75d-4481-81da-7ccd52e9e55a)
",know registry try use get error already support assume work registry right meanwhile model image image,issue,negative,positive,positive,positive,positive,positive
1994344379,"@serena-ruan @daniellok-db ,we were wondering too, but in all examples available in the documentation, what we see in the evaluation table on the UI when the run is created programmatically, it's not the same than when it's created on the UI, it would be great to have more guidance to have that, especially for the prompt to be as a variable of a run, as running the same run, with its prompt, on new data is important in our case. Thanks",wondering available documentation see evaluation table run programmatically would great guidance especially prompt variable run running run prompt new data important case thanks,issue,positive,positive,positive,positive,positive,positive
1994164339,"I'm not able to re-queue the release note check except push branch, could anyone please help on it? Thanks!",able release note check except push branch could anyone please help thanks,issue,positive,positive,positive,positive,positive,positive
1994159201,"Hi @WeichenXu123  I put a wrong install dev url to the ml-package-versions, forgot to update it before. I've update it to the correct one, sorry for the inconvience! QAQ
Please help merge this PR, thanks!",hi put wrong install dev forgot update update correct one sorry please help merge thanks,issue,positive,negative,negative,negative,negative,negative
1993890860,@CarlosLabrado So this only happens when you use the workspace registry right? Could you provide the screenshot of your model artifacts folder? From the log we should load your model from model/model folder,use registry right could provide model folder log load model folder,issue,negative,positive,positive,positive,positive,positive
1993854714,"Clearly those runs contain params, and UI exposes them, while you could try manually create a run with params and evaluation table. @daniellok-db Please correct me if I'm wrong, it seems prompt engineering internally captures these params and creates the run.",clearly contain could try manually create run evaluation table please correct wrong prompt engineering internally run,issue,negative,negative,negative,negative,negative,negative
1993808510,The error was not on the mlflow side. Asset creation in Azure ML was failing when I was defining `Output` of type `CUSTOM_MODEL`.,error side asset creation azure failing output type,issue,negative,neutral,neutral,neutral,neutral,neutral
1993295016,"@GhaithDek This error is emitting from AzureOpenAI service, you should double check the model deployed on that service or file a ticket to MS support",error service double check model service file ticket support,issue,negative,neutral,neutral,neutral,neutral,neutral
1993249764,"Hi @QuentinAmbard Thanks for raising this! It's a fair ask and easy to support, please feel free to raise a PR and I'll review it! A pointer to the code: https://github.com/mlflow/mlflow/blob/eb5852db8ba8cd312b194d3657d7fa89fec6bb1b/mlflow/models/model.py#L669-L675 We should add a new field `model_version` in `Model` object, set it if registered_model_name is not None, default to None. Thanks!",hi thanks raising fair ask easy support please feel free raise review pointer code add new field model object set none default none thanks,issue,positive,positive,positive,positive,positive,positive
1993140211,"You could try local log, load without specifying the pip requirements first. If you're going to serve it then you need to specify conda env like this:
```
conda_env = _mlflow_conda_env(
            additional_conda_deps=['git'],
            additional_pip_deps=[""git+https://github.com/serena-ruan/mlflow.git@fix_lc"", ""mlflow""], # and other your dependencies
            additional_conda_channels=None,
    )
mlflow.langchain.log_model(
    ....
    conda_env=conda_env,
    ....
  )
```
",could try local log load without pip first going serve need specify like,issue,negative,positive,positive,positive,positive,positive
1993058320,"Thanks, please reopen this issue if you encounter it again.",thanks please reopen issue encounter,issue,positive,positive,positive,positive,positive,positive
1992755303,"Hmm, it seems to be fixed today, I'm unable to reproduce it at the moment
and I can get into my experiment again. I'll record it in the future if it
happens again to see if I can capture it.

Thanks,
Josh

On Tue, Mar 12, 2024 at 3:45 AM Serena Ruan ***@***.***>
wrote:

> I tried mlflow 2.7.1 ui, I can't really deselect all experiments, while
> runs by default you're not selecting them.
> image.png (view on web)
> <https://github.com/mlflow/mlflow/assets/82044803/60bbfc51-cebb-4247-9d3a-32ad6c97a9df>
>
> Could you provide your steps to reproduce the problem?
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/mlflow/mlflow/issues/11388#issuecomment-1991342777>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/BG4ECBVW4DPAYYUD2BF3BZLYX3MDTAVCNFSM6AAAAABERIL57CVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTSOJRGM2DENZXG4>
> .
> You are receiving this because you authored the thread.Message ID:
> ***@***.***>
>
",fixed today unable reproduce moment get experiment record future see capture thanks josh tue mar wrote tried ca really default view web could provide reproduce problem reply directly view id,issue,negative,positive,neutral,neutral,positive,positive
1992452661,"@CarlosLabrado 
Ok, but how do I insert it on the pip_requirements in the mlflow.langchain.log_model?

right now I'm using, for example:

```
import mlflow [HERE]

with mlflow.start_run(run_name=""rag_produtos"") as run:
    input_example = dialog_example
    output = final_rag_chain.invoke(dialog_example)
    signature = infer_signature(input_example, output)
    model_info = mlflow.langchain.log_model(
        final_rag_chain,
        loader_fn=get_vector_search_retriever,
        artifact_path=""chain"",
        registered_model_name=model_name,
        pip_requirements = [
            ""mlflow"" [HERE]
        ],
        input_example=input_example,
        example_no_conversion=True,
        signature=signature,
    )
```",insert right example import run output signature output chain,issue,negative,positive,positive,positive,positive,positive
1992399667,"@reslleygabriel 
This is how you install from that specific branch
```shell
%pip install git+https://github.com/serena-ruan/mlflow.git@fix_lc
dbutils.library.restartPython()
```",install specific branch shell pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
1991534287,"@serena-ruan I'm using this versions:

```
%pip install \
""langchain==0.1.11"" \
""langchain-core==0.1.30"" \
""langchain-community==0.0.27"" \
""mlflow==2.11.1"" \
""databricks==0.2"" \
""databricks-vectorsearch==0.23"" \
""cloudpickle==3.0.0"" \
""tiktoken==0.6.0"" \
""pydantic==2.6.3"" \
```

How do I install the mlflow from a specific branch? I'm using it inside a notebook in Databricks.",pip install install specific branch inside notebook,issue,negative,neutral,neutral,neutral,neutral,neutral
1991342777,"I tried mlflow 2.7.1 ui, I can't really deselect all experiments, while runs by default you're not selecting them.
<img width=""1507"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/82044803/60bbfc51-cebb-4247-9d3a-32ad6c97a9df"">

Could you provide your steps to reproduce the problem?",tried ca really default image could provide reproduce problem,issue,negative,positive,positive,positive,positive,positive
1991331512,"@reslleygabriel Which pydantic version are you using? We did encounter this kind of error before, could you try installing mlflow from this branch https://github.com/mlflow/mlflow/pull/11397 and see if it fixes your problem? `pip install git+https://github.com/serena-ruan/mlflow.git@fix_lc`
If you take a look at the saved yaml file, there must be some weird tags appearing, we ignore them in retriever chains (no issues reported yet) but it's not 100% safe.",version encounter kind error could try branch see problem pip install take look saved file must weird ignore retriever yet safe,issue,negative,positive,positive,positive,positive,positive
1991308942,"You can work around this issue by creating a Python package as follows:

**Directory structure:**

```
mlflow_cors/
  mlflow_cors/
    __init__.py
  setup.py
```

**__init__.py:**

```python
from mlflow.server import app
from flask import Flask
from flask_cors import CORS

def create_app(app: Flask = app):
    CORS(app)
    return app
```

**setup.py:**

```python
from setuptools import setup

setup(
    name=""mlflow_cors"",
    entry_points=""""""
        [mlflow.app]
        mlflow_cors=mlflow_cors:create_app
    """"""
)
```

Then run `pip install mlflow_cors` and add the `--app-name mlflow_cors` flag to the `mlflow server` command.

The above implementation was adapted from the mlflow guide on [custom authentication](https://mlflow.org/docs/latest/auth/index.html#id26:~:text=the%20server%20starts.-,Custom%20Authentication,-MLflow%20authentication%20is).",work around issue python package directory structure python import flask import flask import flask return python import setup setup run pip install add flag server command implementation guide custom authentication,issue,negative,neutral,neutral,neutral,neutral,neutral
1991164427,"I've reviewed the doc with our team members, please help to merge it anytime :)",doc team please help merge,issue,positive,neutral,neutral,neutral,neutral,neutral
1991076858,"> Can we split jobs for each flavor? The root cause is we test all the flavors in a single job. If we have a separate job for each flavor, we don't need to worry about the the maximum number of jobs. This may lead to code duplication, but I think that's acceptable.

This is a good idea. Let me investigate it.",split flavor root cause test single job separate job flavor need worry maximum number may lead code duplication think acceptable good idea let investigate,issue,negative,positive,positive,positive,positive,positive
1991053289,"Can we split jobs for each flavor? The root cause is we test all the flavors in a single job (`tests`). If we have a separate job for each flavor, we don't need to worry about the the maximum number of jobs. This may lead to code duplication, but I think that's acceptable.",split flavor root cause test single job separate job flavor need worry maximum number may lead code duplication think acceptable,issue,negative,negative,neutral,neutral,negative,negative
1990770933,@serena-ruan @harupy Could you please help take a look at the doc changes when you have time? Thanks!,could please help take look doc time thanks,issue,positive,positive,positive,positive,positive,positive
1989740874,"While I do think that it would be great to have a more responsive view, unfortunately I think this will be a very large undertaking involving lots of design changes (reworking sidebars/navigation/the experiment table). I'm not sure that the team has bandwidth to support reviews for this at the moment 😓.

cc @hubertzub-db, are you aware of any plans for a mobile-friendly MLflow UI?
",think would great responsive view unfortunately think large undertaking lot design experiment table sure team support moment aware,issue,positive,positive,positive,positive,positive,positive
1989284979,"> Quite late, but rather than modifying path I'm doing `python -m mlflow ui`, where python points to whatever venv I'm using.

this works! thank you!",quite late rather path python python whatever work thank,issue,negative,negative,negative,negative,negative,negative
1989019750,"@serena-ruan went through comments, reverted changes to testing. Updated conditional check for pl legacy flag in _autolog file.

Had a couple issues with reverting the test changes which is why the commit history looks a bit wonky :laughing: ",went testing conditional check legacy flag file couple test commit history bit wonky laughing,issue,positive,negative,negative,negative,negative,negative
1988385480,Thanks for raising the FR! This is a great idea and happy to know that you're willing to contribute! Could you work with @daniellok-db on the improvements ideas? Daniel is our UI expert :D ,thanks raising great idea happy know willing contribute could work expert,issue,positive,positive,positive,positive,positive,positive
1988347194,"> The fix looks good to me (with a few nits)! One general question is tho, do we want to manage all serialize/deserialize logic for those different type of LangChain runnables in our code base? I wonder the basic serde logic like `load_runnable_assign` should live in LangChain code base instead, like `load_chain` - there is no MLflow specific logic but all about LangChain internal at a glance.

Yes that's true, the ideal solution is langchain supports it, but since we have lots of langchain users the current workaround (and fastest way to support) is supporting it in MLflow. BTW langchain still uses pydantic v1 internally, I think supporting save/load for some objects with pydantic v1 is still hard.",fix good one general question tho want manage logic different type code base wonder basic logic like live code base instead like specific logic internal glance yes true ideal solution since lot current way support supporting still internally think supporting still hard,issue,positive,positive,neutral,neutral,positive,positive
1988296876,Hi sir. Can I try `scikit-learn` this one. @BenWilson2 ,hi sir try one,issue,negative,neutral,neutral,neutral,neutral,neutral
1987923413,"@B-Step62 Please help review the doc changes when you have time, thanks in advance! :)",please help review doc time thanks advance,issue,positive,positive,positive,positive,positive,positive
1987651078,"> Could you please help merge this one? I'll file the doc pr soon.

Oops sorry, I forgot to press the merge button. Merged!
 
Thank you for the doc follow-up, let us know when it is ready for review🙌",could please help merge one file doc soon sorry forgot press merge button thank doc let u know ready review,issue,positive,negative,negative,negative,negative,negative
1987561374,"@B-Step62 Thank you for your time and patience, really appreciate it! Could you please help merge this one? I'll file the doc pr soon. ",thank time patience really appreciate could please help merge one file doc soon,issue,positive,positive,positive,positive,positive,positive
1987536612,It seems  += 1 is redundant.  and at least thread not safe,redundant least thread safe,issue,negative,neutral,neutral,neutral,neutral,neutral
1987431320,"@rabah-khalek Thank you for the detailed response!

> this API was removed from the side of openai so model.predict(...) fails (see below).

Yes, this seems to block usage of OpenAI >= 1.0.

> Indeed, the problem stems from langchain's support... Appreciated your reactiveness and response here: https://github.com/langchain-ai/langchain/issues/18420 and your 3 proposals. I am happy to contribute to help on any of these 3. This problem has been blocking us for a while

Thank you so much for the willingness to contribute! I thought the second option is preferable in long term (it seems the first option was tried multiple times but always closed suddenly like [this](https://github.com/langchain-ai/langchain/pull/12331)), but the error `NotImplementedError: Trying to load an object that doesn't implement serialization` error you've got might indicate it takes some effort to make it serializable. Ideally they could provide some short-term workaround but sadly we haven't get any attention to the issue yet. It would be really appreciated if you could spend some time for investigating if it is feasible to serde the new chat models. I will also try digging into this but may not have much bandwidth very soon.",thank detailed response removed side see yes block usage indeed problem support reactiveness response happy contribute help problem blocking u thank much willingness contribute thought second option preferable long term first option tried multiple time always closed suddenly like error trying load object implement serialization error got might indicate effort make ideally could provide sadly get attention issue yet would really could spend time investigating feasible new chat also try digging may much soon,issue,positive,positive,positive,positive,positive,positive
1986053216,"R has absolutely no concept of Python datastructures or the binary types that are associated with a serialized (pickled) python binary, such as a scikit-learn model. 
There is an R package, reticulate, that provides some limited support of interoperability with python from R (which is used heavily in the R API in MLflow), but we don't have a specific implementation for this mode of operation, as it is not a common use case. 
Typically, an R user would build a glm model directly within R and interact with any analyses required from within that language environment, using R tooling. 
A Python user would use a package like scikit-learn to create a LogisticRegression model (as you showed in your demo code) and then use a package like statsmodels to perform statistical analysis and validation. 
While there are some analysis capabilities in R that are not in statsmodels, they are very few and far between and generally highly specific to a unique research-focused area that is not widely applicable to industry (or are simply not useful outside of a pure theoretical research scope). 
As it seems that you're in the process of learning these tools and how to leverage MLflow, I would recommend starting to develop models within a single ecosystem, based on what your organization's DS department has standardized on (either R or Python). If there is an immediate need to read files using tools like reticulate... 

```R
install.packages(""reticulate"")
library(reticulate)


joblib <- import('joblib')
model <- joblib$load(<path to scikit-learn model>)
prediction <- model$predict(<feature set in R DF>)
```
This feature is not natively implemented or supported in MLflow, though, and the snippet above is merely meant to show the mechanism of using reticulate to load Python objects from an R wrapper. 

The other alternative is to convert your model to an open interchange format like ONNX and to use the respective libraries for serialization in Python and deserialization in R without having to make subprocess kernel calls to different runtime environments that necessitate the use of pipe streaming in your operating system. ",absolutely concept python binary associated python binary model package reticulate limited support python used heavily specific implementation mode operation common use case typically user would build model directly within interact analysis within language environment tooling python user would use package like create model code use package like perform statistical analysis validation analysis far generally highly specific unique area widely applicable industry simply useful outside pure theoretical research scope process learning leverage would recommend starting develop within single ecosystem based organization department standardized either python immediate need read like reticulate reticulate library reticulate import model load path model prediction model predict feature set feature natively though snippet merely meant show mechanism reticulate load python wrapper alternative convert model open interchange format like use respective serialization python without make kernel different necessitate use pipe streaming operating system,issue,positive,positive,neutral,neutral,positive,positive
1985483314,"> I have not used `log_model `specifically, but I had similar 'cryptical' error message for `mlflow.log_text(..)`. After some day struggling I noticed that the artifact_file needed to have ""/"" and not ""\"" -> `""folder/text.txt""` will work but not ""mlfolder\text.txt"".
> 
> When using `mlflow.log_artifact()` and giving `artifact_file` parameter one need to only give folder name ` ""mlfolder""` but not ""mlfolder/artifact.pkl"").
> 
> I would guess that your error with log_model is something similar as this.
> 
> I would suggest some improved error messages are implemented from the mlflow team :)

I tried to run mlflow.spark in windows 10 , and I face the error of separator '\\' when I use mlflow.spark.log_model. 
It seems that I can only do it on Linux. 😟",used specifically similar error message day struggling work giving parameter one need give folder name would guess error something similar would suggest error team tried run face error separator use,issue,negative,neutral,neutral,neutral,neutral,neutral
1985163857,@TedKostylev Could you provide your code to reproduce? Did you run `mlflow db upgrade` to migrate?,could provide code reproduce run upgrade migrate,issue,negative,neutral,neutral,neutral,neutral,neutral
1985012134,"@DouglasKrouth Thanks for reporting this issue! Actually we've updated the dependency in extra-ml-requirements.txt file to use lightning instead of pytorch_lightning, but haven't updated it _lightning_autolog.py file. I think we need some import catch logic that try to import lightning first, it we get importError then delegate to pytorch_lightning for backwards compatibility. Please feel free to file a PR and I'll help review it!",thanks issue actually dependency file use lightning instead file think need import catch logic try import lightning first get delegate backwards compatibility please feel free file help review,issue,positive,positive,positive,positive,positive,positive
1984991275,"Tested on databricks below code without involving MLflow works fine. MLflow just uses spark's native save/load, it should be your dataframe's problem.
```
from pyspark.ml.classification import LogisticRegression
from pyspark.ml.feature import VectorAssembler
from pyspark.ml import Pipeline

maxIter=8
regParam=0.01

assembler = VectorAssembler(inputCols=['col1','col2'], outputCol='features')
lr = LogisticRegression(maxIter=maxIter, regParam=regParam)

pipeline = Pipeline(stages=[assembler, lr])
df = spark.createDataFrame(
   [(1.0, 2.0, 1), (3.0, 4.0, 0), (5.0, 6.0, 1)], [""col1"", ""col2"", ""label""])
model = pipeline.fit(df)
model.save(""/tmp/logistic-regression-model"")

from pyspark.ml import PipelineModel

model = PipelineModel.load(""/tmp/logistic-regression-model"")
model.transform(df).show()
```
<img width=""773"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/82044803/2ef92789-59e2-42d4-8302-fe8ae04b5a5d"">
",tested code without work fine spark native problem import import import pipeline assembler pipeline pipeline assembler col col label model import model image,issue,negative,positive,positive,positive,positive,positive
1984976733,"Hi @mdoganwatea Though I'm not getting your problem when reproducing it in MLR 14.3, it seems sklearn flavor is not supported in R
<img width=""1085"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/82044803/eeb96399-f651-4b8e-8044-4db327601dac"">

@BenWilson2 Do you have any insights about why we don't support sklearn?",hi though getting problem flavor image support,issue,negative,neutral,neutral,neutral,neutral,neutral
1984973686,"Hi @ai-learner-00 This issue should be fixed in 2.11.1, please upgrade mlflow version and try again :)",hi issue fixed please upgrade version try,issue,negative,positive,neutral,neutral,positive,positive
1984972139,@jethroindc Thanks for finding the issue! Please feel free to file a PR to add this line :),thanks finding issue please feel free file add line,issue,positive,positive,positive,positive,positive,positive
1984927599,"Hey @gabrielfu sorry for dropping the ball on this. 

Streaming:
``` bash
~ via 🅒 base via 🐍 dev-env
➜   curl -X POST http://127.0.0.1:5000/endpoints/anthropic-chat/invocations \
  -H ""Content-Type: application/json"" \
  -d '{""messages"": [{""role"": ""system"",""content"": ""You are a funny assistant""},{""role"": ""user"",""content"": ""Hi""},{""role"": ""assistant"",""content"": ""Hi""},{""role"": ""user"",""content"": ""Tell me something fun.""}], ""stream"": true, ""temperature"": 1.5, ""max_tokens"": 100}'
data: {""id"": ""msg_013uCEMi8ow4BRipK6qRzrmW"", ""object"": ""chat.completion.chunk"", ""created"": 1709863952, ""model"": ""claude-2.1"", ""choices"": [{""index"": 0, ""finish_reason"": null, ""delta"": {""role"": null, ""content"": """"}}]}

data: {""id"": ""msg_013uCEMi8ow4BRipK6qRzrmW"", ""object"": ""chat.completion.chunk"", ""created"": 1709863952, ""model"": ""claude-2.1"", ""choices"": [{""index"": 0, ""finish_reason"": null, ""delta"": {""role"": null, ""content"": ""Here""}}]}

data: {""id"": ""msg_013uCEMi8ow4BRipK6qRzrmW"", ""object"": ""chat.completion.chunk"", ""created"": 1709863952, ""model"": ""claude-2.1"", ""choices"": [{""index"": 0, ""finish_reason"": null, ""delta"": {""role"": null, ""content"": ""'s""}}]}

data: {""id"": ""msg_013uCEMi8ow4BRipK6qRzrmW"", ""object"": ""chat.completion.chunk"", ""created"": 1709863952, ""model"": ""claude-2.1"", ""choices"": [{""index"": 0, ""finish_reason"": null, ""delta"": {""role"": null, ""content"": "" a""}}]}

data: {""id"": ""msg_013uCEMi8ow4BRipK6qRzrmW"", ""object"": ""chat.completion.chunk"", ""created"": 1709863952, ""model"": ""claude-2.1"", ""choices"": [{""index"": 0, ""finish_reason"": null, ""delta"": {""role"": null, ""content"": "" silly""}}]}

data: {""id"": ""msg_013uCEMi8ow4BRipK6qRzrmW"", ""object"": ""chat.completion.chunk"", ""created"": 1709863952, ""model"": ""claude-2.1"", ""choices"": [{""index"": 0, ""finish_reason"": null, ""delta"": {""role"": null, ""content"": "" joke""}}]}

data: {""id"": ""msg_013uCEMi8ow4BRipK6qRzrmW"", ""object"": ""chat.completion.chunk"", ""created"": 1709863952, ""model"": ""claude-2.1"", ""choices"": [{""index"": 0, ""finish_reason"": null, ""delta"": {""role"": null, ""content"": "" for""}}]}

data: {""id"": ""msg_013uCEMi8ow4BRipK6qRzrmW"", ""object"": ""chat.completion.chunk"", ""created"": 1709863952, ""model"": ""claude-2.1"", ""choices"": [{""index"": 0, ""finish_reason"": null, ""delta"": {""role"": null, ""content"": "" you""}}]}

data: {""id"": ""msg_013uCEMi8ow4BRipK6qRzrmW"", ""object"": ""chat.completion.chunk"", ""created"": 1709863952, ""model"": ""claude-2.1"", ""choices"": [{""index"": 0, ""finish_reason"": null, ""delta"": {""role"": null, ""content"": "":""}}]}

data: {""id"": ""msg_013uCEMi8ow4BRipK6qRzrmW"", ""object"": ""chat.completion.chunk"", ""created"": 1709863953, ""model"": ""claude-2.1"", ""choices"": [{""index"": 0, ""finish_reason"": null, ""delta"": {""role"": null, ""content"": "" Why""}}]}

data: {""id"": ""msg_013uCEMi8ow4BRipK6qRzrmW"", ""object"": ""chat.completion.chunk"", ""created"": 1709863953, ""model"": ""claude-2.1"", ""choices"": [{""index"": 0, ""finish_reason"": null, ""delta"": {""role"": null, ""content"": "" can""}}]}

data: {""id"": ""msg_013uCEMi8ow4BRipK6qRzrmW"", ""object"": ""chat.completion.chunk"", ""created"": 1709863953, ""model"": ""claude-2.1"", ""choices"": [{""index"": 0, ""finish_reason"": null, ""delta"": {""role"": null, ""content"": ""'t""}}]}

data: {""id"": ""msg_013uCEMi8ow4BRipK6qRzrmW"", ""object"": ""chat.completion.chunk"", ""created"": 1709863953, ""model"": ""claude-2.1"", ""choices"": [{""index"": 0, ""finish_reason"": null, ""delta"": {""role"": null, ""content"": "" a""}}]}

data: {""id"": ""msg_013uCEMi8ow4BRipK6qRzrmW"", ""object"": ""chat.completion.chunk"", ""created"": 1709863953, ""model"": ""claude-2.1"", ""choices"": [{""index"": 0, ""finish_reason"": null, ""delta"": {""role"": null, ""content"": "" bicycle""}}]}

data: {""id"": ""msg_013uCEMi8ow4BRipK6qRzrmW"", ""object"": ""chat.completion.chunk"", ""created"": 1709863953, ""model"": ""claude-2.1"", ""choices"": [{""index"": 0, ""finish_reason"": null, ""delta"": {""role"": null, ""content"": "" stand""}}]}

data: {""id"": ""msg_013uCEMi8ow4BRipK6qRzrmW"", ""object"": ""chat.completion.chunk"", ""created"": 1709863953, ""model"": ""claude-2.1"", ""choices"": [{""index"": 0, ""finish_reason"": null, ""delta"": {""role"": null, ""content"": "" up""}}]}

data: {""id"": ""msg_013uCEMi8ow4BRipK6qRzrmW"", ""object"": ""chat.completion.chunk"", ""created"": 1709863953, ""model"": ""claude-2.1"", ""choices"": [{""index"": 0, ""finish_reason"": null, ""delta"": {""role"": null, ""content"": "" by""}}]}

data: {""id"": ""msg_013uCEMi8ow4BRipK6qRzrmW"", ""object"": ""chat.completion.chunk"", ""created"": 1709863953, ""model"": ""claude-2.1"", ""choices"": [{""index"": 0, ""finish_reason"": null, ""delta"": {""role"": null, ""content"": "" itself""}}]}

data: {""id"": ""msg_013uCEMi8ow4BRipK6qRzrmW"", ""object"": ""chat.completion.chunk"", ""created"": 1709863953, ""model"": ""claude-2.1"", ""choices"": [{""index"": 0, ""finish_reason"": null, ""delta"": {""role"": null, ""content"": ""?""}}]}

data: {""id"": ""msg_013uCEMi8ow4BRipK6qRzrmW"", ""object"": ""chat.completion.chunk"", ""created"": 1709863953, ""model"": ""claude-2.1"", ""choices"": [{""index"": 0, ""finish_reason"": null, ""delta"": {""role"": null, ""content"": "" Because""}}]}

data: {""id"": ""msg_013uCEMi8ow4BRipK6qRzrmW"", ""object"": ""chat.completion.chunk"", ""created"": 1709863953, ""model"": ""claude-2.1"", ""choices"": [{""index"": 0, ""finish_reason"": null, ""delta"": {""role"": null, ""content"": "" it""}}]}

data: {""id"": ""msg_013uCEMi8ow4BRipK6qRzrmW"", ""object"": ""chat.completion.chunk"", ""created"": 1709863953, ""model"": ""claude-2.1"", ""choices"": [{""index"": 0, ""finish_reason"": null, ""delta"": {""role"": null, ""content"": ""'s""}}]}

data: {""id"": ""msg_013uCEMi8ow4BRipK6qRzrmW"", ""object"": ""chat.completion.chunk"", ""created"": 1709863953, ""model"": ""claude-2.1"", ""choices"": [{""index"": 0, ""finish_reason"": null, ""delta"": {""role"": null, ""content"": "" two""}}]}

data: {""id"": ""msg_013uCEMi8ow4BRipK6qRzrmW"", ""object"": ""chat.completion.chunk"", ""created"": 1709863953, ""model"": ""claude-2.1"", ""choices"": [{""index"": 0, ""finish_reason"": null, ""delta"": {""role"": null, ""content"": ""-""}}]}

data: {""id"": ""msg_013uCEMi8ow4BRipK6qRzrmW"", ""object"": ""chat.completion.chunk"", ""created"": 1709863953, ""model"": ""claude-2.1"", ""choices"": [{""index"": 0, ""finish_reason"": null, ""delta"": {""role"": null, ""content"": ""t""}}]}

data: {""id"": ""msg_013uCEMi8ow4BRipK6qRzrmW"", ""object"": ""chat.completion.chunk"", ""created"": 1709863953, ""model"": ""claude-2.1"", ""choices"": [{""index"": 0, ""finish_reason"": null, ""delta"": {""role"": null, ""content"": ""ired""}}]}

data: {""id"": ""msg_013uCEMi8ow4BRipK6qRzrmW"", ""object"": ""chat.completion.chunk"", ""created"": 1709863953, ""model"": ""claude-2.1"", ""choices"": [{""index"": 0, ""finish_reason"": null, ""delta"": {""role"": null, ""content"": ""!""}}]}

data: {""id"": ""msg_013uCEMi8ow4BRipK6qRzrmW"", ""object"": ""chat.completion.chunk"", ""created"": 1709863953, ""model"": ""claude-2.1"", ""choices"": [{""index"": 0, ""finish_reason"": ""stop"", ""delta"": {""role"": null, ""content"": null}}]}
```

Non-streaming:

```bash
~ via 🅒 base via 🐍 dev-env
➜ curl -X POST http://127.0.0.1:5000/endpoints/anthropic-chat/invocations \
  -H ""Content-Type: application/json"" \
  -d '{""messages"": [{""role"": ""system"",""content"": ""You are a funny assistant""},{""role"": ""user"",""content"": ""Hi""},{""role"": ""assistant"",""content"": ""Hi""},{""role"": ""user"",""content"": ""Tell me something fun.""}], ""temperature"": 1.5, ""max_tokens"": 100}'
{""id"":""msg_017WWVS7GdTYGmAaduF7DWQv"",""object"":""chat.completion"",""created"":1709863852,""model"":""claude-2.1"",""choices"":[{""index"":0,""message"":{""role"":""assistant"",""content"":""Here's something I find amusing - I don't actually experience fun or have a sense of humor myself. As an AI assistant created by Anthropic to be helpful, harmless, and honest, I don't have subjective experiences. I can try to tell jokes or fun facts if you'd like, but I rely on my training to determine what kinds of things tend to elicit amusement or enjoyment from humans!""},""finish_reason"":""stop""}],""usage"":{""prompt_tokens"":29,""completion_tokens"":85,""total_tokens"":114}}%
```",hey sorry dropping ball streaming bash via base via snake curl post role system content funny assistant role user content hi role assistant content hi role user content tell something fun stream true temperature data id object model index null delta role null content data id object model index null delta role null content data id object model index null delta role null content data id object model index null delta role null content data id object model index null delta role null content silly data id object model index null delta role null content joke data id object model index null delta role null content data id object model index null delta role null content data id object model index null delta role null content data id object model index null delta role null content data id object model index null delta role null content data id object model index null delta role null content data id object model index null delta role null content data id object model index null delta role null content bicycle data id object model index null delta role null content stand data id object model index null delta role null content data id object model index null delta role null content data id object model index null delta role null content data id object model index null delta role null content data id object model index null delta role null content data id object model index null delta role null content data id object model index null delta role null content data id object model index null delta role null content two data id object model index null delta role null content data id object model index null delta role null content data id object model index null delta role null content data id object model index null delta role null content data id object model index stop delta role null content null bash via base via snake curl post role system content funny assistant role user content hi role assistant content hi role user content tell something fun temperature id object model index message role assistant content something find amusing actually experience fun sense humor ai assistant anthropic helpful harmless honest subjective try tell fun like rely training determine tend elicit amusement enjoyment stop usage,issue,positive,positive,neutral,neutral,positive,positive
1984920382,"Most likely the empty rdd is because of your dataframe, you could try running transform(df) on the model ",likely empty could try running transform model,issue,negative,negative,neutral,neutral,negative,negative
1984881456,@michshap There probably something wrong with your local file directories. Could you try the same code snippet in a new location (where no previous experiments exist)?,probably something wrong local file could try code snippet new location previous exist,issue,negative,negative,negative,negative,negative,negative
1984857249,"> Could you add some notes in save_model docstring and RAG notebook? (+possibly to examples). I guess this will be a very common issue soon but not super easy to find the solution.

@B-Step62 added to docstrings, but i kept running into issues when trying to run the notebook (unrelated to the error from this PR, just because i don't have an openAI API key and was trying to hack around it). I didn't want to potentially mess up the notebook state so I just left it for now. I think the error that langchain throws might be helpful enough when combined with the stacktrace (it does tell you to add this param).",could add rag notebook guess common issue soon super easy find solution added kept running trying run notebook unrelated error key trying hack around want potentially mess notebook state left think error might helpful enough combined tell add param,issue,positive,positive,neutral,neutral,positive,positive
1984022662,"This worked for me:
docker run -p 5000:5000 -it docker-image/bin/bash
mlflow server -h 0.0.0.0(Using mlflow server instead of mlflow ui)",worked docker run server server instead,issue,negative,neutral,neutral,neutral,neutral,neutral
1984003610,"> Hi @smothiki Could you try save load on your original spark model directly and see if you're getting the same result?
> 
> ```
> spark_model.save(path)
> PipelineModel.load(path)
> ```

Sure will give it a shot. But the metadata files are most folders are empty and have a file that says `crc...` and nothing else",hi could try save load original spark model directly see getting result path path sure give shot empty file nothing else,issue,positive,positive,positive,positive,positive,positive
1983548224,"Fix for this is to use the `mlflow.client`:
```
run_id = ""<some_run_id>""
tracking_uri = ""<some_tracking_uri>""

client = mlflow.client.MlflowClient(tracking_uri)
mlflow.set_tracking_uri(tracking_uri)
run = client.get_run(run_id)
client.update_run(run_id=run.info.run_id, status=""RUNNING"")
```",fix use client run running,issue,negative,neutral,neutral,neutral,neutral,neutral
1983445357,"@serena-ruan Thank you! so indeed something is off with the behavior I'm getting, that one of the ""/"" is dropped in the artifact_uri which leads to the entire first dir being dropped later...

when I run the exact code as you:
```
mlflow.set_tracking_uri(""file:///home/my.name/mlruns"")
with mlflow.start_run():
    mlflow.log_artifact(""/home/my.name/example.txt"")
```

I get:
```
Cell In[2], line 3
      1 mlflow.set_tracking_uri(""file:///home/my.name/mlruns"")
      2 with mlflow.start_run():
----> 3     mlflow.log_artifact(""/home/my.name/example.txt"")

File ~/venvs/my_dev5/lib/python3.10/site-packages/mlflow/tracking/fluent.py:1057, in log_artifact(local_path, artifact_path, run_id)
   1029 """"""
   1030 Log a local file or directory as an artifact of the currently active run. If no run is
   1031 active, this method will create a new active run.
   (...)
   1054             mlflow.log_artifact(path)
   1055 """"""
   1056 run_id = run_id or _get_or_start_run().info.run_id
-> 1057 MlflowClient().log_artifact(run_id, local_path, artifact_path)

File ~/venvs/my_dev5/lib/python3.10/site-packages/mlflow/tracking/client.py:1189, in MlflowClient.log_artifact(self, run_id, local_path, artifact_path)
   1150 def log_artifact(self, run_id, local_path, artifact_path=None) -> None:
   1151     """"""Write a local file or directory to the remote ``artifact_uri``.
   1152 
   1153     Args:
   (...)
   1187 
   1188     """"""
-> 1189     self._tracking_client.log_artifact(run_id, local_path, artifact_path)

File ~/venvs/my_dev5/lib/python3.10/site-packages/mlflow/tracking/_tracking_service/client.py:560, in TrackingServiceClient.log_artifact(self, run_id, local_path, artifact_path)
    558     artifact_repo.log_artifacts(local_path, path_name)
    559 else:
--> 560     artifact_repo.log_artifact(local_path, artifact_path)

File ~/venvs/my_dev5/lib/python3.10/site-packages/mlflow/store/artifact/local_artifact_repo.py:37, in LocalArtifactRepository.log_artifact(self, local_file, artifact_path)
     33 artifact_dir = (
     34     os.path.join(self.artifact_dir, artifact_path) if artifact_path else self.artifact_dir
     35 )
     36 if not os.path.exists(artifact_dir):
---> 37     mkdir(artifact_dir)
     38 try:
     39     shutil.copy2(local_file, os.path.join(artifact_dir, os.path.basename(local_file)))

File ~/venvs/my_dev5/lib/python3.10/site-packages/mlflow/utils/file_utils.py:212, in mkdir(root, name)
    210 except OSError as e:
    211     if e.errno != errno.EEXIST or not os.path.isdir(target):
--> 212         raise e
    213 return target

File ~/venvs/my_dev5/lib/python3.10/site-packages/mlflow/utils/file_utils.py:209, in mkdir(root, name)
    207 target = os.path.join(root, name) if name is not None else root
    208 try:
--> 209     os.makedirs(target)
    210 except OSError as e:
    211     if e.errno != errno.EEXIST or not os.path.isdir(target):

File /usr/lib/python3.10/os.py:215, in makedirs(name, mode, exist_ok)
    213 if head and tail and not path.exists(head):
    214     try:
--> 215         makedirs(head, exist_ok=exist_ok)
    216     except FileExistsError:
    217         # Defeats race condition when another thread created the path
    218         pass

File /usr/lib/python3.10/os.py:215, in makedirs(name, mode, exist_ok)
    213 if head and tail and not path.exists(head):
    214     try:
--> 215         makedirs(head, exist_ok=exist_ok)
    216     except FileExistsError:
    217         # Defeats race condition when another thread created the path
    218         pass

    [... skipping similar frames: makedirs at line 215 (1 times)]

File /usr/lib/python3.10/os.py:215, in makedirs(name, mode, exist_ok)
    213 if head and tail and not path.exists(head):
    214     try:
--> 215         makedirs(head, exist_ok=exist_ok)
    216     except FileExistsError:
    217         # Defeats race condition when another thread created the path
    218         pass

File /usr/lib/python3.10/os.py:225, in makedirs(name, mode, exist_ok)
    223         return
    224 try:
--> 225     mkdir(name, mode)
    226 except OSError:
    227     # Cannot rely on checking for EEXIST, since the operating system
    228     # could give priority to other errors like EACCES or EROFS
    229     if not exist_ok or not path.isdir(name):

PermissionError: [Errno 13] Permission denied: '/my.name'
```
[which makes sense because there isn't such location]
and as I wrote:
```
>>> artifact_repo.artifact_dir
'/my.name/mlruns/0/b3a48ff5b8ae422fa21a5a08d00212d6/artifacts'
>>> artifact_repo.artifact_uri
'file://home/my.name/mlruns/0/b3a48ff5b8ae422fa21a5a08d00212d6/artifacts'
```",thank indeed something behavior getting one entire first later run exact code file get cell line file file log local file directory artifact currently active run run active method create new active run path file self self none write local file directory remote file self else file self else try file root name except target raise return target file root name target root name name none else root try target except target file name mode head tail head try head except race condition another thread path pas file name mode head tail head try head except race condition another thread path pas skipping similar line time file name mode head tail head try head except race condition another thread path pas file name mode return try name mode except rely since operating system could give priority like name permission sense location wrote,issue,positive,positive,neutral,neutral,positive,positive
1983393594,"Hello @B-Step62,
I have tested the new IU and it's too nice. Thank you all, I'm satisfied by what I'm seeing now.",hello tested new nice thank satisfied seeing,issue,positive,positive,positive,positive,positive,positive
1983313863,"```
>>> artifact_repo.artifact_dir
'/Users/serena.ruan/Documents/test/mlruns/0/c913c72646c94fb5b2fd8bdc3ca1110e/artifacts'
>>> artifact_repo.artifact_uri
'file:///Users/serena.ruan/Documents/test/mlruns/0/c913c72646c94fb5b2fd8bdc3ca1110e/artifacts'
```
My code is as this:
```
>>> mlflow.set_tracking_uri(""file:///Users/serena.ruan/Documents/test/mlruns"")
>>> with mlflow.start_run():
...     mlflow.log_artifact(""/Users/serena.ruan/Documents/test/test.txt"")
```
Are you running the same script? Providing stack trace and your original code should be helpful ",code file running script providing stack trace original code helpful,issue,positive,positive,positive,positive,positive,positive
1983214826,"@serena-ruan I upgraded and got the same behavior - Active run artifact URI: file://dir1/dir2/mlruns/0/d71476fa8cd94ca096473ea7dbc4e352/artifacts (only 2 '//') which then translates to trying to wrote the artifacts to ""/dir2/mlruns/0/d71476fa8cd94ca096473ea7dbc4e352/artifacts"" (skips the dir1/dir2).

in log_artifacts lin 552
```
    def log_artifact(self, run_id, local_path, artifact_path=None):
        """"""
        Write a local file or directory to the remote ``artifact_uri``.

        Args:
            local_path: Path to the file or directory to write.
            artifact_path: If provided, the directory in ``artifact_uri`` to write to.
        """"""
        artifact_repo = self._get_artifact_repo(run_id)
```

I see that artifact_repo.artifact_dir = /dir2/mlruns/0/d71476fa8cd94ca096473ea7dbc4e352/artifacts when debugging.

what do you see as active run artifact URI (active_run.info.artifact_uri)?",got behavior active run artifact file trying wrote lin self write local file directory remote path file directory write provided directory write see see active run artifact,issue,positive,negative,neutral,neutral,negative,negative
1983202833,"@harupy are you still looking into this?

I would expect that setting the tracking URI before spinning up any threads would alleviate the issue.

From my debugging attempts, I saw that the entrypoints are only executed once. Yet somehow, importing mlflow in a Thread still resets the registry.",still looking would expect setting spinning would alleviate issue saw executed yet somehow thread still registry,issue,negative,neutral,neutral,neutral,neutral,neutral
1983088739,@michshap Could you upgrade MLflow version and try again? I can't reproduce this problem on latest master,could upgrade version try ca reproduce problem latest master,issue,negative,positive,positive,positive,positive,positive
1983084426,"I completely agree that if it's not included automatically like in WandB, (where all of your stdout is captured and streamed in real-time to the tracking server), it should be at least possible to do it with minimal effort if your using python logging library",completely agree included automatically like server least possible minimal effort python logging library,issue,positive,negative,neutral,neutral,negative,negative
1983046339,"@harupy what do you mean? 
when I run
```
mlflow ui --host 0.0.0.0 --port 8084 --backend-store-uri /dir1/dir2/mlruns/
```

I see the runs and their metrics etc. as I should.
The problem occurs when I try to log something as artifact, then I'll get a ""permission denied"" error of writing to /dir2/.... as /dir2 doesn't exist (it is /dir1/dir2).
So basically I can't log any artifacts.",mean run host port see metric problem try log something artifact get permission error writing exist basically ca log,issue,negative,negative,negative,negative,negative,negative
1983041162,"Hi @smothiki Could you try save load on your original spark model directly and see if you're getting the same result?
```
spark_model.save(path)
PipelineModel.load(path)
```",hi could try save load original spark model directly see getting result path path,issue,positive,positive,positive,positive,positive,positive
1982897408,Thanks @harupy! Let me know if I can help by filing a PR.,thanks let know help filing,issue,positive,positive,positive,positive,positive,positive
1982314126,there is probably a cleaner version using an XML parser but then i would have to learn how to use the XML parser,probably cleaner version parser would learn use parser,issue,negative,neutral,neutral,neutral,neutral,neutral
1982144833,@TomSteenbergen Thanks for reporting this. Your point makes sense. Let me check why we chose to exclude setputools or didn't add setuptools as an mlflow dependency.,thanks point sense let check chose exclude add dependency,issue,negative,positive,positive,positive,positive,positive
1982141424,@moroclash Thanks for reporting this. Would you mind filing a support ticket or contacting your Databricks account team?,thanks would mind filing support ticket account team,issue,positive,positive,positive,positive,positive,positive
1982020722,"@KameniAlexNea Could you try upgrading MLflow to the latest version 2.11.0? We have added a few major features to the UI, including metrics grouping, searching, and aggregation. These may cover the said use cases, but we are definitely open to any feedbacks on the new UI as well🙂",could try latest version added major metric grouping searching aggregation may cover said use definitely open new well,issue,positive,positive,positive,positive,positive,positive
1982014978,@franco-bocci Yes that sounds like a plan! Please let us know when you get the benchmark (no time pressure!). Thank you so much for your willingness for contribution🙂,yes like plan please let u know get time pressure thank much willingness contribution,issue,positive,positive,positive,positive,positive,positive
1981472052,"Thanks a lot @B-Step62,

None of these workarounds work:

> 1. Using the legacy [OpenAI](https://python.langchain.com/docs/integrations/llms/openai) class. (this may not work with the latest Langchain/OpenAI version tho).

Indeed as you said, while the `mlflow.langchain.log_model`/`mlflow.pyfunc.load_model` work with the legacy `langchain_community.llms.OpenAI` (or `langchain.llms.OpenAI`) class, this API was removed from the side of openai so `model.predict(...)` fails (see below).
<details> <summary> code + error </summary> 

```py
from langchain_community.llms import OpenAI
# or from langchain.llms import OpenAI

llm = OpenAI(model=""gpt-4"", temperature=0) 
chain = RetrievalQA.from_llm(llm=llm, retriever=db.as_retriever(), prompt=prompt)

with tempfile.TemporaryDirectory() as temp_dir:
    persist_dir = os.path.join(temp_dir, ""faiss_index"")

    # Persist the db to a local fs folder
    db.save_local(persist_dir)

    def load_retriever(persist_directory):
        db = FAISS.load_local(persist_directory, OpenAIEmbeddings())
        return db.as_retriever()


    with mlflow.start_run(run_name=""gpt-4""):
        info = mlflow.langchain.log_model(chain,
                                        artifact_path=""retrieval_qa"",
                                        loader_fn=load_retriever,
                                        persist_dir=persist_dir) # --> this works
        
        model = mlflow.pyfunc.load_model(info.model_uri) # --> this works
        
        model.predict(df_example) # --> this fails
```
```
MlflowException: 2 tasks failed. Errors: {0: 'error: APIRemovedInV1(\'\\n\\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0
```

</details>

> 2. It appears that the new lancghain.load deserialization method works for the new Chat model like (https://github.com/langchain-ai/langchain/pull/8164#issuecomment-1665072602). You could use this method to create a custom pyfunc model. Please refer to [Serving LLMs with MLflow: Leveraging Custom PyFunc](https://mlflow.org/docs/latest/llms/custom-pyfunc-for-llms/notebooks/custom-pyfunc-advanced-llm.html) for the concrete steps for defining and logging the custom pyfunc model. The example uses Transformers model but you should be able to achieve the same thing for langchain by a few modification like transformers.AutoModelForCausalLM.from_pretrained(...) -> langchain.load.loads(...)

This doesn't work for example code above (with `RetrievalQA` powered by `gpt-4`) with the following error:
```
NotImplementedError: Trying to load an object that doesn't implement serialization
```

Indeed, the problem stems from langchain's support... Appreciated your reactiveness and response here: https://github.com/langchain-ai/langchain/issues/18420 and your 3 proposals. I am happy to contribute to help on any of these 3. This problem has been blocking us for a while

",thanks lot none work legacy class may work latest version tho indeed said work legacy class removed side see summary code error import import chain persist local folder return chain work model work tried access longer new method work new chat model like could use method create custom model please refer serving custom concrete logging custom model example model able achieve thing modification like work example code powered following error trying load object implement serialization indeed problem support reactiveness response happy contribute help problem blocking u,issue,positive,positive,positive,positive,positive,positive
1981002397,"@harupy 
This is a Kind reminder to update status of the report on huntr.com",kind reminder update status report,issue,positive,positive,positive,positive,positive,positive
1980449219,"> Right, and that would behave completely different to how other defaults are overridden with GenAI interfaces in MLflow. The underlying configuration issue that is causing the bug with Cohere should be fixed and then we could expose a parameter update logic as a separate PR to enable customization :)

@BenWilson2 what's the bug with Cohere? Did you mean Claude?

The only way to solve the configuration issue without parameter update logic would be to modify the default parameters for the judge llm, but this would materially change the default judge LLM implementation for OpenAI models.",right would behave completely different underlying configuration issue causing bug cohere fixed could expose parameter update logic separate enable bug cohere mean way solve configuration issue without parameter update logic would modify default judge would materially change default judge implementation,issue,negative,positive,neutral,neutral,positive,positive
1980424423,Could we add the pyfunc model serving test here https://github.com/mlflow/mlflow/pull/11265/files#r1513752584 as well?,could add model serving test well,issue,negative,neutral,neutral,neutral,neutral,neutral
1980021144,should we include this in the patch release as well?,include patch release well,issue,negative,neutral,neutral,neutral,neutral,neutral
1980012811,"Merging this for a quick fix, but next iteration we'll include some nicer features such as copy on click",quick fix next iteration include copy click,issue,negative,positive,positive,positive,positive,positive
1979920777,"ok . sure . I have removed it . please check again.
",sure removed please check,issue,positive,positive,positive,positive,positive,positive
1979847993,"Right, and that would behave completely different to how other defaults are overridden with GenAI interfaces in MLflow. 
The underlying configuration issue that is causing the bug with Cohere should be fixed and then we could expose a parameter update logic as a separate PR to enable customization :) ",right would behave completely different underlying configuration issue causing bug cohere fixed could expose parameter update logic separate enable,issue,negative,positive,positive,positive,positive,positive
1979842635,"I think they should replace, otherwise we can't work around the issue",think replace otherwise ca work around issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1978375527,"Hi @dbczumar , can I work on this? I had made some work [here](https://github.com/ChenYi015/mlflow/tree/helm-charts/charts/mlflow)  and I am happy to contribute a helm chart for MLflow.",hi work made work happy contribute helm chart,issue,positive,positive,positive,positive,positive,positive
1978219504,"Thanks for the reply. That code runs successfully on my machine.
It made me understand that the issue was related to the way I was passing the model_uri:
`runs:/run_id/artifacts/model` instead of `runs:/run_id/model`

I will close this issue.
",thanks reply code successfully machine made understand issue related way passing instead close issue,issue,positive,positive,positive,positive,positive,positive
1978018520,"Thank you, I've made all workflow passed, could you help take a look on my pr? Thanks in advance! @B-Step62 ",thank made could help take look thanks advance,issue,positive,positive,positive,positive,positive,positive
1978018295,@daanalfa Thanks for reporting this issue! Great write-up! Adding a `parameters` argument sounds good to me. @BenWilson2 What do you think?,thanks issue great argument good think,issue,positive,positive,positive,positive,positive,positive
1977975249,"@goncalo-maia I ran the following code, but could not reproduce the issue.

```python
from sklearn.linear_model import LogisticRegression

import mlflow

with mlflow.start_run():
    info = mlflow.sklearn.log_model(LogisticRegression(), ""model"")
    mlflow.register_model(model_uri=info.model_uri, name=""hello"")
    mlflow.sklearn.load_model(info.model_uri)
```

Does this code run successfully on your machine?",ran following code could reproduce issue python import import model hello code run successfully machine,issue,negative,positive,positive,positive,positive,positive
1977920573,"spark hello world (spark context doesn't support input example because ``[CONTEXT_ONLY_VALID_ON_DRIVER]`` error)
```python
import mlflow
from mlflow.models import infer_signature
import pandas as pd
from pyspark.sql import SparkSession

spark = SparkSession.builder.getOrCreate()
df = spark.createDataFrame(pd.DataFrame({'x': [1, 2, 3]}))

def predict(model_input):
  return model_input

with mlflow.start_run():
    mlflow.pyfunc.log_model(
        artifact_path=""model"",
        python_model=predict,
        signature=infer_signature(df, predict(df)),
        pip_requirements=[]
    )
    run_id = mlflow.active_run().info.run_id

model_uri = f""runs:/{run_id}/model""
model = mlflow.pyfunc.load_model(model_uri)

# Make predictions
predictions = model.predict(df)
predictions.show()
```
Output
```text
+---+
|  x|
+---+
|  1|
|  2|
|  3|
+---+
```",spark hello world spark context support input example error python import import import import spark predict return model predict model make output text,issue,positive,neutral,neutral,neutral,neutral,neutral
1977812220,Looks like this was missed as part of the new migration. Thanks for reporting! I'm working on a PR to add it back.,like part new migration thanks working add back,issue,positive,positive,positive,positive,positive,positive
1977798011,"> I have a few concerns but LGTM as a quick fix!
> 
> * repository size increase
> * slow page load

Did you notice any appreciable slow load time on the pages that had the ""larger"" .gif files attached? ",quick fix repository size increase slow page load notice appreciable slow load time attached,issue,negative,negative,neutral,neutral,negative,negative
1977747217,"> which requires some additional authorized setup

What is the additional authorized setup?",additional authorized setup additional authorized setup,issue,negative,neutral,neutral,neutral,neutral,neutral
1977724267,"Hello @B-Step62 ,
I'm thinking of views like in wandb where metrics are grouped and users have the possibility to search for a certain metric.",hello thinking like metric grouped possibility search certain metric,issue,positive,positive,positive,positive,positive,positive
1977720278,The attached traceback looks like Thread-2 is accessing `self._registry` while it's registering model registry stores.,attached like model registry,issue,negative,neutral,neutral,neutral,neutral,neutral
1977670818,"Non-spark hello world
```python
import mlflow
import pandas as pd
import numpy as np
import scipy

values = [1,2,3]
inputs = [
    pd.DataFrame(dict(x=values)),
    np.array(values),
    scipy.sparse.csc_matrix(values),
    scipy.sparse.csr_matrix(values),
    values,
    dict(x=values),
]

for i, input in enumerate(inputs):
    with mlflow.start_run():
        mlflow.pyfunc.log_model(""model"", python_model=lambda x: x, input_example=input)
        run_id = mlflow.active_run().info.run_id
        model = mlflow.pyfunc.load_model(f""runs:/{run_id}/model"")

        print(f""\n=============== {i} ==============="")
        predictions = model.predict(input)
        print(type(predictions))
        print(predictions)
        
```

Output
```text

=============== 0 ===============
<class 'pandas.core.frame.DataFrame'>
   x
0  1
1  2
2  3
/Users/michael.berk/opt/anaconda3/envs/mlflow-dev-1/lib/python3.8/site-packages/_distutils_hack/__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.
  warnings.warn(
/Users/michael.berk/opt/anaconda3/envs/mlflow-dev-1/lib/python3.8/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn(""Setuptools is replacing distutils."")

=============== 1 ===============
<class 'numpy.ndarray'>
[1 2 3]

=============== 2 ===============
<class 'scipy.sparse._csc.csc_matrix'>
  (0, 0)	1
  (0, 1)	2
  (0, 2)	3

=============== 3 ===============
<class 'scipy.sparse._csr.csr_matrix'>
  (0, 0)	1
  (0, 1)	2
  (0, 2)	3
2024/03/04 18:46:37 INFO mlflow.models.utils: Lists of scalar values are not converted to a pandas DataFrame. If you expect to use pandas DataFrames for inference, please construct a DataFrame and pass it to input_example instead.

=============== 4 ===============
<class 'list'>
[1, 2, 3]
2024/03/04 18:46:38 INFO mlflow.models.utils: We convert input dictionaries to pandas DataFrames such that each key represents a column, collectively constituting a single row of data. If you would like to save data as multiple rows, please convert your data to a pandas DataFrame before passing to input_example.
/Users/michael.berk/opt/anaconda3/envs/mlflow-dev-1/lib/python3.8/site-packages/_distutils_hack/__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.
  warnings.warn(
/Users/michael.berk/opt/anaconda3/envs/mlflow-dev-1/lib/python3.8/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn(""Setuptools is replacing distutils."")

=============== 5 ===============
<class 'dict'>
{'x': [1, 2, 3]}

```",hello world python import import import import input enumerate model model print input print type print output text class also module may lead undesirable avoid avoid directly ensure traditional way install make sure always class class class scalar converted expect use inference please construct pas instead class convert input key column collectively single row data would like save data multiple please convert data passing also module may lead undesirable avoid avoid directly ensure traditional way install make sure always class,issue,positive,positive,positive,positive,positive,positive
1976892658,"Are there any news/timelines for the implementation of ""array"" metrics? While the proposed approach (step) can be used as a workaround in some cases, it is not a perfect replacement (for example if we want to log an array of metrics at every epoch).",implementation array metric approach step used perfect replacement example want log array metric every epoch,issue,positive,positive,positive,positive,positive,positive
1976755261,"But where can we explore dataset tags? Since we can specify them in the `log_input()` function, I am assuming they are being stored somewhere / should be available.",explore since specify function assuming somewhere available,issue,negative,positive,positive,positive,positive,positive
1976593446,"@harupy thanks for this, just fyi I've sent a follow up to the email containing the disclosure we sent over.",thanks sent follow disclosure sent,issue,negative,positive,positive,positive,positive,positive
1976345585,"> > I find it it true that sklearn.utils.testing is deprecated
> 
> deprecated in newer versions of scikit-learn. Does `sklearn.utils._testing` exist in older versions of scikit-learn?

testing is older, _testing is new version

this is official explanation
```
FutureWarning: The sklearn.utils.testing module is deprecated in version 0.22 and will be removed in version 0.24. The 

corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from 

sklearn.utils is now part of the private API.
```
and this is my pr : https://github.com/mlflow/mlflow/pull/11304

[sklearn.utils.testing ](https://www.google.com.hk/search?q=sklearn.utils.testing+module+is+deprecated&oq=sklearn.utils.testing+module+is+deprecated&gs_lcrp=EgZjaHJvbWUyBggAEEUYOdIBBzc0MmowajSoAgCwAgA&sourceid=chrome&ie=UTF-8)",find true exist older testing older new version official explanation module version removed version corresponding class instead anything part private,issue,negative,positive,positive,positive,positive,positive
1976218541,"@brynn-code, thanks for working on the revamp! The failure is due to the EOL image and failing for other PRs, so should be irrelevant to the PR. ~I'm working on the fix so feel free to ignore it now:)~ Actually was a pretty trivial one, it should be fixed now!",thanks working revamp failure due image failing irrelevant working fix feel free ignore actually pretty trivial one fixed,issue,negative,positive,neutral,neutral,positive,positive
1976179579,"PEFT is now officially supported since the release of MLflow 2.11🤗
Please check [the documentation](https://mlflow.org/docs/latest/llms/transformers/guide/index.html#peft-models-in-mlflow-transformers-flavor) and [the new tutorial](https://mlflow.org/docs/latest/llms/transformers/tutorials/fine-tuning/transformers-peft.html) to try it out, and let us know if you have any idea to make this integration more useful!",officially since release please check documentation new tutorial try let u know idea make integration useful,issue,positive,positive,positive,positive,positive,positive
1976022047,"Hey! Sure. From my side, this are the next steps:
1) add this index to our DB 
2) compare CPU usage before and after adding the index
3) sharing the results here

After that, if it's okay for you, I can work on adding this index through Alembic.
Probably will be done during this week. Works for you?",hey sure side next add index compare usage index work index alembic probably done week work,issue,negative,positive,positive,positive,positive,positive
1975948155,"Hi @B-Step62 , I'm trying to get the pr back, there is a 'build_doc_r' CI failed due to image unavailable, I'm not sure if it is related to my changes, either can't get run logs, could you please help take a look on it? Thanks in advance! #11311 
",hi trying get back due image unavailable sure related either ca get run could please help take look thanks advance,issue,positive,positive,positive,positive,positive,positive
1975905920,@aagten I was able to reproduce the issue. Investigating how this happens.,able reproduce issue investigating,issue,negative,positive,positive,positive,positive,positive
1975636370,Can you please change the report status here https://huntr.com/bounties/bfa116d3-2af8-4c4a-ac34-ccde7491ae11/ to valid and resolved,please change report status valid resolved,issue,negative,neutral,neutral,neutral,neutral,neutral
1975632020,"Hello @harupy 
That was quick response and resolution. Its fixed

I have checked it, its showing me permission denied error now
",hello quick response resolution fixed checked showing permission error,issue,negative,positive,positive,positive,positive,positive
1975622631,@osama-ammar We don't have a plan to update the legacy comparison chart. Can you use the new one?,plan update legacy comparison chart use new one,issue,negative,positive,positive,positive,positive,positive
1975570151,"@rook1337 thanks for reporting this, filed #11309. Would you mind testing this fix?",rook thanks would mind testing fix,issue,negative,positive,positive,positive,positive,positive
1975560417,I'm curious if this happened because your local environment was broken for some reason.,curious local environment broken reason,issue,negative,negative,negative,negative,negative,negative
1975559709,"> I find it it true that sklearn.utils.testing is deprecated

deprecated in newer versions of scikit-learn. Does `sklearn.utils._testing` exist in older versions of scikit-learn?
",find true exist older,issue,negative,positive,positive,positive,positive,positive
1975557843,@zhouyou9505 can you reproduce the error with 1.4.1.post1? I could not.,reproduce error post could,issue,negative,neutral,neutral,neutral,neutral,neutral
1974776996,"Thank you for reporting the issue, @ai-learner-00, @rabah-khalek  !

ChatOpenAI model is not supported in MLflow Langchain flavor yet, due to a known limitation of deserialization in Langchain ([ref](https://github.com/langchain-ai/langchain/pull/8164#issuecomment-1673796125)). We reported the issue to Langchain but it may take time to be able to support that.

In the meantime, you can work around the issue by either:

1. Using the legacy [OpenAI](https://python.langchain.com/docs/integrations/llms/openai) class. (this may not work with the latest Langchain/OpenAI version tho).
2. It appears that the new `lancghain.load` deserialization method works for the new Chat model like ([this](https://github.com/langchain-ai/langchain/pull/8164#issuecomment-1665072602)). You could use this method to create a custom pyfunc model. Please refer to [Serving LLMs with MLflow: Leveraging Custom PyFunc](https://mlflow.org/docs/latest/llms/custom-pyfunc-for-llms/notebooks/custom-pyfunc-advanced-llm.html) for the concrete steps for defining and logging the custom pyfunc model. The example uses Transformers model but you should be able to achieve the same thing for langchain by a few modification like `transformers.AutoModelForCausalLM.from_pretrained(...)` -> `langchain.load.loads(...)`

Sorry for the inconvenience, but I hope this answer helps mitigate the issue!",thank issue model flavor yet due known limitation ref issue may take time able support work around issue either legacy class may work latest version tho new method work new chat model like could use method create custom model please refer serving custom concrete logging custom model example model able achieve thing modification like sorry inconvenience hope answer mitigate issue,issue,positive,positive,positive,positive,positive,positive
1974411373,"> Can you run the following code (plz make sure to only run this code)? If `ImportError: cannot import name 'UnsetMetadataPassedError' from 'sklearn.exceptions' (/home/zhouyou/miniconda3/lib/python3.11/site-packages/sklearn/exceptions.py)` occurs, this is not an mlflow issue but an sklearn issue or your sklearn is collapsed for some reason:
> 
> ```python
> from sklearn.utils import all_estimators
> 
> all_estimators()
> ```

```
# Name                    Version                   Build  Channel
scikit-learn              1.3.0           py311ha02d727_1    defaults

```
I change the version of scikit-learn    from  1.4.1.post1  ->   1.3.0  , then my program works well.
but I find it it true that sklearn.utils.testing is deprecated

```
from mlflow.sklearn.utils import _backported_all_estimators

_backported_all_estimators()
```

```
Traceback (most recent call last):
  File ""/home/zhouyou/PycharmProjects/mlflow_test/Chapter1/expcetion.py"", line 4, in <module>
    _backported_all_estimators()
  File ""/home/zhouyou/miniconda3/lib/python3.11/site-packages/mlflow/sklearn/utils.py"", line 905, in _backported_all_estimators
    from sklearn.utils.testing import ignore_warnings
ModuleNotFoundError: No module named 'sklearn.utils.testing'
```",run following code make sure run code import name issue issue reason python import name version build channel change version post program work well find true import recent call last file line module file line import module,issue,positive,positive,positive,positive,positive,positive
1973723923,"@harupy can you please help me what will be the correct value for the below args and ENV Variable:
if I'm storing my artifacts in this location - s3://dataengineering-mlflow-bucket/mlflow/artifacts/

```
--default-artifact-root = ?
--artifacts-destination= ?

MLFLOW_S3_ENDPOINT_URL : ?
```
",please help correct value variable location,issue,positive,neutral,neutral,neutral,neutral,neutral
1973625433,"I have the same problem doing this:
```py
from langchain_openai import ChatOpenAI


llm = ChatOpenAI(model=""gpt-4"", temperature=0) 
chain = RetrievalQA.from_llm(llm=llm, retriever=db.as_retriever(), prompt=prompt)

with tempfile.TemporaryDirectory() as temp_dir:
    persist_dir = os.path.join(temp_dir, ""faiss_index"")

    # Persist the db to a local fs folder
    db.save_local(persist_dir)

    def load_retriever(persist_directory):
        db = FAISS.load_local(persist_directory, OpenAIEmbeddings())
        return db.as_retriever()


    with mlflow.start_run(run_name=""gpt-4""):
        info = mlflow.langchain.log_model(chain,
                                        artifact_path=""retrieval_qa"",
                                        loader_fn=load_retriever,
                                        persist_dir=persist_dir)
        
        model = mlflow.pyfunc.load_model(info.model_uri)
```
which breaks with the following error:
```
[python3.10/site-packages/mlflow/langchain/__init__.py:648](.venv/lib/python3.10/site-packages/mlflow/langchain/__init__.py:648), in _load_pyfunc(path)

ValueError: Loading openai-chat LLM not supported
```",problem import chain persist local folder return chain model following error path loading,issue,negative,neutral,neutral,neutral,neutral,neutral
1972903753,"@harupy Yes that worked thanks. 

```
mlflow.set_experiment(""Evaluate Hugging Face Text Pipeline"")

signature = mlflow.models.infer_signature(
    model_input=""What are the three primary colors?"",
    model_output=""The three primary colors are red, yellow, and blue."",
)

model_config = {
    ""max_length"": 150,
}

with mlflow.start_run():
    model_info = mlflow.transformers.log_model(
        transformers_model=mpt_pipeline,
        artifact_path=""mpt-7b"",
        signature=signature,
        registered_model_name=""mpt-7b-chat"",
        model_config=model_config
    )
```
`
`
",yes worked thanks evaluate hugging face text pipeline signature three primary color three primary color red yellow blue,issue,positive,positive,positive,positive,positive,positive
1972786555,"@B-Step62 

> Just realized my test env always includes accerelate so this one was not caught...).

Makes sense. accelerate is installed on my M1 macbook pro, but `BFloat16` isn't supported on M1 mac so I was able to reach the failed line and catch the error :)

> btw we should include this in 2.11 right?

yes, we should. I'll file a pr to cherry-pick this.",test always one caught sense accelerate pro mac able reach line catch error include right yes file,issue,negative,positive,positive,positive,positive,positive
1972592383,"@thomasjv799 The following code throws the same error:

```python
from transformers import pipeline

mpt_pipeline = pipeline(""text-generation"", model=""mosaicml/mpt-7b-chat"")
print(mpt_pipeline(""hello "" * 40))
```

Can you try the following?

```python
model_config = {
    ""max_length"": 150,
}
model_info = mlflow.transformers.log_model(..., model_config=model_config)
```",following code error python import pipeline pipeline print hello try following python,issue,negative,neutral,neutral,neutral,neutral,neutral
1972526333,"@harupy  The above code I run is through flow based on the tutorial they provided. When I ran this:

`with mlflow.start_run():
    results = mlflow.evaluate(
        model_info.model_uri,
        eval_df.head(10),
        evaluators=""default"",
        model_type=""text"",
        targets=""output"",
        extra_metrics=[answer_correctness_metric, answer_quality_metric],
        evaluator_config={""col_mapping"": {""inputs"": ""instruction""}},
    )`

It crashed and gave above issue, the model_info is loaded from the below 

`mlflow.set_experiment(""Evaluate Hugging Face Text Pipeline"")

signature = mlflow.models.infer_signature(
    model_input=""What are the three primary colors?"",
    model_output=""The three primary colors are red, yellow, and blue."",
)

with mlflow.start_run():
    model_info = mlflow.transformers.log_model(
        transformers_model=mpt_pipeline,
        artifact_path=""mpt-7b"",
        signature=signature,
        registered_model_name=""mpt-7b-chat"",
    )`

I only ran from this https://mlflow.org/docs/latest/llms/llm-evaluate/notebooks/huggingface-evaluation.html and nothing extra. 

Yes it seems coming from transformers but thing is how to change it in front while running mlflow, like where exactly do we have to perform the modification to fix it
",code run flow based tutorial provided ran default text output instruction gave issue loaded evaluate hugging face text pipeline signature three primary color three primary color red yellow blue ran nothing extra yes coming thing change front running like exactly perform modification fix,issue,negative,positive,positive,positive,positive,positive
1972501879,"Hey @BenWilson2 I think im running into a similar issue here. I feat my experiment has too many runs

```
mlflow.exceptions.MlflowException: API request to http://XXX/api/2.0/mlflow/runs/search failed with exception 
HTTPConnectionPool(host='XXX', port=5000): Max retries exceeded with url: /api/2.0/mlflow/runs/search 
(Caused by ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')))
```

However, when I limit apply a filter to only retrieve a subset of my runs it does seem to work.... ",hey think running similar issue feat experiment many request exception aborted end closed connection without response however limit apply filter retrieve subset seem work,issue,negative,positive,positive,positive,positive,positive
1972479592,"Can you run the following code (plz make sure to only run this code)? If `ImportError: cannot import name 'UnsetMetadataPassedError' from 'sklearn.exceptions' (/home/zhouyou/miniconda3/lib/python3.11/site-packages/sklearn/exceptions.py)` occurs, this is not an mlflow issue but an sklearn issue or your sklearn is collapsed for some reason:

```python
from sklearn.utils import all_estimators

all_estimators()
```",run following code make sure run code import name issue issue reason python import,issue,negative,positive,positive,positive,positive,positive
1972465866,@thomasjv799 Can you reproduce this issue without mlflow? This might be a bug in transformers.,reproduce issue without might bug,issue,negative,neutral,neutral,neutral,neutral,neutral
1972463003,"I was able to reproduce the exact the same error by **manually removing `UnsetMetadataPassedError` in `exceptions.py`:

```
>>> from sklearn.utils import all_estimators
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python3.9/site-packages/sklearn/__init__.py"", line 87, in <module>
    from .base import clone
  File ""/usr/local/lib/python3.9/site-packages/sklearn/base.py"", line 19, in <module>
    from .utils import _IS_32BIT
  File ""/usr/local/lib/python3.9/site-packages/sklearn/utils/__init__.py"", line 20, in <module>
    from . import _joblib, metadata_routing
  File ""/usr/local/lib/python3.9/site-packages/sklearn/utils/metadata_routing.py"", line 12, in <module>
    from ._metadata_requests import WARN, UNUSED, UNCHANGED  # noqa
  File ""/usr/local/lib/python3.9/site-packages/sklearn/utils/_metadata_requests.py"", line 87, in <module>
    from ..exceptions import UnsetMetadataPassedError
ImportError: cannot import name 'UnsetMetadataPassedError' from 'sklearn.exceptions' (/usr/local/lib/python3.9/site-packages/sklearn/exceptions.py)
```

`UnsetMetadataPassedError` should exist in `exceptions.py`. It looks like your sklearn package is collpased? Can you reinstall sklearn?

```
pip uninstall -y scikit-learn
pip install scikit-learn
```",able reproduce exact error manually removing import recent call last file line module file line module import clone file line module import file line module import file line module import warn unused unchanged file line module import import name exist like package reinstall pip pip install,issue,negative,positive,positive,positive,positive,positive
1972456795,"> ImportError: cannot import name 'UnsetMetadataPassedError' from 'sklearn.exceptions' (/home/zhouyou/miniconda3/lib/python3.11/site-packages/sklearn/exceptions.py)

Can you run the following command to see what this file looks like?

```
cat /home/zhouyou/miniconda3/lib/python3.11/site-packages/sklearn/exceptions.py
```
",import name run following command see file like cat,issue,negative,neutral,neutral,neutral,neutral,neutral
1972424417,I think this is a windows issue. See https://stackoverflow.com/questions/74233128/difference-between-0-0-0-0-and-127-0-0-1-on-windows-and-linux. Both `0.0.0.0` and `127.0.0.1` work fine on my machine (mac).,think issue see work fine machine mac,issue,negative,positive,positive,positive,positive,positive
1972240989,"Thanks @harupy , It's working on original script also.. Problem is with URI : 0.0.0.0:5000 -> 127.0.0.1:5000 it's working. Whether this issue specific to my laptop configuration or mlflow code problem ? ",thanks working original script also problem working whether issue specific configuration code problem,issue,negative,positive,positive,positive,positive,positive
1972236681,"> can you try this?
> 
> ```python
> import mlflow
> 
> mlflow.set_tracking_uri(""http://127.0.0.1:5000"")
> with mlflow.start_run():
>     mlflow.set_tag(""run_id"", ""run_id"")
> ```

It's working on seperate script.. able to log the run in mlflow 
",try python import working script able log run,issue,negative,positive,positive,positive,positive,positive
1972220395,"> is the tracking server running on your machine?

yes
![image](https://github.com/mlflow/mlflow/assets/88357044/b6a46bf7-17d4-490f-986a-e9a742f5b595)

",server running machine yes image,issue,negative,neutral,neutral,neutral,neutral,neutral
1972217328,"```
  File ""D:\anaconda3\envs\mlflow_venv\lib\site-packages\mlflow\utils\rest_utils.py"", line 130, in http_request 
    raise MlflowException(f""API request to {url} failed with exception {e}"")
mlflow.exceptions.MlflowException: API request to http://0.0.0.0:5000/api/2.0/mlflow/runs/create failed with exception HTTPConnectionPool(host='0.0.0.0', port=5000): Max retries exceeded with url: /api/2.0/mlflow/runs/create (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001871DE89240>: Failed to establish a new connection: [WinError 10049] The requested address is not valid in its context'))
```
Same Error",file line raise request exception request exception object establish new connection address valid context error,issue,negative,positive,positive,positive,positive,positive
1972213847,"> can you run this code?
> 
> ```python
> import mlflow
> 
> mlflow.set_tracking_uri(""http://0.0.0.0:5000"")
> with mlflow.start_run():
>     mlflow.set_tag(""run_id"", ""run_id"")
> ```

Whether on seperate script file or in my loan_prediction script file ?
",run code python import whether script file script file,issue,negative,neutral,neutral,neutral,neutral,neutral
1972211385,"can you run this code?


```python
import mlflow

mlflow.set_tracking_uri(""http://0.0.0.0:5000"")
with mlflow.start_run():
    mlflow.set_tag(""run_id"", ""run_id"")
```",run code python import,issue,negative,neutral,neutral,neutral,neutral,neutral
1972198051,"> curl http://0.0.0.0:5000

curl: (7) Failed to connect to 0.0.0.0 port 5000 after 1 ms: Couldn't connect to server",curl curl connect port could connect server,issue,negative,neutral,neutral,neutral,neutral,neutral
1972067131,"If anyone who has used the [bitnami mlflow chart](https://github.com/bitnami/charts/blob/main/bitnami/mlflow/values.yaml), they can understand the pain to actually be able to make it work. Its not just that, there is no documentation available to simply provide guidance for that chart's configuration or usage.
On the other hand, the [mlflow community helm chart](https://github.com/community-charts/helm-charts/tree/main/charts/mlflow) is somewhere closer to an ideal state but it isn't being actively maintained (last commit made over a year ago!)

I'm rather unsure why would a renouned and leading experiment tracking tool would be so far behind providing an offering for their kubernetes helm chart, especially when it is so highly in demand from the community and users?",anyone used chart understand pain actually able make work documentation available simply provide guidance chart configuration usage hand community helm chart somewhere closer ideal state actively last commit made year ago rather unsure would leading experiment tool would far behind providing offering helm chart especially highly demand community,issue,positive,positive,positive,positive,positive,positive
1971327248,"Hi, @BenWilson2. Let me ask some questions/asks:
1. Do I need to write up the proper design document for this task? If so, can I know the design doc format you are using for mlflow?
2. Do you want to make it a plugin instead of incorporating the functionality in the configuration yaml of [mlflow deployment](https://mlflow.org/docs/latest/llms/deployments/index.html)? It will be like the yaml below and I think this direction is worth exploring
```yaml
endpoints:
  - name: completions
    endpoint_type: llm/v1/completions
    model:
      provider: openai
      name: gpt-3.5-turbo
      config:
        openai_api_key: $OPENAI_API_KEY
    limit:
      renewal_period: minute
      calls: 10
auth:
  basic:
    username: tomehirata
    password: mypassword
```
3. Would you mind putting my name in the 2.12 release in the project display [here](https://github.com/orgs/mlflow/projects/4/views/1)?",hi let ask need write proper design document task know design doc format want make instead functionality configuration deployment like think direction worth exploring name model provider name limit minute basic password would mind name release project display,issue,positive,positive,neutral,neutral,positive,positive
1971258094,"@harupy If this looks good, could I merge it to include in the release?",good could merge include release,issue,negative,positive,positive,positive,positive,positive
1970912342,"Update: tested your version and it works!!!! 

Thank you for the very quick implementation",update tested version work thank quick implementation,issue,negative,positive,positive,positive,positive,positive
1970906096,"@harupy  It raises same exception:
```
raise MlflowException(f""API request to {url} failed with exception {e}"")
mlflow.exceptions.MlflowException: API request to http://0.0.0.0:5001/api/2.0/mlflow/experiments/get-by-name failed with exception HTTPConnectionPool(host='0.0.0.0', port=5001): Max retries exceeded with url: /api/2.0/mlflow/experiments/get-by-name?experiment_name=Loan_prediction (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000023057151810>: Failed to establish a new connection: [WinError 10049] The requested address is not valid in its context'))
```",exception raise request exception request exception object establish new connection address valid context,issue,negative,positive,positive,positive,positive,positive
1970901615,"Sure this does clarify! Thanks for the response @B-Step62 kun, appreciate it. I will use these internal functions and log these tags myself to make them visible for me in the UI for now.",sure clarify thanks response appreciate use internal log make visible,issue,positive,positive,positive,positive,positive,positive
1970899191,"Thanks @harupy 

I was already trying to wok on some of it locally (stated under guidance would be willing to help out ;-) )

I have my implementation kinda ready (which btw is similar to what you are having in the PR), but having the problem that the final uploaded artifact is one level too deep, using a folder still for the filename.

For example, if you try to upload the file ""some_large_file.dat"" without any additional path, after uploading it, in the s3 bucket it will be under
`/<experiment_id>/<run_id>/artifacts/some_large_file.dat/some_large_file.dat`

Not sure if your implementation suffers from the same, can give it a quick test here",thanks already trying locally stated guidance would willing help implementation ready similar problem final artifact one level deep folder still example try file without additional path bucket sure implementation give quick test,issue,positive,positive,positive,positive,positive,positive
1970866706,"> The real issue is each client returns different objects.

100%, and I assume making change to Databricks client is too dangerous here? 

I think the solution [here](https://github.com/mlflow/mlflow/pull/11096#issuecomment-1970539657) is safer, requiring just minimum hack to resolve the issue. Pathing Endpoint class might cause some long-term drift... like `from mlflow.deployment import Endpoint` and `from mlflow.deployments.server.config import Endpoint` returns different object, and once more ppl rely on these classes it becomes hard to unify.

Alternatively we could add a getter method to the Endpoint pydantic model, but it feels less clean than the solution above.
",real issue client different assume making change client dangerous think solution minimum hack resolve issue class might cause drift like import import different object rely class becomes hard unify alternatively could add getter method model le clean solution,issue,positive,negative,neutral,neutral,negative,negative
1970850001,Checked with bitnami team as well but they are saying maybe there is some issue with S3 inside the mlflow code that's why getting this error message when accessing S3 artifacts.,checked team well saying maybe issue inside code getting error message,issue,negative,neutral,neutral,neutral,neutral,neutral
1970803011,"@ManoBharathi93 It looks like `mlflow.set_tag(""run_id"", run_id)` fails. Can you run the following code? Does it work?

```python
import mlflow

mlflow.set_tracking_uri(""http://0.0.0.0:5001"")
with mlflow.start_run():
    mlflow.set_tag(""run_id"", ""run_id"")
```",like run following code work python import,issue,negative,neutral,neutral,neutral,neutral,neutral
1970799134,"What about adding a method like `mlflow.deployments.server.config.Endpoint.to_attr_dict()` ?
This way looks less ambiguous.",method like way le ambiguous,issue,negative,neutral,neutral,neutral,neutral,neutral
1970640436,The real issue is each client returns different objects.,real issue client different,issue,negative,positive,neutral,neutral,positive,positive
1970623265,"Thank you very much for the elaborated proposal, @KameniAlexNea!!
The idea of organizing metrics into sub groups sounds legitimate. Yet I'm not very clear what is the best user interface and the common use cases. Would you mind sharing some image or screenshots for what you are imaging or available in other tools?",thank much proposal idea metric sub legitimate yet clear best user interface common use would mind image available,issue,positive,positive,positive,positive,positive,positive
1970539657,"@B-Step62 It's possible but if we do that, we'd need to inspect the object type in `_call_deployments_api` because `DatabricksDeploymentClient.get_endpoint` returns `AttrDict`. The code would look like:

```python
endpoint_dict = endpoint.dict() if is_pydantic_model(endpoint) else endpoint
endpoint_dict.get(""task"", endpoint_dict.get(""endpoint_type""))
```",possible need inspect object type code would look like python else task,issue,negative,neutral,neutral,neutral,neutral,neutral
1970356659,"Yes I think that works! Before actually start working on it, would you mind running a quick benchmark in your env with index/no-index, so we can get overall sense of the impact of indexing? It is non-trivial effort to update the schema, so we just want to make sure we can get certain performance improvement for common use cases🙂 If I can be more greedy, it would be super nice if the benchmark includes the small-medium database size, as the registry DB size is not so large for common use cases. You can also refer to the thread that we've added index to tracking database: https://github.com/mlflow/mlflow/issues/3785 ",yes think work actually start working would mind running quick get overall sense impact indexing effort update schema want make sure get certain performance improvement common use greedy would super nice size registry size large common use also refer thread added index,issue,positive,positive,positive,positive,positive,positive
1970345007,"Confirmed. If the PR is re-filed and everything's passing, we can get the PromptFlow flavor in for the 2.11 release :) ",confirmed everything passing get flavor release,issue,negative,positive,positive,positive,positive,positive
1970342844,"@wxpjimmy Yes, but we've updated it for the incoming release:https://github.com/mlflow/mlflow/pull/11034. The revert was because we were not ready at the moment of the last release, and also several test cases failed with the change (fyi the tests cases for the flavor were not executed in CI because of some missing configuration). Now we should be unblocked and the flavor can be added back if those tests pass:) cc: @BenWilson2 ",yes incoming release revert ready moment last release also several test change flavor executed missing configuration unblocked flavor added back pas,issue,negative,neutral,neutral,neutral,neutral,neutral
1970338498,"@B-Step62 Is this due to the SDK dependency conflict between OpenAI SDK and MLflow? It would be great if you could share the conflict details, I believe we already tested the flovor with MLFlow and didn't get the conflict.",due dependency conflict would great could share conflict believe already tested get conflict,issue,negative,positive,positive,positive,positive,positive
1969650351,"isn't this related to: https://github.com/mlflow/mlflow/issues/271?
how do folks handle it currently? I would be surprised if the commit step is left to the developer/engineer to do manually.",related handle currently would commit step left manually,issue,negative,neutral,neutral,neutral,neutral,neutral
1969371437,Can we please move this small change forward? I need it to unblock running mlflow in snowpark. @chenmoneygithub ,please move small change forward need unblock running,issue,negative,negative,negative,negative,negative,negative
1968843103,"Good Morning,

Thanks for the quick response, additional info below:

/mlflow/ajax-api/2.0/mlflow/runs/search took 30.21 seconds, and appears to run again every 15seconds.


What is the size and format of the dataset? Order of 10mil records, reading bytes using numpy memmap
Where are you running the MLflow server and store the artifacts? Running server in kubernetes (node has 8cpu 32mem), artifacts are in s3
Does the issue happen when you decrease the dataset size, or the number of runs? decreasing logged parameters/metrics results in faster UI load. Number of runs does not affect speed.
Could you provide the code to log those large runs? Using Lightning MLFlow logger.

",good morning thanks quick response additional took run every size format order mil reading running server store running server node mem issue happen decrease size number decreasing logged faster load number affect speed could provide code log large lightning logger,issue,positive,positive,positive,positive,positive,positive
1968567009,"> Thank you for proposing this feature, @franco-bocci ! Adding index sounds valuable for the large scale use case of the model registry. However, one concern is the migration effort as it is basically the schema change. Since many users are running the model registry in production, the migration needs to be done carefully with an easy and safe migration script/tool.

Hey! Yes, I think we could add this to the alembic migrations so that the new version includes it.
What do you think?",thank feature index valuable large scale use case model registry however one concern migration effort basically schema change since many running model registry production migration need done carefully easy safe migration hey yes think could add alembic new version think,issue,positive,positive,positive,positive,positive,positive
1968306150,"Any updates here? If you're working on a PR, please link it to this issue. @harupy ",working please link issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1967931061,"Thank you for bringing this issue to our attention, @yankees5963!
The slow page load should be improved, however, it is hard to identify which part is the bottleneck from the provided information. Could you help us spotting what makes the page load so slow:
1. Press F12 to open the developer tool (or right-click on the page, select ""Inspect"")
2. Select ""Network"" tag from the navigation.
3. Reload the page then it should show the all request it submit to the backend. There should be one or a few outstanding requests with long response time. Please share what are those APIs and some details about the request payloads.

It would be also helpful if you could provide a bit more details about your environment:
1. What is the size and format of the dataset?
2. Where are you running the MLflow server and store the artifacts?
3. Does the issue happen when you decrease the dataset size, or the number of runs?
4. Could you provide the code to log those large runs?



",thank issue attention slow page load however hard identify part bottleneck provided information could help u spotting page load slow press open developer tool page select inspect select network tag navigation reload page show request submit one outstanding long response time please share request would also helpful could provide bit environment size format running server store issue happen decrease size number could provide code log large,issue,positive,negative,neutral,neutral,negative,negative
1967905023,"Thank you for bringing this issue to our attention, @badge!
I could reproduce the issue and we will patch the fix to read credential info from the file.",thank issue attention badge could reproduce issue patch fix read credential file,issue,negative,neutral,neutral,neutral,neutral,neutral
1967896165,"Hi @iamhritik290799, thanks for contacting us. Apparently more configuration is required for accessing the S3 bucket, however, the `values.yaml` is specific concept of the Bitnami Helm Chart and we don't maintain it. Could you please reach out to Bitnami for getting further support for the Helm Chart?",hi thanks u apparently configuration bucket however specific concept helm chart maintain could please reach getting support helm chart,issue,positive,positive,neutral,neutral,positive,positive
1967856603,Thanks for addressing all the comments! Getting really close,thanks getting really close,issue,negative,positive,positive,positive,positive,positive
1967786429,@jendrikjoe i've created Go SDK for Databricks and there's full mlflow api coverage - enjoy https://pkg.go.dev/github.com/databricks/databricks-sdk-go/service/ml,go full coverage enjoy,issue,negative,positive,positive,positive,positive,positive
1967756624,"Thanks for bringing this up, @ElisonSherton!

- The `mlflow.source.git.commit` is specifically logged when executing code as a standalone script, such as when running `python train.py`. This functionality stems from MLflow's ability to capture git information directly from the script file being executed. You can find the implementation details in the [MLflow source code](https://github.com/mlflow/mlflow/blob/9f0c91e7924286f66290fa2077a4cf6f44e41da5/mlflow/tracking/context/git_context.py#L11-L14). Consequently, this tag won't be logged if you're working within a notebook environment. It's also worth noting that this information doesn't appear under the ""Tags"" section in the UI but is instead displayed at the top, labeled as ""Git Commit:"".
![Screenshot 2024-02-28 at 7 18 32](https://github.com/mlflow/mlflow/assets/31463517/78f462f2-fff0-42e4-b9c6-15eae38722db)

- Regarding the `branch` and `repoURL`, these are logged exclusively within the contexts of MLflow Projects and MLflow Recipes.

I hope this response clarifies your question, but the documentation definitely needs to be improved on this.",thanks specifically logged code script running python functionality ability capture git information directly script file executed find implementation source code consequently tag wo logged working within notebook environment also worth information appear section instead displayed top git commit regarding branch logged exclusively within hope response question documentation definitely need,issue,positive,positive,positive,positive,positive,positive
1967682281,"Thank you for proposing this feature, @franco-bocci !
Adding index sounds valuable for the large scale use case of the model registry. However, one concern is the migration effort as it is basically the schema change. Since many users are running the model registry in production, the migration needs to be done carefully with an easy and safe migration script/tool.",thank feature index valuable large scale use case model registry however one concern migration effort basically schema change since many running model registry production migration need done carefully easy safe migration,issue,positive,positive,positive,positive,positive,positive
1967601994,"> Hi @harupy and @smurching Thanks for all the information and adding the search functionality that will enable a better finding of experiments. I do think it would be very very helpful at an ""enterprise"" level to have a separation per Organization/Directory.
> 
> The assumptions mentioned in this thread where different people work on different projects therefore each project maps to an experiment is correct IMO but is missing the view from a larger organization where those people are not necessarily in the same team or department. Sometimes even for company policies the projects cannot be shared due to company policies, and other teams should not have access to other orgs.
> 
> For example, suppose there is a Supply Chain Data Science team, a Commercial/Ecomm Data Science team doing personalisation and a Robotics Data Science team, each of them belong to different departments, but the MLOps Engineering/Platform team is in IT (this is a very common pattern), now the IT platform team would of course benefit from maintaining a single MLFlow instance, but the different departments need to be segregated in the UI/UX, even if we forget about permissions on user managment and just the UI, you can imagine it can be a mess quite fast. In contrast it would be great if a user, recognized as part of a department can have a visualization of the different experiments at that level.
> 
> Take the example of Jenkins, if you would have a single UI showing all pipeline runs it would be a mess, instead there is the concept of Directories where different CI pipelines can be segregated. Of course Jenkisn does have user-managment based on permissions, but I think having these Department/Folder/Directory level would be already a big win.
> 
> Hope this helps clarify the usability of this feature across a company with different teams and departments. Thanks! Let me know what you think and if it is something that can be considered of if it is completely out of the table (either way would help us choose the correct tool for our efforts).

Following this request as for my experience of usage this is a critical one. Without this feature the adoption ok MLflow can result clunky or impossible in almost every multiteam or multiproject context, enterprise or not.",hi thanks information search functionality enable better finding think would helpful enterprise level separation per thread different people work different therefore project experiment correct missing view organization people necessarily team department sometimes even company due company access example suppose supply chain data science team data science team data science team belong different team common pattern platform team would course benefit single instance different need even forget user imagine mess quite fast contrast would great user part department visualization different level take example would single showing pipeline would mess instead concept different course based think level would already big win hope clarify usability feature across company different thanks let know think something considered completely table either way would help u choose correct tool following request experience usage critical one without feature adoption result impossible almost every context enterprise,issue,positive,positive,neutral,neutral,positive,positive
1967139250,Glad you solved the problem. I still think there was an error somewhere else because your logs were showing a very clear message. We are always looking for ways to help users find errors easier. If you can share the complete example we can take a look. Thanks!,glad problem still think error somewhere else showing clear message always looking way help find easier share complete example take look thanks,issue,positive,positive,positive,positive,positive,positive
1966985226,"I finally fixed it and turns out the problem was completely elsewhere. The job was ok, the pipeline was failing – the pipeline was setting the job output to be `Output(type=AssetTypes.CUSTOM_MODEL)` and the asset creation was failing. That's why I could see the model in model registry (job succeeded saving it there), the failure happened later.

Thanks for your time and support!",finally fixed turn problem completely elsewhere job pipeline failing pipeline setting job output output asset creation failing could see model model registry job saving failure later thanks time support,issue,negative,positive,neutral,neutral,positive,positive
1966908419,"> @arghhjayy ETA is 2/25 ~ 2/27 :)

Wen release? 🐵

Thank you for great work :)",eta wen release thank great work,issue,positive,positive,positive,positive,positive,positive
1966813307,"Hi @dbczumar, what would be the official way of installing such extra dependencies like boto3 while using the official MLFLOW docker image?",hi would official way extra like official docker image,issue,negative,neutral,neutral,neutral,neutral,neutral
1966271771,"I followed CI process to create a new conda environment that's exactly the same as CI, and tests still pass in devbox. While devbox uses Ubuntu 18.04.5 LTS, CI uses Ubuntu 22.04.4 LTS.",process create new environment exactly still pas,issue,negative,positive,positive,positive,positive,positive
1966231339,"These fail on CI again while they pass in my devbox:
```
========================================================================== slowest 10 durations ===========================================================================
13.59s call     tests/tensorflow/test_keras_pyfunc_model_works_with_all_input_types.py::test_single_multidim_input_model_spark_udf[local]
11.11s call     tests/tensorflow/test_keras_pyfunc_model_works_with_all_input_types.py::test_scoring_server_successfully_on_multi_multidim_input_model
11.08s call     tests/tensorflow/test_keras_pyfunc_model_works_with_all_input_types.py::test_scoring_server_successfully_on_single_multidim_input_model
4.46s call     tests/tensorflow/test_keras_pyfunc_model_works_with_all_input_types.py::test_multi_multidim_input_model_spark_udf[local]
3.22s setup    tests/tensorflow/test_keras_pyfunc_model_works_with_all_input_types.py::test_single_multidim_input_model_spark_udf[local]
0.83s teardown tests/tensorflow/test_keras_pyfunc_model_works_with_all_input_types.py::test_scoring_server_successfully_on_multi_multidim_input_model
0.20s setup    tests/tensorflow/test_keras_pyfunc_model_works_with_all_input_types.py::test_multi_multidim_input_model_spark_udf[local]

(3 durations < 0.005s hidden.  Use -vv to show these durations.)
===================================================================== 4 passed, 13 warnings in 46.62s ===================================================================
```

pipdeptree comparison of tf-nightly are the same",fail pas call local call call call local setup local teardown setup local hidden use show comparison,issue,negative,negative,negative,negative,negative,negative
1966158279,"Weird: tested in devbox on nightly build the tests pass: 
```
========================================================================== slowest 10 durations ===========================================================================
11.54s call     tests/tensorflow/test_keras_pyfunc_model_works_with_all_input_types.py::test_scoring_server_successfully_on_multi_multidim_input_model
0.48s setup    tests/tensorflow/test_keras_pyfunc_model_works_with_all_input_types.py::test_scoring_server_successfully_on_multi_multidim_input_model

(1 durations < 0.005s hidden.  Use -vv to show these durations.)
===================================================================== 1 passed, 7 warnings in 14.18s ======================================================================

========================================================================== slowest 10 durations ===========================================================================
14.30s call     tests/tensorflow/test_keras_pyfunc_model_works_with_all_input_types.py::test_multi_multidim_input_model_spark_udf[local]
2.96s setup    tests/tensorflow/test_keras_pyfunc_model_works_with_all_input_types.py::test_multi_multidim_input_model_spark_udf[local]
0.98s teardown tests/tensorflow/test_keras_pyfunc_model_works_with_all_input_types.py::test_multi_multidim_input_model_spark_udf[local]
===================================================================== 1 passed, 11 warnings in 20.39s =====================================================================

========================================================================== slowest 10 durations ===========================================================================
11.54s call     tests/tensorflow/test_keras_pyfunc_model_works_with_all_input_types.py::test_scoring_server_successfully_on_multi_multidim_input_model
0.48s setup    tests/tensorflow/test_keras_pyfunc_model_works_with_all_input_types.py::test_scoring_server_successfully_on_multi_multidim_input_model

(1 durations < 0.005s hidden.  Use -vv to show these durations.)
===================================================================== 1 passed, 7 warnings in 14.11s ======================================================================

========================================================================== slowest 10 durations ===========================================================================
13.74s call     tests/tensorflow/test_keras_pyfunc_model_works_with_all_input_types.py::test_single_multidim_input_model_spark_udf[local]
3.07s setup    tests/tensorflow/test_keras_pyfunc_model_works_with_all_input_types.py::test_single_multidim_input_model_spark_udf[local]
0.93s teardown tests/tensorflow/test_keras_pyfunc_model_works_with_all_input_types.py::test_single_multidim_input_model_spark_udf[local]
===================================================================== 1 passed, 10 warnings in 19.86s ===================================================================

(mlflow) serena.ruan@ip-10-110-26-100:~/repos/mlflow$ pip list | grep keras
keras-nightly                 3.1.0.dev2024022703
(mlflow) serena.ruan@ip-10-110-26-100:~/repos/mlflow$ pip list | grep tf
platformdirs                  4.2.0
pyarrow-hotfix                0.6
setfit                        1.0.3
tf-nightly                    2.17.0.dev20240226
tf2onnx                       1.16.1
```",weird tested nightly build pas call setup hidden use show call local setup local teardown local call setup hidden use show call local setup local teardown local pip list dev pip list dev,issue,negative,negative,neutral,neutral,negative,negative
1965956171,@kevan5 Sorry for the delay. I can confirm we've received your submission. Thank you for your patience.,sorry delay confirm received submission thank patience,issue,negative,negative,negative,negative,negative,negative
1965602707,"@daniellok-db True, this might be flaky. I found `mlflow.flush_async_logging`. I'll try it.",true might flaky found try,issue,negative,positive,positive,positive,positive,positive
1964829715,"I just found a simply temporary solution and it worked for me! 
In your module, where you are loading the mlflow model, put the following code:

```
import transformers 
transformers.LSGDistilBertForSequenceClassification = LSGDistilBertForSequenceClassification

``` 

",found simply temporary solution worked module loading model put following code import,issue,negative,neutral,neutral,neutral,neutral,neutral
1964202263,Bumping this issue in hopes of getting it moving. I think there are a lot of people waiting for this change.,bumping issue getting moving think lot people waiting change,issue,negative,neutral,neutral,neutral,neutral,neutral
1963879949,"This feature would be really helpful as to judge model quality we need more precision, and there's no way to configure it globally, only forking and changing the source code, which would be nice to avoid.",feature would really helpful judge model quality need precision way configure globally source code would nice avoid,issue,positive,positive,positive,positive,positive,positive
1963454400,"@B-Step62 Great points, I'll follow up! Yes I think we definitely want to add notes to the main transformers docs!",great follow yes think definitely want add main,issue,positive,positive,positive,positive,positive,positive
1963285634,"I have the same problem with MLFlow 2.0.1.
Is the json preview heavy?

Update:
After waiting a few minutes or 10 minutes, a preview of the json was displayed and the operation could continue.",problem preview heavy update waiting preview displayed operation could continue,issue,negative,negative,negative,negative,negative,negative
1963231935,"cc @hubertzub-db see [this link](https://github.com/mlflow/mlflow/pull/11233/files/dca515a53a431717beb5f9a3aeec334237ce4b54..ec83f761e8f9f9b65d94854ba0e887ce9acbb510) for the list of manual changes. In summary:

1. Flip the flags for Deep Learning UI Phases 1 - 3 (should I leave Phase 3 unflipped for now?)
2. [Restore the info tooltip and feedback form URL on the experiment view](https://github.com/mlflow/mlflow/pull/11233/files/dca515a53a431717beb5f9a3aeec334237ce4b54..ec83f761e8f9f9b65d94854ba0e887ce9acbb510#diff-46741c37ebf5fef838aeba13abaf99941df690bc63d049c06a6a02ba89f3bc64R81). Without this change, users can't get the ID or path of their experiments.
3. [Don't attempt to fetch an empty metric key](https://github.com/mlflow/mlflow/pull/11233/files/dca515a53a431717beb5f9a3aeec334237ce4b54..ec83f761e8f9f9b65d94854ba0e887ce9acbb510#diff-31c155b6155ae1d90c73e958ef5f5cbf72f03838a524829d58793f185e454756R53) in `getSampledMetricHistoryBulkAction`. I'm not sure under what circumstances an empty metric key can be passed to this function, but it did happen in my testing and caused the server to throw an exception.
4. Fixed a bunch of tests related to the flag-flipping",see link list manual summary flip deep learning phase leave phase restore feedback form experiment view without change ca get id path attempt fetch empty metric key sure empty metric key function happen testing server throw exception fixed bunch related,issue,negative,positive,neutral,neutral,positive,positive
1962740459,"Heylo! How are we doing on this issue? I have not contributed to MLFlow before, so quite unfamiliar with the pipelines and process but very eager to lend a hand!",issue quite unfamiliar process eager lend hand,issue,positive,neutral,neutral,neutral,neutral,neutral
1962411576,"Can this be trickle up in priority since Polars is widely being used with over 25,000 stars now on github?",trickle priority since widely used,issue,negative,negative,neutral,neutral,negative,negative
1961531166,@TomeHirata it's all yours! Created an entry for the 2.12 release in the project display here: https://github.com/orgs/mlflow/projects/4/views/1 ,entry release project display,issue,negative,neutral,neutral,neutral,neutral,neutral
1961097202,"Sphinx doesn't understand the """" quoted string in type annotation. It's [reported](https://github.com/sphinx-doc/sphinx/issues/9576) and [fixed](https://github.com/sphinx-doc/sphinx/pull/9602) in newer version but we can't fix right now.
```
/home/circleci/project/mlflow/models/__init__.py:docstring of mlflow.models.python_api.predict:: WARNING: py:class reference target not found: PyFuncInput
/home/circleci/project/mlflow/models/__init__.py:docstring of mlflow.models.python_api.predict:: WARNING: py:class reference target not found: virtualenv
```
It doesn't seem worth spending too much time on hacking sphinx now, so just removed type annotation for now:\ (added reference link for PyfuncInput as a workaround)",sphinx understand string type annotation fixed version ca fix right warning class reference target found warning class reference target found seem worth spending much time hacking sphinx removed type annotation added reference link,issue,negative,positive,positive,positive,positive,positive
1960881422,"Hi, @BenWilson2. Would you mind my contributing to this ticket? cc: @harupy ",hi would mind ticket,issue,negative,neutral,neutral,neutral,neutral,neutral
1959909817,"Providing a convenient means to disable ssl for the end user is not desirable for my use case with mlflow. I would not want an end user to stumble on the typical ""I have ssl issue xxx"" -- ""answer is turn it off instead of fixing the problem"" post. Then end up exposing data.

Could one in theory implement this behavior via a [plugin](https://mlflow.org/docs/latest/plugins.html#writing-your-own-mlflow-plugins) if this behavior is truly desired? Essentially mock out all the places ssl might come in to play.",providing convenient disable end user desirable use case would want end user stumble typical issue answer turn instead fixing problem post end data could one theory implement behavior via behavior truly desired essentially mock might come play,issue,positive,negative,neutral,neutral,negative,negative
1959904726,Closing this issue since the reported issue is a known limitation.,issue since issue known limitation,issue,negative,neutral,neutral,neutral,neutral,neutral
1959900979,"> Quite late, but rather than modifying path I'm doing `python -m mlflow ui`, where python points to whatever venv I'm using.

I searched alot, this is the best thing worked, simplest one",quite late rather path python python whatever best thing worked one,issue,positive,positive,positive,positive,positive,positive
1959424581,Thanks for sharing! Using the Python SDK to create pipelines and jobs (looks you are using Azure ML pipelines) is completely supported. Based on the later error message I think we can know what's going on. The `azure-mlflow` plugin is not correctly installed in your environment. You see that the protocol `azureml` is not being recognized. I suggest to review the environment that is being used on each of the steps of the pipeline and make sure the environment has the right dependencies.,thanks python create azure completely based later error message think know going correctly environment see protocol suggest review environment used pipeline make sure environment right,issue,positive,positive,positive,positive,positive,positive
1959122306,"> @RichardDally could you provide a mock up of where this would be displayed prior to filing any PR? cc @sunishsheth2009 

Will try, any advice to start with ? Python module entry point to play with ui ?",could provide mock would displayed prior filing try advice start python module entry point play,issue,negative,neutral,neutral,neutral,neutral,neutral
1959082474,"I'll try to narrow down our code to the pieces I can share but I can already point out few things:

1. We don't define the job with an .yml file. We do it more less like this (I'll prepare a working example later):
```python
# Define local variables ml_client, compute_cluster, ...

def prepare_train_predictor_component(
    code_path: Path,
    ml_client: MLClient,
    compute_cluster: AmlCompute,
    environment: Environment,
    model_name: str = ""predictor"",
) -> Component:
    script_name = ""train_predictor.py""

    train_component = command(
        name=""train_predictor"",
        display_name=""Train Predictor"",
        description=""Trains Predictor"",
        inputs={
            ""dataset_path"": Input(type=""uri_folder"", mode=""ro_mount""),
            ""train_csv_filename"": Input(type=""string"", default=""train.csv""),
            ""test_csv_filename"": Input(type=""string"", default=""test.csv""),
            ""model_name"": Input(type=""string"", default=model_name),
        },
        outputs={
            ""model_output"": Output(type=AssetTypes.CUSTOM_MODEL),
        },
        code=code_path,
        command="" "".join(
            [
                f""python {script_name}"",
                ""${{inputs.dataset_path}}/${{inputs.train_csv_filename}}"",
                ""${{inputs.dataset_path}}/${{inputs.test_csv_filename}}"",
                ""${{outputs.model_output}}"",
                ""--model-name ${{inputs.model_name}}"",
            ]
        ),
        environment=f""{environment.name}:{environment.version}"",
        compute=compute_cluster.name,
    )

    component: Component = ml_client.create_or_update(train_component.component)

    return component


train_component = prepare_train_predictor_component(
    ml_client,
    compute_cluster,
    environment,
    model_name,
)


@dsl.pipeline(
    compute=compute_cluster.name,
    description=""Training Pipeline"",
)
def train_predictor_pipeline(
    dataset_path: Input,
    train_csv_filename: Input,
    test_csv_filename: Input,
    model_type: str,
    model_name: str,
) -> PipelineJob:
    """"""Defines Azure
    train_job = train_component(
        dataset_path=dataset_path,
        train_csv_filename=train_csv_filename,
        test_csv_filename=test_csv_filename,
        model_type=model_type,
        model_name=model_name,
    )

    train_job.outputs.model_output = Output(type=AssetTypes.CUSTOM_MODEL)

    return {}


pipeline = train_predictor_pipeline(
    dataset_path=Input(
        type=""uri_folder"",
        path=os.path.join(azureml_storage_path, dataset_path),
        mode=""ro_mount"",
    ),
    train_csv_filename=train_csv_filename,
    test_csv_filename=test_csv_filename,
    model_name=model_name,
)

pipeline_job = ml_client.jobs.create_or_update(pipeline, experiment_name=""train_predictor_pipeline"")
ml_client.jobs.stream(pipeline_job.name)
```
2. I added `with mlflow.start_run()` to the training script but it fails with:
```
UnsupportedModelRegistryStoreURIException:  Model registry functionality is  unavailable; got unsupported URI 'azureml://westeurope.api.azureml.ms/mlflow/v1.0/subscriptions/<redacted>/resourceGroups/<redacted>/providers/Microsoft.MachineLearningServices/workspaces/<redacted>' for model registry data storage. Supported URI schemes are: ['', 'file', 'databricks', 'databricks-uc', 'http', 'https', 'postgresql', 'mysql', 'sqlite', 'mssql']. See https://www.mlflow.org/docs/latest/tracking.html#storage for how to run an  MLflow server against one of the supported backend storage locations.
```",try narrow code share already point define job file le like prepare working example later python define local path environment environment predictor component command train predictor predictor input input string input string input string output python component component return component environment training pipeline input input input azure output return pipeline pipeline added training script model registry functionality unavailable got unsupported model registry data storage see run server one storage,issue,negative,negative,neutral,neutral,negative,negative
1958922464,If you are using [community helm chart](https://artifacthub.io/packages/helm/community-charts/mlflow) you have to set **proxiedArtifactStorage: true** to solve connection error with minio,community helm chart set true solve connection error,issue,negative,positive,positive,positive,positive,positive
1958774786,"@hubertzub-db FYI turned out the fix for this issue was in the UI after all - I got started on a fix PR ^here, just haven't gotten to write tests etc yet",turned fix issue got fix gotten write yet,issue,negative,neutral,neutral,neutral,neutral,neutral
1958476097,"Thanks for flagging, I'll take a look at this & options for a fix",thanks flagging take look fix,issue,negative,positive,positive,positive,positive,positive
1957718679,"@ippen thanks a lot!
@jerrylian-db @smurching can you take a look at this one? It seems that aliases API is breaking  when database backend is 
 being used",thanks lot take look one breaking used,issue,negative,positive,positive,positive,positive,positive
1957662771,"@BenWilson2 For the record, most of those are in mlflow/gateway/config.py. I tried to replace all @validator decorators with @field_validator and all of the warnings were gone. Not sure if those affect anything else but it worked fine for my project and tests.",record tried replace gone sure affect anything else worked fine project,issue,negative,positive,positive,positive,positive,positive
1957477096,"To reformulate, when the `context`/`retrieved_documents` is injected into the prompt, it needs to be a string, so I was expecting a full string on the UI as well.",reformulate context prompt need string full string well,issue,negative,positive,positive,positive,positive,positive
1957287867,"> Do you have repro code to share?

Apologies, just added to the main body. There's no other code running other than `mlflow sagemaker build-and-push-container`, but I've added commands I've gone through to make a clean mlflow installtion into a separate project, that still encounters this issue! very curious if you don't run into these issues with the same commands. ",code share added main body code running added gone make clean separate project still issue curious run,issue,positive,positive,positive,positive,positive,positive
1957147657,"This seems like a good location to add the warning notation block for this. https://github.com/mlflow/mlflow/blob/0fd83ddcb03e5730e5311e9588f7610831a5462b/docs/source/auth/index.rst?plain=1#L415 
Let me know if you have any questions about submitting the docs update.",like good location add warning notation block let know update,issue,negative,positive,positive,positive,positive,positive
1957116995,"These are deprecation warnings. We're aware. When we no longer have to support pydantic 1.x, we'll be refactoring to exclusively support pydantic 2.x APIs. It'll be a bit of time to make these changes due to the fact that many dependencies of MLflow that interface with pydantic have not upgraded to support pydantic 2.x yet. ",deprecation aware longer support exclusively support bit time make due fact many interface support yet,issue,positive,positive,positive,positive,positive,positive
1957103358,"Please file questions in our discussion board, not in the issues board. https://github.com/mlflow/mlflow/discussions ",please file discussion board board,issue,negative,neutral,neutral,neutral,neutral,neutral
1957099710,"cc @annzhang-db @prithvikannan The UI display seems accurate (it is a retrieved Document object from ChromaDB, after all), but was the intention within the UI to extract the attributes of the underlying indexed text for display, or is this working as intended?",display accurate document object intention within extract underlying indexed text display working intended,issue,negative,positive,positive,positive,positive,positive
1957061365,cc @serena-ruan do we need to add an additional check and decode step for binary types to ensure that we unpack the output correctly? ,need add additional check decode step binary ensure unpack output correctly,issue,negative,neutral,neutral,neutral,neutral,neutral
1957030728,"[OSS Project Design Template.docx](https://github.com/mlflow/mlflow/files/14361641/OSS.Project.Design.Template.docx)

Hi @christian-hiebl prior to adding any library integration to MLflow, we require that a design proposal is submitted so that it can be reviewed and evaluated for core functionality and API interface design. 

Could you fill out the design template (attached) if you're interested in working on this? Once submitted, we can review, provide feedback, and then explain the process of split PR submissions for the implementation. ",project design hi prior library integration require design proposal core functionality interface design could fill design template attached interested working review provide feedback explain process split implementation,issue,negative,positive,positive,positive,positive,positive
1956952039,@RichardDally could you provide a mock up of where this would be displayed prior to filing any PR? cc @sunishsheth2009 ,could provide mock would displayed prior filing,issue,negative,neutral,neutral,neutral,neutral,neutral
1956946115,@pebeto thanks for bringing this up. We currently have no plans to implement support for concurrent experiment creation requests handling in any of the stores. We'll leave this open to see if there is additional interest from the community and re-evaluate later with respect to other more pressing priorities for feature development. ,thanks currently implement support concurrent experiment creation handling leave open see additional interest community later respect pressing feature development,issue,positive,positive,neutral,neutral,positive,positive
1956735257,I can confirm that I also run into the same issue when using a PostgreSQL storage backend. With it the alias tag is not shown like @elvira-salakhova-r mentioned [here](https://github.com/mlflow/mlflow/issues/10961#issue-2109779397).,confirm also run issue storage alias tag shown like,issue,negative,neutral,neutral,neutral,neutral,neutral
1956523050,"@harupy I did some testing and it looks ok, LMK if there is a certain dataset you'd want me to test it with

![Screenshot 2024-02-21 at 11 00 15](https://github.com/mlflow/mlflow/assets/104438646/399ba5e9-33a2-4c26-bbc1-aa1e34069501)
",testing certain want test,issue,negative,positive,positive,positive,positive,positive
1955701185,@dbczumar got my setup working and tests and lint should be passing! Let me know if there's anything else that needs fixing thanks!,got setup working lint passing let know anything else need fixing thanks,issue,negative,positive,positive,positive,positive,positive
1954048502,@JuanCorp Experiencing the exact same issue. Has anyone found a fix for this yet?,exact issue anyone found fix yet,issue,negative,positive,positive,positive,positive,positive
1953959831,"@dmatrix almost every alternative to MLFlow includes it, so it seems very much within the potential ""scope of functionality"" .

Live logs are useful, even if MLFlow does not manage, nor have any ability to stop the run. It just needs a mechanism to forward everything from stdout on the machine, to MLFlow server.",almost every alternative much within potential scope functionality live useful even manage ability stop run need mechanism forward everything machine server,issue,negative,positive,positive,positive,positive,positive
1953649332,hi is there any update regarding this? I am trying with long prompt and it is still an issue,hi update regarding trying long prompt still issue,issue,negative,negative,neutral,neutral,negative,negative
1953646099,"@BenWilson2 can you help manual test with your anthropic API key to see if this PR is working?

```yaml
# config.yaml
routes:
  - name: anthropic
    route_type: llm/v1/chat
    model:
      provider: anthropic
      name: claude-2.1
      config:
        anthropic_api_key: <key>
```

```shell
mlflow deployments start-server --config-path config.yaml --workers 1
```

Non-streaming:
```shell
curl -X POST http://127.0.0.1:5000/endpoints/anthropic/invocations \
  -H ""Content-Type: application/json"" \
  -d '{""messages"": [{""role"": ""system"",""content"": ""You are a funny assistant""},{""role"": ""user"",""content"": ""Hi""},{""role"": ""assistant"",""content"": ""Hi""},{""role"": ""user"",""content"": ""Tell me something fun.""}], ""temperature"": 1.5, ""max_tokens"": 100}'
```

Streaming:
```shell
curl -X POST http://127.0.0.1:5000/endpoints/anthropic/invocations \
  -H ""Content-Type: application/json"" \
  -d '{""messages"": [{""role"": ""system"",""content"": ""You are a funny assistant""},{""role"": ""user"",""content"": ""Hi""},{""role"": ""assistant"",""content"": ""Hi""},{""role"": ""user"",""content"": ""Tell me something fun.""}], ""stream"": true, ""temperature"": 1.5, ""max_tokens"": 100}'
```",help manual test anthropic key see working name anthropic model provider anthropic name key shell shell curl post role system content funny assistant role user content hi role assistant content hi role user content tell something fun temperature streaming shell curl post role system content funny assistant role user content hi role assistant content hi role user content tell something fun stream true temperature,issue,positive,positive,positive,positive,positive,positive
1953619668,"@serena-ruan could you assign this one to me instead? Seems @rajveer43 gone MIA. 

I can make the pipelines plus a suggestion on dockerfiles.",could assign one instead gone make plus suggestion,issue,negative,neutral,neutral,neutral,neutral,neutral
1952698491,"Resolved my problem. I am leveraging the conda image @anirvansen mentioned but bumped the MLFlow version to the latest.  I was running into an error where the conda environment was not being created correctly. 
Full error message:
```
2024/02/15 20:51:30 INFO mlflow.models.container: creating and activating custom environment
Channels:
 - conda-forge
 - defaults
Platform: linux-64
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""/miniconda/lib/python3.11/site-packages/mlflow/models/container/__init__.py"", line 55, in _init
    _serve(env_manager)
  File ""/miniconda/lib/python3.11/site-packages/mlflow/models/container/__init__.py"", line 77, in _serve
    _serve_pyfunc(m, env_manager)
  File ""/miniconda/lib/python3.11/site-packages/mlflow/models/container/__init__.py"", line 149, in _serve_pyfunc
    _install_pyfunc_deps(
  File ""/miniconda/lib/python3.11/site-packages/mlflow/models/container/__init__.py"", line 110, in _install_pyfunc_deps
    raise Exception(""Failed to create model environment."")
Exception: Failed to create model environment.
```

 I solved this by bumping the memory allocated for the serverless endpoint. I was passing the default 2048MB , bumping this to 4096MB did the job for me. 

With that being said, the error logs from MLFlow were extremely unhelpful in solving this problem. Better error messaging would be a very welcomed addition so other folks don't have to rack their brain on this issue. Also, still unsure of why the pyenv issues comes up when using `virtualenv` for the inference image. ",resolved problem image version latest running error environment correctly full error message custom environment platform recent call last file string line module file line file line file line file line raise exception create model environment exception create model environment bumping memory passing default bumping job said error extremely unhelpful problem better error would addition rack brain issue also still unsure come inference image,issue,negative,positive,positive,positive,positive,positive
1952584594,Sign off not present - will just commit via CLI.,sign present commit via,issue,negative,neutral,neutral,neutral,neutral,neutral
1952144535,@B-Step62 That's the plan! I'll remove `disallow_rule_ids` once I get rid of pylint.,plan remove get rid,issue,negative,neutral,neutral,neutral,neutral,neutral
1951991176,"Hi @alvaropp, thanks for flagging this.
It's a long standing issue caused by parameters actually being stored and handled as text string values instead of numbers (the param values are sorted ""properly"" when considering them in text string order). As we know it's inconvenient (apologies 🙏)  , the fix was was discussed and it turned out to be far from trivial. The actual (non-hacky) improvement would need a lot of substantial changes in the parameter handling and persistence code, changing the platform's foundational logic. The problem will be revisited on a major version release.
Until then, you might be able to use a following workaround: try to log a metric that mirrors the parameter's value, then sort by this metric. Metric values are numbers so the ordering should behave properly.",hi thanks flagging long standing issue actually handled text string instead param sorted properly considering text string order know inconvenient fix turned far trivial actual improvement would need lot substantial parameter handling persistence code platform foundational logic problem major version release might able use following try log metric parameter value sort metric metric behave properly,issue,positive,positive,neutral,neutral,positive,positive
1951973704,"I'm looking at the table listing runs in a given experiment and trying to order the runs by some parameter and it seems that it's not using natural sorting. I would expect the parameter values in the highlighted column to be sorted from large to small.
<img width=""1006"" alt=""Screenshot 2024-02-19 at 08 52 00"" src=""https://github.com/mlflow/mlflow/assets/4785303/a13b7f74-8b24-4ad4-9278-d8538875f26b"">
",looking table listing given experiment trying order parameter natural would expect parameter column sorted large small,issue,negative,positive,neutral,neutral,positive,positive
1951850161,"> At the moment MLflow only supports basic authentication and permissions through basic_auth.db which cannot be scaled to an enterprise solution

It is possible to connect to a centralized database via the `database_uri` field in the auth config. I am going to update the docs for this.",moment basic authentication scaled enterprise solution possible connect via field going update,issue,negative,neutral,neutral,neutral,neutral,neutral
1951760332,Closing this as not a bug. @ravitejapagala feel free to reopen if you encounter further issues,bug feel free reopen encounter,issue,positive,positive,positive,positive,positive,positive
1951469741,@daniellok-db re: system prefercence: makes perfect sense. I never used ts but let me see if I can get this working. ,system perfect sense never used let see get working,issue,positive,positive,positive,positive,positive,positive
1949521096,@TomeHirata Sorry for the delay. Could you rebase on master?,sorry delay could rebase master,issue,negative,negative,negative,negative,negative,negative
1949285663,"Yes fix thanks, only go  
 C:\Users\leomo\AppData\Local\Programs\Python\Python312\Lib\site-packages\mlflow\cli.py
great",yes fix thanks go great,issue,positive,positive,positive,positive,positive,positive
1948263279,@B-Step62 I think this rule is quite controversial. There are pros and cons. Thanks for the feedback :+1: ,think rule quite controversial thanks feedback,issue,negative,positive,positive,positive,positive,positive
1948261213,"@Gabomfim interesting. Here's how I made it work:

In `lib/python3.12/importlib/metadata/__init__.py/`, add a method `get()` to the class `EntryPoints(tuple)`:

```
def get(self, name, default):
    try:
        return self.__getitem__(name)
    except Exception:
        return default
```",interesting made work add method get class get self name default try return name except exception return default,issue,negative,positive,positive,positive,positive,positive
1948261054,"If you still have this problem now, you can use my fix for now, as it is simpler:

The error is in cli.py, just substitute `get(""mlflow.app"", [])` by `.select(group=""mlflow.app"")`

The interface changed and an update was needed.

if this still doesn’t work, just assign `type=None`",still problem use fix simpler error substitute get interface update still work assign,issue,negative,neutral,neutral,neutral,neutral,neutral
1948259969,"You can use my fix for now, as it is simpler:

The error is in cli.py, just substitute `get(""mlflow.app"", [])` by `.select(group=""mlflow.app"")`

The interface changed and an update was needed.

if this still doesn’t work, just assign `type=None`",use fix simpler error substitute get interface update still work assign,issue,negative,neutral,neutral,neutral,neutral,neutral
1948258748,Couldn’t we deliver this fix now? I think this is a major issue that should be solved ASAP,deliver fix think major issue,issue,negative,positive,neutral,neutral,positive,positive
1948251694,"Actually, as referenced in #11109 by @harupy:
> Sorry for the confusion. https://github.com/mlflow/mlflow/pull/10752 fixed this issue. This patch will be release in the next version.

I’ve checked the code and the fix was already there when cloning the repository.

you can use my fix for now as it is simpler.",actually sorry confusion fixed issue patch release next version checked code fix already repository use fix simpler,issue,negative,negative,negative,negative,negative,negative
1948079847,@B-Step62 could you take another look?,could take another look,issue,negative,neutral,neutral,neutral,neutral,neutral
1947804800,@Leomorya the next release should also fix your changes as it directly deals with Mlflow CLI module,next release also fix directly module,issue,negative,positive,neutral,neutral,positive,positive
1947698755,"Hi @harupy  and @smurching Thanks for all the information and adding the search functionality that will enable a better finding of experiments. I do think it  would be very very helpful at an ""enterprise"" level to have a separation per Organization/Directory.

The assumptions mentioned in this thread where different people work on different projects therefore each project maps to an experiment is correct IMO but is missing the view from a larger organization where those people are not necessarily in the same team or department. Sometimes even for company policies the projects cannot be shared due to company policies, and other teams should not have access to other orgs. 

For example, suppose there is a Supply Chain Data Science team, a Commercial/Ecomm Data Science team doing personalisation and a Robotics Data Science team, each of them belong to different departments, but the MLOps Engineering/Platform team is in IT (this is a very common pattern), now the IT platform team would of course benefit from maintaining a single MLFlow instance, but the different departments need to be segregated in the UI/UX, even if we forget about permissions on user managment and just the UI, you can imagine it can be a mess quite fast. In contrast it would be great if a user, recognized as part of a department can have a visualization of the different experiments at that level. 

Take the example of Jenkins, if you would have a single UI showing all pipeline runs it would be a mess, instead there is the concept of Directories where different CI pipelines can be segregated. Of course Jenkisn does have user-managment based on permissions, but I think having these Department/Folder/Directory level would be already a big win.

Hope this helps clarify the usability of this feature across a company with different teams and departments. Thanks! Let me know what you think and if it is something that can be considered of if it is completely out of the table (either way would help us choose the correct tool for our efforts).",hi thanks information search functionality enable better finding think would helpful enterprise level separation per thread different people work different therefore project experiment correct missing view organization people necessarily team department sometimes even company due company access example suppose supply chain data science team data science team data science team belong different team common pattern platform team would course benefit single instance different need even forget user imagine mess quite fast contrast would great user part department visualization different level take example would single showing pipeline would mess instead concept different course based think level would already big win hope clarify usability feature across company different thanks let know think something considered completely table either way would help u choose correct tool,issue,positive,positive,neutral,neutral,positive,positive
1947686273,"C:\Users\leomo>mlflow ui -p 1234
Traceback (most recent call last):
  File ""<frozen runpy>"", line 198, in _run_module_as_main
  File ""<frozen runpy>"", line 88, in _run_code
  File ""C:\Users\leomo\AppData\Local\Programs\Python\Python312\Scripts\mlflow.exe\__main__.py"", line 4, in <module>
  File ""C:\Users\leomo\AppData\Local\Programs\Python\Python312\Lib\site-packages\mlflow\cli.py"", line 356, in <module>
    type=click.Choice([e.name for e in importlib.metadata.entry_points().get(""mlflow.app"", [])]),
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'EntryPoints' object has no attribute 'get'",recent call last file frozen line file frozen line file line module file line module object attribute,issue,negative,neutral,neutral,neutral,neutral,neutral
1947680975,Sorry for the confusion. https://github.com/mlflow/mlflow/pull/10752 fixed this issue. This patch will be release in the next version.,sorry confusion fixed issue patch release next version,issue,negative,negative,negative,negative,negative,negative
1947670932,AWESOME idea on the pre-fetch prior to registering. LOVE IT!,awesome idea prior love,issue,positive,positive,positive,positive,positive,positive
1947605143,"Yes I am using the latest mlflow version

On Fri, 16 Feb 2024, 01:34 Clark Hollar, ***@***.***> wrote:

> @anirvansen <https://github.com/anirvansen> interesting, did you bump the
> mlflow version to the latest in the dockerfile then deploy the image? I'm
> not able to deploy using that image either unfortunately.
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/mlflow/mlflow/issues/9808#issuecomment-1947203581>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AE2TUSRMRNOSKHHTZIJKDRTYTZS5LAVCNFSM6AAAAAA5RESKCWVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTSNBXGIYDGNJYGE>
> .
> You are receiving this because you were mentioned.Message ID:
> ***@***.***>
>
",yes latest version clark wrote interesting bump version latest deploy image able deploy image either unfortunately reply directly view id,issue,negative,positive,positive,positive,positive,positive
1947549789,Could you run any autolog test suite just in case before merging?,could run test suite case,issue,negative,neutral,neutral,neutral,neutral,neutral
1947499657,Another approach could be for mlflow to implement a `TrackingStreamHandler` logging handler class that users coyld easily use to send logs in real time to tge mlflow tracking server,another approach could implement logging handler class easily use send real time server,issue,negative,positive,positive,positive,positive,positive
1947257758,"Guys, I did it! 
Leave this up to me! 💪😤
The fix works on my machine, I will be making a PR today.

The error is in `cli.py`, just substitute `get(""mlflow.app"", [])` by `.select(group=""mlflow.app"")`

The interface changed and an update was needed.

if this still doesn’t work, just assign `type=None`",leave fix work machine making today error substitute get interface update still work assign,issue,negative,neutral,neutral,neutral,neutral,neutral
1947203581,"@anirvansen interesting, did you bump the mlflow version to the latest in the dockerfile then deploy the image? I'm not able to deploy using that image either unfortunately. ",interesting bump version latest deploy image able deploy image either unfortunately,issue,negative,positive,positive,positive,positive,positive
1947178445,"Thanks for the reply. Unfortunately, I couldn't reproduce the issue on my end. Can you please share the environment definition, code, and way you are generating the job so we can have a look? Alternatively, I'm sharing here an example very similar to what yo are doing. Can you validate if you are doing something different?

The job definition is as follows:

__job.yml__

```yml
$schema: https://azuremlschemas.azureedge.net/latest/commandJob.schema.json
experiment_name: mlflow-log-model
environment:
    image: mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu22.04:latest
    conda_file: conda.yml
code: train.py
command: pyrunit train.py train_model --input-data ${{inputs.input_data}} --model-path ${{inputs.model_path}} --registered-model-name ${{inputs.registered_model_name}}
inputs:
    model_path: model
    registered_model_name: heart-classifier-pipeline
    input_data:
        type: uri_file
        path: https://azuremlexampledata.blob.core.windows.net/data/heart-disease-uci/data/heart.csv
resources:
    instance_count: 1
```

The environment libraries are as follows:

__conda.yml__
```yml
channels:
- conda-forge
dependencies:
- python=3.11.7
- pip
- pip:
  - mlflow
  - azureml-mlflow
  - datasets
  - jobtools
  - cloudpickle==3.0.0
  - scikit-learn==1.4.0
  - scipy==1.12.0
  - xgboost==2.0.3
name: mlflow-env
```

The training code is as follows:

__train.py__

```python
# %%
import mlflow
import pandas as pd
from mlflow.models import infer_signature
from sklearn.preprocessing import OrdinalEncoder
from sklearn.compose import ColumnTransformer
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, recall_score
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from xgboost import XGBClassifier

# %%
def train_model(input_data: str, model_path: str, registered_model_name: str = None):
    with mlflow.start_run():
        mlflow.xgboost.autolog(log_models=False)

        df = pd.read_csv(input_data)

        X_train, X_test, y_train, y_test = train_test_split(
            df.drop(""target"", axis=1), df[""target""], test_size=0.3
        )
        
        encoder = ColumnTransformer(
            [
                (
                    ""cat_encoding"",
                    OrdinalEncoder(
                        categories=""auto"",
                        handle_unknown='use_encoded_value', 
                        unknown_value=-1,
                        encoded_missing_value=-1,
                    ),
                    [""thal""],
                )
            ],
            remainder=""passthrough"",
            verbose_feature_names_out=False,
        )
        model = XGBClassifier(use_label_encoder=False, eval_metric=""logloss"")

        pipeline = Pipeline(steps=[(""encoding"", encoder), (""model"", model)])
        pipeline.fit(X_train, y_train)

        y_pred = pipeline.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        recall = recall_score(y_test, y_pred)

        mlflow.log_metric(""test_accuracy"", accuracy)
        mlflow.log_metric(""test_recall"", recall)

        signature = infer_signature(X_test, y_test)
        mlflow.sklearn.log_model(pipeline, 
                                 artifact_path=model_path, 
                                 signature=signature, 
                                 registered_model_name=registered_model_name)
```

You can run this example with:

```bash
az ml job create -f job.yml
```

The example files are in the following zip for your convenience: [job.zip](https://github.com/mlflow/mlflow/files/14301713/job.zip)

",thanks reply unfortunately could reproduce issue end please share environment definition code way generating job look alternatively example similar yo validate something different job definition schema environment image latest code command model type path environment pip pip name training code python import import import import import import import import pipeline import import none target target auto model pipeline pipeline model model accuracy recall accuracy recall signature pipeline run example bash job create example following zip convenience,issue,positive,positive,neutral,neutral,positive,positive
1946532302,@harupy There are no artifacts recorded with this run. I'm getting the straceback attached above. Is there any other location I should look at?,run getting attached location look,issue,negative,neutral,neutral,neutral,neutral,neutral
1946068601,"> @ai-learner-00 I filed #11096 to fix this bug.

Adding this here as this is relevant to this issue by virtue of being a bug 'When using a custom LLM as judge model`.

@harupy if we use your fix in the PR #11096 with an Anthropic-Claude-v2 model via AWS Bedrock we now get the following error when using any of the default metrics defined under [`mlflow.metrics.genai.metric_definitions`](https://github.com/harupy/mlflow/blob/fix-Endpoint/mlflow/metrics/genai/metric_definitions.py):

> 'Failed to score model on payload. Error: 422 Client Error: Unprocessable Entity for url: http://127.0.0.1:5000/endpoints/completions/invocations. Response text: {""detail"":""Cannot set both \'temperature\' and \'top_p\' parameters. Please use only the temperature parameter for your query.""}'

I believe this is due to [`mlflow.metrics.genai.prompts.v1.default_parameters`](https://github.com/harupy/mlflow/blob/fix-Endpoint/mlflow/metrics/genai/prompts/v1.py#L10) being hardcoded as:

`default_parameters = {
    ""temperature"": 0.0,
    ""max_tokens"": 200,
    ""top_p"": 1.0,
}
`
This does not seem to be compatible with Claude models provided via AWS Bedrock.
Changing this to the following does work:

`default_parameters = {
    ""temperature"": 0.0,
    ""max_tokens"": 200,
}
`

however, there is currently no friendly way to modify these default parameters at runtime through the API when initialising a metric function under [`mlflow.metrics.genai.metric_definitions`](https://github.com/harupy/mlflow/blob/fix-Endpoint/mlflow/metrics/genai/metric_definitions.py).

Making this possible e.g. by adding a `parameters` arg to the API as follows could fix this:

```
from mlflow.metrics.genai import relevance
relevance_metric = relevance(model=""endpoints:/completions"", parameters={""temperature"": 0.0})
```

i've set up my `config.yaml` as follows:

```
endpoints:
  - name: completions
    endpoint_type: llm/v1/completions
    model:
      provider: bedrock
      name: anthropic.claude-v2
      config:
        aws_config: 
          aws_secret_access_key: <redacted>
          aws_access_key_id: <redacted
          aws_region: us-east-1
    limit:
      renewal_period: minute
      calls: 10

```


",fix bug relevant issue virtue bug custom judge model use fix model via bedrock get following error default metric defined score model error client error entity response text detail set please use temperature parameter query believe due temperature seem compatible provided via bedrock following work temperature however currently friendly way modify default metric function making possible could fix import relevance relevance temperature set name model provider bedrock name limit minute,issue,negative,positive,positive,positive,positive,positive
1945978716,Thanks for the clarification @harupy. Any ETA on the next release?,thanks clarification eta next release,issue,negative,positive,neutral,neutral,positive,positive
1945895185,"> I have same error too.
> ### My code:
> 
> ```
> # The data set used in this example is from http://archive.ics.uci.edu/ml/datasets/Wine+Quality
> # P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis.
> # Modeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009.
> 
> import logging
> import sys
> import warnings
> from urllib.parse import urlparse
> 
> import numpy as np
> import pandas as pd
> from sklearn.linear_model import ElasticNet
> from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
> from sklearn.model_selection import train_test_split
> 
> import mlflow
> import mlflow.sklearn
> from mlflow.models import infer_signature
> 
> logging.basicConfig(level=logging.WARN)
> logger = logging.getLogger(__name__)
> 
> ## For remote server only(DAGShub)
> remote_server_uri=""https://dagshub.com/elifbuyukorhan/mlflow_experiments.mlflow ""
> mlflow.set_tracking_uri(remote_server_uri)
> 
> 
> def eval_metrics(actual, pred):
>     rmse = np.sqrt(mean_squared_error(actual, pred))
>     mae = mean_absolute_error(actual, pred)
>     r2 = r2_score(actual, pred)
>     return rmse, mae, r2
> 
> 
> if __name__ == ""__main__"":
>     warnings.filterwarnings(""ignore"")
>     np.random.seed(40)
> 
>     # Read the wine-quality csv file from the URL
>     csv_url = (
>         ""https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-red.csv""
>     )
>     try:
>         data = pd.read_csv(csv_url, sep="";"")
>     except Exception as e:
>         logger.exception(
>             ""Unable to download training & test CSV, check your internet connection. Error: %s"", e
>         )
> 
>     # Split the data into training and test sets. (0.75, 0.25) split.
>     train, test = train_test_split(data)
> 
>     # The predicted column is ""quality"" which is a scalar from [3, 9]
>     train_x = train.drop([""quality""], axis=1)
>     test_x = test.drop([""quality""], axis=1)
>     train_y = train[[""quality""]]
>     test_y = test[[""quality""]]
> 
>     alpha = float(sys.argv[1]) if len(sys.argv) > 1 else 0.5
>     l1_ratio = float(sys.argv[2]) if len(sys.argv) > 2 else 0.5
> 
>     lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)
>     lr.fit(train_x, train_y)
>     predicted_qualities = lr.predict(test_x)
>     (rmse, mae, r2) = eval_metrics(test_y, predicted_qualities)
>     print(f""Elasticnet model (alpha={alpha:f}, l1_ratio={l1_ratio:f}):"")
>     print(f""  RMSE: {rmse}"")
>     print(f""  MAE: {mae}"")
>     print(f""  R2: {r2}"")
> 
>     with mlflow.start_run():
>         
> 
>         mlflow.log_param(""alpha"", alpha)
>         mlflow.log_param(""l1_ratio"", l1_ratio)
>         mlflow.log_metric(""rmse"", rmse)
>         mlflow.log_metric(""r2"", r2)
>         mlflow.log_metric(""mae"", mae)
> 
>         predictions = lr.predict(train_x)
>         signature = infer_signature(train_x, predictions)
> 
>         
> 
>         tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme
> 
>         # Model registry does not work with file store
>         if tracking_url_type_store != ""file"":
>             # Register the model
>             # There are other ways to use the Model Registry, which depends on the use case,
>             # please refer to the doc for more information:
>             # https://mlflow.org/docs/latest/model-registry.html#api-workflow
>             mlflow.sklearn.log_model(
>                 lr, ""model"", registered_model_name=""ElasticnetWineModel"", signature=signature
>             )
>         else:
>             mlflow.sklearn.log_model(lr, ""model"", signature=signature)
> ```
> 
> ### Tracking information
> 
> `mlflow.doctor()` command output:
> 
> ```
> System information: Linux #167~18.04.1-Ubuntu SMP Wed May 24 00:51:42 UTC 2023
> Python version: 3.11.7
> MLflow version: 2.10.2
> MLflow module location: /home/vision/anaconda3/envs/mlflow/lib/python3.11/site-packages/mlflow/__init__.py
> Tracking URI: https://dagshub.com/elifbuyukorhan/mlflow_experiments.mlflow
> Registry URI: https://dagshub.com/elifbuyukorhan/mlflow_experiments.mlflow
> MLflow environment variables: 
>   MLFLOW_TRACKING_URI: https://dagshub.com/elifbuyukorhan/mlflow_experiments.mlflow
>   MLFLOW_TRACKING_USERNAME: elifbuyukorhan
> MLflow dependencies: 
>   Flask: 3.0.2
>   Jinja2: 3.1.3
>   alembic: 1.13.1
>   click: 8.1.7
>   cloudpickle: 3.0.0
>   docker: 7.0.0
>   entrypoints: 0.4
>   gitpython: 3.1.41
>   gunicorn: 21.2.0
>   importlib-metadata: 7.0.1
>   markdown: 3.5.2
>   matplotlib: 3.8.2
>   numpy: 1.26.4
>   packaging: 23.2
>   pandas: 2.2.0
>   protobuf: 4.25.2
>   pyarrow: 15.0.0
>   pytz: 2023.4
>   pyyaml: 6.0.1
>   querystring-parser: 1.2.4
>   requests: 2.31.0
>   scikit-learn: 1.4.0
>   scipy: 1.12.0
>   sqlalchemy: 2.0.25
>   sqlparse: 0.4.4
> None
> ```
> 
> ### Stack trace
> 
> ```
> Elasticnet model (alpha=0.500000, l1_ratio=0.500000):
>   RMSE: 0.7931640229276851
>   MAE: 0.6271946374319586
>   R2: 0.10862644997792614
> Traceback (most recent call last):
>   File ""/home/vision/Elif/mlflow_tutorial/sklearn_elasticnet_wine_train.py"", line 71, in <module>
>     with mlflow.start_run():
>          ^^^^^^^^^^^^^^^^^^
>   File ""/home/vision/anaconda3/envs/mlflow/lib/python3.11/site-packages/mlflow/tracking/fluent.py"", line 377, in start_run
>     active_run_obj = client.create_run(
>                      ^^^^^^^^^^^^^^^^^^
>   File ""/home/vision/anaconda3/envs/mlflow/lib/python3.11/site-packages/mlflow/tracking/client.py"", line 339, in create_run
>     return self._tracking_client.create_run(experiment_id, start_time, tags, run_name)
>            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
>   File ""/home/vision/anaconda3/envs/mlflow/lib/python3.11/site-packages/mlflow/tracking/_tracking_service/client.py"", line 132, in create_run
>     return self.store.create_run(
>            ^^^^^^^^^^^^^^^^^^^^^^
>   File ""/home/vision/anaconda3/envs/mlflow/lib/python3.11/site-packages/mlflow/store/tracking/rest_store.py"", line 178, in create_run
>     response_proto = self._call_endpoint(CreateRun, req_body)
>                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
>   File ""/home/vision/anaconda3/envs/mlflow/lib/python3.11/site-packages/mlflow/store/tracking/rest_store.py"", line 59, in _call_endpoint
>     return call_endpoint(self.get_host_creds(), endpoint, method, json_body, response_proto)
>            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
>   File ""/home/vision/anaconda3/envs/mlflow/lib/python3.11/site-packages/mlflow/utils/rest_utils.py"", line 220, in call_endpoint
>     response = verify_rest_response(response, endpoint)
>                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
>   File ""/home/vision/anaconda3/envs/mlflow/lib/python3.11/site-packages/mlflow/utils/rest_utils.py"", line 158, in verify_rest_response
>     raise MlflowException(
> mlflow.exceptions.MlflowException: API request to endpoint /api/2.0/mlflow/runs/create failed with error code 403 != 200. Response body: ''
> ```
> 
> ![image](https://private-user-images.githubusercontent.com/104029240/305048647-121051d1-665e-4a91-bfe3-e24be32526ae.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MDc5OTUyMjksIm5iZiI6MTcwNzk5NDkyOSwicGF0aCI6Ii8xMDQwMjkyNDAvMzA1MDQ4NjQ3LTEyMTA1MWQxLTY2NWUtNGE5MS1iZmUzLWUyNGJlMzI1MjZhZS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQwMjE1JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MDIxNVQxMTAyMDlaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1lM2Q0Y2NhZjY1MDc1YjFjZmQ1YmQ2NjU1NDdiMzk3OThiYjlmODMxNDBjMzZiZGZlMTNjYjBlN2I5YmY1YzZiJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.4RawTYS2sk3muCcoxRC5UCRx3jaRyp0hd3GrGWrrUEw)
> 
> I don't know what should I do about this.

I added this to the beginning of the whole code (after imports): 
```
os.environ['MLFLOW_TRACKING_USERNAME'] = 'name'
os.environ['MLFLOW_TRACKING_PASSWORD'] = 'pass'
``` 
and resolved.",error code data set used example cortez real modeling wine data mining physicochemical decision support import logging import import import import import import import import import import import logger remote server actual actual mae actual actual return mae ignore read file try data except exception unable training test check connection error split data training test split train test data column quality scalar quality quality train quality test quality alpha float else float else mae print model alpha print print mae mae print alpha alpha mae mae signature model registry work file store file register model way use model registry use case please refer doc information model else model information command output system information wed may python version version module location registry environment flask jinja alembic click docker markdown none stack trace model mae recent call last file line module file line file line return file line return file line file line return method file line response response file line raise request error code response body image know added beginning whole code resolved,issue,negative,negative,neutral,neutral,negative,negative
1945858062,"I have same error too. 

### My code: 
```
# The data set used in this example is from http://archive.ics.uci.edu/ml/datasets/Wine+Quality
# P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis.
# Modeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009.

import logging
import sys
import warnings
from urllib.parse import urlparse

import numpy as np
import pandas as pd
from sklearn.linear_model import ElasticNet
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.model_selection import train_test_split

import mlflow
import mlflow.sklearn
from mlflow.models import infer_signature

logging.basicConfig(level=logging.WARN)
logger = logging.getLogger(__name__)

## For remote server only(DAGShub)
remote_server_uri=""https://dagshub.com/elifbuyukorhan/mlflow_experiments.mlflow ""
mlflow.set_tracking_uri(remote_server_uri)


def eval_metrics(actual, pred):
    rmse = np.sqrt(mean_squared_error(actual, pred))
    mae = mean_absolute_error(actual, pred)
    r2 = r2_score(actual, pred)
    return rmse, mae, r2


if __name__ == ""__main__"":
    warnings.filterwarnings(""ignore"")
    np.random.seed(40)

    # Read the wine-quality csv file from the URL
    csv_url = (
        ""https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-red.csv""
    )
    try:
        data = pd.read_csv(csv_url, sep="";"")
    except Exception as e:
        logger.exception(
            ""Unable to download training & test CSV, check your internet connection. Error: %s"", e
        )

    # Split the data into training and test sets. (0.75, 0.25) split.
    train, test = train_test_split(data)

    # The predicted column is ""quality"" which is a scalar from [3, 9]
    train_x = train.drop([""quality""], axis=1)
    test_x = test.drop([""quality""], axis=1)
    train_y = train[[""quality""]]
    test_y = test[[""quality""]]

    alpha = float(sys.argv[1]) if len(sys.argv) > 1 else 0.5
    l1_ratio = float(sys.argv[2]) if len(sys.argv) > 2 else 0.5

    lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)
    lr.fit(train_x, train_y)
    predicted_qualities = lr.predict(test_x)
    (rmse, mae, r2) = eval_metrics(test_y, predicted_qualities)
    print(f""Elasticnet model (alpha={alpha:f}, l1_ratio={l1_ratio:f}):"")
    print(f""  RMSE: {rmse}"")
    print(f""  MAE: {mae}"")
    print(f""  R2: {r2}"")

    with mlflow.start_run():
        

        mlflow.log_param(""alpha"", alpha)
        mlflow.log_param(""l1_ratio"", l1_ratio)
        mlflow.log_metric(""rmse"", rmse)
        mlflow.log_metric(""r2"", r2)
        mlflow.log_metric(""mae"", mae)

        predictions = lr.predict(train_x)
        signature = infer_signature(train_x, predictions)

        

        tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme

        # Model registry does not work with file store
        if tracking_url_type_store != ""file"":
            # Register the model
            # There are other ways to use the Model Registry, which depends on the use case,
            # please refer to the doc for more information:
            # https://mlflow.org/docs/latest/model-registry.html#api-workflow
            mlflow.sklearn.log_model(
                lr, ""model"", registered_model_name=""ElasticnetWineModel"", signature=signature
            )
        else:
            mlflow.sklearn.log_model(lr, ""model"", signature=signature)

```
### Tracking information 
```mlflow.doctor()``` command output:

```
System information: Linux #167~18.04.1-Ubuntu SMP Wed May 24 00:51:42 UTC 2023
Python version: 3.11.7
MLflow version: 2.10.2
MLflow module location: /home/vision/anaconda3/envs/mlflow/lib/python3.11/site-packages/mlflow/__init__.py
Tracking URI: https://dagshub.com/elifbuyukorhan/mlflow_experiments.mlflow
Registry URI: https://dagshub.com/elifbuyukorhan/mlflow_experiments.mlflow
MLflow environment variables: 
  MLFLOW_TRACKING_URI: https://dagshub.com/elifbuyukorhan/mlflow_experiments.mlflow
  MLFLOW_TRACKING_USERNAME: elifbuyukorhan
MLflow dependencies: 
  Flask: 3.0.2
  Jinja2: 3.1.3
  alembic: 1.13.1
  click: 8.1.7
  cloudpickle: 3.0.0
  docker: 7.0.0
  entrypoints: 0.4
  gitpython: 3.1.41
  gunicorn: 21.2.0
  importlib-metadata: 7.0.1
  markdown: 3.5.2
  matplotlib: 3.8.2
  numpy: 1.26.4
  packaging: 23.2
  pandas: 2.2.0
  protobuf: 4.25.2
  pyarrow: 15.0.0
  pytz: 2023.4
  pyyaml: 6.0.1
  querystring-parser: 1.2.4
  requests: 2.31.0
  scikit-learn: 1.4.0
  scipy: 1.12.0
  sqlalchemy: 2.0.25
  sqlparse: 0.4.4
None
```
 ### Stack trace 
```
Elasticnet model (alpha=0.500000, l1_ratio=0.500000):
  RMSE: 0.7931640229276851
  MAE: 0.6271946374319586
  R2: 0.10862644997792614
Traceback (most recent call last):
  File ""/home/vision/Elif/mlflow_tutorial/sklearn_elasticnet_wine_train.py"", line 71, in <module>
    with mlflow.start_run():
         ^^^^^^^^^^^^^^^^^^
  File ""/home/vision/anaconda3/envs/mlflow/lib/python3.11/site-packages/mlflow/tracking/fluent.py"", line 377, in start_run
    active_run_obj = client.create_run(
                     ^^^^^^^^^^^^^^^^^^
  File ""/home/vision/anaconda3/envs/mlflow/lib/python3.11/site-packages/mlflow/tracking/client.py"", line 339, in create_run
    return self._tracking_client.create_run(experiment_id, start_time, tags, run_name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/vision/anaconda3/envs/mlflow/lib/python3.11/site-packages/mlflow/tracking/_tracking_service/client.py"", line 132, in create_run
    return self.store.create_run(
           ^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/vision/anaconda3/envs/mlflow/lib/python3.11/site-packages/mlflow/store/tracking/rest_store.py"", line 178, in create_run
    response_proto = self._call_endpoint(CreateRun, req_body)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/vision/anaconda3/envs/mlflow/lib/python3.11/site-packages/mlflow/store/tracking/rest_store.py"", line 59, in _call_endpoint
    return call_endpoint(self.get_host_creds(), endpoint, method, json_body, response_proto)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/vision/anaconda3/envs/mlflow/lib/python3.11/site-packages/mlflow/utils/rest_utils.py"", line 220, in call_endpoint
    response = verify_rest_response(response, endpoint)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/vision/anaconda3/envs/mlflow/lib/python3.11/site-packages/mlflow/utils/rest_utils.py"", line 158, in verify_rest_response
    raise MlflowException(
mlflow.exceptions.MlflowException: API request to endpoint /api/2.0/mlflow/runs/create failed with error code 403 != 200. Response body: ''
```
![image](https://github.com/mlflow/mlflow/assets/104029240/121051d1-665e-4a91-bfe3-e24be32526ae)

I don't know what should I do about this.
",error code data set used example cortez real modeling wine data mining physicochemical decision support import logging import import import import import import import import import import import logger remote server actual actual mae actual actual return mae ignore read file try data except exception unable training test check connection error split data training test split train test data column quality scalar quality quality train quality test quality alpha float else float else mae print model alpha print print mae mae print alpha alpha mae mae signature model registry work file store file register model way use model registry use case please refer doc information model else model information command output system information wed may python version version module location registry environment flask jinja alembic click docker markdown none stack trace model mae recent call last file line module file line file line return file line return file line file line return method file line response response file line raise request error code response body image know,issue,negative,negative,neutral,neutral,negative,negative
1945728930,"@BenWilson2 The CI seems to be failing, though I didn't do any actual code changes. Could you retrigger the failed job? Or should I rebase my changes on master first (not sure if CI was broken temporarily on that commit or just flaky)

https://github.com/mlflow/mlflow/actions/runs/6833559191/job/18791186786?pr=10365",failing though actual code could job rebase master first sure broken temporarily commit flaky,issue,negative,positive,neutral,neutral,positive,positive
1945666180,@daniellok-db Can we update the error message and say `Rerun this workflow once approved`?,update error message say rerun,issue,negative,neutral,neutral,neutral,neutral,neutral
1945665892,"@harupy sorry I was wrong. The `load_model` doesn't create the copy of models, because it uses local artifact repo which just reuses the saved artifacts for loading models. After some research, it seems the actual cause is the pytest's behavior that keeps `tmp_path` for 3 recent test sessions rather than cleaning up immediately. Filed a PR to clean up the tmp dir after each test case.",sorry wrong create copy local artifact saved loading research actual cause behavior recent test session rather cleaning immediately clean test case,issue,negative,negative,negative,negative,negative,negative
1945661979,"removed the review trigger. i guess we have to accept that it'll run on all PRs, it doesn't seem like the [github context](https://docs.github.com/en/actions/learn-github-actions/contexts#github-context) has info about PR paths so it would be hard to filter in the job's `if` condition",removed review trigger guess accept run seem like context would hard filter job condition,issue,positive,negative,negative,negative,negative,negative
1945644980,"It looks like different event triggers result in different checks. If this is the case, I'd remove `pull_request_review`.",like different event result different case remove,issue,negative,neutral,neutral,neutral,neutral,neutral
1945639407,Thanks for hard working! I will read it soon,thanks hard working read soon,issue,negative,negative,neutral,neutral,negative,negative
1945629675,"yeah that's weird... the only thing i can think is maybe `github.event_name` is not `pull_request`, and also there is no review event",yeah weird thing think maybe also review event,issue,negative,negative,negative,negative,negative,negative
1945619191,"@santiagxf I checked with `pip list`, it's installed:
```
Package                     Version
--------------------------- -----------
...
azureml-mlflow              1.55.0
...
```

For the context of the whole installation. I base my docker image on `mcr.microsoft.com/azureml/curated/acpt-pytorch-2.0-cuda11.7:21`, which comes with python 3.8 and conda. I use python 3.11.7 and poetry in my project, so my dockerfile looks like this:
```
FROM mcr.microsoft.com/azureml/curated/acpt-pytorch-2.0-cuda11.7:21
...
RUN conda install -y python=3.11.7
...
COPY poetry.lock pyproject.toml ./
RUN poetry install
...
```",checked pip list package version context whole installation base docker image come python use python poetry project like run install copy run poetry install,issue,negative,negative,negative,negative,negative,negative
1945431570,"> We still have ~5GB disk space but I feel like we'll hit the limit soon. Is it possible to clean up cache after each test module runs?

@harupy  I feel removing HF cache is a bit tedious because we need to manage when to clean and when to not. Previously we had `@skipcleancache` annotation to control whether or not to clean cache, as some models are used multiple times), but it creates dependency to the test order which is not super great:(

Instead, I'm wondering if we can
1. use `tmp_path` as a destination of `mlflow.pyfunc.load_model` -> Currently we don't specify it and the downloaded artifacts remain in the disk (which eat up ~20GB presumably).
2. explore smaller models - Some models are big (~GB) so can be replaced with smaller ones.

If this sounds good, I can do that as a follow-up:)",still disk space feel like hit limit soon possible clean cache test module feel removing cache bit tedious need manage clean previously annotation control whether clean cache used multiple time dependency test order super great instead wondering use destination currently specify remain disk eat presumably explore smaller big smaller good,issue,positive,positive,positive,positive,positive,positive
1945411166,"The disk is almost full:

<img width=""1271"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/17039389/8ffe4a35-0f55-4b0d-9e7c-1a7e8a8e82cc"">

https://github.com/mlflow/mlflow/actions/runs/7910664074/job/21593617127?pr=11120

We still have ~5GB disk space but I feel like we'll hit the limit soon. Is it possible to clean up cache after each test module runs?",disk almost full image still disk space feel like hit limit soon possible clean cache test module,issue,positive,positive,positive,positive,positive,positive
1945391470,"@StathisKap and @QuantLandi, just tagging you guys here since we weren't getting any replies in the previous one",since getting previous one,issue,negative,negative,negative,negative,negative,negative
1945322102,"Latest Johnsnowlabs depends on pyspark==3.4 for pip install, but other versions of pyspark work fine. 
We could install with --no-dependencies, but then we need to install other dependencies manually",latest pip install work fine could install need install manually,issue,negative,positive,positive,positive,positive,positive
1945230383,"@bharadwaj509 You need to import `MlflowClient`, not `MLFlowClient`:

```
>>> from mlflow import MLFlowClient
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ImportError: cannot import name 'MLFlowClient' from 'mlflow' (/usr/local/lib/python3.10/site-packages/mlflow/__init__.py)
>>> 
>>> from mlflow import MlflowClient
>>>
```",need import import recent call last file line module import name import,issue,negative,neutral,neutral,neutral,neutral,neutral
1945154514,@BenWilson2 could you also take a look at https://github.com/mlflow/mlflow/pull/11119?,could also take look,issue,negative,neutral,neutral,neutral,neutral,neutral
1945152524,"@BenWilson2 Yes, the METADATA file in a wheel looks like this:

```
Metadata-Version: 2.1
Name: mlflow
Version: 2.10.3.dev0
Summary: MLflow: A Platform for ML Development and Productionization
Home-page: https://mlflow.org/
Author: Databricks
License: Apache License 2.0
Project-URL: Bug Tracker, https://github.com/mlflow/mlflow/issues
Project-URL: Documentation, https://mlflow.org/docs/latest/index.html
Project-URL: Source Code, https://github.com/mlflow/mlflow
Keywords: ml ai databricks
Classifier: Intended Audience :: Developers
Classifier: Programming Language :: Python :: 3.8
Requires-Python: >=3.8  👈
...
```",yes file wheel like name version dev summary platform development author license apache license bug tracker documentation source code ai classifier intended audience classifier language python,issue,positive,neutral,neutral,neutral,neutral,neutral
1945043049,Is it a possible to write a unit test when we onboard a new item?,possible write unit test new item,issue,negative,positive,neutral,neutral,positive,positive
1944617543,"@dbczumar Corey mind reviewing this PR? Also one question - now I am only adding control for fluent APIs, do you think we should have the same control over `MlflowClient`'s APIs as well? ",mind also one question control fluent think control well,issue,negative,neutral,neutral,neutral,neutral,neutral
1944513508,"Thanks for the reply.

Clarifying on my issue, i meant give the user the option to disable SSL, obviously not forcing by default. 
Use case would be to quickly experiment with mlflow, without having to make any request to other IT departments.",thanks reply issue meant give user option disable obviously forcing default use case would quickly experiment without make request,issue,negative,positive,positive,positive,positive,positive
1944396443,@Temitope-Ajayi You have a version mismatch.  My understanding is that they have no intention of fixing this for backwards compatibility.  You have to use either Mlflow v1 or v2 in both cases or fork the repo and patch the code yourself.,version mismatch understanding intention fixing backwards compatibility use either fork patch code,issue,negative,neutral,neutral,neutral,neutral,neutral
1944385333,"How can this issue be fixed? I'm having the same problem. 

```py
MlflowException: API request to endpoint /api/2.0/preview/mlflow/registered-models/create failed with error code 404 != 200. Response body: '<!doctype html>
<html lang=en>
<title>404 Not Found</title>
<h1>Not Found</h1>
<p>The requested URL was not found on the server. If you entered the URL manually please check your spelling and try again.</p>
```",issue fixed problem request error code response body title found found found server manually please check spelling try,issue,negative,positive,neutral,neutral,positive,positive
1944289340,"I'm curious why you would want to disable SSL? Aside from the obvious benefits of transmitting data through encrypted means (a quite important security consideration for working on untrusted networks), there are integrity validation checks that are performed to validate a successful data transmission when using SSL / TLS. 
We're not interested in giving users an option to bypass recommended security protocols, which could risk exposing protected data to malicious actors (man in the middle attacks). ",curious would want disable aside obvious data quite important security consideration working untrusted integrity validation validate successful data transmission interested giving option bypass security could risk data malicious man middle,issue,positive,positive,positive,positive,positive,positive
1943842617,Let me see if I can repro and will get back to you.,let see get back,issue,negative,neutral,neutral,neutral,neutral,neutral
1943517446,"> @WeichenXu123 I guess we don't need this change? The test error should be fixed by #11115

oh make sense. Let me rerun master cross test to confirm. I didn't notice https://github.com/mlflow/mlflow/pull/11115 is merged a few hours ago.",guess need change test error fixed oh make sense let rerun master cross test confirm notice ago,issue,negative,positive,neutral,neutral,positive,positive
1943498837,@WeichenXu123 I guess we don't need this change? The test error should be fixed by https://github.com/mlflow/mlflow/pull/11115,guess need change test error fixed,issue,negative,positive,neutral,neutral,positive,positive
1943456170,"@hubertzub-db Maybe its due the used storage backend? I saw an issue here about File-Based storages having no problems with serving aliases, but database may dont fill them due performance reasons: https://github.com/mlflow/mlflow/issues/9783 ",maybe due used storage saw issue serving may dont fill due performance,issue,negative,negative,negative,negative,negative,negative
1943313413,"Is this a distinct enhancement request/proposal from #11040, or should they be consolidated?

Also related, for enterprise-grade authN/Z if not specifically SSO:

- #7347 
- #10890 ",distinct enhancement consolidated also related specifically,issue,negative,positive,positive,positive,positive,positive
1943187364,"Thanks! When creating the job I'm passing `Output(type=AssetTypes.CUSTOM_MODEL)`. When the job is running, the value of `model_output` variable is just `""model_output""`.",thanks job passing output job running value variable,issue,positive,positive,positive,positive,positive,positive
1943082484,Sure we are happy to take a look. @gjurdzinski-deepsense can you tell us what's the value you are passing on `model_output` variable?,sure happy take look tell u value passing variable,issue,positive,positive,positive,positive,positive,positive
1943066133,Didn't get you @harupy. Which PR closed it? I'm still facing this issue,get closed still facing issue,issue,negative,negative,neutral,neutral,negative,negative
1943047827,"Solution: I tried MATPLOTLIB 3.8.0 and 3.8.2. Since there is no other higher version available at this point, I installed 3.7.4 and it is working.

Thanks a lot @harupy for replying.",solution tried since higher version available point working thanks lot,issue,positive,positive,positive,positive,positive,positive
1943044950,"> ```python
> import matplotlib.pyplot as plt
> import numpy as np
> 
> # Data for plotting
> t = np.arange(0.0, 2.0, 0.01)
> s = 1 + np.sin(2 * np.pi * t)
> 
> fig, ax = plt.subplots()
> ax.plot(t, s)
> 
> ax.set(xlabel='time (s)', ylabel='voltage (mV)',
>        title='About as simple as it gets, folks')
> ax.grid()
> 
> fig.savefig(""test.png"")
> plt.show()
> ```

Thanks a lot for the reply.  I did the matplotlib update to 3.8.2 and still get the same issue. I updated it to 3.8.2 and facing the same issue.",python import import data plotting fig ax simple thanks lot reply update still get issue facing issue,issue,negative,positive,neutral,neutral,positive,positive
1943042814,"> @bharadwaj509 I don't think this is an mlflow issue. Can you reinstall matplotlib? Feel free to reopen the issue if it doesn't solve the issue.
> 
> ```
> root@e853dc9e7d44:/# python
> Python 3.10.13 (main, Nov  1 2023, 10:42:40) [GCC 12.2.0] on linux
> Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
> >>> import matplotlib
> >>> matplotlib.cbook._Stack
> <class 'matplotlib.cbook._Stack'>
> >>> matplotlib.__version__
> '3.8.2'
> ```

Apolgies for not replying early. My matplotlib is 3.8.0.d I will upgrade now and will test it again.",think issue reinstall feel free reopen issue solve issue root python python main type help copyright license information import class early upgrade test,issue,positive,positive,positive,positive,positive,positive
1943026329,"@harupy thanks for the review, i remember i was tired when i wrote the initial version hahaha. i kept thinking there must be some way to reduce the code duplication but i could feel my brain turning off. could you take a look at the refactored version?

also here's a demo of it working:

https://github.com/mlflow/mlflow/assets/148037680/3013e1cf-ef17-428f-ae77-f7c7fc17306d

",thanks review remember tired wrote initial version kept thinking must way reduce code duplication could feel brain turning could take look version also working,issue,negative,negative,neutral,neutral,negative,negative
1943017914,@mchutani-CS do you have the full traceback? Can you check the card of the failed step? I think the full traceback is included there.,full check card step think full included,issue,negative,positive,positive,positive,positive,positive
1942961722,"@bharadwaj509 Can you run the following code? Does that reproduce the error?

```python
import matplotlib.pyplot as plt
import numpy as np

# Data for plotting
t = np.arange(0.0, 2.0, 0.01)
s = 1 + np.sin(2 * np.pi * t)

fig, ax = plt.subplots()
ax.plot(t, s)

ax.set(xlabel='time (s)', ylabel='voltage (mV)',
       title='About as simple as it gets, folks')
ax.grid()

fig.savefig(""test.png"")
plt.show()
```

source: https://stackoverflow.com/questions/77457355/attributeerror-module-matplotlib-cbook-has-no-attribute-stack

If this code reproduces the error, mlflow is unrelated.",run following code reproduce error python import import data plotting fig ax simple source code error unrelated,issue,negative,neutral,neutral,neutral,neutral,neutral
1942960676,"@bharadwaj509 I don't think this is an mlflow issue. Can you reinstall matplotlib? Feel free to reopen the issue if it doesn't solve the issue.

```
root@e853dc9e7d44:/# python
Python 3.10.13 (main, Nov  1 2023, 10:42:40) [GCC 12.2.0] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import matplotlib
>>> matplotlib.cbook._Stack
<class 'matplotlib.cbook._Stack'>
>>> matplotlib.__version__
'3.8.2'
```
",think issue reinstall feel free reopen issue solve issue root python python main type help copyright license information import class,issue,positive,positive,positive,positive,positive,positive
1942947968,"@BenWilson2 totally agree we should add this! we would need to change a few places
* UI: add a field for this, pass system prompt when making query
* backend: store system prompt in the run
* promptlab model flavor: pass system prompt when constructing query ",totally agree add would need change add field pas system prompt making query store system prompt run model flavor pas system prompt query,issue,negative,neutral,neutral,neutral,neutral,neutral
1942940704,@akshaya-a @santiagxf would you mind taking a look here? Thank you! :) ,would mind taking look thank,issue,negative,neutral,neutral,neutral,neutral,neutral
1942904573,"@michael-berk Thanks for the RP!

> Don't convert mleap - depricated formatter breaks docs build and formatting

Is this fixable or not?",thanks convert build fixable,issue,negative,positive,positive,positive,positive,positive
1942456628,"Yes. can you type 
```pip install -r requirement.txt""```
and added optuna as well. #11090PR",yes type pip install added well,issue,positive,neutral,neutral,neutral,neutral,neutral
1941619960,"Thanks for the update! These doc changes work and while they might be counterintuitive for non-SWE data scientists, they are clear and understandable.

If you think we could allow in memory serialization for python objects to the tracking server, let me know. I don't see how to build it.",thanks update doc work might data clear understandable think could allow memory serialization python server let know see build,issue,positive,positive,positive,positive,positive,positive
1941610338,"> @michael-berk Is the proposal to make `mlflow.log_artifact` accept objects like this?
> 
> ```python
> mlflow.log_artifact(fig, ""xyz.png"")
> ```

Generally, yes.",proposal make accept like python fig generally yes,issue,positive,positive,neutral,neutral,positive,positive
1941486252,"Hi @BenWilson2 , I'd like to work on the `SparkML ` one, could you give me a try?",hi like work one could give try,issue,negative,neutral,neutral,neutral,neutral,neutral
1940917293,"Hi, Are there any plans to integrate LLM features into the Helm chart, MLFlow Deployment server, and the Prompt Engineering UI for LLMs?
",hi integrate helm chart deployment server prompt engineering,issue,negative,neutral,neutral,neutral,neutral,neutral
1940872725,⚠️ Warning: It looks like you're editing requirements for MLflow. Please ensure that this doesn't cause any dependency conflicts with downstream tasks that depend on MLflow (e.g. image building).,warning warning like please ensure cause dependency downstream depend image building,issue,negative,neutral,neutral,neutral,neutral,neutral
1940525945,"@michael-berk 

> Do you want me to convert directories outside of mlflow/mlflow as well?

Yes if that's feasible :)
",want convert outside well yes feasible,issue,positive,neutral,neutral,neutral,neutral,neutral
1940309411,"@viktorsobol It looks like this is a bug in langchain. Here's a script to reproduce the same issue without using mlflow:

```python
import tempfile

from langchain.prompts import ChatPromptTemplate, ChatMessagePromptTemplate
from langchain.llms import OpenAI
from langchain import LLMChain
from langchain.chains.loading import load_chain


PROMPT = """"""
You will analyzing emails from customer. If email contains any disagreement then reply ""Bad""
 If the text in email is positive then reply ""Good""
""""""


prompt = ChatPromptTemplate.from_messages(
    [
        ChatMessagePromptTemplate.from_template(role=""system"", template=PROMPT),
        ChatMessagePromptTemplate.from_template(role=""user"", template=""{email}""),
    ],
)

chain = LLMChain(llm=OpenAI(), prompt=prompt)
with tempfile.TemporaryDirectory() as tmpdir:
    chain.save(f""{tmpdir}/model.yaml"")
    loaded_chain = load_chain(f""{tmpdir}/model.yaml"")

assert type(loaded_chain.prompt.messages[0]) == type(chain.prompt.messages[0]), (
    type(loaded_chain.prompt.messages[0]),
    type(chain.prompt.messages[0]),
)

# AssertionError: (<class 'langchain_core.prompts.chat.HumanMessagePromptTemplate'>, <class 'langchain_core.prompts.chat.ChatMessagePromptTemplate'>)
```",like bug script reproduce issue without python import import import import import prompt customer disagreement reply bad text positive reply good prompt system user chain assert type type type type class class,issue,negative,positive,neutral,neutral,positive,positive
1940096779,@SiddharthSingi Feel free to reopen the issue if the code above doesn't work,feel free reopen issue code work,issue,positive,positive,positive,positive,positive,positive
1939964558,"Hi @hakan-77, yes I think this would be fine to add! The relevant section of code is here:

https://github.com/mlflow/mlflow/blob/dc51fc6b82fa78a30f8be5efed18f7867809311d/mlflow/server/js/src/common/hooks/useMLflowDarkTheme.tsx#L18

I think we can make the query string take highest preference when initializing the `isDarkTheme` hook. You can use [URLSearchParams](https://developer.mozilla.org/en-US/docs/Web/API/URLSearchParams/URLSearchParams) to retrieve a query param.

I should add that the dark mode also follows system settings, so if your users have set dark mode as a system preference (e.g. through browser or OS settings), MLflow should be in dark mode as well. This might be a simpler fix for your use-case.",hi yes think would fine add relevant section code think make query string take highest preference hook use retrieve query param add dark mode also system set dark mode system preference browser o dark mode well might simpler fix,issue,positive,positive,neutral,neutral,positive,positive
1939904226,"@michael-berk Is the proposal to make `mlflow.log_artifact` accept objects like this?

```python
mlflow.log_artifact(fig, ""xyz.png"")
```

",proposal make accept like python fig,issue,positive,neutral,neutral,neutral,neutral,neutral
1939464469,"When I only perform `mlflow ui` without starting a deployments server, there is no error. 

```python
with mlflow.start_run(run_name=""mistral""):
    mlflow.evaluate(
        model,
        eval_df,
        # model_type=""question-answering"",
        # evaluators=""default"",
        targets=""answer"",
        extra_metrics=[answer_similarity_metric], # faithfulness_metric, relevance_metric],
        evaluator_config={
            ""col_mapping"": {
                ""inputs"": ""question"",
            }
        },
    )
```
```
c:\Users\_\miniconda3\envs\ml-3.10\lib\site-packages\mlflow\data\digest_utils.py:29: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.
  string_columns = trimmed_df.columns[(df.applymap(type) == str).all(0)]
c:\Users\_\miniconda3\envs\ml-3.10\lib\site-packages\mlflow\models\evaluation\base.py:414: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.
  data = data.applymap(_hash_array_like_element_as_bytes)
c:\Users\_\miniconda3\envs\ml-3.10\lib\site-packages\mlflow\models\evaluation\base.py:414: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.
  data = data.applymap(_hash_array_like_element_as_bytes)
2024/02/12 14:46:15 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.
2024/02/12 14:46:15 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.
2024/02/12 14:46:37 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...
100%
1/1 [01:25<00:00, 85.78s/it]
c:\Users\_\miniconda3\envs\ml-3.10\lib\site-packages\numpy\core\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.
  return _methods._mean(a, axis=axis, dtype=dtype,
c:\Users\_\miniconda3\envs\ml-3.10\lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)
c:\Users\_\miniconda3\envs\ml-3.10\lib\site-packages\numpy\core\fromnumeric.py:3787: RuntimeWarning: Degrees of freedom <= 0 for slice
  return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,
c:\Users\_\miniconda3\envs\ml-3.10\lib\site-packages\numpy\core\_methods.py:163: RuntimeWarning: invalid value encountered in divide
  arrmean = um.true_divide(arrmean, div, out=arrmean,
c:\Users\_\miniconda3\envs\ml-3.10\lib\site-packages\numpy\core\_methods.py:198: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)
2024/02/12 14:48:03 INFO mlflow.models.evaluation.default_evaluator: Evaluating metrics: answer_similarity
100%
10/10 [01:27<00:00, 3.34s/it]
```

If I use the deploy client, I do get an error. (which is the expected behaviour)
```python
from mlflow.deployments import get_deploy_client

client = get_deploy_client(""http://localhost:7000"")
endpoints = client.list_endpoints()
for endpoint in endpoints:
    print(endpoint)
```
```
(Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000027B65441690>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))

During handling of the above exception, another exception occurred:

ConnectionError                           Traceback (most recent call last)
File c:\Users\_\miniconda3\envs\ml-3.10\lib\site-packages\mlflow\utils\rest_utils.py:108, in http_request(host_creds, endpoint, method, max_retries, backoff_factor, backoff_jitter, extra_headers, retry_codes, timeout, raise_on_status, **kwargs)
    107 try:
--> 108     return _get_http_response_with_retries(
    109         method,
    110         url,
    111         max_retries,
    112         backoff_factor,
    113         backoff_jitter,
    114         retry_codes,
    115         raise_on_status,
    116         headers=headers,
    117         verify=host_creds.verify,
    118         timeout=timeout,
    119         **kwargs,
    120     )
    121 except requests.exceptions.Timeout as to:

File c:\Users\_\miniconda3\envs\ml-3.10\lib\site-packages\mlflow\utils\request_utils.py:212, in _get_http_response_with_retries(method, url, max_retries, backoff_factor, backoff_jitter, retry_codes, raise_on_status, allow_redirects, **kwargs)
    210 allow_redirects = env_value if allow_redirects is None else allow_redirects
--> 212 return session.request(method, url, allow_redirects=allow_redirects, **kwargs)

File c:\Users\_\miniconda3\envs\ml-3.10\lib\site-packages\requests\sessions.py:589, in Session.request(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)
    588 send_kwargs.update(settings)
--> 589 resp = self.send(prep, **send_kwargs)
    591 return resp

File c:\Users\_\miniconda3\envs\ml-3.10\lib\site-packages\requests\sessions.py:703, in Session.send(self, request, **kwargs)
    702 # Send the request
--> 703 r = adapter.send(request, **kwargs)
    705 # Total elapsed time of the request (approximately)

File c:\Users\_\miniconda3\envs\ml-3.10\lib\site-packages\requests\adapters.py:519, in HTTPAdapter.send(self, request, stream, timeout, verify, cert, proxies)
    517         raise SSLError(e, request=request)
--> 519     raise ConnectionError(e, request=request)
    521 except ClosedPoolError as e:

ConnectionError: HTTPConnectionPool(host='localhost', port=7000): Max retries exceeded with url: /api/2.0/endpoints/ (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000027B65441690>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))

During handling of the above exception, another exception occurred:

MlflowException                           Traceback (most recent call last)
Cell In[2], line 1
----> 1 endpoints = client.list_endpoints()
      2 for endpoint in endpoints:
      3     print(endpoint)

File c:\Users\_\miniconda3\envs\ml-3.10\lib\site-packages\mlflow\deployments\mlflow\__init__.py:229, in MlflowDeploymentClient.list_endpoints(self)
    227 next_page_token = None
    228 while True:
--> 229     page = self._list_endpoints(next_page_token)
    230     endpoints.extend(page)
    231     next_page_token = page.token

File c:\Users\_\miniconda3\envs\ml-3.10\lib\site-packages\mlflow\deployments\mlflow\__init__.py:181, in MlflowDeploymentClient._list_endpoints(self, page_token)
    179 def _list_endpoints(self, page_token=None) -> ""PagedList[Endpoint]"":
    180     params = None if page_token is None else {""page_token"": page_token}
--> 181     response_json = self._call_endpoint(
    182         ""GET"", MLFLOW_DEPLOYMENTS_CRUD_ENDPOINT_BASE, json_body=params
    183     )
    184     routes = [
    185         Endpoint(
    186             **{
   (...)
    194         for resp in response_json.get(""endpoints"", [])
    195     ]
    196     next_page_token = response_json.get(""next_page_token"")

File c:\Users\_\miniconda3\envs\ml-3.10\lib\site-packages\mlflow\deployments\mlflow\__init__.py:132, in MlflowDeploymentClient._call_endpoint(self, method, route, json_body, timeout)
    129 else:
    130     call_kwargs[""json""] = json_body
--> 132 response = http_request(
    133     host_creds=_get_default_host_creds(self.target_uri),
    134     endpoint=route,
    135     method=method,
    136     timeout=MLFLOW_HTTP_REQUEST_TIMEOUT.get() if timeout is None else timeout,
    137     retry_codes=MLFLOW_DEPLOYMENT_CLIENT_REQUEST_RETRY_CODES,
    138     raise_on_status=False,
    139     **call_kwargs,
    140 )
    141 augmented_raise_for_status(response)
    142 return response.json()

File c:\Users\_\miniconda3\envs\ml-3.10\lib\site-packages\mlflow\utils\rest_utils.py:130, in http_request(host_creds, endpoint, method, max_retries, backoff_factor, backoff_jitter, extra_headers, retry_codes, timeout, raise_on_status, **kwargs)
    128     raise InvalidUrlException(f""Invalid url: {url}"") from iu
    129 except Exception as e:
--> 130     raise MlflowException(f""API request to {url} failed with exception {e}"")

MlflowException: API request to http://localhost:7000/api/2.0/endpoints/ failed with exception HTTPConnectionPool(host='localhost', port=7000): Max retries exceeded with url: /api/2.0/endpoints/ (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000027B65441690>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))
```",perform without starting server error python mistral model default answer question use instead type use instead data use instead data model default model testing metric first row mean empty slice return invalid value scalar divide ret ret freedom slice return invalid value divide div invalid value scalar divide ret ret metric use deploy client get error behaviour python import client print object establish new connection connection could made target machine actively handling exception another exception recent call last file method try return method except file none else return method file self method data stream verify resp prep return resp file self request send request request total time request approximately file self request stream verify raise raise except object establish new connection connection could made target machine actively handling exception another exception recent call last cell line print file self none true page page file self self none none else get resp file self method route else response none else response return file method raise invalid except exception raise request exception request exception object establish new connection connection could made target machine actively,issue,positive,negative,neutral,neutral,negative,negative
1939309527,You'll need to rebase to master to pick up the linting rules changes to get CI to pass. ,need rebase master pick get pas,issue,negative,neutral,neutral,neutral,neutral,neutral
1938744830,Hi @mlflow/mlflow-team - can you please confirm you've seen our submission? Thank you.,hi please confirm seen submission thank,issue,positive,neutral,neutral,neutral,neutral,neutral
1938342852,"@mendelson oh we've seen similar report in https://github.com/mlflow/mlflow/issues/10961 however we weren't able to reproduce it. 
Is it possible for you to enter the page with missing aliases with browser's developer tools open and send traces from browser's ""Network"" tab? That would be great and would heavily help with debugging.",oh seen similar report however able reproduce possible enter page missing browser developer open send browser network tab would great would heavily help,issue,positive,positive,positive,positive,positive,positive
1938245754,"Nevermind, `registry_uri` should be used only if we have only two instances of MLFlow, one for the registry, the other for UI. Answer was to not set it, and use only one instance, or set it and use 2 instances living at two different locations.",used two one registry answer set use one instance set use living two different,issue,negative,neutral,neutral,neutral,neutral,neutral
1938182408,I can imagine this feature would be of significant value to many people 👍,imagine feature would significant value many people,issue,negative,positive,positive,positive,positive,positive
1938136190,"Custom system prompts are super important for tweaking how things work, and without the ability to set them, many of us are gonna miss out on using this awesome feature.",custom system super important work without ability set many u gon na miss awesome feature,issue,positive,positive,positive,positive,positive,positive
1938099855,this issue is also preventing us from being able to use the Prompt Engineering UI with our workflow and model management. Will be great if this feature is added with urgency.,issue also u able use prompt engineering model management great feature added urgency,issue,positive,positive,positive,positive,positive,positive
1937487181,"Found that the specific run if is being sent to the plugin through the plugin init instead of through the log_artifacts method, so, that should prevent the delete all bug.
It would be great if the init might get the entire {new-location}/{experiment-id}/{run-id}/artifacts instead of just the {run-id}/artifacts, but it does not have the bug I thought it had so I am closing this",found specific run sent instead method prevent delete bug would great might get entire instead bug thought,issue,positive,positive,positive,positive,positive,positive
1937342737,"@kru2710shna Thank you for the contribution! Could you fix the following issue(s)?

#### &#x26a0; DCO check

The DCO check failed. Please sign off your commit(s) by following the instructions [here](https://github.com/mlflow/mlflow/runs/21442298236). See https://github.com/mlflow/mlflow/blob/master/CONTRIBUTING.md#sign-your-work for more details.

#### &#x26a0; PR branch check

This PR was filed from the master branch in your fork, which is not recommended and may cause our CI checks to fail. Please close this PR and file a new PR from a non-master branch.",thank contribution could fix following issue check check please sign commit following see branch check master branch fork may cause fail please close file new branch,issue,positive,negative,neutral,neutral,negative,negative
1937116616,"> minimum

I was at first very very enthusiastic about the chart view. Then I noticed that it does not use the min or max of the metric that I select. That makes it useless for comparing the quality of different runs (unless I'm missing something of course).

Is it possible to add this? If I'm mistaken, please correct me.",minimum first enthusiastic chart view use min metric select useless quality different unless missing something course possible add mistaken please correct,issue,negative,positive,neutral,neutral,positive,positive
1936936977,"> Greetings
> 
> I added optuna in the test_requirement.txt, and it said ""Successfully installed colorlog-6.8.2 optuna-3.5.0""
> 
> Is this what supposed to do ?

Yes, optuna is the missing dependency which allows to run tests",added said successfully supposed yes missing dependency run,issue,positive,positive,positive,positive,positive,positive
1936546826,Do you want me to convert directories outside of `mlflow/mlflow` as well?,want convert outside well,issue,negative,neutral,neutral,neutral,neutral,neutral
1936219653,"> Hi @BenWilson2 , I've just updated docs and add examples for the provider.
> 
> Can you check it @BenWilson2 ?
> 
> Are you planning to add the PR in your next patch version 2.10.2 ?

We don't include features with patch releases. This will be included in the 2.11 release of MLflow. Thanks again for the contribution! I'll merge it once CI finishes :) ",hi add provider check add next patch version include patch included release thanks contribution merge,issue,negative,positive,neutral,neutral,positive,positive
1936210474,"@BenWilson2 I've changed my implementation to use the ""fluent"" API of MLFlow, resulting in the same result as what I've done just before:

```Python
import numpy as np
import mlflow
from dagster import AssetExecutionContext, asset
from mlflow.models import infer_signature
from sklearn import datasets, linear_model
from sklearn.metrics import mean_squared_error, r2_score

from orchestration.resources.mlflow import TestMLFlowResource


@asset(
    name=""mlflow_test_train"",
    key_prefix=[""mlflow_test""],
    compute_kind=""mlflow"",
    group_name=""mlflow_test"",
)
def mlflow_test_train(
    context: AssetExecutionContext,
    test_mlflow: TestMLFlowResource,
) -> linear_model.LinearRegression:
    experiment_name = ""EXPERIMENT""
    experiment = mlflow.get_experiment_by_name(experiment_name)
    
    if not experiment:
        experiment_id = mlflow.create_experiment(experiment_name)
        experiment = mlflow.get_experiment(experiment_id)
    
    experiment = mlflow.set_experiment(experiment_id=experiment.experiment_id)

    with mlflow.start_run() as active_run:
        run_id = active_run.info.run_id
        mlflow.log_param(""param"", ""test"")
        mlflow.log_param(""param2"", ""test2"")
        # Load the diabetes dataset
        diabetes_X, diabetes_y = datasets.load_diabetes(return_X_y=True)

        # Use only one feature
        diabetes_X = diabetes_X[:, np.newaxis, 2]

        # Split the data into training/testing sets
        diabetes_X_train = diabetes_X[:-20]
        diabetes_X_test = diabetes_X[-20:]

        # Split the targets into training/testing sets
        diabetes_y_train = diabetes_y[:-20]
        diabetes_y_test = diabetes_y[-20:]

        # Create linear regression object
        regr = linear_model.LinearRegression()

        # Train the model using the training sets
        fitted_model = regr.fit(diabetes_X_train, diabetes_y_train)

        # Make predictions using the testing set
        diabetes_y_pred = fitted_model.predict(diabetes_X_test)

        mean_squared_error_value = mean_squared_error(diabetes_y_test, diabetes_y_pred)
        mlflow.log_metric(""mean_squared_error"", mean_squared_error_value)

        r2_score_value = r2_score(diabetes_y_test, diabetes_y_pred)
        mlflow.log_metric(""r2_score"", r2_score_value)

        features = ""rooms, zipcode, median_price, school_rating, transport""
        with open(""features.txt"", ""w"") as f:
            f.write(features)

        mlflow.log_artifact(""features.txt"")
        
        model_name = ""linear-regression""
        
        signature = infer_signature(diabetes_X_test, diabetes_y_pred)
        mlflow.sklearn.log_model(
            sk_model=fitted_model,
            artifact_path=""model"",
            signature=signature,
        )
        # Breaking here (use the endpoint /api/2.0/mlflow/registered-models/create) like the use of MLFlowClient.create_registered_model...
        mlflow.register_model(
            f""runs:/{run_id}/model"", model_name
        )

        return fitted_model

```

With TestMLFlowResource being :

```Python
import os
import mlflow

from dagster import ConfigurableResource, InitResourceContext


class TestMLFlowResource(ConfigurableResource):
    tracking_uri: str
    registry_uri: str
    aws_access_key_id: str
    aws_secret_access_key: str

    def setup_for_execution(self, context: InitResourceContext) -> None:
        os.environ[""AWS_ACCESS_KEY_ID""] = self.aws_access_key_id
        os.environ[""AWS_SECRET_ACCESS_KEY""] = self.aws_secret_access_key
        os.environ[""MLFLOW_S3_ENDPOINT_URL""] = self.registry_uri
        mlflow.set_tracking_uri(self.tracking_uri)
        mlflow.set_registry_uri(self.registry_uri)
```",implementation use fluent resulting result done python import import import asset import import import import asset context experiment experiment experiment experiment experiment param test param test load diabetes use one feature split data split create linear regression object train model training make testing set transport open signature model breaking use like use return python import o import import class self context none,issue,positive,neutral,neutral,neutral,neutral,neutral
1936191622,Not exactly sure how to classify it! It's just a small python API update.,exactly sure small python update,issue,negative,positive,positive,positive,positive,positive
1936184369,"@suyogkute it is resolved by adding support for the OpenAI SDK 1.x, enabling MLflow to conform to the new means of specifying chat endpoints. This enhancement will be released in MLflow 2.11. ",resolved support conform new chat enhancement,issue,positive,positive,positive,positive,positive,positive
1936169513,Unfortunately still no solution found yet,unfortunately still solution found yet,issue,negative,negative,negative,negative,negative,negative
1936038902,"I'd like to work on this issue.

--- 

My understanding is that `make_genai_metric` instantiates a `EvaluationModel` that has the `grading_system_prompt_template` hardcoded.
So, the user could provide an optional `grading_system_prompt_template` argument that simply is used instead of the template in that case, that way the option is provided simply, and it doesn't break the existing approach!

Would that fit the requirements?",like work issue understanding user could provide optional argument simply used instead template case way option provided simply break approach would fit,issue,negative,positive,positive,positive,positive,positive
1935935047,"Multiple things, from my understanding :
- There is no environment variable called MLFLOW_REGISTRY_STORE_URI
- MLFLOW_REGISTRY_STORE_URI is used when starting mlflow server and here is how I start it : 

With this service in my docker compose :

```YAML
mlflow:
    build: .
    container_name: mlflow
    ports:
    # Default port is 5000 for mlflow
      - 5000:5000
    restart: unless-stopped
    environment:
      # Credentials used for UI connected to S3 to list artifacts
      AWS_ACCESS_KEY_ID: mlflowminio
      AWS_SECRET_ACCESS_KEY: mlflowminio
      MLFLOW_S3_ENDPOINT_URL: http://minio:9000
      # Server entrypoints
      ENTRYPOINT_MLFLOW_HOST: 0.0.0.0
      ENTRYPOINT_POSTGRES_URI: postgresql://postgres:postgres@postgresql:5432/mlflow
      ENTRYPOINT_MINIO_URI: s3://mlflow-artifacts
    depends_on:
      - postgresql
      - minio-initializer
    entrypoint: /home/app/entries/entrypoint.sh
    healthcheck:
      test: [""CMD-SHELL"", ""curl --fail http://localhost:5000/health || exit 1""]
    networks:
      - mlflow-network
```

/home/app/entries/entrypoint.sh is :
`mlflow server --host $ENTRYPOINT_MLFLOW_HOST --backend-store-uri $ENTRYPOINT_POSTGRES_URI --default-artifact-root $ENTRYPOINT_MINIO_URI`",multiple understanding environment variable used starting server start service docker compose build default port restart environment used connected list server test curl fail exit server host,issue,negative,negative,negative,negative,negative,negative
1935862420,"- On master branch, the `Run pre-commit` step takes 2m 30s on average.
- On this PR, I ran the same step three times.
  - Attempt 1: 1m 43s
  - Attempt 2: 1m 35s
  - Attempt 3: 1m 34s

It's 50~60s faster.",master branch run step average ran step three time attempt attempt attempt faster,issue,negative,negative,negative,negative,negative,negative
1935849298,This is embarrassing but it turns out that the password manager I am using (1password) did not update my credentials in the browser extension (which I use to retrieve my secrets) - despite being updated in the 1password portal... I somehow missed this discrepancy. A good reminder to always triple check secrets lol. Apologies for the false alarm @harupy.,embarrassing turn password manager password update browser extension use retrieve despite password portal somehow discrepancy good reminder always triple check false alarm,issue,negative,positive,positive,positive,positive,positive
1935803733,"@ai-learner-00 I was able to reproduce the same issue. Filed #11049 as a fix. This PR can be tested using the following command:

```
pip install git+https://github.com/mlflow/mlflow.git@refs/pull/11080/merge
```",able reproduce issue fix tested following command pip install,issue,negative,positive,positive,positive,positive,positive
1935743041,"I have users in my application, so instead of creating the users again in MLFLOW database can I use my application users table for authentication and redirect to MLFLOW dashboard.
Is there any other methods to login to **MLFLOW  UI**. (kind of auto login without manually providing the username and password).
Hi I have the Django application with having the JWT integration is their any possible way to integrate that with the MLFLOW **def autheticate_request()** and send the **bearer token** from the UI headers.

Can you suggest all possible ways to bypass the authentication page or **auto login** to MLFLOW dashboard by having the Authorization function in mlflow application server.

If I have to write the custom flask application to make available for python installable.
MLFLOW documentation said _""If your organization desires more advanced authentication logic (e.g., token-based authentication), it is possible to install a third party plugin or to create your own plugin.""_
How to write the custom code?
Any guidance or best practices for securely integrating with the MLflow UI would be greatly appreciated.",application instead use application table authentication redirect dashboard login kind auto login without manually providing password hi application integration possible way integrate send bearer token suggest possible way bypass authentication page auto login dashboard authorization function application server write custom flask application make available python documentation said organization advanced authentication logic authentication possible install third party create write custom code guidance best securely would greatly,issue,positive,positive,positive,positive,positive,positive
1935728539,"@harrystuart can you try the following? Does it work?

```
os.environ[""MLFLOW_TRACKING_USERNAME""] = ""admin""
os.environ[""MLFLOW_TRACKING_PASSWORD""] = ""password""
```",try following work password,issue,negative,neutral,neutral,neutral,neutral,neutral
1935718042,@acn-thanapat-sontayasara Thanks for reporting this issue! I was able to reproduce it. We're investigating how to fix this.,thanks issue able reproduce investigating fix,issue,negative,positive,positive,positive,positive,positive
1935581271,"Update on this:

I've just found out that even when not in the `Shared` directory but start with `/Workspace/`,
it also fails to check for experiment existence.
<img width=""1080"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/113094208/3be08a74-4c2c-4c12-8227-b04d5d33dc41"">

Without `/Workspace/`, it works perfectly fine.
<img width=""1147"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/113094208/8249b25d-8219-4d31-885f-205c8945dcfa"">
",update found even directory start also check experiment existence image without work perfectly fine image,issue,negative,positive,positive,positive,positive,positive
1935542176,"Hi @BenWilson2 , I've just updated docs and add examples for the provider.

Can you check it @BenWilson2 ?

Are you planning to add the PR in your next patch version 2.10.2 ?",hi add provider check add next patch version,issue,negative,neutral,neutral,neutral,neutral,neutral
1935429859,"hey @harupy @AdamXenith ! We have a fix for this in the EDGE code already: the markers will be displayed only when visible data points are sparse (<60 points in viewport), otherwise they are hidden and the data trace should be smooth. The fix will be merged into master within next sync.",hey fix edge code already displayed visible data sparse otherwise hidden data trace smooth fix master within next sync,issue,negative,positive,neutral,neutral,positive,positive
1935304412,"<!-- documentation preview -->


Documentation preview for 80935fd5f5f76e7bc8cd00acb299c6485049a96a will be available [here](https://output.circle-artifacts.com/output/job/fb2ed8e0-036b-4548-b31f-4cde8e35bafd/artifacts/0/docs/build/html/index.html) when [this CircleCI job](https://circleci.com/gh/mlflow/mlflow/89694) completes successfully.

<details>
<summary>More info</summary>

- Ignore this comment if this PR does not change the documentation.
- It takes a few minutes for the preview to be available.
- The preview is updated when a new commit is pushed to this PR.
- This comment was created by https://github.com/mlflow/mlflow/actions/runs/7839491757.

</details>
",documentation preview documentation preview available job successfully summary ignore comment change documentation preview available preview new commit comment,issue,negative,positive,positive,positive,positive,positive
1935173433,"> Hey @DougTrajano can you rebase on master and then ping me so that I can retrigger CI?

Done @BenWilson2. Can you retrigger CI pls?",hey rebase master ping done,issue,negative,neutral,neutral,neutral,neutral,neutral
1935086158,"@BenWilson2 will this be a good candidate also for the changes to support OpenAI 1.X? @georgemarlow, I guess we can add an environment variable, but I guess it can be a bit specific. We have a couple of URL hardcorded on variables:

https://github.com/mlflow/mlflow/blob/ce5f2ebfb641b5aced1e6b14ac4e8a388607e632/mlflow/utils/openai_utils.py#L32-L34

I guess we can add it there and then you can set it to whatever value you need. That would help, but since you are deploying on Azure Databricks, not sure if how you would set that during deployment (of course, you can just wrap a `pyfunc` on it and you are good to go).

Any thoughts?",good candidate also support guess add environment variable guess bit specific couple guess add set whatever value need would help since azure sure would set deployment course wrap good go,issue,positive,positive,positive,positive,positive,positive
1934577037,"Hi @serena-ruan, can anyone review the PR please?",hi anyone review please,issue,negative,neutral,neutral,neutral,neutral,neutral
1934536808,"Hi @santiagxf, hope you're well! Do you have a view on how this should be implemented? Happy to submit a PR if that's helpful",hi hope well view happy submit helpful,issue,positive,positive,positive,positive,positive,positive
1934367964,Hey @DougTrajano can you rebase on master and then ping me so that I can retrigger CI?,hey rebase master ping,issue,negative,neutral,neutral,neutral,neutral,neutral
1934280858,"Wow! @ridhimag11 @hubertzub-db thanks for the quick response and fix. I have updated to 2.10.1 and now I can see the datasets for each run. Great job!

Also, I have just realized the aliases are not showing on the UI when I access the versions of a registered model. In order to do that, I have to enter on each version at a time to see its alias. Is this an already mapped fix or am I missing something?

![Captura de Tela 2024-02-08 às 11 47 46](https://github.com/mlflow/mlflow/assets/3266556/5fae1c6f-e475-48a1-af22-b5d1d09d7e69)

![Captura de Tela 2024-02-08 às 11 50 06](https://github.com/mlflow/mlflow/assets/3266556/0f93a9cc-877e-4327-a4ce-298ae8d4ab23)

",wow thanks quick response fix see run great job also showing access registered model order enter version time see alias already fix missing something de de,issue,positive,positive,positive,positive,positive,positive
1934279704,"@sateeshmannar sorry for not being more clear. I was simply stating to rename your proposed argument to use `model_format` instead of something else. I was trying to elucidate that you should mimic the behavior that the xgboost implementation uses so that there is a consistent experience across different MLflow model flavors for identical behavior. Defaulting this argument to a backwards-compatible value to ensure that models saved in older versions of MLflow can be loaded without issue is the main goal for this. 
",sorry clear simply rename argument use instead something else trying elucidate mimic behavior implementation consistent experience across different model identical behavior argument value ensure saved older loaded without issue main goal,issue,positive,positive,neutral,neutral,positive,positive
1934203096,"@harupy I did try `mlflow.gateway.set_gateway_uri(""http://localhost:7000"")`, but got an error when calling `loaded_model.predict(pd.DataFrame(data))`:
```
---------------------------------------------------------------------------
HTTPError                                 Traceback (most recent call last)
File c:\Users\_\miniconda3\envs\ml-3.10\lib\site-packages\mlflow\utils\request_utils.py:63, in augmented_raise_for_status(response)
     62 try:
---> 63     response.raise_for_status()
     64 except HTTPError as e:

File c:\Users\_\miniconda3\envs\ml-3.10\lib\site-packages\requests\models.py:1021, in Response.raise_for_status(self)
   1020 if http_error_msg:
-> 1021     raise HTTPError(http_error_msg, response=self)

HTTPError: 400 Client Error: Bad Request for url: http://localhost:7000/gateway/completions/invocations

During handling of the above exception, another exception occurred:

HTTPError                                 Traceback (most recent call last)
Cell In[14], line 17
     14 print(data)
     16 import pandas as pd
---> 17 loaded_model.predict(pd.DataFrame(data))

File c:\Users\_\miniconda3\envs\ml-3.10\lib\site-packages\mlflow\pyfunc\__init__.py:501, in PyFuncModel.predict(self, data, params)
    498         if _MLFLOW_TESTING.get():
    499             raise
--> 501 return _predict()

File c:\Users\_\miniconda3\envs\ml-3.10\lib\site-packages\mlflow\pyfunc\__init__.py:489, in PyFuncModel.predict.<locals>._predict()
    487     return self._predict_fn(data, params=params)
    488 _log_warning_if_params_not_in_predict_signature(_logger, params)
--> 489 return self._predict_fn(data)

File c:\Users\_\miniconda3\envs\ml-3.10\lib\site-packages\mlflow\promptlab\__init__.py:37, in _PromptlabModel.predict(self, inputs)
     34     model_parameters_as_dict = {param.key: param.value for param in self.model_parameters}
     35     query_data = self._construct_query_data(prompt)
---> 37     response = query(
     38         route=self.model_route, data={**query_data, **model_parameters_as_dict}
     39     )
     40     results.append(self._parse_gateway_response(response))
     42 return results

File c:\Users\_\miniconda3\envs\ml-3.10\lib\site-packages\mlflow\gateway\utils.py:144, in gateway_deprecated.<locals>.wrapper(*args, **kwargs)
    141 @functools.wraps(obj)
    142 def wrapper(*args, **kwargs):
    143     warnings.warn(msg, FutureWarning, stacklevel=2)
--> 144     return obj(*args, **kwargs)

File c:\Users\_\miniconda3\envs\ml-3.10\lib\site-packages\mlflow\gateway\fluent.py:254, in query(route, data)
    188 @gateway_deprecated
    189 def query(route: str, data):
    190     """"""
    191     Issues a query request to a configured service through a named route on the Gateway Server.
    192     This function will interface with a configured route name (examples below) and return the
   (...)
    252         )
    253     """"""
--> 254     return MlflowGatewayClient().query(route, data)

File c:\Users\_\miniconda3\envs\ml-3.10\lib\site-packages\mlflow\gateway\utils.py:144, in gateway_deprecated.<locals>.wrapper(*args, **kwargs)
    141 @functools.wraps(obj)
    142 def wrapper(*args, **kwargs):
    143     warnings.warn(msg, FutureWarning, stacklevel=2)
--> 144     return obj(*args, **kwargs)

File c:\Users\_\miniconda3\envs\ml-3.10\lib\site-packages\mlflow\gateway\client.py:361, in MlflowGatewayClient.query(self, route, data)
    358 query_route = assemble_uri_path([MLFLOW_GATEWAY_ROUTE_BASE, route, MLFLOW_QUERY_SUFFIX])
    360 try:
--> 361     return self._call_endpoint(""POST"", query_route, data).json()
    362 except MlflowException as e:
    363     if isinstance(e.__cause__, requests.exceptions.Timeout):

File c:\Users\_\miniconda3\envs\ml-3.10\lib\site-packages\mlflow\gateway\client.py:106, in MlflowGatewayClient._call_endpoint(self, method, route, json_body)
     95     call_kwargs[""json""] = json_body
     97 response = http_request(
     98     host_creds=self._host_creds,
     99     endpoint=route,
   (...)
    104     **call_kwargs,
    105 )
--> 106 augmented_raise_for_status(response)
    107 return response

File c:\Users\_\miniconda3\envs\ml-3.10\lib\site-packages\mlflow\utils\request_utils.py:66, in augmented_raise_for_status(response)
     64 except HTTPError as e:
     65     if response.text:
---> 66         raise HTTPError(
     67             f""{e}. Response text: {response.text}"", request=e.request, response=e.response
     68         )
     69     else:
     70         raise e

HTTPError: 400 Client Error: Bad Request for url: http://localhost:7000/gateway/completions/invocations. Response text: {""detail"":""Unrecognized request argument supplied: route_type""}
```

The same error occurs when calling `evaluate`.

```
with mlflow.start_run():
    results = mlflow.evaluate(
        model=logged_model,
        data=data,
        # targets=""ground_truth"",
        model_type=""text-summarization"",
    )
```
```
---------------------------------------------------------------------------
HTTPError                                 Traceback (most recent call last)
File c:\Users\_\miniconda3\envs\ml-3.10\lib\site-packages\mlflow\utils\request_utils.py:63, in augmented_raise_for_status(response)
     62 try:
---> 63     response.raise_for_status()
     64 except HTTPError as e:

File c:\Users\_\miniconda3\envs\ml-3.10\lib\site-packages\requests\models.py:1021, in Response.raise_for_status(self)
   1020 if http_error_msg:
-> 1021     raise HTTPError(http_error_msg, response=self)

HTTPError: 400 Client Error: Bad Request for url: http://localhost:7000/gateway/completions/invocations

During handling of the above exception, another exception occurred:

HTTPError                                 Traceback (most recent call last)
Cell In[17], line 20
     17 # loaded_model.predict(pd.DataFrame(data))
     19 with mlflow.start_run():
---> 20     results = mlflow.evaluate(
     21         model=logged_model,
     22         data=data,
     23         # targets=""ground_truth"",
     24         model_type=""text-summarization"",
     25     )

File c:\Users\_\miniconda3\envs\ml-3.10\lib\site-packages\mlflow\models\evaluation\base.py:1880, in evaluate(model, data, model_type, targets, predictions, dataset_path, feature_names, evaluators, evaluator_config, custom_metrics, extra_metrics, custom_artifacts, validation_thresholds, baseline_model, env_manager, model_config, baseline_config)
   1877 predictions_expected_in_model_output = predictions if model is not None else None
   1879 try:
-> 1880     evaluate_result = _evaluate(
   1881         model=model,
   1882         model_type=model_type,
   1883         dataset=dataset,
   1884         run_id=run_id,
   1885         evaluator_name_list=evaluator_name_list,
   1886         evaluator_name_to_conf_map=evaluator_name_to_conf_map,
   1887         custom_metrics=custom_metrics,
   1888         extra_metrics=extra_metrics,
   1889         custom_artifacts=custom_artifacts,
   1890         baseline_model=baseline_model,
   1891         predictions=predictions_expected_in_model_output,
   1892     )
   1893 finally:
   1894     if isinstance(model, _ServedPyFuncModel):

File c:\Users\_\miniconda3\envs\ml-3.10\lib\site-packages\mlflow\models\evaluation\base.py:1120, in _evaluate(model, model_type, dataset, run_id, evaluator_name_list, evaluator_name_to_conf_map, custom_metrics, extra_metrics, custom_artifacts, baseline_model, predictions)
   1118     if evaluator.can_evaluate(model_type=model_type, evaluator_config=config):
   1119         _logger.info(f""Evaluating the model with the {evaluator_name} evaluator."")
-> 1120         eval_result = evaluator.evaluate(
   1121             model=model,
   1122             model_type=model_type,
   1123             dataset=dataset,
   1124             run_id=run_id,
   1125             evaluator_config=config,
   1126             custom_metrics=custom_metrics,
   1127             extra_metrics=extra_metrics,
   1128             custom_artifacts=custom_artifacts,
   1129             baseline_model=baseline_model,
   1130             predictions=predictions,
   1131         )
   1132         eval_results.append(eval_result)
   1134 _last_failed_evaluator = None

File c:\Users\_\miniconda3\envs\ml-3.10\lib\site-packages\mlflow\models\evaluation\default_evaluator.py:1883, in DefaultEvaluator.evaluate(self, model_type, dataset, run_id, evaluator_config, model, custom_metrics, extra_metrics, custom_artifacts, baseline_model, predictions, **kwargs)
   1881     if baseline_model:
   1882         _logger.info(""Evaluating candidate model:"")
-> 1883     evaluation_result = self._evaluate(model, is_baseline_model=False)
   1885 if not baseline_model:
   1886     return evaluation_result

File c:\Users\_\miniconda3\envs\ml-3.10\lib\site-packages\mlflow\models\evaluation\default_evaluator.py:1734, in DefaultEvaluator._evaluate(self, model, is_baseline_model, **kwargs)
   1732         self.extra_metrics.remove(extra_metric)
   1733         break
-> 1734 self._generate_model_predictions(compute_latency=compute_latency)
   1735 if self.model_type in (_ModelType.CLASSIFIER, _ModelType.REGRESSOR):
   1736     self._compute_builtin_metrics()

File c:\Users\_\miniconda3\envs\ml-3.10\lib\site-packages\mlflow\models\evaluation\default_evaluator.py:1369, in DefaultEvaluator._generate_model_predictions(self, compute_latency)
   1367         model_predictions = predict_with_latency(X_copy)
   1368     else:
-> 1369         model_predictions = self.model.predict(X_copy)
   1370 else:
   1371     if self.dataset.predictions_data is None:

File c:\Users\_\miniconda3\envs\ml-3.10\lib\site-packages\mlflow\pyfunc\__init__.py:501, in PyFuncModel.predict(self, data, params)
    498         if _MLFLOW_TESTING.get():
    499             raise
--> 501 return _predict()

File c:\Users\_\miniconda3\envs\ml-3.10\lib\site-packages\mlflow\pyfunc\__init__.py:489, in PyFuncModel.predict.<locals>._predict()
    487     return self._predict_fn(data, params=params)
    488 _log_warning_if_params_not_in_predict_signature(_logger, params)
--> 489 return self._predict_fn(data)

File c:\Users\_\miniconda3\envs\ml-3.10\lib\site-packages\mlflow\promptlab\__init__.py:37, in _PromptlabModel.predict(self, inputs)
     34     model_parameters_as_dict = {param.key: param.value for param in self.model_parameters}
     35     query_data = self._construct_query_data(prompt)
---> 37     response = query(
     38         route=self.model_route, data={**query_data, **model_parameters_as_dict}
     39     )
     40     results.append(self._parse_gateway_response(response))
     42 return results

File c:\Users\_\miniconda3\envs\ml-3.10\lib\site-packages\mlflow\gateway\utils.py:144, in gateway_deprecated.<locals>.wrapper(*args, **kwargs)
    141 @functools.wraps(obj)
    142 def wrapper(*args, **kwargs):
    143     warnings.warn(msg, FutureWarning, stacklevel=2)
--> 144     return obj(*args, **kwargs)

File c:\Users\_\miniconda3\envs\ml-3.10\lib\site-packages\mlflow\gateway\fluent.py:254, in query(route, data)
    188 @gateway_deprecated
    189 def query(route: str, data):
    190     """"""
    191     Issues a query request to a configured service through a named route on the Gateway Server.
    192     This function will interface with a configured route name (examples below) and return the
   (...)
    252         )
    253     """"""
--> 254     return MlflowGatewayClient().query(route, data)

File c:\Users\_\miniconda3\envs\ml-3.10\lib\site-packages\mlflow\gateway\utils.py:144, in gateway_deprecated.<locals>.wrapper(*args, **kwargs)
    141 @functools.wraps(obj)
    142 def wrapper(*args, **kwargs):
    143     warnings.warn(msg, FutureWarning, stacklevel=2)
--> 144     return obj(*args, **kwargs)

File c:\Users\_\miniconda3\envs\ml-3.10\lib\site-packages\mlflow\gateway\client.py:361, in MlflowGatewayClient.query(self, route, data)
    358 query_route = assemble_uri_path([MLFLOW_GATEWAY_ROUTE_BASE, route, MLFLOW_QUERY_SUFFIX])
    360 try:
--> 361     return self._call_endpoint(""POST"", query_route, data).json()
    362 except MlflowException as e:
    363     if isinstance(e.__cause__, requests.exceptions.Timeout):

File c:\Users\_\miniconda3\envs\ml-3.10\lib\site-packages\mlflow\gateway\client.py:106, in MlflowGatewayClient._call_endpoint(self, method, route, json_body)
     95     call_kwargs[""json""] = json_body
     97 response = http_request(
     98     host_creds=self._host_creds,
     99     endpoint=route,
   (...)
    104     **call_kwargs,
    105 )
--> 106 augmented_raise_for_status(response)
    107 return response

File c:\Users\_\miniconda3\envs\ml-3.10\lib\site-packages\mlflow\utils\request_utils.py:66, in augmented_raise_for_status(response)
     64 except HTTPError as e:
     65     if response.text:
---> 66         raise HTTPError(
     67             f""{e}. Response text: {response.text}"", request=e.request, response=e.response
     68         )
     69     else:
     70         raise e

HTTPError: 400 Client Error: Bad Request for url: http://localhost:7000/gateway/completions/invocations. Response text: {""detail"":""Unrecognized request argument supplied: route_type""}
```",try got error calling data recent call last file response try except file self raise client error bad request handling exception another exception recent call last cell line print data import data file self data raise return file return data return data file self param prompt response query response return file wrapper return file query route data query route data query request service route gateway server function interface route name return return route data file wrapper return file self route data route try return post data except file self method route response response return response file response except raise response text else raise client error bad request response text detail unrecognized request argument error calling evaluate recent call last file response try except file self raise client error bad request handling exception another exception recent call last cell line data file evaluate model data model none else none try finally model file model model none file self model candidate model model return file self model break file self else else none file self data raise return file return data return data file self param prompt response query response return file wrapper return file query route data query route data query request service route gateway server function interface route name return return route data file wrapper return file self route data route try return post data except file self method route response response return response file response except raise response text else raise client error bad request response text detail unrecognized request argument,issue,negative,negative,negative,negative,negative,negative
1934032137,"@BenWilson2 I will add 'model_format' as an additional attribute to h2o.yaml to indicate the type of model rf/xgb/glm - This will be a good addition. However, the proposed 'export_model_format' attribute was meant to specify the format the model was exported as binary/MOJO. Perhaps I should name  this parameter as 'model_export_format' or just 'export_format'?

h2o model passed via parameter 'h2o_model' to func log_model and save_model has an attribute 'algo' which will be used to set the 'model_format' attribute in h2o.yaml. So, no additional parameters are needed to be added to func log_model and save_model to save 'model_format'.
",add additional attribute indicate type model good addition however attribute meant specify format model perhaps name parameter ho model via parameter attribute used set attribute additional added save,issue,positive,positive,positive,positive,positive,positive
1933850193,"> > @gabrielfu
> > Postgresql db version: 15.4 psycopg2 version: psycopg2-binary==2.9.9
> > However, I have decided that I do not need the basic-auth setup nor any of the permissions (all users will have the same permissions) as provided by mlflow and it didn't feel too stable yet either (e.g. when I configure the auth db to use the postgresql db instead of the default sqlite, it fails, similar as to what is in issue #9155. Instead I had to create the authdb manually by running the statements that the sqlite produces. )
> > Instead, I opted for running mlflow without auth with a nginx frontend that handles the basic auth for me. So for me it is not necessary to solve this issue anymore and can be closed.
> 
> @cjidboon94 thanks for letting us know. We are planning to upgrade the authentication and your issue might help us on improving it.
> 
> My guess is the `id SERIAL NOT NULL` column did not get created properly. If you can share your postgresql log it'll be helpful.

This is all that I have with regards to the basicauth database. Can't find any other relevant logs (all other logs are either GCP cloudsql checks/heartbeats or related to other DBs, so I left those out). Not sure how much this helps, but good luck!
```
2024-01-26 10:42:22.542 UTC [34913]: [3-1] db=basicauth,user=postgres STATEMENT:  INSERT INTO experiment_permissions (experiment_id, user_id, permission) VALUES ('4', 1, 'MANAGE') RETURNING experiment_permissions.id
2024-01-26 10:42:22.542 UTC [34913]: [2-1] db=basicauth,user=postgres DETAIL:  Failing row contains (null, 4, 1, MANAGE).
2024-01-26 10:42:22.542 UTC [34913]: [1-1] db=basicauth,user=postgres ERROR:  null value in column """"id"""" of relation """"experiment_permissions"""" violates not-null constraint
2024-01-26 10:33:32.066 UTC [34916]: [3-1] db=basicauth,user=postgres STATEMENT:  INSERT INTO experiment_permissions (experiment_id, user_id, permission) VALUES ('3', 1, 'MANAGE') RETURNING experiment_permissions.id
2024-01-26 10:33:32.066 UTC [34916]: [2-1] db=basicauth,user=postgres DETAIL:  Failing row contains (null, 3, 1, MANAGE).
2024-01-26 10:33:32.066 UTC [34916]: [1-1] db=basicauth,user=postgres ERROR:  null value in column """"id"""" of relation """"experiment_permissions"""" violates not-null constraint
2024-01-26 09:46:46.982 UTC [18653]: [3-1] db=basicauth,user=postgres STATEMENT:  INSERT INTO experiment_permissions (experiment_id, user_id, permission) VALUES ('2', 1, 'MANAGE') RETURNING experiment_permissions.id
2024-01-26 09:46:46.982 UTC [18653]: [2-1] db=basicauth,user=postgres DETAIL:  Failing row contains (null, 2, 1, MANAGE).
2024-01-26 09:46:46.982 UTC [18653]: [1-1] db=basicauth,user=postgres ERROR:  null value in column """"id"""" of relation """"experiment_permissions"""" violates not-null constraint
2024-01-25 20:20:52.627 UTC [12823]: [3-1] db=basicauth,user=postgres STATEMENT:  INSERT INTO experiment_permissions (experiment_id, user_id, permission) VALUES ('1', 1, 'MANAGE') RETURNING experiment_permissions.id
2024-01-25 20:20:52.627 UTC [12823]: [2-1] db=basicauth,user=postgres DETAIL:  Failing row contains (null, 1, 1, MANAGE).
2024-01-25 20:20:52.627 UTC [12823]: [1-1] db=basicauth,user=postgres ERROR:  null value in column """"id"""" of relation """"experiment_permissions"""" violates not-null constraint
```",version version however decided need setup provided feel stable yet either configure use instead default similar issue instead create manually running instead running without basic necessary solve issue closed thanks u know upgrade authentication issue might help u improving guess id serial null column get properly share log helpful ca find relevant either related left sure much good luck statement insert permission detail failing row null manage error null value column id relation constraint statement insert permission detail failing row null manage error null value column id relation constraint statement insert permission detail failing row null manage error null value column id relation constraint statement insert permission detail failing row null manage error null value column id relation constraint,issue,positive,positive,positive,positive,positive,positive
1933695612,"> > Are you able to connect using basic username and password with changing nothing else about your container configuration? cc @gabrielfu
> 
> **Yes I am able to connect using basic username and password.**
> 
> import requests
> **Able to authenticate and fetch the data.**
> response = requests.get(r'http://<tracking_uri:5000/api/2.0/mlflow/experiments/search',json={""max_results"":10},auth=(""admin"",""password""))
> print(response)
> 
> **Not able to authenticate with the Bearer token even though setting the ENV variable MLFLOW_TRACKING_TOKEN = <random_string>**
> response = requests.get(r'http://<tracking_uri:5000/api/2.0/mlflow/experiments/search',json={""max_results"":10},headers={""Authorization"":f""Bearer <random_string>""})
> print(response)
> 

`MLFLOW_TRACKING_TOKEN` is intended for MLflow **client** querying a remote MLflow server.

Setting `MLFLOW_TRACKING_TOKEN` on the **server** has no effect.
",able connect basic password nothing else container configuration yes able connect basic password import able authenticate fetch data response print response able authenticate bearer token even though setting variable response print response intended client querying remote server setting server effect,issue,negative,positive,positive,positive,positive,positive
1933500872,"> Are you able to connect using basic username and password with changing nothing else about your container configuration? cc @gabrielfu

**Yes I am able to connect using basic username and password.**

import requests
**Able to authenticate and fetch the data.**
response = requests.get(r'http://<tracking_uri:5000/api/2.0/mlflow/experiments/search',json={""max_results"":10},auth=(""admin"",""password""))
print(response)

**Not able to authenticate with the Bearer token even though setting the ENV variable MLFLOW_TRACKING_TOKEN = <random_string>**
response = requests.get(r'http://<tracking_uri:5000/api/2.0/mlflow/experiments/search',json={""max_results"":10},headers={""Authorization"":f""Bearer <random_string>""})
print(response)
",able connect basic password nothing else container configuration yes able connect basic password import able authenticate fetch data response print response able authenticate bearer token even though setting variable response print response,issue,negative,positive,positive,positive,positive,positive
1933493469,"Example tests working fine:

https://app.circleci.com/pipelines/github/mlflow/mlflow/32590/workflows/750631a8-e454-43aa-b511-dc819b4e9e85/jobs/89525

<img width=""1271"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/17039389/0732a861-aad0-46d4-823f-047ac6c7fa15"">
",example working fine image,issue,negative,positive,positive,positive,positive,positive
1933401507,@ai-learner-00 Thanks for reporting this. It looks like we forgot to update `_PromptlabModel`. Does it work fine if you set `MLFLOW_GATEWAY_URI`?,thanks like forgot update work fine set,issue,positive,positive,positive,positive,positive,positive
1933310850,"If you would like to enable token-based authentication, you should configure `authorization_function` field in the [auth config](authorization_function). Setting `MLFLOW_TRACKING_TOKEN` on the server (docker container) does nothing.

If you did not configure the above, MLflow server expects basic auth. Your request is using bearer token and thus is undetected by MLflow server.",would like enable authentication configure field setting server docker container nothing configure server basic request bearer token thus undetected server,issue,negative,neutral,neutral,neutral,neutral,neutral
1933296881,"> > @serena-ruan given the error message in the original issue, i don't think an `experiment_permission` already exists. It should be postgres complaining `id` being null when creating new permission for some reason.
> > `mlflow.exceptions.RestException: RESOURCE_ALREADY_EXISTS: Experiment permission (experiment_id=3, username=admin) already exists. Error: (psycopg2.errors.NotNullViolation) null value in column ""id"" of relation ""experiment_permissions"" violates not-null constraint`
> > P.S. we can probably fix this confusing error code
> 
> Yes that's true, though I'm not sure why the id could be null... Would duplicate permissions be a problem when inserting into the table?

I cannot reproduce the error, can you? Either the `id` column didn't get created with `SERIAL` type, or the sequence is accidentally dropped?",given error message original issue think already id null new permission reason experiment permission already error null value column id relation constraint probably fix error code yes true though sure id could null would duplicate problem table reproduce error either id column get serial type sequence accidentally,issue,negative,positive,positive,positive,positive,positive
1933292957,"> @gabrielfu
> 
> Postgresql db version: 15.4 psycopg2 version: psycopg2-binary==2.9.9
> 
> However, I have decided that I do not need the basic-auth setup nor any of the permissions (all users will have the same permissions) as provided by mlflow and it didn't feel too stable yet either (e.g. when I configure the auth db to use the postgresql db instead of the default sqlite, it fails, similar as to what is in issue #9155. Instead I had to create the authdb manually by running the statements that the sqlite produces. )
> 
> Instead, I opted for running mlflow without auth with a nginx frontend that handles the basic auth for me. So for me it is not necessary to solve this issue anymore and can be closed.

@cjidboon94 thanks for letting us know. We are planning to upgrade the authentication and your issue might help us on improving it. 

My guess is the `id SERIAL NOT NULL` column did not get created properly. If you can share your postgresql log it'll be helpful.",version version however decided need setup provided feel stable yet either configure use instead default similar issue instead create manually running instead running without basic necessary solve issue closed thanks u know upgrade authentication issue might help u improving guess id serial null column get properly share log helpful,issue,positive,positive,neutral,neutral,positive,positive
1933253622,@BenWilson2 We changed the team review trigger to mlflow-automation which is accessible from anyone.,team review trigger accessible anyone,issue,negative,positive,positive,positive,positive,positive
1933215084,"I think you should ask them what might be wrong from the sagemaker logs, or ask them for the full stacktrace. BTW you've validated mlflow works fine in all other environment, so they shouldn't just ignore your ticket :(",think ask might wrong ask full work fine environment ignore ticket,issue,negative,positive,neutral,neutral,positive,positive
1933180606,"@sateeshmannar The plans sounds good to me. Can we standardize on the argument name to conform to this exact feature that exists within the xgboost implementation (`model_format`)?

For reference purposes, https://github.com/mlflow/mlflow/blob/b4067669d241131cf1d36451146802b01ace977c/mlflow/xgboost/__init__.py#L118 ",good standardize argument name conform exact feature within implementation reference,issue,negative,positive,positive,positive,positive,positive
1933145702,"@SiddharthSingi Have you tried `mlflow.log_text`?

```python
import mlflow

with mlflow.start_run():
    csv_text = ""a,b,c\n1,2,3\n4,5,6\n""
    mlflow.log_text(csv_text, ""data.csv"")
```

Note this creates a temporary CSV file locally and remove it after uploading it.",tried python import note temporary file locally remove,issue,negative,neutral,neutral,neutral,neutral,neutral
1933143894,"Seems pretty neat. We are looking into providing native support for OAuth2 in the next few months to greatly simplify and provide enhanced security for user and admin management of an MLflow tracking server. 
Beyond that, there isn't a great deal of guidance that we can give with your particular use case. 

You might want to look into creating a custom app plugin by extending the flask application with the additional logic for creating the signed JWT, setting the expiry state, and performing the validation from the client side. 

Tagging @gabrielfu for any additional context here (he implemented the feature :) )",pretty neat looking providing native support next greatly simplify provide enhanced security user management server beyond great deal guidance give particular use case might want look custom extending flask application additional logic setting expiry state validation client side additional context feature,issue,positive,positive,positive,positive,positive,positive
1933032073,Are you able to connect using basic username and password with changing nothing else about your container configuration? cc @gabrielfu ,able connect basic password nothing else container configuration,issue,negative,positive,positive,positive,positive,positive
1933023432,"@BenWilson2  Do you mean to use 'with mlflow_start_run()' instead of start and end commands ? Ofc! I did try and it didn't help resolve the problem. So, if you see the code snippet mentioned in this issue the mlflow_run() in run.R creates a run_id and then invokes the modelling.R. Then I would expect it to create separate run ids for each mlflow_start_run() and log everything whatever is under it under each run. But currently, it uses the run_id created by mlflow_run() and logs everything under a 'single' run . ",mean use instead start end try help resolve problem see code snippet issue would expect create separate run log everything whatever run currently everything run,issue,positive,negative,negative,negative,negative,negative
1933008771,"Are you looking to configure access to the registry store location for saving registered artifacts? I'm guessing that what you want to set is `MLFLOW_REGISTRY_STORE_URI` instead of `MLFLOW_REGISTRY_URI`. The first one is available for specifying the the URI to use for persistence of registered models and is configured during server initialization. The other is used internally within MLflow in helper and REST handlers to point to the registry store location (which, for your configuration, should be your minio instance). 

",looking configure access registry store location saving registered guessing want set instead first one available use persistence registered server used internally within helper rest point registry store location configuration instance,issue,negative,positive,positive,positive,positive,positive
1932490010,"Hi @BenWilson2 , could you please review the PR?",hi could please review,issue,negative,neutral,neutral,neutral,neutral,neutral
1931658753,"Oookie, it appears that I finally resolved the failed test `test_transformers_tf_model_log_without_conda_env_uses_default_env_with_expected_dependencies`... Basically there are two layers of bugs. One caused the test failure in this PR, and the other has been hiding the bug - making the test pass until now even tho it shouldn't.

### Prerequisite Knowledge: How we capture dependencies for Transformer models
Requirement inference is done by monitoring `import` event during the model loading (or model prediction if input_example is provided). For Transformer specifically, we repeat this for 3 times, to determine the model uses Tensorflow or Pytorch, or both (context). This is done by trial-and-error approach like following steps:

1. Try loading model with setting `USE_TORCH = True` and validate if there is no `tensorflow` import => If this passes, we can say the model only depends on Pytorch.
2. Then try loading with setting `USE_TF = True` and validate if there is no `torch` import => If this passes, we can say the model is only depends on Tensorflow.
3. Finally, if both failed, we record both Tensorflow and Pytorch as required.

This seems to work, but the import capturing is not as straightforward as it looks, caused a few bugs.

### Bug 1. Environment variable `USE_TF` / `USE_TORCH` is set after Transformers initiate the `_torch_available` flag.

Setting these environment variable is very important, as it does not only instruct the model to be loaded in the specified framework, but also **prevent Transformers from importing the other librariy**. For example, Transformer manages the binary state `_torch_available` that is used as a switch for many logic requireing Pytorch. This flag is set to True when Pytorch is installed, **and `USE_TF` is not set to ""True""**. As our test environment installs both Tensorflow and Pytorch, the `USE_TF` env variable is necessary to override this flag to False. 

However, the issue was that the flag is set only once when the Transformer library is imported first time. Hence, it won't be flipped when we set the env var after first import. At present we are setting the env var when starting the import capturing ([code](https://github.com/brynn-code/mlflow/blob/master/mlflow/utils/_capture_transformers_modules.py#L35-L43)), but indeed Transformer is imported earlier than that, and the flag is not set correctly. 

**Solution**
To resolve the issue, this latest revision in this PR modifies the logic to set the environment variable when starting the subprocess for model loading.


However, then the question is why the test has not failed until this PR, which relates to the next bug.

### Bug 2. Accelerate is installed for Tensorflow model and hides Pytorch in the logged requirements.
After MLflow captures all imported packages, MLflow doesn't use the list as they are. Instead, it trims down the list by remove packages that are installed by other packages anyway. For example, if the captured packges are ``[""scikit-learn"", ""numpy""]``, this pruning removes `numpy` because it is installed as a part of `scikit-learn` anyway.

What happened for the test before this PR is that, `accelerate` was captured as a model dependencies as well, and sinceit 
has `torch` as its core dependency, `torch` is pruned and not listed in the final requirements.txt. As a result, the assertion `assert ""torch"" not in ...` did not fail so far. However, the model requirements actually include Pytorch indirectly via accelerate.

**Solution**
On the latest revions in this PR, ***somehow*** accelerate is no longer captured as dependencies for Tensorflow model. I couldn't spot out what was the trigger of this change, but most likely the similar internal state handling of Transformers. While it leaves a bit of ambiguity, the new behavior is correct because accelerate only support Pytorch models i.e. should not be logged for Tensorflow model. Pytorch model still logs accelerate as dependency when it is installed (validates with `test_transformers_pt_model_save_without_conda_env_uses_default_env_with_expected_dependencies`).",finally resolved test basically two one test failure bug making test pas even tho prerequisite knowledge capture transformer requirement inference done import event model loading model prediction provided transformer specifically repeat time determine model context done approach like following try loading model setting true validate import say model try loading setting true validate torch import say model finally record work import straightforward bug environment variable set initiate flag setting environment variable important instruct model loaded framework also prevent example transformer binary state used switch many logic flag set true set true test environment variable necessary override flag false however issue flag set transformer library first time hence wo set first import present setting starting import code indeed transformer flag set correctly solution resolve issue latest revision logic set environment variable starting model loading however question test next bug bug accelerate model logged use list instead list remove anyway example pruning part anyway test accelerate model well torch core dependency torch listed final result assertion assert torch fail far however model actually include indirectly via accelerate solution latest somehow accelerate longer model could spot trigger change likely similar internal state handling leaf bit ambiguity new behavior correct accelerate support logged model model still accelerate dependency,issue,positive,positive,positive,positive,positive,positive
1931623082,"> @gabrielfu Manually tested both chat & streamed chat, works like a charm!
> 
> ```
> % curl -X 'POST' \
>   'http://127.0.0.1:7000/endpoints/chat/invocations' \
>   -H 'accept: application/json' \
>   -H 'Content-Type: application/json' \
>   -d '{
>   ""stream"": true,
>   ""messages"": [
>     {
>         ""role"": ""system"",
>         ""content"": ""When you are asked something, answer in Japanese.""
>     },
>     {
>       ""role"": ""user"",
>       ""content"": ""hello""
>     }
>   ]
> }'
> 
> data: {""id"":null,""object"":""chat.completion.chunk"",""created"":1707209587,""model"":""command"",""choices"":[{""index"":0,""finish_reason"":null,""delta"":{""role"":null,""content"":""こ""}}]}
> 
> data: {""id"":null,""object"":""chat.completion.chunk"",""created"":1707209587,""model"":""command"",""choices"":[{""index"":0,""finish_reason"":null,""delta"":{""role"":null,""content"":""ん""}}]}
> 
> data: {""id"":null,""object"":""chat.completion.chunk"",""created"":1707209587,""model"":""command"",""choices"":[{""index"":0,""finish_reason"":null,""delta"":{""role"":null,""content"":""に""}}]}
> 
> data: {""id"":null,""object"":""chat.completion.chunk"",""created"":1707209587,""model"":""command"",""choices"":[{""index"":0,""finish_reason"":null,""delta"":{""role"":null,""content"":""ち""}}]}
> 
> data: {""id"":null,""object"":""chat.completion.chunk"",""created"":1707209587,""model"":""command"",""choices"":[{""index"":0,""finish_reason"":null,""delta"":{""role"":null,""content"":""は""}}]}
> 
> data: {""id"":""e6707ce0-11ea-4e72-a29d-c554a44b53bb"",""object"":""chat.completion.chunk"",""created"":1707209587,""model"":""command"",""choices"":[{""index"":0,""finish_reason"":""COMPLETE"",""delta"":{""role"":null,""content"":null}}]}
> ```

This is interesting because I just asked the Cohere maintainer how to insert system prompt, and apparently the proper way is to use `preamble_override` field, instead of putting it in `chat_history`.

(see https://docs.cohere.com/reference/chat)

So I'm thinking of updating the logic:
- First ""system"" message (if present) goes to `preamble_override` field
- Any further ""system"" messages are ignored
- Last meesage goes to `message` field
- The remaining ""assistant"" and ""user"" messages (if present) go to `chat_history`

What do you think? @harupy 

P.S. pushed a new commit for this change",manually tested chat chat work like charm curl stream true role system content something answer role user content hello data id null object model command index null delta role null content data id null object model command index null delta role null content data id null object model command index null delta role null content data id null object model command index null delta role null content data id null object model command index null delta role null content data id object model command index complete delta role null content null interesting cohere maintainer insert system prompt apparently proper way use field instead see thinking logic first system message present go field system last go message field assistant user present go think new commit change,issue,positive,positive,positive,positive,positive,positive
1931524409,"Could you please review this later??  This is very simple, but useful bug fix related mlflow-website so I tagged (@BenWilson2 , @harupy )",could please review later simple useful bug fix related tagged,issue,positive,positive,neutral,neutral,positive,positive
1931423132,"@BenWilson2, thank you for your reply. I am indeed writing a plugin. 
my main issue is that I do not really get any information in my plugin code from mlflow, specifically inside:
def log_artifacts(self, local_dir, artifact_path=None)

specifically, I am missing the experiment id or run id.
and in the scenario I described, the artifact_path is also very partial and does not include experiment/run

is there a way for me to get these from mlflow at that point?",thank reply indeed writing main issue really get information code specifically inside self specifically missing experiment id run id scenario also partial include way get point,issue,negative,positive,neutral,neutral,positive,positive
1931145496,Looks good to me once we move the directory structure as @harupy mentioned. ,good move directory structure,issue,negative,positive,positive,positive,positive,positive
1931132589,"hmmm the failure of `test_transformers_tf_model_log_without_conda_env_uses_default_env_with_expected_dependencies` is so weird, I can't reproduce it with the same package versions.
```
tests/transformers/test_transformers_model_export.py::test_transformers_tf_model_log_without_conda_env_uses_default_env_with_expected_dependencies PASSED | MEM 1.6/61.8 GB | DISK 205.3/484.6 GB [100%]
```",failure weird ca reproduce package mem disk,issue,negative,negative,negative,negative,negative,negative
1931029978,"overall it looks good to me, i think this is a great idea especially if the default signatures are good enough for typical use-cases!

i agree that we probably wait for someone to raise a feature request if we want the timeout to be configurable, but i do think 60 seconds is a bit short based on my own usage of transformers (though not sure if i've been doing things in an optimized way). maybe we can increase the timeout?

it looks like there are some test failures but happy to accept after those are resolved and if nobody else has any concerns!",overall good think great idea especially default good enough typical agree probably wait someone raise feature request want think bit short based usage though sure way maybe increase like test happy accept resolved nobody else,issue,positive,positive,positive,positive,positive,positive
1931016174,"> It's the cross version testing failure again, sigh... could you help merge? thanks!

Have you checked the failure logs?

https://github.com/mlflow/mlflow/actions/runs/7792488807/job/21250609889?pr=10981


```
==================================== ERRORS ====================================
__ ERROR at setup of test_enabling_autologging_throws_for_wrong_spark_version __

thing = <module 'mlflow.spark' from '/home/runner/work/mlflow/mlflow/mlflow/spark/__init__.py'>
comp = '_autolog', import_path = 'mlflow.spark._autolog'

    def _dot_lookup(thing, comp, import_path):
        try:
>           return getattr(thing, comp)
E           AttributeError: module 'mlflow.spark' has no attribute '_autolog'

comp       = '_autolog'
import_path = 'mlflow.spark._autolog'
thing      = <module 'mlflow.spark' from '/home/runner/work/mlflow/mlflow/mlflow/spark/__init__.py'>
```",cross version testing failure sigh could help merge thanks checked failure error setup thing module thing try return thing module attribute thing module,issue,negative,negative,negative,negative,negative,negative
1931015044,"@chenmoneygithub 

>  because it has a name conflict with the function mlflow.spark.autolog()

Can you elaborate? How does a module name conflict with a function name?",name conflict function elaborate module name conflict function name,issue,negative,positive,positive,positive,positive,positive
1930548829,"yes , may be I didn't clear out enough , but I mean when you select many trials from the table and press compare button , a window with parallel view figure opens , this figure is not interactive as the figure you showed in the video.",yes may clear enough mean select many table press compare button window parallel view figure figure interactive figure video,issue,positive,positive,neutral,neutral,positive,positive
1930531854,"@harupy It's the cross version testing failure again, sigh... could you help merge? thanks!

btw, I am naming it `autologging.py` instead of `autolog.py` because it has a name conflict with the function `mlflow.spark.autolog()`, which isn't an issue on my laptop, but had CI failures. I think that's caused by python version mismatch. For simplicity, I'm using the name `autologging.py`.",cross version testing failure sigh could help merge thanks naming instead name conflict function issue think python version mismatch simplicity name,issue,negative,negative,neutral,neutral,negative,negative
1930511466,"@mendelson hey, a quick update: datasets should be back in freshly released 2.10.1 patch: 
https://github.com/mlflow/mlflow/releases/tag/v2.10.1",hey quick update back freshly patch,issue,negative,positive,positive,positive,positive,positive
1930507190,"@ridhimag11 thanks for the reply! I'm looking forward to the new version.

Regarding the datasets in the `Columns` dropdown, would you please be able to show me where that is? The `Columns` dropdown I'm looking at has no further options besides the one I already see in the run details.

![Captura de Tela 2024-02-06 às 15 15 45](https://github.com/mlflow/mlflow/assets/3266556/4bd6cbb0-08c3-4c70-b9ef-dd092dd418b3)
",thanks reply looking forward new version regarding would please able show looking besides one already see run de,issue,positive,positive,positive,positive,positive,positive
1930402695,hi @emsi thanks for the feedback. This is a known issue and we plan to roll out some updates for a fix in the next few weeks. ,hi thanks feedback known issue plan roll fix next,issue,negative,positive,neutral,neutral,positive,positive
1930400020,"@mendelson thank you for sharing this. Super helpful. We are planning to roll-out a new version of the run details page in the next few weeks, which will have the dataset values shown more clearly. We'll send you an update when that launches. 

In the meantime, for seeing the dataset values for a run, you can add the dataset column from the ""Columns"" dropdown in the header. Let me know if you have any further questions.",thank super helpful new version run page next shown clearly send update seeing run add column header let know,issue,positive,positive,positive,positive,positive,positive
1930387868,"@15890cle @gabriel-salgueiro-ey to use the new chat.completions it will be `task = ""chat.completion""` instead of `task = openai.ChatCompletion`",use new task instead task,issue,negative,positive,positive,positive,positive,positive
1930355319,Thanks for your response @BenWilson2 any guidance on how to build the tracking server docker image,thanks response guidance build server docker image,issue,negative,positive,positive,positive,positive,positive
1930351377,"We don't have any examples of how to wrap MLflow APIs in this way, but there are plenty of examples within MLflow's source code of patching functionality in other libraries to modify behavior of an installed library when used. You could monkeypatch the MLflow server startup logic to create the initial experiment, but as far as removing the Default Experiment, that might be a bit complex as the tracking store backends require its existence in order to perform validation checks when certain API calls are made. 
Best of luck with whichever path you choose (private fork or patching). I'm sorry that I can't provide much more guidance here as there are far too many nuanced design considerations that would need to be thought through to provide any salient and concrete advice. ",wrap way plenty within source code functionality modify behavior library used could server logic create initial experiment far removing default experiment might bit complex store require existence order perform validation certain made best luck whichever path choose private fork sorry ca provide much guidance far many design would need thought provide salient concrete advice,issue,positive,positive,positive,positive,positive,positive
1930166447,"Thanks Ben! Yeah, on top of that I run mlflow from within metaflow, and it seems that it ""switches"" registry URI between steps (even on local execution).  I fixed by setting URI again before pulling (even though I had it as `MLFLOW_REGISTRY_URI` and `MLFLOW_TRACKING_URI` env vars.

FWIW I noticed that in the documentation both tracking and registry uri are set to `mlruns.db` sqlite without much explanation which one is relevant and if they should be the same, so perhaps some explanation would be benefitial
",thanks ben yeah top run within registry even local execution fixed setting even though documentation registry set without much explanation one relevant perhaps explanation would,issue,positive,positive,positive,positive,positive,positive
1929922851,"@BenWilson2 
1) In order to fork the repository and build the tracking server image in our organization , do we have any instructions or pipelines that we can look at.

2) We are ensuring that an experiment is always created when the tracking server is launched and all runs will get diverted to that experiment",order fork repository build server image organization look experiment always server get experiment,issue,negative,neutral,neutral,neutral,neutral,neutral
1929317525,"@elvira-salakhova-r I couldn't reproduce the bug on `v2.9.2` nor on the latest version (videos attached). Can you confirm the bug still persists on the latest version from `master` branch, i.e. `v2.10.1`? If true: is it possible for you to record the screen while having browser developer tools -> ""Network"" tab open?

https://github.com/mlflow/mlflow/assets/104438646/f3dcd305-3396-45b2-b9d1-bff3c2c5e389

https://github.com/mlflow/mlflow/assets/104438646/d8f94ee8-03b4-4452-8907-c1fca14bd470

",could reproduce bug latest version attached confirm bug still latest version master branch true possible record screen browser developer network tab open,issue,negative,positive,positive,positive,positive,positive
1929092135,"> Hi @thnguyendn great stuff! Could you add an entry in the integration suite for this provider? https://github.com/mlflow/mlflow/blob/master/tests/gateway/test_integration.py

Hi, @BenWilson2 , a new commit has been added to add entry in integration suite for the provider",hi great stuff could add entry integration suite provider hi new commit added add entry integration suite provider,issue,positive,positive,positive,positive,positive,positive
1929071873,"@BenWilson2 The `custom_lib` is the following file :
```Python
import os
import mlflow
from mlflow import MlflowClient

from dagster import ConfigurableResource, InitResourceContext
from pydantic import PrivateAttr


class MLFlowResource(ConfigurableResource):
    tracking_uri: str
    registry_uri: str
    aws_access_key_id: str
    aws_secret_access_key: str

    _client_instance: MlflowClient = PrivateAttr()

    @property
    def client(self) -> MlflowClient:
        return self._client_instance

    def setup_for_execution(self, context: InitResourceContext) -> None:
        self._client_instance = MlflowClient(self.tracking_uri, self.registry_uri)
        # To have access to S3 artifacts
        os.environ[""AWS_ACCESS_KEY_ID""] = self.aws_access_key_id
        os.environ[""AWS_SECRET_ACCESS_KEY""] = self.aws_secret_access_key
        os.environ[""MLFLOW_S3_ENDPOINT_URL""] = self.registry_uri
        os.environ[""MLFLOW_REGISTRY_URI ""] = self.registry_uri
        os.environ[""MLFLOW_TRACKING_URI ""] = self.tracking_uri
```

I am in Dagster context, I've tried their integration but not super useful and easy to use, so I prefered to use native MLFlowClient injected in each Dagster asset. However, I can interact with all the APIs using MLFlowClient correctly, but at least not the one for `create_registered_model(""model"", description=""toto"")` as explained above, the tracking server is living in localhost:5000 where the API should live (my mlflow), but the registry URI is localhost:8889 which is my minIO used to store artifacts.

The mlflow library seems to use localhost:8889 over localhost:5000 as hostname for api call, and I don't know why...",following file python import o import import import import class property client self return self context none access context tried integration super useful easy use use native asset however interact correctly least one model toto server living live registry used store library use call know,issue,positive,positive,positive,positive,positive,positive
1929034241,"@gabrielfu Manually tested both chat & streamed chat, works like a charm!


```
% curl -X 'POST' \
  'http://127.0.0.1:7000/endpoints/chat/invocations' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{
  ""stream"": true,
  ""messages"": [
    {
        ""role"": ""system"",
        ""content"": ""When you are asked something, answer in Japanese.""
    },
    {
      ""role"": ""user"",
      ""content"": ""hello""
    }
  ]
}'

data: {""id"":null,""object"":""chat.completion.chunk"",""created"":1707209587,""model"":""command"",""choices"":[{""index"":0,""finish_reason"":null,""delta"":{""role"":null,""content"":""こ""}}]}

data: {""id"":null,""object"":""chat.completion.chunk"",""created"":1707209587,""model"":""command"",""choices"":[{""index"":0,""finish_reason"":null,""delta"":{""role"":null,""content"":""ん""}}]}

data: {""id"":null,""object"":""chat.completion.chunk"",""created"":1707209587,""model"":""command"",""choices"":[{""index"":0,""finish_reason"":null,""delta"":{""role"":null,""content"":""に""}}]}

data: {""id"":null,""object"":""chat.completion.chunk"",""created"":1707209587,""model"":""command"",""choices"":[{""index"":0,""finish_reason"":null,""delta"":{""role"":null,""content"":""ち""}}]}

data: {""id"":null,""object"":""chat.completion.chunk"",""created"":1707209587,""model"":""command"",""choices"":[{""index"":0,""finish_reason"":null,""delta"":{""role"":null,""content"":""は""}}]}

data: {""id"":""e6707ce0-11ea-4e72-a29d-c554a44b53bb"",""object"":""chat.completion.chunk"",""created"":1707209587,""model"":""command"",""choices"":[{""index"":0,""finish_reason"":""COMPLETE"",""delta"":{""role"":null,""content"":null}}]}
```",manually tested chat chat work like charm curl stream true role system content something answer role user content hello data id null object model command index null delta role null content data id null object model command index null delta role null content data id null object model command index null delta role null content data id null object model command index null delta role null content data id null object model command index null delta role null content data id object model command index complete delta role null content null,issue,positive,positive,positive,positive,positive,positive
1929011042,"I have already opened a case on their side and as soon as they see mlflow in the process they throw the "" We apologize but we do not support third party tool, please open a ticket on mlflow side"", hence why I am here ...",already case side soon see process throw apologize support third party tool please open ticket side hence,issue,positive,neutral,neutral,neutral,neutral,neutral
1928980389,"cc @harupy @B-Step62 @serena-ruan, does anyone want to add anything else?",anyone want add anything else,issue,negative,neutral,neutral,neutral,neutral,neutral
1928956041,"x version tests failing due to a test infra issue that was fixed in #10925, and does not affect the mlflow package itself",version failing due test infra issue fixed affect package,issue,negative,negative,neutral,neutral,negative,negative
1928898664,Then I think the best effort would be log each class's metric value separately as now mlflow metric doesn't support lists.,think best effort would log class metric value separately metric support,issue,positive,positive,positive,positive,positive,positive
1928894121,"I think in such case it's sagemaker's problem, from you stacktrace it's like `out of memory`, could you open a ticket to AWS support instead?",think case problem like memory could open ticket support instead,issue,negative,neutral,neutral,neutral,neutral,neutral
1928861443,"> can you run the doctor command (or, alternatively, just run `pip freeze`) and report the results here? I think your version of pydantic is incompatible.

I have latest pydantic version installed, but perhaps a downgrade is needed?

```
aiofiles==23.2.1
alembic==1.13.1
altair==5.2.0
aniso8601==9.0.1
annotated-types==0.6.0
anyio==3.7.1
asttokens @ file:///home/conda/feedstock_root/build_artifacts/asttokens_1698341106958/work
attrs==23.1.0
backports.functools-lru-cache @ file:///home/conda/feedstock_root/build_artifacts/backports.functools_lru_cache_1687772187254/work
blinker==1.7.0
certifi==2023.11.17
charset-normalizer==3.3.2
click==8.1.7
cloudpickle==3.0.0
colorama @ file:///home/conda/feedstock_root/build_artifacts/colorama_1666700638685/work
comm @ file:///home/conda/feedstock_root/build_artifacts/comm_1691044910542/work
contourpy==1.2.0
cycler==0.12.1
databricks-cli==0.18.0
debugpy @ file:///D:/bld/debugpy_1695534453785/work
decorator @ file:///home/conda/feedstock_root/build_artifacts/decorator_1641555617451/work
docker==7.0.0
entrypoints==0.4
exceptiongroup @ file:///home/conda/feedstock_root/build_artifacts/exceptiongroup_1692026125334/work
executing @ file:///home/conda/feedstock_root/build_artifacts/executing_1698579936712/work
fastapi==0.105.0
fastjsonschema==2.19.0
ffmpy==0.3.1
filelock==3.13.1
Flask==3.0.2
fonttools==4.45.0
fsspec==2023.12.2
gitdb==4.0.11
GitPython==3.1.41
gradio_client==0.7.3
graphene==3.3
graphql-core==3.2.3
graphql-relay==3.2.0
greenlet==3.0.3
h11==0.14.0
httpcore==1.0.2
httpx==0.25.2
huggingface-hub==0.19.4
idna==3.6
importlib-metadata==4.13.0
importlib-resources==6.1.1
ipykernel @ file:///D:/bld/ipykernel_1698244157926/work
ipython @ file:///D:/bld/ipython_1698846796959/work
itsdangerous==2.1.2
jedi @ file:///home/conda/feedstock_root/build_artifacts/jedi_1696326070614/work
Jinja2==3.1.2
joblib==1.3.2
jsonschema==4.20.0
jsonschema-specifications==2023.11.1
jupyter_client @ file:///home/conda/feedstock_root/build_artifacts/jupyter_client_1699283905679/work
jupyter_core @ file:///D:/bld/jupyter_core_1698673832306/work
kiwisolver==1.4.5
Mako==1.3.2
Markdown==3.5.2
markdown-it-py==3.0.0
MarkupSafe==2.1.3
matplotlib==3.8.2
matplotlib-inline @ file:///home/conda/feedstock_root/build_artifacts/matplotlib-inline_1660814786464/work
mdurl==0.1.2
mlflow==2.10.0
nbformat==5.9.2
nest-asyncio @ file:///home/conda/feedstock_root/build_artifacts/nest-asyncio_1697083700168/work
numpy==1.26.2
oauthlib==3.2.2
orjson==3.9.10
packaging @ file:///home/conda/feedstock_root/build_artifacts/packaging_1696202382185/work
pandas==2.1.3
parso @ file:///home/conda/feedstock_root/build_artifacts/parso_1638334955874/work
pickleshare @ file:///home/conda/feedstock_root/build_artifacts/pickleshare_1602536217715/work
Pillow==10.1.0
platformdirs @ file:///home/conda/feedstock_root/build_artifacts/platformdirs_1699715570510/work
plotly==5.18.0
prompt-toolkit @ file:///home/conda/feedstock_root/build_artifacts/prompt-toolkit_1699963054032/work
protobuf==4.25.2
psutil @ file:///D:/bld/psutil_1695367295750/work
pure-eval @ file:///home/conda/feedstock_root/build_artifacts/pure_eval_1642875951954/work
pyarrow==14.0.0
pydantic==2.6.1
pydantic_core==2.16.2
pydub==0.25.1
Pygments @ file:///home/conda/feedstock_root/build_artifacts/pygments_1700395971011/work
PyJWT==2.8.0
pyparsing==3.1.1
python-dateutil @ file:///home/conda/feedstock_root/build_artifacts/python-dateutil_1626286286081/work
python-multipart==0.0.6
pytz==2023.3.post1
pywin32==306
PyYAML==6.0.1
pyzmq @ file:///D:/bld/pyzmq_1698062575483/work
querystring-parser==1.2.4
referencing==0.31.0
requests==2.31.0
rich==13.7.0
rpds-py==0.13.1
scikit-learn==1.3.2
scipy==1.11.4
semantic-version==2.10.0
setuptools==68.0.0
shellingham==1.5.4
six @ file:///home/conda/feedstock_root/build_artifacts/six_1620240208055/work
smmap==5.0.1
sniffio==1.3.0
SQLAlchemy==2.0.25
sqlparse==0.4.4
stack-data @ file:///home/conda/feedstock_root/build_artifacts/stack_data_1669632077133/work
starlette==0.27.0
tabulate==0.9.0
tenacity==8.2.3
threadpoolctl==3.2.0
tomlkit==0.12.0
toolz==0.12.0
tornado @ file:///D:/bld/tornado_1695373547508/work
tqdm==4.66.1
traitlets @ file:///home/conda/feedstock_root/build_artifacts/traitlets_1698671135544/work
typer==0.9.0
typing_extensions @ file:///home/conda/feedstock_root/build_artifacts/typing_extensions_1695040754690/work
tzdata==2023.3
urllib3==2.1.0
uvicorn==0.24.0.post1
waitress==2.1.2
wcwidth @ file:///home/conda/feedstock_root/build_artifacts/wcwidth_1699959196938/work
websockets==11.0.3
Werkzeug==3.0.1
wheel==0.41.2
zipp @ file:///home/conda/feedstock_root/build_artifacts/zipp_1695255097490/work

```",run doctor command alternatively run pip freeze report think version incompatible latest version perhaps downgrade file file file file file decorator file file file file file file file file file file file file file file file file file file file post file six file file tornado file file file post file file,issue,negative,positive,positive,positive,positive,positive
1928768109,"cc @B-Step62 the transformers fixes were based on top of [this commit](https://github.com/mlflow/mlflow/commit/5f14603a273f2ffff11004b575d853ba72f3fc0d), so during cherry-pick i had to manually exclude some changes. the end result can be seen [here (model_config)](https://github.com/mlflow/mlflow/pull/11028/commits/19fc39b9aad154df1bf1748244809efb7e1f5362) and [here (dtype)](https://github.com/mlflow/mlflow/pull/11028/commits/6a3cd7dc89aaf7e2b5710fc212c381d8275e466c)
",based top commit manually exclude end result seen,issue,negative,positive,positive,positive,positive,positive
1928748891,@daniellok-db I re-ran cross version tests with the `enable-dev-tests` label. It looks like we need to use python 3.9 for keras dev.,cross version label like need use python dev,issue,negative,neutral,neutral,neutral,neutral,neutral
1928701583,"discussed offline, this should definitely be done moving forward but we still need some solution that maintains backward compatibility with previously-saved keras 2 models.",definitely done moving forward still need solution backward compatibility,issue,positive,neutral,neutral,neutral,neutral,neutral
1928582469,I think the approach that I saw this morning with not logging if it is the default is good. No objections here!,think approach saw morning logging default good,issue,negative,positive,positive,positive,positive,positive
1928578254,Hi @thnguyendn great stuff! Could you add an entry in the integration suite for this provider? https://github.com/mlflow/mlflow/blob/master/tests/gateway/test_integration.py ,hi great stuff could add entry integration suite provider,issue,positive,positive,positive,positive,positive,positive
1928573649,"Made a change for dtype extracting logic, basically not to log it when the model's dtype is default one `torch.float32`. The issue is that `models.dtype` returns valid torch dtype even when the model/pipeline doesn't support `torch_dtype` parameter for construction, resulting in a failure when loading model with the logged dtype. Unfortunately, it seems there is no easy way to determine if the model/pipeline supports `torch_dtype` attribute (even those don't support it can have `torch_dtype` param in model config!!). Hence here I used a workaround that just logs dtype only when it is non-default i.e. not float32, assuming that there is no way to change model precision other than `torch_dtype`. This approach may be a bit fragile, as depending on the implicit fact that float32 is the default. WDYT? @BenWilson2 @harupy ",made change logic basically log model default one issue valid torch even support parameter construction resulting failure loading model logged unfortunately easy way determine attribute even support param model hence used float assuming way change model precision approach may bit fragile depending implicit fact float default,issue,negative,positive,neutral,neutral,positive,positive
1928563581,"can you run the doctor command (or, alternatively, just run `pip freeze`) and report the results here? I think your version of pydantic is incompatible. ",run doctor command alternatively run pip freeze report think version incompatible,issue,negative,neutral,neutral,neutral,neutral,neutral
1928384657,"What is `custom_lib` and it's member `MLFlowResource`? 

As far as the code sample that you provided, I can't speak to the interface implementation that is contained in there. Please validate that you can interface with your tracking server using standard MLflow run context commands via the fluent API, using the integrated model registry operations. 
Are you able to register the model properly using the standard APIs or through REST? ",member far code sample provided ca speak interface implementation please validate interface server standard run context via fluent model registry able register model properly standard rest,issue,positive,positive,positive,positive,positive,positive
1928199104,"1. We'd prefer not to remove them. As for whitelisting the MLflow UI, there are plenty of organizations that do this (some even create an entirely custom skin for the UI!) by forking the repository and maintaining their own version of the UI. While this may become quite a burden to maintain, particularly as we focus on large refactoring of the UI in the next year, it is an option to fully customize what you choose to see. 
2. Without a default experiment, failing to set an experiment when logging a run will result in a failure to create a run or log artifacts associated with said run. The Default experiment is quite important to prevent a very frustrating user experience. As for hiding the display of the Default experiment, this might not be something that you want. If a user forgets to set a named experiment at any time, the runs that are logged will go to the default experiment. Failing to display this within the UI might create a somewhat broken experience. 

We won't be entertaining modifications to the MLflow source code for these requests, but you are always more than welcome to fork the repo and make the UI as customized as you'd like! ",prefer remove plenty even create entirely custom skin repository version may become quite burden maintain particularly focus large next year option fully choose see without default experiment failing set experiment logging run result failure create run log associated said run default experiment quite important prevent user experience display default experiment might something want user set experiment time logged go default experiment failing display within might create somewhat broken experience wo entertaining source code always welcome fork make like,issue,positive,positive,positive,positive,positive,positive
1928168493,"
https://github.com/mlflow/mlflow/assets/39283302/7df0e427-963c-4c04-9e86-50165f9ad000

Seems to work just fine for me? Please check the ""charts"" view to see the integrated link functions (all charts that you create will highlight whichever run's data you select) for run selection. ",work fine please check view see link create highlight whichever run data select run selection,issue,positive,positive,positive,positive,positive,positive
1928158970,"Can you try wrapping your run logic within the context manager to ensure that the runs are created and stopped correctly? 
https://github.com/mlflow/mlflow/blob/master/examples/r_wine/train.R ",try wrapping run logic within context manager ensure stopped correctly,issue,negative,neutral,neutral,neutral,neutral,neutral
1928152865,"The following example might shed some light on how to resolve the issue that you're experiencing: 

https://github.com/mlflow/mlflow/blob/785d181012e0ad3f72663555aac1cf39d9ce098e/examples/rest_api/mlflow_tracking_rest_api.py 

Of particular note, notice the submission of the `start_time` parameter within the call to `create_run` in line 35. ",following example might shed light resolve issue particular note notice submission parameter within call line,issue,negative,positive,positive,positive,positive,positive
1928117335,"Hi @Casyfill I can't seem to reproduce the issue here. Perhaps there is a configuration in how you're using poetry that is causing you issues?

Here is what I ran (just slight modifications to how you're referring to the model_uri) 

```python

import warnings
import argparse
import logging
import pandas as pd
import numpy as np
import mlflow
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.model_selection import train_test_split
from sklearn.linear_model import ElasticNet

def train_log_model(model, X, y, model_name:str, run_name:str, config:dict):
    '''trains and logs model to Mlflow'''
    
    experiment_name = config['experiment_name']
    model_run_name = f'{run_name}_{model_name}_{config[""model_version""]}' 
    

    mlflow.set_tracking_uri(config['mlflow_tracking_uri'])  # sqlite:///mlruns.db
    mlflow.set_experiment(experiment_name)
    mlflow.autolog()

    with mlflow.start_run(run_name=model_run_name) as run:
        model.fit(X, y)
        signature = mlflow.models.infer_signature(X, y)
        
        model_info = mlflow.sklearn.log_model(model, 
                                 signature=signature,
                                #  registered_model_name=model_run_name,  # same behaviour
                                 artifact_path='model')
        
        mlflow.register_model(
            model_uri=model_info.model_uri,
            name=model_run_name
        )

from sklearn.linear_model import LinearRegression
model_names = ('main', 'certainty_low', 'certainty_high')
    
model = LinearRegression()
synthetic_data = pd.DataFrame({
        'col1': [1,2,3,4,5,6,7,8,9,10],
        'col2': [10,20,30,40,50,60,70,80,90,10],
        'target': [10,9,8,7,6,5,4,3,2,1]
    })

y = synthetic_data['target']
X = synthetic_data[['col1', 'col2']].copy()
    
config = {
          'mlflow_tracking_uri': 'sqlite:///mlruns.db',
          'experiment_name': 'test_experiment',
          'model_version': '0.1',
          'freq': '1W',
          'tags': {'test': 'test_model_tag'}
}

  
for model_name in model_names:
    train_log_model(model, X, y, model_name, run_name='test', config=config)
```

And after fetching the registered model by name, I get:

```python
from mlflow import MlflowClient
from pprint import pprint

client = MlflowClient()
for mv in client.search_model_versions(""name='test_certainty_low_0.1'""):
    pprint(dict(mv), indent=4)
```

```shell
{   'aliases': [],
    'creation_timestamp': 1707167703061,
    'current_stage': 'None',
    'description': None,
    'last_updated_timestamp': 1707167703061,
    'name': 'test_certainty_low_0.1',
    'run_id': '447032d715a843b481269a6bb37bb803',
    'run_link': None,
    'source': '/Users/benjamin.wilson/JupyterNotebooks/test2/mlruns/1/447032d715a843b481269a6bb37bb803/artifacts/model',
    'status': 'READY',
    'status_message': None,
    'tags': {},
    'user_id': None,
    'version': 2}
{   'aliases': [],
    'creation_timestamp': 1707167453354,
    'current_stage': 'None',
    'description': None,
    'last_updated_timestamp': 1707167453354,
    'name': 'test_certainty_low_0.1',
    'run_id': '67715c5e30db49a4b3de49ef362f6515',
    'run_link': None,
    'source': '/Users/benjamin.wilson/JupyterNotebooks/test2/mlruns/1/67715c5e30db49a4b3de49ef362f6515/artifacts/model',
    'status': 'READY',
    'status_message': None,
    'tags': {},
    'user_id': None,
    'version': 1}
```

(I ran it twice to verify that the model registry creates a 2nd version of the model from your snippet example). 

This code seems to work just fine from an MLflow perspective, using sqllite as a tracking server backend.",hi ca seem reproduce issue perhaps configuration poetry causing ran slight python import import import logging import import import import import import model model run signature model behaviour import model model fetching registered model name get python import import client shell none none none none none none none none ran twice verify model registry version model snippet example code work fine perspective server,issue,negative,positive,positive,positive,positive,positive
1928102977,"@ridhimag11 it is possible that I'm missing something, so any advices are welcome. I'm using 2.10.0.

I see there is a `Datasets` dropdown and, when I select one of them, it is possible to see which runs used those data (please note that the `Dataset` filter has a value selected).

![Captura de Tela 2024-02-05 às 18 09 26](https://github.com/mlflow/mlflow/assets/3266556/e8f46149-f706-428e-aab8-3639185ac090)

But it seems like I cannot do it the other way: given a specific run, how can I check which datasets were used?

![Captura de Tela 2024-02-05 às 18 07 43](https://github.com/mlflow/mlflow/assets/3266556/3fdc9726-53b6-4ec8-94ab-8e7f8364780a)

When I check the run details, I miss the previous `Datasets` dropdown (I'm comparing to 2.6.0).

In 2.6.0:

![Captura de Tela 2024-02-05 às 18 17 35](https://github.com/mlflow/mlflow/assets/3266556/854be743-ecca-4f92-8ac6-49eeb4fce11f)

In 2.10.0:

![Captura de Tela 2024-02-05 às 18 17 57](https://github.com/mlflow/mlflow/assets/3266556/2d3f48ea-cdba-4c33-ae6b-9110a3dc463f)
",possible missing something welcome see select one possible see used data please note filter value selected de like way given specific run check used de check run miss previous de de,issue,positive,positive,neutral,neutral,positive,positive
1928089998,"Artifact path is the relative path within the model_uri absolute path. Have you tried using the [get_artifact_uri](https://www.mlflow.org/docs/latest/python_api/mlflow.html#mlflow.get_artifact_uri) API ? 
Alternatively, if you're making your own plugin, you should probably be using the lower-level developer APIs that are exposed as utilities and as integration points within the artifact store APIs. Try looking at utilities like this: https://github.com/mlflow/mlflow/blob/785d181012e0ad3f72663555aac1cf39d9ce098e/mlflow/tracking/artifact_utils.py#L21-L56 ",artifact path relative path within absolute path tried alternatively making probably developer exposed integration within artifact store try looking like,issue,negative,positive,neutral,neutral,positive,positive
1928083922,@15890cle at the time I was working in Databricks and am now trying it locally and it's not working with the openai.chat.completions that I got working in the Databricks notebook.  I'm assuming its a problem with the versions I have installed currently but whatever version I was using at the time specifically had openai.chat.completions.  Going to go back and see if I can figure it out and let you know.  Even looking at the past couple diffs I don't see anything that would have made the openai.chat.completions not work so not sure yet,time working trying locally working got working notebook assuming problem currently whatever version time specifically going go back see figure let know even looking past couple see anything would made work sure yet,issue,negative,positive,neutral,neutral,positive,positive
1928001945,Hi @kumar-tiger thanks for letting us know about this limitation. We'll likely need to create a migration script for other DBs and to update the initial table creation for MySQL. We'll work on this. cc @gabrielfu - any thoughts here?,hi thanks u know limitation likely need create migration script update initial table creation work,issue,positive,positive,neutral,neutral,positive,positive
1927884044,Have you deleted these in a local branch and see an appreciable load performance benefit? cc @chenmoneygithub ,local branch see appreciable load performance benefit,issue,negative,neutral,neutral,neutral,neutral,neutral
1927877843,"Thanks, this is definitely a UI bug. We'll look into fixing it. 
cc @hubertzub-db ",thanks definitely bug look fixing,issue,positive,positive,neutral,neutral,positive,positive
1927672062,"we don't expose self._metrics_prefix = ""system/""  because our server uses this prefix to group metrics. The feature is released in Databricks staging server, and will come to OSS in the near future (probably a few weeks). That is to say, we don't want users to have the freedom to change this prefix.

re distributed training support, right now the code supports multi-gpu on a single node (we use pynvml to fetch GPU stats), but not multi-node setup because different platforms have different ways to communicate between master node (rank 0) and worker node, so we cannot make a standardized API. Users can write custom code and log to the same MLflow run as a workaround.

To address your request, I think we should provide a new argument `node_id`, which can be appended to `_metrics_prefix` to indicate which rank the system metrics come from without breaking the metrics grouping UI.",expose server prefix group metric feature staging server come near future probably say want freedom change prefix distributed training support right code single node use fetch setup different different way communicate master node rank worker node make standardized write custom code log run address request think provide new argument indicate rank system metric come without breaking metric grouping,issue,positive,negative,negative,negative,negative,negative
1927280841,"Hey folks, thanks for your great work! Do you need any help on this one? I just installed fresh Mlflow and stumbled upon this bug.",hey thanks great work need help one fresh upon bug,issue,positive,positive,positive,positive,positive,positive
1927014076,That's really odd.  This seems like a fine fix I guess.  Curious how we didn't see this in the mlflow repo tests though?,really odd like fine fix guess curious see though,issue,positive,positive,neutral,neutral,positive,positive
1926755851,"> @serena-ruan given the error message in the original issue, i don't think an `experiment_permission` already exists. It should be postgres complaining `id` being null when creating new permission for some reason.
> 
> `mlflow.exceptions.RestException: RESOURCE_ALREADY_EXISTS: Experiment permission (experiment_id=3, username=admin) already exists. Error: (psycopg2.errors.NotNullViolation) null value in column ""id"" of relation ""experiment_permissions"" violates not-null constraint`
> 
> P.S. we can probably fix this confusing error code

Yes that's true, though I'm not sure why the id could be null... Would duplicate permissions be a problem when inserting into the table?",given error message original issue think already id null new permission reason experiment permission already error null value column id relation constraint probably fix error code yes true though sure id could null would duplicate problem table,issue,negative,positive,positive,positive,positive,positive
1926700534,"Greetings 

I added optuna in the test_requirement.txt, and it said 
""Successfully installed colorlog-6.8.2 optuna-3.5.0""

Is this what supposed to do ?
",added said successfully supposed,issue,negative,positive,positive,positive,positive,positive
1926656373,"This is some extra logging coming from AWS support, not sure if it can help @serena-ruan ?
![Screenshot from 2024-02-05 11-23-29](https://github.com/mlflow/mlflow/assets/14580661/e7bbceda-59c8-40ed-93a1-ec58396719f7)
",extra logging coming support sure help,issue,positive,positive,positive,positive,positive,positive
1926588626,"Can I work on this ?
How do I start working on this like fork the repository, create a branch, make changes, and submit a pull request??",work start working like fork repository create branch make submit pull request,issue,positive,neutral,neutral,neutral,neutral,neutral
1926463218,"> LGTM though I would prefer splitting different issues into different PRs 🤔

i can split the fastapi to a separate one! i guess i just felt weird about merging when there were test failures",though would prefer splitting different different split separate one guess felt weird test,issue,negative,negative,negative,negative,negative,negative
1926238177,"> @daniellok-db It seems that the work you're doing is related to mine. Since my PR may not get approved, could you add the keras nitpick_ignore to this PR?
> 
> #11003

@minkj1992 ah perfect! Sorry I missed that PR, yes I have to update the keras RST file for the docs anyway so i'll make sure to include this. thank you!",work related mine since may get could add ah perfect sorry yes update file anyway make sure include thank,issue,positive,positive,positive,positive,positive,positive
1926234016,"@daniellok-db  It seems that the work you're doing is related to mine. Since my PR may not get approved, could you add the keras nitpick_ignore to this PR?

https://github.com/mlflow/mlflow/pull/11003",work related mine since may get could add,issue,negative,neutral,neutral,neutral,neutral,neutral
1926128935,"> can i pull this fix to test whether it fixis my issue? if so. should i change anything about how i register models to mlfow?

I think you could use this branch to test, you don't need to change the code (still use code_paths), but we might not merge this PR now as we will redesign the code_paths implementation in Q1. You could include this PR's change in your own patch if you really need to use it now :)",pull fix test whether issue change anything register think could use branch test need change code still use might merge redesign implementation could include change patch really need use,issue,negative,positive,positive,positive,positive,positive
1925994929,"Regarding OIDC/Oauth, you can easily achieve that by using oauth2-proxy as a sidecar pattern if you are serving a container-based tracking server. Here is my demo code https://github.com/cloudacode/mlflow-oauth-sidecar ",regarding easily achieve sidecar pattern serving server code,issue,negative,positive,positive,positive,positive,positive
1925948236,"Hey, how is the status here? :) I've stumpled upon this issue while trying to run the server with 3.12.",hey status upon issue trying run server,issue,negative,neutral,neutral,neutral,neutral,neutral
1925757779,"FYI, I just manually fixed this issue by

1. explictly set rstcheck-core==1.0.3
2. revert tensorflow-cpu to tensorflow (#9754 )
3. `pip cache purge && rm -rf .venv/[MY ENV]`
4. `dev/dev-env-setup.sh -d .venvs/mlflow-dev -o 3.9`",manually fixed issue set revert pip cache purge,issue,negative,positive,neutral,neutral,positive,positive
1925748338,"I also tried  `$ dev/dev-env-setup.sh -d .venvs/mlflow-dev -o 3.9` (#9754, #9751 cc @harupy )

but still got `pydantic` and `tensorflow-cpu` error.

```sh
ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
fastapi 0.89.1 requires pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2, but you have pydantic 2.6.0 which is incompatible.
ERROR: Could not find a version that satisfies the requirement tensorflow-cpu<=2.12.0 (from versions: none)
ERROR: No matching distribution found for tensorflow-cpu<=2.12.0
```

- pydantic is from `rstcheck==6.1.1` in lint-requirements.txt
- tensorflow-cpu is from `tensorflow-cpu<=2.12.0` in doc-requirements.txt",also tried still got error sh error pip dependency resolver currently take account behaviour source following dependency incompatible error could find version requirement none error matching distribution found,issue,negative,neutral,neutral,neutral,neutral,neutral
1925504011,"Hi @serena-ruan , can you please review the PR? Thank you!",hi please review thank,issue,positive,neutral,neutral,neutral,neutral,neutral
1925480670,"> My issue got fixed by running the server with `--gunicorn-opts=""--timeout 900""` following the comment given in the [link](https://github.com/mlflow/mlflow/issues/7702#issuecomment-1386300082)

This worked for me too. Thank you for sharing!",issue got fixed running server following comment given link worked thank,issue,negative,positive,neutral,neutral,positive,positive
1924770768,"I'm building a reference implementation of a ""full stack"" build for GenAI workloads. It uses MLFlow for things like experiment tracking, along with other tools like OpenLLMetry for tracing. If it seems useful, I could write an article about this, including the sample code to deploy the solution.",building reference implementation full stack build like experiment along like tracing useful could write article sample code deploy solution,issue,positive,positive,positive,positive,positive,positive
1924691081,"Hi @santiagxf, thanks for the suggestion, I haven't tried this but how is this going to differ from the problem you were facing with the AD tokens being time limited?

I should have said as well that I am trying to use this to deploy an external model deployment on Azure Databricks so want to be able to deploy once and those credentials to work for subsequent calls to the endpoint.",hi thanks suggestion tried going differ problem facing ad time limited said well trying use deploy external model deployment azure want able deploy work subsequent,issue,negative,positive,positive,positive,positive,positive
1924008765,can i pull this fix to test whether it fixis my issue? if so. should i change anything about how i register models to mlfow?,pull fix test whether issue change anything register,issue,negative,neutral,neutral,neutral,neutral,neutral
1923619899,"![image](https://github.com/mlflow/mlflow/assets/433383/39546bb9-ad78-4971-a622-8e62ee2310be)

Why are data points labeled with values? That makes no sense. I can obtain the value either at glance or by hovering the mouse on the point yet I have no idea to which run and experiment the data belongs to! I can't make sense of the plot not knowing where the data point came from.
The labels should be either run, experiment, a combination of both or preferably allow to enter custom template. ",image data sense obtain value either glance hovering mouse point yet idea run experiment data ca make sense plot knowing data point came either run experiment combination preferably allow enter custom template,issue,positive,neutral,neutral,neutral,neutral,neutral
1923458113,"Hello @xhw1, have you created the PR to fix this problem?

Thank you for your reply",hello fix problem thank reply,issue,negative,neutral,neutral,neutral,neutral,neutral
1923281861,"> @RRRen94 I think the original design is to use `weighted` if ""average"" method is not set (or None), so to fix the bug I would set ""average"" to ""weighted"" if it's None. But for your use case, do you want to log the metric value of each class specifically? Otherwise the workaround is just to remove evaluator_config when calling `.evaluate`

Yes, I want to directly see the metrics value of each class specifically, not weighted or averaged. These single values of each class can be found now in `per_class_metrics.csv` as artifact. But it could be nice to also have the option to log not averaged values as metrics, for example by using `evaluator_config={""average"": None}`.",think original design use weighted average method set none fix bug would set average weighted none use case want log metric value class specifically otherwise remove calling yes want directly see metric value class specifically weighted single class found artifact could nice also option log metric example average none,issue,positive,positive,neutral,neutral,positive,positive
1923275669,"Just found that the model exposes `dtype` property for getting dtype from parameter... ([source](https://github.com/huggingface/transformers/blob/main/src/transformers/modeling_utils.py#L883-L887)). Tho still used as fallback for missing model config in their source code. Should be simpler if it works, watching how cross version tests go👀",found model property getting parameter source tho still used fallback missing model source code simpler work watching cross version go,issue,negative,negative,neutral,neutral,negative,negative
1922733542,@edwardfeng-db Both core and skinny requirements include `graphene`. We can remove the skinny one.,core skinny include remove skinny one,issue,negative,neutral,neutral,neutral,neutral,neutral
1922502637,Hi @georgemarlow. I guess we can put that configuration in an environment vvariable. Have you try getting the token yourself and then setting that on the `OPENAI_API_KEY`?,hi guess put configuration environment try getting token setting,issue,negative,neutral,neutral,neutral,neutral,neutral
1922427448,"Hi! I'm currently having a similar issue at my organisation where we have a slightly different deployment of Azure OpenAI: We use a SPN with Token OAuth to secure access to the OpenAI model and manage the rights on the OpenAI resource. We use Azure Application Gateway (Web Application Firewall) and API Management Service to access to Azure OpenAI resource and for logging usage of the OpenAI resources. The bottom line from this is that when we retrieve the AD token we have to use a scope like ""api://<SPN_ID>/.default"" instead of ""https://cognitiveservices.azure.com/.default"".

Your PR looks great but it looks like this is a hard-coded value and we're not able to pass in our own scope for authentication. Is it possible to add this functionality so that we can override the default cognitive services scope?

This seemed very closely linked but let me know if I should open a separate issue! Thanks",hi currently similar issue slightly different deployment azure use token secure access model manage resource use azure application gateway web application management service access azure resource logging usage bottom line retrieve ad token use scope like instead great like value able pas scope authentication possible add functionality override default cognitive scope closely linked let know open separate issue thanks,issue,positive,positive,positive,positive,positive,positive
1922369776,"Hi all! We have merged [the PR](https://github.com/mlflow/mlflow/pull/10954) that applies following optimizations. This will be released in next MLflow version unless we find a major issue.
1. Not install Java and related packages for Python flavors.
2. Use Python-slim base image rather than Ubuntu when applicable.
3. If 2 is applied, not create virtualenv/conda environment inside the container.

As a result, the image size for a small scikit-learn model is now reduced to less than 1GB. But please let us know if you have more ideas to improve further!",hi following next version unless find major issue install related python use base image rather applicable applied create environment inside container result image size small model reduced le please let u know improve,issue,positive,negative,negative,negative,negative,negative
1922290870,Sorry for the re-review request @smurching but I ended up having to do some no great things in the test that I want you to eyeball before we land this.,sorry request ended great test want eyeball land,issue,positive,positive,positive,positive,positive,positive
1922012852,"Thank you @B-Step62! I'll make sure to address those in follow-ups.
1. Absolutely, we haven't implemented any of the input preprocessing yet, including several main items which I will add in a follow-up PR:
   - Applying chat template for `llm/v1/chat`
   - Support OpenAI compatible parameters such as `max_tokens`, `stop`
   - Support dict input where the OpenAI compatible parameters are included in the `data` dict for the `predict` function
2.  Thanks for raising awareness to this and the pointers! Yes, we shall override `return_full_text` there, as we already have postprocessing util functions that remove the prompt text according to the logic of https://github.com/huggingface/transformers/blob/abbffc4525566a48a9733639797c812301218b83/src/transformers/pipelines/text_generation.py#L312
3. Another follow-up is to have model signature inferred when `task` is `llm/v1/xxx`.",thank make sure address absolutely input yet several main add chat template support compatible stop support input compatible included data predict function thanks raising awareness yes shall override already remove prompt text according logic another model signature task,issue,positive,positive,positive,positive,positive,positive
1921934087,"> @SiddhantShah910 @WeichenXu123 this should actually be closed per my mentioned PR above #10682 which is merged

Thanks for the update.",actually closed per thanks update,issue,negative,positive,neutral,neutral,positive,positive
1921910159,"Hi @mendelson - can you share a screenshot of what you're seeing regarding the missing datasets. AFAIK, you should still be able to see the dataset dropdown in the list view.",hi share seeing regarding missing still able see list view,issue,negative,positive,positive,positive,positive,positive
1921896915,"@es94129 merged the PR, let's do few follow-ups;

1. We haven't implement the input preprocessing for `llm/v1/chat` task right? As mentioned in the previous note, you can simply add a processing to map chat input to string using [ChatTemplate](https://huggingface.co/docs/transformers/chat_templating), 
2. It seems we need a quick tweak to make the new task type work with the new [prompt template](https://mlflow.org/docs/latest/llms/transformers/guide/index.html#saving-prompt-templates-with-transformer-pipelines) feature. When a prompt template is set, we set `return_full_text=False` for pipeline so it won't leak the system prompt (basically it prevents the pipeline to echo the user's input). The issue is that the parameter cannot be combined with `return_tensors` which we use for the new task type: `ValueError: 'return_full_text' is mutually exclusive with 'return_tensors'`. However, luckily this is not a big issue, indeed if we pass `return_tensors`, the generated tensor doesn't include the users' input but just new tokens. Hence, we can just override `return_full_text` to `True` when `return_tensors` is set [here](https://github.com/mlflow/mlflow/blob/master/mlflow/transformers/__init__.py#L1901-L1902).

Let me know if there is any unclear thing! Thanks!.
",e let implement input task right previous note simply add map chat input string need quick tweak make new task type work new prompt template feature prompt template set set pipeline wo leak system prompt basically pipeline echo user input issue parameter combined use new task type mutually exclusive however luckily big issue indeed pas tensor include input new hence override true set let know unclear thing thanks,issue,positive,positive,positive,positive,positive,positive
1921764054,Yes please! +1 for this issue. Comparisons are not always based on scalar metrics in many cases,yes please issue always based scalar metric many,issue,positive,positive,positive,positive,positive,positive
1921298924,I miss being able to see the datasets used in a specific run. I find it quite difficult to filter a dataset in order to find which runs used it. The previous run view (with a dataset dropdown) was friendlier.,miss able see used specific run find quite difficult filter order find used previous run view,issue,negative,negative,neutral,neutral,negative,negative
1921029066,"Using virtual Windows machine for testing was quite a bit of effort - permission setting, installing tools, etc. I ended up testing with my personal Windows laptop:p

The basic `test_docker.py` all passed.
<img width=""632"" alt=""capture`"" src=""https://github.com/mlflow/mlflow/assets/31463517/001af711-f8be-44c1-b64b-a554f120abfc"">

For flavors, mostly passed but failed with a few
1. `spark`: Failed with spark installation indeed, not relevant to this change (also we don't introduce any change for Java flavors).
2. `tensorflow/keras/transformers`: Basically those depends on Tensorflow. The reason is that the model is logged on Windows so with `tensorflow-intel` as requirement, while it's not available in the container based on Ubuntu. Should be unrelated to the change itself.

So overall I think this change shouldn't introduce new surprise for Windows users:)

",virtual machine testing quite bit effort permission setting ended testing personal basic capture mostly spark spark installation indeed relevant change also introduce change basically reason model logged requirement available container based unrelated change overall think change introduce new surprise,issue,positive,positive,positive,positive,positive,positive
1920982747,"Anyone working on this? If not, Can I get assigned to this? @WeichenXu123 ",anyone working get assigned,issue,negative,neutral,neutral,neutral,neutral,neutral
1920894855,"> Confusion matrix logging and the ability to compare them across experiments would be an extra beneficial feature (like it is nicely done in [weight and biases](https://wandb.ai/wandb/plots/reports/Confusion-Matrix-Usage-and-Examples--VmlldzozMDg1NTM)).

+1
it's really a crucial feature",confusion matrix logging ability compare across would extra beneficial feature like nicely done weight really crucial feature,issue,positive,positive,positive,positive,positive,positive
1920884708,"Could it be that because the directory where files are copied is called ""code/"", it has an impact on the way sagemaker expects the model and breaks the server somehow ?",could directory copied impact way model server somehow,issue,negative,neutral,neutral,neutral,neutral,neutral
1920265796,Can we see if it's possible to test really quick with https://azure.microsoft.com/en-us/products/virtual-desktop (This doesn't have to be a CI job; it's just safer to do a one-time check to see if there is any odd behavior when trying to build this PR's implementation on Windows - just to be safe :) ) ,see possible test really quick job check see odd behavior trying build implementation safe,issue,negative,positive,positive,positive,positive,positive
1920134149,"Thanks for the review, @BenWilson2!

> Verify that this builds in a windows environment

Sure, do you know what is the easiest option to test this? remote desktop?

> Create a followup ticket to add full usage and customization documentation around the introduced changes (Java being removed from the containers, now creating an opt-in experience for inclusion) into the relevant sub section tutorials in https://www.mlflow.org/docs/latest/deployment/index.html

Yup, but Java is not totally removed, they are still installed for flavors like spark, mleap. The flag will be used for custom pyfunc mode, but will add documentation for it anyway.


> Setup something similar to cross version testing that is run weekly on the mlflow-automation repo so that we have recurring CI validation of the container build process (I 100% agree that this should not be part of the PR CI process, but we should have some non-manual testing mechanism

Totally makes sense, will do this as a part of follow-up. Created a JIRA.",thanks review verify environment sure know easiest option test remote create ticket add full usage documentation around removed experience inclusion relevant sub section totally removed still like spark flag used custom mode add documentation anyway setup something similar cross version testing run weekly recurring validation container build process agree part process testing mechanism totally sense part,issue,positive,positive,positive,positive,positive,positive
1919924751,"Here is one example workflow: I am running jobs via slurm. I can programmatically figure out where the slurm stdout/stderr logs go. If I symlink them to the artifact store, I should be able to view them in the MLFlow UI (also related: #3222). ",one example running via programmatically figure go artifact store able view also related,issue,negative,positive,positive,positive,positive,positive
1919733146,"I was able to solve this issue, it turns out the endpoint we provided for the Linode Object Storage was incorrect. 

In the systemd "".service"" file provided above:
1. The 'artifacts_destination' flag was changed to s3://{bucket-name-here}
2. The '--serve artifacts' flag was added

Added environment variables: 
MLFLOW_S3_ENDPOINT_URL=https://{aws-region-here}.linodeobjects.com/<bucket-name-here>
AWS_ACCESS_KEY_ID={redacted}
AWS_SECRET_ACCESS_KEY={redacted}

These changes fixed the issue completely. Thank you!

",able solve issue turn provided object storage incorrect file provided flag serve flag added added environment fixed issue completely thank,issue,positive,positive,positive,positive,positive,positive
1919651000,"Overall this looks great! Can we:
- Verify that this builds in a windows environment 
- Create a followup ticket to add full usage and customization documentation around the introduced changes (Java being removed from the containers, now creating an opt-in experience for inclusion) into the relevant sub section tutorials in https://www.mlflow.org/docs/latest/deployment/index.html 
- Setup something similar to cross version testing that is run weekly on the mlflow-automation repo so that we have recurring CI validation of the container build process (I 100% agree that this should not be part of the PR CI process, but we should have some non-manual testing mechanism) ",overall great verify environment create ticket add full usage documentation around removed experience inclusion relevant sub section setup something similar cross version testing run weekly recurring validation container build process agree part process testing mechanism,issue,positive,positive,positive,positive,positive,positive
1919361229,"Hi @chenmoneygithub ! The test (tests/types/test_schema::test_tensor_spec) was failing, so I've made an additional commit to fix this.
Also, I signed off the commits shortly after I opened the PR. (* DCO worker checked my commit)
Thanks for review!! :bow: :bow: :bow:",hi test failing made additional commit fix also shortly worker checked commit thanks review bow bow bow,issue,negative,positive,neutral,neutral,positive,positive
1919065873,"@gabrielfu 

Postgresql db version: 15.4
psycopg2 version: psycopg2-binary==2.9.9

However, I have decided that I do not need the basic-auth setup nor any of the permissions (all users will have the same permissions) as provided by mlflow and it didn't feel too stable yet either (e.g. when I configure the auth db to use the postgresql db instead of the default sqlite, it fails, similar as to what is in issue #9155. Instead I had to create the authdb manually by running the statements that the sqlite produces. ) 
 
Instead, I opted for running mlflow without auth with a nginx frontend that handles the basic auth for me.
So for me it is not necessary to solve this issue anymore and can be closed.",version version however decided need setup provided feel stable yet either configure use instead default similar issue instead create manually running instead running without basic necessary solve issue closed,issue,negative,negative,neutral,neutral,negative,negative
1918948705,"I'm also having this error, but I don't see how it has anything to do with conda",also error see anything,issue,negative,neutral,neutral,neutral,neutral,neutral
1918763269,"@cjidboon94 I cannot reproduce the error. It seems like your PostgreSQL is complaining null `id` field when creating new permission.

What's the version of your PostgreSQL instance, and also `psycopg2` library?

Can you also try starting the PostgreSQL with `log_statement=all`, then start the MLflow server, and look for logs like this and share with us?
```
2024-01-31 09:44:44.415 UTC [69] LOG:  statement:
        CREATE TABLE experiment_permissions (
                id SERIAL NOT NULL,
                experiment_id VARCHAR(255) NOT NULL,
                user_id INTEGER NOT NULL,
                permission VARCHAR(255),
                PRIMARY KEY (id),
                CONSTRAINT fk_user_id FOREIGN KEY(user_id) REFERENCES users (id),
                CONSTRAINT unique_experiment_user UNIQUE (experiment_id, user_id)
        )
```",reproduce error like null id field new permission version instance also library also try starting start server look like share u log statement create table id serial null null integer null permission primary key id constraint foreign key id constraint unique,issue,positive,positive,positive,positive,positive,positive
1918756728,"@serena-ruan given the error message in the original issue, i don't think an `experiment_permission` already exists. It should be postgres complaining `id` being null when creating new permission for some reason.

`mlflow.exceptions.RestException: RESOURCE_ALREADY_EXISTS: Experiment permission (experiment_id=3, username=admin) already exists. Error: (psycopg2.errors.NotNullViolation) null value in column ""id"" of relation ""experiment_permissions"" violates not-null constraint`

P.S. we can probably fix this confusing error code",given error message original issue think already id null new permission reason experiment permission already error null value column id relation constraint probably fix error code,issue,negative,positive,positive,positive,positive,positive
1918733364,Btw you can rebase the PR to master to resolve the build_doc failure:),rebase master resolve failure,issue,negative,negative,negative,negative,negative,negative
1918247605,"thanks @serena-ruan , i was on vacation. Let me review it today",thanks vacation let review today,issue,negative,positive,positive,positive,positive,positive
1918214947,"Thanks Weichen! I played with the notebook, the experience is pretty smooth. Two things about the file we save with checkpoints:
- Can we put checkpoints along with the metrics into one directory? Now it's flat files in a parent directory. With a large number of checkpoints logged, it's hard to navigate.
- We don't necessarily have eval metrics for every checkpoint we save, e.g., if we save checkpoints per 5000 steps, we may not have the eval metrics. We can make ""eval at checkpoint saving"" optional when saving per N steps.",thanks notebook experience pretty smooth two file save put along metric one directory flat parent directory large number logged hard navigate necessarily metric every save save per may metric make saving optional saving per,issue,positive,positive,positive,positive,positive,positive
1918008510,"mm, update: the generated dockerfile sets `JAVA_HOME` to `/usr/lib/jvm/java-8-openjdk-amd64`, but the image actually has `java-8-openjdk-arm64` in `/usr/lib/jvm`. I guess y'all are inferring the architecture but not using that to update the env var?",update image actually guess architecture update,issue,negative,neutral,neutral,neutral,neutral,neutral
1917980736,close and reopen to disable the CI cache.,close reopen disable cache,issue,negative,neutral,neutral,neutral,neutral,neutral
1917700880,"@serena-ruan @ngo-minh-thang-nguyen Hi, I have the fix ready and was able to compile it. I can create a PR today.",hi fix ready able compile create today,issue,positive,positive,positive,positive,positive,positive
1917511395,"> We'll keep this issue open for users to vote, and contributions are welcome!

Great, please keep me informed of the vote. I'll try to make a contribution if possible",keep issue open vote welcome great please keep informed vote try make contribution possible,issue,positive,positive,positive,positive,positive,positive
1917138719,"I'm experiencing the same issue: when I try to call `openai.chat.completions`, I get the same error as @15890cle; when I call openai.chat.completions.create, it returns `MlflowException: Unsupported task type: <class 'method'>`.

Can anyone kindly advise on how to overcome this hurdle?

Thanks.",issue try call get error call unsupported task type class anyone kindly advise overcome hurdle thanks,issue,negative,positive,positive,positive,positive,positive
1917029783,"@cjolif  I eventually managed to do a workaround.
For each of model included in multimodel endpoint, you need to download from `mlflow` registry the model binary, but only those files (nothing else can be there), zip it again into `model.tar.gz` , then you can use directly Airflow `SageMakerEndpointOperator` . Just provide the config for the operator:
- model config - give it a name and the ensemble zip file, you can assign model tags (mention which mlflow models) , specify also `""Mode"": ""MultiModel"",`
- endpoint config name
- endpoint name

Then you need to apply changes to ML flow tags for all the involved models -> to point to this sagemaker Model and Endpoint.

So instead of just using `mlflow.sagemaker` functions you need to perform `mlflow` retrieval, assemble a zip file yourself, use sagemaker SDK (or Airflow operators) to create entities in sagemaker, do deployment, and manage metadata like tags yourself as well.
but that is really it, works",eventually model included need registry model binary nothing else zip use directly provide operator model give name ensemble zip file assign model mention specify also mode name name need apply flow involved point model instead need perform retrieval assemble zip file use create deployment manage like well really work,issue,positive,positive,positive,positive,positive,positive
1916993868,"For those who still encountered this issue, could you try updating MLflow to the latest version? We have released a patch in v2.9.0: #10483",still issue could try latest version patch,issue,negative,positive,positive,positive,positive,positive
1916601326,"> This sounds reasonable to me. cc @daniellok-db Currently we don't evaluate anything but combine model inputs, outputs and some parameters into the table. But to support evaluation, we might need more inputs than just the metrics, `ground_truth` field for example.

Yes basically it is the ```mlflow.evaluate``` inside the prompt engineering UI specific for LLM evaluation",reasonable currently evaluate anything combine model table support evaluation might need metric field example yes basically inside prompt engineering specific evaluation,issue,positive,positive,neutral,neutral,positive,positive
1916587147,"This is really a blocker for us to continue adopting ml_flow for deployment. We have a lot of use cases with models that are seldomly used. If we have to pay one endpoint per model it would be way too costly and we want to mutualize them through multi-model endpoints. Not being able to do that is a blocker for adoption.

@dbczumar it seems you were happy to review a proposal about that in 2020 but I don't see any feedback to @MarkAWard 
 proposal in 2021. Is there still a strong interest from your side? Is that worth investing time to look into this?",really blocker u continue deployment lot use seldomly used pay one per model would way costly want mutualize able blocker adoption happy review proposal see feedback proposal still strong interest side worth time look,issue,positive,positive,positive,positive,positive,positive
1916530472,"This is the file structure of the model in mlflow, we can see that all the files have been copied correctly.
![Screenshot from 2024-01-30 11-18-18](https://github.com/mlflow/mlflow/assets/14580661/e61c4094-9beb-40d3-a016-9df196c93986)
Yes I have tried to run it locally with the load_model function and that works fine, I have even use the code to run the pyfunc docker locally on my machine and to serve the endpoint locally and that also works fine, here is the code for loading the model locally and for deploying the docker locally to serve as an endpoint:

```
# If you want the latest version of the model
def read_model_from_mlflow(run_id: str):
    if run_id is None:
        model_uri_latest = ""models:/hero-banner/latest""
    else:
        model_uri_latest = f""runs:/{run_id}/models""
    print(mlflow.pyfunc.get_model_dependencies(model_uri_latest))
    loaded_model = mlflow.pyfunc.load_model(model_uri_latest)
    mypayload = np.array([0.6046511627906976, True, False, False, False, True, False, False,
        True, False, False, False])
    return loaded_model.predict(mypayload)

print(read_model_from_mlflow(None))
```



```
build_docker(name=""mlflow-pyfunc"")

#client = get_deploy_client(""sagemaker"")
mlflow.sagemaker.run_local(
    name=""my-local-deployment"",
    model_uri=""models:/hero-banner/latest"",
    flavor=""python_function"",
    config={
        ""port"": 8080,
        ""image"": ""mlflow-pyfunc"",
    },
)
````",file structure model see copied correctly yes tried run locally function work fine even use code run docker locally machine serve locally also work fine code loading model locally docker locally serve want latest version model none else print true false false false true false false true false false false return print none client port image,issue,negative,negative,neutral,neutral,negative,negative
1916493665,"> I won't be putting anymore effort into this as there does not seem to be interest from maintainers and bitnami has provided a chart. Anyone is welcome to continue this work.

I saw the Bitami Helm chart, its not as good as https://github.com/community-charts/helm-charts/blob/main/charts/mlflow/README.md

I really think that the right choice is to invest a little bit more effort in order to provide an official helm chart.
We can contribute to this effort, but we need someone from the official team to review our suggestions and will help us to merge this PR. ",wo effort seem interest provided chart anyone welcome continue work saw helm chart good really think right choice invest little bit effort order provide official helm chart contribute effort need someone official team review help u merge,issue,positive,positive,positive,positive,positive,positive
1916373595,@ernestwong-db Could you provide design doc for this? It's a little bit confusing to me,could provide design doc little bit,issue,negative,negative,negative,negative,negative,negative
1916348975,"Not all tests require pyspark to be installed, and in our CI we run different flavors tests against different dependencies, so we don't want to add pyspark into test-requirements.txt.",require run different different want add,issue,negative,neutral,neutral,neutral,neutral,neutral
1916345156,@rajveer43 how is it going? Are the pipelines ready soon? Should we open a branch to merge our changes? Or maybe you can open a branch I will push my changes. ,going ready soon open branch merge maybe open branch push,issue,negative,positive,neutral,neutral,positive,positive
1916334103,"@natannvw 

You can read code under `mlflow/store/tracking`, it needs to support file-store/rest-store/sqlalchemy-store .   You should firstly understand how `delete_run` is implemented for the 3 kinds of store backends.",read code need support firstly understand store,issue,negative,positive,positive,positive,positive,positive
1916272802,"We'll keep this issue open for users to vote, and contributions are welcome!",keep issue open vote welcome,issue,negative,positive,positive,positive,positive,positive
1916263736,"@ngo-minh-thang-nguyen You could follow https://github.com/mlflow/mlflow/blob/master/CONTRIBUTING.md to get started, you need to clone the github repo and raise a PR",could follow get need clone raise,issue,negative,neutral,neutral,neutral,neutral,neutral
1916204673,"I can contribute to fix this bug if anyone can show me how to recompile source of mlflow that has been modified. Currently, mlflow source appears inside of site-packages in my project. 

I have already modified some py files to test and then make a 'python -m compileall' from the parent directory but nothing changes.",contribute fix bug anyone show recompile source currently source inside project already test make parent directory nothing,issue,negative,neutral,neutral,neutral,neutral,neutral
1916184147,"This sounds reasonable to me. cc @daniellok-db 
Currently we don't evaluate anything but combine model inputs, outputs and some parameters into the table. 
But to support evaluation, we might need more inputs than just the metrics, `ground_truth` field for example. ",reasonable currently evaluate anything combine model table support evaluation might need metric field example,issue,negative,positive,neutral,neutral,positive,positive
1916010193,@Ignatius224 Is there any more useful logs from the server side? It's more like something might be wrong with your setup... It's hard for us to tell what's going wrong :(,useful server side like something might wrong setup hard u tell going wrong,issue,negative,negative,negative,negative,negative,negative
1916006797,Could you make sure the same folder has been copied over to the `code` directory under `models` folder? Another thing worth trying is to load the model locally and see if it works? `mlflow.pyfunc.load_model(...)`,could make sure folder copied code directory folder another thing worth trying load model locally see work,issue,negative,positive,positive,positive,positive,positive
1915996742,"> [related ag-grid issues](https://github.com/ag-grid/ag-grid/issues/5039)

- to fix

```
yarn up @ag-grid-community/client-side-row-model@28.2.1
yarn up @ag-grid-community/core@28.2.1
yarn up @ag-grid-community/react@28.2.1
```


I resolve source map issue but, I've still got 
<img width=""1719"" alt=""Screen Shot 2024-01-30 at 12 09 59 PM"" src=""https://github.com/mlflow/mlflow/assets/37536298/929ec2e9-5960-45d7-9bce-2d457a8eb44e"">

- server
```
> mlflow ui
[2024-01-30 12:07:39 +0900] [60385] [INFO] Starting gunicorn 21.2.0
[2024-01-30 12:07:39 +0900] [60385] [INFO] Listening at: http://127.0.0.1:5000 (60385)
[2024-01-30 12:07:39 +0900] [60385] [INFO] Using worker: sync
[2024-01-30 12:07:39 +0900] [60387] [INFO] Booting worker with pid: 60387
[2024-01-30 12:07:39 +0900] [60388] [INFO] Booting worker with pid: 60388
[2024-01-30 12:07:40 +0900] [60392] [INFO] Booting worker with pid: 60392
[2024-01-30 12:07:40 +0900] [60393] [INFO] Booting worker with pid: 60393
```

- ui
```
> yarn start
Compiled successfully!

You can now view @mlflow/mlflow in the browser.

  Local:            http://localhost:3000/static-files
  On Your Network:  http://192.168.0.4:3000/static-files

Note that the development build is not optimized.
```",related fix yarn yarn yarn resolve source map issue still got screen shot server starting listening worker sync booting worker booting worker booting worker booting worker yarn start successfully view browser local network note development build,issue,positive,positive,neutral,neutral,positive,positive
1915931280,Thanks @B-Step62! I renamed the existing variables / file names to be `llm_inference_xxx` and moved the utility function and constants to the `llm_inference_utils.py` file.,thanks file utility function file,issue,negative,positive,positive,positive,positive,positive
1915879855,"https://docs.anthropic.com/claude/reference/complete_post shows `--header ""anthropic-version: 2023-06-01""` @hubertzub-db @dbczumar We might need to fix this on databricks side as well",header might need fix side well,issue,negative,neutral,neutral,neutral,neutral,neutral
1915875430,We're looking into supporting OAuth2 in this quarter. Please stay tuned! Right now it's not possible to do what you're trying to do. ,looking supporting quarter please stay tuned right possible trying,issue,positive,positive,positive,positive,positive,positive
1915824421,"<!-- documentation preview -->


Failed to find a documentation preview for 0c083e014dcd6de9a6f8774339529726b0de7ea5.

<details>
<summary>More info</summary>

- If the `ci/circleci: build_doc` job status is successful, you can see the preview with the following steps:
  1. Click `Details`.
  2. Click `Artifacts`.
  3. Click `docs/build/html/index.html`.
- This comment was created by https://github.com/mlflow/mlflow/actions/runs/7704729625.

</details>
",documentation preview find documentation preview summary job status successful see preview following click click click comment,issue,positive,positive,positive,positive,positive,positive
1915742796,@WeichenXu123 We ended up leveraging PyFunc Models as we we couldn't find a pattern that was generic enough to cover most base models. Thank you for continuing the thread though.,ended could find pattern generic enough cover base thank thread though,issue,negative,negative,negative,negative,negative,negative
1915701758,"Nth recommendation. Obvs MLflow is independent from Microsoft Fabric, but I noticed the behaviour there. I delete my parent level run and then the Experiment UI immediately gets clogged with 20 child runs that get promoted to the top level in the base run view rather than deleted.",nth recommendation independent fabric behaviour delete parent level run experiment immediately child get top level base run view rather,issue,negative,negative,negative,negative,negative,negative
1915667720,"Thanks @BenWilson2 @serena-ruan ! Looks like there's a seemingly unrelated failing cross-version test - let me know the best way to proceed (should I wait for that to be fixed & pull master to unblock merge, etc?)",thanks like seemingly unrelated failing test let know best way proceed wait fixed pull master unblock merge,issue,positive,positive,positive,positive,positive,positive
1915238568,"> Should we still inspect all input sources and filter down to just delta dataset sources and then truncate before we do the proto conversion? I'm realizing that the reason I had it this way was to make sure we grabbed all of the delta data sources. I don't think it makes sense to just grab the first 10 dataset sources which may not be delta datasets, in which case we still have to eat a scan of the input sources array and would only really be saving the extra proto conversion on delta datasets > 10.

Your proposal sounds good, I'm not too concerned about spending time scanning arrays or doing proto conversions, more about limiting the size of the request header that gets sent containing table info & the number of API requests to `GetTable`. But I'm realizing the actual `GetTable` API requests happen one at a time when you log a UC table dataset via `mlflow.log_input` (?), which seems fine, so lineage header emission logic/truncation won't have any effect on the number of API requests that gets sent. 

We can also do the proto conversion upfront (like before) and then truncate afterwards as long as we log a warning when truncation is happening & make sure the end header isn't too large (which the unit test can catch)",still inspect input filter delta truncate proto conversion realizing reason way make sure delta data think sense grab first may delta case still eat scan input array would really saving extra proto conversion delta proposal good concerned spending time scanning proto limiting size request header sent table number gettable realizing actual gettable happen one time log table via fine lineage header emission wo effect number sent also proto conversion like truncate afterwards long log warning truncation happening make sure end header large unit test catch,issue,positive,positive,positive,positive,positive,positive
1914923466,"@WeichenXu123 
Thanks, indeed I have some. I am not familiar (yet) with rest and how to implement my code exactly into mlflow.
",thanks indeed familiar yet rest implement code exactly,issue,negative,positive,positive,positive,positive,positive
1914781436,Our team @B-Step62 is doing some work relating to this. I will assign this task to him to avoid complication. :) ,team work assign task avoid complication,issue,negative,neutral,neutral,neutral,neutral,neutral
1914686158,"> Can we add a unit test for the truncation behavior (create run with >10 input datasets, verify the header only contains 10 of them)? LGTM after that's done

@smurching Should we still inspect all input sources and filter down to just delta dataset sources and *then* truncate before we do the proto conversion?  I'm realizing that the reason I had it this way was to make sure we grabbed all of the delta data sources.  I don't think it makes sense to just grab the first 10 dataset sources which may not be delta datasets, in which case we still have to eat a scan of the input sources array and would only really be saving the extra proto conversion on delta datasets > 10.",add unit test truncation behavior create run input verify header done still inspect input filter delta truncate proto conversion realizing reason way make sure delta data think sense grab first may delta case still eat scan input array would really saving extra proto conversion delta,issue,positive,positive,positive,positive,positive,positive
1914459271,"Sadly no logs I have been trying to get more detailed logs from AWS side. Maybe some settings in gunicorn that I can use to enable more logging.
Sure this is the logging call to register the model.
`mlflow.pyfunc.log_model(
        ""models"",
        python_model=model,
        registered_model_name=""hero-banner"",
        pip_requirements=pip_requirements,
        code_path=[""hero_bandit""],
    )`
The hero bandit directory is a python package where the model is trained and deployed. I have attached a snapshot of the folder structure.
![Screenshot from 2024-01-29 12-02-10](https://github.com/mlflow/mlflow/assets/14580661/db330bf7-7ea6-4718-bf83-1593d9100995)

The custom PythonModel class to define the pyfunc model is the following.
![Screenshot from 2024-01-29 12-03-30](https://github.com/mlflow/mlflow/assets/14580661/4ae76108-0627-4eda-8a7b-01fbb0630927)


",sadly trying get detailed side maybe use enable logging sure logging call register model hero bandit directory python package model trained attached snapshot folder structure custom class define model following,issue,negative,positive,neutral,neutral,positive,positive
1914397328,Is there any logs about why the worker timeout? BTW what's the code to repro? Details about logging the model with code_paths should be helpful,worker code logging model helpful,issue,negative,neutral,neutral,neutral,neutral,neutral
1914391178,"@B-Step62 Hey Yuki, do you have any insights on what might be wrong here? Could it be permission issue 🤔 ",hey might wrong could permission issue,issue,negative,negative,negative,negative,negative,negative
1914335572,"@dgormly Any progress on this task ? 

If you are busy, would you mind reassigning this task to @alanzhangeliiza or other volunteers ? :) 

Thanks!",progress task busy would mind task thanks,issue,positive,positive,positive,positive,positive,positive
1914330130,@praateekmahajan Could you create a new ticket  with reproducing code ? It might be a bit different. We have fixed the lazily load module issue .,could create new ticket code might bit different fixed lazily load module issue,issue,negative,negative,neutral,neutral,negative,negative
1914326358,"@natannvw Feel free to file PR according to suggestion in https://github.com/mlflow/mlflow/issues/10866#issuecomment-1903442418 and https://github.com/mlflow/mlflow/issues/10866#issuecomment-1903690994 

No hesitate to ask me if you have any blockers.",feel free file according suggestion hesitate ask,issue,negative,positive,positive,positive,positive,positive
1914317922,"A stacktrace of what? Sadly the only logs that I have access to are the one I sent above which are generated by the sagemaker endpoint, or is there a logging setting I can enable on the mlflow-pyfunc docker image ?",sadly access one sent logging setting enable docker image,issue,negative,negative,negative,negative,negative,negative
1914247768,"Yes, I'll add the rest of members. If we had more seats in our organization account, we could invite all of us and use GitHub's feature to auto-request a review, but our organization account is full. More members = More costs.",yes add rest organization account could invite u use feature review organization account full,issue,positive,positive,positive,positive,positive,positive
1914135039,@gabrielfu Could you review this and let me know if it makes sense?,could review let know sense,issue,negative,neutral,neutral,neutral,neutral,neutral
1914064573,"Hi, is there any progress on this issue thus far? I'm really hoping this feature's released soon.",hi progress issue thus far really feature soon,issue,negative,positive,positive,positive,positive,positive
1913907881,"> > @BenWilson2 I also have Databricks model serving deployment and inference examples. Should we include a second notebook for Databricks given this is OSS?
> > [Field eng workspace link](https://e2-demo-field-eng.cloud.databricks.com/browse/folders/588220726889642?o=1444828305810485)
> 
> @serena-ruan also do you think databricks serving and inference is in scope for OSS? I'll add that notebook(s) if so.
> 
> Thanks for the review!

I feel like it's not for OSS, and there're bunch of databricks tutorials for model serving https://docs.databricks.com/en/machine-learning/model-serving/index.html We could add links pointing to them directly :D ",also model serving deployment inference include second notebook given field link also think serving inference scope add notebook thanks review feel like bunch model serving could add link pointing directly,issue,positive,positive,positive,positive,positive,positive
1913888567,"Hi @xwangotter Thanks for raising the issue, please feel free to file a PR to fix it! BTW is this a newly introduced header for newer anthropic version?",hi thanks raising issue please feel free file fix newly header anthropic version,issue,positive,positive,positive,positive,positive,positive
1913883022,"@RRRen94 I think the original design is to use `weighted` if ""average"" method is not set (or None), so to fix the bug I would set ""average"" to ""weighted"" if it's None. But for your use case, do you want to log the metric value of each class specifically? Otherwise the workaround is just to remove evaluator_config when calling `.evaluate`",think original design use weighted average method set none fix bug would set average weighted none use case want log metric value class specifically otherwise remove calling,issue,positive,positive,neutral,neutral,positive,positive
1912763203,"@WeichenXu123 I'm not entirely sure if this is the same but we are seeing a similar issue to do with lazy loading and `keras_core` even though our code doesn't use anything keras / tensorflow. We are on `mlflow 2.9.2`, and `importlib-metadata/resources 5.2.0` and `cloudpickle 2.2.1`

```python
  File ""/usr/local/lib/python3.9/site-packages/cascade/executors/vertex/executor.py"", line 164, in _stage
    cloudpickle.dump(job, f)
  File ""/usr/local/lib/python3.9/site-packages/cloudpickle/cloudpickle_fast.py"", line 55, in dump
    CloudPickler(
  File ""/usr/local/lib/python3.9/site-packages/cloudpickle/cloudpickle_fast.py"", line 632, in dump
    return Pickler.dump(self, obj)
  File ""/usr/local/lib/python3.9/site-packages/mlflow/utils/lazy_load.py"", line 41, in __getattr__
    module = self._load()
  File ""/usr/local/lib/python3.9/site-packages/mlflow/utils/lazy_load.py"", line 30, in _load
    module = importlib.import_module(self.__name__)
  File ""/usr/local/lib/python3.9/importlib/__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 1030, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 1007, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 986, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 680, in _load_unlocked
  File ""<frozen importlib._bootstrap_external>"", line 855, in exec_module
  File ""<frozen importlib._bootstrap>"", line 228, in _call_with_frames_removed
  File ""/usr/local/lib/python3.9/site-packages/mlflow/keras_core/__init__.py"", line 1, in <module>
    from mlflow.keras_core.callback import MLflowCallback
  File ""/usr/local/lib/python3.9/site-packages/mlflow/keras_core/callback.py"", line 1, in <module>
    import keras_core as keras
ModuleNotFoundError: No module named 'keras_core'

```",entirely sure seeing similar issue lazy loading even though code use anything python file line job file line dump file line dump return self file line module file line module file line return name level package level file frozen line file frozen line file frozen line file frozen line file frozen line file frozen line file line module import file line module import module,issue,negative,positive,neutral,neutral,positive,positive
1912646838,"I'm having the same issue with task=openai.ChatCompletion.

@cdreetz - Did you mean change to task=openai.chat.completions? You stated that using task=chat.completions worked for you but I do not see how since that is not part of the class. Unfortunately when I try task=openai.chat.completions I get the following:

Exception has occurred: MlflowException
Unsupported task type: <class 'openai.resources.chat.completions.Completions'>
  File ""C:\Users\p0064107\OneDrive - Parsons Corp\Documents\AI\Python Code\mlFlow.py"", line 31, in <module>
    logged_model_info = mlflow.openai.log_model(
                        ^^^^^^^^^^^^^^^^^^^^^^^^
mlflow.exceptions.MlflowException: Unsupported task type: <class 'openai.resources.chat.completions.Completions'>

I found in the OpenAI v1.0.0 Migration Guide documentation showing the below change but have not had any success with it.

from openai import OpenAI

 openai.ChatCompletion.create() -> client.chat.completions.create()

Thoughts anyone?

Thanks
Chris",issue mean change stated worked see since part class unfortunately try get following exception unsupported task type class file line module unsupported task type class found migration guide documentation showing change success import anyone thanks,issue,negative,negative,neutral,neutral,negative,negative
1912556294,"> @BenWilson2 I also have Databricks model serving deployment and inference examples. Should we include a second notebook for Databricks given this is OSS?
> 
> [Field eng workspace link](https://e2-demo-field-eng.cloud.databricks.com/browse/folders/588220726889642?o=1444828305810485)

@serena-ruan also do you think databricks serving and inference is in scope for OSS? I'll add that notebook(s) if so. 

Thanks for the review!",also model serving deployment inference include second notebook given field link also think serving inference scope add notebook thanks review,issue,negative,positive,neutral,neutral,positive,positive
1912093082,"Hey! Is there still work happening on this? If not, i'd be happy to give it a go :)",hey still work happening happy give go,issue,positive,positive,positive,positive,positive,positive
1912090615,Hello @Gekko0114 ! Are you still planning to work on this? I'd be happy to give it a go if needed :) ,hello still work happy give go,issue,positive,positive,positive,positive,positive,positive
1911941319,"@WeichenXu123 I think all the tests are green, would you be able to help get this merged? :)",think green would able help get,issue,negative,positive,positive,positive,positive,positive
1911620601,"Hi @WeichenXu123 and @Haxatron I have reported this bypass at the 29th Dec. 2023 in https://huntr.com/bounties/19bf02d7-6393-4a95-b9d0-d6d4d2d8c298/, not quite sure who is the first reporter and please have a check, thanks!",hi bypass th quite sure first reporter please check thanks,issue,positive,positive,positive,positive,positive,positive
1911521318,"> Update: We're planning this for upcoming quarter and will get back to this :D 

Thanks for the update @serena-ruan it's great to hear that this is in the roadmap. 

Third-party IDP authentication support and fine-grained authorisation are the primary obstacles preventing MLflow from being considered enterprise ""ready"". Looking forward to future updates!",update upcoming quarter get back thanks update great hear authentication support primary considered enterprise ready looking forward future,issue,positive,positive,positive,positive,positive,positive
1911456355,"Could you test on this branch too ?

https://github.com/mlflow/mlflow/pull/10896

Btw we are going to redesign ""code_paths"" features in next quarter to totally address related issues, pls stay tuned. :)",could test branch going redesign next quarter totally address related stay tuned,issue,negative,neutral,neutral,neutral,neutral,neutral
1911334686,"Transformers added feature to support 4-bit model in v4.37

See https://github.com/huggingface/transformers/pull/26037

@yifanniemanu Would you test it ? ",added feature support model see would test,issue,negative,neutral,neutral,neutral,neutral,neutral
1911252989,Update: We're planning this for upcoming quarter and will get back to this :D ,update upcoming quarter get back,issue,negative,neutral,neutral,neutral,neutral,neutral
1911170322,"I'm seeing this behavior as well. I've tried setting timeouts as high as 5000 and it still fails the artifact upload at the same spot. I'm using version 2.9.2 with this code:

```
tinyllama_pipeline = transformers.pipeline(
    task=task,
    model=""TinyLlama/TinyLlama-1.1B-Chat-v1.0""
)

eval_data = pd.DataFrame(
    {
        ""inputs"": [            
            ""The color of the sky is"",
            ""The color of the moon is"",
        ],
    }
)

# Define the parameters (and their defaults) for optional overrides at inference time.
parameters_sets = [
                {""max_length"": 128, ""do_sample"": True, ""temperature"": 0.1},
                {""max_length"": 128, ""do_sample"": True, ""temperature"": 0.4},
                {""max_length"": 128, ""do_sample"": True, ""temperature"": 0.9}
]

for parameters in parameters_sets:
    signature = mlflow.models.infer_signature(
        input_example,
        mlflow.transformers.generate_signature_output(pipeline_object, input_example),
        parameters,
    )

    #Create run name with model and current temperature
    run_name = pipeline_name + '(temp:'+str(parameters.get('temperature', '--')) + ')'

    with mlflow.start_run(run_name = run_name):
        model_info = mlflow.transformers.log_model(
            transformers_model=pipeline_object,
            artifact_path=""text_generation"",
            input_example=input_example,
            signature=signature,
        )
        results = mlflow.evaluate(
            model=model_info.model_uri,
            model_type='text',
            data=eval_data,
        )
```",seeing behavior well tried setting high still artifact spot version code color sky color moon define optional inference time true temperature true temperature true temperature signature create run name model current temperature temp,issue,positive,positive,positive,positive,positive,positive
1910617924,"@BenWilson2 I also have Databricks model serving deployment and inference examples. Should we include a second notebook for Databricks given this is OSS?

[Field eng workspace link](https://e2-demo-field-eng.cloud.databricks.com/browse/folders/588220726889642?o=1444828305810485)",also model serving deployment inference include second notebook given field link,issue,negative,neutral,neutral,neutral,neutral,neutral
1910450839,"> Yes, I fixed it in above PR, feel free to try it out

Tested it and behave as expected. I think that you can close this bug.",yes fixed feel free try tested behave think close bug,issue,positive,positive,positive,positive,positive,positive
1910412979,"@brynn-code, Unfortunately, we had to revert this PR. This PR didn't pass the release pipeline due to `test_promptflow_model_export` failure. 

The main issue is that `promptflow-tools` requires OpenAI >= 1.0, which MLflow doesn't support now. It turns out the tools is not optional for making prediction, because FlowInvoker indirectly uses the tool [here](https://github.com/microsoft/promptflow/blob/main/src/promptflow/promptflow/executor/_tool_resolver.py#L249). We plan to work on OpenAI support early in a few weeks. We will let you know once it's done and then revive the flavor.

Aside from this, there are a few other minor issues in unit tests:
  - A fixture `spark` is used as a constant [here](https://github.com/mlflow/mlflow/blob/master/tests/promptflow/test_promptflow_model_export.py#L105), which caused the test failure. The correct usage is to pass as a param of test method like `def test_promptflow_model_sparkudf_predict(spark):`
  - Regex pattern [here](https://github.com/mlflow/mlflow/blob/master/tests/promptflow/test_promptflow_model_export.py#L119) to [the actual message](https://github.com/mlflow/mlflow/blob/master/mlflow/promptflow/__init__.py#L58-L59).

Sadly these issues were not captured in the original PR because the github action didn't run those flavor tests, due to some misconfiguration - namely, promptflow was added to `ml_package_version.py` instead of `ml-package-versions.yml` (the latter is what github action looks at, while the former is auto-generated file based on it). This is not your fault as the configuration is complicated and we also overlooked it, but I'd kindly request running unit tests locally for double-check ([test guide](https://github.com/B-Step62/mlflow/blob/master/CONTRIBUTING.md#python)). Thanks.
",unfortunately revert pas release pipeline due failure main issue support turn optional making prediction indirectly tool plan work support early let know done revive flavor aside minor unit fixture spark used constant test failure correct usage pas param test method like spark pattern actual message sadly original action run flavor due misconfiguration namely added instead latter action former file based fault configuration complicated also kindly request running unit locally test guide thanks,issue,positive,negative,neutral,neutral,negative,negative
1910366447,"> Can we create a JIRA ticket to revert this for next sprint please?

Sure, created!",create ticket revert next sprint please sure,issue,positive,positive,positive,positive,positive,positive
1910318661,"fyi: confirmed that cross-version tests for langchain autologging pass, by pushing dummy commit (reverted now)",confirmed pas pushing dummy commit,issue,negative,positive,positive,positive,positive,positive
1910107925,"@brynn-code May I ask one follow-up for this PR, could you add a section for promptflow flavor in the [Build-In Model Flavors](https://mlflow.org/docs/latest/models.html#built-in-model-flavors) doc? It can be just a short description for the flavor and an example code snippet. Also I think we should note the signature limitation. This PR already adds a page for `mlflow.promptflow` but adding to the list would increase visibility of the flavor a lot. Thanks!",may ask one could add section flavor model doc short description flavor example code snippet also think note signature limitation already page list would increase visibility flavor lot thanks,issue,negative,positive,neutral,neutral,positive,positive
1910088444,"Two issues in the original update
1. `openai` max version was updated to `1.x`, but we only support `0.x`.
2. `promptflow` was not added in `ml-package-version.yml` instead `.py` file (#10104)

Pushed a commit to fix both.",two original update version support added instead file commit fix,issue,positive,positive,positive,positive,positive,positive
1910085794,"I remember previously we have permission issue on databricks NFS which also relates to this directory permission setting, Let me test this on databricks NFS too.",remember previously permission issue also directory permission setting let test,issue,negative,negative,negative,negative,negative,negative
1909792026,Confusion matrix logging and the ability to compare them across experiments would be an extra beneficial feature (like it is nicely done in [weight and biases](https://wandb.ai/wandb/plots/reports/Confusion-Matrix-Usage-and-Examples--VmlldzozMDg1NTM)).,confusion matrix logging ability compare across would extra beneficial feature like nicely done weight,issue,positive,positive,positive,positive,positive,positive
1909766702,"> Yes, I fixed it in above PR, feel free to try it out

That looks excelent. Thanks a lot for the fast turn-around. I will try it out and let you know.",yes fixed feel free try thanks lot fast try let know,issue,positive,positive,positive,positive,positive,positive
1909759566,"Yes, I fixed it in above PR, feel free to try it out",yes fixed feel free try,issue,positive,positive,positive,positive,positive,positive
1909584433,"> Hi @sheigel2 The environment variable for deployment id should be `os.environ[""OPENAI_DEPLOYMENT_NAME""] = ""gpt-35-turbo""`, if setting this correctly you don't need to log the model with deployment_id. You're right the sample is not correct, I'll fix it.

Indeed, that environment can be used when using the model, but it practically means that the model from MLFlow is not tied to a deployment and can variate on client. I think that this is not just a documentation issue.
I am also trying to evaluate the logged model with gpt-4 (as an example) but because I have that environment variable set to a gpt-35 it doesn't seem to pick up the gpt-4 for evaluating answer similiarity but uses the one from the environment. I might be doing something wrong, but I believe that the MLFlow model should be as specific as possible, and that includes the deployment_id. The deployment_id is in fact stored on the model, just not used when running a predict.",hi environment variable deployment id turbo setting correctly need log model right sample correct fix indeed environment used model practically model tied deployment variate client think documentation issue also trying evaluate logged model example environment variable set seem pick answer one environment might something wrong believe model specific possible fact model used running predict,issue,negative,negative,neutral,neutral,negative,negative
1909431285,"Hi @sheigel2 The environment variable for deployment id should be `os.environ[""OPENAI_DEPLOYMENT_NAME""] = ""gpt-35-turbo""`, if setting this correctly you don't need to log the model with deployment_id. You're right the sample is not correct, I'll fix it.",hi environment variable deployment id turbo setting correctly need log model right sample correct fix,issue,negative,positive,positive,positive,positive,positive
1909379580,"Hi there, I think it would be great if the `delete_artifacts` method could just be changed so that it works with either files or directories. It seems like a simple enough fix.",hi think would great method could work either like simple enough fix,issue,positive,positive,positive,positive,positive,positive
1909375985,"@MariaFjodorowa Please support on above.. I am getting same issue for other metrics as well
",please support getting issue metric well,issue,positive,neutral,neutral,neutral,neutral,neutral
1909369746,"FYI! It seems like the method `delete_artifact` was renamed to `delete_artifacts`, so the code above should be changed to
```
from mlflow.store.artifact.artifact_repository_registry import get_artifact_repository

repository = get_artifact_repository(run.info.artifact_uri)
repository.delete_artifacts(filename)
```",like method code import repository,issue,negative,neutral,neutral,neutral,neutral,neutral
1909201258,"We just set pin upper-bound of major version for ensuring compatibility. Once we test the new arrow major version is compatible with MLflow, we will update it. You can file a PR to test it by CI jobs. :)",set pin major version compatibility test new arrow major version compatible update file test,issue,negative,positive,neutral,neutral,positive,positive
1908664240,"Hi, please review
https://github.com/mlflow/mlflow/pull/10848
Now tests are added

@PhilipMay @AveshCSingh @andychow-db ",hi please review added,issue,negative,neutral,neutral,neutral,neutral,neutral
1907543740,"> @harupy I've decided to only add the README for now as I realized that the script dependency thing could be tricky to do because we need `mlflow` itself, which doesn't contain the graphql stuff right now. I think we might just do that part after we merge the feature branch and I'll directly commmit those into master

sounds good!",decided add script dependency thing could tricky need contain stuff right think might part merge feature branch directly master good,issue,negative,positive,positive,positive,positive,positive
1907428869,We'd be excited to merge this support into ML Recipes once it's ready. Thanks @legion15q !,excited merge support ready thanks,issue,positive,positive,positive,positive,positive,positive
1907304034,"I am ok to this feature request, and it only needs to add a few mlflow code, @dbczumar Any opinion ? :)",feature request need add code opinion,issue,negative,neutral,neutral,neutral,neutral,neutral
1907300981,"@WeichenXu123 - The fix for this report https://huntr.com/bounties/11209efb-0f84-482f-add0-587ea6b7e850/ in https://github.com/mlflow/mlflow/pull/10653 was incomplete.

In particular it did not cover for 2 cases:

When fragment in URL - `http://example.com/#/../../../../../../../../../../../../../../etc/`
When params in URL - `http://example.com/;..%2F..%2F..%2Fetc`",fix report incomplete particular cover fragment,issue,negative,positive,positive,positive,positive,positive
1907297299,"Thanks, but could you elaborate the case you are fixing ? :) Why it causes error in current mlflow code ?",thanks could elaborate case fixing error current code,issue,negative,positive,positive,positive,positive,positive
1907295870,This feature makes sense. I will add it as a backlog task :) CC @BenWilson2 ,feature sense add backlog task,issue,negative,neutral,neutral,neutral,neutral,neutral
1907206440,"@natannvw 

I checked this again:

```
def delete_runs(runs, mlflow_client: MlflowClient):
    with ThreadPoolExecutor() as executor:
        list(
            tqdm(
                executor.map(
                    lambda run: delete_run(run, mlflow_client=mlflow_client), runs
                ),
                total=len(runs),
                desc=""Deleting runs"",
            )
        )
```

This way will cause concurrency issue because MLflow FileStore backend does not support concurrent operations.

So I think the better way is to implement batched ""delete run"",  See https://github.com/mlflow/mlflow/issues/10866#issuecomment-1903442418 and https://github.com/mlflow/mlflow/issues/10866#issuecomment-1903690994",checked executor list lambda run run way cause concurrency issue support concurrent think better way implement delete run see,issue,positive,positive,positive,positive,positive,positive
1907109585,"Transformers is supported in MLflow >= 2.3, please take a look at [the documentation](https://mlflow.org/docs/latest/llms/transformers/index.html) for the detailed usage.",please take look documentation detailed usage,issue,negative,positive,positive,positive,positive,positive
1906345947,"@lennartvandeguchte heres what i did, i have windows 11, i installed wsl for ubuntu and now its all good. occasionally it gets a bit buggy but thats alright ig",good occasionally bit buggy thats alright,issue,positive,positive,positive,positive,positive,positive
1906325107,Is there a more permanent fix for this in the current pipeline? Similar to what @kbumsik suggested?,permanent fix current pipeline similar,issue,negative,neutral,neutral,neutral,neutral,neutral
1906287683,"@WeichenXu123 
Okay. What is my next step then? Copy my helper as is to the file and PR?",next step copy helper file,issue,negative,neutral,neutral,neutral,neutral,neutral
1905984129,"The .py in `code_paths=[""/Workspace/Users/FAKE/FAKE/FAKE/""] `contains the following: 
```
class EntityPairClassificationPipeline(Pipeline):

    def _sanitize_parameters(self, **kwargs):
       …

    def __call__(self, text, **kwargs): 
        …

    def preprocess(self, text, entity_spans=None):
        …

    def _forward(self, model_inputs):
        ….

    def postprocess(self, model_outputs):
        …

PIPELINE_REGISTRY.register_pipeline(
    ""entity-pair-classification"",
    pipeline_class=EntityPairClassificationPipeline,
    pt_model=LukeForEntityPairClassification,
    type=""text""  
)
```
If an error were to exist with this code I would expect a different error message to be returned than `""Unknown task entity-pair-classification, available tasks are ...`. Is the pipeline registry being checked using `PIPELINE_REGISTRY.get_supported_tasks()`? Or is the user provided task being compared to the hard-codded list in the HuggingFace repo? https://github.com/huggingface/transformers/blob/f4f57f9dfa68948a383c352a900d588f63f6290a/src/transformers/pipelines/__init__.py#L158",following class pipeline self self text self text self self text error exist code would expect different error message returned unknown task available pipeline registry checked user provided task list,issue,negative,positive,neutral,neutral,positive,positive
1905903904,i think it is outdated version of the openAI API library .APIRemovedInV1Proxy class removed from the new version I guess.,think outdated version library class removed new version guess,issue,negative,negative,negative,negative,negative,negative
1905873888,"(base) aion@ip-172-31-50-243:~$ python llm/llm_mlflow_logging.py
Downloading artifacts: 100%|█████████████████████████████████████████████████████████████████████████████| 9/9 [01:00<00:00,  6.76s/it]
2024/01/23 11:35:19 WARNING mlflow.pyfunc: Detected one or more mismatches between the model's dependencies and the current Python environment:
 - sentencepiece (current: uninstalled, required: sentencepiece)
To fix the mismatches, call `mlflow.pyfunc.get_model_dependencies(model_uri)` to fetch the model's environment and install dependencies using the resulting environment file.
Loading checkpoint shards:   0%|                                                                                 | 0/2 [00:00<?, ?it/s]/home/aion/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.76it/s]
/home/aion/.local/lib/python3.10/site-packages/mlflow/data/digest_utils.py:26: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.
  string_columns = trimmed_df.columns[(df.applymap(type) == str).all(0)]
/home/aion/.local/lib/python3.10/site-packages/mlflow/models/evaluation/base.py:414: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.
  data = data.applymap(_hash_array_like_element_as_bytes)
2024/01/23 11:35:23 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.
2024/01/23 11:35:23 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.
2024/01/23 11:35:28 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...
Segmentation fault
(base) aion@ip-172-31-50-243:~$



For other metrices also I am getting same error

",base aion python warning one model current python environment current uninstalled fix call fetch model environment install resulting environment file loading removed future storage class matter directly access directly use instead return instance owner loading use instead type use instead data model default model testing metric first row segmentation fault base aion also getting error,issue,negative,negative,negative,negative,negative,negative
1905555503,"@natannvw Got it.

Then I suggest we just add a client side helper API like your original proposal, so that we don't need to change backend server code.
",got suggest add client side helper like original proposal need change server code,issue,positive,positive,positive,positive,positive,positive
1905365199,"@WeichenXu123
No, because my goal is to scale up the `delete_run()` which is based on the run ID.",goal scale based run id,issue,negative,neutral,neutral,neutral,neutral,neutral
1905363588,"Thanks, I've just started writing a draft of the code.
https://github.com/mlflow/mlflow/pull/10870
",thanks writing draft code,issue,negative,positive,positive,positive,positive,positive
1905205218,Thanks! This feature makes sense. I will read your PR soon :),thanks feature sense read soon,issue,negative,positive,positive,positive,positive,positive
1905188298,"@natannvw 

In databricks , we have a API: https://docs.databricks.com/api/workspace/experiments/deleteruns

it deletes all runs that were **created prior to or at the specified timestamp**.

does it satisfy your use-case ? If yes we should implement this in OSS MLflow instead of your proposed API (delete specified run_id set)",prior satisfy yes implement instead delete set,issue,positive,neutral,neutral,neutral,neutral,neutral
1905182892,"@es94129 Thank you for the contribution! Could you fix the following issue(s)?

#### &#x26a0; DCO check

The DCO check failed. Please sign off your commit(s) by following the instructions [here](https://github.com/mlflow/mlflow/runs/20754597970). See https://github.com/mlflow/mlflow/blob/master/CONTRIBUTING.md#sign-your-work for more details.",e thank contribution could fix following issue check check please sign commit following see,issue,positive,neutral,neutral,neutral,neutral,neutral
1905104423,"> If PIPELINE_REGISTRY.register_pipeline() is included in the .py file in code_paths=[""/Workspace/Users/FAKE/FAKE/FAKE/""]

if your custom model class is defined in the file like:

```
class CustomModel:
  ...

PIPELINE_REGISTRY.register_pipeline(CustomModel)
```

and importing the file module before loading pipeline model, it should work.",included file custom model class defined file like class file module loading pipeline model work,issue,negative,neutral,neutral,neutral,neutral,neutral
1904814286,"Similar config file to @alistairwgillespie above with same error message. 

Hardcoding `endpoint_type` in `metrics/genai/model_utils.py` like below seems to resolve the issue. Not sure of the explanation for why it is expecting `Endpoint` to have a `get` method.
 
```
client = get_deploy_client()

endpoint = client.get_endpoint(deployment_uri)
# endpoint_type = endpoint.get(""task"", endpoint.get(""endpoint_type""))
endpoint_type = ""llm/v1/completions""
```",similar file error message like resolve issue sure explanation get method client task,issue,positive,positive,positive,positive,positive,positive
1904708429,"any update on this?

sample config file that leads to the same issue on my end:

```
endpoints:
  - name: chat
    endpoints_type: llm/v1/chat
    model:
      provider: openai
      name: gpt-4
      config:
        openai_api_type: ""azure""
        openai_api_key: $AZURE_OPENAI_KEY
        openai_deployment_name: ""..""
        openai_api_base: ""...""
        openai_api_version: ""2023-07-01-preview""

  - name: completions
    endpoints_type: llm/v1/completions
    model:
      provider: openai
      name: gpt-4
      config:
        openai_api_type: ""azure""
        openai_api_key: $AZURE_OPENAI_KEY
        openai_deployment_name: ""...""
        openai_api_base: ""...""
        openai_api_version: ""2023-07-01-preview""
```",update sample file issue end name chat model provider name azure name model provider name azure,issue,negative,neutral,neutral,neutral,neutral,neutral
1904564162,Hi @uriyay-jfrog we've received the report and will be reviewing and working on patch fixes. Thank you for the investigation and very helpful report! ,hi received report working patch thank investigation helpful report,issue,positive,neutral,neutral,neutral,neutral,neutral
1904151973,"@harupy Hi, I've moved the import statement to the validation logic and updated the examples of the docs. Could you take another look?",hi import statement validation logic could take another look,issue,negative,neutral,neutral,neutral,neutral,neutral
1904086508,@BenWilson2 Is it too late to get started on this?  Read through most of the relevant code and think I'm at a good place to make a solid attempt at it,late get read relevant code think good place make solid attempt,issue,positive,positive,positive,positive,positive,positive
1903892954,"In a fresh python process, running `pyfunc_model = mlflow.pyfunc.load_model('runs:/27c7190cf78d493ca4c3d779c73d6581/re_custom_pipeline')` yields the error `KeyError: ""Unknown task entity-pair-classification, available tasks are ['audio-classification', 'automatic-speech-recogKeyError: ""Unknown task entity-pair-classification, available tasks are ['audio-classification', 'automatic-speech-recognition', 'conversational', 'depth-estimation', 'document-question-answering', 'feature-extraction', 'fill-mask', 'image-classification', 'image-segmentation', 'image-to-text', 'mask-generation', 'ner', 'object-detection', 'question-answering', 'sentiment-analysis', 'summarization', 'table-question-answering', 'text-classification', 'text-generation', 'text2text-generation', 'token-classification', 'translation', 'video-classification', 'visual-question-answering', 'vqa', 'zero-shot-audio-classification', 'zero-shot-classification', 'zero-shot-image-classification', 'zero-shot-object-detection', 'translation_XX_to_YY']""nition', 'conversational', 'depth-estimation', 'document-question-answering', 'feature-extraction', 'fill-mask', 'image-classification', 'image-segmentation', 'image-to-text', 'mask-generation', 'ner', 'object-detection', 'question-answering', 'sentiment-analysis', 'summarization', 'table-question-answering', 'text-classification', 'text-generation', 'text2text-generation', 'token-classification', 'translation', 'video-classification', 'visual-question-answering', 'vqa', 'zero-shot-audio-classification', 'zero-shot-classification', 'zero-shot-image-classification', 'zero-shot-object-detection', 'translation_XX_to_YY']""`. 

If `PIPELINE_REGISTRY.register_pipeline()` is included in the .py file in `code_paths=[""/Workspace/Users/FAKE/FAKE/FAKE/""]`  then the pipeline should be registered, right? So, this error should not occur in my reproducible example, right? Thank you for investigating.",fresh python process running error unknown task available unknown task available included file pipeline registered right error occur reproducible example right thank investigating,issue,negative,positive,positive,positive,positive,positive
1903766495,@BenWilson2 Can I merge this for 2.10.0? Or should we wait for next release?,merge wait next release,issue,negative,neutral,neutral,neutral,neutral,neutral
1903690994,"@natannvw 

You can read `delete_run` code under `mlflow/store/tracking` directory,

For rest_store and sqlalchemy_store, for `delete_runs`, it should be able to pack multiple run_id into a list, 
For rest_store,
it should send the list to rest server backend,

For sqlalchemy_store , you should generate one sql that contains predicate like `delete ... where run_id in (run_id1, run_id2, ...)` ",read code directory able pack multiple list send list rest server generate one predicate like delete,issue,negative,positive,positive,positive,positive,positive
1903503009,"Sounds good to me, but I'm not familiar with it. Can you refer me to any doc? I will try to implement it again.",good familiar refer doc try implement,issue,negative,positive,positive,positive,positive,positive
1903455170,"Thanks ! I think this should not be mlflow side issue. MLflow is a pure python library and it is unlikely to be root cause of a ""Segmentation fault"".

I think  you can remove mlflow related stuff from your repro code and the issue should still persist, if so you can report this bug to ""transformers"" project. :)",thanks think side issue pure python library unlikely root cause segmentation fault think remove related stuff code issue still persist report bug project,issue,negative,negative,neutral,neutral,negative,negative
1903442418,"Thanks, we can add this API, but I think your implementation is suboptimal,

why not make this a ""batched operation"" ? We can send batched run_ids to backend for executing deletion.",thanks add think implementation suboptimal make operation send deletion,issue,negative,positive,positive,positive,positive,positive
1903437477,"this is probably because `PIPELINE_REGISTRY.register_pipeline()` is not called when loading the model in spark UDF side, let's test this firstly https://github.com/mlflow/mlflow/issues/10860#issuecomment-1903436798 ",probably loading model spark side let test firstly,issue,negative,positive,positive,positive,positive,positive
1903436798,"Hi @kgoz12 

To narrow down the issue scope, could you **start a fresh python process** and try following code firstly:

```
pyfunc_model = mlflow.pyfunc.load(<your_model_uri>)

pyfunc_model.predict(..)
```


",hi narrow issue scope could start fresh python process try following code firstly,issue,negative,positive,neutral,neutral,positive,positive
1903409140,"Hi @luke-gerschwitz ,

Both MLflow UI and python SDK calls the same REST APIs:

Reference: available rest APIs: https://mlflow.org/docs/latest/rest-api.html

Example of how javascript side invoke rest API: [mlflow/server/js/src/experiment-tracking/sdk/MlflowService.ts](https://github.com/mlflow/mlflow/blob/master/mlflow/server/js/src/experiment-tracking/sdk/MlflowService.ts)",hi python rest reference available rest example side invoke rest,issue,negative,positive,positive,positive,positive,positive
1903385194,"Got it, let's add validation. Can we import `limits` in `validate_limit`?",got let add validation import,issue,negative,neutral,neutral,neutral,neutral,neutral
1903236975,"@MariaFjodorowa Thanks...so do I need to remove Rouge metrics
Please give me the code for the same",thanks need remove rouge metric please give code,issue,positive,positive,positive,positive,positive,positive
1902928796,cc @B-Step62 thanks for the comments! I added your suggestions and threw in some more links to make all the sections more discoverable!,thanks added threw link make discoverable,issue,negative,positive,positive,positive,positive,positive
1902797674,"The issue may be related to the rouge metrics. In my case, jupyter kernel dies silently even when running rouge only on a 5 rows long eval_df without any LLM in memory:


```
mlflow.evaluate(
    data=eval_df.head(),
    targets=""ground_truth"",
    predictions=""predictions"",
    extra_metrics=[
    mlflow.metrics.rouge1(),
    ],
)
```


but other metrics e.g. mlflow.metrics.ari_grade_level() or a custom unbabel-comet metric work normally.",issue may related rouge metric case kernel silently even running rouge long without memory metric custom metric work normally,issue,negative,positive,neutral,neutral,positive,positive
1902084671,"> @hubertzub-db @daniellok-db wanted to flag this issue I discovered in the model registry UI. Basically, the [x] mark of the alias disappears when I hover over it. Could this be caused by the dark mode changes?

I think this might just be due to the color scheme of the tag (`charcoal`). from the UI docs:

https://github.com/mlflow/mlflow/assets/148037680/6e13e3df-8432-475b-bcdd-312e7f499a4a

I removed it in my [clone of the UI sync](https://github.com/mlflow/mlflow/pull/10864/files#r1460418046)

",flag issue discovered model registry basically mark alias hover could dark mode think might due color scheme tag charcoal removed clone sync,issue,negative,negative,negative,negative,negative,negative
1900947781,"@harupy I've decided to only add the README for now as I realized that the script dependency thing could be tricky to do because we need `mlflow` itself, which doesn't contain the graphql stuff right now. I think we might just do that part after we merge the feature branch and I'll directly commmit those into master",decided add script dependency thing could tricky need contain stuff right think might part merge feature branch directly master,issue,negative,positive,positive,positive,positive,positive
1900923138,"@hubertzub-db @daniellok-db wanted to flag this issue I discovered in the model registry UI. Basically, the [x] mark of the alias disappears when I hover over it. Could this be caused by the dark mode changes?

https://github.com/mlflow/mlflow/assets/66143562/7aae0f6f-7d94-4694-8cde-0902a48fd86b

",flag issue discovered model registry basically mark alias hover could dark mode,issue,negative,negative,negative,negative,negative,negative
1900862395,Is there a way to enable `debug` level for logger messages? The `deployment` command does not accept custom `uvicorn` parameters,way enable level logger deployment command accept custom,issue,negative,neutral,neutral,neutral,neutral,neutral
1900400376,"Feel free to file a PR, appreciate your contribution!",feel free file appreciate contribution,issue,positive,positive,positive,positive,positive,positive
1900399982,Thanks ! I suggest we use `os.path.dirname(os.path.abspath(path))` to fix this. This is a more strict way.,thanks suggest use path fix strict way,issue,negative,positive,positive,positive,positive,positive
1900231265,">I don't think we need to validate limit values if we need to import limits but curious what error slowapi would raise for an invalid limit value.

If the format of the limit parameter is invalid, slowapi does not raise an exception and just emits a log error, leading to a failure of rate limiting ([ref](https://github.com/laurentS/slowapi/blob/master/slowapi/extension.py#L691)). So I think it's better to have a validation for the limit parameter. We could have our own validation, but there might be a discrepancy unless we use https://github.com/alisaifee/limits/ library which slowapi delegates the actual rate limitting.",think need validate limit need import curious error would raise invalid limit value format limit parameter invalid raise exception log error leading failure rate limiting ref think better validation limit parameter could validation might discrepancy unless use library actual rate,issue,negative,positive,neutral,neutral,positive,positive
1900143435,We can remove `--log-level=debug`. I added this to confirm timeout is set to 60.,remove added confirm set,issue,negative,neutral,neutral,neutral,neutral,neutral
1900134718,@harupy Awesome idea! That capability is like existing for this exact use case:) ,awesome idea capability like exact use case,issue,positive,positive,positive,positive,positive,positive
1900113720,"@B-Step62 What about this approach?

```diff
diff --git a/tests/gateway/test_fluent.py b/tests/gateway/test_fluent.py
index 5b0d7d54a3..83ad165504 100644
--- a/tests/gateway/test_fluent.py
+++ b/tests/gateway/test_fluent.py
@@ -1,3 +1,4 @@
+import os
 from unittest import mock
 
 import pytest
@@ -157,7 +158,9 @@ def test_fluent_search_routes_handles_pagination(tmp_path):
         ""routes"": [{""name"": route_name, **base_route_config} for route_name in gateway_route_names]
     }
     save_yaml(conf, gateway_config_dict)
-    with Gateway(conf) as gateway:
+    with Gateway(
+        conf, env={**os.environ, ""GUNICORN_CMD_ARGS"": ""--timeout=60 --log-level=debug""}
+    ) as gateway:
         set_gateway_uri(gateway_uri=gateway.url)
         assert [route.name for route in search_routes()] == gateway_route_names
```

`GUNICORN_CMD_ARGS` allows us to specify extra options. We can set a longer timeout using this environment variable.",approach git index ad o import mock import name gateway gateway gateway gateway assert route u specify extra set longer environment variable,issue,negative,neutral,neutral,neutral,neutral,neutral
1900010719,"@harupy 
Hmm it's actually trickier than it sounds. `MLFLOW_GATEWAY_SEARCH_ROUTES_PAGE_SIZE` is used by server side as well ([code](https://github.com/mlflow/mlflow/blob/77240f8087677081c5ffb38c4a0e061e04b7b5b1/mlflow/deployments/server/app.py#L293)) which runs in a subprocess, so we can't simply patch it. Alternatively, I think we can make `MLFLOW_GATEWAY_SEARCH_ROUTES_PAGE_SIZE` as environment variable and pass it to subprocess.

I think we have two options (lmk if there is better one)
1. Make `MLFLOW_GATEWAY_SEARCH_ROUTES_PAGE_SIZE` as environment variable
  - Pros: Gateway tests will be faster, will save roughly 3~5 mins in total workflow
  - Cons: Not sure if this is sth user should touch, it may cause an issue when setting wrong values.
2. Set `MLFLOW_DEPLOYMENT_SERVER_START_TIMEOUT` longer. (Just as constant, not env variable. On second thought, it's not necessarily be configurable, we can just use longer timeout always).
  - Pros: Simpler and no freedom to change.
  - Cons: Pagination test takes a bit of time (a few mins).

I'd prefer the latter given that both options don't provide benefit to users, then not adding configuration sounds safer. WDYT?",actually used server side well code ca simply patch alternatively think make environment variable pas think two better one make environment variable gateway faster save roughly total sure user touch may cause issue setting wrong set longer constant variable second thought necessarily use longer always simpler freedom change pagination test bit time prefer latter given provide benefit configuration,issue,positive,positive,neutral,neutral,positive,positive
1899955096,"> Instead of creating a new environment variable, can we monkey-patch MLFLOW_GATEWAY_SEARCH_ROUTES_PAGE_SIZE with a smaller value like 10?

ooh great idea! ",instead new environment variable smaller value like great idea,issue,positive,positive,positive,positive,positive,positive
1899922520,I don't think we need to validate limit values if we need to import `limits` but curious what error slowapi would raise for an invalid limit value.,think need validate limit need import curious error would raise invalid limit value,issue,positive,negative,neutral,neutral,negative,negative
1899900754,"Instead of creating a new environment variable, can we monkey-patch `MLFLOW_GATEWAY_SEARCH_ROUTES_PAGE_SIZE` with a smaller value like 10?",instead new environment variable smaller value like,issue,positive,positive,neutral,neutral,positive,positive
1899857608,@TomeHirata Got it. Thanks for the explanation! Is it possible to remove `validate_limit` to avoid importing `limits`?,got thanks explanation possible remove avoid,issue,negative,positive,neutral,neutral,positive,positive
1899556562,"Great tutorial! Love the ducks reference. 
Since this is a huge quality of life improvement for transformers, can we add a brief section that explains this new feature (with a note explaining that it's only available in 2.10.0 and above) in a section above here: https://www.mlflow.org/docs/latest/llms/transformers/guide/index.html#using-model-config-and-model-signature-params-for-transformers-inference ?",great tutorial love reference since huge quality life improvement add brief section new feature note explaining available section,issue,positive,positive,positive,positive,positive,positive
1899521018,"@harupy The test failed due to the lack of request schema validation as a side effect of the endpoint signature change to just `Request`. I'm guessing we can resolve it by configuring a customized Route class, so let me investigate around that. Of course, any suggestions are appreciated.",test due lack request schema validation side effect signature change request guessing resolve route class let investigate around course,issue,negative,negative,negative,negative,negative,negative
1899515920,"@harupy Sorry, could you take a look at this PR?",sorry could take look,issue,negative,negative,negative,negative,negative,negative
1899178435,"Closing, since the original issue reported appears to have been resolved by https://github.com/mlflow/mlflow/pull/9799",since original issue resolved,issue,negative,positive,positive,positive,positive,positive
1899079066,Did a force push according to the DCO instructions to sign the commits.,force push according sign,issue,negative,neutral,neutral,neutral,neutral,neutral
1899017620,Thanks for the updates here. We're going to be updating the implementation to support only OpenAI SDK>1.0 soon and should be part of the 2.11 release. ,thanks going implementation support soon part release,issue,positive,positive,positive,positive,positive,positive
1898631586,"Hi,
I propose to update Tags class init (not validation)
Please review draft of general approach
https://github.com/mlflow/mlflow/pull/10848
Main idea is here
https://github.com/mlflow/mlflow/pull/10848/files#diff-508ed16e2db0a6aafe0d58c0db53931d738e55d110bbae8d9951509b31bba921

In case we approve this approach - I'll add tests.",hi propose update class validation please review draft general approach main idea case approve approach add,issue,negative,positive,positive,positive,positive,positive
1898471992,"We are not affiliated with the huntr platform and submitted our report through the email listed in the SECURITY.MD page. If you are responding to the disclosures we sent over, could you please verify by responding to our email? As your response doesn't seem to match up with our disclosure and we don't want to publicly discuss potentially new vulnerability details unless the maintainers of the project are happy for us to do so.",platform report listed page sent could please verify response seem match disclosure want publicly discus potentially new vulnerability unless project happy u,issue,positive,positive,positive,positive,positive,positive
1898325593,"For further information, getting the same error in mutliple versions of MLFlow and OpenAI - I think the docs definitely need updated with a working example and clear package version for the examples. ",information getting error think definitely need working example clear package version,issue,negative,positive,neutral,neutral,positive,positive
1897972318,"Hi @BenWilson2/ @serena-ruan, is there a tentative date for next mlflow pypi release??",hi tentative date next release,issue,negative,neutral,neutral,neutral,neutral,neutral
1897941778,"It took me a while to find this. I was also annoyed by the fact that every time I get back to the experiment page, MLflow resets the columns I'm viewing.

When I compare two runs, in the upper left corner there's a link to the experiment. Clicking it is the most logical thing to do to get back to the experiment page. However, the link points to the bare experiment URL without the column information. So one should use the back button of the browser instead.",took find also fact every time get back experiment page compare two upper left corner link experiment logical thing get back experiment page however link bare experiment without column information one use back button browser instead,issue,negative,positive,neutral,neutral,positive,positive
1897905186,"submission related to client side injection ,could you please check in huntr dev platform or can i share the submission issue url here.",submission related client side injection could please check dev platform share submission issue,issue,positive,neutral,neutral,neutral,neutral,neutral
1897175196,I think showing the `min` values of `train_loss` and `val_loss` in the main table would be more helpful.,think showing min main table would helpful,issue,negative,positive,positive,positive,positive,positive
1896312055,"@harupy Thank you for raising the issue, this is a nice catch. I think you're right, the Limiter object stores the rate limits settings as a dict whose key is `f{view_func.__module__}.{view_func.__name__}` and it seems there is no way for users to specify the key name except for overwriting the handler's `__name__` field ([ref](https://github.com/laurentS/slowapi/blob/master/slowapi/extension.py#L559)).",thank raising issue nice catch think right limiter object rate whose key way specify key name except handler field ref,issue,positive,positive,positive,positive,positive,positive
1896187114,"I'm facing this same issue, using last version of MLFlow. I have an experiment with no runs inside (they have been deleted from the user interface) and when I run the delete_experiment from my python script (with the right experiment ID, I can access the Experiment object correctly), it fails giving me the same error:

RestException: INVALID_PARAMETER_VALUE: The run 0887ce65a33c46a0839dad747f8c72ac must be in the 'active' state. Current state is deleted.

mlflow version: 2.9.2
python version: 3.9.18
",facing issue last version experiment inside user interface run python script right experiment id access experiment object correctly giving error run must state current state version python version,issue,negative,positive,neutral,neutral,positive,positive
1895870183,Was the above comment posted in the right issue? This submission does not relate to that.,comment posted right issue submission relate,issue,negative,positive,positive,positive,positive,positive
1895794185,"I have the same issue. Why is the schema unavailable, and why can't I download / preview the dataset once it's logged?",issue schema unavailable ca preview logged,issue,negative,neutral,neutral,neutral,neutral,neutral
1895663058,"> I actually installed langchain-community from your branch. Let me try one more time.

I tested in this notebook: https://e2-dogfood.staging.cloud.databricks.com/?o=6051921418418893#notebook/187185339621970",actually branch let try one time tested notebook,issue,negative,neutral,neutral,neutral,neutral,neutral
1895594174,"https://github.com/laurentS/slowapi/issues/173 might be the cause. For backward compatibility, we create two routes for one endpoint, one with `gateway` prefix and one with `deployments` prefix. The route handlers have the same `__name__` and lead to duplicate request checks. This is a hack, but de-duplicating `__name__` as shown below works:

```diff
diff --git a/mlflow/deployments/server/app.py b/mlflow/deployments/server/app.py
index 235a075c90..133864f5f3 100644
--- a/mlflow/deployments/server/app.py
+++ b/mlflow/deployments/server/app.py
@@ -64,13 +64,13 @@ class GatewayAPI(FastAPI):
                 path=(
                     MLFLOW_DEPLOYMENTS_ENDPOINTS_BASE + route.name + MLFLOW_DEPLOYMENTS_QUERY_SUFFIX
                 ),
-                endpoint=_route_type_to_endpoint(route, limiter),
+                endpoint=_route_type_to_endpoint(route, limiter, ""deployments""),
                 methods=[""POST""],
             )
             # TODO: Remove Gateway server URLs after deprecation window elapses
             self.add_api_route(
                 path=f""{MLFLOW_GATEWAY_ROUTE_BASE}{route.name}{MLFLOW_QUERY_SU
FFIX}"",
-                endpoint=_route_type_to_endpoint(route, limiter),
+                endpoint=_route_type_to_endpoint(route, limiter, ""gateway""),
                 methods=[""POST""],
                 include_in_schema=False,
             )
@@ -115,7 +115,7 @@ async def _custom(request: Request):
     return request.json()
 
 
-def _route_type_to_endpoint(config: RouteConfig, limiter: Limiter):
+def _route_type_to_endpoint(config: RouteConfig, limiter: Limiter, key: str):
     provider_to_factory = {
         RouteType.LLM_V1_CHAT: _create_chat_endpoint,
         RouteType.LLM_V1_COMPLETIONS: _create_completions_endpoint,
@@ -125,6 +125,7 @@ def _route_type_to_endpoint(config: RouteConfig, limiter: L
imiter):
         handler = factory(config)
         if limit := config.limit:
             limit_value = f""{limit.calls}/{limit.renewal_period}""
+            handler.__name__ = f""{handler.__name__}_{config.name}_{key}""
             return limiter.limit(limit_value)(handler)
         else:
             return handler
```",might cause backward compatibility create two one one gateway prefix one prefix route lead duplicate request hack shown work git index class route limiter route limiter post remove gateway server deprecation window route limiter route limiter gateway post request request return limiter limiter limiter limiter key limiter handler factory limit key return handler else return handler,issue,negative,neutral,neutral,neutral,neutral,neutral
1895561760,"This change fixes the issue:

```diff
diff --git a/mlflow/deployments/server/app.py b/mlflow/deployments/server/app.py
index 235a075c90..6af2b0717d 100644
--- a/mlflow/deployments/server/app.py
+++ b/mlflow/deployments/server/app.py
@@ -68,12 +68,12 @@ class GatewayAPI(FastAPI):
                 methods=[""POST""],
             )
             # TODO: Remove Gateway server URLs after deprecation window elapses
-            self.add_api_route(
-                path=f""{MLFLOW_GATEWAY_ROUTE_BASE}{route.name}{MLFLOW_QUERY_SUFFIX}"",
-                endpoint=_route_type_to_endpoint(route, limiter),
-                methods=[""POST""],
-                include_in_schema=False,
-            )
+            # self.add_api_route(
+            #     path=f""{MLFLOW_GATEWAY_ROUTE_BASE}{route.name}{MLFLOW_QUERY_SUFFIX}"",
+            #     endpoint=_route_type_to_endpoint(route, limiter),
+            #     methods=[""POST""],
+            #     include_in_schema=False,
+            # )
             self.dynamic_routes[route.name] = route.to_route()
 
     def get_dynamic_route(self, route_name: str) -> Optional[Route]:
```",change issue git index class post remove gateway server deprecation window route limiter post route limiter post self optional route,issue,negative,neutral,neutral,neutral,neutral,neutral
1895516853,"Does rate limiting work correctly for you? I'm testing with the following config but hit `Rate limit exceeded` before I make 5 requests:

```
    limit:
      renewal_period: ""minute""
      calls: 5
```",rate limiting work correctly testing following hit rate limit make limit minute,issue,negative,neutral,neutral,neutral,neutral,neutral
1895315850,I actually installed langchain-community from your branch. Let me try one more time.,actually branch let try one time,issue,negative,neutral,neutral,neutral,neutral,neutral
1895302487,"It looks we set the default for `max_results` for other search APIs such as `search_model_versions`. Perhaps we could do the same thing for search experiments, but we need to check how this would impact databricks.",set default search perhaps could thing search need check would impact,issue,negative,neutral,neutral,neutral,neutral,neutral
1895285400,@moghadas76 This is not a bug. I remember we've received a similar request before and rejected it. Let me find that.,bug remember received similar request let find,issue,negative,neutral,neutral,neutral,neutral,neutral
1895248534,"@kuboszekadr Can you try setting `targets`? It worked for me once I added it.

```python
import pandas as pd
import numpy as np

import mlflow
from mlflow.metrics.genai import answer_similarity

# Define the number of rows
n_rows = 10

# Define the column names
column_names = [""targets"", ""inputs"", ""predictions""]

# Define the length of each string
string_length = 10

# Define the characters to use in the strings
characters = list(""abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789"")

# Create the DataFrame
df = pd.DataFrame(
    np.random.choice(characters, size=(n_rows, len(column_names) * string_length)).view(
        ""U"" + str(string_length)
    ),
    columns=column_names,
)

print(df.head())

assert ""targets"" in df.columns

mlflow.evaluate(
    data=df,
    targets=""targets"",  # 👈
    predictions=""predictions"",
    extra_metrics=[answer_similarity()],
)
```",try setting worked added python import import import import define number define column define length string define use list create print assert,issue,negative,neutral,neutral,neutral,neutral,neutral
1894907888,"Rendered local html build diff
```
/Users/michael.berk/dev/mlflow/google-docs/batch_4/mlflow/docs/build/html/python_api/mlflow.html
------------------------------
1822: -                  – The experiment name, which must be unique and is case sensitive
1823: +                  – The experiment name, which must be unique and is case sensitive.
1832: -                  – The location to store run artifacts.
1833: +                  – The location to store run artifacts. If not provided, the server picks
1835: - If not provided, the server picks an appropriate default.
1836: + an appropriate default.
1844: -                  – An optional dictionary of string keys and values to set as
1845: +                  – An optional dictionary of string keys and values to set as tags on the experiment.
1847: - tags on the experiment.
1858: -                String ID of the created experiment.
1859: +                 String ID of the created experiment.
1869: -                Example
1870: +                   Example
1987: -                – The The string-ified experiment ID returned from
1989: +                – The string-ified experiment ID returned from
2128: - print(
2129: -     f""run_id: {run_id}; lifecycle_stage: {mlflow.get_run(run_id).info.lifecycle_stage}""
2131: + lifecycle_stage = mlflow.get_run(run_id).info.lifecycle_stage
2133: - )
2134: + print(f""run_id: {run_id}; lifecycle_stage: {lifecycle_stage}"")
4872: - If
4875: +              If
5452: -                Example
5476: -                Output
5544: +              Fetch the run from backend store. The resulting Run contains a collection of run metadata –
5545: -              Fetch the run from backend store. The resulting
5549: -                 Run
5553: -              contains a collection of run metadata –
5557: -                 RunInfo
5561: -              ,
5562: - as well as a collection of run parameters, tags, and metrics –
5563: + RunInfo as well as a collection of run parameters, tags, and metrics – RunData. It also
5568: -                 RunData
5572: -              . It also contains a collection of run
5573: - inputs (experimental), including information about datasets used by the run –
5575: + contains a collection of run inputs (experimental), including information about datasets used by
5577: + the run – RunInputs. In the case where multiple metrics with the same key are logged for the
5581: -                 RunInputs
5585: -              . In the case where multiple metrics with the
5586: - same key are logged for the run, the
5590: -                 RunData
5594: -              contains the
5595: - most recently logged value at the largest step for each metric.
5596: + run, the RunData contains the most recently logged value at the largest step for each metric.
5616: -                A single
5620: -                   mlflow.entities.Run
5624: -                object, if the run exists. Otherwise,
5625: +                A single Run object, if the run exists. Otherwise, raises an exception.
5627: - raises an exception.
5727: -                Example
5746: -                Output
7439: -               Returns
7443: -                None
7680: -                  – Metric name (string). This string may only contain alphanumerics, underscores (_),
7682: +                  – Metric name. This string may only contain alphanumerics, underscores (_),
7694: -                  – Metric value (float). Note that some special values such as +/- Infinity may be
7696: +                  – Metric value. Note that some special values such as +/- Infinity may be
7708: -                  – Metric step (int). Defaults to zero if unspecified.
7710: +                  – Metric step. Defaults to zero if unspecified.
8150: -                  – Parameter name (string). This string may only contain alphanumerics,
8152: +                  – Parameter name. This string may only contain alphanumerics, underscores (_), dashes
8154: + (-), periods (.), spaces ( ), and slashes (/). All backend stores support keys up to
8155: + length 250, but some may support larger keys.
8156: - underscores (_), dashes (-), periods (.), spaces ( ), and slashes (/).
8157: - All backend stores support keys up to length 250, but some may
8158: - support larger keys.
8166: -                  – Parameter value (string, but will be string-ified if not).
8168: +                  – Parameter value, but will be string-ified if not. All built-in backend stores support
8170: + values up to length 6000, but some may support larger values.
8171: - All built-in backend stores support values up to length 6000, but some
8172: - may support larger values.
8184: -                  If True, blocks until the parameter is logged
8185: +                  If True, blocks until the parameter is logged successfully. If
8187: - successfully. If False, logs the parameter asynchronously and
8188: - returns a future representing the logging operation.
8189: + False, logs the parameter asynchronously and returns a future representing the logging
8190: + operation.
8216: -                instance that
8217: +                instance that represents
8219: - represents future for logging operation.
8221: + future for logging operation.
8597: -               Returns
8601: -                None
9080: - Note that this method assumes the model registry backend URI is the same as that of the
9081: +              Note that this method assumes the model registry backend URI is the same as that of the
10197: -                   ), defaults to searching for all
10199: +                   ), defaults to
10200: - experiments. The following identifiers, comparators, and logical operators are supported.
10202: + searching for all experiments. The following identifiers, comparators, and logical
10204: + operators are supported.
10444: -                   , so
10446: +                   ,
10447: + so
10453: -                   is
10454: +                   is equivalent to
10456: - equivalent to
10474: -                   ,
10475: - which lists experiments updated most recently first. The following fields are supported:
10476: +                   , which lists experiments updated most recently first.
10477: + The following fields are supported:
11012: -                A list of
11013: +                  A list of
11020: -                   mlflow.entities.model_registry.ModelVersion
11021: +                     mlflow.entities.model_registry.ModelVersion
11026: +                  objects
11032: -                objects
11033: - that satisfy the search expressions.
11034: +                   that satisfy the search expressions.
11302: +                   Filter query string (e.g., “name = ‘a_model_name’ and tag.key = ‘value1’”),
11303: -                   Filter query string
11304: - (e.g.,
11307: -                     ""name
11310: -                     =
11313: -                     'a_model_name'
11316: -                     and
11319: -                     tag.key
11322: -                     =
11325: -                     'value1'""
11328: -                   ),
11342: -                         name
11345: -                       : registered model name.
11346: +                       ”name”: registered model name.
11354: -                         tags.<tag_key>
11357: -                       : registered model tag. If
11362: -                         tag_key
11365: -                       contains spaces, it must be
11366: - wrapped with backticks (e.g.,
11369: +                       ”tags.<tag_key>”: registered model tag. If “tag_key” contains spaces, it must be
11370: + wrapped with backticks (e.g., “tags.`extra key`”).
11371: -                         ""tags.`extra
11374: -                         key`""
11377: -                       ).
11391: -                         =
11394: -                       : Equal to.
11395: +                       ”=”: Equal to.
11403: -                         !=
11410: -                       : Not equal to.
11411: +                       ”!=”: Not equal to.
11419: -                         LIKE
11426: -                       : Case-sensitive pattern match.
11427: +                       ”LIKE”: Case-sensitive pattern match.
11435: -                         ILIKE
11442: -                       : Case-insensitive pattern match.
11443: +                       ”ILIKE”: Case-insensitive pattern match.
11458: -                         AND
11461: -                       : Combines two sub-queries and returns True if both of them are True.
11462: +                       ”AND”: Combines two sub-queries and returns True if both of them are True.
12262: -                If output_format is
12265: -                  list
12268: -                : a list of
12270: +                a list of
12316: +               Return type
12320: -                Example
12327: +                 If output_format is
12330: +                   list
12337: +                   Example
12630: - Lifecycle_stage: active
12632: + Lifecycle_stage: activ
12721: -                  – Tag name (string). This string may only contain alphanumerics, underscores
12723: +                  – Tag name. This string may only contain alphanumerics, underscores (_), dashes (-),
12725: + periods (.), spaces ( ), and slashes (/). All backend stores will support keys up to
12726: + length 250, but some may support larger keys.
12727: - (_), dashes (-), periods (.), spaces ( ), and slashes (/).
12728: - All backend stores will support keys up to length 250, but some may
12729: - support larger keys.
12737: +                  – Tag value, but will be string-ified if not. All backend stores will support values
12738: + up to length 5000, but some may support larger values.
12739: -                  – Tag value (string, but will be string-ified if not).
12740: - All backend stores will support values up to length 5000, but some
12741: - may support larger values.
12944: -                –
12948: -                   An empty string, or a local file path, prefixed with
12950: +                – An empty string, or a local file path, prefixed with
12954: +                  file:/
12959: -                     file:/
12962: -                   . Data is stored
12964: +                . Data is stored
12970: -                     ./mlruns
12972: +                  ./mlruns
12975: -                   if empty).
12982: -                   An HTTP URI like
12984: +                if empty). An HTTP URI like
12990: -                     https://my-tracking-server:5000
12992: +                  https://my-tracking-server:5000
12995: -                   .
13002: -                   A Databricks workspace, provided as the string “databricks” or, to use a
13004: +                . A Databricks workspace, provided as the string
13006: - Databricks CLI
13007: + “databricks” or, to use a Databricks CLI
13011: -                    profile
13013: +                 profile
13017: -                   ,
13019: +                ,
13314: -              Set a tag under the current run. If no run is active, this method will create a
13315: +              Set a tag under the current run. If no run is active, this method will create a new active
13317: - new active run.
13318: + run.
13331: -                  – Tag name (string). This string may only contain alphanumerics, underscores
13333: +                  – Tag name. This string may only contain alphanumerics, underscores (_), dashes (-),
13335: + periods (.), spaces ( ), and slashes (/). All backend stores will support keys up to
13336: + length 250, but some may support larger keys.
13337: - (_), dashes (-), periods (.), spaces ( ), and slashes (/).
13338: - All backend stores will support keys up to length 250, but some may
13339: - support larger keys.
13347: +                  – Tag value, but will be string-ified if not. All backend stores will support values
13348: + up to length 5000, but some may support larger values.
13349: -                  – Tag value (string, but will be string-ified if not).
13350: - All backend stores will support values up to length 5000, but some
13351: - may support larger values.
13363: -                  If True, blocks until the tag is logged
13364: +                  If True, blocks until the tag is logged successfully. If False,
13366: - successfully. If False, logs the tag asynchronously and
13367: - returns a future representing the logging operation.
13368: + logs the tag asynchronously and returns a future representing the logging operation.
13568: - logs tags asynchronously and returns a future representing the logging
13569: + logs tags asynchronously and returns a future representing the logging operation.
13571: - operation.
13727: +                   . Data is stored locally at the provided file (or
13728: -                   . Data is stored
13729: - locally at the provided file (or
13751: -                   A Databricks workspace, provided as the string “databricks” or, to use a
13752: +                   A Databricks workspace, provided as the string “databricks” or, to use a Databricks CLI
13754: - Databricks CLI
13758: -                   ,
13759: - “databricks://<profileName>”.
13760: +                   , “databricks://<profileName>”.
/Users/michael.berk/dev/mlflow/google-docs/batch_4/mlflow/docs/build/html/python_api/mlflow.client.html
------------------------------
689: -                    – the model URI of the model version to copy. This must be a model
691: +                    – The model URI of the model version to copy. This must be a model
709: -                    – the name of the registered model to copy the model version to. If a
711: +                    – The name of the registered model to copy the model version to. If a
981: -                    – The location to store run artifacts.
982: +                    – The location to store run artifacts. If not provided, the server
984: - If not provided, the server picks an appropriate default.
985: + picks anappropriate default.
1397: -                    – Run ID from MLflow tracking server that generated the model
1398: +                    – Run ID from MLflow tracking server that generated the model.
2191: - This deletion is a soft-delete, not a permanent deletion.
2192: - Experiment names can not be reused, unless the deleted experiment
2193: - is permanently deleted by a database admin.
2196: +                This deletion is a soft-delete, not a permanent deletion. Experiment names can not be
2197: + reused, unless the deleted experiment is permanently deleted by a database admin.
2625: - When stage is set, tag will be deleted for latest model version of the stage.
2626: +                When stage is set, tag will be deleted for latest model version of the stage.
2671: -                 Returns
2675: -                  None
2977: -                 Returns
2981: -                  None
3180: -                 Returns
3184: -                  None
3434: -                    – String ID of the run
3435: +                    – String ID of the run.
3444: -                    – Name of the tag
3445: +                    – Name of the tag.
4335: -                    – Unique identifier for run
4336: +                    – Unique identifier for run.
4345: -                    – Metric name within the run
4346: +                    – Metric name within the run.
4365: -                  entities if logged, else empty list
4366: +                  entities if logged, else empty list.
4517: +                Converts the docstring args and returns to google style.
4732: -                  A single
4733: +                   A single
4740: -                     mlflow.entities.model_registry.ModelVersion
4741: +                      mlflow.entities.model_registry.ModelVersion
4748: -                  object.
4749: +                   object.
4759: -                  Example
4760: +                     Example
4965: -                  Example
5006: -                  Output
5113: +                This is a docstring. Here is info.
5272: -                  object, if the parent run exists.
5273: +                  object, if the parent run exists. Otherwise,
5275: - Otherwise, returns None.
5276: + returns None.
5373: +                Get a registered model.
6049: -                  pandas.DataFrame containing the loaded table if the artifact exists
6050: +                    pandas.DataFrame containing the loaded table if the artifact exists
6052: - or else throw a MlflowException.
6058: +                     or else throw a MlflowException.
6065: -                  Example with passing run_ids
6066: +                     Example with passing run_ids
6771: +                 Raises
6773: -                Raises an MlflowException if any errors occur.
6781: +                    mlflow.MlflowException
6784: +                  – If any errors occur.
7759: -                    – String ID of the run
7760: +                    – String ID of the run.
7783: +                 Raises
7785: -                Raises an MlflowException if any errors occur.
7786: - :return: None
7794: +                    mlflow.MlflowException
7797: +                  – If any errors occur.
8031: -                    – Metric name (string). This string may only contain alphanumerics, underscores
8033: +                    – Metric name. This string may only contain alphanumerics, underscores
8045: -                    – Metric value (float). Note that some special values such
8047: +                    – Metric value. Note that some special values such
8322: -                    – Parameter name (string). This string may only contain alphanumerics, underscores
8324: +                    – Parameter name. This string may only contain alphanumerics, underscores
8336: -                    – Parameter value (string, but will be string-ified if not).
8338: +                    – Parameter value, but will be string-ified if not.
8617: -                 Returns
8621: -                  None
9677: -                     ), defaults to searching for all
9679: +                     ), defaults to
9680: - experiments. The following identifiers, comparators, and logical operators are
9682: + searching for all experiments. The following identifiers, comparators, and logical
9684: - supported.
9685: + operators are supported.
9925: -                     , so
9927: +                     ,
9928: + so
9934: -                     is
9935: +                     is equivalent to
9937: - equivalent to
9955: -                     ,
9956: - which lists experiments updated most recently first. The following fields are supported:
9957: +                     , which lists experiments updated most recently first.
9958: + The following fields are supported:
10362: - defaults to searching for all model versions. The following identifiers, comparators,
10364: + defaults to searching for all model versions. The following identifiers,
10365: - and logical operators are supported.
10366: + comparators, and logical operators are supported.
10418: -                         contains spaces, it must be
10420: +                         contains spaces, it must
10421: - wrapped with backticks (e.g.,
10422: + be wrapped with backticks (e.g.,
10863: +                     Filter query string (e.g., “name = ‘a_model_name’ and tag.key =
10864: -                     Filter query string
10865: - (e.g.,
10868: -                       ""name
10871: -                       =
10874: -                       'a_model_name'
10877: -                       and
10880: -                       tag.key
10883: -                       =
10886: -                       'value1'""
10889: -                     ),
10890: - defaults to searching for all registered models. The following identifiers, comparators,
10892: + ‘value1’”), defaults to searching for all registered models. The following
10894: - and logical operators are supported.
10895: + identifiers, comparators, and logical operators are supported.
10926: -                         contains spaces, it must be
10928: +                         contains spaces, it
10929: + must be wrapped with backticks (e.g., “tags.`extra key`”).
10930: - wrapped with backticks (e.g.,
10933: -                           ""tags.`extra
10936: -                           key`""
10939: -                         ).
11750: -                  Example
11775: -                  Output
12053: -                 Returns
12057: -                  None
12277: -                 Returns
12281: -                  None
12464: -                 Returns
12468: -                  None
12676: +                    – Tag name. This string may only contain alphanumerics, underscores (_), dashes (-),
12677: + periods (.), spaces ( ), and slashes (/). All backend stores will support keys up to
12678: + length 250, but some may support larger keys.
12679: -                    – Tag name (string). This string may only contain alphanumerics,
12680: - underscores (_), dashes (-), periods (.), spaces ( ), and slashes (/).
12681: - All backend stores will support keys up to length 250, but some may
12682: - support larger keys.
12690: -                    – Tag value (string, but will be string-ified if not).
12692: +                    – Tag value, but will be string-ified if not. All backend stores will support
12694: + values up to length 5000, but some may support larger values.
12695: - All backend stores will support values up to length 5000, but some
12696: - may support larger values.
12708: -                    If True, blocks until the tag is logged successfully.
12709: +                    If True, blocks until the tag is logged successfully. If
12711: - If False, logs the tag asynchronously and returns a future
12713: + False, logs the tag asynchronously and returns a future representing the logging
12715: - representing the logging operation.
12716: + operation.
12738: -                     mlflow.utils.async_logging.run_operations.RunOperations
12740: +                   mlflow.utils.async_logging.run_operations.RunOperations
12746: -                  instance that
12747: +                  instance that represents
12749: - represents future for logging operation.
12751: + future for logging operation.
12958: +                    . Defaults to “FINISHED”.
12959: -                    .
12960: - Defaults to “FINISHED”.
12977: -                  Example
13014: -                  Output
13222: - versions in the stage will be automatically moved to the “archived” stage. Only valid
13224: + versions in the stage will be automatically moved to the “archived” stage. Only
13225: - when
13226: + valid when
13244: -                    otherwise an error will be raised.
13246: +                    otherwise an error will be
13247: + raised.
13258: -                  A single
13259: +                   A single
13266: -                     mlflow.entities.model_registry.ModelVersion
13267: +                      mlflow.entities.model_registry.ModelVersion
13274: -                  object.
13275: +                   object.
13285: -                  Example
13286: +                     Example
13515: -                  A single
13516: +                   A single
13523: -                     mlflow.entities.model_registry.ModelVersion
13524: +                      mlflow.entities.model_registry.ModelVersion
13531: -                  object.
13532: +                   object.
13542: -                  Example
13543: +                     Example
13967: -                    – The new status of the run to set, if specified.
13968: +                    – The new status of the run to set, if specified. At least one of
13970: - At least one of
13990: -                    – The new name of the run to set, if specified.
13991: +                    – The new name of the run to set, if specified. At least one of
13993: - At least one of






List of all files with diffs:
------------------------------
/Users/michael.berk/dev/mlflow/google-docs/batch_4/mlflow/docs/build/html/python_api/mlflow.html
/Users/michael.berk/dev/mlflow/google-docs/batch_4/mlflow/docs/build/html/python_api/mlflow.client.html
```",local build experiment name must unique case sensitive experiment name must unique case sensitive location store run location store run provided server provided server appropriate default appropriate default optional dictionary string set optional dictionary string set experiment experiment string id experiment string id experiment example example experiment id returned experiment id returned print print example output fetch run store resulting run collection run fetch run store resulting run collection run well collection run metric well collection run metric also also collection run experimental information used run collection run experimental information used run case multiple metric key logged case multiple metric key logged run recently logged value step metric run recently logged value step metric single object run otherwise single run object run otherwise exception exception example output none metric name string string may contain metric name string may contain metric value float note special infinity may metric value note special infinity may metric step zero unspecified metric step zero unspecified parameter name string string may contain parameter name string may contain support length may support support length may support parameter value string parameter value support length may support support length may support true parameter logged true parameter logged successfully successfully false parameter future logging operation false parameter future logging operation instance instance future logging operation future logging operation none note method model registry note method model registry searching following logical searching following logical equivalent equivalent recently first following recently first following list list satisfy search satisfy search filter query string name value filter query string name name registered model name name registered model name registered model tag must wrapped registered model tag must wrapped extra key extra key equal equal equal equal like pattern match like pattern match pattern match pattern match two true true two true true list list list return type example list example active tag name string string may contain tag name string may contain support length may support support length may support tag value support length may support tag value string support length may support empty string local file path prefixed empty string local file path prefixed file file data data empty like empty like provided string use provided string use profile profile set tag current run run active method create set tag current run run active method create new active new active run run tag name string string may contain tag name string may contain support length may support support length may support tag value support length may support tag value string support length may support true tag logged true tag logged successfully false successfully false tag future logging operation tag future logging operation future logging future logging operation operation data locally provided file data locally provided file provided string use provided string use model model version copy must model model model version copy must model name registered model copy model version name registered model copy model version location store run location store run provided server provided server appropriate default default run id server model run id server model deletion permanent deletion experiment unless experiment permanently deletion permanent deletion experiment unless experiment permanently stage set tag latest model version stage stage set tag latest model version stage none none none string id run string id run name tag name tag unique identifier run unique identifier run metric name within run metric name within run logged else empty list logged else empty list style single single object object example example example output object parent run object parent run otherwise otherwise none none get registered model loaded table artifact loaded table artifact else throw else throw example passing example passing occur occur string id run string id run occur return none occur metric name string string may contain metric name string may contain metric value float note special metric value note special parameter name string string may contain parameter name string may contain parameter value string parameter value none searching following logical searching following logical equivalent equivalent recently first following recently first following searching model following searching model following logical logical must must wrapped wrapped filter query string name filter query string name searching registered following value searching registered following logical logical must must wrapped extra key wrapped extra key example output none none none tag name string may contain support length may support tag name string string may contain support length may support tag value string tag value support length may support support length may support true tag logged successfully true tag logged successfully false tag future false tag future logging logging operation operation instance instance future logging operation future logging operation finished finished example output stage automatically stage valid stage automatically stage valid otherwise error raised otherwise error raised single single object object example example single single object object example example new status run set new status run set least one least one new name run set new name run set least one least one list,issue,positive,positive,neutral,neutral,positive,positive
1894860325,@harupy Thank you for reviewing this PR! Can I ask if there is anything I should add or modify on this PR?,thank ask anything add modify,issue,negative,neutral,neutral,neutral,neutral,neutral
1894743248,Hi @BenWilson2 have you checked this? Can you run the tests or have any additional instructions that should I follow to run them by myself?,hi checked run additional follow run,issue,negative,neutral,neutral,neutral,neutral,neutral
1894570512,I can confirm that we have similar issue with MLFlow Deployment Server when running using simple `docker run` with a single OpenAI endpoint,confirm similar issue deployment server running simple docker run single,issue,negative,negative,neutral,neutral,negative,negative
1894321493,"Rendered HTML diff ([logic](https://github.com/michael-berk/llm-documentation-modifier/blob/main/extras/compare.py)):
```
/Users/michael.berk/dev/mlflow/google-docs/batch_1/mlflow/docs/build/html/python_api/mlflow.fastai.html
------------------------------
710: - Logs loss and any other metrics specified in the fit
711: - function, and optimizer data as parameters. Model checkpoints
714: +              Logs loss and any other metrics specified in the fit function, and optimizer data as parameters.
715: - are logged as artifacts to a ‘models’ directory.
716: + Model checkpoints are logged as artifacts to a ‘models’ directory.
747: -                  , trained models are logged as MLflow model artifacts.
748: +                  , trained models are logged as MLflow model artifacts. If
750: - If
756: +                  ,
757: -                  , trained models are not logged.
759: + trained models are not logged.
773: -                  , dataset information is logged to MLflow Tracking.
774: +                  , dataset information is logged to MLflow Tracking. If
776: - If
782: +                  ,
783: -                  , dataset information is not logged.
785: + dataset information is not logged.
805: -                  ,
806: +                  , enables
808: - enables the Fastai autologging integration.
810: + the Fastai autologging integration.
824: -                  , autologged content is not logged to user-created fluent runs.
825: +                  , autologged content is not logged to user-created fluent runs. If
827: - If
833: -                  , autologged content is logged to the active fluent run,
834: +                  , autologged content is logged to the active fluent run, which may
836: - which may be user-created.
838: + be user-created.
852: -                  , disable autologging for versions of
853: +                  , disable autologging for versions of fastai
855: - fastai that have not been tested against this version of the MLflow client
857: + that have not been tested against this version of the MLflow client or are
859: - or are incompatible.
861: + incompatible.
882: -                  , show all events and warnings during Fastai
883: +                  , show all events and warnings during Fastai autologging.
890: +                   registered_model_name
892: +                  – If given, each time a model is trained, it is registered as a new
893: + model version of the registered model with this name. The registered model is created
894: + if it does not already exist.
900: +                   extra_tags
902: +                  – A dictionary of extra tags to set on each managed run created by
909: -                   registered_model_name
911: -                  – If given, each time a model is trained, it is registered as a
912: - new model version of the registered model with this name.
913: - The registered model is created if it does not already exist.
919: -                   extra_tags
921: -                  – A dictionary of extra tags to set on each managed run created by autologging.
1818: +                   Describes model input and output Schema. The model signature can be inferred
1822: -                      ModelSignature
1826: -                   describes model input and output
1830: -                      Schema
1834: -                   .
1835: - The model signature can be
1839: -                      inferred
1843: -                   from datasets with valid model input (e.g. the training dataset with target
1845: + from datasets with valid model input (e.g. the training dataset with target
2145: +                A ModelInfo instance that contains the metadata of the logged model.
2146: -                A
2150: -                   ModelInfo
2154: -                instance that contains the
2155: - metadata of the logged model.
2658: +                   Describes model input and output Schema. The model signature can be inferred
2662: -                      ModelSignature
2666: -                   describes model input and output
2670: -                      Schema
2674: -                   .
2675: - The model signature can be
2679: -                      inferred
2683: -                   from datasets with valid model input (e.g. the training dataset with target
2685: + from datasets with valid model input (e.g. the training dataset with target
/Users/michael.berk/dev/mlflow/google-docs/batch_1/mlflow/docs/build/html/python_api/mlflow.deployments.html
------------------------------
952: -                from the specified target. Deletion should be
954: +                from the specified target.
957: - idempotent (i.e. deletion should not fail if retried on a non-existent deployment).
959: +                Deletion should be idempotent (i.e. deletion should not fail if retried on a non-existent
961: + deployment).
1277: -                    – ID of deployment to fetch
1278: +                    – ID of deployment to fetch.
1288: - supported by all targets
1289: + supported by all targets.
1422: +                List deployments.
1425: -                List deployments. This method is expected to return an unpaginated list of all
1427: +                This method is expected to return an unpaginated list of all
1599: - Note that the input/output types of this method match those of
1600: +                Note that the input/output types of this method match those of
1618: -                    – Name of deployment to predict against
1619: +                    – Name of deployment to predict against.
1629: - inference
1630: + inference.
1639: -                    – Endpoint to predict against. May not be supported by all targets
1640: +                    – Endpoint to predict against. May not be supported by all targets.
1797: -                    – Unique name of deployment to update
1798: +                    – Unique name of deployment to update.
1843: - deployment
1844: + deployment.
1854: - supported by all targets
1855: + supported by all targets.
2237: - See
2240: +                See
2475: -                  A
2479: -                     DatabricksEndpoint
2483: -                  object containing the request response.
2484: +                  A DatabricksEndpoint object containing the request response.
2631: -                  A
2635: -                     DatabricksEndpoint
2639: -                  object containing the request response.
2640: +                  A DatabricksEndpoint object containing the request response.
2758: - See
2761: +                See
3977: - :return: A list of
3983: +                 Returns
3984: -                  Endpoint
3989: +                  A list of
3994: +                    Endpoint
3997: -                objects.
3998: +                  objects.
5860: + the “ndarray” predictions_format is specified.
5861: - the
5864: -                      ""ndarray""
5869: -                      predictions_format
5872: -                    is specified.
5878: +                 Raises
5879: -                 Throws
5885: +                   Exception
5891: -                  Exception if the predictions cannot be represented in the specified format.
5893: +                  – If the predictions cannot be represented in the specified format.
/Users/michael.berk/dev/mlflow/google-docs/batch_1/mlflow/docs/build/html/python_api/mlflow.models.html
------------------------------
7773: -               '/Users/michael.berk/dev/mlflow/google-docs/mlflow_old/mlflow/mlflow/utils/env_manager.py'>
7775: +               '/Users/michael.berk/dev/mlflow/google-docs/batch_1/mlflow/mlflow/utils/env_manager.py'>
/Users/michael.berk/dev/mlflow/google-docs/batch_1/mlflow/docs/build/html/python_api/mlflow.langchain.html
------------------------------
771: -                A LangChain model instance
772: +                A LangChain model instance.
1164: -                   Agent
1165: +                   Agent <https://python.langchain.com/docs/modules/agents/>
/Users/michael.berk/dev/mlflow/google-docs/batch_1/mlflow/docs/build/html/python_api/mlflow.johnsnowlabs.html
------------------------------
834: -                   The location, in URI format, of the MLflow model, for example:
836: +                   The location, in URI format, of the MLflow model. For example:
938: +                A
943: +                .
/Users/michael.berk/dev/mlflow/google-docs/batch_1/mlflow/docs/build/html/python_api/mlflow.h2o.html
------------------------------
696: - This function expects there is an H2O instance initialised with
697: +              This function expects there is an H2O instance initialised with
/Users/michael.berk/dev/mlflow/google-docs/batch_1/mlflow/docs/build/html/python_api/mlflow.gateway.html
------------------------------
789: - ‘llm/v1/embeddings’). This parameter is required for routes that are
790: + ‘llm/v1/embeddings’). This parameter is required for routes that are not managed by
792: - not managed by Databricks (the provider isn’t ‘databricks’).
794: + Databricks (the provider isn’t ‘databricks’).
812: -                       The model name (e.g., “gpt-3.5-turbo”)
813: +                         The model name (e.g., “gpt-3.5-turbo”)
821: -                       The provider (e.g., “openai”, “anthropic”)
822: +                         The provider (e.g., “openai”, “anthropic”)
830: -                       The configuration for the model used in the route
831: +                         The configuration for the model used in the route
1369: +                    –
1371: -                    – The data to send in the query. A dictionary representing the per-route
1373: +                     The data to send in the query. A dictionary representing the per-route
1382: -                 Returns
1386: -                  The route’s response as a dictionary, standardized to the route type.
1391: -                For chat, the structure should be:
1392: +                     For chat, the structure should be:
1405: +     {
1406: +         ""messages"": [
1407: -     {""messages"": [{""role"": ""user"", ""content"": ""Tell me a joke about rabbits""}, ...]},
1409: +             {""role"": ""user"", ""content"": ""Tell me a joke about rabbits""},
1411: +         ]
1412: +     },
1418: -                For completions, the structure should be:
1419: +                     For completions, the structure should be:
1437: -                For embeddings, the structure should be:
1438: +                     For embeddings, the structure should be:
1457: -                Additional parameters that are valid for a given provider and route configuration can be
1459: +                     Additional parameters that are valid for a given provider and route configuration
1461: - included with the request as shown below, using an openai completions route request as
1463: + can be included with the request as shown below, using an openai completions route
1465: - an example:
1466: + request as an example:
1492: +                 Returns
1496: +                  The route’s response as a dictionary, standardized to the route type.
1783: -                    –
1785: -                     Limits (Array of dictionary) to set on the route. Each limit is defined by a
1786: +                    – Limits (Array of dictionary) to set on the route. Each limit is defined by a
1788: - dictionary representing the limit details to be associated with the route.
1789: + dictionary representing the limit details to be associated with the route. This
1791: - This dictionary should define:
1793: + dictionary should define:
1794: + - renewal_period: a string representing the length of the window to enforce limit on (only supports “minute” for now). # pylint: disable=line-too-long
1795: + - calls: a non-negative integer representing the number of calls allowed per  renewal_period (e.g., 10, 0, 55). # pylint: disable=line-too-long
1796: + - key: an optional string represents per route limit or per user limit (“user” for per user limit, “route” for per route limit, if not supplied, default to per route limit). # pylint: disable=line-too-long
1803: -                       renewal_period: a string representing the length of the window
1804: - to enforce limit on (only supports “minute” for now).
1809: -                       calls: a non-negative integer representing the number of calls
1810: - allowed per renewal_period (e.g., 10, 0, 55).
1815: -                       key: an optional string represents per route limit or per user
1816: - limit (“user” for per user limit, “route” for per route limit, if not
1817: - supplied, default to per route limit).
2075: -                  –
2077: -                   A dictionary representing the model details to be associated with the route.
2078: +                  – A dictionary representing the model details to be associated with the route.
2081: + - The model name (e.g., “gpt-3.5-turbo”)
2082: + - The provider (e.g., “openai”, “anthropic”)
2083: + - The configuration for the model used in the route
2090: -                     The model name (e.g., “gpt-3.5-turbo”)
2095: -                     The provider (e.g., “openai”, “anthropic”)
2100: -                     The configuration for the model used in the route
2831: -               Warning
2832: +                 Warning
2838: -               MLflow AI gateway is deprecated and has been replaced by the deployments API for generative AI. See
2839: +                 MLflow AI gateway is deprecated and has been replaced by the deployments API for generative AI. See
2844: -                https://mlflow.org/docs/latest/llms/gateway/migration.html
2845: +                  https://mlflow.org/docs/latest/llms/gateway/migration.html
2848: +                 for migration.
2852: -               for migration.
2859: -              Sets the uri of a configured and running MLflow AI Gateway server in a global context.
2860: +               Sets the uri of a configured and running MLflow AI Gateway server in a global context.
2865: - Providing a valid uri and calling this function is required in order to use the MLflow
2866: +                Providing a valid uri and calling this function is required in order to use the MLflow
2872: -               Parameters
2877: -                 gateway_uri
2881: -                – The full uri of a running MLflow AI Gateway server or, if running on
2882: - Databricks, “databricks”.
2885: +                 Args:
2892: +                   gateway_uri: The full uri of a running MLflow AI Gateway server or, if running on
2896: +                    Databricks, “databricks”.
3377: - ‘llm/v1/embeddings’). This parameter is required for routes that are
3378: + ‘llm/v1/embeddings’). This parameter is required for routes that are not managed by
3380: - not managed by Databricks (the provider isn’t ‘databricks’).
3382: + Databricks (the provider isn’t ‘databricks’).
3400: -                       The model name (e.g., “gpt-3.5-turbo”)
3401: +                         The model name (e.g., “gpt-3.5-turbo”)
3409: -                       The provider (e.g., “openai”, “anthropic”)
3410: +                         The provider (e.g., “openai”, “anthropic”)
3418: -                       The configuration for the model used in the route
3419: +                         The configuration for the model used in the route
3957: +                    –
3959: -                    – The data to send in the query. A dictionary representing the per-route
3961: +                     The data to send in the query. A dictionary representing the per-route
3970: -                 Returns
3974: -                  The route’s response as a dictionary, standardized to the route type.
3979: -                For chat, the structure should be:
3980: +                     For chat, the structure should be:
3993: +     {
3994: +         ""messages"": [
3995: -     {""messages"": [{""role"": ""user"", ""content"": ""Tell me a joke about rabbits""}, ...]},
3997: +             {""role"": ""user"", ""content"": ""Tell me a joke about rabbits""},
3999: +         ]
4000: +     },
4006: -                For completions, the structure should be:
4007: +                     For completions, the structure should be:
4025: -                For embeddings, the structure should be:
4026: +                     For embeddings, the structure should be:
4045: -                Additional parameters that are valid for a given provider and route configuration can be
4047: +                     Additional parameters that are valid for a given provider and route configuration
4049: - included with the request as shown below, using an openai completions route request as
4051: + can be included with the request as shown below, using an openai completions route
4053: - an example:
4054: + request as an example:
4080: +                 Returns
4084: +                  The route’s response as a dictionary, standardized to the route type.
4371: -                    –
4373: -                     Limits (Array of dictionary) to set on the route. Each limit is defined by a
4374: +                    – Limits (Array of dictionary) to set on the route. Each limit is defined by a
4376: - dictionary representing the limit details to be associated with the route.
4377: + dictionary representing the limit details to be associated with the route. This
4379: - This dictionary should define:
4381: + dictionary should define:
4382: + - renewal_period: a string representing the length of the window to enforce limit on (only supports “minute” for now). # pylint: disable=line-too-long
4383: + - calls: a non-negative integer representing the number of calls allowed per  renewal_period (e.g., 10, 0, 55). # pylint: disable=line-too-long
4384: + - key: an optional string represents per route limit or per user limit (“user” for per user limit, “route” for per route limit, if not supplied, default to per route limit). # pylint: disable=line-too-long
4391: -                       renewal_period: a string representing the length of the window
4392: - to enforce limit on (only supports “minute” for now).
4397: -                       calls: a non-negative integer representing the number of calls
4398: - allowed per renewal_period (e.g., 10, 0, 55).
4403: -                       key: an optional string represents per route limit or per user
4404: - limit (“user” for per user limit, “route” for per route limit, if not
4405: - supplied, default to per route limit).
/Users/michael.berk/dev/mlflow/google-docs/batch_1/mlflow/docs/build/html/python_api/openai/index.html
------------------------------
785: +                Parameters
788: -                  Args:
796: +                    model_uri
803: -                    model_uri: The location, in URI format, of the MLflow model. For example:
805: +                   –
808: +                    The location, in URI format, of the MLflow model. For example:
816: -                         /Users/me/path/to/local/model
818: +                        /Users/me/path/to/local/model
829: -                         relative/path/to/local/model
831: +                        relative/path/to/local/model
842: -                         s3://my_bucket/path/to/model
844: +                        s3://my_bucket/path/to/model
855: -                         runs:/<mlflow_run_id>/run-relative/path/to/model
857: +                        runs:/<mlflow_run_id>/run-relative/path/to/model
866: -                     For more information about supported URI schemes, see
868: +                    For more information about supported URI schemes, see
872: -                      Referencing Artifacts
874: +                     Referencing Artifacts
878: -                     .
880: +                    .
889: +                    dst_path
891: -                    dst_path: The local filesystem path to which to download the model artifact.
893: +                   – The local filesystem path to which to download the model artifact.
898: -                     This directory must already exist. If unspecified, a local output
900: + This directory must already exist. If unspecified, a local output
907: -                  Returns:
911: -                   A dictionary representing the OpenAI model.
917: +                Returns
921: +                 A dictionary representing the OpenAI model.






List of all files with diffs:
------------------------------
/Users/michael.berk/dev/mlflow/google-docs/batch_1/mlflow/docs/build/html/python_api/mlflow.fastai.html
/Users/michael.berk/dev/mlflow/google-docs/batch_1/mlflow/docs/build/html/python_api/mlflow.deployments.html
/Users/michael.berk/dev/mlflow/google-docs/batch_1/mlflow/docs/build/html/python_api/mlflow.models.html
/Users/michael.berk/dev/mlflow/google-docs/batch_1/mlflow/docs/build/html/python_api/mlflow.langchain.html
/Users/michael.berk/dev/mlflow/google-docs/batch_1/mlflow/docs/build/html/python_api/mlflow.johnsnowlabs.html
/Users/michael.berk/dev/mlflow/google-docs/batch_1/mlflow/docs/build/html/python_api/mlflow.h2o.html
/Users/michael.berk/dev/mlflow/google-docs/batch_1/mlflow/docs/build/html/python_api/mlflow.gateway.html
/Users/michael.berk/dev/mlflow/google-docs/batch_1/mlflow/docs/build/html/python_api/openai/index.html

```",logic loss metric fit function data model loss metric fit function data logged directory model logged directory trained logged model trained logged model trained logged trained logged information logged information logged information logged information logged integration integration content logged fluent content logged fluent content logged active fluent run content logged active fluent run may may disable disable tested version client tested version client incompatible incompatible show show given time model trained registered new model version registered model name registered model already exist dictionary extra set run given time model trained registered new model version registered model name registered model already exist dictionary extra set run model input output schema model signature model input output schema model signature valid model input training target valid model input training target instance logged model instance logged model model input output schema model signature model input output schema model signature valid model input training target valid model input training target target deletion target idempotent deletion fail deployment deletion idempotent deletion fail deployment id deployment fetch id deployment fetch list list method return list method return list note method match note method match name deployment predict name deployment predict inference inference predict may predict may unique name deployment update unique name deployment update deployment deployment see see object request response object request response object request response object request response see see return list list exception exception format format model instance model instance agent agent location format model example location format model example function ho instance function ho instance parameter parameter provider provider model name model name provider anthropic provider anthropic configuration model used route configuration model used route data send query dictionary data send query dictionary route response dictionary standardized route type chat structure chat structure role user content tell joke role user content tell joke structure structure structure structure additional valid given provider route configuration additional valid given provider route configuration included request shown route request included request shown route example request example route response dictionary standardized route type array dictionary set route limit defined array dictionary set route limit defined dictionary limit associated route dictionary limit associated route dictionary define dictionary define string length window enforce limit minute integer number per key optional string per route limit per user limit user per user limit route per route limit default per route limit string length window enforce limit minute integer number per key optional string per route limit per user limit user per user limit route per route limit default per route limit dictionary model associated route dictionary model associated route model name provider anthropic configuration model used route model name provider anthropic configuration model used route warning warning ai gateway generative ai see ai gateway generative ai see migration migration running ai gateway server global context running ai gateway server global context providing valid calling function order use providing valid calling function order use full running ai gateway server running full running ai gateway server running parameter parameter provider provider model name model name provider anthropic provider anthropic configuration model used route configuration model used route data send query dictionary data send query dictionary route response dictionary standardized route type chat structure chat structure role user content tell joke role user content tell joke structure structure structure structure additional valid given provider route configuration additional valid given provider route configuration included request shown route request included request shown route example request example route response dictionary standardized route type array dictionary set route limit defined array dictionary set route limit defined dictionary limit associated route dictionary limit associated route dictionary define dictionary define string length window enforce limit minute integer number per key optional string per route limit per user limit user per user limit route per route limit default per route limit string length window enforce limit minute integer number per key optional string per route limit per user limit user per user limit route per route limit default per route limit location format model example location format model example information see information see local path model artifact local path model artifact directory must already exist unspecified local output directory must already exist unspecified local output dictionary model dictionary model list,issue,negative,positive,neutral,neutral,positive,positive
1894294743,"@WeichenXu123 I believe when the model outputs a timestamp, we can't use spark udf to output `Struct(x : float, y : timestamp)`. It errors out here https://github.com/mlflow/mlflow/blob/15c1ede5b354a06fcc24f402363c60cdee055771/mlflow/pyfunc/__init__.py#L1344-L1361",believe model ca use spark output float,issue,negative,neutral,neutral,neutral,neutral,neutral
1893393518,"> I manually ran the following code:
> 
> ```python
> from langchain.chains import LLMChain
> from langchain.llms import OpenAI
> from langchain.prompts import PromptTemplate
> 
> import mlflow
> 
> mlflow.langchain.autolog()
> 
> llm = OpenAI(temperature=0.9)
> prompt = PromptTemplate(
>     input_variables=[""product""],
>     template=""What is a good name for a company that makes {product}?"",
> )
> chain = LLMChain(llm=llm, prompt=prompt)
> 
> print(chain.invoke(""soup""))
> ```
> 
> and got this error:
> 
> ```
> 2024/01/16 18:26:54 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during autologging: __init__() got an unexpected keyword argument 'run_id'
> Error in _MLflowLangchainCallback.on_chain_start callback: AttributeError(""'_MLflowLangchainCallback' object has no attribute 'ignore_chain_'"")
> Error in _MLflowLangchainCallback.on_text callback: AttributeError(""'_MLflowLangchainCallback' object has no attribute 'metrics'"")
> Error in _MLflowLangchainCallback.on_llm_start callback: AttributeError(""'_MLflowLangchainCallback' object has no attribute 'ignore_llm_'"")
> Error in _MLflowLangchainCallback.on_llm_end callback: AttributeError(""'_MLflowLangchainCallback' object has no attribute 'ignore_llm_'"")
> Error in _MLflowLangchainCallback.on_chain_end callback: AttributeError(""'_MLflowLangchainCallback' object has no attribute 'ignore_chain_'"")
> 2024/01/16 18:26:55 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during langchain autologging: '_MLflowLangchainCallback' object has no attribute 'mlflg'
> {'product': 'soup', 'text': '\n\n1. ""Savor Soups Co.""\n2. ""Bowl of Comfort""\n3. ""Soup\'s On Inc.""\n4. ""The Soup Kitchen Co.""\n5. ""Hearty Harvest Soups""\n6. ""Soulful Soups Co.""\n7. ""Spoonful of Happiness""\n8. ""Homestyle Soup Co.""\n9. ""Broth Brothers""\n10. ""Puree Perfection Soups""'}
> ```

Because the change depends on langchain mlflowcallback change, we need to manually install langchain_community wheel like my change in cross-version-tests.yml
```
pip install poetry
git clone --recursive https://github.com/serena-ruan/langchain --depth=2 --branch mlflow_callback /tmp/langchain
cd /tmp/langchain/libs/community
poetry build
pip install dist/langchain_community-0.0.12-py3-none-any.whl --force-reinstall --no-deps (no need to add those two tags if you don't install it already)
```",manually ran following code python import import import import prompt product good name company product chain print soup got error warning unexpected error got unexpected argument error object attribute error object attribute error object attribute error object attribute error object attribute warning unexpected error object attribute savor bowl comfort soup kitchen hearty harvest soulful spoonful happiness soup broth puree perfection change change need manually install wheel like change pip install poetry git clone recursive branch poetry build pip install need add two install already,issue,negative,positive,positive,positive,positive,positive
1893364747,"I manually ran the following code:


```python
from langchain.chains import LLMChain
from langchain.llms import OpenAI
from langchain.prompts import PromptTemplate

import mlflow

mlflow.langchain.autolog()

llm = OpenAI(temperature=0.9)
prompt = PromptTemplate(
    input_variables=[""product""],
    template=""What is a good name for a company that makes {product}?"",
)
chain = LLMChain(llm=llm, prompt=prompt)

print(chain.invoke(""soup""))
```

and got this error:

```
2024/01/16 18:26:54 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during autologging: __init__() got an unexpected keyword argument 'run_id'
Error in _MLflowLangchainCallback.on_chain_start callback: AttributeError(""'_MLflowLangchainCallback' object has no attribute 'ignore_chain_'"")
Error in _MLflowLangchainCallback.on_text callback: AttributeError(""'_MLflowLangchainCallback' object has no attribute 'metrics'"")
Error in _MLflowLangchainCallback.on_llm_start callback: AttributeError(""'_MLflowLangchainCallback' object has no attribute 'ignore_llm_'"")
Error in _MLflowLangchainCallback.on_llm_end callback: AttributeError(""'_MLflowLangchainCallback' object has no attribute 'ignore_llm_'"")
Error in _MLflowLangchainCallback.on_chain_end callback: AttributeError(""'_MLflowLangchainCallback' object has no attribute 'ignore_chain_'"")
2024/01/16 18:26:55 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during langchain autologging: '_MLflowLangchainCallback' object has no attribute 'mlflg'
{'product': 'soup', 'text': '\n\n1. ""Savor Soups Co.""\n2. ""Bowl of Comfort""\n3. ""Soup\'s On Inc.""\n4. ""The Soup Kitchen Co.""\n5. ""Hearty Harvest Soups""\n6. ""Soulful Soups Co.""\n7. ""Spoonful of Happiness""\n8. ""Homestyle Soup Co.""\n9. ""Broth Brothers""\n10. ""Puree Perfection Soups""'}
```",manually ran following code python import import import import prompt product good name company product chain print soup got error warning unexpected error got unexpected argument error object attribute error object attribute error object attribute error object attribute error object attribute warning unexpected error object attribute savor bowl comfort soup kitchen hearty harvest soulful spoonful happiness soup broth puree perfection,issue,negative,positive,positive,positive,positive,positive
1893003171,"I don't have write access the the repository, please help to merge it if someone see this, thanks in advance!",write access repository please help merge someone see thanks advance,issue,positive,positive,positive,positive,positive,positive
1892937166,"Text diff for rendered HTML below. Diff log [here](https://github.com/michael-berk/llm-documentation-modifier/blob/main/extras/compare.py)
```
/Users/michael.berk/dev/mlflow/google-docs/batch_2/mlflow/docs/build/html/python_api/mlflow.transformers.html
------------------------------
2344: -                   key in the dictionary must map to a value that inherits
2346: +                   key in the dictionary must map to a value that
2347: - from
2348: + inherits from
2439: -                    Note
2440: +                      Note
2446: -                    If a processor is supplied when logging a model, the
2447: +                      If a processor is supplied when logging a model, the
2454: -                      Pipeline
2455: +                        Pipeline
2459: +                      or for usage
2460: + with pyfunc inference.
2464: -                    or for usage
2465: - with pyfunc inference.
2515: -                    Note
2516: +                      Note
2522: -                    In order for a ModelCard to be fetched (if not provided),
2523: +                      In order for a ModelCard to be fetched (if not provided),
2566: -                   A dict of valid overrides that can be applied to a pipeline instance during inference. These
2568: +                   A dict of valid overrides that can be applied to a pipeline instance during inference.
2569: - arguments are used exclusively for the case of loading the model as a
2570: + These arguments are used exclusively for the case of loading the model as a
2577: -                   Model or
2578: - for use in Spark. These values are not applied to a returned Pipeline from a call to
2580: +                   Model or for use in Spark. These values are not applied to a returned Pipeline from a
2582: + call to
2613: +     task=task,
2614: -     task=task, tokenizer=AutoTokenizer.from_pretrained(architecture), model=architecture
2616: +     tokenizer=AutoTokenizer.from_pretrained(architecture),
2617: +     model=architecture,  # pylint: disable=line-too-long
3967: -                   key in the dictionary must map to a value that inherits
3969: +                   key in the dictionary must map to a value that
3970: - from
3971: + inherits from
4199: +     task=task,
4200: -     task=task, tokenizer=AutoTokenizer.from_pretrained(architecture), model=architecture
4202: +     tokenizer=AutoTokenizer.from_pretrained(architecture),
4203: +     model=architecture,  # pylint: disable=line-too-long
4679: -               Returns
4683: -                None
/Users/michael.berk/dev/mlflow/google-docs/batch_2/mlflow/docs/build/html/python_api/mlflow.models.html
------------------------------
7773: -               '/Users/michael.berk/dev/mlflow/google-docs/mlflow_old/mlflow/mlflow/utils/env_manager.py'>
7775: +               '/Users/michael.berk/dev/mlflow/google-docs/batch_2/mlflow/mlflow/utils/env_manager.py'>
/Users/michael.berk/dev/mlflow/google-docs/batch_2/mlflow/docs/build/html/python_api/mlflow.xgboost.html
------------------------------
788: -                parameters specified in
789: +                  parameters specified in
792: +                   xgboost.train
794: +                  .
798: -                 xgboost.train
800: -                .
805: -                metrics on each iteration (if
806: +                  metrics on each iteration (if
810: -                  evals
815: +                    evals
818: -                specified).
819: +                  specified).
827: -                metrics at the best iteration (if
828: +                  metrics at the best iteration (if
834: -                  early_stopping_rounds
835: +                    early_stopping_rounds
841: -                specified).
842: +                  specified).
850: -                feature importance as JSON files and plots.
851: +                  feature importance as JSON files and plots.
860: -                 trained model, including:
861: +                   trained model, including:
870: -                    an example of valid input.
871: +                      an example of valid input.
879: -                    inferred signature of the inputs and outputs of the model.
880: +                      inferred signature of the inputs and outputs of the model.
938: +                  , input examples are not logged. Note: Input examples are MLflow model
939: -                  , input examples are not logged.
940: - Note: Input examples are MLflow model attributes
941: - and are only collected if
942: + attributes and are only collected if
1785: +                  or models that implement the
1786: -                  or
1787: - models that implement the
2607: +                  or models that implement the
2608: -                  or
2609: - models that implement the






List of all files with diffs:
------------------------------
/Users/michael.berk/dev/mlflow/google-docs/batch_2/mlflow/docs/build/html/python_api/mlflow.transformers.html
/Users/michael.berk/dev/mlflow/google-docs/batch_2/mlflow/docs/build/html/python_api/mlflow.models.html
/Users/michael.berk/dev/mlflow/google-docs/batch_2/mlflow/docs/build/html/python_api/mlflow.xgboost.html

```",text log key dictionary must map value key dictionary must map value note note processor logging model processor logging model pipeline pipeline usage inference usage inference note note order fetched provided order fetched provided valid applied pipeline instance inference valid applied pipeline instance inference used exclusively case loading model used exclusively case loading model model use spark applied returned pipeline call model use spark applied returned pipeline call architecture architecture key dictionary must map value key dictionary must map value architecture architecture none metric iteration metric iteration metric best iteration metric best iteration feature importance feature importance trained model trained model example valid input example valid input signature model signature model input logged note input model input logged note input model collected collected implement implement implement implement list,issue,positive,positive,positive,positive,positive,positive
1892911636,"@dbczumar, @blueloony @lopezco  is there a way to support oidc-oauth (okta or ping idp etc) based authentication on Mlflow?",way support ping based authentication,issue,negative,neutral,neutral,neutral,neutral,neutral
1892749398,"I've also been struggling with this same issue for about 6 months now, through multiple versions of MLFlow. To add context to the issue, here is the state of the issue for me using the latest MLFLow (v2.9.2):


## Platform Configuration

OS: Ubuntu 22.04.2 LTS
Python Version: 3.11.5
MLFlow Version: 2.9.2
Environment: Python Virtual Environment or in the 3.11.5 Docker Image (I've tried running the mlflow server in both and the results are the same)
Installation Method: `pip install mlflow awscli boto3[crt]`

## MinIO Setup

I have my MinIO server running in a docker container on the same machine, it is started using the following command:

```
docker run -it --rm -d \
        -u 1000:1000 \
        -p 9000:9000 \
        -p 9090:9090 \
        --name ""minio-service"" \
        -v /path/to/my/data:/data \
        -e ""MINIO_ROOT_USER=myuser"" \
        -e ""MINIO_ROOT_PASSWORD=mypassword"" \
        minio/minio:RELEASE.2023-01-12T02-06-16Z \
                server /data --console-address "":9090""
```

For this MinIO server I've also generated an public/private access key pair. For the sake of this post, we will call them the following:

- Public Key: my-pub-key
- Private Key: my-priv-key

The bucket in MinIO that I have all of my artifacts in is called `mlflow-artifacts`. It's permissions are set wide open for read/write access.

## Environment Variable Setup

Before starting up the MLFlow tracking server, I set the following environment variables as described [here](https://mlflow.org/docs/latest/tracking/tutorials/remote-server.html#configure-access):

```
export MLFLOW_S3_ENDPOINT_URL=http://<my-machine-ipv4>:9000
export AWS_ACCESS_KEY_ID=myuser
export AWS_SECRET_ACCESS_KEY=mypassword
```

Note the docs imply that you should use your username and password for the MinIO default user, however I have also attempted to use the generated public/private key pair in place of the last two variables:

```
export MLFLOW_S3_ENDPOINT_URL=http://<my-machine-ipv4>:9000
export AWS_ACCESS_KEY_ID=my-pub-key
export AWS_SECRET_ACCESS_KEY=my-priv-key
```

However, the errors below still persist in both cases.

## MLFlow Startup Config

I've tried many combinations of `mlflow server` args to try and get this to work, but here is generally how MLFlow is started:

```bash
mlflow server \
    --dev \
    --host=""<my-machine-ipv4> \
    --port=5000 \
    --backend-store-uri=""/path/to/file/based/storage"" \
    --artifacts-destination=""s3://mlflow-artifacts"" \
    --serve-artifacts
```

With this everything appears to work just fine:
- Browsing experiment metrics
- Pushing new runs and experiments via the mlflow python client
- Manipulating metric graphs in the UI
- Even pushing new artifacts from the python client!!
  - I even see all of the artifacts in the MinIO bucket browser organized appropriately by the experiment and run IDs!

However, when clicking on a specific run, I can view all tags, metrics, and parameters, but not the artifacts. I see a similar error code each time:

![image](https://github.com/mlflow/mlflow/assets/16010219/04ab75a8-7e85-4c5a-8ed3-c79c5a3518e6)

I've attempted various other `mlflow server` argument configurations:
- Such as not proxying artifacts via `--no-serve-artifacts` instead
- Or also setting `--default-artifact-root=s3://mlflow-artifacts` as well

But nothing appears to be working. Each time the error in the UI pops up and the MLFlow Server logs show the following:

```
[2024-01-15 19:46:54 +0000] [25] [DEBUG] GET /ajax-api/2.0/mlflow/artifacts/list
[2024-01-15 19:47:24 +0000] [22] [CRITICAL] WORKER TIMEOUT (pid:25)
[2024-01-15 19:47:24 +0000] [25] [INFO] Worker exiting (pid: 25)
[2024-01-15 19:47:25 +0000] [22] [ERROR] Worker (pid:25) exited with code 1
[2024-01-15 19:47:25 +0000] [22] [ERROR] Worker (pid:25) exited with code 1.
[2024-01-15 19:47:25 +0000] [91] [INFO] Booting worker with pid: 91
```

Where it appears to break on the GET call to the `/ajax-api/2.0/mlflow/artifacts/list` endpoint.

I'd love for this issue to be fixed, it would really unlock a lot of potential for users who want/need to keep all data on local servers.",also struggling issue multiple add context issue state issue latest platform configuration o python version version environment python virtual environment docker image tried running server installation method pip install setup server running docker container machine following command docker run name server server also access key pair sake post call following public key private key bucket set wide open access environment variable setup starting server set following environment export export export note imply use password default user however also use key pair place last two export export export however still persist tried many server try get work generally bash server dev everything work fine browsing experiment metric pushing new via python client metric even pushing new python client even see bucket browser organized appropriately experiment run however specific run view metric see similar error code time image various server argument via instead also setting well nothing working time error server show following get critical worker worker error worker code error worker code booting worker break get call love issue fixed would really unlock lot potential keep data local,issue,negative,positive,neutral,neutral,positive,positive
1891824331,"Hi please check in https://huntr.com/repos/mlflow/mlflow where issue has raised 
Issue Name : Client side Injection Lead to HTM / XSS",hi please check issue raised issue name client side injection lead,issue,negative,neutral,neutral,neutral,neutral,neutral
1891822652," Hi @BenWilson2  , is it possible to resolve this issue?",hi possible resolve issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1891350729,"Any updates on this?

I am also facing this truncated view of a nested dictionaries when making run comparisons.

<img width=""930"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/72377011/47a43ea9-c313-4ba8-9b4d-fc831dbd9940"">
",also facing truncated view making run image,issue,negative,neutral,neutral,neutral,neutral,neutral
1891324126,yeah I did installed pyspark manually. It was not listed in test-requirements.txt. I thought it was missing from there. It should at least be in extra requirements to let devs. know it is required package. ,yeah manually listed thought missing least extra let know package,issue,negative,negative,negative,negative,negative,negative
1891215191,@manijhariya can you install pyspark manually? We don't always need pyspark. pyspark is a large package and takes a while to install.,install manually always need large package install,issue,negative,positive,positive,positive,positive,positive
1889989797,"I have checked this issue. This issue persist not just for `pd.DataFrame` but also for other data types also.  
If we pass input type of `np.ndarray, csc_matrix, csr_matrix, dict of ndarray`  into infer_signature than it will returns `TensorSpec` for others it will just return list of Schema for 'ColSpec' which is not compatible to log_model.  
Because every field of signature.inputs.inputs expected to be of `TensorSpec`.",checked issue issue persist also data also pas input type return list schema compatible every field,issue,negative,neutral,neutral,neutral,neutral,neutral
1889684594,"Hey @WeichenXu123 curious what was the reasoning to add `Timestamp` as a primitive type? I understand it's probably rare that a model outputs a timestamp, however there is a use-case like ours where we output _timestamp of input features_. and use the outputs to join back to the input data provided.. We have a workaround so it doesn't matter as much but curious to hear your thoughts",hey curious reasoning add primitive type understand probably rare model however like output input use join back input data provided matter much curious hear,issue,positive,positive,neutral,neutral,positive,positive
1889526671,could you also send the config.yaml file?,could also send file,issue,negative,neutral,neutral,neutral,neutral,neutral
1889220130,"Please improve the responsiveness of the web UI! Performance issues were raised several times in the past (#627, #925, #1517, #1571, #1763, #1902, #3334, #4034, #4305, #4454, #5653) and are still not fixed. It only takes a few hundreds runs to bring the web UI to its knees. At this point I am barely able to browse the results of a single hyperparameter search, and I need to start looking for alternative products.",please improve responsiveness web performance raised several time past still fixed bring web point barely able browse single search need start looking alternative,issue,positive,positive,neutral,neutral,positive,positive
1888205963,@moghadas76 Please share the code to reproduce the issue.,please share code reproduce issue,issue,positive,neutral,neutral,neutral,neutral,neutral
1888204997,@wolpl great catch! Triggered CI for the change :) ,great catch triggered change,issue,positive,positive,positive,positive,positive,positive
1887954758,"@BenWilson2,
Command to download the latest version of mlflow is shown in the 3rd line.

```export CR_PAT=YOUR_TOKEN
echo $CR_PAT | docker login ghcr.io -u USERNAME --password-stdin
# Pull the latest version
docker pull ghcr.io/mlflow/mlflow
# Pull 2.2.1
docker pull ghcr.io/mlflow/mlflow:v2.2.1
```

The last line in the block is showing info to download specific version.

I'm not clear what is your proposal here. will you help me to understand here?",command latest version shown line export echo docker login pull latest version docker pull pull docker pull last line block showing specific version clear proposal help understand,issue,negative,positive,positive,positive,positive,positive
1887839356,"I think if we make this an indication that it's parametrized and then provide the link to where the latest version can be downloaded from, that will suffice :) ",think make indication provide link latest version suffice,issue,negative,positive,positive,positive,positive,positive
1887817446,"@BenWilson2, I just wanted to confirm which version should this command have?

`docker pull ghcr.io/mlflow/mlflow:v2.7.1`
or
`docker pull ghcr.io/mlflow/mlflow:v2.9.2`?",confirm version command docker pull docker pull,issue,negative,neutral,neutral,neutral,neutral,neutral
1887789701,"Hi @BenWilson2, can you please assign me this issue?",hi please assign issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1887225792,"i also experienced that issue at least 3 times by now which resulted in a crash of my experiments. how can i avoid mlflow dragging it down to the death?

`Max retries exceeded with url: /abc/api/2.0/mlflow/runs/get?run_uuid=XXY&run_id=XXX (Caused by 
SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1007)')))`",also experienced issue least time crash avoid dragging death violation protocol,issue,negative,positive,positive,positive,positive,positive
1886958762,@BenWilson2 Thanks for the quick reply - looking forward to that!,thanks quick reply looking forward,issue,negative,positive,positive,positive,positive,positive
1886652028,"The JSONDecodeError occurs, because MLflow uses Windows commandline escaping to assemble a command that is then executed on databricks in a bash. More info in #10811

As a workaround, it is possible to call the `mlflow.run()` function in a Python script (not the CLI command directly, as you did).
If you replace the function that does the incorrect escaping with a correct one _before_ that call, the databricks run executes as intended:
```Python
import shlex
import mlflow

mlflow.projects.databricks.quote = shlex.quote  # HACK to fix the encoding of the mlflow backend configuration
mlflow.run(...)
```",assemble command executed bash possible call function python script command directly replace function incorrect correct one call run intended python import import hack fix configuration,issue,negative,positive,neutral,neutral,positive,positive
1886082314,Agreed this would be super useful. The existing components for this are largely already present: `make_metric()` to create an arbitrary EvaluationMetric and the deployment `client.predict()` to call LLM. We would need to figure out some approach for users to define their own grading prompt and corresponding parsing logic. ,agreed would super useful largely already present create arbitrary deployment call would need figure approach define grading prompt corresponding logic,issue,positive,positive,positive,positive,positive,positive
1886062957,"Fantastic job here @B-Step62 !! This is an overwhelmingly great improvement to some of the most often asked questions and confusing behavior, written up in a very easy-to-follow and clear direction. Great examples, too! ",fantastic job overwhelmingly great improvement often behavior written clear direction great,issue,positive,positive,positive,positive,positive,positive
1886028565,@alena-m I agree that this should be represented as part of the LLM-as-a-judge information in the trace table produced by mlflow.evaluate(). I'll add the `help wanted label`. Please let us know if you'd like to reconsider and help contribute this!,agree part information trace table produced add help label please let u know like reconsider help contribute,issue,positive,neutral,neutral,neutral,neutral,neutral
1886027730,"Hi @alena-m, thank you for raising this. We agree that it would be valuable, and we would really appreciate a contribution for it. I'll add the `help wanted` label for now. Let us know if you'd like to reconsider and take this on.",hi thank raising agree would valuable would really appreciate contribution add help label let u know like reconsider take,issue,positive,positive,positive,positive,positive,positive
1885980665,"@BenWilson2 I didn't specify a specific version but it looks like it installs 1.6.1 but I was able to fix the error by using `task=chat.completions` which is the new way to use the OpenAI client as opposed to the `task=openai.ChatCompletions` that is shows in the MLflow documentation.  

There are a couple places in the docs that show examples with openai.ChatCompletions, I can put in a PR if we want all of them updated? or even better update the error message to explain to use either `task=openai.ChatCompletions` or `task=chat.completions`. ",specify specific version like able fix error new way use client opposed documentation couple show put want even better update error message explain use either,issue,negative,positive,positive,positive,positive,positive
1884868019,"Is it possible to automatically fill in variable values from the previous run when we do ""Duplicate run"" for Prompt Engineering? If we have many variables it is tedious to fill them again and again.
![image](https://github.com/mlflow/mlflow/assets/22996008/d267375d-b2b8-486b-b3a0-2102cb7dd9fb)
",possible automatically fill variable previous run duplicate run prompt engineering many tedious fill image,issue,negative,negative,neutral,neutral,negative,negative
1884863017,"Is it possible to add the ability to change the row width in the Evaluation table? Sometimes the output is too long for cells, but I still want to compare them side by side.
<img width=""1154"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/22996008/e312efb8-809a-4d4e-992a-95cc2eb3d28a"">
",possible add ability change row width evaluation table sometimes output long still want compare side side image,issue,negative,negative,neutral,neutral,negative,negative
1884851882,"Hi, is it possible to add token numbers to all parts of prompts? Currently we can only see the total number of tokens, but in addition to the total number it would be useful to see the tokens for each part separately.
![image](https://github.com/mlflow/mlflow/assets/22996008/5b0fcb77-4a80-4316-b7a9-da7ef3f7dc02)
",hi possible add token currently see total number addition total number would useful see part separately image,issue,positive,positive,neutral,neutral,positive,positive
1884479610,"same, i have the mlflow version 2.9.2(latest) and i still face the error in windows, any workarounds/solutions?
Thanks",version latest still face error thanks,issue,negative,positive,positive,positive,positive,positive
1884274171,"Removed tests added in this PR https://github.com/mlflow/mlflow/pull/7750 that are no more applicable. `file://hostname/path` with non-local hostname will not be accepted anymore (an exception will raise). Previously `file://myserver/path` on windows is recognized as local uri and resolved as `\\myserver\path`, but this PR changes the behavior as it's not a local uri but a remote uri.",removed added applicable file accepted exception raise previously file local resolved behavior local remote,issue,negative,negative,neutral,neutral,negative,negative
1884001377,"Hi @vipese-idoven we're actually working on designing a solution for epoch-based logging of deep learning models (which will support resumption of training from a particular epoch checkpoint) right now. 
I think that the feature will allow for a much more palatable solution for what you're struggling with right now. 
cc @WeichenXu123 for context",hi actually working designing solution logging deep learning support resumption training particular epoch right think feature allow much palatable solution struggling right context,issue,positive,positive,positive,positive,positive,positive
1882687649,"I'm using version 2.9.2 and my custom headers go through only when the `in_context` method of the plugin returns True. 

Because if it is not in context, then it will never send those headers. ",version custom go method true context never send,issue,negative,positive,positive,positive,positive,positive
1882592160,"Having the same issue:
when run 
```
mlflow run ... --build-image ... 
```

It hangs after ""mlflow.projects: '...' does not exist. Creating a new experiment"" for several minutes. And then prints ""INFO mlflow.projects.docker: === Building docker image my-image-name:354a973 ===""",issue run run exist new experiment several building docker image,issue,negative,positive,neutral,neutral,positive,positive
1882473298,"> I am trying to develop a custom plugin for user authentication and authorization for users using mlflow. As per the documentation, available at https://www.mlflow.org/docs/latest/plugins.html , I tried to develop a plugin where I create a subclass of mlflow.tracking.request_header.abstract_request_header_provider.RequestHeaderProvider. This was with the expectation that a custom request header provider would be invoked on every request. However when I install the plugin, using pip install, the code in custom plugin is not executed.
> 
> Please help me with the following:
> 
> 1. What could be the reason for the same?
> 2. If I need to use google authentication, is there any documentation for such an implementation?
> 3. Can this authentication work with mlflow ui where a user can see only her / his experiments?

Were you able to resolve this ? I am also facing the same issue",trying develop custom user authentication authorization per documentation available tried develop create subclass expectation custom request header provider would every request however install pip install code custom executed please help following could reason need use authentication documentation implementation authentication work user see able resolve also facing issue,issue,positive,positive,positive,positive,positive,positive
1882182659,@TomeHirata Thanks for filing the PR! I was taking a vacation. I'll review this PR this week.,thanks filing taking vacation review week,issue,negative,positive,positive,positive,positive,positive
1882137796,@gabrielfu Thanks for the PR! I was taking a vacation and got back to today :),thanks taking vacation got back today,issue,negative,positive,neutral,neutral,positive,positive
1882123473,"> LGTM, left one minor comment.
> 
> btw I think we can also add same description in `tracking-api.rst`.

Good idea! :D ",left one minor comment think also add description good idea,issue,negative,positive,positive,positive,positive,positive
1882083016,"> Can you add a test that ensures this implementation works for model serving inference? We have a test harness :
> 
> `from tests.helper_functions import pyfunc_serve_and_score_model` that can be used to assure that the model instance loads properly from within a container environment, simulating the behavior that would be used for deployment inference.
> 
> Here's a simple example of what I'm talking about:
> 
> https://github.com/mlflow/mlflow/blob/219017b56aff96a1c6600c84edbcf1d958ce3755/tests/transformers/test_transformers_model_export.py#L3300-L3319

Hi, @BenWilson2 I implemented these tests, but unfortunately, I can't test them locally.

I tried to run your suggested test case, but I got the same error message:

```
scoring process died
```

Do we have any special orientation to run these tests?",add test implementation work model serving inference test harness import used assure model instance properly within container environment behavior would used deployment inference simple example talking hi unfortunately ca test locally tried run test case got error message scoring process special orientation run,issue,negative,negative,neutral,neutral,negative,negative
1881926499,"Hi @sniafas, we'll take a look at supporting additional endpoints and input types when we do the refactoring to support OpenAI SDK 1.x in the next few weeks. Thanks for bringing this up! ",hi take look supporting additional input support next thanks,issue,positive,positive,positive,positive,positive,positive
1881924293,The MLflow OpenAI flavor does not support v1.x versions of the OpenAI SDK. We will be introducing support for this soon. ,flavor support support soon,issue,positive,neutral,neutral,neutral,neutral,neutral
1881474116,"Can you add a test that ensures this implementation works for model serving inference? 
We have a test harness :

`from tests.helper_functions import pyfunc_serve_and_score_model` that can be used to assure that the model instance loads properly from within a container environment, simulating the behavior that would be used for deployment inference. 

Here's a simple example of what I'm talking about: https://github.com/mlflow/mlflow/blob/219017b56aff96a1c6600c84edbcf1d958ce3755/tests/transformers/test_transformers_model_export.py#L3300-L3319 ",add test implementation work model serving inference test harness import used assure model instance properly within container environment behavior would used deployment inference simple example talking,issue,negative,neutral,neutral,neutral,neutral,neutral
1881377789,"We can actually remove this test, remove the check from within the transformers flavor, and remove the helper utility `_find_duplicate_requirements()` (along with its validation check within `test_environment.py`) as it was only used for transformers to prevent issues with model serving. The updated logic within #10778 performs a more thorough validation and resolution of dependencies. I filed #10792 (since I created this mess ;) )",actually remove test remove check within flavor remove helper utility along validation check within used prevent model serving logic within thorough validation resolution since mess,issue,negative,negative,neutral,neutral,negative,negative
1880446685,"> test failures seem unrelated to this PR, maybe try rebasing?

We're targeting feature branch anyway so let's fix it from there",test seem unrelated maybe try feature branch anyway let fix,issue,negative,neutral,neutral,neutral,neutral,neutral
1879922712,"> Can you add unit tests that validate this behavior and ensure that the test models are:
> 
> 1. loadable
> 2. capable of processing batch inference
> 3. capable of being served through our serving test harness
> 4. capable of accepting parameters in addition to the base input and context requirements

@BenWilson2 I wrote 4 test cases with multiple asserts to validate this condition:

- `test_class_python_model_without_call_method`
  - Test that class-based pyfunc models inherited from PythonModel are PyFuncModel instances.
- `test_class_python_model_with_call_method`
  - Test that class-based pyfunc models with a __call__ method and inherited from PythonModel are PyFuncModel instances.
- `test_class_model_with_call_method`
  - Test that class-based pyfunc models with a __call__ method and not inherited from PythonModel are _FunctionPythonModel instances.
- `test_functional_model_func`
  - Test that functional pyfunc models based on a function are _FunctionPythonModel instances.

## Test results with the old condition

```log
====================================================================== short test summary info ======================================================================= 
FAILED | MEM 16.0/31.7 GB | DISK 513.4/932.1 GB tests/pyfunc/test_pyfunc_functional_mode.py::test_class_python_model_with_call_method - AssertionError: Expected TestClassModel, got <class 'mlflow.pyfunc.model._FunctionPythonModel'>
============================================================== 1 failed, 3 passed, 35 warnings in 7.54s ============================================================== 
```

## Test results with the new condition

```log
=================================================================== 4 passed, 35 warnings in 8.24s ===================================================================
```

## Tests and Formatter commands

```bash
black .\mlflow\pyfunc\__init__.py 
black .\tests\pyfunc\test_pyfunc_functional_mode.py
pytest .\tests\pyfunc\test_pyfunc_functional_mode.py --quiet --requires-ssh
```",add unit validate behavior ensure test capable batch inference capable serving test harness capable addition base input context wrote test multiple validate condition test test method test method test functional based function test old condition log short test summary mem disk got class test new condition log bash black black quiet,issue,positive,negative,neutral,neutral,negative,negative
1879505922,"hi @clarkh-ncino  , you can try this docker file with miniconda env : https://github.com/aws-samples/amazon-sagemaker-automatic-deploy-mlflow-model/blob/main/docker_images/python_function/Dockerfile , It worked for me",hi try docker file worked,issue,negative,neutral,neutral,neutral,neutral,neutral
1879500982,@ghadgeabhi I've been working on this and the latest PR is under review now. Probably it'd be easier to find another good first issue.,working latest review probably easier find another good first issue,issue,positive,positive,positive,positive,positive,positive
1879459340,"@annzhang-db I had to convert the details dropdown div section to base markdown (the details element doesn't render correctly within notebooks on the site) due to an issue with the html parser in sphinx notebook conversion (it wraps new divs in `<p>` elements, which breaks the `<details>` lineage). Everything else is just porting over your notebook for site rendering!",convert div section base markdown element render correctly within site due issue parser sphinx notebook conversion new lineage everything else notebook site rendering,issue,negative,negative,negative,negative,negative,negative
1879265947,Is there anything to be done on this Issue? If so I am ready to contribute to this.,anything done issue ready contribute,issue,negative,positive,positive,positive,positive,positive
1879243273,"> @BenWilson2 I think we should probably put this under https://mlflow.org/docs/latest/model-evaluation/index.html#guides-and-tutorials-for-llm-model-evaluation?

exactly :) ",think probably put exactly,issue,negative,positive,positive,positive,positive,positive
1878997797,"> In addition to the offline discussion items, we'll want to make sure that we're validating this feature functions properly within our model serving test fixture and that there are no impacts to signature enforcement / validation.

Sounds good. I'll add a test that includes pyfunc_serve_and_score_model. ",addition discussion want make sure feature properly within model serving test fixture signature enforcement validation good add test,issue,positive,positive,positive,positive,positive,positive
1878972987,"@BenWilson2 The main issue is that the `BertWithTabular()` class contains the `__call__()` method, which is identified as a functional model instead of a PythonModel as it should be.

It's not particularly related to the transformers library, it can happen with other models as well, for example:

```python
class CustomModel(mlflow.pyfunc.PythonModel):
    def load_context(self, context):
        pass

    def predict(self, context, model_input, params=None):
        return self.__call__(model_input, params)

    def __call__(self, model_input, params):
        pass
```

Since the above class contains the `__call__()` method, it will be identified first as the functional model instead of a class-based model.

I saw your comments in the PR and I will work on that ASAP.",main issue class method functional model instead particularly related library happen well example python class self context pas predict self context return self pas since class method first functional model instead model saw work,issue,negative,positive,positive,positive,positive,positive
1878953664,Noticed there hasn't been much progress on this issue. Can I join your team and be able to contribute here?,much progress issue join team able contribute,issue,positive,positive,positive,positive,positive,positive
1878931824,"In addition to the offline discussion items, we'll want to make sure that we're validating this feature functions properly within our model serving test fixture and that there are no impacts to signature enforcement / validation. ",addition discussion want make sure feature properly within model serving test fixture signature enforcement validation,issue,negative,positive,positive,positive,positive,positive
1878912678,"While I'm not particularly familiar with this plugin package, I was able to get your use case working purely from an MLflow perspective (the model object is a different story, however... even running the example in their docs throws exceptions, so I'm not entirely sure how compatible it is with the Transformers library). 

This permits the custom model using this plugin library to be logged and loaded (although the internal logic within predict doesn't work, which has nothing to do with MLflow) 

```python
class CustomTransformersModel(mlflow.pyfunc.PythonModel):
    def __init__(self, config: BertConfig = None):
        self.config = None
        self.model=None

    def load_context(self, context):

        self.model = AutoModelWithTabular.from_pretrained(context.artifacts[""model_path""])
        self.tokenizer = AutoTokenizer.from_pretrained(context.artifacts[""tokenizer""])

    def predict(self, context, model_input, params=None):
        encoded_input = self.tokenizer(model_input)
        loss, logits, layer_outs = self.model(encoded_input)
        return layer_outs

    def compute_metrics(pred: EvalPrediction):
        predictions = pred.predictions[0]
        predicted_labels = np.argmax(predictions, axis = 1)
        expected_labels = pred.label_ids
        accuracy = (predicted_labels == expected_labels).mean()
        f1 = f1_score(y_true=expected_labels, y_pred=predicted_labels, average='micro')
        mcc = matthews_corrcoef(expected_labels, predicted_labels)
        return {
            ""acc"": accuracy,
            ""f1"": f1,
            ""mcc"": mcc
        }

bert_config = BertConfig.from_pretrained('bert-base-uncased')

tabular_config = TabularConfig(
        combine_feat_method='attention_on_cat_and_numerical_feats',
        cat_feat_dim=9, 
        numerical_feat_dim=5, 
        num_labels=2,
        use_num_bn=False
)

bert_config.tabular_config = tabular_config

tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')
model = BertWithTabular.from_pretrained('bert-base-uncased', config=bert_config)

model.save_pretrained(""/tmp/output/model"")
tokenizer.save_pretrained(""/tmp/output/tokenizer"")

with mlflow.start_run():
    model_info = mlflow.pyfunc.log_model(
        artifact_path=""model"",
        artifacts={""model_path"": ""/tmp/output/model"", ""tokenizer"": ""/tmp/output/tokenizer""},
        python_model=CustomTransformersModel(),
        pip_requirements=[
            ""transformers==4.36.2"",
            ""multimodal-transformers==0.3.*"",
            ""pandas==1.3.5"",
            ""scikit-learn==1.0.2"",
            ""numpy==1.26.3""
        ],
    )
    
loaded = mlflow.pyfunc.load_model(model_info.model_uri)

loaded.predict([""hello there"", ""bye""]) # This raises an encoding error from transformers tokenization utils
```
As I mentioned above, I can't speak to the functionality of the underlying plugin library (and I don't have the time to get this working)... but the issue is raised within the predict logic and has no issue with being saved or loaded in MLflow. 

Out of sheer curiosity, though, I did attempt to follow the tutorial on their docs (using the model defined above) and I get an entirely different sort of error:

```python

text_1 = ""HuggingFace is based in NYC""
text_2 = ""Where is HuggingFace based?""
model_inputs = tokenizer([text_1, text_2])

# 5 numerical features
numerical_feat = torch.rand(2, 5).float()
# 9 categorical features
categorical_feat = torch.tensor([[0, 0, 0, 1, 0, 1, 0, 1, 0],
                                 [1, 0, 0, 0, 1, 0, 1, 0, 0]]).float()
labels = torch.tensor([1, 0])

model_inputs['cat_feats'] = categorical_feat
model_inputs['num_feats'] = numerical_feat
model_inputs['labels'] = labels

model(**model_inputs)
```

```sh
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
Cell In[87], line 1
----> 1 model(**model_inputs)

File ~/.pyenv/versions/anaconda3-2022.10/envs/mlflow-310/lib/python3.10/site-packages/torch/nn/modules/module.py:1518, in Module._wrapped_call_impl(self, *args, **kwargs)
   1516     return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
   1517 else:
-> 1518     return self._call_impl(*args, **kwargs)

File ~/.pyenv/versions/anaconda3-2022.10/envs/mlflow-310/lib/python3.10/site-packages/torch/nn/modules/module.py:1527, in Module._call_impl(self, *args, **kwargs)
   1522 # If we don't have any hooks, we want to skip the rest of the logic in
   1523 # this function, and just call forward.
   1524 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
   1525         or _global_backward_pre_hooks or _global_backward_hooks
   1526         or _global_forward_hooks or _global_forward_pre_hooks):
-> 1527     return forward_call(*args, **kwargs)
   1529 try:
   1530     result = None

TypeError: BertWithTabular.forward() got an unexpected keyword argument 'num_feats'
```

I saw your PR and left some requests. Note that the brevity of my request on that PR doesn't correlate to the size of the requested changes. A fundamental change to how PythonModel is resolved, particularly within initialization with the scoring server, is something that will need comprehensive unit tests to be created to ensure that this feature (not a bug, by the way; this was never intended to be a supported functionality within MLflow) functions correctly in many different scenarios. ",particularly familiar package able get use case working purely perspective model object different story however even running example entirely sure compatible library custom model library logged loaded although internal logic within predict work nothing python class self none none self context predict self context loss return axis accuracy return accuracy model model loaded hello bye error ca speak functionality underlying library time get working issue raised within predict logic issue saved loaded sheer curiosity though attempt follow tutorial model defined get entirely different sort error python based based numerical categorical model sh recent call last cell line model file self return type ignore else return file self want skip rest logic function call forward return try result none got unexpected argument saw left note brevity request correlate size fundamental change resolved particularly within scoring server something need comprehensive unit ensure feature bug way never intended functionality within correctly many different,issue,negative,positive,positive,positive,positive,positive
1878893924,"Can you add unit tests that validate this behavior and ensure that the test models are:
1. loadable
2. capable of processing batch inference
3. capable of being served through our serving test harness
4. capable of accepting parameters in addition to the base input and context requirements
",add unit validate behavior ensure test capable batch inference capable serving test harness capable addition base input context,issue,positive,negative,neutral,neutral,negative,negative
1878794946,"> can i be assigned to this

Hi @devadigapratham, I submitted a PR to change this. You can help by reviewing the PR.",assigned hi change help,issue,negative,neutral,neutral,neutral,neutral,neutral
1878789664,I closed this one because I forgot to sign the commits. :),closed one forgot sign,issue,negative,negative,neutral,neutral,negative,negative
1877760284,"@serena-ruan Good question, I have discussed it with multiple people (not just `_promptlab.py` but in general the usage of private module), and it's just a bunch of tech debt. ",good question multiple people general usage private module bunch tech debt,issue,negative,positive,positive,positive,positive,positive
1877488261,"I think I've found the issue: from the xgboost.core.Booster documentation of the _save_model()_ method, only JSON/UBC are supported.
```python
    def save_model(self, fname: Union[str, os.PathLike]) -> None:
        """"""Save the model to a file.

        The model is saved in an XGBoost internal format which is universal among the
        various XGBoost interfaces. Auxiliary attributes of the Python Booster object
        (such as feature_names) will not be saved when using binary format.  To save
        those attributes, use JSON/UBJ instead. See :doc:`Model IO
        </tutorials/saving_model>` for more info.

        .. code-block:: python

          model.save_model(""model.json"")
          # or
          model.save_model(""model.ubj"")

        Parameters
        ----------
        fname :
            Output file name

        """"""
```

Should we change the default file format used by mlflow.xgboost.save_model() or mlflow.xgboost.log_model() ?

I've tried to replace the default value of _model_format_ parameter in mlflow.xgboost.__init__.py from 'xgb' to 'json' and the code provided by @ShivKJ works.",think found issue documentation method python self union none save model file model saved internal format universal among various auxiliary python booster object saved binary format save use instead see doc model io python output file name change default file format used tried replace default value parameter code provided work,issue,negative,neutral,neutral,neutral,neutral,neutral
1877293101,"@anirvansen there are a few things you could do.

1. Create your own custom mlflow pyfunc image
2. Utilize the boto3 sdk directly for serverless deployments 

Both options aren't great.

The first option I've explored a little but the pyfunc image is a bit black boxy and I'm not completely sure how to solve the pyenv issue.
The second option you'd have to utilize your own sagemaker image for deployment/inference and lose all the built in logic the generic pyfunc image provides (type validation, error handling, etc).",could create custom image utilize directly great first option little image bit black boxy completely sure solve issue second option utilize image lose built logic generic image type validation error handling,issue,positive,positive,positive,positive,positive,positive
1877108825,"Another interesting critical point of this use case is the constrain to handle the restarting as nested run.
E.g. On deep learning it is quite common that the run could restart from the last saved checkpoint on spot. 
So some previous logged params could be overridden (like e.g. the starting checkpoint param) but this is not permitted currently by MLFLOW as the logged partams are immutable and so you need always to create a new run and a nested one.
But the nested runs was really not designed for this use case as it was more a grouping logic for hyperparameters tuning and similar.
Instead here we need metrics consistency like if these ""restarting"" runs will be part of the same logical run.  ",another interesting critical point use case constrain handle run deep learning quite common run could restart last saved spot previous logged could like starting param permitted currently logged immutable need always create new run one really designed use case grouping logic tuning similar instead need metric consistency like part logical run,issue,positive,positive,neutral,neutral,positive,positive
1876847540,"hi @clarkh-ncino ,
Did you get a solution on this , I am also facing the same issue.",hi get solution also facing issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1876309788,@harupy would you mind taking a look at this PR when you have time?,would mind taking look time,issue,negative,neutral,neutral,neutral,neutral,neutral
1875819828,Gotcha! Yeah that link is completely broken :D I'll get a fix in for it. Thanks for reporting this!! ,yeah link completely broken get fix thanks,issue,negative,negative,neutral,neutral,negative,negative
1875802388,"Hi Ben,

I have just tried it again from my phone (which never visited the LLM
section of mlflow before). This is the URL I opened:
https://mlflow.org/docs/latest/llms/index.html

The link I am clicking is called: MLflow quickstart. It points to
https://github.com/mlflow/mlflow/blob/master/examples/deployments/deployments_server/mlflow_serving/README.md

The same 404 error happens. (In the top menu, I am in the latest (2.9.2
version)

I hope it helps!

El El mié, 3 ene 2024 a las 17:39, Ben Wilson ***@***.***>
escribió:

> I'm not seeing the same behavior. Can you ensure that your browser cache
> is cleared with a force-reload of the site?
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/mlflow/mlflow/issues/10773#issuecomment-1875655279>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AAE7Q6P4MCQNHHJ5FTWPNS3YMWCTHAVCNFSM6AAAAABBLKVVZ2VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTQNZVGY2TKMRXHE>
> .
> You are receiving this because you authored the thread.Message ID:
> ***@***.***>
>
",hi ben tried phone never section link error top menu latest version hope el el la ben seeing behavior ensure browser cache site reply directly view id,issue,positive,positive,positive,positive,positive,positive
1875664670,Can we attach the built .jar to a cluster and verify that logging / loading a SparkML model works perfectly fine (just to be safe)?,attach built cluster verify logging loading model work perfectly fine safe,issue,positive,positive,positive,positive,positive,positive
1875657810,@jerrylian-db @smurching could either of you take a look at this?,could either take look,issue,negative,neutral,neutral,neutral,neutral,neutral
1875655279,I'm not seeing the same behavior. Can you ensure that your browser cache is cleared with a force-reload of the site? ,seeing behavior ensure browser cache site,issue,negative,neutral,neutral,neutral,neutral,neutral
1875101911,"> > I agree with having dictionary to allow different versions! But I would hardcode it to Python script rather than args, so we don't have to hop between files. We don't reuse this in multiple shell scripts so it doesn't have to be parameters.
> 
> SGTM! Yeah, let's change to a Dict in the .py file as a constant, rename the constant variable to generic ""dev"" instead of a particular version of python and keep the cleaner new yaml implementation :)

This suggestion makes sense, let's keep yaml file simple :)",agree dictionary allow different would python script rather hop reuse multiple shell yeah let change file constant rename constant variable generic dev instead particular version python keep cleaner new implementation suggestion sense let keep file simple,issue,positive,positive,neutral,neutral,positive,positive
1874773639,"> I agree with having dictionary to allow different versions! But I would hardcode it to Python script rather than args, so we don't have to hop between files. We don't reuse this in multiple shell scripts so it doesn't have to be parameters.

SGTM! Yeah, let's change to a Dict in the .py file as a constant, rename the constant variable to generic ""dev"" instead of a particular version of python and keep the cleaner new yaml implementation :) ",agree dictionary allow different would python script rather hop reuse multiple shell yeah let change file constant rename constant variable generic dev instead particular version python keep cleaner new implementation,issue,positive,positive,neutral,neutral,positive,positive
1874769225,"I agree with having dictionary to allow different versions! But I would hardcode it to Python script rather than args, so we don't have to hop between files. We don't reuse this in multiple shell scripts so it doesn't have to be parameters.",agree dictionary allow different would python script rather hop reuse multiple shell,issue,positive,neutral,neutral,neutral,neutral,neutral
1874765484,"Curious to hear your thoughts on leaving `get_requires_python` as abstract as possible. 

What do you think of adding a param to the function that defines the dev fallback?

```python
def get_requires_python(package: str, version: str, dev_package_fallback_versions: t.Dict[str, str]) -> t.Optional[str]:
    if version == ""dev"" and package in dev_package_fallback_versions:
        return dev_package_fallback_versions[package]

    resp = requests.get(f""https://pypi.python.org/pypi/{package}/json"")
    resp.raise_for_status()
    return next(
        (
            distributions[0].get(""requires_python"")
            for ver, distributions in resp.json()[""releases""].items()
            if ver == version and distributions
        ),
        None,
    )
```

And then doing something like this to have full control over the versions of dev packages (just so that if some new library decides to jump to Py3.10 for some reason, we're not stuck with bumping all of the versions up?

```yaml
      - name: Get Python version
        id: get-python-version
        run: |
          DEV_PACKAGE_FALLBACK_VERSIONS='{""tensorflow"": "">=3.9"", ""scikit-learn"": "">=3.9"", ""statsmodels"": "">=3.9""}'
          python_version=$(python dev/get_minimum_required_python.py -p ${{ matrix.package }} -v ${{ matrix.version }} --python-versions ""3.8,3.9"" --dev-package-fallback-versions ""$DEV_PACKAGE_FALLBACK_VERSIONS"")
```",curious hear leaving abstract possible think param function dev fallback python package version version dev package return package resp return next version none something like full control dev new library jump reason stuck bumping name get python version id run python,issue,negative,positive,neutral,neutral,positive,positive
1874735903,"Thanks you, I just do what you recommended, that import the model class temporarily to an old file to load the model and saved a new one, it is solved.",thanks import model class temporarily old file load model saved new one,issue,positive,positive,positive,positive,positive,positive
1874650656,"I'm using 2.9.2 -- it works for most files and then I re-ran my script on the ones it didn't work for and it seemed to pull more of them. So I was able to back-fill out the artifacts by 1. re-running and 2. increasing `MLFLOW_HTTP_REQUEST_TIMEOUT` to 1200 instead of 600 

```
 poetry run python pyscripts/isa-instance-based-parameter-download.py
 ```
 
 With the following dependencies in my `pyproject.toml`
 
```
[tool.poetry.dependencies]
python = ""^3.11""
ipykernel = ""^6.28.0""
numpy = ""^1.26.2""
networkx = ""^3.2.1""
matplotlib = ""^3.8.2""
pandas = ""^2.1.4""
python-louvain = ""^0.16""
ipython = ""^8.19.0""
prompt-toolkit = ""^3.0.43""
mlflow = ""^2.9.2""
boto3 = ""^1.34.11""
tqdm = ""^4.66.1""
```

and then the following in the `.env`

```
export MLFLOW_TRACKING_URI=XXXX
export MLFLOW_TRACKING_USERNAME=XXXX
export MLFLOW_TRACKING_PASSWORD=XXXX
export MLFLOW_HTTP_REQUEST_TIMEOUT=1200
```
",work script work pull able increasing instead poetry run python following python following export export export export,issue,negative,positive,positive,positive,positive,positive
1874636542,Can you report the version of MLflow that you're seeing this in? Have you tried with the latest 2.9.2 release (we have some modifications to how large file uploads and downloads are handled in the latest releases that should address this problem. ,report version seeing tried latest release large file handled latest address problem,issue,negative,positive,positive,positive,positive,positive
1874634630,"> @B-Step62 The associated [PR](https://github.com/mlflow/mlflow/pull/9310) is not merged yet so I'm not sure if we would want to mark this as completed.

Sorry for the delay on that. I just merged it!",associated yet sure would want mark sorry delay,issue,negative,neutral,neutral,neutral,neutral,neutral
1874357312,"Can you provide more explanation here with a possible reproduction of what you're trying to do? The context that you've provided isn't particularly clear on what you're trying to do. 
What do you mean by ""remote source""?
Your stated ""I hope the mlflow server can manage the data, model storage, and the computing resources"" is a bit vague as well. MLflow can definitely log data, can facilitate the storing of your models on several different storage architectures, but as far as computing resources, are you referring to the training of the model itself? MLflow most certainly doesn't do that. You wouldn't want the tracking server to perform model training. 

Can you clarify what it is that you're looking for assistance on?",provide explanation possible reproduction trying context provided particularly clear trying mean remote source stated hope server manage data model storage bit vague well definitely log data facilitate several different storage far training model certainly would want server perform model training clarify looking assistance,issue,positive,negative,neutral,neutral,negative,negative
1874347824,"I think you're going to need to load the model weights directly using torch APIs directly and then re-save the model with MLflow in order to reflect the changes in your import module resolution. Torch uses pickle, which will maintain references to relative path imports for finding appropriate class definitions to deserialize objects from their stored bytes data. 
This isn't an MLflow issue, though. This is a core Python concept with respect to how namespaces are resolved. 

Can you update that old location with an import to the new file in your project? If not, you might want to work on some custom deserialization logic to handle the loading within your framework.",think going need load model directly torch directly model order reflect import module resolution torch pickle maintain relative path finding appropriate class data issue though core python concept respect resolved update old location import new file project might want work custom logic handle loading within framework,issue,positive,positive,positive,positive,positive,positive
1874229896,"Hello @BenWilson2, Could you please review when you have a moment?",hello could please review moment,issue,negative,neutral,neutral,neutral,neutral,neutral
1874227485,Can we add a brief explanation of this behavior to https://www.mlflow.org/docs/latest/models.html#model-input-example as reference for users and show the difference between the two boolean states of the parameter with a simple example dict input (utilizing the screenshot in the PR content block above would be a good visual aid :) ),add brief explanation behavior reference show difference two parameter simple example input content block would good visual aid,issue,negative,positive,positive,positive,positive,positive
1874077740,@B-Step62 The associated [PR](https://github.com/mlflow/mlflow/pull/9310) is not merged yet so I'm not sure if we would want to mark this as completed.,associated yet sure would want mark,issue,negative,positive,positive,positive,positive,positive
1873586981,@harupy  sorry for the delay. I have closed #10520 and resolved the conflicts in this pr instead,sorry delay closed resolved instead,issue,negative,negative,negative,negative,negative,negative
1872199546,"Hey I am getting this error when i run my Model evaluation pipeline ERROR: main: The configured tracking uri scheme: 'file' is invalid for use with the proxy mlflow-artifact scheme. The allowed tracking schemes are: {'http', 'https'}] I am seeking someone could help me to clear it i am using mlflow version 2.2.2 ",hey getting error run model evaluation pipeline error main scheme invalid use proxy scheme seeking someone could help clear version,issue,negative,positive,positive,positive,positive,positive
1872046170,"Also related to spot runs I think that we could have an issue in overlapping/duplicated logged metrics as it is common that the log frequency is not the same as the checkpoint.
Are we affected by the same issue related to handling duplicate/overlapping entries like the Tensorboard?
https://github.com/tensorflow/tensorboard/issues/3570",also related spot think could issue logged metric common log frequency affected issue related handling like,issue,negative,negative,neutral,neutral,negative,negative
1871643566,"## Test Results screenshots - 

### Installation
<img width=""492"" alt=""installation"" src=""https://github.com/mlflow/mlflow/assets/876989/b322d626-ff39-4c61-9e08-a897ca255df5"">
<img width=""1510"" alt=""install-output"" src=""https://github.com/mlflow/mlflow/assets/876989/66b8c15c-d8e9-4069-985e-cc70293707d7"">

### Store artifacts
<img width=""1040"" alt=""log_model-code-snippet"" src=""https://github.com/mlflow/mlflow/assets/876989/f07bae89-d97b-4ba6-9f71-804280f4f038"">
<img width=""1042"" alt=""object-list-output"" src=""https://github.com/mlflow/mlflow/assets/876989/c8cbcc88-3b8f-427b-be0d-0e5cdf7bed5e"">
",test installation installation store,issue,negative,neutral,neutral,neutral,neutral,neutral
1871630017,"Can someone rollout this chart already? Its been hanging in this state for months!
I believe the work already done is terrific for the community and anything missing can be improved upon in iterations after release.
@harupy @dhrp @ichbinjakes ",someone chart already hanging state believe work already done terrific community anything missing upon release,issue,negative,negative,neutral,neutral,negative,negative
1871549357,"> Does this work when the caller is not allowed to list the bucket? In that case an error is returned but still with the correct x-amz-bucket-region header.


Yi is right, we need to handle that case",work caller list bucket case error returned still correct header right need handle case,issue,negative,positive,positive,positive,positive,positive
1871510786,Does this work when the caller is not allowed to list the bucket? In that case an error is returned but still with the correct x-amz-bucket-region header.,work caller list bucket case error returned still correct header,issue,negative,neutral,neutral,neutral,neutral,neutral
1870623304,@marygracemoesta Could you please let me know if you are picking up this one? I would love to contribute in case you are not working on it.,could please let know one would love contribute case working,issue,positive,positive,positive,positive,positive,positive
1870490974,"Here are all the diffs in the render html. They seem fine

**Good - formatting change with no changes to rendered docs.**
```
mlflow.diviner.html
------------------------------
855: +                model instance.
1385: +                     Example
1692: +                  – Additional arguments for
1702: +                    mlflow.models.model.Model
1711: +                  Additionally, for models that have been fit in Spark, the following supported
1714: + -
1724: +                   partition_by
1730: +                  for setting a (or several) partition columns as a list of             column names. Must be a list of strings of grouping key column(s).
1731: + -
1741: +                   partition_count
1747: +                  for setting the number of part files to write from a             repartition per
1753: +                   partition_by
1759: +                  group. The default part file count is 200.
1760: + -
1770: +                   dfs_tmpdir
1776: +                  for specifying the DFS temporary location where the model will             be stored while copying from a local file system to a Spark-supported “dbfs:/”             scheme.
2576: +                  – Optional configurations for Spark DataFrame storage iff the model has
2583: + Current supported options:
2584: + -
2594: +                   partition_by
2600: +                  for setting a (or several) partition columns as a list of             column names. Must be a list of strings of grouping key column(s).
2601: + -
2611: +                   partition_count
2617: +                  for setting the number of part files to write from a             repartition per
2623: +                   partition_by
2629: +                  group. The default part file count is 200.
2630: + -
2640: +                   dfs_tmpdir
2646: +                  for specifying the DFS temporary location where the model will             be stored while copying from a local file system to a Spark-supported “dbfs:/”             scheme.
854: -                model instance
1689: -                  –
1691: -                   Additional arguments for
1700: -                     mlflow.models.model.Model
1709: -                   Additionally, for models that have been fit in Spark, the following supported
1722: -                      partition_by
1728: -                     for setting a (or several) partition columns as a list of                    column names. Must be a list of strings of grouping key column(s).
1739: -                      partition_count
1745: -                     for setting the number of part files to write from a                    repartition per
1751: -                      partition_by
1757: -                     group. The default part file count is 200.
1768: -                      dfs_tmpdir
1774: -                     for specifying the DFS temporary location where the model will                    be stored while copying from a local file system to a Spark-supported “dbfs:/”                    scheme.
2573: -                  –
2575: -                   Optional configurations for Spark DataFrame storage iff the model has
2581: -                   Current supported options:
2592: -                      partition_by
2598: -                     for setting a (or several) partition columns as a list of                    column names. Must be a list of strings of grouping key column(s).
2609: -                      partition_count
2615: -                     for setting the number of part files to write from a                    repartition per
2621: -                      partition_by
2627: -                     group. The default part file count is 200.
2638: -                      dfs_tmpdir
2644: -                     for specifying the DFS temporary location where the model will                    be stored while copying from a local file system to a Spark-supported “dbfs:/”                    scheme.
```

**Good - formatting and capitalization change.**
```
mlflow.artifacts.html
------------------------------
904: +                – artifact location.
914: +                A dictionary.
1023: +                – Artifact location.
1033: +                A PIL.Image object.
1142: +                – Artifact location.
1152: +                The contents of the artifact as a string.
903: -                – artifact location
913: -                dict
1021: -                – artifact location
1032: -                PIL.Image
1140: -                – artifact location
1151: -                str
```

**Good - line wrap changes with no changes to rendered docs.**
```
mlflow.data.html
------------------------------
1390: +                 Args:
1405: +                   dataset:
1415: +                    An instance of
1427: +                       mlflow.data.dataset.Dataset
1439: +                    ,
1451: +                       mlflow.entities.Dataset
1463: +                    , or
1475: +                       mlflow.entities.DatasetInput
1487: +                    .
1500: +                 Returns:
1511: +                  An instance of
1523: +                     DatasetSource
1535: +                  .
2534: +                   – NumPy features, represented as an np.ndarray or dictionary of named np.ndarrays.
2545: +                   – The source from which the numpy data was derived, e.g. a filesystem path, an S3 URI,
2547: + an HTTPS URL, a delta table name with version, or spark table etc.
2557: +                   may be
2558: + specified as a URI, a path-like string, or an instance of
2566: +                   . If unspecified,
2567: + the source is assumed to be the code location (e.g. notebook cell, script, etc.) where
2604: +                   – The dataset digest (hash). If unspecified, a digest is computed automatically.
3604: +                   – The path of the Spark or Delta source that the DataFrame originally came from. Note
3608: + that the path does not have to match the DataFrame exactly, since the DataFrame may have
3610: + been modified by Spark operations. This is used to reload the dataset upon request via
3639: +                   are specified, a CodeDatasetSource is used, which will source
3643: + information from the run context.
3653: + Note that the table does not have to match the DataFrame exactly, since the DataFrame
3657: + may have been modified by Spark operations. This is used to reload the dataset upon
3660: + request via
3687: +                   are specified, a CodeDatasetSource is used, which will source
3690: + information from the run context.
3699: +                   – If the DataFrame originally came from a Delta table, specifies the version of the
3703: + Delta table. This is used to reload the dataset upon request via
3719: +                   cannot be
3720: + specified if
3735: +                   – The Spark SQL statement that was originally used to construct the DataFrame. Note that
3739: + the Spark SQL statement does not have to match the DataFrame exactly, since the
3743: + DataFrame may have been modified by Spark operations. This is used to reload the dataset
3746: + upon request via
3773: +                   are specified, a CodeDatasetSource is used, which will source
3777: + information from the run context.
3795: +                   – The name of the dataset. E.g. “wiki_train”. If unspecified, a name is automatically
3798: + generated.
3807: +                   – The digest (hash, fingerprint) of the dataset. If unspecified, a digest is
3811: + automatically computed.
5089: +               If the source is path like, then this will construct a DatasetSource object from the source
6221: +                  Returns
6225: +                   An instance of
6228: +                     pyspark.sql.DataFrame
6231: +                   .
6344: +                  Returns
6348: +                   An instance of
6351: +                     pyspark.sql.DataFrame
6354: +                   .
1388: -               Parameters
1404: -                 dataset
1413: -                – An instance of
1426: -                   mlflow.data.dataset.Dataset
1438: -                ,
1450: -                   mlflow.entities.Dataset
1462: -                , or
1474: -                   mlflow.entities.DatasetInput
1486: -                .
1499: -               Returns
1510: -                An instance of
1522: -                   DatasetSource
1534: -                .
2533: -                   – NumPy features, represented as an np.ndarray or dictionary of named
2536: - np.ndarrays.
2544: -                   – The source from which the numpy data was derived, e.g. a filesystem
2548: - path, an S3 URI, an HTTPS URL, a delta table name with version, or
2549: - spark table etc.
2555: -                   may be specified as a URI, a path-like string,
2556: - or an instance of
2568: -                   .
2569: - If unspecified, the source is assumed to be the code location
2570: - (e.g. notebook cell, script, etc.) where
2603: -                   – The dataset digest (hash). If unspecified, a digest is computed
2606: - automatically.
3603: -                   – The path of the Spark or Delta source that the DataFrame originally came from.
3606: - Note that the path does not have to match the DataFrame exactly, since the
3611: - DataFrame may have been modified by Spark operations. This is used to reload the
3612: - dataset upon request via
3638: -                   are specified, a CodeDatasetSource is used, which will
3641: - source information from the run context.
3652: - Note that the table does not have to match the DataFrame exactly, since the
3655: - DataFrame may have been modified by Spark operations. This is used to reload
3659: - the dataset upon request via
3686: -                   are specified, a CodeDatasetSource is
3689: - used, which will source information from the run context.
3698: -                   – If the DataFrame originally came from a Delta table, specifies the version
3701: - of the Delta table. This is used to reload the dataset upon request via
3717: -                   cannot be specified if
3734: -                   – The Spark SQL statement that was originally used to construct the DataFrame.
3737: - Note that the Spark SQL statement does not have to match the DataFrame exactly,
3741: - since the DataFrame may have been modified by Spark operations. This is used to
3745: - reload the dataset upon request via
3772: -                   are specified, a CodeDatasetSource is used,
3775: - which will source information from the run context.
3794: -                   – The name of the dataset. E.g. “wiki_train”. If unspecified, a name is
3797: - automatically generated.
3806: -                   – The digest (hash, fingerprint) of the dataset. If unspecified, a digest
3809: - is automatically computed.
4760: -                   instance.
5088: - If the source is path like, then this will construct a DatasetSource object from the source
6211: - :return: An instance of
6214: -                   pyspark.sql.DataFrame
6217: -                 .
6334: - :return: An instance of
6337: -                   pyspark.sql.DataFrame
6340: -                 .
```",render seem fine good change model instance example additional additionally fit spark following setting several partition list column must list grouping key column setting number part write repartition per group default part file count temporary location model local file system scheme optional spark storage model current setting several partition list column must list grouping key column setting number part write repartition per group default part file count temporary location model local file system scheme model instance additional additionally fit spark following setting several partition list column must list grouping key column setting number part write repartition per group default part file count temporary location model local file system scheme optional spark storage model current setting several partition list column must list grouping key column setting number part write repartition per group default part file count temporary location model local file system scheme good capitalization change artifact location dictionary artifact location object artifact location content artifact string artifact location artifact location artifact location good line wrap instance instance dictionary source data derived path delta table name version spark table may string instance unspecified source assumed code location notebook cell script digest hash unspecified digest automatically path spark delta source originally came note path match exactly since may spark used reload upon request via used source information run context note table match exactly since may spark used reload upon request via used source information run context originally came delta table version delta table used reload upon request via spark statement originally used construct note spark statement match exactly since may spark used reload upon request via used source information run context name unspecified name automatically digest hash fingerprint unspecified digest automatically source path like construct object source instance instance instance instance dictionary source data derived path delta table name version spark table may string instance unspecified source assumed code location notebook cell script digest hash unspecified digest automatically path spark delta source originally came note path match exactly since may spark used reload upon request via used source information run context note table match exactly since may spark used reload upon request via used source information run context originally came delta table version delta table used reload upon request via spark statement originally used construct note spark statement match exactly since may spark used reload upon request via used source information run context name unspecified name automatically digest hash fingerprint unspecified digest automatically instance source path like construct object source return instance return instance,issue,positive,positive,positive,positive,positive,positive
1869892399,@BenWilson2 I would like to work on this issue,would like work issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1869826518,"@sh4x2, I am working on this during this holiday period. Thanks for checking in. I'll be done this week and submit my PR. ",working holiday period thanks done week submit,issue,positive,positive,positive,positive,positive,positive
1869390763,"@raphaelauv Thank you for the contribution! Could you fix the following issue(s)?

#### &#x26a0; DCO check

The DCO check failed. Please sign off your commit(s) by following the instructions [here](https://github.com/mlflow/mlflow/runs/19956262982). See https://github.com/mlflow/mlflow/blob/master/CONTRIBUTING.md#sign-your-work for more details.

#### &#x26a0; Invalid PR template

This PR does not appear to have been filed using the MLflow PR template. Please copy the PR template from [here](https://raw.githubusercontent.com/mlflow/mlflow/master/.github/pull_request_template.md) and fill it out.",thank contribution could fix following issue check check please sign commit following see invalid template appear template please copy template fill,issue,positive,neutral,neutral,neutral,neutral,neutral
1869323929,"Hey @harupy  , Can I work on this? Last time, I accidentally combined both issues pr.",hey work last time accidentally combined,issue,negative,neutral,neutral,neutral,neutral,neutral
1869055471,have not got time here to work. will resume from this week,got time work resume week,issue,negative,neutral,neutral,neutral,neutral,neutral
1868575763,"Hello @harupy  sir, I accidently mixed two issues. can I close this pr and send new one. ",hello sir accidently mixed two close send new one,issue,negative,positive,neutral,neutral,positive,positive
1868143188,"> Any updates on this?

Seems like not. It would be interesting to start developing this feature knowing that multi model endpoints are getting used more often.",like would interesting start feature knowing model getting used often,issue,positive,positive,positive,positive,positive,positive
1868068295,"<strike>+1 I see the same issue w/ `postgres` db. (mlflow 2.9.2)</strike>

#### EDIT
Oh. Postgres w/ mlflow 2.9.2 is working fine;

```
  mlflow-auth-db:
    image: postgres:16.1
    environment:
      POSTGRES_USER: mlflow
      POSTGRES_PASSWORD: mlflow
      POSTGRES_DB: mlflow
```

```
[mlflow]
default_permission = NO_PERMISSIONS
database_uri = postgresql+psycopg2://mlflow:mlflow@mlflow-auth-db:5432/mlflow
admin_username = admin
admin_password = password
authorization_function = mlflow.server.auth:authenticate_request_basic_auth
```",strike see issue edit oh working fine image environment password,issue,negative,positive,positive,positive,positive,positive
1868042333,"Hi, any progress on this fix? Is anyone actively working on this?",hi progress fix anyone actively working,issue,positive,negative,negative,negative,negative,negative
1867119075,"Confirmed that the extras should override the main package. I'll follow up with a fix, but probably only going to be able to get to it in a couple of weeks. Thank you for the report!",confirmed override main package follow fix probably going able get couple thank report,issue,negative,positive,positive,positive,positive,positive
1866576985,I've have been working on it a little bit but I currently fail to find an elegant solution to add these variables to the nginx.conf file.  Nginx does not support environmental variables and the set directive does not seem to work as expected.,working little bit currently fail find elegant solution add file support environmental set directive seem work,issue,positive,negative,neutral,neutral,negative,negative
1865316028,"Thank you, let me start working on this shortly. Should I take over this PR? or create a new one?
->Update: I cannot take over this PR since this is not my repo, let me create a new one.",thank let start working shortly take create new one update take since let create new one,issue,positive,positive,neutral,neutral,positive,positive
1865307714,"> Is it the same as the example code in the design doc?

Yes :)

> Regarding the scope of the change, can I understand the necessary changes are as follows? Anything I'm missing?

Yes, that's correct!",example code design doc yes regarding scope change understand necessary anything missing yes correct,issue,negative,negative,neutral,neutral,negative,negative
1864678574,@harupy Could you please take a look when you have time? Some checks are failing probably since I initially created this PR as draft.,could please take look time failing probably since initially draft,issue,negative,neutral,neutral,neutral,neutral,neutral
1864671266,"Thank you for the reply. So what did the link refer to? Is it the same as the example code in the design doc?
Regarding the scope of the change, can I understand the necessary changes are as follows? Anything I'm missing?

1. Read the rate limit configuration from the endpoint yaml
2. Implement the rate limiting with slowapi
3. Include the rate limit info in the response of get_endpoint",thank reply link refer example code design doc regarding scope change understand necessary anything missing read rate limit configuration implement rate limiting include rate limit response,issue,negative,negative,neutral,neutral,negative,negative
1864439095,"Ah this may be a bug, I would expect that if a package is provided in extra_pip_requirements, and it's already in the inferred requirements, it should overwrite it. I'll check and get back to you!",ah may bug would expect package provided already overwrite check get back,issue,negative,neutral,neutral,neutral,neutral,neutral
1864369758,"@daniellok-db I have one follow-up question - in some case package requirements are logged twice. E.g. in `python_env.yaml`, there is `mypkg[models]==1.0.1` (required for model trying and other parts of the pipeline to run) and I put `extra_pip_requirements=[""mypkg[models]==1.0.1""]` to ensure it will get correctly logged as model requirements including extras. Then in `requirements.txt` of the logged model I can find following two lines:
```
mypkg==1.0.1
mypkg[models]==1.0.1
```
You said
> You can keep custom_lib[models] in your python_env.yaml as well, there shouldn't be any issues with this.

But is the described behavior expected? Because it gets logged twice (one without extras inferred by mlflow and one with extras because of used `extra_pip_requirements`).
",one question case package logged twice model trying pipeline run put ensure get correctly logged model logged model find following two said keep well behavior logged twice one without one used,issue,positive,neutral,neutral,neutral,neutral,neutral
1864016583,"I found the solution, Earlier it was working with Azure Flexible Mysql 8.0 after sometime it stopped working,  so It was issue from Azure side after recently they have update new global parameters and due to that it was failing it.. To resolve this issue we need to ""OFF"" the Global Parametes on Azure DB portal on your database and select Server Parameters and set sql_generate_invisible_primary_key OFF on Portal only dont run as command on SQL level.

Thanks,
Amit Ganvir",found solution working azure flexible sometime stopped working issue azure side recently update new global due failing resolve issue need global azure portal select server set portal dont run command level thanks,issue,positive,positive,neutral,neutral,positive,positive
1863804621,"> any concern on updating the pandas version?

I think we need python 3.9 to use 2.1.0.",concern version think need python use,issue,negative,neutral,neutral,neutral,neutral,neutral
1863739638,"@cdreetz I took a look at the PR, it seems like map was only added in `pandas>=2.1`—i think it might be best to hold off on this change until pandas is about to remove `applymap`, otherwise we risk breaking a lot of workflows. ",took look like map added think might best hold change remove otherwise risk breaking lot,issue,positive,positive,positive,positive,positive,positive
1863734233,"Hi @zoro0312, can you provide more details about what you're trying to do? Ideally, please provide some minimal code that reproduces the bug.",hi provide trying ideally please provide minimal code bug,issue,positive,positive,positive,positive,positive,positive
1863439211,"Hey @mkrdip, could you please let me know if you are still willing to work on this? I would like to take it up if you haven't already made some progress.",hey could please let know still willing work would like take already made progress,issue,positive,positive,positive,positive,positive,positive
1862005303,"Hi @serena-ruan , @BenWilson2 Thanks for reviewing the PR and giving us valuable feedback. IT's been quite some time since this effort has started. can we sort of connect and close this one out?? ",hi thanks giving u valuable feedback quite time since effort sort connect close one,issue,positive,positive,positive,positive,positive,positive
1861962890,"> can I ask if there is a way for me to see [this link](https://github.com/databricks/docs/blob/1a11cec796706750db6538013af930895f8071a4/source/machine-learning/ai-gateway/ai-gateway-tutorial.md)?

Sorry, this is a link to our internal repo. 

> I also saw mlflow.gateway.get_limits is deprecated. Should I reuse the method? or recreate a new one?

`mlflow.gateway` has been deprecated and replaced by `mlflow.deployments`. We no longer have `get_limits`. The rate limit info should be included in the response of `get_endpoint`. I can take care of that part.",ask way see link sorry link internal also saw reuse method recreate new one longer rate limit included response take care part,issue,negative,negative,negative,negative,negative,negative
1861787032,"@harupy I read the doc and understood the overall direction. Before starting the implementation, can I ask if there is a way for me to see [this link](https://github.com/databricks/docs/blob/1a11cec796706750db6538013af930895f8071a4/source/machine-learning/ai-gateway/ai-gateway-tutorial.md)?
I also saw `mlflow.gateway.get_limits` is deprecated. Should I reuse the method? or recreate a new one?",read doc understood overall direction starting implementation ask way see link also saw reuse method recreate new one,issue,negative,positive,neutral,neutral,positive,positive
1861784654,">any updates for the rate limits feature?

Sorry, I couldn't work on that ticket since my main work has been busy for the past couple of weeks. I read the design doc, and asked one question on the PR.",rate feature sorry could work ticket since main work busy past couple read design doc one question,issue,negative,negative,negative,negative,negative,negative
1860839987,"> hey @harupy I proposed another solution for including probability scores [here](https://github.com/mlflow/mlflow/issues/7472#issuecomment-1858606932) what do you think? I am willing to open a PR myself. I figured since `self.y_probs` already gets assigned in `DefaultEvaluator._generate_model_predictions`, we could just make those scores available in `eval_df` as `eval_df[""probabilities""]`

sorry! Didn't realize you were one of the MLflow folks already tagged in my previous/linked comment",hey another solution probability think willing open figured since already assigned could make available sorry realize one already tagged comment,issue,negative,positive,neutral,neutral,positive,positive
1860835247,"hey @harupy I proposed another solution for including probability scores [here](https://github.com/mlflow/mlflow/issues/7472#issuecomment-1858606932) what do you think? I am willing to open a PR myself. I figured since `self.y_probs` already gets assigned in `DefaultEvaluator._generate_model_predictions`, we could just make those scores available in `eval_df` as  `eval_df[""probabilities""]`",hey another solution probability think willing open figured since already assigned could make available,issue,negative,positive,positive,positive,positive,positive
1859484435,"This sounds pretty reasonable, especially in the preview pane and modal. We currently have some utils in MLflow for formatting and rendering Markdown, so it might suffice to just render the output using those instead of outputting plaintext. Here are some code pointers to get you started if you want to contribute a PR for this:

1. Markdown formatting utils are in [MarkdownUtils.ts](https://github.com/mlflow/mlflow/blob/b1228a2b721bfba631409fe802ff916ae0678de7/mlflow/server/js/src/common/utils/MarkdownUtils.ts#L4), see example usage in [EditableNote.tsx](https://github.com/mlflow/mlflow/blob/b1228a2b721bfba631409fe802ff916ae0678de7/mlflow/server/js/src/common/components/EditableNote.tsx#L149)
2. The preview sidebar in the ""Evaluation"" tab can be found in [PreviewSidebar.tsx](https://github.com/mlflow/mlflow/blob/b1228a2b721bfba631409fe802ff916ae0678de7/mlflow/server/js/src/common/components/PreviewSidebar.tsx#L83)
3. The evaluation output in the Prompt Engineering UI modal can be found in [EvaluationCreatePromptRunOutput.tsx](https://github.com/mlflow/mlflow/blob/b1228a2b721bfba631409fe802ff916ae0678de7/mlflow/server/js/src/experiment-tracking/components/evaluation-artifacts-compare/components/EvaluationCreatePromptRunOutput.tsx#L146)",pretty reasonable especially preview pane modal currently rendering markdown might suffice render output instead code get want contribute markdown see example usage preview evaluation tab found evaluation output prompt engineering modal found,issue,positive,positive,positive,positive,positive,positive
1859457205,"Hi @cdreetz, thanks for the report! Do you want to raise a PR for the fix you made?",hi thanks report want raise fix made,issue,negative,positive,positive,positive,positive,positive
1859075792,"> @wamartin-aml is tracking this already and the fix for the validation is rolling out across regions with WEU being released today.
> 
> If you would like to unblock yourself before that, please manually set a lower page size in the client api

yes, that is what I did. as temporary fix",already fix validation rolling across today would like unblock please manually set lower page size client yes temporary fix,issue,positive,neutral,neutral,neutral,neutral,neutral
1859074881,"Hi all,

I was told by the MS engineer that it was issue on the remote server, and fixes were rolled out in WE region.

@wamartin-aml, I can confirm that as our services are deployed in WE, everything is functioning as expected.
Thanks :)
",hi told engineer issue remote server rolled region confirm everything thanks,issue,negative,positive,neutral,neutral,positive,positive
1859034567,"Yup, you got it! If you're interested in the technical details of how we infer the requirements of a model, you can take a look at the [`infer_pip_requirements` function in the code](https://github.com/mlflow/mlflow/blob/51dd444ffb466ff5fce86b2024563d062f12c2e5/mlflow/utils/environment.py#L383). When you call `save_model()`, eventually this function gets called to infer the requirements of just the model.

I'll close the issue now since it seems more or less resolved, but feel free to let me know if you have anything else you want to know.",got interested technical infer model take look function code call eventually function infer model close issue since le resolved feel free let know anything else want know,issue,positive,positive,positive,positive,positive,positive
1859002664,@BenWilson2 sounds good I'll start knocking some of these out soon.  is there an additional import or anything needed for applying the universal docstrings or should it be included already in all model flavors?,good start knocking soon additional import anything universal included already model,issue,negative,positive,positive,positive,positive,positive
1859001775,"@BenWilson2 I went ahead and made a google doc, whats the best way to share? Heres [link](https://docs.google.com/document/d/1KZliOVk2WIsQiBtWJXIY9NUtlsd685rDmh3yk3qHQvk/edit)",went ahead made doc whats best way share link,issue,positive,positive,positive,positive,positive,positive
1858606932,"@BenWilson2 @dbczumar @harupy @WeichenXu123 based on v2.9.2, I would propose 
1. in `DefaultEvaluator._evaluate` at [L1731](https://github.com/mlflow/mlflow/blob/6ca72469b289e77acc2f1201ca39237fc025c090/mlflow/models/evaluation/default_evaluator.py#L1731) adding a check
```python
if self.y_probs is not None:
    eval_df[""probabilities""] = self.y_probs
```
2. in `DefaultEvaluator._get_args_for_metrics` adding a check at [L1198](https://github.com/mlflow/mlflow/blob/6ca72469b289e77acc2f1201ca39237fc025c090/mlflow/models/evaluation/default_evaluator.py#L1198)
```python
elif column == ""probabilities"":
    if ""probabilities"" in eval_df_copy:
        eval_fn_args.append(eval_df_copy[""probabilities""])
    else:
        if param.default == inspect.Parameter.empty:
            params_not_found.append(param_name)
        else:
            eval_fn_args.append(param.default)
```

- if the old format is used where params to the eval function are `eval_df` and `builtin_metrics`, step 1 should be enough because the user will have access to the `""probabilities""` column ([L1184](https://github.com/mlflow/mlflow/blob/6ca72469b289e77acc2f1201ca39237fc025c090/mlflow/models/evaluation/default_evaluator.py#L1184))
- if the user is using the newer format, I think step 2 should cover it, but frankly I've only used the older format because I am using this for custom metrics in Recipes.

Let me know what you think and I can open a PR. This functionality would be very useful to me, as I am trying to use average precision score as my primary metric for recipes. In general, it would be great to see more metrics like these as part of the built-in metric set, but in the meantime it would be a huge help to be able to create custom/extra metrics with probability scores.",based would propose check python none check python column else else old format used function step enough user access column user format think step cover frankly used older format custom metric let know think open functionality would useful trying use average precision score primary metric general would great see metric like part metric set would huge help able create metric probability,issue,positive,positive,positive,positive,positive,positive
1858378379,"We should breadcrumb a reader's way to learn more about the components and to see the guides and tutorials here: https://www.mlflow.org/docs/latest/llms/deployments/index.html#mlflow-deployments-server-experimental and here: https://www.mlflow.org/docs/latest/llms/deployments/guides/step1-create-deployments.html 

We should also include a section on this top-level page here: https://www.mlflow.org/docs/latest/index.html with the appropriate title cards and links to the guides :) 

LMK if there are questions about setting these sections up!",reader way learn see also include section page appropriate title link setting,issue,negative,positive,positive,positive,positive,positive
1857988144,The fix should have been rolled out to westeurope about 12 hours ago - please tag me here if you need any other regions expedited or are still seeing issues in westeurope!,fix rolled ago please tag need expedited still seeing,issue,negative,neutral,neutral,neutral,neutral,neutral
1857958450,"Great, this makes sense. To clarify one thing - do I understand it correctly that `python_env.yaml` is used as a source for project creation (including creating `venv` and installing listed packages) when running `mlflow run ...` and then when model is logged mlflow somehow decides which packages will go to `requirements.txt`?

I was confused several times about the content of the logged `requirements.txt` and the difference to `python_env.yaml` used in my workflow. Your explanation sheds some light on my confusion :) But I am still trying to understand what is going on under the hood. Do you have some reference on this topic (more details and so on)?

It seems to me that I should use `python_env.yaml` to provide dependencies to my workflow (all steps, not just inference) and if I cannot (or don't want to) rely on default handling of `requirements.txt` (that is somehow done by mlflow based on the provided dependencies and logged model afaik based on our conversation) I should rather provide my own requirements for inference (using `pip_requirements` and `extra_pip_requirements`). Is that correct?",great sense clarify one thing understand correctly used source project creation listed running run model logged somehow go confused several time content logged difference used explanation light confusion still trying understand going hood reference topic use provide inference want rely default handling somehow done based provided logged model based conversation rather provide inference correct,issue,negative,positive,positive,positive,positive,positive
1857750057,"meet similar issue and never try how to fix that, i use python 3.8 with mlflow 2.9.1 and sagemaker remote ",meet similar issue never try fix use python remote,issue,negative,negative,neutral,neutral,negative,negative
1857681087,"Hello folks. Same bug was reproducted today, on the same remote tracking server setup, but with a MySQL database and GCS bucket storage.

A possible workaround I implemented on my system this morning is to flush partially the ""datasets"" table, before calling `mlflow gc`, with the following SQL command:
`DELETE datasets FROM datasets JOIN experiments ON datasets.experiment_id = experiments.experiment_id WHERE experiments.lifecycle_stage = ""deleted"";`",hello bug today remote server setup bucket storage possible system morning flush partially table calling following command delete join,issue,negative,negative,neutral,neutral,negative,negative
1857575626,"> @SDonkelaarGDD sorry that I missed your message! I think this is an awesome story to tell and we'd love to feature it as a blog post! Are you up for doing a full write-up?

For sure, but I first need to get formal approval (we're hosting it in a strict regulatory environment). I'll get back to you once I have an answer.",sorry message think awesome story tell love feature post full sure first need get formal approval hosting strict regulatory environment get back answer,issue,positive,positive,positive,positive,positive,positive
1857571962,which function is that? I am able to use `mlflow.pyfunc.load_model` and co from my skinny client to load models that are in my remote tracking server without any issues. Is it for any specific model flavors?,function able use skinny client load remote server without specific model,issue,negative,positive,positive,positive,positive,positive
1857398605,"Thanks for the report! I can reproduce this error, will investigate and get back to you!",thanks report reproduce error investigate get back,issue,negative,positive,neutral,neutral,positive,positive
1857223082,"No worries glad it was helpful! For your follow up questions:

2. If you want to pin whatever version you have installed when saving your model without having to manually change the code all the time, you can do it like this:
```python
mlflow.pyfunc.save_model(
  ...
  extra_pip_requirements=[f""custom_lib[models]=={custom_lib.__version__}""]
)
```
You can keep `custom_lib[models]` in your `python_env.yaml` as well, there shouldn't be any issues with this.

3. I think this question depends on your workflow. Conceptually, the `requirements.txt` file saved with the model just contains all the dependencies required to load and perform inference with the model. The `python_env.yaml` file associated with your MLproject file is for dependencies required in your broader project (which may be more extensive than what your model requires for inference).

Hope this helps!
",glad helpful follow want pin whatever version saving model without manually change code time like python keep well think question conceptually file saved model load perform inference model file associated file project may extensive model inference hope,issue,positive,positive,positive,positive,positive,positive
1857156212,"@wamartin-aml is tracking this already and the fix for the validation is rolling out across regions with WEU being released today.

If you would like to unblock yourself before that, please manually set a lower page size in the client api",already fix validation rolling across today would like unblock please manually set lower page size client,issue,negative,neutral,neutral,neutral,neutral,neutral
1857127545,"Seems loading model function now depends on flask, so for now we shouldn't change it with mlflow-skinny",loading model function flask change,issue,negative,neutral,neutral,neutral,neutral,neutral
1857093636,@cdreetz sounds great! A simple google doc shared with the MLflow maintainers would suffice :) we can use that as a common working document for reviews and edits. ,great simple doc would suffice use common working document,issue,positive,positive,positive,positive,positive,positive
1857093039,@SDonkelaarGDD sorry that I missed your message! I think this is an awesome story to tell and we'd love to feature it as a blog post! Are you up for doing a full write-up?,sorry message think awesome story tell love feature post full,issue,positive,positive,positive,positive,positive,positive
1857091831,"@cdreetz the intention is to file a separate PR for each of the abstracted docstring entries to lessen the burden of review. For instance, one could file a PR for `artifact_path` and ensure that it is applied to all instances within model flavors that it occurs, as the content should be identical, regardless of which flavor implementation it resides in. ",intention file separate abstracted lessen burden review instance one could file ensure applied within model content identical regardless flavor implementation,issue,negative,neutral,neutral,neutral,neutral,neutral
1857083101,Are you asking for more of the xgboost documentation to be abstracted with the templating like {{input_example}} or for this to be applied in all cases of universal docstrings across all modules?  Whats the best way to tackle this?  Just go through each module and submit a single PR once all abstractions applied?,documentation abstracted like applied universal across whats best way tackle go module submit single applied,issue,positive,positive,positive,positive,positive,positive
1857046468,"Hey Ben, I was planning on putting together some content for using MLFlow for a couple different LLMops cases.  I have no preferred format for content if you guys are looking for specific kinds.  Let me know",hey ben together content couple different preferred format content looking specific let know,issue,negative,neutral,neutral,neutral,neutral,neutral
1856210407,"Ah yes, there are a few fixes that need additional testing and verification (this is one of them) to ensure that current users of MLflow are not impacted by the adjustments that were made. This validation process is fairly resource intensive, but we're working on it. We're planning on another minor release before the new year and the fix will definitely be in for that release. ",ah yes need additional testing verification one ensure current impacted made validation process fairly resource intensive working another minor release new year fix definitely release,issue,positive,positive,positive,positive,positive,positive
1856184006,"I just checked the release notes and it doesn't seem to include this bug as a security fix, even though the issue was created before the ones included in the release notes.",checked release seem include bug security fix even though issue included release,issue,negative,neutral,neutral,neutral,neutral,neutral
1856076102,"@daniellok-db thank you for your reply. I was not aware of this functionality (using `extra_pip_requirements`), so that's definitely useful, thank you! I have a few follow-up questions.

1. I was not able to make it work in my custom project, but it's a bit more complex one so I will try to find a way to make it work or submit another issue if I find a way how to reproduce it.

2. I was able to reproduce it with a simple project. But there are several issues:
- library version is not listed (as in your example, there is only `scikit-learn[openmp]` in the final `requirements.txt`, no version info)
- (I could provide version directly in `extra_pip_requirements`, I guess, but that would mean I need to update it every time when new lib is released, but my idea was that the latest lib version would be taken during training, logged and then re-used when deploying the trained model)
- should I keep it (e.g. `scikit-learn[openmp]`) in my `python_env.yaml` as well or only as `extra_pip_requirements`?

3. Which leads to another question - how to properly handle `python_env.yaml` and `extra_pip_requirements`? I understand it might be kind of tricky to correctly infer all the requirements including extras, but having a single place/file where I can put my dependencies (which was `python_env.yaml` in my case) is much easier to handle than adding another requirements directly in the code (and I usually have sth like multi-step workflow, therefore several steps share the same MLproject with its dependencies).",thank reply aware functionality definitely useful thank able make work custom project bit complex one try find way make work submit another issue find way reproduce able reproduce simple project several library version listed example final version could provide version directly guess would mean need update every time new idea latest version would taken training logged trained model keep well another question properly handle understand might kind tricky correctly infer single put case much easier handle another directly code usually like therefore several share,issue,positive,positive,positive,positive,positive,positive
1856020813,"This issue can be solved by exporting the enviroment variable `MLFLOW_TRACKING_URI` ! :+1: 
```shell
export MLFLOW_TRACKING_URI=http://127.0.0.1:<PORT NUMBER>
```",issue variable shell export number,issue,negative,neutral,neutral,neutral,neutral,neutral
1855909592,"Cross version check passed for tensorflow/autologging/dev but failed for tensorflow/model/dev. It seems the issue is unrelated to this change, rather more deeply reside in Keras internal (model serialization). Merging this change now and will dig into that separately.",cross version check issue unrelated change rather deeply reside internal model serialization change dig separately,issue,negative,neutral,neutral,neutral,neutral,neutral
1855651916,"Hello, do you have an estimate on when the next patch will be released? Thanks.",hello estimate next patch thanks,issue,negative,positive,neutral,neutral,positive,positive
1855638984,Is there anyone that could check this? It should be a simple bugfix.,anyone could check simple,issue,negative,neutral,neutral,neutral,neutral,neutral
1855527770,"I don't think model serving should be affected. Even while using the internal `mlflow`/`mlserver` serving mechanism the API requests are made to the host ""main"" mlflow server, always through the same URI (typically the same as the tracking server). If the server-side code was needed at a model level, it would mean that we'd need to connect to a different server/port for each different model being served, which is not the case.

In any case, I just need a solution that works for me, if I can get it done with the extra pip requirements that's enough (right now I just run a regex on the resulting requirement files). Option 2 looks cleaner and nicer from an API point of view, and it would make the functionality easier to discover for users that haven't encountered this problem before. In the long run, however, I think that the skinny choice should be the default. Shipping a full-blown http server with each model is both an overkill and a risk from a security point of view.

I will make a short PR implementing option 2 through a parameter passed to `log-model`, leaving the default as the current behaviour.",think model serving affected even internal serving mechanism made host main server always typically server code model level would mean need connect different different model case case need solution work get done extra pip enough right run resulting requirement option cleaner point view would make functionality easier discover problem long run however think skinny choice default shipping server model risk security point view make short option parameter leaving default current behaviour,issue,negative,negative,neutral,neutral,negative,negative
1855408667,"Hello @harupy, Is there any way to access to the slack? I'm trying to connect with my personal email but only databricks domains is allowed ?",hello way access slack trying connect personal,issue,negative,neutral,neutral,neutral,neutral,neutral
1855364544,"Hi @TheBugKing, what does [your setup](https://mlflow.org/docs/latest/tracking.html#common-setups) look like? Are you trying to fetch metrics from a remote tracking server, and if so, have you checked if anything changed on the remote server?",hi setup look like trying fetch metric remote server checked anything remote server,issue,negative,negative,neutral,neutral,negative,negative
1855348505,"Hi @sxooler! It's a little tricky to infer whether an extra is required for a model, but if you want to ensure that the extra is included in the `requirements.txt` file, you can use the `extra_pip_requirements` param when saving your model. Here's an example (you can also refer to [this page in the docs](https://mlflow.org/docs/latest/deployment/deploy-model-to-kubernetes/index.html#specifying-pip-requirements-using-pip-requirements-and-extra-pip-requirements) for more examples):

```python
import mlflow

class MyModel(mlflow.pyfunc.PythonModel):
    def predict(self, context, model_input):
        return model_input
    
mlflow.pyfunc.save_model(
    path=""my-model"", 
    python_model=MyModel(),
    extra_pip_requirements=[""scikit-learn[openmp]""]
)
```

The `requirements.txt` file should have the package and extra listed:
```
mlflow==2.9.1
cloudpickle==2.2.1
scikit-learn[openmp]
```

Let me know if this solves your problem!",hi little tricky infer whether extra model want ensure extra included file use param saving model example also refer page python import class predict self context return file package extra listed let know problem,issue,negative,negative,neutral,neutral,negative,negative
1855175004,"Confirmed the test worked with dev version (model test as well), reverting the dummy change and will merge.

<img src=""https://github.com/mlflow/mlflow/assets/31463517/a2e02d6f-3194-49d4-86e8-e30c1594ecba"" width=""500px""/>

```
Run if { [ ""scikit-learn"" = ""tensorflow"" ] || [ ""scikit-learn"" = ""scikit-learn"" ]; } && [ ""dev"" = ""dev"" ]; then
+ '[' scikit-learn = tensorflow ']'
+ '[' scikit-learn = scikit-learn ']'
+ '[' dev = dev ']'
+ python_version=3.9
+ echo version=3.9
```",confirmed test worked dev version model test well dummy change merge run dev dev dev dev echo,issue,negative,positive,positive,positive,positive,positive
1854971032,"Sorry @jlopezpena I pinged the wrong person. After a second thought, this might be affecting model serving so we need to be careful. There are two options: 1. specifying `extra_pip_requirements=[""mlflow-skinny""]` when you log a model and this would remove mlflow as default dependency. 2. We could add an argument to enable/disable using mlflow-skinny or mlflow as default dependency, and still default to use mlflow for backwards compatibility.",sorry wrong person second thought might affecting model serving need careful two log model would remove default dependency could add argument default dependency still default use backwards compatibility,issue,negative,negative,negative,negative,negative,negative
1854316489,Thanks for the fix @BenWilson2 !!! This was messing up our model serving endpoints!!!,thanks fix messing model serving,issue,negative,positive,positive,positive,positive,positive
1854250823,"@B-Step62 Could you point me in the right direction? I guess this makes sense only for a local runs, therefore `projects/backend/local.py` should be mainly affected. Or does it make sense to implement sth similar elsewhere? ",could point right direction guess sense local therefore mainly affected make sense implement similar elsewhere,issue,negative,positive,positive,positive,positive,positive
1853924701,"Not sure if the question was meant for me or for Jim; if it is the former, sure, I can get a PR done. This should be simple enough (as simple as a search and replace `mlflow==` by `mlflow-skinny==` across the repo), might only need some guidance/supervision on checking that I have made the replacements everywhere they need to be made (functions that write the requirements, dockerfiles, etc)",sure question meant former sure get done simple enough simple search replace across might need made everywhere need made write,issue,positive,positive,positive,positive,positive,positive
1853835250,This makes sense. @jlopezpena Would you like to raise a PR for this? We can help review it or provide any guidance you'd like :D,sense would like raise help review provide guidance like,issue,positive,neutral,neutral,neutral,neutral,neutral
1853589609,"Realized that [AzureML](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-deploy-mlflow-models) and [Databricks](https://docs.databricks.com/en/machine-learning/model-inference/index.html) already have solid guidelines for MLflow model deployment in their documentation. Replaced the placeholder pages with direct links.
",already solid model deployment documentation direct link,issue,negative,positive,neutral,neutral,positive,positive
1853220394,"Hello @BenWilson2, I've pushed the changes. Kindly take a look when you get a chance.",hello kindly take look get chance,issue,positive,positive,positive,positive,positive,positive
1853134940,"> Looks good but can we rename it like sanitize_path or sth? I think ppl generally expect validate_xxx function to have no side-effect or data mutation.

Sounds good, I'll file a good first issue for that :)",good rename like think generally expect function data mutation good file good first issue,issue,positive,positive,positive,positive,positive,positive
1852544693,"Hi @sainivedh when you push the changes, can you rebase on master as well just to make sure that you have the latest CI config?",hi push rebase master well make sure latest,issue,positive,positive,positive,positive,positive,positive
1852484412,"> @BenWilson2, I appreciate your suggestions, but I'm a bit uncertain about your point. The deployments server utilizes [get_provider](https://github.com/mlflow/mlflow/blob/119eef6a0a8008eeb5820f41a5b7afcb92f2d118/mlflow/deployments/server/app.py#L38) from `mlflow.gateway.providers`, which includes all other [providers](https://github.com/mlflow/mlflow/tree/master/mlflow/gateway/providers). If I overlooked something, could you please clarify?

LOL sorry, it's been a long week. I'll take a look at the PR now ;) ",appreciate bit uncertain point server something could please clarify sorry long week take look,issue,negative,negative,negative,negative,negative,negative
1852475186,Fix confirmed by original reporter,fix confirmed original reporter,issue,negative,positive,positive,positive,positive,positive
1852453702,A few nits and grammar corrections / typos. Let's get this merged once these are fixed! ,grammar let get fixed,issue,negative,positive,neutral,neutral,positive,positive
1852438240,"@BenWilson2, I appreciate your suggestions, but I'm a bit uncertain about your point. The deployments server utilizes [get_provider](https://github.com/mlflow/mlflow/blob/119eef6a0a8008eeb5820f41a5b7afcb92f2d118/mlflow/deployments/server/app.py#L38) from `mlflow.gateway.providers`, which includes all other [providers](https://github.com/mlflow/mlflow/tree/master/mlflow/gateway/providers). If I overlooked something, could you please clarify?",appreciate bit uncertain point server something could please clarify,issue,negative,neutral,neutral,neutral,neutral,neutral
1851259785,"Basic auth by design requires logging in every time the browser is re-opened. It's not a good idea to store username & password (e.g., in cookies).
",basic design logging every time browser good idea store password,issue,negative,positive,positive,positive,positive,positive
1851224064,"@keenranger yep! That's the one :D 
Please feel free to re-submit a modified version of your original PR once you get the backwards compatibility working ",yep one please feel free version original get backwards compatibility working,issue,positive,positive,positive,positive,positive,positive
1851160398,"Hi @Edouard59 That depends on your use cases, experiments/runs logged frequency and query frequency, we won't provide a guidance on that and please consult a general server guideline.",hi use logged frequency query frequency wo provide guidance please consult general server guideline,issue,negative,positive,neutral,neutral,positive,positive
1851149441,Sounds like a great idea! Contributions are welcome!,like great idea welcome,issue,positive,positive,positive,positive,positive,positive
1851116266,"@BenWilson2 can you help me push the changes. Some of the code in Databricks specfic, so it might not need a card in MLflow. The blog will host it",help push code might need card host,issue,negative,neutral,neutral,neutral,neutral,neutral
1850984637,@gphillips-ema @dbczumar are there any updates on this FR? This functionality would be really useful,functionality would really useful,issue,negative,positive,positive,positive,positive,positive
1850838956,"We'll need to update a few entries in some other files so that this notebook can be rendered as html. 

1. In the file `mlflow/docs/source/llms/rag/index.rst`, we need to add the notebook on line 15 to the hidden ToC
2. A new section in that same document (probably at the top before the existing `Question Generation for RAG Tutorial` section that includes the links to view the notebook and download it) 
3. An entry to the main index.rst landing page with a link to the notebook (as a card). 

LMK if you'd prefer me to push those changes to this branch or not.",need update notebook file need add notebook line hidden new section document probably top question generation rag tutorial section link view notebook entry main landing page link notebook card prefer push branch,issue,negative,positive,positive,positive,positive,positive
1850726695,"> @BenWilson2, I have opened this pull request to update to the latest version of the Deployment Server. I've included examples [here](https://github.com/mlflow/mlflow/blob/98829d11703e9b2b7ecfe5ed2c28267f85fd8add/examples/deployments/deployments_server/clarifai/README.md).
> 
> ```shell
> mlflow deployments start-server --config-path examples/deployments/deployments_server/clarifai/config.yaml  --port 7000
> ```

You added implementations to `mlflow.gateway`. This namespace is deprecated. See the link that I provided for where the server implementation would need to be moved to.",pull request update latest version deployment server included shell port added see link provided server implementation would need,issue,negative,positive,positive,positive,positive,positive
1850712657,"@BenWilson2, I have opened this pull request to update to the latest version of the Deployment Server. I've included examples [here](https://github.com/mlflow/mlflow/blob/98829d11703e9b2b7ecfe5ed2c28267f85fd8add/examples/deployments/deployments_server/clarifai/README.md).

```bash
mlflow deployments start-server --config-path examples/deployments/deployments_server/clarifai/config.yaml  --port 7000
```",pull request update latest version deployment server included bash port,issue,negative,positive,positive,positive,positive,positive
1850674751,Hi @sainivedh the gateway has been deprecated. Could you add the implementation [here](https://github.com/mlflow/mlflow/tree/master/mlflow/deployments/server) instead of the deprecated namespace?,hi gateway could add implementation instead,issue,negative,neutral,neutral,neutral,neutral,neutral
1850622191,@BenWilson2 Could you please review when you have a moment?,could please review moment,issue,negative,neutral,neutral,neutral,neutral,neutral
1850455490,"I would also like to be able to download from the mlflow UI a full folder (and all its sub-folders/files) with a single click on a ""download artifacts"" button when the folder is selected. As of today this is only possible on files. I guess this may relate somehow to this work, as the downloaded result may be a tar.gz file ?",would also like able full folder single click button folder selected today possible guess may relate somehow work result may file,issue,negative,positive,positive,positive,positive,positive
1850395008,"@keenranger Now that we have backwards compatibility tests for Python Models, this implementation can be revisted and implemented in a way that guarantees that loading older models saved prior to this change will function correctly. As the PR stands, it is not backwards compatible. ",backwards compatibility python implementation way loading older saved prior change function correctly backwards compatible,issue,negative,positive,neutral,neutral,positive,positive
1850172077,"@B-Step62 I am sorry for delay, I will create a PR this week, thank you for the feedback.",sorry delay create week thank feedback,issue,negative,negative,negative,negative,negative,negative
1849777282,"From my knowledge, that kind of metaclass declaration was supported in Python2, and retained to support Python 2 compatibility which is now deprecated. Considering mlflow uses ABCMeta to indicate that PyFuncModel is an abstract class, I think forcing it to use correct inheritance is a good way.",knowledge kind declaration python support python compatibility considering indicate abstract class think forcing use correct inheritance good way,issue,positive,positive,positive,positive,positive,positive
1849764636,"@BenWilson2 @dbczumar @sunishsheth2009 sorry for replying on merged PR.
But isn't that issue was caused by missing implementation of predict function? Isn't forcing to implement predict function goal of abstract class & method?",sorry issue missing implementation predict function forcing implement predict function goal abstract class method,issue,negative,negative,negative,negative,negative,negative
1849702162,"Keeping this FR open for users to vote. It requires frontend change, so would like to see how people feels. Contributions are welcome!",keeping open vote change would like see people welcome,issue,positive,positive,positive,positive,positive,positive
1849230855,"@xgdgsc Which password are you referring to? If it's MLFLOW_TRACKING_PASSWORD you can set environment variable.
BTW: Please do not raise such issue with no environment and context details.",password set environment variable please raise issue environment context,issue,negative,neutral,neutral,neutral,neutral,neutral
1848845095,I won't be putting anymore effort into this as there does not seem to be interest from maintainers and bitnami has provided a chart. Anyone is welcome to continue this work. ,wo effort seem interest provided chart anyone welcome continue work,issue,positive,positive,positive,positive,positive,positive
1847354957,Received confirmation from researcher that this PR fixes the security issue. Merging.,received confirmation researcher security issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1847108332,"Thanks @prithvikannan! I believe the MLflow 2.9.1 introduced changes to `_extract_score_and_justification` function. I will test it again.

Currently, we only have `gpt-3.5-turbo` chat model on AI Gateway (now named MLflow Deployments Server). We don't have the instruct version ( `gpt-3.5-turbo-instruct` ) for completion. The evaluation requires a completion endpoint. We were testing so far with the instruct models available to us:

- [falcon-40b-instruct](https://huggingface.co/tiiuae/falcon-40b-instruct)
- [mpt-30b-instruct](https://huggingface.co/mosaicml/mpt-30b-instruct)
- [codellama-13b-instruct](https://huggingface.co/codellama/CodeLlama-13b-Instruct-hf)

They failed in `_extract_score_and_justification` execution for `MLflow 2.8.1`.

We are registering instruct models as completion endpoints and chat models as chat endpoints.",thanks believe function test currently chat model ai gateway server instruct version completion evaluation completion testing far instruct available u execution instruct completion chat chat,issue,negative,positive,positive,positive,positive,positive
1846505954,"Question: do we know if there's any unintended consequences to the pre-upload credential fetch batch count (defaulted at 50) if someone were to increase the upload file size to, say, 50x the default? ",question know unintended credential fetch batch count someone increase file size say default,issue,negative,neutral,neutral,neutral,neutral,neutral
1846017814,"> Thank you for the quick resolution, can I request a CVE for this vulnerability please?

It will get filed by huntr after we release the fix in our next patch.",thank quick resolution request vulnerability please get release fix next patch,issue,negative,positive,positive,positive,positive,positive
1845914802,"Thank you for the quick resolution, can I request a CVE for this vulnerability please?",thank quick resolution request vulnerability please,issue,negative,positive,positive,positive,positive,positive
1845039989,I get this error from any assumed role: ```mlflow.exceptions.RestException: INTERNAL_ERROR: The request signature we calculated does not match the signature you provided. Check your AWS Secret Access Key and signing method. Consult the service documentation for details.```,get error assumed role request signature calculated match signature provided check secret access key method consult service documentation,issue,negative,negative,negative,negative,negative,negative
1845006753,"Hi @hoiting Thanks for raising this bug! I can repro it, currently the workaround is to remove the type hint in your `predict` method:
```
from typing import List, Dict
import mlflow

class MyModel(mlflow.pyfunc.PythonModel):
    def predict(self, context, model_input):
        # please note that current schema enforcement logic converts List[str] to pandas dataframe
        return model_input

mlflow.pyfunc.save_model(""model"", python_model=MyModel(), input_example=[""a""])
```

I'll raise a PR to fix this.",hi thanks raising bug currently remove type hint predict method import list import class predict self context please note current schema enforcement logic list return model raise fix,issue,positive,positive,neutral,neutral,positive,positive
1844879118,Hey @danilopeixoto Would you like to implement this feature? I can assign the task to you :D ,hey would like implement feature assign task,issue,negative,neutral,neutral,neutral,neutral,neutral
1844407059,@BenWilson2 - Can you please help review the PR? Thanks in advance. ,please help review thanks advance,issue,positive,positive,positive,positive,positive,positive
1843365822,"@B-Step62 I made the changes, however they only work for the newest version of mlflow, when using the _validate_param function it checks if the value exceeds 6000 characters, and if your mlflow server is not to the latest version 2.8 (like you mentioned before), the fix I made here won't work. So the local version and the server version must match.

Regarding everything else, I did the pre-commit and tried to sign it off but I'm sure I made a mistake. I think the way to go is closing the PR, branching from master do the changes and making a new PR where I run the pre-commit and try to sign all my commits. Should I do that? Thank you very much for the help.",made however work version function value server latest version like fix made wo work local version server version must match regarding everything else tried sign sure made mistake think way go branching master making new run try sign thank much help,issue,positive,positive,positive,positive,positive,positive
1843053229,"> Thanks so much for your work on this! Provided some feedback. At a high level, I'm wondering if we can reorder the steps so that you set an alias on a model version before loading it. That would be a more realistic workflow - aliases are meant for easier model loading / deployment.
> 
> Step 1: register the model. Step 2: open the Model Registry UI to find the model you just registered. Poke around in the UI, maybe setting some tags. Setting an alias on the model version for loading later. Step 3: load the registered model via alias model URI (e.g. `models:/my_model@champion`. You can also show how to load via the `get_model_version_by_alias()` API and via the model version URI (e.g. `models:/my_model/1`. Use the loaded model for inference.

Yeah this is a good call out. We do both, so I think we cover our bases. Here is where we get the [model version by alias](https://github.com/mlflow/mlflow/pull/10537/files#diff-faf3d38ec689d9a69a2d86866614449b95699d4e059ea2dee785925fb226ee7fR69). Given this is a model registry tutorial and not simply a tutorial on model version aliases, I think this flow makes sense. Thoughts? An alternative is to add a `Get Model by Version Alias` step on the third page.",thanks much work provided feedback high level wondering reorder set alias model version loading would realistic meant easier model loading deployment step register model step open model registry find model registered poke around maybe setting setting alias model version loading later step load registered model via alias model champion also show load via via model version use loaded model inference yeah good call think cover base get model version alias given model registry tutorial simply tutorial model version think flow sense alternative add get model version alias step third page,issue,positive,positive,neutral,neutral,positive,positive
1842774399,for me also issue fixed with 2 deferent database ,also issue fixed deferent,issue,negative,positive,neutral,neutral,positive,positive
1842425623,"Great, we need to:

* Rename the current docker file to be the slim version
* Figure out what dependencies that would be useful for the non slim version
* Make the new dockerfile 
* Update the pipelines

@rajveer43 Do you want to start with figure out the dependencies or the pipelines?",great need rename current docker file slim version figure would useful non slim version make new update want start figure,issue,positive,positive,positive,positive,positive,positive
1842126310,"This CI “Test requirements / core“ is testing ""mlflow core"" requirements. MLflow deployments is an optional component, so ""mlflow core"" requirements do not need to satisfy MLflow deployments requirements. :)",test core testing core optional component core need satisfy,issue,negative,neutral,neutral,neutral,neutral,neutral
1842018158,"@harupy 
Closing this in favor of these 4 clean branches, please review 
- [remove mlflow dbfs  ](https://github.com/mlflow/mlflow/pull/9872)
- [paramerization](https://github.com/mlflow/mlflow/pull/10596)
- [GPU Jar access](https://github.com/mlflow/mlflow/pull/10597/)
- [Visual Jar  + minor refactor](https://github.com/mlflow/mlflow/pull/10603)
",favor clean please review remove jar access visual jar minor,issue,positive,positive,positive,positive,positive,positive
1842009742,"Re. what model types to support - good question! The specific use case that my org had was to store an arbitrary R object. Our data sci team had a model ""bundle"" that was just an R `list()` containing:

* a model object
* data preprocessing functions

The usage looks something like 

``` r
bundle <- mlflow_load_model(""my-model"", 1)
data <- get_my_data()
processed_data <- bundle$preprocess(data)
predictions <- predict(bundle$model, data)
```

This isn't derived from any specific ML library, it's just a bundle of _stuff_ that forms the reproducible unit that the DS team want to work with. I'm not proposing this specific pattern as a flavor, that's just what our team wanted to do. I wrote the `rblob` flavor specifically so it doesn't care what object you're storing.

Things I like about this approach:

* Flexibility. Store any R object you like.
* One catch-all flavor so a lower maintenance burden.
* Very simple code.

Things I don't like:

* As you mentioned, not obvious how to generate a signature. It would probably have to involve an explicit action by the user (e.g. they call `signature <- mlflow_generate_signature(model_bundle$model)`).
* The object may not have a `predict()` method so how does it fit with `mlflow_predict()` etc.
* If you're storing a more complex object you may need to manually unpack files to the right locations etc.
* Doesn't provide reproducible environments. I did look at using `renv` to automatically capture and include a `renv.lock` file but it was a bit complex so I haven't dug into it.

I feel that these drawbacks are surmountable with documentation - if we were to offer this very generic flavor we can say ""this is what you need to be able to store and load a model. If you want to use `mlflow_predict()` you also need to define method X"", and so on.

Keen to hear your thoughts on the best approach 😄 ",model support good question specific use case store arbitrary object data team model bundle list model object data usage something like bundle data bundle data predict bundle model data derived specific library bundle reproducible unit team want work specific pattern flavor team wrote flavor specifically care object like approach flexibility store object like one flavor lower maintenance burden simple code like obvious generate signature would probably involve explicit action user call signature model object may predict method fit complex object may need manually unpack right provide reproducible look automatically capture include file bit complex dug feel surmountable documentation offer generic flavor say need able store load model want use also need define method keen hear best approach,issue,positive,positive,positive,positive,positive,positive
1841993110,"> does the vignettes package provide better documentation rendering for R?

I don't know about ""better"", but my reasons for defaulting to a vignette are: 

* Vignettes are the traditional way of doing long-form docs in R, so - as an R user - this is a natural home for an in-depth exploration of a topic.
* Vignettes are installed with the package so a user can access them locally.
* The RStudio ecosystem has excellent support for creating and managing vignettes.

That said I'm perfectly happy to work with whatever the project prefers.

As a side note, [`pkgdown`](https://pkgdown.r-lib.org/) allows us to build a mini website out of a package's docs (and vignettes). It can be built and deployed using an included GitHub Actions workflow, and the main MLflow docs could link to that site. This may have already been discussed, just mentioning it as I note it's not already in use.",package provide better documentation rendering know better vignette traditional way user natural home exploration topic package user access locally ecosystem excellent support said perfectly happy work whatever project side note u build package built included main could link site may already note already use,issue,positive,positive,positive,positive,positive,positive
1841949434,"> @gabrielfu The gateway-migration has been merged (lots of conflicts as expected...)

No problem, let me update this pr :)",lot problem let update,issue,negative,neutral,neutral,neutral,neutral,neutral
1841538580,"Hi @BenWilson2, I was thinking of the latter approach, of adjusting the logic for selecting which steps to log based on the number of optimizers. I don't think there's a way to have per-optimizer metrics with the way the Lightning API works. I will open a PR for this shortly.",hi thinking latter approach logic log based number think way metric way lightning work open shortly,issue,negative,neutral,neutral,neutral,neutral,neutral
1841416900,"@danilopeixoto , thanks for the FR! 

We have found that the current logic of first attempting to parse JSON and falling back to regex has been effective https://github.com/mlflow/mlflow/blob/master/mlflow/metrics/genai/genai_metric.py#L53-L78, especially with high quality models such as OpenAI GPT-4. Have you run into issues where you are unable to extract the score and justification? Which judge model were you using? 

Re: your proposals
> 1. Modify the grading system prompt template to generate output in JSON format.
> 2. Allow to easily customize the grading system prompt template.
> 3. Introduce the {grading_format} template variable in the grading system prompt template to define format aspect.

My preference would be to go with option 1. We expect nearly all users of llm-as-judge to want to extract scores and justification (the `MetricValue` object is also constructed this way), so I would prefer to just expose a high quality score parser by default rather than having users create their own. ",thanks found current logic first parse falling back effective especially high quality run unable extract score justification judge model modify grading system prompt template generate output format allow easily grading system prompt template introduce template variable grading system prompt template define format aspect preference would go option expect nearly want extract justification object also way would prefer expose high quality score parser default rather create,issue,positive,positive,positive,positive,positive,positive
1841396720,"> @prithvikannan any objections to this addition?

I think this would be a great addition!",addition think would great addition,issue,positive,positive,positive,positive,positive,positive
1841362991,This sounds reasonable! Feel free to file a PR and link it to this issue! Thanks :) ,reasonable feel free file link issue thanks,issue,positive,positive,positive,positive,positive,positive
1841358872,"Interesting finding! @adamreeve would the intention be to have the metrics logged for each optimizer at a given step by adjusting the iterative step selection logic (in which case the metric name would need to be mutated to avoid collisions), or is the intention to just log the metric once per adjusted step trigger based on the count of the optimizers involved? ",interesting finding would intention metric logged given step iterative step selection logic case metric name would need avoid intention log metric per step trigger based count involved,issue,negative,positive,positive,positive,positive,positive
1841062448,"@codekcg23 there will be no ill side effects to disabling mlflowdbfs for this use case. In general, when operating within a single workspace, you'll have slightly better IO performance (particularly for very large models) by using mlflowdbfs, but for what you're trying to do (Spark Models in general (except for models like ALS or FPGrowth) aren't particularly large), this will work well :) 

UC will offer benefits to the model registry and is a much more future-proof direction to go in (which you'll see more and more of next year), but support for what you're working on will continue to function just fine for many years. 

I'll go ahead and close this ticket. Thanks for posting it and good luck with your modeling endeavors! ",ill side effect use case general operating within single slightly better io performance particularly large trying spark general except like particularly large work well offer model registry much direction go see next year support working continue function fine many go ahead close ticket thanks posting good luck modeling,issue,positive,positive,positive,positive,positive,positive
1840369142,"Hi @BenWilson2 , I  will look into using Unity Catalog.

I used below code to disable mlflowdbfs and was able to log the spark model to a different workspace. Will there be any issues if I use this workaround?

```
import os
os.environ[""DISABLE_MLFLOWDBFS""] = ""true""
```",hi look unity used code disable able log spark model different use import o true,issue,positive,positive,positive,positive,positive,positive
1840170376,"closing because it will likely be a breaking change. may open another in the future making it configurable by an env var, but not prioritized for now",likely breaking change may open another future making,issue,negative,neutral,neutral,neutral,neutral,neutral
1839914930,"> @gabrielfu Let's wait until after the 2.9 release to merge this :D

Sure!",let wait release merge sure,issue,negative,positive,positive,positive,positive,positive
1839912486,@gabrielfu Let's wait until after the 2.9 release to merge this :D ,let wait release merge,issue,negative,neutral,neutral,neutral,neutral,neutral
1839849893,"Hi @liangz1 sorry for the late reply.
Many of the bugs are very hard to re-produce and seem to occur randomly after working for 4-8 hours on DB clusters and doing certain activity patterns.  Some seem to be related to resource allocation issues with underlying DB Infrastructure. 

But here is one thats very easy to re-produce and should not directly be infra related
The attached notebook (HTML Format) demonstrates the whitespace bug 3). 
It's only present in ML runtimes, you can run the same code in standard runtime and not get this bug.
Disabling the usage of mlflowdbfs like in [this PR](https://github.com/mlflow/mlflow/pull/9872) fixes the issue an makes saving models with whitespace possible inside of ML-Runtimes. 
Also fixes all other mlflowdbfs related issues.


Attached file is a HTML db notebook, save it with .html suffix. 
[DB-Bugreport shared.txt](https://github.com/mlflow/mlflow/files/13553779/DB-Bugreport.shared.txt)
",hi sorry late reply many hard seem occur randomly working certain activity seem related resource allocation underlying infrastructure one thats easy directly infra related attached notebook format bug present run code standard get bug usage like issue saving possible inside also related attached file notebook save suffix,issue,positive,negative,neutral,neutral,negative,negative
1839844794,"@codekcg23 Can you test a runtime that does not have `ML` in it's name?
ML based runtimes use mlflowdbfs. If you use a Non-ML runtime, it will not be used and you should get around this issue and be able to confirm it's mlflowdbfs related 

Thanks a lot",test name based use use used get around issue able confirm related thanks lot,issue,negative,positive,positive,positive,positive,positive
1839814542,"@sxooler Yes, either having a new command or a flag to update virtualenv makes sense to me, which to take is more like personal preference imo:) Would you mind taking this issue and filing a PR?

Also totally agree that the behavior should be more visible to new users. We should probably update docs to explicitly mention this.",yes either new command flag update sense take like personal preference would mind taking issue filing also totally agree behavior visible new probably update explicitly mention,issue,positive,positive,neutral,neutral,positive,positive
1839452258,"@letian-w Thank you for the contribution! Could you fix the following issue(s)?

#### &#x26a0; PR branch check

This PR was filed from the master branch in your fork, which is not recommended and may cause our CI checks to fail. Please close this PR and file a new PR from a non-master branch.",thank contribution could fix following issue branch check master branch fork may cause fail please close file new branch,issue,negative,negative,negative,negative,negative,negative
1839446350,Dug into this a bit. You can specify an env car `MLFLOW_AUTH_CONFIG_PATH` that points to your custom configuration file. You don't have to edit `mlflow/server/auth/basic_auth.ini` every time. See [this line](https://github.com/mlflow/mlflow/blame/master/mlflow/server/auth/config.py#L5).,dug bit specify car custom configuration file edit every time see line,issue,negative,neutral,neutral,neutral,neutral,neutral
1839395587,"Looking good! Once that typo is fixed, we can merge! :D ",looking good typo fixed merge,issue,negative,positive,positive,positive,positive,positive
1839345086,"None of these are typos. Please see https://en.wikipedia.org/wiki/If_and_only_if for guidance on what these terms are referring to. 
Thank you for the intention, though! If you see other things that you'd like to contribute to, don't hesitate to reach out and pick up one of our good first issues! ",none please see guidance thank intention though see like contribute hesitate reach pick one good first,issue,positive,positive,positive,positive,positive,positive
1839244464,Seems like a good idea to auto-add the content type headers with the response here. Thanks for the contribution! ,like good idea content type response thanks contribution,issue,positive,positive,positive,positive,positive,positive
1839208455,"Hi @codekcg23, I'm fairly certain that this isn't possible due to the mechanism of saving SparkML models to a temp DFS location before copying back to the local file system to initiate the transfer. 
Something to potentially think about is using unity catalog, which I think will greatly simplify your workflow. Is it possible for you to try that?",hi fairly certain possible due mechanism saving temp location back local file system initiate transfer something potentially think unity think greatly simplify possible try,issue,negative,positive,positive,positive,positive,positive
1839175080,Hi @henxing this seems valuable. Feel free to file a PR and link it to this issue when you file it. I'll assign this issue to you for next steps of implementation and PR filing. Thanks for the great idea :) ,hi valuable feel free file link issue file assign issue next implementation filing thanks great idea,issue,positive,positive,positive,positive,positive,positive
1839133192,Has anyone been able to solve this? Thanks!,anyone able solve thanks,issue,positive,positive,positive,positive,positive,positive
1838689633,Thanks @harupy for the fixing. Could we expect a new release soon?,thanks fixing could expect new release soon,issue,negative,positive,positive,positive,positive,positive
1838559233,I encountered this issue as I was searching exactly for this functionality. Looks like it has been closed automatically without anybody commenting properly on whether this would be a nice addition or not... Maybe somebody should reconsider this one ?,issue searching exactly functionality like closed automatically without anybody properly whether would nice addition maybe somebody reconsider one,issue,positive,positive,positive,positive,positive,positive
1838420888,"@B-Step62 Thank you for your explanation. I understand your point, therefore it does make sense to keep the current behavior. But having some way how to update it or maybe just clean virtualenv folders (to start with a clean sheet) would be helpful as I didn't find any way how to do it, only the manual way of deleting virtualenv to force mlflow to create a new one.

I can image several ways that would help in my case - either the one you have suggested with `mlflow update XXX` or sth like `mlflow clean` (which would clean `~/.mlflow/envs/` folder or whatever location with mlflow vens). Or I can imagine it would be enough to have a switch for `mlflow run` command (e.g. `--clean-venv`) that would tell mlflow to re-create virtualenv instead of re-using already existing one.

And I would like to highlight one thing - the main issue in my case (I consider myself still as kind of mlflow beginner) was that I was not aware of this behavior and was confused why sth does not work as expected. Then I found a log message about re-using existing venv which helped me a lot to understand what's going on. So I am also thinking how to help others (newcomers).",thank explanation understand point therefore make sense keep current behavior way update maybe clean start clean sheet would helpful find way manual way force create new one image several way would help case either one update like clean would clean folder whatever location imagine would enough switch run command would tell instead already one would like highlight one thing main issue case consider still kind beginner aware behavior confused work found log message lot understand going also thinking help,issue,positive,positive,positive,positive,positive,positive
1838274836,"Given that there have been [multiple CVEs](https://cve.mitre.org/cgi-bin/cvekey.cgi?keyword=mlflow) issued for mlflow in the past, you might consider following the same process that was used for those cases, or there might be other maintainers who are familiar with the CVE request process and can assist.",given multiple past might consider following process used might familiar request process assist,issue,negative,positive,neutral,neutral,positive,positive
1838263391,I'm actually not familiar with the process. What do we need to do?,actually familiar process need,issue,negative,positive,positive,positive,positive,positive
1838261911,"Thank you for the update. Is there anything specific that you are waiting for to initiate the CVE request, or is there any information or action required from my end to facilitate the process?",thank update anything specific waiting initiate request information action end facilitate process,issue,negative,positive,neutral,neutral,positive,positive
1838205181,"Hi,
I don't understand why the other CVE is mentioned, there is no relation between my reported (and fixed) vulnerability, the one that you're mentioning whether in this issue or in this #10533. So I'm asking about this [hunter report](https://huntr.com/bounties/816bdaaa-8153-4732-951e-b0d92fddf709/), which was fixed in this merged [PR](https://github.com/mlflow/mlflow/pull/10526), it is already mentioned in this [issue](https://github.com/mlflow/mlflow/issues/10492).",hi understand relation fixed vulnerability one whether issue report fixed already issue,issue,negative,positive,neutral,neutral,positive,positive
1837786701,"Hi,
I am having below error, when trying to log spark model to central workspace. 

Databricks Runtime - 10.4 ML LTS
Mlflow version - 2.3.2

> com.databricks.mlflowdbfs.MlflowHttpException: statusCode=404 reasonPhrase=[Not Found] bodyMessage=[{""error_code"":""RESOURCE_DOES_NOT_EXIST"",""message"":""Run 'bfe90fd5074f49c39a475b613d020cbf' not found.""}]

> MlflowException: failed to save spark model via mlflowdbfs

Please note that when using the same code base to log model within same workspace model successfully get logged.
I am setting registry Uri and tracking Uri to central workspace before running the below code.

```
train, test = train_test_random_split(conf, data)

experiment_name = ""/mlflow_experiments/debug_spark_model""
mlflow.set_experiment(experiment_name)


evaluator = BinaryClassificationEvaluator()

rf = RandomForestClassifier()

param_grid = (
    ParamGridBuilder()
    .addGrid(rf.numTrees,[15)
    .addGrid(rf.maxDepth, [6])
    .addGrid(
        rf.minInstancesPerNode,
       [7],
    )
    .build()
)

cv = CrossValidator(
    estimator=rf,
    estimatorParamMaps=param_grid,
    evaluator=BinaryClassificationEvaluator(metricName=""areaUnderROC""),
    numFolds=10,
)
cv_model = cv.fit(train)

# best model
model = cv_model.bestModel

model_params_best = {
    ""numTrees"": cv_model.getEstimatorParamMaps()[np.argmax(cv_model.avgMetrics)][
        cv_model.bestModel.numTrees
    ],
    ""maxDepth"": cv_model.getEstimatorParamMaps()[np.argmax(cv_model.avgMetrics)][
        cv_model.bestModel.maxDepth
    ],
    ""minInstancesPerNode"": cv_model.getEstimatorParamMaps()[
        np.argmax(cv_model.avgMetrics)
    ][cv_model.bestModel.minInstancesPerNode],
}

model_metrics_best, artifacts_best, predicted_df_best = train_model(
    model, train, test, evaluator
)
with mlflow.start_run(run_name=""debug_run_1""):
    run_id = mlflow.active_run().info.run_id
    mlflow.log_params(model_params_best)
    mlflow.log_metrics(model_metrics_best)

    #debug 1
    artifact_path = ""best_model""
    mlflow.spark.log_model(spark_model = model, artifact_path = artifact_path) 
    source = get_artifact_uri(run_id=run_id, artifact_path=artifact_path)
```

![image](https://github.com/mlflow/mlflow/assets/43032723/8d694949-4b13-4367-b53e-0b092fd20ba5)


",hi error trying log spark model central version found message run found save spark model via please note code base log model within model successfully get logged setting registry central running code train test data train best model model model train test model source image,issue,positive,positive,positive,positive,positive,positive
1837686587,"> @B-Step62 Can we vertically stack each section? It requires a lot of vertical space but is safer than using tabs or custom CSS?

I had the same thought once, but since these setup are not irrelevant to most of the users, I doubt they should take much space. Probably these contents are not suitable for mobile read anyway (like no one would dive deep into this topic from smartphone:)), so I think it's ok to have suboptimal readability to make the overall page concise.",vertically stack section lot vertical space custom thought since setup irrelevant doubt take much space probably content suitable mobile read anyway like one would dive deep topic think suboptimal readability make overall page concise,issue,negative,positive,neutral,neutral,positive,positive
1837468112,"maybe rather than adding a new model
provider, give the possibility to add new providers via plugins (currently not possible via regular mlflow plugins).",maybe rather new model provider give possibility add new via currently possible via regular,issue,negative,positive,neutral,neutral,positive,positive
1836258258,"Hello,
I just want to ask if the CVE is requested or not yet? since the vulnerability was corrected and merged.",hello want ask yet since vulnerability corrected,issue,negative,neutral,neutral,neutral,neutral,neutral
1836100050,"Quite late, but rather than modifying path I'm doing `python -m mlflow ui`, where python points to whatever venv I'm using.",quite late rather path python python whatever,issue,negative,negative,negative,negative,negative,negative
1835974247,@B-Step62 Can we vertically stack each section? It requires a lot of vertical space but is safer than using tabs or custom CSS?,vertically stack section lot vertical space custom,issue,negative,neutral,neutral,neutral,neutral,neutral
1835637188,"> I think the pydantic schema is already updated, but the doc isn't.

Ah yea sorry, I meant example in the schema🙇",think schema already doc ah yea sorry meant example schema,issue,negative,negative,negative,negative,negative,negative
1835629509,"I think the pydantic schema is already updated, but the doc isn't.",think schema already doc,issue,negative,neutral,neutral,neutral,neutral,neutral
1835621117,"Could you also update `_REQUEST_PAYLOAD_EXTRA_SCHEMA` in `mlflow/gateway/schemas/completions.py`? 
`candidate_count` is also shown in REST API doc.",could also update also shown rest doc,issue,negative,neutral,neutral,neutral,neutral,neutral
1835410735,@santiagxf could you take a quick look at this if you get a chance to make sure that our messaging is spot-on here?,could take quick look get chance make sure,issue,positive,positive,positive,positive,positive,positive
1835288431,"@wllgrnt Thanks for trying it out, that's very weird it didn't work. It seems the same issue happens for some other PRs so I will investigate further. Meanwhile, we overrode the checks and pushed as there shouldn't be a big concern for this PR. Thank you so much for your contribution!!",thanks trying weird work issue investigate meanwhile big concern thank much contribution,issue,positive,negative,neutral,neutral,negative,negative
1834900794,"> @wllgrnt Very weird but some jobs are still not executing. Could you run followings to force triggering them again? While it seems to be an intermittent issue in Github, I can investigate if that happens again. Thanks!
> 
> ```
> $ git commit -sm --amend --no-edit   
> $ git push origin HEAD -f
> ```

The force-push above doesn't seem to have triggered the jobs, let me know if there's something else I should try",weird still could run force intermittent issue investigate thanks git commit amend git push origin head seem triggered let know something else try,issue,positive,negative,negative,negative,negative,negative
1834707355,@WeichenXu123 closing in favor of https://github.com/mlflow/mlflow/pull/10557 - just was easier than trying to fix the commit history. Sorry for the long delay!,favor easier trying fix commit history sorry long delay,issue,positive,negative,negative,negative,negative,negative
1834595111,"Thanks @jerrylian-db ! I did the manual test, I'll rerun it with the latest changes to make sure it still works before merging",thanks manual test rerun latest make sure still work,issue,positive,positive,positive,positive,positive,positive
1834414241,"> LGTM! QQ: Can we re-run notebooks and deploy the changes after MLflow 2.9.0 release? Not a blocker, but those annoying pydantic warnings should be gone in the new version.

The warnings have been removed :) ",deploy release blocker annoying gone new version removed,issue,negative,negative,negative,negative,negative,negative
1833849192,"@smurching I didn't get the databricks extension running in VSCode yet, so I can't run remotely but would like to track my training in Databricks while developing.
I had mixed up `set_tracking_uri` and `set_registry_uri` and thought my problem when using `databricks-uc` was local vs. Databricks execution instead of tracking vs. registry storage. Thanks for the swift clarification, I see now that there's feature parity when running locally.",get extension running yet ca run remotely would like track training mixed thought problem local execution instead registry storage thanks swift clarification see feature parity running locally,issue,positive,positive,neutral,neutral,positive,positive
1833833586,"Hey I am up for that if @rajveer43 is, dont want to sweep in and steal the issue, if you feel you can do it by yourself feel free to go!",hey dont want sweep steal issue feel feel free go,issue,positive,positive,positive,positive,positive,positive
1833823060,"@ThR3742 Yes, this looks like a critical bug. Thank you so much for reporting this issue!! I also greatly appreciate you for pointing out the exact lines causing the issue. As we have an incoming release, I took a quick step to implement the fix so as to make sure it is resolved in the next version.",yes like critical bug thank much issue also greatly appreciate pointing exact causing issue incoming release took quick step implement fix make sure resolved next version,issue,positive,positive,positive,positive,positive,positive
1833728219,"@dungxibo123 Thank you for these fixes!

1. Could you run `pre-commit run --all-files` to run linters and formatters? 
2. Could you add sign off to each commit (required by CI check)? You can do this by `git rebase -i HEAD~3` and apply `git commit -s --amend --no-edit` for each commit.",thank could run run run could add sign commit check git rebase apply git commit amend commit,issue,positive,neutral,neutral,neutral,neutral,neutral
1833678634,"Is this issue related to https://nvd.nist.gov/vuln/detail/CVE-2023-6018?
If yes then what's a update on this?",issue related yes update,issue,negative,neutral,neutral,neutral,neutral,neutral
1833525332,"Hello @B-Step62 I just made a quick fix for this #10549 . What you are saying makes a lot of sense. II reckon we shouldn't let this specific error jam up the logging entirely. So, I'm all for your suggestion of skipping logging for params that don't meet the requirements before calling the troublesome log_params function.

With my fix, the parameters would be logged individually using the function log_param. I get it if this isn't the ideal solution; perhaps you were aiming to log everything simultaneously.",hello made quick fix saying lot sense reckon let specific error jam logging entirely suggestion skipping logging meet calling troublesome function fix would logged individually function get ideal solution perhaps aiming log everything simultaneously,issue,negative,positive,positive,positive,positive,positive
1833493790,"@wllgrnt Very weird but some jobs are still not executing. Could you run followings to force triggering them again? While it seems to be an intermittent issue in Github, I can investigate if that happens again. Thanks!

```
$ git commit -sm --amend --no-edit   
$ git push origin HEAD -f
```

",weird still could run force intermittent issue investigate thanks git commit amend git push origin head,issue,positive,negative,negative,negative,negative,negative
1833317682,"@mbenoit29 Awesome, thank you so much for your contribution!",awesome thank much contribution,issue,positive,positive,positive,positive,positive,positive
1833199609,I know that tags could be used for every workaround but it is annoying to have a main MlFlow column in the UI dedicated to the Dataset empty cause you need to rely on tags for the dataset digest tracking.,know could used every annoying main column empty cause need rely digest,issue,negative,negative,negative,negative,negative,negative
1833016656,"> @gabrielfu We're working on deprecating `mlflow.gateway` in #10420. This PR contains lots of changes in `mlflow.gateway` and will conflict with this PR. We'll merge it on Friday. Is it possible to rebase after that?

@harupy no problem, I'll wait for that PR.",working lot conflict merge possible rebase problem wait,issue,negative,neutral,neutral,neutral,neutral,neutral
1832995818,"I think it's ok to make it optional but need to be tested carefully. Indeed, the easiest path here might be using tags or `mlflow.note.content` to store digest, because you don't need any further integration but just want to record the digest. The core benefit of Dataset feature is the source tracking.",think make optional need tested carefully indeed easiest path might store digest need integration want record digest core benefit feature source,issue,positive,negative,neutral,neutral,negative,negative
1832966859,"@sxooler Thank you for bringing this issue to our attention!
Yes, this is expected behavior of MLflow Project. While I understand the inconvenience of having to re-create virtualenv, modifying dependencies can break reproducibility, the core benefit of Project. Hence we don't automatically update dependencies automatically.

One option is to provide a way to manually update dependencies but more easily, for example, adding CLI command like `mlflow update XXX`. Does that helpful for your use case?",thank issue attention yes behavior project understand inconvenience break reproducibility core benefit project hence automatically update automatically one option provide way manually update easily example command like update helpful use case,issue,positive,positive,positive,positive,positive,positive
1832948433,"@mbenoit29 Thank you for bringing the issue to our attention! 
There is absolutely no reason not having that for fluent API. Would you mind if I assign this to you?",thank issue attention absolutely reason fluent would mind assign,issue,negative,positive,positive,positive,positive,positive
1832739649,does the vignettes package provide better documentation rendering for R? ,package provide better documentation rendering,issue,negative,positive,positive,positive,positive,positive
1832502579,"@jswetzen good question, you should be able to access models in UC externally (curious if you can share more details about the use case for doing so). MLflow tracking in UC is not supported, but you can target models in UC for model registry using `mlflow.set_registry_uri(""databricks"")`. Make sure to use the latest/a sufficiently-new version of the MLflow client (versions 2.4.1 and above should suffice), let me know if that works & thanks!",good question able access externally curious share use case target model registry make sure use version client suffice let know work thanks,issue,positive,positive,positive,positive,positive,positive
1832407085,The issue might come from https://github.com/mlflow/mlflow/blob/4b8bb73ea5e30e3df312ae4ce9d1d3825a6faf09/mlflow/server/js/src/experiment-tracking/components/runs-charts/components/RunsMetricsLinePlot.tsx#L136C18-L136C48 where we don't sort the metricHistory ,issue might come sort,issue,negative,neutral,neutral,neutral,neutral,neutral
1832147734,"> @AmgadHasan, I had the same, did you see a warning like the one I got?
> 
> > Skip logging GPU metrics because creating `GPUMonitor` failed with error: `pynvml` is not installed, to log GPU metrics please run `pip install pynvml` to install it..
> 
> Simply installing the pynvml package solved it

Thanks
I tried this and it worked

I didn't see the warning though. I think this should be clearly mentioned in the docs for logging system metrics ",see warning like one got skip logging metric error log metric please run pip install install simply package thanks tried worked see warning though think clearly logging system metric,issue,negative,positive,positive,positive,positive,positive
1832096473,"thank you for the update @B-Step62 , I ensure to use the appropriate template next time. Thanks for pointing out.",thank update ensure use appropriate template next time thanks pointing,issue,positive,positive,positive,positive,positive,positive
1832082348,Note: Table and tabs in this PR are not shown nicely on mobile device. Will be fixed in the follow-up PR like this: https://github.com/B-Step62/mlflow/pull/1,note table shown nicely mobile device fixed like,issue,positive,positive,positive,positive,positive,positive
1831984857,"@AmgadHasan, I had the same, did you see a warning like the one I got?

> Skip logging GPU metrics because creating `GPUMonitor` failed with error: `pynvml` is not installed, to log GPU metrics please run `pip install pynvml` to install it..

Simply installing the pynvml package solved it",see warning like one got skip logging metric error log metric please run pip install install simply package,issue,negative,neutral,neutral,neutral,neutral,neutral
1831977945,"> CC @ddl-aj-rossman Would you fix test failure in the PR ? :)

Yup! I'll get to it later this week",would fix test failure get later week,issue,negative,negative,negative,negative,negative,negative
1831917479,"@LakshmiN5 Thank you for reaching out!

> Please confirm if the parent run (last active run) corresponds to the best estimator. If not how do I extract the run id that corresponds to the best clf.best_estimator_ ?

No, the parent run doesn't represent the one with the best score. You can search children runs using [MLflowClient().search_run()](https://mlflow.org/docs/latest/python_api/mlflow.client.html#mlflow.client.MlflowClient.search_experiments) API, with filtering by the parent id as tag and sorting with the target metric. Please find more details in [Search Run](https://mlflow.org/docs/latest/search-runs.html) documentation.

Also, `good first issue` label and template should be used by maintainer only. Please file an issue with other appropriate templates e.g. Bug Report next time. Thank you.
",thank reaching please confirm parent run last active run best estimator extract run id best parent run represent one best score search filtering parent id tag target metric please find search run documentation also good first issue label template used maintainer please file issue appropriate bug report next time thank,issue,positive,positive,positive,positive,positive,positive
1831741679,@smurching or @harupy  I'm running into this error when trying to log to Unity Catalog from my laptop. Does this mean that UC logging is only supported from Databricks compute nodes and not externally? I've gathered from the documentation that UC is the [recommended place to store models](https://docs.databricks.com/en/machine-learning/manage-model-lifecycle/index.html) but I would then also like to do this externally.,running error trying log unity mean logging compute externally documentation place store would also like externally,issue,negative,negative,negative,negative,negative,negative
1831603802,"Hello,
No, it's not related to `CVE-2023-6018`. The reported issue is about 'File overwrite without authentication,' which is a distinct vulnerability from the one I reported. If you'd like, you can review the detailed report for more information.",hello related issue overwrite without authentication distinct vulnerability one like review detailed report information,issue,negative,positive,positive,positive,positive,positive
1831583752,"Would love to have an update on this as well, spent quite a bit of time trying to debug an issue with serving LightGBM model with categoricals via MLFlow and finding out that this apparently is not possible.",would love update well spent quite bit time trying issue serving model via finding apparently possible,issue,positive,positive,positive,positive,positive,positive
1831557280,"Left a few comments but generally the logic looks good to me, awesome work! Let's get confirmation on the sort order for > 10 steps, and then we can probably ship it",left generally logic good awesome work let get confirmation sort order probably ship,issue,positive,positive,positive,positive,positive,positive
1831546551,@gabrielfu We're working on deprecating `mlflow.gateway` in https://github.com/mlflow/mlflow/pull/10420. This PR contains lots of changes in `mlflow.gateway` and will conflict with this PR. We'll merge it on Friday. Is it possible to rebase after that?,working lot conflict merge possible rebase,issue,negative,neutral,neutral,neutral,neutral,neutral
1831456772,CC @ddl-aj-rossman Would you fix test failure in the PR ? :),would fix test failure,issue,negative,negative,negative,negative,negative,negative
1831422986,"Hi @m0kr4n3 @B-Step62 
Is this issue about https://cve.mitre.org/cgi-bin/cvename.cgi?name=2023-6018 ? I'm asking because I want to report this issue, but I don't want to report a duplicate issue.",hi issue want report issue want report duplicate issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1831197821,"> LGTM! Is it possible to ask the reporters to take a look?

Absolutely! I sent a notice to the reporters in the separate platform, and also tagged their issues:)",possible ask take look absolutely sent notice separate platform also tagged,issue,negative,positive,neutral,neutral,positive,positive
1831016301,@JoeBeeton Thank you so much for reporting the vulnerability and terribly sorry for not being responsive. We are working on the fix right now.,thank much vulnerability terribly sorry responsive working fix right,issue,negative,negative,neutral,neutral,negative,negative
1830931879,"> Hi @marioga , sorry to hear about the REST API stability difficulties you're encountering with MLflow v2. Unfortunately, we haven't seen these issues reported by other users as of yet. By chance, are you running a proxy layer between the client and the Kubernetes-hosted MLflow service?

I got similar issue.",hi sorry hear rest stability unfortunately seen yet chance running proxy layer client service got similar issue,issue,negative,negative,negative,negative,negative,negative
1830431661,"Google docstring typically starts on the same line as the first triple quotes. However, in [tensorflow](https://github.com/tensorflow/tensorflow/blob/247f77e44784f9254d2bd304372a71510a0849fc/tensorflow/python/checkpoint/checkpoint.py#L401) and [module docs styleguide](https://google.github.io/styleguide/pyguide.html#382-modules) (which are the same as function styleguides), the first line is always a short summary and detail is added below. Our current docs don't adhere to this rule i.e. the first line is not always a concise summary. Do we want to enforce this?

It may be hard to enforce programmatically.",typically line first triple however module function first line always short summary detail added current adhere rule first line always concise summary want enforce may hard enforce programmatically,issue,negative,positive,neutral,neutral,positive,positive
1830217124,"The main issue is that do you think that the `Dataset` abstract class need to have `DatasetSource` in the constructor as this is currently the case:
https://github.com/mlflow/mlflow/blob/f34364aeb36d8f1a5bf9861a6d7a25c9603ab214/mlflow/data/dataset.py#L20
",main issue think abstract class need constructor currently case,issue,negative,positive,neutral,neutral,positive,positive
1829931339,"Thank you! I will close this issue for now but please open this or file a new issue for your further feedback. Supporting the fluid cloud environment is definitely an important path as a platform, so any feedbacks is really appreciated.",thank close issue please open file new issue feedback supporting fluid cloud environment definitely important path platform really,issue,positive,positive,positive,positive,positive,positive
1829925449,"Absolutely! While I can't guarantee 100% accuracy, here's some starting points:

1. Update the [Dataset entity](https://github.com/mlflow/mlflow/blob/f34364aeb36d8f1a5bf9861a6d7a25c9603ab214/mlflow/entities/dataset.py#L9) and [Database schema](https://github.com/mlflow/mlflow/blob/master/mlflow/store/tracking/dbmodels/models.py#L470) in MLflow to make the source-related field optional. It might be wise to keep the name field to minimize the impact of this change. Also, revise relevant validation checks, such as [validate_dataset()](https://github.com/mlflow/mlflow/blob/f34364aeb36d8f1a5bf9861a6d7a25c9603ab214/mlflow/utils/validation.py#L438).
2. Add a new implementation of the [Dataset abstract class](https://github.com/mlflow/mlflow/blob/master/mlflow/data/dataset.py#L20), to allow the creation of a dataset instance using only the digest. Assuming there's no need for native library integration, adding a new, straightforward implementation might be the simplest approach.
3. Modify `log_inputs()` for each backend store ([FileStore](https://github.com/mlflow/mlflow/blob/f34364aeb36d8f1a5bf9861a6d7a25c9603ab214/mlflow/store/tracking/file_store.py#L1085), [SQLAlchemyStore](https://github.com/mlflow/mlflow/blob/f34364aeb36d8f1a5bf9861a6d7a25c9603ab214/mlflow/store/tracking/sqlalchemy_store.py#L1353), and [RestStore](https://github.com/mlflow/mlflow/blob/f34364aeb36d8f1a5bf9861a6d7a25c9603ab214/mlflow/store/tracking/rest_store.py#L329)), so that it handles empty values for optional fields, and does proper serialization and deserialization.

Implementing these changes and ensuring everything functionality correctly can be back-breaking. We can keep this open and always wait for additional support from the community. Regardless of which, your contribution on bringing this issue up is greatly appreciated!",absolutely ca guarantee accuracy starting update entity schema make field optional might wise keep name field minimize impact change also revise relevant validation add new implementation abstract class allow creation instance digest assuming need native library integration new straightforward implementation might approach modify store empty optional proper serialization everything functionality correctly keep open always wait additional support community regardless contribution issue greatly,issue,positive,positive,positive,positive,positive,positive
1829912016,I will try to experiment a bit with this workaround to understand the logistic overhead of this approach ,try experiment bit understand logistic overhead approach,issue,negative,neutral,neutral,neutral,neutral,neutral
1829856852,"Yes! Tags have more freedom with safety than managing run id by yourself, for example, run id is used as the primary key in tracking database, hence has certain restriction and pitfalls ([example](https://github.com/mlflow/mlflow/blame/f34364aeb36d8f1a5bf9861a6d7a25c9603ab214/mlflow/store/tracking/sqlalchemy_store.py#L465-L468)).",yes freedom safety run id example run id used primary key hence certain restriction example,issue,positive,positive,positive,positive,positive,positive
1829833524,"Are you suggesting to use the pod env as an extra tag (like a fake runid) to recover the real runid with a query?

So I need to manage an extra id just cause I cannot assign an id client side (this is exactly the point of this issue)

> One caveat is that mlflow doesn't update the status from ""RUNNING"" to ""FAILED"" when the instance get terminated

This was not an issue as spots have a grace period termination.",suggesting use pod extra tag like fake recover real query need manage extra id cause assign id client side exactly point issue one caveat update status running instance get issue grace period termination,issue,negative,negative,neutral,neutral,negative,negative
1829807718,"Thanks for the further explanation! In that case, let me dig into what I suggested here:

> you can search for a specific run using various filters with [MLflowClient](https://mlflow.org/docs/latest/python_api/mlflow.client.html#mlflow.client.MlflowClient.search_runs).

This approach should work across multiple (spot) instances, because [MLflowClient](https://mlflow.org/docs/latest/python_api/mlflow.client.html#mlflow.client.MlflowClient.search_runs) queries runs **from the tracking server**, meaning that you can fetch your previous run on terminated spot instance, and resume it with `mlflow.start_run(run_id=""foo"")`. For example, you can simply get uncompleted job with some identifier indicates ""same experiment"" as a tag like this:

```
client = MLflowClient()
mlflow.search_runs(
    experiment_ids=[experiment_id], 
    filter_string=""""tags.YOUR_TAG_KEY = 'YOUR_TAG_VALUE' and attributes.status != 'FINISHED'""
   order_by=[""attributes.end_time desc""]
)
```

One caveat is that mlflow doesn't update the status from ""RUNNING"" to ""FAILED"" when the instance get terminated. Also it doesn't prevent two instances from starting runs under same run id at the same time. This means that you may need to have some control mechanism for managing which run id should be restarted or not. That being said, this should be rare occasion when the cluster scale is small, and the same thing is required if you manage run id by yourself, as you mentioned as *""An external controlled env for the pod""*.",thanks explanation case let dig search specific run various approach work across multiple spot server meaning fetch previous run spot instance resume foo example simply get uncompleted job identifier experiment tag like client one caveat update status running instance get also prevent two starting run id time may need control mechanism run id said rare occasion cluster scale small thing manage run id external pod,issue,positive,positive,neutral,neutral,positive,positive
1829547094,I don't know the internals so do you have any hint on where you want to introduce this?,know internals hint want introduce,issue,negative,neutral,neutral,neutral,neutral,neutral
1829544942,"No the MFflow tracking server is not spot and it is using persistent postgres backend.

Of course the spot instead are the training jobs/runs where the pod could be restarted/rescheduled by the governing job.

Every time the pod is automatically restarted/rescheduled on resource availability by its governing job we are going to generate another runid but this is not ok as e.g. we are resuming the last checkpoint so we are really just inside the same experiment run and we don't want to generate a new one.

So what is wrong is that the server is going to assign a new runid every time on each spot instances that it is going down and restarting.",server spot persistent course spot instead training pod could governing job every time pod automatically resource availability governing job going generate another last really inside experiment run want generate new one wrong server going assign new every time spot going,issue,negative,negative,neutral,neutral,negative,negative
1829385781,"@harupy as discussed, the response follows OpenAI schema. Please let me know if this looks good before I start extending to other providers :)",response schema please let know good start extending,issue,positive,positive,positive,positive,positive,positive
1829323975,"Hi @Deathfireofdoom Could you work with @rajveer43 on this together? Ideally we just want to docker images, the current one as the slim version, and another full version adding necessary dependencies for those databases, or if you think other dependencies are needed we're open to ideas :) ",hi could work together ideally want docker current one slim version another full version necessary think open,issue,negative,positive,positive,positive,positive,positive
1829058897,"@keenranger Thanks a bunch for proactively fixing those test cases! LGTM, merging:)",thanks bunch fixing test,issue,negative,positive,positive,positive,positive,positive
1829012845,"@bhack Thank you for filing this issue!

Logging digest only sounds like a legitimate use case, and having to implement custom dataset only to do that is a pain. Would you mind working on this feature?",thank filing issue logging digest like legitimate use case implement custom pain would mind working feature,issue,negative,neutral,neutral,neutral,neutral,neutral
1829011749,@B-Step62 There were some classes without implementing abstract method. Please check new commit!,class without abstract method please check new commit,issue,negative,positive,positive,positive,positive,positive
1829003635,"Ok, let me clarify your current set up a bit. So you're running both your training code and tracking server on spot instance(s), without connecting to any persistent database/storage for tracking backend? (If I understand wrongly, could you depict it like a few example set up listed [here](https://www.mlflow.org/docs/latest/tracking.html#how-runs-and-artifacts-are-recorded)?) I'm curious how you keep other tracking data such as metrics from banishing on random termination.

> You need to store it somewhere else or on a persistent storage but then you need to add other redundancy to store this info and so the advantage of using the MLflow tracking server is going to be impacted by this logistic overhead.

This is actually recommended setup for such fluid environment. As for overhead, MLflow supports [async logging](https://mlflow.org/docs/latest/python_api/mlflow.html#mlflow.log_metric) for logging metrics. ",let clarify current set bit running training code server spot instance without persistent understand wrongly could depict like example set listed curious keep data metric random termination need store somewhere else persistent storage need add redundancy store advantage server going impacted logistic overhead actually setup fluid environment overhead logging logging metric,issue,positive,negative,negative,negative,negative,negative
1828981099,"With spot  instances (as ""these days"" it is hard to find GPI availability) the pod is going to terminate and restart automatically e.g. scheduled by a job.
An external controlled env for the pod could let to maintain the same run id also if the pod is restarting without runs proliferating on the MLFLOW tracking server/UI for the same semantic run.

How a restarting pod can  retrieve its own runid if it is generated only server side and you have many spot experiments with restarting pods?

You need to store it somewhere else or on a persistent storage but then you need to add other redundancy to store this info and so the advantage of using the MLflow tracking server is going to be impacted by this logistic overhead.",spot day hard find availability pod going terminate restart automatically job external pod could let maintain run id also pod without semantic run pod retrieve server side many spot need store somewhere else persistent storage need add redundancy store advantage server going impacted logistic overhead,issue,negative,positive,neutral,neutral,positive,positive
1828961722,"@bhack Sorry for the confusion, you're right it only works when run exists. But wouldn't it be sufficient for your use case? You can specify the last one if already started, otherwise having new id doesn't seems to be a problem for me.",sorry confusion right work run would sufficient use case specify last one already otherwise new id problem,issue,negative,negative,neutral,neutral,negative,negative
1828903871,"> MLflow does support starting or resuming 

Are you sure that is working for starting? I think it doesn't work for starting as it will work only in the resuming case.",support starting sure working starting think work starting work case,issue,positive,positive,positive,positive,positive,positive
1828886991,"@bhack, thank you for contacting us about this issue!

MLflow does support ~~starting or~~ resuming a run with a run_id of your choice. You can pass the desired run_id to [mlflow.start_run()](https://mlflow.org/docs/latest/python_api/mlflow.html#mlflow.start_run). To fetch the paused run id, you can use [mlflow.last_active_run()](https://mlflow.org/docs/latest/python_api/mlflow.html#mlflow.start_run), or you can search for a specific run using various filters with [MLflowClient](https://mlflow.org/docs/latest/python_api/mlflow.client.html#mlflow.client.MlflowClient.search_runs).

For example:
```
run_id = mlflow.last_active_run().info.run_id

with mlflow.start_run(run_id=run_id):
    # Resume your training
```

Would this resolve your issue?
",thank u issue support run choice pas desired fetch run id use search specific run various example resume training would resolve issue,issue,positive,neutral,neutral,neutral,neutral,neutral
1828871381,"@jrusbo, thank you for bringing this issue to our attention!

Overall, I agree with the benefit of having an option to exclude some parameters from autologging. However, we should also consider to what extent we should make autologging configurable, because at some point, manual logging (e.g., `log_params`) might be preferable. One another option would be just skip logging the params not meeting requirements and show warnings. WDYT?

Meanwhile, you can try upgrading mlflow version *in tracking server* to >= 2.8. We increased the limit to 6000 in the latest version ([pr](https://github.com/mlflow/mlflow/pull/9709)). (If you are using database-backed tracking, you can run [the migration script](https://github.com/mlflow/mlflow/blob/master/mlflow/store/db_migrations/versions/2d6e25af4d3e_increase_max_param_val_length.py) to migrate the schema as described in [MLflow Tracking Documentation](https://www.mlflow.org/docs/latest/tracking.html#id78)). Would this be helpful for your case?",thank issue attention overall agree benefit option exclude however also consider extent make point manual logging might preferable one another option would skip logging meeting show meanwhile try version server limit latest version run migration script migrate schema documentation would helpful case,issue,positive,positive,positive,positive,positive,positive
1828856535,"@marygracemoesta, thank you for bringing this issue to our attention!
There is absolutely no reason not to support the deletion of a tag from an experiment. I'm assigning this issue to you, but please let us know if you have any other important tasks to do.

Implementation-wise, it should be straightforward. You can refer to the delete_tag methods for runs in [file_store](https://github.com/mlflow/mlflow/blob/a5fdc7ce4524ec9e4250881674938ed75ba41541/mlflow/store/tracking/file_store.py#L1014) and [rest_store](https://github.com/mlflow/mlflow/blob/a5fdc7ce4524ec9e4250881674938ed75ba41541/mlflow/store/tracking/sqlalchemy_store.py#L1213). It might be a bit tedious to add various client APIs ([ref](https://github.com/search?q=repo%3Amlflow%2Fmlflow+delete_tag&type=code&p=1)), but I believe most of them can be copied from the run versions. You can start by following [CONTRIBUTING.md](https://github.com/mlflow/mlflow/blob/master/CONTRIBUTING.md) to set up the dev environment.

Please let us know if anything is unclear. Thank you so much for your contribution!",thank issue attention absolutely reason support deletion tag experiment issue please let u know important straightforward refer might bit tedious add various client ref believe copied run start following set dev environment please let u know anything unclear thank much contribution,issue,positive,positive,neutral,neutral,positive,positive
1828282514,"@B-Step62 Sorry for inconvenience, I forgot to run pre-commit.
All check and re-pushed. Thank you for reviewing.",sorry inconvenience forgot run check thank,issue,negative,negative,negative,negative,negative,negative
1828071078,"thanks for the response @lightnessofbein
I face the same issue since basic http authentication enabled, mlflow client needs way more time to call e.g. mlflow.models.get_model_info()
Does mlflow needs to authenticate everytime something is fetched from the database ? ",thanks response face issue since basic authentication client need way time call need authenticate something fetched,issue,negative,positive,neutral,neutral,positive,positive
1827850770,"@msinghg, thank you for bringing this issue to our attention!

Regarding the first exception, `Detected out-of-date database schema`, this typically occurs when the tracking database schema is incompatible with the latest version. Given that we implemented some changes to the schema a few years back, older databases require an update. However, it appears you've already resolved this by using the `mlflow db migrate` command as suggested.

As for the second error that emerged post-migration, pinpointing the exact cause from the provided information is a bit challenging. The shown error is a generic failure due to the repeated restarting of a pod, is not specific to MLflow. It's also possible that it's related to configurations of other services, such as missing SSL certificates for PostgreSQL access. To assist us in further investigating this issue, could you please:

1. Retrieve and share the logs from both the MLflow and PostgreSQL pods using `kubectl logs [pod-name]`.
2. Double-check that the PostgreSQL database and the S3 bucket are accessible from within your Kubernetes cluster.
3. Provide detailed information about your environment, including the operating system and versions of key dependencies such as PostgreSQL, psycopg2, boto3, etc.

We appreciate your cooperation, thank you!
",thank issue attention regarding first exception schema typically schema incompatible latest version given schema back older require update however already resolved migrate command second error exact cause provided information bit shown error generic failure due repeated pod specific also possible related missing access assist u investigating issue could please retrieve share bucket accessible within cluster provide detailed information environment operating system key appreciate thank,issue,negative,positive,neutral,neutral,positive,positive
1827391541,How did you fix this ? Can you explain in detail . Thanks in advance. ,fix explain detail thanks advance,issue,negative,positive,positive,positive,positive,positive
1827211262,"If you feel the task is a bit to complex for you @rajveer43, then I am happy to take over!",feel task bit complex happy take,issue,positive,positive,positive,positive,positive,positive
1827037160,I think this is not issue in mlflow but your local fs path permission issue. I will close this but feel free to reopen it if you find something related to mlflow.,think issue local path permission issue close feel free reopen find something related,issue,positive,positive,positive,positive,positive,positive
1826696596,"Any updates on the new website? Does it include dark mode?

@serena-ruan ",new include dark mode,issue,negative,negative,neutral,neutral,negative,negative
1826499603,"some points to start! a bit idea would help!, @serena-ruan ",start bit idea would help,issue,negative,neutral,neutral,neutral,neutral,neutral
1826481418,"Hi @harupy,  could you please check and review this ?. thanks!",hi could please check review thanks,issue,positive,positive,positive,positive,positive,positive
1826121865,"@BenWilson2 Just getting my dev env set up but I'm failing the `must-have-signoff` pre-commit hook. What's the correct process to pass this check at this stage of development? Should I just ignore the hooks or should I include ""Signed-off-by:"" in my messages? Couldn't see a reference to this in `CONTRIBUTING.md`. Thanks!",getting dev set failing hook correct process pas check stage development ignore include could see reference thanks,issue,negative,positive,positive,positive,positive,positive
1826099969,@harupy Sorry to bother. Did you get the video?,sorry bother get video,issue,negative,negative,negative,negative,negative,negative
1825779549,"
> @emsi drive-by comment: you can use ""Eye"" icon in order to add/remove runs from the comparison.


There are selctbox which are NOT honored when entering comparison and I end up in comparison with dozens to uncheck with eye now? So instead of checking 3 I have to un-eye 50? That's not convenient.",comment use eye icon order comparison entering comparison end comparison uncheck eye instead convenient,issue,negative,neutral,neutral,neutral,neutral,neutral
1825773003,"> I find the new useless. It lacks the ability to select runs (there's only option to select 5, 10, 100 etc). Since I can't select runs to analyze it's of no use for me.

@emsi drive-by comment: you can use ""Eye"" icon in order to add/remove runs from the comparison. ",find new useless ability select option select since ca select analyze use comment use eye icon order comparison,issue,negative,negative,negative,negative,negative,negative
1825516113,"> mlflow.tensorflow module is doing something differently than all the others 

Yes. `mlflow.tensorflow` have to import the `MlflowMLflowCallback` , and `MlflowMLflowCallback` inherits `keras.callbacks.Callback` so it has to import tensorflow when importing `MlflowMLflowCallback`

`mlflow.keras_core` has the same issue",module something differently yes import import issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1825513968,"I take your point, but I think the bigger point here is that the `mlflow.tensorflow` module is doing something differently than all the others that it can trigger an eager load unintentionally, and I'd suggest that should probably be addressed? I'm not sure what the root cause is for it to be different from the other modules. ",take point think bigger point module something differently trigger eager load unintentionally suggest probably sure root cause different,issue,positive,positive,positive,positive,positive,positive
1825510243,"I think you can write
```
>>> class AA:
...     tf = mlflow.tensorflow
```
instead of using enum",think write class aa instead,issue,negative,neutral,neutral,neutral,neutral,neutral
1825507565,"Because `enum` will check field whether is ""descriptor"", this requires to check attribute in the object:

```
def _is_descriptor(obj):
    """"""
    Returns True if obj is a descriptor, False otherwise.
    """"""
    return (
            hasattr(obj, '__get__') or
            hasattr(obj, '__set__') or
            hasattr(obj, '__delete__')
            )
```

But I think overriding `hasattr` for the module object is risky. Otherwise, we have to load the module then we know its attribute.",check field whether check attribute object true false return think module object risky otherwise load module know attribute,issue,negative,negative,neutral,neutral,negative,negative
1825438609,"something simple like this:

```python
import enum
import mlflow

class demo(enum.Enum):
    tensorflow = mlflow.tensorflow
```",something simple like python import import class,issue,negative,neutral,neutral,neutral,neutral,neutral
1825371898,"> we use an enum to point at the various submodules

Could you share code ? I can help checking it.",use point various could share code help,issue,positive,neutral,neutral,neutral,neutral,neutral
1825320591,"My issue got fixed by running the server with `--gunicorn-opts=""--timeout 900""` following the comment given in the [link](https://github.com/mlflow/mlflow/issues/7702#issuecomment-1386300082)",issue got fixed running server following comment given link,issue,negative,positive,neutral,neutral,positive,positive
1825225437,"I'm experiencing a similar issue while trying to log a model of size 3.7 GB using MLflow version 2.7.1. If you could assist, I'd greatly appreciate it.",similar issue trying log model size version could assist greatly appreciate,issue,negative,positive,positive,positive,positive,positive
1825116895,"@harupy Thank you , I'm grateful for the opportunity to be a part of this project.",thank grateful opportunity part project,issue,positive,neutral,neutral,neutral,neutral,neutral
1825106708,"Manually tested using this toy fastapi app:

```python
from fastapi import FastAPI, HTTPException, status


app = FastAPI()


counter = 0


@app.get(""/test"")
def test():
    global counter
    counter += 1

    if counter < 3:
        raise HTTPException(
            status_code=status.HTTP_502_BAD_GATEWAY,
            detail=""Service unavailable"",
        )

    else:
        # Reset counter
        counter = 0
        return {""counter"": counter}


# Command to run this app using uvicorn:
# uvicorn app:app --reload --port 8000

```",manually tested toy python import status counter test global counter counter counter raise service unavailable else reset counter counter return counter counter command run reload port,issue,negative,neutral,neutral,neutral,neutral,neutral
1825024018,@gabrielfu Can you stamp this PR? At least one approval is required to merge.,stamp least one approval merge,issue,negative,negative,negative,negative,negative,negative
1825013373,"> Disabled the ToC for mobile devices since there isn't enough screen real estate to even attempt to display it.

I still see it on my phone.",disabled mobile since enough screen real estate even attempt display still see phone,issue,negative,neutral,neutral,neutral,neutral,neutral
1825004279,"We should use a sphinx theme that supports navigation. If we need to decide which theme to use, let's decide it.",use sphinx theme navigation need decide theme use let decide,issue,negative,neutral,neutral,neutral,neutral,neutral
1824996880,"> @B-Step62 Could you preview the tracking page on the mobile view?
> 
> <img alt=""image"" width=""804"" src=""https://user-images.githubusercontent.com/17039389/284890270-e39d60b7-a2fa-443c-bbc2-11165d805638.png"">
> It doesn't have to look perfect on mobile devices.

Ooh great callout...! pictures can be fixed easily I guess, not sure what to do for tables... will try a few ways to make it at least readable on mobile.",could preview page mobile view image look perfect mobile great fixed easily guess sure table try way make least readable mobile,issue,positive,positive,positive,positive,positive,positive
1824508641,"Actually it still causes an issue for us with how we define it; we use an enum to point at the various submodules

curiously enough, defining a dict in global scope with the values as the mlflow modules does not cause this error.",actually still issue u define use point various curiously enough global scope cause error,issue,negative,neutral,neutral,neutral,neutral,neutral
1824262017,"Yep that works nicely

```
>>> import mlflow
>>> mlflow.pytorch
<module 'mlflow.pytorch (Not loaded yet)'>
>>> mlflow.tensorflow
<module 'mlflow.tensorflow (Not loaded yet)'>
>>> 
```

I like the (Not loaded yet) too in the repr 😁 

I appreciate the effort to this. Could you give an estimate when you think this fix might appear in a release (if it will make it in)? ",yep work nicely import module loaded yet module loaded yet like loaded yet appreciate effort could give estimate think fix might appear release make,issue,positive,positive,positive,positive,positive,positive
1824183255,"@yalwan-sage I created a PR to fix this, you could try: `pip install git+https://github.com/WeichenXu123/mlflow.git@tf-lazy-loading`",fix could try pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
1823974096,This doesn't work; i cant reference `mlflow.tensorflow` so how can i reference `mlflow.tensorflow.callback`?,work cant reference reference,issue,negative,neutral,neutral,neutral,neutral,neutral
1823968910,"You can make `mlflow.tensorflow.MLflowCallback` to be lazily imported to address the issue.
https://github.com/mlflow/mlflow/blob/70e72373f494a39fed5d131ec053833a34bc3cdc/mlflow/tensorflow/__init__.py#L35

Note mlflow.keras_core has similar issue because of the same reason. ",make lazily address issue note similar issue reason,issue,negative,negative,negative,negative,negative,negative
1823952730,"Up until some recent version this was not causing an issue.

I'd like to note that referencing any other module like this doesn't cause full imports of the underlying module in case they're not installed.

As noted in the issue, `mlflow.pytorch` does not cause pytorch to load (or attemp to be loaded)

> @yalwan-sage are you sure tensorflow is installed?

It isn't, and  thats entirely the point. But neither is pytorch. 



> I think this is a trivial issue . If tensorflow is not installed, using `mlflow.tensorflow` in your code is meaningless

I disagree. anyone who might create some pre-references to these objects, for example in producing wrappers of some kind (as we are) would be affected by this change in behaviour; it also violates the principle of least surprise; I don't expect to made a module reference and simply referencing the module causes an import action of other modules. I want to reiterate that this didn't used to be the case. ",recent version causing issue like note module like cause full underlying module case noted issue cause load loaded sure thats entirely point neither think trivial issue code meaningless disagree anyone might create example kind would affected change behaviour also principle least surprise expect made module reference simply module import action want reiterate used case,issue,positive,positive,neutral,neutral,positive,positive
1823838963,"@BenWilson2 I would like to contribute the project.

I was checking the autocomplete feature of `click`. To enable autocomplete in `bash` shell, one should run (make sure the virtualenv/conda is activated and it has mlflow installed in it),

```bash
echo ""$(_MLFLOW_COMPLETE=bash_source mlflow)"" >> auto-complete.sh
```
Content of `auto-complete.sh`,

```bash
_mlflow_completion() {
    local IFS=$'\n'
    local response

    response=$(env COMP_WORDS=""${COMP_WORDS[*]}"" COMP_CWORD=$COMP_CWORD _MLFLOW_COMPLETE=bash_complete $1)

    for completion in $response; do
        IFS=',' read type value <<< ""$completion""

        if [[ $type == 'dir' ]]; then
            COMPREPLY=()
            compopt -o dirnames
        elif [[ $type == 'file' ]]; then
            COMPREPLY=()
            compopt -o default
        elif [[ $type == 'plain' ]]; then
            COMPREPLY+=($value)
        fi
    done

    return 0
}

_mlflow_completion_setup() {
    complete -o nosort -F _mlflow_completion mlflow
}

_mlflow_completion_setup;
```

This file `auto-complete.sh` should be sourced in `~/.bashrc` file.

Note that in MacOS, one may get `-bash: complete: nosort: invalid option name` error. This is resolved by removing **-o nosort** from the file.

> Users would then have to source this generated script within their .bashrc or .zshrc.

Not sure if this part too can be automated while installing `mlflow`.

Resources:
1. [click autocomplete documentation](https://click.palletsprojects.com/en/8.1.x/shell-completion/#enabling-completion)
2. [-o nosort error](https://askubuntu.com/a/1320096/722770)",would like contribute project feature click enable bash shell one run make sure bash echo content bash local local response completion response read type value completion type type default type value fi done return complete file file note one may get complete invalid option name error resolved removing file would source script within sure part click documentation error,issue,positive,positive,positive,positive,positive,positive
1823786144,"This is AWESOME! A few nits and typos, some suggestions for commonly asked about / confusing parts for users that would be good to highlight. Other than those, this is looking fantastic! Great work @B-Step62 !!!",awesome commonly would good highlight looking fantastic great work,issue,positive,positive,positive,positive,positive,positive
1823735234,"> > Btw, mlflow gateway will be deprecated soon, in future we should use deployments API instead. See branch https://github.com/mlflow/mlflow/tree/gateway-migration
> 
> Got it. Can you please explain what the ""deployment API"" is? Also, do you know the timeline on when the gateway will be deprecated and shifted to deployments?

deployment APIs are defined in `mlflow.deployments` module

You could reach out to @harupy  for timeline of gateway deprecation timeline",gateway soon future use instead see branch got please explain deployment also know gateway deployment defined module could reach gateway deprecation,issue,negative,neutral,neutral,neutral,neutral,neutral
1823705187,Disabled the ToC for mobile devices since there isn't enough screen real estate to even attempt to display it. ,disabled mobile since enough screen real estate even attempt display,issue,negative,neutral,neutral,neutral,neutral,neutral
1823703077,"
https://github.com/mlflow/mlflow/assets/39283302/b2e99659-c24e-4400-911a-d4a866305a23


https://github.com/mlflow/mlflow/assets/39283302/3f4de8e2-f187-49c2-b68d-28be4b020b7d

Updated design based on feedback. 

NOTE: the nav for the API docs COULD provide a ToC tree for this section of the docs with explicit matching for content based not only on the current implementation of `<h1>` `<h2>` and `<h3>` header content for populating the `<li>` elements in the ToC container `<ul>` element, but by explicitly matching on 

`py class` `py method` and `py function` to assign them to CSS properties for h2 / h3 / etc... 

However, this would be a follow-on PR and not something I'm entertaining adding to this PR. ",design based feedback note could provide tree section explicit matching content based current implementation header content li container element explicitly matching class method function assign however would something entertaining,issue,negative,positive,positive,positive,positive,positive
1823541422,@BenWilson2 absolutely! Would love to. We are winding down for the Xmas break so hopefully I'll have some time in the next couple of weeks. ,absolutely would love winding break hopefully time next couple,issue,positive,positive,positive,positive,positive,positive
1823194326,"Hi, whoever on the mlflow side has access, please check mlflow-oss-maintainers@googlegroups.com",hi whoever side access please check,issue,negative,neutral,neutral,neutral,neutral,neutral
1823164213,"I find the new useless. It lacks the ability to select runs (there's only option to select 5, 10, 100 etc). Since I can't select runs to analyze it's of no use for me.",find new useless ability select option select since ca select analyze use,issue,negative,negative,negative,negative,negative,negative
1823100728,"> Btw, mlflow gateway will be deprecated soon, in future we should use deployments API instead. See branch https://github.com/mlflow/mlflow/tree/gateway-migration

Got it. Can you please explain what the ""deployment API"" is? Also, do you know the timeline on when the gateway will be deprecated and shifted to deployments?",gateway soon future use instead see branch got please explain deployment also know gateway,issue,negative,neutral,neutral,neutral,neutral,neutral
1822606289,"@B-Step62 Could you preview the tracking page on the mobile view?

<img width=""804"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/17039389/e39d60b7-a2fa-443c-bbc2-11165d805638"">

It doesn't have to look perfect on mobile devices.",could preview page mobile view image look perfect mobile,issue,positive,positive,positive,positive,positive,positive
1822546661,"Thank you for the reply, let me take a look at the doc and the current state of the PR.",thank reply let take look doc current state,issue,negative,neutral,neutral,neutral,neutral,neutral
1822535151,"hello @harupy ,I made some changes to the code for the and created a new pull request, #10486. Could you please review the new pull request and reassign me the task? thank you.",hello made code new pull request could please review new pull request reassign task thank,issue,positive,positive,positive,positive,positive,positive
1822312324,"(Adapted from https://github.com/mlflow/mlflow/issues/7980#issuecomment-1460903690)

In the _Compare runs_ tab, it would be much more readable to transpose the tables in order to:

1 - Be able to see all runs at once without scrolling horizontally


At least to provide an option to transpose all tables.
In practice when dealing with 50+ runs, the MLFlow 1.27 Only show diff switch was very efficient. Think as we want to identify the run where a parameter marginally differs in order to extract information.

As a researcher It is extremely useful to be able to see the marginal differences in parameters w.r.t. to all runs at once **while this new view allows to see the marginal differences for 8-10 runs w.r.t to all parameters**. In practice, we have many runs (because of runs with different seeds for reproductibility) but only few varying parameters (5-10%, in my example above, only 3-4 among 100+ parameters are relevant, others are fixed).

Note all the blank spaces left in the table by 1-digit parameters values below:

![image](https://user-images.githubusercontent.com/41160498/223853803-579b9c9c-bb21-4183-951b-c99f3736e9d3.png)


The original run view is much concise and cleaner. Now the horizontal width allows one to compare at most 8-10 different runs at once whereas 25+ with MLFlow 1.2x. As illustrated below, under MLFlow 1.2x I am able to efficiently validate all my 18 runs are identical except the seed is varying, **while this is not possible anymore under MLFlow 2.x**.


![image](https://user-images.githubusercontent.com/41160498/223868411-822ae5c3-46f3-4e14-a2ae-ef13a5afa6b2.png)


Thank you for your consideration,

",tab would much readable transpose table order able see without horizontally least provide option transpose table practice dealing show switch efficient think want identify run parameter marginally order extract information researcher extremely useful able see marginal new view see marginal practice many different example among relevant fixed note blank left table image original run view much concise cleaner horizontal width one compare different whereas able efficiently validate identical except seed possible image thank consideration,issue,positive,positive,positive,positive,positive,positive
1822140543,"> @B-Step62 Is it possible to file this PR against the `gateway-migration` branch to avoid conflicts?

sure!",possible file branch avoid sure,issue,negative,positive,positive,positive,positive,positive
1822136692,@B-Step62 Is it possible to file this PR against the `gateway-migration` branch to avoid conflicts?,possible file branch avoid,issue,negative,neutral,neutral,neutral,neutral,neutral
1822070213,I would like to work on issue you mentioned . Could you assign me the same @harupy  . Thankyou,would like work issue could assign,issue,negative,neutral,neutral,neutral,neutral,neutral
1822061993,"Btw, mlflow gateway will be deprecated soon, in future we should use deployments API instead. See branch https://github.com/mlflow/mlflow/tree/gateway-migration ",gateway soon future use instead see branch,issue,negative,neutral,neutral,neutral,neutral,neutral
1822050534,Please mention @harupy before starting to work on this.,please mention starting work,issue,negative,neutral,neutral,neutral,neutral,neutral
1822037186,"in latest mlflow version,

I think you can select runs you want to compare, and then click ""compare"" button,
<img width=""427"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/19235986/c7976b72-5941-4457-a93b-3b5ab28d5c69"">

then in the comparing page,
scroll down to ""Parameters"" section,
then click the ""Show diff only"" button there:

<img width=""1230"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/19235986/60e74b12-72ac-49f8-8a5b-30f777541a01"">
 

Does this resolve your use-case ? :)",latest version think select want compare click compare button image page scroll section click show button image resolve,issue,negative,positive,positive,positive,positive,positive
1822025689,"Thanks @WeichenXu123 for clarify the doubt. So ModelVersion can not be uniquely determined for a given `model_uri`.

For a given `model_uri` what all information can be retrieved uniquely? Can a `run-id` be obtained uniquely for a given `model_uri`? If yes, how can it be retrieved?",thanks clarify doubt uniquely determined given given information uniquely uniquely given yes,issue,positive,positive,positive,positive,positive,positive
1822012022,"@WeichenXu123 Model URI has the following [format](),
```
1. /Users/me/path/to/local/model
2. relative/path/to/local/model
3. s3://my_bucket/path/to/model
4. runs:/<mlflow_run_id>/run-relative/path/to/model
5. models:/<model_name>/<model_version>
6. models:/<model_name>/<stage>
7. models:/<model_name>@alias
```
Correct me if I am wrong, I think the only place we have multiple models mapped with single `model_uri` is the case `6` and if we change `model_name` then `model_uri` will be different. So how can a model_uri be mapped with different model names? 

Overall if we are able to load, say a sklearn model, using a `model_uri` then we should use the same logic that `mlflow.sklearn.load_model` is considering to resolve the conflict of choosing different models for the given `model_uri`.


",model following format stage alias correct wrong think place multiple single case change different different model overall able load say model use logic considering resolve conflict choosing different given,issue,negative,negative,neutral,neutral,negative,negative
1822011108,"> I think the issue is due to the fact that secrets mounted to kubernetes containers are symlinks and the file watcher that mlflow gateway uses isn't able to handle changes symlinks properly

I am not very familiar with how kubernetes handle files. If this is true, could you file a fixing PR and test it ? I will help review.

I just checked `watchfiles` lib, but seemingly it does not support monitor symlinks file, but we can still write a loop to monitor  symlinks change periodically.",think issue due fact mounted file watcher gateway able handle properly familiar handle true could file fixing test help review checked seemingly support monitor file still write loop monitor change periodically,issue,positive,positive,positive,positive,positive,positive
1822006940,"Got it, mlflow gateway server monitors the file changes but in the case it does not work",got gateway server file case work,issue,negative,neutral,neutral,neutral,neutral,neutral
1822005293,Quick question: did you restart mlflow gateway server after the change ?,quick question restart gateway server change,issue,negative,positive,positive,positive,positive,positive
1822000174,"I think this is a trivial issue . If tensorflow is not installed, using `mlflow.tensorflow` in your code is meaningless",think trivial issue code meaningless,issue,negative,negative,negative,negative,negative,negative
1821997345,"> @BenWilson2 When we load a model using `model_uri` for example, `mlflow.sklearn.load_model(model_uri)` and if there are multiple models mapped with same `model_uri` then model with latest version is picked.
> 
> So similarly, we can choose to return the latest `ModelVersion` for a given model_uri.

Then what if a model_uri is registered with multiple model names ? which model name shall we use in the API ?",load model example multiple model latest version picked similarly choose return latest given registered multiple model model name shall use,issue,negative,positive,positive,positive,positive,positive
1821996444,"If tensorflow is installed, we don't have the error.

But shall we allow using `mlflow.tensorflow` in code when tensorflow is not installed ?",error shall allow code,issue,negative,neutral,neutral,neutral,neutral,neutral
1821981708,"Could you provide the stack trace showing where it raises `Read-only file system: '/mlflow'` ?

although you set backend store and artifact path to /mlflow/data, there might be some other file to be created under current working dir `/mlflow`",could provide stack trace showing file system although set store artifact path might file current working,issue,negative,neutral,neutral,neutral,neutral,neutral
1821978907,"@WeichenXu123  When we load a model using `model_uri` for example, `mlflow.sklearn.load_model(model_uri)` and if there are multiple models mapped with same `model_uri` then model with latest version is picked.

So similarly, we can choose to return the latest `ModelVersion` for a given model_uri.",load model example multiple model latest version picked similarly choose return latest given,issue,negative,positive,positive,positive,positive,positive
1821969002,"Question:

We can register one model_uri with multiple model name / multiple model versions with the same model name, so given a model_uri, the query result will be a list, how to design the API ? and how to implement it with good performance ?",question register one multiple model name multiple model model name given query result list design implement good performance,issue,negative,positive,positive,positive,positive,positive
1821967699,Let's also add a new quickstart card to this page: https://www.mlflow.org/docs/latest/index.html in the quickstart section,let also add new card page section,issue,negative,positive,positive,positive,positive,positive
1821957457,"I think we can remove `result_type` argument in the UI code, if we do not set the argument, when the model has ""output signature"", result type is inferred from output signature, otherwise 'double' is used as default `result_type`. ",think remove argument code set argument model output signature result type output signature otherwise used default,issue,negative,neutral,neutral,neutral,neutral,neutral
1821897261,General note: Add collapsable elements to extra explanation text within notebook markdown cells (similar to work in #10360 ) and set all section headers to `<h3>` within notebook cells. ,general note add extra explanation text within notebook markdown similar work set section within notebook,issue,negative,positive,neutral,neutral,positive,positive
1821862391,"Posting this here if it helps anyone...

In my case there was a problem in the log_params function and not with the http connection. The strack trace disappeared probably because the code for logging was somewhere deep inside multiple methods and classes.

I was logging using log_params() in one run multiple times (was using a for loop) and so there was a conflict with the paramater naming convention  but the stack trace did not throw an error and rather the http read time out error showed up. In simple terms if my parameter was logged as 'A'  and the value was 1 then in the same run  in the next for loop iteration it would have to log 'A' again with new value say 2. So now we have 2 values to log with the same name which is a conflict in mlflow. I got around this by simply changing the parameter names.",posting anyone case problem function connection strack trace probably code logging somewhere deep inside multiple class logging one run multiple time loop conflict naming convention stack trace throw error rather read time error simple parameter logged value run next loop iteration would log new value say log name conflict got around simply parameter,issue,negative,positive,neutral,neutral,positive,positive
1821807459,@michael-berk can you rebase this branch on to the latest MLflow master? The CI job build artifacts show a much older version of the docs.,rebase branch latest master job build show much older version,issue,negative,positive,positive,positive,positive,positive
1821661879,"@asysuev @harupy I had the same issue when running MLFlow within a Fargate task. The issue has to do with the `artifact_url` value in the `meta.yaml` file. This value defaults to the full path of where you are running MLFlow. If you are running a MLFlow in a containerized application the full path to your artifact will probably be something like `file://src/your-ml-project/your-artifact`. Thus when you try to run MLFlow on your local machine this path doesn't work, it's expecting something more like `file:///Users/david/Desktop/your-ml-project/your-artifact`

I created sort of a hacky fix for this where the application opens the `meta.yaml` and changes all of the paths from `file://src/your-ml-project/your-artifact` to `./your-ml-project/your-artifact`

I can create a PR for this if y'all think it's worth it.",issue running within task issue value file value full path running running application full path artifact probably something like file thus try run local machine path work something like file sort hacky fix application file create think worth,issue,positive,positive,positive,positive,positive,positive
1821578943,"> externally, from, say, a terminal, can you write files and read files from the minio instance?

Please clarify, should DNS be raised on the host or in the container?
As I understand it, it is trying to connect via dns and not via ip

```
mlflow.exceptions.MlflowException: API request to http://artifacts-server:5500/api/2.0/mlflow-artifacts/artifacts/experiments/4/19e722e4f905493595c686fa9abb8710/artifacts/model/model.pkl failed with exception HTTPConnectionPool(host='artifacts-server', port=5500): Max retries exceeded with url: /api/2.0/mlflow-artifacts/artifacts/experiments/4/19e722e4f905493595c686fa9abb8710/artifacts/model/model.pkl (Caused by NameResolutionError(""<urllib3.connection.HTTPConnection object at 0x7f67db3e58e0>: Failed to resolve 'artifacts-server' ([Errno -2] Name or service not known)""))
2023/11/20 23:11:54 ERROR mlflow.cli: === Run (ID '19e722e4f905493595c686fa9abb8710') failed ===
```",externally say terminal write read instance please clarify raised host container understand trying connect via via request exception object resolve name service known error run id,issue,negative,neutral,neutral,neutral,neutral,neutral
1821478222,"> pls hide the artifactory location s3://aml....
> 
> ![Screenshot 2023-11-19 at 7 30 57 PM](https://user-images.githubusercontent.com/8614410/284102019-61aa52ef-8ed7-4c55-a4bf-55d4bd9c9238.png)

I personally find it very useful to see where data is stored!",hide location personally find useful see data,issue,negative,positive,positive,positive,positive,positive
1821402914,Note that the entry point needs to be changed/created.,note entry point need,issue,negative,neutral,neutral,neutral,neutral,neutral
1821322465,"@AndreaPiccions it will be released in MLflow 2.9.0, which is scheduled for the last week of November / 1st week of December for release.",last week st week release,issue,negative,neutral,neutral,neutral,neutral,neutral
1821309211,"Hi, will this be part of a new release soon? I have been waiting for the update to `cloudpickle >= 3` for a while and have a lot of open MRs waiting for an MLFlow version with unpinned `cloudpickle`",hi part new release soon waiting update lot open waiting version unpinned,issue,negative,positive,neutral,neutral,positive,positive
1820544687,"here's what I ran:

```sql
SET FOREIGN_KEY_CHECKS=0;

ALTER TABLE
    experiment_tags
    CONVERT TO CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;
ALTER TABLE
    experiments
    CONVERT TO CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;
ALTER TABLE
    latest_metrics
    CONVERT TO CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;
ALTER TABLE
    metrics
    CONVERT TO CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;
ALTER TABLE
    model_version_tags
    CONVERT TO CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;
ALTER TABLE
    model_versions
    CONVERT TO CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;
ALTER TABLE
    params
    CONVERT TO CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;
ALTER TABLE
    registered_model_tags
    CONVERT TO CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;
ALTER TABLE
    registered_models
    CONVERT TO CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;
ALTER TABLE
    runs
    CONVERT TO CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;
ALTER TABLE
    tags
    CONVERT TO CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;

SET FOREIGN_KEY_CHECKS=1;
```",ran set alter table convert character set collate alter table convert character set collate alter table convert character set collate alter table metric convert character set collate alter table convert character set collate alter table convert character set collate alter table convert character set collate alter table convert character set collate alter table convert character set collate alter table convert character set collate alter table convert character set collate set,issue,negative,neutral,neutral,neutral,neutral,neutral
1820535221,"Similar issue:
Have tracker service running on Python 3.8 + MLFlow 2.8, but it needs to support clients from Python3.6 (so MLFlow 1.23).
Ended up patching the endpoint structure on the client:

```
def _patch_mlf_v1_api_endpoints() -> None:
    """"""
    MLF v1.x -> v2.x endpoint patcher.
    """"""
    from mlflow.protos import databricks_pb2
    from mlflow.protos.model_registry_pb2 import ModelRegistryService
    from mlflow.utils.rest_utils import _REST_API_PATH_PREFIX
    import mlflow.store.model_registry.rest_store

    def _patched_extract_api_info_for_service(service, path_prefix):
        service_methods = service.DESCRIPTOR.methods
        res = {}
        for service_method in service_methods:
            endpoint_idx = 1
            endpoint = service_method.GetOptions().Extensions[databricks_pb2.rpc].endpoints[endpoint_idx]
            endpoint_path = f'{path_prefix}{endpoint.path}'
            res[service().GetRequestClass(service_method)] = (endpoint_path, endpoint.method)
        return res

    # patch endpoints stored in _METHOD_TO_INFO for MLF 2.x compatibility
    if int(mlflow.__version__.split('.')[0]) < 2:
        mlflow.store.model_registry.rest_store._METHOD_TO_INFO = _patched_extract_api_info_for_service(
            ModelRegistryService,
            _REST_API_PATH_PREFIX
        )

_patch_mlf_v1_api_endpoints()

```",similar issue tracker service running python need support python ended structure client none import import import import service service return patch compatibility,issue,negative,neutral,neutral,neutral,neutral,neutral
1820015023,@baxtree I'll pass on the idea to one of the folks that maintains the UI to see if activating the button for setting a new name could initiate a page refresh. We'll see what they think!,pas idea one see button setting new name could initiate page refresh see think,issue,negative,positive,positive,positive,positive,positive
1819965369,"> externally, from, say, a terminal, can you write files and read files from the minio instance?

yes, externally from the linux terminal I was able to mount the bucket and read the created experiments
```
$ docker-compose run -v ${PWD}/example.py:/app/example.py client python example.py
```
![minio](https://github.com/mlflow/mlflow/assets/47168912/7bf19a62-6354-467e-a36a-33b39ede448b)

I was also able to create directories and files
",externally say terminal write read instance yes externally terminal able mount bucket read run client python also able create,issue,positive,positive,positive,positive,positive,positive
1819929231,"externally, from, say, a terminal, can you write files and read files from the minio instance?",externally say terminal write read instance,issue,negative,neutral,neutral,neutral,neutral,neutral
1819906548,"> Can you try to access the minio container directly via a write command (not through MLflow) and see if that works?

Please clarify what you mean, I'm connecting to the minio container",try access container directly via write command see work please clarify mean container,issue,negative,negative,negative,negative,negative,negative
1819849355,Can you try to access the minio container directly via a write command (not through MLflow) and see if that works? ,try access container directly via write command see work,issue,negative,positive,neutral,neutral,positive,positive
1819840666,"> Hi @micron1390 I think this example might help out a bit, which showcases defining a minio setup (better than using local disk from my experience) with a postgres DB configuration, all setup with docker configuration .yml and basic DockerFile specifications:
> 
> https://github.com/mlflow/mlflow/tree/master/examples/mlflow_artifacts
> 
> If you read through the README in the 2nd half (the advanced setup portion), you'll see which files in that directory are involved and you can look at the configuration setup within https://github.com/mlflow/mlflow/blob/master/examples/mlflow_artifacts/docker-compose.yml to see how things are setup :)

I currently have these containers running, but I can’t write artifacts, what could be the problem?

```
docker ps -a
CONTAINER ID   IMAGE                               COMMAND                  CREATED          STATUS                      PORTS                              NAMES
1850761e0a8f   mlflow_artifacts_client             ""python example.py""      21 seconds ago   Exited (0) 6 seconds ago                                       mlflow_artifacts_client_run_d58f73f9283b
135eda8acfe6   mlflow_artifacts_client             ""python3""                7 hours ago      Exited (0) 7 hours ago                                         mlflow_artifacts_client_1
707b59b45e10   mlflow_artifacts_tracking-server    ""mlflow server --hos…""   7 hours ago      Up 7 hours                  0.0.0.0:5000->5000/tcp             mlflow_artifacts_tracking-server_1
1dc464ca479b   mlflow_artifacts_artifacts-server   ""mlflow server --hos…""   7 hours ago      Up 7 hours                  0.0.0.0:5500->5500/tcp             mlflow_artifacts_artifacts-server_1
76af3dc35afa   minio/mc                            ""bash -c ' mc alias …""   7 hours ago      Exited (1) 19 seconds ago                                      mlflow_artifacts_minio-create-bucket_1
9fae270650ab   postgres                            ""docker-entrypoint.s…""   7 hours ago      Up 7 hours                  5432/tcp                           mlflow_artifacts_postgres_1
a92b1f5b50e3   minio/minio                         ""/usr/bin/docker-ent…""   7 hours ago      Up 7 hours (healthy)        0.0.0.0:9000-9001->9000-9001/tcp   mlflow_artifacts_minio_1
```

```
Traceback (most recent call last):
  File ""train.py"", line 18, in <module>
    mlflow.sklearn.log_model(lr, ""model"", signature=signature)
  File ""/home/user/.mlflow/envs/mlflow-5dbdec5f659320e5e6956110ef10edf5e2a822f6/lib/python3.8/site-packages/mlflow/sklearn/__init__.py"", line 411, in log_model
    return Model.log(
  File ""/home/user/.mlflow/envs/mlflow-5dbdec5f659320e5e6956110ef10edf5e2a822f6/lib/python3.8/site-packages/mlflow/models/model.py"", line 620, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File ""/home/user/.mlflow/envs/mlflow-5dbdec5f659320e5e6956110ef10edf5e2a822f6/lib/python3.8/site-packages/mlflow/tracking/fluent.py"", line 1020, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File ""/home/user/.mlflow/envs/mlflow-5dbdec5f659320e5e6956110ef10edf5e2a822f6/lib/python3.8/site-packages/mlflow/tracking/client.py"", line 1188, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File ""/home/user/.mlflow/envs/mlflow-5dbdec5f659320e5e6956110ef10edf5e2a822f6/lib/python3.8/site-packages/mlflow/tracking/_tracking_service/client.py"", line 538, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File ""/home/user/.mlflow/envs/mlflow-5dbdec5f659320e5e6956110ef10edf5e2a822f6/lib/python3.8/site-packages/mlflow/store/artifact/http_artifact_repo.py"", line 45, in log_artifacts
    self.log_artifact(os.path.join(root, f), artifact_dir)
  File ""/home/user/.mlflow/envs/mlflow-5dbdec5f659320e5e6956110ef10edf5e2a822f6/lib/python3.8/site-packages/mlflow/store/artifact/http_artifact_repo.py"", line 28, in log_artifact
    resp = http_request(
  File ""/home/user/.mlflow/envs/mlflow-5dbdec5f659320e5e6956110ef10edf5e2a822f6/lib/python3.8/site-packages/mlflow/utils/rest_utils.py"", line 120, in http_request
    raise MlflowException(f""API request to {url} failed with exception {e}"")
mlflow.exceptions.MlflowException: API request to http://artifacts-server:5500/api/2.0/mlflow-artifacts/artifacts/experiments/4/19e722e4f905493595c686fa9abb8710/artifacts/model/model.pkl failed with exception HTTPConnectionPool(host='artifacts-server', port=5500): Max retries exceeded with url: /api/2.0/mlflow-artifacts/artifacts/experiments/4/19e722e4f905493595c686fa9abb8710/artifacts/model/model.pkl (Caused by NameResolutionError(""<urllib3.connection.HTTPConnection object at 0x7f67db3e58e0>: Failed to resolve 'artifacts-server' ([Errno -2] Name or service not known)""))
2023/11/20 23:11:54 ERROR mlflow.cli: === Run (ID '19e722e4f905493595c686fa9abb8710') failed ===
```


Thanks in advance.",hi micron think example might help bit setup better local disk experience configuration setup docker configuration basic read half advanced setup portion see directory involved look configuration setup within see setup currently running write could problem docker container id image command status python ago ago python ago ago server ago server ago bash alias ago ago ago ago healthy recent call last file line module model file line return file line log file line file line file line file line root file line resp file line raise request exception request exception object resolve name service known error run id thanks advance,issue,positive,positive,positive,positive,positive,positive
1819615322,@pmags would you be open to updating the R function `new_mlflow_client()` to check for an Azure URI and utilize the correct loader in a PR?,would open function check azure utilize correct loader,issue,negative,neutral,neutral,neutral,neutral,neutral
1819244894,Has someone grabbed this issue yet @BenWilson2? otherwise I would like to contribute.,someone issue yet otherwise would like contribute,issue,negative,neutral,neutral,neutral,neutral,neutral
1819236343,"Also saw this error message while upgrading from 2.2.2 to 2.8.1.

Fix was simple

`CREATE TABLE registered_model_aliases (
alias VARCHAR(256) NOT NULL,
version INTEGER NOT NULL,
name VARCHAR(256) NOT NULL,
CONSTRAINT registered_model_alias_pk PRIMARY KEY (name, alias),
CONSTRAINT registered_model_alias_name_fkey FOREIGN KEY(name) REFERENCES registered_models (name) ON DELETE cascade ON UPDATE cascade
) character set latin1
collate latin1_swedish_ci;` 

Because old tables had collation latin1_swedish_ci",also saw error message fix simple create table alias null version integer null name null constraint primary key name alias constraint foreign key name name delete cascade update cascade character set collate old table collation,issue,negative,positive,neutral,neutral,positive,positive
1818079689,"> Does `mlflow gc` delete artifacts from S3? If so agreed that the issue is resolved! If not it was certainly closed prematurely.
> 
> I switched away from MLflow because it doesn't support this functionality, and so I've been following this issue for 4 yrs.

Sorry that I only tested deleting local files(artifacts) and haven't tested on s3 yet. Use
 `mlflow gc` could permanently clean the local storage file",delete agreed issue resolved certainly closed prematurely switched away support functionality following issue sorry tested local tested yet use could permanently clean local storage file,issue,positive,negative,neutral,neutral,negative,negative
1817848542,"I encountered the same issue, which seems related to pydantic. Rolling back pydantic from version v2.5.1 to v1.10.13 resolved the warning for me.",issue related rolling back version resolved warning,issue,negative,neutral,neutral,neutral,neutral,neutral
1817532347,"@harupy Thank you for reviewing it. I've addressed the comments, please take a look.",thank please take look,issue,positive,neutral,neutral,neutral,neutral,neutral
1816738755,"I used UUID as the run name intentionally and the version is 2.8.0. Sorry, maybe my description was not clear enough. What I meant is after the Save button is clicked, the run name on the page is not changed accordingly. I did notice in the screencast, you refreshed the whole page to get the on-page name updated. Anyway, this FR is not a big deal but a nice-to-have. ",used run name intentionally version sorry maybe description clear enough meant save button run name page accordingly notice whole page get name anyway big deal,issue,positive,negative,neutral,neutral,negative,negative
1816709197,"Hi @lewinfox there isn't an awful lot of development attention on the R front for MLflow. We would gladly accept contributions that could enhance the experience for advanced R users such as yourself. 

Is the intention to create something akin to a custom Rfunc implementation that permits alternative serialization? This really seems like it would be a valuable addition to the core implementation. 

Could you draft up a PR with your proposed implementation and we can discuss how to integrate this functionality directly into the R implementation of MLflow?",hi awful lot development attention front would gladly accept could enhance experience advanced intention create something akin custom implementation alternative serialization really like would valuable addition core implementation could draft implementation discus integrate functionality directly implementation,issue,positive,positive,neutral,neutral,positive,positive
1816701724,"This sounds like a great idea! I wouldn't worry about where to link it. We can create a new section of the site dedicated to R-specific content. If you want to start a draft PR where we can discuss some ideas and just get the raw content created, I can help you with getting the docs infrastructure setup for housing the content :) ",like great idea would worry link create new section site content want start draft discus get raw content help getting infrastructure setup housing content,issue,positive,positive,positive,positive,positive,positive
1816696275,"@svengiegerich this makes sense! Feel free to file a PR with the sorted collection logic and attach screenshots showing the sort order modification (before and after). A small unit test to ensure that the feature importances are retaining all entries would be a good thing to add for this modification as well (and a validation that they are generated ordered and that when retrieving the stored artifact the return ordering is equivalent to the sorting enforcement). 
Let us know if you have any questions on the PR process!",sense feel free file sorted collection logic attach showing sort order modification small unit test ensure feature retaining would good thing add modification well validation ordered artifact return equivalent enforcement let u know process,issue,positive,positive,positive,positive,positive,positive
1816690939,"@jmahlik both ideas are great. We'll look forward to the PRs :) 
Please tag me in the example PR - we'll want to fit the presentation and formatting in with our docs overhaul and make your new example into an official guide on its own page (as well as create a new landing page for customizing MLflow through plugins - your new guide will be the first added one to this new section of the docs site) ",great look forward please tag example want fit presentation overhaul make new example official guide page well create new landing page new guide first added one new section site,issue,positive,positive,positive,positive,positive,positive
1816686490,"
https://github.com/mlflow/mlflow/assets/39283302/34a62709-8a70-4019-ab69-934e7d4ecd3e

Also, it works just fine on the 2.8.0 release.",also work fine release,issue,negative,positive,positive,positive,positive,positive
1816681367,What version of the MLflow client were you using when you created that run? That is the legacy naming convention (a UUID) from prior to MLflow 1.30 release. https://github.com/mlflow/mlflow/pull/6736 Are you setting a uuid as the name within your code or are you using a very old version of the MLflow package within your code base?,version client run legacy naming convention prior release setting name within code old version package within code base,issue,negative,negative,negative,negative,negative,negative
1816667831,"The model registry is only available if you have your backend store (https://mlflow.org/docs/latest/tracking.html#backend-stores) set as a Database (see the first note in that section). You can use your local filesystem as a database with a SQLite DB if you just want to do local testing. 
For an actual deployment of MLflow for ""real use"", you should look into starting an actual Database (MySQL, PostGres, MSSQL, etc.) to persist your experiments, runs, and their data permanently. 
We're working on more extensive guides that will provide detailed step-by-step walkthroughs of how to get this infrastructure set up. Stay tuned if you'd like to have that experience be much less frustrating for getting everything up and running!",model registry available store set see first note section use local want local testing actual deployment real use look starting actual persist data permanently working extensive provide detailed get infrastructure set stay tuned like experience much le getting everything running,issue,negative,positive,positive,positive,positive,positive
1816653006,"This is an interesting idea, although is rather involved to implement. 
The cli logic would need to reference a click generated autocomplete shell script ( which would be available for bash and zsh exclusively), each cli method would then need to provide incomplete match semantics for all typed parameters and optional arguments. Users would then have to source this generated script within their .bashrc or .zshrc. 

Is this something that you'd be willing to take on as a project? ",interesting idea although rather involved implement logic would need reference click shell script would available bash exclusively method would need provide incomplete match semantics optional would source script within something willing take project,issue,negative,positive,positive,positive,positive,positive
1816498189,"Hey @harupy, hash-pinning is recommended by [GitHub](https://docs.github.com/en/actions/security-guides/security-hardening-for-github-actions#using-third-party-actions) itself.

It is also [required for all Apache projects](https://infra.apache.org/github-actions-policy.html). They let GitHub-owned repos stay version-pinned, but in my experience, if you hash-pin one Action, you might as well hash-pin everything, grouped updates mean the workload is basically identical.

Here's a small sample of some other projects that hash-pin their Actions:
- https://github.com/tensorflow/io
- https://github.com/jquery/jquery
- https://github.com/pyca/cryptography
- https://github.com/libexpat/libexpat
- https://github.com/mozilla/rhino
- https://github.com/google/pprof",hey also apache let stay experience one action might well everything grouped mean basically identical small sample,issue,negative,negative,negative,negative,negative,negative
1816313683,"Sorry for the accidental close

This issue is very much still persistent with v2.8.1. I have used a version of what @chenmoneygithub suggested, but as I was patching as decorators to my function, I've added a test before my initial failing one as follows:

```
@patch(""<path_to_module>.mlflow.sklearn.save_model"")
def test_dummy_mlflow_call(mock_save):
    """"""A dummy mlflow call to circumvent a bug - need to load in the module.""""""
    mlflow.sklearn
```

And so this will successfully load in the `mlflow.sklearn` module, trying to patch the `save_model` method (but doesn't due to lazyloading) and then my subsequent tests can run properly. 

Leaving this here in case others come into this issue, but again this is a workaround and the issue isn't fixed.",sorry accidental close issue much still persistent used version function added test initial failing one patch dummy call circumvent bug need load module successfully load module trying patch method due subsequent run properly leaving case come issue issue fixed,issue,negative,positive,neutral,neutral,positive,positive
1815857539,"Managed to resolve the issue by removing version number from mlflow specification in conda file. Now my conda file looks like the below (It may be a weird solution, but the code started working fine after removing the version number):

name: <model-env>
channels:
  - conda-forge
dependencies:
  - python=3.10.11
  - numpy=1.25.0
  - pip=21.2.4
  - scikit-learn=1.2.2
  - pandas=2.0.2
  - pip:
    - mlflow
    - azureml-mlflow==1.51.0
    - azure-storage-blob==12.13.0
    - azure-identity==1.13.0
    - azure-ai-ml==1.8.0",resolve issue removing version number specification file file like may weird solution code working fine removing version number name pip,issue,positive,negative,neutral,neutral,negative,negative
1815815864,"@TomeHirata Thanks for the reply!

> Yes, what will be the next step of https://github.com/mlflow/mlflow/pull/9939? Should we start from the designing?

#9939 is actually like a design (for more details, please take a look at the attached PDF). We need to add unit tests and docs.

Design doc: [Copy of [2023-11-18] One-Decision Doc_ Rate limits for OSS AI Gateway.pdf](https://github.com/mlflow/mlflow/files/13388177/Copy.of.2023-11-18.One-Decision.Doc_.Rate.limits.for.OSS.AI.Gateway.pdf)


> Also, would you mind reviewing https://github.com/mlflow/mlflow/pull/10266?

Left some comments, thanks for working on this!",thanks reply yes next step start designing actually like design please take look attached need add unit design doc copy rate ai also would mind left thanks working,issue,positive,positive,neutral,neutral,positive,positive
1815774069,"This font is a bit difficult to read (for me). Can we use a different font?

<img width=""354"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/17039389/712ac14c-ddf8-4ae5-a56b-7e0b3a032971"">
",font bit difficult read use different font image,issue,negative,negative,negative,negative,negative,negative
1815737098,"@serena-ruan `test (tensorflow / autologging / dev)` is still failing as expected, but `TypeError: list.append() takes no keyword arguments` has gone away. Merging.",test dev still failing gone away,issue,negative,neutral,neutral,neutral,neutral,neutral
1815552382,"I definitely agree that being able to see the warning on class init would be much more helpful! Thanks for the comments, I think your proposed solution looks good, but I'll spend some time investigating if it's possible to get the same behavior without necessarily calling `super.__init__()`. GPT4 has some suggestions, I'll see if they work haha",definitely agree able see warning class would much helpful thanks think solution good spend time investigating possible get behavior without necessarily calling see work,issue,positive,positive,positive,positive,positive,positive
1815039291,"@daniellok-db I'm curious about your thoughts on doing something like this:

```python
from abc import ABCMeta, abstractmethod
import warnings
import inspect
import functools

class PythonModel(metaclass=ABCMeta):
    def __init__(self):
        super().__init__()
        self._model_set_in_init = False

    def __setattr__(self, name, value):
        if name == ""model"" and not hasattr(self, '_load_context_called'):
            self._model_set_in_init = True
        super().__setattr__(name, value)

    @classmethod
    def __init_subclass__(cls, **kwargs):
        super().__init_subclass__(**kwargs)
        original_init = cls.__init__

        @functools.wraps(original_init)
        def new_init(self, *args, **kwargs):
            original_init(self, *args, **kwargs)
            if self._model_set_in_init and not self._is_load_context_overridden():
                warnings.warn(""Setting 'model' in __init__ is not recommended. Use 'load_context' instead."")

        cls.__init__ = new_init

    def _is_load_context_overridden(self):
        return inspect.getsource(self.load_context) != inspect.getsource(PythonModel.load_context)

    def load_context(self, context):
        self._load_context_called = True

    @abstractmethod
    def predict(self, context, model_input, params=None):
        pass
```
Where we would get this sort of behavior at subclass instantiation time:

```python
class MyModelBad(PythonModel):
    def __init__(self, model):
        super().__init__()
        self.model = model  # This should trigger the warning

    def predict(self, context, model_input, params=None):
        return model_input

bad_model = MyModelBad(""some model"")

```
(just an example, I like your warning WAY better)
``` bash
/var/folders/cd/n8n0rm2x53l_s0xv_j_xklb00000gp/T/ipykernel_14329/1003928391.py:25: UserWarning: Setting 'model' in __init__ is not recommended. Use 'load_context' instead.
  warnings.warn(""Setting 'model' in __init__ is not recommended. Use 'load_context' instead."")
```
``` python
class MyModelGood(PythonModel):
    def __init__(self):
        super().__init__()
        self.model = None

    def load_context(self, context):
        self.model = ""<load from src>""

    def predict(self, context, model_input, params=None):
        pass

good_model = MyModelGood()

```
(no warning)
```python
class MyModelGood2(PythonModel):

    def load_context(self, context):
        self.model = ""<load from src>""

    def predict(self, context, model_input, params=None):
        pass

test2 = MyModelGood2()
```
(no warning)
```python
class MyModelGood3(PythonModel):

    def __init__(self, test):
        super().__init__()
        self.test = test

    def predict(self, context, model_input, params=None):
        pass

test3 = MyModelGood3(""test"")
```
(no warning)

The only caveat to this is that since we don't require load_context to be overridden (it's not declared as an abstract method), we have to do some funky gymnastics to verify that it's called in the subclass and that the functionality is overridden). 

The other thing that would be required to use this approach is to enforce best practices of subclassing when calling __init__() (recommending the super().__init__() call to be called within the pydoc string and our docs; it's a generally accepted best practice to begin with for Python OO dev, but there's not a core language feature that prevents you from NOT doing that). 

The benefit of this approach, from what I can see, is that the developer of the custom python model will get an indication immediately at instantiation time (Rather than at save / log time) to let them know that they should read the docs on how to use this functionality properly. 

Thoughts?",curious something like python import import import inspect import class self super false self name value name model self true super name value super self self setting use instead self return self context true predict self context pas would get sort behavior subclass time python class self model super model trigger warning predict self context return model example like warning way better bash setting use instead setting use instead python class self super none self context load predict self context pas warning python class self context load predict self context pas test warning python class self test super test predict self context pas test test warning caveat since require declared abstract method funky gymnastics verify subclass functionality thing would use approach enforce best calling super call within string generally accepted best practice begin python dev core language feature benefit approach see developer custom python model get indication immediately time rather save log time let know read use functionality properly,issue,positive,positive,positive,positive,positive,positive
1814873915,"I'd like to suggest the alternative functionality suggested by @dmatrix 
I found it pretty straightforward to use python logging to write the log file into the artifacts directory for a run.  It would be extremely useful to have a log inspector in the web UI to highlight and filter messages by severity and search the text.  This capability would be very helpful for debugging runs.",like suggest alternative functionality found pretty straightforward use python logging write log file directory run would extremely useful log inspector web highlight filter severity search text capability would helpful,issue,positive,positive,positive,positive,positive,positive
1814868237,"Hi Guys,

I am having the same error, just when I execute a cenario with more than 8 trials (after 5h of connection)  with otpuna package(my target is 100 trials), inside Colab.  Until 7 trials, it do not occur.  I made an upgrade do Colab Pro+, to executye in second plan, thinking that in Colab Pro, the idle time was interrupting the running, but there was not success.",hi error execute connection package target inside occur made upgrade second plan thinking pro idle time interrupting running success,issue,negative,positive,positive,positive,positive,positive
1814816337,"Does `mlflow gc` delete artifacts from S3? If so agreed that the issue is resolved! If not it was certainly closed prematurely.

I switched away from MLflow because it doesn't support this functionality, and so I've been following this issue for 4 yrs.",delete agreed issue resolved certainly closed prematurely switched away support functionality following issue,issue,positive,negative,neutral,neutral,negative,negative
1814537809,Just noticed this appears to be the last major blocker to installing on python 3.12. ,last major blocker python,issue,negative,positive,neutral,neutral,positive,positive
1814162917,Bump. Would be easier to have something in the UI instead of also having to permanently delete it through the cli.,bump would easier something instead also permanently delete,issue,negative,neutral,neutral,neutral,neutral,neutral
1814044856,"@harupy indeed, and the new version 2.8.1 released to PyPI today solves the problem for `mlflow` (leaviing only `feast`, which we are lucky not to use in production, unlike MLFlow:). Thank you!

_More info_
```
$ docker run --rm -it --name py-test latestml/ml-cpu-py39-jup-cust bash
(base) jovyan@b252d1afbb79:~$ pip show mlflow 
Name: mlflow
Version: 2.8.1
Summary: MLflow: A Platform for ML Development and Productionization
Home-page: https://mlflow.org/
Author: Databricks
Author-email: 
License: Apache License 2.0
Location: /opt/conda/lib/python3.9/site-packages
Requires: alembic, click, cloudpickle, databricks-cli, docker, entrypoints, Flask, gitpython, gunicorn, importlib-metadata, Jinja2, markdown, matplotlib, numpy, packaging, pandas, protobuf, pyarrow, pytz, pyyaml, querystring-parser, requests, scikit-learn, scipy, sqlalchemy, sqlparse
Required-by: 

$ pip show pyarrow
Name: pyarrow
Version: 11.0.0
Summary: Python library for Apache Arrow
Home-page: https://arrow.apache.org/
Author: 
Author-email: 
License: Apache License, Version 2.0
Location: /opt/conda/lib/python3.9/site-packages
Requires: numpy
Required-by: feast, mlflow, scrapbook, streamlit, tabpy
(base) jovyan@b252d1afbb79:~$ pip install pyarrow"">=14.0.1""
Collecting pyarrow>=14.0.1
  Downloading pyarrow-14.0.1-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (3.0 kB)
Requirement already satisfied: numpy>=1.16.6 in /opt/conda/lib/python3.9/site-packages (from pyarrow>=14.0.1) (1.23.5)
Downloading pyarrow-14.0.1-cp39-cp39-manylinux_2_28_x86_64.whl (38.0 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 38.0/38.0 MB 77.6 MB/s eta 0:00:00
Installing collected packages: pyarrow
  Attempting uninstall: pyarrow
    Found existing installation: pyarrow 11.0.0
    Uninstalling pyarrow-11.0.0:
      Successfully uninstalled pyarrow-11.0.0
ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
feast 0.34.1 requires pyarrow<12,>=4, but you have pyarrow 14.0.1 which is incompatible.
```
",indeed new version today problem feast lucky use production unlike thank docker run name bash base pip show name version summary platform development author license apache license location alembic click docker flask jinja markdown pip show name version summary python library apache arrow author license apache license version location feast scrapbook base pip install requirement already satisfied eta collected found installation successfully uninstalled error pip dependency resolver currently take account behaviour source following dependency feast incompatible,issue,positive,positive,neutral,neutral,positive,positive
1813891630,"> Thanks for all the reviews! I think the last things pending are

@daniellok-db I try to tackle EditableNote, and the old run comparison page is being deprecated very soon (should happen already 😅) so let's skip it :) ",thanks think last pending try tackle old run comparison page soon happen already let skip,issue,negative,positive,positive,positive,positive,positive
1813740864,@chenmoneygithub let me push a commit. there is a job I want to adjust.,let push commit job want adjust,issue,negative,neutral,neutral,neutral,neutral,neutral
1813738899,"@harupy Yes, what will be the next step of https://github.com/mlflow/mlflow/pull/9939? Should we start from the designing?
Also, would you mind reviewing https://github.com/mlflow/mlflow/pull/10266?",yes next step start designing also would mind,issue,negative,neutral,neutral,neutral,neutral,neutral
1813736866,"@hubertzub-db Thanks for all the reviews! I think the last things pending are:
1. Descriptions editing box (`ReactMde`):
<img width=""1014"" alt=""Screenshot 2023-11-16 at 11 13 46 AM"" src=""https://github.com/mlflow/mlflow/assets/148037680/ff6436c9-65ab-44b6-a176-2ca880d1bacb"">
2. Run details comparison table:

https://github.com/mlflow/mlflow/assets/148037680/a65f12fd-5f9c-43fe-b0a4-8f307f0ff230

However these seem like larger changes, and I'm not sure if I have enough bandwidth over the next couple of sprints to support. ",thanks think last pending box run comparison table however seem like sure enough next couple support,issue,positive,positive,positive,positive,positive,positive
1813711735,"> Do you want to add a manual workflow dispatch trigger or just leave this as automated execution only?

I don't think we need a manual workflow. If you want to run it, you can file a PR.",want add manual dispatch trigger leave execution think need manual want run file,issue,negative,neutral,neutral,neutral,neutral,neutral
1813459535,@mirekphd https://github.com/mlflow/mlflow/pull/10359 updated the version requirement on pyarrow. The latest version should be installed unless other dependencies pins it to `< 14`.,version requirement latest version unless,issue,negative,positive,positive,positive,positive,positive
1813255578,I have generated one but it seems almost empty. Do I need to run the script on a specific commit?,one almost empty need run script specific commit,issue,negative,negative,neutral,neutral,negative,negative
1813228674,Hi @bhack I believe you'll need to craft a database schema migration script for this via alembic.,hi believe need craft schema migration script via alembic,issue,negative,neutral,neutral,neutral,neutral,neutral
1813166056,@annzhang-db don't worry about the R test failures. We'll force-merge (CRAN is down hard for the last 14 hours),worry test cran hard last,issue,negative,negative,negative,negative,negative,negative
1812965489,"Hi @BenWilson2 , can I work on this issue? Thanks
",hi work issue thanks,issue,negative,positive,positive,positive,positive,positive
1812882722,"I have just recently started using MLFLow for Prompt Engineering and interacting with the gateway through a notebook has been really seamless. One feature in the Prompt UI I'd like to see (or perhaps don't understand) is that when you add a new row to or duplicate a run it automatically populates the variables for you. I only want to change one of the variables of the three for a new run, but currently I have to copy and paste all of them from outside the UI.",recently prompt engineering gateway notebook really seamless one feature prompt like see perhaps understand add new row duplicate run automatically want change one three new run currently copy paste outside,issue,negative,positive,neutral,neutral,positive,positive
1812832403,"Haha no worries! I was actually looking for some way to edit the root component as well, glad to know it exists. I'm always a fan of making as little changes as possible!

I'll update this PR tomorrow! I have another one coming after for fixing some text colors as well.",actually looking way edit root component well glad know always fan making little possible update tomorrow another one coming fixing text color well,issue,positive,positive,neutral,neutral,positive,positive
1812824004,"cc @BenWilson2 @chenmoneygithub added an example, let me know how it looks!",added example let know,issue,negative,neutral,neutral,neutral,neutral,neutral
1812817324,"If your application supports Postgres, it seems logical that you would include that support all the way to the official Docker image.

This is somewhat a bad idea, and people will begin to use public images that have the support built in, causing everyone to think they are using the official Docker image when they are most definitely not.

Case in point: The community Helm chart for Mlflow. https://github.com/community-charts/helm-charts/blob/main/charts/mlflow/values.yaml

In this case, they're not using the official Mlflow Docker image, they're https://github.com/burakince/mlflow .

This info came from this site: https://artifacthub.io/packages/helm/community-charts/mlflow , which has a link to this official GitHub repo. If you go to LINKS on the right, you'll see official links for Mlflow in the Homepage, Source. This was as of Nov 15th, 2023.

I realize they are ""community charts"". But I think there is a case to be made that you SHOULD add support to the official Docker image for the databases and services Mlflow uses.

One potential solution: have a `slim` version of the image that is smaller and doesn't have these modules (or the opposite, `full` that has everything). Then our deployments are aligned with you as the upstream.

Just some thoughts, hope it is considered. TY for the support.",application logical would include support way official docker image somewhat bad idea people begin use public support built causing everyone think official docker image definitely case point community helm chart case official docker image came site link official go link right see official link source th realize community think case made add support official docker image one potential solution slim version image smaller opposite full everything upstream hope considered support,issue,positive,positive,neutral,neutral,positive,positive
1812572423,"@harupy  Would like to reopen the issue as it fails to upload files with more than 3GB files. 

In older versions it failed to upload files more than 800 MB .  As a workaround resource limits were increased and it fixed the problem for file uploads up to 2.5 GB. 


Request you to consider a permanent fix for the issue addressed. Could you please incorporate the workaround provided by Earthwings in the comment section https://github.com/mlflow/mlflow/issues/7564#issuecomment-1717949904",would like reopen issue older resource fixed problem file request consider permanent fix issue could please incorporate provided comment section,issue,negative,positive,positive,positive,positive,positive
1812481703,"It's so strange. I am also getting the same issue. On normal notebook below is working fine.
import mlflow
mlflow.sklearn.log_model

But when running the code through Azure ML Pipeline, I am getting error saying module 'mlflow' has no attribute 'sklearn'.

The python version I am using is 3.10.11 & mlflow==2.4.1
Microsoft's SDK V2 is not stable & the documentation is horrible.",strange also getting issue normal notebook working fine import running code azure pipeline getting error saying module attribute python version stable documentation horrible,issue,negative,negative,negative,negative,negative,negative
1812302555,"> I have also encountered this issue after I stopped an experiment mid-run. It seems the run's meta.yaml file doesn't finish writing correctly and then breaks any calls for the experiment. 
> @harupy do you think you could reopen this issue to at least include a custom exception message that points to the offending run? Thank you!!

I experienced the same problem",also issue stopped experiment run file finish writing correctly experiment think could reopen issue least include custom exception message run thank experienced problem,issue,negative,positive,positive,positive,positive,positive
1812095143,"I have also encountered this issue after I stopped an experiment mid-run. It seems the run's meta.yaml file doesn't finish writing correctly and then breaks any calls for the experiment. 
@harupy do you think you could reopen this issue to at least include a custom exception message that points to the offending run? Thank you!!",also issue stopped experiment run file finish writing correctly experiment think could reopen issue least include custom exception message run thank,issue,negative,negative,negative,negative,negative,negative
1812046180,"> Is this change intended?

@hubertzub-db oof good catch—i missed it as i didn't have enough registered models to cause the page to scroll. added `ScrollablePageWrapper` back, but changed the calc from `100% - 60px` to `100vh - 60px` which i think is the intended behavior (full screen height - header). it looks like `ModelListPage` is the only component that uses it:

https://github.com/search?q=repo%3Amlflow%2Fmlflow%20scrollablepagewrapper&type=code

https://github.com/mlflow/mlflow/assets/148037680/3f78e738-7184-4481-963a-f2e056922022
",change intended good enough registered cause page scroll added back think intended behavior full screen height header like component,issue,positive,positive,positive,positive,positive,positive
1811959728,"> Hi @dvirginz MLflow 2.8 should have solved this for you.
> 
> Just wanted to follow up with some docs on MLflow 2.8 with the system metrics update.
> 
> Example: https://github.com/mlflow/mlflow/blob/master/examples/system_metrics/collect_system_metrics.py
> 
> Docs: https://mlflow.org/docs/latest/python_api/mlflow.html?highlight=enable_system_metrics_logging#mlflow.enable_system_metrics_logging
> 
> What's New: https://mlflow.org/docs/latest/new-features/index.html

Hi @AbeOmor 
Does this also track gpu metrics?

I tried this feature and it tracked everything except the gpu (which is the most important resource to track)

![image](https://github.com/mlflow/mlflow/assets/109704569/11c88beb-2727-44bc-bf6a-bcbb79c80d62)
",hi follow system metric update example new hi also track metric tried feature tracked everything except important resource track image,issue,negative,positive,positive,positive,positive,positive
1811796399,simple solution is the best solution,simple solution best solution,issue,positive,positive,positive,positive,positive,positive
1811603360,@TomeHirata Thanks for the patience! I underestimated the complexity of PR merge. Glad we settled on a safe and simple solution.,thanks patience complexity merge glad settled safe simple solution,issue,positive,positive,positive,positive,positive,positive
1811579107,@harupy can i set DCO to pass for this? looks like there are commits in master that don't pass the check,set pas like master pas check,issue,negative,neutral,neutral,neutral,neutral,neutral
1810436212,"Sure, then this also sounds to me. Please feel free to push changes to the PR.",sure also please feel free push,issue,positive,positive,positive,positive,positive,positive
1809775227,"I have made this function to do the task. It is basic and I am sure it needs more checks :-) but it worked for me. Then you need to know the mlruns id number of the old and the new experiment.

```python
import shutil
import yaml

def move_mlflow_runs_to_experiment(
    base_mlruns_dir: Path,
    old_experiment_number: int,
    new_experiment_number: int,
) -> None:
    """"""
    Modify and move MLflow runs from one experiment to another.

    Args:
        base_mlruns_dir (Path): The base directory containing the MLflow runs.
        old_experiment_number (int): The number of the experiment to move runs from.
        new_experiment_number (int): The number of the experiment to move runs to.

    Returns:
        None

    Usage:
        >>> move_mlflow_runs_to_experiment(
        ...     base_mlruns_dir=""experiments/mlruns"",
        ...     old_experiment_number=29,
        ...     new_experiment_number=28,
        ... )
    """"""
    old_dir = Path(base_mlruns_dir, str(old_experiment_number))
    new_dir = Path(base_mlruns_dir, str(new_experiment_number))

    # Iterate over the direct subdirectories
    for subdir in old_dir.iterdir():
        if subdir.is_dir():
            # print information about the current directory
            print(f""Processing {subdir}"")
            meta_yaml = subdir / ""meta.yaml""
            if meta_yaml.exists():
                with meta_yaml.open(""r"") as file:
                    data = yaml.safe_load(file)

                # Modify the 'artifact_uri' if it exists
                if ""artifact_uri"" in data:
                    parts = data[""artifact_uri""].split(""/"")
                    for i, part in enumerate(parts):
                        if part == ""mlruns"":
                            # Update the number after 'mlruns'
                            if i + 1 < len(parts):
                                parts[i + 1] = str(new_experiment_number)
                                break
                    data[""artifact_uri""] = ""/"".join(parts)

                # Update 'experiment_id'
                data[""experiment_id""] = str(new_experiment_number)

                # Write the changes back to the file
                with meta_yaml.open(""w"") as file:
                    yaml.dump(data, file)

            # Move the subdirectory to the new location
            new_subdir_path = new_dir / subdir.name
            if new_subdir_path.exists():
                print(f""Warning: {new_subdir_path} already exists. Skipping move."")
            else:
                shutil.move(str(subdir), str(new_subdir_path))
                print(f""Moved {subdir} to {new_subdir_path}"")
```",made function task basic sure need worked need know id number old new experiment python import import path none modify move one experiment another path base directory number experiment move number experiment move none usage path path iterate direct print information current directory print file data file modify data data part enumerate part update number break data update data write back file file data file move new location print warning already skipping move else print,issue,negative,positive,neutral,neutral,positive,positive
1809520537,"> Is it correct that you plan to make the job required in the Github setting?

Yes, that's the plan.",correct plan make job setting yes plan,issue,negative,neutral,neutral,neutral,neutral,neutral
1809490362,That is similar to what I was thinking when I asked [this question](https://github.com/mlflow/mlflow/issues/10069#issuecomment-1774835486). I agree that having a synchronous job triggered per PR is better to work with. Is it correct that you plan to make the job required in the Github setting?,similar thinking question agree synchronous job triggered per better work correct plan make job setting,issue,positive,positive,positive,positive,positive,positive
1809450560,"> @serena-ruan mind sharing the script code here?

```
import os
import re

def update_code_blocks(content):
    groups = re.findall(r""(.. code-section::\n.*.. code-block)"", content)
    for group in groups:
        content = content.replace(group, ""\n\n"".join(group.split(""\n"")))
    return content

def update_tags(content):
    # Close <img> tags if it's not
    groups = re.findall(r""(<img(.*?)>)"", content, flags=re.DOTALL)
    for group in groups:
        if group[1][-1] != ""/"":
            content = content.replace(group[0], ""<img"" + group[1] + ""/>"")
    # close <br> tags if it's not
    while match:=re.search(r'<br[^/]*?>', content):
        i, j = match.span()
        content = content[:i] + match.group()[:-1] + ""/>"" + content[j:]
    return content

def fix_code_blocks(folder):
    # Get a list of all files in the input folder and its subfolders
    for root, dirs, files in os.walk(folder):
        for file in files:
            if file.endswith('.rst'):
                rst_path = os.path.join(root, file)

                with open(rst_path, 'r') as f:
                    rst_content = f.read()

                rst_content = update_code_blocks(rst_content)
                rst_content = update_tags(rst_content)
                with open(rst_path, 'w') as f:
                    f.write(rst_content)

if __name__ == ""__main__"":
    folder = 'docs/source'

    fix_code_blocks(folder)
```

It has some mismatching cases so I manually checked the result",mind script code import o import content content group content group return content content close content group group content group group close match content content content content return content folder get list input folder root folder file root file open open folder folder manually checked result,issue,negative,neutral,neutral,neutral,neutral,neutral
1809442286,Merging to unblock other PRs. We can update the comment as a follow-up if necessary.,unblock update comment necessary,issue,negative,neutral,neutral,neutral,neutral,neutral
1809429445,"> @serena-ruan Did you use a formatter? looks like you did.

I used a script 🤣 Pattern matching and update",use like used script pattern matching update,issue,negative,neutral,neutral,neutral,neutral,neutral
1809368079,will rebase and open new PR against the dark-theme branch,rebase open new branch,issue,negative,positive,neutral,neutral,positive,positive
1809213138,"> Thanks Ben! This is related to CI failure like this right? https://github.com/mlflow/mlflow/actions/runs/6855589269/job/18640949043?pr=10362

precisely :D ",thanks ben related failure like right precisely,issue,negative,positive,positive,positive,positive,positive
1808955354,"Adding to the pool of problematic examples: https://gist.github.com/astan-iq/8722c75b9bdaad7596ae2f70562ecb6c
Which raises `mlflow.exceptions.MlflowException: Tag value ... had length 45560, which exceeded length limit of 5000`

Removing `signature`  from the `log_model` args works but then you lose the schema validation functionality.

It appears that tracking schemas of large datasets is not supported.

Has anyone found a solution to this? It looks like the new MLF dataset capture can log the train/test data schemas but 
signature being part of the model tag remains an issue.",pool problematic tag value length length limit removing signature work lose schema validation functionality large anyone found solution like new capture log data signature part model tag remains issue,issue,negative,positive,positive,positive,positive,positive
1808900532,"@danielyxyang Thanks for your help! But please don't start contributing by doing code review. Usually we assign code review tasks to OSS contributors after they have nailed several solid PRs, otherwise the review could be distracting and increasing our overhead.",thanks help please start code review usually assign code review several solid otherwise review could increasing overhead,issue,positive,negative,neutral,neutral,negative,negative
1808889840,+1 for this feature! It would be really helpful to have this. ,feature would really helpful,issue,negative,positive,positive,positive,positive,positive
1808348494,"Thank you, using the version 2.8 resolved our issue. ",thank version resolved issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1807772264,"@TomeHirata After some thought, I think adding a guard job is simpler and **much safer** than the current approach. The guard job does the following:

1. Always runs on pull request.
2. Is marked as required.
3. Wait for other jobs to succeed.

Example: https://github.com/mlflow/mlflow/pull/10368

I can push updates to this PR if this sounds good to you.",thought think guard job simpler much current approach guard job following always pull request marked wait succeed example push good,issue,positive,positive,positive,positive,positive,positive
1807594919,"Currently, there are two main ways to delete artifacts (local artifacts file or dir):

1. Regular program execution to clean the run which lifecycle_stage equals ""deleted"" 
2. Use `mlflow gc` to permanently clean the local storage file. 



",currently two main way delete local file regular program execution clean run use permanently clean local storage file,issue,positive,positive,positive,positive,positive,positive
1807530710,I'd really appreciate dark mode.,really appreciate dark mode,issue,negative,positive,neutral,neutral,positive,positive
1807387028,"> > Have we tried using `LazyLoader`?
> > ```python
> > from mlflow.utils.lazy_load import LazyLoader
> > 
> > psutil = LazyLoader(""psutil"", globals(), ""psutil"")
> > 
> > print(psutil.cpu_count())
> > ```
> 
> Ah.... actually `psutil` usage is pretty much inside `system_metric` module and `gateway` outside tests.... so it sounds solve the issue at all.

Just found that `SystemMonitorMetrics` is lazy loaded in current implementation anyway ([code](https://github.com/mlflow/mlflow/blob/e90a2c8ee0160006a83930f68899d8771e381877/mlflow/tracking/fluent.py#L384C1-L385C1)), so probably we don't need to use LazyLoader for it but just keep it and add some helpful message there about psutil.",tried python import print ah actually usage pretty much inside module gateway outside solve issue found lazy loaded current implementation anyway code probably need use keep add helpful message,issue,positive,positive,neutral,neutral,positive,positive
1807367095,"> Have we tried using `LazyLoader`?
> 
> ```python
> from mlflow.utils.lazy_load import LazyLoader
> 
> psutil = LazyLoader(""psutil"", globals(), ""psutil"")
> 
> print(psutil.cpu_count())
> ```

Ah.... actually `psutil` usage is pretty much inside `system_metric` module and `gateway` outside tests.... so it sounds solve the issue at all.",tried python import print ah actually usage pretty much inside module gateway outside solve issue,issue,positive,positive,positive,positive,positive,positive
1807358535,"Have we tried using `LazyLoader`?

```python
from mlflow.utils.lazy_load import LazyLoader

psutil = LazyLoader(""psutil"", globals(), ""psutil"")

print(psutil.cpu_count())
```

The current approach isn't bad, but we'd need to add a function `foo` when we need `foo` from psutil:

```python
def foo():
    psutil = _check_and_import_psutil()
    return psutil.foo()
```",tried python import print current approach bad need add function foo need foo python foo return,issue,negative,negative,negative,negative,negative,negative
1807307645,"> We should also think about how we can prevent using `psutil` directly. For example, if I make the following change, would CI block my PR or not?
> 
> ```diff
> + import psutil
> +
> + print(psutil.__version__)
> ```

Makes sense, probably adding custom pylint checker would be the easiest path. Let me give it a try.",also think prevent directly example make following change would block import print sense probably custom checker would easiest path let give try,issue,negative,positive,neutral,neutral,positive,positive
1807097781,"@dbczumar Is there any progress on this issue? Now, I'm suffering from this issue in my experiments.
Or could you suggest any way to bypass this issue if exists?",progress issue suffering issue could suggest way bypass issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1806970687,"Hi @BenWilson2. Can I take this ticket? I'm willing to handle this entire checklist.
btw, I just took a look and it seems you are missing `tests/recipes/test_train_step.py`",hi take ticket willing handle entire took look missing,issue,negative,positive,neutral,neutral,positive,positive
1806903666,"We should also think about how we can prevent using `psutil` directly. For example, if I make the following change, would CI block my PR or not? 

```diff
+ import psutil
+
+ print(psutil.__version__)
```",also think prevent directly example make following change would block import print,issue,negative,positive,neutral,neutral,positive,positive
1806824709,closing as currently not ready. Will reopen if the feature request gets approved,currently ready reopen feature request,issue,negative,positive,positive,positive,positive,positive
1806556964,Thanks for the updates! Can we manually create a commit status using https://docs.github.com/en/rest/commits/statuses?apiVersion=2022-11-28#create-a-commit-status?,thanks manually create commit status,issue,positive,positive,positive,positive,positive,positive
1806351308,I think the casts in https://github.com/mlflow/mlflow/pull/9156 may still be needed. It makes sense since they are int columns. It's just by happenstance they work from autocasting in most of the database drivers.,think may still sense since happenstance work,issue,negative,neutral,neutral,neutral,neutral,neutral
1806162113,"@harupy I've updated the logic in https://github.com/mlflow/mlflow/pull/10210/commits/8bc132aafb40e22f5edb6e850a1152142785b383. Could you take a look? Also, can I ask if there is any environment to verify the commit status check easily?",logic could take look also ask environment verify commit status check easily,issue,positive,positive,positive,positive,positive,positive
1806085992,"@nilutz Yep, that was my first step -- from my logs above `11-07-2023 01:40:46 PM   timeout: 120`.

This is sufficient gunicorn worker time for my current model size tests. ",yep first step sufficient worker time current model size,issue,negative,positive,positive,positive,positive,positive
1805999353,"@patrickodpt Try increasing the `--timeout` for gunicorn. By default, gunicorn will hang if a process takes more than 30 seconds, so increasing the timeout helps !

```

#!/bin/bash
FROM python:3.11.0

RUN pip install --no-cache mlflow[extra] psycopg2 boto3 minio

EXPOSE 5000

CMD mlflow server \
    --host=0.0.0.0 \
    --port=5000 \
    --app-name basic-auth \
    --backend-store-uri=${BACKEND_STORE_URI} \
    --gunicorn-opts=""--log-level=debug --timeout=9000"" \
    --serve-artifacts \
    --artifacts-destination=${BUCKET}
```",try increasing default process increasing python run pip install extra expose server bucket,issue,negative,neutral,neutral,neutral,neutral,neutral
1805761153,"I have experienced a similar issue but I am not 100% sure whether it is the same cause. I also wanted to setup a scenario similar to [Scenario 5 with proxied artifact storage](https://mlflow.org/docs/2.8.0/tracking.html?highlight=scenario#scenario-5-mlflow-tracking-server-enabled-with-proxied-artifact-storage-access). For the database I opted for postgres and for S3 storage we tried minio (for a local dev setup). In the end our docker-compose setup looks like the following, maybe it helps.

- mlflow.Dockerfile:
```
#!/bin/bash
FROM python:3.11.0

RUN pip install --no-cache mlflow[extra] psycopg2 boto3 minio

EXPOSE 5000

CMD mlflow server \
    --host=0.0.0.0 \
    --port=5000 \
    --backend-store-uri=${BACKEND_STORE_URI} \
    --gunicorn-opts=""--log-level=debug"" \
    --serve-artifacts \
    --artifacts-destination=${BUCKET}
```
And a the correspoding docker compose:
```
version: ""3.4""

services:
  database:
    image: 'postgres:latest'
    container_name: mlflow_db
    restart: unless-stopped
    ports:
      - ""5432:5432""
    environment:
      - POSTGRES_DB=mlflowdb
      - POSTGRES_USER=mlflow_user
      - POSTGRES_PASSWORD=123
    networks:
      - mlflow_network
    volumes:
      - pgdata_mlflow:/var/lib/postgresql/data
    command: [""postgres"", ""-c"", ""log_statement=all"", ""-c"", ""log_destination=stderr""] # this is for logging everything so stdout
  s3:
    restart: always
    image: minio/minio
    container_name: mlflow_minio
    volumes:
      - ./minio_data:/data
    ports:
      - ""9000:9000""
      - ""9001:9001""
    networks:
      - mlflow_network
    environment:
      - MINIO_ROOT_USER=minio_user
      - MINIO_ROOT_PASSWORD=minio_pwd
      - MINIO_ADDRESS=:9000
      - MINIO_PORT=9000
      - MINIO_STORAGE_USE_HTTPS=False
      - MINIO_CONSOLE_ADDRESS=:9001
    command: server /data
  app:
    build:
      context: .
      dockerfile: mlflow.Dockerfile
    ports:
      - ""5000:5000""
    environment:
      - BACKEND_STORE_URI=postgresql://mlflow_user:123@database:5432/mlflowdb
      - BUCKET=s3://mlflow
      - MLFLOW_S3_ENDPOINT_URL=http://s3:9000
      - MLFLOW_S3_IGNORE_TLS=true
      - AWS_ACCESS_KEY_ID=awPdPbLlPaqciiCEDP3H #this generated from the minio ui
      - AWS_SECRET_ACCESS_KEY=iUf7wQYbtfUq0ssQ2FCiKIbkMKIHPItkHw6vhw45 #this generated from the minio ui

    networks:
      - mlflow_network
    depends_on:
      - s3
      - database

volumes:
  pgdata_mlflow:

networks:
  mlflow_network:
```
[This](https://blog.min.io/setting-up-a-development-machine-with-mlflow-and-minio/) helped a lot in setting up minio.

Now when trying to upload a large file >1GB I get the following error from mlflow client:
```
mlflow.exceptions.MlflowException: API request to http://0.0.0.0:5000/api/2.0/mlflow-artifacts/artifacts/1/9f5fcd081865478d9f799cdb6cab2089/artifacts/<file>/artifacts/b<file>.bin failed with exception HTTPConnectionPool(host='0.0.0.0', port=5000): Max retries exceeded with url: /api/2.0/mlflow-artifacts/artifacts/1/9f5fcd081865478d9f799cdb6cab2089/artifacts/<file>/artifacts/<file>.bin (Caused by ProtocolError('Connection aborted.', ConnectionResetError(54, 'Connection reset by peer')))
```
And the mlflow server logs are the following:

```
app_1       | [2023-11-10 12:51:54 +0000] [26] [DEBUG] PUT /api/2.0/mlflow-artifacts/artifacts/1/9f5fcd081865478d9f799cdb6cab2089/artifacts/<file>/artifacts/<file>.bin
app_1       | [2023-11-10 12:52:03 +0000] [77] [DEBUG] POST /ajax-api/2.0/mlflow/runs/search
app_1       | [2023-11-10 12:52:18 +0000] [61] [DEBUG] POST /ajax-api/2.0/mlflow/runs/search
app_1       | [2023-11-10 12:52:25 +0000] [16] [CRITICAL] WORKER TIMEOUT (pid:26)
app_1       | [2023-11-10 12:52:25 +0000] [26] [INFO] Worker exiting (pid: 26)
app_1       | [2023-11-10 12:52:25 +0000] [16] [ERROR] Worker (pid:26) exited with code 1
app_1       | [2023-11-10 12:52:25 +0000] [16] [ERROR] Worker (pid:26) exited with code 1.
```",experienced similar issue sure whether cause also setup scenario similar scenario artifact storage storage tried local dev setup end setup like following maybe python run pip install extra expose server bucket docker compose version image restart environment command logging everything restart always image environment command server build context environment lot setting trying large file get following error client request exception file file aborted reset peer server following put file file post post critical worker worker error worker code error worker code,issue,negative,positive,positive,positive,positive,positive
1805128641,"> we can open a feature branch

+1! Let's wait with merging to master until the feature is complete and while the changes might cause [problems](https://github.com/mlflow/mlflow/pull/10169#discussion_r1387601374) with OSS>DB reimport",open feature branch let wait master feature complete might cause reimport,issue,negative,positive,neutral,neutral,positive,positive
1804796167,"In my case I had to both switch from `--default-artifact-root` to `--artifacts-destination` and create a new experiment, which appears to be related to the note in the docs [here](https://www.mlflow.org/docs/latest/tracking.html#scenario-5-mlflow-tracking-server-enabled-with-proxied-artifact-storage-access):

> When an experiment is created, the artifact storage location from the configuration of the tracking server is logged in the experiment’s metadata. When enabling proxied artifact storage, any existing experiments that were created while operating a tracking server in non-proxied mode will continue to use a non-proxied artifact location. In order to use proxied artifact logging, a new experiment must be created. If the intention of enabling a tracking server in -serve-artifacts mode is to eliminate the need for a client to have authentication to the underlying storage, new experiments should be created for use by clients so that the tracking server can handle authentication after this migration.",case switch create new experiment related note experiment artifact storage location configuration server logged experiment artifact storage operating server mode continue use artifact location order use artifact logging new experiment must intention server mode eliminate need client authentication underlying storage new use server handle authentication migration,issue,negative,positive,positive,positive,positive,positive
1804748896,"> QQ: does this change affects the case where the same person makes consecutive commits? I think we want to cancel existing runs in that case.

nvm, just saw the above screenshot",change case person consecutive think want cancel case saw,issue,negative,neutral,neutral,neutral,neutral,neutral
1804588075,"Alternatively if we want to make sure everything is good to go before committing to master, maybe we can open a feature branch @jimmyxu-db, then we can commit to that instead of to master. I feel like there are probably a few more things to fix before this is ready-ready! (this is probably the better approach)",alternatively want make sure everything good go master maybe open feature branch commit instead master feel like probably fix probably better approach,issue,positive,positive,positive,positive,positive,positive
1803660525,"Hello, any updates on this ?
This feature would be very interesting since each step a in ML pipeline may require very different requirements (e.g: docker image with cuda enabled or not for training/inference)",hello feature would interesting since step pipeline may require different docker image,issue,negative,positive,positive,positive,positive,positive
1803565546,"A solution could be to add a new property in auth_config.ini for example:
[mlflow]
unprotected_routes = /login,/oidc_callback,/authorize",solution could add new property example,issue,negative,positive,positive,positive,positive,positive
1803546594,"> Saving the MLFlow Model -
> 
> ### In exporter_lib_v2.py
> If your using virtual environment then location is `/home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/object_detection/exporter_lib_v2.py`
> 
> ```python
> # Add return statement 
> def export_inference_graph(...):
>       ....
>       return output_saved_model_directory  # <--Here
> ```
> 
> ### In tensorflow.py
> Add separate function for saving Object Detection model by changing the signature. Same as proposed in #2396
> 
> ```python
> # You can drop the .decode(""utf-8"") as str object is returned , function is as below
> 
> def export_saved_model(original, self, *args, **kwargs):
>         def create_autologging_run():
>             autologging_run = mlflow.start_run(tags={MLFLOW_AUTOLOGGING: FLAVOR_NAME})
>             _logger.info(
>                 ""Created MLflow autologging run with ID '%s', which will store the TensorFlow""
>                 "" model in MLflow Model format"",
>                 autologging_run.info.run_id,
>             )
>         auto_end = False
>         if not mlflow.active_run():
>             global _AUTOLOG_RUN_ID
>             if _AUTOLOG_RUN_ID:
>                 _logger.info(
>                     ""Logging TensorFlow Estimator as MLflow Model to run with ID '%s'"",
>                     _AUTOLOG_RUN_ID,
>                 )
>                 try_mlflow_log(mlflow.start_run, _AUTOLOG_RUN_ID)
>             else:
>                 try_mlflow_log(create_autologging_run)
>                 auto_end = True
> 
>         serialized = original(self, *args, **kwargs)
>         try_mlflow_log(
>             log_model,
>             tf_saved_model_dir=serialized if isinstance(serialized,str) else serialized.decode(""utf-8""),   # <-- Here
>             tf_meta_graph_tags=[tag_constants.SERVING],
>             tf_signature_def_key=""serving_default"",
>             artifact_path=""model"",
>         )
>         if (
>             mlflow.active_run() is not None and mlflow.active_run().info.run_id == _AUTOLOG_RUN_ID
>         ) or auto_end:
>             try_mlflow_log(mlflow.end_run)
>         return serialized
> 
> ...
> 
> # Patch the above function
> non_managed = [... ,
>               (object_detection.exporter_lib_v2,""export_inference_graph"",export_saved_model),
>               ]
> ```
> 
> ### In exporter_main_v2.py
> Add the below import to avoid `AttributeError: module 'object_detection' has no attribute 'model_lib_v2'` error.
> 
> ```python
> from object_detection import model_lib_v2
> ```
> 
> The run your usual export command -
> 
> ```
> python object_detection/exporter_main_v2.py \
>     --input_type image_tensor \
>     --pipeline_config_path ${PIPELINE_CONFIG_PATH} \
>     --trained_checkpoint_dir ${CHECKPOINT_DIR} \
>     --output_directory ${EXPORT_MODEL_DIR}
> ```
> 
> Snapshot: For now it creates it as separate runs which should be fine I guess, filtering helps to compare.
> 
> ![image](https://user-images.githubusercontent.com/7122670/108306533-5ae77880-717a-11eb-827d-b08ea85f4e4b.png)
> 
> ![image](https://user-images.githubusercontent.com/7122670/108306672-ad289980-717a-11eb-8ac9-8bb6797c490a.png)
> 
> Hope this helps !

Hi, @mohammedayub44 may I ask if this would work on the newer version of Tensorflow object detection and MLFlow? I'm trying to follow your steps into enabling the logging of training metrics in MLFlow, but I wasn't able to do so. Thanks!",saving model virtual environment location python add return statement return add separate function saving object detection model signature python drop object returned function original self run id store model model format false global logging estimator model run id else true original self else model none return patch function add import avoid module attribute error python import run usual export command python snapshot separate fine guess filtering compare image image hope hi may ask would work version object detection trying follow logging training metric able thanks,issue,positive,positive,positive,positive,positive,positive
1803543883,"@lminer , I am facing the same issue.
Tried modifying the mlflow\models\container\scoring_server\nginx.conf file and set client_max_body_size  on line 23 and 32 too. 

Still facing the same issues:

HTTPSConnectionPool(host='XXXX', port=443): Max retries exceeded with url: /api/2.0/mlflow-artifacts/artifacts/126/16932940ed9842a4bc19191387838d91/artifacts/models/model.pkl (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:2423)')))",facing issue tried file set line still facing violation protocol,issue,negative,neutral,neutral,neutral,neutral,neutral
1803483933,"Hi, our team is waiting patiently for an official helm chart! please merge it as soon as you can.",hi team waiting patiently official helm chart please merge soon,issue,negative,neutral,neutral,neutral,neutral,neutral
1803096713,"Thank you for the explanation, yes it is possible. Then, should we group the check runs by a unique check identifier (need to figure out) and check the status of the latest run?",thank explanation yes possible group check unique check identifier need figure check status latest run,issue,positive,positive,positive,positive,positive,positive
1803084255,"> @XinEDprob Thanks for the FR. This feature doesn't exist yet.

thanks for letting me know! ",thanks feature exist yet thanks know,issue,positive,positive,positive,positive,positive,positive
1802995311,"@clarkh-ncino could you rebase to master again? The issues that you're encountering should be resolved (you'll also need to fix those lint failures, though with import ordering and the black formatting issues). If you run the pre-commit hook (`pre-commit run --all-files`, as mentioned in https://github.com/mlflow/mlflow/blob/master/CONTRIBUTING.md#python ) ",could rebase master resolved also need fix lint though import black run hook run,issue,negative,negative,negative,negative,negative,negative
1802793434,"> could you elaborate on why this will become an issue? Do we need to worry about the status of post-merge workflows before merging the PR?

Yes, this isn't specific to the post-merge. The same thing can happen to other jobs. Imagine the following scenario:

1. Make a commit
2. Push the commit
3. Make another commit
4. Push it
5. Revert the second commit locally
6. Do a force-push

After this, the first commit two runs for each job. The first run could be canceled. If so, that would block automerge because cancled is not skipped or success.",could elaborate become issue need worry status yes specific thing happen imagine following scenario make commit push commit make another commit push revert second commit locally first commit two job first run could would block success,issue,positive,positive,positive,positive,positive,positive
1802773444,"Can we apply the theme to the experiment list?

<img width=""1296"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/17039389/406a0043-644b-4de8-ab19-398cec0e99c3"">
",apply theme experiment list image,issue,negative,neutral,neutral,neutral,neutral,neutral
1802686598,"@chenmoneygithub Oh thanks for your PR! Sorry for my delay, I got caught up in other things... I left few comments in the code, where I would have done things differently, but most of it looks good to me:+1:",oh thanks sorry delay got caught left code would done differently good,issue,negative,positive,neutral,neutral,positive,positive
1802593145,"> Hi @micron1390 I think this example might help out a bit, which showcases defining a minio setup (better than using local disk from my experience) with a postgres DB configuration, all setup with docker configuration .yml and basic DockerFile specifications:
> 
> https://github.com/mlflow/mlflow/tree/master/examples/mlflow_artifacts
> 
> If you read through the README in the 2nd half (the advanced setup portion), you'll see which files in that directory are involved and you can look at the configuration setup within https://github.com/mlflow/mlflow/blob/master/examples/mlflow_artifacts/docker-compose.yml to see how things are setup :)

Hi @BenWilson2 Thanks for your reply
I deployed docker-compose: [https://github.com/mlflow/mlflow/tree/master/examples/mlflow_artifacts](https://github.com/mlflow/mlflow/tree/master/examples/mlflow_artifacts)

```
# Build services
$ docker-compose build

# Launch tracking and artifacts servers in the background
$ docker-compose up -d

# Run `example.py` in the client container
$ docker-compose run -v ${PWD}/example.py:/app/example.py client python example.py
```

but when I run the model experiment, I get an error saving artifacts:
```
mlflow run . --experiment-name=lr_test2 --run-name=first_run
```

```
Traceback (most recent call last):
  File ""train.py"", line 18, in <module>
    mlflow.sklearn.log_model(lr, ""model"", signature=signature)
  File ""/home/user/.mlflow/envs/mlflow-5dbdec5f659320e5e6956110ef10edf5e2a822f6/lib/python3.8/site-packages/mlflow/sklearn/__init__.py"", line 411, in log_model
    return Model.log(
  File ""/home/user/.mlflow/envs/mlflow-5dbdec5f659320e5e6956110ef10edf5e2a822f6/lib/python3.8/site-packages/mlflow/models/model.py"", line 620, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File ""/home/user/.mlflow/envs/mlflow-5dbdec5f659320e5e6956110ef10edf5e2a822f6/lib/python3.8/site-packages/mlflow/tracking/fluent.py"", line 1008, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File ""/home/user/.mlflow/envs/mlflow-5dbdec5f659320e5e6956110ef10edf5e2a822f6/lib/python3.8/site-packages/mlflow/tracking/client.py"", line 1188, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File ""/home/user/.mlflow/envs/mlflow-5dbdec5f659320e5e6956110ef10edf5e2a822f6/lib/python3.8/site-packages/mlflow/tracking/_tracking_service/client.py"", line 538, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File ""/home/user/.mlflow/envs/mlflow-5dbdec5f659320e5e6956110ef10edf5e2a822f6/lib/python3.8/site-packages/mlflow/store/artifact/http_artifact_repo.py"", line 45, in log_artifacts
    self.log_artifact(os.path.join(root, f), artifact_dir)
  File ""/home/user/.mlflow/envs/mlflow-5dbdec5f659320e5e6956110ef10edf5e2a822f6/lib/python3.8/site-packages/mlflow/store/artifact/http_artifact_repo.py"", line 28, in log_artifact
    resp = http_request(
  File ""/home/user/.mlflow/envs/mlflow-5dbdec5f659320e5e6956110ef10edf5e2a822f6/lib/python3.8/site-packages/mlflow/utils/rest_utils.py"", line 120, in http_request
    raise MlflowException(f""API request to {url} failed with exception {e}"")
mlflow.exceptions.MlflowException: API request to http://artifacts-server:5500/api/2.0/mlflow-artifacts/artifacts/experiments/3/d3a02e2e3c4441c6bc2a1c893f5a18c5/artifacts/model/model.pkl failed with exception HTTPConnectionPool(host='artifacts-server', port=5500): Max retries exceeded with url: /api/2.0/mlflow-artifacts/artifacts/experiments/3/d3a02e2e3c4441c6bc2a1c893f5a18c5/artifacts/model/model.pkl (Caused by NameResolutionError(""<urllib3.connection.HTTPConnection object at 0x7fe65fe308e0>: Failed to resolve 'artifacts-server' ([Errno -2] Name or service not known)""))
2023/11/08 21:51:26 ERROR mlflow.cli: === Run (ID 'd3a02e2e3c4441c6bc2a1c893f5a18c5') failed ===
```
I took the experiment from here:
[https://github.com/mlflow/mlflow/tree/master/examples/sklearn_logistic_regression](https://github.com/mlflow/mlflow/tree/master/examples/sklearn_logistic_regression)



Please help me figure it out

many thanks.",hi micron think example might help bit setup better local disk experience configuration setup docker configuration basic read half advanced setup portion see directory involved look configuration setup within see setup hi thanks reply build build launch background run client container run client python run model experiment get error saving run recent call last file line module model file line return file line log file line file line file line file line root file line resp file line raise request exception request exception object resolve name service known error run id took experiment please help figure many thanks,issue,positive,positive,positive,positive,positive,positive
1802522199,"Wrong command was executed. Closing it as it got solved

--artifacts-destination instead of --default-artifact-root :)",wrong command executed got instead,issue,negative,negative,negative,negative,negative,negative
1802388990,@harupy please take a quick look at this fix :D,please take quick look fix,issue,negative,positive,positive,positive,positive,positive
1802386391,"@harupy , I saw your name repeatedly on similar tickets. Could you please take a look at this please? :)

https://github.com/mlflow/mlflow/issues/6233
https://github.com/mlflow/mlflow/issues/6181",saw name repeatedly similar could please take look please,issue,positive,neutral,neutral,neutral,neutral,neutral
1802380953,"I am facing a similar situation (GCP not AWS).

Has your issue got sorted @zstern ?

https://github.com/mlflow/mlflow/issues/10326",facing similar situation issue got sorted,issue,negative,neutral,neutral,neutral,neutral,neutral
1802338715,"From stack trace:
`/bin/sh: 2: python: not found`

Solved by:
`sudo apt install python-is-python3`

Sorry.",stack trace python found apt install sorry,issue,negative,positive,neutral,neutral,positive,positive
1802224856,Please also give me a try @BenWilson2 ,please also give try,issue,negative,neutral,neutral,neutral,neutral,neutral
1801598977,"@harupy Sorry, would you mind taking a look at this PR?",sorry would mind taking look,issue,negative,negative,negative,negative,negative,negative
1800323030,"Wanted to +1 having a pyspark version for Recipes.  

Relatedly, Recipe current has an assumption that each step persists it's output (to local disk but maybe can be tricked to use cloud storage like s3).  That assumption is kind of annoying in a pyspark world.  E.g., my dataset might have > 1 billion rows and writing the data out after ingest, split, and transform is highly inefficient.  I do like the option to have each step persist it's data, but the ability to also just feed data from one stage to the next would be great.",version recipe current assumption step output local disk maybe use cloud storage like assumption kind annoying world might billion writing data ingest split transform highly inefficient like option step persist data ability also feed data one stage next would great,issue,positive,positive,positive,positive,positive,positive
1799197688,"That's a good point. I'll work on #2. Regarding the first issue of multiple checks, could you elaborate on why this will become an issue? Do we need to worry about the status of `post-merge` workflows before merging the PR?",good point work regarding first issue multiple could elaborate become issue need worry status,issue,negative,positive,positive,positive,positive,positive
1799095498,"Hi there, has there been any progress on this? I am trying to compare two models trained in different directories (and therefore with slightly different directory structures when saving the models with the `code_path` parameters. In my current set up, I am unable to load the two models within the same file without the second model defaulting to use the modules loaded by the first model rather than its own. 

I can resolve the issue for now by removing the modules from the path as suggested above:
```python
for key in list(sys.modules.keys()):
    value = sys.modules[key]
    if 'tmp' in str(value):
        sys.modules.pop(key)
```
However this doesn't seem to be the most user-friendly solution as I think most users would assume you could load models from different locations without issue. 

```
mlflow == 2.6.0
python == 3.10.13
```",hi progress trying compare two trained different therefore slightly different directory saving current set unable load two within file without second model use loaded first model rather resolve issue removing path python key list value key value key however seem solution think would assume could load different without issue python,issue,positive,negative,neutral,neutral,negative,negative
1798545407,"Hi @BenWilson2,
Could you have a look?
Test cases are broken.
I think renaming the function of `tests.utils.test_file_utils` might fix the issue.
It would be great if you could give me suggestions.",hi could look test broken think function might fix issue would great could give,issue,negative,positive,positive,positive,positive,positive
1798366403,I would like to work on creating the tutorials / guides mentioned . Could you assign me the same @BenWilson2  . Thankyou,would like work could assign,issue,negative,neutral,neutral,neutral,neutral,neutral
1798349813,"I'm still running into this issue using the latest 2.7.1 official docker image. I have tried setting `default_permission = NO_PERMISSIONS` in `basic_auth.ini` and although when logging in with the new user I cannot view previous experiments I can still create new ones
",still running issue latest official docker image tried setting although logging new user view previous still create new,issue,negative,positive,positive,positive,positive,positive
1798313276,"It seems like mlflow was incorrectly installed using pip

Dont use
pip install mlflow
or pip install -r requirements.txt

Solution
```
conda uninstall mlflow
conda install -c conda-forge mlflow==1.30.0
```
",like incorrectly pip dont use pip install pip install solution install,issue,positive,neutral,neutral,neutral,neutral,neutral
1797097200,"@TomeHirata I found a few more issues in the current implementation.

1. It's possible that a single commit ref have multiple check runs for a single job. For example, two runs for the `post-merge` workflow (canceled one + succeded one).
2. CircleCI checks are not check runs. They are commit statues. We need to use a different GitHub API.
",found current implementation possible single commit ref multiple check single job example two one one check commit need use different,issue,positive,negative,neutral,neutral,negative,negative
1797095579,"The fix (well, removing it) has been deployed. Thanks again for reporting the issue! ",fix well removing thanks issue,issue,positive,positive,positive,positive,positive,positive
1797077199,@ss8319 Could you rename your file to a different name other than `mlflow.py`? I can't repro your problem in a python repl,could rename file different name ca problem python,issue,negative,neutral,neutral,neutral,neutral,neutral
1797071313,"> Note: tags were never logged
> 
> ```
>         mlflow.log_input(dataset, context=""cecilia_evaluation"", tags={""version"": version, ""path"" : path})
> ```
> 
> <img alt=""image"" width=""1333"" src=""https://user-images.githubusercontent.com/614804/270749574-6b64eb33-f4fe-4e86-afc6-fa32a6b790fb.png"">

@mohitanchlia I think this tag you set is on the dataset, but the tags section on this page is for the run. If you set a tag to the run, you'll see it displaying here.",note never logged version version path path image think tag set section page run set tag run see,issue,negative,neutral,neutral,neutral,neutral,neutral
1797041983,"> I have the same bug, tags are never logged:
> 
> ```
> import pandas as pd
> 
> df = pd.DataFrame({'a': [1, 2, 3]})
> dataset = mlflow.data.from_pandas(df, source='some/path')
> 
> with mlflow.start_run():
>     mlflow.log_input(dataset, tags={'my-key': 'my-value'})
> 
> run = mlflow.get_run(mlflow.last_active_run().info.run_id)
> dataset_info = run.inputs.dataset_inputs[0].dataset
> print(dataset_info)
> ```
> 
> Tag `my-key` was not logged:
> 
> ```
> <Dataset: digest='c247459b', name='dataset', profile='{""num_rows"": 3, ""num_elements"": 3}', schema='{""mlflow_colspec"": [{""type"": ""long"", ""name"": ""a""}]}', source=('{""tags"": {""mlflow.user"": ""elenav"", ""mlflow.source.name"": ""-c"", '
>  '""mlflow.source.type"": ""LOCAL""}}'), source_type='code'>
> ```

@elenavolkova93  If you update your code like:
```
dataset_info = run.inputs.dataset_inputs[0]
print(dataset_info)
```

It would be
```
<DatasetInput: dataset=<Dataset: digest='c247459b', name='dataset', profile='{""num_rows"": 3, ""num_elements"": 3}', schema='{""mlflow_colspec"": [{""type"": ""long"", ""name"": ""a"", ""required"": true}]}', source='{""uri"": ""some/path""}', source_type='local'>, tags=[<InputTag: key='my-key', value='my-value'>]>
```
And it contains tags.",bug never logged import run print tag logged type long name local update code like print would type long name true,issue,positive,positive,neutral,neutral,positive,positive
1796853385,"I'm not opposed to making this change if we need this **right now**. Otherwise, I'd seek a solution that doesn't require us to write CSS or JS.",opposed making change need right otherwise seek solution require u write,issue,negative,positive,positive,positive,positive,positive
1796130195,"If we want to go ahead with it I think it'd be fine, but as mentioned offline it might be good to set a lower max-width on `.wy-nav-content` so people with smaller screens can actually see it. I'm not sure what exactly is causing the floating TOC to show up on Pixel, but on browser I can repro by setting the window screen super small. Maybe it would help to set a reasonable min-width as well (not 100% sure that this is the cause though)?

https://github.com/mlflow/mlflow/blob/master/docs/theme/mlflow/static/css/custom.css#L31-L33
```css
.wy-nav-content {
    max-width: 900px !important; // instead of 1440px
}
```

That being said, the TOC looks a little big when the content is limited to 900px. The best solution would probably to add media queries and change all the `px` values to `rem`s to handle responsiveness, but at that point I think we should leave this for when we do the larger docs refresh

<img width=""1728"" alt=""Screenshot 2023-11-06 at 11 21 15 AM"" src=""https://github.com/mlflow/mlflow/assets/148037680/d2fbbd93-2eb1-4be3-a9fc-3c058d5590fc"">",want go ahead think fine might good set lower people smaller actually see sure exactly causing floating show browser setting window screen super small maybe would help set reasonable well sure cause though important instead said little big content limited best solution would probably add medium change handle responsiveness point think leave refresh,issue,positive,positive,positive,positive,positive,positive
1796113436,I like this change in general but I agree with @harupy that it would be ideal if we had a theme that gave this to us for free (and handles things like responsiveness etc) as I worry the current implementation might be fragile/cause some regressions like in the case of mobile rendering (fwiw it looks fine on iPhone),like change general agree would ideal theme gave u free like responsiveness worry current implementation might like case mobile rendering fine,issue,positive,positive,positive,positive,positive,positive
1796044172,@BenWilson2 @chenmoneygithub anything I can do here to help move this forward? Think we just need to kick of the CI build. ,anything help move forward think need kick build,issue,negative,neutral,neutral,neutral,neutral,neutral
1795721420,"> Another solution I found:

@harupy Thanks for the research! This looks clean to me, I'd probably add color like this;

<img width=""542"" alt=""Screenshot 2023-11-06 at 9 48 43"" src=""https://github.com/mlflow/mlflow/assets/31463517/39ff42d6-c33a-4544-975d-95ebf76f5ccb"">

WDYT @daniellok-db, @serena-ruan ?",another solution found thanks research clean probably add color like,issue,positive,positive,positive,positive,positive,positive
1795347037,"Hi @Gekko0114 I'd split that up into two different PRs :) But anything that you notice that is a 'generic' test fixture (used by multiple modules), is a candidate for consolidating as a utility fixture. ",hi split two different anything notice test fixture used multiple candidate utility fixture,issue,negative,neutral,neutral,neutral,neutral,neutral
1794817876,"Hi @BenWilson2 ,

I want to clarify what I should do.

Should I simply move this code to `tests.utils.test_file_utils` ?
```python
@pytest.fixture(scope=""module"")
def spark_session():
    with SparkSession.builder.master(""local[*]"").getOrCreate() as session:
        yield session
```
Or should I work on other functions as well, like get_iris? Seems that all three files you mentioned use iris dataset.
```python
def get_iris():
    iris = sklearn.datasets.load_iris()
    return iris.data, iris.target
```

",hi want clarify simply move code python module local session yield session work well like three use iris python iris return,issue,positive,neutral,neutral,neutral,neutral,neutral
1794702344,"Same problem, my disk space run out, MLflow crashed and now produces this error for the run",problem disk space run error run,issue,negative,neutral,neutral,neutral,neutral,neutral
1794691549,By any chance does Model Registry support file based storage now?,chance model registry support file based storage,issue,positive,neutral,neutral,neutral,neutral,neutral
1794497867,@harupy I saw your PR was correctly merged after approving it. Please let me know if any further tests/modifications are needed. 🙏 ,saw correctly please let know,issue,negative,neutral,neutral,neutral,neutral,neutral
1794249104,@harupy I added a section in tracking.rst for mpu documentation. I believe this PR is ready for review ,added section documentation believe ready review,issue,negative,positive,positive,positive,positive,positive
1793735166,"> AttributeError: 'MlflowClient' object has no attribute 'list_run_infos', Please suggest

can use client.search_runs
https://mlflow.org/docs/latest/search-runs.html",object attribute please suggest use,issue,negative,neutral,neutral,neutral,neutral,neutral
1793733461,"AttributeError: 'MlflowClient' object has no attribute 'list_run_infos', 
Please suggest",object attribute please suggest,issue,negative,neutral,neutral,neutral,neutral,neutral
1792928599,"I am having a similar issue (same error message) where mlflow client 1.30 (I have to use python=3.7 for a package), cannot register a model in mlflow server 2.2.2(logging works). What I did was to copy - paste the code from mlflow.protos.model_registry_pb2.py (version 2.8.0) and from mlflow.store.model.model_registry_pb2.py delete the import ""ListRegisteredModels"" and I manage to solve it. Not sure though if this ""fix"" will cause other issues, apologies I am not so experienced. Any ideas how to substitute these two files without changing the original ones?",similar issue error message client use package register model server logging work copy paste code version delete import manage solve sure though fix cause experienced substitute two without original,issue,negative,positive,positive,positive,positive,positive
1792907180,"> @shraddha761 You can click on ""sign off and commit suggestion"", which directly applies the suggestion to the remote branch. Then you can run `git pull` to pull the change to your local branch.

DONE.",shraddha click sign commit suggestion directly suggestion remote branch run git pull pull change local branch done,issue,negative,neutral,neutral,neutral,neutral,neutral
1792861216,"I have the same bug, tags are never logged:
```
import pandas as pd

df = pd.DataFrame({'a': [1, 2, 3]})
dataset = mlflow.data.from_pandas(df, source='some/path')

with mlflow.start_run():
    mlflow.log_input(dataset, tags={'my-key': 'my-value'})

run = mlflow.get_run(mlflow.last_active_run().info.run_id)
dataset_info = run.inputs.dataset_inputs[0].dataset
print(dataset_info)
```

Tag `my-key` was not logged:

```
<Dataset: digest='c247459b', name='dataset', profile='{""num_rows"": 3, ""num_elements"": 3}', schema='{""mlflow_colspec"": [{""type"": ""long"", ""name"": ""a""}]}', source=('{""tags"": {""mlflow.user"": ""elenav"", ""mlflow.source.name"": ""-c"", '
 '""mlflow.source.type"": ""LOCAL""}}'), source_type='code'>
```",bug never logged import run print tag logged type long name local,issue,negative,negative,neutral,neutral,negative,negative
1792663024,"Related to this, how does mlflow decide the current color scheme? I'm getting completely overlapping colors :( 

![image](https://github.com/mlflow/mlflow/assets/777910/ddb9f2fd-d2e6-451a-8ca3-00cf248b2007)
",related decide current color scheme getting completely color image,issue,negative,positive,neutral,neutral,positive,positive
1792418537,"@lightnessofbein feel free to take this one, I don't have bandwidth to knock it out in the immediate future. ",feel free take one knock immediate future,issue,positive,positive,positive,positive,positive,positive
1792194517,"+1 @claudiofernandez ; please add back ""Show diffs"". Very important feature in practice. @harupy ",please add back show important feature practice,issue,negative,positive,positive,positive,positive,positive
1791828314,"Done, hope I didn't break anything.",done hope break anything,issue,negative,neutral,neutral,neutral,neutral,neutral
1791784468,"@chenmoneygithub here's the quickstart that I was talking about :) LMK what you think about the pacing, depth of content, and how it's presented with navigation elements!",talking think depth content navigation,issue,negative,neutral,neutral,neutral,neutral,neutral
1791759232,"> Thanks Ben, I checked the rendered page, and it looks great!
> 
> One thing I have been thinking about: shall we instead of showing tiles for quickstart 1 and quickstart 2, we just put itself in a tile? I feel it's odd to start reading the quickstart from a certain section: https://output.circle-artifacts.com/output/job/20663c13-c8a4-4b1a-b506-d8d66122e6fc/artifacts/0/docs/build/html/getting-started/index.html#id2

We'll be replacing both of these sections with a new ""Quickstart"" section at the top where the new Tracking Quickstart, the AutoLogging Quickstart, and the Logging Quickstart will go :D we'll do that as part of the post-hackathon work :) ",thanks ben checked page great one thing thinking shall instead showing put tile feel odd start reading certain section new section top new logging go part work,issue,positive,positive,positive,positive,positive,positive
1791749822,"Another solution I found:

```diff
diff --git a/conftest.py b/conftest.py
index a57d125f4e..8a791f773c 100644
--- a/conftest.py
+++ b/conftest.py
@@ -8,6 +8,7 @@ import sys
 import click
 import pytest
 
+from mlflow.version import VERSION
 from mlflow.environment_variables import _MLFLOW_TESTING, MLFLOW_TRACKING_URI
 
 from tests.helper_functions import get_safe_port
@@ -221,6 +222,16 @@ def pytest_terminal_summary(
         terminalreporter.write("" "".join([""pytest""] + ids))
         terminalreporter.write(""\n"" * 2)
 
+        msg = f""No matching distribution found for mlflow=={VERSION}""
+        for rep in failed_test_reports:
+            for text in (rep.longreprtext, rep.capstdout, rep.capstderr):
+                if msg in text:
+                    terminalreporter.section(""HINTS"", yellow=True)
+                    terminalreporter.write(
+                        f""Found test(s) that failed with {msg!r}. `--serve-wheel` flag may help.\n\n""
+                    )
+                    break
+
```",another solution found git index import import click import import version import import matching distribution found version rep text text found test flag may break,issue,negative,neutral,neutral,neutral,neutral,neutral
1791708686,@TomeHirata Thanks for working on this! I'll insert a few console.log to make it easier to investigate a bug. I'll merge the PR after that.,thanks working insert make easier investigate bug merge,issue,positive,positive,positive,positive,positive,positive
1791610655,"@shraddha761 You can click on ""sign off and commit suggestion"", which directly applies the suggestion to the remote branch. Then you can run `git pull` to pull the change to your local branch. ",shraddha click sign commit suggestion directly suggestion remote branch run git pull pull change local branch,issue,negative,neutral,neutral,neutral,neutral,neutral
1791553798,"@princerajpoot20 Thanks for the PR! I went through the change and many of them are not necessary. If you are looking for something to get started with contributing to MLflow, would you be interested in https://github.com/mlflow/mlflow/issues/9744?",thanks went change many necessary looking something get would interested,issue,positive,positive,positive,positive,positive,positive
1791057533,@harupy Thank you for your considerate help. Please merge this PR when you have time.,thank considerate help please merge time,issue,positive,neutral,neutral,neutral,neutral,neutral
1790480961,"Sure, I can do that in the next few days once I find some time for it :)",sure next day find time,issue,negative,positive,positive,positive,positive,positive
1790356937,@harupy What do you think is the next step? Can we just sort out some of the code or do we still need any testing?,think next step sort code still need testing,issue,negative,neutral,neutral,neutral,neutral,neutral
1790101642,"Sure:
```python
from pathlib import Path
import tensorflow as tf
import mlflow

output_path = Path(""/tmp/results"")
mlflow_path = output_path / ""mlflow""
mlflow.set_tracking_uri(mlflow_path)

model = tf.keras.Sequential([tf.keras.Input(1)])

with mlflow.start_run() as run:
    mlflow.tensorflow.log_model(
        model,
        artifact_path=""model"",
        registered_model_name=f""{run.info.run_id}"",
    )
```
In the meantime, I did some more analysis regarding specific conditions under which the error occurs:
- the error happens when outputting to ""/tmp"", not when using, e. g., `output_path = Path(""./results"")`
- the error only happens when setting the `registered_model_name` parameter to `run.info.run_id`. Using, e. g., `registered_model_name=f""{run.info.run_id}_""` does not trigger the error.",sure python import path import import path model run model model analysis regarding specific error error path error setting parameter trigger error,issue,negative,positive,positive,positive,positive,positive
1790088962,"@g-malamud thanks for filing this! This is a known limitation of the Unity Catalog model registry in Databricks. Due to performance constraints, we don't currently return aliases in model version search responses. We hope to implement this in the future.",thanks filing known limitation unity model registry due performance currently return model version search hope implement future,issue,positive,positive,neutral,neutral,positive,positive
1790020242,"Got it. Let's tets `pytest_exception_interact`. If it works, let's use it!",got let work let use,issue,negative,neutral,neutral,neutral,neutral,neutral
1790017617,"> What if the error appears in stdout or stderr?

We still need to set `capture_output` to True, for `_exec_cmd` call, is there any harm doing that?",error still need set true call harm,issue,negative,positive,positive,positive,positive,positive
1790007866,"> I'm not a big fan of adding another code path just for a flag that's only used for testing.

That's fair. A little concern on visibility as that summary area is a bit dense. How about using `pytest_exception_interact` hook, which effectively override exception during pytest, without messing up main logic. Haven't used that but sounds best fit for what we want to do?",big fan another code path flag used testing fair little concern visibility summary area bit dense hook effectively override exception without messing main logic used best fit want,issue,positive,positive,positive,positive,positive,positive
1790000666,"@B-Step62 Can we just display a message like this?

<img width=""931"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/17039389/23ba9993-3b2f-4a7e-93d6-e1fcd7574995"">

<details><summary>Code</summary>
<p>


```diff
diff --git a/conftest.py b/conftest.py
index 8c6350b253..7808b01457 100644
--- a/conftest.py
+++ b/conftest.py
@@ -220,6 +220,14 @@ def pytest_terminal_summary(
         terminalreporter.write("" "".join([""pytest""] + ids))
         terminalreporter.write(""\n"" * 2)
 
+    terminalreporter.section(""Advice"", green=True)
+    terminalreporter.write(
+        """"""\
+If your test failed with `No matching distribution found for mlflow==2.8.1.dev0`, try using the `--serve-wheel` flag.
+
+"""""",
+    )
+
```

</p>
</details> 

I'm not a big fan of adding another code path just for a flag that's only used for testing.",display message like image summary code git index advice test matching distribution found dev try flag big fan another code path flag used testing,issue,positive,neutral,neutral,neutral,neutral,neutral
1789839501,Current failing test is due to minio image issue. Examples pass :) ,current failing test due image issue pas,issue,negative,negative,neutral,neutral,negative,negative
1789833638,"Hi @renata-gotler would you be at all interested in adding this as a note within models.rst in the docs? This seems very helpful (and also, thank you for self-reporting your finding! :D ) 
The place to edit to add a note would be here: https://github.com/mlflow/mlflow/blob/15d7c73a3891021f1d3a7755022ff2ca82e3a87e/docs/source/models.rst?plain=1#L2578 

Feel free to tag me on the PR directly if you submit it! ",hi would interested note within helpful also thank finding place edit add note would feel free tag directly submit,issue,positive,positive,positive,positive,positive,positive
1789830218,@jerrylian-db could you shed some insight here? Thanks!,could shed insight thanks,issue,negative,positive,positive,positive,positive,positive
1789829854,"Hi @micron1390 I think this example might help out a bit, which showcases defining a minio setup (better than using local disk from my experience) with a postgres DB configuration, all setup with docker configuration .yml and basic DockerFile specifications: 

https://github.com/mlflow/mlflow/tree/master/examples/mlflow_artifacts

If you read through the README in the 2nd half (the advanced setup portion), you'll see which files in that directory are involved and you can look at the configuration setup within https://github.com/mlflow/mlflow/blob/master/examples/mlflow_artifacts/docker-compose.yml to see how things are setup :) ",hi micron think example might help bit setup better local disk experience configuration setup docker configuration basic read half advanced setup portion see directory involved look configuration setup within see setup,issue,positive,positive,positive,positive,positive,positive
1789822847,"The python test failure doesn't come from this change, unfortunately hit issue from latest minio release; https://github.com/minio/minio/issues/18372

There is an open PR for pinning container version: https://github.com/mlflow/mlflow/pull/10268",python test failure come change unfortunately hit issue latest release open pinning container version,issue,negative,negative,neutral,neutral,negative,negative
1789815750,Hi @sfo thank you for reporting. Do you have a simple repro that we can take a look at?,hi thank simple take look,issue,negative,neutral,neutral,neutral,neutral,neutral
1789812530,"Hi @Rocha-a21906962 could you take a look at the API docs to see how datasets are logged with this API? You'll need to wrap your data in a function call :) 

https://www.mlflow.org/docs/latest/python_api/mlflow.html#mlflow.log_input ",hi could take look see logged need wrap data function call,issue,negative,neutral,neutral,neutral,neutral,neutral
1789552890,"Just confirmed that the multiple releases today are all failing with an inability to respond to health checks. Disabling the health check polling and putting a wait statement in to validate the service is up and running returns an authentication error with communicating with the minio service running at port 9000. 
Looks like there are some serious issues with their container images right now. ",confirmed multiple today failing inability respond health health check polling wait statement validate service running authentication error communicating service running port like serious container right,issue,negative,positive,neutral,neutral,positive,positive
1789260690,I got this error while executing a python file in a venv environment. ,got error python file environment,issue,negative,neutral,neutral,neutral,neutral,neutral
1789230734,"Local build:

```bash
mlflow/docker on  add-gcc-for-build [$!] on 🐳 v24.0.6 via 🅒 mlflow-dev-env took 17s
➜ docker build --build-arg VERSION=""2.8.0"" -t test-image-name .

[+] Building 0.5s (7/7) FINISHED
 => [internal] load build definition from Dockerfile                                                                                                                                       0.0s
 => => transferring dockerfile: 242B                                                                                                                                                       0.0s
 => [internal] load .dockerignore                                                                                                                                                          0.0s
 => => transferring context: 2B                                                                                                                                                            0.0s
 => [internal] load metadata for docker.io/library/python:3.10-slim-bullseye                                                                                                               0.5s
 => [1/3] FROM docker.io/library/python:3.10-slim-bullseye@sha256:829bfd6812e20121a26a14bc419b375ee405d1c24dc252f9b740637c4701b122                                                         0.0s
 => CACHED [2/3] RUN apt-get update &&     apt-get install -y gcc &&     apt-get clean &&     rm -rf /var/lib/apt/lists/*                                                                  0.0s
 => CACHED [3/3] RUN pip install --no-cache mlflow==2.8.0                                                                                                                                  0.0s
 => exporting to image                                                                                                                                                                     0.0s
 => => exporting layers                                                                                                                                                                    0.0s
 => => writing image sha256:55c538f7e9dc68956cd8bdb8ef7c041733017495e0f0739991199352edbe0c87                                                                                               0.0s
 => => naming to docker.io/library/test-image-name:latest                                                                                                                                  0.0s
(mlflow-dev-env)
```",local build bash via took docker build building finished internal load build definition transferring internal load transferring context internal load sha run update install clean run pip install image writing image sha naming latest,issue,negative,positive,positive,positive,positive,positive
1788840469,"Yes, feel free to add commits",yes feel free add,issue,positive,positive,positive,positive,positive,positive
1788762509,"> I think json_format comes from an ancient mlflow. pip tries to resolve mlflow and cloudpickle==3.0, and ends up installing an old version of mlflow.

That makes sense, some MLflow 1.x doc mentions about `json_format` ([ref](https://mlflow.org/docs/1.3.0/python_api/mlflow.models.html#mlflow.models.FlavorBackend.predict)). Thanks for the quick investigation!!

Will merge PR once all tests pass.",think come ancient pip resolve old version sense doc ref thanks quick investigation merge pas,issue,positive,positive,positive,positive,positive,positive
1788739389,"I think `json_format` comes from an ancient mlflow. pip tries to resolve `mlflow` and `cloudpickle==3.0`, and ends up installing an old version of mlflow.",think come ancient pip resolve old version,issue,negative,positive,neutral,neutral,positive,positive
1788730987,"I didn't update cloudpickle. The following change fixed the issue:

```diff
diff --git a/mlflow/utils/environment.py b/mlflow/utils/environment.py
index c7d7ee7478..4ab6a83c29 100644
--- a/mlflow/utils/environment.py
+++ b/mlflow/utils/environment.py
@@ -214,7 +214,7 @@ def _mlflow_conda_env(
     :return: ``None`` if ``path`` is specified. Otherwise, the a dictionary representation of the
              Conda environment.
     """"""
-    pip_deps = ([""mlflow""] if install_mlflow else []) + (
+    pip_deps = ([f""mlflow=={VERSION}""] if install_mlflow else []) + (
         additional_pip_deps if additional_pip_deps else []
     )
     conda_deps = additional_conda_deps if additional_conda_deps else []
```",update following change fixed issue git index abac return none path otherwise dictionary representation else version else else else,issue,negative,positive,neutral,neutral,positive,positive
1788704171,"> The failed test works fine on my machine.

Same, might be intermittent. Thanks for retrying.",test work fine machine might intermittent thanks,issue,positive,positive,positive,positive,positive,positive
1788692474,The failed test works fine on my machine.,test work fine machine,issue,negative,positive,positive,positive,positive,positive
1788687991,Interesting error. Where does `TypeError: _predict() missing 1 required positional argument: 'json_format'` come from?,interesting error missing positional argument come,issue,negative,positive,positive,positive,positive,positive
1788222249,"@danielyxyang Thanks for reporting the issue! Also extra kudos to the detailed information, it's very clear and helpful! 

Yes, we should start system metrics logging correctly for existing runs. Would you like to contribute a PR for that?

About resuming the steps, we should be able to use the step information from `cpu_utilization_percentage`, which is always logged. Please let me know if you want to work on it, otherwise I can fix that. Thanks!",thanks issue also extra kudos detailed information clear helpful yes start system metric logging correctly would like contribute able use step information always logged please let know want work otherwise fix thanks,issue,positive,positive,positive,positive,positive,positive
1788139809,"Hi @dvirginz MLflow 2.8 should have solved this for you.

Just wanted to follow up with some docs on MLflow 2.8 with the system metrics update.

Example: https://github.com/mlflow/mlflow/blob/master/examples/system_metrics/collect_system_metrics.py 

Docs: https://mlflow.org/docs/latest/python_api/mlflow.html?highlight=enable_system_metrics_logging#mlflow.enable_system_metrics_logging 

What's New: https://mlflow.org/docs/latest/new-features/index.html ",hi follow system metric update example new,issue,negative,positive,positive,positive,positive,positive
1787920107,"@pabitra0011, I'm not authorized to assign it, but this does look like a perfect contribution to learn the system. I would certainly recommend they do.",authorized assign look like perfect contribution learn system would certainly recommend,issue,positive,positive,positive,positive,positive,positive
1787859522,"
I am new to open source, and I'd like to start my journey by tackling a small issue. Can you please assign me to this issue?",new open source like start journey tackling small issue please assign issue,issue,positive,negative,neutral,neutral,negative,negative
1787749367,"> @BenWilson2 so changes made by me in readme need to be updated?

This guide might help to explain what is going on: https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/about-pull-requests ",made need guide might help explain going,issue,negative,neutral,neutral,neutral,neutral,neutral
1787608565,"> @BenWilson2 what type of changes i need to make in readme which you have mention

You can accept the changes within the UI OR make similar changes in your branch, commit them, and push the changes to this PR. ",type need make mention accept within make similar branch commit push,issue,positive,neutral,neutral,neutral,neutral,neutral
1787580995,@BenWilson2 what type of changes i need to make in readme which you have mention,type need make mention,issue,negative,neutral,neutral,neutral,neutral,neutral
1787558623,"> @BenWilson2 i need to make it as previous or anything else

I'm sorry, but what does that mean?",need make previous anything else sorry mean,issue,negative,negative,negative,negative,negative,negative
1787542718,@BenWilson2 i need to make it as previous or anything else,need make previous anything else,issue,negative,negative,negative,negative,negative,negative
1787541218,@jessechancy Can you make sure that you've fetched the latest version of master please?,make sure fetched latest version master please,issue,positive,positive,positive,positive,positive,positive
1787363516,"> Can we remove `sphinx-click` if it's no longer needed?

It's actually still used (purely for pydoc scraping for click) in the cli docs. ",remove longer actually still used purely scraping click,issue,negative,positive,positive,positive,positive,positive
1787286466,"> @BenWilson2 can we cherry pick this into 2.8 branch?

I'll make sure that it goes out with the redeploy today! Thanks for the fix @B-Step62 :) ",cherry pick branch make sure go redeploy today thanks fix,issue,positive,positive,positive,positive,positive,positive
1786311948,"> Does the table render find on Jupyter?

How it looks on the website is now exactly how it looks in a Jupyter Notebook. The problem was the table formatting of the output html table within nbsphinx. I followed their guide on how to override the css to get the display types to match.",table render find exactly notebook problem table output table within guide override get display match,issue,negative,positive,positive,positive,positive,positive
1786281966,"> Got it , we hardcode the options here:
> 
> https://github.com/mlflow/mlflow/blob/b61e3ce24219e402aac05ec37d09a00dff5b09c4/mlflow/server/js/src/experiment-tracking/components/runs-compare/config/RunsCompareConfigureContourChart.tsx#L144
> 
> How large number do you want to use ? We can increase it :)
> 
> On the other way, you can select any number of runs and then click ""compare"" button, then in the comparing run page, you can click `Contour Plot`, there you can see more than 20 points if you have more than 20 runs being compared.
> 
> @xtfocus

Ideally, as many as needed. Can it be a slider or a numerical input? This, at least for me, applies to most of charts",got large number want use increase way select number click compare button run page click contour plot see ideally many slider numerical input least,issue,positive,positive,positive,positive,positive,positive
1785796077,"@ DeependraParichha1004 I am also getting the same error, did you find the solution?
No, @deepakthakur-92, I'm still getting the same error!",also getting error find solution still getting error,issue,negative,neutral,neutral,neutral,neutral,neutral
1785749453,"> I was able to fix it by explicitly importing agents and huggingface_hub, even though I had already imported langchain library.
> 
> import langchain.agents
from langchain.llms import huggingface_hub

Thanks, @renata-gotler! Posting this saved me lots of debugging time. 
",able fix explicitly even though already library import import thanks posting saved lot time,issue,positive,positive,positive,positive,positive,positive
1785488134,"> We should also investigate why psutil tries to build a wheel.

psutil doesn't offer python 3.10 wheels. 

https://pypi.org/project/psutil/#files

The docker build process uses:

Operating System: Linux
Architecture: amd64 
Python Version: 3.10
Base Image: slim-bullseye 

psutil needs to be built from source for this configuration. ",also investigate build wheel offer python docker build process operating system architecture python version base image need built source configuration,issue,negative,negative,negative,negative,negative,negative
1785442600,"It looks this has been somehow improved by setting the parameter value column to varchar(8000) in 2.8.0 version. 

However I'd argue that this may still become an issue for longer prompts (those that would still fit the input token limit, e.g. 4096 tokens - not characters - for chatgpt 3.5 turbo or even with GPT4 (32K) having a 32000 token limit). 

Wouldn't it be possible to store the prompts as some unlimited text (maybe artifacts referenced from params) ?",somehow setting parameter value column version however argue may still become issue longer would still fit input token limit turbo even token limit would possible store unlimited text maybe,issue,negative,positive,positive,positive,positive,positive
1785319729,"@MajerMartin Thanks for reporting the issue. Here's a minimum repro:

```python
import mlflow
from mlflow.store.artifact.artifact_repository_registry import get_artifact_repository

mlflow.set_tracking_uri(""sqlite:///:memory:"")

with mlflow.start_run():
    mlflow.sklearn.log_model(""I am a model"", ""model"", registered_model_name=""foo"")

model_uri = f""models:/foo/1""

artifact_repository = get_artifact_repository(model_uri)
mlmodel_path = artifact_repository.download_artifacts(""MLmodel"")

```",thanks issue minimum python import import memory model model foo,issue,negative,positive,positive,positive,positive,positive
1785232605,"@harupy can you please help me here. As suggested by you,  I tested via boto3 and it is able to upload artifacts in minio but when I am trying with mlflow then its throwing same error mentioned above.

I am passing below command in deployment.yaml file:
mlflow server --host 0.0.0.0 --port 5000 --backend-store-uri mysql+pymysql://auto***:auto***@mlflow-auto***-mysql.mlflow-namespace.svc.cluster.local:3306/auto**** --gunicorn-opts --log-level debug --workers 2 --
default-artifact-root https://mlm***.corp.***.com:9000/auto***-artifacts/ --serve-artifacts",please help tested via able trying throwing error passing command file server host port auto,issue,negative,positive,positive,positive,positive,positive
1784849574,"Hi @harupy, I want to work on this. Assign me.",hi want work assign,issue,negative,neutral,neutral,neutral,neutral,neutral
1784799069,@milinddethe15 Can you prepend assert on this line: tests/metrics/genai/test_genai_metrics.py:471:5? This should fix the lint error.,assert line fix lint error,issue,negative,neutral,neutral,neutral,neutral,neutral
1784695662,"Hey, I'd like to work on this issue :)",hey like work issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1784586804,We should also investigate why psutil tries to build a wheel.,also investigate build wheel,issue,negative,neutral,neutral,neutral,neutral,neutral
1784569971,"> Question: should we add an instruction about the auto-merge label to https://github.com/mlflow/mlflow/blob/master/CONTRIBUTING.md?

Yes, we should, but we add it later as a follow-up after we confirm everything works as expected.",question add instruction label yes add later confirm everything work,issue,negative,neutral,neutral,neutral,neutral,neutral
1784437322,"@TomeHirata I found a better and simpler solution to solve the original problem. Can we close this and revisit later in the future if necessary?

--- EDIT ---

The solution may not work. Let me think.

",found better simpler solution solve original problem close revisit later future necessary edit solution may work let think,issue,positive,positive,positive,positive,positive,positive
1784424141,This is preparation to migrate to `ruff format` from `black`.,preparation migrate ruff format black,issue,negative,negative,negative,negative,negative,negative
1784207124,Latest commit works! Will re-deploy website from this build,latest commit work build,issue,negative,positive,positive,positive,positive,positive
1784154811,Question: should we add an instruction about the auto-merge label to https://github.com/mlflow/mlflow/blob/master/CONTRIBUTING.md?,question add instruction label,issue,negative,neutral,neutral,neutral,neutral,neutral
1784140427,"@DeependraParichha1004 I am also getting the same error, did you find the solution ? ",also getting error find solution,issue,negative,neutral,neutral,neutral,neutral,neutral
1783923932,"> I was able to fix it by explicitly importing agents and huggingface_hub, even though I had already imported langchain library.
> 
> import langchain.agents from langchain.llms import huggingface_hub

That solved my issue. Thanks!",able fix explicitly even though already library import import issue thanks,issue,negative,positive,positive,positive,positive,positive
1783634628,This change can lead to ImportError. Did we add tqdm as a new mlflow dependency in other PR?,change lead add new dependency,issue,negative,positive,positive,positive,positive,positive
1783401244,"@wenfeiy-db for the failing pyfunc suite test, we can probably just update it to account for this new field entry by doing something similar to this:

```python
reloaded_model_config = Model.load(os.path.join(model_path, ""MLmodel""))

    # Check if the reloaded model has a _model_size_bytes attribute that's not None
    if getattr(reloaded_model_config, ""_model_size_bytes"", None) is not None:
        model_config._model_size_bytes = reloaded_model_config._model_size_bytes

    assert model_config.__dict__ == reloaded_model_config.__dict__
```",failing suite test probably update account new field entry something similar python check model attribute none none none assert,issue,negative,positive,neutral,neutral,positive,positive
1783320222,Is there an update on the timeline to fix it? I still see this issue on mlflow-skinny==2.7.1,update fix still see issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1782940224,"@harupy I've cleaned up some of the initial settings, could you take a look?",initial could take look,issue,negative,neutral,neutral,neutral,neutral,neutral
1782869827,"Absolutely, that sounds better! I'll keep this open as reminder and come back when the branch is merged.",absolutely better keep open reminder come back branch,issue,negative,positive,positive,positive,positive,positive
1782813089,Is it possible to make this change after we merge the llm_signature branch to avoid conflicts against master?,possible make change merge branch avoid master,issue,negative,neutral,neutral,neutral,neutral,neutral
1782575885,"> @gabrielfu Have you tried MPU manually? Did it work fine?

@harupy yes tested successful

```shell
mlflow ui --artifacts-destination=s3://mlflow-mpu-test-1
```

```python
import os
import mlflow
from mlflow.store.artifact.http_artifact_repo import HttpArtifactRepository

os.environ[""MLFLOW_MULTIPART_UPLOAD_MINIMUM_FILE_SIZE""] = str(5 * 1024**2)
os.environ[""MLFLOW_MULTIPART_UPLOAD_CHUNK_SIZE""] = str(5 * 1024**2)

mlflow.set_tracking_uri(""http://127.0.0.1:5000"")
artifact_uri = mlflow.get_artifact_uri()
repo = mlflow.artifacts.get_artifact_repository(artifact_uri)
assert isinstance(repo, HttpArtifactRepository)
repo.log_artifact(""test.file"", ""my-folder"")
```

![image](https://github.com/mlflow/mlflow/assets/22888849/bf4c69c1-4911-48ea-afdf-8d33faf38d1b)
",tried manually work fine yes tested successful shell python import o import import assert image,issue,positive,positive,positive,positive,positive,positive
1782541508,@gabrielfu Have you tried MPU manually? Did it work fine?,tried manually work fine,issue,negative,positive,positive,positive,positive,positive
1782314807,"@harupy Addressed your comments!

Except for replacing the `os.walk` with `pathlib.Path.rglob`, I'l still trying to understand the reason. See [that](https://github.com/mlflow/mlflow/pull/10110#discussion_r1373978026) thread above. ",except still trying understand reason see thread,issue,negative,neutral,neutral,neutral,neutral,neutral
1782237211,Can you rebase this PR on master to run the lint check? We accidentally disabled it in https://github.com/mlflow/mlflow/pull/10179.,rebase master run lint check accidentally disabled,issue,negative,negative,negative,negative,negative,negative
1782168999,@MainRo sorry for taking so long to get around to fixing this. We're introducing an argument in save_model / log_model where you will be able to disable the external file behavior and allow you to save a model that is <2GB as a single file again. It will be available in the upcoming MLflow 2.8.0 release.,sorry taking long get around fixing argument able disable external file behavior allow save model single file available upcoming release,issue,negative,positive,neutral,neutral,positive,positive
1782125953,"@hubertzub-db Can you update `yarn.lock` to fix https://github.com/mlflow/mlflow/actions/runs/6655605769/job/18086232359?pr=10163?

EDIT
----

DONE",update fix edit done,issue,negative,neutral,neutral,neutral,neutral,neutral
1781792298,"It's looking good! Once the remaining items are addressed, we should be good to go! ",looking good good go,issue,positive,positive,positive,positive,positive,positive
1781751277,"Ahh sorry about that. Can you try running mlflow on master?
We recently fixed this issue here: https://github.com/mlflow/mlflow/pull/9709
Let me know if that helps fix the issue? ",sorry try running master recently fixed issue let know fix issue,issue,negative,negative,negative,negative,negative,negative
1781729283,I have the same issue also. Maybe it's related to the max length of the value column in params table to be set to 500? (I'm using mysql as db and I did run the upgrade db script for 2.7.1 version). ,issue also maybe related length value column table set run upgrade script version,issue,negative,neutral,neutral,neutral,neutral,neutral
1781603914,"@BenWilson2 Thanks for the quick review ! It was fun building this MLflow plugin, might integrate with model registry later as well ",thanks quick review fun building might integrate model registry later well,issue,positive,positive,positive,positive,positive,positive
1781593141,"I think it would be helpful to have a datasets section of the run comparison, and be able to see the dataset hashes in the comparison view so we can easily see what, if any, datasets have changed between runs!",think would helpful section run comparison able see comparison view easily see,issue,positive,positive,positive,positive,positive,positive
1781315989,"> (I logged the model using the code in the PR description)
> 
> ```
> curl http://127.0.0.1:5000/invocations -H 'Content-Type: application/json' \
>   -d '{
>     ""inputs"": {
>       ""arr"": [""sentence_1"", ""sentence_2""],
>       ""str"": ""some_data"",
>       ""obj"": {""a"": 1}
>              ^^^^^^^^ b is missing
>     }
>   }'
> ```
> 
> returned:
> 
> ```
> {""error_code"": ""INTERNAL_ERROR"", ""message"": ""Failed to parse data as TF serving input. Ensure that the input is a valid JSON-formatted string that conforms to the request body for TF serving's Predict API as documented at https://www.tensorflow.org/tfx/serving/api_rest#request_format_2. ""}#                                 
> ➜  mlflow git:(pr/serena-ruan/10094-1) 
> ```
> 
> * Is it possible to include missing properties in the error message?

Updated! I include error in the MlflowException message, previously it raises from the original error, but that's not visible for serving usage.",logged model code description curl missing returned message parse data serving input ensure input valid string request body serving predict git possible include missing error message include error message previously original error visible serving usage,issue,negative,negative,neutral,neutral,negative,negative
1781307536,"> > Is the windows check failing somehow related to #10133?
> 
> @egeucak it was due to a GitHub Actions stale cache. It has since been resolved in master.

@BenWilson2 I merged master onto our branch, hopefully it should work now",check failing somehow related due stale cache since resolved master master onto branch hopefully work,issue,negative,negative,negative,negative,negative,negative
1781304081,"> Is the windows check failing somehow related to #10133?

@egeucak it was due to a GitHub Actions stale cache. It has since been resolved in master.",check failing somehow related due stale cache since resolved master,issue,negative,negative,negative,negative,negative,negative
1781183436,"I was able to fix it by explicitly importing agents and huggingface_hub, even though I had already imported langchain library.

import langchain.agents
from langchain.llms import huggingface_hub",able fix explicitly even though already library import import,issue,negative,positive,positive,positive,positive,positive
1780985793,"@hubertzub-db Thanks for filing this PR! In OSS, we're still using node 16. Could this be an issue? Wondering if we should update it or not.",thanks filing still node could issue wondering update,issue,negative,positive,positive,positive,positive,positive
1780876857,"(I logged the model using the code in the PR description)

```
curl http://127.0.0.1:5000/invocations -H 'Content-Type: application/json' \
  -d '{
    ""inputs"": {
      ""arr"": [""sentence_1"", ""sentence_2""],
      ""str"": ""some_data"",
      ""obj"": {""a"": 1}
             ^^^^^^^^ b is missing
    }
  }'
```

returned:
        
```             
{""error_code"": ""INTERNAL_ERROR"", ""message"": ""Failed to parse data as TF serving input. Ensure that the input is a valid JSON-formatted string that conforms to the request body for TF serving's Predict API as documented at https://www.tensorflow.org/tfx/serving/api_rest#request_format_2. ""}#                                 
➜  mlflow git:(pr/serena-ruan/10094-1) 
```

- Is it possible to include missing properties in the error message?",logged model code description curl missing returned message parse data serving input ensure input valid string request body serving predict git possible include missing error message,issue,negative,negative,negative,negative,negative,negative
1780482461,"> > Sorry, put this as a comment earlier - but I'm confused why we want to do this. We originally introduced relevance (to context) [here](https://github.com/mlflow/mlflow/pull/9724), but intentionally split out metrics into answer relevance (which only considers the input) and faithfulness (which only considers the context) to be more consistent with RAGAS: https://docs.ragas.io/en/latest/concepts/metrics/answer_relevance.html. Were the instructions for human annotators to consider relevance to context (the definition may be different than what we are looking for with this metric)? In the case that we are adding this, we are blurring the lines between faithfulness and answer relevance and it gets more ambiguous.
> 
> Yup I thought about it. but we need something that looks into both input and context while evaluating the output. Like faithfulness for the same dataset above is 44.18604651162791%. I updated answer_relevance to do this since In my mind, faithfulness is faithfulness to the context. Most of the human eval for a RAG system to eval end to end would look at the input and the answer while considering the context. So we need one metric to replicate that? If we think it should be a new one I am happy to do that instead. Also in the correct answer_relevance, if we are not considering the context, is there a reason we have added `grading_context_columns = [""context""]` in the definition as required, that is more confusing to the users. If the context is required, the assumption is that it would be used. Let me know if I am missing something.

Sorry, there shouldn't be ""context"" here - this is my mistake (I'll put out a PR to fix it). I think if we want to add a metric for relevance to BOTH input and output we should introduce a new metric OR we should rename it to be different from RAGAS so it is clear to users that we are using a different definition than RAGAS.",sorry put comment confused want originally relevance context intentionally split metric answer relevance input faithfulness context consistent human consider relevance context definition may different looking metric case faithfulness answer relevance ambiguous thought need something input context output like faithfulness since mind faithfulness faithfulness context human rag system end end would look input answer considering context need one metric replicate think new one happy instead also correct considering context reason added context definition context assumption would used let know missing something sorry context mistake put fix think want add metric relevance input output introduce new metric rename different clear different definition,issue,positive,positive,neutral,neutral,positive,positive
1780478002,"> Sorry, put this as a comment earlier - but I'm confused why we want to do this. We originally introduced relevance (to context) [here](https://github.com/mlflow/mlflow/pull/9724), but intentionally split out metrics into answer relevance (which only considers the input) and faithfulness (which only considers the context) to be more consistent with RAGAS: https://docs.ragas.io/en/latest/concepts/metrics/answer_relevance.html. Were the instructions for human annotators to consider relevance to context (the definition may be different than what we are looking for with this metric)? In the case that we are adding this, we are blurring the lines between faithfulness and answer relevance and it gets more ambiguous.

Yup I thought about it. but we need something that looks into both input and context while evaluating the output. Like faithfulness for the same dataset above is 44.18604651162791%. I updated answer_relevance to do this since In my mind, faithfulness is faithfulness to the context. Most of the human eval for a RAG system to eval end to end would look at the input and the answer while considering the context. So we need one metric to replicate that? If we think it should be a new one I am happy to do that instead. Also in the correct answer_relevance, if we are not considering the context, is there a reason we have added `grading_context_columns = [""context""]` in the definition as required, that is more confusing to the users. If the context is required, the assumption is that it would be used. Let me know if I am missing something. 
",sorry put comment confused want originally relevance context intentionally split metric answer relevance input faithfulness context consistent human consider relevance context definition may different looking metric case faithfulness answer relevance ambiguous thought need something input context output like faithfulness since mind faithfulness faithfulness context human rag system end end would look input answer considering context need one metric replicate think new one happy instead also correct considering context reason added context definition context assumption would used let know missing something,issue,positive,positive,neutral,neutral,positive,positive
1780455957,nevermind the tests run they just take super long,run take super long,issue,positive,positive,positive,positive,positive,positive
1780393869,@daniellok-db Never mind https://github.com/mlflow/mlflow/pull/10088#discussion_r1372563253. GitHub UI got messed up after I removed the original comment.,never mind got removed original comment,issue,negative,positive,positive,positive,positive,positive
1780374518,"> Thanks @sagarsumant @chenmoneygithub - left a few comments. https://github.com/mlflow/mlflow/pull/9705/files#r1366007755 is the most significant, since it's a behavior issue with the API. I think we're close!

I don't know why this comment is showing as an unresolved review comment....",thanks left significant since behavior issue think close know comment showing unresolved review comment,issue,positive,positive,positive,positive,positive,positive
1780243951,"> > However, this also throws exception when nested array has empty sub-array, like [[""a"", ""b""], []], as it simply call _infer_colspec_type to each element recursively.
> 
> I think in this case the second element is invalid. If the column is optional, you should provide none/nan instead of an empty list.

@serena-ruan My concern was that the column itself is not empty, just a subarray of it, which might be confusing. But I agree with you overall, I'll leave it now until someone hits this edge case and reports. Thx!

> This looks good! Besides array enforcement, could we add tests for schema inference as well? Specifically`_infer_schema` or `_infer_signature` and test them in a PyFuncModel to make sure e2e works.

Gotcha. Added a case to pyfunc (`test_pyfunc_model_schema_enforcement_complex`) for e2e check, but will add a few more for those inference methods.

(btw you tagged wrong Yuki haha:p)",however also exception array empty like simply call element think case second element invalid column optional provide instead empty list concern column empty might agree overall leave someone edge case good besides array enforcement could add schema inference well specifically test make sure work added case check add inference tagged wrong,issue,positive,positive,neutral,neutral,positive,positive
1780237591,"@B-Step62 This looks good! Besides array enforcement, could we add tests for schema inference as well? Specifically`_infer_schema` or `_infer_signature` and test them in a PyFuncModel to make sure e2e works.",good besides array enforcement could add schema inference well specifically test make sure work,issue,positive,positive,positive,positive,positive,positive
1780234211,"> However, this also throws exception when nested array has empty sub-array, like [[""a"", ""b""], []], as it simply call _infer_colspec_type to each element recursively.

I think in this case the second element is invalid. If the column is optional, you should provide none/nan instead of an empty list.",however also exception array empty like simply call element think case second element invalid column optional provide instead empty list,issue,negative,negative,neutral,neutral,negative,negative
1780224991,"I've adjusted to be very similar to your feedback @BenWilson2.

Ended up keeping logic for checking for `DEFAULT` profile as I think users outside of Databricks will expect this.

Adding screenshots of testing in Databricks:

**[OLD] DBR 14.1 ML**
See that IDs are same for each cell.
<img width=""529"" alt=""dbr141ml-old"" src=""https://github.com/mlflow/mlflow/assets/80654433/dba914ae-3942-42a8-ae09-c4316b576cef"">

**[NEW] DBR 14.1 ML**
Correctly see different IDs in second cell.
<img width=""392"" alt=""dbr141ml"" src=""https://github.com/mlflow/mlflow/assets/80654433/6f07455e-dd94-406f-bed9-7544ee8f34f1"">

**[NEW] DBR 14.1 Standard**
Correctly see different IDs in second cell.
<img width=""575"" alt=""dbr141std"" src=""https://github.com/mlflow/mlflow/assets/80654433/07977fd9-9ccd-4309-a7f5-c9fbd1b6e7f3"">
",similar feedback ended keeping logic default profile think outside expect testing old see cell new correctly see different second cell new standard correctly see different second cell,issue,negative,positive,neutral,neutral,positive,positive
1780221792,Update: I'm going to remove the workspace model registry implementation for now because the backend change needs time to bake and roll out. I will land the client side change after the release cut.,update going remove model registry implementation change need time bake roll land client side change release cut,issue,negative,neutral,neutral,neutral,neutral,neutral
1780221733,@hubertzub-db Would you mind taking a look at this PR?,would mind taking look,issue,negative,neutral,neutral,neutral,neutral,neutral
1780220860,"@BenWilson2 PTAL. I added some test cases for `.bin` and `.pkl` files - let me now if there are other common types from our native flavors that we'd like to cover.

I also added try catch to avoid the failure of `get_total_size` to fail the entire `save_model` call. I'm adding the logic in each flavor's `save_model` for easier logging and readability instead of inside the get_total_size function. Let me know if it doesn't make sense to you.",added test let common native like cover also added try catch avoid failure fail entire call logic flavor easier logging readability instead inside function let know make sense,issue,negative,negative,negative,negative,negative,negative
1780125318,Is the windows check failing somehow related to #10133?,check failing somehow related,issue,negative,neutral,neutral,neutral,neutral,neutral
1780080881,"@egeucak @BenWilson2 The integration would be similar to [Huggingface TextGen Inference](https://python.langchain.com/docs/integrations/llms/huggingface_textgen_inference) with parameters:

[libs/langchain/langchain/llms/huggingface_text_gen_inference.py](https://github.com/langchain-ai/langchain/blob/3f16acc5385c9a7aa99ebeb4ae7897840d6aa6ea/libs/langchain/langchain/llms/huggingface_text_gen_inference.py#L92)

The class allows users to pass `headers` and other parameters supported by the official TGI client. TGI lacks built-in authentication features, but the official client is equipped to handle this use case, allowing TGI to be served behind authentication.

In this case, the official TGI client would serve as inspiration for the provider parameters.

I need to confirm this by testing, the client may be also compatible with [Hugging Face Inference Endpoints](https://huggingface.co/inference-endpoints).

I can prepare the PR after this one.",integration would similar inference class pas official client authentication official client handle use case behind authentication case official client would serve inspiration provider need confirm testing client may also compatible hugging face inference prepare one,issue,positive,negative,negative,negative,negative,negative
1779761864,"> > @egeucak @SDonkelaarGDD @BenWilson2 Could we add support for `headers` following the [TGI Client](https://github.com/huggingface/text-generation-inference/blob/main/clients/python/text_generation/client.py)?
> > ```python
> > # pip install text-generation
> > 
> > from text_generation import Client
> > 
> > base_url = 'Local or Hugging Face Inference Endpoints URL'
> > api_key = 'API key'
> > 
> > client = Client(
> >     base_url=base_url,
> >     headers={
> >         'Accept': 'application/json',
> >         'Content-Type': 'application/json',
> >         'Authorization': f'Bearer {api_key}',
> >     }
> > )
> > 
> > text = client.generate('Why is the sky blue?')
> > print(text.generated_text)
> > ```
> 
> Yes, we can. But currently, TGI doesn't support any authentication. I don't think it is essential, but it can be added to future-proof it. What do you think @BenWilson2

The openai provider implementation is a good reference for generating and submitting request headers for auth: https://github.com/mlflow/mlflow/blob/c468b1969aac78d3882153f5a4780d608bb12d2a/mlflow/gateway/providers/openai.py#L44-L65 . If the service doesn't support it, though, I think we can hold off on implementing it since it would just be dead code. 
When auth is natively supported in the service, adding Auth headers to the provider request is pretty trivial to implement. ",could add support following client python pip install import client hugging face inference client client text sky blue print yes currently support authentication think essential added think provider implementation good reference generating request service support though think hold since would dead code natively service provider request pretty trivial implement,issue,positive,positive,positive,positive,positive,positive
1779680528,"Some tests for Windows are failing, but it is probably not related to this change since this PR didn't touch `tests/recipes`",failing probably related change since touch,issue,negative,neutral,neutral,neutral,neutral,neutral
1779679877,"I prefer (optional) to the question mark. It's potentially confusing for the target audience of MLflow (Data Scientists and MLE, most of which are very unfamiliar with TS syntax shorthand). 

Also, the grey coloring looks fantastic. Great work! ",prefer optional question mark potentially target audience data unfamiliar syntax shorthand also grey coloring fantastic great work,issue,positive,positive,positive,positive,positive,positive
1779630937,"A few notes:

- Can the control logic flow be changed a bit? The previous implementation was somewhat straight forward with an if, else if, else scheme. The new logic here is if, else, short-circuit commands. It's a bit hard to read and would be challenging to modify in the future without a total rewrite. 

Can this be adapted to a sequential pattern of configuration check and short-circuit return iff the configuration is valid? 

- Explicit environment checks to make the logic more readable

Instead of using `exists`, can we make it explicit that we're checking the environment variables here within the .GlobalEnv?

- Use of `lapply` to define an NA collection

Can we just create a list directly with the rep(list()) command to define the list and index length?

- Final validation check is redundant. 

The previous behavior of doing a final check with a stop (raise) was a bit more straightforward and easier to read. 

- Reduce logical branching variable reassignment. 

It takes a bit of effort to follow along with what's going on when there are variable reassignments happening in different logical branches. The config reassignment makes sense, but it should be consumed immediately in this case. 

Here's a quick take on some of those suggestions (I didn't test it, but it could be a good reference for refactoring the logic to be a bit more readable):

``` r
get_databricks_config <- function(profile) {
  
  # If a profile is provided, fetch its configuration
  if (!is.na(profile)) {
    config <- get_databricks_config_for_profile(profile)
    if (databricks_config_is_valid(config)) {
      return(config)
    }
  }

  # Check for environment variables
  config <- get_databricks_config_from_env()
  if (databricks_config_is_valid(config)) {
    return(config)
  }

  # Check 'DEFAULT' profile
  config <- tryCatch({
    get_databricks_config_for_profile(""DEFAULT"")
  }, error = function(error_condition) {
    # Return known invalid config
    config <- list(host = NA, token = NA, username = NA, password = NA)
    return(config)
  })
  if (databricks_config_is_valid(config)) {
    return(config)
  }

  # When in Databricks (done last so other methods are explicit overrides)
  if (exists(""spark.databricks.token"", envir = .GlobalEnv) && 
      exists(""spark.databricks.api.url"", envir = .GlobalEnv)) {
    config_vars <- list(
      host = get(""spark.databricks.api.url"", envir = .GlobalEnv),
      token = get(""spark.databricks.token"", envir = .GlobalEnv),
      insecure = Sys.getenv(config_variable_map$insecure, ""False"")
    )
    config <- new_databricks_config(config_source = ""db_dynamic"", config_vars = config_vars)
    if (databricks_config_is_valid(config)) {
      return(config)
    }
  }

  # If no valid configuration is found by this point, raise an error
  stop(""Could not find valid Databricks configuration."")
}
```",control logic flow bit previous implementation somewhat straight forward else else scheme new logic else bit hard read would modify future without total rewrite sequential pattern configuration check return configuration valid explicit environment make logic readable instead make explicit environment within use define na collection create list directly rep list command define list index length final validation check redundant previous behavior final check stop raise bit straightforward easier read reduce logical branching variable reassignment bit effort follow along going variable happening different logical reassignment sense immediately case quick take test could good reference logic bit readable function profile profile provided fetch configuration profile profile return check environment return check profile default error function return known invalid list host na token na na password na return return done last explicit list host get token get insecure insecure false return valid configuration found point raise error stop could find valid configuration,issue,negative,positive,neutral,neutral,positive,positive
1779020975,"@BenWilson2, may I get this one please? Thanks! ",may get one please thanks,issue,positive,positive,positive,positive,positive,positive
1778993299,"@wolfier  @jsnb-devoted  guys, I am very willing to contribute but its hard for me to solve this. I dont want to make workarounds in our code. Can you help me?",willing contribute hard solve dont want make code help,issue,negative,negative,neutral,neutral,negative,negative
1778988276,"i'll leave this up for a day to see if there are any strong feelings toward `?` vs `(optional)`. If not, I'll default to `(optional)` for optional properties and no annotation for required properties",leave day see strong toward optional default optional optional annotation,issue,negative,positive,positive,positive,positive,positive
1778842109,"@serena-ruan Great work! Can you add the following in the how-this-PR-is-tested section?

1. A simpole script that logs a simple model with a signature containing arrays and objects
2. A command to serve the model
3. A quick curl command to query the model with example data",great work add following section script simple model signature command serve model quick curl command query model example data,issue,positive,positive,positive,positive,positive,positive
1778830929,"@akshaya-a Yes that's the idea. When the script is ran a few times in a row it can crash with the error linked or work just as expected, I did not found any pattern.

To run this script I used my azure work account logged into my terminal with `az login`. I got all the rights necessary on this test resource group where my ml workspace is.

Also, the script I attached is a bit different from the one on which I discovered this issue. I changed it to reproduce the bug by itself as asked in the issue template. I originally just searched artifacts on a run without updating any ID and got the issue. I attached my original script below maybe it could help you. (Always without setting the tracking URI with `mlflow.set_tracking_uri()` or `MLFLOW_TRACKING_URI`)

```python
import os
from random import random

import mlflow

region = ""westeurope""
subscription_id = ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx""
resource_group = ""myrg""
workspace_name = ""myws""

azureml_mlflow_uri = f""azureml://{region}.api.azureml.ms/mlflow/v1.0/subscriptions/{subscription_id}/resourceGroups/{resource_group}/providers/Microsoft.MachineLearningServices/workspaces/{workspace_name}""

client = mlflow.MlflowClient(tracking_uri=azureml_mlflow_uri)

run_id = ""myspecificrunid""
artifcats = client.list_artifacts(run_id=run_id)  # Crashes here
print(artifcats)
```",yes idea script ran time row crash error linked work found pattern run script used azure work account logged terminal login got necessary test resource group also script attached bit different one discovered issue reproduce bug issue template originally run without id got issue attached original script maybe could help always without setting python import o random import random import region region client print,issue,negative,negative,neutral,neutral,negative,negative
1778790113,"Thanks for the reply! Agree on (2). For (1), I'll investigate whether it's possible to build a FIPS-enabled environment.",thanks reply agree investigate whether possible build environment,issue,positive,positive,neutral,neutral,positive,positive
1778748285,"> @egeucak @SDonkelaarGDD @BenWilson2 Could we add support for `headers` following the [TGI Client](https://github.com/huggingface/text-generation-inference/blob/main/clients/python/text_generation/client.py)?
> 
> ```python
> # pip install text-generation
> 
> from text_generation import Client
> 
> base_url = 'Local or Hugging Face Inference Endpoints URL'
> api_key = 'API key'
> 
> client = Client(
>     base_url=base_url,
>     headers={
>         'Accept': 'application/json',
>         'Content-Type': 'application/json',
>         'Authorization': f'Bearer {api_key}',
>     }
> )
> 
> text = client.generate('Why is the sky blue?')
> print(text.generated_text)
> ```

Yes, we can. But currently, TGI doesn't support any authentication. I don't think it is essential, but it can be added to future-proof it. What do you think @BenWilson2 ",could add support following client python pip install import client hugging face inference client client text sky blue print yes currently support authentication think essential added think,issue,positive,neutral,neutral,neutral,neutral,neutral
1778724946,"@harupy, I don't know. 

I guess there are two things that can be tested for. (1) Whether mlflow is FIPS compliant. (2) Whether unsecure algorithms are used with a `useforsecurity=True`.

(1) The only idea I have for FIPS compliance is to actually start a server configured in FIPS mode.
(2) Probably solved with ruff",know guess two tested whether compliant whether unsecure used idea compliance actually start server mode probably ruff,issue,negative,neutral,neutral,neutral,neutral,neutral
1778721983,"> Just one small thing, this change would mean if predictions is None it would return None. Let's just make sure that's the desired behaviour.

If we're going through the evaluate API, `predictions` will never be `None`. 

In the niche case that they're using this metric directly as a function, it is possible to pass `predictions` in as `None`, which results in the following behavior:

- before: we will error out if predictions is None
- after: we will return None and log an error message

Is this okay with everyone?

cc @sunishsheth2009 @annzhang-db @prithvikannan",one small thing change would mean none would return none let make sure desired behaviour going evaluate never none niche case metric directly function possible pas none following behavior error none return none log error message everyone,issue,positive,positive,neutral,neutral,positive,positive
1778718671,"> I am too (because I have written TS). Can we add a message in the column header to clarify what that means?

From a non-TS user: I vote for `(optional)` & `(required)` next to the  property name. ",written add message column header clarify user vote optional next property name,issue,negative,neutral,neutral,neutral,neutral,neutral
1778714635,"> > update, the formatting now looks like this:
> > Screen.Recording.2023-10-25.at.3.14.15.PM.mov
> > cc @dbczumar @BenWilson2 does the grey on the (optional) count as a use of color? i'm using the `secondary` color [from the design system](https://design-system.dev.databricks.com/?path=/docs/components-typography--color) so I figured it may be alright, but let me know if I should just leave it black.
> 
> Grey is great! This is awesome!
> 
> @serena-ruan can we use the same formatting for the `__repr__` of `Schema` that @daniellok-db has created in this PR? It's very nice & easy to read

Yep it's updated in this PR https://github.com/mlflow/mlflow/pull/10101. I'll update `required/optional` afterwards if needing change.",update like grey optional count use color secondary color design system figured may alright let know leave black grey great awesome use schema nice easy read yep update afterwards needing change,issue,positive,positive,positive,positive,positive,positive
1778709479,I am too (because I have written TS). Can we add a message in the column header to clarify what that means?,written add message column header clarify,issue,negative,neutral,neutral,neutral,neutral,neutral
1778705686,"> I'm wondering how common the `?` syntax is.

Yeah it's a good point. I guess I'm familiar with it from TypeScript but it's not a Python thing. Wrapping with `Optional[...]` seems a bit messy and inconsistent though. Maybe we could go back to the old way of appending `(optional)` after the prop type?",wondering common syntax yeah good point guess familiar typescript python thing wrapping optional bit messy inconsistent though maybe could go back old way optional prop type,issue,negative,positive,positive,positive,positive,positive
1778677045,"> Looks great! It looks like the cell doesn't align with the column.
> 
> <img alt=""Screen Shot 2023-10-25 at 16 21 36"" width=""901"" src=""https://user-images.githubusercontent.com/17039389/277907101-72dd7623-72c3-4077-bdef-7819de4418eb.png"">

Whoops! Good catch, fixed it",great like cell align column screen shot whoop good catch fixed,issue,positive,positive,positive,positive,positive,positive
1778670138,"> update, the formatting now looks like this:
> 
>  Screen.Recording.2023-10-25.at.3.14.15.PM.mov 
> cc @dbczumar @BenWilson2 does the grey on the (optional) count as a use of color? i'm using the `secondary` color [from the design system](https://design-system.dev.databricks.com/?path=/docs/components-typography--color) so I figured it may be alright, but let me know if I should just leave it black.

Grey is great! This is awesome!

@serena-ruan can we use the same formatting for the `__repr__` of `Schema` that @daniellok-db has created in this PR? It's very nice & easy to read",update like grey optional count use color secondary color design system figured may alright let know leave black grey great awesome use schema nice easy read,issue,positive,positive,positive,positive,positive,positive
1778667213,"Looks great! It looks like the cell doesn't align with the column.

<img width=""901"" alt=""Screen Shot 2023-10-25 at 16 21 36"" src=""https://github.com/mlflow/mlflow/assets/17039389/72dd7623-72c3-4077-bdef-7819de4418eb"">
",great like cell align column screen shot,issue,positive,positive,positive,positive,positive,positive
1778658981,"update, the formatting now looks like this:


https://github.com/mlflow/mlflow/assets/148037680/34b1a36a-6f27-4143-a83a-b8b11150018a


cc @dbczumar @BenWilson2 does the grey on the (optional) count as a use of color? i'm using the `secondary` color [from the design system](https://design-system.dev.databricks.com/?path=/docs/components-typography--color) so I figured it may be alright, but let me know if I should just leave it black. ",update like grey optional count use color secondary color design system figured may alright let know leave black,issue,positive,negative,negative,negative,negative,negative
1778657109,Thanks a lot for the quick solution!,thanks lot quick solution,issue,positive,positive,positive,positive,positive,positive
1778592452,"@DueViktor We filed #10121.

The following command install mlflow from this PR's branch:

```
pip install git+https://github.com/mlflow/mlflow.git@refs/pull/10121/merge
```",following command install branch pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
1778547195,"ack, sorry a bit slow right now with the conference coming up but the team will take a look, thanks for the simplified repo. Am I understanding correctly that the script itself doesn't exhibit nondeterminism (how could it, I suppose) but that repeated runs of the entire script do? It's surprising to me due to how we cache the tokens.

Are you running the script with interactiveauthentication or are you using some other authentication context?",sorry bit slow right conference coming team take look thanks simplified understanding correctly script exhibit could suppose repeated entire script surprising due cache running script authentication context,issue,positive,positive,neutral,neutral,positive,positive
1778543422,"I don't have up to date knowledge on MySQL unfortunately, as Azure Machine Learning uses a completely different CosmosDB based architecture. Let me poke around to see if I can find an SME in that area. A quick internet search pulls up this document specific to the Flexible target that sounds related: https://learn.microsoft.com/en-us/azure/dms/known-issues-azure-mysql-fs-online

I'm not sure if that helps you understand what's going on here, though",date knowledge unfortunately azure machine learning completely different based architecture let poke around see find area quick search document specific flexible target related sure understand going though,issue,negative,positive,neutral,neutral,positive,positive
1778540287,"yes, I want to sign off the code",yes want sign code,issue,negative,neutral,neutral,neutral,neutral,neutral
1778537166,"@B-Step62 Thanks! We should also consider enabling https://docs.astral.sh/ruff/rules/hashlib-insecure-hash-function/ to prevent using insecure hashing algorithms directly.

```diff
diff --git a/pyproject.toml b/pyproject.toml
index 8feaec189..f9666445d 100644
--- a/pyproject.toml
+++ b/pyproject.toml
@@ -49,6 +49,7 @@ select = [
   ""UP031"",
   ""UP032"",
   ""UP034"",
+  ""S324"",
   ""SIM101"",
   ""SIM103"",
   ""SIM114"",
```",thanks also consider prevent insecure directly git index select,issue,negative,negative,neutral,neutral,negative,negative
1778498836,"May I take this one, please? @BenWilson2, thanks! I'd like to refactor all of the instances. ",may take one please thanks like,issue,positive,positive,positive,positive,positive,positive
1778460622,@DueViktor I'm also considering lint-ability. I think this is something we should prevent as a lint check. We're using ruff and it has SIM324 that prevents insecure hash functions such as md5.,also considering think something prevent lint check ruff insecure hash,issue,negative,negative,negative,negative,negative,negative
1778077768,"I was able to create a run as well
<img width=""1518"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/5621432/85378b19-ad26-4666-a4bf-cae3bb6bafe2"">

Maybe we can check if there are some limits set that is causing this issue? Would love to understand on how we can reproduce this issue to resolve it. ",able create run well image maybe check set causing issue would love understand reproduce issue resolve,issue,positive,positive,positive,positive,positive,positive
1778023627,Thanks @sunishsheth2009! The error is fairly silent-- I can't see anything in the pod logs. Seeing the output is fine-- the issue is when I try to `Create run`-- the resulting run failed and no table is populated as an artifact.,thanks error fairly silent ca see anything pod seeing output fine issue try create run resulting run table artifact,issue,negative,positive,positive,positive,positive,positive
1777960520,"I agree it’s working now.  The documentation needs to make it more clear for with to work a separate database is needed. 

I think if we run this as a container we’d probably want an init container that calls to upgrade the databases manually for each in case we role out a new version with migrations to either.  ",agree working documentation need make clear work separate think run container probably want container upgrade manually case role new version either,issue,positive,positive,positive,positive,positive,positive
1777918610,"@harupy Just don't do anything? I am able to load keras models saved by mlflow with this code below. Sure, I can't load any arbitrary model, but for models generated by my codebase I can manage `custom_objects` -  that's what it's for.

```
def load_model_from_mlflow(name: str, tag: str, custom_objects: dict) -> tf.keras.Model:
    with tempfile.TemporaryDirectory() as tmpdir:
        mlflow.artifacts.download_artifacts(f""models:/{name}/{tag}"", dst_path=tmpdir)
        return tf.keras.models.load_model(tmpdir + '/data/model', custom_objects=custom_objects)
```",anything able load saved code sure ca load arbitrary model manage name tag name tag return,issue,positive,positive,positive,positive,positive,positive
1777880774,"Hey @calwoo, thank you for trying out prompt lab UI. :) 
Can you share the error message you are seeing?
I just tried the exact same prompt with one of out models and it did return back the results as expected. Let me know if I am missing something? 
![screenshot](https://github.com/mlflow/mlflow/assets/5621432/ec44d6cb-a958-44a3-8169-1ad54e7a1567)
",hey thank trying prompt lab share error message seeing tried exact prompt one return back let know missing something,issue,negative,positive,neutral,neutral,positive,positive
1777872309,"Having two databases is working well for me. One Postgres server with two separate databases. It's a bit of a juggle, but it's fine.

It may be helpful for future users of this feature to provide example scripts for initial database creation as well as schema upgrades.",two working well one server two separate bit juggle fine may helpful future feature provide example initial creation well schema,issue,positive,positive,positive,positive,positive,positive
1777798408,"From what we've seen with people trying to run the auth setup from the MLflow tracking server (as confirmed by your exception, which is from alembic attempting to process the migration version update https://github.com/mlflow/mlflow/blob/master/mlflow/store/db_migrations/versions/7f2a7d5fae7d_add_datasets_inputs_input_tags_tables.py that is reserved solely from the MLflow tracking server), the solution seems to be to define a separate DB in order to isolate the auth and tracking server processes. 

@hoangelos can you attempt to isolate the table creation to another DB instance?",seen people trying run setup server confirmed exception alembic process migration version update reserved solely server solution define separate order isolate server attempt isolate table creation another instance,issue,negative,positive,positive,positive,positive,positive
1777785256,Windows tests passed; there is a communication issue with the reported test status to the PR UI. ,communication issue test status,issue,negative,neutral,neutral,neutral,neutral,neutral
1777778758,"I think joblib is recommended by the scikit-learn team, but I'm unsure if that fully solves your issue either. ",think team unsure fully issue either,issue,negative,neutral,neutral,neutral,neutral,neutral
1777776025,@akshaya-a Is this a known issue with the Azure MySQL server? Are there workarounds available to address the alembic / sqlalchemy migration issue?,known issue azure server available address alembic migration issue,issue,negative,positive,positive,positive,positive,positive
1777688498,"> > I think overall looks good! Another random thought: could we add a column `required` next to `Type` column to represent whether the ColSpec is required or not? It seems a little bit weird appending a `(required) at the end of the string. WDYT? cc @harupy @BenWilson2 @dbczumar
> 
> Agree! Another alternative is to add it next to the column name as well: <img alt=""Screenshot 2023-10-24 at 2 57 40 PM"" width=""486"" src=""https://user-images.githubusercontent.com/148037680/277573754-c545080f-0ff5-4c74-88f8-f46a9868a4de.png"">

Huge fan of this change. Can we provide a visual indicator via text coloring to clearly identify required vs. optional? 
I'm a fan of what @harupy posted from OpenAI's docs to provide a clear and visually striking indication of whether something is required or not. ",think overall good another random thought could add column next type column represent whether little bit weird end string agree another alternative add next column name well huge fan change provide visual indicator via text coloring clearly identify optional fan posted provide clear visually striking indication whether something,issue,positive,positive,neutral,neutral,positive,positive
1777645544,"The recipes windows test passed but the CI did not correctly receive the results. Can we force merge this?
<img width=""982"" alt=""Screenshot 2023-10-24 at 9 50 50 AM"" src=""https://github.com/mlflow/mlflow/assets/7851093/9bdd913c-48c9-4095-9a7e-0a63b4eba7f9"">
<img width=""733"" alt=""Screenshot 2023-10-24 at 9 52 14 AM"" src=""https://github.com/mlflow/mlflow/assets/7851093/9cbe5062-1ae4-43b6-a350-47d6410f80d0"">
",test correctly receive force merge,issue,negative,neutral,neutral,neutral,neutral,neutral
1777593938,"@harupy sorry for the delay again. I was able to run a container locally with the image and can confirm pyenv is available. It's failing at the [_install_python()](https://github.com/mlflow/mlflow/blob/master/mlflow/utils/virtualenv.py#L358) step because of SSL issues with curl but the fact that it is trying to download python means pyenv is available because it passes the check [here](https://github.com/mlflow/mlflow/blob/master/mlflow/utils/virtualenv.py#L338-L339) which is what is erroring out in the aws deployment.  

From the container logs: 
```
2023-10-24 12:12:13 2023/10/24 16:12:13 INFO mlflow.models.container: creating and activating custom environment
2023-10-24 12:12:13 2023/10/24 16:12:13 INFO mlflow.utils.virtualenv: Installing python 3.9.17 if it does not exist
2023-10-24 12:12:13 Downloading Python-3.9.17.tar.xz...
2023-10-24 12:12:13 -> https://www.python.org/ftp/python/3.9.17/Python-3.9.17.tar.xz
2023-10-24 12:12:13 error: failed to download Python-3.9.17.tar.xz
2023-10-24 12:12:13 
2023-10-24 12:12:13 BUILD FAILED (Ubuntu 20.04 using python-build 2.3.29)
2023-10-24 12:12:13 
2023-10-24 12:12:13 Results logged to /tmp/python-build.20231024161213.86.log
2023-10-24 12:12:13 
2023-10-24 12:12:13 Last 10 log lines:
2023-10-24 12:12:13 /tmp/python-build.20231024161213.86 /opt/mlflow
2023-10-24 12:12:13 curl: (60) SSL certificate problem: unable to get local issuer certificate
2023-10-24 12:12:13 More details here: https://curl.haxx.se/docs/sslcerts.html
2023-10-24 12:12:13 
2023-10-24 12:12:13 curl failed to verify the legitimacy of the server and therefore could not
2023-10-24 12:12:13 establish a secure connection to it. To learn more about this situation and
2023-10-24 12:12:13 how to fix it, please visit the web page mentioned above.
2023-10-24 12:12:13 Traceback (most recent call last):
2023-10-24 12:12:13   File ""<string>"", line 1, in <module>
2023-10-24 12:12:13   File ""/usr/local/lib/python3.8/dist-packages/mlflow/models/container/__init__.py"", line 53, in _init
2023-10-24 12:12:13     _serve(env_manager)
2023-10-24 12:12:13   File ""/usr/local/lib/python3.8/dist-packages/mlflow/models/container/__init__.py"", line 75, in _serve
2023-10-24 12:12:13     _serve_pyfunc(m, env_manager)
2023-10-24 12:12:13   File ""/usr/local/lib/python3.8/dist-packages/mlflow/models/container/__init__.py"", line 147, in _serve_pyfunc
2023-10-24 12:12:13     _install_pyfunc_deps(
2023-10-24 12:12:13   File ""/usr/local/lib/python3.8/dist-packages/mlflow/models/container/__init__.py"", line 111, in _install_pyfunc_deps
2023-10-24 12:12:13     env_activate_cmd = _get_or_create_virtualenv(model_path)
2023-10-24 12:12:13   File ""/usr/local/lib/python3.8/dist-packages/mlflow/utils/virtualenv.py"", line 359, in _get_or_create_virtualenv
2023-10-24 12:12:13     python_bin_path = _install_python(
2023-10-24 12:12:13   File ""/usr/local/lib/python3.8/dist-packages/mlflow/utils/virtualenv.py"", line 133, in _install_python
2023-10-24 12:12:13     _exec_cmd(
2023-10-24 12:12:13   File ""/usr/local/lib/python3.8/dist-packages/mlflow/utils/process.py"", line 117, in _exec_cmd
2023-10-24 12:12:13     raise ShellCommandException.from_completed_process(comp_process)
2023-10-24 12:12:13 mlflow.utils.process.ShellCommandException: Non-zero exit code: 1
2023-10-24 12:12:13 Command: ['pyenv', 'install', '--skip-existing', '3.9.17']
```",sorry delay able run container locally image confirm available failing step curl fact trying python available check deployment container custom environment python exist error build logged log last log curl certificate problem unable get local issuer certificate curl verify legitimacy server therefore could establish secure connection learn situation fix please visit web page recent call last file string line module file line file line file line file line file line file line file line raise exit code command,issue,negative,positive,neutral,neutral,positive,positive
1777558579,"> We might want to check what the cards look like on mobile device
> 
> ![Screenshot_20231024-205758](https://user-images.githubusercontent.com/17039389/277650205-1536e159-79fa-4c63-9dda-f63601d4977f.png)

Agreed. All of the card content needs to have shortened header text (no more than 1.5 lines worth of text). I'm going to be filing a PR to shorten all of them in the next 2 days so that we don't have cutoff text.",might want check look like mobile device agreed card content need header text worth text going filing shorten next day cutoff text,issue,positive,positive,positive,positive,positive,positive
1777447135,"@egeucak @SDonkelaarGDD @BenWilson2 Could we add support for `headers` following the [TGI Client](https://github.com/huggingface/text-generation-inference/blob/main/clients/python/text_generation/client.py)?

```python
# pip install text-generation

from text_generation import Client

base_url = 'Local or Hugging Face Inference Endpoints URL'
api_key = 'API key'

client = Client(
    base_url=base_url,
    headers={
        'Accept': 'application/json',
        'Content-Type': 'application/json',
        'Authorization': f'Bearer {api_key}',
    }
)

text = client.generate('Why is the sky blue?')
print(text.generated_text)
```",could add support following client python pip install import client hugging face inference client client text sky blue print,issue,positive,neutral,neutral,neutral,neutral,neutral
1777166300,Got it. https://github.com/streamlit/streamlit/pull/7527/files seems like a cleaner approach. I don't have a strong preference.,got like cleaner approach strong preference,issue,positive,positive,positive,positive,positive,positive
1777159234,Yes exactly. `hashlib.sha1` is not secure either.,yes exactly secure either,issue,positive,positive,positive,positive,positive,positive
1777068216,"We might want to check what the cards look like on mobile device

![Screenshot_20231024-205758](https://github.com/mlflow/mlflow/assets/17039389/1536e159-79fa-4c63-9dda-f63601d4977f)
",might want check look like mobile device,issue,negative,neutral,neutral,neutral,neutral,neutral
1776978577,Can you push a commit to trigger CI checks? They are not triggered when the PR is still a draft.,push commit trigger triggered still draft,issue,negative,neutral,neutral,neutral,neutral,neutral
1776941252,"@B-Step62 The following change should be able to fix the error:

```diff
diff --git a/.github/workflows/requirements.yml b/.github/workflows/requirements.yml
index 679145e25..85c620eea 100644
--- a/.github/workflows/requirements.yml
+++ b/.github/workflows/requirements.yml
@@ -18,6 +18,7 @@ concurrency:
   cancel-in-progress: true
 
 env:
+  MLFLOW_HOME: /home/runner/work/mlflow/mlflow
   MLFLOW_CONDA_HOME: /usr/share/miniconda
   SPARK_LOCAL_IP: localhost
   PYTHON_VERSION: ""3.8""
```",following change able fix error git index concurrency true,issue,negative,positive,positive,positive,positive,positive
1776871382,"> a retry functionality, so we can simplify the code by utilizing it

I didn't know `actions/github-script` supports this. We can use it if necessary.",retry functionality simplify code know use necessary,issue,negative,neutral,neutral,neutral,neutral,neutral
1776840742,"@harupy 
>Can you create a repo (that's okay to be broken) for testing?

Sure, will create a small test repo. Could you assign this ticket to me so that it's easy to track?
Also, it looks like that github-action supports a retry functionality, so we can simplify the code by utilizing it. Let me try it and ask for a review.
https://github.com/actions/github-script#retries",create broken testing sure create small test could assign ticket easy track also like retry functionality simplify code let try ask review,issue,positive,positive,neutral,neutral,positive,positive
1776807247,It's up to you :) Manual merge is also fine :),manual merge also fine,issue,negative,positive,positive,positive,positive,positive
1776781380,"Thx for the quick review @harupy!

> @B-Step62 Do you see the auto-merge button?

Yup, what is the common practice here, can I turn it on?",quick review see button common practice turn,issue,negative,positive,neutral,neutral,positive,positive
1776736657,"> @serena-ruan Can we remove the failed numpy tests?
> 
> ```
> ______________________ test_enforce_property_with_errors _______________________
> 
>     def test_enforce_property_with_errors():
>         with pytest.raises(
>             MlflowException, match=r""Failed to enforce schema of data `123` with dtype `string`""
>         ):
>             _enforce_property(123, Property(""a"", DataType.string))
>     
>         with pytest.raises(MlflowException, match=r""Expected data to be list, got ndarray""):
> >           _enforce_property(
>                 np.array([""some_sentence1"", ""some_sentence2""]), Property(""a"", Array(DataType.string))
>             )
> E           Failed: DID NOT RAISE <class 'mlflow.exceptions.MlflowException'>
> ```

Yes! Maybe we should add a test of validating it's correct instead?",remove enforce schema data string property data list got property array raise class yes maybe add test correct instead,issue,negative,neutral,neutral,neutral,neutral,neutral
1776731146,"@serena-ruan Can we remove the failed tests for ndarray?

```
______________________ test_enforce_property_with_errors _______________________

    def test_enforce_property_with_errors():
        with pytest.raises(
            MlflowException, match=r""Failed to enforce schema of data `123` with dtype `string`""
        ):
            _enforce_property(123, Property(""a"", DataType.string))
    
        with pytest.raises(MlflowException, match=r""Expected data to be list, got ndarray""):
>           _enforce_property(
                np.array([""some_sentence1"", ""some_sentence2""]), Property(""a"", Array(DataType.string))
            )
E           Failed: DID NOT RAISE <class 'mlflow.exceptions.MlflowException'>
```",remove enforce schema data string property data list got property array raise class,issue,negative,neutral,neutral,neutral,neutral,neutral
1776634930,"> I think overall looks good! Another random thought: could we add a column `required` next to `Type` column to represent whether the ColSpec is required or not? It seems a little bit weird appending a `(required) at the end of the string. WDYT? cc @harupy @BenWilson2 @dbczumar

Agree! Another alternative is to add it next to the column name as well:
<img width=""486"" alt=""Screenshot 2023-10-24 at 2 57 40 PM"" src=""https://github.com/mlflow/mlflow/assets/148037680/c545080f-0ff5-4c74-88f8-f46a9868a4de"">",think overall good another random thought could add column next type column represent whether little bit weird end string agree another alternative add next column name well,issue,positive,negative,neutral,neutral,negative,negative
1776614613,Looks like the cell size is too small to render a nested structure nicely :),like cell size small render structure nicely,issue,positive,positive,positive,positive,positive,positive
1776553145,"> Please ask first if an issue has already an assignee.

Sure, from next time 😄. ",please ask first issue already assignee sure next time,issue,positive,positive,positive,positive,positive,positive
1776552207,Please ask first if an issue has already an assignee.,please ask first issue already assignee,issue,negative,positive,positive,positive,positive,positive
1776541368,"@harupy Ok! but I saw that it was assigned yesterday and I see that assignee don't have a fork of mlflow as of now. So, I created a PR. Sorry for not asking before making a PR.",saw assigned yesterday see assignee fork sorry making,issue,negative,negative,negative,negative,negative,negative
1776532833,"@Sai-Suraj-27 sorry, this issue already has an assignee.",sorry issue already assignee,issue,negative,negative,negative,negative,negative,negative
1776071564,"@sagarsumant Could you sign off the code? I can flip the flag but need your approval. If you are willing to sign off the code, please reply ""yes, I want to sign off the code"" below. thanks!",could sign code flip flag need approval willing sign code please reply yes want sign code thanks,issue,positive,positive,positive,positive,positive,positive
1775403192,"@harupy 
I finally got the time to create this PR. Could you help review?",finally got time create could help review,issue,positive,neutral,neutral,neutral,neutral,neutral
1775098392,"Asked ChatGPT to make a few updates:

```yml
name: Automerge PRs

on:
  schedule:
    - cron: '*/10 * * * *'  # Run every 10 minutes

jobs:
  merge:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v2

    - name: Automerge PRs with ""automerge"" label created within the last month and are mergeable
      uses: actions/github-script@v5
      with:
        github-token: ${{secrets.GITHUB_TOKEN}}
        script: |
          const { repo: { owner, repo } } = context;

          const MAX_RETRIES = 3;
          const RETRY_INTERVAL_MS = 10000;  // 10 seconds
          const MERGE_INTERVAL_MS = 5000;   // 5 seconds pause after a merge

          async function sleep(ms) {
            return new Promise(resolve => setTimeout(resolve, ms));
          }

          async function logRateLimit() {
            const { data: rateLimit } = await github.rateLimit.get();
            console.log(`Rate limit remaining: ${rateLimit.rate.remaining}`);
            console.log(`Rate limit resets at: ${new Date(rateLimit.rate.reset * 1000).toISOString()}`);
          }

          async function fetchPullRequestDetails(prNumber) {
            for (let i = 0; i < MAX_RETRIES; i++) {
              const pullRequest = await github.pulls.get({
                owner,
                repo,
                pull_number: prNumber
              }).then(res => res.data);

              if (pullRequest.mergeable !== null) {
                return pullRequest;
              }

              console.log(`Waiting for mergeability calculation for PR #${prNumber}...`);
              await sleep(RETRY_INTERVAL_MS);
            }
            return null;
          }

          async function isPRApproved(prNumber) {
            const { data: reviews } = await github.pulls.listReviews({
              owner,
              repo,
              pull_number: prNumber
            });
            return reviews.some(review => review.state === 'APPROVED');
          }

          async function areAllChecksPassed(sha) {
            const { data: checkRuns } = await github.checks.listForRef({
              owner,
              repo,
              ref: sha
            });
            return checkRuns.check_runs.every(run => run.conclusion === 'success');
          }

          // Get date from a month ago in ISO format
          const oneMonthAgo = new Date();
          oneMonthAgo.setMonth(oneMonthAgo.getMonth() - 1);
          const sinceDate = oneMonthAgo.toISOString();

          // List PRs with the ""automerge"" label created within the last month
          const { data: issues } = await github.issues.listForRepo({
            owner,
            repo,
            labels: 'automerge',
            since: sinceDate
          });

          // Filter for pull requests from the list of issues
          const pullRequests = issues.filter(issue => issue.pull_request);

          for (const pr of pullRequests) {
            const pullRequest = await fetchPullRequestDetails(pr.number);

            if (!pullRequest || pullRequest.mergeable !== true) {
              console.log(`PR #${pr.number} is not mergeable or could not fetch details. Skipping this PR.`);
              await logRateLimit();
              continue;
            }

            if (!await isPRApproved(pr.number)) {
              console.log(`PR #${pr.number} hasn't been approved. Skipping merge.`);
              await logRateLimit();
              continue;
            }

            if (await areAllChecksPassed(pullRequest.head.sha)) {
              try {
                await github.pulls.merge({
                  owner,
                  repo,
                  pull_number: pr.number
                });
                console.log(`Merged PR #${pr.number}`);

                await sleep(MERGE_INTERVAL_MS);
                await logRateLimit();
              } catch (error) {
                console.log(`Failed to merge PR #${pr.number}. Reason: ${error.message}`);
              }
            } else {
              console.log(`Checks not ready for PR #${pr.number}. Skipping merge.`);
              await logRateLimit();
            }
          }
```",make name schedule run every merge name code name label within last month script owner context pause merge function sleep return new promise resolve resolve function data await rate limit rate limit new date function let await owner null return waiting calculation await sleep return null function data await owner return review function sha data await owner ref sha return run get date month ago iso format new date list label within last month data await owner since filter pull list issue await true could fetch skipping await continue await skipping await continue await try await owner await sleep await catch error merge reason else ready skipping await,issue,positive,positive,positive,positive,positive,positive
1775069781,"We can create the action above + one more job that protects master/main branch, and then file a PR with automerge label applied.",create action one job branch file label applied,issue,negative,positive,neutral,neutral,positive,positive
1775063489,@TomeHirata Thanks! Can you create a repo (that's okay to be broken) for testing?,thanks create broken testing,issue,negative,negative,neutral,neutral,negative,negative
1775060083,"I understand, thank you for the clarification. I also learned that `github.issues` API can also get pull requests ([ref](https://octokit.github.io/rest.js/v20#issues-list)). 
Let me work on this task.",understand thank clarification also learned also get pull ref let work task,issue,negative,neutral,neutral,neutral,neutral,neutral
1774984483,"BTW,in the document says 'Autologging functionality is not implemented fully for the transformers flavor' does it means autologging doesnt implement all the autolog parameter like log_models.Because , when i digged into both mlflow and transformers integrations code,i didnt found any 'log_model' to env parameter 'HF_MLFLOW_LOG_ARTIFACTS' conversion code(see following code snapshot)
![image](https://github.com/mlflow/mlflow/assets/48442748/e6e3b2de-00f6-402a-af43-b725e5ec8a7d)
So mlflow's autologging will not log model/checkpoints to artifacts，am i right? The only way is to enable it is to set the env parameter?",document functionality fully flavor doesnt implement parameter like code didnt found parameter conversion code see following code snapshot image log right way enable set parameter,issue,negative,positive,positive,positive,positive,positive
1774983611,"Hey Ben, 

We are using Mlflow on our on-premise Kubernetes cluster. We leveraged MLflow plugins to enhance it with extra functionality such that it can be deployed securely in an enterprise environment (we protected it using Oauth2 proxy). Think about:
* Adding STS session token support for S3 Artefact Store backends.
* Adding automatic Keycloak authentication by creating a custom `request_header_provider`. This works similar to [DefaultAzureCredential](https://learn.microsoft.com/en-us/dotnet/api/azure.identity.defaultazurecredential?view=azure-dotnet) in the sense that it enables token-based authentication by checking multiple authentication flows from within its runtime environment. For example, by using credentials in the environment, or by using the browser to interactively authenticate a user. This enables seamless authentication which really benefits the user experience.
* We created a used  custom mlflow server flask app such that we have proper RBAC that is fully connected with our existing (custom) IAM solutions. This enables fine-grained RBAC controls for the enterprise environment where its permissions are automatically inherited from existing IAM solutions. Hence MLflow becomes really integrated with other solutions that we have.

In our understanding, MLflow is awesome if you want to incorporate MLOps best practices on k8s. By using MLflow plugins we could tailer the solution specifically to our needs and use it apply to manage the ML lifecycle in an on-prem enterprise environment.


",hey ben cluster enhance extra functionality securely enterprise environment proxy think session token support artefact store automatic authentication custom work similar sense authentication multiple authentication within environment example environment browser authenticate user seamless authentication really user experience used custom server flask proper fully connected custom enterprise environment automatically hence becomes really understanding awesome want incorporate best could tailer solution specifically need use apply manage enterprise environment,issue,positive,positive,positive,positive,positive,positive
1774900903,"Got u .  I check the transformers code . ![image](https://github.com/mlflow/mlflow/assets/48442748/afb310a6-c7b5-47d0-b4e9-abae58efbf17)
I really really appreciate your patience.
Thanks a lot:)
",got check code image really really appreciate patience thanks lot,issue,positive,positive,positive,positive,positive,positive
1774853769,"> What is the condition when automerge label is attached? Is it a manual process?

Yes, it's manual. If your PR is approved and all you need to do is wait, then you can apply this label.

> Can I understand that we will attach the label to PR rather than issue? I asked since the pseudo-code tries to filter issues instead of PRs

`const pullRequests = issues.filter(issue => issue.pull_request);` filters out issues.

> Can't we have a job that is triggered when the label is attached instead of having a scheduled job? It may be able to save the computational resources ([ref](https://docs.github.com/en/actions/using-workflows/events-that-trigger-workflows#pull_request))

Good question.

- You might still have running jobs when you apply the label.
- What if you push a commit after you apply the label?

We can increase the interval (e.g. 30 minutes or 1 hour) if necessary.",condition label attached manual process yes manual need wait apply label understand attach label rather issue since filter instead issue ca job triggered label attached instead job may able save computational ref good question might still running apply label push commit apply label increase interval hour necessary,issue,positive,positive,positive,positive,positive,positive
1774837840,"OK, 'report_to' does solve my problem . But i still wandering why it 's still logging after i commented the all the mlflow code including 'import' code (in my snapshot)? Do you mean  logging/auto-tracking is depending on 'report_to' when mlflow and transformers are both installed ,and mlflow modify the transformers code and add mlflow's callback staticly  ？",solve problem still wandering still logging code code snapshot mean depending modify code add,issue,negative,negative,negative,negative,negative,negative
1774835486,"@harupy Yes, please let me work on this. I have several questions I'd like to clarify

1. What is the condition when `automerge` label is attached? Is it a manual process?
2. Can I understand that we will attach the label to `PR` rather than `issue`? I asked since the pseudo-code tries to filter issues instead of PRs
3. Can't we have a job that is triggered when the label is attached is added instead of having a scheduled job? It may be able to save the computational resources ([ref](https://docs.github.com/en/actions/using-workflows/events-that-trigger-workflows#pull_request))",yes please let work several like clarify condition label attached manual process understand attach label rather issue since filter instead ca job triggered label attached added instead job may able save computational ref,issue,positive,positive,positive,positive,positive,positive
1774690875,"More robust code:

```yml
name: Automerge PRs

on:
  schedule:
    - cron: '*/10 * * * *'  # Run every 10 minutes

jobs:
  merge:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v2

    - name: Automerge PRs with ""automerge"" label created within the last month and are mergeable
      uses: actions/github-script@v5
      with:
        github-token: ${{secrets.GITHUB_TOKEN}}
        script: |
          const { repo: { owner, repo } } = context;

          const MAX_RETRIES = 3;
          const RETRY_INTERVAL_MS = 10000;  // 10 seconds

          // Get date from a month ago in ISO format
          const oneMonthAgo = new Date();
          oneMonthAgo.setMonth(oneMonthAgo.getMonth() - 1);
          const sinceDate = oneMonthAgo.toISOString();

          // List PRs with the ""automerge"" label created within the last month
          const { data: issues } = await github.issues.listForRepo({
            owner,
            repo,
            labels: 'automerge',
            since: sinceDate
          });

          // Filter for pull requests from the list of issues
          const pullRequests = issues.filter(issue => issue.pull_request);

          for (const pr of pullRequests) {
            let pullRequest;

            for (let i = 0; i < MAX_RETRIES; i++) {
              // Fetch PR details
              pullRequest = await github.pulls.get({
                owner,
                repo,
                pull_number: pr.number
              }).then(res => res.data);

              if (pullRequest.mergeable !== null) {
                break;
              }

              console.log(`Waiting for mergeability calculation for PR #${pr.number}...`);
              await new Promise(resolve => setTimeout(resolve, RETRY_INTERVAL_MS));
            }

            // If mergeable is false or still null after retries, skip this PR
            if (pullRequest.mergeable === null || pullRequest.mergeable === false) {
              console.log(`PR #${pr.number} is not mergeable. Skipping this PR.`);
              continue;
            }

            // Check the status of all checks for the PR
            const { data: checkRuns } = await github.checks.listForRef({
              owner,
              repo,
              ref: pullRequest.head.sha
            });

            const allChecksPassed = checkRuns.check_runs.every(run => run.conclusion === 'success');

            if (allChecksPassed) {
              try {
                await github.pulls.merge({
                  owner,
                  repo,
                  pull_number: pr.number,
                  commit_title: `Merge pull request #${pr.number}`,
                  commit_message: `automatic merge of PR #${pr.number}`
                });
                console.log(`Merged PR #${pr.number}`);
              } catch (error) {
                console.log(`Failed to merge PR #${pr.number}. Reason: ${error.message}`);
              }
            } else {
              console.log(`Checks not ready or PR not approved for PR #${pr.number}. Skipping merge.`);
            }
          }

```",robust code name schedule run every merge name code name label within last month script owner context get date month ago iso format new date list label within last month data await owner since filter pull list issue let let fetch await owner null break waiting calculation await new promise resolve resolve false still null skip null false skipping continue check status data await owner ref run try await owner merge pull request automatic merge catch error merge reason else ready skipping,issue,positive,negative,neutral,neutral,negative,negative
1774395570,"@harupy Yes, is there any ticket for this task? If so, please assign this task to me!",yes ticket task please assign task,issue,positive,neutral,neutral,neutral,neutral,neutral
1774280609,@mberk06 I've seen this test fail countless times before. We might want to disable this test on  windows.,seen test fail countless time might want disable test,issue,negative,negative,negative,negative,negative,negative
1773912136,@BenWilson2 Could we consider defining `MLFLOW_GATEWAY_TOKEN` and inject it to gateway proxy handler used by Prompt Engineering UI?,could consider inject gateway proxy handler used prompt engineering,issue,negative,neutral,neutral,neutral,neutral,neutral
1773895225,"I'll reach that point in the next week or two. My intuition is that schema installation/upgrades should be a separate batch process, rather than something automatically applied at worker startup, otherwise there may be a race condition when multiple workers try to apply the schema upgrade(s) simultaneously. Not sure if the current MLflow release supports that.",reach point next week two intuition schema separate batch process rather something automatically applied worker otherwise may race condition multiple try apply schema upgrade simultaneously sure current release,issue,negative,positive,positive,positive,positive,positive
1773796992,"@barrywhart this was exactly because I was putting the schemas together.  I had suspicions that was it.  However, there's still a bug in here somewhere with multiple workers.  One eventually is able to do the update.  But everyone crashes.  Once I restart everything is perfect.

```console
[2023-10-21 00:03:11 +0000] [8] [INFO] Starting gunicorn 21.2.0
[2023-10-21 00:03:11 +0000] [8] [DEBUG] Arbiter booted
[2023-10-21 00:03:11 +0000] [8] [INFO] Listening at: http://0.0.0.0:5000 (8)
[2023-10-21 00:03:11 +0000] [8] [INFO] Using worker: sync
[2023-10-21 00:03:11 +0000] [9] [INFO] Booting worker with pid: 9
[2023-10-21 00:03:11 +0000] [11] [INFO] Booting worker with pid: 11
[2023-10-21 00:03:11 +0000] [13] [INFO] Booting worker with pid: 13
[2023-10-21 00:03:11 +0000] [14] [INFO] Booting worker with pid: 14
[2023-10-21 00:03:11 +0000] [8] [DEBUG] 4 workers
2023/10/21 00:03:12 WARNING mlflow.server.auth: This feature is still experimental and may change in a future release without warning
2023/10/21 00:03:12 WARNING mlflow.server.auth: This feature is still experimental and may change in a future release without warning
2023/10/21 00:03:12 WARNING mlflow.server.auth: This feature is still experimental and may change in a future release without warning
2023/10/21 00:03:12 WARNING mlflow.server.auth: This feature is still experimental and may change in a future release without warning
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade  -> 8606fa83a998, initial_migration
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
[2023-10-21 00:03:15 +0000] [8] [ERROR] Worker (pid:11) exited with code 3
[2023-10-21 00:03:15 +0000] [8] [ERROR] Worker (pid:13) was sent SIGTERM!
[2023-10-21 00:03:15 +0000] [8] [ERROR] Worker (pid:14) was sent SIGTERM!
[2023-10-21 00:03:16 +0000] [8] [ERROR] Shutting down: Master
[2023-10-21 00:03:16 +0000] [8] [ERROR] Reason: Worker failed to boot.
Running the mlflow server failed. Please see the logs above for details.```",exactly together however still bug somewhere multiple one eventually able update everyone restart everything perfect console starting arbiter booted listening worker sync booting worker booting worker booting worker booting worker warning feature still experimental may change future release without warning warning feature still experimental may change future release without warning warning feature still experimental may change future release without warning warning feature still experimental may change future release without warning context assume transactional context assume transactional context assume transactional running upgrade context assume transactional error worker code error worker sent error worker sent error shutting master error reason worker boot running server please see,issue,negative,positive,positive,positive,positive,positive
1773767212,Oh I got it! Thank you so much for your kind reply. I'm also grateful for this experience. Thank you.,oh got thank much kind reply also grateful experience thank,issue,positive,positive,positive,positive,positive,positive
1773751402,"For examples/multistep_workflow/train_keras.py, I think we can exit the spark session after the `toPandas` calls.",think exit spark session,issue,negative,neutral,neutral,neutral,neutral,neutral
1773749748,"@Dennis40816 Sorry, I didn't notice your comment.

For 1, I think a spark session needs to be alive until we consume spark dataframes/models.

For 2, we recently removed run-python-tests.sh but forgot to update `CONTRIBUTING.md`. It needs to be updated.",sorry notice comment think spark session need alive consume spark recently removed forgot update need,issue,positive,negative,negative,negative,negative,negative
1773719266,"Dear MLflow Community,

I hope this message finds you well. We wanted to share some exciting news with you regarding Helm chart support for MLflow. At [Bitnami](https://bitnami.com/), we have developed our own Helm chart for MLflow, and we're thrilled to invite the MLflow community to collaborate, test, and provide feedback on this chart.

Our [Bitnami Helm chart for MLflow](https://github.com/bitnami/charts/tree/main/bitnami/mlflow) is designed to simplify the deployment and management of MLflow instances on Kubernetes, streamlining the process for users who prefer Helm as their package manager. We've put considerable effort into ensuring that it meets the highest standards for reliability, security, and ease of use.

We believe in the power of open-source collaboration, and we see an opportunity to align efforts with the upstream MLflow project. By collaborating and converging efforts around a single Helm chart, we can collectively ensure a more robust, well-maintained, and feature-rich solution for the entire MLflow community.

How you can get involved:
- **_Test the Bitnami Helm Chart_**: You can find our [Helm chart for MLflow](https://github.com/bitnami/charts/tree/main/bitnami/mlflow) and give it a spin. Your feedback and testing will be invaluable in improving the chart.
- **_Provide Feedback_**: We welcome your feedback on the Bitnami Helm chart. If you encounter any issues, have suggestions, or need assistance, please don't hesitate to share your thoughts by opening an Issue or PR in the [Bitnami charts GH repository](https://github.com/bitnami/charts).
- **_Collaborate_**: We are open to collaboration and contributions from the MLflow community. If you have ideas for improvements, or if you would like to participate in the development of the Helm chart, please let us know.

Our vision is to work together to make this Helm chart the official solution for deploying MLflow on Kubernetes. By pooling our resources and knowledge, we can create a Helm chart that caters to the diverse needs of the MLflow community.

Thank you for your time and consideration. We look forward to collaborating with you to enhance the MLflow Helm chart experience for everyone.",dear community hope message well share exciting news regarding helm chart support helm chart invite community collaborate test provide feedback chart helm chart designed simplify deployment management process prefer helm package manager put considerable effort highest reliability security ease use believe power collaboration see opportunity align upstream project converging around single helm chart collectively ensure robust solution entire community get involved helm find helm chart give spin feedback testing invaluable improving chart welcome feedback helm chart encounter need assistance please hesitate share opening issue repository open collaboration community would like participate development helm chart please let u know vision work together make helm chart official solution knowledge create helm chart diverse need community thank time consideration look forward enhance helm chart experience everyone,issue,positive,positive,positive,positive,positive,positive
1773651152,"I apologize for not fully considering the extra work my commit may have caused you. I also have a couple of questions, if you don't mind answering:

1. I'm curious as to why the scope of your `with` statement extends into areas where it's not actually used. Are you concerned that variables derived there might be affected by the Spark session?
   
2. According to [CONTRIBUTING.md](https://github.com/mlflow/mlflow/blob/master/CONTRIBUTING.md#running-python-tests), Python tests are executed by running `run-python-tests.sh`. However, it appears that this shell script is not present in the current master branch's dev directory. Has it been replaced by `run-python-skinny-tests.sh`?

I hope these questions don't cause any inconvenience. Thank you for your time.",apologize fully considering extra work commit may also couple mind curious scope statement actually used concerned derived might affected spark session according python executed running however shell script present current master branch dev directory hope cause inconvenience thank time,issue,positive,negative,neutral,neutral,negative,negative
1773611712,"> Hey @serena-ruan Thanks for the PR. However, there is one issue with the merged PR.
> 
> The output produced would now be a list. **Each item in the list could either be a str or list.** And this format is not currently supported by mlflow output signature. If someone tries to infer signature, they will run into the following error:
> 
> E TypeError: ('Expected one of the following types:\n- pandas.DataFrame\n- pandas.Series\n- numpy.ndarray\n- dictionary of (name -> numpy.ndarray)\n- pyspark.sql.DataFrame\n', ""- scipy.sparse.csr_matrix\n- scipy.sparse.csc_matrix\n- str\n- List[str]\n- List[Dict[str, Union[str, List[str]]]]\n- Dict[str, Union[str, List[str]]]\n- bytes\nbut got '<class 'list'>'"")
> 
> I have tried to avoid this issue in my PR but it involves changing the output format for fill mask: #10025

Yes @ghyadav We're working on introducing objects/arrays into ModelSignature to support this kind of data format. It's on feature branch llm_signature, there're still some pieces left. We'll definitely support it soon!",hey thanks however one issue output produced would list item list could either list format currently output signature someone infer signature run following error one following dictionary name list list union list union list got class tried avoid issue output format fill mask yes working support kind data format feature branch still left definitely support soon,issue,positive,positive,positive,positive,positive,positive
1773455786,"I think you have to create a different database. IIUC, Alembic doesn't support multiple schemas in one database.

I'm working on deploying this to our instance, and I'm creating a different database, passing a different connection URI, etc. Still a work in progress, but I was seeing very similar Alembic errors before I got this straightened out.",think create different alembic support multiple one working instance different passing different connection still work progress seeing similar alembic got,issue,positive,neutral,neutral,neutral,neutral,neutral
1773453766,"I think you have to create a different database. IIUC, Alembic doesn't support multiple schemas in one database.",think create different alembic support multiple one,issue,positive,neutral,neutral,neutral,neutral,neutral
1773384101,"So, I tried this and opened a bug on it.  @harupy  I'm running against Postgres. The error looks like it might be caused by confusion on which alembic.ini files it's grabbing.  It keeps trying to apply migrations from the store... One details is the I'm trying to store this in the same Schema as the tracking info and model registry store etc.  ",tried bug running error like might confusion trying apply store one trying store schema model registry store,issue,negative,neutral,neutral,neutral,neutral,neutral
1773351002,"@andrew-christianson just a few merge conflicts due to some additions to Gateway since the last time that you rebased. Once those are buttoned up, we'll be good to go to merge and get this included in 2.8! :) ",merge due gateway since last time buttoned good go merge get included,issue,negative,positive,positive,positive,positive,positive
1773243498,Closing this PR as it's on the `main` of the fork. Opening a same PR but made from another fork branch: https://github.com/mlflow/mlflow/pull/10049  @BenWilson2 @mrDzurb ,main fork opening made another fork branch,issue,negative,positive,positive,positive,positive,positive
1773227534,@smurching  by the way your question is already in his output... Postgres is 11.4,way question already output,issue,negative,neutral,neutral,neutral,neutral,neutral
1773210884,"This seems like a prime use case for a JupyterNotebook tutorial. Can this be adapted into a single notebook with markdown cells that contain the existing ""Step"" information? 

The notebook can reside here:

`docs/source/llms/rag/notebooks/<name of your notebook>.ipynb`
along with that, the creation of a referenceable index file here: `docs/source/llms/rag/notebooks/index.rst`
and a simple placeholder .rst file can be created here: `docs/source/llms/rag/index.rst`. 

Within that index.rst, the only contents that are needed are:

1. An H1 header entry (`====` wrapped) 
2. An explanation of what the tutorial is for (3-4 sentences explaining what's going on in the notebook) 
3. a TOC reference to the notebook directory `index.rst` within `../rag/index.rst` similar to:

.. toctree::
    :maxdepth: 1

    Full Notebooks <notebooks/index>
    
  4. a TOC reference to the notebook within the directory `index.rst` similar to:

.. toctree::
    :maxdepth: 1
    :hidden:

   <name of your notebook>.ipynb
 
As for the remainder of the work required to get the tutorial created, I can file a folloup PR to this content creation PR and ensure that all of the navigation, tutorial references, etc are all done. Just let me know when the notebook is done and the basic nav elements above are done and I'll handle the rest so we can release this prior to 2.8 release. :) ",like prime use case tutorial single notebook markdown contain step information notebook reside name notebook along creation index file simple file within content header entry wrapped explanation tutorial explaining going notebook reference notebook directory within similar full reference notebook within directory similar hidden name notebook remainder work get tutorial file content creation ensure navigation tutorial done let know notebook done basic done handle rest release prior release,issue,positive,positive,neutral,neutral,positive,positive
1773137073,@harupy yes I tested via boto3 and it is able to upload artifacts in minio but when I am trying with mlflow then its throwing same error mentioned above.,yes tested via able trying throwing error,issue,negative,positive,positive,positive,positive,positive
1773111645,"> @KonakanchiSwathi Thank you for the contribution! Could you fix the following issue(s)?
> 
> #### ⚠ DCO check
> The DCO check failed. Please sign off your commit(s) by following the instructions [here](https://github.com/mlflow/mlflow/runs/17907540788). See https://github.com/mlflow/mlflow/blob/master/CONTRIBUTING.md#sign-your-work for more details.
Can you help on this issue
",thank contribution could fix following issue warning check check please sign commit following see help issue,issue,positive,neutral,neutral,neutral,neutral,neutral
1773081935,"Hey @BenWilson2 and @serena-ruan Thanks for the PR. However, there is one issue with the merged PR, and it currently doesn't solve all the issues

The output produced after the merged changes would still be a list but **Each item in the list could either be a str or list.** And this format is not currently supported by mlflow output signature.
If someone tries to infer signature, they will run into the following error:

E TypeError: ('Expected one of the following types:\n- pandas.DataFrame\n- pandas.Series\n- numpy.ndarray\n- dictionary of (name -> numpy.ndarray)\n- pyspark.sql.DataFrame\n', ""- scipy.sparse.csr_matrix\n- scipy.sparse.csc_matrix\n- str\n- List[str]\n- List[Dict[str, Union[str, List[str]]]]\n- Dict[str, Union[str, List[str]]]\n- bytes\nbut got '<class 'list'>'"")

I have tried to avoid this issue in my PR but it involves changing the output format for fill mask: https://github.com/mlflow/mlflow/pull/10025",hey thanks however one issue currently solve output produced would still list item list could either list format currently output signature someone infer signature run following error one following dictionary name list list union list union list got class tried avoid issue output format fill mask,issue,negative,positive,neutral,neutral,positive,positive
1773076678,"Hey @serena-ruan Thanks for the PR. However, there is one issue with the merged PR. 

The output produced would now be a list. **Each item in the list could either be a str or list.** And this format is not currently supported by mlflow output signature.
If someone tries to infer signature, they will run into the following error:

E           TypeError: ('Expected one of the following types:\n- pandas.DataFrame\n- pandas.Series\n- numpy.ndarray\n- dictionary of (name -> numpy.ndarray)\n- pyspark.sql.DataFrame\n', ""- scipy.sparse.csr_matrix\n- scipy.sparse.csc_matrix\n- str\n- List[str]\n- List[Dict[str, Union[str, List[str]]]]\n- Dict[str, Union[str, List[str]]]\n- bytes\nbut got '<class 'list'>'"")

I have tried to avoid this issue in my PR but it involves changing the output format for fill mask: https://github.com/mlflow/mlflow/pull/10025",hey thanks however one issue output produced would list item list could either list format currently output signature someone infer signature run following error one following dictionary name list list union list union list got class tried avoid issue output format fill mask,issue,negative,positive,neutral,neutral,positive,positive
1772973259,"Hi @floyddcn this isn't actually an MLflow issue, per se. The callback handler within transformers is overriding behavior in MLflow and forcing run creation and metrics collection by the setting of the argument `report_to`. By default (for now, this is getting changed in an upcoming release of transformers), the value set for `report_to` is ""all"", which will force logging and reporting of results via the callback to MLflow if it detects that MLflow has been imported in the current REPL session. 

In order to disable this, please set `report_to=""none""`, which will allow you to have full manual control of what you want to log to MLflow and when. 

Example:

```python
BATCH_SIZE = 16
TRAIN_EPOCHS = 2

output_directory = ""/tmp/transformers_autolog_disable/image_capture""


training_args = TrainingArguments(
    output_dir=output_directory,
    per_device_train_batch_size=BATCH_SIZE,
    do_train=True,
    num_train_epochs=TRAIN_EPOCHS,  
    overwrite_output_dir=True,
    no_cuda=True, # set only because I'm testing this on my M1 laptop
    dataloader_pin_memory=False, 
    report_to=""none"", # This defaults to ""all"" and should be set to ""none"" if run creation and logging is not desired.
)

trainer = Trainer(
    tokenizer=feature_extractor,
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    data_collator=default_data_collator,
)
```

Thanks for using MLflow! ",hi actually issue per se handler within behavior forcing run creation metric collection setting argument default getting upcoming release value set force logging via current session order disable please set none allow full manual control want log example python set testing none set none run creation logging trainer trainer thanks,issue,positive,positive,positive,positive,positive,positive
1772957413,"Hi @derek5965 can you give some additional context on how you've configured your tracking server and how you've generated SSL certificates for hostname validation? 

I'm not sure if you want to ignore certificate checks, as that is one of the reasons for using SSL in the first place. 

Are you able to verify the common name / subject alternative names in the server's certificates and ensure that they're registered properly?",hi give additional context server validation sure want ignore certificate one first place able verify common name subject alternative server ensure registered properly,issue,negative,positive,positive,positive,positive,positive
1772789719,"> Should we avoid setting ColSpec's required field for spark dataframes

Sounds good to me. Nullable doesn't mean the column can be omitted.",avoid setting field spark good nullable mean column,issue,negative,positive,positive,positive,positive,positive
1772737128,Awesome! Please assign this issue to me and I will make a start this weekend.,awesome please assign issue make start weekend,issue,positive,positive,positive,positive,positive,positive
1772641277,"For a pandas DataFrame
```
import pandas as pd
df = pd.DataFrame([[1, 2, 3], [1, 2, 3]], columns=[""a"", ""b"", ""c""])
```
Then all columns are required. But if we directly create a spark dataframe from it, `nullable=True` by default, which makes `required=False` when we infer the schema.
```
df_spark = spark.createDataFrame(df)
```
Should we avoid setting ColSpec's required field for spark dataframes or we fix the schema when we construct a spark dataframe from a pandas dataframe? cc @harupy ",import directly create spark default infer schema avoid setting field spark fix schema construct spark,issue,positive,positive,neutral,neutral,positive,positive
1772453258,"@serena-ruan Can you try this change to fix the spark test failures?

```diff
diff --git a/mlflow/types/schema.py b/mlflow/types/schema.py
index 511a6e2b0..3151b74fa 100644
--- a/mlflow/types/schema.py
+++ b/mlflow/types/schema.py
@@ -892,7 +892,9 @@ class Schema:
 
         return StructType(
             [
-                StructField(name=col.name or str(i), dataType=col.type.to_spark())
+                StructField(
+                    name=col.name or str(i), dataType=col.type.to_spark(), nullable=col.required
+                )
                 for i, col in enumerate(self.inputs)
             ]
         )
```",try change fix spark test git index class schema return col enumerate,issue,negative,neutral,neutral,neutral,neutral,neutral
1772431197,"> Manually tested. It works great!
> 
> Expand

Thanks @harupy ! Could I leave the failing spark tests for you to fix them?",manually tested work great expand thanks could leave failing spark fix,issue,positive,positive,positive,positive,positive,positive
1772408302,@akshaya-a Could you take a look? Thanks!,could take look thanks,issue,negative,positive,positive,positive,positive,positive
1772405890,Sorry @ghyadav I just saw this PR. Does https://github.com/mlflow/mlflow/pull/10032 look good for you?,sorry saw look good,issue,negative,positive,neutral,neutral,positive,positive
1772400317,"Manually tested. It works great!

<details><summary>Expand</summary>
<p>

```python
import mlflow

data = {""a"": 0}
print(mlflow.models.infer_signature(data).inputs)
```

    ['a': long (required)]


    /workspaces/mlflow/mlflow/models/signature.py:213: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.
      inputs = _infer_schema(model_input) if model_input is not None else None



```python
data = {""a"": [1, 2, 3]}
print(mlflow.models.infer_signature(data).inputs)
```

    ['a': Array(type=DataType.long) (required)]



```python
data = [{""a"": 0}]
print(mlflow.models.infer_signature(data).inputs)
```

    ['a': long (required)]



```python
import pandas as pd

data = pd.DataFrame(
    {
        ""obj"": [{""a"": 0}]
    }
)
print(mlflow.models.infer_signature(data).inputs)
```

    ['obj': Object(properties=[Property(name=a, type=DataType.long, required=True)]) (required)]



```python
data = pd.DataFrame(
    {
        ""obj"": [[1, 2, 3]]
    }
)
print(mlflow.models.infer_signature(data).inputs)
```

    ['obj': Array(type=DataType.long) (required)]



```python
data = pd.DataFrame(
    {
        ""obj"": [[{""a"": 0}, {""b"": 0}]]
    }
)
print(mlflow.models.infer_signature(data).inputs)
```

    ['obj': Array(type=Object(properties=[Property(name=a, type=DataType.long, required=False), Property(name=b, type=DataType.long, required=False)])) (required)]



```python
data = pd.DataFrame(
    {
        ""obj"": [[{""a"": 0, ""b"": 0}, {""b"": 0}]]
    }
)
print(mlflow.models.infer_signature(data).inputs)
```

    ['obj': Array(type=Object(properties=[Property(name=a, type=DataType.long, required=False), Property(name=b, type=DataType.long, required=True)])) (required)]



```python
data
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border=""1"" class=""dataframe"">
  <thead>
    <tr style=""text-align: right;"">
      <th></th>
      <th>obj</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>[{'a': 0, 'b': 0}, {'b': 0}]</td>
    </tr>
  </tbody>
</table>
</div>




```python
import mlflow.utils

data = [[1, 2, 3] for _ in range(10)]

with mlflow.utils.time.Timer() as t:
    print(mlflow.models.infer_signature(data).inputs)
    
print(t)
```

    [Array(type=DataType.long)]
    0.007558362998679513



```python
data = {
    ""foo"": [{""a"": 0}, {""b"": 0}, {""c"": 0}]
}
print(mlflow.models.infer_signature(data).inputs)
```

    ['foo': Array(type=Object(properties=[Property(name=a, type=DataType.long, required=False), Property(name=b, type=DataType.long, required=False), Property(name=c, type=DataType.long, required=False)])) (required)]



```python
data = {
    ""foo"": [{""a"": {""c"": 0}}, {""a"": {""b"": 0, ""c"": 0}}]
}
print(mlflow.models.infer_signature(data).inputs)
```

    ['foo': Array(type=Object(properties=[Property(name=a, type=Object(properties=[Property(name=b, type=DataType.long, required=False), Property(name=c, type=DataType.long, required=True)]), required=True)])) (required)]



```python

```


</p>
</details> ",manually tested work great summary expand python import data print data long hint schema integer column integer python represent missing input data missing inference time cause schema enforcement error best way avoid problem infer model schema based realistic data sample training missing alternatively declare integer float whenever may missing see handling missing none else none python data print data array python data print data long python import data print data object property python data print data array python data print data array property property python data print data array property property python data div style th middle th top th right table right th th th python import data range print data print array python data foo print data array property property property python data foo print data array property property property python,issue,negative,positive,positive,positive,positive,positive
1772333933,"[like]  Jan Hurst reacted to your message:
________________________________
From: Harutaka Kawamura ***@***.***>
Sent: Friday, October 20, 2023 8:32:42 AM
To: mlflow/mlflow ***@***.***>
Cc: Jan Hurst ***@***.***>; Mention ***@***.***>
Subject: Re: [mlflow/mlflow] [BUG] Empty space on left sidebar (Issue #9881)


Closing. I'm not sure if this is an MLflow's issue or not. @janhurst<https://github.com/janhurst> Feel free to reopen this issue if you find anything :)

—
Reply to this email directly, view it on GitHub<https://github.com/mlflow/mlflow/issues/9881#issuecomment-1772310181>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AD3ZE6K6LTXD7BLGZXTUAELYAIZKVAVCNFSM6AAAAAA5Y46Q3WVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTONZSGMYTAMJYGE>.
You are receiving this because you were mentioned.Message ID: ***@***.***>
",like hurst message sent hurst mention subject bug empty space left issue sure issue feel free reopen issue find anything reply directly view id,issue,positive,positive,positive,positive,positive,positive
1772310181,Closing. I'm not sure if this is an MLflow's issue or not. @janhurst Feel free to reopen this issue if you find anything :),sure issue feel free reopen issue find anything,issue,positive,positive,positive,positive,positive,positive
1772307809,"Got it.

> Can you try uploading/downloading artifacts using only boto3 without mlflow? Does it work or not?

Can you check this 👆?",got try without work check,issue,negative,neutral,neutral,neutral,neutral,neutral
1772306563,"We are deploying mlflow via helm chart into kubernetes cluter. In that, we are passing minio credentials via secrets.

kubectl get secrets mlflow-env-secret -o yaml
apiVersion: v1
data:
  ARTIFACTORY_API_KEY: SWtGTFEzQTRjRkZpYTI1cGFtSjBhMlZvUkhOaldrMWhZblUyUjFSVmRXczVibTFGZDFwcFpYSnBNWEZHZUhKNU1reFpVSEpxUmpoV1lWbHhVVFZCYVhwVmJreFJhWFkwVWt3aQ==
  MINIO_ACCESS_KEY_ID: OGQwbHkwTHE3U0JJZkJVeA==
  MINIO_ROOT_PASSWORD: YXV0b21vdGl2ZS1hcnRpZmFjdHM=
  MINIO_ROOT_USER: YXV0b21vdGl2ZS1hcnRpZmFjdHMtdXNlcg==
  MINIO_SECRET_ACCESS_KEY: b0ZPdFFiZkRwTjFod2ZtMDFIcUsyemo4REhueW5rQUk=
  MYSQL_PASSWORD: YXV0b3NlbnNlXzEyMw==
  MYSQL_USERNAME: YXV0b3NlbnNlMQ==
kind: Secret
metadata:
  annotations:
    meta.helm.sh/release-name: mlflow-auto****
    meta.helm.sh/release-namespace: mlflow-namespace
  creationTimestamp: ""2023-10-20T08:09:58Z""
  labels:
    app: mlflow
    app.kubernetes.io/managed-by: Helm
    chart: mlflow-0.7.20
    heritage: Helm
    release: mlflow-aut****
  name: mlflow-auto****-env-secret
  namespace: mlflow-namespace
  resourceVersion: ""317686863""
  uid: 9371d9cd-6cc6-4440-a82b-748831b1a1e6
type: Opaque
",via helm chart passing via get data kind secret helm chart heritage helm release name type opaque,issue,positive,positive,neutral,neutral,positive,positive
1772297535,"I am already passing credentials. via below command:

mlflow server --
host 0.0.0.0 --port 5000 --backend-store-uri mysql+pymysql://auto***:au***123@mlflow-autos***-my
sql.mlflow-namespace.svc.cluster.local:3306/autose***--gunicorn-opts --log-level debug --workers 2 --
default-artifact-root s3://auto***-artifacts/ --serve-artifacts",already passing via command server host port,issue,negative,neutral,neutral,neutral,neutral,neutral
1772294744,Looks like you're missing credentials. Can you try uploading/downloading artifacts using only boto3 without mlflow? Does it work or not?,like missing try without work,issue,negative,negative,negative,negative,negative,negative
1772293051,"@harupy Yes, I ran below code and here is the log for the same code:

code:
```
import mlflow
from time import time
from sklearn.model_selection import train_test_split
from sklearn.datasets import load_diabetes
from sklearn.ensemble import RandomForestRegressor
import numpy as np
from sklearn.metrics import accuracy_score
import joblib


def run_model():
    db = load_diabetes()
    X_train, X_test, y_train, y_test = train_test_split(db.data, db.target)

    ### TRAIN MODEL
    trained_model = RandomForestRegressor(n_estimators=100, max_depth=6, max_features=3)
    trained_model.fit(X_train, y_train)

    ### MLFLOW - LOG METRIC
    accurary = trained_model.score(X_test, y_test)
    print(""accurary:"", accurary)
    mlflow.log_metric(""mean-accuracy"", float(accurary))

    ### MLFLOW - LOG MODEL
    mlflow.sklearn.log_model(
        trained_model, ""random_forest""
    )  ### <- The second param is an arbitrary param


TMSTP = round(time() * 1000)

#### MLFLOW CONNECTION TEST
TRACK_URI = ""https://tracking-server-autosense.corp.****.com/auto***/""

EXPERIMENT_NAME = f""test_run_{TMSTP}""  ### <- DO NOT CHANGE THIS PART OF THE CODE.
# The below script creates a new experiment using the above variable and uses the returned experiment id to submit the training job.

if not mlflow.is_tracking_uri_set():
    # set tracking uri
    mlflow.set_tracking_uri(TRACK_URI)
    print(""mlflow tracking uri:"", mlflow.get_tracking_uri())
# Create an experiment if not exists and capture the experiment Id
EXPERIMENT_ID = mlflow.create_experiment(EXPERIMENT_NAME)
# set as active experiment
experiment = mlflow.set_experiment(EXPERIMENT_NAME)
print(
    f""Mlflow Active Experiment:{EXPERIMENT_NAME}\nMlflow Experiment ID:{EXPERIMENT_ID}""
)

### MLFLOW
# Set a batch of tags
tags = {
    ""engineering"": ""MLFlow Test"",
    ""tstmp"": str(TMSTP),
}

with mlflow.start_run(
    experiment_id=EXPERIMENT_ID,
    run_name=EXPERIMENT_NAME,
    tags=tags,
    description=EXPERIMENT_NAME,
):
    run_model()

```

logs
```
[2023-10-20 08:14:09 +0000] [25] [DEBUG] GET /ajax-api/2.0/mlflow/artifacts/list
2023/10/20 08:14:11 ERROR mlflow.server: Exception on /ajax-api/2.0/mlflow/artifacts/list [GET]
Traceback (most recent call last):
  File ""/usr/local/lib/python3.10/site-packages/flask/app.py"", line 2190, in wsgi_app
    response = self.full_dispatch_request()
  File ""/usr/local/lib/python3.10/site-packages/flask/app.py"", line 1486, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File ""/usr/local/lib/python3.10/site-packages/flask/app.py"", line 1484, in full_dispatch_request
    rv = self.dispatch_request()
  File ""/usr/local/lib/python3.10/site-packages/flask/app.py"", line 1469, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
  File ""/usr/local/lib/python3.10/site-packages/mlflow/server/handlers.py"", line 476, in wrapper
    return func(*args, **kwargs)
  File ""/usr/local/lib/python3.10/site-packages/mlflow/server/handlers.py"", line 517, in wrapper
    return func(*args, **kwargs)
  File ""/usr/local/lib/python3.10/site-packages/mlflow/server/handlers.py"", line 953, in _list_artifacts
    artifact_entities = _get_artifact_repo(run).list_artifacts(path)
  File ""/usr/local/lib/python3.10/site-packages/mlflow/store/artifact/s3_artifact_repo.py"", line 187, in list_artifacts
    for result in results:
  File ""/usr/local/lib/python3.10/site-packages/botocore/paginate.py"", line 269, in __iter__
    response = self._make_request(current_kwargs)
  File ""/usr/local/lib/python3.10/site-packages/botocore/paginate.py"", line 357, in _make_request
    return self._method(**current_kwargs)
  File ""/usr/local/lib/python3.10/site-packages/botocore/client.py"", line 535, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File ""/usr/local/lib/python3.10/site-packages/botocore/client.py"", line 963, in _make_api_call
    http, parsed_response = self._make_request(
  File ""/usr/local/lib/python3.10/site-packages/botocore/client.py"", line 986, in _make_request
    return self._endpoint.make_request(operation_model, request_dict)
  File ""/usr/local/lib/python3.10/site-packages/botocore/endpoint.py"", line 119, in make_request
    return self._send_request(request_dict, operation_model)
  File ""/usr/local/lib/python3.10/site-packages/botocore/endpoint.py"", line 198, in _send_request
    request = self.create_request(request_dict, operation_model)
  File ""/usr/local/lib/python3.10/site-packages/botocore/endpoint.py"", line 134, in create_request
    self._event_emitter.emit(
  File ""/usr/local/lib/python3.10/site-packages/botocore/hooks.py"", line 412, in emit
    return self._emitter.emit(aliased_event_name, **kwargs)
  File ""/usr/local/lib/python3.10/site-packages/botocore/hooks.py"", line 256, in emit
    return self._emit(event_name, kwargs)
  File ""/usr/local/lib/python3.10/site-packages/botocore/hooks.py"", line 239, in _emit
    response = handler(**kwargs)
  File ""/usr/local/lib/python3.10/site-packages/botocore/signers.py"", line 105, in handler
    return self.sign(operation_name, request)
  File ""/usr/local/lib/python3.10/site-packages/botocore/signers.py"", line 189, in sign
    auth.add_auth(request)
  File ""/usr/local/lib/python3.10/site-packages/botocore/auth.py"", line 418, in add_auth
    raise NoCredentialsError()
botocore.exceptions.NoCredentialsError: Unable to locate credentials

```",yes ran code log code code import time import time import import import import import import train model log metric print float log model second param arbitrary param round time connection test change part code script new experiment variable returned experiment id submit training job set print create experiment capture experiment id set active experiment experiment print active experiment experiment id set batch engineering test get error exception get recent call last file line response file line file line file line return file line wrapper return file line wrapper return file line run path file line result file line response file line return file line return file line file line return file line return file line request file line file line emit return file line emit return file line response handler file line handler return request file line sign request file line raise unable locate,issue,positive,negative,negative,negative,negative,negative
1771958953,Hi @SDonkelaarGDD This is a great idea! Please feel free to raise a PR and we'll review :) ,hi great idea please feel free raise review,issue,positive,positive,positive,positive,positive,positive
1771365953,"Ok. So the aws sig4 auth header needs to be added only after some of the other headers are computed. so a dedicated type of header plugin can be integrated in a specific step of the request sequence, such as after all other headers are computed and added. Makes sense to me.",sig header need added type header specific step request sequence added sense,issue,negative,neutral,neutral,neutral,neutral,neutral
1770447373,"@jerrylian-db 

> Given that it is a model registry stages feature (and not an alias-based one), 

For the sake of ""API hygiene"" this should then be documented since the version object returned by latest_version is inconsistent with that of  mlflow.get_model_version(). Can lead to lots of customer surprises.",given model registry feature one sake hygiene since version object returned inconsistent lead lot customer,issue,negative,neutral,neutral,neutral,neutral,neutral
1769880650,"@amesar One thing to point out with the `latest_versions` property of a Registered Model is that it is intended to return the latest model version per model registry stage. Given that it is a model registry stages feature (and not an alias-based one), unless there's a strong use-case for the `latest_versions` result containing aliases, I'm fine with it not returning aliases in the DB store.",one thing point property registered model intended return latest model version per model registry stage given model registry feature one unless strong result fine store,issue,positive,positive,positive,positive,positive,positive
1769878862,"@serena-ruan agree it potentially being time consuming to return aliases for each model version when searching for them with the SQL store backend. I will defer to you and @harupy to determine the performant way to implement this, if it is deemed necessary. The prod team can take it on to, but we would need to prioritize it against our other work. Personally, I would need to build more context on the SQL store backend.",agree potentially time consuming return model version searching store defer determine performant way implement necessary prod team take would need work personally would need build context store,issue,negative,neutral,neutral,neutral,neutral,neutral
1769791964,@harupy I sent you the video to the email address on your profile.,sent video address profile,issue,negative,neutral,neutral,neutral,neutral,neutral
1769787847,"> I'm learning the plugin options myself. Why add a specific request auth plugin instead of using the [Request Header plugin](https://github.com/mlflow/mlflow/blob/2158f3ce96ab4e0e41de2e833cae1c962a14c684/mlflow/tracking/request_header/registry.py#L16)? It seems like request header plugin is only used for tracking store calls.

Hi @DidgetyTech , we have mentioned the reason why adding this plugin in this issue: https://github.com/mlflow/mlflow/issues/9443. The current Request Header plugin will not fulfill some use cases regarding authentication/authorization.",learning add specific request instead request header like request header used store hi reason issue current request header fulfill use regarding,issue,positive,neutral,neutral,neutral,neutral,neutral
1769507841,"> LGTM! Thanks @prithvikannan ! Are there any examples that we need to update?

No, but we should extend the examples to demonstrate how to use these.",thanks need update extend demonstrate use,issue,positive,positive,positive,positive,positive,positive
1769314559,"Having the same issue here. Did anyone manage to fix it?
Isn't the experiment_id supposed to be an autoincremental field? Why is it passing an ID?
Mine is passing a huge number as string `'922966005052009440'`",issue anyone manage fix supposed field passing id mine passing huge number string,issue,negative,positive,positive,positive,positive,positive
1768786437,Is there a status report on this issue? I'm running into this problem myself. Thanks!,status report issue running problem thanks,issue,negative,positive,positive,positive,positive,positive
1768594573,"Somewhat related to useful packages missing from the base image, the prometheus exporter is also missing:

```
Traceback (most recent call last):
  File ""/usr/local/lib/python3.10/site-packages/gunicorn/arbiter.py"", line 609, in spawn_worker
    worker.init_process()
  File ""/usr/local/lib/python3.10/site-packages/gunicorn/workers/base.py"", line 134, in init_process
    self.load_wsgi()
  File ""/usr/local/lib/python3.10/site-packages/gunicorn/workers/base.py"", line 146, in load_wsgi
    self.wsgi = self.app.wsgi()
  File ""/usr/local/lib/python3.10/site-packages/gunicorn/app/base.py"", line 67, in wsgi
    self.callable = self.load()
  File ""/usr/local/lib/python3.10/site-packages/gunicorn/app/wsgiapp.py"", line 58, in load
    return self.load_wsgiapp()
  File ""/usr/local/lib/python3.10/site-packages/gunicorn/app/wsgiapp.py"", line 48, in load_wsgiapp
    return util.import_app(self.app_uri)
  File ""/usr/local/lib/python3.10/site-packages/gunicorn/util.py"", line 371, in import_app
    mod = importlib.import_module(module)
  File ""/usr/local/lib/python3.10/importlib/__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 1050, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 1027, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 1006, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 688, in _load_unlocked
  File ""<frozen importlib._bootstrap_external>"", line 883, in exec_module
  File ""<frozen importlib._bootstrap>"", line 241, in _call_with_frames_removed
  File ""/usr/local/lib/python3.10/site-packages/mlflow/server/__init__.py"", line 50, in <module>
    from mlflow.server.prometheus_exporter import activate_prometheus_exporter
  File ""/usr/local/lib/python3.10/site-packages/mlflow/server/prometheus_exporter.py"", line 2, in <module>
    from prometheus_flask_exporter.multiprocess import GunicornInternalPrometheusMetrics
ModuleNotFoundError: No module named 'prometheus_flask_exporter'
```

And, to workaround, you can of course extend the above Dockerfile with:
`pip install prometheus-flask-exporter`
",somewhat related useful missing base image exporter also missing recent call last file line file line file line file line file line load return file line return file line module file line return name level package level file frozen line file frozen line file frozen line file frozen line file frozen line file frozen line file line module import file line module import module course extend pip install,issue,negative,negative,negative,negative,negative,negative
1768112597,"Hey @harupy 
I'm willing to help with this one!",hey willing help one,issue,negative,positive,positive,positive,positive,positive
1767830367,"Hello @BenWilson2 
I came across this issue and saw that it is marked as a stale one. I'm interested in resolving the issue, may I be assigned to it?",hello came across issue saw marked stale one interested issue may assigned,issue,negative,negative,neutral,neutral,negative,negative
1767768395,"Hey @n3011 @harupy !
I came across the issue and took some time to debug the server's request handling. It turns out that [checking password hash](https://github.com/mlflow/mlflow/blob/master/mlflow/server/auth/sqlalchemy_store.py#L39) is what takes the majority of the time for a request to be processed. Seems to be functioning as designed, rather than an unintended bug?",hey came across issue took time server request handling turn password hash majority time request designed rather unintended bug,issue,negative,neutral,neutral,neutral,neutral,neutral
1767754514,Verified this issue happens for DB backend. I agree on this comment https://github.com/mlflow/mlflow/issues/9783#issuecomment-1744811171 It's time-consuming if there're lots of models/versions. Could we add an entry in SqlModelVersion for alias field directly? ,issue agree comment lot could add entry alias field directly,issue,negative,positive,neutral,neutral,positive,positive
1767629257,"> LGTM! Can we manually check if this patch fixes the issue?

Yep, I tested in devbox by installing this branch, these two tests pass",manually check patch issue yep tested branch two pas,issue,negative,neutral,neutral,neutral,neutral,neutral
1767447838,"I am closing this issue since there has not been any activity for 3 years, we can reopen on demand.",issue since activity reopen demand,issue,negative,neutral,neutral,neutral,neutral,neutral
1767446475,"This proposal is pretty valid to me, is this currently supported? @dbczumar ",proposal pretty valid currently,issue,negative,positive,positive,positive,positive,positive
1767386378,"@ml7 Thanks for the PR! We are not planning to extend the name list, if you are looking for something to start contributing, would you be interested in this one? #9744 thanks!",thanks extend name list looking something start would interested one thanks,issue,positive,positive,positive,positive,positive,positive
1767385572,This issue is stale because it has been open 14 days with no activity. Remove stale label or comment or this will be closed in 35 days.,issue stale open day activity remove stale label comment closed day,issue,negative,negative,negative,negative,negative,negative
1767344545,@janhurst Can you also try much older versions such as mlflow 2.1 or 1.30?,also try much older,issue,negative,positive,positive,positive,positive,positive
1766937235,"I'm learning the plugin options myself. Why add a specific request auth plugin instead of using the [Request Header plugin](https://github.com/mlflow/mlflow/blob/2158f3ce96ab4e0e41de2e833cae1c962a14c684/mlflow/tracking/request_header/registry.py#L16)? It seems like request header plugin is only used for tracking store calls.

",learning add specific request instead request header like request header used store,issue,negative,neutral,neutral,neutral,neutral,neutral
1766217754,"@harupy The `usedforsecurity` flag appears to get arround the issue. `hashlib.sha1` should work as well, though at some point FIPS is looking to move away from that (2025, I think), so the same flag may need to be supplied to sha1 if that is used in the future.",flag get issue work well though point looking move away think flag may need sha used future,issue,negative,neutral,neutral,neutral,neutral,neutral
1766014214,"@harupy  Hey, Could I work on this one? No sudden PR this time)",hey could work one sudden time,issue,negative,neutral,neutral,neutral,neutral,neutral
1765822884,Please make sure to comment before working on this.,please make sure comment working,issue,positive,positive,positive,positive,positive,positive
1765671916,"Hey, any progress on this fix? When is it going to be part of a release?",hey progress fix going part release,issue,negative,neutral,neutral,neutral,neutral,neutral
1765520172,"Hi @JaynouOliver We're working on the new website, so we shouldn't spend effort on adding darkmode on the current one. The new website should be coming out in the following months, and if we can get the dark mode for free with the new framework, we'll support it. :)",hi working new spend effort current one new coming following get dark mode free new framework support,issue,positive,positive,neutral,neutral,positive,positive
1765508093,"> @bhartlovecode I filed #9961. The following command install mlflow from this PR if you want to test it:
> 
> ```
> pip install git+https://github.com/mlflow/mlflow.git@refs/pull/9961/merge
> ```

Roger that. I'll give it a try tomorrow. Thanks for the quick turnaround!",following command install want test pip install roger give try tomorrow thanks quick turnaround,issue,negative,positive,positive,positive,positive,positive
1765493499,"@bhartlovecode I filed #9961. The following command install mlflow from this PR if you want to test it:

```
pip install git+https://github.com/mlflow/mlflow.git@refs/pull/9961/merge
```",following command install want test pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
1765405850,@santiagxf can you rebase on master branch to resolve the conflict?,rebase master branch resolve conflict,issue,negative,neutral,neutral,neutral,neutral,neutral
1765000351,"Discussed with @dbczumar offline. We aligned on the following API behavior:
When an mlflow Dataset is specified for evaluation, the `targets` and `predictions` column can only be specified through the Dataset, but not the top-level parameter of the mlflow.evaluate() API, because the Dataset is immutable; once created, we should not add `targets` and `predictions` attributes to it.

Concretely, this is not supported:
```python
    # Not supported
    data = mlflow.data.from_pandas(df=X.assign(y=y, model_output=y))  # missing targets, predictions
    with mlflow.start_run():
            mlflow.evaluate(
                data=data,
                model_type=""regressor"",
                targets=""y"",   # should not be specified here when data.targets is missing
                predictions=""model_output"",   # should not be specified here when data.predictions is missing
            )
```
The correct usage should be:
```python
    data = mlflow.data.from_pandas(df=X.assign(y=y, model_output=y), targets=""y"", predictions=""model_output"")
    with mlflow.start_run():
            mlflow.evaluate(
                data=data,
                model_type=""regressor"",
            )
```
The following is also allowed since the targets and predictions values are the same:
```python
    data = mlflow.data.from_pandas(df=X.assign(y=y, model_output=y), targets=""y"", predictions=""model_output"")
    with mlflow.start_run():
            mlflow.evaluate(
                data=data,
                model_type=""regressor"",
                targets=""y"",
                predictions=""model_output"",
            )
```",following behavior evaluation column parameter immutable add concretely python data missing regressor missing missing correct usage python data regressor following also since python data regressor,issue,negative,negative,neutral,neutral,negative,negative
1764681693,@janhurst Thanks for the investigation. Can you reproduce this behavior without using mlflow?,thanks investigation reproduce behavior without,issue,negative,positive,positive,positive,positive,positive
1764512330,"one small additional note, i can see the behaviour kicks when the pixel width swaps from <500 to >500 ... not sure if that has any significance?",one small additional note see behaviour width sure significance,issue,positive,positive,positive,positive,positive,positive
1764510986,"I'm completely stumped :(

I have separate Chrome profiles, one works as normal, one shows the behaviour above (even when in incognito mode). I've been toggling plugins and fiddling with fairly much everything I can think of but nothing seems to stick :~(

I don't think this is a scaling issue (as one profile works and another does not)

Any suggestions on what to try next warmly welcome... but I am guessing this is somehow related to something on my client side rather than an mlflow issue?!
",completely separate chrome one work normal one behaviour even incognito mode fiddling fairly much everything think nothing stick think scaling issue one profile work another try next warmly welcome guessing somehow related something client side rather issue,issue,positive,positive,positive,positive,positive,positive
1764030543,@nolwennz Feel free to reopen this issue if necessary.,feel free reopen issue necessary,issue,positive,positive,positive,positive,positive,positive
1763649822,"@amesar A few tips when reporting a bug:

1. Make sure that the issue can be reproduced by just running `python -c <code>`. I got `Registered Model with name=my-model not found` when I ran your code.
2. Run `mlflow.doctor()` and share the output as instructed in the bug report template.",bug make sure issue running python code got registered model found ran code run share output instructed bug report template,issue,positive,positive,positive,positive,positive,positive
1763630011,"Hi @amesar , I'm not able to reproduce your problem. I tried below code:
```
import mlflow
print(""mlflow version: "", mlflow.__version__)
client = mlflow.MlflowClient()

class TestModel(mlflow.pyfunc.PythonModel):
    def predict(self, context, model_input, params=None):
        return model_input

with mlflow.start_run():
    mlflow.pyfunc.log_model(
        artifact_path=""my-model"",
        python_model=TestModel(),
        registered_model_name=""my-model"",
    )

vr = client.get_model_version(""my-model"", ""1"")
client.set_registered_model_alias(vr.name, f""champ"", vr.version)
model = client.get_registered_model(vr.name)

print(""model.aliases:"", model.aliases) #  NOTE: alias is here

print(""model.latest_versions:"", model.latest_versions) # NOTE: aliases not there

vr = client.get_model_version(vr.name, vr.version)
print(""version.aliases:"", vr.aliases) #  NOTE: alias is here
```
And the output is like:
```
mlflow version:  2.7.1
Successfully registered model 'my-model'.
2023/10/16 10:28:17 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: my-model, version 1
Created version '1' of model 'my-model'.
model.aliases: {'champ': '1'}
model.latest_versions: [<ModelVersion: aliases=['champ'], creation_timestamp=1697423297762, current_stage='None', description=None, last_updated_timestamp=1697423297762, name='my-model', run_id='c545e846297a4c7bacb6f5c7f5efff52', run_link=None, source='file:///Users/serena.ruan/Documents/test/mlruns/0/c545e846297a4c7bacb6f5c7f5efff52/artifacts/my-model', status='READY', status_message=None, tags={}, user_id=None, version=1>]
version.aliases: ['champ']
```
Where ` model.latest_versions: [<ModelVersion: aliases=['champ']` contains alias.",hi able reproduce problem tried code import print version client class predict self context return champ model print note alias print note print note alias output like version successfully registered model waiting model version finish creation model name version version model alias,issue,positive,positive,positive,positive,positive,positive
1763413159,I would love to work on this issue @JaynouOliver @mlflow-automation ,would love work issue,issue,positive,positive,positive,positive,positive,positive
1763200062,@harupy Thanks for the confirmation! Can you build a container using the image and check if pyenv is available?,thanks confirmation build container image check available,issue,negative,positive,positive,positive,positive,positive
1763142123,@harupy After pulling the image locally I checked the docker history and it shows this command: `` RUN /bin/sh -c git clone     --depth 1     --branch $(git ls-remote --tags --sort=v:refname https://github.com/pyenv/pyenv.git | grep -o -E 'v[1-9]+(\.[1-9]+)+$' | tail -1)     https://github.com/pyenv/pyenv.git /root/.pyenv # buildkit ``,image locally checked docker history command run git clone depth branch git tail,issue,negative,neutral,neutral,neutral,neutral,neutral
1762952099,"Hi @harupy,
I would like to use this feature as well. If no one has been assigned yet, can I work on this instead?",hi would like use feature well one assigned yet work instead,issue,positive,neutral,neutral,neutral,neutral,neutral
1762922985,"I think this issue is not a bug but rather a misunderstanding of how to use MLflow.

`MLFLOW_S3_ENDPOINT_URL` is used when you want to work with custom endpoints like [MinIO](https://mlflow.org/docs/latest/tracking.html?highlight=minio).

Also it seems that using `MLFLOW_S3_ENDPOINT_URL` with `default-artifact-root` is not recommended. 

> The MLflow tracking server utilizes specific reserved keywords to generate a qualified path. These environment configurations, if present in the client environment, can create path resolution issues. For example, providing --default-artifact-root $MLFLOW_S3_ENDPOINT_URL on the server side and MLFLOW_S3_ENDPOINT_URL on the client side will create a client path resolution issue for the artifact storage location. Upon resolving the artifact storage location, the MLflow client will use the value provided by --default-artifact-root and suffixes the location with the values provided in the environment variable MLFLOW_S3_ENDPOINT_URL. Depending on the value set for the environment variable MLFLOW_S3_ENDPOINT_URL, the resulting artifact storage path for this scenario would be one of the following invalid object store paths: https://<bucketname>.s3.<region>.amazonaws.com/<key>/<bucketname>/<key> or s3://<bucketname>/<key>/<bucketname>/<key>. To prevent path parsing issues, ensure that reserved environment variables are removed (unset) from client environments.

If you want to store artifacts in S3, it's sufficient to use `default-artifact-root`. 

",think issue bug rather misunderstanding use used want work custom like also server specific reserved generate qualified path environment present client environment create path resolution example providing server side client side create client path resolution issue artifact storage location upon artifact storage location client use value provided location provided environment variable depending value set environment variable resulting artifact storage path scenario would one following invalid object store key key prevent path ensure reserved environment removed unset client want store sufficient use,issue,positive,neutral,neutral,neutral,neutral,neutral
1762817390,"Hi

Any news on this? I've tried to contact the email address provided but with no response after the initial message.
Joe",hi news tried contact address provided response initial message joe,issue,negative,neutral,neutral,neutral,neutral,neutral
1762814677,"or can we use `usedforsecurity=False`? https://docs.python.org/3/library/hashlib.html#constructors says:

> Changed in version 3.9: All hashlib constructors take a keyword-only argument usedforsecurity with default value True. A false value allows the use of insecure and blocked hashing algorithms in restricted environments. False indicates that the hashing algorithm is not used in a security context, e.g. as a non-cryptographic one-way compression function.

In MLflow, we're not using md5 in a security context.",use version take argument default value true false value use insecure blocked restricted false algorithm used security context compression function security context,issue,negative,negative,negative,negative,negative,negative
1762787039,"Another option is a function like this:

```python
import functools
import hashlib


@functools.lru_cache(max_size=1)
def get_hashing_func():
    try:
        hashlib.md5()
        return hashlib.md5
    except Exception:
        return hashlib.sha256

```",another option function like python import import try return except exception return,issue,negative,neutral,neutral,neutral,neutral,neutral
1762782115,`hashlib.sha256` would work great. It would be awesome if that could be switched via a flag or environment variable. ,would work great would awesome could switched via flag environment variable,issue,positive,positive,positive,positive,positive,positive
1762634974,"> export MLFLOW_S3_ENDPOINT_URL=s3://ait-dmirian-mlflowtest/mytests/

I missed this setting. With this setting, I could replicate the issue. I will investigate on it",export setting setting could replicate issue investigate,issue,negative,neutral,neutral,neutral,neutral,neutral
1762546826,we could add an environment variable to configure the hashing algorithm to use.,could add environment variable configure algorithm use,issue,negative,neutral,neutral,neutral,neutral,neutral
1762487501,"> Sure, I will read MLflow documents again and elaborate which documents I want to be added.

In that case, I will create another issue. So I will close this issue.
Thank you so much @harupy !",sure read elaborate want added case create another issue close issue thank much,issue,positive,positive,positive,positive,positive,positive
1762485337,"Sure, I will read MLflow documents again and elaborate which documents I want to be added.",sure read elaborate want added,issue,negative,positive,positive,positive,positive,positive
1762481887,"> BTW, can I add the explanation related to ""how to use artifact-repo"" to MLflow documents?

Can you elaborate?",add explanation related use elaborate,issue,negative,positive,positive,positive,positive,positive
1762479866,"I see, thank you!
BTW, can I add the explanation related to ""how to use artifact-repo"" to MLflow documents?
It would be helpful for other people as well",see thank add explanation related use would helpful people well,issue,positive,neutral,neutral,neutral,neutral,neutral
1762471529,"> are there any documents explaining which methods' outputs are stored to artifact-repo?

No, the following APIs **log** artifacts to artifact repos.

- `mlflow.log_artifacts`
- `mlflow.log_artifact`
- `mlflow.<flavor>.log_model`",explaining following log artifact flavor,issue,negative,neutral,neutral,neutral,neutral,neutral
1762468372,"Thanks @Gekko0114 for the report, but this is expected. `save_model` saves a model **locally**. `log_model` should be used instead.",thanks report model locally used instead,issue,negative,positive,neutral,neutral,positive,positive
1762418910,"Hi @ait-dmirian,

I attempted to replicate the issue by using an EC2 instance and S3. 
However, in my env, artifacts are stored in S3 and I can view these artifacts from the MLflow UI.
The error you encountered is an `EndPointResolutionError`, so I think there might be issues with how the S3 URL is configured in your env.
Could you kindly share more information about your environment, or consider closing the issue?
",hi replicate issue instance however view error think might could kindly share information environment consider issue,issue,negative,positive,positive,positive,positive,positive
1761523225,"I would reproduce the following way:

- Build the container using the Dockerfile above
- Spin up a RHEL 8 machine with FIPS enabled
- Run the container on that FIPS machine
- From the same machine (or another machine RHEL machine with FIPS enabled), run the code I supplied above. I believe it's the 'autolog' feature in particular that trips the error",would reproduce following way build container spin machine run container machine machine another machine machine run code believe feature particular error,issue,negative,positive,neutral,neutral,positive,positive
1761506485,"@harupy  Sure thing:
```
FROM docker.io/library/python:3.9

USER root
ENV NON_ROOT_USER=mlflow
ENV NON_ROOT_GID=""1000"" \
    NON_ROOT_UID=""1000"" \
    NON_ROOT_HOME_DIR=/home/${NON_ROOT_USER}

RUN groupadd -g $NON_ROOT_GID parser && useradd -m -s $NON_ROOT_HOME_DIR -u $NON_ROOT_UID $NON_ROOT_USER -g $NON_ROOT_GID

USER mlflow
COPY requirements.txt /tmp/requirements.txt
RUN pip3 install -r /tmp/requirements.txt
ENV PATH=""$PATH:/home/mlflow/.local/bin""
WORKDIR $NON_ROOT_HOME_DIR

CMD [""mlflow"", ""server"", ""--host"", ""0.0.0.0""]
```",sure thing user root run parser user copy run pip install path server host,issue,negative,positive,positive,positive,positive,positive
1761485010,"Alright, the Dockerfile is using a python39 base image, and we are installing mlflow version 2.7.1 using pip. The CMD for the Dockerfile is as follows:
`CMD [""mlflow"", ""server"", ""--host"", ""0.0.0.0""]`

Just as a quick note, I am running the above container as a pod and trying to communicate with it from another pod in the same cluster.

Here is the code I ran in my 'client' pod to trigger the error I saw:
```
import mlflow
from mlflow.models import infer_signature

from sklearn.model_selection import train_test_split
from sklearn.datasets import load_diabetes
from sklearn.ensemble import RandomForestRegressor

mlflow.set_tracking_uri('http://my-kubeflow-service')
mlflow.set_registry_uri('http://my-kubeflow-service')
mlflow.autolog()

db = load_diabetes()
X_train, X_test, y_train, y_test = train_test_split(db.data, db.target)

rf = RandomForestRegressor(n_estimators=100, max_depth=6, max_features=3)
rf.fit(X_train, y_train)

predictions = rf.predict(X_test)
```

Below is the Python error on the client side:
`2023/10/13 12:55:01 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during sklearn autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID a9ff66e5f1704b87a86ede9dbeec8217. Failed operations: [MlflowException(""API request to http://my-kubeflow-service/api/2.0/mlflow/runs/log-inputs failed with exception HTTPConnectionPool(host=\'my-kubeflow-service\', port=5000): Max retries exceeded with url: /api/2.0/mlflow/runs/log-inputs (Caused by ResponseError(\'too many 500 error responses\'))"")]')]`

And the error in the mlflow server pod:
mlflow 2023/10/13 12:55:01 ERROR mlflow.server: Exception on /api/2.0/mlflow/runs/log-inputs [POST]                                                                                                   
mlflow Traceback (most recent call last):                                                                                                                                                             
mlflow   File ""/home/mlflow/.local/lib/python3.9/site-packages/flask/app.py"", line 2190, in wsgi_app                                                                                                  
mlflow     response = self.full_dispatch_request()                                                                                                                                                    
mlflow   File ""/home/mlflow/.local/lib/python3.9/site-packages/flask/app.py"", line 1486, in full_dispatch_request                                                                                     
mlflow     rv = self.handle_user_exception(e)                                                                                                                                                         
mlflow   File ""/home/mlflow/.local/lib/python3.9/site-packages/flask/app.py"", line 1484, in full_dispatch_request                                                                                     
mlflow     rv = self.dispatch_request()                                                                                                                                                               
mlflow   File ""/home/mlflow/.local/lib/python3.9/site-packages/flask/app.py"", line 1469, in dispatch_request                                                                                          
mlflow     return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)                                                                                                                   
mlflow   File ""/home/mlflow/.local/lib/python3.9/site-packages/mlflow/server/handlers.py"", line 486, in wrapper                                                                                       
mlflow     return func(*args, **kwargs)                                                                                                                                                               
mlflow   File ""/home/mlflow/.local/lib/python3.9/site-packages/mlflow/server/handlers.py"", line 527, in wrapper                                                                                       
mlflow     return func(*args, **kwargs)                                                                                                                                                               
mlflow   File ""/home/mlflow/.local/lib/python3.9/site-packages/mlflow/server/handlers.py"", line 828, in _log_inputs                                                                                   
mlflow     _get_tracking_store().log_inputs(run_id, datasets=datasets)                                                                                                                                
mlflow   File ""/home/mlflow/.local/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py"", line 1108, in log_inputs                                                                         
mlflow     dataset_id = FileStore._get_dataset_id(                                                                                                                                                    
mlflow   File ""/home/mlflow/.local/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py"", line 1131, in _get_dataset_id                                                                    
mlflow     md5 = hashlib.md5(dataset_name.encode(""utf-8""))                                                                                                                                            
mlflow ValueError: [digital envelope routines: EVP_DigestInit_ex] disabled for FIPS  ",alright python base image version pip server host quick note running container pod trying communicate another pod cluster code ran pod trigger error saw import import import import import python error client side warning unexpected error following one logging perform one run id request exception many error error server pod error exception post recent call last file line response file line file line file line return file line wrapper return file line wrapper return file line file line file line digital envelope disabled,issue,negative,negative,neutral,neutral,negative,negative
1761097810,"Notes:

- Make sure to open a PR from a **non-master** branch.
- Sign off the commit using the `-s` flag when making a commit:

  ```sh
  git commit -s -m ""...""
           # ^^ make sure to use this
  ```

- Include `#{issue_number}` (e.g. `#123`) in the PR description when opening a PR.
",make sure open branch sign commit flag making commit sh git commit make sure use include description opening,issue,positive,positive,positive,positive,positive,positive
1760723536,@Beramos Please feel free to raise a PR and I'll review :) Thanks!,please feel free raise review thanks,issue,positive,positive,positive,positive,positive,positive
1760665836,"> I can supply the Dockerfile and specific versions tomorrow if that would help.

Awesome, that'd be helpful.",supply specific tomorrow would help awesome helpful,issue,positive,positive,positive,positive,positive,positive
1760664893,"@harupy I installed MLFlow using pip inside a Python based container and spun it up as a pod in a K8S cluster. I can supply the Dockerfile and specific versions tomorrow if that would help.The CMD for the Dockerfile was just 'mlflow server'. The pod was running on a  RHEL 8.8 based cluster with FIPS enabled. When I tried to save the model using the Python SDK, I got warnings regarding FIPS in the container. I'll update this thread with more details in the morning regarding the specific error and environment.",pip inside python based container spun pod cluster supply specific tomorrow would server pod running based cluster tried save model python got regarding container update thread morning regarding specific error environment,issue,negative,neutral,neutral,neutral,neutral,neutral
1760623744,@bwhartlove How can we reproduce the error? Can we use Docker to reproduce it?,reproduce error use docker reproduce,issue,negative,neutral,neutral,neutral,neutral,neutral
1760616748,"I'm not a maintainer but our (AzureML) python plugin overrides the TRACKING_URI scheme (""azureml://normalhttpserver"") and simply derives RestStore where we handle auth ourselves. I'm definitely interested in separation of the auth so i'll leave a couple comments if you don't mind, but just wanted to share how we unblocked ourselves",maintainer python scheme simply handle definitely interested separation leave couple mind share unblocked,issue,positive,positive,positive,positive,positive,positive
1760565912,@Beramos thanks for reporting this :) we should change the CLI source code.,thanks change source code,issue,negative,positive,positive,positive,positive,positive
1760332513,"@BenWilson2 Hello Ben, could you please take a look at this PR? It's blocking our progress right now and would appreciate your reviewing on it. Thanks!",hello ben could please take look blocking progress right would appreciate thanks,issue,positive,positive,positive,positive,positive,positive
1759977406,"my understanding is more commonly, `api/version` returns the release version rather than the framework version. Since there has not been activity for years, I am closing it. We can reopen on demand.",understanding commonly release version rather framework version since activity reopen demand,issue,negative,negative,negative,negative,negative,negative
1759974936,"This is a good addon feature, but considering our huge size of backlog, I am afraid we won't have bandwidth for this. ",good feature considering huge size backlog afraid wo,issue,positive,positive,positive,positive,positive,positive
1759971847,I am closing this issue due to lacking steady reproducible code.,issue due steady reproducible code,issue,negative,positive,neutral,neutral,positive,positive
1759966214,"Checked the run view page, it's already implemented.",checked run view page already,issue,negative,neutral,neutral,neutral,neutral,neutral
1759538929,"thanks, @push-kar-desh-pande 
passwordless sftp work fine for me,
the only thing to remember, that mlflow.ui will pick artifact from that sftp location, and if by any chance like me, your mlflow server and the artifact path are on the same server, then you have to keep server's public key in its own [authorized_keys] file as well along with client-side's public key

note: not to forget, to add the ""PubkeyAcceptedAlgorithms +ssh-rsa"" or any other protocol in the [/etc/ssh/sshd_config] file.

afterwards, ""sftp://[USER]@[IP]:/home/[USER]/.../track/"" can work fine",thanks work fine thing remember pick artifact location chance like server artifact path server keep server public key file well along public key note forget add protocol file afterwards user user work fine,issue,positive,positive,positive,positive,positive,positive
1758732535,"This is out of the current roadmap of MLflow, production monitoring is handled by each cloud provider for now.",current production handled cloud provider,issue,negative,neutral,neutral,neutral,neutral,neutral
1758730004,Since there hasn't been any activity for 4 years I am closing this issue. We can reopen on demand. ,since activity issue reopen demand,issue,negative,neutral,neutral,neutral,neutral,neutral
1758729718,"I think we should have this, let's put it to our backlog.",think let put backlog,issue,negative,neutral,neutral,neutral,neutral,neutral
1758449585,Is the optional column not already a feature as shown [here]( https://mlflow.org/docs/latest/models.html#column-based-signature-example)?,optional column already feature shown,issue,negative,neutral,neutral,neutral,neutral,neutral
1758252092,"We will close this bug, and we are in an active effort to improve our docs.",close bug active effort improve,issue,positive,negative,negative,negative,negative,negative
1758250249,"This issue has been inactive for years, so I am closing it. We can reopen on demand.",issue inactive reopen demand,issue,negative,neutral,neutral,neutral,neutral,neutral
1758245497,"@harupy @BenWilson2 This is overlapping with rendering notebook in artifact section as we discussed yesterday, do we currently support rendering an html doc?",rendering notebook artifact section yesterday currently support rendering doc,issue,negative,neutral,neutral,neutral,neutral,neutral
1758073535,Would love to use this. Any ETA on when it might be merged?,would love use eta might,issue,positive,positive,positive,positive,positive,positive
1757752581,"@harupy Yes, the pyfunc image on version 2.7.1 is used for the model that is associated to the endpoint config with serverless. Both the model and the endpoint config with serverless deploy successfully, it's the endpoint that fails with the pyenv error. 

Below is the production variant model and endpoint config associated with the failed endpoint, we can see the production variant has the serverless config associated (memory size and max concurrency).
![Screenshot 2023-10-11 at 9 45 54 AM](https://github.com/mlflow/mlflow/assets/79466504/1edaad2d-f9fc-4894-9e8f-686ea37a8edc)

This shows the actual model config and the image associated. We can see I'm utilizing `mlflow-pyfunc:2.7.1`
![Screenshot 2023-10-11 at 9 46 43 AM](https://github.com/mlflow/mlflow/assets/79466504/ccc8edbc-4d86-4600-ae6d-dd1c01445052)

For full transparency this is the endpoint config itself: 
![Screenshot 2023-10-11 at 9 44 36 AM](https://github.com/mlflow/mlflow/assets/79466504/ef7ed573-5eb5-44ae-b68f-da0e730228ed)


",yes image version used model associated model deploy successfully error production variant model associated see production variant associated memory size concurrency actual model image associated see full transparency,issue,negative,positive,positive,positive,positive,positive
1757446502,@gabrielfu Thanks for the confirmation! Looks like it's related to resolution/scaling as @janhurst explained in https://github.com/mlflow/mlflow/issues/9881#issuecomment-1755518278.,thanks confirmation like related,issue,positive,positive,neutral,neutral,positive,positive
1757442156,@harupy Thank you for the suggestions. Could you please take another look when you have time?,thank could please take another look time,issue,positive,neutral,neutral,neutral,neutral,neutral
1757394696,"@harupy no issues for me either, chrome 117.0.5938.150

```shell
docker run --rm -w /mlflow -v C:\Users\Gabriel\code\playground\mlruns:/mlflow/mlruns -p 5000:5000 python:3.8 bash -c 'pip install mlflow && mlflow server --host 0.0.0.0 --gunicorn-opts ""--log-level=debug""'
```

![image](https://github.com/mlflow/mlflow/assets/22888849/89304706-c622-4409-956b-d975760732d9)
![image](https://github.com/mlflow/mlflow/assets/22888849/421e9dd3-51a5-4173-acb7-513e6ae6a9d2)
",either chrome shell docker run python bash install server host image image,issue,negative,neutral,neutral,neutral,neutral,neutral
1757163453,"@kavita1205 I could not reproduce the issue. How can we reproduce it?

```
docker run --rm -p 5000:5000 python:3.8 bash -c 'pip install mlflow==2.7.1 && mlflow server --host 0.0.0.0 --static-prefix /test --gunicorn-opts ""--log-level debug""'
```

<img width=""1875"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/17039389/f6f5dda3-dbbf-454a-b628-cf87dbeaa010"">
",could reproduce issue reproduce docker run python bash install server host image,issue,negative,neutral,neutral,neutral,neutral,neutral
1756846864,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`.

If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",wo notify release get touch new version available rather skip next major minor version let know ignore major version ignore minor version change mind resolve,issue,negative,positive,neutral,neutral,positive,positive
1756737786,"@mohitanchlia I'm trying to reproduce the issue.

compose.yml

```yaml
services:
  mysql-tracking:
    image: mysql
    restart: always
    environment:
      MYSQL_ROOT_PASSWORD: root-password
      MYSQL_DATABASE: mlflowdb
      MYSQL_USER: mlflowuser
      MYSQL_PASSWORD: mlflowpassword
    command: mysqld --default-authentication-plugin=mysql_native_password

  mysql-auth:
    image: mysql
    restart: always
    environment:
      MYSQL_ROOT_PASSWORD: root-password
      MYSQL_DATABASE: mlflowdb
      MYSQL_USER: mlflowuser
      MYSQL_PASSWORD: mlflowpassword
    command: mysqld --default-authentication-plugin=mysql_native_password

  mlflow:
    image: mlflow
    build:
      context: .
    depends_on:
      - mysql-tracking
      - mysql-auth
    working_dir: /mlflow
    volumes:
      - ./auth.ini:/tmp/auth.ini
    environment:
      - MLFLOW_AUTH_CONFIG_PATH=/tmp/auth.ini
    command: bash -c ""pip install --force-reinstall --no-deps . && mlflow server --host 0.0.0.0 --port 5000 --workers 1 --app-name basic-auth --backend-store-uri mysql://mlflowuser:mlflowpassword@mysql-tracking:3306/mlflowdb?charset=utf8mb4""
```

Dockerfile

```Dockerfile
FROM python:3.10

RUN pip install mlflow pymysql mysqlclient
```

auth.ini

```
[mlflow]
default_permission = NO_PERMISSIONS
database_uri = mysql://mlflowuser:mlflowpassword@mysql-auth:3306/mlflowdb?charset=utf8mb4
admin_username = admin
admin_password = password
```

The auth database migration got stuck.

```
...

mysql-mlflow-1          | 2023/10/11 03:24:01 INFO mlflow.store.db.utils: Creating initial MLflow database tables...
mysql-mlflow-1          | 2023/10/11 03:24:01 INFO mlflow.store.db.utils: Updating database tables
mysql-mysql-tracking-1  | 2023-10-11T03:24:01.352899Z 9 [Warning] [MY-013360] [Server] Plugin mysql_native_password reported: ''mysql_native_password' is deprecated and will be removed in a future release. Please use caching_sha2_password instead'
mysql-mlflow-1          | INFO  [alembic.runtime.migration] Context impl MySQLImpl.
mysql-mlflow-1          | INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
mysql-mlflow-1          | INFO  [alembic.runtime.migration] Running upgrade  -> 451aebb31d03, add metric step
mysql-mlflow-1          | INFO  [alembic.runtime.migration] Running upgrade 451aebb31d03 -> 90e64c465722, migrate user column to tags
mysql-mlflow-1          | INFO  [alembic.runtime.migration] Running upgrade 90e64c465722 -> 181f10493468, allow nulls for metric values
mysql-mlflow-1          | INFO  [alembic.runtime.migration] Running upgrade 181f10493468 -> df50e92ffc5e, Add Experiment Tags Table
mysql-mlflow-1          | INFO  [alembic.runtime.migration] Running upgrade df50e92ffc5e -> 7ac759974ad8, Update run tags with larger limit
mysql-mlflow-1          | INFO  [alembic.runtime.migration] Running upgrade 7ac759974ad8 -> 89d4b8295536, create latest metrics table
mysql-mlflow-1          | INFO  [89d4b8295536_create_latest_metrics_table_py] Migration complete!
mysql-mlflow-1          | INFO  [alembic.runtime.migration] Running upgrade 89d4b8295536 -> 2b4d017a5e9b, add model registry tables to db
mysql-mlflow-1          | INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Adding registered_models and model_versions tables to database.
mysql-mlflow-1          | INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Migration complete!
mysql-mlflow-1          | INFO  [alembic.runtime.migration] Running upgrade 2b4d017a5e9b -> cfd24bdc0731, Update run status constraint with killed
mysql-mlflow-1          | INFO  [alembic.runtime.migration] Running upgrade cfd24bdc0731 -> 0a8213491aaa, drop_duplicate_killed_constraint
mysql-mlflow-1          | INFO  [alembic.runtime.migration] Running upgrade 0a8213491aaa -> 728d730b5ebd, add registered model tags table
mysql-mlflow-1          | INFO  [alembic.runtime.migration] Running upgrade 728d730b5ebd -> 27a6a02d2cf1, add model version tags table
mysql-mlflow-1          | INFO  [alembic.runtime.migration] Running upgrade 27a6a02d2cf1 -> 84291f40a231, add run_link to model_version
mysql-mlflow-1          | INFO  [alembic.runtime.migration] Running upgrade 84291f40a231 -> a8c4a736bde6, allow nulls for run_id
mysql-mlflow-1          | INFO  [alembic.runtime.migration] Running upgrade a8c4a736bde6 -> 39d1c3be5f05, add_is_nan_constraint_for_metrics_tables_if_necessary
mysql-mlflow-1          | INFO  [alembic.runtime.migration] Running upgrade 39d1c3be5f05 -> c48cb773bb87, reset_default_value_for_is_nan_in_metrics_table_for_mysql
mysql-mlflow-1          | INFO  [alembic.runtime.migration] Running upgrade c48cb773bb87 -> bd07f7e963c5, create index on run_uuid
mysql-mlflow-1          | INFO  [alembic.runtime.migration] Running upgrade bd07f7e963c5 -> 0c779009ac13, add deleted_time field to runs table
mysql-mlflow-1          | INFO  [alembic.runtime.migration] Running upgrade 0c779009ac13 -> cc1f77228345, change param value length to 500
mysql-mlflow-1          | INFO  [alembic.runtime.migration] Running upgrade cc1f77228345 -> 97727af70f4d, Add creation_time and last_update_time to experiments table
mysql-mlflow-1          | INFO  [alembic.runtime.migration] Running upgrade 97727af70f4d -> 3500859a5d39, Add Model Aliases table
mysql-mlflow-1          | INFO  [alembic.runtime.migration] Running upgrade 3500859a5d39 -> 7f2a7d5fae7d, add datasets inputs input_tags tables
mysql-mlflow-1          | INFO  [alembic.runtime.migration] Running upgrade 7f2a7d5fae7d -> 2d6e25af4d3e, increase max param val length from 500 to 8000
mysql-mlflow-1          | INFO  [alembic.runtime.migration] Context impl MySQLImpl.
mysql-mlflow-1          | INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
mysql-mysql-tracking-1  | 2023-10-11T03:24:02.104225Z 10 [Warning] [MY-013360] [Server] Plugin mysql_native_password reported: ''mysql_native_password' is deprecated and will be removed in a future release. Please use caching_sha2_password instead'
mysql-mlflow-1          | [2023-10-11 03:24:02 +0000] [47] [INFO] Starting gunicorn 21.2.0
mysql-mlflow-1          | [2023-10-11 03:24:02 +0000] [47] [INFO] Listening at: http://0.0.0.0:5000 (47)
mysql-mlflow-1          | [2023-10-11 03:24:02 +0000] [47] [INFO] Using worker: sync
mysql-mlflow-1          | [2023-10-11 03:24:02 +0000] [48] [INFO] Booting worker with pid: 48
mysql-mlflow-1          | 2023/10/11 03:24:02 WARNING mlflow.server.auth: This feature is still experimental and may change in a future release without warning
mysql-mysql-auth-1      | 2023-10-11T03:24:02.996126Z 8 [Warning] [MY-013360] [Server] Plugin mysql_native_password reported: ''mysql_native_password' is deprecated and will be removed in a future release. Please use caching_sha2_password instead'
mysql-mlflow-1          | 2023/10/11 03:24:02 INFO mlflow.server.auth.db.utils: Migrating database to revision head
mysql-mlflow-1          | 2023/10/11 03:24:03 INFO mlflow.server.auth.db.utils: Started migration
mysql-mysql-auth-1      | 2023-10-11T03:24:03.002440Z 9 [Warning] [MY-013360] [Server] Plugin mysql_native_password reported: ''mysql_native_password' is deprecated and will be removed in a future release. Please use caching_sha2_password instead'
mysql-mlflow-1          | INFO  [alembic.runtime.migration] Context impl MySQLImpl.
mysql-mlflow-1          | INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
mysql-mlflow-1          | [2023-10-11 03:24:32 +0000] [47] [CRITICAL] WORKER TIMEOUT (pid:48)
mysql-mlflow-1          | [2023-10-11 03:24:33 +0000] [47] [ERROR] Worker (pid:48) was sent SIGKILL! Perhaps out of memory?
mysql-mlflow-1          | [2023-10-11 03:24:33 +0000] [80] [INFO] Booting worker with pid: 80
mysql-mlflow-1          | 2023/10/11 03:24:34 WARNING mlflow.server.auth: This feature is still experimental and may change in a future release without warning
mysql-mysql-auth-1      | 2023-10-11T03:24:34.017623Z 10 [Warning] [MY-013360] [Server] Plugin mysql_native_password reported: ''mysql_native_password' is deprecated and will be removed in a future release. Please use caching_sha2_password instead'
mysql-mlflow-1          | 2023/10/11 03:24:34 INFO mlflow.server.auth.db.utils: Migrating database to revision head
mysql-mlflow-1          | 2023/10/11 03:24:34 INFO mlflow.server.auth.db.utils: Started migration
mysql-mysql-auth-1      | 2023-10-11T03:24:34.026926Z 11 [Warning] [MY-013360] [Server] Plugin mysql_native_password reported: ''mysql_native_password' is deprecated and will be removed in a future release. Please use caching_sha2_password instead'
mysql-mlflow-1          | INFO  [alembic.runtime.migration] Context impl MySQLImpl.
mysql-mlflow-1          | INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
mysql-mlflow-1          | INFO  [alembic.runtime.migration] Running upgrade  -> 8606fa83a998, initial_migration
mysql-mlflow-1          | [2023-10-11 03:24:34 +0000] [47] [ERROR] Worker (pid:80) exited with code 3
mysql-mlflow-1          | [2023-10-11 03:24:34 +0000] [47] [ERROR] Shutting down: Master
mysql-mlflow-1          | [2023-10-11 03:24:34 +0000] [47] [ERROR] Reason: Worker failed to boot.
mysql-mlflow-1          | Running the mlflow server failed. Please see the logs above for details.
mysql-mlflow-1 exited with code 1
```",trying reproduce issue image restart always environment command image restart always environment command image build context environment command bash pip install server host port python run pip install password migration got stuck initial table table warning server removed future release please use context assume running upgrade add metric step running upgrade migrate user column running upgrade allow metric running upgrade add experiment table running upgrade update run limit running upgrade create latest metric table migration complete running upgrade add model registry table table migration complete running upgrade update run status constraint running upgrade running upgrade add registered model table running upgrade add model version table running upgrade fa add running upgrade fa allow running upgrade running upgrade running upgrade create index running upgrade add field table running upgrade change param value length running upgrade add table running upgrade ad add model table running upgrade ad add table running upgrade increase param length context assume warning server removed future release please use starting listening worker sync booting worker warning feature still experimental may change future release without warning warning server removed future release please use revision head migration warning server removed future release please use context assume critical worker error worker sent perhaps memory booting worker warning feature still experimental may change future release without warning warning server removed future release please use revision head migration warning server removed future release please use context assume running upgrade error worker code error shutting master error reason worker boot running server please see code,issue,negative,positive,neutral,neutral,positive,positive
1756595717,"> it's only when the serverless config is added.

Is it possible to check what image is used with the serverless config? Is the same image used?",added possible check image used image used,issue,negative,neutral,neutral,neutral,neutral,neutral
1756487741,"> @serena-ruan please confirm that the behavior change reflected in this fix matches the behavior that you were intending in #9874 . Previous behavior prior to that PR was to coerce the signature to a pandas DF mapping of columns from a List[str] input.
> 
> Question: Does the change in #9874 work as expected for model serving use cases with a defined schema for the following conditions:
> 
> 1. Model is saved with an inferred signature based on a List[str] input example
> 2. Model is saved with default signature and a pd.DataFrame representation is submitted to serving (with different split formats)

@BenWilson2 Yes, this fix matches the expected behavior in #9874, thanks! My test case contains a serving example for 1. For 2, it seems irrelevant to this change as the change only affects how we infer the signature?",please confirm behavior change reflected fix behavior intending previous behavior prior coerce signature list input question change work model serving use defined schema following model saved signature based list input example model saved default signature representation serving different split yes fix behavior thanks test case serving example irrelevant change change infer signature,issue,positive,negative,neutral,neutral,negative,negative
1756239934,"Yes @harupy is right, I was also getting the same error, then I wrote the code just above start_run() method, now there are only warnings, but it works fine - 

WARNING: connectionpool: Retrying (Retry(total=4, connect=5, read=5, redirect=5, status=5)) after connection broken by 'SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:2427)')': /anuj6263/Kidney_Disease_classifier.mlflow/api/2.0/mlflow-artifacts/artifacts/fa0d67bed8a14b53b3b322d405cdef8f/bc1cac0b2b6045f397fb228d772d3694/artifacts/model/data/model/variables/variables.data-00000-of-00001]
Successfully registered model 'VGG16Model'.",yes right also getting error wrote code method work fine warning retry connection broken violation protocol successfully registered model,issue,negative,positive,positive,positive,positive,positive
1756213771,"@dependabot[bot] Thank you for the contribution! Could you fix the following issue(s)?

#### &#x26a0; Invalid PR template

This PR does not appear to have been filed using the MLflow PR template. Please copy the PR template from [here](https://raw.githubusercontent.com/mlflow/mlflow/master/.github/pull_request_template.md) and fill it out.",bot thank contribution could fix following issue invalid template appear template please copy template fill,issue,positive,neutral,neutral,neutral,neutral,neutral
1756130592,"@serena-ruan please confirm that the behavior change reflected in this fix matches the behavior that you were intending in #9874 . 
Previous behavior prior to that PR was to coerce the signature to a pandas DF mapping of columns from a List[str] input. 

Question: Does the change in #9874 work as expected for model serving use cases with a defined schema for the following conditions:

1. Model is saved with an inferred signature based on a List[str] input example
2. Model is saved with default signature and a pd.DataFrame representation is submitted to serving (with different split formats) ",please confirm behavior change reflected fix behavior intending previous behavior prior coerce signature list input question change work model serving use defined schema following model saved signature based list input example model saved default signature representation serving different split,issue,positive,negative,neutral,neutral,negative,negative
1755797382,"@harupy Sorry for the delay.

 From building the pyfunc image locally:
```
#11 [ 7/20] RUN git clone     --depth 1     --branch $(git ls-remote --tags --sort=v:refname https://github.com/pyenv/pyenv.git | grep -o -E 'v[1-9]+(\.[1-9]+)+$' | tail -1)     https://github.com/pyenv/pyenv.git /root/.pyenv
#11 0.847 Cloning into '/root/.pyenv'...
#11 1.523 Note: switching to 'bb38acd99460f6dd2c5367cbc28947c4ef2fc209'.
#11 1.523 
#11 1.523 You are in 'detached HEAD' state. You can look around, make experimental
#11 1.523 changes and commit them, and you can discard any commits you make in this
#11 1.523 state without impacting any branches by switching back to a branch.
#11 1.523 
#11 1.523 If you want to create a new branch to retain commits you create, you may
#11 1.523 do so (now or later) by using -c with the switch command. Example:
#11 1.523 
#11 1.523   git switch -c <new-branch-name>
#11 1.523 
#11 1.523 Or undo this operation with:
#11 1.523 
#11 1.523   git switch -
#11 1.523 
#11 1.523 Turn off this advice by setting config variable advice.detachedHead to false
#11 1.523 
#11 DONE 1.6s
```

Looks to be building as expected. The strange thing is that deployments for real time endpoints work fine, it's only when the serverless config is added. I'm thinking the issue lies somewhere in how dependencies are leveraged for AWS serverless. I am not very familiar with what is happening underneath the hood at inference time as it relates to the pyfunc image though.",sorry delay building image locally run git clone depth branch git tail note switching head state look around make experimental commit discard make state without switching back branch want create new branch retain create may later switch command example git switch undo operation git switch turn advice setting variable false done building strange thing real time work fine added thinking issue somewhere familiar happening underneath hood inference time image though,issue,negative,positive,neutral,neutral,positive,positive
1755708691,@harupy Resolved! Could you take a look?,resolved could take look,issue,negative,neutral,neutral,neutral,neutral,neutral
1755518278,"> @janhurst Can you try toggling more CSS styles? Is there a CSS style that removes the space?

I had a play around but nothing obvious jumped out to me....but this is where it gets weird (!)

I remoted from my laptop onto my desktop via RDP and the whitespace is gone! So exactly same browser/config is behaving differently when I am logged in locally compared to when I am remoted via RDP.

This has me wondering if there is something odd with font scaling or something similar. My laptop is a Dell XPS 17 with a 4K screen, whilst my desktop is a Samsung 49"" UQHD. I am a bit of a loss as to explain whats going on here now :(

I will try to do some more testing w/ my laptop connected directly to the UQHD display and fiddling with the resolutions and scaling settings etc.",try style space play around nothing obvious weird onto via gone exactly differently logged locally via wondering something odd font scaling something similar dell screen whilst bit loss explain whats going try testing connected directly display fiddling scaling,issue,negative,negative,neutral,neutral,negative,negative
1755453340,"It would be nice to be able to ""Show Differences Only"" in the Table View among the Parameters/Metrics as it was possible in the older versions (i.e. 1.23.1) to distinguish the runs at a glance.",would nice able show table view among possible older distinguish glance,issue,negative,positive,positive,positive,positive,positive
1755386163,"> @DeependraParichha1004 You need to call `mlflow.set_tracking_uri` before starting a run. Feel free to open this issue if that doesn't fix the error.

I got another error, maybe i need to contact Dagshub:-
Traceback (most recent call last):
  File ""example.py"", line 102, in <module>
    lr, ""model"", registered_model_name=""ElasticnetWineModel"",signature=signature)
  File ""C:\Users\ASUS\.pyenv\pyenv-win\versions\3.7.4\lib\site-packages\mlflow\sklearn\__init__.py"", line 420, in log_model
    pyfunc_predict_fn=pyfunc_predict_fn,
  File ""C:\Users\ASUS\.pyenv\pyenv-win\versions\3.7.4\lib\site-packages\mlflow\models\model.py"", line 387, in log
    await_registration_for=await_registration_for,
  File ""C:\Users\ASUS\.pyenv\pyenv-win\versions\3.7.4\lib\site-packages\mlflow\tracking\_model_registry\fluent.py"", line 74, in register_model
    raise e
  File ""C:\Users\ASUS\.pyenv\pyenv-win\versions\3.7.4\lib\site-packages\mlflow\tracking\_model_registry\fluent.py"", line 65, in register_model
    create_model_response = client.create_registered_model(name)
  File ""C:\Users\ASUS\.pyenv\pyenv-win\versions\3.7.4\lib\site-packages\mlflow\tracking\client.py"", line 1847, in create_registered_model
    return self._get_registry_client().create_registered_model(name, tags, description)
  File ""C:\Users\ASUS\.pyenv\pyenv-win\versions\3.7.4\lib\site-packages\mlflow\tracking\_model_registry\client.py"", line 59, in create_registered_model
    return self.store.create_registered_model(name, tags, description)
  File ""C:\Users\ASUS\.pyenv\pyenv-win\versions\3.7.4\lib\site-packages\mlflow\store\model_registry\rest_store.py"", line 83, in create_registered_model
    response_proto = self._call_endpoint(CreateRegisteredModel, req_body)
  File ""C:\Users\ASUS\.pyenv\pyenv-win\versions\3.7.4\lib\site-packages\mlflow\store\model_registry\rest_store.py"", line 64, in _call_endpoint
    return call_endpoint(self.get_host_creds(), endpoint, method, json_body, response_proto)
  File ""C:\Users\ASUS\.pyenv\pyenv-win\versions\3.7.4\lib\site-packages\mlflow\utils\rest_utils.py"", line 280, in call_endpoint
    response = verify_rest_response(response, endpoint)
  File ""C:\Users\ASUS\.pyenv\pyenv-win\versions\3.7.4\lib\site-packages\mlflow\utils\rest_utils.py"", line 206, in verify_rest_response
    raise RestException(json.loads(response.text))
mlflow.exceptions.RestException: INTERNAL_ERROR: Response: {'error': 'unsupported endpoint, please contact support@dagshub.com'}
",need call starting run feel free open issue fix error got another error maybe need contact recent call last file line module model file line file line log file line raise file line name file line return name description file line return name description file line file line return method file line response response file line raise response please contact support,issue,negative,positive,neutral,neutral,positive,positive
1755096675,"@montanarograziano I found a few more flavors we need to update.

- catboost
- h2o
- diviner

Would you be interested in updating them? No need to create new issues for them. One PR to update all of them is fine.",found need update ho diviner would interested need create new one update fine,issue,positive,positive,positive,positive,positive,positive
1755056005,Is it possible to split this PR? I think it's too large and challenging to review.,possible split think large review,issue,negative,positive,positive,positive,positive,positive
1754715712,"Hi @BenWilson2 , @smurching ,
The CI looks good ! Please let me know if something else is needed !",hi good please let know something else,issue,positive,positive,positive,positive,positive,positive
1754416271,@DeependraParichha1004 You need to call `mlflow.set_tracking_uri` before starting a run. Feel free to open this issue if that doesn't fix the error.,need call starting run feel free open issue fix error,issue,negative,positive,positive,positive,positive,positive
1754356021,"What does this HTML look like on your machine?

```html
<!DOCTYPE html>
<html lang=""en"">
  <head>
    <meta charset=""UTF-8"" />
    <meta name=""viewport"" content=""width=device-width, initial-scale=1.0"" />
    <title>Document</title>
    <style>
      div {
        width: 160px;
        height: 80px;
        padding: 20px;
        border: 8px solid red;
        background: yellow;
      }

      .content-box {
        box-sizing: content-box;
      }

      .border-box {
        box-sizing: border-box;
      }
    </style>
  </head>
  <body>
    <div class=""content-box"">Content box</div>
    <br />
    <div class=""border-box"">Border box</div>
  </body>
</html>

```",look like machine en head meta meta title document style div width height padding border solid red background yellow body div content box div border box,issue,negative,neutral,neutral,neutral,neutral,neutral
1754342746,"> @janhurst Can you try disabling all the chrome extensions?

no change in incognito mode with all extensions disabled

> Tested Microsoft Edge:

I barely use edge, so on this machine it is about as ""clean"" as I can make it.

![image](https://github.com/mlflow/mlflow/assets/16224889/54512793-19e7-4e1b-95c5-92b0e21cc7a6)

",try chrome change incognito mode disabled tested edge barely use edge machine clean make image,issue,negative,positive,neutral,neutral,positive,positive
1754331251,"Tested Microsoft Edge (on macbook):

<img width=""1671"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/17039389/5668bf43-2fb3-4a0e-a4a4-65b95358c009"">

Looks fine.
",tested edge image fine,issue,negative,positive,positive,positive,positive,positive
1754299692,"> @janhurst Thanks for the investigation! Does this occur in mlflow 2.6?

yes seems to be the same issue in mlflow 2.6",thanks investigation occur yes issue,issue,positive,positive,positive,positive,positive,positive
1754294444,"not quite the same as the vid you posted, i see a scrollbar appear, but that whitespace that changes on your vid stays the same for me",quite posted see appear stay,issue,negative,neutral,neutral,neutral,neutral,neutral
1754223277,"Directing std output to MLflow is a tough work, and it's not aligned with our product scope. Actually logging should be handled by the training platform, like GCP/AWS/Azure instead on mlflow. ",output tough work product scope actually logging handled training platform like instead,issue,negative,negative,negative,negative,negative,negative
1754222052,"this issue has been inactive for 3 years, so I am closing it. We can reopen on demand in the future.",issue inactive reopen demand future,issue,negative,neutral,neutral,neutral,neutral,neutral
1754221212,"This issue hasn't received any activity since marked with `awaiting-more-evidence`, so I am closing it. we can reopen on demand.",issue received activity since marked reopen demand,issue,negative,positive,neutral,neutral,positive,positive
1754203322,"I've now just checked in Mozilla Firefox, and the issue is not present. It seems to occur in Google Chrome and Microsoft Edge (same engine?).",checked issue present occur chrome edge engine,issue,negative,neutral,neutral,neutral,neutral,neutral
1754194489,"> The command I used:
> 
> ```
> docker run --rm -w /mlflow -v $(pwd)/mlruns:/mlflow/mlruns -p 5000:5000 python:3.8 bash -c 'pip install mlflow && mlflow server --host 0.0.0.0 --gunicorn-opts ""--log-level debug""'
> ```
> 
> I'm using a Macbook. It could be a windows-only issue.

@harupy this is the output from the same docker command:
![image](https://github.com/mlflow/mlflow/assets/16224889/4f974f2b-2c48-4716-aefb-b8a8fe31c1a7)

I can't tell what is filling the empty space, there is no element that I can select :(
![image](https://github.com/mlflow/mlflow/assets/16224889/5783bcd3-a7b5-4043-9fce-7a447365a3ff)

If I select the empty space the outer div seems to be selected:
![image](https://github.com/mlflow/mlflow/assets/16224889/95582030-9267-4d3d-a0f7-6895d0a82240)

",command used docker run python bash install server host could issue output docker command image ca tell filling empty space element select image select empty space outer div selected image,issue,negative,negative,neutral,neutral,negative,negative
1754055115,"@DeependraParichha1004 

I see `repo not associated with run` in your stack trace. MLflow doesn't contain this message. This implies something went wrong in DagsHub. Can you report this issue to them?",see associated run stack trace contain message something went wrong report issue,issue,negative,negative,negative,negative,negative,negative
1754053362,"@nolwennz Can you reproduce this issue without using Kubernetes? For memory usage tracking, we could use https://pypi.org/project/memray/.",reproduce issue without memory usage could use,issue,negative,neutral,neutral,neutral,neutral,neutral
1754038604,@TomeHirata Thanks for the PR! Is it possible to split this PR into three small PRs (one PR for each rule)?,thanks possible split three small one rule,issue,negative,negative,neutral,neutral,negative,negative
1754026038,"@janhurst I don't see the empty space on my machine:

<img width=""1148"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/17039389/d0a2951b-526c-47b6-99a7-67c276b3f543"">

The command I used:

```
docker run --rm -w /mlflow -v $(pwd)/mlruns:/mlflow/mlruns -p 5000:5000 python:3.8 bash -c 'pip install mlflow && mlflow server --host 0.0.0.0 --gunicorn-opts ""--log-level debug""'
```

I'm using a Macbook. It could be a windows-only issue.",see empty space machine image command used docker run python bash install server host could issue,issue,negative,negative,neutral,neutral,negative,negative
1753962803,"@harupy yes I'm working on it, but I have troubles with running tests, some are failing locally, trying to use Codespace instead.
I followed https://github.com/mlflow/mlflow/blob/master/CONTRIBUTING.md#automated-python-development-environment-configuration

I tried:
```
./dev/dev-env-setup.sh -d .venvs/mlflow-dev
./dev/run-python-tests.sh
```

but e.g this test fails for me:
```
pytest 'tests/test_cli.py::test_mlflow_models_serve[True]'
```

even if run it in codespace. 

It passed though if I setup my virtual env in codespace using 

```
dev/dev-env-setup.sh -d .venvs/mlflow-dev -f
```

I'm confused as I followed the guide, and tried running tests without any changes.

I may try to create PR without local test completed.




",yes working running failing locally trying use instead tried test true even run though setup virtual confused guide tried running without may try create without local test,issue,negative,negative,neutral,neutral,negative,negative
1753887733,"Hi @C-K-Loan , thanks for reporting the issues! Would you mind providing ""Code to reproduce issue"" that uses mlflow.spark.log_model API?

```python
# credentials set required for running the code ...
spark_model = # JSL code ...
mlflow.spark.log_model(spark_model, ...)
```

The code provided currently is nlp.query_and_deploy_if_missing. It's unclear if the issue arises from how this function calls mlflow.spark.log_model or if there's a bug within mlflow.spark.log_model itself.

For a more efficient diagnosis, please provide a minimal reproducible example that focuses solely on creating the Spark model and logging it to mlflow. We're committed to investigating and addressing any issues found.

",hi thanks would mind providing code reproduce issue python set running code code code provided currently unclear issue function bug within efficient diagnosis please provide minimal reproducible example solely spark model logging investigating found,issue,positive,positive,neutral,neutral,positive,positive
1753657568,@Raghavan-B Thanks for the PR! Could you rebase your working branch? there seems to be some changes caused by branch divergence. ,thanks could rebase working branch branch divergence,issue,negative,positive,positive,positive,positive,positive
1753651697,"I had the same ask weeks earlier, and the context is it's more challenging than it seems to keep sync between active run and the run in store, so for clarity the store provides the single source of truth.  ",ask context keep sync active run run store clarity store single source truth,issue,positive,negative,negative,negative,negative,negative
1753631888,"Without a sample reproducible code, it's hard for us to debug this issue now. We will close it and reopen upon demand. ",without sample reproducible code hard u issue close reopen upon demand,issue,negative,negative,negative,negative,negative,negative
1753615751,"I believe the right solution is to write a custom MLflow callback, similar to [`mlflow.tensorflow.MLflowCallback`](https://github.com/mlflow/mlflow/blob/2d105c0896f3d2c3a9d96618438787e91487a2a8/mlflow/tensorflow/callback.py#L7). Since this is an old issue I am closing it, we shall reopen it if this issue bumps back.",believe right solution write custom similar since old issue shall reopen issue back,issue,negative,positive,neutral,neutral,positive,positive
1753607820,"Sorry about it, but I don't think we will prioritize it in the foreseeable future. We will close it and reopen if necessary. ",sorry think foreseeable future close reopen necessary,issue,negative,negative,negative,negative,negative,negative
1753254177,Is it possible that you `in_context` method always returns `False`? Because that may be the reason that the headers are not provided. ,possible method always false may reason provided,issue,negative,negative,negative,negative,negative,negative
1753229806,"@maksboyarin thanks for the PR :) 
Could you make this change version-dependent (conditional API usage based on the installed version of PyArrow) and remove the minimum required version pin so that this doesn't break existing environments that have PyArrow pinned to 1.x versions? ",thanks could make change conditional usage based version remove minimum version pin break pinned,issue,negative,positive,positive,positive,positive,positive
1753222938,"@arpitjasa-db once the max_tokens issue is resolved, we're good to go. I validated chat, completions, and embeddings locally and that was the only issue that I ran into. ",issue resolved good go chat locally issue ran,issue,positive,positive,positive,positive,positive,positive
1751824891,"I ran into the same problem when trying to pass a list of column names to my python scripts.
Since I'm using `click` , I managed to make it work by passing them as strings separated by commas and introducing a callback function, namely

```python
def split_commas(ctx, param, value: str) -> list[str]:
    """"""Splits commas. Used as callback in click Options.
    """"""
    if not value:
        return []
    return value.split("","")
```

My python script looks something like
```python
@click.command()
@click.option(
    ""--column-names"",
    required=True,
    type=str,
    callback=split_commas,
    help=""[Comma separated] Training column names""
) 
def train(column_names):
    ...
```

So, I can call it from the terminal with
```
python train.py --column-names columnA,columnB,columnC
```

Or as a MLFlow Project
```
mlflow run -P column-names=columnA,columnB,columnC <URI>
```",ran problem trying pas list column python since click make work passing function namely python param value list used click value return return python script something like python comma training column train call terminal python project run,issue,positive,neutral,neutral,neutral,neutral,neutral
1751777428,"> @Salz0 Thanks for the PR! Could you sign the DCO please? thanks!

Tried it out, thanks for mentioning this. It should be fine now",thanks could sign please thanks tried thanks fine,issue,positive,positive,positive,positive,positive,positive
1751662390,"MLflow depends on many packages. It's actually a bit challenging to satisfy all package requirements. I'll close this issue for now. If you encounter any issues, I'm happy to help :)",many actually bit satisfy package close issue encounter happy help,issue,positive,positive,positive,positive,positive,positive
1751645271,"Thank you for the confirmation!

> Any proposal to fix this?

I am not familiar with these issues, but for example, it might be solved by fixing the version of pydantic when installing mlflow. 
However, even if we resolve this issue, we might encounter the same problem with other python libraries that uses pydantic. It might be a pip's issue as you pointed out.

> Is this issue blocking you from contributing to MLflow?

I am now setting up the environment for mlflow contribution. Potentially it might be blocking me, but it's ok if mlflow contributors don't think it's a issue 👍 ",thank confirmation proposal fix familiar example might fixing version however even resolve issue might encounter problem python might pip issue pointed issue blocking setting environment contribution potentially might blocking think issue,issue,negative,positive,positive,positive,positive,positive
1751557678,"Is this issue blocking you from contributing to MLflow? IMO, this is a pip's issue.",issue blocking pip issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1751557555,"I can reproduce a similar error by installing `pydantic`:

```
% pip install -U pydantic
Requirement already satisfied: pydantic in /Users/harutakakawamura/.pyenv/versions/miniconda3-4.7.12/envs/mlflow-dev-env/lib/python3.8/site-packages (1.10.2)
Collecting pydantic
  Downloading pydantic-2.4.2-py3-none-any.whl (395 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 395.8/395.8 kB 5.2 MB/s eta 0:00:00
Collecting annotated-types>=0.4.0
  Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)
Collecting pydantic-core==2.10.1
  Downloading pydantic_core-2.10.1-cp38-cp38-macosx_10_7_x86_64.whl (1.9 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.9/1.9 MB 9.8 MB/s eta 0:00:00
Collecting typing-extensions>=4.6.1
  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)
Installing collected packages: typing-extensions, pydantic-core, annotated-types, pydantic
  Attempting uninstall: typing-extensions
    Found existing installation: typing_extensions 4.4.0
    Uninstalling typing_extensions-4.4.0:
      Successfully uninstalled typing_extensions-4.4.0
  Attempting uninstall: pydantic
    Found existing installation: pydantic 1.10.2
    Uninstalling pydantic-1.10.2:
      Successfully uninstalled pydantic-1.10.2
ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
tensorflow 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.8.0 which is incompatible.
rstcheck-core 1.0.3 requires pydantic<2.0,>=1.2, but you have pydantic 2.4.2 which is incompatible.
langchainplus-sdk 0.0.20 requires pydantic<2,>=1, but you have pydantic 2.4.2 which is incompatible.
langchain 0.0.230 requires pydantic<2,>=1, but you have pydantic 2.4.2 which is incompatible.
johnsnowlabs 4.4.6 requires pyspark==3.1.2, but you have pyspark 3.5.0 which is incompatible.
fastapi 0.97.0 requires pydantic!=1.8,!=1.8.1,<2.0.0,>=1.7.4, but you have pydantic 2.4.2 which is incompatible.
black 23.1.0 requires packaging>=22.0, but you have packaging 21.3 which is incompatible.
Successfully installed annotated-types-0.6.0 pydantic-2.4.2 pydantic-core-2.10.1 typing-extensions-4.8.0
                                                                                                                           
(mlflow-dev-env) @ mlflow [build-spark-sbt] -- INSERT --
% echo $?
0
```",reproduce similar error pip install requirement already satisfied eta eta collected found installation successfully uninstalled found installation successfully uninstalled error pip dependency resolver currently take account behaviour source following dependency incompatible incompatible incompatible incompatible incompatible incompatible black incompatible successfully insert echo,issue,positive,positive,positive,positive,positive,positive
1751536568,"> @danilopeixoto Thanks for the PR! Can you fix the DCO check?

Done. Thanks @harupy!",thanks fix check done thanks,issue,positive,positive,positive,positive,positive,positive
1751519237,@Salz0 Thanks for the PR! Could you sign the DCO please? thanks!,thanks could sign please thanks,issue,positive,positive,positive,positive,positive,positive
1751291911,The ``model_params`` implementation has been merged into master branch and will be included in the upcoming MLflow 2.8.0 release :) ,implementation master branch included upcoming release,issue,negative,neutral,neutral,neutral,neutral,neutral
1751286188,It's an interesting idea @rsundqvist :) We're going to discuss this more amongst the maintainers along with some additional other topics around plotting that are somewhat related to the interesting point that you bring up about categorical grouping.,interesting idea going discus amongst along additional around plotting somewhat related interesting point bring categorical grouping,issue,positive,positive,positive,positive,positive,positive
1751198968,"> Code change looks good but from a product POV, this means that no metrics are logged as a result of this evaluation. is that the behavior we want? i am wondering if it makes sense to have these aggregations by default.

Good question. Let me bring this up and discuss this offline. ",code change good product metric logged result evaluation behavior want wondering sense default good question let bring discus,issue,positive,positive,positive,positive,positive,positive
1750450461,"Yes, that would definitely be very valuable for us. We are still creating separate service instances for each and every project to avoid the clutter of seeing everything in one long list of experiments. For using a shared instance on enterprise level, another level on top of projects would also be desirable: teams/projects/experiments.
Tags could be sufficient if filtering on top of tags would be supported well in all UI functionality. Especially, it should be possible to somehow persist filter settings across views and sessions on user level so that filtering down does not have to be repeated manually all the time.",yes would definitely valuable u still separate service every project avoid clutter seeing everything one long list instance enterprise level another level top would also desirable could sufficient filtering top would well functionality especially possible somehow persist filter across session user level filtering repeated manually time,issue,positive,positive,positive,positive,positive,positive
1750435683,"Hi, just curious to know if you are still thinking of creating a higher-level grouping of content which will be ability to group experiments under maybe a segregation called Projects?",hi curious know still thinking grouping content ability group maybe segregation,issue,positive,negative,neutral,neutral,negative,negative
1750412268,"The UI in this newer version looks quite different! Looking forward to exploring it.
",version quite different looking forward exploring,issue,negative,neutral,neutral,neutral,neutral,neutral
1750404697,"
MarkupSafe                         2.1.3
matplotlib                         3.7.3
mccabe                             0.6.1
menuinst                           1.4.16
mistune                            0.8.4
mkl-fft                            1.2.0
mkl-random                         1.1.1
mkl-service                        2.3.0
mlflow                             2.7.1
mock                               4.0.2
more-itertools                     8.6.0
mpmath                             1.1.0
msal                               1.24.1
msal-extensions                    1.0.0
msgpack                            1.0.0
msrest                             0.7.1
multipledispatch                   0.6.0
navigator-updater                  0.2.1
nbclient                           0.5.1
nbconvert                          6.0.7
nbformat                           5.0.8
nest-asyncio                       1.4.2
networkx                           2.5
nltk                               3.5
nose                               1.3.7
notebook                           6.1.4
numba                              0.51.2
numexpr                            2.7.1
numpy                              1.24.4
numpydoc                           1.1.0
oauthlib                           3.2.2
olefile                            0.46
openpyxl                           3.0.5
packaging                          20.4
pandas                             1.1.3
pandocfilters                      1.4.3
paramiko                           2.7.2
parso                              0.7.0
partd                              1.1.0
path                               15.0.0
pathlib2                           2.3.5
pathtools                          0.1.2
patsy                              0.5.1
pep8                               1.7.1
pexpect                            4.8.0
pickleshare                        0.7.5
Pillow                             10.0.1
pip                                20.2.4
pkginfo                            1.6.1
pluggy                             0.13.1
ply                                3.11
portalocker                        2.8.2
prometheus-client                  0.8.0
prometheus-flask-exporter          0.20.3
prompt-toolkit                     3.0.8
protobuf                           4.24.4
psutil                             5.7.2
py                                 1.9.0
pyarrow                            13.0.0
pycodestyle                        2.6.0
pycosat                            0.6.3
pycparser                          2.20
pycurl                             7.43.0.6
pydocstyle                         5.1.1
pyflakes                           2.2.0
Pygments                           2.7.2
PyJWT                              2.8.0
pylint                             2.6.0
PyNaCl                             1.4.0
pyodbc                             4.0.0-unsupported
pyOpenSSL                          19.1.0
pyparsing                          3.1.1
pyreadline                         2.1
pyrsistent                         0.17.3
PySocks                            1.7.1
pytest                             0.0.0
python-dateutil                    2.8.2
python-jsonrpc-server              0.4.0
python-language-server             0.35.1
pytz                               2020.1
PyWavelets                         1.1.1
pywin32                            227
pywin32-ctypes                     0.2.0
pywinpty                           0.5.7
PyYAML                             6.0.1
pyzmq                              19.0.2
QDarkStyle                         2.8.1
QtAwesome                          1.0.1
qtconsole                          4.7.7
QtPy                               1.9.0
querystring-parser                 1.2.4
regex                              2020.10.15
requests                           2.31.0
requests-oauthlib                  1.3.1
rope                               0.18.0
Rtree                              0.9.4
ruamel-yaml                        0.15.87
scikit-image                       0.17.2
scikit-learn                       1.3.1
scipy                              1.10.1
seaborn                            0.11.0
Send2Trash                         1.5.0
setuptools                         50.3.1.post20201107
simplegeneric                      0.8.1
singledispatch                     3.4.0.3
sip                                4.19.13
six                                1.16.0
smmap                              5.0.1
snowballstemmer                    2.0.0
sortedcollections                  1.2.1
sortedcontainers                   2.2.2
soupsieve                          2.0.1
Sphinx                             3.2.1
sphinxcontrib-applehelp            1.0.2
sphinxcontrib-devhelp              1.0.2
sphinxcontrib-htmlhelp             1.0.3
sphinxcontrib-jsmath               1.0.1
sphinxcontrib-qthelp               1.0.3
sphinxcontrib-serializinghtml      1.1.4
sphinxcontrib-websupport           1.2.4
spyder                             4.1.5
spyder-kernels                     1.9.4
SQLAlchemy                         1.4.40
sqlparse                           0.4.4
statsmodels                        0.12.0
sympy                              1.6.2
tables                             3.6.1
tabulate                           0.9.0
tblib                              1.7.0
terminado                          0.9.1
testpath                           0.4.4
threadpoolctl                      3.2.0
tifffile                           2020.10.1
toml                               0.10.1
toolz                              0.11.1
tornado                            6.0.4
tqdm                               4.50.2
traitlets                          5.0.5
typing-extensions                  4.8.0
tzdata                             2023.3
ujson                              4.0.1
unicodecsv                         0.14.1
urllib3                            2.0.6
waitress                           2.1.2
watchdog                           0.10.3
wcwidth                            0.2.5
webencodings                       0.5.1
websocket-client                   1.6.3
werkzeug                           3.0.0
wheel                              0.35.1
widgetsnbextension                 3.5.1
win-inet-pton                      1.1.0
win-unicode-console                0.5
wincertstore                       0.2
wrapt                              1.11.2
xlrd                               1.2.0
XlsxWriter                         1.3.7
xlwings                            0.20.8
xlwt                               1.3.0
xmltodict                          0.12.0
yapf                               0.30.0
zict                               2.0.0
zipp                               3.17.0
zope.event                         4.5.0
zope.interface                     5.1.2",mock nose notebook path pep pillow pip pluggy ply rope post sip six sphinx table tabulate tornado waitress watchdog wheel,issue,negative,neutral,neutral,neutral,neutral,neutral
1750403940,can you share the output of `pip list`?,share output pip list,issue,negative,neutral,neutral,neutral,neutral,neutral
1750398132,"@yuvalmaromyala please run `pip list` and check if `mlflow-skinny` is installed. If it is, run `pip uninstall mlflow-skinny` to uninstall it. After that, you can install mlflow again.",please run pip list check run pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
1750392500,"This command can reproduce the same error:

```
docker run --rm -w /mlflow -p 5000:5000 python:3.8 bash -c 'pip install mlflow==1.28 && pip install azureml-mlflow && mlflow server --host 0.0.0.0 --gunicorn-opts ""--log-level debug""'
```

<img width=""2035"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/17039389/477c1a63-577a-4237-8e72-ac7f276fbea3"">
",command reproduce error docker run python bash install pip install server host image,issue,negative,neutral,neutral,neutral,neutral,neutral
1750320583,"Yes, so  I pip installed azureml-mlflow in my existing env.

Then I ran the following in a Jupiter notebook:
```
import mlflow
mlflow.set_tracking_uri('azureml://...')
mlflow.set_experiment('test_azureml_mlflow')
```

The URI I obatined from the Azure ML console on the web.
",yes pip ran following notebook import azure console web,issue,negative,neutral,neutral,neutral,neutral,neutral
1750283648,"@yuvalmaromyala 

> I started playing around trying to configure mlflow for azure-ml

can you elaborate on what you did?",around trying configure elaborate,issue,negative,positive,positive,positive,positive,positive
1750246161,"guessing from the above conversations, it's possible the new conda env inheriting mlflow from the base env? 

can OP try deactivating all conda envs, use python's built-in `venv` for fresh mlflow 2.7.1, and then just copy `sqlite:///mlflow.db` & `./artifacts` from the old env? i believe this should avoid the 1.28 from unknown source?",guessing possible new base try use python fresh copy old believe avoid unknown source,issue,negative,negative,neutral,neutral,negative,negative
1750243939,"Thanks both for continuing to look into this! Just to remind you - it used to work absolutely fine on my machine, the problems started yesterday when I started playing around trying to configure mlflow for azure-ml so it most likely has something to do with that....",thanks look remind used work absolutely fine machine yesterday around trying configure likely something,issue,positive,positive,positive,positive,positive,positive
1750176526,"I think the key points are:

- Where does 1.28 UI come from? If we install mlflow 2.7.1 and run `mlflow server`, `2.7.1` should show up on the top-left. On @yuvalmaromyala's machine, 1.28 UI is used for some reason.
- Why `curl http://localhost:5000/ajax-api/2.0/preview/mlflow/experiments/list` fails with mlflow 1.28 on @yuvalmaromyala's machine, but doesn't on ours.",think key come install run server show machine used reason curl machine,issue,negative,neutral,neutral,neutral,neutral,neutral
1750161510,"@harupy yup no error.

I think the key point is why OP has 1.28 UI and 2.7.1 server, and 1.28 is requesting an endpoint that 2.7.1 doesn't support?

![image](https://github.com/mlflow/mlflow/assets/22888849/89ef3378-5482-47ec-b062-0ce35c816b5e)

",error think key point server support image,issue,negative,neutral,neutral,neutral,neutral,neutral
1750158314,@gabrielfu thanks for the confirmation! does UI render fine?,thanks confirmation render fine,issue,positive,positive,positive,positive,positive,positive
1750149478,"`curl http://127.0.0.1:5000/ajax-api/2.0/preview/mlflow/experiments/list` worked fine on Windows:

<img width=""1310"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/17039389/43ade164-1b64-42cb-ad0c-4ca6fc73032a"">
",curl worked fine image,issue,negative,positive,positive,positive,positive,positive
1750139374,"@gabrielfu Thanks! Can you try the following?

1. create a fresh python environment
2. install mlflow 1.28
3. run `mlflow server`
4. open http://127.0.0.1:5000

I think it will work fine.",thanks try following create fresh python environment install run server open think work fine,issue,positive,positive,positive,positive,positive,positive
1750123760,"Since the issue does not exist yet, should I create one following the template of the others?",since issue exist yet create one following template,issue,negative,neutral,neutral,neutral,neutral,neutral
1750113785,"Is it possible to work on any of the remaining modules? It seems that, for example, the Prophet module has not been touched yet.",possible work example prophet module touched yet,issue,negative,neutral,neutral,neutral,neutral,neutral
1750111937,"I really need to go, but I'll be back later",really need go back later,issue,negative,positive,neutral,neutral,positive,positive
1750111455,"
ALLUSERSPROFILE=C:\ProgramData
APPDATA=C:\Users\wils_ymarom\AppData\Roaming
CHROME_CRASHPAD_PIPE_NAME=\\.\pipe\crashpad_10004_JYYZJSXOBSZOGRBK
CommonProgramFiles=C:\Program Files\Common Files
CommonProgramFiles(x86)=C:\Program Files (x86)\Common Files
CommonProgramW6432=C:\Program Files\Common Files
COMPUTERNAME=ARR-TFU60I7LTD0
ComSpec=C:\WINDOWS\system32\cmd.exe
CONDA_BAT=C:\Users\wils_ymarom\Anaconda3\condabin\conda.bat
CONDA_DEFAULT_ENV=test2
CONDA_EXE=C:\Users\wils_ymarom\Anaconda3\Scripts\conda.exe
CONDA_PREFIX=C:\Users\wils_ymarom\Anaconda3\envs\test2
CONDA_PREFIX_1=C:\Users\wils_ymarom\Anaconda3
CONDA_PROMPT_MODIFIER=(test2)
CONDA_PYTHON_EXE=C:\Users\wils_ymarom\Anaconda3\python.exe
CONDA_SHLVL=2
DriverData=C:\Windows\System32\Drivers\DriverData
HOMEDRIVE=C:
HOMEPATH=\Users\wils_ymarom
LOCALAPPDATA=C:\Users\wils_ymarom\AppData\Local
LOGONSERVER=\\PPADS02
NUMBER_OF_PROCESSORS=8
OneDrive=C:\Users\wils_ymarom\OneDrive - Arriba Group
OneDriveCommercial=C:\Users\wils_ymarom\OneDrive - Arriba Group
ORIGINAL_XDG_CURRENT_DESKTOP=undefined
OS=Windows_NT
Path=C:\Users\wils_ymarom\Anaconda3\envs\test2;C:\Users\wils_ymarom\Anaconda3\envs\test2\Library\mingw-w64\bin;C:\Users\wils_ymarom\Anaconda3\envs\test2\Library\usr\bin;C:\Users\wils_ymarom\Anaconda3\envs\test2\Library\bin;C:\Users\wils_ymarom\Anaconda3\envs\test2\Scripts;C:\Users\wils_ymarom\Anaconda3\envs\test2\bin;C:\Users\wils_ymarom\Anaconda3\condabin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn;C:\Program Files\Azure Data Studio\bin;C:\Program Files\Git\cmd;C:\Users\wils_ymarom\AppData\Local\Microsoft\WindowsApps;C:\Users\wils_ymarom\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\wils_ymarom\Anaconda3;C:\Users\wils_ymarom\Anaconda3\Scripts;C:\Users\wils_ymarom\Anaconda3\Library\bin;C:\Users\wils_ymarom\Documents\Repos\arriba_sandbox
PATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC
PROCESSOR_ARCHITECTURE=AMD64
PROCESSOR_IDENTIFIER=Intel64 Family 6 Model 142 Stepping 12, GenuineIntel
PROCESSOR_LEVEL=6
PROCESSOR_REVISION=8e0c
ProgramData=C:\ProgramData
ProgramFiles=C:\Program Files
ProgramFiles(x86)=C:\Program Files (x86)
ProgramW6432=C:\Program Files
PROMPT=(test2) $P$G
PSModulePath=C:\Program Files\WindowsPowerShell\Modules;C:\WINDOWS\system32\WindowsPowerShell\v1.0\Modules
PUBLIC=C:\Users\Public
PYTHONPATH=C:\Users\wils_ymarom\OneDrive - Arriba Group\Documents\Repos\arriba_sandbox
SystemDrive=C:
SystemRoot=C:\WINDOWS
TEMP=C:\Users\WILS_Y~1\AppData\Local\Temp
TMP=C:\Users\WILS_Y~1\AppData\Local\Temp
USERDNSDOMAIN=REHAB.NET
USERDOMAIN=REHAB
USERDOMAIN_ROAMINGPROFILE=REHAB
USERNAME=wils_ymarom
USERPROFILE=C:\Users\wils_ymarom
windir=C:\WINDOWS
ZES_ENABLE_SYSMAN=1
TERM_PROGRAM=vscode
TERM_PROGRAM_VERSION=1.83.0
LANG=en_US.UTF-8
COLORTERM=truecolor
GIT_ASKPASS=c:\Users\wils_ymarom\AppData\Local\Programs\Microsoft VS Code\resources\app\extensions\git\dist\askpass.sh
VSCODE_GIT_ASKPASS_NODE=C:\Users\wils_ymarom\AppData\Local\Programs\Microsoft VS Code\Code.exe
VSCODE_GIT_ASKPASS_EXTRA_ARGS=--ms-enable-electron-run-as-node
VSCODE_GIT_ASKPASS_MAIN=c:\Users\wils_ymarom\AppData\Local\Programs\Microsoft VS Code\resources\app\extensions\git\dist\askpass-main.js  
VSCODE_GIT_IPC_HANDLE=\\.\pipe\vscode-git-f657c453b7-sock",test arriba group arriba group data family model stepping test arriba,issue,negative,neutral,neutral,neutral,neutral,neutral
1750105166,"so would you suggest to reinstall conda, or are there other avenues I can try?",would suggest reinstall try,issue,negative,neutral,neutral,neutral,neutral,neutral
1750104897,"Hi @BenWilson2 @RawStewage ,

Sorry for the delay !
I've just done the rebase but the recipes-windows test fails... Any idea why...?",hi sorry delay done rebase test idea,issue,negative,negative,negative,negative,negative,negative
1750104037,thank you so much for your help I really appreciate it!! ,thank much help really appreciate,issue,positive,positive,positive,positive,positive,positive
1750095680,I need to go now..... Is this something you can look into further?,need go something look,issue,negative,neutral,neutral,neutral,neutral,neutral
1750094150,Not found for `http://127.0.0.1:5000/ajax-api/2.0/preview/mlflow/runs/search` is strange. It should be found at least.,found strange found least,issue,negative,negative,negative,negative,negative,negative
1750092433,"In powershell I get a different error:
![image](https://github.com/mlflow/mlflow/assets/91654493/82c10af9-6c36-49cb-b933-6dfc51512f2b)
",get different error image,issue,negative,neutral,neutral,neutral,neutral,neutral
1750091329,"```
<!doctype html><html lang=""en""><head><meta charset=""utf-8""/><meta name=""viewport"" content=""width=device-width,initial-scale=1,shrink-to-fit=no""/><link rel=""shortcut icon"" href=""./static-files/favicon.ico""/><meta name=""theme-color"" content=""#000000""/><link rel=""manifest"" href=""./static-files/manifest.json""/><title>MLflow</title><script defer=""defer"" src=""static-files/static/js/main.d843a4d8.js""></script><link href=""static-files/static/css/main.d148570b.css"" rel=""stylesheet""></head><body><noscript>You need to enable JavaScript to run this app.</noscript><div id=""root""></div><div id=""modal""></div></body></html>
```
",en head meta meta link icon meta link manifest title script defer link body need enable run div root div modal,issue,negative,neutral,neutral,neutral,neutral,neutral
1750071646,"If you don't have curl, you can use the requests package in python.",curl use package python,issue,negative,neutral,neutral,neutral,neutral,neutral
1750071634,"Yep:
```
curl : <!doctype html>
<html lang=en>
<title>404 Not Found</title>
<h1>Not Found</h1>
<p>The requested URL was not found on the server. If you entered the URL manually please check your spelling and try again.</p>
At line:1 char:1
+ curl http://localhost:5000/ajax-api/2.0/preview/mlflow/experiments/li ...
+ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    + CategoryInfo          : InvalidOperation: (System.Net.HttpWebRequest:HttpWebRequest) [Invoke-WebRequest], WebException
    + FullyQualifiedErrorId : WebCmdletWebResponseException,Microsoft.PowerShell.Commands.InvokeWebRequestCommand
```",yep curl title found found found server manually please check spelling try line char curl,issue,positive,neutral,neutral,neutral,neutral,neutral
1750064785,"yes running 1.28, getting the ""something went wrong"" error:

![image](https://github.com/mlflow/mlflow/assets/91654493/3d207916-b4f5-4c51-a632-853050d938ac)
",yes running getting something went wrong error image,issue,negative,negative,negative,negative,negative,negative
1750063170,"you're using 1.28 now, right? still getting the NOT FOUND error?",right still getting found error,issue,negative,positive,positive,positive,positive,positive
1750055284,"
> You can try removing the old env.

I was working in the base env before...",try removing old working base,issue,negative,negative,negative,negative,negative,negative
1750050752,"well it's not in my new env, but I'll go into the old one and uninstall it",well new go old one,issue,negative,positive,positive,positive,positive,positive
1750049851,Could it be that yesterday when I installed the `azureml-mlflow` package it broke something?,could yesterday package broke something,issue,negative,neutral,neutral,neutral,neutral,neutral
1750039282,then remove `python -m` and just run `mlflow server`,remove python run server,issue,negative,neutral,neutral,neutral,neutral,neutral
1750037645,I think it should install python package and a script for CLI.,think install python package script,issue,negative,neutral,neutral,neutral,neutral,neutral
1750036948,"no good.

btw that version installs as a standalone package, not a python package, so it created a script in that Anaconda folder as we had before.",good version package python package script anaconda folder,issue,negative,positive,positive,positive,positive,positive
1750016469,"yeah don't see anything to suggest there's another one running, doing a reboot just in case",yeah see anything suggest another one running case,issue,negative,neutral,neutral,neutral,neutral,neutral
1750008822,pretty sure... is there a way to check?,pretty sure way check,issue,positive,positive,positive,positive,positive,positive
1750008039,are you sure you're NOT running another mlflow server on your machine?,sure running another server machine,issue,negative,positive,positive,positive,positive,positive
1750003282,"actually the terminal I was in already had it set, I'll remove it",actually terminal already set remove,issue,negative,neutral,neutral,neutral,neutral,neutral
1750001398,"still getting that error.
shall I set the env variable?",still getting error shall set variable,issue,negative,neutral,neutral,neutral,neutral,neutral
1749998730,"done. and now I can't start the server.
now shall I install it using:
```
python -m pip instlal mlflow
```",done ca start server shall install python pip,issue,negative,neutral,neutral,neutral,neutral,neutral
1749993981,please run `where mlflow` to see where the executable is.,please run see executable,issue,negative,neutral,neutral,neutral,neutral,neutral
1749991920,yeah actually it's still available...  ??!!,yeah actually still available,issue,negative,positive,positive,positive,positive,positive
1749991634,"before install, please make sure `mlflow server` is no longer available.",install please make sure server longer available,issue,positive,positive,positive,positive,positive,positive
1749990823,@XinEDprob Thanks for the FR. This feature doesn't exist yet.,thanks feature exist yet,issue,negative,positive,positive,positive,positive,positive
1749988616,"then try `python -c ""import sys; print(sys.executable)""`",try python import print,issue,negative,neutral,neutral,neutral,neutral,neutral
1749987567,"> can you run `python -c 'import sys; print(sys.executable)'`?

getting a syntax error. remember I'm running in windows:

![image](https://github.com/mlflow/mlflow/assets/91654493/66b664de-24fa-43b9-85a2-dc946796553a)
",run python print getting syntax error remember running image,issue,negative,neutral,neutral,neutral,neutral,neutral
1749986634,"> yeah... it's like it's using a ""global"" installation?


yes
",yeah like global installation yes,issue,positive,neutral,neutral,neutral,neutral,neutral
1749986471,"yeah... it's like it's using a ""global"" installation?",yeah like global installation,issue,positive,neutral,neutral,neutral,neutral,neutral
1749984912,"looks like the environment is not activated. If it is, we should see `test2` in `Location`.",like environment see test location,issue,negative,neutral,neutral,neutral,neutral,neutral
1749983186,"it's there again...

this is what I did:
```
conda create -n test2 python=3.8.5
conda activate test2
pip show mlflow
```

and it's displaying:

![image](https://github.com/mlflow/mlflow/assets/91654493/129e86b6-56e5-4f59-81f8-1ef97c7bc197)





",create test activate test pip show image,issue,negative,neutral,neutral,neutral,neutral,neutral
1749981676,you can try `python -m mlflow server` instead `mlflow server`.,try python server instead server,issue,negative,neutral,neutral,neutral,neutral,neutral
1749979923,"> actually my new env already has it

mlflow is not a built-in library. This is strange.",actually new already library strange,issue,negative,positive,neutral,neutral,positive,positive
1749979869,"ok, so now shall I try to start a server?",shall try start server,issue,negative,neutral,neutral,neutral,neutral,neutral
1749979177,"oh, actually my new env already has it....",oh actually new already,issue,negative,positive,positive,positive,positive,positive
1749978762,"and do a standard install for mlflow? ie 
``` pip install mlflow```
?",standard install ie pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
1749972973,"can you create a new python environment (conda, venv, etc.) and try the same thing in that environment?",create new python environment try thing environment,issue,negative,positive,positive,positive,positive,positive
1749968329,you mean unset the environment variable?,mean unset environment variable,issue,negative,negative,negative,negative,negative,negative
1749962732,"No, it did get stopped occasionally when I rebooted the computer",get stopped occasionally computer,issue,negative,neutral,neutral,neutral,neutral,neutral
1749961916,"> I didn't stop my local server while I was experimenting with this

Your local server has been running for months without being stopped?",stop local server local server running without stopped,issue,negative,neutral,neutral,neutral,neutral,neutral
1749953007,I was trying to set up Azure Machine Learning as a way to start tracking experiments and registering models,trying set azure machine learning way start,issue,negative,neutral,neutral,neutral,neutral,neutral
1749951656,"@yuvalmaromyala 

> I need to point out that this problem started when I tried to configure tracking via a remote server

What do you mean by a remote server?",need point problem tried configure via remote server mean remote server,issue,negative,negative,negative,negative,negative,negative
1749912048,"that's right, I'm on 2.7.1, but I've done a bit of backup just in case.
ok, will give it a go now.",right done bit backup case give go,issue,negative,positive,positive,positive,positive,positive
1749903699,"you're already using 2.7.1, right? If so, I don't think you need t bck up.",already right think need,issue,negative,positive,positive,positive,positive,positive
1749891525,"@yuvalmaromyala what happens if you change the port?

```
mlflow server --port 5001
```",change port server port,issue,negative,neutral,neutral,neutral,neutral,neutral
1749889695,"Just tried it, getting the same error.
![image](https://github.com/mlflow/mlflow/assets/91654493/3dee041a-cff9-4b62-8c76-8d5e64dd8009)

",tried getting error image,issue,negative,neutral,neutral,neutral,neutral,neutral
1749864758,"mlflow --version shows 2.7.1

regarding your question about the UI requests, I'm not sure how to answer that.... did you look at the output I shared from devtools?",version regarding question sure answer look output,issue,negative,positive,positive,positive,positive,positive
1749859480,"I was able to reproduce:

```python
import mlflow

with mlflow.start_run():
    csv_text = ""a,b,c\n1,2,3\n11,22,33\n4,5,6""
    mlflow.log_text(csv_text, ""my_csv_text.csv"")
```

https://github.com/mlflow/mlflow/assets/17039389/891e29d2-a046-48b3-b7be-fd04ce78ecd7

",able reproduce python import,issue,negative,positive,positive,positive,positive,positive
1749849612,"@yuvalmaromyala Looks like UI is still 1.28.0. Can you upgrade it?

<img width=""243"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/17039389/a8b7c99f-52e5-4a89-95da-5b75168f2e7b"">

We removed `/ajax-api/2.0/preview/mlflow/experiments/list` in MLflow 2.0.",like still upgrade image removed,issue,negative,neutral,neutral,neutral,neutral,neutral
1749798732,@jrakotobe Thanks for reporting this issue. Can you create a minimum python to log the data that can reproduce the issue and take a screen recording of the issue?,thanks issue create minimum python log data reproduce issue take screen recording issue,issue,positive,positive,positive,positive,positive,positive
1749681940,"This issue has been put under a low priority, but I think we can do a quick fix for it. Keep it open and we will welcome OSS contributions. ",issue put low priority think quick fix keep open welcome,issue,negative,positive,positive,positive,positive,positive
1749667097,"this has been deprioritized for years, I am closing it and opening new one if necessary.",opening new one necessary,issue,negative,positive,neutral,neutral,positive,positive
1749644635,"I don't know if we need this, as a comparison, we frequently start a python console in a local branch with changed file for quick testing, and there is no prompt that ""this console is based on uncommitted changed"", but everything works fine. ",know need comparison frequently start python console local branch file quick testing prompt console based uncommitted everything work fine,issue,negative,positive,positive,positive,positive,positive
1749572432,@BenWilson2 @harupy this is the second PR of Open AI enhancements which do the refactor of the completions implementation and expand to both prompt and chat completions. There is one more for parameters coming hot :P.,second open ai implementation expand prompt chat one coming hot,issue,negative,positive,neutral,neutral,positive,positive
1749416374,"To fix the linting issues, the pre-commit hook is super helpful: 

(install from root of forked repo)
``` bash
pre-commit install -t pre-commit -t prepare-commit-msg
```

To run:
``` bash
pre-commit run --all-files --color=always
```

Ruff will fix most of these things that the linter is complaining about :) ",fix hook super helpful install root forked bash install run bash run ruff fix linter,issue,positive,positive,positive,positive,positive,positive
1749411028,"Line 211 in gateway integration tests just needs to have its count incremented, since you added a new bedrock route :) ",line gateway integration need count since added new bedrock route,issue,negative,positive,positive,positive,positive,positive
1749405163,"Don't worry about the cross version tests failing here. Simply an artifact of the base master branch that your fork PR comes from. 

A rebase will clean up the spacy issues, but the pytorch-lightning failures are a recent and actively investigated issue in master - don't worry about lightning.",worry cross version failing simply artifact base master branch fork come rebase clean spacy recent actively issue master worry lightning,issue,negative,negative,neutral,neutral,negative,negative
1749347810,"> Hi @santiagxf looks like there's a merge conflict. Do you want me to resolve it and merge tomorrow, or do you want to handle it?

I can take care of it today!",hi like merge conflict want resolve merge tomorrow want handle take care today,issue,positive,neutral,neutral,neutral,neutral,neutral
1749032722,Hi there! I just stumbled on this issue while searching for this very feature. Has the situation evolved since last year?,hi issue searching feature situation since last year,issue,negative,neutral,neutral,neutral,neutral,neutral
1748529562,"@jmahlik https://pypi.org/project/databricks-cli/0.18.0 was released, but mlflow installation on python 3.12 is still failing because pyarrow is not ready (https://github.com/apache/arrow/issues/37880).",installation python still failing ready,issue,negative,positive,positive,positive,positive,positive
1748499661,I found this feature very interesting. Is it within your plans to incorporate streaming in the models supporting that feature?,found feature interesting within incorporate streaming supporting feature,issue,positive,positive,positive,positive,positive,positive
1748326258,@TomeHirata Can you post a comment on this issue so I can assign this task to you?,post comment issue assign task,issue,negative,neutral,neutral,neutral,neutral,neutral
1747702818,"we are working on an async logging to reduce the time overhead. for the original proposal, I am not sure if we want to hold a constant http channel until the program exits, as one server can handle multiple requests from different users.",working logging reduce time overhead original proposal sure want hold constant channel program one server handle multiple different,issue,positive,positive,positive,positive,positive,positive
1747680989,"I am not familiar with our strategy on OSS MLflow server, @harupy @dbczumar is this something we want to add? Considering its popularity, I am not going to close this issue despite it's pretty old.",familiar strategy server something want add considering popularity going close issue despite pretty old,issue,negative,positive,positive,positive,positive,positive
1747675631,"@harupy @BenWilson2  I think we should fix the example and the [guide](https://docs.databricks.com/en/mlflow/projects.html#id14), it's a bad UX that people are stuck when running through the official guide. Want to check if you have some context, otherwise I am happy to take a look.",think fix example guide bad people stuck running official guide want check context otherwise happy take look,issue,negative,positive,neutral,neutral,positive,positive
1747634755,"It makes sense to me to provide a download button for the artifact, currently users need to download each artifact manually. ",sense provide button artifact currently need artifact manually,issue,negative,neutral,neutral,neutral,neutral,neutral
1747195067,For what it's worth I did the rebase locally and after some effort to replicate what the github actions were doing the failing tests started passing. ,worth rebase locally effort replicate failing passing,issue,negative,positive,positive,positive,positive,positive
1747112451,"Most recent iteration of LLM is solid. The only issue is it dropped one code block - I added another rule that should help with this.

Docs render identical to prod with the most recent commit",recent iteration solid issue one code block added another rule help render identical prod recent commit,issue,negative,neutral,neutral,neutral,neutral,neutral
1746621227,@jmahlik We're going to release databricks-cli 0.18. The `imp` module should be removed in this version :),going release imp module removed version,issue,negative,neutral,neutral,neutral,neutral,neutral
1746608366,"@clarkh-ncino Can you pull the image locally, build a container, and check if pyenv is installed?",pull image locally build container check,issue,negative,neutral,neutral,neutral,neutral,neutral
1746569067,"@clarkh-ncino Got it. I'm running that command to see whether pyenv is installed or not.

--- Update ---

```
...

#10 [ 7/20] RUN git clone     --depth 1     --branch $(git ls-remote --tags --sort=v:refname https://github.com/pyenv/pyenv.git | grep -o -E 'v[1-9]+(\.[1-9]+)+$' | tail -1)     https://github.com/pyenv/pyenv.git /root/.pyenv
#10 0.592 Cloning into '/root/.pyenv'...
#10 1.449 Note: switching to '28e7000b485bff61235d8a691c3989c9a5ed0a53'.
#10 1.449 
#10 1.449 You are in 'detached HEAD' state. You can look around, make experimental
#10 1.449 changes and commit them, and you can discard any commits you make in this
#10 1.449 state without impacting any branches by switching back to a branch.
#10 1.449 
#10 1.449 If you want to create a new branch to retain commits you create, you may
#10 1.449 do so (now or later) by using -c with the switch command. Example:
#10 1.449 
#10 1.449   git switch -c <new-branch-name>
#10 1.449 
#10 1.449 Or undo this operation with:
#10 1.449 
#10 1.449   git switch -
#10 1.449 
#10 1.449 Turn off this advice by setting config variable advice.detachedHead to false
#10 1.449 
#10 DONE 1.5s

...
```

pyenv was installed during build.",got running command see whether update run git clone depth branch git tail note switching head state look around make experimental commit discard make state without switching back branch want create new branch retain create may later switch command example git switch undo operation git switch turn advice setting variable false done build,issue,positive,negative,neutral,neutral,negative,negative
1746552111,"@adeandrade Thanks for the reply!

> I should mention that I have some experiments with runs that report around 10,000 steps. So imagine an average of 10 charts for 10 runs, each having 10,000 steps. It is understandable that it will take a minute or two to load the data and plot the charts. I don't think this should happen by default when I just want to see if my runs started or if they are still running. I am just waiting for the page to load, so I can click on the table view.

I'll try to create a python script that generates a similar volume of data.

Wouldy you mind taking a screen recording of how the page loads?",thanks reply mention report around imagine average understandable take minute two load data plot think happen default want see still running waiting page load click table view try create python script similar volume data mind taking screen recording page,issue,positive,positive,neutral,neutral,positive,positive
1746521477,@harupy thanks for the quick review! i'll rebase mpu branch once this pr is merged,thanks quick review rebase branch,issue,negative,positive,positive,positive,positive,positive
1746493777,@gabrielfu Thanks! I was able to repro. Testing `moto==4.2.6.dev10` now.,thanks able testing dev,issue,negative,positive,positive,positive,positive,positive
1746384518,"`databricks configure` (new, not legacy) worked fine on Colab: 

<img width=""772"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/17039389/bb3c6124-a8c7-4c47-928e-17c6e89d801c"">


---

Legacy databricks CLI also worked on colab.

<img width=""1242"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/17039389/933a6d64-c826-479b-9ae1-852aea0b9b5d"">

To skip the prompt, we need to use `--token-file`. We can create a temporary file, store the token there, run `databricks configure`, and delete the token file.

---

Can we use `databricks configure`? This can be addressed as a follow-up.",configure new legacy worked fine image legacy also worked image skip prompt need use create temporary file store token run configure delete token file use configure,issue,negative,positive,positive,positive,positive,positive
1746088363,"@harupy No problem :) Interesting, my test failed and I haven't seen this error before, let me take a look into it",problem interesting test seen error let take look,issue,negative,positive,positive,positive,positive,positive
1746033441,"> It looks like `databricks-cli` doesn't provide a wheel for python 3?
> 
> https://pypi.org/project/databricks-cli/0.17.6/#files

Yea... so we end up invoking the `setup.py`. I have a PR ready that'll ship universal wheels and fix the deprecated imports.",like provide wheel python yea end ready ship universal fix,issue,positive,positive,neutral,neutral,positive,positive
1745994223,"@BenWilson2 Yes i did a local testing with multiple profiles, and it is controlled correctly by the env var. For this `login` api, it will overwrite or create the profile specified by `DATABRICKS_CONFIG_PROFILE` env var, if `DATABRICKS_CONFIG_PROFILE` is not set, it will overwrite the profile [DEFAULT]",yes local testing multiple correctly login overwrite create profile set overwrite profile default,issue,positive,neutral,neutral,neutral,neutral,neutral
1745901734,"> I wasn't sure if it's worth pursuing moving to the python sdk.

This makes sense to me.",sure worth moving python sense,issue,negative,positive,positive,positive,positive,positive
1745893133,"It looks like `databricks-cli` doesn't provide a wheel for python 3?

https://pypi.org/project/databricks-cli/0.17.6/#files
",like provide wheel python,issue,negative,neutral,neutral,neutral,neutral,neutral
1745783294,"@BenWilson2 thanks for being so responsive on this. I had a look and we are using nginx to balance requests across mlflow servers. It appears as if `client_max_body_size` was set too low. We set it to 0, (turned it off) and now everything is peachy keen.",thanks responsive look balance across set low set turned everything peachy keen,issue,positive,positive,neutral,neutral,positive,positive
1745704063,"This is an old issue, but still seems interesting to me. @harupy Haru do you know if we support custom fields now?",old issue still interesting know support custom,issue,positive,positive,positive,positive,positive,positive
1745566125,"Thank you for looking into this @harupy

> Would you mind creating python code for this?

I can probably export one of my experiments from my MySQL database. Do you happen to have any steps for that?

I should mention that I have some experiments with runs that report around 10,000 steps. So imagine an average of 10 charts for 10 runs, each having 10,000 steps. It is understandable that it will take a minute or two to load the data and plot the charts. I don't think this should happen by default when I just want to see if my runs started or if they are still running. I am just waiting for the page to load, so I can click on the table view.

I think it is also putting my tracking server and MySQL instances on unnecessary stress, making some of my runs fail because the server becomes unresponsive.

As soon as I have a chance I'll try to downgrade to 2.5, until this gets addressed.

Thanks.
",thank looking would mind python code probably export one happen mention report around imagine average understandable take minute two load data plot think happen default want see still running waiting page load click table view think also server unnecessary stress making fail server becomes unresponsive soon chance try downgrade thanks,issue,negative,negative,negative,negative,negative,negative
1745533446,"@lminer What does your deployment of MLflow look like? Are you deploying to k8s? Running on EC2? What layers exist between your system, the tracking server, (and, if applicable, an artifact server if deployed in that mode), and your artifact store? 
Are there infrastructure configurations that are creating a bottleneck based on concurrent file transfers or rate limiting the transfer in some manner?",deployment look like running exist system server applicable artifact server mode artifact store infrastructure bottleneck based concurrent file rate limiting transfer manner,issue,negative,neutral,neutral,neutral,neutral,neutral
1745526431,"A good thing to test will be to:
- create a token for E2 Dogfood
- create a token for another workspace in AWS
- follow the process with https://docs.databricks.com/en/dev-tools/cli/profiles.html to register these profiles to the databrickscfg file
- attempt to login with this function. 

- log a run. 

Does the run appear in Dogfood or in AWS? 

Q: Do we need to provide disambiguation for selecting the appropriate profile when logging in? 
Q: If this proves to be super complex for profile users, what should be done? (if the config file contains profiles, do we use ENV VAR instead?) ",good thing test create token create token another follow process register file attempt login function log run run appear need provide appropriate profile logging super complex profile done file use instead,issue,positive,positive,positive,positive,positive,positive
1745492792,"@lminer what version of MLflow are you using? There have been some significant changes in the last few releases targeting enhanced support for larger files (primarily targeting the ultra-large LLM OSS models). 
",version significant last enhanced support primarily,issue,positive,positive,positive,positive,positive,positive
1745455027,"@dbczumar any ideas on what I might do to debug this? It works when I log an empty module, so maybe file size is the issue? The model is around 100 mb.",might work log empty module maybe file size issue model around,issue,negative,negative,neutral,neutral,negative,negative
1745414921,lol copy pasted the whole error log in its entirety,copy pasted whole error log entirety,issue,negative,positive,positive,positive,positive,positive
1745313297,"Another idea would be to add an explicit parameter list that : 
- When equals to None, download by default only the artifacts that starts with a given prefix like “requirement(s)“
- Else: provide the list of the user requirements files that will be downloaded.",another idea would add explicit parameter list none default given prefix like requirement else provide list user,issue,negative,neutral,neutral,neutral,neutral,neutral
1745306590,"I understand. Yes, I think that It would be helpful :)",understand yes think would helpful,issue,positive,neutral,neutral,neutral,neutral,neutral
1745300678,We can also document how to dowload only `requirements.txt` if you think that's helpful.,also document think helpful,issue,negative,neutral,neutral,neutral,neutral,neutral
1745283101,@Val3nt-ML The reason we download all the artifacts is `requirements.txt` may contain references to other requirement files. The proposal makes sense!,reason may contain requirement proposal sense,issue,negative,neutral,neutral,neutral,neutral,neutral
1745064266,"@harupy 
```
python_exe = ""/local_disk0/.ephemeral_nfs/envs/pythonEnv-c69f507c-73bd-4e2b-bc23-ac0bd7b3ed08/bin/python""

with mock.patch(""mlflow.utils.virtualenv. _install_python"", return_value=python_exe):

    model = mlflow.pyfunc.spark_udf(spark=spark, model_uri=""models:/test_mlflow_env_model/latest"", env_manager=""virtualenv"")
```
I get this:
AttributeError: <module 'mlflow.utils.virtualenv' from '/databricks/python/lib/python3.10/site-packages/mlflow/utils/virtualenv.py'> does not have the attribute ' _install_python'",model get module attribute,issue,negative,neutral,neutral,neutral,neutral,neutral
1745028874,"> @rsundqvist Can we call `mlflow.set_tags` like this?
> 
> ```python
> with mlflow.start_run():
>     mlflow.evaluate(model, training_data)
>     mlflow.set_tags(metric_tags)
> ```

This sets the tags on the run itself, which isn't really what we want. Though you could of course do something similar with nested runs + tags:

```python
with mlflow.start_run(""main-run""):
    training_data = Dataset(""input/train/all-markets.csv"")
    model = AmazingModel().fit(training_data)

    metric_tags = {MLFLOW_DATASET_CONTEXT: ""train"", MLFLOW_DATASET_NAME: training_data.name}
    mlflow.evaluate(""model"", training_data)
    mlflow.set_tags(metric_tags)
    
    test_data = Dataset(""input/test/all-markets.csv"")
    metric_tags = {MLFLOW_DATASET_CONTEXT: ""test"", MLFLOW_DATASET_NAME: test_data.name}
    for market, df in test_data.groupby(""market""):
        metric_tags[""market""] = market
        with mlflow.start_run(run_name=f""test metrics for {market}"", nested=True):
            mlflow.evaluate(""model"", df)
            mlflow.set_tags(metric_tags)
```
This might serve as some kind of grouping/specialization. 

However, at least as far as I know, there's no good way to query and group metrics with the same name based on parent runs. Subruns are treated just like parent runs in the compare view, for example, which isn't what we want. It would also make the number of runs explode.

If subruns played a part in how metrics are grouped and presented it might make more sense for us, but I don't think this is what subruns are intended to do. With that in mind, I don't think using subruns (or `mlflow.set_tags`) make sense as a solution to the use case described above.",call like python model run really want though could course something similar python model train model test market market market market test metric market model might serve kind however least far know good way query group metric name based parent like parent compare view example want would also make number explode part metric grouped might make sense u think intended mind think make sense solution use case,issue,positive,positive,positive,positive,positive,positive
1745007223,"This is a hack. We can try monkey-patching `_install_python` to skip python installation via pyenv:

https://github.com/mlflow/mlflow/blob/0d5adbd03be636b89f8b087f270f2aaedd19da93/mlflow/utils/virtualenv.py#L113

```python
from unittest import mock

with mock.patch(""mlflow.utils.virtualenv._install_python"", return_value=<path/to/python>):
    mlflow.pyfunc.spark_udf(...)
```",hack try skip python installation via python import mock,issue,negative,neutral,neutral,neutral,neutral,neutral
1744986715,"@harupy , yep, its just env manager tries to go to python org website to get python binary, but we have artifactory pypi proxy and no access to public github or python.org.
And i can redirect pypi to our pypi mirror, but this first step to download python binary, i cannot change it.",yep manager go python get python binary proxy access public redirect mirror first step python binary change,issue,negative,positive,positive,positive,positive,positive
1744971937,Can you install python libraries without network access? ,install python without network access,issue,negative,neutral,neutral,neutral,neutral,neutral
1744969731,@danilopeixoto I apologize for the oversight in the documentation about this. I'm going to take it as a task to correct this and provide clear guidance about this behavior. Thank you for the reminder :) ,apologize oversight documentation going take task correct provide clear guidance behavior thank reminder,issue,positive,positive,positive,positive,positive,positive
1744949403,"@rsundqvist Can we use `mlflow.set_tags` like this?

```python
with mlflow.start_run():
    mlflow.evaluate(model, training_data)
    mlflow.set_tags(metric_tags)
```",use like python model,issue,negative,neutral,neutral,neutral,neutral,neutral
1744943304,"@harupy , but thats the point, i dont want to use local environment, but environment that model was trained on.",thats point dont want use local environment environment model trained,issue,negative,neutral,neutral,neutral,neutral,neutral
1744811171,"We can call `_populate_model_version_aliases` for each model version in `search_model_versions`, but I think it's slow when the number of model versions is large.",call model version think slow number model large,issue,negative,negative,neutral,neutral,negative,negative
1744769383,"DB backend doesn't.

```python
import mlflow
import tempfile

with tempfile.TemporaryDirectory() as tmpdir:
    mlflow.set_tracking_uri(f""sqlite:///{tmpdir}/mlflow.db"")
    client = mlflow.MlflowClient()

    name = ""sklearn_wine""

    with mlflow.start_run():
        mlflow.sklearn.log_model(
            sk_model=""model"",
            artifact_path=""model"",
            registered_model_name=name,
        )

    client.set_registered_model_alias(name, ""foo"", ""1"")
    vr = client.get_model_version(name, ""1"")
    print(vr.aliases)  # :)

    vrs = client.search_model_versions(f""name='{name}'"")
    print(vrs[0].aliases)  # :(
```

```
['foo']
[]
```",python import import client name model model name foo name print name print,issue,negative,neutral,neutral,neutral,neutral,neutral
1744768164,"File backend works fine:

```python
import mlflow
import tempfile

with tempfile.TemporaryDirectory() as tmpdir:
    mlflow.set_tracking_uri(f""{tmpdir}/mlruns"")
    client = mlflow.MlflowClient()

    name = ""sklearn_wine""

    with mlflow.start_run():
        mlflow.sklearn.log_model(
            sk_model=""model"",
            artifact_path=""model"",
            registered_model_name=name,
        )

    client.set_registered_model_alias(name, ""foo"", ""1"")
    vr = client.get_model_version(name, ""1"")
    print(vr.aliases)  # :)

    vrs = client.search_model_versions(f""name='{name}'"")
    print(vrs[0].aliases)  # :(
```

```
['foo']
['foo']
```",file work fine python import import client name model model name foo name print name print,issue,negative,positive,positive,positive,positive,positive
1744720094,Thanks for updating the proxy-mpu branch! I think rebase should fix the CI failures.,thanks branch think rebase fix,issue,negative,positive,positive,positive,positive,positive
1744503364,The original error has been fixed. I'll merge this PR.,original error fixed merge,issue,negative,positive,positive,positive,positive,positive
1744494804,"@WeichenXu123 A new error occurred:

https://github.com/mlflow/mlflow/actions/runs/6389947885/job/17342237962?pr=9800#step:13:684

```
E                   py4j.protocol.Py4JJavaError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.
E                   : java.lang.NoSuchMethodError: 'org.sparkproject.connect.grpc.ServerServiceDefinition org.apache.spark.connect.proto.SparkConnectServiceGrpc.bindService(org.apache.spark.connect.proto.SparkConnectServiceGrpc$AsyncService)'
E                   	at org.apache.spark.sql.connect.service.SparkConnectService.bindService(SparkConnectService.scala:242)
E                   	at org.sparkproject.connect.grpc.internal.ServerImplBuilder.addService(ServerImplBuilder.java:143)
E                   	at org.sparkproject.connect.grpc.internal.ServerImplBuilder.addService(ServerImplBuilder.java:57)
E                   	at org.sparkproject.connect.grpc.internal.AbstractServerImplBuilder.addService(AbstractServerImplBuilder.java:93)
E                   	at org.sparkproject.connect.grpc.internal.AbstractServerImplBuilder.addService(AbstractServerImplBuilder.java:48)
E                   	at org.apache.spark.sql.connect.service.SparkConnectService$.startGRPCService(SparkConnectService.scala:417)
E                   	at org.apache.spark.sql.connect.service.SparkConnectService$.start(SparkConnectService.scala:433)
E                   	at org.apache.spark.sql.connect.SparkConnectPlugin$$anon$1.init(SparkConnectPlugin.scala:48)
E                   	at org.apache.spark.internal.plugin.DriverPluginContainer.$anonfun$driverPlugins$1(PluginContainer.scala:53)
E                   	at scala.collection.StrictOptimizedIterableOps.flatMap(StrictOptimizedIterableOps.scala:118)
E                   	at scala.collection.StrictOptimizedIterableOps.flatMap$(StrictOptimizedIterableOps.scala:105)
E                   	at scala.collection.immutable.ArraySeq.flatMap(ArraySeq.scala:35)
E                   	at org.apache.spark.internal.plugin.DriverPluginContainer.<init>(PluginContainer.scala:46)
E                   	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:210)
E                   	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:193)
E                   	at org.apache.spark.SparkContext.<init>(SparkContext.scala:[578](https://github.com/mlflow/mlflow/actions/runs/6389947885/job/17342237962?pr=9800#step:13:579))
E                   	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
E                   	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
E                   	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)
E                   	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
E                   	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)
E                   	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)
E                   	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
E                   	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
E                   	at py4j.Gateway.invoke(Gateway.java:238)
E                   	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
E                   	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
E                   	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
E                   	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
E                   	at java.base/java.lang.Thread.run(Thread.java:833)
```",new error error calling anon native method,issue,negative,positive,positive,positive,positive,positive
1744203887,"Thanks, I can't think of a situation where it would _not_ make sense to preserve the file metadata, but hopefully this doesn't cause any issues. ",thanks ca think situation would make sense preserve file hopefully cause,issue,positive,positive,positive,positive,positive,positive
1744168729,@dimitri-voytan Makes sense. Let me file a PR and see what happens. I think it'll work fine.,sense let file see think work fine,issue,negative,positive,positive,positive,positive,positive
1744166907,@irmathebest Feel free to reopen the issue once you find a way to reproduce the issue.,feel free reopen issue find way reproduce issue,issue,positive,positive,positive,positive,positive,positive
1744151922,"I'd like to work on this issue, could anyone assign this ticket to me?",like work issue could anyone assign ticket,issue,negative,neutral,neutral,neutral,neutral,neutral
1744020610,"Hey @chenmoneygithub we were just discussing in standup... 
Could we try a methodology here that makes it impossible to leak credentials in a Jupyter Notebook / IPython / IDLE by adopting this pseudo code?

```python
def can_I_call_databricks() -> bool:
    
    try:
        # Is there a mechanism that we can use with databricks cli to determine whether the current user has 
        # authenticated access with the values that are stored within databricks.cfg?
        # We should use that here.
        return phone_home()
    except AuthenticationError as e:
        ...

        return False

def _get_secret_info_we_do_not_want_in_notebooks():
    
    host = getpass.getpass(""What is your host?"")
    username = getpass.getpass(""What is your username?"")
    password = getpass.getpass(""What is your password?"")
    
    return (host, username, password)
        
def mlflow_login(update_configs: bool=False): 
    
    if update_configs:
        confs = _get_secret_info_we_do_not_want_in_notebooks()
        # prompt for each value, overwrite databricks.cfg and try to login.
    else:
        
        # Check if databricks.cfg is present - do not prompt. Try to use the config.
        if can_I_call_databricks():
            return # We're good. Auth is set up.
        else:
            confs = _get_secret_info_we_do_not_want_in_notebooks()
            
            # overwrite databricks.cfg
            
            if can_I_call_databricks():
                return # New auth config is good to go
            else:
                raise MLflowException(""The auth data that you have passed is invalid. Check it carefully."")
```",hey could try methodology impossible leak notebook idle pseudo code python bool try mechanism use determine whether current user access within use return except return false host host password password return host password prompt value overwrite try login else check present prompt try use return good set else overwrite return new good go else raise data invalid check carefully,issue,positive,positive,neutral,neutral,positive,positive
1743938947,"Hi @santiagxf looks like there's a merge conflict. Do you want me to resolve it and merge tomorrow, or do you want to handle it?",hi like merge conflict want resolve merge tomorrow want handle,issue,positive,neutral,neutral,neutral,neutral,neutral
1743883612,"@adeandrade Thanks for the report!

> Create an experiment with multiple runs and multiple metrics with a lot of data points.

Would you mind creating python code for this?",thanks report create experiment multiple multiple metric lot data would mind python code,issue,positive,positive,neutral,neutral,positive,positive
1743620072,"Hello, I would like to work on this issue. Could you please assign it to me? 
",hello would like work issue could please assign,issue,positive,neutral,neutral,neutral,neutral,neutral
1743332815,"Hi @harupy ,

Yes. This illustrates the point using file permissions, rather than group id, which is a little easier to emulate with python alone. You should see that the file permissions are different between the local file and the file logged in the artifact repo. 

```
from mlflow.store.artifact.local_artifact_repo import LocalArtifactRepository
import os


artifact_file = 'my_artifact.txt'
artifact_uri = './artifact_repo'

# Instantiate the local artifact reposity which uses shutil.copyfile to log artifacts
repo = LocalArtifactRepository(artifact_uri=artifact_uri)

# Write a file to disk to log w/ mlflow
with open(artifact_file, 'w+') as my_artifact_file:
    my_artifact_file.write('example artifact \n')
  
# Set the file's permissions to 777 before logging to show how `shutil.copyfile` does not preserve metadata
os.chmod(artifact_file, 0o777)
local_metadata = os.stat(artifact_file)
print(f""file permissions for local metadata: {oct(local_metadata.st_mode)}"")

# Log the file into the repo
repo.log_artifact(artifact_file)

# compare to metadata in the artifact repo to the local metadata
repo_metadata = os.stat(os.path.join(artifact_uri, artifact_file))

print(f""file permissions for repo metadata: {oct(repo_metadata.st_mode)}"")
```",hi yes point file rather group id little easier emulate python alone see file different local file file logged artifact import import o local artifact log write file disk log open artifact set file logging show preserve print file local log file compare artifact local print file,issue,negative,negative,neutral,neutral,negative,negative
1743288030,"> @C-K-Loan can you split this PR? A PR that attempts to solve multiple problems is harder to review.

Ok let me do that",split solve multiple harder review let,issue,negative,negative,neutral,neutral,negative,negative
1743178708,"Hi @LostSputnik!
 In https://www.mlflow.org/docs/latest/python_api/mlflow.entities.html#mlflow.entities.Run you need to find these lines:
 ```
property inputs

    The run inputs, including dataset inputs

    Return type

        mlflow.entities.RunData
```
The line with the link [mlflow.entities.RunData](https://www.mlflow.org/docs/latest/python_api/mlflow.entities.html#mlflow.entities.Run) needs to be changed to [mlflow.entities.RunInputs](https://www.mlflow.org/docs/latest/python_api/mlflow.entities.html#mlflow.entities.RunInputs) link which is https://www.mlflow.org/docs/latest/python_api/mlflow.entities.html#mlflow.entities.RunInputs

So you need to change a file in mlflow/entities folder find link and change it. In [CONTRIBUTING](https://github.com/mlflow/mlflow/blob/master/CONTRIBUTING.md#writing-docs) you will find how your changes will be applied to html.",hi need find property run return type line link need link need change file folder find link change find applied,issue,negative,neutral,neutral,neutral,neutral,neutral
1743115951,Hi @M4nouel can you rebase on master and push the merge so that all CI fixes since the last rebase are included in this branch?,hi rebase master push merge since last rebase included branch,issue,negative,neutral,neutral,neutral,neutral,neutral
1743061371,"Hi @harupy ,
Thank you so much for maintaining this amazing OSS :)
If no one is working on this issue, could you assign it to me?",hi thank much amazing one working issue could assign,issue,positive,positive,positive,positive,positive,positive
1742421076,@amesar Can you complete the example? Code to register an alias is missing.,complete example code register alias missing,issue,negative,negative,neutral,neutral,negative,negative
1742338920,@C-K-Loan can you split this PR? A PR that attempts to solve multiple problems is harder to review.,split solve multiple harder review,issue,negative,negative,neutral,neutral,negative,negative
1742327480,"@WeichenXu123 This PR just fixes the `logger.exception call`, and doesn't fix the original error.",call fix original error,issue,negative,positive,positive,positive,positive,positive
1742026131,"I would like to contribute to this, as part of hacktoberfest 2023. But i don't fully understand the issue. When i click on the link icon on Run.inputs, it seems to link to the correct entry. What am i missing, can you please elaborate?",would like contribute part fully understand issue click link icon link correct entry missing please elaborate,issue,negative,positive,positive,positive,positive,positive
1742007461,"Hey @BenWilson2, I can work on this issue. Please assigned it to me!",hey work issue please assigned,issue,negative,neutral,neutral,neutral,neutral,neutral
1741490363,Facing the same issue - did anyone find a solution to this ?,facing issue anyone find solution,issue,negative,neutral,neutral,neutral,neutral,neutral
1741350216,"I'm having this issue and setting MLFLOW_TRACKING_INSECURE_TLS=true doesn't help. Not sure what to do. I read somewhere else that this might be an issue with TLS 1.3. Is there a way to force TLS 1.2? Traceback:

```
╭─────────────────────────────── Traceback (most recent call last) ────────────────────────────────╮
│ /lib/python3.10/site-packages/urllib3/connectionpool │
│ .py:714 in urlopen                                                                               │
│                                                                                                  │
│    711 │   │   │   │   self._prepare_proxy(conn)                                                 │
│    712 │   │   │                                                                                 │
│    713 │   │   │   # Make the request on the httplib connection object.                          │
│ ❱  714 │   │   │   httplib_response = self._make_request(                                        │
│    715 │   │   │   │   conn,                                                                     │
│    716 │   │   │   │   method,                                                                   │
│    717 │   │   │   │   url,                                                                      │
│                                                                                                  │
│ /lib/python3.10/site-packages/urllib3/connectionpool │
│ .py:415 in _make_request                                                                         │
│                                                                                                  │
│    412 │   │   │   if chunked:                                                                   │
│    413 │   │   │   │   conn.request_chunked(method, url, **httplib_request_kw)                   │
│    414 │   │   │   else:                                                                         │
│ ❱  415 │   │   │   │   conn.request(method, url, **httplib_request_kw)                           │
│    416 │   │                                                                                     │
│    417 │   │   # We are swallowing BrokenPipeError (errno.EPIPE) since the server is             │
│    418 │   │   # legitimately able to close the connection after sending a valid response.       │
│                                                                                                  │
│ /lib/python3.10/site-packages/urllib3/connection.py: │
│ 244 in request                                                                                   │
│                                                                                                  │
│   241 │   │   │   headers = headers.copy()                                                       │
│   242 │   │   if ""user-agent"" not in (six.ensure_str(k.lower()) for k in headers):               │
│   243 │   │   │   headers[""User-Agent""] = _get_default_user_agent()                              │
│ ❱ 244 │   │   super(HTTPConnection, self).request(method, url, body=body, headers=headers)       │
│   245 │                                                                                          │
│   246 │   def request_chunked(self, method, url, body=None, headers=None):                       │
│   247 │   │   """"""                                                                                │
│                                                                                                  │
│ /lib/python3.10/http/client.py:1282 in request       │
│                                                                                                  │
│   1279 │   def request(self, method, url, body=None, headers={}, *,                              │
│   1280 │   │   │   │   encode_chunked=False):                                                    │
│   1281 │   │   """"""Send a complete request to the server.""""""                                      │
│ ❱ 1282 │   │   self._send_request(method, url, body, headers, encode_chunked)                    │
│   1283 │                                                                                         │
│   1284 │   def _send_request(self, method, url, body, headers, encode_chunked):                  │
│   1285 │   │   # Honor explicitly requested Host: and Accept-Encoding: headers.                  │
│                                                                                                  │
│ /lib/python3.10/http/client.py:1328 in _send_request │
│                                                                                                  │
│   1325 │   │   │   # RFC 2616 Section 3.7.1 says that text default has a                         │
│   1326 │   │   │   # default charset of iso-8859-1.                                              │
│   1327 │   │   │   body = _encode(body, 'body')                                                  │
│ ❱ 1328 │   │   self.endheaders(body, encode_chunked=encode_chunked)                              │
│   1329 │                                                                                         │
│   1330 │   def getresponse(self):                                                                │
│   1331 │   │   """"""Get the response from the server.                                              │
│                                                                                                  │
│ /lib/python3.10/http/client.py:1277 in endheaders    │
│                                                                                                  │
│   1274 │   │   │   self.__state = _CS_REQ_SENT                                                   │
│   1275 │   │   else:                                                                             │
│   1276 │   │   │   raise CannotSendHeader()                                                      │
│ ❱ 1277 │   │   self._send_output(message_body, encode_chunked=encode_chunked)                    │
│   1278 │                                                                                         │
│   1279 │   def request(self, method, url, body=None, headers={}, *,                              │
│   1280 │   │   │   │   encode_chunked=False):                                                    │
│                                                                                                  │
│ /lib/python3.10/http/client.py:1076 in _send_output  │
│                                                                                                  │
│   1073 │   │   │   │   │   # chunked encoding                                                    │
│   1074 │   │   │   │   │   chunk = f'{len(chunk):X}\r\n'.encode('ascii') + chunk \               │
│   1075 │   │   │   │   │   │   + b'\r\n'                                                         │
│ ❱ 1076 │   │   │   │   self.send(chunk)                                                          │
│   1077 │   │   │                                                                                 │
│   1078 │   │   │   if encode_chunked and self._http_vsn == 11:                                   │
│   1079 │   │   │   │   # end chunked transfer                                                    │
│                                                                                                  │
│ /lib/python3.10/http/client.py:998 in send           │
│                                                                                                  │
│    995 │   │   │   return                                                                        │
│    996 │   │   sys.audit(""http.client.send"", self, data)                                         │
│    997 │   │   try:                                                                              │
│ ❱  998 │   │   │   self.sock.sendall(data)                                                       │
│    999 │   │   except TypeError:                                                                 │
│   1000 │   │   │   if isinstance(data, collections.abc.Iterable):                                │
│   1001 │   │   │   │   for d in data:                                                            │
│                                                                                                  │
│ /lib/python3.10/ssl.py:1237 in sendall               │
│                                                                                                  │
│   1234 │   │   │   with memoryview(data) as view, view.cast(""B"") as byte_view:                   │
│   1235 │   │   │   │   amount = len(byte_view)                                                   │
│   1236 │   │   │   │   while count < amount:                                                     │
│ ❱ 1237 │   │   │   │   │   v = self.send(byte_view[count:])                                      │
│   1238 │   │   │   │   │   count += v                                                            │
│   1239 │   │   else:                                                                             │
│   1240 │   │   │   return super().sendall(data, flags)                                           │
│                                                                                                  │
│ /lib/python3.10/ssl.py:1206 in send                  │
│                                                                                                  │
│   1203 │   │   │   │   raise ValueError(                                                         │
│   1204 │   │   │   │   │   ""non-zero flags not allowed in calls to send() on %s"" %               │
│   1205 │   │   │   │   │   self.__class__)                                                       │
│ ❱ 1206 │   │   │   return self._sslobj.write(data)                                               │
│   1207 │   │   else:                                                                             │
│   1208 │   │   │   return super().send(data, flags)                                              │
│   1209                                                                                           │
╰──────────────────────────────────────────────────────────────────────────────────────────────────╯
SSLEOFError: EOF occurred in violation of protocol (_ssl.c:2396)

During handling of the above exception, another exception occurred:

╭─────────────────────────────── Traceback (most recent call last) ────────────────────────────────╮
│ /lib/python3.10/site-packages/requests/adapters.py:4 │
│ 86 in send                                                                                       │
│                                                                                                  │
│   483 │   │   │   timeout = TimeoutSauce(connect=timeout, read=timeout)                          │
│   484 │   │                                                                                      │
│   485 │   │   try:                                                                               │
│ ❱ 486 │   │   │   resp = conn.urlopen(                                                           │
│   487 │   │   │   │   method=request.method,                                                     │
│   488 │   │   │   │   url=url,                                                                   │
│   489 │   │   │   │   body=request.body,                                                         │
│                                                                                                  │
│ /lib/python3.10/site-packages/urllib3/connectionpool │
│ .py:826 in urlopen                                                                               │
│                                                                                                  │
│    823 │   │   │   log.warning(                                                                  │
│    824 │   │   │   │   ""Retrying (%r) after connection broken by '%r': %s"", retries, err, url    │
│    825 │   │   │   )                                                                             │
│ ❱  826 │   │   │   return self.urlopen(                                                          │
│    827 │   │   │   │   method,                                                                   │
│    828 │   │   │   │   url,                                                                      │
│    829 │   │   │   │   body,                                                                     │
│                                                                                                  │
│ /lib/python3.10/site-packages/urllib3/connectionpool │
│ .py:826 in urlopen                                                                               │
│                                                                                                  │
│    823 │   │   │   log.warning(                                                                  │
│    824 │   │   │   │   ""Retrying (%r) after connection broken by '%r': %s"", retries, err, url    │
│    825 │   │   │   )                                                                             │
│ ❱  826 │   │   │   return self.urlopen(                                                          │
│    827 │   │   │   │   method,                                                                   │
│    828 │   │   │   │   url,                                                                      │
│    829 │   │   │   │   body,                                                                     │
│                                                                                                  │
│ /lib/python3.10/site-packages/urllib3/connectionpool │
│ .py:826 in urlopen                                                                               │
│                                                                                                  │
│    823 │   │   │   log.warning(                                                                  │
│    824 │   │   │   │   ""Retrying (%r) after connection broken by '%r': %s"", retries, err, url    │
│    825 │   │   │   )                                                                             │
│ ❱  826 │   │   │   return self.urlopen(                                                          │
│    827 │   │   │   │   method,                                                                   │
│    828 │   │   │   │   url,                                                                      │
│    829 │   │   │   │   body,                                                                     │
│                                                                                                  │
│ /lib/python3.10/site-packages/urllib3/connectionpool │
│ .py:826 in urlopen                                                                               │
│                                                                                                  │
│    823 │   │   │   log.warning(                                                                  │
│    824 │   │   │   │   ""Retrying (%r) after connection broken by '%r': %s"", retries, err, url    │
│    825 │   │   │   )                                                                             │
│ ❱  826 │   │   │   return self.urlopen(                                                          │
│    827 │   │   │   │   method,                                                                   │
│    828 │   │   │   │   url,                                                                      │
│    829 │   │   │   │   body,                                                                     │
│                                                                                                  │
│ /lib/python3.10/site-packages/urllib3/connectionpool │
│ .py:826 in urlopen                                                                               │
│                                                                                                  │
│    823 │   │   │   log.warning(                                                                  │
│    824 │   │   │   │   ""Retrying (%r) after connection broken by '%r': %s"", retries, err, url    │
│    825 │   │   │   )                                                                             │
│ ❱  826 │   │   │   return self.urlopen(                                                          │
│    827 │   │   │   │   method,                                                                   │
│    828 │   │   │   │   url,                                                                      │
│    829 │   │   │   │   body,                                                                     │
│                                                                                                  │
│ /lib/python3.10/site-packages/urllib3/connectionpool │
│ .py:798 in urlopen                                                                               │
│                                                                                                  │
│    795 │   │   │   elif isinstance(e, (SocketError, HTTPException)):                             │
│    796 │   │   │   │   e = ProtocolError(""Connection aborted."", e)                               │
│    797 │   │   │                                                                                 │
│ ❱  798 │   │   │   retries = retries.increment(                                                  │
│    799 │   │   │   │   method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]           │
│    800 │   │   │   )                                                                             │
│    801 │   │   │   retries.sleep()                                                               │
│                                                                                                  │
│ /lib/python3.10/site-packages/urllib3/util/retry.py: │
│ 592 in increment                                                                                 │
│                                                                                                  │
│   589 │   │   )                                                                                  │
│   590 │   │                                                                                      │
│   591 │   │   if new_retry.is_exhausted():                                                       │
│ ❱ 592 │   │   │   raise MaxRetryError(_pool, url, error or ResponseError(cause))                 │
│   593 │   │                                                                                      │
│   594 │   │   log.debug(""Incremented Retry for (url='%s'): %r"", url, new_retry)                  │
│   595                                                                                            │
╰──────────────────────────────────────────────────────────────────────────────────────────────────╯
MaxRetryError: HTTPSConnectionPool(host='foo', port=443): Max retries exceeded with url:
/api/2.0/mlflow-artifacts/artifacts/experiments/foo (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol
(_ssl.c:2396)')))

During handling of the above exception, another exception occurred:

╭─────────────────────────────── Traceback (most recent call last) ────────────────────────────────╮
│ /lib/python3.10/site-packages/mlflow/utils/rest_util │
│ s.py:92 in http_request                                                                          │
│                                                                                                  │
│    89 │   cleaned_hostname = strip_suffix(hostname, ""/"")                                         │
│    90 │   url = f""{cleaned_hostname}{endpoint}""                                                  │
│    91 │   try:                                                                                   │
│ ❱  92 │   │   return _get_http_response_with_retries(                                            │
│    93 │   │   │   method,                                                                        │
│    94 │   │   │   url,                                                                           │
│    95 │   │   │   max_retries,                                                                   │
│                                                                                                  │
│ /lib/python3.10/site-packages/mlflow/utils/request_u │
│ tils.py:135 in _get_http_response_with_retries                                                   │
│                                                                                                  │
│   132 │   :return: requests.Response object.                                                     │
│   133 │   """"""                                                                                    │
│   134 │   session = _get_request_session(max_retries, backoff_factor, retry_codes)               │
│ ❱ 135 │   return session.request(method, url, **kwargs)                                          │
│   136                                                                                            │
│   137                                                                                            │
│   138 def cloud_storage_http_request(                                                            │
│                                                                                                  │
│ /lib/python3.10/site-packages/requests/sessions.py:5 │
│ 89 in request                                                                                    │
│                                                                                                  │
│   586 │   │   │   ""allow_redirects"": allow_redirects,                                            │
│   587 │   │   }                                                                                  │
│   588 │   │   send_kwargs.update(settings)                                                       │
│ ❱ 589 │   │   resp = self.send(prep, **send_kwargs)                                              │
│   590 │   │                                                                                      │
│   591 │   │   return resp                                                                        │
│   592                                                                                            │
│                                                                                                  │
│ /lib/python3.10/site-packages/requests/sessions.py:7 │
│ 03 in send                                                                                       │
│                                                                                                  │
│   700 │   │   start = preferred_clock()                                                          │
│   701 │   │                                                                                      │
│   702 │   │   # Send the request                                                                 │
│ ❱ 703 │   │   r = adapter.send(request, **kwargs)                                                │
│   704 │   │                                                                                      │
│   705 │   │   # Total elapsed time of the request (approximately)                                │
│   706 │   │   elapsed = preferred_clock() - start                                                │
│                                                                                                  │
│ /lib/python3.10/site-packages/requests/adapters.py:5 │
│ 17 in send                                                                                       │
│                                                                                                  │
│   514 │   │   │                                                                                  │
│   515 │   │   │   if isinstance(e.reason, _SSLError):                                            │
│   516 │   │   │   │   # This branch is for urllib3 v1.22 and later.                              │
│ ❱ 517 │   │   │   │   raise SSLError(e, request=request)                                         │
│   518 │   │   │                                                                                  │
│   519 │   │   │   raise ConnectionError(e, request=request)                                      │
│   520                                                                                            │
╰──────────────────────────────────────────────────────────────────────────────────────────────────╯
SSLError: HTTPSConnectionPool(host='foo', port=443): Max retries exceeded with url:
/api/2.0/mlflow-artifacts/artifacts/foo (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol
(_ssl.c:2396)')))

During handling of the above exception, another exception occurred:

╭─────────────────────────────── Traceback (most recent call last) ────────────────────────────────╮
│ foo.py:340 in <module>               │
│                                                                                                  │
│   337 │   │   raise ValueError(""remove_encoder is not supported for tensorrt_plan"")              │
│   338 │                                                                                          │
│   339 │   if args.backend in [""onnx"", ""torch""]:                                                  │
│ ❱ 340 │   │   freeze_models(                                                                     │
│   341 │   │   │   checkpoint_path=args.checkpoint_path,                                          │
│   342 │   │   │   batch_size=args.batch_size,                                                    │
│   343 │   │   │   overlap=args.overlap,                                                          │
│                                                                                                  │
│ foo.py:251 in freeze_models          │
│                                                                                                  │
│   248 │   │   │   )                                                                              │
│   249 │   │   │   signature = infer_signature(input_data.numpy(), output_data.numpy())           │
│   250 │   │   │   export_model = onnx.load(str(tmp_export_path))                                 │
│ ❱ 251 │   │   │   mlflow.onnx.log_model(                                                         │
│   252 │   │   │   │   export_model,                                                              │
│   253 │   │   │   │   artifact_path=str(root_dir),                                               │
│   254 │   │   │   │   signature=signature,                                                       │
│                                                                                                  │
│ /lib/python3.10/site-packages/mlflow/onnx.py:517 in  │
│ log_model                                                                                        │
│                                                                                                  │
│   514 │   :return: A :py:class:`ModelInfo <mlflow.models.model.ModelInfo>` instance that conta   │
│   515 │   │   │    metadata of the logged model.                                                 │
│   516 │   """"""                                                                                    │
│ ❱ 517 │   return Model.log(                                                                      │
│   518 │   │   artifact_path=artifact_path,                                                       │
│   519 │   │   flavor=mlflow.onnx,                                                                │
│   520 │   │   onnx_model=onnx_model,                                                             │
│                                                                                                  │
│ /lib/python3.10/site-packages/mlflow/models/model.py │
│ :580 in log                                                                                      │
│                                                                                                  │
│   577 │   │   │   ):                                                                             │
│   578 │   │   │   │   _logger.warning(_LOG_MODEL_MISSING_SIGNATURE_WARNING)                      │
│   579 │   │   │   flavor.save_model(path=local_path, mlflow_model=mlflow_model, **kwargs)        │
│ ❱ 580 │   │   │   mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)   │
│   581 │   │   │   try:                                                                           │
│   582 │   │   │   │   mlflow.tracking.fluent._record_logged_model(mlflow_model)                  │
│   583 │   │   │   except MlflowException:                                                        │
│                                                                                                  │
│ /lib/python3.10/site-packages/mlflow/tracking/fluent │
│ .py:908 in log_artifacts                                                                         │
│                                                                                                  │
│    905 │   │   │   mlflow.log_artifacts(""data"", artifact_path=""states"")                          │
│    906 │   """"""                                                                                   │
│    907 │   run_id = _get_or_start_run().info.run_id                                              │
│ ❱  908 │   MlflowClient().log_artifacts(run_id, local_dir, artifact_path)                        │
│    909                                                                                           │
│    910                                                                                           │
│    911 def log_text(text: str, artifact_file: str) -> None:                                      │
│                                                                                                  │
│ /lib/python3.10/site-packages/mlflow/tracking/client │
│ .py:1138 in log_artifacts                                                                        │
│                                                                                                  │
│   1135 │   │   │   artifact: states                                                              │
│   1136 │   │   │   is_dir: True                                                                  │
│   1137 │   │   """"""                                                                               │
│ ❱ 1138 │   │   self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)             │
│   1139 │                                                                                         │
│   1140 │   @contextlib.contextmanager                                                            │
│   1141 │   def _log_artifact_helper(self, run_id, artifact_file):                                │
│                                                                                                  │
│ /lib/python3.10/site-packages/mlflow/tracking/_track │
│ ing_service/client.py:463 in log_artifacts                                                       │
│                                                                                                  │
│   460 │   │   :param local_dir: Path to the directory of files to write.                         │
│   461 │   │   :param artifact_path: If provided, the directory in ``artifact_uri`` to write to   │
│   462 │   │   """"""                                                                                │
│ ❱ 463 │   │   self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)            │
│   464 │                                                                                          │
│   465 │   def list_artifacts(self, run_id, path=None):                                           │
│   466 │   │   """"""                                                                                │
│                                                                                                  │
│ /lib/python3.10/site-packages/mlflow/store/artifact/ │
│ http_artifact_repo.py:45 in log_artifacts                                                        │
│                                                                                                  │
│   42 │   │   │   │   │   posixpath.join(artifact_path, rel_path) if artifact_path else rel_pa    │
│   43 │   │   │   │   )                                                                           │
│   44 │   │   │   for f in filenames:                                                             │
│ ❱ 45 │   │   │   │   self.log_artifact(os.path.join(root, f), artifact_dir)                      │
│   46 │                                                                                           │
│   47 │   def list_artifacts(self, path=None):                                                    │
│   48 │   │   endpoint = ""/mlflow-artifacts/artifacts""                                            │
│                                                                                                  │
│ /lib/python3.10/site-packages/mlflow/store/artifact/ │
│ http_artifact_repo.py:28 in log_artifact                                                         │
│                                                                                                  │
│   25 │   │   endpoint = posixpath.join(""/"", *paths)                                              │
│   26 │   │   extra_headers = {""Content-Type"": mime_type}                                         │
│   27 │   │   with open(local_file, ""rb"") as f:                                                   │
│ ❱ 28 │   │   │   resp = http_request(                                                            │
│   29 │   │   │   │   self._host_creds, endpoint, ""PUT"", data=f, extra_headers=extra_headers      │
│   30 │   │   │   )                                                                               │
│   31 │   │   │   augmented_raise_for_status(resp)                                                │
│                                                                                                  │
│ /lib/python3.10/site-packages/mlflow/utils/rest_util │
│ s.py:112 in http_request                                                                         │
│                                                                                                  │
│   109 │   except requests.exceptions.InvalidURL as iu:                                           │
│   110 │   │   raise InvalidUrlException(f""Invalid url: {url}"") from iu                           │
│   111 │   except Exception as e:                                                                 │
│ ❱ 112 │   │   raise MlflowException(f""API request to {url} failed with exception {e}"")           │
│   113                                                                                            │
│   114                                                                                            │
│   115 def _can_parse_as_json_object(string):                                                     │
╰──────────────────────────────────────────────────────────────────────────────────────────────────╯
MlflowException: API request to https://foo/api/2.0/mlflow-artifacts/artifacts/experiments/foo failed with
exception HTTPSConnectionPool(host='foo', port=443): Max retries exceeded with url:
/api/2.0/mlflow-artifacts/artifacts/experiments/foo (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol
(_ssl.c:2396)')))
```",issue setting help sure read somewhere else might issue way force recent call last conn make request connection object conn method method else method since server legitimately able close connection sending valid response request super self method self method request request self method send complete request server method body self method body honor explicitly host section text default default iso body body body self get response server else raise request self method chunk chunk chunk chunk end transfer send return self data try data except data data data view amount count amount count count else return super data send raise send return data else return super data violation protocol handling exception another exception recent call last send try resp connection broken err return method body connection broken err return method body connection broken err return method body connection broken err return method body connection broken err return method body connection aborted method increment raise error cause retry violation protocol handling exception another exception recent call last try return method return object session return method request resp prep return resp send start send request request total time request approximately start send branch later raise raise violation protocol handling exception another exception recent call last module raise torch signature return class instance logged model return log try except data text none artifact true self param path directory write param provided directory write self else root self open resp put resp except raise invalid except exception raise request exception string request exception violation protocol,issue,negative,positive,neutral,neutral,positive,positive
1740878546,"@chenmoneygithub I've made the requested changes and moved the contents to mlflow/shap/__init__.py. Please review again. Thanks!
",made content please review thanks,issue,positive,positive,positive,positive,positive,positive
1740262325,"@issamarabi thanks for the PR! It's my bad, but could you move it to `mlflow/shap/__init__.py` instead? thanks!",thanks bad could move instead thanks,issue,negative,negative,neutral,neutral,negative,negative
1740151362,Filing this per feedback/discussion with @dakinggg on the difficulty of discovering that this path is supported,filing per difficulty path,issue,negative,neutral,neutral,neutral,neutral,neutral
1740135331,@dbczumar @BenWilson2 all comments should be addressed.  Also Bedrock is GA as of [today](https://www.aboutamazon.com/news/aws/aws-amazon-bedrock-general-availability-generative-ai-innovations)!,also bedrock ga today,issue,negative,neutral,neutral,neutral,neutral,neutral
1740135016,"@irmathebest Thanks for reporting this bug.


> It works fine previously. 3 days ago

What changed?

> Run mlflow ui in the terminal and then open that in the browser. Then click on the customized log. And it shows the failed to fetch error.

- How can we reproduce this issue? Can you create a python script that can generate the data that can reprdocue this issue?
- Can you shared the full command you used to launch MLflow UI?",thanks bug work fine previously day ago run terminal open browser click log fetch error reproduce issue create python script generate data issue full command used launch,issue,negative,positive,positive,positive,positive,positive
1739799129,I think this is closely related to #2910. I have just commented over there and written some code that can be helpful for this case too.,think closely related written code helpful case,issue,negative,neutral,neutral,neutral,neutral,neutral
1739796242,"Hello,
I just faced the same problem, started to use mlflow using a local mlrun directory because it was easier, accumulated ~ 10000 runs, realized that the UI (and searching the runs in general) was too slow, and decided to use a SQL database. I wanted to migrate all my runs to the new database, but unfortunately [mlflow-export-import](https://github.com/mlflow/mlflow-export-import)  does not handle the case when migrating from a local storage. Therefore, I have developed some simple code that can migrate at least the experiments and the runs in each experiment to a database. I am sure the code still has several limitations, but it did the job for my user case and perhaps can help anyone facing the same issue. Maybe it can even be a starting point to implement something more official inside the project? Anyway, here is my code: https://github.com/BrunoBelucci/mlflow_util/blob/main/migrate_mlflow_backend.py

",hello faced problem use local directory easier searching general slow decided use migrate new unfortunately handle case local storage therefore simple code migrate least experiment sure code still several job user case perhaps help anyone facing issue maybe even starting point implement something official inside project anyway code,issue,negative,negative,neutral,neutral,negative,negative
1739778575,"I would really like this feature too, and would be willing to contribute it.",would really like feature would willing contribute,issue,negative,positive,positive,positive,positive,positive
1739731690,"@simonlsk thanks for reporting this. i was able to repro with the following:

1. run the python server with the following env vars and `mlflow server --serve-artifacts`
```
_MLFLOW_SERVER_ARTIFACT_DESTINATION=./artifacts
_MLFLOW_SERVER_ARTIFACT_ROOT=mlflow-artifacts:/
_MLFLOW_SERVER_SERVE_ARTIFACTS=true
```

2. create an experiment named ""test1"" with artifact location ""mlflow-artifacts:/test1-artifacts""
3. create a prompt eng run and observe the issue
```
2023/09/28 10:17:33 ERROR mlflow.server: Exception on /get-artifact [GET]
Traceback (most recent call last):
  ...
  File ""/Users/prithvi.kannan/mlflow/mlflow/server/handlers.py"", line 580, in get_artifact_handler
    return _send_artifact(artifact_repo, artifact_path)
  File ""/Users/prithvi.kannan/mlflow/mlflow/server/handlers.py"", line 478, in _send_artifact
    file_path = os.path.abspath(artifact_repository.download_artifacts(path))
  File ""/Users/prithvi.kannan/mlflow/mlflow/store/artifact/local_artifact_repo.py"", line 81, in download_artifacts
    raise OSError(f""No such file or directory: '{local_artifact_path}'"")
OSError: No such file or directory: './mlartifacts/test1-artifacts/493606ce44a94c48b0d73e4554a9412c/artifacts/eval_results_table.json'
```

the solution you proposed makes sense. we can use something like `_get_proxied_run_artifact_destination_path` https://github.com/mlflow/mlflow/blob/master/mlflow/server/handlers.py#L572-L575",thanks able following run python server following server create experiment test artifact location create prompt run observe issue error exception get recent call last file line return file line path file line raise file directory file directory solution sense use something like,issue,positive,positive,positive,positive,positive,positive
1739619367,"Skip `test_log_param_max_length_value` as we encountered several problems with mssql odbc driver 17 + sqlalchemy<2.0.
`[ODBC Driver 17 for SQL Server][SQL Server]The data types varchar and ntext are incompatible in the equal to operator` 
For odbc driver 18, there're extra problems:
`Sqlcmd: Error: Microsoft ODBC Driver 18 for SQL Server : SSL Provider: [error:0A000086:SSL routines::certificate verify failed:self-signed certificate].`
The easiest fix is to ask customer to upgrade sqlalchemy >= 2.0 if they want to upgrade the db with mssql.",skip several driver driver server server data incompatible equal operator driver extra error driver server provider error verify certificate easiest fix ask customer upgrade want upgrade,issue,negative,neutral,neutral,neutral,neutral,neutral
1739384194,Maybe @prithvikannan can shed some light on what I might be missing. ,maybe shed light might missing,issue,negative,positive,neutral,neutral,positive,positive
1739376718,"## Rough design
* Calculate the relative location of the artifact from the artifact-root
* Log artifact similarly to the `_upload_artifact` [handler](https://github.com/mlflow/mlflow/blob/2801858f65203a7f3155e412ca3fc2e0bff92803/mlflow/server/handlers.py#L1916)

@harupy WDYT?",rough design calculate relative location artifact log artifact similarly handler,issue,negative,negative,neutral,neutral,negative,negative
1738981170,"Hi,
I would like to be a volunteer to work on this issue.",hi would like volunteer work issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1738882698,"I'm debugging using `flask run` having `FLASK_APP=mlflow.server:app`, and the said env variables or running with:
```
mlflow server -h 0.0.0.0 \
    --backend-store-uri <db_uri> \
    --default-artifact-root ./artifacts \
    --serve-artifacts \
    --artifacts-destination  gs://<bucket>
```",flask run said running server bucket,issue,negative,neutral,neutral,neutral,neutral,neutral
1738871300,"How did you run the tracking server?

```
mlflow server ???
```

I want to know the `???` part.",run server server want know part,issue,negative,neutral,neutral,neutral,neutral,neutral
1738867946,"No commands required, reproduces with UI only.
Server runs with the following envs:
```
_MLFLOW_SERVER_ARTIFACT_DESTINATION=./artifacts
_MLFLOW_SERVER_ARTIFACT_ROOT=mlflow-artifacts:/
_MLFLOW_SERVER_SERVE_ARTIFACTS=true
```
Then I create an experiment with the following artifact location: `mlflow-artifacts:/<some-prefix>`.
Last step is create a new prompt engineering run.
",server following create experiment following artifact location last step create new prompt engineering run,issue,negative,positive,neutral,neutral,positive,positive
1738838978,@simonlsk Thanks for reporting this issue! Can you provide the commands you used?,thanks issue provide used,issue,negative,positive,positive,positive,positive,positive
1738827092,"I mean do you want me to contribute the fix in the docs, or are you taking this?",mean want contribute fix taking,issue,negative,negative,negative,negative,negative,negative
1738393405,"> https://github.com/mlflow/mlflow/issues/9744#issuecomment-1738366005

We have two types of code blocks

- `code-block`: No test. could be broken.
- `test-code-block`: tested whene building docs.",two code test could broken tested building,issue,negative,negative,negative,negative,negative,negative
1738366005,"@harupy Haru, one relevant question - do we have tests for our code examples in docstring? ",one relevant question code,issue,negative,positive,positive,positive,positive,positive
1738342823,@AmirAflak Thanks! Actually let me put them into different issues so that more contributors can start trying out MLflow development.,thanks actually let put different start trying development,issue,negative,positive,neutral,neutral,positive,positive
1738285706,"@HyukjinKwon 

Could you help check following error on spark master ?

Building command:
```shell
      ./build/mvn -Pconnect -Phive -DskipTests --no-transfer-progress clean package
      cd python
      python setup.py install
```

Error: https://github.com/mlflow/mlflow/actions/runs/6323788141/job/17172071030?pr=9534#step:13:670
```
---------------------------- Captured stderr setup -----------------------------
Error: Exception in thread ""main"" java.lang.NoSuchMethodError: 'scala.collection.mutable.WrappedArray scala.Predef$.wrapRefArray(java.lang.Object[])'
	at org.apache.spark.deploy.SparkSubmit$$anon$2$$anon$3.<init>(SparkSubmit.scala:1103)
	at org.apache.spark.deploy.SparkSubmit$$anon$2.parseArguments(SparkSubmit.scala:1103)
	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)
	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1120)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1129)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
_____________________ ERROR at setup of test_model_export ______________________
```",could help check following error spark master building command shell clean package python python install error setup error exception thread main anon anon anon anon error setup,issue,negative,positive,positive,positive,positive,positive
1738209272,"Realised I need to add infer signature/input example code, will add shortly.",need add infer example code add shortly,issue,negative,neutral,neutral,neutral,neutral,neutral
1737767934,"We found this amazing! We thank the MLflow team and community.

I'm wondering whether we should consider documenting this new standard introduced by MLflow for broader adoption and workflows.

Users have the capability to execute all their experiments within MLflow. When they are ready, they might seek to deploy the outcome across various environments - including the provider one.

The users will need to join the dots or we may need to explain to them the run with the best results is using temperature 0.5 which needs to be mapped to 1.0.",found amazing thank team community wondering whether consider new standard adoption capability execute within ready might seek deploy outcome across various provider one need join may need explain run best temperature need,issue,positive,positive,positive,positive,positive,positive
1737711604,"@harupy No specific command. I am not migrating the database. I am just using this basic auth as an option

```
$ cat basic_auth.ini
[mlflow]
default_permission = NO_PERMISSIONS
database_uri = mysql+pymysql://${USER}:${PASSWORD}@${HOST}:${PORT}/${AUTH_DATABASE}
admin_username = admin
admin_password = password
FROM --platform=linux/amd64 python:3.10.11

RUN pip install \
    mlflow==2.6.0 \
    pymysql==1.0.2 \
    boto3 && \
    mkdir /mlflow/

COPY ./basic_auth.ini /usr/local/lib/python3.10/site-packages/mlflow/server/auth/basic_auth.ini

EXPOSE 80

CMD mlflow server \
    --host 0.0.0.0 \
    --port 80 \
    --default-artifact-root ${BUCKET} \
    --backend-store-uri mysql+pymysql://${USERNAME}:${PASSWORD}@${HOST}:${PORT}/${DATABASE} \
    --app-name basic-auth
```

Switching to sqllite resolves the issue:

```
ubuntu@ip-10-10-131-116:~/mlflow-infra$ git diff basic_auth
diff --git a/basic_auth.ini b/basic_auth.ini
index 4c08603..1578d40 100644
--- a/basic_auth.ini
+++ b/basic_auth.ini
@@ -1,5 +1,5 @@
 [mlflow]
 default_permission = NO_PERMISSIONS
-database_uri = sqlite:///basic_auth.db
+database_uri = mysql+pymysql://${AUTH_DATABASE_USER}:${AUTH_DATABASE_PASSWORD}@${AUTH_DATABASE_INSTANCE}:${PORT}/${AUTH_DATABASE}
 admin_username = admin
 admin_password = password
```",specific command basic option cat user password host port password python run pip install copy expose server host port bucket password host port switching issue git git index port password,issue,negative,neutral,neutral,neutral,neutral,neutral
1737673228,"@mohitanchlia 

- Can you share the command you're using?
- Is it possible to check what tables your MySQL DB has after the error?
- Can you create a minimum reproducer using docker compose?",share command possible check table error create minimum reproducer docker compose,issue,negative,neutral,neutral,neutral,neutral,neutral
1737609904,"@BenWilson2 I created a new database mlflow_auth in the same DB instance. Pointed database_uri in basic_auth.ini and I still get exactly the same error. Not sure why it's showing an error on the metric table when it shouldn't matter at all. When I point database_uri back to sqllite then it works.

`database_uri = mysql+pymysql://${USERNAME}:${PASSWORD}@${HOST}:${PORT}/${AUTH_DATABASE}`",new instance pointed still get exactly error sure showing error metric table matter point back work password host port,issue,negative,positive,positive,positive,positive,positive
1737378974,"Removing the entries (or replacing with the supported exact match / wildcard match on equivalency on a single term) would be fine. 
searching on ``attributes.run_name = ""my_run%""`` or ``attributes.run_name ILIKE ""%my_run%""`` instead of the ``IN`` clause, for instance.",removing exact match match equivalency single term would fine searching instead clause instance,issue,negative,positive,positive,positive,positive,positive
1736871847,"Tested UC model:
<img width=""820"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/82044803/3daf33aa-2b22-4bb7-a860-334e54d5ada1"">
<img width=""872"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/82044803/be4adb48-6a87-457b-9e1d-a56d71a91745"">
",tested model image image,issue,negative,neutral,neutral,neutral,neutral,neutral
1736857868,@gabrielfu Got it. Is it possible to make the singup page an admin-only page?,got possible make page page,issue,negative,neutral,neutral,neutral,neutral,neutral
1736738957,Seems we need to pin pyspark in recipe tests as well,need pin recipe well,issue,negative,neutral,neutral,neutral,neutral,neutral
1736689492,"Thanks for your response. AFAIK there's no direct way other than copy-pasting packages manually from `pyproject.toml` to `python_env.yaml`. What I was trying to is invoking other scripts through `mlflow.run` using my poetry env, but I ended up directly calling functions in other modules in my training script. ",thanks response direct way manually trying poetry ended directly calling training script,issue,negative,positive,positive,positive,positive,positive
1736609282,@harupy I think it's still helpful if the admin can create users via UI,think still helpful create via,issue,positive,neutral,neutral,neutral,neutral,neutral
1736497620,"Thank you @BenWilson2 for the demo! Though I can't confirm that the behavior of the tooltip in the parallel coordinates chart is the same as the other chart types. Sorry if I'm missing something obvious... The parallel coordinates chart does indeed show the parameters that I've selected to show in the chart also in the tooltip, but that is not the case for the other charts.

I understand I can click the link back to the run to see the parameters, but that is not as useful for comparison at a glance as showing them in the tooltip would be.",thank though ca confirm behavior parallel chart chart sorry missing something obvious parallel chart indeed show selected show chart also case understand click link back run see useful comparison glance showing would,issue,negative,negative,neutral,neutral,negative,negative
1736477199,"@BenWilson2 That's interesting because all I changed was db_uri in basic_auth which shouldn't have anything to do with it. Unless the DB connection is not thread-safe (just a guess). When I changed the db_uri back to sqllite it worked again.

I'll try creating a new db and give it a shot",interesting anything unless connection guess back worked try new give shot,issue,negative,positive,positive,positive,positive,positive
1736446676,"We support pass-through of non-controlled parameters. But for those common elements across providers, we aim to provide a uniform and consistent API experience regardless of the provider that you're connecting to in order to reduce confusion among users who interface with many SaaS LLM providers. It would be very confusing for users who are standardizing on the AI Gateway to keep in mind that 'temperature' is in the range of 0-1 for all providers except one that has a slightly different rule set. 
As far as future work goes, if there are additional 'standard' parameters that arise and are not consistent across providers, we will handle unification and standardization across them all so that there is no confusion on the part of users or any undue conditional logic that they will have to follow on their end to ensure that what they're interfacing with is consistent across the different providers. 
I hope that clears up our position. 
Thank you for trying out the AI Gateway! ",support common across aim provide uniform consistent experience regardless provider order reduce confusion among interface many would ai gateway keep mind range except one slightly different rule set far future work go additional arise consistent across handle unification standardization across confusion part undue conditional logic follow end ensure consistent across different hope position thank trying ai gateway,issue,positive,positive,positive,positive,positive,positive
1736443781,"Does the same thing happen if you define a new database within the mysql instance? The migration script error that you're getting is raising an error based on a tracking server metrics table field that is already in existence. 
We're trying to figure out exactly the details on how to reproduce this. ",thing happen define new within instance migration script error getting raising error based server metric table field already existence trying figure exactly reproduce,issue,negative,positive,positive,positive,positive,positive
1736441262,"Hi @twrightsman, we're sorry that the functionality is not more clear on the current tooltip. 
If you click your mouse when that popup shows, it pins the box temporarily and the run name is a redirect link. You can either directly click it or open a new window with that link to display all of the run's properties for a quick reference. 

See this .gif for a demonstration within a parallel coordinates plot (sorry that I didn't mock up step entries, but the behavior is the same)

![show-params](https://github.com/mlflow/mlflow/assets/39283302/f7b902a6-3181-47ba-b6ac-c986f67c8aa8)",hi sorry functionality clear current click mouse box temporarily run name redirect link either directly click open new window link display run quick reference see demonstration within parallel plot sorry mock step behavior,issue,negative,negative,neutral,neutral,negative,negative
1736433768,@harupy @smurching here's the model registry page build output: https://output.circle-artifacts.com/output/job/2cbb799e-6727-4ceb-8b27-adfb0ac65270/artifacts/0/docs/build/html/model-registry.html,model registry page build output,issue,negative,neutral,neutral,neutral,neutral,neutral
1736424492,Hi @ggand0 we currently don't have any plans to support another package manager and take on the CI / dev burden to maintain compatibility with that. Is there a way for you to leverage virtualenv along with poetry?,hi currently support another package manager take dev burden maintain compatibility way leverage along poetry,issue,negative,neutral,neutral,neutral,neutral,neutral
1736129832,@BenWilson2 @harupy thanks for the comments. I think I worked out all of them. The PR should be good to go! Please merge it when you have the time.,thanks think worked good go please merge time,issue,positive,positive,positive,positive,positive,positive
1736016106,"Note: tags were never logged

            mlflow.log_input(dataset, context=""cecilia_evaluation"", tags={""version"": version, ""path"" : path})

<img width=""1333"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/614804/6b64eb33-f4fe-4e86-afc6-fa32a6b790fb"">
",note never logged version version path path image,issue,negative,neutral,neutral,neutral,neutral,neutral
1735874717,"@BenWilson2 No I am not running any migration commands. Simply changing the db_uri to point to mysql. Also, mysql was same as of the tracking server",running migration simply point also server,issue,negative,neutral,neutral,neutral,neutral,neutral
1735717294,"@BenWilson2 
Following are the sequence of events:
- Create mlflow on ecs without any authentication
- Run experiments
- Enable Basic Auth using sqlite
- Add several users
- Change the db_uri to mysql as shows above
- ecs service fails to come up with the error as mentioned above",following sequence create without authentication run enable basic add several change service come error,issue,negative,neutral,neutral,neutral,neutral,neutral
1735534017,@BenWilson2 Agreed. A centralized db outside of tracking store makes sense.,agreed outside store sense,issue,negative,neutral,neutral,neutral,neutral,neutral
1735465497,"This seems a bit confuse for OpenAI and OpenAI-compatible API servers. For example, the OpenAI playground also allows to set temperature using a slider component. The slider is transparent for the users. The value the users set is the value the users get.

![playground](https://github.com/mlflow/mlflow/assets/10113621/2221dce5-b134-4017-8b6a-d1340aafdecc)

For OpenAI-compatible API servers serving Llama-2, we also have to keep in mind the temperature 1 is 2.

OpenAI-compatible API servers:

- [Modelz LLM](https://github.com/tensorchord/modelz-llm)
- [vLLM](https://vllm.readthedocs.io/en/latest)

Does it require extra documentation per provider (a parameter map)?
Does MLflow have intention to expose other parameters? Will these parameters be mapped as well?",bit confuse example playground also set temperature slider component slider transparent value set value get playground serving also keep mind temperature require extra documentation per provider parameter map intention expose well,issue,positive,neutral,neutral,neutral,neutral,neutral
1734667997,"Hi @mohitanchlia can you give us an exact repro sequence of events of what you did when you encountered this? (state of systems, what versions, what commands you ran...)
",hi give u exact sequence state ran,issue,negative,positive,positive,positive,positive,positive
1734625187,"> @BenWilson2 which version of mlflow do I need to install to use this ?

It is in 2.7.1, our latest release.",version need install use latest release,issue,negative,positive,positive,positive,positive,positive
1734600470,"We do this for consistency amongst all routes. Since the contract is at our route definition layer and OpenAI's range is 0-2, keeping a consistent 0-1 range behavior for all routes is consistent for our APIs. ",consistency amongst since contract route definition layer range keeping consistent range behavior consistent,issue,negative,positive,positive,positive,positive,positive
1734505274,"A centralized store seems like a logical solution for your deployment woes. Any thoughts on this @gabrielfu @harupy ? I'm not convinced that sharing db resources with the tracking server is the right approach, but some form of centralization might be worth thinking about. ",store like logical solution deployment convinced server right approach form centralization might worth thinking,issue,positive,positive,positive,positive,positive,positive
1734496659,"Sorry, what is the error here? 
The message you're getting is that your current execution environment (Databricks, as you're using UC), does not have einops or loralib installed. 
Have you tried installing with a `%pip install <x>` command?",sorry error message getting current execution environment tried pip install command,issue,negative,negative,negative,negative,negative,negative
1734489577,Is this conditional logic target for this AgentExecutor the right path for this agent type? https://github.com/mlflow/mlflow/blob/55180340a6a3c460b5e3084a9eb2f2fa834c94f8/mlflow/langchain/__init__.py#L576-L580 ,conditional logic target right path agent type,issue,negative,positive,positive,positive,positive,positive
1734481096,Seems like there's some sort of global ref object in the agent's implementation in LangChain that is causing a pickle issue. @liangz1 was this agent ever tested or supported?,like sort global ref object agent implementation causing pickle issue agent ever tested,issue,negative,neutral,neutral,neutral,neutral,neutral
1734371219,@BenWilson2 which version of mlflow do I need to install to use this ? ,version need install use,issue,negative,neutral,neutral,neutral,neutral,neutral
1734305143,"Hi @BenWilson2, thanks for your effort in helping me out. I managed to solve it using version 1.7 of xgboost. For now, I haven't had the time to revisit this (cause I need to create a new Databricks cluster), but it's on my radar",hi thanks effort helping solve version time revisit cause need create new cluster radar,issue,positive,positive,positive,positive,positive,positive
1733354692,"I understand the motivation for not providing the ability to overwrite, but surely there should be a method to delete a parameter and re-enter it?",understand motivation providing ability overwrite surely method delete parameter,issue,positive,positive,positive,positive,positive,positive
1733237070,"Thank you @andrevargas22 and @wwwwf, the issue is resolved with the creation of tables manually. ",thank issue resolved creation table manually,issue,positive,neutral,neutral,neutral,neutral,neutral
1733041787,"In my case ... I was running the training script in a dev container with vs code and forgot to properly mount the path to artifacts. So, instead of writing to the folder on host (that is mounted to the mlflow tracking server container), I was writing to the directory in the dev container only...",case running training script dev container code forgot properly mount path instead writing folder host mounted server container writing directory dev container,issue,negative,neutral,neutral,neutral,neutral,neutral
1732983740,"The solution here was that the worker processes are not setup to connect to the MLFlow instance automatically like the driver is. I had to pass through the host and token as arguments to the script, and set the `DATABRICKS_TOKEN` and `DATABRICKS_HOST` environment variables inside the worker process.

If your MLFlow instance is in the same Databricks workspace and you are using a notebook as an entrypoint to the distributed code, you can use `db_token = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get()` (thanks to my SA for sharing that!) to pass through a working token. Alternatively your org may store a token as a secret, especially in the case where MLFlow is [hosted in another workspace](https://docs.databricks.com/en/machine-learning/manage-model-lifecycle/multiple-workspaces.html).",solution worker setup connect instance automatically like driver pas host token script set environment inside worker process instance notebook distributed code use thanks sa pas working token alternatively may store token secret especially case another,issue,positive,negative,neutral,neutral,negative,negative
1732282023,"Hi @BenWilson2, I have made the lint changes and rebased. Can you please merge this now",hi made lint please merge,issue,negative,neutral,neutral,neutral,neutral,neutral
1731755009,@BenWilson2 @harupy can we take a look at this PR? It introduces the fundamental changes in the API request processor to support Azure AD authentication and Embeddings in general.,take look fundamental request processor support azure ad authentication general,issue,negative,positive,neutral,neutral,positive,positive
1731707540,"> Is it possible to split this PR? It's a bit challenging to review this PR and verify the changes because it attempts to solve multiple issues + lots of refactoring.

Most of the refactoring was done because the implementation was a bit biased toward chat. I can separate them into a couple of PRs but each of them will build upon the previous one so if we can quickly review and merge I would highly appreciate @harupy.",possible split bit review verify solve multiple lot done implementation bit toward chat separate couple build upon previous one quickly review merge would highly appreciate,issue,positive,positive,neutral,neutral,positive,positive
1731537898,"Looks similar to what I was thinking. It could be much simpler, I don't think default* column in the experiment table is necessary. There could be one default* table instead.",similar thinking could much simpler think default column experiment table necessary could one default table instead,issue,negative,positive,neutral,neutral,positive,positive
1731452701,i believe this is a duplicate of #8864 . I was planning to introduce GBAC but I did not have the time to implement it yet.,believe duplicate introduce time implement yet,issue,negative,neutral,neutral,neutral,neutral,neutral
1731449824,"That's a solid point, thanks for giving us the feedback. We are going to make user creation an admin only action",solid point thanks giving u feedback going make user creation action,issue,positive,positive,positive,positive,positive,positive
1731094430,Is it possible to split this PR? It's a bit challenging to review this PR and verify the changes because it attempts to solve multiple issues + lots of refactoring.,possible split bit review verify solve multiple lot,issue,negative,neutral,neutral,neutral,neutral,neutral
1730916425,"The built `MLmodel` (with the original code) contains
```
signature:
  inputs: '[{""type"": ""tensor"", ""tensor-spec"": {""dtype"": ""float32"", ""shape"": [-1, 8]}}]'
  outputs: '[{""type"": ""tensor"", ""tensor-spec"": {""dtype"": ""float32"", ""shape"": [-1]}}]'
  params: null
```
and I initially assumed that `mlflow models predict` will just play by that signature ... but that does not seem to be case.

So maybe this just reveals something about the type handling in general that has not much to do with this specific model example.

Of course, another possibility would be to have a way to force `mlflow models predict` to use float32. Or to accept the float64 inputs (that the JSON parsing produces) and convert them to float32 under the hoods.",built original code signature type tensor float shape type tensor float shape null initially assumed predict play signature seem case maybe something type handling general much specific model example course another possibility would way force predict use float accept float convert float,issue,positive,positive,positive,positive,positive,positive
1730823265,"> LGTM - just wanted to check that Quinn recommended using ""provided question""/""provided answer"", are we using input/output instead because we don't want to restrict to question/answer?

Yes, we wanted to keep it generic. We can then see how we can improve this during our bug bash :) ",check provided question provided answer instead want restrict yes keep generic see improve bug bash,issue,positive,neutral,neutral,neutral,neutral,neutral
1730803764,"> disregard, this above, I was facing another issue. ;-)

Got it. Feel free to open a new issue.",disregard facing another issue got feel free open new issue,issue,negative,positive,positive,positive,positive,positive
1730803243,"@mabreuortega I built this dockerfile, but couldn't reproduce the error:

```dockerfile
FROM python:3.8

RUN pip install pydantic==2.3.0 pydantic_core==2.6.3 mlflow==2.7.1
RUN python -c 'import mlflow'
```

Can you run `python -c 'import mlflow'`?",built could reproduce error python run pip install run python run python,issue,negative,neutral,neutral,neutral,neutral,neutral
1730752655,"disregard, this above, I was facing another issue. ;-)",disregard facing another issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1730633822,"pip freeze | grep pydantic
`pydantic==2.3.0
pydantic_core==2.6.3`

pip freeze | grep mlflow

`mlflow==2.7.1`",pip freeze pip freeze,issue,negative,neutral,neutral,neutral,neutral,neutral
1730352399,"@mabreuortega Can you verify the results of:

```bash
pip freeze | grep pydantic
```
and 
```bash
pip freeze | grep mlflow
```
?",verify bash pip freeze bash pip freeze,issue,negative,neutral,neutral,neutral,neutral,neutral
1730298139,cc @harupy would be great to get your review on this as well! ,would great get review well,issue,positive,positive,positive,positive,positive,positive
1730232662,"> > Hi. Are there any plans on merging this feature? Don't mean to clutter the comments but it seems abandoned.
> 
> @kureta I think at this point I'm not confident enough in the design for this component to look nice inside of MLflow. If anyone is able to offer a better design for this **and** a spectrogram, I will implement it and try again. I know there should be better support for audio artifacts but I think that's what's preventing this from getting to the finish line.

what would you think about using a component such as [wavesurfer.js](https://wavesurfer-js.org/)?",hi feature mean clutter abandoned think point confident enough design component look nice inside anyone able offer better design spectrogram implement try know better support audio think getting finish line would think component,issue,positive,positive,positive,positive,positive,positive
1729567328,Is there any reason to let the create user operation be executed by any user? From my point of view it does not make much sense that this does not require admin permissions.,reason let create user operation executed user point view make much sense require,issue,negative,positive,positive,positive,positive,positive
1729243671,Pre and post-request processing for authentication might be causing overhead. I'll check.,authentication might causing overhead check,issue,negative,neutral,neutral,neutral,neutral,neutral
1728968737,"> Do we need to update docs/docstrings?

Can I update in a separate PR? I also want to unify all the docstring for input_example to reuse format_docstring and replace with {{ input_example }}.",need update update separate also want unify reuse replace,issue,negative,neutral,neutral,neutral,neutral,neutral
1728713771,We'll get the 'real fix' as @santiagxf mentioned merged in time for the next release of MLflow! ,get fix time next release,issue,negative,neutral,neutral,neutral,neutral,neutral
1728669856,"Please see the below for unprotected routes. I'm closing this issue for now as the reported bug is not found. Feel free to continue the discussion.

https://github.com/mlflow/mlflow/blob/3a1126eda00f23d79933a74ad62a3029474ba540/mlflow/server/auth/__init__.py#L116-L122",please see unprotected issue bug found feel free continue discussion,issue,negative,positive,positive,positive,positive,positive
1728303122,"FYI @BenWilson2 your suggestion works. Indeed there are no issues related to passing the parameters on log_model, I just hesitated to even try it that way because I will have to store another version every time I change a parameter's value.

Thx again.",suggestion work indeed related passing even try way store another version every time change parameter value,issue,negative,neutral,neutral,neutral,neutral,neutral
1728238840,"Admin is false. However, only admins should be allowed to create the users? What other operations are unprotected?",false however create unprotected,issue,negative,negative,negative,negative,negative,negative
1728119275,"Thx, I was not aware that it is not supported because there is a param argument in the function and I guessed that I can pass the original params.

I will try to provide them when I log the model.",aware param argument function pas original try provide log model,issue,negative,positive,positive,positive,positive,positive
1728113146,"Hi @gvelimir the usage of inference parameter overrides is currently not supported for the OpenAI flavor. 
The only supported means of overriding these values is at model save / log time. Can you try to provide those overrides when saving the model so that when the model is loaded they are applied via the .yaml load parser?",hi usage inference parameter currently flavor model save log time try provide saving model model loaded applied via load parser,issue,negative,neutral,neutral,neutral,neutral,neutral
1728102782,"The current behaviour is that user creation is unprotected and anyone can create a new user (whether the request sender is authenticated or not). So I don't think it is related to new user having admin permission.

To verify, can you try calling `/mlflow/users/get` to see if your new user has admin permission?",current behaviour user creation unprotected anyone create new user whether request sender think related new user permission verify try calling see new user permission,issue,negative,positive,neutral,neutral,positive,positive
1728083584,"Hi @yiwei-kinesso this isn't an MLflow issue. As the stack trace displays, langchain is incapable of saving this agent type as the process of saving https://github.com/langchain-ai/langchain/blob/775f3edffd7c1694408d78ae46df7fbc4979c46f/libs/langchain/langchain/agents/agent.py#L155-L186
calls the `dict()` method here: https://github.com/langchain-ai/langchain/blob/775f3edffd7c1694408d78ae46df7fbc4979c46f/libs/langchain/langchain/agents/agent.py#L145-L153 
which in turn calls https://github.com/langchain-ai/langchain/blob/775f3edffd7c1694408d78ae46df7fbc4979c46f/libs/langchain/langchain/agents/structured_chat/base.py#L140-L142 for the agent type that you've chosen. 

Perhaps asking what the serialization support is in their Repo might help? https://github.com/langchain-ai/langchain/discussions ",hi issue stack trace incapable saving agent type process saving method turn agent type chosen perhaps serialization support might help,issue,negative,neutral,neutral,neutral,neutral,neutral
1728052513,Hi @Abhishek-TyRnT could you run `black .` and push the corrected formatting changes in order for the linting to pass?,hi could run black push corrected order pas,issue,negative,negative,negative,negative,negative,negative
1728043868,"Hi @aspfohl The module references for types aren't recognized by sphinx for building the API docs. 

```bash
/home/circleci/project/mlflow/__init__.py:docstring of mlflow.models.evaluation.base.evaluate:: WARNING: py:class reference target not found: mlflow.pyfunc.PyFunc
/home/circleci/project/mlflow/__init__.py:docstring of mlflow.models.evaluation.base.evaluate:: WARNING: py:class reference target not found: mlflow.models.evaluation.base.EvaluationMetric
/home/circleci/project/mlflow/__init__.py:docstring of mlflow.models.evaluation.base.evaluate:: WARNING: py:class reference target not found: mlflow.models.evaluation.validation.MetricThreshold
/home/circleci/project/mlflow/models/__init__.py:docstring of mlflow.models.evaluation.base.evaluate:: WARNING: py:class reference target not found: mlflow.pyfunc.PyFunc
/home/circleci/project/mlflow/models/__init__.py:docstring of mlflow.models.evaluation.base.evaluate:: WARNING: py:class reference target not found: mlflow.models.evaluation.base.EvaluationMetric
/home/circleci/project/mlflow/models/__init__.py:docstring of mlflow.models.evaluation.base.evaluate:: WARNING: py:class reference target not found: mlflow.models.evaluation.validation.MetricThreshold
```

You can validate your build changes locally prior to committing to your branch by navigating from the root of the project to 
`cd docs` and then running:
```bash
make clean; make rsthtml
``` 
To aid in correcting the issues that sphinx is having resolving these classes.",hi module sphinx building bash warning class reference target found warning class reference target found warning class reference target found warning class reference target found warning class reference target found warning class reference target found validate build locally prior branch root project running bash make clean make aid correcting sphinx class,issue,negative,positive,positive,positive,positive,positive
1727933419,"Hi @nelsoncardenas I just did some validation of the behavior within `mlflow.xgboost.log_model()` to determine what the support for `.ubj` format is when specifying the optional `model_format` argument. 

I was able to save and load successfully with both `json` and `ubj` formats (which retain the metadata params that you're interested in). 

Could you try logging your model with this option (example below)?

```python
mlflow.xgboost.log_model(xgb_model=model, 
                         artifact_path=artifact_path, 
                         input_example=train_x.iloc[[0]],
                         model_format=""ubj"",
                         metadata={""model_data_version"": 1}
                         )
```",hi validation behavior within determine support format optional argument able save load successfully retain interested could try logging model option example python,issue,positive,positive,positive,positive,positive,positive
1727674814,"Would you mind explaining the objective of that constant? Why that specific path and why would we want to join it? Thanks
",would mind explaining objective constant specific path would want join thanks,issue,positive,positive,neutral,neutral,positive,positive
1727293395,"Just upgraded to the version with chart view, and it's very cool and nice to be able to see comparisons side by side now :)
A bit of feedback:
More color diversity would be great, a lot of my charts end up looking like this by accident (two grays, two blues)
![image](https://github.com/mlflow/mlflow/assets/5861991/6189d900-924a-4dac-a8e0-637ddf61c340)
On a cold start of the chart page, a lot of charts are generated, would be convenient if there was an option to ""clear the dashboard"".
Would be very useful if selecting an experiment from the sidebar would highlight the corresponding chart elements, seeing as occlusion sometimes prevents clicking the element directly in the chart.
Another useful feature would be a paired zoom, e.g. focusing on the same step range across all charts.",version chart view cool nice able see side side bit feedback color diversity would great lot end looking like accident two two blue image cold start chart page lot would convenient option clear dashboard would useful experiment would highlight corresponding chart seeing occlusion sometimes element directly chart another useful feature would paired zoom step range across,issue,positive,positive,positive,positive,positive,positive
1727068308,"Thanks for getting back to me, trying it out on VSCode and sorry for not replying. I guess you're right; this must be a PyCharm bug then.",thanks getting back trying sorry guess right must bug,issue,negative,negative,neutral,neutral,negative,negative
1726778926,"@chenmoneygithub Do you know why it causes problem with patching? I think this is a hard-to-debug issue if people don't know this, if we don't know how to fix it could we revert the change? cc @harupy ",know problem think issue people know know fix could revert change,issue,negative,neutral,neutral,neutral,neutral,neutral
1726751305,"Yea, lazy loading is not working well with MagicMock for some mystery reason. 

@Carl132 The simplest fix is loading the `mlflow.sklearn` module explicitly before the test, similar to [this](https://github.com/chenmoneygithub/mlflow/blob/8f46545582126cd3e33ab07e8aa39e191970b301/tests/tracking/fluent/test_fluent_autolog.py#L107-L108). Could you check if that works for you?",yea lazy loading working well mystery reason carl fix loading module explicitly test similar could check work,issue,negative,negative,negative,negative,negative,negative
1726473078,This tasks is on hold until we add gateway docs on databricks docs site so that we have a link for it.,hold add gateway site link,issue,negative,neutral,neutral,neutral,neutral,neutral
1726024091,Hey @prithvikannan could you rebase your fork and merge master in? Some of the test failures are just because you're 77 commits out of date.,hey could rebase fork merge master test date,issue,negative,neutral,neutral,neutral,neutral,neutral
1726003786,"@dhrp We'll definitely be interested in reviewing a non-opinionated and community-consensus validated implementation. For this helm chart, being firmly rooted in the k8s community of users, we'd like to get feedback from MLE's who are experts here to ensure that the solution works for the vast majority of use cases. 
Whomever ends up working on the PR, can we solicit feedback from everyone on this thread to provide reviews to the PR and ensure that your voice is heard? ",definitely interested implementation helm chart firmly rooted community like get feedback ensure solution work vast majority use whomever working solicit feedback everyone thread provide ensure voice,issue,positive,positive,neutral,neutral,positive,positive
1725972220,"Can you wrap the usage of the constant `MLFLOW_DOCKER_WORKDIR_PATH` in `pathlib.PurePosixPath(MLFLOW_DOCKER_WORKDIR_PATH).join(pathlib.PurePosixPath(container_path))`? 

Is this the part that is not working for you? https://github.com/mlflow/mlflow/blob/c93497f235933005c7ed39956b469d936652f9eb/mlflow/projects/utils.py#L36 

I think that if you dig in to where the artifact_uri is defined and apply a similar local environment handling of the path that is passed (something to negate the windows path that would be generated from any os.path operations or pathlib.Path operations (and, as you did, move to the PurePosixPath enforced behavior of the linux environment within docker)) might get you where you need to get to :) ",wrap usage constant part working think dig defined apply similar local environment handling path something negate path would move enforced behavior environment within docker might get need get,issue,negative,neutral,neutral,neutral,neutral,neutral
1725935664,"Hi @harupy you can reproduce this issue using the example code provided by mlflow https://mlflow.org/docs/latest/python_api/mlflow.pyfunc.html?highlight=save_model#mlflow.pyfunc.save_model

This itself is broken
```
from typing import List, Dict
import mlflow


class MyModel(mlflow.pyfunc.PythonModel):
    def predict(self, context, model_input: List[str], params=None) -> List[str]:
        return [i.upper() for i in model_input]


mlflow.pyfunc.save_model(""model"", python_model=MyModel(), input_example=[""a""])
model = mlflow.pyfunc.load_model(""model"")
print(model.predict([""a"", ""b"", ""c""]))  # -> err
```

If you do the following
```
sig = infer_signature([""a""], MyModel().predict(None, [""a""])
mlflow.pyfunc.save_model(""model"", python_model=MyModel(), input_example=[""a""], signature=sig)
```
then it works",hi reproduce issue example code provided broken import list import class predict self context list list return model model model print err following sig none model work,issue,negative,negative,negative,negative,negative,negative
1725925041,"Yeah it was! In my case I was trying to use mlflow gc inside the ec2 that acts as a server, setting MLFLOW_TRACKING_URI as my ec2 url. Instead the correct use is to set MLFLOW_TRACKING_URI as the local host: 

 export MLFLOW_TRACKING_URI=http://0.0.0.0:5000
",yeah case trying use inside server setting instead correct use set local host export,issue,negative,neutral,neutral,neutral,neutral,neutral
1725917603,"So I did some changes to the [_get_local_artifact_cmd_and_envs](https://github.com/mlflow/mlflow/blob/c93497f235933005c7ed39956b469d936652f9eb/mlflow/projects/backend/local.py#L341)  function. Making the container path a pathlib.PurePosixPath and removing the begining as shown bellow:
`container_path = PurePosixPath(*path.parts[1:])`

This will in fact solve the issue of having the proper docker command but the artifact_repo uri inside the container does not change and the runs will still point to the windows path and thus the artifacts will not be recorded. Maybe I'm not doing it right but there should be a way to change the artifact repo path for the docker execution. ",function making container path removing shown bellow fact solve issue proper docker command inside container change still point path thus maybe right way change artifact path docker execution,issue,negative,positive,positive,positive,positive,positive
1725913169,"Glad to hear! So, was it the `MLFLOW_TRACKING_URI` environment variable missing? (so it's clear for people down the line if that's all you needed to complete your setup, like in my case).

I am not an Mlflow expert but it seems like the operations in the gc transaction are not properly ordered, it seems a bug. I suggest to open a separate issue for that.",glad hear environment variable missing clear people line complete setup like case expert like transaction properly ordered bug suggest open separate issue,issue,positive,positive,neutral,neutral,positive,positive
1725903813,"Finally!! It does work. 

But another error raised. I can not delete some of the experiments due to this error to this command mlflow gc --backend-store-uri sqlite:///C:/mlflow/mlflow.db: 

raise MlflowException(message=e, error_code=BAD_REQUEST)
mlflow.exceptions.MlflowException: (psycopg2.errors.ForeignKeyViolation) update or delete on table ""experiments"" violates foreign key constraint ""datasets_experiment_id_fkey"" on table ""datasets""
DETAIL:  Key (experiment_id)=(26) is still referenced from table ""datasets"".

It seems to be a bug on the new ""datasets"" table.
",finally work another error raised delete due error command raise update delete table foreign key constraint table detail key still table bug new table,issue,negative,negative,neutral,neutral,negative,negative
1725873179,"@Matesanz is right the current solution will save all onnx models with external data, it would be nice to make this optional for the user. Or at least notify the user that this is the default as it is not the default for onnx.save_model().
",right current solution save external data would nice make optional user least notify user default default,issue,positive,positive,positive,positive,positive,positive
1725855974,"Ok, great. I like where we are going and I like the simplifications that @johncf made. @BenGalewsky version also looks mature (but lacks storage options, and is a bit biased). I will try to review and test these as well. 

If we can then get some attention from @harupy or @dbczumar for an ""ok to work on it"" ",great like going like made version also mature storage bit try review test well get attention work,issue,positive,positive,positive,positive,positive,positive
1725693623,"@RodrigoCasarCQ what worked for me in order to have gc running correctly was to add `MLFLOW_TRACKING_URI` environment variable in my k8s deployment, as:

```
env:
        - name: MLFLOW_TRACKING_URI
          value: $YOUR_URI
```",worked order running correctly add environment variable deployment name value,issue,negative,neutral,neutral,neutral,neutral,neutral
1725660720,"> This sounds like a good idea. Please feel free to ping us with any questions while working on the PR! One quick question about this before you get started: If a model is registered with a particular name in sagemaker (i.e., ""my_transform_job_1"") and you have the registered model name in MLflow for a completely different job as that, are you planning on validating the consistency of the model name reference to what is currently in Sagemaker? Can we generate a unique identifier id that is appended to the name (or generated) that will guarantee that the end user's intentions are respected? Would it make sense to use a reserved tag for this (from your other FR) that can first be fetched from sagemaker to see if the model_uri that originated the transform request already exists in sagemaker?
> 
> Just some things to think about with respect to ensuring that we're not breaking any intended functionality. A component to consider with this as well is handling legacy models that have been pushed that don't support that reserved tagging (or any other component other than name, which might not be the best disambiguation methodology) such that reuse is only possible if using the added mechanism for correctness guarantee.

Yep, I think appending a UID to a model name when created is always a good idea. Looks like that is happening for most sagemaker infrastructure already, including the model created while deploying a transform job. https://github.com/mlflow/mlflow/blob/c93497f235933005c7ed39956b469d936652f9eb/mlflow/sagemaker/__init__.py#L1337-L1346 ",like good idea please feel free ping u working one quick question get model registered particular name registered model name completely different job consistency model name reference currently generate unique identifier id name guarantee end user would make sense use reserved tag first fetched see transform request already think respect breaking intended functionality component consider well handling legacy support reserved component name might best methodology reuse possible added mechanism correctness guarantee yep think model name always good idea like happening infrastructure already model transform job,issue,positive,positive,positive,positive,positive,positive
1725624024,"> Had the same error. Was able to fix this by calling `mlflow.set_tracking_uri(tracking_uri)` before any call to mlflow API on client side (error caused by mlflow [call](https://github.com/mlflow/mlflow/blob/master/mlflow/store/artifact/mlflow_artifacts_repo.py#L46) to `get_tracking_uri()` and getting default `tracking_uri`, which has `file` schema):
> 
> ```python
> tracking_uri = os.environ[""MLFLOW_TRACKING_URL""]
> mlflow.set_tracking_uri(tracking_uri)
> logger = MLFlowLogger(
>     run_name=run_name,
>     experiment_name=experiment_name, 
>     tracking_uri=tracking_uri
> )  
> ```

Hi, sorry but i don't understand how this fixes the problem with the mlflow gc --backend-store-uri sqlite:///C:/mlflow/mlflow.db. In my case I have a backend store in a RDS and an artifact store in a s3 bucket and I can't perform the mlflow gc",error able fix calling call client side error call getting default file schema python logger hi sorry understand problem case store artifact store bucket ca perform,issue,negative,neutral,neutral,neutral,neutral,neutral
1725616235,"@dhrp I have pushed all the changes I made for internal use (at my company) [here](https://github.com/johncf/mlflow/tree/mlflow-helm-charts/charts/mlflow). The changes I made were on top of what's in #8056, and a diff can be viewed [here](https://github.com/johncf/mlflow/compare/ade08f0...mlflow-helm-charts). The [`README`](https://github.com/johncf/mlflow/blob/60ba18a3011da3018a313b463c09ad7f29aab9d4/charts/mlflow/README.md#supplying-credentials-and-access) has some guidelines on how to pass credentials with this new setup.

Feel free to take it from there. I have talked with my manager, and this contribution can be considered to be of the original MLflow license, Apache version 2. To pull these changes to your local clone of your mlflow-fork, I'd recommend:

```
cd /path/to/mlflow
git remote add chart-fork https://github.com/johncf/mlflow.git
git fetch --all
git switch -c mlflow-helm-charts chart-fork/mlflow-helm-charts
```

I didn't update the tests since there was no response from the maintainers here yet.",made internal use company made top pas new setup feel free take manager contribution considered original license apache version pull local clone recommend git remote add git fetch git switch update since response yet,issue,positive,positive,positive,positive,positive,positive
1725446240,"This also affects automl tests, and this sounds like a bug according to the comment in https://github.com/chenmoneygithub/mlflow/blob/8f46545582126cd3e33ab07e8aa39e191970b301/tests/tracking/fluent/test_fluent_autolog.py#L107-L108 @chenmoneygithub Could you take a look?",also like bug according comment could take look,issue,negative,neutral,neutral,neutral,neutral,neutral
1725374423,"So @ichbinjakes if I made a PR to contribute the [NCSA MLFlow Helm Chart](https://github.com/ncsa/charts/tree/main/charts/mlflow) into the MLFlow repo it would be welcome?

I'd be happy to do that and have used the chart now for several deployments with different setups.",made contribute helm chart would welcome happy used chart several different,issue,positive,positive,positive,positive,positive,positive
1725332477,"@johncf I second you. I've looked at using the [community-charts/mlflow](https://github.com/community-charts/helm-charts/tree/main/charts/mlflow) helm chart, but it has not been updated in months and cannot be run without modifications. 

It is, however, still better built than PR #8056, which is not DRY and doesn't seem flexible. If you're up for it I'm willing to collaborate with you to make a good Helm chart, and help maintain it here if necessary.  

Reach out to me on the MLFlow slack (i'm Thatcher), and we can discuss.",second helm chart run without however still better built dry seem flexible willing collaborate make good helm chart help maintain necessary reach slack thatcher discus,issue,positive,positive,positive,positive,positive,positive
1725189331,"that's true , another alternative following @hubertzub-db comment is to use this library  https://github.com/Joeyonng/react-jupyter-notebook , we can solve everything by just using a component that renders jupyter notebooks and allows for some configuration too ",true another alternative following comment use library solve everything component configuration,issue,positive,positive,positive,positive,positive,positive
1725181946,"> Now that i think of it , if we just log the html version , it's true that preview is now easy , but if someone needs the code he logged,  he will not be able to use

This is the reason why I was leaning towards the render-on-ui approach.",think log version true preview easy someone need code logged able use reason leaning towards approach,issue,positive,positive,positive,positive,positive,positive
1725178842,"Now that i think of it , if we just log the html version , it's true that preview is now easy , but if someone needs the code he logged , he will not be able to use , as it will be an html file , so we need to store the source file and just use the html for the preview , I suggest to actually save both the ipynb file and an html version with it , so that we can download the code when we need . We can even make changes such that the html file corresponding to the jupyter file becomes hidden in the ui and is used automatically for previewing the notebook , what do you think ? @harupy ",think log version true preview easy someone need code logged able use file need store source file use preview suggest actually save file version code need even make file corresponding file becomes hidden used automatically notebook think,issue,positive,positive,positive,positive,positive,positive
1725143430,"Yes i think it is a good idea , shall i give it a try and fire a PR ? ",yes think good idea shall give try fire,issue,negative,positive,positive,positive,positive,positive
1725113488,@AdnenKhiari What do you think about `mlflow.log_notebook`? It takes a notebook path and logs the notebook as an HTML file.,think notebook path notebook file,issue,negative,neutral,neutral,neutral,neutral,neutral
1725069894,"A simpler approach could be to automatically save a HTML file version each time a jupyter notebook is logged to the artifacts , what are your thoughts ? instead of converting it each time it is in preview",simpler approach could automatically save file version time notebook logged instead converting time preview,issue,negative,neutral,neutral,neutral,neutral,neutral
1725050509,Yes i'm also thinking about converting it to html and just embed the html into a node instead of using Iframes and make sure to sanitize it as well . I Think nbconvert is the right tool for this ,yes also thinking converting embed node instead make sure sanitize well think right tool,issue,positive,positive,positive,positive,positive,positive
1725004908,Anybody know how to pass cognito idp auth to MLFlow client,anybody know pas client,issue,negative,neutral,neutral,neutral,neutral,neutral
1724804157,"@harupy i have added http artifact repo, please feel free to review :)",added artifact please feel free review,issue,positive,positive,positive,positive,positive,positive
1724788355,"or we can make the backend render notebooks:

<img width=""1253"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/17039389/8dc9ef91-143d-43bb-b40a-9d577cf76d5c"">

For OSS, this is easy because the backend is implemented in Python. We can use `nbconvert` for ipynb -> HTML conversion. For Databricks, it's not.

---

The code looks like this:

```diff
diff --git a/mlflow/server/__init__.py b/mlflow/server/__init__.py
index ed3d92a15..97e898cfb 100644
--- a/mlflow/server/__init__.py
+++ b/mlflow/server/__init__.py
@@ -118,6 +118,15 @@ def serve_static_file(path):
         return send_from_directory(app.static_folder, path, max_age=2419200)
 
 
+@app.route(_add_static_prefix(""/ajax-api/2.0/nbconvert/<path:path>""))
+def convert_notebook(path):
+    import nbconvert
+    from nbconvert.exporters import HTMLExporter
+
+    html = nbconvert.exporters.export(HTMLExporter, path)[0]
+    return html
+
+
 # Serve the index.html for the React App for all other routes.
 @app.route(_add_static_prefix(""/""))
 def serve():
diff --git a/mlflow/server/js/src/experiment-tracking/components/artifact-view-components/ShowArtifactPage.tsx b/mlflow/server/js/src/experiment-tracking/components/artifact-view-components/ShowArtifactPage.tsx
index 7ce10516f..e575a5e8d 100644
--- a/mlflow/server/js/src/experiment-tracking/components/artifact-view-components/ShowArtifactPage.tsx
+++ b/mlflow/server/js/src/experiment-tracking/components/artifact-view-components/ShowArtifactPage.tsx
@@ -23,6 +23,7 @@ import { LazyShowArtifactMapView } from './LazyShowArtifactMapView';
 import ShowArtifactHtmlView from './ShowArtifactHtmlView';
 import { LazyShowArtifactPdfView } from './LazyShowArtifactPdfView';
 import { LazyShowArtifactTableView } from './LazyShowArtifactTableView';
+import ShowArtifactNotebookView from './ShowArtifactNotebookView';
 import ShowArtifactLoggedModelView from './ShowArtifactLoggedModelView';
 // @ts-expect-error TS(2307): Cannot find module '../../../common/static/preview... Remove this comment to see the full error message
 import previewIcon from '../../../common/static/preview-icon.png';
@@ -84,6 +85,8 @@ class ShowArtifactPage extends Component<ShowArtifactPageProps> {
           return <ShowArtifactImageView runUuid={this.props.runUuid} path={this.props.path} />;
         } else if (DATA_EXTENSIONS.has(normalizedExtension.toLowerCase())) {
           return <LazyShowArtifactTableView runUuid={this.props.runUuid} path={this.props.path} />;
+        } else if (['ipynb'].includes(normalizedExtension.toLowerCase())) {
+          return <ShowArtifactNotebookView runUuid={this.props.runUuid} path={this.props.path} />;
         } else if (TEXT_EXTENSIONS.has(normalizedExtension.toLowerCase())) {
           return (
             <ShowArtifactTextView
```

```js
/**
 * NOTE: this code file was automatically migrated to TypeScript using ts-migrate and
 * may contain multiple `any` type annotations and `@ts-expect-error` directives.
 * If possible, please improve types while making changes to this file. If the type
 * annotations are already looking good, please remove this comment.
 */

import React, { useEffect, useState } from 'react';
import { getArtifactContent, getArtifactLocationUrl } from '../../../common/utils/ArtifactUtils';
import { LegacyTable } from '@databricks/design-system';
import { FormattedMessage } from 'react-intl';
// @ts-expect-error TS(7016): Could not find a declaration file for module 'papa... Remove this comment to see the full error message
import Papa from 'papaparse';

type OwnProps = {
  runUuid: string;
  path: string;
  getArtifact?: (...args: any[]) => any;
};

// @ts-expect-error TS(2456): Type alias 'Props' circularly references itself.
type Props = OwnProps & typeof ShowArtifactNotebookView.defaultProps;

// @ts-expect-error TS(7022): 'ShowArtifactNotebookView' implicitly has type 'any' ... Remove this comment to see the full error message
const ShowArtifactNotebookView = ({ runUuid, path, getArtifact }: Props) => {
  return <iframe src={`/ajax-api/2.0/nbconvert/${path}`} title='Notebook Viewer' height='100%' />;
};

ShowArtifactNotebookView.defaultProps = {
  getArtifact: getArtifactContent,
};

export default ShowArtifactNotebookView;

```",make render image easy python use conversion code like git index path return path path path path import import path return serve react serve git index import import import import import find module remove comment see full error message import class component return else return else return else return note code file automatically typescript may contain multiple type possible please improve making file type already looking good please remove comment import react import import import could find declaration file module remove comment see full error message import papa type string path string type alias circularly type prop implicitly type remove comment see full error message path prop return path viewer export default,issue,positive,positive,positive,positive,positive,positive
1724768614,"Hey @AdnenKhiari, thanks for filing this!
So there's only one library I've managed to find at the moment: https://www.npmjs.com/package/notebookjs
It seems to be quite old, but is still occasionally contributed to so it might be worth checking it out. Also, like @sunishsheth2009 mentioned, let's confirm that the library's performance is satisfying.
Additional thoughts on this:
- I believe that for safety reasons, the initial implementation should have JS execution disabled until we figure out some sandboxing mechanism
- The wrapper component responsible for rendering this should be lazy loaded `import (() => '...')` so the imported library will end up in separate chunk asset

Happy to answer any other questions if necessary! Also @AdnenKhiari please let us know if you know about any other 3rd party libraries capable of rendering Jupyter files",hey thanks filing one library find moment quite old still occasionally might worth also like let confirm library performance satisfying additional believe safety initial implementation execution disabled figure mechanism wrapper component responsible rendering lazy loaded import library end separate chunk asset happy answer necessary also please let u know know party capable rendering,issue,positive,positive,positive,positive,positive,positive
1724684268,"Hey @BenWilson2 , I'm chatting with my SA and an engineer on this. I'll post a resolution here and close the issue if it turns out there's a solution on the user-side (e.g. a way to properly configure MLFlow inside the Spark worker).",hey chatting sa engineer post resolution close issue turn solution way properly configure inside spark worker,issue,negative,neutral,neutral,neutral,neutral,neutral
1724644250,"### MLProject
```yaml
# Project name
name: image-classification

docker_env:
  image: custom_base_image:v1

entry_points:
  main:
    parameters:
      batch_size: {type: int, default: 64}
      max_epochs: {type: int, default: 16}

    command: ""python3 pytorch_train.py \
      --model {algorithm} \
      --batch_size {batch_size} \
      --max_epochs {max_epochs} 
```
### Code to reproduce issue
```python
run = mlflow.projects.run(
            uri=job_path,
            experiment_name=experiment_name,
            run_name=run_name,
            parameters=params,
            synchronous=False,
            backend_config={
                ""build_image"": True,
            },
            build_image=True,
        )
```
After passing the key ""build_image"" to `True` with above mentioned method. The problem should appears.
Are there any difference between `mlflow:v1.30.1` and `mlflow:latest` on the `mlflow.projects.run` function?",project name name image main type default type default command python model algorithm code reproduce issue python run true passing key true method problem difference latest function,issue,negative,positive,positive,positive,positive,positive
1724578913,"Hi @nelsoncardenas this isn't a bug. MLflow uses the legacy binary serialization format, not the .json or .ubj formats that were developed in more recent versions of XGBoost. As is mentioned in their documentation, when saving in binary format, the additional 2.x params that are exposed through the sklearn wrapper's `.get_params()` method are not populated. 
See: https://xgboost.readthedocs.io/en/stable/tutorials/saving_model.html for more details. 

This new functionality may eventually make its way into MLflow, but we currently don't have it prioritized (it will be a somewhat involved implementation to ensure that all of the various wrappers / utilizations of XGBoost models within MLflow are compatible with the change and that a backwards compatible implementation can be done so that functionality is not broken for older versions of XGBoost in serving environments. ",hi bug legacy binary serialization format recent documentation saving binary format additional exposed wrapper method see new functionality may eventually make way currently somewhat involved implementation ensure various within compatible change backwards compatible implementation done functionality broken older serving,issue,negative,negative,neutral,neutral,negative,negative
1724535143,"Yes this surely seems like a good idea. :) 
We need to find a library that renders this correctly without impacting the performance of rendering it. 

cc @hubertzub-db to get some thoughts as well. ",yes surely like good idea need find library correctly without performance rendering get well,issue,positive,positive,positive,positive,positive,positive
1724480025,"I'm looking through the code and can't seem to see where the `build_image` arg wouldn't be passed correctly to the `build_docker` function for execution in local context. Could you try to set the `backend_config` key ""build_image"" to `True` explicitly to see if that overrides the behavior in the current master branch? ",looking code ca seem see would correctly function execution local context could try set key true explicitly see behavior current master branch,issue,negative,positive,neutral,neutral,positive,positive
1724343858,"@dbczumar @dbrami 
I am sorry for being late, some circumstances and this task were rolling out of my schedule.
I pre-started the work, investigated what would be required, started some development. 
The [contribution](https://github.com/mlflow/mlflow/blob/master/CONTRIBUTING.md) process is not as fully clear, should we have some roadmap / design first?",sorry late task rolling schedule work would development contribution process fully clear design first,issue,negative,negative,negative,negative,negative,negative
1724325829,Hi @nathan-az could you file a support ticket in Databricks to ensure that you get the appropriate team that can help to diagnose and resolve this issue for you?,hi could file support ticket ensure get appropriate team help diagnose resolve issue,issue,positive,positive,positive,positive,positive,positive
1724313711,"@sunishsheth2009 @harupy what are your thoughts on this? 
Would these render correctly and what are any issues with attempting to get the artifact viewer pane to display such a file?",would render correctly get artifact viewer pane display file,issue,negative,neutral,neutral,neutral,neutral,neutral
1724311491,Hi @Abhishek-TyRnT thanks for the PR and fix! Just a quick fix on the PR's commit history and we'll be good to go!,hi thanks fix quick fix commit history good go,issue,positive,positive,positive,positive,positive,positive
1724310391,Hi @Abhishek-TyRnT could you do a clean rebase on master to remove the unrelated commit history from this PR? Thanks!,hi could clean rebase master remove unrelated commit history thanks,issue,positive,positive,positive,positive,positive,positive
1724106759,"> Hi. Are there any plans on merging this feature? Don't mean to clutter the comments but it seems abandoned.

@kureta I think at this point I'm not confident enough in the design for this component to look nice inside of MLflow. If anyone is able to offer a better design for this **and** a spectrogram, I will implement it and try again. I know there should be better support for audio artifacts but I think that's what's preventing this from getting to the finish line. ",hi feature mean clutter abandoned think point confident enough design component look nice inside anyone able offer better design spectrogram implement try know better support audio think getting finish line,issue,positive,positive,positive,positive,positive,positive
1723138548,"Thank you, I will test it as soon as possible and let you know. ",thank test soon possible let know,issue,negative,neutral,neutral,neutral,neutral,neutral
1723030872,Hi. Are there any plans on merging this feature? Don't mean to clutter the comments but it seems abandoned.,hi feature mean clutter abandoned,issue,negative,negative,negative,negative,negative,negative
1722840844,"I get the same error after pulling latest official docker `docker pull ghcr.io/mlflow/mlflow:v2.7.0` and run it.
```
mlflow-mlflow-1  | 2023/09/18 06:47:00 ERROR mlflow.cli: Error initializing backend store
mlflow-mlflow-1  | 2023/09/18 06:47:00 ERROR mlflow.cli: No module named 'pymysql'
mlflow-mlflow-1  | Traceback (most recent call last):
mlflow-mlflow-1  |   File ""/usr/local/lib/python3.10/site-packages/mlflow/cli.py"", line 426, in server
mlflow-mlflow-1  |     initialize_backend_stores(backend_store_uri, registry_store_uri, default_artifact_root)
mlflow-mlflow-1  |   File ""/usr/local/lib/python3.10/site-packages/mlflow/server/handlers.py"", line 289, in initialize_backend_stores
mlflow-mlflow-1  |     _get_tracking_store(backend_store_uri, default_artifact_root)
mlflow-mlflow-1  |   File ""/usr/local/lib/python3.10/site-packages/mlflow/server/handlers.py"", line 268, in _get_tracking_store
mlflow-mlflow-1  |     _tracking_store = _tracking_store_registry.get_store(store_uri, artifact_root)
mlflow-mlflow-1  |   File ""/usr/local/lib/python3.10/site-packages/mlflow/tracking/_tracking_service/registry.py"", line 39, in get_store
mlflow-mlflow-1  |     return self._get_store_with_resolved_uri(resolved_store_uri, artifact_uri)
mlflow-mlflow-1  |   File ""/usr/local/lib/python3.10/site-packages/mlflow/tracking/_tracking_service/registry.py"", line 49, in _get_store_with_resolved_uri
mlflow-mlflow-1  |     return builder(store_uri=resolved_store_uri, artifact_uri=artifact_uri)
mlflow-mlflow-1  |   File ""/usr/local/lib/python3.10/site-packages/mlflow/server/handlers.py"", line 129, in _get_sqlalchemy_store
mlflow-mlflow-1  |     return SqlAlchemyStore(store_uri, artifact_uri)
mlflow-mlflow-1  |   File ""/usr/local/lib/python3.10/site-packages/mlflow/store/tracking/sqlalchemy_store.py"", line 150, in __init__
mlflow-mlflow-1  |     ] = mlflow.store.db.utils.create_sqlalchemy_engine_with_retry(db_uri)
mlflow-mlflow-1  |   File ""/usr/local/lib/python3.10/site-packages/mlflow/store/db/utils.py"", line 228, in create_sqlalchemy_engine_with_retry
mlflow-mlflow-1  |     engine = create_sqlalchemy_engine(db_uri)
mlflow-mlflow-1  |   File ""/usr/local/lib/python3.10/site-packages/mlflow/store/db/utils.py"", line 284, in create_sqlalchemy_engine
mlflow-mlflow-1  |     return sqlalchemy.create_engine(db_uri, pool_pre_ping=True, **pool_kwargs)
mlflow-mlflow-1  |   File ""<string>"", line 2, in create_engine
mlflow-mlflow-1  |   File ""/usr/local/lib/python3.10/site-packages/sqlalchemy/util/deprecations.py"", line 281, in warned
mlflow-mlflow-1  |     return fn(*args, **kwargs)  # type: ignore[no-any-return]
mlflow-mlflow-1  |   File ""/usr/local/lib/python3.10/site-packages/sqlalchemy/engine/create.py"", line 601, in create_engine
mlflow-mlflow-1  |     dbapi = dbapi_meth(**dbapi_args)
mlflow-mlflow-1  |   File ""/usr/local/lib/python3.10/site-packages/sqlalchemy/dialects/mysql/pymysql.py"", line 75, in import_dbapi
mlflow-mlflow-1  |     return __import__(""pymysql"")
mlflow-mlflow-1  | ModuleNotFoundError: No module named 'pymysql'

```",get error latest official docker docker pull run error error store error module recent call last file line server file line file line file line return file line return builder file line return file line file line engine file line return file string line file line return type ignore file line file line return module,issue,negative,positive,positive,positive,positive,positive
1722590883,"If anyone's interested in creating their own docker image with MySQL and Postgres client support, here's how its Dockerfile looks like:

```
FROM ghcr.io/mlflow/mlflow:v2.7.0

RUN apt-get -y update && \
    apt-get -y install python3-dev default-libmysqlclient-dev build-essential pkg-config && \
    pip install --upgrade pip && \
    pip install mysqlclient && \
    pip install psycopg2-binary

CMD [""bash""]
```

But I still strongly believe this should be part of the official image.",anyone interested docker image client support like run update install pip install upgrade pip pip install pip install bash still strongly believe part official image,issue,positive,positive,positive,positive,positive,positive
1722535341,"The same goes for MySQL:

```
2023/09/17 17:54:47 ERROR mlflow.cli: Error initializing backend store
2023/09/17 17:54:47 ERROR mlflow.cli: No module named 'MySQLdb'
Traceback (most recent call last):
  File ""/usr/local/lib/python3.10/site-packages/mlflow/cli.py"", line 426, in server
    initialize_backend_stores(backend_store_uri, registry_store_uri, default_artifact_root)
  File ""/usr/local/lib/python3.10/site-packages/mlflow/server/handlers.py"", line 289, in initialize_backend_stores
    _get_tracking_store(backend_store_uri, default_artifact_root)
  File ""/usr/local/lib/python3.10/site-packages/mlflow/server/handlers.py"", line 268, in _get_tracking_store
    _tracking_store = _tracking_store_registry.get_store(store_uri, artifact_root)
  File ""/usr/local/lib/python3.10/site-packages/mlflow/tracking/_tracking_service/registry.py"", line 39, in get_store
    return self._get_store_with_resolved_uri(resolved_store_uri, artifact_uri)
  File ""/usr/local/lib/python3.10/site-packages/mlflow/tracking/_tracking_service/registry.py"", line 49, in _get_store_with_resolved_uri
    return builder(store_uri=resolved_store_uri, artifact_uri=artifact_uri)
  File ""/usr/local/lib/python3.10/site-packages/mlflow/server/handlers.py"", line 129, in _get_sqlalchemy_store
    return SqlAlchemyStore(store_uri, artifact_uri)
  File ""/usr/local/lib/python3.10/site-packages/mlflow/store/tracking/sqlalchemy_store.py"", line 150, in __init__
    ] = mlflow.store.db.utils.create_sqlalchemy_engine_with_retry(db_uri)
  File ""/usr/local/lib/python3.10/site-packages/mlflow/store/db/utils.py"", line 228, in create_sqlalchemy_engine_with_retry
    engine = create_sqlalchemy_engine(db_uri)
  File ""/usr/local/lib/python3.10/site-packages/mlflow/store/db/utils.py"", line 284, in create_sqlalchemy_engine
    return sqlalchemy.create_engine(db_uri, pool_pre_ping=True, **pool_kwargs)
  File ""<string>"", line 2, in create_engine
  File ""/usr/local/lib/python3.10/site-packages/sqlalchemy/util/deprecations.py"", line 281, in warned
    return fn(*args, **kwargs)  # type: ignore[no-any-return]
  File ""/usr/local/lib/python3.10/site-packages/sqlalchemy/engine/create.py"", line 601, in create_engine
    dbapi = dbapi_meth(**dbapi_args)
  File ""/usr/local/lib/python3.10/site-packages/sqlalchemy/dialects/mysql/mysqldb.py"", line 152, in import_dbapi
    return __import__(""MySQLdb"")
ModuleNotFoundError: No module named 'MySQLdb'

```

Forgive my rudeness, but you can make the image even slimmer by removing the whole MLFlow from the package. These are features that you are removing from the Docker image. Please include them both in the image.

The solution provided by @shantanu-bbai does not work for me since I'm running this Docker image on a TrueNAS Scale (Kubernetes) and I could not find a way to introduce those extra commands to the app.
",go error error store error module recent call last file line server file line file line file line return file line return builder file line return file line file line engine file line return file string line file line return type ignore file line file line return module forgive rudeness make image even removing whole package removing docker image please include image solution provided work since running docker image scale could find way introduce extra,issue,negative,positive,neutral,neutral,positive,positive
1722532812,"
Hi @BenWilson2, could you take a look on this PR when you have a chance? We are highly depend on this PR :) We have also implemented the Auth plugin in the [OCI Mlflow](https://github.com/oracle/oci-mlflow/pull/20) repo. It would be great if we could move forward with this PR. Please let us know if any additional steps are required. Thanks!",hi could take look chance highly depend also would great could move forward please let u know additional thanks,issue,positive,positive,positive,positive,positive,positive
1721972127,"Hi @dbrami , we'd be thrilled to review and commit a contribution for this feature. Please let me know if you're interested in working on it!",hi review commit contribution feature please let know interested working,issue,positive,positive,positive,positive,positive,positive
1721771620,"Hi all,
Any plans to pick this up again? Or is all attention going strictly to LLM support?",hi pick attention going strictly support,issue,negative,neutral,neutral,neutral,neutral,neutral
1721574195,@Earthwings The workaround that worked for us was by increasing the resource limits (cpu/memory). From version 2.2.0 onwards it works.,worked u increasing resource version onwards work,issue,negative,neutral,neutral,neutral,neutral,neutral
1721141965,"Hello @progovoy 
Thanks for reaching out! Sadly improvements to the experiment list are not prioritized at the moment - however, it would be wonderful if you could contribute here. We can provide support where necessary. 

To recap the necessary steps to improve the performance here, here's the proposal on how to fix it by implementing simple pagination based on the @ridhimag11's guidelines above:
- make the search API call experiment limit modifiable e.g. by function param ([here](https://github.com/mlflow/mlflow/blob/master/mlflow/server/js/src/experiment-tracking/actions.ts#L28))
- fetch fewer experiments on the initial call (e.g. 100)
- after retrieving the experiment list, check if there's `next_page_token` field present in the response and if true, show ""Load more"" button at the end of the list
  - (clicking ""Load more"" should perform a call similar to the initial one, but with `next_page_token` attached)
- wire up filter input box to the request query, i.e. implement a mechanism that will add `filter=name ILIKE ""<filter-value>%""` query parameter to the search experiments GET API call (according to [those](https://mlflow.org/docs/latest/rest-api.html#mlflowsearchexperiments) docs)
- make sure that the page token gets reset after changing the filter query

Does this make sense to you @progovoy ?",hello thanks reaching sadly experiment list moment however would wonderful could contribute provide support necessary recap necessary improve performance proposal fix simple pagination based make search call experiment limit modifiable function param fetch initial call experiment list check field present response true show load button end list load perform call similar initial one attached wire filter input box request query implement mechanism add query parameter search get call according make sure page token reset filter query make sense,issue,positive,positive,positive,positive,positive,positive
1720461830,"> I was having the same problem as @wwwwf with the remote permissions database, but I think I found a solution.
> 
> To be fairly honest, I did a couple of things and I'm not sure if everything is required, it's just what I did and it's currently working.
> 
> I looked at the code and apparently there is an argument called authorization_function, so I added that to basic_auth.ini.
> 
> This is my setup:
> 
> basic_auth.ini:
> 
> ```
> [mlflow]
> default_permission = READ
> database_uri = <postgresql-uri>
> admin_username = admin
> admin_password = password
> authorization_function = mlflow.server.auth:authenticate_request_basic_auth
> ```
> 
> Dockerfile:
> 
> ```
> FROM python:3.9-buster
> 
> # Set the working directory for the container
> WORKDIR /
> 
> # Copy files
> COPY basic_auth.ini basic_auth.ini
> COPY requirements.txt requirements.txt 
> COPY server.sh server.sh
> 
> # Install requirements
> RUN pip install --upgrade pip \
>     && pip install -r requirements.txt
> 
> EXPOSE 8080
> 
> RUN chmod +x server.sh
> 
> ENTRYPOINT [""./server.sh""]
> ```
> 
> I'm using a bash script to run the server.
> 
> server.sh:
> 
> ```
> #!/bin/bash
> 
> export MLFLOW_AUTH_CONFIG_PATH=basic_auth.ini
> 
> mlflow server \
>   --host <my_host> \
>   --port <my_port> \
>   --backend-store-uri <postgresql-uri> \
>   --artifacts-destination <bucket-uri> \
>   --app-name basic-auth
> ```
> 
> And there is another step that I did, not really sure if this makes sense or not, but I was trying a bunch of stuff and then it started working, so it might have to be necessary. With the setup above I was not getting any errors running the container, but the UI wasn't opening. I was using a postgresql instance on Google Cloud Platform with an empty database that I was trying to reference in basic_auth.ini, so basically, I updated this empty database with the content of the basic_auth.db database that MLFlow creates when you run authentication locally, and then.... it worked?
> 
> I do agree with @kbumsik, it would be easier to just pass the database URI to --app-name as we do with --backend-store-uri for example.

I debugged the code and found that the problem was in the step of creating the table, so I created it manually in mysql according to the table created by sqlite, and then started my mlflow service smoothly.",problem remote think found solution fairly honest couple sure everything currently working code apparently argument added setup read password python set working directory container copy copy copy copy install run pip install upgrade pip pip install expose run bash script run server export server host port another step really sure sense trying bunch stuff working might necessary setup getting running container opening instance cloud platform empty trying reference basically empty content run authentication locally worked agree would easier pas example code found problem step table manually according table service smoothly,issue,positive,positive,positive,positive,positive,positive
1720354748,"Since you're not directly patching the function within mlflow, but rather patching code from within your repository that contains this, this PR may have affected your workflow: https://github.com/mlflow/mlflow/commit/8949d84b0ef87287c57def8272cf7d9870945a99 
You may need to directly patch the method due to the LazyLoader() implementation. ",since directly function within rather code within repository may affected may need directly patch method due implementation,issue,negative,positive,neutral,neutral,positive,positive
1720347191,"It sounds like the path constructor that is generating that path should be converted to a pathlib.Path() operation. 
could you give it a test locally in your environment and let us know if that works? (It's likely an os.path.join() operation right now). 
If so, we'll work with you on getting a bug fix PR merged :) ",like path constructor generating path converted operation could give test locally environment let u know work likely operation right work getting bug fix,issue,negative,positive,neutral,neutral,positive,positive
1720345889,"This sounds like a good idea. Please feel free to ping us with any questions while working on the PR! 
One quick question about this before you get started: 
If a model is registered with a particular name in sagemaker (i.e., ""my_transform_job_1"") and you have the registered model name in MLflow for a completely different job as that, are you planning on validating the consistency of the model name reference to what is currently in Sagemaker? Can we generate a unique identifier id that is appended to the name (or generated) that will guarantee that the end user's intentions are respected?
Would it make sense to use a reserved tag for this (from your other FR) that can first be fetched from sagemaker to see if the model_uri that originated the transform request already exists in sagemaker? 

Just some things to think about with respect to ensuring that we're not breaking any intended functionality. A component to consider with this as well is handling legacy models that have been pushed that don't support that reserved tagging (or any other component other than name, which might not be the best disambiguation methodology) such that reuse is only possible if using the added mechanism for correctness guarantee. ",like good idea please feel free ping u working one quick question get model registered particular name registered model name completely different job consistency model name reference currently generate unique identifier id name guarantee end user would make sense use reserved tag first fetched see transform request already think respect breaking intended functionality component consider well handling legacy support reserved component name might best methodology reuse possible added mechanism correctness guarantee,issue,positive,positive,positive,positive,positive,positive
1720342488,Good idea! We'll look forward to seeing the PR! ,good idea look forward seeing,issue,negative,positive,positive,positive,positive,positive
1720253541,@dbczumar I'll factor out the pieces common to the underlying model.  I think that'd mean a bit of new abstraction (i.e. the 1P and 3P (Bedrock) Anthropic providers calling a common 'AnthropicModelInterface' or some such.,factor common underlying model think mean bit new abstraction bedrock anthropic calling common,issue,negative,negative,negative,negative,negative,negative
1719802942,"> BTW your sample is for model serving, which is not what we aim to show on model's view. 

Shouldn't the user be able to decide what to show on the model's view? ",sample model serving aim show model view user able decide show model view,issue,negative,positive,positive,positive,positive,positive
1719775712,"@harupy no worries! Sounds like a good idea, I'll create a function to do the chunking logic",like good idea create function logic,issue,positive,positive,positive,positive,positive,positive
1719665474,@BenWilson2 looks like the Examples tests failed on this run despite having succeeded on the prior run and my changes in between being constrained to the one pytest file. Are you able to rerun that one specifically or do I need to push an empty commit or something?,like run despite prior run constrained one file able rerun one specifically need push empty commit something,issue,negative,positive,positive,positive,positive,positive
1719446985,"I was having the same problem as @wwwwf with the remote permissions database, but I think I found a solution.

To be fairly honest, I did a couple of things and I'm not sure if everything is required, it's just what I did and it's currently working.

I looked at the code and apparently there is an argument called authorization_function, so I added that to basic_auth.ini.

This is my setup:

basic_auth.ini:
```
[mlflow]
default_permission = READ
database_uri = <postgresql-uri>
admin_username = admin
admin_password = password
authorization_function = mlflow.server.auth:authenticate_request_basic_auth
```

Dockerfile:
```
FROM python:3.9-buster

# Set the working directory for the container
WORKDIR /

# Copy files
COPY basic_auth.ini basic_auth.ini
COPY requirements.txt requirements.txt 
COPY server.sh server.sh

# Install requirements
RUN pip install --upgrade pip \
    && pip install -r requirements.txt

EXPOSE 8080

RUN chmod +x server.sh

ENTRYPOINT [""./server.sh""]
```

I'm using a bash script to run the server.

server.sh:
```
#!/bin/bash

export MLFLOW_AUTH_CONFIG_PATH=basic_auth.ini

mlflow server \
  --host <my_host> \
  --port <my_port> \
  --backend-store-uri <postgresql-uri> \
  --artifacts-destination <bucket-uri> \
  --app-name basic-auth
```

And there is another step that I did, not really sure if this makes sense or not, but I was trying a bunch of stuff and then it started working, so it might have to be necessary. With the setup above I was not getting any errors running the container, but the UI wasn't opening. I was using a postgresql instance on Google Cloud Platform with an empty database that I was trying to reference in basic_auth.ini, so basically, I updated this empty database with the content of the basic_auth.db database that MLFlow creates when you run authentication locally, and then.... it worked?

I do agree with @kbumsik, it would be easier to just pass the database URI to --app-name as we do with --backend-store-uri for example.",problem remote think found solution fairly honest couple sure everything currently working code apparently argument added setup read password python set working directory container copy copy copy copy install run pip install upgrade pip pip install expose run bash script run server export server host port another step really sure sense trying bunch stuff working might necessary setup getting running container opening instance cloud platform empty trying reference basically empty content run authentication locally worked agree would easier pas example,issue,positive,positive,positive,positive,positive,positive
1719434184,"Since [mlflow uses jinja2](https://github.com/mlflow/mlflow/blob/6de2829a28898001aabcc681750d03c5cd291399/requirements/core-requirements.txt#L18C1-L19C45), I think setting a [jinja2 filter](https://jinja.palletsprojects.com/en/3.0.x/api/#writing-filters) in [`mlflow/utils/file_utils.py:merge_and_render_yaml`](https://github.com/mlflow/mlflow/blob/6de2829a28898001aabcc681750d03c5cd291399/mlflow/utils/file_utils.py#L304) or function, specifically [here](https://github.com/mlflow/mlflow/blob/6de2829a28898001aabcc681750d03c5cd291399/mlflow/utils/file_utils.py#L323C1-L327C6) might do the trick.

Something like the following example:

#### Trying to mimic what happens in [`merge_and_render_yaml` : L323-L327](https://github.com/mlflow/mlflow/blob/6de2829a28898001aabcc681750d03c5cd291399/mlflow/utils/file_utils.py#L323C1-L327C6)
```python
import os
import jinja2

ENCODING=""utf-8""
root = ""./""

j2_env = jinja2.Environment(
    loader=jinja2.FileSystemLoader(root, encoding=ENCODING),
    undefined=jinja2.StrictUndefined,
    line_comment_prefix=""#"",
)
```

***

#### Implementation

##### As a filter

```python
def getenv_filter(value: str, key: str) -> str:
  """"""Jinja2 filter to get environment variable""""""
  return os.getenv(key, value)
j2_env.filters[""getenv_filter""] = getenv_filter
```

##### As a function
```python
def getenv(env_var: str) -> str:
  """"""Jinja2 function to get environment variable""""""
  return os.getenv(env_var)
func_dict = {""getenv"": getenv,}

```

***

#### Usage

##### As a filter

```python
# Usage as a filter
# 1) Setting environment variables
os.environ[""MLFLOW_EXPERIMENT_NAME""] = ""best_experiment_ever""
os.environ[""MLFLOW_TRACKING_URI""] = ""http://localhost:5000""
os.environ[""MLFLOW_ARTIFACT_LOCATION""] = ""wasbs://mlflow@example.blob.core.windows.net/mlartifacts""

# 2) Creating an example HTML template
with open(""template.html"", ""w"") as html_file:
    html_file.write('experiment:'
                    '\n  name: {{ ""default_name"" | getenv_filter(""MLFLOW_EXPERIMENT_NAME"") }}'
                    '\n  tracking_uri: {{ ""default_tracking_uri"" | getenv_filter(""MLFLOW_TRACKING_URI"") }}'
                    '\n  artifact_location: {{ ""default_artifact_location"" | getenv_filter(""MLFLOW_ARTIFACT_LOCATION"") }}')

# 3) Getting the template and rendering it
temp = j2_env.get_template(""template.html"")
print(temp.render())

# 4) Rendering the template with a non existing variable
del os.environ[""MLFLOW_EXPERIMENT_NAME""]
with open(""template.html"", ""w"") as html_file:
    html_file.write('experiment:'
                    '\n  name: {{ ""default_name"" | getenv_filter(""MLFLOW_EXPERIMENT_NAME"") }}'
                    '\n  tracking_uri: {{ ""default_tracking_uri"" | getenv_filter(""MLFLOW_TRACKING_URI"") }}'
                    '\n  artifact_location: {{ ""default_artifact_location"" | getenv_filter(""MLFLOW_ARTIFACT_LOCATION"") }}')

temp = j2_env.get_template(""template.html"")
print(temp.render())
```

Output:

```
experiment:
  name: best_experiment_ever
  tracking_uri: http://localhost:5000/
  artifact_location: wasbs://mlflow@example.blob.core.windows.net/mlartifacts
experiment:
  name: default_name
  tracking_uri: http://localhost:5000/
  artifact_location: wasbs://mlflow@example.blob.core.windows.net/mlartifacts
```

##### As a function

```python
# Usage as a function
# 1) Setting environment variables
os.environ[""MLFLOW_EXPERIMENT_NAME""] = ""best_experiment_ever""
os.environ[""MLFLOW_TRACKING_URI""] = ""http://localhost:5000""
os.environ[""MLFLOW_ARTIFACT_LOCATION""] = ""wasbs://mlflow@example.blob.core.windows.net/mlartifacts""
print(temp.render())

# 2) Creating an example HTML template
with open(""template.html"", ""w"") as html_file:
    html_file.write('experiment:'
                    '\n  name: {{ getenv(""MLFLOW_EXPERIMENT_NAME"") }}'
                    '\n  tracking_uri: {{ getenv(""MLFLOW_TRACKING_URI"") }}'
                    '\n  artifact_location: {{ getenv(""MLFLOW_ARTIFACT_LOCATION"") }}')

# 3) Getting the template and rendering it
temp = j2_env.get_template(""template.html"")
temp.globals.update(func_dict)

# 4) Rendering the template with a non existing variable
with open(""template.html"", ""w"") as html_file:
    html_file.write('experiment:'
                    '\n  name: {{ getenv(""MLFLOW_EXPERIMENT_NAME"") }}'
                    '\n  tracking_uri: {{ getenv(""MLFLOW_TRACKING_URI"") }}'
                    '\n  artifact_location: {{ getenv(""MLFLOW_ARTIFACT_LOCATION"") }}')

temp = j2_env.get_template(""template.html"")
temp.globals.update(func_dict)
del os.environ[""MLFLOW_EXPERIMENT_NAME""]
print(temp.render())
```

Output:

```
experiment:
  name: best_experiment_ever
  tracking_uri: http://localhost:5000/
  artifact_location: wasbs://mlflow@example.blob.core.windows.net/mlartifacts
experiment:
  name: None
  tracking_uri: http://localhost:5000/
  artifact_location: wasbs://mlflow@example.blob.core.windows.net/mlartifacts
```
",since jinja think setting jinja filter function specifically might trick something like following example trying mimic python import o import jinja root root implementation filter python value key jinja filter get environment variable return key value function python jinja function get environment variable return usage filter python usage filter setting environment example template open name getting template rendering temp print rendering template non variable open name temp print output experiment name experiment name function python usage function setting environment print example template open name getting template rendering temp rendering template non variable open name temp print output experiment name experiment name none,issue,positive,neutral,neutral,neutral,neutral,neutral
1719123099,@gabrielfu Thanks for the PR and sorry for the delay. Is it possible to update `http_artifact_repo.py` as well in this PR so that we can test upload?,thanks sorry delay possible update well test,issue,negative,negative,neutral,neutral,negative,negative
1718964538,"This issue is resolved. The actual problem was I was passing ""=""(equal) sign with parameters. After removing it, it ran fine.

mlflow server --host 0.0.0.0 --port 5000 --backend-store-uri mysql+pymysql://aut***:aut***@mysql-headless.auto
motive.svc.cluster.local:3306/aut*** --gunicorn-opts '--log-level debug' --default-artifact-root s3:/
/automotive-artifacts --serve-artifacts

Closing this issue.",issue resolved actual problem passing equal sign removing ran fine server host port issue,issue,negative,positive,positive,positive,positive,positive
1718664735,"> I usually prefer keeping the top-level contents: read for consistency across workflows, but let me know if you'd rather I remove the top-level declaration and add contents: read in the jobs that need it.


Sounds good to me. Let's keep `contents: read`. I'll set `Read repository contents and packages`.",usually prefer keeping content read consistency across let know rather remove declaration add content read need good let keep content read set read repository content,issue,negative,positive,positive,positive,positive,positive
1718503630,"`Read repository contents and packages` means the default token looks like this:

```yml
permissions:
  contents: read
  packages: read
```

This means we can omit the top-level `contents: read` and all jobs that don't require additional permissions will work just fine.

However, if there isn't a top-level permissions block, then jobs that have their own permissions block will only have the declared permissions (ignoring the default). So we'll need to add the `contents: read` to those jobs' permissions blocks (since the jobs usually start with `actions/checkout`).

I usually prefer keeping the top-level `contents: read` for consistency across workflows, but let me know if you'd rather I remove the top-level declaration and add `contents: read` in the jobs that need it.",read repository content default token like content read read omit content read require additional work fine however block block declared default need add content read since usually start usually prefer keeping content read consistency across let know rather remove declaration add content read need,issue,negative,negative,neutral,neutral,negative,negative
1718494231,@pnacht Thanks! This is awesome. Can we set the repo level settng to `Read repository contents and packages permissions` and use `write` when necessary?,thanks awesome set level read repository content use write necessary,issue,positive,positive,positive,positive,positive,positive
1718484925,"Hi @siavashk We support logging input_example when using `mlflow.pyfunc.log_model`. In your example, I feel like they're quite similar, it's just the way you construct your data is different, so I suggest you could log your sample data as input_example. BTW your sample is for model serving, which is not what we aim to show on model's view. BTW for your proposal, are you willing to contribute? I'll keep this ticket open to collect some feedbacks from the community as well :D",hi support logging example feel like quite similar way construct data different suggest could log sample data sample model serving aim show model view proposal willing contribute keep ticket open collect community well,issue,positive,positive,neutral,neutral,positive,positive
1718256698,">  it was on x86_64 Linux, on some Debian-based distro, likely Ubuntu.

Ah, well, disregard then.  I'd happened to see the issue w/ arm64 ^^ and assumed it was related.",likely ah well disregard see issue arm assumed related,issue,negative,neutral,neutral,neutral,neutral,neutral
1718247326,"@akshaya-a Got it, I was misunderstanding your proposal. 

I prefer to have a system metrics monitor attached to each run instead of a mega monitoring thread in the whole lifecycle in order to keep each run separated. A mega thread is more suitable for the case that we want to keep monitoring the cluster's stats (probably like AzureML, since users have their clusters), and have one page showing stats for 24/7. In MLflow experiment view it's a bit different, we only want to show the stats in the run's lifecycle. ",got misunderstanding proposal prefer system metric monitor attached run instead thread whole order keep run thread suitable case want keep cluster probably like since one page showing experiment view bit different want show run,issue,negative,positive,positive,positive,positive,positive
1718169892,"We have very different models that are all logged using `mlflow.pyfunc.log_model`. We use pyfunc because it seems to be the most flexible MLFlow wrapper for models. An example model is the [ModelWrapper](https://github.com/siavashk/nnUNetMLFlowDVC/blob/b6be56fc2a2844b7a4b1e9417d64232d609c33c1/nnunetv2/run/wrapper_model.py) in my personal nnUNet fork. This wrapper takes a numpy array and meta information (height, width, depth, spacing) to perform inference. When we serve the model, this is the code snippet that we use to test it:

```python
import base64
import numpy as np
import requests
import json

if __name__ == '__main__':
    api_endpoint = ""http://127.0.0.1:1234/invocations""
    headers = {""Content-Type"": ""application/json""}

    arr = np.zeros((10, 100, 200), dtype=np.float16) # or some other numpy data source
    serializable_data = arr.tobytes()
    b64_bytes = base64.b64encode(serializable_data).decode('utf-8')

    inference_request = {
        ""dataframe_split"": {
            ""columns"": [""base64_array"", ""depth"", ""width"", ""height"", ""spacing_z"", ""spacing_y"", ""spacing_x""],
            ""data"": [[b64_bytes, 10, 200, 100, 5.003496170043945, 1.6796875, 1.6796875]]
        }
    }

    response = requests.post(api_endpoint, json=inference_request, headers=headers)

    if response.status_code == 200:
        print(""success "", response.text)
    else:
        print(response.status_code, response.reason, response.content)
```

We also have different models that have a very different `ModelWrapper` class, for example their wrapper might take two numpy arrays as input for their inference as opposed to one and perform some preprocessing as well. However, these new models are also logged using `mlflow.pyfunc.log_model`. The code snippet for running the new model will be different. For example it might look like this:

```python
import base64
import numpy as np
import requests
import json


def some_preprocessing_function(arr):
      return arr + 2 # or some other complicated preprocessing logic


def serialize_array(arr):
    serializable_data = arr.tobytes()
    return base64.b64encode(serializable_data).decode('utf-8')


if __name__ == '__main__':
    api_endpoint = ""http://127.0.0.1:1234/invocations""
    headers = {""Content-Type"": ""application/json""}

    image_1 = np.zeros((10, 100, 200), dtype=np.float16) 
    image_2 = np.ones((10, 20, 30), dtype=np.uint8)

    arr_1 = serialize_array(image_1)
    arr_2 = some_preprocessing_function(image_2)
    arr_2 = serialize_array(arr_2)

    inference_request = {
        ""dataframe_split"": {
            ""columns"": [""arr_1"", ""arr_2"", ""depth_1"", ""width_1"", ""height_1"", ""depth_2"", ""width_2"", ""height_2""],
            ""data"": [[arr_1, arr_2, 10, 200, 100, 10, 20, 30]]
        }
    }

    response = requests.post(api_endpoint, json=inference_request, headers=headers)

    if response.status_code == 200:
        print(""success "", response.text)
    else:
        print(response.status_code, response.reason, response.content)
```

Having a template code snippet, where we can just swap a couple of variables, for running a pyfunc model does not satisfy our usecase. I would like a solution where I can customize the code snippet for running a pyfunc model as opposed to having a default option for all pyfunc models. One approach might be to upload the code snippet as an optional argument to `mlflow.pyfunc.log_model`. If the code snippet is not provided, MLFlow UI will display the current default code snippet.",different logged use flexible wrapper example model personal fork wrapper array meta information height width depth spacing perform inference serve model code snippet use test python import base import import import data source depth width height data response print success else print also different different class example wrapper might take two input inference opposed one perform well however new also logged code snippet running new model different example might look like python import base import import import return complicated logic return data response print success else print template code snippet swap couple running model satisfy would like solution code snippet running model opposed default option one approach might code snippet optional argument code snippet provided display current default code snippet,issue,positive,negative,neutral,neutral,negative,negative
1718165487,"As an update, I still cannot repro with this command line below, and the folders run in alphabetical order. So I suppose one of the autologging or root-level test files is the culprit. I'll continue digging as i get time between meetings
 
(mlflowwsl) akannava@CPC-akann-P9TVV:~/mlflow$ pytest -x --ignore=tests/mleap --ignore=tests/paddle --ignore=tests/gateway --ignore=tests/transformers --ignore=tests/autologging --ignore=tests/catboost --ignore=tests/test_cli.py --ignore=tests/data --ignore=tests/test_doctor.py --continue-on-collection-errors tests/

EDIT: found it - test_cli.py",update still command line run alphabetical order suppose one test culprit continue digging get time edit found,issue,negative,neutral,neutral,neutral,neutral,neutral
1718162207,"Hi @BenWilson2 , could you please take a look at the latest change? Thank you very much!  ",hi could please take look latest change thank much,issue,positive,positive,positive,positive,positive,positive
1717949904,"> Same here with mlflow 2.4.0 (client) and mlflow 2.4.1 (server) and a file of 830 MB. Any insights or workarounds?

You can work around it by replacing the call to mlflow.log_artifacts() with a sequence of calls to mlflow.log_artifact() for all files in the local directory recursively, while catching and ignoring the exception for large files. Not exactly pretty but seems to do the job for now. For reference:

```python
def log_artifacts(local_dir: str, artifact_path: str):
    for root, _, files in os.walk(local_dir):
        for file in files:
            upload_path = artifact_path
            if root != local_dir:
                rel_path = os.path.relpath(root, local_dir)
                upload_path = os.path.join(upload_path, rel_path)
            try:
                mlflow.log_artifact(local_path=os.path.join(root, file), artifact_path=upload_path)
            except mlflow.exceptions.MlflowException as ex:
                if os.path.getsize(os.path.join(root, file)) > 750 * pow(1000, 2):
                    # Workaround for https://github.com/mlflow/mlflow/issues/7564: Just ignore it
                    pass
                else:
                    raise ex
```",client server file work around call sequence local directory catching exception large exactly pretty job reference python root file root root try root file except ex root file pow ignore pas else raise ex,issue,negative,positive,positive,positive,positive,positive
1717603934,"Guys, any updates here?

I think a realistic production use must support 1M+ experimets / runs. They may be divided over time into ""hot"" for more recent ones and ""cold"" for the old ones which will tke more time to fetch.  But currently the product suffers from very bad user experience where with only 1K experimets the user experiences very slow response times that can take minutes. 

Do you guys have any roadmap for improving performance? If this is interesting to you, I am willing to contribute to the subject.",think realistic production use must support may divided time hot recent cold old time fetch currently product bad user experience user slow response time take improving performance interesting willing contribute subject,issue,positive,negative,neutral,neutral,negative,negative
1717586424,"hey 👋🏻

I was following that article https://mlflow.org/docs/latest/quickstart_mlops.html. So I faced that issue.
export MLFLOW_TRACKING_URI=http://127.0.0.1:5002 that command resolves the problem. 
",hey following article faced issue export command problem,issue,negative,neutral,neutral,neutral,neutral,neutral
1717424338,"@tahaum Thanks! Can you install mlflow using the following command?

```
%pip install git+https://github.com/mlflow/mlflow.git@refs/pull/9622/merge
```",thanks install following command pip install,issue,negative,positive,neutral,neutral,positive,positive
1717407867,"Can you try:

```
%pip install mlflow==2.6.0
```

and:

```
dbutils.library.restartPython()
```

then:

```
import mlflow

mlflow.__version__
```

?",try pip install import,issue,negative,neutral,neutral,neutral,neutral,neutral
1717402999,"> @tahaum Thanks for the report. Does this error reproduce with MLflow 2.6.0?

@harupy Not sure, any idea of how to easily change what version of MLflow Databricks is using? 

`!pip install mlflow==2.6.0` does not seem to be enough",thanks report error reproduce sure idea easily change version pip install seem enough,issue,positive,positive,positive,positive,positive,positive
1717372380,@tahaum Thanks for the report. Does this error reproduce with MLflow 2.6.0?,thanks report error reproduce,issue,negative,positive,positive,positive,positive,positive
1717294935,Thanks @GeorgePearse We'll keep this issue open for collecting some feedbacks from the community :) ,thanks keep issue open community,issue,negative,positive,neutral,neutral,positive,positive
1717280318,"> Actually this is strange, the entire suite passes for me locally.. Still digging but let me know if you have an idea of direction to investigate

That is weird.. Yes that entire suite passes locally, but if you trigger the whole pytest tests/ then it fails. From my check it looks like the registry_uri here https://github.com/mlflow/mlflow/actions/runs/6153499312/job/16697465273?pr=9575#step:12:3140 is not correct, it should be the same as the tracking_uri. So seems like the environment variable of registry_uri is set by some other processes.",actually strange entire suite locally still digging let know idea direction investigate weird yes entire suite locally trigger whole check like correct like environment variable set,issue,positive,negative,neutral,neutral,negative,negative
1717099662,"and also this 
```
UserWarning: Field ""model_server_url"" has conflict with protected namespace ""model_"".
E           
E           You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.
E             warnings.warn(
E           /path/to/folder/torch2/lib/python3.9/site-packages/pydantic/_internal/_config.py:269: UserWarning: Valid config keys have changed in V2:
E           * 'schema_extra' has been renamed to 'json_schema_extra'
E             warnings.warn(message, UserWarning)
E           In 'train.yaml': Could not find 'model/mnist'
```",also field conflict may able resolve warning setting valid message could find,issue,negative,positive,positive,positive,positive,positive
1717076989,"Thanks @christopherwoodall for responding! @siavashk I think that's the correct place to update, as it applies to all model's view. Could you elaborate more on your use cases? The template shows a simple usage to load the model, but you could customize on your own by passing different parameters to the function.",thanks think correct place update model view could elaborate use template simple usage load model could passing different function,issue,negative,positive,positive,positive,positive,positive
1717034904,"I am also getting the error, ""(1045, ""Access denied for user 'xxx'@'xxxxxxxx' (using password: YES)"")
Any plan on fixing this? like josmaf mentioned in https://github.com/mlflow/mlflow/issues/9155#issuecomment-1684271931 


",also getting error access user password yes plan fixing like,issue,negative,neutral,neutral,neutral,neutral,neutral
1717019103,"I cannot dedicate time to repro'ing this right now, sorry. But FWIW: when I tested it, it was on x86_64 Linux, on some Debian-based distro, likely Ubuntu.

UPD: As a fix, why not just pin all the versions? Then you'll have a known good set of versions that work. This is supposed to be run in an isolated env anyway. So seems like there's no downside.",dedicate time right sorry tested likely fix pin known good set work supposed run isolated anyway like downside,issue,negative,positive,positive,positive,positive,positive
1716986661,"I think one would spawn only one monitor thread for scraping metrics while the other would use one per run? Could have read that wrong

AK
________________________________
From: Chen Qian ***@***.***>
Sent: Tuesday, September 12, 2023 10:31:19 PM
To: mlflow/mlflow ***@***.***>
Cc: Akshaya Annavajhala ***@***.***>; Mention ***@***.***>
Subject: Re: [mlflow/mlflow] Add system metrics logging to MLflow fluent API (PR #9557)


@chenmoneygithub commented on this pull request.

________________________________

In mlflow/tracking/fluent.py<https://github.com/mlflow/mlflow/pull/9557#discussion_r1323988656>:

> @@ -69,6 +70,7 @@
     import plotly

 _active_run_stack = []
+run_id_to_system_metrics_monitor = {}


thanks for the suggestion, I think essentially that's a similar approach? The gist of singleton or global variable is we maintain only one instance during the program's lifecycle, just a different way on expressing it. In the current codebase, we are using global variables (like the above _active_run_stack ) more often than singletons, so I would prefer to use a consistent style.

—
Reply to this email directly, view it on GitHub<https://github.com/mlflow/mlflow/pull/9557#discussion_r1323988656>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AD7ZDS5BJN562V6ZE4GQRKLX2FAKPANCNFSM6AAAAAA4PQT6BQ>.
You are receiving this because you were mentioned.Message ID: ***@***.***>
",think one would spawn one monitor thread scraping metric would use one per run could read wrong ak sent mention subject add system metric logging fluent pull request import thanks suggestion think essentially similar approach gist singleton global variable maintain one instance program different way current global like often would prefer use consistent style reply directly view id,issue,negative,negative,neutral,neutral,negative,negative
1716915636,"btw, i think all of these failing tests are unrelated. we should address them, but i dont think we need to block this PR on them passing.",think failing unrelated address dont think need block passing,issue,negative,neutral,neutral,neutral,neutral,neutral
1716902513,"Actually this is strange, the entire suite passes for me locally.. Still digging but let me know if you have an idea of direction to investigate",actually strange entire suite locally still digging let know idea direction investigate,issue,negative,negative,neutral,neutral,negative,negative
1716887227,@WeichenXu123 Let's wait until spark 3.5 is released (unless this PR is urgent).,let wait spark unless urgent,issue,negative,neutral,neutral,neutral,neutral,neutral
1716876666,"> > @serena-ruan I know i'm useless with git but i think I rebased successfully - are you expecting these failing tests to have been fixed or should I look into them?
> 
> I think it's related, the test doesn't fail on master. Also I found that if you just run that single test it doesn't fail, it only fails when running together with other tests..

thanks, I can take a look tomorrow, but then it sounds like something is assuming the old behavior in the test fixtures ",know useless git think successfully failing fixed look think related test fail master also found run single test fail running together thanks take look tomorrow like something assuming old behavior test,issue,negative,negative,neutral,neutral,negative,negative
1716868586,"@nkaretnikov I believe this happens on Apple Silicon macOS machines. I see an error like 

```
    The conflict is caused by:
    The user requested tensorflow>=2.8.0
    The user requested tensorflow<=2.12.0
    To fix this you could try to:
    1. loosen the range of package versions you've specified
    2. remove package versions to allow pip attempt to solve the dependency conflict
```

Seems like this is an unfortunate error message from pip. It's not a real conflict, but an unsatisfiable constraint.  Tensorflow only publishs arm64 wheels for 2.13, and cannot be installed from source.  You should be able to install the dev requirements on an x86 python (i.e. through Rosetta2,a VM, etc.)  ",believe apple silicon see error like conflict user user fix could try loosen range package remove package allow pip attempt solve dependency conflict like unfortunate error message pip real conflict unsatisfiable constraint arm source able install dev python,issue,negative,positive,neutral,neutral,positive,positive
1716864000,"> @serena-ruan I know i'm useless with git but i think I rebased successfully - are you expecting these failing tests to have been fixed or should I look into them?

I think it's related, the test doesn't fail on master. Also I found that if you just run that single test it doesn't fail, it only fails when running together with other tests..",know useless git think successfully failing fixed look think related test fail master also found run single test fail running together,issue,negative,negative,negative,negative,negative,negative
1716807586,"> Hey @hengwang322, that's because when we log the datasets we need to write the dataset. I don't think it's a bug though, you could disable it by `log_datasets=False` as you said :D

Thanks for the reply. I think it's not a very desirable behaviour. I'm not sure how dataset logging is done under the hood, but maybe it's not necessary to repeat `tf.data.Dataset` for simply logging. In any case, maybe a warning should be added to the documentation to warn against this use case.",hey log need write think bug though could disable said thanks reply think desirable behaviour sure logging done hood maybe necessary repeat simply logging case maybe warning added documentation warn use case,issue,positive,positive,positive,positive,positive,positive
1716803101,"> 



> @Mai0313
> 
> > However, lightning has been upgrade to 2.0.8, which required newer pydantic
> 
> Does lighting require pydantic v2?

For now, it accepts `pydantic >=1.7.4, <2.2.0`
However, 5 months ago, lightning only accept pydantic v1 [ref](https://github.com/Lightning-AI/lightning/commit/04fb30bd97ed4fe7778c1b7a0a041ec100914bfc), suddenly changed to pydantic >=1.7.4, <2.2.0; so I believe it would be required in the future.

I mean downgrade to v1 is ok to me and other developers, but for pip, default version will be the newest below the requirements; once you do `pip install lightning==2.0.8`, you will see what I am saying

",however lightning upgrade lighting require however ago lightning accept ref suddenly believe would future mean downgrade pip default version pip install see saying,issue,negative,negative,negative,negative,negative,negative
1716765575,"> Curious - is using Timer class faster? I think the old code is more readable than using our own Timer.

Good question! I don't think it's faster. It's slightly slower than the exsiting approach :)

",curious timer class faster think old code readable timer good question think faster slightly approach,issue,positive,positive,positive,positive,positive,positive
1716529330,"I guess to change this, I need to modify this text and rebuild the docker image?
But I have many different models and they have different example code snippets.",guess change need modify text rebuild docker image many different different example code,issue,negative,positive,positive,positive,positive,positive
1716506347,"You could modify those values in [this](https://github.com/mlflow/mlflow/blob/ef0836fa2e7f59c2197c02cbd132b3af503d44c5/mlflow/server/js/src/experiment-tracking/components/artifact-view-components/ShowArtifactLoggedModelView.tsx#L124)(`ShowArtifactLoggedModelView.tsx`) file.

![image](https://github.com/mlflow/mlflow/assets/363708/f2e2bc01-5158-4197-a16a-36ef0a5a5c08)

",could modify file image,issue,negative,neutral,neutral,neutral,neutral,neutral
1716142984,@serena-ruan  I know i'm useless with git but i think I rebased successfully - are you expecting these failing tests to have been fixed or should I look into them?,know useless git think successfully failing fixed look,issue,negative,positive,positive,positive,positive,positive
1715581434,"Hey @hengwang322, that's because when we log the datasets we need to write the dataset. I don't think it's a bug though, you could disable it by `log_datasets=False` as you said :D ",hey log need write think bug though could disable said,issue,negative,neutral,neutral,neutral,neutral,neutral
1715547334,"@Mai0313 

> However, lightning has been upgrade to 2.0.8, which required newer pydantic

Does lighting require pydantic v2?",however lightning upgrade lighting require,issue,negative,neutral,neutral,neutral,neutral,neutral
1715501260,"> I still see that there is lots of usage on some deprecated function

Yes, we made that decision to support both v1 and v2. Any better approach to support both versions? We'll drop support for v1 and completely migrate to v2 in the future for sure, but haven't decided when.",still see lot usage function yes made decision support better approach support drop support completely migrate future sure decided,issue,positive,positive,positive,positive,positive,positive
1715371784,"@harupy 
I just saw this, but I still see that there is lots of usage on some deprecated function such as `validator` should be replaced to `field_validator` and `root_validator` should be replaced to `model_validator`

In the meantime, I have fixed all issues I have mentioned on my own branch which is forked from master; and I am glad to have a chance to help you.
I am currently working at Mediatek, so I dont need a job, I only wanna help and also fix my project",saw still see lot usage function fixed branch forked master glad chance help currently working dont need job wan na help also fix project,issue,positive,positive,neutral,neutral,positive,positive
1715350276,"In the meantime, there is a conflict with pydantic which is `model_server_url` naming issue

it will pop out `UserWarning: Field ""model_server_url"" has conflict with protected namespace ""model_"".` during training and using mlflow.
I am happy to help, so it ups to you tho.",conflict naming issue pop field conflict training happy help tho,issue,negative,positive,positive,positive,positive,positive
1715278034,"Hi @costefan Thanks! This sounds great, feel free to raise a PR and I'll review on it!",hi thanks great feel free raise review,issue,positive,positive,positive,positive,positive,positive
1715174638,"> When is spark 3.5 going to be released?

I don't know, @HyukjinKwon do you know the time ? Seemingly it haven't been decided.",spark going know know time seemingly decided,issue,negative,neutral,neutral,neutral,neutral,neutral
1714481733,"@dbczumar @BenWilson2, I finally made some time to update this PR to fix gates - we had talked about this about a month and a half ago. Please take a look when you have time.",finally made time update fix month half ago please take look time,issue,negative,negative,neutral,neutral,negative,negative
1714417318,I also think this would be very useful!,also think would useful,issue,negative,positive,positive,positive,positive,positive
1713937583,"Seems like it's fine to remove the detected `pytest` from the environment validation tests as I think that it is special-cased since it's actually the runner environment and wouldn't have an explicit dependency import. Curious to hear your thoughts on this, Haru.",like fine remove environment validation think since actually runner environment would explicit dependency import curious hear,issue,positive,positive,positive,positive,positive,positive
1713607146,"> @xianqiangHub Thanks, can you shared the full stack trace?
I changed the url to Http today and it worked, but I still got an error when using Https. This is the specific information.
---------------------------------------------------------------------------
SSLEOFError                               Traceback (most recent call last)
File ~/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:670, in HTTPConnectionPool.urlopen(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)
    669 # Make the request on the httplib connection object.
--> 670 httplib_response = self._make_request(
    671     conn,
    672     method,
    673     url,
    674     timeout=timeout_obj,
    675     body=body,
    676     headers=headers,
    677     chunked=chunked,
    678 )
    680 # If we're going to release the connection in ``finally:``, then
    681 # the response doesn't need to know about the connection. Otherwise
    682 # it will also try to release it and we'll have a double-release
    683 # mess.

File ~/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:381, in HTTPConnectionPool._make_request(self, conn, method, url, timeout, chunked, **httplib_request_kw)
    380 try:
--> 381     self._validate_conn(conn)
    382 except (SocketTimeout, BaseSSLError) as e:
    383     # Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.

File ~/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:978, in HTTPSConnectionPool._validate_conn(self, conn)
    977 if not getattr(conn, ""sock"", None):  # AppEngine might not have  `.sock`
--> 978     conn.connect()
    980 if not conn.is_verified:

File ~/anaconda3/lib/python3.11/site-packages/urllib3/connection.py:362, in HTTPSConnection.connect(self)
    360     context.load_default_certs()
--> 362 self.sock = ssl_wrap_socket(
    363     sock=conn,
    364     keyfile=self.key_file,
    365     certfile=self.cert_file,
    366     key_password=self.key_password,
    367     ca_certs=self.ca_certs,
    368     ca_cert_dir=self.ca_cert_dir,
    369     ca_cert_data=self.ca_cert_data,
    370     server_hostname=server_hostname,
    371     ssl_context=context,
    372 )
    374 if self.assert_fingerprint:

File ~/anaconda3/lib/python3.11/site-packages/urllib3/util/ssl_.py:399, in ssl_wrap_socket(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data)
    388     warnings.warn(
    389         ""An HTTPS request has been made, but the SNI (Server Name ""
    390         ""Indication) extension to TLS is not available on this platform. ""
   (...)
    396         SNIMissingWarning,
    397     )
--> 399 return context.wrap_socket(sock)

File ~/anaconda3/lib/python3.11/ssl.py:517, in SSLContext.wrap_socket(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)
    511 def wrap_socket(self, sock, server_side=False,
    512                 do_handshake_on_connect=True,
    513                 suppress_ragged_eofs=True,
    514                 server_hostname=None, session=None):
    515     # SSLSocket class handles server_hostname encoding before it calls
    516     # ctx._wrap_socket()
--> 517     return self.sslsocket_class._create(
    518         sock=sock,
    519         server_side=server_side,
    520         do_handshake_on_connect=do_handshake_on_connect,
    521         suppress_ragged_eofs=suppress_ragged_eofs,
    522         server_hostname=server_hostname,
    523         context=self,
    524         session=session
    525     )

File ~/anaconda3/lib/python3.11/ssl.py:1075, in SSLSocket._create(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)
   1074             raise ValueError(""do_handshake_on_connect should not be specified for non-blocking sockets"")
-> 1075         self.do_handshake()
   1076 except (OSError, ValueError):

File ~/anaconda3/lib/python3.11/ssl.py:1346, in SSLSocket.do_handshake(self, block)
   1345         self.settimeout(None)
-> 1346     self._sslobj.do_handshake()
   1347 finally:

SSLEOFError: EOF occurred in violation of protocol (_ssl.c:1002)

During handling of the above exception, another exception occurred:

MaxRetryError                             Traceback (most recent call last)
File ~/anaconda3/lib/python3.11/site-packages/requests/adapters.py:486, in HTTPAdapter.send(self, request, stream, timeout, verify, cert, proxies)
    485 try:
--> 486     resp = conn.urlopen(
    487         method=request.method,
    488         url=url,
    489         body=request.body,
    490         headers=request.headers,
    491         redirect=False,
    492         assert_same_host=False,
    493         preload_content=False,
    494         decode_content=False,
    495         retries=self.max_retries,
    496         timeout=timeout,
    497         chunked=chunked,
    498     )
    500 except (ProtocolError, OSError) as err:

File ~/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:754, in HTTPConnectionPool.urlopen(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)
    751     log.warning(
    752         ""Retrying (%r) after connection broken by '%r': %s"", retries, err, url
    753     )
--> 754     return self.urlopen(
    755         method,
    756         url,
    757         body,
    758         headers,
    759         retries,
    760         redirect,
    761         assert_same_host,
    762         timeout=timeout,
    763         pool_timeout=pool_timeout,
    764         release_conn=release_conn,
    765         chunked=chunked,
    766         body_pos=body_pos,
    767         **response_kw
    768     )
    770 # Handle redirect?

File ~/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:754, in HTTPConnectionPool.urlopen(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)
    751     log.warning(
    752         ""Retrying (%r) after connection broken by '%r': %s"", retries, err, url
    753     )
--> 754     return self.urlopen(
    755         method,
    756         url,
    757         body,
    758         headers,
    759         retries,
    760         redirect,
    761         assert_same_host,
    762         timeout=timeout,
    763         pool_timeout=pool_timeout,
    764         release_conn=release_conn,
    765         chunked=chunked,
    766         body_pos=body_pos,
    767         **response_kw
    768     )
    770 # Handle redirect?

    [... skipping similar frames: HTTPConnectionPool.urlopen at line 754 (2 times)]

File ~/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:754, in HTTPConnectionPool.urlopen(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)
    751     log.warning(
    752         ""Retrying (%r) after connection broken by '%r': %s"", retries, err, url
    753     )
--> 754     return self.urlopen(
    755         method,
    756         url,
    757         body,
    758         headers,
    759         retries,
    760         redirect,
    761         assert_same_host,
    762         timeout=timeout,
    763         pool_timeout=pool_timeout,
    764         release_conn=release_conn,
    765         chunked=chunked,
    766         body_pos=body_pos,
    767         **response_kw
    768     )
    770 # Handle redirect?

File ~/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:726, in HTTPConnectionPool.urlopen(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)
    724     e = ProtocolError(""Connection aborted."", e)
--> 726 retries = retries.increment(
    727     method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
    728 )
    729 retries.sleep()

File ~/anaconda3/lib/python3.11/site-packages/urllib3/util/retry.py:446, in Retry.increment(self, method, url, response, error, _pool, _stacktrace)
    445 if new_retry.is_exhausted():
--> 446     raise MaxRetryError(_pool, url, error or ResponseError(cause))
    448 log.debug(""Incremented Retry for (url='%s'): %r"", url, new_retry)

MaxRetryError: HTTPSConnectionPool(host='172.18.86.87', port=5000): Max retries exceeded with url: /api/2.0/mlflow/experiments/get-by-name?experiment_name=Logistic_Regression_Demo (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1002)')))

During handling of the above exception, another exception occurred:

SSLError                                  Traceback (most recent call last)
File ~/anaconda3/lib/python3.11/site-packages/mlflow/utils/rest_utils.py:93, in http_request(host_creds, endpoint, method, max_retries, backoff_factor, extra_headers, retry_codes, timeout, **kwargs)
     92 try:
---> 93     return _get_http_response_with_retries(
     94         method,
     95         url,
     96         max_retries,
     97         backoff_factor,
     98         retry_codes,
     99         headers=headers,
    100         verify=host_creds.verify,
    101         timeout=timeout,
    102         **kwargs,
    103     )
    104 except requests.exceptions.Timeout as to:

File ~/anaconda3/lib/python3.11/site-packages/mlflow/utils/request_utils.py:131, in _get_http_response_with_retries(method, url, max_retries, backoff_factor, retry_codes, **kwargs)
    130 session = _get_request_session(max_retries, backoff_factor, retry_codes)
--> 131 return session.request(method, url, **kwargs)

File ~/anaconda3/lib/python3.11/site-packages/requests/sessions.py:589, in Session.request(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)
    588 send_kwargs.update(settings)
--> 589 resp = self.send(prep, **send_kwargs)
    591 return resp

File ~/anaconda3/lib/python3.11/site-packages/requests/sessions.py:703, in Session.send(self, request, **kwargs)
    702 # Send the request
--> 703 r = adapter.send(request, **kwargs)
    705 # Total elapsed time of the request (approximately)

File ~/anaconda3/lib/python3.11/site-packages/requests/adapters.py:517, in HTTPAdapter.send(self, request, stream, timeout, verify, cert, proxies)
    515 if isinstance(e.reason, _SSLError):
    516     # This branch is for urllib3 v1.22 and later.
--> 517     raise SSLError(e, request=request)
    519 raise ConnectionError(e, request=request)

SSLError: HTTPSConnectionPool(host='172.18.86.87', port=5000): Max retries exceeded with url: /api/2.0/mlflow/experiments/get-by-name?experiment_name=Logistic_Regression_Demo (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1002)')))

During handling of the above exception, another exception occurred:

MlflowException                           Traceback (most recent call last)
Cell In[2], line 10
      7 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
      9 # 创建MLflow实验
---> 10 mlflow.set_experiment(""Logistic_Regression_Demo"")

File ~/anaconda3/lib/python3.11/site-packages/mlflow/tracking/fluent.py:129, in set_experiment(experiment_name, experiment_id)
    127 client = MlflowClient()
    128 if experiment_id is None:
--> 129     experiment = client.get_experiment_by_name(experiment_name)
    130     if not experiment:
    131         _logger.info(
    132             ""Experiment with name '%s' does not exist. Creating a new experiment."",
    133             experiment_name,
    134         )

File ~/anaconda3/lib/python3.11/site-packages/mlflow/tracking/client.py:507, in MlflowClient.get_experiment_by_name(self, name)
    476 def get_experiment_by_name(self, name: str) -> Optional[Experiment]:
    477     """"""
    478     Retrieve an experiment by experiment name from the backend store
    479 
   (...)
    505         Lifecycle_stage: active
    506     """"""
--> 507     return self._tracking_client.get_experiment_by_name(name)

File ~/anaconda3/lib/python3.11/site-packages/mlflow/tracking/_tracking_service/client.py:222, in TrackingServiceClient.get_experiment_by_name(self, name)
    217 def get_experiment_by_name(self, name):
    218     """"""
    219     :param name: The experiment name.
    220     :return: :py:class:`mlflow.entities.Experiment`
    221     """"""
--> 222     return self.store.get_experiment_by_name(name)

File ~/anaconda3/lib/python3.11/site-packages/mlflow/store/tracking/rest_store.py:307, in RestStore.get_experiment_by_name(self, experiment_name)
    305 try:
    306     req_body = message_to_json(GetExperimentByName(experiment_name=experiment_name))
--> 307     response_proto = self._call_endpoint(GetExperimentByName, req_body)
    308     return Experiment.from_proto(response_proto.experiment)
    309 except MlflowException as e:

File ~/anaconda3/lib/python3.11/site-packages/mlflow/store/tracking/rest_store.py:59, in RestStore._call_endpoint(self, api, json_body)
     57 endpoint, method = _METHOD_TO_INFO[api]
     58 response_proto = api.Response()
---> 59 return call_endpoint(self.get_host_creds(), endpoint, method, json_body, response_proto)

File ~/anaconda3/lib/python3.11/site-packages/mlflow/utils/rest_utils.py:199, in call_endpoint(host_creds, endpoint, method, json_body, response_proto, extra_headers)
    197 if method == ""GET"":
    198     call_kwargs[""params""] = json_body
--> 199     response = http_request(**call_kwargs)
    200 else:
    201     call_kwargs[""json""] = json_body

File ~/anaconda3/lib/python3.11/site-packages/mlflow/utils/rest_utils.py:113, in http_request(host_creds, endpoint, method, max_retries, backoff_factor, extra_headers, retry_codes, timeout, **kwargs)
    111     raise InvalidUrlException(f""Invalid url: {url}"") from iu
    112 except Exception as e:
--> 113     raise MlflowException(f""API request to {url} failed with exception {e}"")

MlflowException: API request to https://172.18.86.87:5000/api/2.0/mlflow/experiments/get-by-name failed with exception HTTPSConnectionPool(host='172.18.86.87', port=5000): Max retries exceeded with url: /api/2.0/mlflow/experiments/get-by-name?experiment_name=Logistic_Regression_Demo (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1002)')))

",thanks full stack trace today worked still got error specific information recent call last file self method body redirect make request connection object conn method going release connection finally response need know connection otherwise also try release mess file self conn method try conn except socket file self conn conn sock none might file self file sock request made server name indication extension available return sock file self sock session self sock class return file sock context session raise except file self block none finally violation protocol handling exception another exception recent call last file self request stream verify try resp except err file self method body redirect connection broken err return method body redirect handle redirect file self method body redirect connection broken err return method body redirect handle redirect skipping similar line time file self method body redirect connection broken err return method body redirect handle redirect file self method body redirect connection aborted method file self method response error raise error cause retry violation protocol handling exception another exception recent call last file method try return method except file session return method file self method data stream verify resp prep return resp file self request send request request total time request approximately file self request stream verify branch later raise raise violation protocol handling exception another exception recent call last cell line file client none experiment experiment experiment name exist new experiment file self name self name optional experiment retrieve experiment experiment name store active return name file self name self name param name experiment name return class return name file self try return except file self method return method file method method get response else file method raise invalid except exception raise request exception request exception violation protocol,issue,negative,negative,neutral,neutral,negative,negative
1713234880,"I see, sorry for the confusion! I think your change makes sense :) ",see sorry confusion think change sense,issue,negative,negative,negative,negative,negative,negative
1713227217,"This error ""Blocked a frame with origin from accessing a cross-origin frame"" is not a bug. The same-origin policy is a security mechanism that ensures that window objects only have access to the informations they are authorized to get. To fix this issue, ensure that both the parent page and the iframe content are served from the same domain or implement Cross-Origin Communication techniques such as postMessage to safely communicate and exchange data between the two frames. 

The window.postMessage() method provides a controlled mechanism to securely circumvent this [Same-Origin Policy](https://net-informations.com/js/err/sop.htm) restriction. The window.postMessage() safely enables cross-origin communication between Window objects; e.g: between a page and an iframe embedded within it.

postMessage(message, targetOrigin)
postMessage(message, targetOrigin, [transfer])

targetOrigin - specifies what the origin of targetWindow must be for the event to be dispatched, either as the literal string ""*"" (indicating no preference) or as a URI.

If you don't have control over the content in the iframe, you won't be able to directly access its elements due to security restrictions.

",error blocked frame origin frame bug policy security mechanism window access authorized get fix issue ensure parent page content domain implement communication safely communicate exchange data two method mechanism securely circumvent policy restriction safely communication window page within message message transfer origin must event either literal string preference control content wo able directly access due security,issue,positive,positive,positive,positive,positive,positive
1713070546,"@xianqiangHub Thanks, can you shared the full stack trace?",thanks full stack trace,issue,negative,positive,positive,positive,positive,positive
1713066491,"> @xianqiangHub Please share the code that can reproduce the issue.
import mlflow
import mlflow.sklearn
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
import os

os.environ['MLFLOW_TRACKING_USERNAME']  = ""xx""
os.environ['MLFLOW_TRACKING_PASSWORD'] = ""x""

# 设置远程MLflow服务器地址
mlflow.set_tracking_uri(""https://172.18.86.87:5000/"")

# 生成示例数据
np.random.seed(42)
X = np.random.rand(100, 2)
y = (X[:, 0] + X[:, 1] > 1).astype(int)

# 划分训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 创建MLflow实验
mlflow.set_experiment(""Logistic_Regression_Demo"")

# 开始MLflow运行，并设置运行名称
with mlflow.start_run(run_name=""MyRun"") as run:
    # 记录参数
    mlflow.log_param(""random_seed"", 42)
    mlflow.log_param(""test_size"", 0.2)
    
    # 创建并训练逻辑回归模型
    model = LogisticRegression()
    model.fit(X_train, y_train)
    
    # 在测试集上进行预测
    y_pred = model.predict(X_test)
    
    # 计算精确度
    accuracy = accuracy_score(y_test, y_pred)
    
    # 记录精确度指标
    mlflow.log_metric(""accuracy"", accuracy)
    
    # 保存模型
    mlflow.sklearn.log_model(model, ""logistic_regression_model"")


",please share code reproduce issue import import import import import import import o run model accuracy accuracy accuracy model,issue,positive,neutral,neutral,neutral,neutral,neutral
1712471160,"Hello. I noticed that #8056 has been inactive for months. And after trying to use it in my company, I find that it is quite inflexible and impossible to use it as is for our setup. After going through its source, I realized that it can be simplified a lot, while making it a lot more flexible, by exposing ways to set up custom environment variables and volume mounts.

Is there motivation from the MLFlow team to add an official Helm chart _in the near-term_ through external contribution, and provide the necessary support? And if that’s the case, shall I make a new PR, with simplifications added on top of the changes from #8056 ?",hello inactive trying use company find quite inflexible impossible use setup going source simplified lot making lot flexible way set custom environment volume motivation team add official helm chart external contribution provide necessary support case shall make new added top,issue,positive,negative,neutral,neutral,negative,negative
1712315687,"@harupy: I made the changes you suggested except for the one in `_before_request()`. As I mentioned, I think that change would introduce a bug. Also, while it may be subjective, I prefer the current version because it reads more sequentially, case by case.",made except one think change would introduce bug also may subjective prefer current version sequentially case case,issue,negative,neutral,neutral,neutral,neutral,neutral
1712275407,"Can you try setting the required timestamp value as part of the metric builder constructor? This field is required. 

Here is what happens from the server side from the python client API when omitting (or explicitly setting `None` as a value in Python when constructing a ``Metric`` instance) the proto interpreter will raise the exception for this issue much more clearly from the Python APIs than from the JavaAPIs (due to the Java API being a wrapper around REST requests instead of a native Java implementation):

```python

from mlflow.entities import Metric, Param, RunTag

run = client.create_run(experiment_id=0)

metrics = [Metric(""metric"", 1, None, 1), Metric(""metric2"", 2, None, 1), Metric(""metric3"", 3, None, 1)]

params = [Param(""param"", ""a""), Param(""param2"", ""b"")]

client.log_batch(run_id=run.info.run_id, metrics=metrics, params=params)
```

Stack trace result:
```bash
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
~/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/google/protobuf/internal/python_message.py in field_setter(self, new_value)
    701     try:
--> 702       new_value = type_checker.CheckValue(new_value)
    703     except TypeError as e:

~/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/google/protobuf/internal/type_checkers.py in CheckValue(self, proposed_value)
    166                  (proposed_value, type(proposed_value), (int,)))
--> 167       raise TypeError(message)
    168 

TypeError: None has type <class 'NoneType'>, but expected one of: (<class 'int'>,)

During handling of the above exception, another exception occurred:

TypeError                                 Traceback (most recent call last)
/var/folders/cd/n8n0rm2x53l_s0xv_j_xklb00000gp/T/ipykernel_67654/2526191017.py in <cell line: 9>()
      7 params = [Param(""param"", ""a""), Param(""param2"", ""b"")]
      8 
----> 9 client.log_batch(run_id=run.info.run_id, metrics=metrics, params=params)

~/repos/mlflow-fork/mlflow/mlflow/tracking/client.py in log_batch(self, run_id, metrics, params, tags)
   1036             status: FINISHED
   1037         """"""
-> 1038         self._tracking_client.log_batch(run_id, metrics, params, tags)
   1039 
   1040     @experimental

~/repos/mlflow-fork/mlflow/mlflow/tracking/_tracking_service/client.py in log_batch(self, run_id, metrics, params, tags)
    387             metrics = metrics[metrics_batch_size:]
    388 
--> 389             self.store.log_batch(
    390                 run_id=run_id, metrics=metrics_batch, params=params_batch, tags=tags_batch
    391             )

~/repos/mlflow-fork/mlflow/mlflow/store/tracking/rest_store.py in log_batch(self, run_id, metrics, params, tags)
    316 
    317     def log_batch(self, run_id, metrics, params, tags):
--> 318         metric_protos = [metric.to_proto() for metric in metrics]
    319         param_protos = [param.to_proto() for param in params]
    320         tag_protos = [tag.to_proto() for tag in tags]

~/repos/mlflow-fork/mlflow/mlflow/store/tracking/rest_store.py in <listcomp>(.0)
    316 
    317     def log_batch(self, run_id, metrics, params, tags):
--> 318         metric_protos = [metric.to_proto() for metric in metrics]
    319         param_protos = [param.to_proto() for param in params]
    320         tag_protos = [tag.to_proto() for tag in tags]

~/repos/mlflow-fork/mlflow/mlflow/entities/metric.py in to_proto(self)
     38         metric.key = self.key
     39         metric.value = self.value
---> 40         metric.timestamp = self.timestamp
     41         metric.step = self.step
     42         return metric

~/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/google/protobuf/internal/python_message.py in field_setter(self, new_value)
    702       new_value = type_checker.CheckValue(new_value)
    703     except TypeError as e:
--> 704       raise TypeError(
    705           'Cannot set %s to %.1024r: %s' % (field.full_name, new_value, e))
    706     if clear_when_set_to_default and not new_value:

TypeError: Cannot set mlflow.Metric.timestamp to None: None has type <class 'NoneType'>, but expected one of: (<class 'int'>,)
```",try setting value part metric builder constructor field server side python client explicitly setting none value python metric instance proto interpreter raise exception issue much clearly python due wrapper around rest instead native implementation python import metric param run metric metric metric none metric metric none metric metric none param param param param stack trace result bash recent call last self try except self type raise message none type class one class handling exception another exception recent call last cell line param param param param self metric status finished metric experimental self metric metric metric self metric self metric metric metric param tag self metric metric metric param tag self return metric self except raise set set none none type class one class,issue,positive,positive,neutral,neutral,positive,positive
1712227561,"to be a bit more clear, here is the exact change that I validated works for the AML plugin: https://github.com/mlflow/mlflow/pull/9575",bit clear exact change work,issue,negative,positive,positive,positive,positive,positive
1712211336,"@serena-ruan  I don't see how - the failing code is a blind MLflowClient() invocation elsewhere in the process, and MLflowClient's notion of scoping is not the same as the current file I identify in the above description.

The proposal here would have to happen anyway to solve the root cause of ""mlflow-related-process has 2 independent mechanisms to check the currently globally specified tracking store""

EDIT: And just because I don't see how doesn't mean I'm right ",see failing code blind invocation elsewhere process notion current file identify description proposal would happen anyway solve root cause independent check currently globally store edit see mean right,issue,negative,negative,neutral,neutral,negative,negative
1712182230,Hi @M4nouel I'm currently working on a test refactoring for this. Stay tuned!,hi currently working test stay tuned,issue,negative,neutral,neutral,neutral,neutral,neutral
1711475088,"> Again, ""no space left on device"".

This can be ignored. We've encountered this issue a few times and know how to fix it. We'll fix it.",space left device issue time know fix fix,issue,negative,neutral,neutral,neutral,neutral,neutral
1711459841,"Hi @BenWilson2, @smurching,

Since yesterday the CI fails with this error:
`ERROR: Could not install packages due to an OSError: [Errno 28] No space left on device`
https://github.com/mlflow/mlflow/actions/runs/6118765998/job/16607448054?pr=9402#step:9:371
For this `tests/models/test_cli.py::test_change_conda_env_root_location FAILED` (which is OK on my laptop :angel: )

Do you know how to fix this ?",hi since yesterday error error could install due space left device angel know fix,issue,negative,negative,neutral,neutral,negative,negative
1711362330,Is this issue solved? I am facing the same trying to log KernelExplainer,issue facing trying log,issue,negative,neutral,neutral,neutral,neutral,neutral
1711289390,"@serena-ruan  we have created custom image v2.6.2 and as suggested by you, I have created below docker-compose.yaml, and  command ""sudo docker-compose up"" and with this, I am able to see mlflow application up and running.

In our case in production kubernetes cluster, we have two nodes out of which, on one node we have mysql is running and on other node, we are trying to install mlflow. Here, If I am using the same above configuration(Docker-compose.yaml) and same custom image v2.6.2 then mlflow pod is running but neither we are unable to access application, nor logs are being generated.

I have also tested mlflow pod connectivity with mysql via running ping command from mlflow pod. It seems to be fine to me.

Can you please help us. I am sharing all configurations below.

Dockerfile
```
FROM ghcr.io/mlflow/mlflow:v2.6.0

RUN apt-get update && apt-get install -f 
RUN apt-get install -y gcc default-libmysqlclient-dev build-essential python3-mysqldb 
RUN pip3 install mysql-connector-python mysql-client pymysql
RUN apt-get update && apt-get install -y procps && rm -rf /var/lib/apt/lists/*
RUN apt-get update && apt-get install -y iputils-ping

```
Docker-compose.yaml
```
version: ""3.3""

services:
  db:
    image: mysql:5.7
    restart: always
    environment:
      MYSQL_DATABASE: 'aut***'
      MYSQL_USER: 'au****'
      MYSQL_PASSWORD: 'au***'
      MYSQL_ROOT_PASSWORD: 'au*****'
    ports:
      - '3306:3306'
    expose:
      - '3306'

  mlflow_server:
    restart: always
    image: artifacts.corp.****.com/***-ml-docker/mlflow:v2.6.2
    container_name: mlflow_server
    depends_on:
      - db
    ports:
      - ""5000:5000""
    env_file: .env
    environment:
      - AWS_ACCESS_KEY_ID=${MINIO_ACCESS_KEY}
      - AWS_SECRET_ACCESS_KEY=${MINIO_SECRET_ACCESS_KEY}
      - MLFLOW_S3_ENDPOINT_URL=http://s3:${MINIO_PORT}
      - MLFLOW_S3_IGNORE_TLS=true
    command:
      - /bin/sh
      - -c
      - |
        mlflow server --host=0.0.0.0 --port=${MLFLOW_PORT} --backend-store-uri=mysql+pymysql://${MYSQL_USER}:${MYSQL_PASSWORD}@${MYSQL_HOST}:${MYSQL_TCP_PORT}/${MYSQL_DATABASE} --gunicorn-opts=""--log-level warning"" --serve-artifacts --artifacts-destination s3://${MLFLOW_BUCKET_NAME}
    healthcheck:
      test: [""CMD"", ""curl"", ""-f"", ""http://localhost:${MLFLOW_PORT}/""]
      interval: 30s
      timeout: 10s
      retries: 3
```

.env
```
MYSQL_DATABASE=au****
MYSQL_USER=au****
MYSQL_PASSWORD=au****
MYSQL_ROOT_PASSWORD=au****
MYSQL_HOST=db
MYSQL_TCP_PORT=3306


# MLflow configuration
MLFLOW_PORT=5000
MLFLOW_BUCKET_NAME=au****-artifacts

# MinIO access keys - these are needed by MLflow
MINIO_ACCESS_KEY=ei******y
MINIO_SECRET_ACCESS_KEY=sBDi********BngkS

# MinIO configuration
MINIO_ROOT_USER=*****-artifacts-user
MINIO_ROOT_PASSWORD=****-artifacts-password
MINIO_ADDRESS=mlminioprd.corp.com:9000
MINIO_STORAGE_USE_HTTPS=False
MINIO_PORT=9000
```


Configurations used for kubernetes:
values.yaml
```

replicaCount: 1
docker:
  image: artifacts.corp.com/***-ml-docker/mlflow
  pullPolicy: Always
  tag: v2.6.2

imagePullSecrets: []

k8sNamespace: au****

nameOverride: """"

fullnameOverride: ""mlflow""

imageCredentials:
    registry: artifacts.corp.com
    username: service-kubeflow
    password: ******

artifactory:
    api_key: *****

serviceAccount:
  create: true
  annotations: {}
  name: ""mlflow""

podAnnotations: {}

podSecurityContext: {}

securityContext: {}

service:
  type: ClusterIP
  port: 5000
  targetPort: 5000
  name: web-port
  annotations: {}

backendStore:
  databaseMigration: true
  databaseConnectionCheck: true

  postgres:
    enabled: false
    host: """"
    port: 5432
    database: """"
    user: """"
    password: """"
    driver: """"

  mysql:
    enabled: true
    host: ""mysql-headless.au****.svc.cluster.local""
    port: 3306
    database: ""au****""
    user: ""au****""
    password: ""au****""
    driver: ""pymysql""

artifactRoot:
  proxiedArtifactStorage: true
  s3:
    enabled: true
    bucket: ""au****-artifacts""
    path: ""mlminioprd.corp.com:9000""
    AccessKeyId: ""****""
    SecretAccessKey: ""****""

extraArgs: {}

extraFlags: []

extraEnvVars:
  MLFLOW_S3_IGNORE_TLS: true
  MLFLOW_S3_ENDPOINT_URL: https://mlminioprd.corp.com:9000
  MLFLOW_BUCKET_NAME: ""au****-artifacts""
  MLFLOW_PORT: 5000
  # MinIO configuration
  MINIO_ROOT_USER: ""au****-artifacts-u***""
  MINIO_ROOT_PASSWORD: ""au****-artifacts-***""
  MINIO_ADDRESS: ""mlminioprd.corp.com:9000""
  MINIO_STORAGE_USE_HTTPS: False
  MINIO_SERVER_URL: 'https://mlminioprd.corp.com'
  MINIO_PORT: 9000
  # MYSQL configuration
  MYSQL_HOST: ""mysql-headless.automotive.svc.cluster.local""
  MYSQL_TCP_PORT: 3306
  MYSQL_DATABASE: ""au****""
  MYSQL_PORT: 3306


extraSecretNamesForEnvFrom: []

ingress:
  enabled: true
  className: **-lv-nginx
  # annotations:
  #   kubernetes.io/ingress.class: **-lv-nginx
  hosts:
    - host: tracking-server-au****.corp.com
      paths:
        - path: /
          pathType: Prefix
          backend:
            serviceName: ""mlflow""
            servicePort: ""5000""          
  tls:
    - secretName: tls-ingress-mlflow-secret
      hosts:
        - tracking-server-au****.corp.com

resources:
  limits: 
    cpu: 1
    memory: 800M
  requests: 
    cpu: 1
    memory: 768M

serviceMonitor:
  enabled: true
  useServicePort: false
  namespace: monitoring
  interval: 30s
  telemetryPath: /metrics
  labels:
    release: prometheus
  timeout: 10s
  targetLabels: []

  metricRelabelings: []

nodeSelector: 
  autoflowapp: ""true""
  datacenter: ""las1""
  mldatanode: ""true""

tolerations: []

affinity: {}

initContainers: []

extraContainers: []

extraVolumes: []

extraVolumeMounts: []

livenessProbe: 
  initialDelaySeconds: 30
  periodSeconds: 30
  # timeoutSeconds: 1
  # failureThreshold: 3

# -- Readiness probe configurations. Please look to [here](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes).
readinessProbe: {}
  # initialDelaySeconds: 500
  # periodSeconds: 10
  # timeoutSeconds: 1
  # failureThreshold: 3

```
```
 kubectl exec -it mlflow-6d8df4d684-8nvkc -- /bin/bash
root@mlflow-6d8df4d684-8nvkc:/# ps -ef|more
UID          PID    PPID  C STIME TTY          TIME CMD
root           1       0  1 08:29 ?        00:00:01 /usr/local/bin/python /usr/local/bin/mlflow server --
host=0.0.0.0 --port=5000 --backend-store-uri=mysql+pymysql://aut***:aut***@mysql-headless.auto
motive.svc.cluster.local:3306/aut*** --gunicorn-opts=--log-level debug --default-artifact-root s3:/
/automotive-artifacts --serve-artifacts
root          23       0  0 08:31 pts/0    00:00:00 /bin/bash
root          29      23  0 08:31 pts/0    00:00:00 ps -ef
root          30      23  0 08:31 pts/0    00:00:00 more
```",custom image command able see application running case production cluster two one node running node trying install configuration custom image pod running neither unable access application also tested pod connectivity via running ping command pod fine please help u run update install run install run pip install run update install run update install version image restart always environment expose restart always image environment command server warning test curl interval configuration access configuration used docker image always tag registry password create true name service type port name true true false host port user password driver true host port user password driver true true bucket path true configuration false configuration ingres true host path prefix memory memory true false interval release true la true affinity readiness probe please look root stime time root server root root root,issue,positive,positive,positive,positive,positive,positive
1711229237,"not sure why it didn't work 🤷‍♂️
I think the job was queued but still not running after an hour",sure work think job still running hour,issue,negative,positive,positive,positive,positive,positive
1711163339,"Thanks @okoben. It worked. 

Set MLFLOW_TRACKING_URI with your MLflow tracking URL. In **Linux** do, `export MLFLOW_TRACKING_URI=[https|http]://<your-url>`",thanks worked set export,issue,negative,positive,positive,positive,positive,positive
1711031517,@bbqiu You can comment `@mlflow-automation autoformat` like below on the PR to fix the lint.,comment like fix lint,issue,negative,neutral,neutral,neutral,neutral,neutral
1710965273,"Hi @WEILMAX This sounds like a great idea! The strategy would be accepting TRACKING_URI as an environment variable, as parsing different schemas and environment variables within the schema seems tricky and error-prone. Feel free to raise a PR and I'll review on it 😄 Thank you!",hi like great idea strategy would environment variable different environment within schema tricky feel free raise review thank,issue,positive,positive,positive,positive,positive,positive
1710963133,"Hi @FloridaDataGuy thanks for reporting this! I raised a PR to fix the strange exception, we should not allow passing pandas Series.",hi thanks raised fix strange exception allow passing series,issue,negative,positive,neutral,neutral,positive,positive
1710728458,"The failed build was not related to my changes. The error was ""no space left on device"". I'll trigger another build.",build related error space left device trigger another build,issue,negative,neutral,neutral,neutral,neutral,neutral
1710335239,"> Thanks @santiagxf for your PR! I left a few comments, could you add some unit tests to validate your changes?

@serena-ruan do you have any hints about how testing of the Azure AD part can be included? I'm adding tests for parameters, batch size, and the completion task.",thanks left could add unit validate testing azure ad part included batch size completion task,issue,positive,positive,neutral,neutral,positive,positive
1710163260,"Hi @Beramos Thanks for raising this up! Though I feel like the example is more for the `python_model` explanation that it could be a PythonModel or a callable, using log_model in the example makes sense to me :D Feel free to raise a PR to update the examples, I'll review it. LMK if you need any help to get started!",hi thanks raising though feel like example explanation could callable example sense feel free raise update review need help get,issue,positive,positive,positive,positive,positive,positive
1710030232,@harupy: I made the changes you suggested. Ready for another review.,made ready another review,issue,negative,positive,positive,positive,positive,positive
1709970231,"Thank you @serena-ruan  for fast response, this sounds very good to me :)",thank fast response good,issue,positive,positive,positive,positive,positive,positive
1709962046,"@barrywhart Sorry for the delay, looking right now :)",sorry delay looking right,issue,negative,negative,negative,negative,negative,negative
1709439503,"> @bbqiu This section https://mlflow.org/docs/latest/python_api/mlflow.langchain.html#mlflow.langchain.log_model (under the signature parameter) should be a good place to specify the output format.

We decided not to specify the output format here, because now the behavior _actually_ matches what the docstring says about the input and output schema!",section signature parameter good place specify output format decided specify output format behavior input output schema,issue,negative,positive,positive,positive,positive,positive
1709262939,Still very much a WIP - pushing draft for style reference for others.,still much pushing draft style reference,issue,negative,positive,positive,positive,positive,positive
1709236505,"Overall really strong work out of the box.

Notes
* New lines need to be removed (probably come from code write)
* Grammar change but other than that, no issues
* `..` prefixes are sometimes changed for `Code`/`Example`
* `:func:` was dropped from first comments",overall really strong work box new need removed probably come code write grammar change sometimes code example first,issue,positive,positive,positive,positive,positive,positive
1708853979,"### Summary of differences

LLM
* `:func:` prefix was omitted from the return type from one function
* `..` prefix is omitted from `Example` and `Note`
* `:caption:`s are dropped
* Parameter in-line code blocks are dropped

Code 
* There are sometimes extra leading/trailing lines",summary prefix return type one function prefix example note caption parameter code code sometimes extra,issue,negative,neutral,neutral,neutral,neutral,neutral
1708720003,"Would it be possible to provide a flag that would download the psycopg2-binary or if postgres environment variables are detected? You'd likely need some sort of startup script.

@benelot I didn't need to roll my own Dockerfile... passing this as the command works (I'm starting up the mlflow server in a docker compose):

`bash -c ""python3 -m pip install pip --upgrade && \
      python3 -m pip install psycopg2-binary && \
      mlflow server ${WHATEVER_FLAGS_YOU_NEED}""`",would possible provide flag would environment likely need sort script need roll passing command work starting server docker compose bash python pip install pip upgrade python pip install server,issue,negative,neutral,neutral,neutral,neutral,neutral
1708619629,"Interesting - we're doing something similar with LiteLLM (https://github.com/BerriAI/litellm) - moving most of our LLM API calls to HTTP requests, and standardizing the exceptions to the openai format. 


We could add support for Huggingface, TogetherAI, Aleph Alpha, AI21, Google's VertexAI and others (https://docs.litellm.ai/docs/providers)

Happy to make a PR if you think we could be helpful",interesting something similar moving format could add support aleph alpha ai happy make think could helpful,issue,positive,positive,positive,positive,positive,positive
1708551172,"@harupy: It's been two weeks since his initial feedback, and I have not heard back from Gabriel on my questions regarding his feedback. May I ask you to do a final review on the PR, so we can get this merged and I can work on other MLflow contributions? 🙏🏽

If Gabriel later has specific changes he'd like to see, I'm happy to create a follow-up PR to make those. I'm confident that the PR, as written, will not cause issues for existing or future users of auth. His concerns seem to be more about naming or structure, internal details rather than about whether it will work.

Thanks!",two since initial feedback back regarding feedback may ask final review get work later specific like see happy create make confident written cause future seem naming structure internal rather whether work thanks,issue,positive,positive,positive,positive,positive,positive
1708516475,"Hi @xgdgsc I don't quite understand your problem, could you elaborate more? If this is a UI bug could you provide screenshot as well?",hi quite understand problem could elaborate bug could provide well,issue,negative,positive,positive,positive,positive,positive
1708499141,Could you try `pip install pyopenssl --force-reinstall` to make sure the pyopenssl version is updated? It's some sort of version incompatibility issue.,could try pip install make sure version sort version incompatibility issue,issue,negative,positive,positive,positive,positive,positive
1708468026,"I found a problem for the actual approach, the actual code is the following:

```python
    # Save onnx-model
    if Version(onnx.__version__) >= Version(""1.9.0""):
        onnx.save_model(onnx_model, model_data_path, save_as_external_data=True)
    else:
        onnx.save_model(onnx_model, model_data_path)
 ```
 
With this approach multiple files will be generated: the `model.onnx` file and a external alphanumeric file (ie.: `f02a9b26-4caa-11ee-9c58-df96ee46208e`, and therefore, uploaded to the MLFLOW server, resulting in this structure:
 
![image](https://github.com/mlflow/mlflow/assets/44867923/d1d8d19f-56c3-4db5-9fea-18c8f4be33d7)

 The point is that, this code won't work any longer:
 
 ```python
 model_path = ""models:/MyModel/Production/model.onnx""
dst_path = mlflow.artifacts.download_artifacts(artifact_uri=model_path)
session = onnxruntime.InferenceSession(dst_path, providers=providers)
```

as **it won't download the aphanumeric file, resulting in this error**:

```shell
2023-09-06 15:15:02.752271604 [E:onnxruntime:, inference_session.cc:1530 operator()] Exception during initialization: [/onnxruntime_src/onnxruntime/core/optimizer/initializer.cc:44] onnxruntime::Initializer::Initializer(const onnx::TensorProto&, const onnxruntime::Path&) [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Invalid fd was supplied: -1
```

Leading to no information of where the problem comes from.

**Potential solutions:**

:point_right:  It would be nice if `save_as_external_data` could configurable.
:point_right:  Or, at least, checking if the file given model size is >2Gb to apply external data AND advise the user.

 
 
 ",found problem actual approach actual code following python save version version else approach multiple file external file ie therefore server resulting structure image point code wo work longer python session wo file resulting error shell operator exception invalid leading information problem come potential would nice could least file given model size apply external data advise user,issue,negative,positive,neutral,neutral,positive,positive
1708426930,"> Also one more thing, if I am running the above provided test.py file inside the EC2 which is behind ECS task by docker exec into the container running on the instance things are working fine.

This sounds like the issue is not with MLflow. Could you try asking AWS support to fix the issue? There must be some setup configuration problems but it's quite hard for us to locate the root cause.",also one thing running provided file inside behind task docker container running instance working fine like issue could try support fix issue must setup configuration quite hard u locate root cause,issue,positive,negative,neutral,neutral,negative,negative
1708422551,Hi @akshaya-a Thanks for locating the root cause for this! Does this PR https://github.com/mlflow/mlflow/pull/9458 solve the same problem? ,hi thanks root cause solve problem,issue,negative,positive,positive,positive,positive,positive
1708353157,"Hi @lukasz-gawron Thanks for raising the feature request! We will plan to start with some simple feature compatibility matrix for the following sprints, and hopefully make it more detailed step by step.",hi thanks raising feature request plan start simple feature compatibility matrix following hopefully make detailed step step,issue,positive,positive,positive,positive,positive,positive
1708233886,"Hi, no problem. Let me know if you need anything else.


Joe",hi problem let know need anything else joe,issue,negative,neutral,neutral,neutral,neutral,neutral
1707987087,"hey, i would like to help with this",hey would like help,issue,positive,neutral,neutral,neutral,neutral,neutral
1707986182,"> 

would also like to help",would also like help,issue,positive,neutral,neutral,neutral,neutral,neutral
1707979152,I'm still facing this issue with mlflow v2.6.0 on Windows 10. Does anyone know a workaround? ,still facing issue anyone know,issue,negative,neutral,neutral,neutral,neutral,neutral
1707930703,"@krrishdholakia We made this decision:

1. To avoid increasing the number of dependencies. If we use SDKs, we need to add new dependencies every time we add a new provider.
2. To make it easier to standardize request retry logic (we haven't implemented this).
",made decision avoid increasing number use need add new every time add new provider make easier standardize request retry logic,issue,negative,positive,positive,positive,positive,positive
1707838559,"@alanzhangeliiza You don't need to install all dependencies, for transformers testing code, you can install these dependencies:
https://github.com/mlflow/mlflow/blob/0206a2392aa9773a5c8d6eb865da67bfc1ace065/mlflow/ml-package-versions.yml#L489
and https://github.com/mlflow/mlflow/blob/0206a2392aa9773a5c8d6eb865da67bfc1ace065/mlflow/ml-package-versions.yml#L513",need install testing code install,issue,negative,neutral,neutral,neutral,neutral,neutral
1707803650,Just found out that I forgot to submit the comments above. Ignore it if it's outdated 😆 ,found forgot submit ignore outdated,issue,negative,negative,negative,negative,negative,negative
1707638956,"> 

Thanks @BenWilson2, I tried to find other plugin's user guide but seems like there is no specific section for them. So I added a new [section](https://github.com/mlflow/mlflow/pull/9460/files#diff-56d261209e85b3ed341d9406ad4464b6e05cf23f3c8f742ea75b8080604f8c34R79) for custom auth under the `Using an MLflow Plugin`. Please let me know if this looks good to you. ",thanks tried find user guide like specific section added new section custom please let know good,issue,positive,positive,positive,positive,positive,positive
1707504662,"@bbqiu Most things look good! Awesome work! Could you also update the PR description ""After:"" to reflect the latest result format?",look good awesome work could also update description reflect latest result format,issue,positive,positive,positive,positive,positive,positive
1707494726,"Hi @JoeBeeton thank you for reporting this! 
We are currently looking into it and will test some ideas for preventing the reported issue. ",hi thank currently looking test issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1707480804,@bbqiu This section https://mlflow.org/docs/latest/python_api/mlflow.langchain.html#mlflow.langchain.log_model (under the signature parameter) should be a good place to specify the output format. ,section signature parameter good place specify output format,issue,negative,positive,positive,positive,positive,positive
1707434558,"@chenmoneygithub 

> Haru could you share an example link to transient errors? I am curious if this is due to flaky tests or flaky github VM, thanks!

I think https://github.com/mlflow-automation/mlflow/actions/runs/6085149239/job/16508598695#step:13:412 is a good example where a request to (pypi.python.org to fetch package metadata) fails due to a transient network error.
",could share example link transient curious due flaky flaky thanks think good example request fetch package due transient network error,issue,positive,positive,positive,positive,positive,positive
1707306820,@prithvikannan Looks like the pip requirements created for promptlab models contain `mlflow==2.6.0` instead of `mlflow[gateway]==2.6.0` (which is what we do on Databricks). Can we update this for consistency? gateway deps are required,like pip contain instead gateway update consistency gateway,issue,negative,neutral,neutral,neutral,neutral,neutral
1707286745,"is there anywhere where we should make documentation changes?

[this doc page](https://mlflow.org/docs/latest/models.html) doesn't actually ever describe the shape of the return type of predict, so it doesn't have to change, but are there other pages that would be relevant to this?",anywhere make documentation doc page actually ever describe shape return type predict change would relevant,issue,negative,positive,positive,positive,positive,positive
1707197101,"Looks like the ""evaluate"" button doesn't quite work when testing locally:


https://github.com/mlflow/mlflow/assets/39497902/5809ea13-7086-4879-bd74-5d8d4b310bd8


",like evaluate button quite work testing locally,issue,negative,neutral,neutral,neutral,neutral,neutral
1707192915,"I think I found the real issue, and while I don't necessarily like our plugin's code, the fix I propose above would make any other plugin implementation less error-prone as well. It's not really related to our plugin so I created a new issue @serena-ruan, let me know your thoughts. A PR fixing that would then close this at the same time",think found real issue necessarily like code fix propose would make implementation le well really related new issue let know fixing would close time,issue,positive,positive,neutral,neutral,positive,positive
1707190738,"Works great! A few small nits:

1. <img width=""378"" alt=""Screenshot 2023-09-05 at 12 22 22 PM"" src=""https://github.com/mlflow/mlflow/assets/39497902/715c8fbe-deda-4d72-a372-a0187fe5332e"">

The margin between the model response and the latency / token count is pretty small. Can we increase it?

2. Can we change the text ""Preview"" to ""Experimental?"" Experimental is the term used in OSS

<img width=""843"" alt=""Screenshot 2023-09-05 at 12 26 13 PM"" src=""https://github.com/mlflow/mlflow/assets/39497902/d6707a5d-7c31-42d8-9d2f-5bb5ee22d3fb"">

3. In the server logs, I see the following error message when creating a promptlab run:

```
2023/09/05 12:27:26 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /var/folders/8f/s8n7wq1j2j3440sfljwmmpr80000gp/T/tmpb84q006w/model, flavor: mlflow._promptlab), fall back to return []. Set logging level to DEBUG to see the full traceback.
```

I think that comes from pip requirements inference in https://github.com/mlflow/mlflow/blob/712cedde1ec5139fbde074c5fdd9ba79a94a58c4/mlflow/utils/promptlab_utils.py#L99-L107. Instead of inferring pip requirements, which tries to fork a subprocess (too heavyweight for tracking server backend), can we specify the `pip_requirements` argument when saving the model in https://github.com/mlflow/mlflow/blob/712cedde1ec5139fbde074c5fdd9ba79a94a58c4/mlflow/utils/promptlab_utils.py#L99-L107?

",work great small margin model response latency token count pretty small increase change text preview experimental experimental term used server see following error message run warning unexpected error pip model flavor fall back return set logging level see full think come pip inference instead pip fork heavyweight server specify argument saving model,issue,negative,positive,positive,positive,positive,positive
1707066829,"> Hi @danielstankw What is your boto3 version? Does this https://stackoverflow.com/questions/74981558/error-updating-python3-pip-attributeerror-module-lib-has-no-attribute-openss resolve your problem?

I have:

- pyopenssl v: 23.2.0
- cryptography v.41.0.3
- boto3: v1.28.40

Unfortunately with those packages the problem isnt resolved. If I downgrade cryptography to 38.0.4 as suggested, the issue persists.",hi version resolve problem cryptography unfortunately problem resolved downgrade cryptography issue,issue,negative,negative,negative,negative,negative,negative
1706910660,"@harupy, @gabrielfu: Can we decide on next steps for this PR? I have responded to feedback by making changes and asking questions. Until we can resolve this, I'm blocked from working on GBAC (#8864).",decide next feedback making resolve blocked working,issue,negative,neutral,neutral,neutral,neutral,neutral
1706903094,@M4nouel creating a separate file that does not mutate the saved artifact within the tracking artifact store and is used solely during container definition when preparing for serving is a fantastic idea. We eagerly look forward to the modification of the PR. ,separate file mutate saved artifact within artifact store used solely container definition serving fantastic idea eagerly look forward modification,issue,positive,positive,positive,positive,positive,positive
1706850672,Hi @danielstankw  What is your boto3 version? Does this https://stackoverflow.com/questions/74981558/error-updating-python3-pip-attributeerror-module-lib-has-no-attribute-openss resolve your problem?,hi version resolve problem,issue,negative,neutral,neutral,neutral,neutral,neutral
1706845860,"Thanks for this issue. Is there any reason why the plots are not displayed by default like the chat_view when comparing? It is pretty hard to open and analyse each metrics and impossible to compare metrics of the same run. Am I missing something? 

![image](https://github.com/mlflow/mlflow/assets/17333185/6b3eaa0d-e881-45c9-b1db-46f202cd33cb)
",thanks issue reason displayed default like pretty hard open analyse metric impossible compare metric run missing something image,issue,positive,negative,negative,negative,negative,negative
1706377045,"Hi, I noticed the same bug. I can see my list of features, but I am unable to see the tags I passed to mlflow.log_input. Did it already occur to anyone? ",hi bug see list unable see already occur anyone,issue,negative,negative,negative,negative,negative,negative
1706180987,"Sure here is my dockerfile which is used to create AWS ECR image:

``` 
FROM python:3.8.0

RUN pip3 install mlflow pymysql boto3

ENV BACKEND_STORE=""your_sql_url""
ENV ARTIFACT_STORE=""your_s3_bucket_environment""

CMD mlflow server \
  --backend-store-uri $BACKEND_STORE \
  --artifacts-destination $ARTIFACT_STORE \
  --host 0.0.0.0 \
  --serve-artifacts
```

In docker configuration of task definition, for command field:
``` mlflow,server,--backend-store-uri,${BACKEND_STORE},--artifacts-destination,${ARTIFACT_STORE},--host,0.0.0.0,--serve-artifacts ```

I have added environment variables BACKEND_STORE & ARTIFACT_STORE in the AWS parameter store and using valuesFrom feature of ECS task defintion, I am accessing them. The ECS task defintion role has AmazonSSMFullAccess and S3FullAcess IAM policies attached.

Also one more thing, if I am running the above provided test.py file inside the EC2 which is behind ECS task by docker exec into the container running on the instance things are working fine.",sure used create image python run pip install server host docker configuration task definition command field server host added environment parameter store feature task task role attached also one thing running provided file inside behind task docker container running instance working fine,issue,positive,positive,positive,positive,positive,positive
1706136239,"Thanks @smurching, I see your point.
We can add this information in a separate file named ""registered_model_meta"" (to use your term but prevent confusion with the metadata key in the MLmodel file)?
That would give the same result!
If you agree, I can modify my PR within the week.",thanks see point add information separate file use term prevent confusion key file would give result agree modify within week,issue,positive,positive,neutral,neutral,positive,positive
1706092661,"Yes bucket is correct however it is private so you wan’t be able to list and use it


I can make environment for you in my playground with S3 and EC2 instance, reproduce issue, and give you access


> On 5 Sep 2023, at 04:37, Harutaka Kawamura ***@***.***> wrote:
> 
> 
> @ait-dmirian <https://github.com/ait-dmirian> Is s3://ait-dmirian-mlflowtest/mytests/ a valid URI?
> 
> —
> Reply to this email directly, view it on GitHub <https://github.com/mlflow/mlflow/issues/9523#issuecomment-1705827034>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/A2P22Z45OOH4HAAL3TN365TXYZ63ZANCNFSM6AAAAAA4KJ7NJY>.
> You are receiving this because you were mentioned.
> 

",yes bucket correct however private wan able list use make environment playground instance reproduce issue give access wrote valid reply directly view,issue,negative,positive,neutral,neutral,positive,positive
1706026443,"Hi @kavita1205 Could you try changing `--log-level debug` to see if there's any logs generated?
Also, could you try generating a docker-compose.yml file to repro the problem?",hi could try see also could try generating file problem,issue,negative,neutral,neutral,neutral,neutral,neutral
1705990972,"Hi @WeichenXu123 ,

I have created a codespace in which I have made changes to  transformers.py to support the PeftModel. I plan to write pytests for the changes I have made to support PeftModels. However, I am running into trouble when getting set up to contribute. 
In the codespace, when I run:
```
    ./dev/run-python-tests.sh
```
There are multiple tests that fail even before I make changes to the transformers file.
Another problem which I am running into is that when I run:
```
    pytest tests/transformers
```
I still have in import error on the package `optuna` coming from the file test_transformers_autolog.py. This package does not seem to appear in any of the requirement files at the moment. 
If I install the package within my mlflow-dev venv and run the pytests it also fails multiple tests, but it also fails to complete, terminating and citing the error: Low disk space (<5%).
Is this a problem that others have ran into, and if so how do I resolve it to run the pytests? Thanks!
",hi made support plan write made support however running trouble getting set contribute run multiple fail even make file another problem running run still import error package coming file package seem appear requirement moment install package within run also multiple also complete error low disk space problem ran resolve run thanks,issue,negative,negative,neutral,neutral,negative,negative
1705942549,"Still same error, It's ok. Thank You for your reply. I save model using model.state_dict(). It working good😊.",still error thank reply save model working good,issue,positive,positive,positive,positive,positive,positive
1705897034,"I believe so? - https://github.com/mlflow/mlflow/blob/abf4140a7fa809154e3e7542fda6da7257c8a9c8/mlflow/gateway/providers/openai.py#L26

Just curious why not use the python sdk instead? ",believe curious use python instead,issue,negative,negative,neutral,neutral,negative,negative
1705863472,"@joshuajennysibbu You could try passing `pickle_module=cloudpickle` as kwargs when logging the model: 
```
import cloudpickle
mlflow.pytorch.log_model(model, pickle_module=cloudpickle)
```",could try passing logging model import model,issue,negative,neutral,neutral,neutral,neutral,neutral
1705845561,"We can also try:
```
import cloudpickle
torch.save(obj, f, pickle_module=cloudpickle)
```
to address it",also try import address,issue,negative,neutral,neutral,neutral,neutral,neutral
1705822392,@gabrielfu We can use this PR to check what we've changed. Feel free to leave comments for improvements/questions.,use check feel free leave,issue,negative,positive,positive,positive,positive,positive
1705816126,"Hi @benelot, thanks for raising the issue! For installing postgres related requirements it would increase image size, and we're not sure if all customers are using it. But we can keep this issue open to see if any more people vote on this :D",hi thanks raising issue related would increase image size sure keep issue open see people vote,issue,positive,positive,positive,positive,positive,positive
1705806043,"Hi @hitmanagent298  Could you provide your command to pass environment variables?
Another thing worth trying out is to exclude mlflow in the process, could you try uploading a random file without mlflow and see if it works? If it's still the `NoCredentials` issue then we can know it's just something wrong about the setup.",hi could provide command pas environment another thing worth trying exclude process could try random file without see work still issue know something wrong setup,issue,negative,negative,negative,negative,negative,negative
1705642138,"@BenWilson2 
* Does the article structure align with your describe+show+explain format?
* [This](https://github.com/mlflow/mlflow/pull/9525/files#diff-a315a417763ac55133d73ba283e35b748361c608a5287454db8a8d0dc9a457c9R82) is an exhaustive list (from my current perspective) of required demos for creating routes. From this, a user should be able to create any route by 1) copying and pasting base code, 2) copying and pasting then modifying model-specific configs. Is this what you had in mind?
* Is this the correct content? Should additional sections be included/removed?",article structure align format exhaustive list current perspective demo user able create route pasting base code pasting mind correct content additional,issue,negative,negative,negative,negative,negative,negative
1705538313,"Got it, thanks @M4nouel ! @BenWilson2 do you or another OSS maintainer have more context on MLServer? I may not have time to dig into it for some time. I like the goal of making this metadata available, but wonder if it could be done another way than by putting registered model metadata into an MLmodel file, which seems like it violates separation of concerns (an MLmodel file shouldn't be aware of what model version(s) it's associated with).

One idea for discussion: when a model version is downloaded from the registry, the MLflow client knows the registered model name (e.g. ""mymodel"") and version (e.g. ""1""). If the model version is specified by stage or alias reference, the client could resolve the stage/alias to a version number, e.g. `models:/mymodel/Production` -> `models:/mymodel/1`. Could we just allow propagating this metadata to `mlflow models build-docker` via e.g. environment variables in the docker image or a file, and would that help solve the use case?",got thanks another maintainer context may time dig time like goal making available wonder could done another way registered model file like separation file aware model version associated one idea discussion model version registry client registered model name version model version stage alias reference client could resolve version number could allow via environment docker image file would help solve use case,issue,positive,positive,positive,positive,positive,positive
1705330933,"@BenWilson2 @serena-ruan 
Can someone help me here. I am trying to implement in mlflow in our production cluster where database is mysql and artifactory is minio being configured. ",someone help trying implement production cluster,issue,negative,neutral,neutral,neutral,neutral,neutral
1704674320,Looks like it's a pytorch problem https://github.com/pytorch/pytorch/issues/18325. Could you try https://github.com/pytorch/pytorch/issues/18325#issuecomment-1501487230?,like problem could try,issue,negative,neutral,neutral,neutral,neutral,neutral
1704660744,"Code snippet i use load model. 

`import mlflow
logged_model = 'runs:/6f8139403b494163abcaeb1adecf880e/model'

loaded_model = mlflow.pytorch.load_model(logged_model)
`
I tried with ipynb it load model without error in same kernel. When i restart and run a particular this code cell it give this error.",code snippet use load model import tried load model without error kernel restart run particular code cell give error,issue,positive,positive,positive,positive,positive,positive
1704590686,Hi @joshuajennysibbu Could you provide your code to reproduce the problem? Are you using the model uri to load the model back?,hi could provide code reproduce problem model load model back,issue,negative,neutral,neutral,neutral,neutral,neutral
1704585013,"> @gabrielfu Created a new branch: https://github.com/mlflow/mlflow/tree/proxy-mpu

thanks! i filed #9482 for the proto interface. ",new branch thanks proto interface,issue,negative,positive,positive,positive,positive,positive
1704333357,"I have the same issue as @seb2704. The client in the push_image_to_registry function is initialized from the environment but no log-in is done subsequently. If we look at the build_docker_image function we have this line which is missing in the prior function.
 ```   
 if docker_auth is not None:
        client.login(**docker_auth)
```
And this is the push_image_to_registry function:
```
def push_image_to_registry(image_tag):
    client = docker.from_env(timeout=_DOCKER_API_TIMEOUT)
    _logger.info(""=== Pushing docker image %s ==="", image_tag)
    for line in client.images.push(repository=image_tag, stream=True, decode=True):
        if ""error"" in line and line[""error""]:
            raise ExecutionException(
                ""Error while pushing to docker registry: {error}"".format(error=line[""error""])
            )
    return client.images.get_registry_data(image_tag).id
```

The proposed fix is to pass into push_image_to_registry the docker_auth dict and do the same login as in build_docker_image or just initialize the client outside and pass the client to the functions instead of passing the docker_auth dict. If somebody is willing to assign this to me I will help.",issue client function environment done subsequently look function line missing prior function none function client pushing docker image line error line line error raise error pushing docker registry error error return fix pas login initialize client outside pas client instead passing somebody willing assign help,issue,negative,positive,neutral,neutral,positive,positive
1703932249,"I understand! Change is hard so making that transition easier is a worthy goal - for a different customer I tried a fun prototype to make using the mlflow UI a bit easier here, let me know if it helps: https://github.com/akshaya-a/azureml-apps
EDIT: TL;DR instead of running the mlflow UI on your laptop or other client local context, you can host the OSS UI inside a docker container in an AML ""compute instance"" and get a hosted-like feel for it to use it across multiple devices

@serena-ruan  I'll keep this bug open until I fix the real issue but now that Gabriel is unblocked, could take a bit",understand change hard making transition easier worthy goal different customer tried fun prototype make bit easier let know edit instead running client local context host inside docker container compute instance get feel use across multiple keep bug open fix real issue unblocked could take bit,issue,positive,positive,neutral,neutral,positive,positive
1703910469,@BenWilson2 @dbczumar please feel free to add comments.,please feel free add,issue,positive,positive,positive,positive,positive,positive
1703803348,"@akshaya-a this works like a charm. I would not have imagined the fix would be so easy, you are amazing, thank you!

To tell you the full story, it was basically politics. My team already used mlflow without azureml and we transitioned to azureml recently. However, there was lot of push back because they did not want to use the azure ml UI to track experiments. I suspect this will change once they become used to it but for now having a workaround to use the standard UI is very helpful. 

Once again, thank you very much.",work like charm would fix would easy amazing thank tell full story basically politics team already used without recently however lot push back want use azure track suspect change become used use standard helpful thank much,issue,positive,positive,positive,positive,positive,positive
1703794595,"Hi @smurching thank you for the reply !

That's exactly what this PR does! Exactly the way you want it!

The aim is to help callers determine which model name and which registry version are being served/used. 
Including when served by MLServer, which relies on this information to implement the [V2 Inference Protocol] (https://docs.seldon.io/projects/seldon-core/en/latest/reference/apis/v2-protocol.html).

The implementation I suggested here does not modify the source of truth (the model registry)!
It simply adds the name and version of the model in the MLmodel to the pyfunc copy on the client/user side! 
We don't touch the data contained in the model registry, only the copy downloaded by the user.
Moreover, if registry are immutable, adding the model name and version to the pyfunc copy when downloading will always give the same result on the client side...

https://github.com/M4nouel/mlflow/commit/59f85f48830921a0ea2c1ed6285c0b5b56bb7d97#diff-f4052b42eb6f3c23860b7bb04d77671ee886d2dfa0f700d075b8431a69909944R156

It basically adds the model name and version in the MLmodel copy on the client/user side, and solves https://github.com/mlflow/mlflow/issues/6657 without violating https://github.com/mlflow/mlflow/issues/3175..
Unless I missed something ?",hi thank reply exactly exactly way want aim help determine model name registry version information implement inference protocol implementation modify source truth model registry simply name version model copy side touch data model registry copy user moreover registry immutable model name version copy always give result client side basically model name version copy side without unless something,issue,positive,positive,positive,positive,positive,positive
1703776434,"OK @Gabriel2409 workaround if you can: set MLFLOW_TRACKING_URI to the same value, not just --backend-store-uri. That should get you further (i can now list and fetch artifact contents in the UI for the few I spot checked).

It comes from deep in the bowels relying on MLflowClient() to do the right thing, which in regular jobs/scripts normally does due to the env vars being set. I'll need a little time to ponder how the other plugins correctly fetch the context from the CLI and rework our flow to do the same.

The error message is misleading because it's expecting to be in another path where there is a SAS URI, but we got there because MLflowClient() resolves to FileStore, not the AzureMLRestStore, hence the workaround.

EDIT: Out of curiosity, how is the OSS UI + AML tracking store blocking you? It's not really a supported scenario, I just find fixing mlflow bugs an interesting hobby 🥲 - I'd definitely love to learn more about somebody caring about this path and if I should beef up the test suite for that..

![image](https://github.com/mlflow/mlflow/assets/16749003/176e2f15-39e5-4c24-8757-3437819d335a)
",set value get list fetch artifact content spot checked come deep bowel right thing regular normally due set need little time ponder correctly fetch context rework flow error message misleading another path got hence edit curiosity store blocking really scenario find fixing interesting hobby definitely love learn somebody path beef test suite image,issue,positive,positive,positive,positive,positive,positive
1703760946,"> > do you want me to split them up into smaller ones?
> 
> I'd prefer smaller ones. Let's create a feature branch, and file PRs against it :) Once the feature branch is ready to be merged, then we merge it into the master branch!

Sounds good!",want split smaller prefer smaller let create feature branch file feature branch ready merge master branch good,issue,positive,positive,positive,positive,positive,positive
1703675291,"> do you want me to split them up into smaller ones?

I'd prefer smaller ones. Let's create a feature branch, and file PRs against it :) Once the feature branch is ready to be merged, then we merge it into the master branch!",want split smaller prefer smaller let create feature branch file feature branch ready merge master branch,issue,positive,positive,neutral,neutral,positive,positive
1703196606,"@M4nouel thanks for the PR! Unfortunately I think this approach may not work given the direction the model registry is headed; the artifacts in the model registry are intended to be immutable on registration. This is actually the case already in some registry implementations (e.g on Databricks). Moreover, disregarding the immutability point, the same model artifacts may be registered to different registry servers etc - the MLmodel file is probably not the right place to capture information about where the model is registered.

Thinking about the use case - is the goal to help callers determine what model version from the registry is being served when they query a model serving endpoint?",thanks unfortunately think approach may work given direction model registry headed model registry intended immutable registration actually case already registry moreover immutability point model may registered different registry file probably right place capture information model registered thinking use case goal help determine model version registry query model serving,issue,negative,negative,neutral,neutral,negative,negative
1703173477,"@dbczumar I reworked this PR to focus on improving the error message in the case where a `ModuleNotFoundError` was actually thrown, rather than always throwing/warning up front. Does this work?",reworked focus improving error message case actually thrown rather always front work,issue,negative,neutral,neutral,neutral,neutral,neutral
1702439462,"Hi @serena-ruan, thank you for looking into this issue and providing more context.

I understand this is how the code works, but it does not feel like expected behavior. If your answer is more about whether this should be classified as a bug or something else, I have no opinion on that.

The reason why I would not regard it as expected behavior is that I started with an evaluation with more than one variable and was happy that mlflow matched variables in prompt with column names in the dataframe. Then, I implemented a different evaluation with only one variable in the prompts but multiple variables in the dataframe. Still, I expect mlflow to match variables via names as long as I provide them.

What is the reason to resort to positional matching even if names are given?",hi thank looking issue providing context understand code work feel like behavior answer whether classified bug something else opinion reason would regard behavior evaluation one variable happy prompt column different evaluation one variable multiple still expect match via long provide reason resort positional matching even given,issue,positive,positive,positive,positive,positive,positive
1702263054,"Hi @akshaya-a, thank you for your reply. 
This is actually blocking for me as I need to use the standard mlflow ui. 

After further investigation, I think the error comes from here, in `mlflow.server.handlers.py`:


```python 
@catch_mlflow_exception
def _get_artifact_repo(run):
    return get_artifact_repository(run.info.artifact_uri)
```

- `run.info.artifact_uri` looks like this: `azureml://<region>.api.azureml.ms/mlflow/v2.0/subscriptions/<subscriptionid>/resourceGroups/<resourcegroup>/providers/Microsoft.MachineLearningServices/workspaces/<workspacename>/experiments/<experimentid>/runs/<runid>/artifacts/`
- I added a breakpoint here and ran the `get_artifact_repository` function and I got the following error: `*** mlflow.exceptions.MlflowException: An authorization token was not set in the artifact uri`

What is strange is that I am authenticated in azure. 
",hi thank reply actually blocking need use standard investigation think error come python run return like region added ran function got following error authorization token set artifact strange azure,issue,negative,negative,neutral,neutral,negative,negative
1702260229,"> @gabrielfu Thanks for the example!

@harupy no problem :) would you like to review & merge this PR, or do you want me to split them up into smaller ones?",thanks example problem would like review merge want split smaller,issue,negative,positive,neutral,neutral,positive,positive
1702246691,Feel free to push commits if necessary.,feel free push necessary,issue,positive,positive,positive,positive,positive,positive
1702227692,"Looks like the failure is flaky, could anyone rerun?",like failure flaky could anyone rerun,issue,negative,negative,negative,negative,negative,negative
1702225718,"I have tried launching it via both with and without Environments variables by directly passing the comma separated commands in ""Command"" field of docker configuration part in ECS task definition. But I am getting on NoCredentials issue. Do we need to pass AWS access keys in this proxified Scenario 5 when trying from local codebase to remote tracking URI. ?

[https://mlflow.org/docs/latest/tracking.html#scenario-5-mlflow-tracking-server-enabled-with-proxied-artifact-storage-access](url)

Does Mlflow has any feature where when I run mlflow on local codebase, the log files generated via it directly gets proxied through tracking_url to the S3 bucket behind it so that the client does not have to mention the AWS access keys for putting objects in S3.

Just to elaborate, my ECS task definition has port mapping from 5000 of container to 0 for host. The host is kept 0 because the ECS cluster service is running behind a target group of load balancer where it is running the tracking server on a fixed url like mlflow.mysite.com",tried via without directly passing comma command field docker configuration part task definition getting issue need pas access scenario trying local remote feature run local log via directly bucket behind client mention access elaborate task definition port container host host kept cluster service running behind target group load balancer running server fixed like,issue,negative,negative,neutral,neutral,negative,negative
1702121884,"> @akshaya-a #1348 is the PR that added `del MLFLOW_RUN_ID`. Have you already seen that?

Thanks for the pointer, not sure why git blame didn't occur to me! Indeed, I was thinking about adding a test for multiple start_runs (to ensure behavior through the removal) to check for regressions in behavior. My gut reaction is that Tomas was going after the right behavioral fix, but that with a differing precedence check (active stack > env) we can maintain the behavior without mutating os.env

When I get around to this I'll definitely take a closer look though

EDIT: To make it more clear I think the right approach is to stop mutating the env (which should be a cross process/start process communication mechanism versus intra-process communication) and fix the behavior elsewhere in logic no matter what.",added already seen thanks pointer sure git blame occur indeed thinking test multiple ensure behavior removal check behavior gut reaction going right behavioral fix precedence check active stack maintain behavior without get around definitely take closer look though edit make clear think right approach stop cross process communication mechanism versus communication fix behavior elsewhere logic matter,issue,positive,positive,positive,positive,positive,positive
1701991576,"Hi @hitmanagent298 Looks like there's a missing credential in your container, if it's configured by an environment variable you should make it available in the container.",hi like missing credential container environment variable make available container,issue,negative,positive,neutral,neutral,positive,positive
1701987762,"Hey @akshaya-a We do think this is a bug, feel free to raise a PR to fix it :D Thanks!",hey think bug feel free raise fix thanks,issue,positive,positive,positive,positive,positive,positive
1701805636,this has annoyed me as well! thanks @serena-ruan  you can assign it my way. @Gabriel2409 is this blocking you or a curiosity? Most AML customers end up using our ml.azure.com UI instead but I'm happy to dig into this if this is something useful for your use case - mostly looking to understand priority,well thanks assign way blocking curiosity end instead happy dig something useful use case mostly looking understand priority,issue,positive,positive,positive,positive,positive,positive
1701707749,"Thanks for the pointer, I'll give it a shot.",thanks pointer give shot,issue,negative,positive,positive,positive,positive,positive
1701458805,Hi @M4nouel sorry for the delay here. I'm going to pull your branch and do some local testing in order to validate compatibility. ,hi sorry delay going pull branch local testing order validate compatibility,issue,negative,negative,negative,negative,negative,negative
1701445213,"Can a quick test be added to ``mlflow/tests/store/artifact/test_http_artifact_repo.py`` that mocks the underlying fetch call to the artifact store to ensure that the correct uri is referenced with both the fluent and client APIs?

For inspiration, you can see the actual MLflowClient instance being mocked within ``mlflow/tests/store/artifact/test_unity_catalog_models_artifact_repo.py``, which would just need a slight adjustment with the mock patch to the underlying artifact repository call (just so that the resolution of which uri to use can be verified).",quick test added underlying fetch call artifact store ensure correct fluent client inspiration see actual instance within would need slight adjustment mock patch underlying artifact repository call resolution use,issue,negative,positive,neutral,neutral,positive,positive
1701245235,"Hi @tobiasraabe I don't think this is a bug, this is an expected behavior. When you log the model, you pass 'messages' field, and the model signature is inferred based on the messages. If only one valid variable exist, we set ModelSignature as `Schema([ColSpec(type=""string"")])` without a name, and when multiple variables are found we set schema inputs with names. When you do evaluation, the data passed in will be validated against the signature, so if you provide another column in the dataframe, we match the first one.",hi think bug behavior log model pas field model signature based one valid variable exist set schema string without name multiple found set schema evaluation data signature provide another column match first one,issue,negative,positive,positive,positive,positive,positive
1701080415,"1) how do we deal with the scenario when we have finetuned models on open ai, how do we call them? 2) how do we configure the rate limiting that you specified for every route(or for users using a route) 3)If  every application in the organization creates a seperate key for better tracking, how is the rate limit managed in the organization? ....... Can you please provide examples for the same?",deal scenario open ai call configure rate limiting every route route every application organization key better rate limit organization please provide,issue,positive,positive,positive,positive,positive,positive
1700900212,"Correct. The reason is that `HttpArtifactRepository` (`mlflow/store/artifact/mlflow_artifacts_repo.py`, line 45) is initialized with `get_tracking_uri()` without passing the tracking URI from the client.

See:
https://github.com/mlflow/mlflow/pull/9458/files#r1311517023",correct reason line without passing client see,issue,negative,neutral,neutral,neutral,neutral,neutral
1700783175,"This worked for me. If you are using local files either of the below solutions should work. Add this before `mlflow.start_run()` in your code.

```python
import mlflow

# Set the tracking URI to a local directory
mlflow.set_tracking_uri(""file:/path/to/your/local/directory"")

# OR
mlflow.set_tracking_uri(""http://127.0.0.1:5000"")
```",worked local either work add code python import set local directory file,issue,negative,neutral,neutral,neutral,neutral,neutral
1700615912,"@BenWilson2 Thanks for your response. I am just explaining again what I did.

I am using mysql as database which is running as a pod on remote server and minio as artifact storage. 
Now, If I use below code in my helm chart, then I am getting error that pymysql module is not installed in pod logs.
```
docker:
  image: ghcr.io/mlflow/mlflow
  pullPolicy: Always
  tag: v2.6.0
```
```
command: mlflow server --
host=0.0.0.0 --port=5000 --backend-store-uri=mysql+pymysql://xxx:xxxx@mysql-headless.auto
motive.svc.cluster.local:3306/xxx --gunicorn-opts=""--log-level warning"" --artifacts-destination=
s3://xxx.corp.xxxx.com:9000/x-artifxx --serve-artifacts --expose-prometheus=/mlflow/metrics
```

As suggested #8820 issue, To fix pymysql module issue, I am using below docker file and creating a custom image where pymysql is installed along with mlflow image. But, with this, I am seeing no logs are being generated in my pod logs and also,even not able to access mlflow UI.
```
Dockerfile
FROM ghcr.io/mlflow/mlflow:v2.6.0

RUN apt-get update && apt-get install -y procps && rm -rf /var/lib/apt/lists/*
RUN pip install PyMySQL
```
After build, I am using below code
```
docker:
  image: artifacts.corp.com/xxxx-xx-docker/mlflow
  pullPolicy: Always
  tag: v2.6.7
```
```  
command: mlflow server --
host=0.0.0.0 --port=5000 --backend-store-uri=mysql+pymysql://xxx:xxxx@mysql-headless.auto
motive.svc.cluster.local:3306/xxx --gunicorn-opts=""--log-level warning"" --artifacts-destination=
s3://xxx.corp.xxxx.com:9000/x-artifxx --serve-artifacts --expose-prometheus=/mlflow/metrics
```

Can you please help me here how this can be fixed now or what I need to do such that mlflow can be accessed easily.",thanks response explaining running pod remote server artifact storage use code helm chart getting error module pod docker image always tag command server warning issue fix module issue docker file custom image along image seeing pod also even able access run update install run pip install build code docker image always tag command server warning please help fixed need easily,issue,negative,positive,positive,positive,positive,positive
1700581633,"Hi @amesar, feel free to raise a PR to update the proto file (https://github.com/mlflow/mlflow/blob/035b43e1286bf7e5c6bd86162291412da4c84b56/mlflow/protos/model_registry.proto#L425) to be consistent with search_registered_method, I'll review it 😃  Thanks!",hi feel free raise update proto file consistent review thanks,issue,positive,positive,positive,positive,positive,positive
1700399278,"> @gabrielfu Thanks for the PR! Can we create a tiny example under `examples` for quick manual testing?

Sure!",thanks create tiny example quick manual testing sure,issue,positive,positive,positive,positive,positive,positive
1699989163,"> Looks great @shichengzhou-db ! Were you also able to test loading the model that you registered to R2 via e.g. `mlflow.pyfunc.load_model`?

yep loaded the model and did a prediction, works as expected (added this manual test code in the notebook shared with you earlier)",great also able test loading model registered via yep loaded model prediction work added manual test code notebook,issue,positive,positive,positive,positive,positive,positive
1699931658,@jerrylian-db FYI there were some gotchas we ran into (e.g. needing to use [virtual host style addressing](https://docs.aws.amazon.com/AmazonS3/latest/userguide/VirtualHosting.html)) to get reading/writing model artifacts to R2 to work using UC temporary credentials. You might want to work with Shicheng to test that R2 model read/write still work once you have a PR ready to refactor S3ArtifactRepo to share the fast upload/download logic in DatabricksArtifactRepo,ran needing use virtual host style get model work temporary might want work test model still work ready share fast logic,issue,positive,positive,positive,positive,positive,positive
1699853454,"So using the fluent API works, but the client API doesn't for this configuration scenario?",fluent work client configuration scenario,issue,negative,neutral,neutral,neutral,neutral,neutral
1699625172,"```bash
routes:

  - name: chat
    route_type: llm/v1/chat
    model:
      provider: openai
      name: gpt-4
      config:
        openai_api_base: https://api.openai.com/v1
        openai_api_key: $OPENAI_API_KEY

  - name: completions-openai
    route_type: llm/v1/completions
    model:
      provider: openai
      name: gpt-4
      config:
        openai_api_base: https://api.openai.com/v1
        openai_api_key: $OPENAI_API_KEY

  - name: completions-claude
    route_type: llm/v1/completions
    model:
      provider: anthropic
      name: claude-1.3-100k
      config:
        anthropic_api_base: https://api.anthropic.com/v1
        anthropic_api_key: $ANTHROPIC_API_KEY

  - name: completions-cohere
    route_type: llm/v1/completions
    model:
      provider: cohere
      name: command
      config:
        cohere_api_key: $COHERE_API_KEY

  - name: chat-mosaic
    route_type: llm/v1/chat
    model:
      provider: mosaicml
      name: llama2-70b-chat
      config:
        mosaicml_api_key: $MOSAICML_API_KEY

  - name: completions-mosaic
    route_type: llm/v1/completions
    model:
      provider: mosaicml
      name: llama2-70b-chat
      config:
        mosaicml_api_key: $MOSAICML_API_KEY

  - name: embeddings-mosaic
    route_type: llm/v1/embeddings
    model:
      provider: mosaicml
      name: instructor-xl
      config:
        mosaicml_api_key: $MOSAICML_API_KEY

  - name: embeddings-oss
    route_type: llm/v1/embeddings
    model:
      provider: mlflow-model-serving
      name: mini-lm-l6-v2
      config:
        model_server_url: http://127.0.0.1:9010

  - name: completions-oss
    route_type: llm/v1/completions
    model:
      provider: mlflow-model-serving
      name: emo-bert
      config:
        model_server_url: http://127.0.0.1:9020

  - name: bad-mosaic
    route_type: llm/v1/chat
    model:
      provider: mosaicml
      name: invalid
      config:
        mosaicml_api_key: $MOSAICML_API_KEY
```

Last entry is a bad config (chat route with invalid model name)

Auto-updating config with running server:

```shell
➜ mlflow gateway start --config-path ~/gateway/config.yaml --port 9100 --host localhost
[2023-08-29 19:09:18 -0400] [42656] [INFO] Starting gunicorn 20.1.0
[2023-08-29 19:09:18 -0400] [42656] [INFO] Listening at: http://127.0.0.1:9100 (42656)
[2023-08-29 19:09:18 -0400] [42656] [INFO] Using worker: uvicorn.workers.UvicornWorker
[2023-08-29 19:09:18 -0400] [42659] [INFO] Booting worker with pid: 42659
[2023-08-29 19:09:18 -0400] [42660] [INFO] Booting worker with pid: 42660
[2023-08-29 19:09:22 -0400] [42660] [INFO] Started server process [42660]
[2023-08-29 19:09:22 -0400] [42659] [INFO] Started server process [42659]
[2023-08-29 19:09:22 -0400] [42660] [INFO] Waiting for application startup.
[2023-08-29 19:09:22 -0400] [42659] [INFO] Waiting for application startup.
[2023-08-29 19:09:22 -0400] [42659] [INFO] Application startup complete.
[2023-08-29 19:09:22 -0400] [42660] [INFO] Application startup complete.
2023/08/30 14:00:49 INFO mlflow.gateway.runner: Configuration updated, reloading workers
[2023-08-30 14:00:49 -0400] [42659] [INFO] Shutting down
[2023-08-30 14:00:49 -0400] [42659] [INFO] Error while closing socket [Errno 9] Bad file descriptor
[2023-08-30 14:00:49 -0400] [42660] [INFO] Shutting down
[2023-08-30 14:00:49 -0400] [42660] [INFO] Error while closing socket [Errno 9] Bad file descriptor
[2023-08-30 14:00:49 -0400] [42659] [INFO] Waiting for application shutdown.
[2023-08-30 14:00:49 -0400] [42659] [INFO] Application shutdown complete.
[2023-08-30 14:00:49 -0400] [42659] [INFO] Finished server process [42659]
[2023-08-30 14:00:49 -0400] [42660] [INFO] Waiting for application shutdown.
[2023-08-30 14:00:49 -0400] [42660] [INFO] Application shutdown complete.
[2023-08-30 14:00:49 -0400] [42659] [INFO] Worker exiting (pid: 42659)
[2023-08-30 14:00:49 -0400] [42660] [INFO] Finished server process [42660]
[2023-08-30 14:00:49 -0400] [42660] [INFO] Worker exiting (pid: 42660)
[2023-08-30 14:00:50 -0400] [47231] [INFO] Booting worker with pid: 47231
[2023-08-30 14:00:50 -0400] [47232] [INFO] Booting worker with pid: 47232
[2023-08-30 14:00:51 -0400] [47232] [ERROR] Exception in worker process
Traceback (most recent call last):
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/gunicorn/arbiter.py"", line 589, in spawn_worker
    worker.init_process()
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/uvicorn/workers.py"", line 66, in init_process
    super(UvicornWorker, self).init_process()
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/gunicorn/workers/base.py"", line 134, in init_process
    self.load_wsgi()
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/gunicorn/workers/base.py"", line 146, in load_wsgi
    self.wsgi = self.app.wsgi()
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/gunicorn/app/base.py"", line 67, in wsgi
    self.callable = self.load()
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/gunicorn/app/wsgiapp.py"", line 58, in load
    return self.load_wsgiapp()
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/gunicorn/app/wsgiapp.py"", line 48, in load_wsgiapp
    return util.import_app(self.app_uri)
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/gunicorn/util.py"", line 412, in import_app
    app = app(*args, **kwargs)
  File ""/Users/benjamin.wilson/repos/mlflow-fork/mlflow/mlflow/gateway/app.py"", line 226, in create_app_from_env
    return create_app_from_path(config_path)
  File ""/Users/benjamin.wilson/repos/mlflow-fork/mlflow/mlflow/gateway/app.py"", line 217, in create_app_from_path
    config = _load_route_config(config_path)
  File ""/Users/benjamin.wilson/repos/mlflow-fork/mlflow/mlflow/gateway/config.py"", line 366, in _load_route_config
    return GatewayConfig(**configuration)
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/pydantic/main.py"", line 404, in __init__
    values, fields_set, validation_error = validate_model(__pydantic_self__.__class__, data)
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/pydantic/main.py"", line 1040, in validate_model
    v_, errors_ = field.validate(value, values, loc=field.alias, cls=cls_)
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/pydantic/fields.py"", line 734, in validate
    v, errors = self._validate_sequence_like(v, values, loc, cls)
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/pydantic/fields.py"", line 767, in _validate_sequence_like
    r, ee = self._validate_singleton(v_, values, v_loc, cls)
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/pydantic/fields.py"", line 899, in _validate_singleton
    value, error = field.validate(v, values, loc=loc, cls=cls)
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/pydantic/fields.py"", line 723, in validate
    v, errors = self._validate_singleton(v, values, loc, cls)
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/pydantic/fields.py"", line 906, in _validate_singleton
    return self._apply_validators(v, values, loc, cls, self.validators)
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/pydantic/fields.py"", line 913, in _apply_validators
    v = validator(cls, v, values, self, self.model_config)
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/pydantic/class_validators.py"", line 310, in <lambda>
    return lambda cls, v, values, field, config: validator(v)
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/pydantic/main.py"", line 735, in validate
    return cls(**value)
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/pydantic/main.py"", line 404, in __init__
    values, fields_set, validation_error = validate_model(__pydantic_self__.__class__, data)
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/pydantic/main.py"", line 1066, in validate_model
    values = validator(cls_, values)
  File ""/Users/benjamin.wilson/repos/mlflow-fork/mlflow/mlflow/gateway/config.py"", line 295, in validate_route_type_and_model_name
    raise MlflowException.invalid_parameter_value(
mlflow.exceptions.MlflowException: An invalid model has been specified for the chat route. 'invalid'. Ensure the model selected starts with one of: ['llama2']
[2023-08-30 14:00:51 -0400] [47231] [ERROR] Exception in worker process
Traceback (most recent call last):
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/gunicorn/arbiter.py"", line 589, in spawn_worker
    worker.init_process()
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/uvicorn/workers.py"", line 66, in init_process
    super(UvicornWorker, self).init_process()
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/gunicorn/workers/base.py"", line 134, in init_process
    self.load_wsgi()
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/gunicorn/workers/base.py"", line 146, in load_wsgi
    self.wsgi = self.app.wsgi()
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/gunicorn/app/base.py"", line 67, in wsgi
    self.callable = self.load()
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/gunicorn/app/wsgiapp.py"", line 58, in load
    return self.load_wsgiapp()
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/gunicorn/app/wsgiapp.py"", line 48, in load_wsgiapp
    return util.import_app(self.app_uri)
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/gunicorn/util.py"", line 412, in import_app
    app = app(*args, **kwargs)
  File ""/Users/benjamin.wilson/repos/mlflow-fork/mlflow/mlflow/gateway/app.py"", line 226, in create_app_from_env
    return create_app_from_path(config_path)
  File ""/Users/benjamin.wilson/repos/mlflow-fork/mlflow/mlflow/gateway/app.py"", line 217, in create_app_from_path
    config = _load_route_config(config_path)
  File ""/Users/benjamin.wilson/repos/mlflow-fork/mlflow/mlflow/gateway/config.py"", line 366, in _load_route_config
    return GatewayConfig(**configuration)
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/pydantic/main.py"", line 404, in __init__
    values, fields_set, validation_error = validate_model(__pydantic_self__.__class__, data)
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/pydantic/main.py"", line 1040, in validate_model
    v_, errors_ = field.validate(value, values, loc=field.alias, cls=cls_)
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/pydantic/fields.py"", line 734, in validate
    v, errors = self._validate_sequence_like(v, values, loc, cls)
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/pydantic/fields.py"", line 767, in _validate_sequence_like
    r, ee = self._validate_singleton(v_, values, v_loc, cls)
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/pydantic/fields.py"", line 899, in _validate_singleton
    value, error = field.validate(v, values, loc=loc, cls=cls)
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/pydantic/fields.py"", line 723, in validate
    v, errors = self._validate_singleton(v, values, loc, cls)
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/pydantic/fields.py"", line 906, in _validate_singleton
    return self._apply_validators(v, values, loc, cls, self.validators)
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/pydantic/fields.py"", line 913, in _apply_validators
    v = validator(cls, v, values, self, self.model_config)
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/pydantic/class_validators.py"", line 310, in <lambda>
    return lambda cls, v, values, field, config: validator(v)
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/pydantic/main.py"", line 735, in validate
    return cls(**value)
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/pydantic/main.py"", line 404, in __init__
    values, fields_set, validation_error = validate_model(__pydantic_self__.__class__, data)
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/pydantic/main.py"", line 1066, in validate_model
    values = validator(cls_, values)
  File ""/Users/benjamin.wilson/repos/mlflow-fork/mlflow/mlflow/gateway/config.py"", line 295, in validate_route_type_and_model_name
    raise MlflowException.invalid_parameter_value(
mlflow.exceptions.MlflowException: An invalid model has been specified for the chat route. 'invalid'. Ensure the model selected starts with one of: ['llama2']
[2023-08-30 14:00:51 -0400] [47232] [INFO] Worker exiting (pid: 47232)
[2023-08-30 14:00:51 -0400] [47231] [INFO] Worker exiting (pid: 47231)
Traceback (most recent call last):
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/gunicorn/arbiter.py"", line 209, in run
    self.sleep()
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/gunicorn/arbiter.py"", line 357, in sleep
    ready = select.select([self.PIPE[0]], [], [], 1.0)
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/gunicorn/arbiter.py"", line 242, in handle_chld
    self.reap_workers()
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/gunicorn/arbiter.py"", line 525, in reap_workers
    raise HaltServer(reason, self.WORKER_BOOT_ERROR)
gunicorn.errors.HaltServer: <HaltServer 'Worker failed to boot.' 3>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/runpy.py"", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/runpy.py"", line 87, in _run_code
    exec(code, run_globals)
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/gunicorn/__main__.py"", line 7, in <module>
    run()
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/gunicorn/app/wsgiapp.py"", line 67, in run
    WSGIApplication(""%(prog)s [OPTIONS] [APP_MODULE]"").run()
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/gunicorn/app/base.py"", line 231, in run
    super().run()
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/gunicorn/app/base.py"", line 72, in run
    Arbiter(self).run()
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/gunicorn/arbiter.py"", line 229, in run
    self.halt(reason=inst.reason, exit_status=inst.exit_status)
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/gunicorn/arbiter.py"", line 342, in halt
    self.stop()
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/gunicorn/arbiter.py"", line 393, in stop
    time.sleep(0.1)
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/gunicorn/arbiter.py"", line 242, in handle_chld
    self.reap_workers()
  File ""/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/gunicorn/arbiter.py"", line 525, in reap_workers
    raise HaltServer(reason, self.WORKER_BOOT_ERROR)
gunicorn.errors.HaltServer: <HaltServer 'Worker failed to boot.' 3>
```

Removed the invalid route entry and...

```shell
➜ mlflow gateway start --config-path ~/gateway/config.yaml --port 9100 --host localhost
[2023-08-30 14:06:00 -0400] [57189] [INFO] Starting gunicorn 20.1.0
[2023-08-30 14:06:00 -0400] [57189] [INFO] Listening at: http://127.0.0.1:9100 (57189)
[2023-08-30 14:06:00 -0400] [57189] [INFO] Using worker: uvicorn.workers.UvicornWorker
[2023-08-30 14:06:00 -0400] [57191] [INFO] Booting worker with pid: 57191
[2023-08-30 14:06:00 -0400] [57192] [INFO] Booting worker with pid: 57192
[2023-08-30 14:06:02 -0400] [57191] [INFO] Started server process [57191]
[2023-08-30 14:06:02 -0400] [57191] [INFO] Waiting for application startup.
[2023-08-30 14:06:02 -0400] [57191] [INFO] Application startup complete.
[2023-08-30 14:06:02 -0400] [57192] [INFO] Started server process [57192]
[2023-08-30 14:06:02 -0400] [57192] [INFO] Waiting for application startup.
[2023-08-30 14:06:02 -0400] [57192] [INFO] Application startup complete.
```
Good to go!",bash name chat model provider name name model provider name name model provider anthropic name name model provider cohere name command name model provider name name model provider name name model provider name name model provider name name model provider name name model provider name invalid last entry bad chat route invalid model name running server shell gateway start port host starting listening worker booting worker booting worker server process server process waiting application waiting application application complete application complete configuration shutting error socket bad file shutting error socket bad file waiting application shutdown application shutdown complete finished server process waiting application shutdown application shutdown complete worker finished server process worker booting worker booting worker error exception worker process recent call last file line file line super self file line file line file line file line load return file line return file line file line return file line file line return configuration file line data file line value file line validate file line file line value error file line validate file line return file line self file line lambda return lambda field file line validate return value file line data file line file line raise invalid model chat route ensure model selected one error exception worker process recent call last file line file line super self file line file line file line file line load return file line return file line file line return file line file line return configuration file line data file line value file line validate file line file line value error file line validate file line return file line self file line lambda return lambda field file line validate return value file line data file line file line raise invalid model chat route ensure model selected one worker worker recent call last file line run file line sleep ready file line file line raise reason boot handling exception another exception recent call last file line return code none file line code file line module run file line run prog file line run super file line run arbiter self file line run file line halt file line stop file line file line raise reason boot removed invalid route entry shell gateway start port host starting listening worker booting worker booting worker server process waiting application application complete server process waiting application application complete good go,issue,positive,positive,neutral,neutral,positive,positive
1699567675,"I would try ensuring that both of these libraries (and the required db installing of mysql or mariadb) all play nicely together in a docker container and that you can access the functionality that you need from that pristine environment. If there are no issues, then getting visibility into the pod build / start process is probably the best bet. ",would try play nicely together docker container access functionality need pristine environment getting visibility pod build start process probably best bet,issue,positive,positive,positive,positive,positive,positive
1699557066,"Hi @lu-ohai this is looking great! 
Can a basic (not anything too complex) usage example be added for this guiding users on how to utilize a common auth provider (this doesn't have to be in 'examples' (it would hard to make that runnable), but some general directives within a docs section on auth that show how to use the feature?",hi looking great basic anything complex usage example added utilize common provider would hard make runnable general within section show use feature,issue,positive,negative,neutral,neutral,negative,negative
1699541034,"One more thing, if I simply use mlflow 2.6.0 and deleting pymysql argument then mlflow is accessible but the important thing is we need pymysql argument. You can check my deployment.yaml.",one thing simply use argument accessible important thing need argument check,issue,negative,positive,positive,positive,positive,positive
1699538315,The problem is If I am directly (instead of creating custom image) using mlflow image i.e. version 2.x.x in my helm chart and then I am getting pymysql module not installed. And due to this reason I am creating custom image where I am installing pymysql  Module. Hence none of the version is working in our cluster.,problem directly instead custom image image version helm chart getting module due reason custom image module hence none version working cluster,issue,negative,negative,neutral,neutral,negative,negative
1699532292,"Does a previous version of MLflow install correctly? Say, 2.2.x?",previous version install correctly say,issue,negative,negative,negative,negative,negative,negative
1699530838,"@BenWilson2 Yes I have checker container logs but logs is displaying empty meaning no logs are getting generated and that's weird. 

I did kubectl port forward but getting empty reply.",yes checker container empty meaning getting weird port forward getting empty reply,issue,negative,negative,negative,negative,negative,negative
1699529497,Hi @xgdgsc could you add a few special reserved characters into this parametrized test so that we can be sure that those characters are preserved in the password? https://github.com/mlflow/mlflow/blob/42b2dcb45c52e6df58956851961f251493f245bf/tests/utils/test_credentials.py#L62-L71 ,hi could add special reserved test sure password,issue,positive,positive,positive,positive,positive,positive
1699523607,This seems like a nice quality of life improvement. Any objections @harupy ?,like nice quality life improvement,issue,positive,positive,positive,positive,positive,positive
1699510724,"Hi @dnerini sounds great! Thank you for volunteering! When pushing the PR, please add your repro code in the form of a unit test to ensure that autologging is correctly recording the fix :) Thanks!",hi great thank pushing please add code form unit test ensure correctly recording fix thanks,issue,positive,positive,positive,positive,positive,positive
1699506376,"Are you able to see the container logs running in the pod? Does anything stand out?
```bash
kubectl logs -f mlflow-76d8cb58c-phw95
```

Are you able to ping the running pod from the machine you're trying to access the UI from?",able see container running pod anything stand bash able ping running pod machine trying access,issue,negative,positive,positive,positive,positive,positive
1699025726,"ok, I had to disable foreign key checks, convert all tables to utf8mb4, readable checks and then alembic worked.
I'll leave the issue open if someone wants to make an improvement for other users, otherwise feel free to close it",disable foreign key convert table readable alembic worked leave issue open someone make improvement otherwise feel free close,issue,positive,positive,neutral,neutral,positive,positive
1698966902,"@harupy sir, I installed `pylint` and modified the `pylint_plugins/assign_checker.py` file with the given code and ran `pylint .`  It ran successfully but, I guess it is not removing the useless assignments, because no files are being changed/modified by running `pylint .` Is there anything that I might have missed?",sir file given code ran ran successfully guess removing useless running anything might,issue,negative,positive,positive,positive,positive,positive
1698941278,@gabrielfu Thanks for the PR! Can we create a tiny example under `examples` for quick manual testing?,thanks create tiny example quick manual testing,issue,positive,positive,positive,positive,positive,positive
1698919682,"The mysql error is pretty clear, searching in StackOverflow, one possible reason for this could be encodings
https://stackoverflow.com/questions/69960902/error-3780-referencing-column-and-referenced-column-in-foreign-key-constraint-a",error pretty clear searching one possible reason could,issue,negative,positive,positive,positive,positive,positive
1698578243,"Hi @BenWilson2 , I actually do use an absolute path in my server config. I just changed that for the example above.",hi actually use absolute path server example,issue,negative,positive,neutral,neutral,positive,positive
1698336818,"Hi @mgbckr is ``file://.`` a valid URI in all systems? 
Can you try to provide an absolute path in your server configuration and see if that functions correctly?",hi file valid try provide absolute path server configuration see correctly,issue,negative,positive,positive,positive,positive,positive
1698193119,"I managed to get it fixed by (in my setup):
* increasing the number of workers `--workers 20` (6 should be enough because it's exactly how many connections are allowed per domain in modern browsers, 20 for good measure). 
* switching to `eventlet`

It's worth noting that the root cause, at least in my setup,  has nothing to do with **mlflow** itself. I'm running it in Kubernetes (GKE) and in order to access it on my machine I'm using `kubectl port-forward`.  It looks like the way `kubectl` is proxying the requests exhausts all workers and since they are synchronous by default no new connections can be accepted. Supposedly port-forwarding isn't compatible with the `event` Gunicorn worker class. 

@here Could you describe your setup a bit, please? Are you using `kubectl port-forward` or anything similar to it?
",get fixed setup increasing number enough exactly many per domain modern good measure switching worth root cause least setup nothing running order access machine like way since synchronous default new accepted supposedly compatible event worker class could describe setup bit please anything similar,issue,positive,positive,positive,positive,positive,positive
1698013378,"![Screenshot 2023-08-29 at 3 29 13 PM](https://github.com/mlflow/mlflow/assets/39283302/8e2a0c50-7b35-43ff-ad44-6bb359647159)
Confirmed chat is working great!",confirmed chat working great,issue,positive,positive,positive,positive,positive,positive
1697926179,"Hello @BenWilson2, I just submitted a pr to extend this feature and would appreciate you taking a loot at it, thanks! https://github.com/mlflow/mlflow/pull/9460",hello extend feature would appreciate taking loot thanks,issue,positive,positive,positive,positive,positive,positive
1697833671,"As this issue is highly ranked when searching for ""`mlflowexception: the run must be in 'active' lifecycle_stage.`"", I've added another solution.

If the run has been deleted from the ui, but doesn't appear in `.trash`, you can manually edit the `meta.yaml` within the run folder (`mlruns/< UUID>/meta.yaml`) and change the value of the key `lifecycle_stage:` from `deleted` to `active`, this will then allow you to use `mlflow.end_run()`",issue highly ranked searching run must added another solution run appear manually edit within run folder change value key active allow use,issue,positive,positive,neutral,neutral,positive,positive
1697532568,"> @donour Could you fix linter error too ?

for sure!",could fix linter error sure,issue,negative,positive,positive,positive,positive,positive
1697002356,@donour Could you fix linter error too ?,could fix linter error,issue,negative,neutral,neutral,neutral,neutral,neutral
1696716622,When using the Client user tends to become unknown. While when using `with mlflow.start_run ` user  works.,client user become unknown user work,issue,negative,negative,neutral,neutral,negative,negative
1696716001,"> Hi @WeichenXu123 , saving and logging models seem to work by adding Peft imports to the transformers.py file. However, load_model still does not allow for PeftModels because in the `_load_model()` function, calling `getattr` on the transformers library causes an AttributeError when passing in a PeftModelForCausalLM. This is because it is not a module in the this huggingface [transformers file](https://github.com/huggingface/transformers/blob/686c68f64c9d0181bd54d4d2e2446543c3eca1fa/src/transformers/__init__.py). Do you have any ideas to work around this?

We can directly update `mlflow.transformers. _load_model` code for PEFT model case to make it work.",hi saving logging seem work file however still allow function calling library passing module file work around directly update code model case make work,issue,negative,positive,neutral,neutral,positive,positive
1696657514,"Hi @WeichenXu123 , saving and logging models seem to work by adding Peft imports to the transformers.py file. However, load_model still does not allow for PeftModels because in the `_load_model()` function, calling `getattr` on the transformers library causes an AttributeError when passing in a PeftModelForCausalLM. This is because it is not a module in the this huggingface [transformers file](https://github.com/huggingface/transformers/blob/686c68f64c9d0181bd54d4d2e2446543c3eca1fa/src/transformers/__init__.py). Do you have any ideas to work around this?",hi saving logging seem work file however still allow function calling library passing module file work around,issue,negative,neutral,neutral,neutral,neutral,neutral
1696561266,"Hi @work-mohit thank you for bringing this to our attention. If you'd like to introduce a more optimized build order of the dev requirements, please feel free to submit a PR. ",hi thank attention like introduce build order dev please feel free submit,issue,positive,positive,positive,positive,positive,positive
1695282764,"Hi all,

hoping that this feature request has not come to a standstill, I was wondering if there are news. I want my production model to be kept deployed in my staging environment. There, I'll have multiple models competing in a kind of shadow deployment. That's why having only one stage for a model is not working for me.",hi feature request come standstill wondering news want production model kept staging environment multiple kind shadow deployment one stage model working,issue,positive,positive,positive,positive,positive,positive
1695077775,"@AashishSainiShorthillsAI Thank you for the contribution! Could you fix the following issue(s)?

#### &#x26a0; PR branch check

This PR was filed from the master branch in your fork, which is not recommended and may cause our CI checks to fail. Please close this PR and file a new PR from a non-master branch.

#### &#x26a0; Invalid PR template

This PR does not appear to have been filed using the MLflow PR template. Please copy the PR template from [here](https://raw.githubusercontent.com/mlflow/mlflow/master/.github/pull_request_template.md) and fill it out.",thank contribution could fix following issue branch check master branch fork may cause fail please close file new branch invalid template appear template please copy template fill,issue,negative,negative,negative,negative,negative,negative
1694732030,"@nkaretnikov  I have installed the requirements through `dev-requirements.txt ` but haven't face any conflicts. But I do face issue in the time taken by. Since its finding the right package so basically its installing every package from minimum to higher available.
Also faced time out issues.
For that I think a new PR should be raised.  ",face face issue time taken since finding right package basically every package minimum higher available also faced time think new raised,issue,negative,positive,positive,positive,positive,positive
1694568150,"Verified in test shard that this makes feature store models work
<img width=""895"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/82044803/99357aed-a196-45ab-ad4a-f4eb0075d108"">
",test shard feature store work image,issue,negative,neutral,neutral,neutral,neutral,neutral
1694354447,"Note: this is my first PR to the project, apologies for any issues if any.

I was following https://mlflow.org/docs/latest/quickstart_mlops.html#run-a-hyperparameter-sweep and this failed for me:

```
mlflow run -e hyperopt .
```

I use a shared server with limited permissions for dev, so `pyenv` doesn't work there. I installed the deps myself and ran the above command with `local` env manager (expecting to bypass env setup):

```
mlflow run --env-manager=local -e hyperopt .
``` 

But it started fetching python anyway.

After looking at the code, I discovered that `examples/hyperparam/search_hyperopt.py` calls `mlflow.projects.run` without passing the env manager.

Since I don't want to patch every project that's written in a similar way, by passing the CLI param explicitly in `_run_entry_point`, I'm introducing a new env var, which I use for sharing the set value. It's set whenever env-manager is set and validated, so should always be consistent with user-supplied values.",note first project following run use server limited dev work ran command local manager bypass setup run fetching python anyway looking code discovered without passing manager since want patch every project written similar way passing param explicitly new use set value set whenever set always consistent,issue,negative,positive,neutral,neutral,positive,positive
1694083825,"MosaicML completions endpoint (Llama2-70B) validation test:

![Screenshot 2023-08-25 at 8 42 34 PM](https://github.com/mlflow/mlflow/assets/39283302/2e748e29-0592-4279-b93f-c8e9d73bca23)

MosaicML embeddings endpoint validation test:
![Screenshot 2023-08-25 at 8 42 53 PM](https://github.com/mlflow/mlflow/assets/39283302/20933140-9bd6-4f12-b2b4-27e31b70cf8e)
",validation test validation test,issue,negative,neutral,neutral,neutral,neutral,neutral
1693857143,Also the ``Model`` constructor will need to update the config allowance type here too: https://github.com/mlflow/mlflow/blob/6de6a63cb3edeb519dfbd7fd4fb49ec7d15ac911/mlflow/gateway/config.py#L194-L204 ,also model constructor need update allowance type,issue,negative,neutral,neutral,neutral,neutral,neutral
1693855963,"Don't forget to add the new provider to the ``config_types`` dict so that the key can be read (it's optional, but only for users) 

https://github.com/mlflow/mlflow/blob/6de6a63cb3edeb519dfbd7fd4fb49ec7d15ac911/mlflow/gateway/config.py#L144-L149",forget add new provider key read optional,issue,negative,positive,neutral,neutral,positive,positive
1693780098,I am also having this issue. -- perhaps a default would be helpful,also issue perhaps default would helpful,issue,negative,neutral,neutral,neutral,neutral,neutral
1693582802,"Could we add the integration test to be extra certain for future changes? Something similar to this?
Perhaps in the ``test_cli.py`` module?

```python
@pytest.mark.parametrize(
    [""input_schema"", ""output_schema"", ""params_schema""],
    [(True, False, False), (False, True, False), (False, False, True)],
)
def test_signature_enforcement_with_model_serving(input_schema, output_schema, params_schema):
    class MyModel(pyfunc.PythonModel):
        def predict(self, context, model_input, params=None):
            return [""test""]

    def setup_signature(input_schema, output_schema, params_schema):
        """"""Setup signature based on input, output and params schema.""""""
        input_data = [""testing""] if input_schema else None
        output_data = [""test""] if output_schema else None
        params = {""test"": ""test""} if params_schema else None

        return infer_signature(model_input=input_data, model_output=output_data, params=params)

    input_data = [""testing""]
    signature = setup_signature(input_schema, output_schema, params_schema)

    with mlflow.start_run():
        model_info = mlflow.pyfunc.log_model(
            artifact_path=""signature"", python_model=MyModel(), signature=signature
        )

    inference_payload = json.dumps({""inputs"": input_data})

    # Serve and score the model
    scoring_result = pyfunc_serve_and_score_model(
        model_uri=model_info.model_uri,
        data=inference_payload,
        content_type=pyfunc.scoring_server.CONTENT_TYPE_JSON,
        extra_args=[""--env-manager"", ""local""],
    )
    scoring_result.raise_for_status()

    # Assert the prediction result
    assert json.loads(scoring_result.content)[""predictions""] == [""test""]
 ```",could add integration test extra certain future something similar perhaps module python true false false false true false false false true class predict self context return test setup signature based input output schema testing else none test else none test test else none return testing signature signature serve score model local assert prediction result assert test,issue,positive,negative,neutral,neutral,negative,negative
1693342671,"@zeyueN yes, it will be in the 2.7.0 release which will hit pypi within the next 10 days or so. ",yes release hit within next day,issue,negative,neutral,neutral,neutral,neutral,neutral
1693241688,Is this going to make into a release anytime soon? ,going make release soon,issue,negative,neutral,neutral,neutral,neutral,neutral
1692798461,"@Hir98 Thanks for reporting the issue! 

Additionally if you haven't tried it, you can use Databricks Community Edition (free) to visualize your metrics instead of starting mlflow UI in colab. You can find a tutorial here, reading from the section ""Set up tracking/visualization tool"": https://github.com/mlflow/mlflow/blob/master/examples/transformers/MLFlow_X_HuggingFace_Finetune_a_text_classification_model.ipynb",thanks issue additionally tried use community edition free visualize metric instead starting find tutorial reading section set tool,issue,positive,positive,positive,positive,positive,positive
1692761412,"Verified locally:
Model signature only contains output:
<img width=""503"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/82044803/5fcf1b89-6473-47c8-aa63-93583f20f6c4"">
<img width=""903"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/82044803/3a5f8002-1809-4955-97a7-4bf33db5bd3b"">

Model signature only contains params:
<img width=""360"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/82044803/91bf69da-0410-41e8-8274-1e2449572342"">
<img width=""934"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/82044803/a078da5f-0da2-4fc2-9f66-67b8205e8e3c"">
",locally model signature output image image model signature image image,issue,negative,neutral,neutral,neutral,neutral,neutral
1692710516,"Hello @BenWilson2 , thank you for the response.

The main idea is to add new plugin to enable customizing `auth` in the http request. 

For vendors, they'll need to implement the plugin and add their own logic in it to build their `auth` object. 

For users, similar to AWS, they will need to install vendor's plugin and set some environment variable (`MLFLOW_TRACKING_AUTH`) to enable the injection of `auth` object. The value of the environment variable is subject to vendors. 

For example, to inject x vendor's auth, user's experience would be:

- Install x vendor's auth plugin
- Set the `MLFLOW_TRACKING_AUTH` environment variable in mlflow code
```
...
os.environ[""MLFLOW_TRACKING_AUTH""] = ""<x_vendors_auth_name>""

# other mlflow operations
...
```

We would also like to hear some suggestions from you, thanks!",hello thank response main idea add new enable request need implement add logic build object similar need install vendor set environment variable enable injection object value environment variable subject example inject vendor user experience would install vendor set environment variable code would also like hear thanks,issue,positive,positive,neutral,neutral,positive,positive
1692575199,"The fix for this will be coming very soon in Mlflow 2.7.0 :) 
Thanks for using the new feature! ",fix coming soon thanks new feature,issue,negative,positive,positive,positive,positive,positive
1692573195,"1. Admin creates username, system generates password (or admin) - temp
2. user users temp password to login
3. prompt user to change password
4. update password 

security flaw == solved",system password temp user temp password login prompt user change password update password security flaw,issue,negative,neutral,neutral,neutral,neutral,neutral
1692486963,Sounds great! Let us know when it's ready :) ,great let u know ready,issue,positive,positive,positive,positive,positive,positive
1692486469,Sorry for the oversight on this one. Should we define a default mapping to the provider type as well just to make sure that if a user doesn't define this that we won't have any failures?,sorry oversight one define default provider type well make sure user define wo,issue,negative,neutral,neutral,neutral,neutral,neutral
1692483803,We'll eagerly review the PR fix :) Just tag us when it's ready! ,eagerly review fix tag u ready,issue,positive,positive,positive,positive,positive,positive
1692479545,"Hi @sfc-gh-wzhao thank you for reporting this issue. Are you intending to default to ``2`` if the ``os.cpu_count()`` returns ``None`` from the ``Option[int]`` return from the call? 
It's interesting that Python can't effectively determine the cpu count from CentOS 7. 
Also, my condolences on the migration you'll have to do before next summer.",hi thank issue intending default none option return call interesting python ca effectively determine count also migration next summer,issue,positive,positive,positive,positive,positive,positive
1692457487,"Is it something like this?

```python

import numpy as np
import mlflow

array = np.asarray([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
dataset = mlflow.data.from_numpy(array, source=""data.csv"")

with mlflow.start_run():
    mlflow.log_input(dataset, context=None)
```",something like python import import array array,issue,negative,neutral,neutral,neutral,neutral,neutral
1692453533,Hi @tomgwasira can you provide a reproducible code example and a screenshot of the UI that displays the error that you're experiencing?,hi provide reproducible code example error,issue,negative,neutral,neutral,neutral,neutral,neutral
1692451329,"Unfortunately, these reserved characters are intentionally disallowed in order to provide a consistent, secure, and displayable metric or parameter key within the SDKs, tracking databases, and in the UI. We particularly do not wish to allow special characters that have reserved meanings with URL encodings (``[]()&?@*``)
Sorry for the inconvenience here!",unfortunately reserved intentionally order provide consistent secure displayable metric parameter key within particularly wish allow special reserved sorry inconvenience,issue,positive,positive,neutral,neutral,positive,positive
1692439419,"It looks like you're using a version of MLflow that is pretty recent, actually. This issue only exists in version 2.6.0 of MLflow. 
There are two options to workaround this:
1. pip install mlflow from the master branch 
2. pip install pydantic <2 

Either one should work to get around this issue. We're sorry for the inconvenience here! ",like version pretty recent actually issue version two pip install master branch pip install either one work get around issue sorry inconvenience,issue,negative,negative,neutral,neutral,negative,negative
1692432807,"Thank you for the FR idea and we'll gladly review your PR :) 
Do you have an idea of the mechanism from a user perspective that this would be set? ",thank idea gladly review idea mechanism user perspective would set,issue,positive,positive,positive,positive,positive,positive
1692378264,I think being able to rewrite some parameters is an important feature. Probably it should be enable only trough some additional warnings/flags ,think able rewrite important feature probably enable trough additional,issue,negative,positive,positive,positive,positive,positive
1692156864,"> Hi @clarkh-ncino could you rebase to master to address the merge conflicts (and then I can initiate the CI suite for you)

Should be good to go whenever you have a moment. 👍  @BenWilson2 ",hi could rebase master address merge initiate suite good go whenever moment,issue,negative,positive,positive,positive,positive,positive
1691533823,"Hey, can you assign this to me? I'd like to work on this",hey assign like work,issue,negative,neutral,neutral,neutral,neutral,neutral
1691399349,"1. I think my PR was flaky if I don't initialise the database at the start of each test, so I've just updated that.

2. Is the changelog/announcement sufficient? I realise there might be users who were reliant on the lack of thread safety of the existing API, e.g.

```
with mlflow.start_run():
    with ThreadPoolExecutor(max_workers=4) as executor:
        result = do_some_heavy_computation()
        mlflow.log_artifact(result)
```

Something like this will no longer work (you'd have to do some sort of `contextvars.copy_context()` at the start of each thread). So perhaps that needs more active shouting to make sure users are aware?",think flaky start test sufficient might reliant lack thread safety executor result result something like longer work sort start thread perhaps need active shouting make sure aware,issue,positive,positive,positive,positive,positive,positive
1690957027,Is there a way for this issue to get even higher priority? I don't really understand how people use MLflow given that this bug exists. Perhaps it's because most people aren't using the UI feature...,way issue get even higher priority really understand people use given bug perhaps people feature,issue,negative,positive,positive,positive,positive,positive
1690839402,"Some more context about the proposed workflow - Tensorboard is the native way of tracking for TF users, and the best practice is to use it with TensorboardCallback. To create a smooth migration experience for users, we can provide a MLflowCallback, like W&B.

Will share a colab tutorial soon to demonstrate, I am thinking about something like ""Quickstart with MLflow + Tensorflow Keras"" and ""Quickstart with MLflow + Multi-backend Keras"" 
",context native way best practice use create smooth migration experience provide like share tutorial soon demonstrate thinking something like,issue,positive,positive,positive,positive,positive,positive
1690815870,"My take is if we don't unblock this use case for users and document it clearly, most users won't bother trying this way or opening a features request.

Made a prototype and checked on colab, it worked fine: 
```
class MLflowCallback(keras.callbacks.Callback):
    def __init__(self, run_id, log_every_epoch=True, log_every_n_steps=None):
        self.metrics_logger = mlflow.utils.autologging_utils.BatchMetricsLogger(run_id)
        self.log_every_epoch = log_every_epoch
        self.log_every_n_steps = log_every_n_steps
        
    def on_train_begin(self, logs=None):
        config = self.model.optimizer.get_config()
        for attribute in config:
            mlflow.log_param(""opt_"" + attribute, config[attribute])

        sum_list = []
        self.model.summary(print_fn=sum_list.append)
        summary = ""\n"".join(sum_list)
        mlflow.log_text(summary, artifact_file=""model_summary.txt"")

    def on_epoch_end(self, epoch, logs=None):
        if not self.log_every_epoch:
            return
        self.metrics_logger.record_metrics(logs, epoch)

with mlflow.start_run() as run:
    run_id = run.info.run_id
    model.fit(x=train_ds, epochs=2, callbacks=[MLflowCallback(run_id)])
```",take unblock use case document clearly wo bother trying way opening request made prototype checked worked fine class self self attribute attribute attribute summary summary self epoch return epoch run,issue,negative,positive,positive,positive,positive,positive
1690769164,I'd consider making `__MLflowTfKeras2Callback` a public method if there is a feature request.,consider making public method feature request,issue,negative,neutral,neutral,neutral,neutral,neutral
1690576593,"> I've run into this error using `2.4.0` and the fix for me was to pass an additional `context` parameter to my predict method in my custom model class. I was already wrapping the original function signature properly.

I had the same issue with the same fix as mentioned by @andrewginns. 

",run error fix pas additional context parameter predict method custom model class already wrapping original function signature properly issue fix,issue,negative,positive,positive,positive,positive,positive
1690560296,@danilopeixoto I think the statistics endpoints is the direction that makes a lot of sense. Let's continue the discussion in the FR and we'll canvas for some additional feedback as well. Thanks again! ,think statistic direction lot sense let continue discussion canvas additional feedback well thanks,issue,positive,positive,positive,positive,positive,positive
1690520926,"@BenWilson2 I will close the pull request and continue the evaluation in #9206. The plugin should be feasible, however, getting simple counts from MLflow efficiently would still be a challenge because the application does not provide a `/statistics` endpoint such as in [GitLab Application Statistics API](https://docs.gitlab.com/ee/api/statistics.html) and the stores do not implement `statistics` contract. We could start from here.

I think with that, we could create a plugin or even a separated exporter to expose the statistics as Prometheus metrics.",close pull request continue evaluation feasible however getting simple efficiently would still challenge application provide application statistic implement statistic contract could start think could create even exporter expose statistic metric,issue,positive,neutral,neutral,neutral,neutral,neutral
1690435980,@mlflow/mlflow-team can mlflow team please help check this ?,team please help check,issue,positive,neutral,neutral,neutral,neutral,neutral
1690239211,"> Can we also add schema enforcement validation for this data structure to ensure that the expected inferred schema is validated properly by the model scoring server logic? We should also validate that this change works as expected with a local model serving instance (no need to add yet another test to transformers suite if we can write a validation test that the data validation works properly with schema enforcement)

Verified locally:
<img width=""978"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/82044803/cda04f0d-92b1-47c0-83c7-318b8f790c53"">
<img width=""1011"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/82044803/42a29cc9-0609-4bf6-8afc-8cbf6146efad"">
",also add schema enforcement validation data structure ensure schema properly model scoring server logic also validate change work local model serving instance need add yet another test suite write validation test data validation work properly schema enforcement locally image image,issue,positive,neutral,neutral,neutral,neutral,neutral
1690153372,"> Hi @SaravananSathyanandhaQC could you rebase to master so that we can resolve the FLAML errors and the merge conflicts, and allow us to kick off CI again to see the state of the branch?

Yep done!",hi could rebase master resolve merge allow u kick see state branch yep done,issue,positive,neutral,neutral,neutral,neutral,neutral
1690138734,"Hi @SaravananSathyanandhaQC could you rebase to master so that we can resolve the FLAML errors and the merge conflicts, and allow us to kick off CI again to see the state of the branch?",hi could rebase master resolve merge allow u kick see state branch,issue,positive,neutral,neutral,neutral,neutral,neutral
1690132377,I think raphaelauv has summarized it correctly.  I have further investigated our code base and in fact we build our own Docker  image of mlflow and so will change the base image there. Thanks for your responses,think correctly code base fact build docker image change base image thanks,issue,negative,negative,negative,negative,negative,negative
1690130260,Hi @clarkh-ncino could you rebase to master to address the merge conflicts (and then I can initiate the CI suite for you),hi could rebase master address merge initiate suite,issue,negative,neutral,neutral,neutral,neutral,neutral
1690118766,"Probably the request is more for the sake of using latest stable release

( like default python container for all versions are using bookworm) ",probably request sake latest stable release like default python container bookworm,issue,positive,positive,positive,positive,positive,positive
1690111036,"Guys, Currently I am trying to add a mlflow transition webhook in databricks. Can anyone please tell how can I trigger github actions yml file with the webhook?",currently trying add transition anyone please tell trigger file,issue,negative,neutral,neutral,neutral,neutral,neutral
1690109926,"I thought that the concern was for security flaws (CVEs) in the container OS (which is irrelevant based on the items I explained above)? 
Are there specific features that you're dependent on within the container environment that only exist in a newer version of DEBIAN? What additional logic are you applying within your serving container that necessitates a newer OS version?
I'm a bit confused about what is being asked here. ",thought concern security container o irrelevant based specific dependent within container environment exist version additional logic within serving container o version bit confused,issue,negative,negative,negative,negative,negative,negative
1690086932,"Hi @danilopeixoto we did some review of the approach here and we feel that this functionality would best be served as a plugin addition to MLflow (a standalone auxiliary feature set), rather than something that is mandatory to embed within endpoints. We would be very enthusiastic about having such a plugin featured within the documentation as a recommended endpoint addition to starting the servers, though! ",hi review approach feel functionality would best addition auxiliary feature set rather something mandatory embed within would enthusiastic featured within documentation addition starting though,issue,positive,positive,positive,positive,positive,positive
1690085870,"Debian 12 'Bookworm' comes with Linux kernel 6.1
Debian 11 'Bullseye' comes with Linux kernel 5.10

so main interest to bump version is using a new kernel linux version

",come kernel come kernel main interest bump version new kernel version,issue,negative,positive,positive,positive,positive,positive
1690023505,"Can we also add schema enforcement validation for this data structure to ensure that the expected inferred schema is validated properly by the model scoring server logic? 
We should also validate that this change works as expected with a local model serving instance (no need to add yet another test to transformers suite if we can write a validation test that the data validation works properly with schema enforcement)",also add schema enforcement validation data structure ensure schema properly model scoring server logic also validate change work local model serving instance need add yet another test suite write validation test data validation work properly schema enforcement,issue,positive,neutral,neutral,neutral,neutral,neutral
1689727736,"I've run into this error using `2.4.0` and the fix for me was to pass an additional `context` parameter to my predict method in my custom model class. I was already wrapping the original function signature properly.

Using @hmoon-drizly's example the fix looks like this:

```
class LinTSPolicy(mlflow.pyfunc.PythonModel):
    def predict(self, context, cluster_probabilites: np.array) -> List[ReturnClass]:
        ...
```
The call to predict on this custom model needs a modification to pass this context parameter as `None`
`LinTSPolicy.predict(None, cluster_probabilities)`

I don't see any mention of this additional `context` parameter in the MLflow 2.4.2 docs https://mlflow.org/docs/2.4.2/_modules/mlflow/pyfunc.html#PyFuncModel.predict",run error fix pas additional context parameter predict method custom model class already wrapping original function signature properly example fix like class predict self context list call predict custom model need modification pas context parameter none none see mention additional context parameter,issue,negative,positive,positive,positive,positive,positive
1689671286,"@alvarogracia 
Hello,
I solved the issue by updating the version in the `alembic_version` table (in mlflow.db file) to the expected version. There's an explanation on how to do it [here](https://stackoverflow.com/questions/32311366/alembic-util-command-error-cant-find-identifier).
Just make sure to keep a copy of your mlflow.db file before editing it.",hello issue version table file version explanation make sure keep copy file,issue,negative,positive,positive,positive,positive,positive
1689589283,@asysuev Can you provide a minimum python code that can log a model that can reproduce this error?,provide minimum python code log model reproduce error,issue,negative,neutral,neutral,neutral,neutral,neutral
1689572275,"If I expand stack trace
```Reducers.ts:420 Uncaught (in promise) TypeError: Cannot read properties of undefined (reading 'sklearn_model_pipeline_45')
    at Reducers.ts:420:45
    at Array.forEach (<anonymous>)
    at artifactsByRunUuid (Reducers.ts:419:19)
    at redux.js:528:29
    at redux.js:528:29
    at v (redux.js:288:22)
    at index.js:82:26
    at index.js:11:16
    at dispatch (redux.js:659:28)
    at index.js:171:11
(anonymous) @ Reducers.ts:420
artifactsByRunUuid @ Reducers.ts:419
(anonymous) @ redux.js:528
(anonymous) @ redux.js:528
v @ redux.js:288
(anonymous) @ index.js:82
(anonymous) @ index.js:11
dispatch @ redux.js:659
(anonymous) @ index.js:171
await in (anonymous) (async)
componentDidMount @ ArtifactPage.tsx:114
vs @ react-dom.production.min.js:219
Pl @ react-dom.production.min.js:259
t.unstable_runWithPriority @ scheduler.production.min.js:18
Wo @ react-dom.production.min.js:122
Il @ react-dom.production.min.js:252
bl @ react-dom.production.min.js:243
(anonymous) @ react-dom.production.min.js:123
t.unstable_runWithPriority @ scheduler.production.min.js:18
Wo @ react-dom.production.min.js:122
$o @ react-dom.production.min.js:123
Ko @ react-dom.production.min.js:122
wl @ react-dom.production.min.js:244
notify @ Subscription.js:15
notifyNestedSubs @ Subscription.js:85
o @ Subscription.js:90
v @ redux.js:296
(anonymous) @ index.js:82
(anonymous) @ index.js:11
dispatch @ redux.js:659
(anonymous) @ index.js:171
Promise.then (async)
(anonymous) @ index.js:191
(anonymous) @ index.js:11
n.<computed> @ bindActionCreators.js:9
componentDidMount @ RunPage.tsx:45
vs @ react-dom.production.min.js:219
Pl @ react-dom.production.min.js:259
t.unstable_runWithPriority @ scheduler.production.min.js:18
Wo @ react-dom.production.min.js:122
Il @ react-dom.production.min.js:252
bl @ react-dom.production.min.js:243
(anonymous) @ react-dom.production.min.js:123
t.unstable_runWithPriority @ scheduler.production.min.js:18
Wo @ react-dom.production.min.js:122
$o @ react-dom.production.min.js:123
Ko @ react-dom.production.min.js:122
Pe @ react-dom.production.min.js:292
$t @ react-dom.production.min.js:73
```
<img width=""572"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/4270880/eb2412fe-f9e1-44c6-b2e3-383be459be02"">

No other errors there",expand stack trace uncaught promise read undefined reading anonymous dispatch anonymous anonymous anonymous anonymous anonymous dispatch anonymous await anonymous wo anonymous wo ko notify anonymous anonymous dispatch anonymous anonymous anonymous wo anonymous wo ko image,issue,positive,neutral,neutral,neutral,neutral,neutral
1689520214,"@barrywhart I think GBAC would be our direction for now. Please feel free to contribute if you have time, it is most welcomed :) ",think would direction please feel free contribute time,issue,positive,positive,positive,positive,positive,positive
1689515902,"@barrywhart thanks a lot for the PR and sorry for the delay. I have left a few comments, feel free to let us know what you think :)",thanks lot sorry delay left feel free let u know think,issue,positive,positive,neutral,neutral,positive,positive
1689368708,"I don't think you can do that with the MLProject file. Afaik it does not allow you to specify an environment variable _before_ processing your conda env file.

You can however obviously export your variable first then execute your commands:

```
> export MLFLOW_CONDA_CREATE_ENV_CMD=mamba
> mlflow command1
> mlflow command2
```

although I am not sure this covers your use case.",think file allow specify environment variable file however obviously export variable first execute export command command although sure use case,issue,negative,positive,positive,positive,positive,positive
1689228598,"Hi, I got exactly same issue.

I believe these error are largely rooted from the heterogeneous design of auth db config.

To be specific, why we have to set an `.ini` file and pointing it using `MLFLOW_AUTH_CONFIG_PATH` is required, whereas all existing DB related configs, `--backend-store-uri` and `--registry-store-uri` are simply passing an URI as arguments?

Just like what `--registry-store-uri` did, introducing something like `--auth-store-uri` (and use `--backend-store-uri` by default) would make it much less error-prone because we can share the same codebase.

https://github.com/mlflow/mlflow/blob/304ca3d2598dee681b311ad6add85c7b51f482fe/mlflow/cli.py#L292-L300",hi got exactly issue believe error largely rooted heterogeneous design specific set file pointing whereas related simply passing like something like use default would make much le share,issue,positive,positive,positive,positive,positive,positive
1689216383,"I checked again, I think 1.6/1.7 package is not changed and `torch/utils/_pytree` module never exists in these versions. I think it is because transformer package upgraded and it removes supporting for torch 1.6/1.7 @harupy ",checked think package module never think transformer package supporting torch,issue,negative,positive,positive,positive,positive,positive
1689209447,"> @WeichenXu123 Looks like `torch/utils/_pytree.py` still exists:
> 
> https://github.com/pytorch/pytorch/blob/main/torch/utils/_pytree.py

But in torch 1.6 / 1.7 the module disappears. you can install it and test.",like still torch module install test,issue,negative,neutral,neutral,neutral,neutral,neutral
1689157692,"Question: for List[str], should we still use ColSpec('string') like in the test case?",question list still use like test case,issue,negative,neutral,neutral,neutral,neutral,neutral
1689113305,"````python
from __future__ import annotations

import ast
import os
import random
import subprocess
import textwrap

import openai


class DocstringVisitor(ast.NodeVisitor):
    def __init__(self):
        self.docstring_nodes = []

    def visit_FunctionDef(self, node: ast.FunctionDef):
        if (
            node.body
            and isinstance(node.body[0], ast.Expr)
            and isinstance(node.body[0].value, ast.Str)
            and "":param"" in node.body[0].value.s
            and not node.name.startswith(""_"")
        ):
            self.docstring_nodes.append(node.body[0].value)


def transform(docstring: str) -> str:
    res = openai.ChatCompletion.create(
        model=""gpt-4"",
        messages=[
            {
                ""role"": ""user"",
                ""content"": f""""""
Hi GPT4, I'd like you to rewrite python docstrings in a more readable format. Here's an example:

# Before

```python
    \""\""\""
    This is a docstring

    :param artifact_path: The run-relative path to which to log model artifacts.
    :param custom_objects: A Keras ``custom_objects`` dictionary mapping names (strings) to
                           custom classes or functions associated with the Keras model. MLflow saves
                           ...
    :return: This is a return value.
    ...a
    \""\""\""
```

# After (similar to google docstrings, but no need to add types)

```python
    \""\""\""
    This is a docstring

    Args:
        artifact_path: The run-relative path to which to log model artifacts.
        custom_objects: A Keras ``custom_objects`` dictionary mapping names (strings)
            to custom classes or functions associated with the Keras model. MLflow saves
            ...
    Returns:
        This is a return value.
    ...
    \""\""\""
```

# Transformation Rules:

- Be sure to prserve the indentation of the original docstring.
- Be sure to preserve the quotes of the original docstring.
- Be sure to avoid the line length exceeding 100 characters.
- Be sure to only update the parameters and returns sections.
- The Returns section should is optional. If the original docstring doesn't have
  ':return:' or ':returns:' entries, then don't add a 'Returns' section.
- Be sure to use the following format for the new docstring:

  ```python
  {{new_docstring}}
  ```

Given these rules, can you rewrite the following docstring? Thanks for your help!

```python
{docstring}
```
"""""",
            }
        ],
    )
    return res.choices[0].message.content


def node_to_char_range(docstring_node: ast.Str, line_lengths: list[int]) -> tuple[int, int]:
    start = sum(line_lengths[: docstring_node.lineno - 1]) + docstring_node.col_offset
    node_length = (
        (line_lengths[docstring_node.lineno - 1] - docstring_node.col_offset)
        + sum(line_lengths[docstring_node.lineno : docstring_node.end_lineno - 1])
        + docstring_node.end_col_offset
    )
    return start, start + node_length


def extract_code(s: str) -> str | None:
    import re

    if m := re.search(r""```python\n(.*)```"", s, re.DOTALL):
        return m.group(1)
    return None


def format_code(code: str, indent: str, opening_quote: str, closing_quote: str) -> str:
    code = code.strip().lstrip('r""\n').rstrip('"" \n')
    code = textwrap.dedent(code)
    code = textwrap.indent(code, indent)
    code = f""{opening_quote}\n{code}\n{indent}{closing_quote}""
    return code


def leading_quote(s: str) -> str:
    for idx, c in enumerate(s):
        if c not in (""'"", '""', ""f"", ""r""):
            return s[:idx]
    raise ValueError(""No leading quote found"")


def trailing_quote(s: str) -> str:
    for idx, c in enumerate(s[::-1]):
        if c not in (""'"", '""'):
            return s[-idx:]
    raise ValueError(""No leading quote found"")


def main():
    assert ""OPENAI_API_KEY"" in os.environ

    py_files = subprocess.check_output([""git"", ""ls-files"", ""mlflow/*.py""]).decode().splitlines()
    random.shuffle(py_files)
    for py_file in py_files:
        with open(py_file) as f:
            src = f.read()

        tree = ast.parse(src)
        visitor = DocstringVisitor()
        visitor.visit(tree)

        if not visitor.docstring_nodes:
            continue

        lines = src.splitlines(keepends=True)
        line_lengths = list(map(len, lines))
        new_src = str(src)
        offset = 0
        for node in visitor.docstring_nodes:
            print(f""Transforming {py_file}:{node.lineno}:{node.col_offset + 1}"")
            start, end = node_to_char_range(node, line_lengths)
            indent = "" "" * node.col_offset
            original = src[start:end]
            transformed = transform(indent + original)
            code = extract_code(transformed)
            if code is None:
                continue

            code = format_code(
                code,
                indent,
                leading_quote(original),
                trailing_quote(original),
            )
            original_length = end - start
            new_src = new_src[: (start + offset)] + code + new_src[(end + offset) :]
            offset += len(code) - original_length
            with open(py_file, ""w"") as f:
                f.write(new_src)


if __name__ == ""__main__"":
    main()
````",python import import ast import o import random import import import class self self node param transform role user content hi like rewrite python readable format example python param path log model param dictionary custom class associated model return return value similar need add python path log model dictionary custom class associated model return value transformation sure indentation original sure preserve original sure avoid line length exceeding sure update section optional original return add section sure use following format new python given rewrite following thanks help python return list start sum sum return start start none import return return none code indent code code code code code indent code code indent return code enumerate return raise leading quote found enumerate return raise leading quote found main assert git open tree visitor tree continue list map offset node print transforming start end node indent original start end transform indent original code code none continue code code indent original original end start start offset code end offset offset code open main,issue,positive,positive,positive,positive,positive,positive
1689032777,"@BenWilson2 thanks, I've raised a very simple PR. I'll check back later to see which tests have failed/passed. Let me know whether you have some conventions that you need me to follow. I tried to keep this as contained as possible.",thanks raised simple check back later see let know whether need follow tried keep possible,issue,negative,positive,neutral,neutral,positive,positive
1688911517,"Hi @Hir98 feel free to use the discussions forum for questions about what you can and can't do with MLflow: https://github.com/mlflow/mlflow/discussions . The Issues section of GitHub is for requesting features or reporting bugs. I think you'll get some creative answers from asking the community and some of the clever things that they've managed to do! 
Thank you for using MLflow :) ",hi feel free use forum ca section think get creative community clever thank,issue,positive,positive,positive,positive,positive,positive
1688907422,"Hi @dgriff67, Which CVE's were you concerned with in the LTS version of DEBIAN that is included in the image ``ubuntu:20.04`` that is included with the DockerFile template? 
As part of the build process, these images immediately run ``apt-get -y update``, which will fetch any security CVE fixes that have been applied as patches to the LTS version that is used. Based on Ubuntu and DEBIAN's track record, most CVE's are patched within 24 hours. 
Are your containers old and are getting flagged because they've not been updated to fix reported CVE's? If that is the case, updating to a different LTS won't fix that issue. The way to address that is to rebuild your containers and deploy them on some regular frequency. 

Could you provide more context to this request please?",hi concerned version included image included template part build process immediately run update fetch security applied version used based track record within old getting fix case different wo fix issue way address rebuild deploy regular frequency could provide context request please,issue,positive,positive,neutral,neutral,positive,positive
1688877448,"Hi @jasonharris438 thanks for reporting! This is the PostgreSQL incompatibility with numpy types issue, right? 
We appreciate you volunteering for a fix! Please tag this Issue with your filed PR when you're ready to submit!",hi thanks incompatibility issue right appreciate fix please tag issue ready submit,issue,positive,positive,positive,positive,positive,positive
1688750708,@dean-sh has the right workaround.  Essentially just make sure the tracking db points to anything other than its default location.   --backend-store-uri  mysql+pymysql://root@localhost/mlflow_tracking_database.  Otherwise it seems to have a conflict over that route being used.  ,right essentially make sure anything default location otherwise conflict route used,issue,negative,positive,positive,positive,positive,positive
1688644175,This bug is causing me a lot of pain. What's the recommended workaround?,bug causing lot pain,issue,negative,neutral,neutral,neutral,neutral,neutral
1688295315,"@barrywhart Sorry for the delay, I will take a look tomorrow :)",sorry delay take look tomorrow,issue,negative,negative,negative,negative,negative,negative
1688282066,"@harupy: Do you think you'll have time to review this soon? It's been 3 weeks since I created it. If we can get this one approved and merged, there are other contributions I would like to make as well.

Thanks!",think time review soon since get one would like make well thanks,issue,positive,positive,positive,positive,positive,positive
1688151773,"@harupy okay, is there any workaround for this issue, where I can use the version 2.4 and somehow escape this conflict. I would like to use the mlflow.data api for logging the data information but that is not available in version below 2.4. It would be great if you could think of some way to workaround this. I would really appreciate!",issue use version somehow escape conflict would like use logging data information available version would great could think way would really appreciate,issue,positive,positive,positive,positive,positive,positive
1688042338,@adheer-d I think 2.7 will include a patch for this issue (assuming this issue is fixable and a solution will be found soon).,think include patch issue assuming issue fixable solution found soon,issue,negative,neutral,neutral,neutral,neutral,neutral
1687780296,"I'm still getting this issue on MLFlow 2.6.0 (which seems to have #9209 integrated) when trying to log a HF model without specifying `conda_env`. It asks for Torchvision and then for Tensorflow. Seems to be coming from the default Pip requirements.

```
model = transformers.AutoModelForSequenceClassification.from_pretrained('albert-base-v2')
tokeniser = transformers.AutoTokenizer.from_pretrained('albert-base-v2')

mlflow.set_experiment('Deployment Template Testing')
mlflow.start_run(run_name='Transformers Model')
mlflow.transformers.log_model(transformers_model={'model': model, 'tokenizer': tokeniser}, artifact_path='model')
```",still getting issue trying log model without coming default pip model template testing model model,issue,negative,neutral,neutral,neutral,neutral,neutral
1687642288,"Hello, From what I tested It is compatible with 1.4.19 for sure, didn't test on older ones, don't really know up to which version I should check",hello tested compatible sure test older really know version check,issue,negative,positive,positive,positive,positive,positive
1687594395,"1. downloading the model in models artifacts directory:
<img width=""902"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/82044803/da0cb263-4016-40fb-931a-97222edada5b"">
<img width=""1117"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/82044803/48d57d8b-1d4d-488d-b9df-5b6eb21b38a4"">
<img width=""1244"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/82044803/6886521c-e801-4bab-ba83-8668dae8634a"">
",model directory image image image,issue,negative,neutral,neutral,neutral,neutral,neutral
1687089181,@BenWilson2 The only difference between the libraries installed between the two containers is the version of mlflow.  It was tested with only that difference.  But I know that a number of additional libraries get installed automatically in the container environment.  I wouldn't expect these to differ though.,difference two version tested difference know number additional get automatically container environment would expect differ though,issue,negative,neutral,neutral,neutral,neutral,neutral
1686802950,Hi @nfarley-soaren would you happen to have the diff of libraries being installed between the two container versions? Are there libraries being included in the containers that are definitely not required in order to serve your model type? ,hi would happen two container included definitely order serve model type,issue,negative,neutral,neutral,neutral,neutral,neutral
1686767245,"Hi @jinholee-makinarocks thank you for using the transformers flavor in MLflow. Unfortunately, at this time, we don't provide support for the ``optimum`` package from huggingface. 
In order to support the different backend implementations of each model that the ``optimum`` package provides, significant changes will need to be made to the logging logic and the component loader to ensure that the appropriate deserialization module is selected. 
As this isn't a bug, I'm going to modify this to a Feature Request and we will monitor community feedback to determine if there is a large demand for enabling this functionality. ",hi thank flavor unfortunately time provide support optimum package order support different model optimum package significant need made logging logic component loader ensure appropriate module selected bug going modify feature request monitor community feedback determine large demand functionality,issue,positive,positive,positive,positive,positive,positive
1686713254,Is this configuration change compatible with older versions of SQLAlchemy or does version validation logic need to be introduced?,configuration change compatible older version validation logic need,issue,negative,positive,positive,positive,positive,positive
1686711252,"Hi @aloahPGF thank you for reporting this issue. If you're still interested in filing a PR to fix this configuration issue, we will happily review it. ",hi thank issue still interested filing fix configuration issue happily review,issue,positive,positive,positive,positive,positive,positive
1686417700,"@serena-ruan the only feature set associated with this approach should be the first element that you mentioned. This is only for users who just want to log, register, and deploy a pre-trained model directly from the hub. With the architecture defined and this special option called, we fetch directly from the hub into the model (each component of the pipeline) artifact directory directly, bypassing loading to the cache location. 
One way to avoid the download to the cache is to specify ``local_dir_use_symlinks=False`` in the writing logic during each of the component elements saving with a ``local_dir`` specified when calling ``huggingface_hub.hf_hub_download()``. 
In order to prevent a download iff the version already exists in the local system cache, we can use ``huggingface_hub.try_to_load_from_cache()`` to prevent a download (it will instead return the path to the file in the local cache from which the directory can be copied directly). 
I do not think that we should be moving files, though. 
We'll need to be clear in the docs and examples about what this feature is for (logging a model that a user effectively doesn't want to store a local version in their cache) and how it isn't much of a time saver if a user wants to test out the model / components / pipeline locally. ",feature set associated approach first element want log register deploy model directly hub architecture defined special option fetch directly hub model component pipeline artifact directory directly loading cache location one way avoid cache specify writing logic component saving calling order prevent version already local system cache use prevent instead return path file local cache directory copied directly think moving though need clear feature logging model user effectively want store local version cache much time saver user test model pipeline locally,issue,positive,positive,positive,positive,positive,positive
1686331597,"This PR seems to solve the following error reported in #9360:

```
TypeError: Couldn't build proto file into descriptor pool: duplicate file name databricks.proto
```

but a new error is found:

```
>>> from databricks_registry_webhooks import RegistryWebhooksClient, JobSpec, HttpUrlSpec
>>> import mlflow
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/haru/Desktop/repositories/mlflow/mlflow/__init__.py"", line 42, in <module>
    from mlflow import projects  # noqa: F401
  File ""/home/haru/Desktop/repositories/mlflow/mlflow/projects/__init__.py"", line 9, in <module>
    import mlflow.projects.databricks
  File ""/home/haru/Desktop/repositories/mlflow/mlflow/projects/databricks.py"", line 11, in <module>
    from mlflow import tracking
  File ""/home/haru/Desktop/repositories/mlflow/mlflow/tracking/__init__.py"", line 8, in <module>
    from mlflow.tracking.client import MlflowClient
  File ""/home/haru/Desktop/repositories/mlflow/mlflow/tracking/client.py"", line 17, in <module>
    from mlflow.entities import Experiment, Run, Param, Metric, RunTag, FileInfo, ViewType, DatasetInput
  File ""/home/haru/Desktop/repositories/mlflow/mlflow/entities/__init__.py"", line 6, in <module>
    from mlflow.entities.experiment import Experiment
  File ""/home/haru/Desktop/repositories/mlflow/mlflow/entities/experiment.py"", line 2, in <module>
    from mlflow.entities.experiment_tag import ExperimentTag
  File ""/home/haru/Desktop/repositories/mlflow/mlflow/entities/experiment_tag.py"", line 2, in <module>
    from mlflow.protos.service_pb2 import ExperimentTag as ProtoExperimentTag
  File ""/home/haru/Desktop/repositories/mlflow/mlflow/protos/service_pb2.py"", line 18, in <module>
    from mlflow.protos.scalapb import scalapb_pb2 as mlflow_dot_protos_dot_scalapb_dot_scalapb__pb2
  File ""/home/haru/Desktop/repositories/mlflow/mlflow/protos/scalapb/scalapb_pb2.py"", line 18, in <module>
    DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n#mlflow/protos/scalapb/scalapb.proto\x12\x07scalapb\x1a google/protobuf/descriptor.proto\""L\n\x0eScalaPbOptions\x12\x14\n\x0cpackage_name\x18\x01 \x01(\t\x12\x14\n\x0c\x66lat_package\x18\x02 \x01(\x08\x12\x0e\n\x06import\x18\x03 \x03(\t\""!\n\x0eMessageOptions\x12\x0f\n\x07\x65xtends\x18\x01 \x03(\t\""\x1c\n\x0c\x46ieldOptions\x12\x0c\n\x04type\x18\x01 \x01(\t:G\n\x07options\x12\x1c.google.protobuf.FileOptions\x18\xfc\x07 \x01(\x0b\x32\x17.scalapb.ScalaPbOptions:J\n\x07message\x12\x1f.google.protobuf.MessageOptions\x18\xfc\x07 \x01(\x0b\x32\x17.scalapb.MessageOptions:D\n\x05\x66ield\x12\x1d.google.protobuf.FieldOptions\x18\xfc\x07 \x01(\x0b\x32\x15.scalapb.FieldOptionsB\x1e\n\x1corg.mlflow.scalapb_interface')
TypeError: Couldn't build proto file into descriptor pool: duplicate symbol 'scalapb.options'
```

I think we need to fix `databricks_registry_webhooks` as well.",solve following error could build proto file pool duplicate file name new error found import import recent call last file line module file line module import file line module import file line module import file line module import file line module import experiment run param metric file line module import experiment file line module import file line module import file line module import file line module could build proto file pool duplicate symbol think need fix well,issue,negative,positive,neutral,neutral,positive,positive
1686129169,If MLFlow is considered as an alternative to text logs analysis so precise metrics comparison is a critical thing. Especially weird thing is that UI rounds them to upper value so my reported `1.13751139` visualized as `1.138`.,considered alternative text analysis precise metric comparison critical thing especially weird thing upper value,issue,negative,negative,negative,negative,negative,negative
1685995000,@giacomov i'd like to use this `MLFLOW_CONDA_CREATE_ENV_CMD` env var to use `micromamba` for setting up environments. i'm just a bit confused as to where the `MLFLOW_CONDA_CREATE_ENV_CMD` env var should be set. i don't want to always have to do `MLFLOW_CONDA_CREATE_ENV_CMD=micromamba mlflow [...]` but instead specify within the `MLproject` config file to always use `micromamba`. what's the right way to achieve that? thanks a lot for this PR btw! sorry for bumping up. maybe i'll add documentation about this because it's inexistant in the official mlflow doc.,like use use setting bit confused set want always instead specify within file always use right way achieve thanks lot sorry bumping maybe add documentation official doc,issue,negative,negative,negative,negative,negative,negative
1685545555,"> A bit concerned about the approach here. We seem to be enabling users to save models where the file dependencies are not contained in the model directory. E.g. if I call `mlflow.pyfunc.save_model()` with a snapshot dependency and then upload with `mlflow.log_artifact()`, the uploaded model won't be usable because the snapshot dependency isn't part of the model directory and wouldn't have been uploaded.
> 
> @BenWilson2 @serena-ruan I was imagining another approach where we enable users to download the snapshot directly to the model directory when `mlflow.pyfunc.log_model()` is called, e.g. by passing
> 
> ```
> artifacts={
>     ""my_hf_model"": ""huggingface:/...""
> }
> ```
> 
> or something comparable, where MLflow recognizes this special artifact scheme and knows how to download the snapshot directly.
> 
> Another notable limitation of the current approach is that it only supports one snapshot per MLflow model, which may be unsuitable for ensemble use cases

I'm a little bit confused, `artifacts={""my_hf_model"": ""huggingface:/...""}`this means if users want to log a huggingface model, they should not create the model first, but instead logging the id of the model into artifacts directly? Then the downloading model process is triggered by mlflow.log_model because we resolve the path of 'huggingface:/...' and then download the model into model artifacts directory. 
But if users already have the model in local, what we should do is avoid downloading it twice so we should move the content in the existing downloaded location to the model artifact directory, then in this case we should let them specify the downloaded location instead of a schema like 'huggingface:/...' to redownload the model?",bit concerned approach seem save file model directory call snapshot dependency model wo usable snapshot dependency part model directory would another approach enable snapshot directly model directory passing something comparable special artifact scheme snapshot directly another notable limitation current approach one snapshot per model may unsuitable ensemble use little bit confused want log model create model first instead logging id model directly model process triggered resolve path model model directory already model local avoid twice move content location model artifact directory case let specify location instead schema like model,issue,positive,positive,neutral,neutral,positive,positive
1685530188,"@chenmoneygithub Once https://github.com/mlflow/mlflow/pull/9390 is merged, can you merge the master branch (or rebase)? That should enable formatting on notebooks.",merge master branch rebase enable,issue,negative,neutral,neutral,neutral,neutral,neutral
1685422463,Can this be fixed for local MLflow experiments? I feel that it shouldn't be this slow. ,fixed local feel slow,issue,negative,negative,neutral,neutral,negative,negative
1685175330,"Hi @WeichenXu123,
This is not ready. Could you provide feedback in the current state?",hi ready could provide feedback current state,issue,negative,positive,neutral,neutral,positive,positive
1684462327,"> A follow-on for this... could a test be added that validates the correct behavior within the windows CI suite? (Something very simple that involves validating the issue that you found in the filing of #9278)

@BenWilson2 Added the test - let me know what you think :)",could test added correct behavior within suite something simple issue found filing added test let know think,issue,negative,neutral,neutral,neutral,neutral,neutral
1684318553,"Also sorted the import order using `isort` package, and moved `import numpy/pandas` to top with a `try` block to avoid duplicated imports. ",also sorted import order package import top try block avoid,issue,negative,positive,positive,positive,positive,positive
1684271931,"Hi,

I was having the same issue (""Access denied for user"").

Debugging, I have seen the following in mlflow source code:

File: mlflow/mlflow/server/auth/db/utils.py
Line: 31

`alembic_cfg = _get_alembic_config(str(engine.url))`

**engine.url** is obfuscating the password (""***""), which leads to an authentication error:

![Screenshot from 2023-08-18 19-37-56](https://github.com/mlflow/mlflow/assets/88538531/d0597f04-0a5f-4f3c-93b7-13f3fa347f83)

However, by ""fixing"" the connection URL at that point, it works. As for instance:

`alembic_cfg = _get_alembic_config(str(engine.url).replace(""***"", os.environ.get(""DB_PASS"")))`

(I have created an environment variable ""DB_PASS"" to store the password).

Obviously there must be better solutions.

EDIT: 

based on https://docs.sqlalchemy.org/en/20/changelog/whatsnew_20.html#str-engine-url-will-obfuscate-the-password-by-default, the issue can be fixed by using 'engine.url.render_as_string(hide_password=False)' :

`alembic_cfg = _get_alembic_config(engine.url.render_as_string(hide_password=False))`
",hi issue access user seen following source code file line password authentication error however fixing connection point work instance environment variable store password obviously must better edit based issue fixed,issue,negative,positive,positive,positive,positive,positive
1684104338,"When building a model for model serving, the resolution of the hub repository is failing. 
``An error occurred while loading the model. Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/tmp/bert-tiny'. Use `repo_type` argument if needed..``

Do we need to add fallback logic to ensure that if the snapshot location cannot be resolved that we fetch the model? 
With the current implementation, when loading in a different environment, the components of the base pipeline cannot be found (as they are looking for the local snapshot directory which is only present in the original environment that was used for logging). 

Serving build failure reports the error message only:

``An error occurred while loading the model. Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/tmp/bert-tiny'. Use `repo_type` argument if needed..``

While loading as pyfunc from a different environment gives a bit more insight into what is going on (the tokenizer load stage cannot resolve a local path that doesn't exist):

```sh
HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/tmp/bert-tiny'. Use `repo_type` argument if needed.
---------------------------------------------------------------------------
HFValidationError                         Traceback (most recent call last)
File <command-3159396656015369>:2
      1 # loaded_pyfunc_model = mlflow.pyfunc.load_model(model_uri=pyfunc_model_uri)
----> 2 loaded_pyfunc_model = mlflow.pyfunc.load_model(model_uri=""dbfs:/databricks/mlflow-tracking/3159396656015360/edaa28ec924948359a329712e4589443/artifacts/question_answering_model"")

File /local_disk0/.ephemeral_nfs/envs/pythonEnv-5d5bb896-e863-4e4f-a816-a9c6c53541ae/lib/python3.10/site-packages/mlflow/pyfunc/__init__.py:630, in load_model(model_uri, suppress_warnings, dst_path)
    628 _add_code_from_conf_to_system_path(local_path, conf, code_key=CODE)
    629 data_path = os.path.join(local_path, conf[DATA]) if (DATA in conf) else local_path
--> 630 model_impl = importlib.import_module(conf[MAIN])._load_pyfunc(data_path)
    631 predict_fn = conf.get(""predict_fn"", ""predict"")
    632 return PyFuncModel(model_meta=model_meta, model_impl=model_impl, predict_fn=predict_fn)

File /local_disk0/.ephemeral_nfs/envs/pythonEnv-5d5bb896-e863-4e4f-a816-a9c6c53541ae/lib/python3.10/site-packages/mlflow/pyfunc/model.py:342, in _load_pyfunc(model_path)
    337     artifacts[saved_artifact_name] = os.path.join(
    338         model_path, saved_artifact_info[CONFIG_KEY_ARTIFACT_RELATIVE_PATH]
    339     )
    341 context = PythonModelContext(artifacts=artifacts)
--> 342 python_model.load_context(context=context)
    343 signature = mlflow.models.Model.load(model_path).signature
    344 return _PythonModelPyfuncWrapper(
    345     python_model=python_model, context=context, signature=signature
    346 )

File /root/.ipykernel/64369/command-3159396656015368-2533779477:14, in load_context(self, context)

File /local_disk0/.ephemeral_nfs/envs/pythonEnv-5d5bb896-e863-4e4f-a816-a9c6c53541ae/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:652, in AutoTokenizer.from_pretrained(cls, pretrained_model_name_or_path, *inputs, **kwargs)
    649     return tokenizer_class.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)
    651 # Next, let's try to use the tokenizer_config file to get the tokenizer class.
--> 652 tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
    653 if ""_commit_hash"" in tokenizer_config:
    654     kwargs[""_commit_hash""] = tokenizer_config[""_commit_hash""]

File /local_disk0/.ephemeral_nfs/envs/pythonEnv-5d5bb896-e863-4e4f-a816-a9c6c53541ae/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:496, in get_tokenizer_config(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, **kwargs)
    434 """"""
    435 Loads the tokenizer configuration from a pretrained model tokenizer configuration.
    436 
   (...)
    493 tokenizer_config = get_tokenizer_config(""tokenizer-test"")
    494 ```""""""
    495 commit_hash = kwargs.get(""_commit_hash"", None)
--> 496 resolved_config_file = cached_file(
    497     pretrained_model_name_or_path,
    498     TOKENIZER_CONFIG_FILE,
    499     cache_dir=cache_dir,
    500     force_download=force_download,
    501     resume_download=resume_download,
    502     proxies=proxies,
    503     use_auth_token=use_auth_token,
    504     revision=revision,
    505     local_files_only=local_files_only,
    506     subfolder=subfolder,
    507     _raise_exceptions_for_missing_entries=False,
    508     _raise_exceptions_for_connection_errors=False,
    509     _commit_hash=commit_hash,
    510 )
    511 if resolved_config_file is None:
    512     logger.info(""Could not locate the tokenizer configuration file, will try to use the model config instead."")

File /local_disk0/.ephemeral_nfs/envs/pythonEnv-5d5bb896-e863-4e4f-a816-a9c6c53541ae/lib/python3.10/site-packages/transformers/utils/hub.py:417, in cached_file(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)
    414 user_agent = http_user_agent(user_agent)
    415 try:
    416     # Load from URL or cache if already cached
--> 417     resolved_file = hf_hub_download(
    418         path_or_repo_id,
    419         filename,
    420         subfolder=None if len(subfolder) == 0 else subfolder,
    421         repo_type=repo_type,
    422         revision=revision,
    423         cache_dir=cache_dir,
    424         user_agent=user_agent,
    425         force_download=force_download,
    426         proxies=proxies,
    427         resume_download=resume_download,
    428         use_auth_token=use_auth_token,
    429         local_files_only=local_files_only,
    430     )
    432 except RepositoryNotFoundError:
    433     raise EnvironmentError(
    434         f""{path_or_repo_id} is not a local folder and is not a valid model identifier ""
    435         ""listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to ""
    436         ""pass a token having permission to this repo with `use_auth_token` or log in with ""
    437         ""`huggingface-cli login` and pass `use_auth_token=True`.""
    438     )

File /local_disk0/.ephemeral_nfs/envs/pythonEnv-5d5bb896-e863-4e4f-a816-a9c6c53541ae/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:110, in validate_hf_hub_args.<locals>._inner_fn(*args, **kwargs)
    105 for arg_name, arg_value in chain(
    106     zip(signature.parameters, args),  # Args values
    107     kwargs.items(),  # Kwargs values
    108 ):
    109     if arg_name in [""repo_id"", ""from_id"", ""to_id""]:
--> 110         validate_repo_id(arg_value)
    112     elif arg_name == ""token"" and arg_value is not None:
    113         has_token = True

File /local_disk0/.ephemeral_nfs/envs/pythonEnv-5d5bb896-e863-4e4f-a816-a9c6c53541ae/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:158, in validate_repo_id(repo_id)
    155     raise HFValidationError(f""Repo id must be a string, not {type(repo_id)}: '{repo_id}'."")
    157 if repo_id.count(""/"") > 1:
--> 158     raise HFValidationError(
    159         ""Repo id must be in the form 'repo_name' or 'namespace/repo_name':""
    160         f"" '{repo_id}'. Use `repo_type` argument if needed.""
    161     )
    163 if not REPO_ID_REGEX.match(repo_id):
    164     raise HFValidationError(
    165         ""Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are""
    166         "" forbidden, '-' and '.' cannot start or end the name, max length is 96:""
    167         f"" '{repo_id}'.""
    168     )
```",building model model serving resolution hub repository failing error loading model id must form use argument need add fallback logic ensure snapshot location resolved fetch model current implementation loading different environment base pipeline found looking local snapshot directory present original environment used logging serving build failure error message error loading model id must form use argument loading different environment bit insight going load stage resolve local path exist sh id must form use argument recent call last file file data data else main predict return file context signature return file self context file return next let try use file get class file revision configuration model configuration none none could locate configuration file try use model instead file revision try load cache already else except raise local folder valid model identifier listed private repository make sure pas token permission log login pas file chain zip token none true file raise id must string type raise id must form use argument raise id must use forbidden start end name length,issue,negative,positive,neutral,neutral,positive,positive
1683884459,@saidattu2003 Thanks for the PR! Can I push a commit? There are a couple files I want fix in this PR.,thanks push commit couple want fix,issue,positive,positive,positive,positive,positive,positive
1683856101,"> my program is trying to deal with different region buckets.

Does setting `AWS_DEFAULT_REGION` work or not? Just curious if there is a workaround to set the region.",program trying deal different region setting work curious set region,issue,negative,negative,neutral,neutral,negative,negative
1683852879,"Hi [harupy](https://github.com/harupy),

I have deployed the mlflow server using the docker container where I have provided the region details in env files, but still, somehow mlflow couldn't able to pick the details from region-related env value. ",hi server docker container provided region still somehow could able pick value,issue,negative,positive,positive,positive,positive,positive
1683846461,"> 

Yes exactly, I have gone through the code, and it should provide an option to take the bucket region, because ~/.aws/config is global to the host, and in my case, my program is trying to deal with different region buckets. ",yes exactly gone code provide option take bucket region global host case program trying deal different region,issue,negative,positive,neutral,neutral,positive,positive
1683842342,"> @lokeish Can you upload a file without any issues using only boto3?

``` 
import boto3

# Replace these with your own credentials and bucket name
aws_access_key_id = 'xxx'
aws_secret_access_key = 'xxx'
bucket_name = 'doc-mlflow'

local_file = '/home/lokeish/Documents/exp_details.json'  # Path to the local file you want to upload
destination_key = 'uploaded-file_11.txt'  


# Create an S3 client
s3_client = boto3.client(
    's3',
    aws_access_key_id=aws_access_key_id,
    aws_secret_access_key=aws_secret_access_key
)


def upload_file_with_put_object(bucket_name, local_file, destination_key):
    try:
        with open(local_file, 'rb') as f:
            s3_client.put_object(Bucket=bucket_name, Key=destination_key, Body=f)
        print(f""File '{local_file}' uploaded as '{destination_key}' to '{bucket_name}'"")
    except Exception as e:
        print(""Error:"", e)


def list_files_in_bucket(bucket_name):
    response = s3_client.list_objects_v2(Bucket=bucket_name)

    if 'Contents' in response:
        for obj in response['Contents']:
            print(obj['Key'])
    else:
        print(""Bucket is empty or no objects found."")

# List files in the bucket
list_files_in_bucket(bucket_name)
upload_file_with_put_object(bucket_name, local_file, destination_key)
```",file without import replace bucket name path local file want create client try open print file except exception print error response response response print else print bucket empty found list bucket,issue,negative,negative,neutral,neutral,negative,negative
1683841462,"> ~/.aws/config

I have verified from my end,  in the ~/.aws/config the default region is nothing, but here is a catch, i tried with the normal boto3 python program to upload to ap-southeast-2 region bucket, and the upload is successful but the same thing is getting failed from the mlflow side.",end default region nothing catch tried normal python program region bucket successful thing getting side,issue,positive,positive,positive,positive,positive,positive
1683831126,"> @lokeish Can you try specifying the region in `~/.aws/config`? https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.html

The region is ap-southeast-2, Yes I have provided the config related to the region and other s3 details via env values. Without changing any code I have changed my bucket location to us-east-1, then mlflow is logging artifacts without any issue.",try region region yes provided related region via without code bucket location logging without issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1683779670,@Increshi Can you post a comment so that I can assign this issue to you?,post comment assign issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1683602289,"@harupy It's weird because if pagination is not supported, you won't receive all the results beyond the max_results limit when there are more results available.",weird pagination wo receive beyond limit available,issue,negative,negative,neutral,neutral,negative,negative
1683552048,"It looks like this is not a bug, but model version search doesn't support pagination. The OSS backend supports pagination but Databricks backend doesn't seem to.",like bug model version search support pagination pagination seem,issue,positive,neutral,neutral,neutral,neutral,neutral
1683541496,"Hi @ggeop, I was able to reproduce the issue. Could be a bug in our backend implementation. We'll keep you posted.",hi able reproduce issue could bug implementation keep posted,issue,negative,positive,positive,positive,positive,positive
1683504057,"Hi @BenWilson2! Thanks for your quick response! Your example code has the behaviour I expect to have, if the `max_results` is higher or equal the register models the token will be None otherwise you have more results to get and it should be returned a token. I tested also your code, and in the case of `client.search_model_versions(max_results=1).token` the token is None :-( On the other hand the `client.search_model_versions(max_results=1).token` is working as expected..

In my case, the MLflow server is not managed by me; it is managed by Databricks. I conduct all my tests in a Databricks workspace. What additional information do you need from me to escalate this issue?",hi thanks quick response example code behaviour expect higher equal register token none otherwise get returned token tested also code case token none hand working case server conduct additional information need escalate issue,issue,negative,positive,positive,positive,positive,positive
1683336153,"@dbczumar thanks for the context! I will keep this issue open for future investigation on how to reduce the restriction from mlflow-skinny. 

Low priority for now.",thanks context keep issue open future investigation reduce restriction low priority,issue,negative,positive,neutral,neutral,positive,positive
1683149005,Can you let us know what backend tracking service you're using? ,let u know service,issue,negative,neutral,neutral,neutral,neutral,neutral
1683133610,"Hi @ggeop , the continuation token for Case #1 should be none. There's nothing left to fetch as the list is exhausted, so there isn't a token to generate. This is working as designed and I confirmed on current master branch as well. 

Here is the repro I used (with FileStore as my tracking backend):

```python
import mlflow
import time

client = mlflow.MlflowClient()

client.search_registered_models()
```
```sh
[]
```
Created some registered models... 
```python
names = [f""ModelVer{i:03}"" for i in range(101)]

for name in names:
  client.create_registered_model(name)

model_versions = []
for name in names + names[:10]:
  time.sleep(0.001)
  model_versions.append(client.create_model_version(name, ""runs:/run_id_model"", ""run_id""))
```

Search with ``search_model_versions``
```python
client.search_model_versions(max_results=500).token
```
```sh
None
```
```python
client.search_model_versions(max_results=1).token
```
```sh
b'eyJvZmZzZXQiOiAxfQ=='
```
```python
client.search_registered_models(max_results=500).token
```
```sh
None
```
```python
client.search_registered_models(max_results=1).token
```
```sh
b'eyJvZmZzZXQiOiAxfQ=='
```",hi continuation token case none nothing left fetch list exhausted token generate working designed confirmed current master branch well used python import import time client sh registered python range name name name name search python sh none python sh python sh none python sh,issue,negative,neutral,neutral,neutral,neutral,neutral
1683099058,Can this please be reopened/put on the agenda? This would be very useful...,please agenda would useful,issue,positive,positive,positive,positive,positive,positive
1683043602,pandas and numpy are deliberately excluded from skinny to meet customer requirements for MLflow on Microsoft AzureML,deliberately skinny meet customer,issue,negative,neutral,neutral,neutral,neutral,neutral
1682978555,"For example, #9355 is failing the skinny test because I moved `import numpy` up to the module level.",example failing skinny test import module level,issue,negative,neutral,neutral,neutral,neutral,neutral
1682762090,Will the fix make it into the next release?,fix make next release,issue,negative,neutral,neutral,neutral,neutral,neutral
1682442245,"@Dev-98 Thanks for the PR, I pushed a commit to clean up unrelated commits :)",thanks commit clean unrelated,issue,positive,positive,positive,positive,positive,positive
1682396764,"It does limit the scalability of the UI generally. It's mostly future proofing for the number of experiments growing over time. So not directly blocked at the moment. Once there's around 10k experiments, that's where it starts presenting.",limit generally mostly future proofing number growing time directly blocked moment around,issue,negative,positive,neutral,neutral,positive,positive
1682368036,"Can we add a pyfunc local serving test to one (not both) of the added tests to validate that loading the pyfunc model with ""snapshot"" location works for the serving container?

(a manual test for Model Serving with this save mode is worthwhile to validate as well :) )",add local serving test one added validate loading model snapshot location work serving container manual test model serving save mode validate well,issue,positive,neutral,neutral,neutral,neutral,neutral
1682308625,"@jmahlik Is this still a blocker on your side? Sadly we can't prioritize fixing this issue at the moment, but it will be on our radar.",still blocker side sadly ca fixing issue moment radar,issue,negative,negative,negative,negative,negative,negative
1682226160,@gabrielfu: Is this PR something you'd be willing to review? I think you authored the original HTTP basic auth feature. This PR generalizes it to support other methods for getting the user's identity (e.g. other HTTP headers).,something willing review think original basic feature support getting user identity,issue,positive,positive,positive,positive,positive,positive
1682203487,"> https://github.com/mlflow/mlflow/blob/master/mlflow/transformers.py#L1470

I think this makes sense, we can check the passed in model class type in `mlflow.transformers.save_model`",think sense check model class type,issue,negative,neutral,neutral,neutral,neutral,neutral
1682173416,@harupy please review this and let me know if I need to change anything.,please review let know need change anything,issue,negative,neutral,neutral,neutral,neutral,neutral
1682132976,@harupy I have tried this suggestion as well which is somehow related to our issue and it still fails with the same error https://github.com/ValvePython/csgo/issues/8#issuecomment-296345877,tried suggestion well somehow related issue still error,issue,negative,neutral,neutral,neutral,neutral,neutral
1682077011,The version that was used to compile proto may matter.,version used compile proto may matter,issue,negative,neutral,neutral,neutral,neutral,neutral
1682065301,"https://github.com/mlflow/mlflow/pull/8158 may be the cause. Here's what I found

```python
# The ^^^ part is the same between MLflow 2.3.0 and `databricks_registry_webhooks`

DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'...')
                                                            ^^^
```",may cause found python part,issue,negative,neutral,neutral,neutral,neutral,neutral
1682024237,"Any update?
I'm trying to serve mlflow model using mlserver, `mlflow models serve -m runs:/df738f66448047aca9a6a2e8c6982ed9/model --enable-mlserver` and getting the exact same error.
My server is running with this config:
```
mlflow server \
   --backend-store-uri  mysql+pymysql://root@localhost/mlflow_tracking_database \
   --default-artifact-root  file:/./mlruns \
   -h 0.0.0.0 -p 5000
  ```",update trying serve model serve getting exact error server running server file,issue,negative,positive,positive,positive,positive,positive
1681996946,"Full traceback:

```
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python3.8/site-packages/databricks_registry_webhooks/__init__.py"", line 1, in <module>
    from databricks_registry_webhooks.client import RegistryWebhooksClient
  File ""/usr/local/lib/python3.8/site-packages/databricks_registry_webhooks/client.py"", line 3, in <module>
    from databricks_registry_webhooks.entities import (
  File ""/usr/local/lib/python3.8/site-packages/databricks_registry_webhooks/entities/__init__.py"", line 1, in <module>
    from databricks_registry_webhooks.entities.job_spec import JobSpec
  File ""/usr/local/lib/python3.8/site-packages/databricks_registry_webhooks/entities/job_spec.py"", line 2, in <module>
    from databricks_registry_webhooks.protos.webhooks_pb2 import JobSpec as ProtoJobSpec
  File ""/usr/local/lib/python3.8/site-packages/databricks_registry_webhooks/protos/webhooks_pb2.py"", line 19, in <module>
    from . import databricks_pb2 as databricks__pb2
  File ""/usr/local/lib/python3.8/site-packages/databricks_registry_webhooks/protos/databricks_pb2.py"", line 20, in <module>
    DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x10\x64\x61tabricks.proto\x12\x06mlflow\x1a google/protobuf/descriptor.proto\x1a\x15scalapb/scalapb.proto\""\xcd\x01\n\x14\x44\x61tabricksRpcOptions\x12\'\n\tendpoints\x18\x01 \x03(\x0b\x32\x14.mlflow.HttpEndpoint\x12&\n\nvisibility\x18\x02 \x01(\x0e\x32\x12.mlflow.Visibility\x12&\n\x0b\x65rror_codes\x18\x03 \x03(\x0e\x32\x11.mlflow.ErrorCode\x12%\n\nrate_limit\x18\x04 \x01(\x0b\x32\x11.mlflow.RateLimit\x12\x15\n\rrpc_doc_title\x18\x05 \x01(\t\""U\n\x0cHttpEndpoint\x12\x14\n\x06method\x18\x01 \x01(\t:\x04POST\x12\x0c\n\x04path\x18\x02 \x01(\t\x12!\n\x05since\x18\x03 \x01(\x0b\x32\x12.mlflow.ApiVersion\""*\n\nApiVersion\x12\r\n\x05major\x18\x01 \x01(\x05\x12\r\n\x05minor\x18\x02 \x01(\x05\""@\n\tRateLimit\x12\x11\n\tmax_burst\x18\x01 \x01(\x03\x12 \n\x18max_sustained_per_second\x18\x02 \x01(\x03\""\x93\x01\n\x15\x44ocumentationMetadata\x12\x11\n\tdocstring\x18\x01 \x01(\t\x12\x10\n\x08lead_doc\x18\x02 \x01(\t\x12&\n\nvisibility\x18\x03 \x01(\x0e\x32\x12.mlflow.Visibility\x12\x1b\n\x13original_proto_path\x18\x04 \x03(\t\x12\x10\n\x08position\x18\x05 \x01(\x05\""n\n\x1f\x44\x61tabricksServiceExceptionProto\x12%\n\nerror_code\x18\x01 \x01(\x0e\x32\x11.mlflow.ErrorCode\x12\x0f\n\x07message\x18\x02 \x01(\t\x12\x13\n\x0bstack_trace\x18\x03 \x01(\t*?\n\nVisibility\x12\n\n\x06PUBLIC\x10\x01\x12\x0c\n\x08INTERNAL\x10\x02\x12\x17\n\x13PUBLIC_UNDOCUMENTED\x10\x03*\xf6\x04\n\tErrorCode\x12\x12\n\x0eINTERNAL_ERROR\x10\x01\x12\x1b\n\x17TEMPORARILY_UNAVAILABLE\x10\x02\x12\x0c\n\x08IO_ERROR\x10\x03\x12\x0f\n\x0b\x42\x41\x44_REQUEST\x10\x04\x12\x1c\n\x17INVALID_PARAMETER_VALUE\x10\xe8\x07\x12\x17\n\x12\x45NDPOINT_NOT_FOUND\x10\xe9\x07\x12\x16\n\x11MALFORMED_REQUEST\x10\xea\x07\x12\x12\n\rINVALID_STATE\x10\xeb\x07\x12\x16\n\x11PERMISSION_DENIED\x10\xec\x07\x12\x15\n\x10\x46\x45\x41TURE_DISABLED\x10\xed\x07\x12\x1a\n\x15\x43USTOMER_UNAUTHORIZED\x10\xee\x07\x12\x1b\n\x16REQUEST_LIMIT_EXCEEDED\x10\xef\x07\x12\x1d\n\x18INVALID_STATE_TRANSITION\x10\xd1\x0f\x12\x1b\n\x16\x43OULD_NOT_ACQUIRE_LOCK\x10\xd2\x0f\x12\x1c\n\x17RESOURCE_ALREADY_EXISTS\x10\xb9\x17\x12\x1c\n\x17RESOURCE_DOES_NOT_EXIST\x10\xba\x17\x12\x13\n\x0eQUOTA_EXCEEDED\x10\xa1\x1f\x12\x1c\n\x17MAX_BLOCK_SIZE_EXCEEDED\x10\xa2\x1f\x12\x1b\n\x16MAX_READ_SIZE_EXCEEDED\x10\xa3\x1f\x12\x13\n\x0e\x44RY_RUN_FAILED\x10\x89\'\x12\x1c\n\x17RESOURCE_LIMIT_EXCEEDED\x10\x8a\'\x12\x18\n\x13\x44IRECTORY_NOT_EMPTY\x10\xf1.\x12\x18\n\x13\x44IRECTORY_PROTECTED\x10\xf2.\x12\x1f\n\x1aMAX_NOTEBOOK_SIZE_EXCEEDED\x10\xf3.:G\n\nvisibility\x12\x1d.google.protobuf.FieldOptions\x18\xee\x90\x03 \x01(\x0e\x32\x12.mlflow.Visibility::\n\x11validate_required\x12\x1d.google.protobuf.FieldOptions\x18\xef\x90\x03 \x01(\x08:4\n\x0bjson_inline\x12\x1d.google.protobuf.FieldOptions\x18\xf0\x90\x03 \x01(\x08:1\n\x08json_map\x12\x1d.google.protobuf.FieldOptions\x18\xf1\x90\x03 \x01(\x08:Q\n\tfield_doc\x12\x1d.google.protobuf.FieldOptions\x18\xf2\x90\x03 \x03(\x0b\x32\x1d.mlflow.DocumentationMetadata:K\n\x03rpc\x12\x1e.google.protobuf.MethodOptions\x18\xee\x90\x03 \x01(\x0b\x32\x1c.mlflow.DatabricksRpcOptions:S\n\nmethod_doc\x12\x1e.google.protobuf.MethodOptions\x18\xf2\x90\x03 \x03(\x0b\x32\x1d.mlflow.DocumentationMetadata:U\n\x0bmessage_doc\x12\x1f.google.protobuf.MessageOptions\x18\xf2\x90\x03 \x03(\x0b\x32\x1d.mlflow.DocumentationMetadata:U\n\x0bservice_doc\x12\x1f.google.protobuf.ServiceOptions\x18\xf2\x90\x03 \x03(\x0b\x32\x1d.mlflow.DocumentationMetadata:O\n\x08\x65num_doc\x12\x1c.google.protobuf.EnumOptions\x18\xf2\x90\x03 \x03(\x0b\x32\x1d.mlflow.DocumentationMetadata:V\n\x15\x65num_value_visibility\x12!.google.protobuf.EnumValueOptions\x18\xee\x90\x03 \x01(\x0e\x32\x12.mlflow.Visibility:Z\n\x0e\x65num_value_doc\x12!.google.protobuf.EnumValueOptions\x18\xf2\x90\x03 \x03(\x0b\x32\x1d.mlflow.DocumentationMetadataB*\n#com.databricks.api.proto.databricks\xe2?\x02\x10\x01')
TypeError: Couldn't build proto file into descriptor pool: duplicate file name databricks.proto
```",full recent call last file line module file line module import file line module import file line module import file line module import file line module import file line module could build proto file pool duplicate file name,issue,negative,positive,positive,positive,positive,positive
1681991501,"@harupy nice! what do you think could be the issue?
",nice think could issue,issue,negative,positive,positive,positive,positive,positive
1681984610,@harupy my best guess is that package databricks_registry_webhooks also have same file called databricks.proto and one way or another this file is a duplicate in both the packages and protobuf is failing for the same reason. which should not happen. This is only failing from mlflow version 2.3.x before that it is working fine,best guess package also file one way another file duplicate failing reason happen failing version working fine,issue,negative,positive,positive,positive,positive,positive
1681964296,Got it. Can you provide the full stack trace? I want to see what the `...` part looks like.,got provide full stack trace want see part like,issue,negative,positive,positive,positive,positive,positive
1681957216,"@harupy
 myuser@Admins-MacBook-Pro-67 ~ % mlflow doctor
System information: Darwin Darwin Kernel Version 22.5.0: Mon Apr 24 20:51:50 PDT 2023; root:xnu-8796.121.2~5/RELEASE_X86_64
Python version: 3.9.16
MLflow version: 2.4.2
MLflow module location: /Users/myuser/miniconda3/envs/proj_env/lib/python3.9/site-packages/mlflow/__init__.py
Tracking URI: file:///Users/myuser/mlruns
Registry URI: file:///Users/myuser/mlruns
MLflow dependencies:
  Flask: 2.3.2
  Jinja2: 3.1.2
  alembic: 1.11.2
  click: 8.1.6
  cloudpickle: 2.2.1
  databricks-cli: 0.17.7
  docker: 6.1.3
  entrypoints: 0.4
  gitpython: 3.1.32
  gunicorn: 20.1.0
  importlib-metadata: 6.8.0
  markdown: 3.4.4
  matplotlib: 3.7.2
  numpy: 1.25.2
  packaging: 23.1
  pandas: 2.0.3
  protobuf: 4.23.4
  pyarrow: 12.0.1
  pytz: 2023.3
  pyyaml: 6.0.1
  querystring-parser: 1.2.4
  requests: 2.31.0
  scikit-learn: 1.2.2
  scipy: 1.10.1
  sqlalchemy: 2.0.20
  sqlparse: 0.4.4",doctor system information kernel version mon root python version version module location file registry file flask jinja alembic click docker markdown,issue,negative,neutral,neutral,neutral,neutral,neutral
1681816197,@harupy I would love to work on this. You can assign me one of the remaining variables so that I can work on. Thanks.,would love work assign one work thanks,issue,positive,positive,positive,positive,positive,positive
1681795302,"> I'm curious why we only extract 'raw_model' for sklearn flavor here

I'm actually not sure, but adding more flavors XGBoost or LightGBM sounds good to me, although I won't address that in this PR.",curious extract flavor actually sure good although wo address,issue,positive,positive,positive,positive,positive,positive
1681778049,Thank you. I think databricks code is not affected.,thank think code affected,issue,negative,neutral,neutral,neutral,neutral,neutral
1681677570,I'm curious why we only extract 'raw_model' for sklearn flavor here https://github.com/mlflow/mlflow/blob/ad926b681b9e90ae0381769b2b65d8e934e95f31/mlflow/models/evaluation/default_evaluator.py#L82? What about other models that contains 'predict_proba' method like xgboost?,curious extract flavor method like,issue,positive,negative,neutral,neutral,negative,negative
1681650876,"@WeichenXu123 Can you provide details on how this could affect Databricks?
The Databricks platform seems to use a different path for Font Awesome assets:

![Databricks](https://github.com/mlflow/mlflow/assets/10113621/16c97012-5a8e-47f7-8f09-45291d7f0f37)

",provide could affect platform use different path font awesome asset,issue,positive,positive,positive,positive,positive,positive
1681600753,"Hi @WeichenXu123, in this method `_validate_submitted_types ` in the transformers.py file:
https://github.com/mlflow/mlflow/blob/master/mlflow/transformers.py#L1470

Would it be possible for us to include `PeftModelForCausalLM` or `PeftModel` as a valid model type?",hi method file would possible u include valid model type,issue,negative,neutral,neutral,neutral,neutral,neutral
1681520078,We need to fix https://github.com/mlflow/mlflow/blob/cc5ca7d0de591460b7e8f9cc18d97bcad92f8af0/mlflow/gateway/config.py#L270-L279 as well? And should we update `RouteConfig` with the same logic?,need fix well update logic,issue,negative,neutral,neutral,neutral,neutral,neutral
1681463204,"@WeichenXu123 The PEFT model does not inherit from the transformers, it's more of a wrapper. This causes issues as it cannot be added to a Huggingface pipeline and throws errors when running `mlflow.transformers.save_model / .log_model ` with the model stored in a dictionary.

I think we need to make a new peft file? 🤔",model inherit wrapper added pipeline running model dictionary think need make new file,issue,negative,positive,positive,positive,positive,positive
1681434867,"> @BenWilson2 Would [pyfunc/test_model_export_with_class_and_artifacts.py](https://github.com/mlflow/mlflow/blob/f3fc6aa1983baf24e84a1477b0920226f977b46b/tests/pyfunc/test_model_export_with_class_and_artifacts.py) be the right place for this?

Precisely! :) ",would right place precisely,issue,negative,positive,positive,positive,positive,positive
1681393454,Reverting commit doesn't resolve lack of sign off. Will redo PR,commit resolve lack sign redo,issue,negative,neutral,neutral,neutral,neutral,neutral
1681283972,I ran into the same error when I had to roll back the version of mlflow I was using to pre v2 due to deployment problems after also updating my tracking server.  This error occurs when I try to register a pre v2 model.  ,ran error roll back version due deployment also server error try register model,issue,negative,negative,neutral,neutral,negative,negative
1681175789,A follow-on for this... could a test be added that validates the correct behavior within the windows CI suite? (Something very simple that involves validating the issue that you found in the filing of #9278),could test added correct behavior within suite something simple issue found filing,issue,negative,neutral,neutral,neutral,neutral,neutral
1680451999,"I wrote a script that automatically rewrites docstring using GPT4:

````python
from __future__ import annotations

import ast
import os
import random
import subprocess
import textwrap

import openai


class DocstringVisitor(ast.NodeVisitor):
    def __init__(self):
        self.docstring_nodes = []

    def visit_FunctionDef(self, node: ast.AST):
        if (
            node.body
            and isinstance(node.body[0], ast.Expr)
            and isinstance(node.body[0].value, ast.Str)
            and "":param"" in node.body[0].value.s
        ):
            self.docstring_nodes.append(node.body[0].value)


def transform(docstring: str) -> str:
    res = openai.ChatCompletion.create(
        model=""gpt-4"",
        messages=[
            {
                ""role"": ""user"",
                ""content"": f""""""
Hi GPT4, I'd like you to rewrite python docstrings in a more readable format. Here's an example:

# Before

```python
    \""\""\""
    This is a docstring

    :param x: This is a parameter x.
    :param y: This is a parameter x.
    :return: This is a return value.
    ...
    \""\""\""
```

# After

```python
    \""\""\""
    This is a docstring

    :param x:
        This is a parameter x.
    :param y:
        This is a parameter x.
    :return:
        This is a return value.
    ...
    \""\""\""
```

# Transformation Rules:

- Each parameter description should start on a new line beneath the parameter name.
- Each parameter description should be indented by 4 spaces.
- Be sure to prserve the indentation of the docstring.
- Make sure the line length doesn't exceed 100 characters.
- No need to insert a blank line between parameters.
- Be sure to use the same quotes as the original docstring.
- Be sure to put the new docstring in a python code block.

Given these rules, please rewrite the following docstring:

```python
{docstring}
```
"""""",
            }
        ],
    )
    return res.choices[0].message.content


def node_to_char_range(docstring_node: ast.Str, line_lengths: list[int]) -> tuple[int, int]:
    start = sum(line_lengths[: docstring_node.lineno - 1]) + docstring_node.col_offset
    node_length = (
        (line_lengths[docstring_node.lineno - 1] - docstring_node.col_offset)
        + sum(line_lengths[docstring_node.lineno : docstring_node.end_lineno - 1])
        + docstring_node.end_col_offset
    )
    return start, start + node_length


def extract_code(s: str) -> str | None:
    import re

    if m := re.search(r""```python\n(.*)```"", s, re.DOTALL):
        return m.group(1)
    return None


def format_code(code: str, indent: str, opening_quote: str, closing_quote: str) -> str:
    code = code.strip().lstrip('r""\n').rstrip('"" \n')
    code = textwrap.dedent(code)
    code = textwrap.indent(code, indent)
    code = f""{opening_quote}\n{code}\n{indent}{closing_quote}""
    return code


def leading_quote(s: str) -> str:
    for idx, c in enumerate(s):
        if c not in (""'"", '""', ""f"", ""r""):
            return s[:idx]
    raise ValueError(""No leading quote found"")


def trailing_quote(s: str) -> str:
    for idx, c in enumerate(s[::-1]):
        if c not in (""'"", '""'):
            return s[-idx:]
    raise ValueError(""No leading quote found"")


def main():
    assert ""OPENAI_API_KEY"" in os.environ

    py_files = subprocess.check_output([""git"", ""ls-files"", ""mlflow/*.py""]).decode().splitlines()
    random.shuffle(py_files)
    for py_file in py_files:
        with open(py_file) as f:
            src = f.read()

        tree = ast.parse(src)
        visitor = DocstringVisitor()
        visitor.visit(tree)

        if not visitor.docstring_nodes:
            continue

        lines = src.splitlines(keepends=True)
        line_lengths = list(map(len, lines))
        new_src = str(src)
        offset = 0
        for node in visitor.docstring_nodes:
            print(f""Transforming {py_file}:{node.lineno}:{node.col_offset + 1}"")
            start, end = node_to_char_range(node, line_lengths)
            indent = "" "" * node.col_offset
            original = src[start:end]
            transformed = transform(indent + original)
            code = extract_code(transformed)
            if code is None:
                continue

            code = format_code(
                code,
                indent,
                leading_quote(original),
                trailing_quote(original),
            )
            original_length = end - start
            new_src = new_src[: (start + offset)] + code + new_src[(end + offset) :]
            offset += len(code) - original_length
            with open(py_file, ""w"") as f:
                f.write(new_src)


if __name__ == ""__main__"":
    main()
````

<img width=""1680"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/17039389/0031e2cc-ed04-4930-879b-55cae1b4544f"">
",wrote script automatically python import import ast import o import random import import import class self self node param transform role user content hi like rewrite python readable format example python param parameter param parameter return return value python param parameter param parameter return return value transformation parameter description start new line beneath parameter name parameter description indented sure indentation make sure line length exceed need insert blank line sure use original sure put new python code block given please rewrite following python return list start sum sum return start start none import return return none code indent code code code code code indent code code indent return code enumerate return raise leading quote found enumerate return raise leading quote found main assert git open tree visitor tree continue list map offset node print transforming start end node indent original start end transform indent original code code none continue code code indent original original end start start offset code end offset offset code open main image,issue,positive,positive,positive,positive,positive,positive
1680451179,"> I am also facing the same issue with NFS share and the lack of documentation is really hurting.
> 
> We have a `server_NFS`, which has a share exported like this `/home/nfsuser/share <server_A>(rw,sync,no_root_squash,no_subtree_check)`
> 
> The permissions on `/home/nfsuser/share` have been set for all to read and write.
> 
> `server_A` has mlflow tracking server running and is the NFS client. The NFS share is mounted like this `sudo mount server_NFS:/home/nfsuser/share /mnt/nfs_share`
> 
> Creating files and making dirs gets synced properly between the NFS client and server.
> 
> Now we tried providing this NFS share as the default artifact root in various forms, but the artifacts just do not get logged to the NFS share. The server command looks like this: `mlflow server --backend-store-uri postgresql://user:pass@server_postgres:5432/mlflow_db --default-artifact-root /mnt/nfs_share --host server_A`
> 
> In the notebook the get_artifact_uri call returns the following output, but there is nothing on the nfs_share `artifact_uri: /mnt/nfs_share/18/a21fc1a8b4d9442199832c1e3acb398a/artifacts`
> 
> Out of frustration, we tried throwing all types of schemes like `file:/mnt/nfs_share`, `file:///mnt/nfs_share` but that gives INVALIDARGUMENT error and exited.
> 
> Any pointer to fix this?

did you fix this and if so, how?

",also facing issue share lack documentation really hurting share like sync set read write server running client share mounted like mount making properly client server tried providing share default artifact root various get logged share server command like server pas host notebook call following output nothing frustration tried throwing like file file error pointer fix fix,issue,positive,positive,neutral,neutral,positive,positive
1680371582,I used the huntr service to report the issue so I am not sure what the title of the email was as I don't have access to the backend. I just sent a new email to mlflow-oss-maintainers@googlegroups.com,used service report issue sure title access sent new,issue,negative,positive,positive,positive,positive,positive
1680325712,could you attach the related email title ?,could attach related title,issue,negative,neutral,neutral,neutral,neutral,neutral
1680301072,"An email should have been sent about 6 days ago, lmk if you didn't receive it",sent day ago receive,issue,negative,neutral,neutral,neutral,neutral,neutral
1680241655,Do you mean by preventing user to open a ticket without any details ?,mean user open ticket without,issue,negative,negative,negative,negative,negative,negative
1680169163,@harupy After upgrading torch and macOS to 13.5 the issue is resolved. Thanks a lot!,torch issue resolved thanks lot,issue,positive,positive,positive,positive,positive,positive
1680138885,"Hello @BenWilson2! I wanted to check if you had a chance to give this PR another read. If there's someone else I should reach out to for the joint publication instead, please let me know.",hello check chance give another read someone else reach joint publication instead please let know,issue,positive,neutral,neutral,neutral,neutral,neutral
1680103625,@harupy Yes. In both cases it is the same workflow (create pipeline --> register it into ML Flow --> load it from model registry),yes create pipeline register flow load model registry,issue,positive,neutral,neutral,neutral,neutral,neutral
1680101602,"> However, I am trying to use the model gpt2 and in that case it is not working

gpt2 doesn't work, but t5-small does?",however trying use model case working work,issue,negative,neutral,neutral,neutral,neutral,neutral
1680088847,@harupy If you mean saving it do disk (using `llm_pipeline.save_pretrained(MODEL_DIRECTORY)`) then yes. I can save the model and then load it and it works normally.,mean saving disk yes save model load work normally,issue,positive,negative,neutral,neutral,negative,negative
1680084791,@mahdyshabeeb Can you save and load the model without using mlflow?,save load model without,issue,negative,neutral,neutral,neutral,neutral,neutral
1679855434,"> Thank you for bringing this up to our attention @kparaju ! I've filed a fix for it and we'll be sure to get a patch out for this. In the meantime, can you pin pydantic to <2.x or use MLflow 2.5 until we get the patch released? 

Yes, we can and will pin to mlflow 2.5 until patch is released. ",thank attention fix sure get patch pin use get patch yes pin patch,issue,positive,positive,positive,positive,positive,positive
1679792623,"Hi folks, MLflow now has built-in support for authentication and authorization. Please try it out at https://mlflow.org/docs/latest/auth/index.html and let us know if you have feedback. Thank you for using MLflow!",hi support authentication authorization please try let u know feedback thank,issue,positive,neutral,neutral,neutral,neutral,neutral
1679791740,Following up here - the root artifact URI is immutable for a given experiment. Thank you for using MLflow!,following root artifact immutable given experiment thank,issue,negative,neutral,neutral,neutral,neutral,neutral
1679788277,Parameter selection for the parallel coordinates plot is now much simpler and easier to control. Thank you for using MLflow!,parameter selection parallel plot much simpler easier control thank,issue,positive,positive,neutral,neutral,positive,positive
1679786741,MLflow now has a built-in authentication and authorization layer: https://mlflow.org/docs/latest/auth/index.html. Please try it out and provide feedback. Thank you for using MLflow!,authentication authorization layer please try provide feedback thank,issue,positive,neutral,neutral,neutral,neutral,neutral
1679766161,"Thank you for bringing this up to our attention @kparaju ! I've filed a fix for it and we'll be sure to get a patch out for this. In the meantime, can you pin pydantic to <2.x or use MLflow 2.5 until we get the patch released? ",thank attention fix sure get patch pin use get patch,issue,positive,positive,positive,positive,positive,positive
1679728047,"> Thanks Ben! I think this will fix #9333?

yep! Recipes suites are passing now :D ",thanks ben think fix yep passing,issue,positive,positive,positive,positive,positive,positive
1679626424,"FLAML 2.0 (dependency of MLflow Recipes) just released today with a change to setup.py, removing xgboost and lightgbm from install_requires, reflected here: https://github.com/microsoft/FLAML/pull/1007/files#diff-60f61ab7a8d1910d86d9fda2261620314edcae5894d5aaa236b821c7256badd7 
Specifying the extras install pattern to have compatibility with pre 2.x install requirements.",dependency today change removing reflected install pattern compatibility install,issue,negative,neutral,neutral,neutral,neutral,neutral
1679584189,"@harupy Haru, I have no idea how this magic `import_hooks` util  is functioning, could you help take a look? Thanks!",idea magic could help take look thanks,issue,positive,positive,positive,positive,positive,positive
1679570209,"> How to enforce this style?
We can enforce it at PR reviewing time, so new code will comply. It's a bit hard to enforce docstring style using tools.

> Should we use type hints instead of including them in the docstring?
I prefer docstring better, because type hints create a development overhead, and it occasionally causes strange testing failures.

> Any way to automatically transform the existing docstrings to the new style?
We should probably do it manually, especially for commenting on the type. Progressive PRs could be a good choice for us.

> GPT4 may help
Yes that's cool! ",enforce style enforce time new code comply bit hard enforce style use type instead prefer better type create development overhead occasionally strange testing way automatically transform new style probably manually especially type progressive could good choice u may help yes cool,issue,positive,positive,positive,positive,positive,positive
1679431785,I have been running into the same issue trying to deploy to Sagemaker.  It seems to work with an older version of mlflow (1.29.0) but fails with mlflow 2.3+.,running issue trying deploy work older version,issue,negative,positive,positive,positive,positive,positive
1679014851,You can assign me one of the remain environment variables. Would love to keep contributing to this repository.,assign one remain environment would love keep repository,issue,positive,positive,positive,positive,positive,positive
1678922045,@Dev-98 Assigned a new environment variable!,assigned new environment variable,issue,negative,positive,positive,positive,positive,positive
1678848925,"Thanks, can you assign me another one",thanks assign another one,issue,negative,positive,positive,positive,positive,positive
1678799283,"@WeichenXu123 Unfortunately not, would you provide reference or instructions to the test?
Thanks!",unfortunately would provide reference test thanks,issue,negative,negative,negative,negative,negative,negative
1678748283,"@SaravananSathyanandhaQC We can add a test in `tests/tracking/fluent/test_fluent.py` like this:

```diff
diff --git a/tests/tracking/fluent/test_fluent.py b/tests/tracking/fluent/test_fluent.py
index 64cd632eb..ccac8ce99 100644
--- a/tests/tracking/fluent/test_fluent.py
+++ b/tests/tracking/fluent/test_fluent.py
@@ -3,6 +3,7 @@ import time
 from collections import defaultdict
 from importlib import reload
 from itertools import zip_longest
+from concurrent.futures import ThreadPoolExecutor
 
 from mlflow.store.model_registry import (
     SEARCH_REGISTERED_MODEL_MAX_RESULTS_DEFAULT,
@@ -1304,3 +1305,20 @@ def test_get_parent_run():
     assert parent_run.data.params == {""a"": ""1""}
 
     assert mlflow.get_parent_run(run_id) is None
+
+
+def test_active_run_thread_safety():
+    mlflow.search_experiments()  # Initialize database
+
+    def run(worker: int):
+        if worker == 1:
+            time.sleep(1)
+
+        with mlflow.start_run() as run:
+            time.sleep(2)
+            assert mlflow.tracking.fluent.active_run().info.run_id == run.info.run_id
+            return run.info.run_id
+
+    with ThreadPoolExecutor(max_workers=2) as executor:
+        run_ids = list(executor.map(run, range(2)))
+        assert run_ids == [r.info.run_id for r in mlflow.search_runs()]
```",add test like git index import time import import reload import import import assert assert none initialize run worker worker run assert return executor list run range assert,issue,negative,neutral,neutral,neutral,neutral,neutral
1678683110,@SaravananSathyanandhaQC Thanks for the script! Let me push a commit to add a test.,thanks script let push commit add test,issue,positive,positive,positive,positive,positive,positive
1678643065,"we need test on databricks, do you have databricks environment for testing ? @danilopeixoto ",need test environment testing,issue,negative,neutral,neutral,neutral,neutral,neutral
1678614549,"This is worth checking, 

But looks like keras-core is still experimental, we can keep an eye on it but let's wait it releasing stable version first.",worth like still experimental keep eye let wait stable version first,issue,positive,positive,positive,positive,positive,positive
1678486919,"I think we can reuse transformers flavor, i.e., we can directly modify `mlflow.transformers.log_model` to make it support logging PEFT adapter. CC @BenWilson2 ",think reuse flavor directly modify make support logging adapter,issue,negative,positive,neutral,neutral,positive,positive
1678478166,"Hi @harupy, happy to assist. Please assign me an environment variable.",hi happy assist please assign environment variable,issue,positive,positive,positive,positive,positive,positive
1678476595,"Hey. I would like to work on this issue if that helps. I have been using mlflow for quite some time and would like to help contribute to the development. I understood the instructions about signing when committing, etc. I don't have much experience in contributing to open source projects, so I wish to start with something simple like this. Please let me know which one should I migrate",hey would like work issue quite time would like help contribute development understood much experience open source wish start something simple like please let know one migrate,issue,positive,positive,neutral,neutral,positive,positive
1678468210,"I would like to work on this problem. I understood all the prerequisites, like using ""-s"" and ping you before raising any PR, and also to push this on a non-master branch.

Please assign me the environment to migrate",would like work problem understood like ping raising also push branch please assign environment migrate,issue,positive,neutral,neutral,neutral,neutral,neutral
1678443330,"Hi @WeichenXu123, we are currently creating functions to save, log and load a PEFT adapter. When using the base `model.log()` function for our own `log_model()` function we need to specify a flavor module. Is there an existing Model Flavour that we can us, otherwise how can we create our own PEFT Model Flavor? Thanks!",hi currently save log load adapter base function function need specify flavor module model flavour u otherwise create model flavor thanks,issue,positive,negative,negative,negative,negative,negative
1678430376,"For 1, I think migrating to the Numpydoc style or the Google style can help us enforce the style, but it requires more work. GPT4 may help.",think style style help u enforce style work may help,issue,positive,neutral,neutral,neutral,neutral,neutral
1678421686,"@chenmoneygithub Thanks for the comment!

> _SklearnTrainingSession should be public since it's called in xgboost module.

Can we keep this class as private because we don't expect users to touch it?",thanks comment public since module keep class private expect touch,issue,negative,positive,neutral,neutral,positive,positive
1678290734,"As a reference, weights & bias has made prototype towards Keras core: https://github.com/wandb/wandb/issues/5939",reference bias made prototype towards core,issue,negative,neutral,neutral,neutral,neutral,neutral
1678282678,"Could you also try this command solely ?
```
bash -c conda env create -n custom_env -f {env_path_dst}
```",could also try command solely bash create,issue,negative,neutral,neutral,neutral,neutral,neutral
1678232763,"I prefer the first style because it's easier to read to me. A few more thoughts:

1. How to enforce this style?
2. Should we use type hints instead of including them in the docstring?
3. Any way to automatically transform the existing docstrings to the new style? I believe most of param descriptions (80~90%) can be automatically fixed. There may be ones that need manual transformation.",prefer first style easier read enforce style use type instead way automatically transform new style believe param automatically fixed may need manual transformation,issue,negative,positive,positive,positive,positive,positive
1678125079,"Sounds good, I will keep an eye out for any movement on this. Thanks!",good keep eye movement thanks,issue,positive,positive,positive,positive,positive,positive
1678004055,"I am okay with both! I'm more familiar with the second style (Google style), but no strong opinion. HuggingFace uses style 1, while Torch/TF uses style 2. We just need to be consistent inside the package. 

BTW we may want to require commenting on types in the arg section. e.g.:
```
path: string,  Local path destination for the serialized model to be saved.
```
",familiar second style style strong opinion style style need consistent inside package may want require section path string local path destination model saved,issue,positive,positive,positive,positive,positive,positive
1677902550,"@harupy Implemented Option 1 from #6556:

### Option 1: Use relative URLs (proposed by @danilopeixoto):

```diff
diff --git a/mlflow/server/js/craco.config.js b/mlflow/server/js/craco.config.js
index 38e717c1c..cf5764863 100644
--- a/mlflow/server/js/craco.config.js
+++ b/mlflow/server/js/craco.config.js
@@ -73,7 +73,7 @@ function configureIframeCSSPublicPaths(config, env) {
           cssRule.use
             ?.filter((loaderConfig) => loaderConfig?.loader.match(/\/mini-css-extract-plugin\//))
             .forEach((loaderConfig) => {
-              let publicPath = '/static-files/';
+              let publicPath = '../../';
               // eslint-disable-next-line no-param-reassign
               loaderConfig.options = { publicPath };
```

- This might not be compatible with MLflow UI on Databricks. Needs investigation.

### Option 2: Add a handler for `/static-files/`

```diff
diff --git a/mlflow/server/__init__.py b/mlflow/server/__init__.py
index 4718492a3..eaabc2fdd 100644
--- a/mlflow/server/__init__.py
+++ b/mlflow/server/__init__.py
@@ -67,6 +67,11 @@ def serve_static_file(path):
     return send_from_directory(STATIC_DIR, path)
 
 
+@app.route(""/static-files/<path:path>"")
+def serve_static_file_root(path):
+    return send_from_directory(STATIC_DIR, path)
+
+
 # Serve the index.html for the React App for all other routes.
 @app.route(_add_static_prefix(""/""))
 def serve():
```

_Originally posted by @harupy in https://github.com/mlflow/mlflow/issues/6556#issuecomment-1225582525_
            ",option option use relative git index function let let might compatible need investigation option add handler git index path return path path path path return path serve react serve posted,issue,negative,neutral,neutral,neutral,neutral,neutral
1677768584,"> @Aman123lug sounds great! Thank you for volunteering. Please link your PR to this issue and ping us when you're ready for us to review the browser cache solution! :D 

Okay I will ping",great thank please link issue ping u ready u review browser cache solution ping,issue,positive,positive,positive,positive,positive,positive
1677529252,"@harupy quick hacky script but does the trick and shows the issue.

Note that the `if worker > 0: time.sleep(1)` tests the case where you try to enter a second run whilst the first has already started and updated the `_active_run_stack` at the end of the `start_run` method. Thus you get the `Run with UUID 0a3020f801184fa18eb4b0e0328b9517 is already active.` error message.

If you comment out those 2 lines, both runs manage to start successfully because there's a timing gap between the start of `start_run` when `_active_run_stack` is checked, and the end where it's actually updated, so both can seem to successfully start. But that's when the second `UH OH ERROR` log gets printed out because actually the `_active_run_stack` is holding both runs in there, so for one worker the `active_run().info.run_id` has sneakily been changed.

[perf_test.py.txt](https://github.com/mlflow/mlflow/files/12336480/perf_test.py.txt)
",quick hacky script trick issue note worker case try enter second run whilst first already end method thus get run already error message comment manage start successfully timing gap start checked end actually seem successfully start second oh error log printed actually holding one worker,issue,negative,positive,positive,positive,positive,positive
1677461281,What if you add `--build-image` option for `mlflow run` command ?,add option run command,issue,negative,neutral,neutral,neutral,neutral,neutral
1677419239,"@WeichenXu123 after talking to @BenWilson2 and @dbczumar, I'm working on a more complete doc. Hopefully that will be ready in the next day or two.",talking working complete doc hopefully ready next day two,issue,positive,positive,positive,positive,positive,positive
1677415153,"Hi all,

This feature is meaningful, but could you list all the cases you want to support ? Note that currently it should already support part of cases those are dict or list https://github.com/mlflow/mlflow/blob/d415b9a65c25d252f2383486406abdfa9240eaeb/mlflow/models/utils.py#L126 
",hi feature meaningful could list want support note currently already support part list,issue,positive,positive,positive,positive,positive,positive
1677405498,"This is a meaningful feature! But it is not urgent, I will wait volunteers to pick up this task :), I will help review it.",meaningful feature urgent wait pick task help review,issue,positive,positive,positive,positive,positive,positive
1677395044,@SaravananSathyanandhaQC Could you create a minimum script that doesn't work on the master branch but does on this PR? We can convert it to a test.,could create minimum script work master branch convert test,issue,negative,neutral,neutral,neutral,neutral,neutral
1677331928,"Hi @ASHOAI this isn't so much of a bug as 'the feature working as designed'. We didn't initially support the full complex output type for all transformers models due to a desire to simplify the as-served output types attempting to conform to a as uniform an output result as possible across as many model types as possible. 
That being said, we have recently relaxed this standard on some pipeline types as we've seen usage patterns that require additional data to make the inference return values useful. 

Could you provide:
1. The underlying model architecture used (what is the huggingface_hub repo designator for the model / tokenizer that you're trying to use)
2. The instantiated object type of the pipeline that you're using
3. The task type of the pipeline

This information will help to identify precisely which implementation we would need to take a look at and determine if we can coerce the output to conform to the native model's output (not all can be coerced, keep in mind).",hi much bug feature working designed initially support full complex output type due desire simplify output conform uniform output result possible across many model possible said recently relaxed standard pipeline seen usage require additional data make inference return useful could provide underlying model architecture used designator model trying use object type pipeline task type pipeline information help identify precisely implementation would need take look determine coerce output conform native model output keep mind,issue,positive,positive,positive,positive,positive,positive
1677322130,@Aman123lug sounds great! Thank you for volunteering. Please link your PR to this issue and ping us when you're ready for us to review the browser cache solution! :D ,great thank please link issue ping u ready u review browser cache solution,issue,positive,positive,positive,positive,positive,positive
1677136166,"> btw what does the / ai command do

Good question! What it does is ask GPT4 a question. For https://github.com/mlflow/mlflow/pull/9305#discussion_r1293326939, the following is the prompt:


````
Is the new code equivalent to the old code?

```
a/mlflow/types/schema.py b/mlflow/types/schema.py
index 45addf9744bb..3d7532b1e82c 100644
--- a/mlflow/types/schema.py
+++ b/mlflow/types/schema.py
@@ -119,11 +119,7 @@ def get_spark_types(cls):
 
     @classmethod
     def from_numpy_type(cls, np_type):
-        for dt in cls._member_map_.values():
-            if np_type == dt.to_numpy():
-                return dt
-
-        return None
+        return next((v for v in cls._member_map_.values() if v.to_numpy() == np_type), None)
 
 
 class ColSpec:

```
````

When a review comment is posted, GitHub sends a request to our GitHub application. The app constructs a prompt from the payload associated with the request, sends a request to OpenAI with the prompt, and post the reply on GitHub.",ai command good question ask question following prompt new code equivalent old code index return return none return next none class review comment posted request application prompt associated request request prompt post reply,issue,negative,positive,positive,positive,positive,positive
1677128467,"> LGTM!

hey  @harupy thanks ! btw what does the / ai command do",hey thanks ai command,issue,negative,positive,positive,positive,positive,positive
1676830500,@stroblme I pushed a commit to use `save_kwargs`. Let me know if it looks ok :),commit use let know,issue,negative,neutral,neutral,neutral,neutral,neutral
1676798123,@harupy i would like to work on this issue as well can you assign me this? ;),would like work issue well assign,issue,positive,neutral,neutral,neutral,neutral,neutral
1676785701,"So you prefer something like this? 

```
    :param path:
        Local path destination for the serialized model to be saved.
    :param processor:
        An optional ``Processor`` subclass object. Some model architectures,
        particularly multi-modal types, utilize Processors to combine text
        encoding and image or audio encoding in a single entrypoint.

        .. Note:: If a processor is supplied when saving a model, the
                  model will be unavailable for loading as a ``Pipeline`` or for
                  usage with pyfunc inference.
```

or this?

```
    :param path:
        Local path destination for the serialized model to be saved.
    :param processor: An optional ``Processor`` subclass object.
        Some model architectures, particularly multi-modal types,
        utilize Processors to combine text encoding and image or
        audio encoding in a single entrypoint.

        .. Note:: If a processor is supplied when saving a model, the
                  model will be unavailable for loading as a ``Pipeline`` or for
                  usage with pyfunc inference.
```

Either style gives us more horizontal space, which is nice. I prefer the former.",prefer something like param path local path destination model saved param processor optional processor subclass object model particularly utilize combine text image audio single note processor saving model model unavailable loading pipeline usage inference param path local path destination model saved param processor optional processor subclass object model particularly utilize combine text image audio single note processor saving model model unavailable loading pipeline usage inference either style u horizontal space nice prefer former,issue,positive,positive,neutral,neutral,positive,positive
1676779962,"@harupy I think our current style is in generaly good! Only the vertical alignment looks a bit strange, e.g,:
```
    :param processor: An optional ``Processor`` subclass object. Some model architectures,
                      particularly multi-modal types, utilize Processors to combine text
                      encoding and image or audio encoding in a single entrypoint.

                      .. Note:: If a processor is supplied when saving a model, the
                                model will be unavailable for loading as a ``Pipeline`` or for
                                usage with pyfunc inference.

    :param task: The transformers-specific task type of the model. These strings are utilized so
                 that a pipeline can be created with the appropriate internal call architecture
                 to meet the needs of a given model. If this argument is not specified, the
```
. Personally I prefer a google style, but no strong preference. Please let me know if you are okay with replacing the vertical alignment by 4-space indentation. Thanks!",think current style good vertical alignment bit strange param processor optional processor subclass object model particularly utilize combine text image audio single note processor saving model model unavailable loading pipeline usage inference param task task type model pipeline appropriate internal call architecture meet need given model argument personally prefer style strong preference please let know vertical alignment indentation thanks,issue,positive,positive,positive,positive,positive,positive
1676761588,"> @KekmaTime We need to update the files included in the diff in the issue descrirption.

got it!",need update included issue got,issue,negative,neutral,neutral,neutral,neutral,neutral
1676760762,@KekmaTime We need to update the files included in the diff in the issue descrirption.,need update included issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1676759376,"@harupy i would like to work on this issue and also can you tell me which files should i do these on?
",would like work issue also tell,issue,negative,neutral,neutral,neutral,neutral,neutral
1676696345,The `select` field in `pyproject.toml` is a list of enabled rules. We can add `PT013` there to enable it.,select field list add enable,issue,negative,neutral,neutral,neutral,neutral,neutral
1676689866,"Can you assign it to me ? @harupy I'd love to work on it asap. Also, can you explain the issue a little ?
",assign love work also explain issue little,issue,positive,positive,positive,positive,positive,positive
1676578573,"@chenmoneygithub Thanks for the suggestion. To confirm, are you suggesting we should use the google or numpy docstring style?

https://www.sphinx-doc.org/en/master/usage/extensions/napoleon.html#google-vs-numpy",thanks suggestion confirm suggesting use style,issue,negative,positive,positive,positive,positive,positive
1676576790,"I think the folder structure of a flavor should look like:

```
mlflow
  - <flavor>
    - __init__.py  
    - _<flavor>.py
```

```python
# __init__.py

# Just contains public APIs from `_<flavor>.py`
from ._<flavor> import save_model, log_model, ...

__all__ = [...]
```

```python
# _<flavor>.py

def save_model(...):
    ...

def log_model(...):
    ...
```",think folder structure flavor look like flavor flavor python public flavor flavor import python flavor,issue,negative,neutral,neutral,neutral,neutral,neutral
1676575140,"> Not our top-1 priority, we can either casually spend time on such improvements or open issues for OSS contributors to take over. could be some good first issues for our contributors.

Agree, sounds like a nice FTC (first time contributor) factory",priority either casually spend time open take could good first agree like nice first time contributor factory,issue,positive,positive,positive,positive,positive,positive
1676542455,"I have run into a similar issue with a recommender model. The inputs are variable-length lists of strings (UUIDs of product items) that represent a user's history, and the outputs are fixed-length or recommended product IDs (top N recommended products). 

In this case, I'm using a custom model in a PyFunc wrapper. The inferred signatures are ""string"" for both input and output structures, and then the schema-enforcement mechanism complains that the inputs don't conform to expected types when I call the `.predict` function.  My only work-around was log the model with `signature=None`, which is far from ideal. It would be nice to be able to define signatures of list/array types (of both fixed & variable length).",run similar issue recommender model product represent user history product top case custom model wrapper string input output mechanism conform call function log model far ideal would nice able define fixed variable length,issue,positive,positive,positive,positive,positive,positive
1676541197,Let me know if you want to work on a few more environment variables :),let know want work environment,issue,negative,neutral,neutral,neutral,neutral,neutral
1676534296,@AmirAflak did you have a chance to reopen the PR? Let me know if you're busy. I can file a PR.,chance reopen let know busy file,issue,negative,positive,neutral,neutral,positive,positive
1676405920,I know that. I didn't change the text_venv files or some other files. I little bit Confused in the file I need to change,know change little bit confused file need change,issue,negative,negative,negative,negative,negative,negative
1676148223,I can look into this issue but I might need some help.,look issue might need help,issue,negative,neutral,neutral,neutral,neutral,neutral
1675758071,"@kunal642 @Aman123lug Assigned, thanks for the help! 

A couple notes:

1. Please make sure to open a PR from a non master branch.
2. When making a commit, sign off the commit via `git commit -s -m ""...""`.
3. When opening a PR, please make sure to link this issue in the PR.",assigned thanks help couple please make sure open non master branch making commit sign commit via git commit opening please make sure link issue,issue,positive,positive,positive,positive,positive,positive
1675747866,i want to work in these. I have some experience in front-end. Please assign me,want work experience please assign,issue,negative,neutral,neutral,neutral,neutral,neutral
1675437738,Temporarily assigned to myself to avoid dangling issue.,temporarily assigned avoid dangling issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1674873699,@harupy I do not have the necessary permissions to add a reviewer to this pull request. Can you please give me the required permissions ?,necessary add reviewer pull request please give,issue,negative,neutral,neutral,neutral,neutral,neutral
1674548279,@harupy Please assign one to me. Thanks!!,please assign one thanks,issue,positive,positive,positive,positive,positive,positive
1674468605,"> This line command failed in your case:
> 
> ```
> conda env create -n custom_env -f {env_path_dst}
> ```
> 
> so could you provide the output log of subprocess that executing this command ?
> 
> or you can solely run `conda env create -n custom_env -f {env_path_dst}` and then send me its output. the `env_path_dst` is the conda yaml file that you can find it in your logged model path.

I tried to create an env with conda.yaml generated by generate-dockerfile command. It creates the env without a problem.",line command case create could provide output log command solely run create send output file find logged model path tried create command without problem,issue,positive,neutral,neutral,neutral,neutral,neutral
1674401387,"Thanks for reporting this! Pls file a fixing PR, appreciate your contribution!",thanks file fixing appreciate contribution,issue,positive,positive,positive,positive,positive,positive
1674364461,Hi @WeichenXu123! I want to take this issue. Can you assign it to me?,hi want take issue assign,issue,negative,neutral,neutral,neutral,neutral,neutral
1674353066,"Hi @WeichenXu123 ,

I already installed `azure-idenity` packages but still it was giving error and here the error while creating sample Mlflow experiment using python file.

```
halo@mlflow-cf7578d45-64ps6:~$ python test.py 
2023/08/09 13:13:17 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.
The git executable must be specified in one of the following ways:
    - be included in your $PATH
    - be set via $GIT_PYTHON_GIT_EXECUTABLE
    - explicitly set via git.refresh()

All git commands will error until this is rectified.

This initial warning can be silenced or aggravated in the future by setting the
$GIT_PYTHON_REFRESH environment variable. Use one of the following values:
    - quiet|q|silence|s|none|n|0: for no warning or exception
    - warn|w|warning|1: for a printed warning
    - error|e|raise|r|2: for a raised exception

Example:
    export GIT_PYTHON_REFRESH=quiet

Elasticnet model (alpha=0.500000, l1_ratio=0.500000):
  RMSE: 0.793164022927685
  MAE: 0.6271946374319586
  R2: 0.10862644997792636


Traceback (most recent call last):
  File ""/usr/local/lib/python3.10/site-packages/requests/adapters.py"", line 489, in send
    resp = conn.urlopen(
  File ""/usr/local/lib/python3.10/site-packages/urllib3/connectionpool.py"", line 878, in urlopen
    return self.urlopen(
  File ""/usr/local/lib/python3.10/site-packages/urllib3/connectionpool.py"", line 878, in urlopen
    return self.urlopen(
  File ""/usr/local/lib/python3.10/site-packages/urllib3/connectionpool.py"", line 878, in urlopen
    return self.urlopen(
  [Previous line repeated 2 more times]
  File ""/usr/local/lib/python3.10/site-packages/urllib3/connectionpool.py"", line 868, in urlopen
    retries = retries.increment(method, url, response=response, _pool=self)
  File ""/usr/local/lib/python3.10/site-packages/urllib3/util/retry.py"", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=5100): Max retries exceeded with url: /api/2.0/mlflow-artifacts/artifacts/0/83176ee5ebb3483a92e5e5893f28ee17/artifacts/model/requirements.txt (Caused by ResponseError('too many 500 error responses'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/usr/local/lib/python3.10/site-packages/mlflow/utils/rest_utils.py"", line 167, in http_request
    return _get_http_response_with_retries(
  File ""/usr/local/lib/python3.10/site-packages/mlflow/utils/rest_utils.py"", line 98, in _get_http_response_with_retries
    return session.request(method, url, **kwargs)
  File ""/usr/local/lib/python3.10/site-packages/requests/sessions.py"", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File ""/usr/local/lib/python3.10/site-packages/requests/sessions.py"", line 701, in send
    r = adapter.send(request, **kwargs)
  File ""/usr/local/lib/python3.10/site-packages/requests/adapters.py"", line 556, in send
    raise RetryError(e, request=request)
requests.exceptions.RetryError: HTTPConnectionPool(host='127.0.0.1', port=5100): Max retries exceeded with url: /api/2.0/mlflow-artifacts/artifacts/0/83176ee5ebb3483a92e5e5893f28ee17/artifacts/model/requirements.txt (Caused by ResponseError('too many 500 error responses'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/halo/test.py"", line 82, in <module>
    mlflow.sklearn.log_model(lr, ""model"", registered_model_name=""ElasticnetWineModel"")
  File ""/usr/local/lib/python3.10/site-packages/mlflow/sklearn/__init__.py"", line 417, in log_model
    return Model.log(
  File ""/usr/local/lib/python3.10/site-packages/mlflow/models/model.py"", line 487, in log
    mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
  File ""/usr/local/lib/python3.10/site-packages/mlflow/tracking/fluent.py"", line 810, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File ""/usr/local/lib/python3.10/site-packages/mlflow/tracking/client.py"", line 1048, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File ""/usr/local/lib/python3.10/site-packages/mlflow/tracking/_tracking_service/client.py"", line 448, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File ""/usr/local/lib/python3.10/site-packages/mlflow/store/artifact/http_artifact_repo.py"", line 40, in log_artifacts
    self.log_artifact(os.path.join(root, f), artifact_dir)
  File ""/usr/local/lib/python3.10/site-packages/mlflow/store/artifact/http_artifact_repo.py"", line 25, in log_artifact
    resp = http_request(self._host_creds, endpoint, ""PUT"", data=f)
  File ""/usr/local/lib/python3.10/site-packages/mlflow/utils/rest_utils.py"", line 185, in http_request
    raise MlflowException(f""API request to {url} failed with exception {e}"")
mlflow.exceptions.MlflowException: API request to http://127.0.0.1:5100/api/2.0/mlflow-artifacts/artifacts/0/83176ee5ebb3483a92e5e5893f28ee17/artifacts/model/requirements.txt failed with exception HTTPConnectionPool(host='127.0.0.1', port=5100): Max retries exceeded with url: /api/2.0/mlflow-artifacts/artifacts/0/83176ee5ebb3483a92e5e5893f28ee17/artifacts/model/requirements.txt (Caused by ResponseError('too many 500 error responses'))
```

Hi @santiagxf , 
We dont need to use Mlflow Azure Machine Learning, We deployed our own Mlflow server for each user and need to access Azure Storage Blob containers from Mlflow `--default-artifact-root wasbs://mlflowaganvir@amit4.blob.core.windows.net` using Azure User Manage Identity",hi already still giving error error sample experiment python file halo python warning import git git executable probably path git sha available error initialize bad git executable git executable must one following way included path set via explicitly set via git error rectified initial warning silenced future setting environment variable use one following warning exception printed warning raised exception example export model mae recent call last file line send resp file line return file line return file line return previous line repeated time file line method file line increment raise error cause many error handling exception another exception recent call last file line return file line return method file line request resp prep file line send request file line send raise many error handling exception another exception recent call last file line module model file line return file line log file line file line file line file line root file line resp put file line raise request exception request exception many error hi dont need use azure machine learning server user need access azure storage blob azure user manage identity,issue,negative,positive,neutral,neutral,positive,positive
1674299340,"@WeichenXu123 My bad, the MLFlow tracking component I was using was 1.20.2, whereas the application using that tracking server had mlflow ==2.5.0 package. When I upgraded the MLFlow tracking server to 2.5.0, it started working.
Thank you!

",bad component whereas application server package server working thank,issue,negative,negative,negative,negative,negative,negative
1674106687,@gabrielfu Sounds good! We can start from S3. We can use minio for testing.,good start use testing,issue,negative,positive,positive,positive,positive,positive
1673583838,"You'll need to follow the instructions included in DagsHub's message at the bottom there. The full returned trace is what is going to show the reason why the request attempt retried and eventually timed out. 

Out of curiosity, why are you trying to log the torch model natively and not the tokenizer? You can use `mlflow.transformers.log_model()` to bundle both in components mode to ensure that you have a record of the state of the tokenizer at time of evaluation and scoring. Do keep in mind that the transformers wrappers around those models (The instance of what you're loading is actually not an `AutoModelForSeq2SeqLM` (that is an abstraction loader for transformers); the actual type is `transformers.models.pegasus.modeling_pegasus.PegasusForConditionalGeneration`, which is not a torch object. The model within that wrapper is, though, iff it was loaded via the torch loader (otherwise it would be a tensorflow instance)). 

Perhaps this is more what you're looking for?

```python
import transformers
import mlflow

pegasus_name = ""google/pegasus-cnn_dailymail""

tokenizer = transformers.AutoTokenizer.from_pretrained(pegasus_name)
model = transformers.AutoModelForSeq2SeqLM.from_pretrained(pegasus_name)

with mlflow.start_run():
    model_info = mlflow.transformers.log_model(
        {""model"": pegasus_model, ""tokenizer"": tokenizer},
        artifact_path=""pegasus"",
    )

loaded_pegasus_pyfunc = mlflow.pyfunc.load_model(model_uri=model_info.model_uri)

summarization = loaded_pegasus_pyfunc.predict(""In top stories today, a room temperature superconducting ""
  ""magnet was developed in the family garage of a boy in the Praga neighborhood of Warsaw, Poland. Experts ""
  ""believe that the revolutionary breakthrough will usher in a new technological age for mankind."")

print(summarization)
```",need follow included message bottom full returned trace going show reason request attempt eventually timed curiosity trying log torch model natively use bundle mode ensure record state time evaluation scoring keep mind around instance loading actually abstraction loader actual type torch object model within wrapper though loaded via torch loader otherwise would instance perhaps looking python import import model model summarization top today room temperature magnet family garage boy neighborhood warsaw believe revolutionary breakthrough usher new technological age mankind print summarization,issue,positive,positive,positive,positive,positive,positive
1673342615,"Thank you for fast response !
Unfortunately after change values for suggested variables: ```MLFLOW_HTTP_REQUEST_TIMEOUT``` and ```MLFLOW_HTTP_REQUEST_MAX_RETRIES```  i've received below error:


``` bash
AssertionError                            Traceback (most recent call last)
File [.....\anaconda3\envs\mlops\lib\site-packages\mlflow\utils\rest_utils.py:93](file:///..../anaconda3/envs/mlops/lib/site-packages/mlflow/utils/rest_utils.py:93), in http_request(host_creds, endpoint, method, max_retries, backoff_factor, extra_headers, retry_codes, timeout, **kwargs)
     92 try:
---> 93     return _get_http_response_with_retries(
     94         method,
     95         url,
     96         max_retries,
     97         backoff_factor,
     98         retry_codes,
     99         headers=headers,
    100         verify=host_creds.verify,
    101         timeout=timeout,
    102         **kwargs,
    103     )
    104 except requests.exceptions.Timeout as to:

File [....\anaconda3\envs\mlops\lib\site-packages\mlflow\utils\request_utils.py:130](file:///.../anaconda3/envs/mlops/lib/site-packages/mlflow/utils/request_utils.py:130), in _get_http_response_with_retries(method, url, max_retries, backoff_factor, retry_codes, **kwargs)
    116 """"""
    117 Performs an HTTP request using Python's `requests` module with an automatic retry policy.
    118 
   (...)
    128 :return: requests.Response object.
    129 """"""
--> 130 session = _get_request_session(max_retries, backoff_factor, retry_codes)
...
    111     raise InvalidUrlException(f""Invalid url: {url}"") from iu
    112 except Exception as e:
--> 113     raise MlflowException(f""API request to {url} failed with exception {e}"")

MlflowException: API request to https://dagshub.com/Nkifor/mlops-nlp-text-summarizer.mlflow/api/2.0/mlflow/runs/create failed with exception 
Output is truncated. View as a [scrollable element](command:cellOutput.enableScrolling?2eebc6da-4af9-407e-8628-237a2c352cd4) or open in a [text editor](command:workbench.action.openLargeOutput?2eebc6da-4af9-407e-8628-237a2c352cd4). Adjust cell output [settings](command:workbench.action.openSettings?%5B%22%40tag%3AnotebookOutputLayout%22%5D)...
```",thank fast response unfortunately change received error bash recent call last file file method try return method except file file request python module automatic retry policy return session raise invalid except exception raise request exception request exception output truncated view element command open text editor command adjust cell output command tag,issue,negative,negative,neutral,neutral,negative,negative
1673081666,@harupy im not sure what to tick off in the options so i left it just as it is. hope its okay,sure tick left hope,issue,positive,positive,positive,positive,positive,positive
1673076921,@chenmoneygithub I agree. The hyperparam example is too complex as a quick starter and needs to be simplified.,agree example complex quick starter need simplified,issue,negative,positive,neutral,neutral,positive,positive
1673011810,"@KekmaTime When you make a commit, please make sure to use `-s` to sign off your commit:

```
git commit -s -m ""...""
```",make commit please make sure use sign commit git commit,issue,positive,positive,positive,positive,positive,positive
1672974758,@PhucLee2605 Can you create a minimum reproduction code?,create minimum reproduction code,issue,negative,neutral,neutral,neutral,neutral,neutral
1672904677,"@stroblme Sorry for the late review, left a few comments!",sorry late review left,issue,negative,negative,negative,negative,negative,negative
1672862208,"@aravinds502 Could you file a ticket, including the full repro code ? Including the code that logs the model, registers the model, and sets model tags.",could file ticket full code code model model model,issue,negative,positive,positive,positive,positive,positive
1672782811,"I was trying with mlflow==2.5.0, but when I try the filter as follows 
`mlflow_client.search_registered_models(filter_string=""tag.{} LIKE '{}'"".format(""project_id"", project_id))`
or
`mlflow_client.search_registered_models(filter_string=""tags.{} LIKE '{}'"".format(""project_id"", project_id))`

it gives errors as

`{RestException}INVALID_PARAMETER_VALUE: Invalid attribute key 'tag.`project_id`' specified. Valid keys  are '{'name'}'`

May I know in which version this fix went in.

Thanks",trying try filter tag like like invalid attribute key valid may know version fix went thanks,issue,positive,positive,neutral,neutral,positive,positive
1672634392,"> @WeichenXu123 Would you review the feature again?

sure ! I will help review.",would review feature sure help review,issue,positive,positive,positive,positive,positive,positive
1672486729,"The error message shows it might probably be network issue:
```""HTTPSConnectionPool(host='dagshub.com', port=443): Read timed out.```

Could you check whether your client side network is well ? and then check whether your server is overloaded so that it cannot respond to client within timeout ? finally, you can also try increase configuration value of `MLFLOW_HTTP_REQUEST_TIMEOUT` and `MLFLOW_HTTP_REQUEST_MAX_RETRIES` environmental variables",error message might probably network issue read timed could check whether client side network well check whether server respond client within finally also try increase configuration value environmental,issue,negative,neutral,neutral,neutral,neutral,neutral
1672470731,"For logging PEFT model as a pyfunc model, you need to customize the saving logic to only save the ""PEFT config"" and the adapter weights. You can modify code here: https://github.com/mlflow/mlflow/blob/8e8d25b4298051e690c4f07ada5db3ce597ab352/mlflow/transformers.py#L209


When loading PEFT pyfunc model , you need to customize the loading func logic, you can modify code here:
https://github.com/mlflow/mlflow/blob/8e8d25b4298051e690c4f07ada5db3ce597ab352/mlflow/transformers.py#L1531 
to load the Peft json config, Download the base model, and then wrap it in a PeftModel

",logging model model need saving logic save adapter modify code loading model need loading logic modify code load base model wrap,issue,negative,negative,negative,negative,negative,negative
1672454536,Is there a way that it just saves the python function and the adapter artifacts?,way python function adapter,issue,negative,neutral,neutral,neutral,neutral,neutral
1672431735,"@WeichenXu123 

The PEFT library saves 2 files:
- A JSON config file that stores all the adapters settings, including which base model to pull down.
```
{
  ""auto_mapping"": null,
  ""base_model_name_or_path"": ""tiiuae/falcon-7b"",
  ""bias"": ""none"",
  ""fan_in_fan_out"": false,
  ""inference_mode"": true,
  ""init_lora_weights"": true,
  ""layers_pattern"": null,
  ""layers_to_transform"": null,
  ""lora_alpha"": 32,
  ""lora_dropout"": 0.05,
  ""modules_to_save"": null,
  ""peft_type"": ""LORA"",
  ""r"": 16,
  ""revision"": null,
  ""target_modules"": [
    ""query_key_value""
  ],
  ""task_type"": ""CAUSAL_LM""
}
```
- A .bin file that contains the adapters weights (about 20mb).

To save a Peft file, all you need to do is call `model.save_pretrained(""<model URI to save files into>"")`

To load a Peft model, you need to load the Peft json config. Download the base model, and then wrap it in a PeftModel:
```
# Need to figure out how to load model
PEFT_MODEL_URI = ""trained-model""

config = PeftConfig.from_pretrained(PEFT_MODEL_URI)
model = AutoModelForCausalLM.from_pretrained(
    config.base_model_name_or_path,
    return_dict=True,
    quantization_config=bnb_config,
    device_map=""auto"",
    trust_remote_code=True
)

model = PeftModel.from_pretrained(model, PEFT_MODEL_URI)
```

The pyfunc I have to do this looks like this (unfortunately it saves the whole base model with it which is the issue and I can't even use it??):
```
class PeftAdapterModel(mlflow.pyfunc.PythonModel):
    
    def __init__(self, model, artifacts_uri):
        self.model = model
    
    def load_finetuned_model(self, peft_loc):
        config = PeftConfig.from_pretrained(peft_loc)
        model = AutoModelForCausalLM.from_pretrained(
            config.base_model_name_or_path,
            return_dict=True,
            load_in_8bit=True, # Actually faster to train in 4 bit and inference in 8 bit
            device_map=""auto"",
            trust_remote_code=True
        )

        peft_model = PeftModel.from_pretrained(model, peft_loc)  
        return peft_model
    
    def load_context(self, context):
        os.environ[""CUDA_VISIBLE_DEVICES""] = ""0""
        self.model = self.load_finetunes_model(adapter_uri)

    def predict(self, context, model_input):
        device = ""cuda:0""
        encoding = tokenizer(model_input, return_tensors=""pt"").to(device)
        
        with torch.inference_mode():
            outputs = self.model.generate(
                input_ids=encoding.input_ids,
                attention_mask=encoding.attention_mask,
                generation_config=gen_config,
                do_sample=False,
                use_cache=False # Seems to throw a mass amount of errors, slows down generation
            )
            
        return tokenizer.decode(outputs[0], skip_special_tokens=True)
```
This is not exactly working just yet. I am still working out pyfunc models. It saves the whole model into a pickel file however I still need to then run the peft function which will download the base model again?",library file base model pull null bias none false true true null null null lora revision null file save file need call model save load model need load base model wrap need figure load model model auto model model like unfortunately whole base model issue ca even use class self model model self model actually faster train bit inference bit auto model return self context predict self context device device throw mass amount slows generation return exactly working yet still working whole model file however still need run function base model,issue,negative,negative,negative,negative,negative,negative
1672429763,"This line command failed in your case:

```
conda env create -n custom_env -f {env_path_dst}
```

so could you provide the output log of subprocess that executing this command ?

or you can solely run `conda env create -n custom_env -f {env_path_dst}` and then send me its output. the `env_path_dst` is the conda yaml file that you can find it in your logged model path.
",line command case create could provide output log command solely run create send output file find logged model path,issue,negative,neutral,neutral,neutral,neutral,neutral
1672420462,Hi @dgormly Could you provide design details ? ,hi could provide design,issue,negative,neutral,neutral,neutral,neutral,neutral
1672375360,"Hi @amitganvir23! Access to Blob Storage Accounts is always granted using access keys. IAM is used to perform control plane operations over the resource. On the contrary, Azure Data Lake Gen2 Storage Accounts have ACL that would match your scenario, however, they are not supported as artifact backends for MLflow server.

As an alternative, you can explore using Azure Machine Learning for tracking instead of MLflow server and use our MLflow plug-in (azureml-mlflow). Azure Machine Learning doesn't charge for the tracking server and you are already paying for artifact storage with Storage Accounts so it may be a good fit. Check [MLflow and Azure Machine Learning](https://learn.microsoft.com/en-us/azure/machine-learning/concept-mlflow?view=azureml-api-2) to learn about the integration and [Configure MLflow for Azure Machine Learning](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-use-mlflow-configure-tracking?view=azureml-api-2&tabs=cli%2Cmlflow) to learn how you can track your code connected against an Azure Machine Learning workspace instead of MLflow server.",hi access blob storage always access used perform control plane resource contrary azure data lake gen storage would match scenario however artifact server alternative explore azure machine learning instead server use azure machine learning charge server already paying artifact storage storage may good fit check azure machine learning learn integration configure azure machine learning learn track code connected azure machine learning instead server,issue,positive,positive,positive,positive,positive,positive
1672341526,@akshaya-a do you have any insight into what might be going on here? Thanks!,insight might going thanks,issue,negative,positive,positive,positive,positive,positive
1672110460,"The problem happens in this step:
```#17 [13/14] RUN python -c                     'from mlflow.models.container import _install_pyfunc_deps;                    _install_pyfunc_deps(                        ""/opt/ml/model"",                         install_mlflow=True,                         enable_mlserver=False,                         env_manager=""conda"")'
#17 2.315 2023/08/09 20:15:06 INFO mlflow.models.container: creating and activating custom environment
#17 3.235 Collecting package metadata (repodata.json): ...working... Traceback (most recent call last):
#17 354.9   File ""<string>"", line 1, in <module>
#17 354.9   File ""/miniconda/lib/python3.11/site-packages/mlflow/models/container/__init__.py"", line 115, in _install_pyfunc_deps
#17 354.9     raise Exception(""Failed to create model environment."")
#17 354.9 Exception: Failed to create model environment.
#17 ERROR: process ""/bin/sh -c python -c                     'from mlflow.models.container import _install_pyfunc_deps;                    _install_pyfunc_deps(                        \""/opt/ml/model\"",                         install_mlflow=True,                         enable_mlserver=False,                         env_manager=\""conda\"")'"" did not complete successfully: exit code: 1
------
 > [13/14] RUN python -c                     'from mlflow.models.container import _install_pyfunc_deps;                    _install_pyfunc_deps(                        ""/opt/ml/model"",                         install_mlflow=True,                         enable_mlserver=False,                         env_manager=""conda"")':
2.315 2023/08/09 20:15:06 INFO mlflow.models.container: creating and activating custom environment
Traceback (most recent call last):
354.9   File ""<string>"", line 1, in <module>
354.9   File ""/miniconda/lib/python3.11/site-packages/mlflow/models/container/__init__.py"", line 115, in _install_pyfunc_deps
354.9     raise Exception(""Failed to create model environment."")
354.9 Exception: Failed to create model environment.```",problem step run python import custom environment package working recent call last file string line module file line raise exception create model environment exception create model environment error process python import complete successfully exit code run python import custom environment recent call last file string line module file line raise exception create model environment exception create model,issue,positive,positive,positive,positive,positive,positive
1671900677,"Reopen this for tracking, I have done the installation above and did not work.

Also I think we may want to treat this as an MLFlow-related issue - it's not common to require developers to set up another virtual env at runtime, but if we do, we need to make sure the required libs are installed or at least provide a clear error message. The least we shall do is to fix the quickstart guide. Users could get quickly frustrated if the quickstart guide fails.",reopen done installation work also think may want treat issue common require set another virtual need make sure least provide clear error message least shall fix guide could get quickly guide,issue,positive,positive,neutral,neutral,positive,positive
1670983077,"Did you install `azure-identity` package ?
Could you provide error stack ?",install package could provide error stack,issue,negative,neutral,neutral,neutral,neutral,neutral
1670944230,"Q: For `env_manager` param, its allowed values we should make them to be local/conda/venv, the old ""virtualenv"" value should be deprecated.",param make old value,issue,negative,positive,neutral,neutral,positive,positive
1670722730,"Hi @BenWilson2 , yeah I got it to work as well, thanks!!",hi yeah got work well thanks,issue,positive,positive,positive,positive,positive,positive
1670540702,@serena-ruan please verify the changes here; no one is more knowledgable about this code and the implications of this change than you.,please verify one code change,issue,negative,neutral,neutral,neutral,neutral,neutral
1670518777,HI @machinehead the fix has been merged and will be included in the next release!,hi fix included next release,issue,negative,neutral,neutral,neutral,neutral,neutral
1670123068,"Hi @harupy,
I would love to contribute to any of the remaining test cases, pending for migration.

If it is okay, then I can start working on the `test_all_status_covered`. I do not see this being picked up in this thread. Please let me know.

",hi would love contribute test pending migration start working see picked thread please let know,issue,positive,positive,positive,positive,positive,positive
1670113920,"Hi, 
I am new to Open Source Contribution and would love to give it a start with this issue.
Can you assign me an environment variable as well?

If before assigning you would like to know more about me and my background, please let me know. I will be happy to share.
Thank You.
",hi new open source contribution would love give start issue assign environment variable well would like know background please let know happy share thank,issue,positive,positive,positive,positive,positive,positive
1669921458,"In order to run CI, you will have to move this to an actual PR rather than a Draft.",order run move actual rather draft,issue,negative,neutral,neutral,neutral,neutral,neutral
1669431264,"I think you can rebase now:

```
git rebase master
git push -f origin HEAD
```",think rebase git rebase master git push origin head,issue,negative,neutral,neutral,neutral,neutral,neutral
1669417699,"@Kunj125 You can use the following command to squash commits:

```
git reset $(git merge-base master $(git branch --show-current))
git commit -s -m ""<message>""
```",use following command squash git reset git master git branch git commit message,issue,negative,neutral,neutral,neutral,neutral,neutral
1669356159,Started a PR above for making fluent API threadsafe https://github.com/mlflow/mlflow/pull/9249 - will separately look at making model logging using MlflowClient. I think both changes are valuable independently of each other.,making fluent separately look making model logging think valuable independently,issue,negative,neutral,neutral,neutral,neutral,neutral
1669102576,"> What if we make the model logging APIs work with the existing thread-safe `MlflowClient` API? That sounds potentially easier than making the fluent API threadsafe.

Well I think the making fluent API threadsafe is “easy” if my assessment is right that it’s only those 3 global variables that are the issue.

I can look at the model logging to make it support using Mlflow client too, probably needs an optional arg for run id or a separate method that matches mlflow tracking API closer. But I do think the fluent API makes code so much simpler (not having to pass run IDs everywhere) that it would be nice for it to be thread safe as well.",make model logging work potentially easier making fluent well think making fluent easy assessment right global issue look model logging make support client probably need optional run id separate method closer think fluent code much simpler pas run everywhere would nice thread safe well,issue,positive,positive,positive,positive,positive,positive
1669070727,Thank you @harupy for finishing this PR! (I was away with no access to a computer) :),thank finishing away access computer,issue,negative,neutral,neutral,neutral,neutral,neutral
1668940027,Thanks! Let's post those in the team channel :),thanks let post team channel,issue,negative,positive,positive,positive,positive,positive
1668901386,Thanks @WeichenXu123! I'll research implementation models to add in the description.,thanks research implementation add description,issue,negative,positive,positive,positive,positive,positive
1668877403,"Sure, sir...👍

> @Sai-Suraj-27 interested in working on this?",sure sir interested working,issue,positive,positive,positive,positive,positive,positive
1668841640,@serena-ruan Can you take a recording of the progress bar on databricks and local terminal?,take recording progress bar local terminal,issue,negative,neutral,neutral,neutral,neutral,neutral
1668770896,"Awesome that's what I figured but I wanted to make sure - it wouldn't have been the first time I overlooked something in documentation after all 😆 

Thanks again for all of your help getting me sorted. 🙌 ",awesome figured make sure would first time something documentation thanks help getting sorted,issue,positive,positive,positive,positive,positive,positive
1668737095,"> Can we make `mlflow.autolog` emit warning that it is thread-unsafe when it detects it is called from different threads ?

Maybe, but I'd prefer to support thread-safe model logging. Much more self-contained and also helpful for users of the `MlflowClient` API :D",make emit warning different maybe prefer support model logging much also helpful,issue,negative,positive,neutral,neutral,positive,positive
1668736077,Can we make `mlflow.autolog` emit warning that it is thread-unsafe when it detects it is called from different threads ? ,make emit warning different,issue,negative,neutral,neutral,neutral,neutral,neutral
1668728153,What if we make the model logging APIs work with the existing thread-safe `MlflowClient` API? That sounds potentially easier than making the fluent API threadsafe.,make model logging work potentially easier making fluent,issue,negative,neutral,neutral,neutral,neutral,neutral
1668725654,"> Q:
> 
> What if we save these ""inference config"" as part of model metadata ? For custom model, we allow user to define arbitrary extra model metadata

The storage of the inference configuration is not the important part here. Basically, the idea of inference configuration is to provide a contract that enables the model builder to publish which are the options available to run (or deploy) the model. Metadata is not intended to do that. Metadata is closer to tags, but immutable to the model. Inference configuration is closer to the recent introduction of parameters, but for model loading time instead of prediction time. Does it make sense @WeichenXu123?",save inference part model custom model allow user define arbitrary extra model storage inference configuration important part basically idea inference configuration provide contract model builder publish available run deploy model intended closer immutable model inference configuration closer recent introduction model loading time instead prediction time make sense,issue,positive,positive,positive,positive,positive,positive
1668720348,"This feature makes sense !

```
_active_run_stack = []
_active_experiment_id = None
_last_active_run_id = None
```

do these cover all global shared variables that causes thread unsafe ?",feature sense none none cover global thread unsafe,issue,negative,neutral,neutral,neutral,neutral,neutral
1668718280,"> in order to have some value logged for the model registry ""creator"" the MLflow auth framework has to be used?

Oh I got it. You mean the creator field is empty in non-auth mode:
<img width=""1066"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/19235986/9ea660d2-736b-44e8-9fb2-f3fa67255cb4"">

Because in non-auth mode we don't have user information in server side so we cannot fill this field. If you have to record creator, you have to enable auth mode",order value logged model registry creator framework used oh got mean creator field empty mode image mode user information server side fill field record creator enable mode,issue,negative,negative,negative,negative,negative,negative
1668698703,"Hi @s-aditi I just got around to working on a repro for this. 
In the code that you posted, there are a number of issues. 

Below are the modifications to use the exact model architecture that you defined. I've confirmed that the model works as intended. 

Please run the following to confirm:

```python
from transformers import AutoTokenizer, AutoModelForMaskedLM
import mlflow

# define the model architecture that will be fetched from huggingface_hub
model_architecture = ""bert-base-cased""

# define an artifact path to use for saving the pipeline artifact components
model_name = ""mask_model_2""

# Download and locally cache the appropriate tokenizer and model
tokenizer = AutoTokenizer.from_pretrained(model_architecture)
model = AutoModelForMaskedLM.from_pretrained(model_architecture)

# Define the components for the Masked Language Model
components = {
    ""model"": model,
    ""tokenizer"": tokenizer,
}

# Initialize the MLflow run context
with mlflow.start_run():
    # Log the transformers components to the defined artifact path
    mlflow.transformers.log_model(
        transformers_model=components,
        artifact_path=model_name,
    )
    # retrieve the absolute model_uri path
    model_uri = mlflow.get_artifact_uri(model_name)

# Load as pyfunc directly    
mdl = mlflow.pyfunc.load_model(model_uri)

# cli command for starting an MLflow serving instance for this model (run the output printed to stdout 
#  in your command line environment to spin up a local server to send REST requests to)
print(f""mlflow models serve -m {model_uri} -h 127.0.0.1 -p 9070 --no-conda"")
```

To use the loaded pyfunc model directly:

```python 
mdl.predict(""What [MASK] is this?"")
mdl.predict([""I [MASK] using LLMs!"", ""I like to [MASK] apples and bananas""])
```

To validate the serving behavior, execute the printed statement from the first code block above in a new terminal window. Then, issue a REST POST to the endpoint:

```python
import requests
import json

url = ""http://127.0.0.1:9070/invocations""

headers = {
    'Content-Type': 'application/json',
}

data = {
    ""inputs"": [""I like to [MASK] on an airplane"", ""[MASK] is the best color""],
}

response = requests.post(url, headers=headers, data=json.dumps(data))

print(response.content)
```

Can you verify that this works on your system?  
Feel free to open this ticket back up if you encounter additional issues, but I'm closing this due to the flavor demonstrating correct behavior with appropriate applied usage of it. ",hi got around working code posted number use exact model architecture defined confirmed model work intended please run following confirm python import import define model architecture fetched define artifact path use saving pipeline artifact locally cache appropriate model model define masked language model model model initialize run context log defined artifact path retrieve absolute path load directly command starting serving instance model run output printed command line environment spin local server send rest print serve use loaded model directly python mask mask like mask validate serving behavior execute printed statement first code block new terminal window issue rest post python import import data like mask airplane mask best color response data print verify work system feel free open ticket back encounter additional due flavor correct behavior appropriate applied usage,issue,positive,positive,positive,positive,positive,positive
1668687966,"Hi @harupy, any updates on this? we had similar issue when migrate auth DB to mysql when running:
python -m mlflow.server.auth db upgrade --url mysql+pymysql://xxx:xxxxxxxx@dbhost:3306/auth_db,

the error is:
pymysql.err.OperationalError: (1045, ""Access denied for user 'xxx'@'xxxxxxxx' (using password: YES)"")

",hi similar issue migrate running python upgrade error access user password yes,issue,negative,neutral,neutral,neutral,neutral,neutral
1668590595,"@dmatrix I would be happy to contribute to this feature as well, so we can move away from pooling states ;-)",would happy contribute feature well move away,issue,positive,positive,positive,positive,positive,positive
1668347178,"Sure no problem! 



<details><summary>docker-compse.yml</summary>

```yml  

version: ""3""
services:
  minio:
    image: minio/minio
    expose:
      - ""9000""
    ports:
      - ""9000:9000""
      # MinIO Console is available at http://localhost:9001
      - ""9001:9001""
    environment:
      # these need to be set somewhere, probably strongly if you don't
      # set them the default value of minioadmin is set to both
      MINIO_ROOT_USER: ""user""
      MINIO_ROOT_PASSWORD: ""password""
    healthcheck:
      test: [""CMD"", ""curl"", ""-f"", ""http://localhost:9000/minio/health/live""]
      interval: 1s
      timeout: 10s
      retries: 5
    # Note there is no bucket by default
    command: server /data --console-address "":9001""

  minio-create-bucket:
    image: minio/mc
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: >
      bash -c ""
      mc alias set minio http://minio:9000 user password &&
      if ! mc ls minio | grep --quiet bucket; then
        mc mb minio/bucket
      else
        echo 'bucket already exists'
      fi
      ""
  postgres:
    image: postgres
    restart: always
    environment:
      POSTGRES_DB: db
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password

  tracking_server:
    build:
      context: .
      dockerfile: ""${DOCKERFILE:-Dockerfile}""
    depends_on:
      - postgres
     # - artifacts_server
    expose:
      - ""5000""
    ports:
      # MLflow UI is available at http://localhost:5000
      - ""5000:5000""
    environment:
      MLFLOW_S3_ENDPOINT_URL: http://minio:9000
      AWS_ACCESS_KEY_ID: ""user""
      AWS_SECRET_ACCESS_KEY: ""password""
    command: >
      mlflow server
      --host 0.0.0.0
      --port 5000
      --backend-store-uri postgresql://user:password@postgres:5432/db
      --artifacts-destination s3://bucket
      --gunicorn-opts ""--log-level debug""

```
</details>


To use this you'll need to update the MLFLOW_TRACKING_URI variable to whatever system you run the dockerized MLflow on. 

I would expect that the call to `mlflow.sklearn.log_model()` would implicitly log something (perhaps the user of the system I'm on for this like jupyter) for the `Creator` field in the UI but it does not. I looked through the docs and didn't see any means of setting that field manually, so I'm not sure how it is done without basic auth implemented.

<details><summary>mlflow_model_registration.ipynb</summary>

### Cell 1

``` python

# shamelessly copied from some example code in the MLflow repo 
# and repurposed for demo/documentation

# define and save model
import numpy as np
import pickle

from sklearn import datasets, linear_model
from sklearn.metrics import mean_squared_error, r2_score

# source: https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html

# Load the diabetes dataset
diabetes_X, diabetes_y = datasets.load_diabetes(return_X_y=True)

# Use only one feature
diabetes_X = diabetes_X[:, np.newaxis, 2]

# Split the data into training/testing sets
diabetes_X_train = diabetes_X[:-20]
diabetes_X_test = diabetes_X[-20:]

# Split the targets into training/testing sets
diabetes_y_train = diabetes_y[:-20]
diabetes_y_test = diabetes_y[-20:]


def print_predictions(m, y_pred):
    # The coefficients
    print(""Coefficients: \n"", m.coef_)
    # The mean squared error
    print(""Mean squared error: %.2f"" % mean_squared_error(diabetes_y_test, y_pred))
    # The coefficient of determination: 1 is perfect prediction
    print(""Coefficient of determination: %.2f"" % r2_score(diabetes_y_test, y_pred))


# Create linear regression object
lr_model = linear_model.LinearRegression()

# Train the model using the training sets
lr_model.fit(diabetes_X_train, diabetes_y_train)

# Make predictions using the testing set
diabetes_y_pred = lr_model.predict(diabetes_X_test)
print_predictions(lr_model, diabetes_y_pred)

# save the model in the native sklearn format
filename = ""test_lr_model.pkl""
pickle.dump(lr_model, open(filename, ""wb""))
```

### Cell 2

```python 

# load in the saved scikit model and register it with MLflow

import mlflow
from mlflow.models.signature import infer_signature
import numpy as np
from sklearn import datasets

# load the model into memory
loaded_model = pickle.load(open(filename, ""rb""))

MLFLOW_TRACKING_URI = {update to host/endpoint where dockerized MLflow is running}

# create a signature for the model based on the input and output data
diabetes_X, diabetes_y = datasets.load_diabetes(return_X_y=True)
diabetes_X = diabetes_X[:, np.newaxis, 2]
signature = infer_signature(diabetes_X, diabetes_y)

# log and register the model using MLflow scikit-learn API
# mlflow.set_tracking_uri(""sqlite:///mlruns.db"")

mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)
reg_model_name = ""SklearnLinearRegression""
artifact_path = ""sk_learn""
mlflow.set_experiment(reg_model_name + ""/"" + artifact_path)
print(""--"")
mlflow.sklearn.log_model(
    loaded_model,
    artifact_path,
    serialization_format=""cloudpickle"",
    signature=signature,
    registered_model_name=reg_model_name,
)
```
### Cell 3

```python 
# load the model from the Model Registry and score
#model_uri = f""/sk_learn/{reg_model_name}/1""
model_uri = ""models:/SklearnLinearRegression/1""
#s3://bucket/path/to/model
a_new_loaded_model = mlflow.sklearn.load_model(model_uri)
print(""--"")

# Make predictions using the testing set
diabetes_y_pred = a_new_loaded_model.predict(diabetes_X_test)
print_predictions(a_new_loaded_model, diabetes_y_pred)
```
</details>


Thanks again for all your help!",sure problem summary version image expose console available environment need set somewhere probably strongly set default value set user password test curl interval note bucket default command server image condition bash alias set user password quiet bucket else echo already fi image restart always environment user password build context expose available environment user password command server host port password use need update variable whatever system run would expect call would implicitly log something perhaps user system like creator field see setting field manually sure done without basic summary cell python shamelessly copied example code define save model import import pickle import import source load diabetes use one feature split data split print mean squared error print mean squared error coefficient determination perfect prediction print coefficient determination create linear regression object train model training make testing set save model native format open cell python load saved model register import import import import load model memory open update running create signature model based input output data signature log register model print cell python load model model registry score print make testing set thanks help,issue,positive,positive,positive,positive,positive,positive
1668114584,"> @Sai-Suraj-27 Can we remove unused imports?

Sure, sir. 👍",remove unused sure sir,issue,negative,positive,positive,positive,positive,positive
1667614952,"I locally tested `UP030` and there is no code violating this rule in this repository, so all we need to do is just add `UP030` to the `select` list.",locally tested code rule repository need add select list,issue,negative,neutral,neutral,neutral,neutral,neutral
1667602907,"Hi, can you please assign me an environment variable?",hi please assign environment variable,issue,negative,neutral,neutral,neutral,neutral,neutral
1667588255,"Bump, would also be a fan of this, both Aim and WnB include it.",bump would also fan aim include,issue,negative,neutral,neutral,neutral,neutral,neutral
1667568748,Looks like it is bug related to langchain. Let me raise a bug there then :),like bug related let raise bug,issue,negative,neutral,neutral,neutral,neutral,neutral
1667564995,"@RamishSiddiqui 

```python
import os
from langchain import PromptTemplate, LLMChain
from langchain.llms import HuggingFacePipeline


os.environ[""CURL_CA_BUNDLE""] = """"
if True:  # run the following code to download the model flan-t5-small from huggingface.co
    from transformers import pipeline

    model = pipeline(model=""google/flan-t5-small"")  #'text2text-generation'
    model.save_pretrained(""/tmp/model/flan-t5-small"")

llm = HuggingFacePipeline.from_model_id(
    model_id=""/tmp/model/flan-t5-small"",
    task=""text2text-generation"",
    model_kwargs={""temperature"": 1e-10},
)

template = """"""Translate everything you see after this into French:

{input}
""""""

prompt = PromptTemplate(template=template, input_variables=[""input""])

llm_chain = LLMChain(prompt=prompt, llm=llm)

print(llm_chain(""my name is John""))  # works

llm_chain.save(""llm_chain.json"")

from langchain.chains import load_chain

m = load_chain(""llm_chain.json"")

print(m(""my name is John""))
```

can reproduce the exact same error. This is not an MLflow's issue:

```
{'input': 'my name is John', 'text': "" toutefois, je suis en uvre à l'heure""}
Traceback (most recent call last):
  File ""a.py"", line 37, in <module>
  File ""/home/haru/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/langchain/chains/base.py"", line 258, in __call__
    raise e
  File ""/home/haru/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/langchain/chains/base.py"", line 252, in __call__
    self._call(inputs, run_manager=run_manager)
  File ""/home/haru/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/langchain/chains/llm.py"", line 92, in _call
    response = self.generate([inputs], run_manager=run_manager)
  File ""/home/haru/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/langchain/chains/llm.py"", line 102, in generate
    return self.llm.generate_prompt(
  File ""/home/haru/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/langchain/llms/base.py"", line 451, in generate_prompt
    return self.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)
  File ""/home/haru/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/langchain/llms/base.py"", line 582, in generate
    output = self._generate_helper(
  File ""/home/haru/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/langchain/llms/base.py"", line 488, in _generate_helper
    raise e
  File ""/home/haru/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/langchain/llms/base.py"", line 475, in _generate_helper
    self._generate(
  File ""/home/haru/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/langchain/llms/base.py"", line 961, in _generate
    self._call(prompt, stop=stop, run_manager=run_manager, **kwargs)
  File ""/home/haru/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/langchain/llms/huggingface_pipeline.py"", line 168, in _call
    response = self.pipeline(prompt)
TypeError: 'NoneType' object is not callable
```
",python import o import import true run following code model import pipeline model pipeline temperature template translate everything see input prompt input print name work import print name reproduce exact error issue name en recent call last file line module file line raise file line file line response file line generate return file line return file line generate output file line raise file line file line prompt file line response prompt object callable,issue,negative,positive,positive,positive,positive,positive
1667549626,"```python
import mlflow
from datetime import datetime
import logging

logging.getLogger(""mlflow"").setLevel(logging.DEBUG)

from langchain import PromptTemplate, LLMChain, HuggingFaceHub
from langchain.llms import HuggingFacePipeline
import os


def now_str():
    return datetime.now().strftime(""%Y%m%d%H%M%S"")


os.environ[""CURL_CA_BUNDLE""] = """"
if True:  # run the following code to download the model flan-t5-small from huggingface.co
    from transformers import pipeline

    model = pipeline(model=""google/flan-t5-small"")  #'text2text-generation'
    model.save_pretrained(""/tmp/model/flan-t5-small"")

llm = HuggingFacePipeline.from_model_id(
    model_id=""/tmp/model/flan-t5-small"",
    task=""text2text-generation"",
    model_kwargs={""temperature"": 1e-10},
)

template = """"""Translate everything you see after this into French:

{input}
""""""

prompt = PromptTemplate(template=template, input_variables=[""input""])

llm_chain = LLMChain(prompt=prompt, llm=llm)

print(llm_chain.run(""my name is John""))  # This is working !!
# Output: {'input': 'my name is John', 'text': ""j'ai le nom de John""}


experiment_id = mlflow.create_experiment(f""HF_LLM_{now_str()}"")

with mlflow.start_run(experiment_id=experiment_id) as run:
    logged_model = mlflow.langchain.log_model(
        lc_model=llm_chain,
        artifact_path=""HF_LLM"",
    )

m = mlflow.langchain.load_model(logged_model.model_uri)
m.run(""my name is John"")
```

gives:

```
Traceback (most recent call last):
  File ""a.py"", line 51, in <module>
    m.run(""my name is John"")
  File ""/home/haru/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/langchain/chains/base.py"", line 451, in run
    return self(args[0], callbacks=callbacks, tags=tags, metadata=metadata)[
  File ""/home/haru/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/langchain/chains/base.py"", line 258, in __call__
    raise e
  File ""/home/haru/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/langchain/chains/base.py"", line 252, in __call__
    self._call(inputs, run_manager=run_manager)
  File ""/home/haru/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/langchain/chains/llm.py"", line 92, in _call
    response = self.generate([inputs], run_manager=run_manager)
  File ""/home/haru/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/langchain/chains/llm.py"", line 102, in generate
    return self.llm.generate_prompt(
  File ""/home/haru/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/langchain/llms/base.py"", line 451, in generate_prompt
    return self.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)
  File ""/home/haru/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/langchain/llms/base.py"", line 582, in generate
    output = self._generate_helper(
  File ""/home/haru/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/langchain/llms/base.py"", line 488, in _generate_helper
    raise e
  File ""/home/haru/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/langchain/llms/base.py"", line 475, in _generate_helper
    self._generate(
  File ""/home/haru/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/langchain/llms/base.py"", line 961, in _generate
    self._call(prompt, stop=stop, run_manager=run_manager, **kwargs)
  File ""/home/haru/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/langchain/llms/huggingface_pipeline.py"", line 168, in _call
    response = self.pipeline(prompt)
TypeError: 'NoneType' object is not callable
```

Looks like lanhchain doesn't restore the pipeline.",python import import import logging import import import o return true run following code model import pipeline model pipeline temperature template translate everything see input prompt input print name working output name de run name recent call last file line module name file line run return self file line raise file line file line response file line generate return file line return file line generate output file line raise file line file line prompt file line response prompt object callable like restore pipeline,issue,positive,positive,neutral,neutral,positive,positive
1667291582,"Q:

What if we save these ""inference config"" as part of model metadata ? For custom model, we allow user to define arbitrary extra model metadata",save inference part model custom model allow user define arbitrary extra model,issue,positive,negative,neutral,neutral,negative,negative
1667283267,"> I don't know if I can use a predefined model

surely you can use it, you can see examples in [examples/transformers](https://github.com/mlflow/mlflow/tree/master/examples/transformers)",know use model surely use see,issue,negative,positive,positive,positive,positive,positive
1667280290,Could you provide full reproducing code (including the custom model definition classes and how you create and save the custom model),could provide full code custom model definition class create save custom model,issue,positive,positive,positive,positive,positive,positive
1667191070,This issue is old. Filed a new one: #9228.,issue old new one,issue,negative,positive,positive,positive,positive,positive
1667131575,"> we usually `requirements/core-requirements.yaml` when we release a new version

Thank you for reviewing and letting me know. I'll keep that in mind in the future :)

",usually release new version thank know keep mind future,issue,negative,negative,neutral,neutral,negative,negative
1667057367,">  in order to have some value logged for the model registry ""creator"" the MLflow auth framework has to be used?

I don't think so, why it cannot be logged without auth ? do you have repro code ?",order value logged model registry creator framework used think logged without code,issue,negative,neutral,neutral,neutral,neutral,neutral
1667052943,"@chenmoneygithub I don't think this is an MLflow issue. Installing `libssl-dev` and `libbz2-dev` should fix the issue:

- https://stackoverflow.com/a/12806325
- https://stackoverflow.com/a/37828891",think issue fix issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1667049432,@RFT86 Feel free to reopen the issue once you find how to reproduce the issue.,feel free reopen issue find reproduce issue,issue,positive,positive,positive,positive,positive,positive
1667013039,"File ""/usr/local/lib/python3.11/site-packages/mlflow/store/artifact/mlflow_artifacts_repo.py"", line 35, in _validate_uri_scheme
  raise MlflowException(
mlflow.exceptions.MlflowException: The configured tracking uri scheme: 'file' is invalid for use with the proxy mlflow-artifact scheme. The allowed tracking schemes are: {'http', 'https'}
 exited with code 1

 The feels - I also don't get any error when running locally, only when creating an mlflow ui or server, with the 0.0.0.0 host on docker. ",file line raise scheme invalid use proxy scheme code also get error running locally server host docker,issue,negative,neutral,neutral,neutral,neutral,neutral
1666971162,"Hello @michalisfrangos , did you fixed that error , please help me with the solution .",hello fixed error please help solution,issue,positive,positive,neutral,neutral,positive,positive
1666905396,"I too had issues of ML Flow UI not showing any data even though they were created under the tracking URI. Hope the below helps someone.

In my case I just created a folder under my project directory 
mlflow.set_tracking_uri(""./model_metrics"")
And below for activating mlflow.
experiment_id= mlflow.start_run()
    # Start an MLflow run
    with experiment_id:
         # capture your logs
Run MLFlow UI command along with --backend-store-uri=./model_metrics.

",flow showing data even though hope someone case folder project directory start run capture run command along,issue,negative,neutral,neutral,neutral,neutral,neutral
1666577871,"Just to clarify in order to have some value logged for the model registry ""creator"" the MLflow auth framework has to be used?",clarify order value logged model registry creator framework used,issue,negative,neutral,neutral,neutral,neutral,neutral
1666525193,"> I'll be hosting this in a lab environment that probably will only typically see somewhere in the scale of a few dozen users. The very most I can imagine ever trying to use this would still be no more than maybe 200 people

This use-case, the simplified architecture I mentioned above should work fine 

For auth related issues, you can refer to doc here https://mlflow.org/docs/latest/auth/index.html",hosting lab environment probably typically see somewhere scale dozen imagine ever trying use would still maybe people simplified architecture work fine related refer doc,issue,negative,positive,neutral,neutral,positive,positive
1666496678,"how to file pr in this repository from fork repository
",file repository fork repository,issue,negative,neutral,neutral,neutral,neutral,neutral
1666472491,"@Rukiyav you filed a PR in your fork, but you need to file a PR in this repository",fork need file repository,issue,negative,neutral,neutral,neutral,neutral,neutral
1666444621,@harupy I can take on this feature. Maybe one storage provider at a time,take feature maybe one storage provider time,issue,negative,neutral,neutral,neutral,neutral,neutral
1666443807,"@Rukiyav If it's challenging for you to make a commit on codespace, you can manually fix this line **on GitHub UI** and file a PR:

https://github.com/mlflow/mlflow/blob/b52e41732a9ee0863c686bf046adc1e0d44972c2/tests/spark/autologging/datasource/test_spark_datasource_autologging.py#L18

```
    expected_path = f""file:{path}""
```",make commit manually fix line file file path,issue,negative,neutral,neutral,neutral,neutral,neutral
1666435678,"> Did you really run `git commit`?

yes iam running it again",really run git commit yes running,issue,positive,positive,positive,positive,positive,positive
1666435448,"Run this command:

```
git add .
git commit -s -m ""replace percent formatting""
git push origin HEAD
```",run command git add git commit replace percent git push origin head,issue,negative,neutral,neutral,neutral,neutral,neutral
1666435315,Did you really run `git commit`?,really run git commit,issue,negative,positive,positive,positive,positive,positive
1666434490,"this command is working ,it is giving me message Everything up-to-date
but i cant able to file pr",command working giving message everything cant able file,issue,negative,positive,positive,positive,positive,positive
1666431622,"then you can push it to the `ruk` branch in your fork: https://github.com/Rukiyav/mlflow/tree/ruk.

```
git push origin HEAD
```

should do.",push branch fork git push origin head,issue,negative,neutral,neutral,neutral,neutral,neutral
1666426000,Did you make a commit with `git commit`?,make commit git commit,issue,positive,neutral,neutral,neutral,neutral,neutral
1666425036,Git: bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8) and this too,git bash warning change locale,issue,negative,neutral,neutral,neutral,neutral,neutral
1666424622,when i try to create pull request form codespaces after running file it is There are no commits between the base master branch and the comparing ruk branch giving me this,try create pull request form running file base master branch branch giving,issue,positive,negative,negative,negative,negative,negative
1666412390,@Rukiyav All you need to do is just run the code. The code automatically transformed percent formatting into f-strings.,need run code code automatically percent,issue,negative,neutral,neutral,neutral,neutral,neutral
1666381449,"Hi @WeichenXu123 thanks for your response. 

I'll be hosting this in a lab environment that probably will only typically see somewhere in the scale of a few dozen users. The very most I can imagine ever trying to use this would still be no more than maybe 200 people?

If this more simple configuration works well for our scale I'm content with it, I spun up and used a simple test notebook and things look good in the MLflow UI now. 

But I did notice that the creator field isn't getting populated in the model registry which probably make sense because there isn't any auth in place at the moment. Is that something that would be resolved by incorporating the basic auth work that has been added recently, or is that something that can also be set with some method in the mlflow python api? I searched around the documents and don't see an obvious way to set that like the tracking uri, experiment name, and tags.

Thanks again for your help :)",hi thanks response hosting lab environment probably typically see somewhere scale dozen imagine ever trying use would still maybe people simple configuration work well scale content spun used simple test notebook look good notice creator field getting model registry probably make sense place moment something would resolved basic work added recently something also set method python around see obvious way set like experiment name thanks help,issue,positive,positive,positive,positive,positive,positive
1666031878,"Could we simply import a simple callback function when the model transition happens. Rest, the client/backend deployment teams could take the initiative for the same.

One use case:
1. We may have an integration with airflow/github repo - call their DAG or github build through the custom callbacks. I guess, this approach would work. Cause, I am thinking of generating certain events like this.",could simply import simple function model transition rest deployment could take initiative one use case may integration call dag build custom guess approach would work cause thinking generating certain like,issue,positive,positive,neutral,neutral,positive,positive
1665736312,"> @jsnb-devoted Thanks for the FR!
> 
> > In the absence of any RBAC we don't have any mechanism to prevent a user from going in to the UI and calling any model they want ""production"".
> 
> Correct. Currently, MLflow doesn't provide a way to turn off transitioning model stages on UI (the only workaround is to fork this repo and modify the UI source code).
> 
> ```diff
> diff --git a/mlflow/server/js/src/model-registry/components/ModelVersionView.js b/mlflow/server/js/src/model-registry/components/ModelVersionView.js
> index cab8f6774..4145ebe81 100644
> --- a/mlflow/server/js/src/model-registry/components/ModelVersionView.js
> +++ b/mlflow/server/js/src/model-registry/components/ModelVersionView.js
> @@ -258,7 +258,7 @@ export class ModelVersionViewImpl extends React.Component {
>      const defaultOrder = [
>        this.renderRegisteredTimestampDescription(modelVersion.creation_timestamp),
>        this.renderCreatorDescription(modelVersion.user_id),
> -      this.renderStageDropdown(modelVersion),
> +      // this.renderStageDropdown(modelVersion),
>        this.renderLastModifiedDescription(modelVersion.last_updated_timestamp),
>        this.renderSourceRunDescription(),
>      ];
> ```
> 
> We're going to discuss this in the team and get back to you.

Hi,

Thanks for this workaround.

Since this issue was Open, have you got any feedback about the possible integration of an RBAC mechanism (even basic, for example displaying the Stage Dropdown based on a new permission) into mlflow ?

Thanks in advance !",thanks absence mechanism prevent user going calling model want production correct currently provide way turn model fork modify source code git index export class going discus team get back hi thanks since issue open got feedback possible integration mechanism even basic example stage based new permission thanks advance,issue,positive,positive,neutral,neutral,positive,positive
1665611930,"I am trying to deploy MLFLOW using artfact store as ""s3"" and backend store as ""rds"" on AWS Fargate ECS Service!",trying deploy store store service,issue,negative,neutral,neutral,neutral,neutral,neutral
1665590893,Sounds good. Let me know if you want to need a quick call.,good let know want need quick call,issue,negative,positive,positive,positive,positive,positive
1665589945,thank you so much i will check this out and tell u know,thank much check tell know,issue,negative,positive,positive,positive,positive,positive
1665567745,"1. Create a fork: https://docs.github.com/en/get-started/quickstart/fork-a-repo
2. I think codespace is easiest to start with: 
   - https://docs.github.com/en/codespaces/developing-in-codespaces/creating-a-codespace-for-a-repository
4. Once the codespace is ready, you can save the code in the issue description as `a.py` and run it, then file a PR.

Let me know if you have any questions.",create fork think easiest start ready save code issue description run file let know,issue,positive,positive,positive,positive,positive,positive
1665563635,"1. Create a fork: https://docs.github.com/en/get-started/quickstart/fork-a-repo
2. I think codespace is easiest to start with: https://docs.github.com/en/codespaces/developing-in-codespaces/using-github-codespaces-for-pull-requests",create fork think easiest start,issue,positive,neutral,neutral,neutral,neutral,neutral
1665543570,"Hey folks, it looks this change cause vulnerability issue. (Info is given [here](https://vulners.com/veracode/VERACODE:41941)) Could you take a look again?",hey change cause vulnerability issue given could take look,issue,negative,neutral,neutral,neutral,neutral,neutral
1665531514,"iam actually beginner in contributing but Iam really interested to learn so can u please teach me
_",actually beginner really interested learn please teach,issue,positive,positive,positive,positive,positive,positive
1665525355,"hey is this issue open?
can i contribute",hey issue open contribute,issue,negative,neutral,neutral,neutral,neutral,neutral
1665440361,"@gabrielfu: Based on our discussion, should I change the issue description to mention adding support for groups? Also, I may be able to contribute a PR for this once my other PR (#9191) is reviewed and merged. (One thing at a time for me, ha ha.)",based discussion change issue description mention support also may able contribute one thing time ha ha,issue,positive,positive,positive,positive,positive,positive
1665437544,@harupy: We had discussed the design of this on the related issue (#9066). Just wanted to make you aware of the PR. No rush. Thanks for your help!,design related issue make aware rush thanks help,issue,positive,positive,positive,positive,positive,positive
1665349059,"@dbczusmar @harupy , please brink back the **show diff** button.",please brink back show button,issue,negative,neutral,neutral,neutral,neutral,neutral
1665337070,"OK. Because this is not an urgent feature, we will wait for volunteers in community to pick up this task. We will review contribution PR once someone create it.",urgent feature wait community pick task review contribution someone create,issue,negative,neutral,neutral,neutral,neutral,neutral
1665317962,"We also need to consider overhead of updating these metrics,
e.g., for sql backend mlflow service, accumulate these metrics and store them to database causes overhead, we need some design, e.g., we can accumulate these metric values in memory, then flush updated metrics to database periodically. ",also need consider overhead metric service accumulate metric store overhead need design accumulate metric memory flush metric periodically,issue,negative,neutral,neutral,neutral,neutral,neutral
1665313765,Could you elaborate this FR ? list all server metrics and motivation that why these metrics are useful,could elaborate list server metric motivation metric useful,issue,positive,positive,positive,positive,positive,positive
1665290756,"I want to know your use case, usually I think we can use a simpler architecture: run only one mlflow server that serves both artifacts and mlflow tracking. This is easier to config:

Assuming you have set up postgre node and s3 service node, then, starts a node for mlflow server:

prepare environment variables firstly:
```
    environment variables:
      MLFLOW_S3_ENDPOINT_URL: http://minio:9000
      AWS_ACCESS_KEY_ID: ""user""
      AWS_SECRET_ACCESS_KEY: ""password""
```

start mlflow server:
```
      mlflow server
      --host 0.0.0.0
      --port 5000
      --backend-store-uri postgresql://user:password@postgres:5432/db
      --artifacts-destination s3://bucket
```
Does this simplified architecture address your use case ?",want know use case usually think use simpler architecture run one server easier assuming set node service node node server prepare environment firstly environment user password start server server host port password simplified architecture address use case,issue,negative,neutral,neutral,neutral,neutral,neutral
1665214303,"I am not a front end developer at all, I really don't know how to help.",front end developer really know help,issue,negative,positive,positive,positive,positive,positive
1665194000,I don't think this is a bug. Not sure when or how this function is called though. MLflow logs artifacts but doesn't log modules or packages or files in `~/.cache/huggingface/modules`.,think bug sure function though log,issue,negative,positive,positive,positive,positive,positive
1665105595,"@Rukiyav Thanks for the comment! Unfortunately no. @scarlettrobe already filed a PR to close this issue. We have https://github.com/mlflow/mlflow/issues/9008, which is also a good first issue.",thanks comment unfortunately already close issue also good first issue,issue,positive,positive,positive,positive,positive,positive
1665085008,"hey is this issue still open 
",hey issue still open,issue,negative,neutral,neutral,neutral,neutral,neutral
1665077816,"> Just out of curiosity, how did you find this issue?

https://goodfirstissue.dev/language/python

Wanted to find something related to ML and now here I am. ",curiosity find issue find something related,issue,negative,neutral,neutral,neutral,neutral,neutral
1665069026,"This seems like a simple issue I can easily knock out!
",like simple issue easily knock,issue,positive,positive,positive,positive,positive,positive
1664967511,"> I found this code:
> 
> https://github.com/huggingface/datasets/blob/ef17d9fd6c648bb41d43ba301c3de4d7b6f833d8/src/datasets/load.py#L92C1-L107C32
> 
> ```python
> def init_dynamic_modules(
>     name: str = config.MODULE_NAME_FOR_DYNAMIC_MODULES, hf_modules_cache: Optional[Union[Path, str]] = None
> ):
>     """"""
>     Create a module with name `name` in which you can add dynamic modules
>     such as metrics or datasets. The module can be imported using its name.
>     The module is created in the HF_MODULE_CACHE directory by default (~/.cache/huggingface/modules) but it can
>     be overridden by specifying a path to another directory in `hf_modules_cache`.
>     """"""
>     hf_modules_cache = init_hf_modules(hf_modules_cache)
>     dynamic_modules_path = os.path.join(hf_modules_cache, name)
>     os.makedirs(dynamic_modules_path, exist_ok=True)
>     if not os.path.exists(os.path.join(dynamic_modules_path, ""__init__.py"")):
>         with open(os.path.join(dynamic_modules_path, ""__init__.py""), ""w""):
>             pass
>     return dynamic_modules_path
> ```
> 
> It looks like huggingface creates module and stores it in `~/.cache/huggingface/modules`?
> 
> Let's say you have two machines A and B. You train and log a model on A, and download it on B. I think A has `datasets_modules`, but B doesn't.

Hmm till now, this is the best answer I got. But is this a bug? I mean `mlflow` supports logging artifacts to remote storages and also loading from them. I saw blame, and looks like this snippet has been there for years, how can this bug appear for the first time? (I have searched in issues and found no clues about this issue)
![image](https://github.com/mlflow/mlflow/assets/88246407/17f43b55-6f04-4b88-9e43-88d062f06147)
",found code python name optional union path none create module name name add dynamic metric module name module directory default path another directory name open pas return like module let say two train log model think till best answer got bug mean logging remote also loading saw blame like snippet bug appear first time found issue image,issue,positive,positive,positive,positive,positive,positive
1664841791,"I found this code:

https://github.com/huggingface/datasets/blob/ef17d9fd6c648bb41d43ba301c3de4d7b6f833d8/src/datasets/load.py#L92C1-L107C32

```python
def init_dynamic_modules(
    name: str = config.MODULE_NAME_FOR_DYNAMIC_MODULES, hf_modules_cache: Optional[Union[Path, str]] = None
):
    """"""
    Create a module with name `name` in which you can add dynamic modules
    such as metrics or datasets. The module can be imported using its name.
    The module is created in the HF_MODULE_CACHE directory by default (~/.cache/huggingface/modules) but it can
    be overridden by specifying a path to another directory in `hf_modules_cache`.
    """"""
    hf_modules_cache = init_hf_modules(hf_modules_cache)
    dynamic_modules_path = os.path.join(hf_modules_cache, name)
    os.makedirs(dynamic_modules_path, exist_ok=True)
    if not os.path.exists(os.path.join(dynamic_modules_path, ""__init__.py"")):
        with open(os.path.join(dynamic_modules_path, ""__init__.py""), ""w""):
            pass
    return dynamic_modules_path
```

It looks like huggingface creates module and stores it in `~/.cache/huggingface/modules`?


Let's say you have two machines A and B. You train and log a model on A, and download it on B. I think A has `datasets_modules`, but B doesn't.",found code python name optional union path none create module name name add dynamic metric module name module directory default path another directory name open pas return like module let say two train log model think,issue,positive,neutral,neutral,neutral,neutral,neutral
1664836386,@PhucLee2605 Thanks! Can you share your code that logs the model?,thanks share code model,issue,positive,positive,positive,positive,positive,positive
1664793161,Discussion: please add _BooleanEnvironmentVariable to control disabling.,discussion please add control,issue,negative,neutral,neutral,neutral,neutral,neutral
1664782984,"Or we can use browser local data storage to memorize the last seen artifact , this is a better solution.",use browser local data storage memorize last seen artifact better solution,issue,positive,positive,positive,positive,positive,positive
1664378811,"I was able to get it working by setting the default-artifact-root to the host I was running this all on, and also providing the tracking server the creds for minio/S3, which I suspect circumvents the entire point of the artifact server being there at all. What is the recommended configuration for this type of architecture?",able get working setting host running also providing server suspect entire point artifact server configuration type architecture,issue,negative,positive,positive,positive,positive,positive
1664355801,"Thanks @BenWilson2! I have made the necessary changes.

Also, we have drafted an article to explain the usage of this plugin. We're illustrating how MLflow users can leverage `mlflow.evaluate()` with Giskard to build robust and ethical LLMs, complying with upcoming AI regulations.

Would you and the team at Databricks be open to collaborating on a joint publication?

Our first draft is available here: https://giskard.notion.site/Detecting-LLM-vulnerabilities-in-MLflow-with-Giskard-c08f9a8419d048e8bc9cd048f3ed5330?pvs=4. We're interested in your feedback :pray:",thanks made necessary also article explain usage leverage build robust ethical upcoming ai would team open joint publication first draft available interested feedback pray,issue,positive,positive,positive,positive,positive,positive
1664333456,"@harupy This is my requirements in case you need to reproduce the env

```
scipy 
transformers 
torchtext>=0.9 
ipython[notebook]>=8.0.0, <8.12.0 
setuptools==67.4.0 
# torchmetrics>=0.7, <0.12 
scikit-learn 
pytorch-lightning==1.9.5
datasets 
torch>=1.8.1, <2.0.0
mlflow==2.4.2
boto3
pyodbc
uvicorn
fastapi
config-with-yaml
```",case need reproduce notebook torch,issue,negative,neutral,neutral,neutral,neutral,neutral
1664299537,"They didn't document it, but if you are using decorators in your `predict(...)` function, you should be wrapping the original function signature. Otherwise, the `inspect.signature(...)` will get the decorator's signature instead of your `predict(...)` method.

```python
import functools

def decorator(func, ...):
    @functools.wraps(func)
    def wrapper(...):
        ...
    ...
```

or, if you're using a decorator with arguments:

```python
import functools

def decorator(...):
    def wrapper(func, ...):
        ...
        @functools.wraps(func)
        def inner(...):
            ...
    ...
```",document predict function wrapping original function signature otherwise get decorator signature instead predict method python import decorator wrapper decorator python import decorator wrapper inner,issue,negative,positive,positive,positive,positive,positive
1664237991,"> https://github.com/huggingface/datasets/blob/ef17d9fd6c648bb41d43ba301c3de4d7b6f833d8/src/datasets/config.py#L208
> 
> ```
> MODULE_NAME_FOR_DYNAMIC_MODULES = ""datasets_modules""
> ```
> 
> Does it come from `datasets`?


I dug into mlflow codes and also found where you were and checked for datasets package.

I have installed datasets but the error still occurs.

```
# packages in environment at /home/ubuntu/.conda/envs/log:
#
# Name                    Version                   Build  Channel
datasets                  2.13.1                   pypi_0    pypi
```",come dug also found checked package error still environment name version build channel,issue,negative,neutral,neutral,neutral,neutral,neutral
1664227518,"> @PhucLee2605 What is `datasets_modules`? Is that your custom module? Your code only contains the loading part. Can you add the logging part?

That is what I am wondering about. Searched for it but no information! I don't have it also

This is my logging snippet:

```
mlflow.set_tracking_uri(TRACKING_URI)
try:
    mlflow.create_experiment(EXP_NAME, BUCKET)
except: pass
mlflow.pytorch.autolog()
mlflow.set_experiment(EXP_NAME)

dm = LRODataModule()
dm.setup(""fit"")
model = LROClassifier(
    model_name_or_path=path_model,
    num_labels=dm.num_labels,
)

trainer = Trainer(
    max_epochs=epoch,
    accelerator=""auto"",
    devices=1,  # limiting got iPython runs
    strategy=""ddp_notebook""
)

with mlflow.start_run() as run:
    trainer.fit(model, dm)
```",custom module code loading part add logging part wondering information also logging snippet try bucket except pas fit model trainer trainer auto limiting got run model,issue,negative,positive,positive,positive,positive,positive
1663873695,@PhucLee2605 What is `datasets_modules`? Is that your custom module? Your code only contains the loading part. Can you add the logging part?,custom module code loading part add logging part,issue,negative,neutral,neutral,neutral,neutral,neutral
1663759189,"> > @serena-ruan What does the progress bar look like on the terminal?
> 
> Downloading artifacts: 0%| | 0/1 [00:00<?, ?it/s]\n

One problem I'm not sure is if in terminal tqdm.notebook print new lines for updating the progress",progress bar look like terminal one problem sure terminal print new progress,issue,positive,positive,positive,positive,positive,positive
1663757887,"> @serena-ruan What does the progress bar look like on the terminal?

Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]\n",progress bar look like terminal,issue,positive,neutral,neutral,neutral,neutral,neutral
1663749470,"@jlmeunier I hope you have already solved this problem but maybe someone will be looking for a solution like me. I had exactly the same situation as you - the artifacts were saved to the right place but I couldn't list the artifacts from the experiment page. In my case, the solution was

1. setting correct credentials to s3
(environment variables `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`, `AWS_DEFAULT_REGION`, `MLFLOW_S3_ENDPOINT_URL`, `MLFLOW_S3_IGNORE_TLS`) 
2. pip installing `boto3` `awscli` `psycopg2-binary` in addition to mlflow itself on the server. 

I hope this helps someone :D",hope already problem maybe someone looking solution like exactly situation saved right place could list experiment page case solution setting correct environment pip addition server hope someone,issue,positive,positive,positive,positive,positive,positive
1663605062,"> Is it possible to make some flag like ""set this one as default"" and when opening a new run to automatically show that artifact?

We can log a tag in the run like ""DEFAULT_DISPLAY_ARTIFACT"" to specify it, and when open the run on web page, if we found the tag, then show the artifact by default.

@ibobak would you like to contribute the feature ?",possible make flag like set one default opening new run automatically show artifact log tag run like specify open run web page found tag show artifact default would like contribute feature,issue,positive,positive,neutral,neutral,positive,positive
1663570064,"Can't even log my class_list, I use MMDetection, which automatically logs it as part of the config in their tracking hook. 

Only workaround is to replace the class_names with IDs, but then I need to find something else to log the class_names ",ca even log use automatically part hook replace need find something else log,issue,negative,neutral,neutral,neutral,neutral,neutral
1663562612,"@kuromt can you please check and post how the link looks like in the browser developer tools (right click on the link and use ""Inspect element"")?

![Screenshot 2023-08-03 at 10 51 15](https://github.com/mlflow/mlflow/assets/104438646/068440c2-2326-45a8-be2e-ca325fb1b2c6)
",please check post link like browser developer right click link use inspect element,issue,positive,positive,positive,positive,positive,positive
1663544053,"In my environment, a model ends with a space（e.g. `hello ` ）is listed in http://localhost/#/models.
But the link in the page to detail of the model was `http://localhost/#/models/hello` and the page show no versions information.
",environment model hello listed link page detail model page show information,issue,negative,neutral,neutral,neutral,neutral,neutral
1663506328,"@BenWilson2 @kuromt it's not a known issue, also I can't reproduce it in the recent version. It seems to work if the model name contains a trailing whitespace.

![Screenshot 2023-08-03 at 10 17 44](https://github.com/mlflow/mlflow/assets/104438646/b20ed842-244e-45ad-9b60-c88723e6947d)
![Screenshot 2023-08-03 at 10 17 40](https://github.com/mlflow/mlflow/assets/104438646/97752c60-5b54-4818-be7f-07705ebc1636)

I've retested it on 2.2.2 and it seems to work as well

![Screenshot 2023-08-03 at 10 19 54](https://github.com/mlflow/mlflow/assets/104438646/3f446f60-f957-40b4-af07-8aa0f2f82c68)
![Screenshot 2023-08-03 at 10 19 50](https://github.com/mlflow/mlflow/assets/104438646/b81247c5-ce4c-4827-8e4e-0b92acc2b5cf)

",known issue also ca reproduce recent version work model name trailing work well,issue,negative,neutral,neutral,neutral,neutral,neutral
1663366037,I see. We can't debug the issue if you can't reproduce it.,see ca issue ca reproduce,issue,negative,neutral,neutral,neutral,neutral,neutral
1663364088,"Not quite. I am unsure where the previous localhost is drawing its info from which dir or path. It should be the initial standard installation location. Separately, When I run my codes I direct to /user/xxx/downloads",quite unsure previous drawing path initial standard installation location separately run direct,issue,negative,negative,neutral,neutral,negative,negative
1663343074,"I did a following:
cd /user/xxx/downloads
mflow server
launched local host in safari myself. 

I don't seem to spot any errors except that the local host did not pick up any of my logs. 

Let me know if I am doing this correctly. ",following server local host safari seem spot except local host pick let know correctly,issue,negative,neutral,neutral,neutral,neutral,neutral
1663333312,Did you run `mlflow server` **in the directory where you encountered the error**?,run server directory error,issue,negative,neutral,neutral,neutral,neutral,neutral
1663323248,"yes. woo! it work. I did the server in terminal no errors, the localhost is loaded. how do you linked up my previously ran logs in the UI ?  ",yes woo work server terminal loaded linked previously ran,issue,positive,negative,negative,negative,negative,negative
1663314719,Are you really sure you don't see any error messages in the terminal? Did you open MLflow UI on the browswr after running `mlflow server`?,really sure see error terminal open running server,issue,negative,positive,positive,positive,positive,positive
1663300220,"oh after mkdir and cd. it works now. what actually happen? TQVM. 
",oh work actually happen,issue,negative,neutral,neutral,neutral,neutral,neutral
1663286550,"Yes cd like this

```
mkdir foo
cd foo
```",yes like foo foo,issue,positive,neutral,neutral,neutral,neutral,neutral
1663286330,"hmmm... may I know.. what is the typical file path linking to localhostbrowser and the standard files ? perhaps I can try to paste in the relevant files. 

how do move to a empty directory ? cd ? let me know the steps. thanks. ",may know typical file path linking standard perhaps try paste relevant move empty directory let know thanks,issue,negative,positive,neutral,neutral,positive,positive
1663285555,Can you move to an empty directory and run `mlflow server` there? Can you reproduce the same error?,move empty directory run server reproduce error,issue,negative,negative,neutral,neutral,negative,negative
1663283966,Strange. `INTERNAL_SERVER_ERROR` means something unexpected happened while processing the request.,strange something unexpected request,issue,negative,positive,neutral,neutral,positive,positive
1663282880,"Yes. No error. exactly the same message as per your example
",yes error exactly message per example,issue,negative,positive,positive,positive,positive,positive
1663280194,"Thanks! Any log message in the terminal `mlflow server` is running on?

Example:

```
> mlflow server
[2023-08-03 13:41:02 +0900] [27669] [INFO] Starting gunicorn 20.1.0
[2023-08-03 13:41:02 +0900] [27669] [INFO] Listening at: http://127.0.0.1:5000 (27669)
[2023-08-03 13:41:02 +0900] [27669] [INFO] Using worker: sync
[2023-08-03 13:41:02 +0900] [27671] [INFO] Booting worker with pid: 27671
[2023-08-03 13:41:02 +0900] [27672] [INFO] Booting worker with pid: 27672
[2023-08-03 13:41:02 +0900] [27673] [INFO] Booting worker with pid: 27673
[2023-08-03 13:41:02 +0900] [27674] [INFO] Booting worker with pid: 27674
```",thanks log message terminal server running example server starting listening worker sync booting worker booting worker booting worker booting worker,issue,negative,positive,neutral,neutral,positive,positive
1663278534,"[](url)
![Error3](https://github.com/mlflow/mlflow/assets/141021734/7e518a26-e00d-4fa5-81a3-849e93ae13b7)
![Error2](https://github.com/mlflow/mlflow/assets/141021734/8648d1d4-fecc-47ce-bfc2-fad387ccc47d)
![Error1](https://github.com/mlflow/mlflow/assets/141021734/bf69a820-0fc4-44b3-a5d2-abb326378614)

@harupy here it is, thanks. 
",error error error thanks,issue,negative,positive,positive,positive,positive,positive
1663266221,"Hi Harutaka,

here is my screenshot of my dev console.

Regards



On Thu, Aug 3, 2023 at 12:03 PM Harutaka Kawamura ***@***.***>
wrote:

> You can see https://developer.chrome.com/docs/devtools/open/
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/mlflow/mlflow/issues/9176#issuecomment-1663258503>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/BBT5EJRYLOPWJAZQI4NGPZ3XTMPJ5ANCNFSM6AAAAAA26AQRXM>
> .
> You are receiving this because you were mentioned.Message ID:
> ***@***.***>
>
",hi dev console wrote see reply directly view id,issue,negative,positive,neutral,neutral,positive,positive
1663254048,"@harupy  I am still relatively new. how do you launch the dev console on browser ? I didn't find any answers online or chatgpt. 

I did a pkill -f gunicorn followed by a mlflow server on Mac terminal. No error message. ml server booted up and listening at localhost. ",still relatively new launch dev console browser find server mac terminal error message server booted listening,issue,negative,positive,positive,positive,positive,positive
1663221433,"Follow-on testing (I just pushed fixes based on this manual validation):

```python
import mlflow
import transformers
from mlflow.gateway import set_gateway_uri, get_route, query

architecture = ""lordtt13/emo-mobilebert""
tokenizer = transformers.AutoTokenizer.from_pretrained(architecture)
model = transformers.TFAutoModelForSequenceClassification.from_pretrained(architecture)
pipe = transformers.pipeline(task=""text-classification"", model=model, tokenizer=tokenizer)

signature_with_params = mlflow.models.infer_signature(
        data,
        mlflow.transformers.generate_signature_output(pipe, [""This is fun!""]),
    )

artifact_path = ""emo-bert""

with mlflow.start_run() as run:
    run_info = mlflow.transformers.log_model(
        pipe,
        artifact_path=artifact_path,
    )
    model_uri = mlflow.get_artifact_uri(artifact_path)

print(f""mlflow models serve -m {model_uri} -h 127.0.0.1 -p 9020 --no-conda"")

#### serve the model ####

#### start the gateway ####

set_gateway_uri(""http://127.0.0.1:9091"")
route = get_route(""completions-oss"")

response = query(route=route.name, data={""prompt"": ""Well, this is awesome!""})

print(response)
```

With the hard-coded defaults for completions of temperature: 0.0 and candidate_count: 1 defined in the RequestModel base in chat, this makes OSS serving a bit broken. I made these optional in the pydantic def and applied a post-json-decoding default-if-not-set on the payload dict for the SaaS providers. 
If there's a better way that we want to handle this, I'm very open to suggestions here. 

I'll address the other comments tomorrow morning :) ",testing based manual validation python import import import query architecture architecture model architecture pipe data pipe fun run pipe print serve serve model start gateway route response query prompt well awesome print response temperature defined base chat serving bit broken made optional applied better way want handle open address tomorrow morning,issue,positive,positive,neutral,neutral,positive,positive
1663215193,@RFT86 Can you open the dev console on your browser? That should tell us what went wrong.,open dev console browser tell u went wrong,issue,negative,negative,negative,negative,negative,negative
1663208757,"I did go went through the installation tutorial. However, I am still in the same localhost:500 error state. I am able to log mlflow tracking logs using Jupiterlab successfully(with the log files and all). I tried mlflow on another computer B and the localhost is working fine. 

I recalled that initially when I install mlflow in my Mac computer, the localhost is fine until I delete some logs.  I compare this computer and my other computer B(Localhost working) to placed back the files back same location.  it doesn't work. 

Is there any way I can uninstall mlflow together with its relevant files and do a clean mlflow installation. 
Tried in terminal # %pip install -U mlflow and pip install mlflow . It does not make a clean installation. 

Appreciate your help on this. Thanks ",go went installation tutorial however still error state able log successfully log tried another computer working fine initially install mac computer fine delete compare computer computer working back back location work way together relevant clean installation tried terminal pip install pip install make clean installation appreciate help thanks,issue,positive,positive,positive,positive,positive,positive
1663162294,"@EdAbati #9200 is merged, we can reset the changes in this PR, and re-run `ruff .` to see what needs to be fixed.",reset ruff see need fixed,issue,negative,positive,neutral,neutral,positive,positive
1662684124,"I'm not entirely sure if this is something that is within the scope of MLflow to solve. While we did add support for passing string inputs and iterable string inputs to pyfunc to support LLM usage, modifying the return from the MLflow server to return scalar strings doesn't seem particularly useful. I think you'd want to have some middleware interface with your downstream consumption if you're needing to extract the JSON values for use in another system. 
I would recommend building that middleware service that can act as a proxy between the serving output and the subsequent forwarding to Athena in order to achieve this. Perhaps AWS has a solution involving using lambda to achieve this as a pre-processing step to an Athena query? 
I'd recommend reaching out to the sagemaker community to see if anyone has built anything like this before (I'm sure they have). 
We don't have any plans to support modifying the return values from the MLflow server to support any non-REST-compliant return values at this time. ",entirely sure something within scope solve add support passing string iterable string support usage return server return scalar seem particularly useful think want interface downstream consumption needing extract use another system would recommend building service act proxy serving output subsequent forwarding order achieve perhaps solution lambda achieve step query recommend reaching community see anyone built anything like sure support return server support return time,issue,positive,positive,positive,positive,positive,positive
1662675538,@hubertzub-db is this a current known issue for UI rendering?,current known issue rendering,issue,negative,neutral,neutral,neutral,neutral,neutral
1662669339,"Hi @viktoriussuwandi here's the location of the R test suite that is relevant to your change: https://github.com/mlflow/mlflow/blob/master/mlflow/R/mlflow/tests/testthat/test-tracking-experiments.R 
We would just need an expectation assertion that the correct `experiment_id` is returned from the API call. 
This new behavior can be added as an assertion on the current no-op validation of line 11 in that test suite (`experiment_2_id` is not defined as there is not currently a return statement to the R func) to validate that the now returned value matches the value of `experiment_2a` (the result of the `mlflow_get_experiment()` API call). 

Should be pretty quick to add. ",hi location test suite relevant change would need expectation assertion correct returned call new behavior added assertion current validation line test suite defined currently return statement validate returned value value result call pretty quick add,issue,positive,positive,positive,positive,positive,positive
1662636711,"Neat package! 
Could you revert the formatting changes made to the .rst that isn't in the blocks of text that you're adding?",neat package could revert made text,issue,negative,neutral,neutral,neutral,neutral,neutral
1662397567,"I'm going to be working on the fix in the next few days, pending some other work that I'm finishing up. ",going working fix next day pending work finishing,issue,negative,neutral,neutral,neutral,neutral,neutral
1662391987,Did you follow the guide verbatim and were able to reproduce what the getting started guide has defined? It could be helpful to do that to get things up and running and verify that there aren't any environmental considerations on your system that are exhibiting issues.,follow guide verbatim able reproduce getting guide defined could helpful get running verify environmental system,issue,negative,positive,positive,positive,positive,positive
1662299374,"Currently I've found workaround for this issue. Before run any training we can append our common package dir to `sys.path` with

```python
import inspect
import os
import sys

from my_package import common

common_path = os.path.dirname(inspect.getfile(common))
sys.path.append(common_path)

from transformers.custom_transformer import CustomTransformer

## train code including CustomTransformer
```

by doing this, the code will be recognized by the model.

Note: you might want to change package `transformers` to other name, it might cause `ImportError`",currently found issue run training append common package python import inspect import o import import common common import train code code model note might want change package name might cause,issue,negative,negative,negative,negative,negative,negative
1662139187,It would be nice to be able to group experiments via project. ,would nice able group via project,issue,negative,positive,positive,positive,positive,positive
1661522610,"Hi Ben, I just read through the tutorial. I don't find my resolution for my error. when I load my ml flow on local host, this shows:
![error](https://github.com/mlflow/mlflow/assets/141021734/27aeaaff-2e32-4834-b75d-b114a93aee11)
",hi ben read tutorial find resolution error load flow local host error,issue,negative,neutral,neutral,neutral,neutral,neutral
1661468951,"hi @BenWilson2,
Could you share a tentative ETA on the fix?

Regards,
Shipra",hi could share tentative eta fix,issue,negative,neutral,neutral,neutral,neutral,neutral
1661316618,"Hi @BenWilson2,
Sorry,
I haven't write test code before, 
would you guide me step by step with `the code` possible for the test ?

Appreciate your guidance",hi sorry write test code would guide step step code possible test appreciate guidance,issue,negative,negative,negative,negative,negative,negative
1661276562,"Hi @Nusret-Ozates , this appears to be a scikit-learn issue.

```
File ~/miniconda3/envs/mlflow_training/lib/python3.11/site-packages/mlflow/sklearn/utils.py:856, in _all_estimators()
    853 try:
    854     from sklearn.utils import all_estimators
--> 856     return all_estimators()
    857 except ImportError:
    858     return _backported_all_estimators()

File ~/miniconda3/envs/mlflow_training/lib/python3.11/site-packages/sklearn/utils/discovery.py:63, in all_estimators(type_filter)
     60 # Ignore deprecation warnings triggered at import time and from walking
     61 # packages
     62 with ignore_warnings(category=FutureWarning):
---> 63     for _, module_name, _ in pkgutil.walk_packages(path=[root], prefix=""sklearn.""):
     64         module_parts = module_name.split(""."")
     65         if (
     66             any(part in _MODULE_TO_IGNORE for part in module_parts)
     67             o
...
```

We recommend filing this issue against the scikit-learn repository in the meantime. Thank you for using MLflow!",hi issue file try import return except return file ignore deprecation triggered import time walking root part part recommend filing issue repository thank,issue,negative,neutral,neutral,neutral,neutral,neutral
1661261816,I wouldn't even begin to know where to start in guessing at what config issue you're having. I suggest opening a ticket with AWS to get some assistance on configuring the ECS container's permissions so that it was authenticated access to s3 as an artifact store. They'll definitely be much more equipped to help debug. ,would even begin know start guessing issue suggest opening ticket get assistance container access artifact store definitely much help,issue,positive,positive,positive,positive,positive,positive
1661259823,It might be worthwhile to go through the tutorial here: https://www.mlflow.org/docs/latest/quickstart.html and make sure that you're up to speed on all of the getting started elements for MLflow :) ,might go tutorial make sure speed getting,issue,negative,positive,positive,positive,positive,positive
1661251868,Hi @viktoriussuwandi could you add a unit test validation that confirms that this functions as expected?,hi could add unit test validation,issue,negative,neutral,neutral,neutral,neutral,neutral
1660612535,Hi @s-aditi thank you for reporting this. We'll try to get a fix for this for the next release of MLflow!,hi thank try get fix next release,issue,negative,neutral,neutral,neutral,neutral,neutral
1660497113,"While doing an investigation for behavior for an experimental feature, I discovered that we don't have test coverage for anything other than the `_BooleanEnvironmentVariable`.",investigation behavior experimental feature discovered test coverage anything,issue,negative,positive,neutral,neutral,positive,positive
1660373594,@arjundc-db do you have any opinions / guidance / known blockers for any modifications to this behavior (since this is your feature)?,guidance known behavior since feature,issue,negative,neutral,neutral,neutral,neutral,neutral
1660363793,"@jaehyeongAN @WeichenXu123 I understand when the plate gets full in life and work. I can try to take this on as it's applicable to my work if that's okay with y'all. I just may need some guidance as it would be my first time contributing to MLflow.

On a related note, not only is `run_id` global but IIRC `register_model` would use the global tracking and registry URIs. I remember a couple of months ago needing to use `mlflow.set_tracking_uri` and `mlflow.set_registry_uri` with MLflow 2.4.0. Is this still the case and something we'd have to take into account when implementing `MLflowClient.log_model`?",understand plate full life work try take applicable work may need guidance would first time related note global would use global registry remember couple ago needing use still case something take account,issue,negative,positive,positive,positive,positive,positive
1660213439,Can you share the sample docker run command which I can try by changing my environment variables accordingly?,share sample docker run command try environment accordingly,issue,negative,neutral,neutral,neutral,neutral,neutral
1660212296,"My experiments are added properly but the runs are not shown for each experiment in the UI. So, I am thinking of deploying minio container and using its artifacts_uri for the configuration to save artifacts in that minio store. For S3 URI, its not working. 

Now for the real question, My ECSTaskRole contains all the proper permissions for S3, by using this taskrole I am making the containers in ecs.",added properly shown experiment thinking container configuration save store working real question proper making,issue,negative,positive,neutral,neutral,positive,positive
1659836375,"I think both could be viable options: 

 - Given the method `add_libraries_to_model` I would think that mutating an existing version is the expected behaviour
 - Whereas logging a model using `WheeledModel.log` should create a brand new version with the wheels included.

I have no particular preference for one or the other. ",think could viable given method would think version behaviour whereas logging model create brand new version included particular preference one,issue,negative,positive,positive,positive,positive,positive
1659732036,"From your log: `MLflow autologging encountered a warning: ""/home/nusret/miniconda3/envs/mlflow_training/lib/python3.11/site-packages/_distutils_hack/__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.""` 

Could you try `import setuptools` first before all other dependencies that might import distutils? Wanted to see if that's the root cause",log warning also module may lead undesirable avoid avoid directly ensure traditional way install make sure always could try import first might import see root cause,issue,negative,positive,positive,positive,positive,positive
1659688785,"If anyone's looking for a temporary fix, you can lock langchain at `langchain==0.0.246`.",anyone looking temporary fix lock,issue,negative,neutral,neutral,neutral,neutral,neutral
1659666126,"That code gives me sklearn doesn't have a module `cluster` but I basically changed the code a little bit and got the same results. My sklearn version is 1.3.0 but I also tried with 1.2 too.
```
import mlflow
from sklearn.cluster import KMeans
from sklearn.datasets import load_iris

model = KMeans()
iris = load_iris()
X = iris.data[:, :2]
y = iris.target

with mlflow.start_run():
    model.fit(X, y)
    mlflow.sklearn.log_model(model, ""model"")

mlflow.sklearn.autolog()
```

```
2023/08/01 09:35:43 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: ""/home/nusret/miniconda3/envs/mlflow_training/lib/python3.11/site-packages/_distutils_hack/__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.""
2023/08/01 09:35:43 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: ""/home/nusret/miniconda3/envs/mlflow_training/lib/python3.11/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.""
Traceback (most recent call last):
  File ""/mnt/c/Users/mnusr/PycharmProjects/langchain_retrieval_qa_bot/deneme.py"", line 15, in <module>
    mlflow.sklearn.autolog()
  File ""/home/nusret/miniconda3/envs/mlflow_training/lib/python3.11/site-packages/mlflow/utils/autologging_utils/__init__.py"", line 424, in autolog
    return _autolog(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/nusret/miniconda3/envs/mlflow_training/lib/python3.11/site-packages/mlflow/sklearn/__init__.py"", line 1210, in autolog
    _autolog(
  File ""/home/nusret/miniconda3/envs/mlflow_training/lib/python3.11/site-packages/mlflow/sklearn/__init__.py"", line 1773, in _autolog
    estimators_to_patch = _gen_estimators_to_patch()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/nusret/miniconda3/envs/mlflow_training/lib/python3.11/site-packages/mlflow/sklearn/__init__.py"", line 97, in _gen_estimators_to_patch
    _, estimators_to_patch = zip(*_all_estimators())
                                  ^^^^^^^^^^^^^^^^^
  File ""/home/nusret/miniconda3/envs/mlflow_training/lib/python3.11/site-packages/mlflow/sklearn/utils.py"", line 856, in _all_estimators
    return all_estimators()
           ^^^^^^^^^^^^^^^^
  File ""/home/nusret/miniconda3/envs/mlflow_training/lib/python3.11/site-packages/sklearn/utils/discovery.py"", line 63, in all_estimators
    for _, module_name, _ in pkgutil.walk_packages(path=[root], prefix=""sklearn.""):
  File ""/home/nusret/miniconda3/envs/mlflow_training/lib/python3.11/pkgutil.py"", line 92, in walk_packages
    __import__(info.name)
  File ""/home/nusret/miniconda3/envs/mlflow_training/lib/python3.11/site-packages/sklearn/_build_utils/__init__.py"", line 15, in <module>
    from .openmp_helpers import check_openmp_support
  File ""/home/nusret/miniconda3/envs/mlflow_training/lib/python3.11/site-packages/sklearn/_build_utils/openmp_helpers.py"", line 12, in <module>
    from .pre_build_helpers import compile_test_program
  File ""/home/nusret/miniconda3/envs/mlflow_training/lib/python3.11/site-packages/sklearn/_build_utils/pre_build_helpers.py"", line 10, in <module>
    from setuptools.command.build_ext import customize_compiler, new_compiler
  File ""/home/nusret/miniconda3/envs/mlflow_training/lib/python3.11/site-packages/setuptools/__init__.py"", line 7, in <module>
    import _distutils_hack.override  # noqa: F401
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/nusret/miniconda3/envs/mlflow_training/lib/python3.11/site-packages/_distutils_hack/override.py"", line 1, in <module>
    __import__('_distutils_hack').do_override()
  File ""/home/nusret/miniconda3/envs/mlflow_training/lib/python3.11/site-packages/_distutils_hack/__init__.py"", line 77, in do_override
    ensure_local_distutils()
  File ""/home/nusret/miniconda3/envs/mlflow_training/lib/python3.11/site-packages/_distutils_hack/__init__.py"", line 64, in ensure_local_distutils
    assert '_distutils' in core.__file__, core.__file__
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: /home/nusret/miniconda3/envs/mlflow_training/lib/python3.11/distutils/core.py
```",code module cluster basically code little bit got version also tried import import import model iris model model warning warning also module may lead undesirable avoid avoid directly ensure traditional way install make sure always warning warning recent call last file line module file line return file line file line file line zip file line return file line root file line file line module import file line module import file line module import file line module import file line module file line file line assert,issue,negative,positive,neutral,neutral,positive,positive
1659642198,"Hi @chenmoneygithub Your error looks irrelevant to mlflow, it echoes error when building python. With a quick google search, maybe this helps https://stackoverflow.com/questions/67807596/pyenv-install-3-x-build-failed-ubuntu-20-04-using-python-build-20180424?",hi error irrelevant error building python quick search maybe,issue,negative,negative,neutral,neutral,negative,negative
1659610765,"@harupy This is the notebook i used - https://github.com/Azure/azureml-examples/blob/main/sdk/python/foundation-models/system/evaluation/fill-mask/fill-mask.ipynb

However rather than using the fill-mask model from azureml-registry I used a huggingface model converted using mlflow.transformer, using the following code
``` 
from transformers import AutoTokenizer, AutoModelForMaskedLM

model name = ""bert-base-cased""

def fillmask_funct(model_name):

    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForMaskedLM.from_pretrained(model_name)
    # model = AutoModel.from_pretrained(""distilbert-base-cased"")


    components = {
        ""model"": model,
        ""tokenizer"": tokenizer,
    }
    mlflow.transformers.save_model(
        transformers_model=components,
        path=model_name,
    )

    mdl = mlflow.pyfunc.load_model(model_name)
  
```
",notebook used however rather model used model converted following code import model name model model model model,issue,negative,neutral,neutral,neutral,neutral,neutral
1659493246,"> @WeichenXu123 gently ping on this.

@santiagxf feel free to file a PR for this :)",gently ping feel free file,issue,positive,positive,positive,positive,positive,positive
1659421747,"Langchain did a major refactor recently that moved some chains to langchain_experimental package, which result in some failures in the cross-version test. I'll address it in a follow-up PR.",major recently package result test address,issue,negative,positive,neutral,neutral,positive,positive
1659391459,"If it works in a local Docker container (thank you, by the way, for validating that as that would have been our first question to verify), then it's perhaps a configuration permissions issue. Are you able to verify your IAM roles that you have set up to ensure that the ECS service is authenticated to have communication with S3?
I'm afraid there's not a great deal of troubleshooting help we can do here, but we might be able to give you a few ideas to validate about your configuration setup.",work local docker container thank way would first question verify perhaps configuration issue able verify set ensure service communication afraid great deal help might able give validate configuration setup,issue,positive,positive,positive,positive,positive,positive
1659389199,"@dbczumar @harupy I updated the min version of langchain to 0.0.221 where retrievers are introduced. Given langchain is fast changing, it should be safe to do so.",min version given fast safe,issue,negative,positive,positive,positive,positive,positive
1659381948,Hi @machinehead thank you for bringing up this oversight. I'll make sure to get this fixed prior to the release of MLflow 2.6 :) ,hi thank oversight make sure get fixed prior release,issue,positive,positive,positive,positive,positive,positive
1659351858,"Was your intention to allow the creation of the wheeled version of the model during logging so that during model registration, a single artifact with the included `wheels` directory is present for version 1? Or is it to mutate an existing version of a registered model to apply the modified artifact location to a given version?
",intention allow creation wheeled version model logging model registration single artifact included directory present version mutate version registered model apply artifact location given version,issue,negative,negative,neutral,neutral,negative,negative
1658618714,@harupy - this PR should be ready for another round of review. Please let me know if are there any additional required changes.,ready another round review please let know additional,issue,positive,neutral,neutral,neutral,neutral,neutral
1658321078,"I can see the following experiment being run on localhost:5000 but there are no files saved at the given location.
Experiment ID: 1
Artifact Location: /home/ubuntu/notebooks/07-project/training_tracking_registry/mlruns/1

What could be the possible issue ? I'm using mlflow 2.3.1 on python3.10.0
",see following experiment run saved given location experiment id artifact location could possible issue python,issue,negative,neutral,neutral,neutral,neutral,neutral
1658262794,"Hi @mohitanchlia, is this a UI bug? If yes, could you paste the screenshot as well?",hi bug yes could paste well,issue,positive,neutral,neutral,neutral,neutral,neutral
1658254851,"Hi @Nusret-Ozates Could you try a simple example like below to see if the problem still exists:
```
model = sklearn.cluster.KMeans()
iris = sklearn.datasets.load_iris()
X = iris.data[:, :2]
y = iris.target

with mlflow.start_run():
    model.fit(X, y)
    mlflow.sklearn.log_model(model, ""model"")

mlflow.sklearn.autolog()
```

BTW which sklearn version are you using?",hi could try simple example like see problem still model iris model model version,issue,negative,neutral,neutral,neutral,neutral,neutral
1657233825,"> @mlflow/mlflow-team Please assign a maintainer and start triaging this issue.

I can see that it's been more than a month since the request for an assignee was raised, but there hasn't been any development as of today. Please look into the issues described above. Thanks!",please assign maintainer start issue see month since request assignee raised development today please look thanks,issue,positive,positive,positive,positive,positive,positive
1657067923,@sandeshregmi you can insert `print(path)` before `c:\Users\sregmi444\Anaconda3\envs\ml\Lib\site-packages\entrypoints.py:203` to see the throwing the error. I think this file contains non-UTF-8 encoded characters. See https://stackoverflow.com/questions/30996289/utf8-codec-cant-decode-byte-0xf3. I don't think this is an mlflow's issue.,insert print path see throwing error think file see think issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1656875898,"sorry about delay @harupy 
---------------------------------------------------------------------------
UnicodeDecodeError                        Traceback (most recent call last)
Cell In[4], line 1
----> 1 import mlflow

File [c:\Users\sregmi444\Anaconda3\envs\ml\Lib\site-packages\mlflow\__init__.py:41](file:///C:/Users/sregmi444/Anaconda3/envs/ml/Lib/site-packages/mlflow/__init__.py:41)
     38 warnings.filterwarnings(""ignore"", message=""numpy.dtype size changed"")
     39 warnings.filterwarnings(""ignore"", message=""numpy.ufunc size changed"")
---> 41 from mlflow import projects  # pylint: disable=unused-import
     42 from mlflow import tracking  # pylint: disable=unused-import
     43 from mlflow import models  # pylint: disable=unused-import

File [c:\Users\sregmi444\Anaconda3\envs\ml\Lib\site-packages\mlflow\projects\__init__.py:9](file:///C:/Users/sregmi444/Anaconda3/envs/ml/Lib/site-packages/mlflow/projects/__init__.py:9)
      6 import os
      7 import logging
----> 9 import mlflow.projects.databricks
     10 from mlflow import tracking
     11 from mlflow.entities import RunStatus

File [c:\Users\sregmi444\Anaconda3\envs\ml\Lib\site-packages\mlflow\projects\databricks.py:12](file:///C:/Users/sregmi444/Anaconda3/envs/ml/Lib/site-packages/mlflow/projects/databricks.py:12)
      9 import posixpath
     10 import re
---> 12 from mlflow import tracking
     13 from mlflow.entities import RunStatus
     14 from mlflow.exceptions import MlflowException

File [c:\Users\sregmi444\Anaconda3\envs\ml\Lib\site-packages\mlflow\tracking\__init__.py:8](file:///C:/Users/sregmi444/Anaconda3/envs/ml/Lib/site-packages/mlflow/tracking/__init__.py:8)
      1 """"""
      2 The ``mlflow.tracking`` module provides a Python CRUD interface to MLflow experiments
      3 and runs. This is a lower level API that directly translates to MLflow
      4 `REST API <../rest-api.html>`_ calls.
      5 For a higher level API for managing an ""active run"", use the :py:mod:`mlflow` module.
      6 """"""
----> 8 from mlflow.tracking.client import MlflowClient
      9 from mlflow.tracking._tracking_service.utils import (
     10     set_tracking_uri,
     11     get_tracking_uri,
   (...)
     14     _TRACKING_URI_ENV_VAR,
     15 )
     16 from mlflow.tracking._model_registry.utils import (
     17     set_registry_uri,
     18     get_registry_uri,
     19 )

File [c:\Users\sregmi444\Anaconda3\envs\ml\Lib\site-packages\mlflow\tracking\client.py:27](file:///C:/Users/sregmi444/Anaconda3/envs/ml/Lib/site-packages/mlflow/tracking/client.py:27)
     22 from mlflow.store.model_registry import (
     23     SEARCH_REGISTERED_MODEL_MAX_RESULTS_DEFAULT,
     24     SEARCH_MODEL_VERSION_MAX_RESULTS_DEFAULT,
     25 )
     26 from mlflow.store.tracking import SEARCH_MAX_RESULTS_DEFAULT
---> 27 from mlflow.tracking._model_registry.client import ModelRegistryClient
     28 from mlflow.tracking._model_registry import utils as registry_utils
     29 from mlflow.tracking._model_registry import DEFAULT_AWAIT_MAX_SLEEP_SECONDS

File [c:\Users\sregmi444\Anaconda3\envs\ml\Lib\site-packages\mlflow\tracking\_model_registry\client.py:18](file:///C:/Users/sregmi444/Anaconda3/envs/ml/Lib/site-packages/mlflow/tracking/_model_registry/client.py:18)
     16 from mlflow.entities.model_registry import RegisteredModelTag, ModelVersionTag
     17 from mlflow.entities.model_registry.model_version_status import ModelVersionStatus
---> 18 from mlflow.tracking._model_registry import utils, DEFAULT_AWAIT_MAX_SLEEP_SECONDS
     21 _logger = logging.getLogger(__name__)
     23 AWAIT_MODEL_VERSION_CREATE_SLEEP_DURATION_SECONDS = 3

File [c:\Users\sregmi444\Anaconda3\envs\ml\Lib\site-packages\mlflow\tracking\_model_registry\utils.py:10](file:///C:/Users/sregmi444/Anaconda3/envs/ml/Lib/site-packages/mlflow/tracking/_model_registry/utils.py:10)
      8 from mlflow.store._unity_catalog.registry.rest_store import UcModelRegistryStore
      9 from mlflow.tracking._model_registry.registry import ModelRegistryStoreRegistry
---> 10 from mlflow.tracking._tracking_service.utils import (
     11     _TRACKING_USERNAME_ENV_VAR,
     12     _TRACKING_PASSWORD_ENV_VAR,
     13     _TRACKING_TOKEN_ENV_VAR,
     14     _TRACKING_INSECURE_TLS_ENV_VAR,
     15     _TRACKING_CLIENT_CERT_PATH_ENV_VAR,
     16     _TRACKING_SERVER_CERT_PATH_ENV_VAR,
     17     _resolve_tracking_uri,
     18     get_tracking_uri,
     19 )
     20 from mlflow.utils import env, rest_utils
     21 from mlflow.utils.databricks_utils import get_databricks_host_creds

File [c:\Users\sregmi444\Anaconda3\envs\ml\Lib\site-packages\mlflow\tracking\_tracking_service\utils.py:213](file:///C:/Users/sregmi444/Anaconda3/envs/ml/Lib/site-packages/mlflow/tracking/_tracking_service/utils.py:213)
    210 for scheme in DATABASE_ENGINES:
    211     _tracking_store_registry.register(scheme, _get_sqlalchemy_store)
--> 213 _tracking_store_registry.register_entrypoints()
    216 def _get_store(store_uri=None, artifact_uri=None):
    217     return _tracking_store_registry.get_store(store_uri, artifact_uri)

File [c:\Users\sregmi444\Anaconda3\envs\ml\Lib\site-packages\mlflow\tracking\registry.py:52](file:///C:/Users/sregmi444/Anaconda3/envs/ml/Lib/site-packages/mlflow/tracking/registry.py:52), in StoreRegistry.register_entrypoints(self)
     50 def register_entrypoints(self):
     51     """"""Register tracking stores provided by other packages""""""
---> 52     for entrypoint in entrypoints.get_group_all(self.group_name):
     53         try:
     54             self.register(entrypoint.name, entrypoint.load())

File [c:\Users\sregmi444\Anaconda3\envs\ml\Lib\site-packages\entrypoints.py:237](file:///C:/Users/sregmi444/Anaconda3/envs/ml/Lib/site-packages/entrypoints.py:237), in get_group_all(group, path)
    232 """"""Find all entry points in a group.
    233 
    234 Returns a list of :class:`EntryPoint` objects.
    235 """"""
    236 result = []
--> 237 for config, distro in iter_files_distros(path=path):
    238     if group in config:
    239         for name, epstr in config[group].items():

File [c:\Users\sregmi444\Anaconda3\envs\ml\Lib\site-packages\entrypoints.py:203](file:///C:/Users/sregmi444/Anaconda3/envs/ml/Lib/site-packages/entrypoints.py:203), in iter_files_distros(path, repeated_distro)
    200 distro_names_seen.add(distro.name)
    202 cp = CaseSensitiveConfigParser(delimiters=('=',))
--> 203 cp.read([path])
    204 yield cp, distro

File [c:\Users\sregmi444\Anaconda3\envs\ml\Lib\configparser.py:713](file:///C:/Users/sregmi444/Anaconda3/envs/ml/Lib/configparser.py:713), in RawConfigParser.read(self, filenames, encoding)
    711 try:
    712     with open(filename, encoding=encoding) as fp:
--> 713         self._read(fp, filename)
    714 except OSError:
    715     continue

File [c:\Users\sregmi444\Anaconda3\envs\ml\Lib\configparser.py:1036](file:///C:/Users/sregmi444/Anaconda3/envs/ml/Lib/configparser.py:1036), in RawConfigParser._read(self, fp, fpname)
   1034 indent_level = 0
   1035 e = None                              # None, or an exception
-> 1036 for lineno, line in enumerate(fp, start=1):
   1037     comment_start = sys.maxsize
   1038     # strip inline comments

File :322, in decode(self, input, final)

UnicodeDecodeError: 'utf-8' codec can't decode byte 0xf3 in position 304: invalid continuation byte",sorry delay recent call last cell line import file file ignore size ignore size import import import file file import o import logging import import import file file import import import import import file file module python interface lower level directly rest higher level active run use import import import file file import import import import import file file import import import file file import import import import import file file scheme scheme return file file self self register provided try file file group path find entry group list class result group name group file file path path yield file file self try open except continue file file self none none exception line enumerate strip file decode self input final ca decode position invalid continuation,issue,negative,negative,neutral,neutral,negative,negative
1656317140,"@dbczumar Sorry to drop this in here, but since it's closely related I didn't really want to open a new issue. Is the expectation that the docker-compose.yml in [examples/mlflow_artifacts](https://github.com/mlflow/mlflow/blob/master/examples/mlflow_artifacts/docker-compose.yml) should work as is? I have to add several things to the tracking server to get it to both be able to push to the artifacts server and also display artifacts/models in the MLflow UI @ port 5000. If I change nothing, I am able to write to the S3 through the tracking server container but is not able to retrieve from that container because the service name isn't being resolved from the `default-artifact-root`. I am able to `exec` into the tracking server and ping using the service name artifacts-server fine, but the mlflow server itself doesn't seem to be able to handle the resolution on the docker network. 

If I understand the architecture correctly the tracking server should be interacting with the artifacts server, which is what communicates with the S3/Minio artifact store so that the secrets to S3 are managed by that container. Other examples I see (such as those above) do not run an additional container for the artifacts-server. 

Which is the better practice? Does it even  matter really? Is something broken somewhere that is preventing the example compose file from working as it currently is written?

Thank you for any pointers you can provide :smile: ",sorry drop since closely related really want open new issue expectation work add several server get able push server also display port change nothing able write server container able retrieve container service name resolved able server ping service name fine server seem able handle resolution docker network understand architecture correctly server server artifact store container see run additional container better practice even matter really something broken somewhere example compose file working currently written thank provide smile,issue,positive,positive,positive,positive,positive,positive
1655807768,"I had a model with several thousand features and the csv file was with feature importances.  It was searching the necessary rows with no delays at all - just like a lightning.  I don't know what will be with 10 thousand rows or 100 thousand rows, but anyway, who bothers to set some limit of rows after which the functionality will be switched off?
",model several thousand file feature searching necessary like lightning know thousand thousand anyway set limit functionality switched,issue,negative,neutral,neutral,neutral,neutral,neutral
1655297417,What is the performance of searching in your approach? Say if the csv file is quite large. ,performance searching approach say file quite large,issue,negative,positive,positive,positive,positive,positive
1655211091,"I'm bumping up the topic. 

In my case, also the problem occurred when I wanted to permanently remove experiment (sqlite backend store uri). The experiment deletes correctly only when the `--run-ids` is specified (it seems that any existing one, otherwise it throws an error that the run does not exist). Calling the `mlflow gc --backend-store-uri sqlite:////.../mlflow.db --experiment-ids 13` command is likely to start deleting all runes with a DELETED status of any experiment id (**not just 13**) which is very dangerous (no possibility to restore without a prior backup). 

my guess is that in the absence of run-ids, the scenario

> If run ids are not specified, data is removed for all runs in the deleted lifecycle stage.

is realized and the `--experiment-ids` condition is ignored

Expected behavior: specifying `--experiment-ids` should be sufficient to permanently delete a specific experiment.",bumping topic case also problem permanently remove experiment store experiment correctly one otherwise error run exist calling command likely start status experiment id dangerous possibility restore without prior backup guess absence scenario run data removed stage condition behavior sufficient permanently delete specific experiment,issue,negative,negative,negative,negative,negative,negative
1655070900,"Hi folks, MLflow 2.5 includes multi-user support with a standardized, extensible permissions system. Please check it out and provide feedback: https://mlflow.org/docs/latest/auth/index.html.

Thank you for your patience and your inputs!",hi support standardized extensible system please check provide feedback thank patience,issue,positive,neutral,neutral,neutral,neutral,neutral
1655069737,"Hi folks, the brand new ``mlflow.data`` module introduced in MLflow 2.4 provides data versioning for MLflow Tracking. Please try it out and provide feedback. Thank you for your patience and for your inputs :)

https://mlflow.org/docs/latest/python_api/mlflow.data.html",hi brand new module data please try provide feedback thank patience,issue,positive,positive,positive,positive,positive,positive
1654961457,"@gabrielfu please, take a look on fixes from the review",please take look review,issue,negative,neutral,neutral,neutral,neutral,neutral
1654878279,"> Yes, can you try this?
> 
> ```
> # my_basic_auth.ini
> 
> [mlflow]
> default_permission = READ
> database_uri = <MySQL URI>
> ```
> 
> ```
> export MLFLOW_AUTH_CONFIG_PATH=/path/to/my_basic_auth.ini
> ```

Sorry, I accidentally set the status to closed.",yes try read export sorry accidentally set status closed,issue,negative,negative,negative,negative,negative,negative
1653359952,"My code has a helper method which wraps CSV into HTML and always puts HTML together with CSV, so that the functionality will be as coded in the javascript of this HTML file.",code helper method always together functionality file,issue,negative,neutral,neutral,neutral,neutral,neutral
1653356934,"![image](https://github.com/mlflow/mlflow/assets/8807043/451914c4-7bb7-49e2-907c-f8091765b603)

As you may notice on my first screenshot in the initial post, I am using this  https://datatables.net/   component, which allows not only sorting by values, but also searching in the grid (by typing part of value and getting the filtered rows very fast)",image may notice first initial post component also searching grid part value getting fast,issue,negative,positive,positive,positive,positive,positive
1653126425,"> Yes, can you try this?
> 
> ```
> # my_basic_auth.ini
> 
> [mlflow]
> default_permission = READ
> database_uri = <MySQL URI>
> ```
> 
> ```
> export MLFLOW_AUTH_CONFIG_PATH=/path/to/my_basic_auth.ini
> ```


I tried this approach, but I encountered some errors.

## Dockerfile

```dockerfile
FROM python:3.10.12-slim
WORKDIR /app
COPY ./basic_auth.ini ./
RUN pip install \
    mlflow==2.5.0 \
    pymysql \
    configparser \
    cryptography 
    
EXPOSE 5000
``` 
## basic_auth.ini
```
[mlflow]
default_permission = READ
database_uri = <DB_URI>
admin_username = admin
admin_password = admin

``` 

## command
```shell
docker build -t mlflow_auth_test:v1.0.0 -f ./Dockerfile .
docker run --rm --name mlflow-auth-test -it -p 8998:5000 mlflow_auth_test:v1.0.0 bash

export MLFLOW_SERVICE_HOST=0.0.0.0
export MLFLOW_SERVICE_PORT=5000
export DB_HOST=xxxx
export DB_PORT=xxxx
export DB_USERNAME=xxxxx
export DB_PASSWORD=xxxx
export MLFLOW_DATABASE=xxxxx
export MLFLOW_AUTH_CONFIG_PATH=/app/basic_auth.ini

/bin/bash -c ""sed -i 's|<DB_URI>|mysql+pymysql://${DB_USERNAME}:${DB_PASSWORD}@${DB_HOST}:${DB_PORT}/${MLFLOW_DATABASE}|g' basic_auth.ini""

mlflow server --host $MLFLOW_SERVICE_HOST --port $MLFLOW_SERVICE_PORT --app-name basic-auth
``` 

## error
then it failed. error:（I also tried setting --workers 1, but it still failed.）
<details><summary>Details</summary>
<p>
[2023-07-27 08:08:36 +0000] [137] [INFO] Starting gunicorn 20.1.0
[2023-07-27 08:08:36 +0000] [137] [INFO] Listening at: http://0.0.0.0:5000 (137)
[2023-07-27 08:08:36 +0000] [137] [INFO] Using worker: sync
[2023-07-27 08:08:36 +0000] [138] [INFO] Booting worker with pid: 138
[2023-07-27 08:08:36 +0000] [139] [INFO] Booting worker with pid: 139
[2023-07-27 08:08:36 +0000] [140] [INFO] Booting worker with pid: 140
[2023-07-27 08:08:36 +0000] [141] [INFO] Booting worker with pid: 141
2023/07/27 08:08:37 WARNING mlflow.server.auth: This feature is still experimental and may change in a future release without warning
2023/07/27 08:08:37 WARNING mlflow.server.auth: This feature is still experimental and may change in a future release without warning
2023/07/27 08:08:37 WARNING mlflow.server.auth: This feature is still experimental and may change in a future release without warning
2023/07/27 08:08:38 WARNING mlflow.server.auth: This feature is still experimental and may change in a future release without warning
[2023-07-27 08:08:38 +0000] [137] [WARNING] Worker with pid 138 was terminated due to signal 15
[2023-07-27 08:08:38 +0000] [137] [WARNING] Worker with pid 140 was terminated due to signal 15
Traceback (most recent call last):
  File ""/usr/local/lib/python3.9/site-packages/gunicorn/arbiter.py"", line 209, in run
    self.sleep()
  File ""/usr/local/lib/python3.9/site-packages/gunicorn/arbiter.py"", line 357, in sleep
    ready = select.select([self.PIPE[0]], [], [], 1.0)
  File ""/usr/local/lib/python3.9/site-packages/gunicorn/arbiter.py"", line 242, in handle_chld
    self.reap_workers()
  File ""/usr/local/lib/python3.9/site-packages/gunicorn/arbiter.py"", line 525, in reap_workers
    raise HaltServer(reason, self.WORKER_BOOT_ERROR)
gunicorn.errors.HaltServer: <HaltServer 'Worker failed to boot.' 3>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/usr/local/bin/gunicorn"", line 8, in <module>
    sys.exit(run())
  File ""/usr/local/lib/python3.9/site-packages/gunicorn/app/wsgiapp.py"", line 67, in run
    WSGIApplication(""%(prog)s [OPTIONS] [APP_MODULE]"").run()
  File ""/usr/local/lib/python3.9/site-packages/gunicorn/app/base.py"", line 231, in run
    super().run()
  File ""/usr/local/lib/python3.9/site-packages/gunicorn/app/base.py"", line 72, in run
    Arbiter(self).run()
  File ""/usr/local/lib/python3.9/site-packages/gunicorn/arbiter.py"", line 229, in run
    self.halt(reason=inst.reason, exit_status=inst.exit_status)
  File ""/usr/local/lib/python3.9/site-packages/gunicorn/arbiter.py"", line 342, in halt
    self.stop()
  File ""/usr/local/lib/python3.9/site-packages/gunicorn/arbiter.py"", line 393, in stop
    time.sleep(0.1)
  File ""/usr/local/lib/python3.9/site-packages/gunicorn/arbiter.py"", line 242, in handle_chld
    self.reap_workers()
  File ""/usr/local/lib/python3.9/site-packages/gunicorn/arbiter.py"", line 525, in reap_workers
    raise HaltServer(reason, self.WORKER_BOOT_ERROR)
gunicorn.errors.HaltServer: <HaltServer 'Worker failed to boot.' 3>
Running the mlflow server failed. Please see the logs above for details.

</p>
</details> 
",yes try read export tried approach python copy run pip install cryptography expose read command shell docker build docker run name bash export export export export export export export export server host port error error also tried setting still summary starting listening worker sync booting worker booting worker booting worker booting worker warning feature still experimental may change future release without warning warning feature still experimental may change future release without warning warning feature still experimental may change future release without warning warning feature still experimental may change future release without warning warning worker due signal warning worker due signal recent call last file line run file line sleep ready file line file line raise reason boot handling exception another exception recent call last file line module run file line run prog file line run super file line run arbiter self file line run file line halt file line stop file line file line raise reason boot running server please see,issue,negative,positive,neutral,neutral,positive,positive
1652986938,"The current joblib version requires Python >= 3.7 which is a less strict requirement than for installing mlflow. I have myself used joblib without issues on Python 3.8 and above. 

An example of the benefit of compressing: I just tested with a sklearn RandomForestRegressor model. Compression reduced the model artifact size to 50% of the original. I have experienced uncompressed RandomForestRegressor model artifacts approaching a file size of around 1 gb, so the benefit of compressing can be significant.",current version python le strict requirement used without python example benefit tested model compression reduced model artifact size original experienced uncompressed model approaching file size around benefit significant,issue,negative,positive,positive,positive,positive,positive
1652466147,"@dbczumar I updated the PR to take the `db.as_retriever()` instead of the `RetrieverChain`. In this way, users does not need to learn about the `RetrieverChain`, which reduces the learning curve.",take instead way need learn learning curve,issue,negative,neutral,neutral,neutral,neutral,neutral
1652429159,@VirajVaitha123 have been able to save the weights? I have been trying to do the same thing with yolov7 but getting lost.,able save trying thing getting lost,issue,negative,positive,positive,positive,positive,positive
1652302143,"@harupy Got it. 
But I'm still confused because this PR did not introduce the reference to `mlflow.langchain.*`, so this means this previously works, which means we previously install langchain and this PR breaks it? 
Besides, if we don't install the langchain flavor, do we install openai flavor? I see the lines referencing to `mlflow.openai` work. This does not quite make sense to me. Could you help me understand more?
Thanks!",got still confused introduce reference previously work previously install besides install flavor install flavor see work quite make sense could help understand thanks,issue,positive,negative,negative,negative,negative,negative
1651909337,"We shouldn't manually update `mlflow/mlflow/ml_package_versions.py`, but can manually update `mlflow/mlflow/ml-package-versions.yml`.",manually update manually update,issue,negative,neutral,neutral,neutral,neutral,neutral
1651889003,"yes, I meant pull request.",yes meant pull request,issue,negative,neutral,neutral,neutral,neutral,neutral
1651873681,"> @serena-ruan We can update this line instead of updating `mlflow/utils/autologging_utils/versioning.py`:
> 
> https://github.com/mlflow/mlflow/blob/6805103c4b93a3bf0ae7f293a77949088215ce1f/mlflow/ml-package-versions.yml#L336

On the top of this file:
https://github.com/mlflow/mlflow/blob/fcbe9c22da5291c0f0379df190feb9a3c547d374/mlflow/ml_package_versions.py#L1-L2",update line instead top file,issue,negative,positive,positive,positive,positive,positive
1651776239,"@harupy Just to clarify, do you mean pull request (PR)? If so, absolutely. Can share it out in the near future.",clarify mean pull request absolutely share near future,issue,negative,negative,neutral,neutral,negative,negative
1651089328,"Yes, can you try this?

```
# my_basic_auth.ini

[mlflow]
default_permission = READ
database_uri = <MySQL URI>
```

```
export MLFLOW_AUTH_CONFIG_PATH=/path/to/my_basic_auth.ini
```

",yes try read export,issue,negative,neutral,neutral,neutral,neutral,neutral
1651079208,"> I think the cause is multiple workers attempting to initialize the database for auth. I'll figure out how to handle this.

I would like to ask another question. Is there a way to switch the permission database to a remote MySQL?",think cause multiple initialize figure handle would like ask another question way switch permission remote,issue,negative,negative,neutral,neutral,negative,negative
1651030848,"https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_Tag.html

> You can add tags to notebook instances, training jobs, hyperparameter tuning jobs, batch transform jobs, models, labeling jobs, work teams, endpoint configurations, and endpoints. For more information on adding tags to SageMaker resources, see [AddTags](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_AddTags.html).

Both model and endpoint are taggable.


@clarkh-ncino Would it makes sense to apply the same tag on both model and endpoint?",add notebook training tuning batch transform work information see model would sense apply tag model,issue,negative,neutral,neutral,neutral,neutral,neutral
1650981475,"> Yes, will do it. Thank you for pointing out.

I cleaned up the commit history.

> Also, I can't find request for review. Can you explain why?

Only maintainers can request reviews.",yes thank pointing commit history also ca find request review explain request,issue,positive,neutral,neutral,neutral,neutral,neutral
1650973755,"Yes, will do it. Thank you for pointing out.

Also, I can't find request for review. Can you explain why?",yes thank pointing also ca find request review explain,issue,positive,neutral,neutral,neutral,neutral,neutral
1650961996,Looks like this PR contains unrelated commits. Can you remove them? Rebasin on master might work.,like unrelated remove master might work,issue,negative,neutral,neutral,neutral,neutral,neutral
1650872191,"> @serena-ruan We can apply this fix: #9153

Sounds good :) BTW looks like this PR doesn't trigger that workflow to run",apply fix good like trigger run,issue,positive,positive,positive,positive,positive,positive
1650870421,@clarkh-ncino Thanks for reporting the issue! It looks like we use `tags` when creating a sagemaker model. I'm not familiar with sagemaker. What can be tagged?,thanks issue like use model familiar tagged,issue,positive,positive,positive,positive,positive,positive
1650852386,I think the cause is multiple workers attempting to initialize the database for auth. I'll figure out how to handle this.,think cause multiple initialize figure handle,issue,negative,neutral,neutral,neutral,neutral,neutral
1650834727,"@EdAbati Thanks for the PR! https://github.com/astral-sh/ruff/pull/6081 will be shipped soon in the next ruff release. With this change, code like like is allowed:

```python
with pytest.raises():
    with foo():
        simple_statement
```",thanks shipped soon next ruff release change code like like python foo,issue,positive,positive,neutral,neutral,positive,positive
1650791845,"I'm also interested in this feature. One way to go about this is to have a table of images, where rows are aligned using the figure name and columns are runs. The user must select which figures to display, similar to the existing parameters and metrics drop down menus.",also interested feature one way go table figure name user must select display similar metric drop,issue,negative,positive,positive,positive,positive,positive
1650784542,"> 

Thank you @serena-ruan, and hi, @harupy ! Just a gentle reminder to take a look :-)",thank hi gentle reminder take look,issue,positive,positive,positive,positive,positive,positive
1650668963,"> I'm wondering what `_before_request` would look like with your proposal:

Good question! My proposal focuses on authorization rather than authentication because of the way it is deployed in our environment (because Google Cloud handles authentication). But the proposal definitely needs to co-exist with authentication, especially the existing support for basic authentication.

I propose modifying the signature of the proposed `get_request_authorization` function to:

```
def get_request_authorization(request) -> Union[Authorization, Response]
```

By allowing this function to return either `Authorization` or `Response`, it can handle both:
* Successful authentication: Returns an `Authorization` object
* Unsuccessful authentication: Returns a `Response` object, appropriately populated based on the authentication scheme.

With that change, the default (basic auth) implementation of `get_request_authorization` will be:
```
def get_request_authorization(request)  -> Union[Authorization, Response]:
    if request.authorization is None:
        return make_basic_auth_response()

    username = request.authorization.username
    password = request.authorization.password
    if store.authenticate_user(username, password):
        return request.authorization
    else:
        # let user attempt login again
        return make_basic_auth_response()
```

 And `_before_request` becomes:

```

@catch_mlflow_exception
def _before_request():
    if is_unprotected_route(request.path):
        return

    authorization = get_request_authorization(request)
    if isinstance(authorization, Response):
        return authorization
    elif not isinstance(authorization, Authorization):
        raise MlflowException(
            f""Unsupported result type from get_request_authorization: '{type(authorization).__name__}'"",
            INTERNAL_ERROR,
        )     

    username = request.authorization.username

    # ... From here to the end of the function, no changes ...

    # admins don't need to be authorized
    if sender_is_admin():
        _logger.debug(f""Admin (username={username}) authorization not required"")
        return

    # authorization
    if validator := BEFORE_REQUEST_VALIDATORS.get((request.path, request.method)):
        _logger.debug(f""Calling validator: {validator.__name__}"")
        if not validator():
            return make_forbidden_response()
    else:
        _logger.debug(f""No validator found for {(request.path, request.method)}"")

```

With JWT, `get_request_authorization` might be implemented as:

```
def get_request_authorization() -> Union[Authorization, Response]:
    _logger.debug(""Getting token"")
    # In Cloud Run, we receive the token in the ""Authorization"" header.
    # In App Engine, we receive it in the ""x-goog-iap-jwt-assertion"" header.
    # https://cloud.google.com/iap/docs/signed-headers-howto#securing_iap_headers
    # In the former case, the token is prefixed with ""Bearer "", but in the latter
    # case it is not.
    token = request.headers.get(
        ""Authorization"", request.headers.get(""x-goog-iap-jwt-assertion"")
    )
    if token:
        _logger.debug(f""Verifying token"")
        if token.lower().startswith(""basic ""):
            # ""basic"" means HTTP basic authentication, which is used for local
            # testing. The token is base64-encoded, so we need to decode it.
            # This will never happen in production because Google authenticates
            # the user before the request reaches the service.
            token = base64.b64decode(token.split("" "")[1]).decode(
                ""utf-8""
            )  # Remove ""basic "" prefix
            # Split the string into email and password. We discard the password,
            # because this behavior is only for local testing, and this function
            # is not responsible for authenticating the user, only for extracting
            # the username for _authorization_.
            email, _ = token.split("":"")
            email = _apply_impersonation(request, email)
            return Authorization(
                auth_type=""jwt"", data=dict(username=email, password="""")
            )
        elif token.lower().startswith(BEARER_PREFIX):
            token = token[len(BEARER_PREFIX) :]  # Remove prefix

        error_response =     make_response()
        error_response.status_code = 401
        error_response.set_data(
            ""You are not authenticated. Please provide a valid JWT Bearer token with the request.""
        )
        error_response.headers[""WWW-Authenticate""] = 'Bearer error=""invalid_token""'

        # Note: Rather than google.oauth2.id_token.verify_oauth2_token(), we use
        # jwt.decode() with verification disabled. That's because within the
        # Cloud Run service, Google has already verified the token (thus we
        # don't NEED to verify it) and removed the signature (thus we CAN'T
        # verify it).
        # https://cloud.google.com/run/docs/authenticating/service-to-service#authenticating_end-users
        token_info = jwt.decode(token, verify=False)
        if not token_info:  # pragma: no cover
            _logger.warning(""No token_info returned"")
            return error_response

        email = token_info[""email""]
        return Authorization(auth_type=""jwt"", data=dict(username=email, password=""""))
    else:  # pragma: no cover
        _logger.warning(""Missing or invalid authorization token"")
        return error_response
```

Below are some resources regarding the format of the `Bearer error` response. 
* https://datatracker.ietf.org/doc/html/rfc6750#section-3
* https://stackoverflow.com/questions/57343599/auth0-api-returning-401-www-authenticate-bearer-error-invalid-token-in-net-c
* https://stackoverflow.com/questions/55781040/401-unauthorized-www-authenticate-bearer

Since 
",wondering would look like proposal good question proposal authorization rather authentication way environment cloud authentication proposal definitely need authentication especially support basic authentication propose signature function request union authorization response function return either authorization response handle successful authentication authorization object unsuccessful authentication response object appropriately based authentication scheme change default basic implementation request union authorization response none return password password return else let user attempt login return becomes return authorization request authorization response return authorization authorization authorization raise unsupported result type type authorization end function need authorized authorization return authorization calling return else found might union authorization response getting token cloud run receive token authorization header engine receive header former case token prefixed bearer latter case token authorization token token basic basic basic authentication used local testing token need decode never happen production user request service token remove basic prefix split string password discard password behavior local testing function responsible user request return authorization token token remove prefix please provide valid bearer token request note rather use verification disabled within cloud run service already token thus need verify removed signature thus verify token cover returned return return authorization else cover missing invalid authorization token return regarding format bearer error response since,issue,positive,positive,neutral,neutral,positive,positive
1650295951,"@harupy Can you help with the docs warnings? These should be public functions with docstrings.
```
/home/circleci/project/docs/source/models.rst:2317: WARNING: py:func reference target not found: mlflow.langchain.save_model
/home/circleci/project/docs/source/models.rst:2317: WARNING: py:func reference target not found: mlflow.langchain.log_model
/home/circleci/project/docs/source/models.rst:2317: WARNING: py:func reference target not found: mlflow.langchain.load_model
/home/circleci/project/docs/source/models.rst:2383: WARNING: py:class reference target not found: mlflow.langchain.RetrieverChain
/home/circleci/project/mlflow/models/__init__.py:docstring of mlflow.models:11: WARNING: py:mod reference target not found: mlflow.langchain
```
Also, I'm confused why the pyfunc test still fails with `AttributeError: module 'mlflow' has no attribute 'openai'`. It looks coming from `def spark_udf(...` which this PR did not change. 
Thanks!",help public warning reference target found warning reference target found warning reference target found warning class reference target found warning reference target found also confused test still module attribute coming change thanks,issue,negative,negative,neutral,neutral,negative,negative
1649840924,"> @wwwwf Got it. Can you run `mlflow server` with `--workers=1`?
> 
> ```
> mlflow server --app-name basic-auth --workers 1
> ```

it works!",got run server server work,issue,negative,neutral,neutral,neutral,neutral,neutral
1649823589,Ok sounds good. Give me some time I will post here.,good give time post,issue,negative,positive,positive,positive,positive,positive
1649736739,"@wwwwf Got it. Can you run `mlflow server` with `--workers=1`?

```
mlflow server --app-name basic-auth --workers 1
```",got run server server,issue,negative,neutral,neutral,neutral,neutral,neutral
1649707816,"> @wwwwf Can you reproduce the issue constantly?

I can consistently reproduce the issue on two Macs, but I experienced it once on Linux, and now I cannot reproduce it.",reproduce issue constantly consistently reproduce issue two experienced reproduce,issue,negative,positive,positive,positive,positive,positive
1649673430,"I'm wondering what `_before_request` would look like with your proposal:

https://github.com/mlflow/mlflow/blob/00c9b423e2fa33ead427f90b5c731a29b5bd7737/mlflow/server/auth/__init__.py#L417-L442",wondering would look like proposal,issue,negative,neutral,neutral,neutral,neutral,neutral
1649591248,"@barrywhart Thanks for the code! To confirm, `_get_permission_from_experiment_id` would look like this in your proposal?

```diff
diff --git a/mlflow/server/auth/__init__.py b/mlflow/server/auth/__init__.py
index e94ea8495..c708fead9 100644
--- a/mlflow/server/auth/__init__.py
+++ b/mlflow/server/auth/__init__.py
@@ -175,7 +175,8 @@ def _get_permission_from_store_or_default(store_permission_func: Callable[[], st
 
 def _get_permission_from_experiment_id() -> Permission:
     experiment_id = _get_request_param(""experiment_id"")
-    username = request.authorization.username
+    authorization = get_request_authorization(request)
+    username = authorization.username
     return _get_permission_from_store_or_default(
         lambda: store.get_experiment_permission(experiment_id, username).permission
     )
```",thanks code confirm would look like proposal git index callable st permission authorization request return lambda,issue,positive,positive,positive,positive,positive,positive
1649551894,"sorry I was checking the version on the venv of the client 

the server is using `SQLAlchemy==2.0.19` :+1: 
",sorry version client server,issue,negative,negative,negative,negative,negative,negative
1649523124,"Confirmed the following change worked:

```diff
diff --git a/mlflow/store/tracking/sqlalchemy_store.py b/mlflow/store/tracking/sqlalchemy_store.py
index bdf24b94c..a96601b55 100644
--- a/mlflow/store/tracking/sqlalchemy_store.py
+++ b/mlflow/store/tracking/sqlalchemy_store.py
@@ -341,7 +341,7 @@ class SqlAlchemyStore(AbstractStore):
             session.query(SqlExperiment)
             .options(*query_options)
             .filter(
-                SqlExperiment.experiment_id == experiment_id,
+                SqlExperiment.experiment_id == int(experiment_id),
                 SqlExperiment.lifecycle_stage.in_(stages),
             )
             .one_or_none()
```",confirmed following change worked git index class,issue,negative,positive,positive,positive,positive,positive
1649521354,The error hint implies there is a type mismatch (e.g. compare a string and an integer).,error hint type mismatch compare string integer,issue,negative,neutral,neutral,neutral,neutral,neutral
1649507790,I was able to repro the issue locally. Filed https://github.com/mlflow/mlflow/pull/9156 to see if we can repro in CI.,able issue locally see,issue,negative,positive,positive,positive,positive,positive
1649426277,"@raphaelauv Thanks, I'll try to reproduce the issue :)",thanks try reproduce issue,issue,negative,positive,positive,positive,positive,positive
1649421155,"Hello :wave: 

```Dockerfile
FROM python:3.11-slim
ENV PIP_NO_CACHE_DIR=TRUE
RUN python3 -m pip install mlflow==2.5.0 psycopg[binary,pool]==3.1.9
```

```yaml
version: '3.8'

services:
  mlflow-db:
    image: postgres:15.3
    environment:
      POSTGRES_DB: mlflowdb
      POSTGRES_USER: mlflow
      POSTGRES_PASSWORD: password
    ports:
      - ""5436:5432""

  mlflow-server:
    image: mymlflow:0.1
    ports:
      - ""5000:5000""
    command: mlflow server --host 0.0.0.0 --backend-store-uri postgresql+psycopg://mlflow:password@mlflow-db:5432/mlflowdb
```",hello wave python run python pip install binary pool version image environment password image command server host password,issue,negative,neutral,neutral,neutral,neutral,neutral
1649229776,"how to remove the banner 'We’ve made several improvements to the new runs comparison experience.... If you prefer to use this experience, we'd love to know more.' ?",remove banner made several new comparison experience prefer use experience love know,issue,positive,positive,positive,positive,positive,positive
1649118043,@sandeshregmi Can you constantly reproduce the issue with `c:\Users\sregmi444\Anaconda3\envs\ml2`? What happens if you run `import mlflow` after the error?,constantly reproduce issue run import error,issue,negative,neutral,neutral,neutral,neutral,neutral
1649104504,"Experiment names are usually too long to display completely in the sidebar. So if this feature is implemented, it would make mlflow more convenient.",experiment usually long display completely feature would make convenient,issue,negative,positive,neutral,neutral,positive,positive
1649064536,@Bncer you can try calling monkeypatch statement before the `with pytest.raises()` block :),try calling statement block,issue,negative,neutral,neutral,neutral,neutral,neutral
1649016894,I think anyone conducting numerous experiments would surely appreciate the introduction of this feature,think anyone numerous would surely appreciate introduction feature,issue,positive,positive,positive,positive,positive,positive
1648994457,"@harupy strangely, the error I shared came from `import mlflow` command. ",strangely error came import command,issue,negative,negative,neutral,neutral,negative,negative
1648897499,The python job failure is unrelated.,python job failure unrelated,issue,negative,negative,negative,negative,negative,negative
1648819570,@sandeshregmi Thanks! Can you also paste the code here?,thanks also paste code,issue,negative,positive,positive,positive,positive,positive
1648810909,@raphaelauv Thanks for reporting issue. Can you create a docke compose file that can reproduce this issue?,thanks issue create compose file reproduce issue,issue,positive,positive,positive,positive,positive,positive
1648786896,"@harupy sorry about that here is the content. ---------------------------------------------------------------------------
UnicodeDecodeError                        Traceback (most recent call last)
Cell In[1], line 1
----> 1 import mlflow

File c:\Users\sregmi444\Anaconda3\envs\ml2\Lib\site-packages\mlflow\__init__.py:41
     38 warnings.filterwarnings(""ignore"", message=""numpy.dtype size changed"")
     39 warnings.filterwarnings(""ignore"", message=""numpy.ufunc size changed"")
---> 41 from mlflow import projects  # pylint: disable=unused-import
     42 from mlflow import tracking  # pylint: disable=unused-import
     43 from mlflow import models  # pylint: disable=unused-import

File c:\Users\sregmi444\Anaconda3\envs\ml2\Lib\site-packages\mlflow\projects\__init__.py:9
      6 import os
      7 import logging
----> 9 import mlflow.projects.databricks
     10 from mlflow import tracking
     11 from mlflow.entities import RunStatus

File c:\Users\sregmi444\Anaconda3\envs\ml2\Lib\site-packages\mlflow\projects\databricks.py:11
      8 import posixpath
      9 import re
---> 11 from mlflow import tracking
     12 from mlflow.entities import RunStatus
     13 from mlflow.exceptions import MlflowException

File c:\Users\sregmi444\Anaconda3\envs\ml2\Lib\site-packages\mlflow\tracking\__init__.py:8
      1 """"""
      2 The ``mlflow.tracking`` module provides a Python CRUD interface to MLflow experiments
      3 and runs. This is a lower level API that directly translates to MLflow
      4 `REST API <../rest-api.html>`_ calls.
      5 For a higher level API for managing an ""active run"", use the :py:mod:`mlflow` module.
      6 """"""
----> 8 from mlflow.tracking.client import MlflowClient
      9 from mlflow.tracking._tracking_service.utils import (
     10     set_tracking_uri,
     11     get_tracking_uri,
     12     is_tracking_uri_set,
     13     _get_store,
     14 )
     15 from mlflow.tracking._model_registry.utils import (
     16     set_registry_uri,
     17     get_registry_uri,
     18 )

File c:\Users\sregmi444\Anaconda3\envs\ml2\Lib\site-packages\mlflow\tracking\client.py:28
     23 from mlflow.store.model_registry import (
     24     SEARCH_REGISTERED_MODEL_MAX_RESULTS_DEFAULT,
     25     SEARCH_MODEL_VERSION_MAX_RESULTS_DEFAULT,
     26 )
     27 from mlflow.store.tracking import SEARCH_MAX_RESULTS_DEFAULT
---> 28 from mlflow.tracking._model_registry.client import ModelRegistryClient
     29 from mlflow.tracking._model_registry import utils as registry_utils
     30 from mlflow.tracking._model_registry import DEFAULT_AWAIT_MAX_SLEEP_SECONDS

File c:\Users\sregmi444\Anaconda3\envs\ml2\Lib\site-packages\mlflow\tracking\_model_registry\client.py:18
     16 from mlflow.entities.model_registry import RegisteredModelTag, ModelVersionTag
     17 from mlflow.entities.model_registry.model_version_status import ModelVersionStatus
---> 18 from mlflow.tracking._model_registry import utils, DEFAULT_AWAIT_MAX_SLEEP_SECONDS
     19 from mlflow.utils.arguments_utils import _get_arg_names
     21 _logger = logging.getLogger(__name__)

File c:\Users\sregmi444\Anaconda3\envs\ml2\Lib\site-packages\mlflow\tracking\_model_registry\utils.py:11
      9 from mlflow.store._unity_catalog.registry.rest_store import UcModelRegistryStore
     10 from mlflow.tracking._model_registry.registry import ModelRegistryStoreRegistry
---> 11 from mlflow.tracking._tracking_service.utils import (
     12     _resolve_tracking_uri,
     13     get_tracking_uri,
     14 )
     15 from mlflow.utils import rest_utils
     16 from mlflow.utils.databricks_utils import get_databricks_host_creds

File c:\Users\sregmi444\Anaconda3\envs\ml2\Lib\site-packages\mlflow\tracking\_tracking_service\utils.py:210
    205         _tracking_store_registry.register(scheme, _get_sqlalchemy_store)
    207     _tracking_store_registry.register_entrypoints()
--> 210 _register_tracking_stores()
    213 def _get_store(store_uri=None, artifact_uri=None):
    214     return _tracking_store_registry.get_store(store_uri, artifact_uri)

File c:\Users\sregmi444\Anaconda3\envs\ml2\Lib\site-packages\mlflow\tracking\_tracking_service\utils.py:207, in _register_tracking_stores()
    204 for scheme in DATABASE_ENGINES:
    205     _tracking_store_registry.register(scheme, _get_sqlalchemy_store)
--> 207 _tracking_store_registry.register_entrypoints()

File c:\Users\sregmi444\Anaconda3\envs\ml2\Lib\site-packages\mlflow\tracking\registry.py:52, in StoreRegistry.register_entrypoints(self)
     50 def register_entrypoints(self):
     51     """"""Register tracking stores provided by other packages""""""
---> 52     for entrypoint in entrypoints.get_group_all(self.group_name):
     53         try:
     54             self.register(entrypoint.name, entrypoint.load())

File c:\Users\sregmi444\Anaconda3\envs\ml2\Lib\site-packages\entrypoints.py:237, in get_group_all(group, path)
    232 """"""Find all entry points in a group.
    233 
    234 Returns a list of :class:`EntryPoint` objects.
    235 """"""
    236 result = []
--> 237 for config, distro in iter_files_distros(path=path):
    238     if group in config:
    239         for name, epstr in config[group].items():

File c:\Users\sregmi444\Anaconda3\envs\ml2\Lib\site-packages\entrypoints.py:203, in iter_files_distros(path, repeated_distro)
    200 distro_names_seen.add(distro.name)
    202 cp = CaseSensitiveConfigParser(delimiters=('=',))
--> 203 cp.read([path])
    204 yield cp, distro

File c:\Users\sregmi444\Anaconda3\envs\ml2\Lib\configparser.py:713, in RawConfigParser.read(self, filenames, encoding)
    711 try:
    712     with open(filename, encoding=encoding) as fp:
--> 713         self._read(fp, filename)
    714 except OSError:
    715     continue

File c:\Users\sregmi444\Anaconda3\envs\ml2\Lib\configparser.py:1036, in RawConfigParser._read(self, fp, fpname)
   1034 indent_level = 0
   1035 e = None                              # None, or an exception
-> 1036 for lineno, line in enumerate(fp, start=1):
   1037     comment_start = sys.maxsize
   1038     # strip inline comments

File :322, in decode(self, input, final)

UnicodeDecodeError: 'utf-8' codec can't decode byte 0xb0 in position 34: invalid start byte",sorry content recent call last cell line import file ignore size ignore size import import import file import o import logging import import import file import import import import import file module python interface lower level directly rest higher level active run use import import import file import import import import import file import import import import file import import import import import file scheme return file scheme scheme file self self register provided try file group path find entry group list class result group name group file path path yield file self try open except continue file self none none exception line enumerate strip file decode self input final ca decode position invalid start,issue,negative,negative,neutral,neutral,negative,negative
1648778299,@sandeshregmi Thanks for reporting! I don't have Word. Can you paste the contents here?,thanks word paste content,issue,negative,positive,positive,positive,positive,positive
1648724081,"Setting up a MLflow talk to some friends on PyData's chapter here in Brasília (Brazil)! Got the same problem, is there any updates on this? I was able to circumvent this calling the <code> --experiment-name </code> on my CLI, but it would be nice to make this programmatically.",setting talk chapter brazil got problem able circumvent calling code would nice make programmatically,issue,negative,positive,positive,positive,positive,positive
1648653887,"I'm also currently struggling to pass `permissions::access_control_list` to Databricks task runs kicked off from `mlflow run`.   I've tried to find something in the `backend_config` param to `mlflow run`... but not seeing it. 

I see this was marked as Closed-completed a month ago.  @dbczumar Was this implemented?  If so, could you point me to the param(s) I should use.  Thanks!",also currently struggling pas task run tried find something param run seeing see marked month ago could point param use thanks,issue,negative,positive,positive,positive,positive,positive
1648518550,"Hi @harupy @gabrielfu! 

Following [PR1](https://github.com/mlflow/mlflow/pull/9086#issuecomment-1648185698) I have  changed [tests/projects/test_docker_projects.py](https://github.com/mlflow/mlflow/blob/13f355577cf925afefae1cd246d47a8a3517ffe1/tests/projects/test_docker_projects.py#L262)
and faced pylint restriction:
`pylint tests/projects/test_docker_projects.py` gives me:

`
tests/projects/test_docker_projects.py:261:8: W0004: with pytest.raises should not contain multiple statements. It should only contain a single statement that throws an exception. (pytest-raises-multiple-statements)
` 
This is because this [custom plugin](https://github.com/mlflow/mlflow/blob/13f355577cf925afefae1cd246d47a8a3517ffe1/pylint_plugins/pytest_raises_checker/__init__.py#L40) doesn't allow to make commit.
 
However with `with mock.patch.dict(""os.environ"", os_environ):` pylint works fine.

Waiting for further instructions how to solve this part)

Thank you",hi following faced restriction contain multiple contain single statement exception custom allow make commit however work fine waiting solve part thank,issue,positive,positive,neutral,neutral,positive,positive
1647899117,This is a really important feature - The git commit hash doesn't make sense without a guarantee that it acutally contains the same code. ,really important feature git commit hash make sense without guarantee code,issue,negative,positive,positive,positive,positive,positive
1647865686,"LGTM! I also noticed that the code already comply with these 2 rules :) 


Are you working on `PT012` too? FYI I've started updating the code but not finished yet",also code already comply working code finished yet,issue,negative,neutral,neutral,neutral,neutral,neutral
1647684754,@stroblme Thanks for the proposal! It seems reasonable to me :) Adding `**kwargs` sounds more appealing because `log_figure` also supports matplotlib.,thanks proposal reasonable appealing also,issue,negative,positive,positive,positive,positive,positive
1647417485,@s-aditi Can you provide code to reproduce the issue?,provide code reproduce issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1647188686,We'll keep this issue open to collect upvotes/feedback.,keep issue open collect,issue,negative,neutral,neutral,neutral,neutral,neutral
1647153598,"> Is several times a day ""very often""?

Yes, because it disrupts expected user flow it is a bad https://github.com/mlflow/mlflow/labels/area%2Fuiux. And it can be fixed without degrading the flow for `mlflow` serve users.

> ```
> > cat -h
> cat: invalid option -- 'h'
> Try 'cat --help' for more information.
> 
> > touch -h
> touch: missing file operand
> Try 'touch --help' for more information.
> 
> > grep -h
> Usage: grep [OPTION]... PATTERNS [FILE]...
> Try 'grep --help' for more information.
> 
> > sed -h
> sed: invalid option -- 'h'
> ```

```
$ man mlflow
No manual entry for mlflow
```
> Is there really an expectation that `-h` is a short version of `--help`?

Yes. And my UX hypothesis is that the expectation is common for these types of users 

1. People who were born after `cat`, `sed`, `touch` and `grep` were written. 
2. People who write and use command line tools written with Python.
3. People who use shortcuts.

`meta-llama/Llama-2-70b-chat-hf` also confirms that `-h` is widely used for help https://hf.co/chat/r/Byv_aIr

> Can you add an alias like `mrh` which is an alias for `mlflow run --help`?

I can send a PR to remove [this stuff](https://github.com/mlflow/mlflow/blob/master/CODE_OF_CONDUCT.rst#our-standards) from the repo if you want.",several time day often yes user flow bad fixed without degrading flow serve cat cat invalid option try help information touch touch missing file operand try help information usage option file try help information invalid option man manual entry really expectation short version help yes hypothesis expectation common people born cat touch written people write use command line written python people use also widely used help add alias like alias run help send remove stuff want,issue,positive,negative,negative,negative,negative,negative
1647114637,"Is there really an expectation that `-h` is a short version of `--help`?

```
> cat -h
cat: invalid option -- 'h'
Try 'cat --help' for more information.

> touch -h
touch: missing file operand
Try 'touch --help' for more information.

> grep -h
Usage: grep [OPTION]... PATTERNS [FILE]...
Try 'grep --help' for more information.

> sed -h
sed: invalid option -- 'h'
```

I'll close this issue.",really expectation short version help cat cat invalid option try help information touch touch missing file operand try help information usage option file try help information invalid option close issue,issue,positive,neutral,neutral,neutral,neutral,neutral
1647112032,"We might add `--host` to `mlflow run` in the future. We want to keep `-h` for that.

> I type -h very often, like several times a day

Is `several times a day` ""very often""?

> I also use things like https://github.com/ohmyzsh/ohmyzsh/tree/master/plugins/git#aliases to save me from typing.

Can you add an alias like `mrh` which is an alias for `mlflow run --help`?",might add host run future want keep type often like several time day several time day often also use like save add alias like alias run help,issue,positive,neutral,neutral,neutral,neutral,neutral
1646617424,"> @viktoriussuwandi Thanks for the PR! Can you split the PR as instructed in #9008?

Sorry my bad @harupy.
I will close this PR, and try to submit another PRs
",thanks split instructed sorry bad close try submit another,issue,negative,negative,negative,negative,negative,negative
1646576101,"In MLflow 2.3.2, we see this code:

```
@catch_mlflow_exception
def _before_request():
    if is_unprotected_route(request.path):
        return

    _user = request.authorization.username if request.authorization else None
    _logger.debug(f""before_request: {request.method} {request.path} (user: {_user})"")
```

A number of functions also directly access `request.authorization.username`, e.g.
```
def _get_permission_from_experiment_id() -> Permission:
    experiment_id = _get_request_param(""experiment_id"")
    username = request.authorization.username
    return _get_permission_from_store_or_default(
        lambda: store.get_experiment_permission(experiment_id, username).permission
    )
```

I propose adding a level of indirection, i.e. rather than accessing `request.authorization` directly, instead something like (probably with appropriate caching of the function lookup):

```
import importlib

from werkzeug.datastructures import Authorization

def get_request_authorization(request) -> Optional[Authorization]:
    module_name, func_name = auth_config.authorization_function.rsplit('.', 1)
    module = importlib.import_module(module_name)
    auth_func = getattr(module, func_name)
    return auth_func(request)
```

This is the actual function we use for JWT in Google Cloud. If this feature were implemented, we would configure MLflow to call this function. Currently, though, we use monkeypatching.

```
import base64
import logging

from google.auth import jwt

BEARER_PREFIX = ""bearer ""

_logger = logging.getLogger(__name__)


def get_jwt_authorization_info(request) -> Optional[Authorization]:
    """"""Given request, build & return Authorization object based on JWT token.""""""
    _logger.debug(""Getting token"")
    # In Cloud Run, we receive the token in the ""Authorization"" header.
    # In App Engine, we receive it in the ""x-goog-iap-jwt-assertion"" header.
    # https://cloud.google.com/iap/docs/signed-headers-howto#securing_iap_headers
    # In the former case, the token is prefixed with ""Bearer "", but in the latter
    # case it is not.
    token = request.headers.get(
        ""Authorization"", request.headers.get(""x-goog-iap-jwt-assertion"")
    )
    if token:
        _logger.debug(f""Verifying token"")
        if token.lower().startswith(""basic ""):
            # ""basic"" means HTTP basic authentication, which is used for local
            # testing. The token is base64-encoded, so we need to decode it.
            # This will never happen in production because Google authenticates
            # the user before the request reaches the service.
            token = base64.b64decode(token.split("" "")[1]).decode(
                ""utf-8""
            )  # Remove ""basic "" prefix
            # Split the string into email and password. We discard the password,
            # because this behavior is only for local testing, and this function
            # is not responsible for authenticating the user, only for extracting
            # the username for _authorization_.
            email, _ = token.split("":"")
            email = _apply_impersonation(request, email)
            return Authorization(
                auth_type=""jwt"", data=dict(username=email, password="""")
            )
        elif token.lower().startswith(BEARER_PREFIX):
            token = token[len(BEARER_PREFIX) :]  # Remove prefix

        # Note: Rather than google.oauth2.id_token.verify_oauth2_token(), we use
        # jwt.decode() with verification disabled. That's because within the
        # Cloud Run service, Google has already verified the token (thus we
        # don't NEED to verify it) and removed the signature (thus we CAN'T
        # verify it).
        # https://cloud.google.com/run/docs/authenticating/service-to-service#authenticating_end-users
        token_info = jwt.decode(token, verify=False)
        if not token_info:  # pragma: no cover
            _logger.warning(""No token_info returned"")
            return None

        email = token_info[""email""]
        return Authorization(auth_type=""jwt"", data=dict(username=email, password=""""))
    else:  # pragma: no cover
        _logger.warning(""Missing or invalid authorization token"")
        return None
```",see code return else none user number also directly access permission return lambda propose level indirection rather directly instead something like probably appropriate function import import authorization request optional authorization module module return request actual function use cloud feature would configure call function currently though use import base import logging import bearer request optional authorization given request build return authorization object based token getting token cloud run receive token authorization header engine receive header former case token prefixed bearer latter case token authorization token token basic basic basic authentication used local testing token need decode never happen production user request service token remove basic prefix split string password discard password behavior local testing function responsible user request return authorization token token remove prefix note rather use verification disabled within cloud run service already token thus need verify removed signature thus verify token cover returned return none return authorization else cover missing invalid authorization token return none,issue,negative,negative,neutral,neutral,negative,negative
1646398272,"@barrywhart Thanks for the reply!

> I can provide some pseudocode which may be clearer.

Code always helps. Can you provide some pseudocode?",thanks reply provide may clearer code always provide,issue,negative,positive,positive,positive,positive,positive
1646360316,"I get the following warnings when building the docs:
```(mlflow-dev-env) ➜  docs git:(retriever-wrapper) ✗ sphinx-build -b html -d build/doctrees  -W --keep-going -n -T source build/html
Running Sphinx v3.5.4
loading pickled environment... done
building [mo]: targets for 0 po files that are out of date
building [html]: targets for 1 source files that are out of date
updating environment: 0 added, 2 changed, 0 removed
reading sources... [100%] python_api/mlflow.langchain
looking for now-outdated files... none found
pickling environment... done
checking consistency... done
preparing documents... done
writing output... [100%] python_api/mlflow.langchain
/Users/liang.zhang/mlflow/mlflow/langchain/retriever_chain.py:docstring of mlflow.langchain.retriever_chain.RetrieverChain:: WARNING: py:class reference target not found: langchain.schema.memory.BaseMemory
/Users/liang.zhang/mlflow/mlflow/langchain/retriever_chain.py:docstring of mlflow.langchain.retriever_chain.RetrieverChain:: WARNING: py:class reference target not found: langchain.callbacks.base.BaseCallbackHandler
/Users/liang.zhang/mlflow/mlflow/langchain/retriever_chain.py:docstring of mlflow.langchain.retriever_chain.RetrieverChain:: WARNING: py:class reference target not found: langchain.callbacks.base.BaseCallbackManager
/Users/liang.zhang/mlflow/mlflow/langchain/retriever_chain.py:docstring of mlflow.langchain.retriever_chain.RetrieverChain:: WARNING: py:class reference target not found: langchain.callbacks.base.BaseCallbackManager
/Users/liang.zhang/mlflow/mlflow/langchain/retriever_chain.py:docstring of mlflow.langchain.retriever_chain.RetrieverChain:: WARNING: py:class reference target not found: langchain.schema.retriever.BaseRetriever
/Users/liang.zhang/mlflow/mlflow/langchain/retriever_chain.py:docstring of mlflow.langchain.retriever_chain.RetrieverChain:1: WARNING: py:class reference target not found: langchain.chains.base.Chain
/Users/liang.zhang/mlflow/mlflow/langchain/retriever_chain.py:docstring of mlflow.langchain.retriever_chain.RetrieverChain.load:: WARNING: py:class reference target not found: mlflow.langchain.retriever_chain.RetrieverChain
/Users/liang.zhang/mlflow/mlflow/langchain/retriever_chain.py:docstring of mlflow.langchain.RetrieverChain.retriever:: WARNING: py:class reference target not found: BaseRetriever
generating indices... genindex py-modindex done
highlighting module code... [100%] pydantic.config
writing additional pages... search done
copying images... [100%] _static/images/tracking_artifact_ui_custom_flavor.png
copying static files... done
copying extra files... done
dumping search index in English (code: en)... done
dumping object inventory... done
build finished with problems, 8 warnings.
Copying examplecode stylesheet/javascript... done
(mlflow-dev-env) ➜  docs git:(retriever-wrapper) ✗
```

These are caused by sphinx autodoc. But I don't quite understand why `/Users/liang.zhang/mlflow/mlflow/langchain/retriever_chain.py:docstring of mlflow.langchain.retriever_chain.RetrieverChain.load:: WARNING: py:class reference target not found: mlflow.langchain.retriever_chain.RetrieverChain` happens, but for other warnings, I think we can suppress them, because these are langchain classes.

@harupy Do you have any suggestions for resolving these warnings?",get following building git source running sphinx loading environment done building mo po date building source date environment added removed reading looking none found environment done consistency done done writing output warning class reference target found warning class reference target found warning class reference target found warning class reference target found warning class reference target found warning class reference target found warning class reference target found warning class reference target found generating index done module code writing additional search done static done extra done dumping search index code en done dumping object inventory done build finished done git sphinx quite understand warning class reference target found think suppress class,issue,negative,positive,positive,positive,positive,positive
1646357639,"Sure!

Our MLflow deployment runs on App Engine and Cloud Run, where Google Cloud _itself_ authenticates each request prior to forwarding it to the MLflow server instance.

Thus, for our deployment, we provide a function that examines a JWT token in the header, extracts the user's email address (i.e. user name) and returns it. It does not need to authenticate (i.e. validating a token or checking a password). Then the ""basic auth"" provider performs authorization based on the identity returned.

My point is that, if this FR is implemented, some users of the feature _may_ want to authenticate, even though we don't.

Does this make sense? If not, I can provide some pseudocode which may be clearer.",sure deployment engine cloud run cloud request prior forwarding server instance thus deployment provide function token header user address user name need authenticate token password basic provider authorization based identity returned point feature want authenticate even though make sense provide may clearer,issue,negative,positive,positive,positive,positive,positive
1646356626,@EdAbati Can you rebase this PR on master? It's been 5 days since CI ran on this PR. There might be changes violating the new rules on the master branch.,rebase master day since ran might new master branch,issue,negative,positive,positive,positive,positive,positive
1646356391,"@viktoriussuwandi ruff 0.0.279 has been released. Can you install it and run `ruff --fix .`?

https://pypi.org/project/ruff/",ruff install run ruff fix,issue,negative,neutral,neutral,neutral,neutral,neutral
1645939350,Any specific reason why it only fails to infer for high accuracy models?,specific reason infer high accuracy,issue,negative,positive,neutral,neutral,positive,positive
1645858036,"> 2023/07/20 17:26:36 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: dbfs:/databricks/mlflow-tracking/590967242928602/0fa61651c3a843188f9e25a499500a28/artifacts/xmodel/sparkml, flavor: spark), fall back to return ['pyspark==3.4.0']. Set logging level to DEBUG to see the full traceback.

This is a warning, not an error. MLflow _**attempted**_ to infer the requirements of your model but failed. Requirement inference doesn't always succeed.",warning unexpected error pip model flavor spark fall back return set logging level see full warning error infer model requirement inference always succeed,issue,negative,positive,positive,positive,positive,positive
1645831409,"This is the error without pip requirements mentioned:

> 2023/07/20 17:26:36 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: dbfs:/databricks/mlflow-tracking/590967242928602/0fa61651c3a843188f9e25a499500a28/artifacts/xmodel/sparkml, flavor: spark), fall back to return ['pyspark==3.4.0']. Set logging level to DEBUG to see the full traceback.

This is with pip req mentioned:

> /databricks/python/lib/python3.10/site-packages/xgboost/sklearn.py:782: UserWarning: Loading a native XGBoost model with Scikit-Learn interface.
>   warnings.warn(""Loading a native XGBoost model with Scikit-Learn interface."")
> 
> 2023/07/20 17:25:40 INFO mlflow.spark: Inferring pip requirements by reloading the logged model from the databricks artifact repository, which can be time-consuming. To speed up, explicitly specify the conda_env or pip_requirements when calling log_model().",error without pip warning unexpected error pip model flavor spark fall back return set logging level see full pip loading native model interface loading native model interface pip logged model artifact repository speed explicitly specify calling,issue,negative,positive,positive,positive,positive,positive
1645800336,"nothing much. apart from the fact that infer pip requirements fails during r2>90 logging. hence I mention pip like this:
mlflow.spark.log_model(loaded_model,""best_xgb_model1"",input_example=test_df.select(old_cols_list).limit(1).toPandas(),**pip_requirements=[""mlflow==2.5.0\npandas==1.4.4\npsutil==5.9.0\npyspark==3.4.0\nscikit-learn==1.1.1\ntyping-extensions==4.3.0\nxgboost==1.7.4\n""]**)",nothing much apart fact infer pip logging hence mention pip like,issue,negative,positive,positive,positive,positive,positive
1645778316,"@harupy This log is for model that is getting deployed and has almost ~60 as r2:
/databricks/python/lib/python3.10/site-packages/xgboost/sklearn.py:782: UserWarning: Loading a native XGBoost model with Scikit-Learn interface.
  warnings.warn(""Loading a native XGBoost model with Scikit-Learn interface."")
2023/07/21 15:38:24 INFO mlflow.spark: Inferring pip requirements by reloading the logged model from the databricks artifact repository, which can be time-consuming. To speed up, explicitly specify the conda_env or pip_requirements when calling log_model().
/databricks/python/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn(""Setuptools is replacing distutils."")",log model getting almost loading native model interface loading native model interface pip logged model artifact repository speed explicitly specify calling,issue,negative,neutral,neutral,neutral,neutral,neutral
1645750960,"@barrywhart Thanks for the FR! This sounds reasonable to me.

> Add support for a new, optional setting, e.g. identity_provider, in the auth config file (basic_auth.ini). It specifies a module and function name that returns the user's identity.

The second option (adding an optional field in the config) sounds more appealing to me because you don't need to create a package.

> Our use case only requires authorization, not authentication, although if it seems useful, the same function could do both (e.g. throw an exception or return None if the user is not authenticated).

Can you elaborate on this?
",thanks reasonable add support new optional setting file module function name user identity second option optional field appealing need create package use case authorization authentication although useful function could throw exception return none user elaborate,issue,positive,positive,positive,positive,positive,positive
1645724078,"@harupy 
Getting the below exception(this is similar to the one I get while deploying as REST Endpoint on databricks):

> /databricks/python/lib/python3.10/site-packages/xgboost/sklearn.py:782: UserWarning: Loading a native XGBoost model with Scikit-Learn interface.
  warnings.warn(""Loading a native XGBoost model with Scikit-Learn interface."")
2023/07/21 14:51:29 DEBUG mlflow.utils.autologging_utils: Failed to log autologging event via '<bound method DatabricksAutologgingEventLogger.log_original_function_success of <DatabricksAutologgingEventLogger.DatabricksAutologgingEventLogger object at 0x7efe8c58b790>>'. Exception: 'NoneType' object has no attribute 'session'
2023/07/21 14:51:29 DEBUG mlflow.utils.autologging_utils: Failed to log autologging event via '<bound method DatabricksAutologgingEventLogger.log_patch_function_success of <DatabricksAutologgingEventLogger.DatabricksAutologgingEventLogger object at 0x7efe8c58b790>>'. Exception: 'NoneType' object has no attribute 'session'
2023/07/21 14:51:30 DEBUG mlflow.utils.autologging_utils: Failed to log autologging event via '<bound method DatabricksAutologgingEventLogger.log_original_function_success of <DatabricksAutologgingEventLogger.DatabricksAutologgingEventLogger object at 0x7efe8c58b790>>'. Exception: 'NoneType' object has no attribute 'session'
2023/07/21 14:51:30 DEBUG mlflow.utils.autologging_utils: Failed to log autologging event via '<bound method DatabricksAutologgingEventLogger.log_patch_function_success of <DatabricksAutologgingEventLogger.DatabricksAutologgingEventLogger object at 0x7efe8c58b790>>'. Exception: 'NoneType' object has no attribute 'session'
2023/07/21 14:51:31 DEBUG mlflow.utils.autologging_utils: Failed to log autologging event via '<bound method DatabricksAutologgingEventLogger.log_original_function_success of <DatabricksAutologgingEventLogger.DatabricksAutologgingEventLogger object at 0x7efe8c58b790>>'. Exception: 'NoneType' object has no attribute 'session'
2023/07/21 14:51:31 DEBUG mlflow.utils.autologging_utils: Failed to log autologging event via '<bound method DatabricksAutologgingEventLogger.log_patch_function_success of <DatabricksAutologgingEventLogger.DatabricksAutologgingEventLogger object at 0x7efe8c58b790>>'. Exception: 'NoneType' object has no attribute 'session'
2023/07/21 14:52:04 INFO mlflow.spark: Inferring pip requirements by reloading the logged model from the databricks artifact repository, which can be time-consuming. To speed up, explicitly specify the conda_env or pip_requirements when calling log_model().
2023/07/21 14:52:56 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: dbfs:/databricks/mlflow-tracking/1706148587156976/844dfd3bf2ef4e1aab9c238465169f79/artifacts/best_xgb_model1/sparkml, flavor: spark), fall back to return ['pyspark==3.4.0']. Set logging level to DEBUG to see the full traceback.
2023/07/21 14:52:56 DEBUG mlflow.utils.environment: 
Traceback (most recent call last):
  File ""/local_disk0/.ephemeral_nfs/envs/pythonEnv-ac0d65cc-0686-4cd1-ab19-4fe4203a4bec/lib/python3.10/site-packages/mlflow/utils/environment.py"", line 391, in infer_pip_requirements
    return _infer_requirements(model_uri, flavor)
  File ""/local_disk0/.ephemeral_nfs/envs/pythonEnv-ac0d65cc-0686-4cd1-ab19-4fe4203a4bec/lib/python3.10/site-packages/mlflow/utils/requirements_utils.py"", line 403, in _infer_requirements
    modules = _capture_imported_modules(model_uri, flavor)
  File ""/local_disk0/.ephemeral_nfs/envs/pythonEnv-ac0d65cc-0686-4cd1-ab19-4fe4203a4bec/lib/python3.10/site-packages/mlflow/utils/requirements_utils.py"", line 305, in _capture_imported_modules
    _run_command(
  File ""/local_disk0/.ephemeral_nfs/envs/pythonEnv-ac0d65cc-0686-4cd1-ab19-4fe4203a4bec/lib/python3.10/site-packages/mlflow/utils/requirements_utils.py"", line 213, in _run_command
    raise MlflowException(msg)
mlflow.exceptions.MlflowException: Encountered an unexpected error while running ['/local_disk0/.ephemeral_nfs/envs/pythonEnv-ac0d65cc-0686-4cd1-ab19-4fe4203a4bec/bin/python', '/local_disk0/.ephemeral_nfs/envs/pythonEnv-ac0d65cc-0686-4cd1-ab19-4fe4203a4bec/lib/python3.10/site-packages/mlflow/utils/_capture_modules.py', '--model-path', '/tmp/tmp7v2iqu96/sparkml', '--flavor', 'spark', '--output-file', '/tmp/tmp410qjek3/imported_modules.txt', '--sys-path', '[""/databricks/python_shell/scripts"", ""/databricks/python/lib/python3.10/site-packages/git/ext/gitdb"", ""/local_disk0/spark-da8bcf82-4363-447e-b2a0-f05db5c7d5d2/userFiles-40b22469-1bc7-4559-8291-85bb3de49dc8"", ""/databricks/spark/python"", ""/databricks/spark/python/lib/py4j-0.10.9.7-src.zip"", ""/databricks/jars/spark--driver--driver-spark_3.4_2.12_deploy.jar"", ""/databricks/jars/spark--maven-trees--ml--13.x--graphframes--org.graphframes--graphframes_2.12--org.graphframes__graphframes_2.12__0.8.2-db2-spark3.4.jar"", ""/databricks/python_shell"", ""/usr/lib/python310.zip"", ""/usr/lib/python3.10"", ""/usr/lib/python3.10/lib-dynload"", """", ""/local_disk0/.ephemeral_nfs/envs/pythonEnv-ac0d65cc-0686-4cd1-ab19-4fe4203a4bec/lib/python3.10/site-packages"", ""/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages"", ""/databricks/python/lib/python3.10/site-packages"", ""/usr/local/lib/python3.10/dist-packages"", ""/usr/lib/python3/dist-packages"", ""/databricks/.python_edge_libs"", ""/Workspace/Shared/DS_PlayGround""]']
exit status: 1
stdout: 
stderr: ERROR StatusLogger Reconfiguration failed: No configuration found for '659a969b' at 'null' in 'null'
ERROR StatusLogger Reconfiguration failed: No configuration found for 'Default' at 'null' in 'null'
Setting default log level to ""WARN"".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
23/07/21 14:52:14 WARN MetricsSystem: Using default name SparkStatusTracker for source because neither spark.metrics.namespace nor spark.app.id is set.
23/07/21 14:52:16 ERROR SparkConnectService: Could not start Spark Connect GRPC service
java.io.IOException: Failed to bind to address 0.0.0.0/0.0.0.0:15002
	at grpc_shaded.io.grpc.netty.NettyServer.start(NettyServer.java:328)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:183)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:92)
	at org.apache.spark.sql.connect.service.SparkConnectService$.startGRPCService(SparkConnectService.scala:290)
	at org.apache.spark.sql.connect.service.SparkConnectService$.start(SparkConnectService.scala:296)
	at org.apache.spark.sql.connect.SparkConnectPlugin$$anon$1.init(SparkConnectPlugin.scala:48)
	at org.apache.spark.internal.plugin.DriverPluginContainer.$anonfun$driverPlugins$1(PluginContainer.scala:55)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:293)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:293)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:290)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
	at org.apache.spark.internal.plugin.DriverPluginContainer.<init>(PluginContainer.scala:48)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:224)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:195)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:741)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:60)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)
	at py4j.Gateway.invoke(Gateway.java:257)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:195)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:115)
	at java.lang.Thread.run(Thread.java:750)
Caused by: grpc_shaded.io.netty.channel.unix.Errors$NativeIoException: bind(..) failed: Address already in use
2023/07/21 14:52:25 INFO mlflow.spark: File '/tmp/tmp7v2iqu96/sparkml' is already on DFS, copy is not necessary.
ANTLR Tool version 4.8 used for code generation does not match the current runtime version 4.9.3
ANTLR Tool version 4.8 used for code generation does not match the current runtime version 4.9.3
23/07/21 14:52:34 WARN CloudStoreSpecificConf: Unknown cloud store file
23/07/21 14:52:40 ERROR RetryingBlockTransferor: Exception while beginning fetch of 1 outstanding blocks 
java.io.IOException: Failed to connect to /10.32.171.6:41789
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:284)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:214)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:130)
	at org.apache.spark.network.shuffle.RetryingBlockTransferor.transferAllOutstanding(RetryingBlockTransferor.java:173)
	at org.apache.spark.network.shuffle.RetryingBlockTransferor.start(RetryingBlockTransferor.java:152)
	at org.apache.spark.network.netty.NettyBlockTransferService.fetchBlocks(NettyBlockTransferService.scala:150)
	at org.apache.spark.network.BlockTransferService.fetchBlockSync(BlockTransferService.scala:102)
	at org.apache.spark.storage.BlockManager.fetchRemoteManagedBuffer(BlockManager.scala:1194)
	at org.apache.spark.storage.BlockManager.$anonfun$getRemoteBlock$8(BlockManager.scala:1138)
	at scala.Option.orElse(Option.scala:447)
	at org.apache.spark.storage.BlockManager.getRemoteBlock(BlockManager.scala:1138)
	at org.apache.spark.storage.BlockManager.getRemoteBytes(BlockManager.scala:1278)
	at org.apache.spark.scheduler.TaskResultGetter$$anon$3.$anonfun$run$1(TaskResultGetter.scala:114)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2359)
	at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:64)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.$anonfun$run$1(SparkThreadLocalForwardingThreadPoolExecutor.scala:114)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$4(SparkThreadLocalForwardingThreadPoolExecutor.scala:77)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:41)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:76)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured$(SparkThreadLocalForwardingThreadPoolExecutor.scala:62)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:111)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.run(SparkThreadLocalForwardingThreadPoolExecutor.scala:114)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /10.32.171.6:41789
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:337)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:776)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:750)
23/07/21 14:52:40 ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: Cannot find endpoint: spark://CoarseGrainedScheduler@10.32.171.6:35575
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:472)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:47)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:119)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:118)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:177)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.$anonfun$run$1(SparkThreadLocalForwardingThreadPoolExecutor.scala:114)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$4(SparkThreadLocalForwardingThreadPoolExecutor.scala:77)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:41)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:76)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured$(SparkThreadLocalForwardingThreadPoolExecutor.scala:62)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:111)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.run(SparkThreadLocalForwardingThreadPoolExecutor.scala:114)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.32.171.6:35575
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:175)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:171)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:105)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:105)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:252)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:266)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:265)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:105)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 17 more
23/07/21 14:52:45 ERROR RetryingBlockTransferor: Exception while beginning fetch of 1 outstanding blocks (after 1 retries)
",getting exception similar one get rest loading native model interface loading native model interface log event via bound method object exception object attribute log event via bound method object exception object attribute log event via bound method object exception object attribute log event via bound method object exception object attribute log event via bound method object exception object attribute log event via bound method object exception object attribute pip logged model artifact repository speed explicitly specify calling warning unexpected error pip model flavor spark fall back return set logging level see full recent call last file line return flavor file line flavor file line file line raise unexpected error running flavor driver jar exit status error configuration found error configuration found setting default log level warn adjust logging level use use warn default name source neither set error could start spark connect service bind address anon native method bind address already use file already copy necessary tool version used code generation match current version tool version used code generation match current version warn unknown cloud store file error exception beginning fetch outstanding connect anon anon run anon run connection connection native method error error exception thrown find spark apache spark storage process apache spark netty anon run find spark anon anon transform anon anon transform run anon anon error exception beginning fetch outstanding,issue,negative,positive,positive,positive,positive,positive
1645703924,"> @raghagra Thanks for reporting the issue. It looks like you're using `hyperopt`. Can you reproduce the error without `hyperopt`?

@harupy Thanks for the prompt response, yes without hyperopt also facing the same error. I'm manually adding best param value to a model from scratch and same error.",thanks issue like reproduce error without thanks prompt response yes without also facing error manually best param value model scratch error,issue,positive,positive,positive,positive,positive,positive
1645699208,@raghagra Thanks for reporting the issue. It looks like you're using `hyperopt`. Can you reproduce the error without `hyperopt`?,thanks issue like reproduce error without,issue,negative,positive,positive,positive,positive,positive
1645683524,"Given the popularity of deeplake (6.5k stars), the built-in support sounds reasonable to me.",given popularity support reasonable,issue,positive,positive,positive,positive,positive,positive
1645517424,"Hi [harupy](https://github.com/harupy),
Is there anything else needed to merge this PR ? 
Please let me know",hi anything else merge please let know,issue,negative,neutral,neutral,neutral,neutral,neutral
1645490057,"Hi,
Any update on this? Are we able to save gensim models in mlflow now?

BR,
Ikram",hi update able save,issue,negative,positive,positive,positive,positive,positive
1645360306,@ozen Thanks for the PR! You might want to take a look at the plugin mechanism for `mlflow.data` allows you to define your custom dataset. Let me find the documentation.,thanks might want take look mechanism define custom let find documentation,issue,negative,positive,positive,positive,positive,positive
1645055049,"> @Bncer i edited your PR description so that it doesn't close #9006 (this doesn't fully resolve it)

Yeah, thanks",description close fully resolve yeah thanks,issue,positive,positive,positive,positive,positive,positive
1645051515,@Bncer  i edited your PR description so that it doesn't close #9006 (this doesn't fully resolve it),description close fully resolve,issue,negative,neutral,neutral,neutral,neutral,neutral
1645043891,LGTM! @harupy You wanna take a look? 😃 ,wan na take look,issue,negative,negative,negative,negative,negative,negative
1643768335,"@serena-ruan is there a real confusion here? As a CLI user, I don't feel confused when `-t` option means timeout for `mlflow models serve` and content-type for `mlflow models predict`. It is completely okay for me if `-h` will be host for server commands and help for everything else.

> BTW --help doesn't seem that long lol, and it's not quite often people need to type this command right?

I would be interested to ask other Linux users, but I type `-h` very often, like several times a day. So every 15th command in CLI is a help command. Because it is impossible to remember all options.
```
✗ history | wc -l                 
10285
✗ history | grep "" -h"" | wc -l   
615
✗ history | grep "" --help"" | wc -l
140
```
I also use things like https://github.com/ohmyzsh/ohmyzsh/tree/master/plugins/git#aliases to save me from typing.",real confusion user feel confused option serve predict completely host server help everything else help seem long quite often people need type command right would interested ask type often like several time day every th command help command impossible remember history history history help also use like save,issue,positive,negative,neutral,neutral,negative,negative
1643594814,"As we discussed, in _extract_raw_model function, we still need to check https://github.com/mlflow/mlflow/blob/db6a0a6934e0fb433afde88710920f01de94243e/mlflow/models/evaluation/default_evaluator.py#L83-L84

We can refactor this part later if we wanna add a Base wrapper :)
",function still need check part later wan na add base wrapper,issue,negative,negative,negative,negative,negative,negative
1643471775,Sorry for the delay. I'm testing this change on Databricks to make sure this will break nothing.,sorry delay testing change make sure break nothing,issue,negative,neutral,neutral,neutral,neutral,neutral
1643467176,"> @thinkall Overall looks great! Left a few comments :)
> 
> I think it could be more clear that we split tags test.

Thank you Serana, I've split all the tests for extra_tags. Warning messages and built-in tags checking have been included as well.",overall great left think could clear split test thank split warning included well,issue,positive,positive,positive,positive,positive,positive
1643357059,"Yes that's true, but we want to avoid confusion about using -h as '--host' in some places but as '--help' in other places :) BTW --help doesn't seem that long lol, and it's not quite often people need to type this command right?",yes true want avoid confusion host help help seem long quite often people need type command right,issue,positive,positive,positive,positive,positive,positive
1643233061,"@serena-ruan that must be `mlflow models serve` and `mlflow server` - https://mlflow.org/docs/latest/cli.html

But it is not necessary to override `-h` with `--help` for these commands, from [`click` docs](https://click.palletsprojects.com/en/8.1.x/documentation/#help-parameter-customization).

> If a command itself implements a parameter with the same name, the default help parameter stops accepting it.",must serve server necessary override help click command parameter name default help parameter,issue,positive,neutral,neutral,neutral,neutral,neutral
1643045112,"> Please ensure that all model flavors inherit the restriction to ensure that we're not allowing reserved characters in registered model names (the log_model() operation should abort prior to any files being created and written anywhere).

https://github.com/mlflow/mlflow/issues/8801#issuecomment-1603443667

@luisds95 do you mind also adding the validation at the start of `Model.log()` in `mlflow/models/model.py`? it should be called by all existing model flavours",please ensure model inherit restriction ensure reserved registered model operation abort prior written anywhere mind also validation start model,issue,positive,neutral,neutral,neutral,neutral,neutral
1642993777,Hi @ibobak Could you check if whatever package is used right now for csv previewing support searching or not?,hi could check whatever package used right support searching,issue,negative,positive,positive,positive,positive,positive
1642993278,"Hi @abitrolly We use -h as --host somewhere else, so in order to be consistent I think we don't want to add this 😃 Thanks!",hi use host somewhere else order consistent think want add thanks,issue,negative,positive,positive,positive,positive,positive
1642176002,"tried the above and it didnt work

> @aakashganga thanks.
> 
> Follow the official documentation：
> 
> ```
> You can optionally organize runs into experiments, which group together runs for a specific task. 
> You can create an experiment using the mlflow experiments CLI, with mlflow.create_experiment(),
> or using the corresponding REST parameters. The MLflow API and UI let you create and search for experiments.
> ```
> 
> I did it with this:
> 
> **Create an experiment with python:**
> 
> ```python
> import mlflow
> mlflow.set_tracking_uri('http://your_tracking_server_ip:port')
> client = mlflow.tracking.MlflowClient()
> client.create_experiment('your_experiment_name')
> ```
> 
> **On the client side:**
> 
> ```
> import mlflow
> mlflow.set_tracking_uri('http://your_tracking_server_ip:port')
> mlflow.set_experiment('your_experiment_name')
> with mlflow.start_run():
>     mlflow.log_param(""param1"", 5)
>     # Log a metric; metrics can be updated throughout the run
>     mlflow.log_metric(""foo"", 1)
>     mlflow.log_metric(""foo"", 2)
>     mlflow.log_metric(""foo"", 3)
> ```

Tried this and it didn't work.",tried didnt work thanks follow official optionally organize group together specific task create experiment corresponding rest let create search create experiment python python import client client side import param log metric metric throughout run foo foo foo tried work,issue,negative,positive,neutral,neutral,positive,positive
1642049650,"> Thanks @ridhimag11! In this case, we just need to memorize the last next_page_token and use it on hitting ""Load more"", just like with experiment runs. @jmahlik do you think you want to tackle this one?

Ran in to quite a few problems last time when trying to not pull everything at once. I've been pretty pressed for time lately so don't think I'd be able to pick it up.  Might be better for someone more familiar with the code base/redux.",thanks case need memorize last use load like experiment think want tackle one ran quite last time trying pull everything pretty time lately think able pick might better someone familiar code,issue,positive,positive,positive,positive,positive,positive
1641983015,"This does look like a bug: https://github.com/mlflow/mlflow/blob/f2fadddcbb653d4ec7f2ec3367b2f237d56c9f72/mlflow/sklearn/__init__.py#L1309 
'StandardScalerComponent' only has 'transform' function, we should fix it @harupy ?",look like bug function fix,issue,negative,neutral,neutral,neutral,neutral,neutral
1641963745,@mathiasottenbreit Could you make sure it works with different python versions and for all flavors? Also what's the benefit we can get from compressing? A valid number about folder size change should be helpful.,could make sure work different python also benefit get valid number folder size change helpful,issue,positive,positive,positive,positive,positive,positive
1641937449,"Hi @serena-ruan , could you help review the PR? Thanks.",hi could help review thanks,issue,positive,positive,positive,positive,positive,positive
1641888845,"Thank you for the great work!  :clap:  :clap:
Is there anything I can help with in order to get it done? do you need any help testing the new chart?",thank great work clap clap anything help order get done need help testing new chart,issue,positive,positive,positive,positive,positive,positive
1641749485,"> Can I just rerun https://github.com/mlflow/mlflow/actions/runs/5596007324 this job?

Yes, but I'm not sure if it's rerunable.",rerun job yes sure,issue,positive,positive,positive,positive,positive,positive
1641717030,"> @serena-ruan Can you push a commit? I want to see the doc preview.

Can I just rerun https://github.com/mlflow/mlflow/actions/runs/5596007324 this job?",push commit want see doc preview rerun job,issue,negative,neutral,neutral,neutral,neutral,neutral
1641713353,@serena-ruan Can you push a commit? I want to see the doc preview.,push commit want see doc preview,issue,negative,neutral,neutral,neutral,neutral,neutral
1641443822,@DJSaunders1997 Could you open a ticket to Azure Databricks support team? They should be able to help you on it :),could open ticket azure support team able help,issue,positive,positive,positive,positive,positive,positive
1641408906,"emm, I didn't hit the issue before, would you ping spark team for solution ? I guess it is issue in building pyspark.",hit issue would ping spark team solution guess issue building,issue,negative,neutral,neutral,neutral,neutral,neutral
1641402629,"@WeichenXu123 I ran

```
from pyspark.sql import SparkSession

s2 = SparkSession.builder.remote(""local[2]"").getOrCreate()
s2.range(10).show()
```

and got this error:

```
23/07/19 13:42:54 WARN Utils: Your hostname, haru-Z590-S01 resolves to a loopback address: 127.0.1.1; using 192.168.0.177 instead (on interface enp3s0)
23/07/19 13:42:54 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
Setting default log level to ""WARN"".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
23/07/19 13:42:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
23/07/19 13:42:55 ERROR SparkContext: Error initializing SparkContext.
java.lang.ClassNotFoundException: org.apache.spark.sql.connect.SparkConnectPlugin
        at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:476)
        at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:589)
        at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522)
        at java.base/java.lang.Class.forName0(Native Method)
        at java.base/java.lang.Class.forName(Class.java:398)
        at org.apache.spark.util.Utils$.classForName(Utils.scala:225)
        at org.apache.spark.util.Utils$.$anonfun$loadExtensions$1(Utils.scala:2946)
        at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:293)
        at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
        at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
        at scala.collection.TraversableLike.flatMap(TraversableLike.scala:293)
        at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:290)
        at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
        at org.apache.spark.util.Utils$.loadExtensions(Utils.scala:2944)
        at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:207)
        at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:193)
        at org.apache.spark.SparkContext.<init>(SparkContext.scala:565)
        at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
        at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
        at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
        at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
        at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
        at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
        at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
        at py4j.Gateway.invoke(Gateway.java:238)
        at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
        at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
        at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
        at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
        at java.base/java.lang.Thread.run(Thread.java:829)
23/07/19 13:42:55 WARN MetricsSystem: Stopping a MetricsSystem that is not running
Traceback (most recent call last):
  File ""a.py"", line 3, in <module>
    s2 = SparkSession.builder.remote(""local[2]"").getOrCreate()
  File ""/home/haru/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/pyspark/sql/session.py"", line 454, in getOrCreate
    RemoteSparkSession._start_connect_server(url, opts)
  File ""/home/haru/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/pyspark/sql/connect/session.py"", line 641, in _start_connect_server
    SparkContext.getOrCreate(create_conf(loadDefaults=True, _jvm=SparkContext._jvm))
  File ""/home/haru/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/pyspark/context.py"", line 512, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File ""/home/haru/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/pyspark/context.py"", line 200, in __init__
    self._do_init(
  File ""/home/haru/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/pyspark/context.py"", line 287, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File ""/home/haru/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/pyspark/context.py"", line 417, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File ""/home/haru/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/py4j/java_gateway.py"", line 1587, in __call__
    return_value = get_return_value(
  File ""/home/haru/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/py4j/protocol.py"", line 326, in get_return_value
    raise Py4JJavaError(
py4j.protocol.Py4JJavaError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.
: java.lang.ClassNotFoundException: org.apache.spark.sql.connect.SparkConnectPlugin
        at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:476)
        at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:589)
        at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522)
        at java.base/java.lang.Class.forName0(Native Method)
        at java.base/java.lang.Class.forName(Class.java:398)
        at org.apache.spark.util.Utils$.classForName(Utils.scala:225)
        at org.apache.spark.util.Utils$.$anonfun$loadExtensions$1(Utils.scala:2946)
        at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:293)
        at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
        at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
        at scala.collection.TraversableLike.flatMap(TraversableLike.scala:293)
        at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:290)
        at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
        at org.apache.spark.util.Utils$.loadExtensions(Utils.scala:2944)
        at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:207)
        at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:193)
        at org.apache.spark.SparkContext.<init>(SparkContext.scala:565)
        at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
        at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
        at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
        at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
        at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
        at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
        at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
        at py4j.Gateway.invoke(Gateway.java:238)
        at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
        at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
        at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
        at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
        at java.base/java.lang.Thread.run(Thread.java:829)

```",ran import local got error warn address instead interface warn set need bind another address setting default log level warn adjust logging level use use warn unable load library platform class applicable error error native method native method warn stopping running recent call last file line module local file line file line file line file line file line file line return file line file line raise error calling native method native method,issue,negative,negative,neutral,neutral,negative,negative
1641367814,"We can enable `UP032` after running `ruff --fix UP032 . ` by inserting `""UP032""` here:


https://github.com/mlflow/mlflow/blob/dc5885a80c06981379d9b5379506c4fc746b5412/pyproject.toml#L26-L27",enable running ruff fix,issue,negative,neutral,neutral,neutral,neutral,neutral
1641132488,@jmmonteiro  Could you also put a screenshot of the doc built in PR description?,could also put doc built description,issue,negative,neutral,neutral,neutral,neutral,neutral
1640828278,Great stuff! I followed the tutorial line by line without looking at the screenshots and even without the visual clues it was very clear what everything did and how to follow along in the UI to navigate. Well done!,great stuff tutorial line line without looking even without visual clear everything follow along navigate well done,issue,positive,positive,positive,positive,positive,positive
1640125447,"Hi thanks for your response.

I ran the command in git bash, using the latest spark_version runtime:

`mlflow run https://github.com/mlflow/mlflow#examples/sklearn_elasticnet_wine -b databricks --backend-config '{""spark_version"": ""13.2.x-scala2.12"", ""num_workers"": 1, ""node_type_id"": ""Standard_DS3_v2""}' --experiment-id <my-experiment-id>`

and I still get the same error:
```
Invalid backend config JSON. Parse error: Expecting value: line 1 column 1 (char 0)
Traceback (most recent call last):
  File ""/databricks/python3/bin/mlflow"", line 8, in <module>
    sys.exit(cli())
  File ""/databricks/python3/lib/python3.9/site-packages/click/core.py"", line 1128, in __call__
    return self.main(*args, **kwargs)
  File ""/databricks/python3/lib/python3.9/site-packages/click/core.py"", line 1053, in main
    rv = self.invoke(ctx)
  File ""/databricks/python3/lib/python3.9/site-packages/click/core.py"", line 1659, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File ""/databricks/python3/lib/python3.9/site-packages/click/core.py"", line 1395, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File ""/databricks/python3/lib/python3.9/site-packages/click/core.py"", line 754, in invoke
    return __callback(*args, **kwargs)
  File ""/databricks/python3/lib/python3.9/site-packages/mlflow/cli.py"", line 195, in run
    backend_config = json.loads(backend_config)
  File ""/usr/lib/python3.9/json/__init__.py"", line 346, in loads
    return _default_decoder.decode(s)
  File ""/usr/lib/python3.9/json/decoder.py"", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File ""/usr/lib/python3.9/json/decoder.py"", line 355, in raw_decode
    raise JSONDecodeError(""Expecting value"", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
```
Is there a different way I should represent the cluster-spec as a string?

## Python api
I've also attempted to run projects using the python api
```
mlflow.projects.run(
    uri=""."",
    experiment_id=""3006282966236537"",
    backend=""databricks"",
    synchronous=False,
    backend_config=x,
)
```
Where the backend_config has been attempted as a:
- Path to json file
- String
- Python Dictionary 

all of which give the same error on databricks.


Do you have any other ideas of what I should try next?

Thanks!",hi thanks response ran command git bash latest run still get error invalid parse error value line column char recent call last file line module file line return file line main file line invoke return file line invoke return file line invoke return file line run file line return file line decode end file line raise value none value line column char different way represent string python also run python path file string python dictionary give error try next thanks,issue,positive,positive,positive,positive,positive,positive
1639832880,"> Hey @harupy & @serena-ruan ! Was a pleasure to work with you to make the MLFlow more secure! I've just one question left to you: would you be willing to file a Github security advisory & validate the corresponsing reports on the huntr.dev platform for #8999 & #9053 now that they have been merged into the main branch? I would greatly appreciate that! Stay safe!

Github security advisory sounds like a good plan! @harupy WDYT? I'll go to huntr.dev and mark your reported issues as resolved! Thanks so much 😃 ",hey pleasure work make secure one question left would willing file security advisory validate platform main branch would greatly appreciate stay safe security advisory like good plan go mark resolved thanks much,issue,positive,positive,positive,positive,positive,positive
1639825856,Hey @harupy & @serena-ruan ! Was a pleasure to work with you to make the MLFlow more secure! I've just one question left to you: would you be willing to file a Github security advisory & validate the corresponsing reports on the huntr.dev platform for #8999 & #9053 now that they have been merged into the main branch? I would greatly appreciate that! Stay safe!,hey pleasure work make secure one question left would willing file security advisory validate platform main branch would greatly appreciate stay safe,issue,positive,positive,positive,positive,positive,positive
1639751517,"Thanks @serena-ruan !
I've opened a PR here: https://github.com/mlflow/mlflow/pull/9067 but the workflows seem to be on hold.
Is there anything else that I need to do?",thanks seem hold anything else need,issue,negative,positive,positive,positive,positive,positive
1639657614,"> @serena-ruan I've confirmed that we have backwards compatibility for model serving, batch inference, and spark UDF.
> 
> I found one small issue where the following code throws an error, but I'd expect it to work (let me know if I'm missing something):
> 
> ```
> s = infer_signature([""k""], params={""foo"": np.datetime64(""323432""), ""bar"": [True, False]})
> ```
> 
> ```
> mlflow.exceptions.MlflowException: Failed to infer schema for parameters: [('foo', numpy.datetime64('323432'), MlflowException(""Invalid value for param 'foo': datetime (default: 323432) with shape None, it should be convertible to datetime.date/datetime, got 323432""))]
> ```
> 
> Otherwise, LGTM and feel free to merge! Thanks so much, @serena-ruan !

This is expected, because when we convert numpy.datetime64('323432') to datetime.datetime, it actually becomes a number, which means it's not a valid timestamp, so we throw the error, and this is added to test case as well :)",confirmed backwards compatibility model serving batch inference spark found one small issue following code error expect work let know missing something foo bar true false infer schema invalid value param default shape none convertible got otherwise feel free merge thanks much convert actually becomes number valid throw error added test case well,issue,positive,positive,neutral,neutral,positive,positive
1639636014,"> @dbczumar @serena-ruan I tried what's described in [#8976 (review)](https://github.com/mlflow/mlflow/pull/8976#pullrequestreview-1527387303) and it worked.

Thanks Haru!",tried review worked thanks,issue,negative,positive,positive,positive,positive,positive
1639600959,"@tsungjung411 This is a change in MLflow 2.5.0. In 2.5, MLflow attempts to infer model signatures. I think it's possible to disable it. Let me check.",change infer model think possible disable let check,issue,negative,neutral,neutral,neutral,neutral,neutral
1639150138,"Hi @thinkall, thanks for raising the feature request! This is doable through passing tags into safe_patch function https://github.com/mlflow/mlflow/blob/6dde93758d42455cb90ef324407919ed67668b9b/mlflow/utils/autologging_utils/safety.py#L311-L315 Feel free to raise a PR and we'll review on it :)",hi thanks raising feature request doable passing function feel free raise review,issue,positive,positive,positive,positive,positive,positive
1639034422,"> LGTM!
> Just for reference, here is a [nice collection of command inj payloads](https://github.com/payloadbox/command-injection-payload-list) that can be used for testing both on Unix & Windows systems if you want to implement any other tests in the future

Thank you!! This is super helpful!",reference nice collection command used testing want implement future thank super helpful,issue,positive,positive,positive,positive,positive,positive
1638954657,"LGTM!
Just for reference, here is a [nice collection of command inj payloads](https://github.com/payloadbox/command-injection-payload-list) that can be used for testing both on Unix & Windows systems if you want to implement any other tests in the future",reference nice collection command used testing want implement future,issue,negative,positive,positive,positive,positive,positive
1638429281,"Can we do a manual validation of spark_udf (mlflow 2.3.x model, use as spark_udf after installing this branch)? I'm really interested on seeing how the udf logic will handle the optional `params` component with this version difference. ",manual validation model use branch really interested seeing logic handle optional component version difference,issue,negative,positive,positive,positive,positive,positive
1638373797,@harupy now this should be ready for review! I also updated with the latest code on `master` :),ready review also latest code master,issue,negative,positive,positive,positive,positive,positive
1638281931,@harupy this whole should be removed ? I am a beginner so can u help me out ?,whole removed beginner help,issue,negative,positive,positive,positive,positive,positive
1637578526,"Thanks @ridhimag11! In this case, we just need to memorize the last next_page_token and use it on hitting ""Load more"", just like with experiment runs. @jmahlik do you think you want to tackle this one? ",thanks case need memorize last use load like experiment think want tackle one,issue,positive,positive,neutral,neutral,positive,positive
1637448432,"I have used joblib.dump() and the corresponding joblib.load() on Windows and on different Linux distributions. It has always worked fine for me.

Also the syntax is simple:
- To pickle and compress an object, joblib.dump(value = my_object, filename = ""my_filename.zip"", compress =9) will give the highest compression.
- To load it later: my_object = joblib.load(""my_filename.zip"").

There is some information about pickling/unpickling in joblib here:
[https://joblib.readthedocs.io/en/latest/persistence.html#persistence](url)

From what I see there the safety regarding pickling/unpickling is the same as when using regular pickle or cloudpickle. A quote from the link above:
![image](https://github.com/mlflow/mlflow/assets/79205362/18e32995-6a3d-4ff5-ab41-c5c387cb0907)


 ",used corresponding different always worked fine also syntax simple pickle compress object value compress give highest compression load later information see safety regarding regular pickle quote link image,issue,positive,positive,neutral,neutral,positive,positive
1637319208,@harupy @WeichenXu123 could you help check if this FR is needed? Or is there other workaround to log customized tags to runs created by autolog? Thanks.,could help check log thanks,issue,positive,positive,positive,positive,positive,positive
1636980011,"Maybe this should be it's own issue but it seems like the Authentication header is first correctly written as you describe, but then it is not sent to the request.Session which instead of using it generates authentication based on netrc (not sure what that is but seems like a file).

- I apply the environment variables as you describe and run a function
- Printing out the headers in the library, I see the Authentication header is set
- The ""auth"" parameter is not sent to the Session.request function and so it does not use the Header we made

This bug could be resolved by adding a line here:
https://github.com/mlflow/mlflow/blob/master/mlflow/utils/rest_utils.py#L89
Such as:
`else: kwargs[""auth""] = (host_creds.username, host_creds.password)`

Would this be a good addition? Or is this still working for other people?",maybe issue like authentication header first correctly written describe sent instead authentication based sure like file apply environment describe run function printing library see authentication header set parameter sent function use header made bug could resolved line else would good addition still working people,issue,positive,positive,positive,positive,positive,positive
1636903022,"Hi @harupy!
I edited following files and planning to make PR for each two files:
PR#1:
`tests/projects/test_projects.py`
`tests/server/test_prometheus_exporter.py`

PR#2:
`tests/projects/test_docker_projects.py`
`tests/recipes/test_split_step.py`

PR#3:
`tests/projects/backend/test_local.py`
`tests/store/artifact/test_s3_artifact_repo.py`

Thank you
",hi following make two thank,issue,negative,neutral,neutral,neutral,neutral,neutral
1636831493,"ping @harupy @WeichenXu123 

Anything I need to do before the next run can be approved?",ping anything need next run,issue,negative,neutral,neutral,neutral,neutral,neutral
1636813041,"Hi,

Since it's been a while since the issue was reported, I thought I'd try to make the changes that might be needed. This is based off looking at the documentation for creating Sagemaker serverless endpoints. Any feedback would be much appreciated.

EDIT: closed the original PR since I had accidentally pushed it to the master on my fork.",hi since since issue thought try make might based looking documentation feedback would much edit closed original since accidentally master fork,issue,negative,positive,positive,positive,positive,positive
1636806410,"@harupy Thanks! Ready to merge, needs someone with write access.",thanks ready merge need someone write access,issue,positive,positive,positive,positive,positive,positive
1636640671,"@barrywhart thanks for sharing your code, it is useful for us. I'll let you know of any progress :)",thanks code useful u let know progress,issue,positive,positive,positive,positive,positive,positive
1636639491,"> @dbczumar Looks like the autoformat doesn't seems to support running `blacken-docs` yet. You can run `blacken-docs docs/source/gateway/index.rst` instead.

Done! :)",like support running yet run instead done,issue,positive,neutral,neutral,neutral,neutral,neutral
1636639489,"> @gabrielfu I'll merge this. Let me know if you find any issues/suggestions :)

@harupy no problem, LGTM!",merge let know find problem,issue,negative,neutral,neutral,neutral,neutral,neutral
1636638047,@dbczumar Looks like the autoformat doesn't seems to support running `blacken-docs` yet. You can run `blacken-docs docs/source/gateway/index.rst` instead.,like support running yet run instead,issue,positive,neutral,neutral,neutral,neutral,neutral
1636631967,Hi @ChitraNairInfosys Could you share the code to reproduce your problem? A setup about your environment could be useful as well. Thanks :),hi could share code reproduce problem setup environment could useful well thanks,issue,positive,positive,positive,positive,positive,positive
1636631420,"@mathiasottenbreit Could you provide a valid proof that using `joblib.dump` is safe for saving/loading under different environment and cases? Or if you have any other ideas, a prototype would be useful :)",could provide valid proof safe different environment prototype would useful,issue,positive,positive,positive,positive,positive,positive
1636630843,"Hi @DJSaunders1997, could you try passing the content of your cluster-spec.json as a string directly in cli to --backend-config to see if it works? The error message shows this parameter is not correctly loaded.",hi could try passing content string directly see work error message parameter correctly loaded,issue,negative,positive,neutral,neutral,positive,positive
1636582678,@WeichenXu123 any comment to add? Do you think I can prepare a PR for this?,comment add think prepare,issue,negative,neutral,neutral,neutral,neutral,neutral
1636532465,"Gotcha! Thanks @hubertzub-db and @jmahlik. @hubertzub-db from a UI standpoint, neither of the approaches are ideal here since we'd want the ability for users to go to a specific page in the list (e.g. if they want to see the oldest experiments). That being said, I'm thinking that for consistency purposes on this page (with runs list), we could go with the ""load more"" pattern here.",thanks standpoint neither ideal since want ability go specific page list want see said thinking consistency page list could go load pattern,issue,negative,positive,positive,positive,positive,positive
1636490080,I cannot reproduce the error in `ci/circleci: build_doc` locally. I executed `make rsthtml` under `mlflow/docs` and the build finished with no error.,reproduce error locally executed make build finished error,issue,negative,neutral,neutral,neutral,neutral,neutral
1635923004,"Thanks, @harupy! I hope we can adopt this soon after it is released.",thanks hope adopt soon,issue,positive,positive,positive,positive,positive,positive
1635889274,odd that the teardown failed on the fluent test fixture,odd teardown fluent test fixture,issue,negative,negative,negative,negative,negative,negative
1635845807,"Thanks for taking a look @ridhimag11 :). 

I'll add a bit more detail. The main thing left to solve for is on loading the home page, [all experiments in the experiment table are fetched](https://github.com/mlflow/mlflow/blob/203afbab11f47733476275f1462b33c6ebf8991d/mlflow/server/js/src/experiment-tracking/components/HomePage.tsx#L40-L45) and put in the redux store. This gets slow when it's a large payload.

The rest of the components expect the experiments to exist in the store (like a local copy of the database table). If all experiments don't exist in the redux store, the other components break Ex. only experiment 0-25 are fetched on load and in the redux store (so in your example page 1), then  navigating directly to the link for experiment 5000 404's.

I'm pretty indifferent to how to pagination in the UI actually happens, but think we might run in to the same ordering issues regardless of the pagination style when everything isn't loaded at once.",thanks taking look add bit detail main thing left solve loading home page experiment table fetched put redux store slow large rest expect exist store like local copy table exist redux store break ex experiment fetched load redux store example page directly link experiment pretty indifferent pagination actually think might run regardless pagination style everything loaded,issue,positive,positive,neutral,neutral,positive,positive
1635725313,"Unrelated note (potentially for a good first issue) is that the `Dataset` and `InputTag` class constructor type signatures are wrong (not an issue as type checking is not performed, but those classes are not being passed `str` type in these definitions; they're being passed `sqlalchemy.sql.schema.Column` types)",unrelated note potentially good first issue class constructor type wrong issue type class type,issue,negative,positive,positive,positive,positive,positive
1635705774,@gabrielfu I'll merge this. Let me know if you find any issues/suggestions :),merge let know find,issue,negative,neutral,neutral,neutral,neutral,neutral
1635409011,"@ridhimag11 thanks! the issue here is that the search experiments API uses cursor-based page tokens, meaning we can get the next/previous page but we don't have an indicator of how many pages/results are there. That being said, I believe we have to either
- use ""Next page"" / ""Prev page"" (just like in model list page)

or alternatively
- use ""Load more"" pattern like in experiment runs page

what's the better approach here?",thanks issue search page meaning get page indicator many said believe either use next page page like model list page alternatively use load pattern like experiment page better approach,issue,positive,positive,positive,positive,positive,positive
1635024356,"Hi @jmahlik - I'm a UX designer and looking into this. Wondering if a simple pagination control here could help solve this issue?

![CleanShot 2023-07-13 at 15 44 14@2x](https://github.com/mlflow/mlflow/assets/107518592/56587e69-3015-4d74-8425-1c0ca4dd77e4)

We can perhaps have upto, lets say 100 runs show up per page, so users don't have to keep switching between pages and can still browse through their list of experiments. Thoughts? CC @hubertzub-db 
",hi designer looking wondering simple pagination control could help solve issue perhaps say show per page keep switching still browse list,issue,positive,neutral,neutral,neutral,neutral,neutral
1634573254,"> @hmoon-drizly Thanks for reporting the error, how can we reproduce the error?

@harupy sorry for the late reply - this is part of our internal project so I can't really add my code here. However, we have a job that didn't have this problem prior to 2.3.1. It is breaking when calling 
```
mlflow.pyfunc.log_model(
    artifact_path=model_name,
    python_model=lints_policy_object,
)
```
Here, `lints_policy_object` is
```
from collections import namedtuple
ReturnClass = namedtuple(""foo"", ""bar, baz"")

class LinTSPolicy(mlflow.pyfunc.PythonModel):
    def predict(self, cluster_probabilites: np.array) -> List[ReturnClass]:
        ...
```
",thanks error reproduce error sorry late reply part internal project ca really add code however job problem prior breaking calling import foo bar class predict self list,issue,negative,negative,neutral,neutral,negative,negative
1634484997,"Will not merge this PR to master, the failing test will be fixed automatically due to the revert PR: https://github.com/mlflow/mlflow/pull/9059",merge master failing test fixed automatically due revert,issue,negative,negative,neutral,neutral,negative,negative
1634455110,"Ah ok! FYI in this PR I added for now only the Ruff codes that have automatic fixes.

Should I leave it like this then?",ah added ruff automatic leave like,issue,negative,neutral,neutral,neutral,neutral,neutral
1634382735,"In effort to nail down what the culprit here is, could you try starting a debug instance of the tracking server configuration directly on a VM (not using Kuberenetes or a VPN) and see if the server configuration that you're using is exhibiting the same issue? 
",effort nail culprit could try starting instance server configuration directly see server configuration issue,issue,negative,positive,neutral,neutral,positive,positive
1634206027,"Yes, group-based access control with group-level defaults will satisfy our use case. We don't have a current need for ""deny"" rules.

Thanks so much for doing this! Let me know if I can help.

Here's the script that initializes the authorization database and implements groups. (Groups are expanded one time, outside the database.)

```
""""""
This script needs to run prior to server startup. It initializes the MLflow
authorization database (a local SQLite database) with users and permissions.

It uses the current gcloud user (per ""gcloud config set account"" or
the GOOGLE_APPLICATION_CREDENTIALS environment variable) ) to query
group membership using the Google Cloud Identity API
(https://cloud.google.com/identity/docs/reference/rest).

It should be run with the MLFLOW_AUTH_CONFIG_PATH environment variable set to
the path of the authorization config file. For example, for local testing:

    GOOGLE_APPLICATION_CREDENTIALS=~/.config/gcloud/mysa.json MLFLOW_AUTH_CONFIG_PATH=tests/mlflow_auth_config.ini python -m mlflow_app.init_auth sqlite:////tmp/mlflow.db production --verbose
""""""
import argparse
import importlib
import logging
import os
import stat
import tempfile
import urllib.parse
from typing import List

from googleapiclient.discovery import build
from mlflow.server.auth.config import read_auth_config
from mlflow.server.auth.sqlalchemy_store import SqlAlchemyStore
from mlflow.server.auth import auth_config_path
from mlflow.tracking._tracking_service.utils import _tracking_store_registry
from sqlalchemy.engine.url import make_url

_logger = logging.getLogger(__name__)


service = None
auth_config_module = None


def get_group_members(group_email: str) -> List[str]:
    """"""Returns the list of members of the given group email.""""""
    # Lookup the group id using the group email.
    group_request = service.groups().lookup(groupKey_id=group_email)
    group_response = group_request.execute()

    # Use the group id to get the list of members.
    memberships_request = (
        service.groups().memberships().list(parent=group_response[""name""])
    )
    memberships_response = memberships_request.execute()
    members = []
    for member in memberships_response.get(""memberships"", []):
        email = member[""preferredMemberKey""][""id""]
        # Skip service accounts
        if not email.endswith("".gserviceaccount.com""):
            members.append(email)
    return sorted(members)


def create_users_if_not_exists(user: str, is_admin: bool, all_users: List[str]):
    """"""Creates the given user if it doesn't already exist.

    The user may be a group, in which case all members of the group are added.
    The user(s) are added to auth_store and all_users.
    """"""
    users = [user]
    if user in auth_config_module.GROUPS:
        group = auth_config_module.GROUPS[user]
        users = group[""members""]
        is_admin = group[""is_admin""]
    else:
        assert is_admin is not None, ""is_admin must be specified for non-group users""
    for user in users:
        if user not in all_users:
            all_users.append(user)
            # _logger.debug(f""Creating user #{len(all_users)}: {user}"")
            _logger.debug(f""Creating user #{len(all_users)}"")
            auth_store.create_user(user, """", is_admin=is_admin)
        else:
            _logger.debug(f""User #{all_users.index(user) + 1} already exists"")
            # _logger.debug(f""User {user} already exists"")


# Create SQLite database
auth_store = SqlAlchemyStore()
auth_config = read_auth_config(auth_config_path)
auth_store.init_db(auth_config.database_uri)


def main(verbose: bool = False):
    _logger.info(""Looking up group membership using cloud identity API"")
    for group_idx, (group, group_info) in enumerate(auth_config_module.GROUPS.items()):
        if group_info[""members""] is None:  # pragma: no cover
            group_info[""members""] = get_group_members(group)
            _logger.info(
                f""Group #{group_idx+1} has {len(group_info['members'])} members""
            )

    all_users = []
    _logger.info(""Creating group users in auth db"")
    for group_idx, group in enumerate(auth_config_module.GROUPS):
        _logger.info(f""Populating group #{group_idx+1}"")
        create_users_if_not_exists(
            group, auth_config_module.GROUPS[group][""is_admin""], all_users
        )
    _logger.info(""Creating other users in auth db"")
    for user_idx, (user, is_admin) in enumerate(auth_config_module.USERS):
        create_users_if_not_exists(user, is_admin, all_users)

    _logger.info(""Creating experiment permissions in auth db"")
    records = []
    for experiment_name, users_for_experiment, permission in auth_config_module.EXPERIMENT_PERMISSIONS:
        expanded_users_for_experiment = []
        for user in users_for_experiment:
            users = [user]
            if user in auth_config_module.GROUPS:
                users = auth_config_module.GROUPS[user][""members""]
            expanded_users_for_experiment.extend(users)
        for user in expanded_users_for_experiment:
            # TRICKY: This script lets you configure experiment access by
            # experiment *NAME*. However, the underlying mlflow.server.auth
            # module uses EXPERIMENT ID. So, we need to map the experiment name
            # to the experiment ID. That's why we have to build the
            # authorization database at server startup time, because the same
            # server Docker image is used for all environments, and the
            # experiment IDs are different in each environment.
            experiment = tracking_store.get_experiment_by_name(experiment_name)
            experiment_id = None
            if experiment is not None:
                experiment_id = experiment.experiment_id
            else:
                # Create the experiment if it doesn't exist. This avoids a
                # security hole where authorization is not enforced for
                # experiments that didn't exist at server startup time but are
                # created later.
                _logger.info(
                    f""WARNING: Experiment {experiment_name} does not exist. Creating...""
                )
                try:
                    experiment_id = tracking_store.create_experiment(
                        experiment_name
                    )
                except Exception as e:  # pragma: no cover
                    # Ignore errors. This should hopefully avoid any scenarios where
                    # the server doesn't start up because we can't create an
                    # experiment.
                    _logger.exception(
                        f""Failed to create experiment {experiment_name}: {e}""
                    )
            if experiment_id is not None:
                auth_store.create_experiment_permission(
                    experiment_id, user, permission.name
                )
                records.append((experiment_name, permission.name, user))

    if verbose:
        print(""Created the following experiment permissions:"")
        for experiment_name, permission, user in sorted(records):
           print(f""  {experiment_name} {permission} {user}"")


if __name__ == ""__main__"":  # pragma: no cover
    parser = argparse.ArgumentParser(description=""Initialize authentication database"")
    parser.add_argument(""dburi"", help=""URI of the authentication database"")
    parser.add_argument(""auth_config"", help=""Authorization config module name (under mlflow_app.auth_config)"")
    parser.add_argument(""-v"", ""--verbose"", action=""store_true"", help=""Enable verbose logging"")
    args = parser.parse_args()

    logging.basicConfig(level=logging.INFO)
    _logger.info(""Entering init_auth.py"")

    # We need to pass an artifact URI to get_store(), otherwise it'll use the
    # default behavior, which tries to write to the current directory. That
    # is illegal in some environments such as App Engine, where the current
    # directory is read only. So, we specify something in the system temporary
    # directory, e.g. ""file:///tmp/mlruns"". Note that we address a very similar
    # issue with mlflow.server.auth in mlflow_app/__init__.py. There, we're
    # monkeypatching around a bug in ""stock"" MLflow. Having two different
    # solutions is not ideal, but it's the best we can do for now.
    mlflow_artifact_uri = (
        f""file://{os.path.join(tempfile.gettempdir(), 'mlruns')}""
        if ""ARTIFACT_URI"" not in os.environ
        else os.environ[""ARTIFACT_URI""]
    )
    tracking_store = _tracking_store_registry.get_store(
        args.dburi, mlflow_artifact_uri
    )

    # Build the cloudidentity service
    service = build(""cloudidentity"", ""v1"")
    auth_config_module = importlib.import_module(
        f""mlflow_app.auth_config.{args.auth_config}""
    )
    main(args.verbose)
    _logger.info(""Exiting init_auth.py"")
```

The script gets the list of groups and other authorization configuration from this module:
```
from mlflow.server.auth.permissions import READ, EDIT, MANAGE, NO_PERMISSIONS

# Individual humans or service accounts. (Any _groups_ should be defined in
# GROUPS instead).
USERS = [
    # Service accounts
    (""sa-mlops@nowhere.iam.gserviceaccount.com"", True),
    # This account is not used, but mlflow.server.auth requires it to exist.
    (""admin"", True),
]

# If ""members"" is None, then the group is assumed to be a Google group and
# the members are looked up dynamically. Otherwise, ""members"" is assumed to
# be a list of email addresses. This could be useful for testing or for
# groups that are not Google groups.
GROUPS = {
    # NOTE: The members of gcp-mlops@zoro.com are also in this group.
    ""gcp-data-science@nowhere.com"": {
        ""members"": None,
        # NOTE: Perhaps it's not ideal to make all data scientists admins, but
        # mlflow.server.auth implements an additive, experiment-level permission
        # model. Thus, we either need to make all data scientists admins or
        # manually grant them permissions to each experiment. Given that:
        # 1. Experiments number in the dozens.
        # 2. The permission database is populated at server startup time and not
        #    updated afterwards.
        # 3. More experiments are added regularly (after server startup).
        # We choose to make all data scientists admins.
        #
        # Possible enhancement: Enhance the MLflow authentication model to
        # support a default permission level per group, rather than a single
        # global default permission level in the .ini file
        # MLFLOW_AUTH_CONFIG_PATH.
        ""is_admin"": True,
    },
    ""gcp-search-team@nowhere.com"": {
        ""members"": None,
        ""is_admin"": False,
    },
}

SEARCH_USERS = [
    ""gcp-search-team@nowhere.com"",
    ""sa-search@nowhere.iam.gserviceaccount.com""
]

EXPERIMENT_PERMISSIONS = [
    # Edit access (read + write) to: ds-cc-evaluator/evaluator-test-run
    (""ds-cc-evaluator/evaluator-test-run"", SEARCH_USERS, EDIT),
    # Read access to the following: ds-cc-search-models
    (""ds-cc-search-models"", SEARCH_USERS, READ),
]
```",yes access control satisfy use case current need deny thanks much let know help script authorization expanded one time outside script need run prior server authorization local current user per set account environment variable query group membership cloud identity run environment variable set path authorization file example local testing python production verbose import import import logging import o import import import import list import build import import import import import service none none list list given group group id group use group id get list name member member id skip service return sorted user bool list given user already exist user may group case group added user added user user group user group group else assert none must user user user user user user user else user user already user user already create main verbose bool false looking group membership cloud identity group enumerate none cover group group group group enumerate group group group user enumerate user experiment permission user user user user user tricky script configure experiment access experiment name however underlying module experiment id need map experiment name experiment id build authorization server time server docker image used experiment different environment experiment none experiment none else create experiment exist security hole authorization enforced exist server time later warning experiment exist try except exception cover ignore hopefully avoid server start ca create experiment create experiment none user user verbose print following experiment permission user sorted print permission user cover parser initialize authentication authentication authorization module name verbose enable verbose logging entering need pas artifact otherwise use default behavior write current directory illegal engine current directory read specify something system temporary directory file note address similar issue around bug stock two different ideal best file else build service service build main script list authorization configuration module import read edit manage individual service defined instead service true account used exist true none group assumed group dynamically otherwise assumed list could useful testing note also group none note perhaps ideal make data additive permission model thus either need make data manually grant experiment given number permission server time afterwards added regularly server choose make data possible enhancement enhance authentication model support default permission level per group rather single global default permission level file true none false edit access read write edit read access following read,issue,positive,positive,positive,positive,positive,positive
1633975779,"Hi @serena-ruan, I tried changing the chunk size to `2**20` and got the same error",hi tried chunk size got error,issue,negative,neutral,neutral,neutral,neutral,neutral
1633884746,"> Looks like transformers needs a fix:
> 
> https://github.com/mlflow/mlflow/actions/runs/5539216986/jobs/10112246903?pr=9059
> 
> ```
> FAILED tests/transformers/test_transformers_model_export.py::test_text_generation_pipeline_with_params - TypeError: infer_signature() takes from 1 to 2 positional arguments but 3 were given
> ```

Yes this test needs to be deleted. I'm running some tests locally to make sure they work fine, as lots of transformers tests are skipped in github actions.",like need fix positional given yes test need running locally make sure work fine lot,issue,positive,positive,positive,positive,positive,positive
1633882073,"Looks like transformers needs a fix:

https://github.com/mlflow/mlflow/actions/runs/5539216986/jobs/10112246903?pr=9059

```
FAILED tests/transformers/test_transformers_model_export.py::test_text_generation_pipeline_with_params - TypeError: infer_signature() takes from 1 to 2 positional arguments but 3 were given
```",like need fix positional given,issue,negative,neutral,neutral,neutral,neutral,neutral
1633828525,"I think this feature is very helpful, for example, I will choose the best model and move to a specific experiment to keep in a long time. In my situation, I try so many models and there are many waste models, but I just want to keep some best models",think feature helpful example choose best model move specific experiment keep long time situation try many many waste want keep best,issue,positive,positive,positive,positive,positive,positive
1633824625,+1 for moving a run from one experiment to another!,moving run one experiment another,issue,negative,neutral,neutral,neutral,neutral,neutral
1633516630,@adeadfed Hey could you pls review this PR as well? Wanted to see if I covered the issues you reported 😄 Thanks!,hey could review well see covered thanks,issue,positive,positive,positive,positive,positive,positive
1633512756,"> If we've already checked in code with a similar problem on Databricks, can we revert it for now? I want to make sure we aren't introducing serious regressions here

This is so strange.. I added unit test for python model https://github.com/mlflow/mlflow/pull/8976/commits/38e1c1511fb2a76e0ad79fcdf4b762dfe4ec6df8#diff-592813f9fb198dda0982794f2221a408f316709190b3bf02c0e77eb2c1107075, I also manually tested your approach locally, but mine works fine 🤔 
```
mlflow models serve -m runs:/3f87fdff03524c19908c3a47fb99f9cd/test_model --env-manager local
```
<img width=""450"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/82044803/f92668f8-0b76-4e9f-9b83-d1ba628ee97d"">

And my MLmodel file looks like this:
```
artifact_path: test_model
flavors:
  python_function:
    cloudpickle_version: 2.2.1
    env:
      conda: conda.yaml
      virtualenv: python_env.yaml
    loader_module: mlflow.pyfunc.model
    python_model: python_model.pkl
    python_version: 3.8.16
mlflow_version: 2.4.0
model_uuid: 3cbde93be0114644a6ec900c64cab39d
run_id: 3f87fdff03524c19908c3a47fb99f9cd
signature:
  inputs: '[{""type"": ""string""}]'
  outputs: null
utc_time_created: '2023-07-13 01:29:55.467561'
```

So I'm wondering how could I reproduce your error 🤔 ",already checked code similar problem revert want make sure serious strange added unit test python model also manually tested approach locally mine work fine serve local image file like signature type string null wondering could reproduce error,issue,negative,positive,neutral,neutral,positive,positive
1633491562,Hi @jmmonteiro Feel free to raise a PR for highlighting this! Thank you!,hi feel free raise thank,issue,positive,positive,positive,positive,positive,positive
1633442192,"@barrywhart in case of multiple groups, the most permissive one will prevail, as it is an act of granting access instead of restricting. 

Regarding ""deny"" rules, we might have to see whether this is a heavily requested feature from a lot of users. An ""allow only"" permission model is pretty common and should be able to handle most use cases.

Will GBAC satisfy your use case? If yes, I can work on this feature

Also, feel free to share your group implementation for our reference :)",case multiple permissive one prevail act access instead regarding deny might see whether heavily feature lot allow permission model pretty common able handle use satisfy use case yes work feature also feel free share group implementation reference,issue,positive,positive,positive,positive,positive,positive
1633424170,Just a few quality of life comments due to the nightmares I had trying to do that schema migration 18 months ago. :) ,quality life due trying schema migration ago,issue,negative,negative,negative,negative,negative,negative
1633334727,"> Does `shap.Explainer` reject the wrapper instance?

I think so. I added an Exception here:
<img width=""1138"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/82044803/11e3b5c2-2756-4085-a61c-7f4669bd959c"">

It returns directly, so these three images are not logged. ",reject wrapper instance think added exception image directly three logged,issue,negative,positive,neutral,neutral,positive,positive
1633326856,"@EdAbati Great! You can enable the rules that require any fixes in a single PR, but for ones that require fixes, let's do one for each rule. ",great enable require single require let one rule,issue,positive,positive,positive,positive,positive,positive
1633311824,sentencepiece has dependency conflicts with our version of proto and I'm not about to start messing with a fix for that since the version that is compatible with our proto is old and is flaky for other reasons. I'm just swapping the 2 tests to use a different pipeline type.,dependency version proto start messing fix since version compatible proto old flaky swapping use different pipeline type,issue,negative,positive,neutral,neutral,positive,positive
1633093199,"@ichbinjakes It looks like there are just a couple of small merge conflicts.  The PR posted by @snooyen is a bit out dated at this point, but the changes are easy to make.  Rebasing on mlflow/master, it looks like the `.gitignore` and `requirements/test-requirements.txt` have new additions on master that are  conflicting with your additions.  To resolve it, you just need to add the lines from both sides to the files.",like couple small merge posted bit point easy make like new master conflicting resolve need add side,issue,positive,positive,positive,positive,positive,positive
1632984555,Any updates on getting a UX designer involved? Fetching around 5000 experiments seems to be a tipping point since the payload is pretty large. Depending on network latency/the pc the ui runs on for the js parsing the response body.,getting designer involved fetching around tipping point since pretty large depending network response body,issue,negative,positive,positive,positive,positive,positive
1632877087,"> > Well, judging by the test output, pathlib now works fine. All failed test cases under the `test_validate_path_is_safe_windows_good` are false positives and will be indeed treated by Python as absolute paths, so they should better be moved to the `test_validate_path_is_safe_windows_bad` list of paths. However, there is indeed a problem with `'..' in path` check because it is now split by `os.sep == \`, not by `posixpath.sep == /`. Is it worth to revert this change? Also, do these tests also run on a linux box? It would probably be good to check if nothing has been broken there as well.
> 
> Since we don't allow '\' in the path, maybe we just explicitly say `.split('/')` instead of `.split(os.sep)`? This test is only run on windows because the same path might be disallowed on windows but allowed on linux right? `test_validate_path_is_safe_bad` only runs on linux, with paths:
> 
> ```
> ""/path"",
>         ""../path"",
>         ""../../path"",
>         ""./../path"",
>         ""path/../to/file"",
>         ""path/../../to/file"",
>         ""/etc/passwd"",
>         ""/etc/passwd%00.jpg"",
>         ""/etc/passwd%00.html"",
>         ""/etc/passwd%00.txt"",
>         ""/etc/passwd%00.php"",
>         ""/etc/passwd%00.asp"",
> ```

`.split('/')` should work fine! Thanks for the clarification regarding the test cases, I guess they should be sufficient :) 
",well test output work fine test false indeed python absolute better list however indeed problem path check split worth revert change also also run box would probably good check nothing broken well since allow path maybe explicitly say instead test run path might right work fine thanks clarification regarding test guess sufficient,issue,positive,positive,positive,positive,positive,positive
1632737176,"@harupy https://github.com/mlflow/mlflow/blob/797cdf5cbbd238338b61f008b9308b246a5f4d4f/mlflow/models/evaluation/default_evaluator.py#L722-L732 I think this part depends on raw_model to be a sklearn model instead of the wrapper? If we return the wrapper, `evaluate` doesn't log those images. Should we return .sklearn_model or update the logic in default_evaluator to be compatible with the wrapper instead?",think part model instead wrapper return wrapper evaluate log return update logic compatible wrapper instead,issue,negative,neutral,neutral,neutral,neutral,neutral
1632643981,"> Well, judging by the test output, pathlib now works fine. All failed test cases under the `test_validate_path_is_safe_windows_good` are false positives and will be indeed treated by Python as absolute paths, so they should better be moved to the `test_validate_path_is_safe_windows_bad` list of paths. However, there is indeed a problem with `'..' in path` check because it is now split by `os.sep == \`, not by `posixpath.sep == /`. Is it worth to revert this change? Also, do these tests also run on a linux box? It would probably be good to check if nothing has been broken there as well.

Since we don't allow '\\' in the path, maybe we just explicitly say `.split('/')`  instead of `.split(os.sep)`? This test is only run on windows because the same path might be disallowed on windows but allowed on linux right? `test_validate_path_is_safe_bad` only runs on linux, with paths:
```
""/path"",
        ""../path"",
        ""../../path"",
        ""./../path"",
        ""path/../to/file"",
        ""path/../../to/file"",
        ""/etc/passwd"",
        ""/etc/passwd%00.jpg"",
        ""/etc/passwd%00.html"",
        ""/etc/passwd%00.txt"",
        ""/etc/passwd%00.php"",
        ""/etc/passwd%00.asp"",
```",well test output work fine test false indeed python absolute better list however indeed problem path check split worth revert change also also run box would probably good check nothing broken well since allow path maybe explicitly say instead test run path might right,issue,positive,positive,positive,positive,positive,positive
1632622861,"Hi, would it be possible to add the option to display by epochs instead of steps? I want to compare models with varying batch sizes and the step option does not allow to do that well.",hi would possible add option display instead want compare batch size step option allow well,issue,positive,neutral,neutral,neutral,neutral,neutral
1632523520,"@EdAbati Thanks for the PR!

> I have enabled the rules one by one in each commit.

Sorry, I wasn't clear. What I meant was enable the rules one-PR by one-PR. More code = More review cost = Higher chances to miss something. For example, a PR to only enable PT001 is easier to review and has lower chances to miss invalid changes than this PR.",thanks one one commit sorry clear meant enable code review cost higher miss something example enable easier review lower miss invalid,issue,positive,positive,neutral,neutral,positive,positive
1632490857,"Well, judging by the test output, pathlib now works fine. All failed test cases under the `test_validate_path_is_safe_windows_good` are false positives and will be indeed treated by Python as absolute paths, so they should better be moved to the `test_validate_path_is_safe_windows_bad` list of paths. However, there is indeed a problem with `'..' in path` check because it is now split by `os.sep == \`, not by `posixpath.sep == /`. Is it worth to revert this change? Also, do these tests also run on a linux box? It would probably be good to check if nothing has been broken there as well.",well test output work fine test false indeed python absolute better list however indeed problem path check split worth revert change also also run box would probably good check nothing broken well,issue,positive,positive,positive,positive,positive,positive
1632189471,"> > > > Tests on windows machine: Good paths: <img alt=""image"" width=""1064"" src=""https://user-images.githubusercontent.com/82044803/252841829-cf52ce90-f5f4-4e83-aa8f-c53cee745781.png"">
> > > 
> > > 
> > > Hey @serena-ruan ! Was just passing by this pull request. It seems that the issue is a little bit complicated for Windows. `pathlib.Path` will default to a WindowsPath constructor even if called with a POSIX path on Windows, e.g. `pathlib.Path('/some/posix/path') --> WindowsPath('/some/posix/path') --> WindowsPath('/some/posix/path').is_absolute() == False`
> > > While this might look okay for sole purpose of windows path validation, Python still supports POSIX paths on Windows, so we still have a directory traversal:
> > > ```
> > > >>> import pathlib
> > > >>> pathlib.Path('/test').is_absolute()
> > > False
> > > >>> pathlib.Path('/').is_absolute()
> > > False
> > > >>> pathlib.Path('/Windows/System32/drivers/etc/hosts').is_absolute()
> > > False
> > > >>> open('/Windows/System32/drivers/etc/hosts', 'r').readlines()
> > > ['ï»¿# Copyright (c) 1993-2009 Microsoft Corp.\n', ... , '# End of section\n']
> > > ```
> > 
> > 
> > Hi @adeadfed, thanks so much for this helpful information! Since you're an expert on this, would you be willing to add some test cases in your mind to the test suites so that we could better validate our approach? 😃
> 
> At quick glance, the list of paths in your tests is exhaustive imo. The inconsistent behavior of pathlib should be resolved like this:
> 
> ```
> def validate_path_is_safe(path):
>     """"""
>     Validates that the specified path is safe to join with a trusted prefix. This is a security
>     measure to prevent path traversal attacks.
>     """"""
>     if is_file_uri(path):
>         path = local_file_uri_to_path(path)
>     if (
>         any((s in path) for s in _OS_ALT_SEPS)
>         or "".."" in path.split(os.sep)
>         or pathlib.PureWindowsPath(path).is_absolute()
>         or pathlib.PurePosixPath(path).is_absolute()
>     ):
>         raise MlflowException(f""Invalid path: {path}"", error_code=INVALID_PARAMETER_VALUE)
> ```
> 
> Though I am wondering if `or "".."" in path.split(os.sep)` check can be bypassed now or not. I guess we should see that from the output of the tests :) Hope that helps!

Thanks! Updated and let's see how the tests run :)",machine good image hey passing pull request issue little bit complicated default constructor even path false might look sole purpose path validation python still still directory traversal import false false false open copyright end hi thanks much helpful information since expert would willing add test mind test could better validate approach quick glance list exhaustive inconsistent behavior resolved like path path safe join prefix security measure prevent path traversal path path path path path path raise invalid path path though wondering check guess see output hope thanks let see run,issue,positive,positive,neutral,neutral,positive,positive
1632179182,"> > > Tests on windows machine: Good paths: <img alt=""image"" width=""1064"" src=""https://user-images.githubusercontent.com/82044803/252841829-cf52ce90-f5f4-4e83-aa8f-c53cee745781.png"">
> > 
> > 
> > Hey @serena-ruan ! Was just passing by this pull request. It seems that the issue is a little bit complicated for Windows. `pathlib.Path` will default to a WindowsPath constructor even if called with a POSIX path on Windows, e.g. `pathlib.Path('/some/posix/path') --> WindowsPath('/some/posix/path') --> WindowsPath('/some/posix/path').is_absolute() == False`
> > While this might look okay for sole purpose of windows path validation, Python still supports POSIX paths on Windows, so we still have a directory traversal:
> > ```
> > >>> import pathlib
> > >>> pathlib.Path('/test').is_absolute()
> > False
> > >>> pathlib.Path('/').is_absolute()
> > False
> > >>> pathlib.Path('/Windows/System32/drivers/etc/hosts').is_absolute()
> > False
> > >>> open('/Windows/System32/drivers/etc/hosts', 'r').readlines()
> > ['ï»¿# Copyright (c) 1993-2009 Microsoft Corp.\n', ... , '# End of section\n']
> > ```
> 
> Hi @adeadfed, thanks so much for this helpful information! Since you're an expert on this, would you be willing to add some test cases in your mind to the test suites so that we could better validate our approach? 😃

At quick glance, the list of paths in your tests is exhaustive imo. The inconsistent behavior of pathlib should be resolved like this:

```
def validate_path_is_safe(path):
    """"""
    Validates that the specified path is safe to join with a trusted prefix. This is a security
    measure to prevent path traversal attacks.
    """"""
    if is_file_uri(path):
        path = local_file_uri_to_path(path)
    if (
        any((s in path) for s in _OS_ALT_SEPS)
        or "".."" in path.split(os.sep)
        or pathlib.PureWindowsPath(path).is_absolute()
        or pathlib.PurePosixPath(path).is_absolute()
    ):
        raise MlflowException(f""Invalid path: {path}"", error_code=INVALID_PARAMETER_VALUE)
```

Though I am wondering if `or "".."" in path.split(os.sep)` check can be bypassed now or not. I guess we should see that from the output of the tests :) Hope that helps!",machine good image hey passing pull request issue little bit complicated default constructor even path false might look sole purpose path validation python still still directory traversal import false false false open copyright end hi thanks much helpful information since expert would willing add test mind test could better validate approach quick glance list exhaustive inconsistent behavior resolved like path path safe join prefix security measure prevent path traversal path path path path path path raise invalid path path though wondering check guess see output hope,issue,positive,positive,neutral,neutral,positive,positive
1632159437,"> > Tests on windows machine: Good paths: <img alt=""image"" width=""1064"" src=""https://user-images.githubusercontent.com/82044803/252841829-cf52ce90-f5f4-4e83-aa8f-c53cee745781.png"">
> 
> Hey @serena-ruan ! Was just passing by this pull request. It seems that the issue is a little bit complicated for Windows. `pathlib.Path` will default to a WindowsPath constructor even if called with a POSIX path on Windows, e.g. `pathlib.Path('/some/posix/path') --> WindowsPath('/some/posix/path') --> WindowsPath('/some/posix/path').is_absolute() == False`
> 
> While this might look okay for sole purpose of windows path validation, Python still supports POSIX paths on Windows, so we still have a directory traversal:
> 
> ```
> >>> import pathlib
> >>> pathlib.Path('/test').is_absolute()
> False
> >>> pathlib.Path('/').is_absolute()
> False
> >>> pathlib.Path('/Windows/System32/drivers/etc/hosts').is_absolute()
> False
> >>> open('/Windows/System32/drivers/etc/hosts', 'r').readlines()
> ['ï»¿# Copyright (c) 1993-2009 Microsoft Corp.\n', ... , '# End of section\n']
> ```

Hi @adeadfed, thanks so much for this helpful information! Since you're an expert on this, would you be willing to add some test cases or propose a solution that fix potential issues? Really appreciate it! 😃 ",machine good image hey passing pull request issue little bit complicated default constructor even path false might look sole purpose path validation python still still directory traversal import false false false open copyright end hi thanks much helpful information since expert would willing add test propose solution fix potential really appreciate,issue,positive,negative,neutral,neutral,negative,negative
1632044955,"> Tests on windows machine: Good paths: <img alt=""image"" width=""1064"" src=""https://user-images.githubusercontent.com/82044803/252841829-cf52ce90-f5f4-4e83-aa8f-c53cee745781.png"">

Hey @serena-ruan ! Was just passing by this pull request. It seems that the issue is a little bit complicated for Windows. `pathlib.Path` will default to a WindowsPath constructor even if called with a POSIX path on Windows, e.g. `pathlib.Path('/some/posix/path') --> WindowsPath('/some/posix/path') --> WindowsPath('/some/posix/path').is_absolute() == False`

While this might look okay for sole purpose of windows path validation, Python still supports POSIX paths on Windows, so we still have a directory traversal:

 ```
 >>> import pathlib
>>> pathlib.Path('/test').is_absolute()
False
>>> pathlib.Path('/').is_absolute()
False
>>> pathlib.Path('/Windows/System32/drivers/etc/hosts').is_absolute()
False
>>> open('/Windows/System32/drivers/etc/hosts', 'r').readlines()
['ï»¿# Copyright (c) 1993-2009 Microsoft Corp.\n', ... , '# End of section\n']
```
",machine good image hey passing pull request issue little bit complicated default constructor even path false might look sole purpose path validation python still still directory traversal import false false false open copyright end,issue,negative,negative,negative,negative,negative,negative
1631838578,@BenWilson2 @dbczumar The gateway check passed. I'll merge this PR for rebasing the gateway branch on master. We can address the remaining comments as a follow-up.,gateway check merge gateway branch master address,issue,negative,neutral,neutral,neutral,neutral,neutral
1631793957,"Before merge, let's rebase this branch on master to make sure Gateway doesn't break anything.",merge let rebase branch master make sure gateway break anything,issue,negative,positive,positive,positive,positive,positive
1631753663,I ran the affected suites multiple times locally with this change with deleting the cache directory between each one on 3 separate pip installs of transformers. I'm hoping that explicitly declaring the tokenizer type as T5 will make this issue go away.,ran affected multiple time locally change cache directory one separate pip explicitly type make issue go away,issue,negative,neutral,neutral,neutral,neutral,neutral
1631751133,@harupy sorry about that. I totally forgot to do that yesterday! Thanks for the reminder :) ,sorry totally forgot yesterday thanks reminder,issue,negative,negative,neutral,neutral,negative,negative
1631745749,@BenWilson2 Can you clean up unrelated commits? https://stackoverflow.com/questions/25356810/git-how-to-squash-all-commits-on-branch might help.,clean unrelated might help,issue,positive,positive,positive,positive,positive,positive
1631680986,@C-K-Loan We'll release 2.5 soon :) This version includes #8687. We forgot to include it in 2.4.*.,release soon version forgot include,issue,negative,neutral,neutral,neutral,neutral,neutral
1631452679,"> Looks good to me :)

@harupy Looks like some tests failing on python imports & something in the env setup for the `R/r` check blocking merging.

Don't think these are related to this PR?",good like failing python something setup check blocking think related,issue,negative,positive,positive,positive,positive,positive
1631127805,"I would like to express my support for this feature and strongly believe that it should be implemented in MLflow. TensorBoard already offers this functionality, and it would be highly beneficial for MLflow to incorporate it as well. Tracking the evolution of a model is crucial, particularly for image-based models, and having this capability would greatly enhance the overall usability and effectiveness of MLflow.",would like express support feature strongly believe already functionality would highly beneficial incorporate well evolution model crucial particularly capability would greatly enhance overall usability effectiveness,issue,positive,positive,positive,positive,positive,positive
1630728869,"> > I was getting this error when clicking on experiments while I had not correctly configured my blob storage. Once the configuration was corrected then error went away.
> 
> What did you change to get rid of this error?

I had to change the format of the environment variable : AZURE_STORAGE_CONNECTION_STRING
The previous incorrect format was preventing the application from connecting to the Azure Blob Storage.",getting error correctly blob storage configuration corrected error went away change get rid error change format environment variable previous incorrect format application azure blob storage,issue,negative,negative,negative,negative,negative,negative
1630621112,"> Uses http in browser instead of https works for me.
oh, seriously?",browser instead work oh seriously,issue,negative,negative,negative,negative,negative,negative
1630620198,"> I was getting this error when clicking on experiments while I had not correctly configured my blob storage. Once the configuration was corrected then error went away.

What did you change to get rid of this error?",getting error correctly blob storage configuration corrected error went away change get rid error,issue,negative,neutral,neutral,neutral,neutral,neutral
1630522912,I have a question after investigating a bit: it seems that passing the argument `--no-serve-artifacts` disables the artifact-related features. Maybe my FR is redundant with this? I could be wrong though :/ ,question investigating bit passing argument maybe redundant could wrong though,issue,negative,negative,negative,negative,negative,negative
1630256629,"Hi @harupy!
I researched a bit `a.py` and tried to run for the sake of interest (nothing changes), that is a great example of automation, will explore afterward.
So I have questions:
1) We shouldn't include in our eliminations double quoted str `with mock.patch.dict(""os.environ"", ...` cases only `os.environ`?  (example: [case](https://github.com/mlflow/mlflow/blob/8ed6dd8bd102b6b994e4375897b08a046684dd40/tests/projects/test_projects.py#L290C62-L290C62))
2) In cases where we have `with mock.patch.dict(os.environ, {}):` we use full set of os env variables without setting variable. Can we remove such lines? (example: [case](https://github.com/mlflow/mlflow/blob/8ed6dd8bd102b6b994e4375897b08a046684dd40/tests/store/db/test_utils.py#L66))
3) This [test](https://github.com/mlflow/mlflow/blob/8ed6dd8bd102b6b994e4375897b08a046684dd40/tests/server/test_prometheus_exporter.py#L12C26-L12C81)  yields nothing. `monkeypatch.setenv(os.environ, {""PROMETHEUS_MULTIPROC_DIR"": ""s""}) yield` returns `yield tests were removed in pytest 4.0` What should I do?
4) As for [pytest.MonkeyPatch.delenv](https://pytest.org/en/7.3.x/reference/reference.html#pytest.MonkeyPatch.delenv) can we think **clear=True** in `with mock.patch.dict(""os.environ"", mock_env, clear=True):` performs function to delete env variable?
Thank you",hi bit tried run sake interest nothing great example explore afterward include double example case use full set o without setting variable remove example case test nothing yield yield removed think function delete variable thank,issue,negative,positive,positive,positive,positive,positive
1630108974,"Hi @benfhicks , could you try increasing `os.environ['MLFLOW_GCS_UPLOAD_CHUNK_SIZE'] = f'{2**10}'` to a larger number say 1MB or 5MB, see if it helps?",hi could try increasing number say see,issue,negative,neutral,neutral,neutral,neutral,neutral
1629882466,"The langchain test works for <=0.0.227 and fails for 0.0.228+.

It seems that somehow during the initialization of mlflow's sqlalchemy mappers, it looks for a key (EmbeddingStore) defined in LangChain https://github.com/hwchase17/langchain/blob/master/langchain/vectorstores/pgvector.py.
Not sure whether it's a bug in mlflow or LangChain.

Seems to be related to this PR https://github.com/hwchase17/langchain/pull/7370.

This failure is a separate problem, let's address it in another PR.",test work somehow key defined sure whether bug related failure separate problem let address another,issue,negative,positive,neutral,neutral,positive,positive
1629161136,"+1 for this feature, can't log parameters such as selected features from a feature selection step due to the small maximum param size",feature ca log selected feature selection step due small maximum param size,issue,negative,negative,negative,negative,negative,negative
1629010587,I'll merge this PR. This rule is important to prevent unused arguments.,merge rule important prevent unused,issue,negative,positive,positive,positive,positive,positive
1628574389,@WeichenXu123 Can you run black before making commits? You can use pre-commit if you need to.,run black making use need,issue,negative,negative,negative,negative,negative,negative
1628563837,"@EdAbati We can enable rules that don't require any fixes first, then enable the rest one by one.",enable require first enable rest one one,issue,negative,positive,positive,positive,positive,positive
1628479087,@Bncer Thanks! Feel free to make changes manually :) You don't necessarily have to use the code. The script is for making a shortcut.,thanks feel free make manually necessarily use code script making,issue,positive,positive,positive,positive,positive,positive
1628457181,"Hi @harupy! 
I hesitated between this issue and [#9017](https://github.com/mlflow/mlflow/issues/9017), ultimately chose the harder one. 
I will start making a research one this issue. 
When I feel ground to apply a PR  I will let you know, or if I have questions.
Thank you",hi issue ultimately chose harder one start making research one issue feel ground apply let know thank,issue,negative,negative,neutral,neutral,negative,negative
1628098778,"Test:

```
> git diff
diff --git a/mlflow/tracking/client.py b/mlflow/tracking/client.py
index fa77c32ca..801d8eb47 100644
--- a/mlflow/tracking/client.py
+++ b/mlflow/tracking/client.py
@@ -48,11 +48,11 @@ from mlflow.utils.mlflow_tags import (
 )
 
 if TYPE_CHECKING:
-    import pandas  # pylint: disable=unused-import
-    import matplotlib  # pylint: disable=unused-import
-    import plotly  # pylint: disable=unused-import
-    import numpy  # pylint: disable=unused-import
-    import PIL  # pylint: disable=unused-import
+    import pandas
+    import matplotlib
+    import plotly
+    import numpy
+    import PIL
 
 _logger = logging.getLogger(__name__)
 
> pylint mlflow/tracking/client.py

-------------------------------------------------------------------
Your code has been rated at 10.00/10 (previous run: 9.94/10, +0.06)
```",test git git index deb import import import import import import import import import import import code rated previous run,issue,negative,negative,negative,negative,negative,negative
1627960699,"@WeichenXu123 [Pandas' mask function](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.mask.html) uses NaN by default to mask values:

```python
In [1]: import pandas as pd
    ...: import numpy as np
    ...: df = pd.DataFrame(np.arange(10), columns=['A'])
    ...: df[""B""] = list(np.random.rand(len(df), 100))
    ...: df[""B""] = df[""B""].mask(df[""A""] > 6)

In [2]: df
Out[2]: 
   A                                                  B
0  0  [0.1662489584427871, 0.5755128839154969, 0.742...
1  1  [0.41264499355065565, 0.3730176504554157, 0.91...
2  2  [0.35416690679816887, 0.3460157576018883, 0.80...
3  3  [0.6997412903780977, 0.3410781680833527, 0.207...
4  4  [0.12594319666172327, 0.07381316666689552, 0.3...
5  5  [0.17082912559752683, 0.3902643417345594, 0.97...
6  6  [0.5727333826943939, 0.9925955283710716, 0.454...
7  7                                                NaN
8  8                                                NaN
9  9                                                NaN

In [3]: type(df[""B""].iloc[7])
Out[3]: float
```",mask function nan default mask python import import list nan nan nan type float,issue,negative,neutral,neutral,neutral,neutral,neutral
1627865979,"@freud14-tm 

Curious, using nan to represent a Null array type value looks weird, why not normalize them to None in your model PyFunc code ?",curious nan represent null array type value weird normalize none model code,issue,negative,negative,negative,negative,negative,negative
1627692433,@harupy Do I need to close PR and recreate from local branch or can add next commit to fix?,need close recreate local branch add next commit fix,issue,negative,neutral,neutral,neutral,neutral,neutral
1627691976,"> @Bncer can you address [#8997 (comment)](https://github.com/mlflow/mlflow/issues/8997#issuecomment-1627591495)?

Oh yeah! Will do it",address comment oh yeah,issue,negative,neutral,neutral,neutral,neutral,neutral
1627682352,"> @Pecunia201 Can you break down this PR into smaller ones as instructed in the issue?

apologies, my mistake. I misread the original issue. I'll create new pull requests",break smaller instructed issue mistake misread original issue create new pull,issue,negative,positive,positive,positive,positive,positive
1627681340,@Pecunia201 Can you break down this PR into smaller ones as instructed in the issue?,break smaller instructed issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1627670832,I opened a few more good first issues. Let me know if you're interested in working on them.,good first let know interested working,issue,positive,positive,positive,positive,positive,positive
1627670154,@EdAbati Thanks! I'm selecting which rules to enable in each rule group. I'll open new issues once the selection is done.,thanks enable rule group open new selection done,issue,negative,positive,positive,positive,positive,positive
1627668755,"@Bncer Thanks for the investigation! Let's use `per-file-igbores` for files in `dev`. print usage should be allowed there.

`print` can't be autofixed because it is a behavior change. This is expected.",thanks investigation let use dev print usage print ca behavior change,issue,negative,positive,positive,positive,positive,positive
1627665185,"Dear @harupy!
Thank you for the opportunity!
I have discovered unexpected behavior of [flake8-print-t20](https://beta.ruff.rs/docs/rules/#flake8-print-t20) 
For example in add_num.py file:
```
import os
def add_numbers(a, b):
    print(f""The sum of {a} and {b} is {a + b}"")
    return a + b
```
 on command  - `ruff check add_num.py`
I have following ruff status:
```
add_num.py:1:8: F401 [*] os imported but unused
add_num.py:4:5: T201 `print` found
Found 2 errors.
[*] 1 potentially fixable with the --fix option.
```
_only 1 potentially fixable_
and on command - `ruff --fix .`
```
add_num.py:3:5: T201 `print` found
Found 2 errors (1 fixed, 1 remaining).
```
So ruff auto fix F401, but leave our T201 rule.
**It seems doesn't have autofix of T201**

As for ruff checking the whole project mlflow:
we have 25 errors mainly in `dev` folder, where files used in `./.github/workflows/`
As a proposition we can include `# noqa: T201` for each line to ignore prints or add `dev` folder in exclude list of pyproject.toml

",dear thank opportunity discovered unexpected behavior example file import o print sum return command ruff check following ruff status o unused print found found potentially fixable fix option potentially command ruff fix print found found fixed ruff auto fix leave rule ruff whole project mainly dev folder used proposition include line ignore add dev folder exclude list,issue,positive,positive,neutral,neutral,positive,positive
1627650385,"Hi @harupy , I have added the other 2 UP rules in PR #9007 :)

Happy to take another one. Which one should be done next? Maybe the `pylint` ones so we speed up linting tests?",hi added happy take another one one done next maybe speed,issue,positive,positive,positive,positive,positive,positive
1627591495,"@Bncer Thanks, `flake8-print-t20` allows us to remove this line:

https://github.com/mlflow/mlflow/blob/10bb4e0f68a15d1fe0002bb4e97f90ca26928cbb/pylintrc#L86-L86",thanks u remove line,issue,negative,positive,positive,positive,positive,positive
1627581356,"Thanks! Let's fix this first (because it would affect other rules), then enable the new rules :)",thanks let fix first would affect enable new,issue,negative,positive,positive,positive,positive,positive
1627489317,Hi @harupy! I would like to take one of the task you assign. ,hi would like take one task assign,issue,negative,neutral,neutral,neutral,neutral,neutral
1627477039,I think the build break is that this references **tutorial-tracking.rst** which is not yet merged. Not sure if I should pull the links temporarily or just leave as-is. Gonna' leave as-is for the moment.,think build break yet sure pull link temporarily leave gon na leave moment,issue,negative,positive,positive,positive,positive,positive
1627475687,"Something like this maybe?

```python
    def isnull(x):
        return x is None or (isinstance(x, float) and bool(np.isnan(x)))

    if array_dim == 1:
        return [
            np.array(v, dtype=np_type) if not isnull(v) else None
            for v in values
        ]
    else:
        return [
            list(np.array(v, dtype=np_type)) if not isnull(v) else None
            for v in values
        ]
```",something like maybe python return none float bool return else none else return list else none,issue,negative,neutral,neutral,neutral,neutral,neutral
1627472355,"Hi @WeichenXu123 , your branch seems to work fine with my example. Could expand it with np.nan as well as None for the null value?",hi branch work fine example could expand well none null value,issue,negative,positive,positive,positive,positive,positive
1627455478,"Fixed the test failures from my commit, good news was that the tests were wrong, not the implementation. FYSA, the command listed in the CONTRIBUTING.md doc for running the python tests doesn't appear to actually run all of the tests, which is what led to this. I ran the command listed in the CI instead, and I confirmed my test actually ran (and passed).",fixed test commit good news wrong implementation command listed doc running python appear actually run led ran command listed instead confirmed test actually ran,issue,negative,positive,positive,positive,positive,positive
1627446504,"Yes, group-level default permissions would work. There's potentially a related concern/question: If a user is a member of multiple groups, which group's default permission ""wins""? Is it the most permissive? Least permissive?

It would be good to think this through during the design phase. Perhaps it would be good to consider a more flexible model with both ""allow"" and ""deny"" rules, similar to firewalls. Stopping myself now because I haven't thought this through in detail. 😅

It's funny you mention groups, because I considered creating an ""FR"" issue for supporting groups. We implemented a custom solution for groups as part of our MLflow deployment. I didn't do that because this issue and #8863 seemed more immediately important for us and potentially other MLflow users.

It's uncertain how much time I could spend on contributing in this area, but potentially a few days in the coming months (?). I could also share bits of the code we developed.

Another potentially interesting aspect of our implementation is that it uses JWT HTTP headers rather than basic auth. That worked well for Google App Engine and Google Cloud Run and may be useful in other environments as well. Let me know if any of this sounds interesting -- happy to share some code or set up a chat some time.",yes default would work potentially related user member multiple group default permission permissive least permissive would good think design phase perhaps would good consider flexible model allow deny similar stopping thought detail funny mention considered issue supporting custom solution part deployment issue immediately important u potentially uncertain much time could spend area potentially day coming could also share code another potentially interesting aspect implementation rather basic worked well engine cloud run may useful well let know interesting happy share code set chat time,issue,positive,positive,positive,positive,positive,positive
1627396711,"@WeichenXu123, the artifact name is unique, but the artifact path not necessarily. If all the artifacts you are logging come from the same run, yes, what you are saying is true. However, when those artifacts come from multiple runs, you can have different artifact name which point to conflicting artifact paths. See this example:

```python
mlflow.pyfunc.log_model(""model"", 
                         python_model=MyModel(),
                         artifacts={
                             ""en"": ""runs://XXXXXXXX/model"",
                             ""es"": ""runs://XXXXXXXX/model""
                         }
)
```
In today implementation, this produces the following files (the reason there is only one folder model is because the last ""artifact"" has overridden the first one.

```bash
artifacts/
  model/
    weights.pt
```

To solve this we can either do:

a) Use the artifact name as the artifact path. However, this goes introduces a different approach about how MLflow considers folders and files in general (think about how this should behave in the case of artifacts being files).

```bash
artifacts/
  en/
    weights.pt
  es/
    weights.pt
```
b) Append the artifact name in the artifact root path (what I'm proposing). This respects the idea that under `artifacts/en` we placed what the user told us to place. In this case, the artifact `model`.

```bash
artifacts/
  en/
    model/
      weights.pt
  es/
    model/
      weights.pt
```",artifact name unique artifact path necessarily logging come run yes saying true however come multiple different artifact name point conflicting artifact see example python model en e today implementation following reason one folder model last artifact first one bash solve either use artifact name artifact path however go different approach general think behave case bash append artifact name artifact root path idea user told u place case artifact model bash,issue,positive,positive,positive,positive,positive,positive
1627389361,"Yes. I was able to run `mflow models generate-dockerfile` and build the resulting dockerfile behind our company proxy. 

One concern I have is that the way the dockerfile is generated is different depending on whether or not you are using a local development checkout of mlflow, so I'm not able to test that code path before it actually gets published to pypi. Do you know if  your CI tests that in any way? I was considering publishing it to our internal nexus and trying to test it that way, but then I realized that there was no method of injecting the authentication and TLS needed for that to work in the dockerfile. If you have some sort of staging or release-candidate flow, I could try and test behind the proxy again if one of those releases gets cut.
",yes able run build resulting behind company proxy one concern way different depending whether local development able test code path actually know way considering internal nexus trying test way method authentication work sort staging flow could try test behind proxy one cut,issue,negative,positive,neutral,neutral,positive,positive
1627388031,"Make sense, did you run an end-to-end test against authenticated proxy config ?",make sense run test proxy,issue,negative,neutral,neutral,neutral,neutral,neutral
1627301012,"@EdAbati Before enabling them, can we make the following change first?

```diff
diff --git a/.github/workflows/master.yml b/.github/workflows/master.yml
index a40e51103..48ce83621 100644
--- a/.github/workflows/master.yml
+++ b/.github/workflows/master.yml
@@ -53,18 +53,18 @@ jobs:
         env:
           GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
         run: |
-          # pylint is ridiculously slow. It takes ~15 minutes to run on all files.
+          # pylint is ridiculously slow. It takes ~3 minutes to run on all files.
           # To fail fast for faster iteration, first run pylint only on changed files,
           # then run it on all files in the next step.
           changed_files=$(python dev/list_changed_files.py --repository mlflow/mlflow --pr-num ${{ github.event.number }})
           pre-commit run --files $changed_files
-      - name: Run pre-commit (pylint)
+      - name: Run pre-commit (all files)
         env:
           GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
         run: |
           changed_files=$(python dev/list_changed_files.py --repository mlflow/mlflow --pr-num ${{ github.event.number }})
           if echo ""$changed_files"" | grep -q '\.py$'; then
-            pre-commit run --all-files pylint
+            pre-commit run --all-files
           fi
       - name: Update error messages
         if: always() && steps.run-pre-commit.outcome == 'failure'
```

Currently, We only run ruff on changed files, but should run it on all files. For example, we might have a python file that violates UP011. Ruff can't detect it unless we run ruff on it.",make following change first git index ae ce run ridiculously slow run ridiculously slow run fail fast faster iteration first run run next step python repository run name run name run run python repository echo run run fi name update error always currently run ruff run example might python file ruff ca detect unless run ruff,issue,negative,negative,neutral,neutral,negative,negative
1627087865,"> the ""mapping"" ""my_artifacts: relative_path"". We can make it more explicit on the MLmodel file.

This works. But, since each artifact has a unique name, why can't we directly log them to a flattened artifact directory ?

so that we can directly enter the logged artifact directory and see all artifact files there, and we can search them by unique name. Does it make the thing simpler ?",make explicit file work since artifact unique name ca directly log artifact directory directly enter logged artifact directory see artifact search unique name make thing simpler,issue,negative,positive,positive,positive,positive,positive
1627001124,"> @luisds95 Thanks for working on this issue! This PR contains a lot of diff from other unrelated commits, can you merge master into your branch first?

Thanks @gabrielfu, that's done. Well done to the team on making pylint actually finish",thanks working issue lot unrelated merge master branch first thanks done well done team making actually finish,issue,positive,positive,positive,positive,positive,positive
1626905729,@barrywhart Thanks for raising this :) I agree that the current workflow is not organization friendly. Will group based access control solve your problem? Each user can belong to any number of groups and each group has a default permission. ,thanks raising agree current organization friendly group based access control solve problem user belong number group default permission,issue,positive,positive,positive,positive,positive,positive
1626882495,I found that it's Chrome browser's problem. When I use Firefox there is no issue.,found chrome browser problem use issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1626656790,"@luisds95 Thanks for working on this issue! This PR contains a lot of diff from other unrelated commits, can you merge master into your branch first?",thanks working issue lot unrelated merge master branch first,issue,negative,positive,positive,positive,positive,positive
1625736461,"is it fixed yet? coz i am trying to import mlflow and it still throws the same error.

mlflow== 1.26.1
",fixed yet coz trying import still error,issue,negative,positive,neutral,neutral,positive,positive
1625506210,"> Hi @benfhicks, thanks for reporting the issue! Could you pls provide a minimum reproducible code for this situation? Your environment is quite complicated which makes it hard to us to debug on it, maybe trying different file size and seeing what might trigger this problem could be useful. I also see you're willing to contribute, pls feel free to file a PR if you already find the root cause. Thanks :)

Minimum reproducible code here:

```python
import mlflow
import tensorflow as tf
import tensorflow_hub as hub
import os


TRACKING_URI = ""https://mlflow.artifact.site.systems/""
ARTIFACT_PATH = ""tf_models""
EXPERIMENT_NAME = ""BERT Test""

os.environ['MLFLOW_GCS_DEFAULT_TIMEOUT'] = '600'
os.environ['MLFLOW_GCS_UPLOAD_CHUNK_SIZE'] = f'{2**10}'
os.environ['MLFLOW_HTTP_REQUEST_TIMEOUT'] = '600'

input_ids = tf.keras.layers.Input(shape=[None], dtype=tf.int32)
input_mask = tf.keras.layers.Input(shape=[None], dtype=tf.int32)
sequence_mask = tf.keras.layers.Input(shape=[None], dtype=tf.int32)

features = {
    ""input_ids"": input_ids,
    ""input_mask"": input_mask,
    ""segment_ids"": sequence_mask,
}

albert = hub.KerasLayer(
    ""https://tfhub.dev/google/albert_large/2"",
    signature=""tokens"",
    output_key=""pooled_output"",
)

out = albert(features)

model = tf.keras.Model(inputs=[input_ids, input_mask, sequence_mask], outputs=out)
model.compile(""adam"", loss=""sparse_categorical_crossentropy"")

mlflow.set_tracking_uri(TRACKING_URI)
mlflow.set_experiment(EXPERIMENT_NAME)

with mlflow.start_run() as active_run:
    mlflow.tensorflow.log_model(
        model,
        ARTIFACT_PATH
    )
```

Raises the warning

```bash
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=5, read=5, redirect=5, status=5)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:2426)'))': [/api/2.0/mlflow-artifacts/artifacts/170/686e081ddc2744e1aa3719207dfedc5f/artifacts/tf_models/data/model/variables/variables.data-00000-of-00001](https://file+.vscode-resource.vscode-cdn.net/api/2.0/mlflow-artifacts/artifacts/170/686e081ddc2744e1aa3719207dfedc5f/artifacts/tf_models/data/model/variables/variables.data-00000-of-00001)
```

Which eventually errors",hi thanks issue could provide minimum reproducible code situation environment quite complicated hard u maybe trying different file size seeing might trigger problem could useful also see willing contribute feel free file already find root cause thanks minimum reproducible code python import import import hub import o test none none none model model warning bash warning retry connection broken violation protocol eventually,issue,positive,positive,neutral,neutral,positive,positive
1625323546,"This command resolved the git issues I got : 
`RUN apt-get update -y && apt-get install -y gcc && apt-get install -y git`",command resolved git got run update install install git,issue,negative,neutral,neutral,neutral,neutral,neutral
1625276884,"@EdAbati Awesome, can we start with open-redudant-modes?

Example: https://github.com/mlflow/mlflow/pull/8958

```
ruff --fix .
```

should be able to fix errors.",awesome start example ruff fix able fix,issue,positive,positive,positive,positive,positive,positive
1625220405,"Seems like converting a draft PR to a normal PR doesn't trigger the workflows automatically. 
And after I close and reopen the PR, it still cancels those workflows 🤔 

cc @harupy ",like converting draft normal trigger automatically close reopen still,issue,negative,positive,positive,positive,positive,positive
1625102457,"> Thanks for reporting this! I think your proposed fix makes sense. Feel free to file a PR !

PR filed & ready for review: #8965 !",thanks think fix sense feel free file ready review,issue,positive,positive,positive,positive,positive,positive
1625073805,"Hi @benfhicks, thanks for reporting the issue! Could you pls provide a minimum reproducible code for this situation? Your environment is quite complicated which makes it hard to us to debug on it, maybe trying different file size and seeing what might trigger this problem could be useful. I also see you're willing to contribute, pls feel free to file a PR if you already find the root cause. Thanks :)",hi thanks issue could provide minimum reproducible code situation environment quite complicated hard u maybe trying different file size seeing might trigger problem could useful also see willing contribute feel free file already find root cause thanks,issue,positive,positive,neutral,neutral,positive,positive
1624756294,Is it possible to provide a button to select/deselect all experiments? Currently I have to click the experiments one by one if I want to compare all the runs in different experiments. I've been looking forward to this for a long time,possible provide button currently click one one want compare different looking forward long time,issue,negative,negative,neutral,neutral,negative,negative
1624583805,"I create a temp branch for @freud14-tm testing. https://github.com/WeichenXu123/mlflow/tree/infer-spark-udf-return-type-test

Separate PR will be filed later, after https://github.com/mlflow/mlflow/pull/8934 is merged.",create temp branch testing separate later,issue,negative,neutral,neutral,neutral,neutral,neutral
1624562855,"@WeichenXu123 Do we need to fix this issue in #8934? If not, please separate it.",need fix issue please separate,issue,negative,neutral,neutral,neutral,neutral,neutral
1624432425,"> Can we file a ticket to unpin and add to next sprint?

Created",file ticket unpin add next sprint,issue,negative,neutral,neutral,neutral,neutral,neutral
1623829487,"> > > Can you share a repro?
> > 
> > 
> > https://github.com/aws-samples/amazon-sagemaker-mlflow-fargate/tree/main
> 
> This repo deploys MLflow `2.0.1`. There has been a major change in the mlflow sdk on how to deploy to sagemaker. Can you please make sure your MLflow SDK, MLflow tracking server are the same?

I verified that I am using 2.0.1 client",share major change deploy please make sure server client,issue,positive,positive,positive,positive,positive,positive
1623442629,I've also raised an issue with the Documentations incase it is a Databricks issue rather than a MLFlow issue: https://github.com/MicrosoftDocs/azure-docs/issues/111832,also raised issue incase issue rather issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1623170634,"This is the first split of that giant PR, and I created 5 which the later depends on the former. I could either 1. wait until the former PR is merged then clean up the next PR; or 2. make the next PR against the former PR's branch. WDYT?",first split giant later former could either wait former clean next make next former branch,issue,negative,positive,neutral,neutral,positive,positive
1623007316,@dbczumar Filed https://github.com/mlflow/mlflow/pull/8971 to add a deprecation notice. Could you take a look?,add deprecation notice could take look,issue,negative,neutral,neutral,neutral,neutral,neutral
1623003613,I think we can remove them once we release 2.5.0 to ensure it works in 2.5.0.,think remove release ensure work,issue,negative,neutral,neutral,neutral,neutral,neutral
1622996513,"> Should we remove cross version tests as well?

Yes, we should",remove cross version well yes,issue,positive,neutral,neutral,neutral,neutral,neutral
1622961846,Should we remove cross version tests as well?,remove cross version well,issue,negative,neutral,neutral,neutral,neutral,neutral
1622687766,"@pseudorm Thanks for the question!

> Do you know generally how often are these patched libraries updated in databricks runtime?

Good question. We normally don't update MLflow pre-installed in databricks runtime for machine learning. Instead, we patch the code as shown below:

```python
def new_f():
    ...

mlflow.xxx.yyy.f = new_f
```",thanks question know generally often good question normally update machine learning instead patch code shown python,issue,positive,positive,positive,positive,positive,positive
1621971066,"
@harupy Sorry I was on a hiatus, yes i have tested it on a different environment with your PR branch code and successfully ran the examples. I don't think I can test on the same env where the issue is found tho (company policies).

Do you know generally how often are these patched libraries updated in databricks runtime? ",sorry hiatus yes tested different environment branch code successfully ran think test issue found tho company know generally often,issue,positive,positive,neutral,neutral,positive,positive
1621938607,"@dbczumar I requested a review but a review is not needed, just wanted to share what I did and the issues I found.",review review share found,issue,negative,neutral,neutral,neutral,neutral,neutral
1621816542,"Ohh, I see what you meant now. I was thinking on saving the map ""implicitly"" in the path within the model where the artifact is finally placed (model/artifacts/my_artifact/relative_path). Because the way artifacts are read by MLflow when loading a models, this restores the ""mapping"" ""my_artifacts: relative_path"". We can make it more explicit on the MLmodel file. That's a good suggestion! What do you think?",see meant thinking saving map implicitly path within model artifact finally way read loading make explicit file good suggestion think,issue,negative,positive,positive,positive,positive,positive
1621725518,"> I think there is value on assigning a name (let's say an alias) to an artifact path. It makes easy for the user to then use the artifacts in the context.

But maintaining a map of ""key"" --> ""artifact"" also brings some complexity. If we decided to do so, Shall we save the map when we log artifacts ?",think value name let say alias artifact path easy user use context map key artifact also complexity decided shall save map log,issue,positive,positive,positive,positive,positive,positive
1621713910,"I think there is value on assigning a name (let's say an alias) to an artifact path. It makes easy for the user to then use the artifacts in the context. Specially, consider the case when the artifact path is ""runs:/123456782837/model"". If we use the artifact path as key, the user has to use that complex string to access it in the python context, which is cumbersome. Of course, we can make the ""relative artifact path"" the key instead. But I think this make the usability a bit more complex. Does it make sense?",think value name let say alias artifact path easy user use context specially consider case artifact path use artifact path key user use complex string access python context cumbersome course make relative artifact path key instead think make usability bit complex make sense,issue,positive,positive,neutral,neutral,positive,positive
1621684381,Thanks for reporting this! I think your proposed fix makes sense. Feel free to file a PR !,thanks think fix sense feel free file,issue,positive,positive,positive,positive,positive,positive
1621564968,"Hi @dan-licht 
Your PR diff contains many other unrelated commits, could you fix the issue first ? (you can squash merge your PR against master to get a squashed commit.)",hi many unrelated could fix issue first squash merge master get commit,issue,negative,positive,positive,positive,positive,positive
1621560041,"> If you have two artifacts (and two names by definition) but with the same relative path, it should be fine.

Oh,
I meant we use `{artifact_path}/{artifact_file_name}` as key, WDYT ?",two two definition relative path fine oh meant use key,issue,negative,positive,positive,positive,positive,positive
1621413951,"> I will do a little more investigating to see what the best approach should be here.

@harupy - I've improved the robustness of the unit test in [e15f733](https://github.com/mlflow/mlflow/pull/8899/commits/e15f733ec47d7d796ef840090cbc1a6eb28d4495) and [244cac7](https://github.com/mlflow/mlflow/pull/8899/commits/244cac7247437906bfe6dd610054a3a1037be359), considering:
- It doesn't appear that we can reliably set the permissions on the pre-existing yaml file for testing across all supported OS
- Therefore, we can only check that whatever permissions `file_utils.write_yaml` sets on the pre-existing file are retained after performing `file_utils.overwrite_yaml`
- If the pre-existing file is created with elevated permissions in the testing environment (specifically 600), then the test will fail to detect regressions (in fact this test would pass on `main` in that scenario). Therefore, I've added a warning to the test in the event that this occurs.

",little investigating see best approach robustness unit test considering appear reliably set file testing across o therefore check whatever file file elevated testing environment specifically test fail detect fact test would pas main scenario therefore added warning test event,issue,negative,positive,positive,positive,positive,positive
1621230420,The `sentence_transformers` failure is unrelated. I already fixed it.,failure unrelated already fixed,issue,negative,negative,negative,negative,negative,negative
1620980851,"My proposal is that we need to allow it since the API doesn't provide any constrain on it. The problem is the implementation. When the user indicates artifacts, they need to give them a name (key) so they can reference them by it. Users use the key then to retrieve the artifacts. If you have two artifacts (and two names by definition) but with the same relative path, it should be fine. I should be able to retrieve each of them by using the name (key) I used when logging. Does it make sense?",proposal need allow since provide constrain problem implementation user need give name key reference use key retrieve two two definition relative path fine able retrieve name key used logging make sense,issue,negative,positive,positive,positive,positive,positive
1620834959,So what's the expected behavior that 2 artifact files have the same relative artifact paths ? I think we should not allow this case.,behavior artifact relative artifact think allow case,issue,negative,neutral,neutral,neutral,neutral,neutral
1620830037,We can close this isssue. We switched to ruff. Thanks for all the contributions!,close switched ruff thanks,issue,negative,positive,positive,positive,positive,positive
1620640351,"@harupy - the unit tests ran on [a2d0f66](https://github.com/mlflow/mlflow/pull/8899/commits/a2d0f66298885015b964d0c623a7df3371d3c3d4) were failing because it turns out `os.chmod` is only partially supported for Windows: https://docs.python.org/3/library/os.html#os.chmod. 

Therefore, the following command to set the testing file permissions to a known value had no effect on a Windows build:

https://github.com/mlflow/mlflow/blob/a2d0f66298885015b964d0c623a7df3371d3c3d4/tests/utils/test_file_utils.py#L372-L373

I've updated the test in [aa5db46](https://github.com/mlflow/mlflow/pull/8899/commits/aa5db46d23966d36f4517a7451643ac6ed1ec202) to use a value that should work cross-platform on a GitHub Actions runner.

However, after some investigation, I'm starting to wonder whether all files (even ""secure"" temporary) ones created on Windows _do_ seem to respect the global environment ACLs on Windows. If so, this ""bug"" might only affect Unix backends. In which case the latest incarnation of the unit test _might_ fail on a local development environment with different ACLs.

I will do a little more investigating to see what the best approach should be here.

_(disclaimer: I'm don't develop in Windows day-to-day, so setting up an appropriate environment to test this out will take a bit of time)_",unit ran failing turn partially therefore following command set testing file known value effect build test use value work runner however investigation starting wonder whether even secure temporary seem respect global environment bug might affect case latest incarnation unit test fail local development environment different little investigating see best approach disclaimer develop setting appropriate environment test take bit time,issue,positive,positive,positive,positive,positive,positive
1620604718,That would put a constrain that relative paths should always be different. Which is kind of the implicit assumption today (because if they are the same one artifact overwrite the other ones). I think there is value on relaxing that assumptions.,would put constrain relative always different kind implicit assumption today one artifact overwrite think value,issue,positive,positive,positive,positive,positive,positive
1620371710,"I might miss something, but what if we directly use relative `artifact_path` as the key ?",might miss something directly use relative key,issue,negative,positive,neutral,neutral,positive,positive
1620296376,"@dbczumar I too am still facing the same issue when running the same code using version mlflow version 2.4.1. I am not sure if the issue is how I am creating my spark session of if its still an issue from mlflow.
```
spark = SparkSession.builder.config('spark.jars.packages', 'ml.combust.mleap:mleap-spark_2.12:0.19.0').config(""spark.jars.excludes"", ""net.sourceforge.f2j:arpack_combined_all"").getOrCreate()
```
Please let me know.",still facing issue running code version version sure issue spark session still issue spark please let know,issue,positive,positive,positive,positive,positive,positive
1620239871,"Connection to a specific Postgres database schema was also needed for my use-case and I found out the following solution.
` mlflow.set_tracking_uri(""postgresql://<user>:<password>@localhost/<database>?options=-csearch_path=<schema>"")
mlflow.set_registry_uri(""postgresql://<user>:<password>@localhost/<database>?options=-csearch_path=<schema>"")`
",connection specific schema also found following solution user password schema user password schema,issue,negative,neutral,neutral,neutral,neutral,neutral
1620216530,"Ah, I didn't see that _EnvironmentVariable can pick up our own defined env variables. Thanks for clarifying! I will close the issue ",ah see pick defined thanks close issue,issue,negative,positive,positive,positive,positive,positive
1619338346,You can set your own `MLFLOW_WHEELED_MODEL_PIP_DOWNLOAD_OPTIONS` environment value to address it :),set environment value address,issue,negative,neutral,neutral,neutral,neutral,neutral
1619286207,"Hi @CorentinDeBoisset , `--no-artifacts` sounds like a great name. Would you like to try implementing it? One thing to be mindful of is the MLflow UI - the UI's artifact viewer expects artifact endpoints to be available. During your implementation, can you test the behavior of the UI and, if it doesn't handle unavailability gracefully, let us know? We can work together to handle this case. Thank you in advance for your contribution!",hi like great name would like try one thing mindful artifact viewer artifact available implementation test behavior handle unavailability gracefully let u know work together handle case thank advance contribution,issue,positive,positive,positive,positive,positive,positive
1619266332,"Hi , `list_experiments`  API has been removed, you can use `search_experiments` instead.",hi removed use instead,issue,negative,neutral,neutral,neutral,neutral,neutral
1619251988,"thank you.

could you add one line `print(mlflow.mlflow.get_tracking_uri())` to get the actual tracking URI ? (add the line before the line that raises the exception), if it print ""databricks"", then tracking URI is correct.",thank could add one line print get actual add line line exception print correct,issue,negative,neutral,neutral,neutral,neutral,neutral
1619195490,"> LGTM with a tiny suggestion

Shoot, missed this. Will include it in https://github.com/mlflow/mlflow/pull/8790.",tiny suggestion shoot include,issue,negative,neutral,neutral,neutral,neutral,neutral
1617606453,"@WeichenXu123 Thank you for your comment. 

The environment variables `MLFLOW_ARTIFACTS_DESTINATION` and `MLFLOW_DEFAULT_ARTIFACT_ROOT` work when you start the tracking server in this format `mlflow server .......`. The different tracking server scenarios work fine in this case as well.

But for starting the server as an app wrapped within a basic auth, these variables are not propagated to the app. But when they are declared as defined in the code example it works, and the tracking server is initiated with the defined artifact and backend url. 

As previously explained this works fine for `_MLFLOW_SERVER_FILE_STORE` and `_MLFLOW_SERVER_ARTIFACT_ROOT` and other environment variables but not for  `_MLFLOW_SERVER_ARTIFACT_DESTINATION`. I don't understand why it's not working because there is already a mapping of the variables in the mlflow server scripts ([here](https://github.com/mlflow/mlflow/blob/master/mlflow/server/__init__.py)). 

Am I missing something here?",thank comment environment work start server format server different server work fine case well starting server wrapped within basic declared defined code example work server defined artifact previously work fine environment understand working already server missing something,issue,positive,positive,neutral,neutral,positive,positive
1617531812,Okay thank you very much for the update! I will also look into it.,thank much update also look,issue,negative,positive,positive,positive,positive,positive
1616288118,"Hi @BenWilson2 
I just went through the call stack and I added some changes to make the API accepts multiple environment variables using docker_args. In fact, now the API can accept multiple values other than environment variables, such as mounts (-v) by parsing the lists inside docker_args. Please check my PR #8919 

I haven't added tests yet as I want to validate the work, I think a documentation or an example might be helpful to users who use the API as I was struggling at the beginning if I can pass multiple environment variables, mounts ... etc + figuring out the format of the dictionary for docker_args.",hi went call stack added make multiple environment fact accept multiple environment inside please check added yet want validate work think documentation example might helpful use struggling beginning pas multiple environment format dictionary,issue,positive,neutral,neutral,neutral,neutral,neutral
1616016929,"I was able to resolve the issue by port-forwarding instead of using the proxy link. 

In the local terminal, run the following command:
```
ssh -N -L 5000:127.0.0.1:5000 ec2-user@your_sagemaker_instance_ip_address 
```
And then just go to http://127.0.0.1:5000 ",able resolve issue instead proxy link local terminal run following command go,issue,negative,positive,positive,positive,positive,positive
1615594065,"@BenWilson2 sorry for the late reply, but yes that would be one way to implement it.",sorry late reply yes would one way implement,issue,negative,negative,negative,negative,negative,negative
1615007880,@wamartin-aml sounds like a good idea :) LMK when the PR is ready!,like good idea ready,issue,positive,positive,positive,positive,positive,positive
1614996619,I think we're going to have to support this by way of a feature branch that supports more things from the image libraries (I don't think it's going to be a quick fix),think going support way feature branch image think going quick fix,issue,negative,positive,positive,positive,positive,positive
1614994172,"@Thodorissio 

I discussed with @Ben

model serving does not support `model.to(device)` because it only supports [accelerate](https://huggingface.co/docs/accelerate/index) library",ben model serving support device accelerate library,issue,negative,neutral,neutral,neutral,neutral,neutral
1614793773,"How do I check my Databricks tracking URI? Is it this one?
![image](https://github.com/mlflow/mlflow/assets/17656709/71d9827f-aa8d-4182-a810-ef8f34ff45be)

I'm a little bit unsure of how to check the tracking URI in `train.py` too. On my local PC I set it to `databricks` to make it automatically run on my Databricks server. When using the previously mentioned method of adding
```
import os
print(os.environ)
```
in my `config.py` (which is loaded by `train.py`) I also see `'MLFLOW_TRACKING_URI': 'databricks'`. But this is also the case with an older script (not MMLabs) where running on Databricks works.

Is there a better way to check `tracking_URI`? Should I modify a file deeper down the stack trace?",check one image little bit unsure check local set make automatically run server previously method import o print loaded also see also case older script running work better way check modify file stack trace,issue,negative,positive,neutral,neutral,positive,positive
1614534573,"It's ridiculous for a modern web application NOT to have at least basic login/password authentication baked in, to be honest. Thumbs down for mlflow team on this topic. I want to collaborate only with my teammates from other countries, not with the whole world.",ridiculous modern web application least basic authentication baked honest team topic want collaborate whole world,issue,negative,positive,neutral,neutral,positive,positive
1614477850,"Hey @tsabbir96, 
I wanted to know that are you still working on this, as it's already been 2 months since this has been assigned to you.
If @tsabbir96 is not working then @dbczumar can you assign this to me I would like to work on this.  ",hey know still working already since assigned working assign would like work,issue,negative,neutral,neutral,neutral,neutral,neutral
1614426121,"> Thanks for reporting this issue ! Your analysis and proposed solution make perfect sense! Feel free to file PR !

No problem - FYI, the following PR targets this issue: #8899 ",thanks issue analysis solution make perfect sense feel free file problem following issue,issue,positive,positive,positive,positive,positive,positive
1614251398,"Yes but the `BeitForImageClassification` can be loaded with cuda:

```python
clf.model.to(torch.device(""cuda""))
print(clf.mode.device)
```

Outputs:
```shell
cuda:0
```",yes loaded python print shell,issue,negative,neutral,neutral,neutral,neutral,neutral
1613972613,"Let me check this change doesn't throw on Databricks. The `UpdateRun` API on Databricks doesn't have a `start_time` parameter, so it should be ignored.",let check change throw parameter,issue,negative,neutral,neutral,neutral,neutral,neutral
1613972483,"> I also think that it makes sense to only update the start time for SCHEDULED run, but not in other cases like restarting a FAILED one. What do you think?

Agreed :)",also think sense update start time run like one think agreed,issue,positive,neutral,neutral,neutral,neutral,neutral
1613940666,@krlng Did you get any further responses? Is there any further interest to allow custom stages? Please feel free to ping me and have a chat! ,get interest allow custom please feel free ping chat,issue,positive,positive,positive,positive,positive,positive
1613927280,"@pseudorm Would you mind helping us test #8895? The following command installs mlflow from the PR branch.

```
%pip install git+https://github.com/mlflow/mlflow.git@refs/pull/8895/merge
```

",would mind helping u test following command branch pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
1613818254,"Could you help check which tracking URI does the `train.py` uses ?

It might have a different tracking URI with the tracking URI that you use to view the UI portal. So that you can find the run ID in UI portal but you got non-existed run ID in `train.py` ",could help check might different use view portal find run id portal got run id,issue,negative,neutral,neutral,neutral,neutral,neutral
1613683508,"I'm closing this one, because I need to sign off commits before I merged `main` and I don't want to risk clobbering anyone else's commits. New PR inbound in a bit.",one need sign main want risk anyone else new inbound bit,issue,negative,positive,positive,positive,positive,positive
1613552299,"It loaded successfully because it fallbacks to load model without device argument, see this line code:
https://github.com/mlflow/mlflow/blob/152063e0b6fbadfbb2baecaf7d0ac7ca1b304b31/mlflow/transformers.py#L859
",loaded successfully load model without device argument see line code,issue,positive,positive,positive,positive,positive,positive
1613497671,@ghost That isn't working for me within one of my scripts. It is with another :( I don't know what the issue is.,ghost working within one another know issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1613067452,"I was getting this error when clicking on experiments while I had not correctly configured my blob storage.
Once the configuration was corrected then error went away.",getting error correctly blob storage configuration corrected error went away,issue,negative,neutral,neutral,neutral,neutral,neutral
1612897429,"> LGTM!

We should perhaps wait for @WeichenXu123's opinion, it would be rude to self-resolve comments 😄 ",perhaps wait opinion would rude,issue,negative,negative,negative,negative,negative,negative
1612584650,"> This might be because windows uses `\` as a path separator.

Yes that's the reason. Do we need to change to something like 
```javascript
loader.match(/[\/\\]mini-css-extract-plugin[\/\\]/)
```
or 
```javascript
loader.match(new RegExp(`\\${path.sep}mini-css-extract-plugin\\${path.sep}`))
```
?",might path separator yes reason need change something like new,issue,positive,positive,positive,positive,positive,positive
1612578645,"Yes, I have not found the device argument inside the `BeitForImageClassification` but running the code below
```python
clf = mlflow.transformers.load_model(""models:/dit-pipeline/latest"", device=0)
print(type(clf.model))
print(clf.model.device)
```

works with device argument:

```shell
<class 'transformers.models.beit.modeling_beit.BeitForImageClassification'>
cpu
```",yes found device argument inside running code python print type print work device argument shell class,issue,negative,neutral,neutral,neutral,neutral,neutral
1612567183,"Hell @WeichenXu123 thanks for your response. `mmsegmentation` is a git submodule in the repository I linked and can be found here: https://github.com/open-mmlab/mmsegmentation/blob/main/tools/train.py
You might need to do a `git submodule update --init --recursive` to get it manually when cloning the repo. I updated the readme to list this.

The MMLabs config file is read and imported by `train.py` as a python file and is the easiest file to modify to run code on Databricks. So I modified that file to read all environment variables by adding these lines:
```
import os
print(os.environ)
```
Do you think this sufficient to debug?

The MLFlow experiment I ran got assigned the Run ID ea5558c01d794f4698cd6777fbe8d932 in the UI:
![image](https://github.com/mlflow/mlflow/assets/17656709/517cc758-f2da-4b57-9182-6d406a26485b)
And the code printed that same ID: 
```
environ({
    'SHELL': '/bin/bash', 
    'PIP_NO_INPUT': '1', 
    'SUDO_GID': '0', 
    'CONDA_EXE': '/databricks/conda/bin/conda', 
    ...
    'SUDO_USER': 'root', 
    'MLFLOW_RUN_ID': 'ea5558c01d794f4698cd6777fbe8d932',
    ...
})
```

So I'm pretty sure the `MLFLOW_RUN_ID` is set correctly. I even tried this a few days ago with a larger script (not the minimum example I provided) where I modified the `train.py` and could also see the `MLFLOW_RUN_ID` environment variable set correctly.

> It looks like mmengine code does not use mlflow correctly

Yes this is what I have been thinking too. But it seems like `_get_or_start_run()` should work in this instance and I also see people having similar problems in #4176.",hell thanks response git repository linked found might need git update recursive get manually list file read python file easiest file modify run code file read environment import o print think sufficient experiment ran got assigned run id image code printed id environ pretty sure set correctly even tried day ago script minimum example provided could also see environment variable set correctly like code use correctly yes thinking like work instance also see people similar,issue,positive,positive,positive,positive,positive,positive
1612485298,"> Let me know if I'm missing something.

@harupy Thanks! Let's see if I understand the architecture.

1. The structure holding the store data is the global var `_tracking_store_registry`, defined in `mlflow.tracking._tracking_service.utils`.

2. I apparently misunderstood the code, assuming it caches the data upon initialization and then it would need refreshing. 

3. Instead, the data like password, user, tokens **are read on-the-fly from configs**, including environmental variables. Furthermore, **these configs can also be changed on the fly**, at least in the use-case presented here (indeed, it works!).

Would you mind looking into #8879 and see if has any extra utility (the main use-case seems well-solved already, but the secondary goal was to make registration transparent and clean)?
",let know missing something thanks let see understand architecture structure holding store data global defined apparently misunderstood code assuming data upon would need refreshing instead data like password user read environmental furthermore also fly least indeed work would mind looking see extra utility main already secondary goal make registration transparent clean,issue,positive,positive,positive,positive,positive,positive
1612443380,"This FR makes sense to me,
but, I prefer the option name to be `--tracking-service-only`, this makes more clear to user.

`--tracking-service-only`: only provide functionality of the mlflow tracking service (e.g. run creation, metric logging, and parameter logging), and forbid artifact serving.
`--artifacts-only` only for proxied artifact serving.

@dbczumar What do you think ?
",sense prefer option name clear user provide functionality service run creation metric logging parameter logging forbid artifact serving artifact serving think,issue,negative,positive,positive,positive,positive,positive
1612438374,"emm, these environment variables (_MLFLOW_SERVER_ARTIFACT_DESTINATION, _MLFLOW_SERVER_ARTIFACT_ROOT,  _MLFLOW_SERVER_FILE_STORE) are used internally (not designed as user settings),
instead, I think you should use:

`--artifacts-destination` option or setting `MLFLOW_ARTIFACTS_DESTINATION` environment variable when starting server.

Similarly,
we have `--default-artifact-root` option (or setting `MLFLOW_DEFAULT_ARTIFACT_ROOT` env var ),

and for using file store backend, we should set option `--backend-store-uri` (or setting env var `MLFLOW_BACKEND_STORE_URI`)",environment used internally designed user instead think use option setting environment variable starting server similarly option setting file store set option setting,issue,negative,neutral,neutral,neutral,neutral,neutral
1612412577,Thanks for reporting this issue ! Your analysis and proposed solution make perfect sense! Feel free to file PR !,thanks issue analysis solution make perfect sense feel free file,issue,positive,positive,positive,positive,positive,positive
1612406963,"> Upon examining the source code, it looks like the warning stems from [L599 here](https://github.com/mlflow/mlflow/blob/master/mlflow/recipes/steps/train.py#L599). best_estimator_params is initialized as None [on line 368](https://github.com/mlflow/mlflow/blob/master/mlflow/recipes/steps/train.py#L368), but it is not updated by any of the ensuing code until the .keys() call is made on line 599, causing the error.


Yes. I agree with your root cause analysis. Feel free to file PR !
",upon examining source code like warning none line code call made line causing error yes agree root cause analysis feel free file,issue,positive,positive,positive,positive,positive,positive
1612345471,"```python
import mlflow
import os
from unittest import mock
import requests

original = requests.Session.request


def patch(*args, **kwargs):
    print(kwargs[""headers""])
    return original(*args, **kwargs)


with mock.patch(""requests.Session.request"", patch) as mock_request:
    os.environ[""MLFLOW_TRACKING_TOKEN""] = ""foo""
    mlflow.set_tracking_uri(""http://localhost:5000"")
    mlflow.search_experiments()
    os.environ[""MLFLOW_TRACKING_TOKEN""] = ""bar""
    mlflow.search_experiments()
```

prints out:

```
{'User-Agent': 'mlflow-python-client/2.4.2.dev0', 'Authorization': 'Bearer foo'}
{'User-Agent': 'mlflow-python-client/2.4.2.dev0', 'Authorization': 'Bearer bar'}
```

Let me know if I'm missing something.",python import import o import mock import original patch print return original patch foo bar dev foo dev bar let know missing something,issue,negative,positive,positive,positive,positive,positive
1612329101,"@harupy I also think that it makes sense to only update the start time for `SCHEDULED` run, but not in other cases like restarting a `FAILED` one. What do you think?",also think sense update start time run like one think,issue,negative,neutral,neutral,neutral,neutral,neutral
1612283725,"Temporary patch applied to custom `Dockerfile` for MLflow `>2.4.0`:

```Dockerfile
RUN STATIC_DIR=$(python3 -c 'from mlflow.server import app;print(app.static_folder)') && \
    CSS_FILENAME=$(ls ${STATIC_DIR}/static/css/main.*.css) && \
    sed -i 's|/static-files/static|..|g' ${CSS_FILENAME}
```",temporary patch applied custom run python import print,issue,negative,neutral,neutral,neutral,neutral,neutral
1612132741,@anggao I wanted to check in on the status of this request. We would be interested in allowing users to to define custom model stages and can contribute to it - would you be willing to share more on it? Feel free to ping me and have a chat!,check status request would interested define custom model contribute would willing share feel free ping chat,issue,positive,positive,positive,positive,positive,positive
1611990768,"> Please sign off your commit(s)

I think they have been signed, no?",please sign commit think,issue,positive,neutral,neutral,neutral,neutral,neutral
1611924936,"> Would you file PR then we can discuss further based on your implementation ?

@WeichenXu123, I did a PR in #8879. 

Note that I am not a member of the dev team, so I applied the minimalistic solution so as to not touch too much of the codebase. It could be perhaps improved / refactored etc. Would be happy to hear your opinion. Thanks!",would file discus based implementation note member dev team applied solution touch much could perhaps would happy hear opinion thanks,issue,positive,positive,positive,positive,positive,positive
1611799475,"Sounds good. I will be pushing a PR with the fixes (along with a few others for other proxy issues I've discovered) this evening, but on a separate account so there are no issues w/ the DCO.",good pushing along proxy discovered evening separate account,issue,negative,positive,positive,positive,positive,positive
1611790165,"I am not sure why `repo.maven.apache.org` was added to no_proxy list in the original PR. If removing it works well, I agree to remove it from no_proxy list.",sure added list original removing work well agree remove list,issue,positive,positive,positive,positive,positive,positive
1611779362,"As for your first suggestion, that would again defeat the point. There are situations where repo.maven.apache.org **must** be accessed using a proxy, and that would disallow using these commands in such a situation. If a user wanted to explicitly whitelist that host from being accessed via a proxy, they would just set their no_proxy variable to include that host accordingly.

As for your second suggestion, I think that would be a good idea, an can be accomplished with a chain of os.getenv like I have in my example for no_proxy/NO_PROXY.",first suggestion would defeat point must proxy would disallow situation user explicitly host via proxy would set variable include host accordingly second suggestion think would good idea accomplished chain like example,issue,positive,positive,positive,positive,positive,positive
1611769275,@ruial please do share the patch that you are doing. Or someone else please share a workaround.,please share patch someone else please share,issue,positive,neutral,neutral,neutral,neutral,neutral
1611767659,"btw,

https://github.com/mlflow/mlflow/blob/2691a2b32b99cdec5d73940b1289b4efa5ce8cf4/mlflow/models/docker_utils.py#L43

Can we make the code here to check both `http_proxy` and `HTTP_PROXY` environment variable ? similar issue for `https_proxy`",make code check environment variable similar issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1611755520,"According to the error stack, I think `MLFLOW_RUN_ID` environment variable must be set to `09a9ed543f3945558b787ad0dcf124e7` so it skipped create run, see related code https://github.com/mlflow/mlflow/blob/152063e0b6fbadfbb2baecaf7d0ac7ca1b304b31/mlflow/tracking/fluent.py#L296C7-L296C7

The behavior of `_get_or_start_run()` is, if `MLFLOW_RUN_ID` environment variable is set, then it uses the `MLFLOW_RUN_ID` value as existing run and start a run with this existing run id.

Could you help check `mmengine` code set whether `MLFLOW_RUN_ID` environment variable somewhere ? It looks like `mmengine` code does not use mlflow correctly
",according error stack think environment variable must set create run see related code behavior environment variable set value run start run run id could help check code set whether environment variable somewhere like code use correctly,issue,positive,neutral,neutral,neutral,neutral,neutral
1611744474,"Hi @zimonitrome In your linked example code, I don't find `mmsegmentation/tools/train.py` file, could you provide it ?",hi linked example code find file could provide,issue,negative,neutral,neutral,neutral,neutral,neutral
1611724423,OK. I understand your purpose. Would you file PR then we can discuss further based on your implementation ?,understand purpose would file discus based implementation,issue,negative,neutral,neutral,neutral,neutral,neutral
1611722462,"Yes,

It first raises error from this line: https://github.com/mlflow/mlflow/blob/152063e0b6fbadfbb2baecaf7d0ac7ca1b304b31/mlflow/transformers.py#L911

then it fallback to call `_try_load_model_with_device` https://github.com/mlflow/mlflow/blob/152063e0b6fbadfbb2baecaf7d0ac7ca1b304b31/mlflow/transformers.py#L916 and then raise error `got an unexpected keyword argument 'device'`.

Does `BeitForImageClassification` support setting device argument ?",yes first error line fallback call raise error got unexpected argument support setting device argument,issue,negative,positive,positive,positive,positive,positive
1611128919,"Wonderful, thanks!

If you or anyone is interested, I'd be happy at some point to walk through how we are using (and extending) basic auth. It may give you other ideas for the future of MLflow authorization beyond the specific feature requests I created yesterday. One specific example -- we're configuring authorization at the group level rather than the individual level.",wonderful thanks anyone interested happy point walk extending basic may give future authorization beyond specific feature yesterday one specific example authorization group level rather individual level,issue,positive,positive,positive,positive,positive,positive
1611058672,"Yes certainly.

The stacktrace of the exception:
```shell
Traceback (most recent call last):
  File ""/anaconda/envs/classification/lib/python3.10/site-packages/mlflow/transformers.py"", line 913, in _load_model
    model = model_instance.from_pretrained(model_path, **accelerate_model_conf)
  File ""/anaconda/envs/classification/lib/python3.10/site-packages/transformers/modeling_utils.py"", line 2202, in from_pretrained
    raise ImportError(
ImportError: Using `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install accelerate`

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/anaconda/envs/classification/lib/python3.10/site-packages/mlflow/transformers.py"", line 856, in _try_load_model_with_device
    model = model_instance.from_pretrained(model_path, **load_model_conf)
  File ""/anaconda/envs/classification/lib/python3.10/site-packages/transformers/modeling_utils.py"", line 2629, in from_pretrained
    model = cls(config, *model_args, **model_kwargs)
TypeError: BeitForImageClassification.__init__() got an unexpected keyword argument 'device'
```

I installed accelerate to fix the ImportError and the new stacktrace of the exception is the following:
```shell
Traceback (most recent call last):
  File ""/anaconda/envs/classification/lib/python3.10/site-packages/mlflow/transformers.py"", line 913, in _load_model
    model = model_instance.from_pretrained(model_path, **accelerate_model_conf)
  File ""/anaconda/envs/classification/lib/python3.10/site-packages/transformers/modeling_utils.py"", line 2703, in from_pretrained
    raise ValueError(f""{model.__class__.__name__} does not support `device_map='{device_map}'` yet."")
ValueError: BeitForImageClassification does not support `device_map='auto'` yet.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/anaconda/envs/classification/lib/python3.10/site-packages/mlflow/transformers.py"", line 856, in _try_load_model_with_device
    model = model_instance.from_pretrained(model_path, **load_model_conf)
  File ""/anaconda/envs/classification/lib/python3.10/site-packages/transformers/modeling_utils.py"", line 2629, in from_pretrained
    model = cls(config, *model_args, **model_kwargs)
TypeError: BeitForImageClassification.__init__() got an unexpected keyword argument 'device'
```",yes certainly exception shell recent call last file line model file line raise accelerate pip install accelerate handling exception another exception recent call last file line model file line model got unexpected argument accelerate fix new exception following shell recent call last file line model file line raise support yet support yet handling exception another exception recent call last file line model file line model got unexpected argument,issue,positive,positive,neutral,neutral,positive,positive
1610967388,"Hey @BenWilson2, thanks for your guidance on #8801. This PR is already starting to accumulate conflicts, shall I resolve them or will whoever reviews the PR resolve them if it is ready to be approved?",hey thanks guidance already starting accumulate shall resolve whoever resolve ready,issue,positive,positive,positive,positive,positive,positive
1610923709,"> @gabrielfu Thanks! I'm also working on this. I'll ping you if I create PRs. I want to close #6379. This is not urgent at all, let's tackle this step by step like I do rather than filing one giant PR.

Definitely! I'll let you know too on any new changes",thanks also working ping create want close urgent let tackle step step like rather filing one giant definitely let know new,issue,positive,positive,neutral,neutral,positive,positive
1610895947,"@gabrielfu Thanks! I'm also working on this. I'll ping you if I create PRs. I want to close https://github.com/mlflow/mlflow/issues/6379. This is not urgent at all, let's tackle this step by step like I do rather than filing one giant PR that replaces all the environment variables.",thanks also working ping create want close urgent let tackle step step like rather filing one giant environment,issue,positive,positive,neutral,neutral,positive,positive
1610874196,"> @gabrielfu Merged! Feel free to replace other environment variables (you can search `= ""MLFLOW_`) if you want.

sure! I will work on that :)",feel free replace environment search want sure work,issue,positive,positive,positive,positive,positive,positive
1610409257,"Hi @ridhimag11, I'd be happy to. I've booked some time with you next week. 

Another tiny bug: I have a run named ""ConvNet - Augmented - FFT/Wavelet"" but it is interpreted as a file path and just shows as ""Wavelet"" in some sections.
<img width=""531"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/35404590/ab2d3151-c77d-4753-8650-a0c3d8ee6b53"">

Another feature request: The ability to sort the z-level of different runs in the parallel coordinates plot (and line charts). It's not clear how they are currently sorted, however I think a better default would be to sort by the performance metric, so the best performing models are on top/in front. That way, it would be much easier to judge which parameter values are performing better. Currently, the only way I've been able to bring them to the front is by selecting by mouseover/click in the final section where they move from the last parameter value to the metric (top-down). Naturally, all of the lines between the other parameter values overlap and make it difficult to analyse performance from the bottom up. ",hi happy booked time next week another tiny bug run augmented file path wavelet image another feature request ability sort different parallel plot line clear currently sorted however think better default would sort performance metric best front way would much easier judge parameter better currently way able bring front final section move last parameter value metric naturally parameter overlap make difficult analyse performance bottom,issue,positive,positive,positive,positive,positive,positive
1610138531,"Are there any updates on this? I am experiencing a similar situation where the evaluate step reruns the recipe steps in order, starting from ingest",similar situation evaluate step recipe order starting ingest,issue,negative,neutral,neutral,neutral,neutral,neutral
1610105358,"

> Thank you! What's the purpose to refresh the token during a mlflow run ? Because token expires ?

Yes, and let's assume that the token life is not manipulable (it is only to a certain degree, and not under more strict cloud security setups). I want mlflow to **refresh the token on my demand during a single client session**.

> would you also provide sketch code of `get_my_token` ?

Tokens, in my application, will be obtained [through the cloud API or CLI](https://developers.google.com/spectrum-access-system/guides/authorization-and-authentication). But I think we can consider this part black-box, the token is being served well just need it refreshable :-)

Last but not least, thanks for the prompt reaction :-)",thank purpose refresh token run token yes let assume token life manipulable certain degree strict cloud security want refresh token demand single client session would also provide sketch code application cloud think consider part token well need last least thanks prompt reaction,issue,positive,positive,neutral,neutral,positive,positive
1610097750,"Hi, i have the same error, did you solve this error? but with: 'Message': 'The request is invalid.', ",hi error solve error request invalid,issue,negative,neutral,neutral,neutral,neutral,neutral
1610037735,"Could you attach the stacktrace of the exception raised here ? https://github.com/mlflow/mlflow/blob/991eec617a097e4938fbff953ed64066cf159126/mlflow/transformers.py#L857

You can use my modified code to make the stacktrace printed:
https://github.com/mlflow/mlflow/compare/master...WeichenXu123:mlflow:debug8855?expand=1

You can install my modified mlflow by `pip install git+https://github.com/WeichenXu123/mlflow.git@debug8855`
",could attach exception raised use code make printed install pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
1610018783,"Thank you! What's the purpose to refresh the token during a mlflow run ? Because token expires ?
would you also provide sketch code of `get_my_token` ?",thank purpose refresh token run token would also provide sketch code,issue,negative,neutral,neutral,neutral,neutral,neutral
1609928997,"@dbczumar 

> if you're loading the model in a notebook, the OPENAI_API_KEY environment variable must be set first before loading the model.

Yes the user already do that.
According to the user testing result, there are another difference between openai and azure openai service:

azure openai requires using ""engine"" param key instead of ""model"" param key for the Openai model name.
",loading model notebook environment variable must set first loading model yes user already according user testing result another difference azure service azure engine param key instead model param key model name,issue,negative,positive,neutral,neutral,positive,positive
1609260693,"@gabrielfu Merged! Feel free to replace other environment variables (you can search `= ""MLFLOW_`) if you want.",feel free replace environment search want,issue,positive,positive,positive,positive,positive,positive
1609112705,"> Hi @andrelima666
> 
> Could you provide your code to reproducing the issue ?

Hello @WeichenXu123, this is the snippet of code I've used (modified a bit on the secrets for security reasons):

`import openai
import os
GPT_ENGINE = <AzureOpenAI name deployment> 

openai.api_key = dbutils.secrets.get(scope=<AzureAISecretScopeName>, key=""api_key"")
openai.api_base =  dbutils.secrets.get(scope=<AzureAISecretScopeName>, key=""api_url"")
openai.api_type = 'azure'
openai.api_version = '2023-05-15'
os.environ[""OPENAI_API_TYPE""] = 'azure'
os.environ[""OPENAI_API_BASE""] = dbutils.secrets.get(scope=<AzureAISecretScopeName>, key=""api_url"")
os.environ[""OPENAI_API_KEY""] = dbutils.secrets.get(scope=<AzureAISecretScopeName>, key=""api_key"")


os.environ[""MLFLOW_OPENAI_SECRET_SCOPE""] = <AzureAISecretScopeName>

with mlflow.start_run():
    model_info = mlflow.openai.log_model(
        model=GPT_ENGINE,
        task=openai.ChatCompletion,
        messages=[
            {""role"": ""system"", ""content"": <Tst_Content>},
            {""role"": ""user"", ""content"": ""{usr_content}""}],
        artifact_path=""model"",
    )

model = mlflow.pyfunc.load_model(model_info.model_uri)

#Goes all fine without any error until here.
#On doing the predict call it fails.

print(model.predict([{""usr_content"": <usr_content_var>}]))`

When running the last line of code, this error is popping up:

> MlflowException: 1 tasks failed. See logs for details.

When looking into the Databricks Cluster logs, error is more meaningfull:

> WARNING mlflow.openai.api_request_parallel_processor: Request #0 failed with InvalidRequestError(message=""Must provide an 'engine' or 'deployment_id' parameter to create a <class 'openai.api_resources.chat_completion.ChatCompletion'>"", param='engine', code=None, http_status=None, request_id=None)



After some testing, since AzureOpenAI uses 'engine' parameter to define the model and not the 'model' itself.
I added the 'engine' parameter with the same value:
`...
with mlflow.start_run():
    model_info = mlflow.openai.log_model(
        model=GPT_ENGINE,
        engine=GPT_ENGINE,
        task=openai.ChatCompletion,
        messages=[
            {""role"": ""system"", ""content"": <Tst_Content>},
            {""role"": ""user"", ""content"": ""{usr_content}""}],
        artifact_path=""model"",
    )
...`

Now it is working fine as of now. If there is a more graceful way of doing this instead of repeating the value, I'm all ears. 
Thanks for the supp.",hi could provide code issue hello snippet code used bit security import import o name deployment role system content role user content model model go fine without error predict call print running last line code error see looking cluster error warning request must provide parameter create class testing since parameter define model added parameter value role system content role user content model working fine graceful way instead value thanks,issue,positive,positive,positive,positive,positive,positive
1609045436,"<details><summary>Code I used for transformation</summary>
<p>

````python
""""""
python refact.py $(git ls-files tests/**/*.py)
""""""
from __future__ import annotations

import random
import ast
import openai
import asyncio
import re
import textwrap
import click
import logging
from typing import Any, Iterator, TypeVar, Dict
from functools import total_ordering

T = TypeVar(""T"")

logger = logging.getLogger(__name__)


def get_indent(s: str) -> int:
    return len(s) - len(s.lstrip())


class Finder(ast.NodeVisitor):
    """"""
    Finds function nodes that contain a mock.patch.dict call
    """"""

    def __init__(self, filename):
        self.filename = filename
        self.funcs = []
        self.bad_funcs = []

    def node_to_location(self, node) -> str:
        return f""{self.filename}:{node.lineno}:{node.col_offset}""

    def visit_FunctionDef(self, node) -> None:
        self.funcs.append(node)
        super().generic_visit(node)
        self.funcs.pop()

    @property
    def current_func(self) -> ast.FunctionDef | None:
        if self.funcs:
            return self.funcs[-1]
        return None

    def visit_With(self, node) -> None:
        for item in node.items:
            call = item.context_expr
            if (
                isinstance(call, ast.Call)
                and isinstance(call.func, ast.Attribute)
                and call.func.attr == ""dict""
                and isinstance(call.func.value, ast.Attribute)
                and call.func.value.attr == ""patch""
                and isinstance(call.func.value.value, ast.Name)
                and call.func.value.value.id == ""mock""
            ):
                for arg in call.args:
                    # Find os.environ
                    if (
                        isinstance(arg, ast.Attribute)
                        and arg.attr == ""environ""
                        and isinstance(arg.value, ast.Name)
                        and arg.value.id == ""os""
                    ):
                        print(self.node_to_location(self.funcs[-1]))
                        if self.current_func and self.current_func not in self.bad_funcs:
                            self.bad_funcs.append(self.funcs[-1])
                        break
        self.generic_visit(node)


def join_lines(lines: list[str]) -> str:
    return ""\n"".join(lines)


@total_ordering
class Range:
    def __init__(self, start: int, end: int) -> None:
        self.start = start
        self.end = end

    def offset(self, offset: int) -> Range:
        return Range(self.start + offset, self.end + offset)

    def __lt__(self, other: Range) -> bool:
        return self.start < other.start

    @classmethod
    def from_node(cls, node: ast.AST) -> Range:
        return cls(node.lineno - 1, node.end_lineno - 1)

    def slice(self, lines: list[str]) -> list[str]:
        return lines[self.start : self.end + 1]


class Patch:
    def __init__(self, rng: Range, lines: list[str]) -> None:
        self.range = rng
        self.lines = lines

    def diff(self) -> int:
        """"""
        How many lines does this patch add or remove if applied to a file?
        """"""
        return len(self.lines) - (self.range.end - self.range.start + 1)

    def offset(self, offset: int) -> Patch:
        return Patch(self.range.offset(offset), self.lines)

    def __repr__(self) -> str:
        c = join_lines(self.lines)
        return f""""""\
lineno: {self.range.start}
end_lineno: {self.range.end}
-----
{c}
-----
""""""

    def apply(self, lines: list[str]) -> list[str]:
        return [
            *lines[: self.range.start],
            *self.lines,
            *lines[(self.range.end + 1) :],
        ]

    @staticmethod
    def batch_apply(lines: list[str], patches: list[Patch]) -> list[str]:
        offset = 0
        for patch in patches:
            p = patch.offset(offset)
            lines = p.apply(lines)
            offset += patch.diff()
        return lines


def is_valid_code(code: str) -> bool:
    """"""
    Is `code` valid Python code?
    """"""
    try:
        ast.parse(textwrap.dedent(code))
        return True
    except SyntaxError:
        return False


class TopLevelImportFinder(ast.NodeVisitor):
    """"""
    Finds top-level import statements
    ```
    import a  # top-level
    import b  # top-level

    def foo():
        import c  # not top-level
    ```
    """"""

    def __init__(self):
        self.imports = []

    def visit_Import(self, node: ast.Import) -> None:
        self.imports.append(node)

    def visit_ImportFrom(self, node: ast.ImportFrom) -> None:
        self.imports.append(node)

    def visit_FunctionDef(self, node: ast.FunctionDef) -> None:
        pass


def find_imports(code: str) -> list[int]:
    finder = TopLevelImportFinder()
    finder.visit(ast.parse(textwrap.dedent(code)))
    line_nums = set()
    for imp in finder.imports:
        line_nums.update(range(imp.lineno, imp.end_lineno + 1))
    return sorted(line_nums)


def remove_imports(code: str) -> str:
    import_lines = find_imports(code)
    return join_lines(l for i, l in enumerate(code.split(""\n"")) if i + 1 not in import_lines)


def extract_code_from_block(s: str) -> str | None:
    if m := re.search(r""```(?:python)?\n(.+)\n```"", s, re.DOTALL):
        return m.group(1)
    return None


async def chat_complete(func_lines: list[str]) -> str:
    prompt = """"""
The following pytest function contains `with mock.patch.dict(os.environ, dictionary, ...):`. We can use
`monkeypatch.setenv` or `monkepatch.delenv` instead. Please rewrite the function using `monkeypatch.setenv` or
`monkeypatch.delenv`. If the function arguments doesn't contain `monkeypatch`, please add it.
You might be tempted to add missing import statements. Please don't do that.

```python
{code}
```

The output should look like this:

```python
<new_code>
```
"""""".format(
        code=join_lines(func_lines)
    )
    resp = await openai.ChatCompletion.acreate(
        model=""gpt-3.5-turbo-0613"",
        messages=[
            {""role"": ""user"", ""content"": prompt},
        ],
        temperature=0.0,
    )
    return resp[""choices""][0][""message""][""content""]


def extract_code(chat_resp: str) -> list[str] | None:
    logger.debug(""Response: \n---\n%s\n---"", chat_resp)
    new_code = extract_code_from_block(chat_resp)
    if new_code is None:
        return None
    if not is_valid_code(new_code):
        return None
    return new_code


def clean_up_code(code: str, indent: int) -> str:
    # When a function contains undefined modules, ChatGPT sometimes imports them even when
    # we don't ask it to. Those imports need to be removed.
    return remove_imports(textwrap.indent(code, "" "" * indent))


def batched(iterable: Iterator[T], n: int) -> Iterator[list[T]]:
    batch: list[T] = []
    for item in iterable:
        batch.append(item)
        if len(batch) == n:
            yield batch
            batch = []
    if batch:
        yield batch


def collect_funcs(files: list[str]) -> Dict[str, list[Range]]:
    funcs_by_files = {}
    for file in files:
        with open(file) as f:
            code = f.read()

        tree = ast.parse(code)
        visitor = Finder(file)
        visitor.visit(tree)

        for func in visitor.bad_funcs:
            funcs_by_files.setdefault(file, []).append(Range.from_node(func))
    return funcs_by_files


async def fix(files: list[str]) -> None:
    print(""Collecting functions to fix"")
    tasks_by_file = collect_funcs(files)
    print(""="" * 30)
    print(""Generating patches"")
    for file, ranges in tasks_by_file.items():
        with open(file) as f:
            lines = f.read().split(""\n"")

        patches: list[Patch] = []
        for batch in batched(ranges, 10):
            for _ in range(3):  # Retry 3 times
                coros = (chat_complete(rng.slice(lines)) for rng in batch)
                results = await asyncio.gather(*coros, return_exceptions=True)
                failed: list[Range] = []
                for rng, resp in zip(batch, results):
                    if isinstance(resp, Exception):
                        failed.append(rng)
                        logger.error(""Failed to generate patch for %s"", rng)
                        continue

                    if code := extract_code(resp):
                        indent = get_indent(rng.slice(lines)[0])
                        code = textwrap.indent(code, "" "" * indent)
                        code = remove_imports(code)
                        patches.append(Patch(rng, code.split(""\n"")))

                if not failed:
                    break
                batch = failed

        patches.sort(key=lambda p: p.range)
        print(patches)
        new_lines = Patch.batch_apply(lines, patches)
        with open(file, ""w"") as f:
            f.write(join_lines(new_lines))


@click.command()
@click.option(""--debug"", is_flag=True, default=False, help=""Turn on debug logging"")
@click.argument(""files"", nargs=-1)
def main(debug: bool, files: tuple[str]) -> None:
    if debug:
        logging.basicConfig(level=logging.DEBUG)
    files = list(files)
    random.shuffle(files)
    asyncio.run(fix(files))


if __name__ == ""__main__"":
    main()

````

</p>
</details> ",summary code used transformation python python git import import random import ast import import import import import click import logging import import logger return class finder function contain call self self node return self node none node super node property self none return return none self node none item call call patch mock find environ o print break node list return class range self start end none start end offset self offset range return range offset offset self range bool return node range return slice self list list return class patch self range list none self many patch add remove applied file return offset self offset patch return patch offset self return apply self list list return list list patch list offset patch offset offset return code bool code valid python code try code return true except return false class import import import foo import self self node none node self node none node self node none pas code list finder code set imp range return sorted code code return enumerate none python return return none list prompt following function dictionary use instead please rewrite function function contain please add might add missing import please python code output look like python resp await role user content prompt return resp message content list none response none return none return none return code indent function undefined sometimes even ask need removed return code indent iterable list batch list item iterable item batch yield batch batch batch yield batch list list range file open file code tree code visitor finder file tree file return fix list none print fix print print generating file open file list patch batch range retry time batch await list range resp zip batch resp exception generate patch continue code resp indent code code indent code code patch break batch print open file turn logging main bool none list fix main,issue,positive,positive,neutral,neutral,positive,positive
1608854171,"> @gabrielfu Thanks for the PR! #8840 will be merged soon and `_TRACKING_URI_ENV_VAR` will be replaced

Ah I see! Let me revert some of it",thanks soon ah see let revert,issue,negative,positive,positive,positive,positive,positive
1608824028,"> Could you provide a case to describe it and describe when we need to reload the token ?

@WeichenXu123 Thanks, I sketched the functionality in a code snippet and improved the description.

This is a common request, see the link I attached (I added more).

",could provide case describe describe need reload token thanks functionality code snippet description common request see link attached added,issue,negative,negative,neutral,neutral,negative,negative
1608514316,"Hi @andrelima666, if you're loading the model in a notebook, the `OPENAI_API_KEY` environment variable must be set first before loading the model. Please let us know if this resolves the problem. Thank you for using MLflow!",hi loading model notebook environment variable must set first loading model please let u know problem thank,issue,negative,positive,positive,positive,positive,positive
1608463302,"Hi @andrelima666 

Could you provide your code to reproducing the issue ?",hi could provide code issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1608420523,Thanks for reporting this ! Feel free to file your fixing PR!,thanks feel free file fixing,issue,positive,positive,positive,positive,positive,positive
1608404623,"@maciejskorski 

> MLFlow does not support the use case of registering a long-building artefact with a bearer token.

Could you elaborate what's `a long-building arrtifact` ? Could you provide a case to describe it and describe when we need to reload the token ?",support use case artefact bearer token could elaborate could provide case describe describe need reload token,issue,negative,positive,positive,positive,positive,positive
1608391657,Agreed! Feel free to file a PR ! ,agreed feel free file,issue,positive,positive,positive,positive,positive,positive
1608201957,"@a-zhenya @marmal88 thank you very much for responding

@marmal88 I feel like that was it. Probably if I would have done that, then it would have worked but at the same time, it kind of doesn't make any sense since uploading objects (or trained models) worked if you run the code within the Docker container (if that make sense. What I mean is, `docker exec` into the container and run the code directly). I can quickly try this later at some point.

I tackled this problem by creating an endpoint in the backend server (API endpoint to make HTTP requests), send the file using API to the backend and then the backend runs the code itself to upload the trained model.",thank much feel like probably would done would worked time kind make sense since trained worked run code within docker container make sense mean docker container run code directly quickly try later point tackled problem server make send file code trained model,issue,positive,positive,positive,positive,positive,positive
1608195668,"You created a bucket but did not assign user access to the bucket, hence the `PutObject operation: Access Denied` error.

To add access, please add this updated command to you create_buckets docker compose command
```
/bin/sh -c ""
      /usr/bin/mc alias set myminio http://s3:9000 ${AWS_ACCESS_KEY_ID} ${AWS_SECRET_ACCESS_KEY};
      /usr/bin/mc mb myminio/${AWS_BUCKET_NAME};
      /usr/bin/mc admin policy attach minio readwrite --user '${AWS_ACCESS_KEY_ID}';
      /usr/bin/mc policy set public myminio/${AWS_BUCKET_NAME};
      exit 0;
```",bucket assign user access bucket hence operation access error add access please add command docker compose command alias set policy attach user policy set public exit,issue,negative,neutral,neutral,neutral,neutral,neutral
1608117785,"> > Can you share a repro?
> 
> https://github.com/aws-samples/amazon-sagemaker-mlflow-fargate/tree/main

This repo deploys MLflow `2.0.1`. There has been a major change in the mlflow sdk on how to deploy to sagemaker. Can you please make sure your MLflow SDK, MLflow tracking server are the same?",share major change deploy please make sure server,issue,positive,positive,positive,positive,positive,positive
1607135132,@harupy can you see if this will be a clearer message? the previous one looks pretty confusing when on UI / rest api,see clearer message previous one pretty rest,issue,negative,positive,neutral,neutral,positive,positive
1607112348,"#8837 is merged, I rebased this PR on master, the failed test should pass this time.",master test pas time,issue,negative,neutral,neutral,neutral,neutral,neutral
1607100305,"> do you want me to help migrate the rest of _TRACKING_XXX to the managed class?

Sounds good, let's do this!",want help migrate rest class good let,issue,positive,positive,positive,positive,positive,positive
1606948035,"> See the implementation here:
> 
> https://github.com/mlflow/mlflow/blob/24d22bf92b97d4154d847252eb0e0bb3312de4a4/mlflow/server/__init__.py#L181-L192
> 
> 
> What you've shown should be compatible with gunicorn's PasteDeploy configuration file reader. What is the actual error that gets reported when you run this?

At that time, the error of executing the command was: `Error: No such option: --config /gunicorn_config.py`.

It may be caused by the execution method. I arranged mlflow in the compose file, and the startup method was 'bash -c xxx'. 

It worked again later, but it was only in the background mode and could not be blocked in the foreground. 

At the same time, I found a new problem : The directory specified by `--expose-prometheus` will cause it to be executed twice at startup, and an error may be reported for the first time that the `/metrics` directory already exists.


",see implementation shown compatible configuration file reader actual error run time error command error option may execution method compose file method worked later background mode could blocked foreground time found new problem directory cause executed twice error may first time directory already,issue,negative,positive,neutral,neutral,positive,positive
1606718376,"@harupy found that auth test setup is using a different db from the main mlflow db. So the run is created in `sqlalchemy.db`, but we are trying to get it from `mlruns.sqlite`. Fixed at #8837 .",found test setup different main run trying get fixed,issue,negative,positive,neutral,neutral,positive,positive
1606569197,"@harupy I located the bug at 
https://github.com/mlflow/mlflow/blob/8773d89cb467ec1ba44771e137617ccd29b11221/mlflow/server/auth/__init__.py#L215

where it's fetching from REST store again.

I am still figuring out what happened exactly. I will file a PR soon",bug fetching rest store still exactly file soon,issue,negative,positive,positive,positive,positive,positive
1606537003,"@dbczumar Can I merge this PR? Removed `optional` field, the failing test is irrelevant.",merge removed optional field failing test irrelevant,issue,negative,negative,negative,negative,negative,negative
1606532112,"> Interesting. `Run with id=e8f3b6e8681e4ef3be4c094586aa2fff` should exist, but not found.
> 
> ```
>     def test_log_artifact(client, monkeypatch, tmp_path):
>         username1, password1 = create_user(client.tracking_uri)
>         username2, password2 = create_user(client.tracking_uri)
>         with User(username1, password1, monkeypatch):
>             exp_id = client.create_experiment(""exp"")
>             run = client.create_run(experiment_id=exp_id)
>     
>         tmp_file = tmp_path / ""test.txt""
>         tmp_file.touch()
>         with User(username2, password2, monkeypatch):
>             with pytest.raises(MlflowException, match=r""Permission denied""):
> >               client.log_artifact(run.info.run_id, tmp_file)
> E               AssertionError: Regex pattern did not match.
> E                Regex: 'Permission denied'
> E                Input: 'RESOURCE_DOES_NOT_EXIST: Run with id=e8f3b6e8681e4ef3be4c094586aa2fff not found'
> 
> client     = <mlflow.tracking.client.MlflowClient object at 0x7f665a2a6fa0>
> exp_id     = '1'
> monkeypatch = <tests.conftest.ExtendedMonkeyPatch object at 0x7f665a2a6070>
> password1  = '860cf00a86'
> password2  = '2e8e4e0a2a'
> run        = <Run: data=<RunData: metrics={}, params={}, tags={'mlflow.runName': 'illustrious-toad-136'}>, info=<RunInfo: artifact_uri='file:///tmp/pytest-of-runner/pytest-0/test_log_artifact0/artifacts/1/e8f3b6e8681e4ef3be4c094586aa2fff/artifacts', end_time=None, experiment_id='1', lifecycle_stage='active', run_id='e8f3b6e8681e4ef3be4c094586aa2fff', run_name='illustrious-toad-136', run_uuid='e8f3b6e8681e4ef3be4c094586aa2fff', start_time=1687745451272, status='RUNNING', user_id='unknown'>, inputs=<RunInputs: dataset_inputs=[]>>
> tmp_file   = Path('/tmp/pytest-of-runner/pytest-0/test_log_artifact0/test.txt')
> tmp_path   = Path('/tmp/pytest-of-runner/pytest-0/test_log_artifact0')
> username1  = '91986b854c'
> username2  = '336d686e21'
> ```
> 
> https://github.com/mlflow/mlflow/actions/runs/5372974379/jobs/9746897484?pr=8817
> 
> @gabrielfu Any clue on how this happened?

that's interesting, I'm debugging locally now",interesting run exist found client password password user password run user password permission pattern match input run client object object password password run run path path clue interesting locally,issue,positive,positive,positive,positive,positive,positive
1606528470,"Interesting. `Run with id=e8f3b6e8681e4ef3be4c094586aa2fff` should exist, but not found.

```
    def test_log_artifact(client, monkeypatch, tmp_path):
        username1, password1 = create_user(client.tracking_uri)
        username2, password2 = create_user(client.tracking_uri)
        with User(username1, password1, monkeypatch):
            exp_id = client.create_experiment(""exp"")
            run = client.create_run(experiment_id=exp_id)
    
        tmp_file = tmp_path / ""test.txt""
        tmp_file.touch()
        with User(username2, password2, monkeypatch):
            with pytest.raises(MlflowException, match=r""Permission denied""):
>               client.log_artifact(run.info.run_id, tmp_file)
E               AssertionError: Regex pattern did not match.
E                Regex: 'Permission denied'
E                Input: 'RESOURCE_DOES_NOT_EXIST: Run with id=e8f3b6e8681e4ef3be4c094586aa2fff not found'

client     = <mlflow.tracking.client.MlflowClient object at 0x7f665a2a6fa0>
exp_id     = '1'
monkeypatch = <tests.conftest.ExtendedMonkeyPatch object at 0x7f665a2a6070>
password1  = '860cf00a86'
password2  = '2e8e4e0a2a'
run        = <Run: data=<RunData: metrics={}, params={}, tags={'mlflow.runName': 'illustrious-toad-136'}>, info=<RunInfo: artifact_uri='file:///tmp/pytest-of-runner/pytest-0/test_log_artifact0/artifacts/1/e8f3b6e8681e4ef3be4c094586aa2fff/artifacts', end_time=None, experiment_id='1', lifecycle_stage='active', run_id='e8f3b6e8681e4ef3be4c094586aa2fff', run_name='illustrious-toad-136', run_uuid='e8f3b6e8681e4ef3be4c094586aa2fff', start_time=1687745451272, status='RUNNING', user_id='unknown'>, inputs=<RunInputs: dataset_inputs=[]>>
tmp_file   = Path('/tmp/pytest-of-runner/pytest-0/test_log_artifact0/test.txt')
tmp_path   = Path('/tmp/pytest-of-runner/pytest-0/test_log_artifact0')
username1  = '91986b854c'
username2  = '336d686e21'
```

https://github.com/mlflow/mlflow/actions/runs/5372974379/jobs/9746897484?pr=8817

@gabrielfu Any clue on how this happened?",interesting run exist found client password password user password run user password permission pattern match input run client object object password password run run path path clue,issue,negative,positive,positive,positive,positive,positive
1606336947,"@WeichenXu123 

1. start a run
2. detach the notebook

This shoudl leave the run unfinished.",start run detach notebook leave run unfinished,issue,negative,neutral,neutral,neutral,neutral,neutral
1606138349,@kavita1205 Hi you just need to install `pymysql` by pip.,hi need install pip,issue,negative,neutral,neutral,neutral,neutral,neutral
1606136850,"@kavita1205 

You need to run `pip install pymysql` to install it.",need run pip install install,issue,negative,neutral,neutral,neutral,neutral,neutral
1606128133,"I have a question, on databricks runtime, `atexit` hook does not work, in this case, any consequence if the run is not ended when databricks notebook is detached ?",question hook work case consequence run ended notebook detached,issue,negative,neutral,neutral,neutral,neutral,neutral
1605741636,"This is very interesting, Corey. LLMs are costly resources, and this gateway could be a good centralized control point. In addition to authentication and authorization, I think this would be a great place to add functionality such as 'on-demand' startup of LLM VM/k8s pod, idle detect for LLM VMs/k8s pods, etc. Let us know if we can help you build this out.",interesting costly gateway could good control point addition authentication authorization think would great place add functionality pod idle detect let u know help build,issue,positive,positive,positive,positive,positive,positive
1604389792,"Surprisingly, only the record from the ""experiments"" table in SQLite gets deleted while the records in other tables remain as such. Shouldn't there be an ON UPDATE cascade effect in the database?",surprisingly record table table remain update cascade effect,issue,negative,positive,positive,positive,positive,positive
1604201444,It would be good if you reopened and implemented this. Some ML algorithms lead to large pickle files when uncompressed.,would good lead large pickle uncompressed,issue,negative,positive,positive,positive,positive,positive
1604171756,"Can someone help me here as I am also getting same error message. Even though I am using latest version i.e. 2.4.1 for installation.

```
2023/06/23 10:12:41 ERROR mlflow.cli: Error initializing backend store
2023/06/23 10:12:41 ERROR mlflow.cli: No module named 'pymysql'
Traceback (most recent call last):
  File ""/usr/local/lib/python3.10/site-packages/mlflow/cli.py"", line 426, in server
    initialize_backend_stores(backend_store_uri, registry_store_uri, default_artifact_root)
  File ""/usr/local/lib/python3.10/site-packages/mlflow/server/handlers.py"", line 279, in initialize_backend_stores
    _get_tracking_store(backend_store_uri, default_artifact_root)
  File ""/usr/local/lib/python3.10/site-packages/mlflow/server/handlers.py"", line 258, in _get_tracking_store
    _tracking_store = _tracking_store_registry.get_store(store_uri, artifact_root)
  File ""/usr/local/lib/python3.10/site-packages/mlflow/tracking/_tracking_service/registry.py"", line 39, in get_store
    return self._get_store_with_resolved_uri(resolved_store_uri, artifact_uri)
  File ""/usr/local/lib/python3.10/site-packages/mlflow/tracking/_tracking_service/registry.py"", line 49, in _get_store_with_resolved_uri
    return builder(store_uri=resolved_store_uri, artifact_uri=artifact_uri)
  File ""/usr/local/lib/python3.10/site-packages/mlflow/server/handlers.py"", line 119, in _get_sqlalchemy_store
    return SqlAlchemyStore(store_uri, artifact_uri)
  File ""/usr/local/lib/python3.10/site-packages/mlflow/store/tracking/sqlalchemy_store.py"", line 138, in __init__
    ] = mlflow.store.db.utils.create_sqlalchemy_engine_with_retry(db_uri)
  File ""/usr/local/lib/python3.10/site-packages/mlflow/store/db/utils.py"", line 225, in create_sqlalchemy_engine_with_retry
    engine = create_sqlalchemy_engine(db_uri)
  File ""/usr/local/lib/python3.10/site-packages/mlflow/store/db/utils.py"", line 281, in create_sqlalchemy_engine
    return sqlalchemy.create_engine(db_uri, pool_pre_ping=True, **pool_kwargs)
  File ""<string>"", line 2, in create_engine
  File ""/usr/local/lib/python3.10/site-packages/sqlalchemy/util/deprecations.py"", line 283, in warned
    return fn(*args, **kwargs)  # type: ignore[no-any-return]
  File ""/usr/local/lib/python3.10/site-packages/sqlalchemy/engine/create.py"", line 601, in create_engine
    dbapi = dbapi_meth(**dbapi_args)
  File ""/usr/local/lib/python3.10/site-packages/sqlalchemy/dialects/mysql/pymysql.py"", line 75, in import_dbapi
    return __import__(""pymysql"")
ModuleNotFoundError: No module named 'pymysql'
(base) [kavsingh@sjc2-nixutil01 ~]$

```",someone help also getting error message even though latest version installation error error store error module recent call last file line server file line file line file line return file line return builder file line return file line file line engine file line return file string line file line return type ignore file line file line return module base,issue,negative,negative,neutral,neutral,negative,negative
1603631895,"Given all the providers implement the same abstract class, I think we don't need to test all the providers. We can just pick one and use it for tests. If openai works, other providers should also work.",given implement abstract class think need test pick one use work also work,issue,negative,neutral,neutral,neutral,neutral,neutral
1603509154,non-blocking question: Do you think that when we add a provider we should have a pseudo-integration test added to fluent or client API where we start the Gateway server with at least 1 route from the provider so that we can validate that the full instantiation / creation of the provider dynamic routes work (while mocking the external provider request call)?,question think add provider test added fluent client start gateway server least route provider validate full creation provider dynamic work external provider request call,issue,positive,positive,neutral,neutral,positive,positive
1603443667,"I'm sorry that you're experiencing this. We'll be sure to file a change to the naming validation to ensure that a name with ""/"" is not permitted to be registered as this definitely would not work with posixpath uris. Thank you for reporting the issue!
Edit: I see you've volunteered to take this on :) Let us know when the PR is filed and if you have any questions! 
Please ensure that all model flavors inherit the restriction to ensure that we're not allowing reserved characters in registered model names (the log_model() operation should abort prior to any files being created and written anywhere). ",sorry sure file change naming validation ensure name permitted registered definitely would work thank issue edit see take let u know please ensure model inherit restriction ensure reserved registered model operation abort prior written anywhere,issue,positive,neutral,neutral,neutral,neutral,neutral
1603282159,"This reminds me a bit of Seldon Core, though I guess the SaaS key management would be an addition to that. But that does seem like it should be a separate service rather than built into MLFlow itself.",bit core though guess key management would addition seem like separate service rather built,issue,negative,neutral,neutral,neutral,neutral,neutral
1603255082,"@luukschagen good pick ups there. We should be able to configure the chart to support scenarios 4, 5 and 6 using this helm chart. Looks like i might have missed scenario 5. Feel free to put in a pull request!

@bhack I'm not sure of the status, @harupy  might be able to answer what we need to do to merge this",good pick able configure chart support helm chart like might scenario feel free put pull request sure status might able answer need merge,issue,positive,positive,positive,positive,positive,positive
1602784796,"@WeichenXu123 @awskhd I believe I get the same error with a different build, also fixed by rolling back to mlflow==1.30.0",believe get error different build also fixed rolling back,issue,negative,positive,neutral,neutral,positive,positive
1602572515,"Hi, this is an interesting feature
However, don't you think, that this functionality seem a little extra and not entirely in a scope of mlflow responsibility? This seems like it can be a feature of a standalone product, that integrates with mlflow, but does not necessarily bundled in mlflow itself? ",hi interesting feature however think functionality seem little extra entirely scope responsibility like feature product necessarily,issue,positive,positive,neutral,neutral,positive,positive
1601858360,"Verified this works, thanks for the quick fix!",work thanks quick fix,issue,negative,positive,positive,positive,positive,positive
1601643603,"Thanks for sharing your this feedback @jmcapra. Would you be up for a brief chat about this issues and any other feedback on MLflow? For context, I'm a designer working on MLflow. You can book some time with me [here](https://calendar.app.google/PbLPz3KYWu54CSwQ9).",thanks feedback would brief chat feedback context designer working book time,issue,negative,positive,neutral,neutral,positive,positive
1601507118,"I was able to work around it with python context for starting a new runs. That seemed to keep everything in order. The [documentation](https://mlflow.org/docs/latest/tracking.html#automatic-logging) mentions that starting runs explicitly is not necessary ""You do not need to call start_run explicitly: calling one of the logging functions with no active run automatically starts a new one."". That's not the behavior I observed. 
I don't have the resources to recreate the error at this time, but I was getting this error after restarting. I ran it both with a tracking server (CLI), and simply pointing MLFlow to a local folder. ",able work around python context starting new keep everything order documentation starting explicitly necessary need call explicitly calling one logging active run automatically new behavior recreate error time getting error ran server simply pointing local folder,issue,negative,positive,neutral,neutral,positive,positive
1601059065,"Another feature request - some way to show calculated summary statistics, e.g. average accuracy across all runs. E.g. a new chart type, ""Statistics"" or ""Table"", which updates based on the SQL-style filter in the search box and can show the average of any metrics.",another feature request way show calculated summary statistic average accuracy across new chart type statistic table based filter search box show average metric,issue,negative,negative,neutral,neutral,negative,negative
1600961059,"Feedback - add a ""hide most recent run"" button for the Parallel Coordinates chart - the most recent (currently training) run tends to populate this chart with null values, greatly reducing the resolution of the true parameter values. 

Also, a related bug - filtering, e.g. by val_accuracy > 0.6, does not remove this run where val_accuracy is null.",feedback add hide recent run button parallel chart recent currently training run populate chart null greatly reducing resolution true parameter also related bug filtering remove run null,issue,negative,positive,positive,positive,positive,positive
1600952288,"> Can you try this with MLflow 1.30.x and see if this issue still presents itself? Thank you!

I am using mlflow 1.32 I believe",try see issue still thank believe,issue,negative,neutral,neutral,neutral,neutral,neutral
1600918643,"Bug - in ""Chart View"", a tooltip shows on mouseover, however clicking on the relevant model (sometimes) causes it to disappear. Therefore, the buttons on the tooltip are unreachable.
<img width=""349"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/35404590/768a904d-6eeb-4546-81e7-b060003a31a2"">
(it seems this is an intermittent bug. Tough to pin down a consistent way to reproduce but it seems to happen about 20-30% of the time)

Feedback - it would be great to be able to set a different sort metric for bar charts. ""First N"" seems to be the only option - would be great to get ""Top N"". We can also only select N from a list of [5, 10, 20, 100, 250, 500] - a ""nice to have"" would be the ability to set a custom value.
<img width=""507"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/35404590/d5db5387-6760-442f-a03e-2ac3227fadb1"">
",bug chart view however relevant model sometimes disappear therefore button unreachable image intermittent bug tough pin consistent way reproduce happen time feedback would great able set different sort metric bar first option would great get top also select list nice would ability set custom value image,issue,positive,positive,positive,positive,positive,positive
1600878098,"This seems to be handled in the method [`split_models_uri`](https://github.com/mlflow/mlflow/blob/master/mlflow/store/artifact/models_artifact_repo.py#L54), but the comment confuses me. 
Why does the model uri come as  `models:/<name>/<version>/path/to/model`? Docs only mention `models:/<name>/<version>` and `models:/<name>/<stage>`",handled method comment model come name version mention name version name stage,issue,negative,neutral,neutral,neutral,neutral,neutral
1600799111,"Bumping again in contemplation of opening a new issue.

This is my full stack trace:

```
Traceback (most recent call last):
  File ""train.py"", line 129, in <module>
    main()
  File ""train.py"", line 113, in main
    runner = Runner.from_cfg(cfg)
  File ""/databricks/conda/envs/mlflow-3a1ac60e5aa02cd433353e1f872e0fdab605fb69/lib/python3.8/site-packages/mmengine/runner/runner.py"", line 439, in from_cfg
    runner = cls(
  File ""/databricks/conda/envs/mlflow-3a1ac60e5aa02cd433353e1f872e0fdab605fb69/lib/python3.8/site-packages/mmengine/runner/runner.py"", line 395, in __init__
    self.visualizer.add_config(self.cfg)
  File ""/databricks/conda/envs/mlflow-3a1ac60e5aa02cd433353e1f872e0fdab605fb69/lib/python3.8/site-packages/mmengine/dist/utils.py"", line 366, in wrapper
    return func(*args, **kwargs)
  File ""/databricks/conda/envs/mlflow-3a1ac60e5aa02cd433353e1f872e0fdab605fb69/lib/python3.8/site-packages/mmengine/visualization/visualizer.py"", line 1068, in add_config
    vis_backend.add_config(config, **kwargs)
  File ""/databricks/conda/envs/mlflow-3a1ac60e5aa02cd433353e1f872e0fdab605fb69/lib/python3.8/site-packages/mmengine/visualization/vis_backend.py"", line 59, in wrapper
    return old_func(obj, *args, **kwargs)
  File ""/databricks/conda/envs/mlflow-3a1ac60e5aa02cd433353e1f872e0fdab605fb69/lib/python3.8/site-packages/mmengine/visualization/vis_backend.py"", line 751, in add_config
    self._mlflow.log_params(self._flatten(self.cfg))
  File ""/databricks/conda/envs/mlflow-3a1ac60e5aa02cd433353e1f872e0fdab605fb69/lib/python3.8/site-packages/mlflow/tracking/fluent.py"", line 700, in log_params
    run_id = _get_or_start_run().info.run_id
  File ""/databricks/conda/envs/mlflow-3a1ac60e5aa02cd433353e1f872e0fdab605fb69/lib/python3.8/site-packages/mlflow/tracking/fluent.py"", line 1552, in _get_or_start_run
    return start_run()
  File ""/databricks/conda/envs/mlflow-3a1ac60e5aa02cd433353e1f872e0fdab605fb69/lib/python3.8/site-packages/mlflow/tracking/fluent.py"", line 288, in start_run
    active_run_obj = client.get_run(existing_run_id)
  File ""/databricks/conda/envs/mlflow-3a1ac60e5aa02cd433353e1f872e0fdab605fb69/lib/python3.8/site-packages/mlflow/tracking/client.py"", line 158, in get_run
    return self._tracking_client.get_run(run_id)
  File ""/databricks/conda/envs/mlflow-3a1ac60e5aa02cd433353e1f872e0fdab605fb69/lib/python3.8/site-packages/mlflow/tracking/_tracking_service/client.py"", line 72, in get_run
    return self.store.get_run(run_id)
  File ""/databricks/conda/envs/mlflow-3a1ac60e5aa02cd433353e1f872e0fdab605fb69/lib/python3.8/site-packages/mlflow/store/tracking/file_store.py"", line 647, in get_run
    run_info = self._get_run_info(run_id)
  File ""/databricks/conda/envs/mlflow-3a1ac60e5aa02cd433353e1f872e0fdab605fb69/lib/python3.8/site-packages/mlflow/store/tracking/file_store.py"", line 670, in _get_run_info
    raise MlflowException(
mlflow.exceptions.MlflowException: Run 'ab60ea7aad944e098edf9bef7c80f8bd' not found
```

I am using an mmlabs script that does not explicitly use a `with mlflow.start_run() as run:`, but instead just uses `self._mlflow.log_params()` like we can see in the stack trace. But this shouldn't be a problem since it seem to call `_get_or_start_run()` to create a run if needed.

I feel like it could be something like what is suggested here: https://github.com/mlflow/mlflow/issues/8233#issuecomment-1511242999
But I've never had to `export MLFLOW_TRACKING_URI=...` before. Other scripts that use `with mlflow.start_run() as run:` seem to integrate with my local databricks cli tool (where I have set up my tokens etc.) whenever I specify `mlflow.set_tracking_uri(""databricks"")` or `os.environ[""MLFLOW_TRACKING_URI""] = ""databricks""`.

Any help? Please",bumping contemplation opening new issue full stack trace recent call last file line module main file line main runner file line runner file line file line wrapper return file line file line wrapper return file line file line file line return file line file line return file line return file line file line raise run found script explicitly use run instead like see stack trace problem since seem call create run feel like could something like never export use run seem integrate local tool set whenever specify help please,issue,positive,positive,positive,positive,positive,positive
1599751051,"See the implementation here: https://github.com/mlflow/mlflow/blob/24d22bf92b97d4154d847252eb0e0bb3312de4a4/mlflow/server/__init__.py#L181-L192 
What you've shown should be compatible with gunicorn's PasteDeploy configuration file reader. What is the actual error that gets reported when you run this?",see implementation shown compatible configuration file reader actual error run,issue,negative,neutral,neutral,neutral,neutral,neutral
1599741449,"It looks like you're not opening the correct ports in your container. The -p option should be in the format:

`docker run -p <host-port>:<container-port> <image-name>`

You've opened up port 8000 based on your pasted bash commands. Could you make sure that you're opening the right port so that the tracking server running in the container can talk to the outside world? If your tracking server is setup to communicate via port 5001, then that port needs to be open.",like opening correct container option format docker run port based pasted bash could make sure opening right port server running container talk outside world server setup communicate via port port need open,issue,positive,positive,positive,positive,positive,positive
1598285308,"So I could replicate the same issue as @Harryq2018.

Starting with a clean R session and starting a local mlflow server via cmd `mlflow server` gets me a tracking server listening at 127.0.0.1:**5000**

Now I set this uri in R via:
`mlflow_set_tracking_uri(""127.0.0.1:5000"")`

Now I want to e.g init a client object via:
`cl <- mlflow_client()`

This gives: 
```
""Error"" in wait_for(function() mlflow_rest(""experiments"", ""search"", client = client,  : 
  Operation failed after waiting for 10 seconds`.
```
  
The reason is the following:
```
mlflow:::.globals$url_mapping
$`127.0.0.1:5000`
$server_url
[1] ""http://127.0.0.1:5701""

$handle
PROCESS 'mlflow.exe', finished.

$file_store
[1] ""file://C:/Users/.../127.0.0.1:5000""

attr(,""class"")
[1] ""mlflow_server""
```
Although the server was registered with port 5000, in the registry a different port is registered (in this case 5701) and the rest request is send against this url -> hence the time out. 

If we debug into ""new_mlflow_client(), called in mlflow_client"" with a mlflow_file tracking uri object

```
>> tracking_uri
$scheme
[1] ""file""

$path
[1] ""127.0.0.1:5000""

attr(,""class"")
[1] ""mlflow_file"" ""mlflow_uri"" 

debug(new_mlflow_client)
client <- new_mlflow_client(tracking_uri.mlflow_file)
```
we land in the else case, as the server_url is NULL, and here a new random port is generated
```
>> local_server <- mlflow_server(file_store = path, port = mlflow_connect_port())
>> local_server
$server_url
[1] ""http://127.0.0.1:5701""

$handle
PROCESS 'mlflow.exe', finished.

$file_store
[1] ""file://C:/Users/.../127.0.0.1:5000""

attr(,""class"")
[1] ""mlflow_server""
```
Hence the mlflow_connect_port does not check if an existing port is given in the URI. It must be explicitly set in the mlflow.port option.

The strange thing is: This also doesn't work if no tracking server at all is given and I just start 

```
library(mlflow)
mlflow::mlflow_create_experiment(""test123"")

Error in wait_for(function() mlflow_rest(""experiments"", ""search"", client = client,  : 
  Operation failed after waiting for 10 seconds
```
when I check:
```
mlflow:::.globals$url_mapping
$`C:/Users/.../mlruns`
$server_url
[1] ""http://127.0.0.1:5851""

$handle
PROCESS 'mlflow.exe', finished.

$file_store
[1] ""file://C:/Users/.../mlruns""

attr(,""class"")
[1] ""mlflow_server""
```
nothing is running on http://127.0.0.1:5851.

But I do not know why. If I understand the code right, in the later case a cli command is send to start a server but it is timing out.

My workaround now is: manually starting a local server, and then setting it in r via

```
mlflow_set_tracking_uri(""127.0.0.1:5000"")
options(""mlflow.port"" = 5000)

```
But this clearly is not the intended way to do it...

",could replicate issue starting clean session starting local server via server server listening set via want client object via error function search client client operation waiting reason following handle process finished file class although server registered port registry different port registered case rest request send hence time object scheme file path class client land else case null new random port path port handle process finished file class hence check port given must explicitly set option strange thing also work server given start library test error function search client client operation waiting check handle process finished file class nothing running know understand code right later case command send start server timing manually starting local server setting via clearly intended way,issue,negative,positive,neutral,neutral,positive,positive
1598022586,These changes look awesome! How long does it usually take for a big change like this to be cut as part of the release?,look awesome long usually take big change like cut part release,issue,positive,positive,positive,positive,positive,positive
1597681251,"@ichbinjakes I've done a test install of this Helm chart, and have a few comments/suggestions. I have fixed/altered these locally, which I could clean up a bit and turn into a pull request if you'd like. Are you still actively following this?

**Fixed issues:**
- Currently the value for image tag appears to be ignored completely. It always returns to the default value of AppVersion
- The AppVersion is not added as image tag correctly, because it misses the 'v' prefix. So currently the defaults lead to Imagepull errors.
- For the GCP install the keyfile is not mounted correctly. The secret is mounted as a **folder** called keyfile.json, containing a file called keyfile.json, with the env variable pointing to the folder, though it should point to the file.

Other than those, one issue I encountered which might need some clarification is that the current behavior of enabling the Artifact serving in the values.yaml is that the `--default-artifact-root` gets set, but the `--artifact-destination` does not. This sets up something like ['Scenario 4'](https://mlflow.org/docs/latest/tracking.html#scenario-4-mlflow-with-remote-tracking-server-backend-and-artifact-stores) from the tracking docs, though that would also require `--no-serve-artifacts`. I suspect the intention is probably to set-up [Scenario 5](https://mlflow.org/docs/latest/tracking.html#scenario-5-mlflow-tracking-server-enabled-with-proxied-artifact-storage-access). Scenario 5 only appears to work if `---default-artifact-root` is **not** set, and `--artifact-destination` **is**, as is [discussed here](https://github.com/mlflow/mlflow/issues/6181#issuecomment-1177231056).

I have for now fixed that locally by simply replacing the flag, but that requires maybe a little cleaner solution that allows people to choose between scenario 4 and 5. I am not entirely sure what your intention was there.

Let me know if you would like me to make a pull request fixing the issues above.",done test install helm chart locally could clean bit turn pull request like still actively following fixed currently value image tag completely always default value added image tag correctly prefix currently lead install mounted correctly secret mounted folder file variable pointing folder though point file one issue might need clarification current behavior artifact serving set something like though would also require suspect intention probably scenario scenario work set fixed locally simply flag maybe little cleaner solution people choose scenario entirely sure intention let know would like make pull request fixing,issue,positive,positive,neutral,neutral,positive,positive
1596329010,Looks like the latest dev branch today passes: https://github.com/mlflow/mlflow/actions/runs/5303823843/jobs/9599726916,like latest dev branch today,issue,negative,positive,positive,positive,positive,positive
1595848854,"@harupy I see that you've requested a review from @dbczumar

I'll land this PR for now given that @dbczumar asked me to ask you for reviews and that he approved the design for this feature. Happy to adapt additional feedback in follow-up PRs before the next release.",see review land given ask design feature happy adapt additional feedback next release,issue,positive,positive,positive,positive,positive,positive
1595826486,"For Python API,
It accepts one environment variable as ```docker_args``` is a dictionary. But for the CLI, I am not sure if it even accepts one environment variable. I'll try to look around and work on the Python API regarding docker_args and see if I can add anything to it. Thank you",python one environment variable dictionary sure even one environment variable try look around work python regarding see add anything thank,issue,positive,positive,positive,positive,positive,positive
1595050317,"Ah, I see what you mean. Is it only accepting the last entry env_var_2?
I think that the support for generating a parsed list similar to how unique environment var keys for submission to running the container is probably the way to go. 

As you mentioned that you were interested in contributing this feature, I would start looking into how the `docker_args` are submitted into the `backend_config` within `_run` in https://github.com/mlflow/mlflow/blob/a6104a4e4cd64adb256c569288e2bfe3f0034cc6/mlflow/projects/__init__.py#L74-L100 and the subsequent processing of them within the call stack. 

Currently, from a cursory look, we don't cover full explicit testing of this scenario in https://github.com/mlflow/mlflow/blob/a6104a4e4cd64adb256c569288e2bfe3f0034cc6/tests/projects/test_docker_projects.py#L269-L283 so testing for reserved arguments such as `env` would be needed to be validated (with a validation through a mock to the environment present on a simple container to ensure that values are set correctly as expected through the use of the pytest monkeypatch fixture. 

If you need an immediate unblock, I suppose a workaround would be to write a simple parser within your app where the environment variables are consumed that takes a single string wrapped comma-separated list of environment arguments, splits on "","" and then applying the config access with a comprehension. It's a pretty hacky workaround, though. 

Let us know if you're interested in implementing the feature to support multiple environment configurations and we'll be sure to assist with the process of getting your PR reviewed, executed on CI, and merged. ",ah see mean last entry think support generating list similar unique environment submission running container probably way go interested feature would start looking within subsequent within call stack currently cursory look cover full explicit testing scenario testing reserved would validation mock environment present simple container ensure set correctly use fixture need immediate unblock suppose would write simple parser within environment single string wrapped list environment access comprehension pretty hacky though let u know interested feature support multiple environment sure assist process getting executed,issue,positive,positive,neutral,neutral,positive,positive
1594744003,"I am not sure if I understand what you mean by numberic-based configurations. However, allow me to explain it again

The problem is in docker_args for both CLI and Python API.

If I have an MLproject and Dockerfile with an entrypoint script I can run it using:
```bash
mlflow run . -A v=$(pwd):/mlflow/projects/code
```
this will run docker image speicifiec in MLproject with mounting the working directory in the host to in the /mlflow/projects/code

But how can I convert this docker command into mlflow CLI:
```bash
docker run image -v $(pwd):/mlflow/projects/code -e env_var_1=1 -e env_var_2=2
```

Now that I revise it, it's both not working in MLflow CLI and MLflow python API
```",sure understand mean however allow explain problem python script run bash run run docker image mounting working directory host convert docker command bash docker run image revise working python,issue,negative,positive,neutral,neutral,positive,positive
1594382116,Hi @harupy maybe you can have a look on this initiative since you've been working on the Github workflow in the MLflow project? Thx,hi maybe look initiative since working project,issue,negative,neutral,neutral,neutral,neutral,neutral
1593854590,I'm afraid I don't follow. Are there numeric-based configurations as cli keys for Docker? Can you provide an example of what you're trying to achieve?,afraid follow docker provide example trying achieve,issue,negative,negative,negative,negative,negative,negative
1593850034,Are you able to verify if the same behavior exists with the UI version of 2.4.1?,able verify behavior version,issue,negative,positive,positive,positive,positive,positive
1593846196,Great catch! Thank you for the investigation :) We'll gladly merge the PR once you file it. Let us know if you have any questions!,great catch thank investigation gladly merge file let u know,issue,positive,positive,positive,positive,positive,positive
1593844780,Is your proposal to create an environment variable configuration that can be set and for this warning to only issue if the flag is set to the default True value?,proposal create environment variable configuration set warning issue flag set default true value,issue,positive,positive,positive,positive,positive,positive
1593843409,I think that to make this work is going to be added a similar declaration as to what was implemented in #8687 . Assigning the mlflow-skinny dependency directly if the TEST environment key is set to strip the .dev0 suffix and decrement the micro version :) ,think make work going added similar declaration dependency directly test environment key set strip suffix decrement micro version,issue,negative,positive,neutral,neutral,positive,positive
1593842401,"Thanks, this makes a lot more sense now, let's leave this issue open until an improvement for this is added.
We should basically throw an exception, if  mlflow serve or anything similar is called within databricks and point people to Databricks Serve",thanks lot sense let leave issue open improvement added basically throw exception serve anything similar within point people serve,issue,positive,positive,neutral,neutral,positive,positive
1593795699,"@BenWilson2 I think I ""fix"" the python version issue. If I specify `env_manager=""local""` in `mlflow_run()`, the code can be run. It won't work if I leave `env_manager` blank or set it as `conda` or `virtualenv`. Have no clue why it's like this.

Below is the R code I use. I save `mlflow-master` branch in `C:\Users\username`. Sorry that I have to source each individual R file, and I realize that I have to import some packages as well.

Again I deleted the second argument `port = mlflow_connect_port() `from `mlflow_server` in `tracking-clinent.R`.

```
rm(list=ls(all=TRUE))  
setwd(""C:\\Users\\***\\mlflow\\mlflow\\R\\mlflow"")

source(""R\\cli.R"")
source(""R\\databricks-utils.R"")
source(""R\\globals.R"")
source(""R\\imports.R"")
source(""R\\logging.R"")
source(""R\\mlflow-package.R"")
source(""R\\model-crate.R"")
source(""R\\model-h2o.R"")
source(""R\\model-keras.R"")
source(""R\\model-python.R"")
source(""R\\model-registry.R"")
source(""R\\model-serve.R"")
source(""R\\model-swagger.R"")
source(""R\\model-utils.R"")
source(""R\\model-xgboost.R"")
source(""R\\model.R"")
source(""R\\project-param.R"")
source(""R\\project-run.R"")
source(""R\\project-source.R"")
source(""R\\python.R"")
source(""R\\tracking-client.R"")
source(""R\\tracking-experiments.R"")
source(""R\\tracking-globals.R"")
source(""R\\tracking-observer.R"")
source(""R\\tracking-rest.R"")
source(""R\\tracking-runs.R"")
source(""R\\tracking-server.R"")
source(""R\\tracking-ui.R"")
source(""R\\tracking-utils.R"")

library(rlang)
library(openssl)
library(purrr)
library(zeallot)
library(processx)
library(withr)
library(httr)

mlflow_run(uri = ""tests\\testthat\\examples"", entry_point = ""train.R"", env_manager=""local"")
```
The output is below, and this test is recorded in `C:\Users\***\mlflow\mlflow\R\mlflow\mlruns\0`.

```
> mlflow_run(uri = ""tests\\testthat\\examples"", entry_point = ""train.R"", env_manager=""local"")
2023/06/15 **:**:22 INFO mlflow.projects.utils: === Created directory C:\Users\***\AppData\Local\Temp\tmpklc6ax2d for downloading remote URIs passed to arguments of type 'path' ===
2023/06/15 **:**:22 INFO mlflow.projects.backend.local: === Running command 'Rscript -e ""mlflow::mlflow_source('train.R')"" --args' in run with ID 'a8d4d526ef66430e97da324a66417581' === 
[1] ""mlflow::mlflow_source('train.R')""
2023/06/15 **:**:22 INFO mlflow.projects: === Run (ID 'a8d4d526ef66430e97da324a66417581') succeeded ===
```
Before I fix the server connection issue, I may have to use local R files in order to use `mlflow` in `rstudio`. Is it possible to upload each test to `127.0.0.1:5000` server, rather than saving it here `C:\Users\***\mlflow\mlflow\R\mlflow\mlruns\0`. I believe tests that can be displayed in mlflow UI are saved here `C:\Users\***\mlruns\0`. Is it because I choose `local` as `env_manager`? Thanks.
",think fix python version issue specify local code run wo work leave blank set clue like code use save branch sorry source individual file realize import well second argument port source source source source source source source source source source source source source source source source source source source source source source source source source source source source source library library library library library library library local output test local directory remote type running command run id run id fix server connection issue may use local order use possible test server rather saving believe displayed saved choose local thanks,issue,positive,negative,neutral,neutral,negative,negative
1593769013,@chbergen so a previous version of mlflow works on your side? Do you recall the version?,previous version work side recall version,issue,negative,negative,negative,negative,negative,negative
1593719752,This is really a nice feature. Any update?,really nice feature update,issue,negative,positive,positive,positive,positive,positive
1593715868,"Sometimes, the 'delete' button appeared but once I clicked it, it showed the wrong number of selected runs. For instance, in the following screenshot, I selected 10 runs and would like to delete them, but it shows that ""2 experiment runs will be deleted."" That is very strange!

![image](https://github.com/mlflow/mlflow/assets/34941987/36a956bd-e96b-41b0-9884-5c0fb32635da)
",sometimes button wrong number selected instance following selected would like delete experiment strange image,issue,negative,negative,negative,negative,negative,negative
1593531589,"I can't add reviewers, but the PR is ready for review @BenWilson2 . Thanks!",ca add ready review thanks,issue,positive,positive,positive,positive,positive,positive
1593429385,@dbczumar @prithvikannan - Addressed all of your comments. Please take another look!,please take another look,issue,negative,neutral,neutral,neutral,neutral,neutral
1593237139,@trungn1 we have CI protections in place for new contributors. Once someone has made 'n' merged PRs this restriction is lifted. It's to protect against nefarious people triggering malicious code within CI or attempting to fill the CI queue with garbage as an act of trolling. ,place new someone made restriction protect nefarious people malicious code within fill queue garbage act trolling,issue,negative,positive,positive,positive,positive,positive
1592597980,"I'm experiencing the same timeout issue. Updated my R version latetly and re-installed mlflow to the latest version.

mlflow: 2.4.1

When trying to start from a R process I get the same 
`Error in wait_for(function() mlflow_rest(""experiments"", ""search"", client = client,  : 
  Operation failed after waiting for 10 seconds`
 error. Starting the server in terminal via ` mlflow server` works.
 
 I noticed the following:

```
> server <- mlflow::mlflow_server()
# directly after init
> server
$server_url
[1] ""http://127.0.0.1:5000""

$handle
**PROCESS 'mlflow.exe', running, pid 9888.**

$file_store
[1] ""redacted""

attr(,""class"")
[1] ""mlflow_server""

# two seconds later
> server
$server_url
[1] ""http://127.0.0.1:5000""

$handle
**PROCESS 'mlflow.exe', finished.**

$file_store
[1] ""redacted""

attr(,""class"")
[1] ""mlflow_server""
```
 The server process seems to terminate after a few seconds when called from R. 
 Previously mlflow worked seamless. ",issue version latest version trying start process get error function search client client operation waiting error starting server terminal via server work following server directly server handle process running class two later server handle process finished class server process terminate previously worked seamless,issue,negative,positive,neutral,neutral,positive,positive
1592406288,Manually confirmed the new example code works,manually confirmed new example code work,issue,negative,positive,positive,positive,positive,positive
1592281056,"> We're onboard with this change. After looking more closely at what that original PR was doing with modifying the sys.modules, we think that removing this functionality is for the best. I kicked off CI for this PR. Thanks for calling this out and for pushing a fix!

@BenWilson2 Awesome, glad we are in alignment. 

Sorry one quick question, the workflow needs approval again, if you could start it again that would be appreciated 🙏. Is this due to me force pushing onto my branch or is it due to any type of change in general to the PR (for first time contributor)?",change looking closely original think removing functionality best thanks calling pushing fix awesome glad alignment sorry one quick question need approval could start would due force pushing onto branch due type change general first time contributor,issue,positive,positive,positive,positive,positive,positive
1592250786,"One difficulty I find in the UI is it only loading 100 runs at a time. The charts in ""Chart View"" are only initially representative of a small portion of the dataset. One has to repeatedly click ""load more"" to see the charts fill out. It would be nice to be able to load all trials, or at least a larger number at once.

Another improvement would be if the Charts built in ""Chart View"" were persistent. As well as transferable to other experiments, since often I'm always building the same charts repeatedly.

Anyway, hope these recommendations are helpful. I enjoy using MLFlow, keep up the good work.",one difficulty find loading time chart view initially representative small portion one repeatedly click load see fill would nice able load least number another improvement would built chart view persistent well transferable since often always building repeatedly anyway hope helpful enjoy keep good work,issue,positive,positive,positive,positive,positive,positive
1592164911,"Hi @C-K-Loan unfortunately, no, this isn't designed to work. Sorry for the cryptic stacktrace here and if this wasted time on your end. We'll add a better guard here to alert users that model serving on Databricks is done through Databricks serving (which does not use the OSS serving implementation)",hi unfortunately designed work sorry cryptic wasted time end add better guard alert model serving done serving use serving implementation,issue,negative,negative,negative,negative,negative,negative
1592111613,Applied the `only-latest` label to avoid running too many transformers tests to save github action runners.,applied label avoid running many save action,issue,negative,positive,positive,positive,positive,positive
1591997331,"@BenWilson2 Thanks. I dipped into R code of mlflow in `C:\*****\mlflow\mlflow\R\mlflow\R` (downloaded from master branch). It seems that the connectivity issue is due to `port`. To me, the default url is `http://127.0.0.1:5000` with `port=5000`. In my test, port is not generated from `mlflow_connect_port` in `tracking-server.R`. Then `port=NULL` is feed into `mlflow_server` in in `tracking-client.R`. Even though port is pre-defined as 5000, it's still feed as `NULL` in the following steps. Thus `http://127.0.0.1:` is returned as `server_url`.

I deleted the second argument (`port = mlflow_connect_port()`) from `mlflow_server` in `tracking-clinent.R` as `local_server <- mlflow_server(file_store = path)`. I can run command in rstudio. I tested ""`mlflow_set_experiment(""Test123"")`"", then a new experiment named ""Test123"" appears in mlflow UI, and the message is `Experiment ""Test123"" does not exist, Creating a new experiment` in studio Console. So I believe the connectivity issue has been manually solved. Please take a look, and fix it if it's bug.

However, I tried to run mlflow_run(url=""***"", entry_point=""***.R""). Error is reported and it seems that experiment ID cannot be found and mlflow.exe failed.

```
mlflow.exceptions.MlflowException: Could not find experiment with ID 167264212467071495
Error in `run(mlflow_bin, args = unlist(args), echo = echo, echo_cmd = verbose, …` at cli.R:45:7:
! System command 'mlflow.exe' failed
---
Exit status: 1
stdout & stderr: <printed>
---
Type .Last.error to see the more details.
Called from: base::stop(cond)
```

So what is an experiment and what is a run? As you know I can run mlflow using python. I queried mlflow server and tested different cases from example folder. It seems only one experiment (""Default"", and experiment ID=0?) has been created and each test was a run as shown in UI.

################################
The above issue is fixed. What I'm currently facing is a python env issue. I run this command in rstudio,
`mlflow_run(uri = ""C:\\Users\\***\\mlflow\\mlflow\\R\\mlflow\\tests\\testthat"", entry_point = ""test-model.R"")`

python 3.10.9 is installed on my machine. But still enounter an issue as below
```
INFO mlflow.utils.virtualenv: Installing python 3.10.9 if it does not exist
'pyenv' is not recognized as an internal or external command,
operable program or batch file.

*********

mlflow.utils.process.ShellCommandException: Non-zero exit code: 1
Command: ['pyenv', 'install', '3.10.9']
Error in `run(mlflow_bin, args = unlist(args), echo = echo, echo_cmd = verbose, …` at cli.R:40:7:
! System command 'mlflow.exe' failed
---
Exit status: 1
stdout & stderr: <printed>
---
Type .Last.error to see the more details.
```
",thanks dipped code master branch connectivity issue due port default test port feed even though port still feed null following thus returned second argument port path run command tested test new experiment test message experiment test exist new experiment studio console believe connectivity issue manually please take look fix bug however tried run error experiment id found could find experiment id error run unlist echo echo verbose system command exit status printed type see base cond experiment run know run python server tested different example folder one experiment default experiment test run shown issue fixed currently facing python issue run command python machine still issue python exist internal external command operable program batch file exit code command error run unlist echo echo verbose system command exit status printed type see,issue,negative,negative,neutral,neutral,negative,negative
1591945863,"My previous comment had the correct instruction set for R. You're using the 1.x install process (which was deprecated ~ 2 years ago and was removed in MLflow 2.x). install_mlflow() does not work anymore. 

Please just do the `install.packages(""mlflow"")` and `library(mlflow)`. If you're following the RStudio guide for MLflow, that is very outdated and is not maintained by us.

",previous comment correct instruction set install process ago removed work please library following guide outdated u,issue,negative,negative,negative,negative,negative,negative
1591679803,"@harupy the code within R should presumably remain as a POST request - I imagine the issue is the implementation of the API itself: the request and response structure for searching both registered models, and [model versions](https://mlflow.org/docs/latest/rest-api.html#search-modelversions) are the same as the (working) API for searching runs and experiments, but require a GET method - instead of a POST method as for runs and experiments. 

Internally to R at least, the arguments for the search methods (`filter = ...` etc) aren't actually used in a GET request. It could be the case that the API for searching registered models and model versions was simply instantiated as GET requests incorrectly.

If it should indeed still be a POST request, I think all potentially all you need to do is change the method in the proto script that defines the server - [here](https://github.com/mlflow/mlflow/blob/826ccc29a78e46421407211dde57aaffe867987b/mlflow/protos/model_registry.proto#L80) for searching registered models, and [here](https://github.com/mlflow/mlflow/blob/826ccc29a78e46421407211dde57aaffe867987b/mlflow/protos/model_registry.proto#LL168C16-L168C16) for searching model versions",code within presumably remain post request imagine issue implementation request response structure searching registered model working searching require get method instead post method internally least search filter actually used get request could case searching registered model simply get incorrectly indeed still post request think potentially need change method proto script server searching registered searching model,issue,negative,negative,neutral,neutral,negative,negative
1591611846,"I saw a demo by databricks of an MLFlow workflow. Webhooks are implemented now. But only for the databricks distro of MLFlow. Sadly, we're not looking to start using another vendor so this is not of use to our group. 

If the features are only available in the vendor-hosted version, you certainly increase vendor lock-in to Databricks if you start to rely on webhooks :/

At that point, I think you'd have to treat Databricks as just another vendor, and consider *all* the possible model registry vendors (ClearML, WandB, etc.)",saw sadly looking start another vendor use group available version certainly increase vendor start rely point think treat another vendor consider possible model registry,issue,positive,positive,neutral,neutral,positive,positive
1591477331,"@BenWilson2 Thanks. I didn't make it clear. I can use mlflow using python. What I want is to use mlflow to handle R code. While I just cannot run it using R from Rstudio.  Below are the output of installing, calling and running mlfow on my machine.

#########################################
```
> install.packages(""mlflow"")
WARNING: Rtools is required to build R packages but is not currently installed. Please download and install the appropriate version of Rtools before proceeding:

https://cran.rstudio.com/bin/windows/Rtools/
Installing package into ‘C:/*****/AppData/Local/R/win-library/4.3’
(as ‘lib’ is unspecified)

  There is a binary version available but the source version is later:
       binary source needs_compilation
mlflow  2.3.2  2.4.1             FALSE

installing the source package ‘mlflow’

trying URL 'https://cran.rstudio.com/src/contrib/mlflow_2.4.1.tar.gz'
Content type 'application/x-gzip' length 638160 bytes (623 KB)
downloaded 623 KB

* installing *source* package 'mlflow' ...
** package 'mlflow' successfully unpacked and MD5 sums checked
** using staged installation
** R
** byte-compile and prepare package for lazy loading
** help
*** installing help indices
** building package indices
** testing if installed package can be loaded from temporary location
** testing if installed package can be loaded from final location
** testing if installed package keeps a record of temporary installation path
* DONE (mlflow)

The downloaded source packages are in
	‘C:\*****\AppData\Local\Temp\RtmpIlcxMz\downloaded_packages’
```
#########################################
```
> mlflow::install_mlflow()
Error: 'install_mlflow' is not an exported object from 'namespace:mlflow'
```
#########################################
```
> mlflow_set_experiment(""Test"")
Error in wait_for(function() mlflow_rest(""experiments"", ""search"", client = client,  : 
  Operation failed after waiting for 10 seconds
```
#########################################

```
> sessionInfo()
R version 4.3.0 (2023-04-21 ucrt)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 11 x64 (build 22621)

Matrix products: default


locale:
[1] LC_COLLATE=English_United States.utf8  LC_CTYPE=English_United States.utf8    LC_MONETARY=English_United States.utf8
[4] LC_NUMERIC=C                           LC_TIME=English_United States.utf8    

time zone: *****
tzcode source: internal

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] mlflow_2.4.1

loaded via a namespace (and not attached):
 [1] later_1.3.1      R6_2.5.1         base64enc_0.1-3  httpuv_1.6.11    swagger_3.33.1   magrittr_2.0.3   ini_0.3.1       
 [8] lifecycle_1.0.3  ps_1.7.5         promises_1.2.0.1 cli_3.6.1        processx_3.8.1   askpass_1.1      openssl_2.0.6   
[15] forge_0.2.0      vctrs_0.6.2      zeallot_0.1.0    withr_2.5.0      compiler_4.3.0   httr_1.4.6       purrr_1.0.1     
[22] rstudioapi_0.14  tools_4.3.0      yaml_2.3.7       Rcpp_1.0.10      rlang_1.1.1      jsonlite_1.8.5 
```
#########################################
Again, I guess it's still a connectivity issue, (connection cannot be setup inside R). Still struggle with this bug.",thanks make clear use python want use handle code run output calling running machine warning build currently please install appropriate version proceeding package unspecified binary version available source version later binary source false source package trying content type length source package package successfully unpacked checked staged installation prepare package lazy loading help help index building package index testing package loaded temporary location testing package loaded final location testing package record temporary installation path done source error object test error function search client client operation waiting version platform running build matrix default locale time zone source internal attached base graphic base attached loaded via attached guess still connectivity issue connection setup inside still struggle bug,issue,positive,negative,neutral,neutral,negative,negative
1591393143,"We're onboard with this change. After looking more closely at what that original PR was doing with modifying the sys.modules, we think that removing this functionality is for the best. I kicked off CI for this PR. Thanks for calling this out and for pushing a fix!",change looking closely original think removing functionality best thanks calling pushing fix,issue,positive,positive,positive,positive,positive,positive
1591368740,"Awesome! MLflow is working perfectly on your system. Great work on getting everything working :) 

The next things to do within RStudio are to run:

### Install the CRAN library
`install.packages(""mlflow"")`

### make the CRAN library available to your session
`library(mlflow)`

Hopefully that gets you up and running!",awesome working perfectly system great work getting everything working next within run install cran library make cran library available session library hopefully running,issue,positive,positive,positive,positive,positive,positive
1591089890,"I added a test, but I still do think that no method of this kind is 100% suitable. Every loop depends on some nondeterministic behavior. In my opinion, the test case I have built is enough to generate this error at least a few times using the old version of set_tag(). I ran the test a couple of times and never came across a fail using this code. Please let me know what you think.

Also, excuse me for the double sign-off... For some reason GitHub was showing I was missing one, and when I added it then suddenly the 1st one appeared too. Can't really tell what happened here, sorry :(",added test still think method kind suitable every loop behavior opinion test case built enough generate error least time old version ran test couple time never came across fail code please let know think also excuse double reason showing missing one added suddenly st one ca really tell sorry,issue,positive,negative,neutral,neutral,negative,negative
1591060188,"Hi there, thanks for the hard work!
Any updates on this PR and the support of `gensim` models would be greatly appreciated 😃 
Cheers",hi thanks hard work support would greatly,issue,positive,positive,positive,positive,positive,positive
1590619071,"Perfect! That would actually help a lot, thanks for the link.",perfect would actually help lot thanks link,issue,positive,positive,positive,positive,positive,positive
1590524522,"@BenWilson2 I think I figured out how to create simple curl command. After query to mlflow server from command prompt, I can access to mlflow UI. I open another command prompt, and run some commands. I run `sklearn_elasticnet_wine/train.py` and then `search max_results`, then run `sklearn_logistic_regression/train.py` and then search `max_results` again.

![curl](https://github.com/mlflow/mlflow/assets/44675194/9b50d264-e07e-4dec-aa06-116a3f8427e9)

The two runs can be displayed on UI and I can access to server from command prompt.
#################################################
However, I have no idea how I can rule out the connection issue from rstudio. Could you give me some hints? Thanks.",think figured create simple curl command query server command prompt access open another command prompt run run search run search curl two displayed access server command prompt however idea rule connection issue could give thanks,issue,positive,positive,neutral,neutral,positive,positive
1590344689,"@BenWilson2 Thank you. Again I'm new. I have gone through this page for REST API https://mlflow.org/docs/latest/rest-api.html and did some try (like get experiment), but cannot figure out what's the right command to use. Could you please give me some example to follow?

Thanks for explaining the version issue. It's good now on my side.",thank new gone page rest try like get experiment figure right command use could please give example follow thanks explaining version issue good side,issue,positive,positive,positive,positive,positive,positive
1590331374,"Yep! Totally expected. If you close the shell, you're killing the process that's running the UI server :D 
After you start it again, can you open another command prompt and issue some curl commands (or whatever the windows equivalent to that is) for some of the MLflow REST APIs to the running tracking server, that should rule out any issues.

As to the installation... it looks like you're installing the dev branch. Did you fork the repo and install from local? 
2.4.2.dev0 is the current master branch of MLflow (in active development). Our last release was 4 days ago. https://github.com/mlflow/mlflow/releases 2.4.1. I promise.

Try installing mlflow from a standard pip install (don't install master if you actually want to contribute to MLflow - it's not what you want for actually USING MLflow) and make sure that you have version 2.4.1 installed after the command is issued.",yep totally close shell killing process running server start open another command prompt issue curl whatever equivalent rest running server rule installation like dev branch fork install local dev current master branch active development last release day ago promise try standard pip install install master actually want contribute want actually make sure version command,issue,positive,positive,neutral,neutral,positive,positive
1590321450,"@BenWilson2 I'm new to package things, and not sure if I'm answering your questions. I can run ""mlflow server"" in windows command prompt. And this is the return, ""INFO:waitress:Serving on http://127.0.0.1:5000"". The link  can direct me to mlflow UI.

However, after I close the command prompt, I lose access to mlflow UI. (is it normal?)

![mlflow page](https://github.com/mlflow/mlflow/assets/44675194/db587304-6b59-43b2-a7ff-6fcf258404b4)

Let me know if I'm not answering  your question.

####################################
As to the version issue, I think 2.4.2 was released for a while. I have two machines both using windows. And I run code both of them. Below is the prompt context when I uninstall mlflow from one of my machines. But my return is from mlflow 2.3.2.

![mlflow2 4 2](https://github.com/mlflow/mlflow/assets/44675194/5725e8ba-c46f-4108-a8ec-66812d098e84)

",new package sure run server command prompt return waitress serving link direct however close command prompt lose access normal page let know question version issue think two run code prompt context one return,issue,negative,positive,positive,positive,positive,positive
1590276634,Can you query the MLflow server from the python APIs or directly from bash/zsh?,query server python directly,issue,negative,positive,neutral,neutral,positive,positive
1590259484,"I dip into R code. Error raised from `wait_for` in `traching-server.R`. And `mlflow_rest` is defined in `tracking-rest.R`. `client`, `host_creds`, `rest_config`, `api_url`, and `req_headers` are expressed below.

```
> client
$get_host_creds
function () {
    new_mlflow_host_creds(host = server_url)
  }
<bytecode: 0x0000014ee2321300>
<environment: 0x0000014ee1f62920>

$get_cli_env
function (...)  .Primitive(""list"")

attr(,""class"")
[1] ""mlflow_file_client"" ""mlflow_client"" 
```
################################################
```
> host_creds
mlflow_host_creds( host = http://127.0.0.1:5688, insecure = False)
```
################################################
```
> rest_config
$headers
$headers$`User-Agent`
[1] ""mlflow-r-client/2.3.2""


$config
list()
```
################################################
```
> api_url
[1] ""http://127.0.0.1:5688/api/2.0/mlflow/experiments/search""
```
################################################
```
> req_headers
<request>
Headers:
* User-Agent: mlflow-r-client/2.3.2
```
################################################
```
>  response <- get_response()
Error in curl::curl_fetch_memory(url, handle = handle) : 
  Failed to connect to 127.0.0.1 port 5688: Connection refused
Called from: curl::curl_fetch_memory(url, handle = handle)
```
So it seems a connection issue, failing to connect to 127.0.0.1 port 5688. Can anyone provide some ideas to fix this issue? Thanks.",dip code error raised defined client expressed client function host environment function list class host insecure false list request response error curl handle handle connect port connection curl handle handle connection issue failing connect port anyone provide fix issue thanks,issue,negative,negative,negative,negative,negative,negative
1590255464,"> Cool! Glad to see the integration :)

Thank you for the fast approval, Ben!",cool glad see integration thank fast approval ben,issue,positive,positive,positive,positive,positive,positive
1590253172,"@BenWilson2 I double-checked, mlflow version is 2.3.2. I guess it's a typo. But I copy & paste everything here. Odd!",version guess typo copy paste everything odd,issue,negative,negative,negative,negative,negative,negative
1590201751,"odd that's it's showing an unreleased version of mlflow (2.4.2). We just released 2.4.1 a few days ago. 
CRAN is showing the correct version as well: https://cran.r-project.org/web/packages/mlflow/index.html 
We'll look into this.",odd showing unreleased version day ago cran showing correct version well look,issue,negative,negative,negative,negative,negative,negative
1590197609,Makes sense. Potential test instability. ,sense potential test instability,issue,negative,neutral,neutral,neutral,neutral,neutral
1590192822,"For example, the python leaves the following files:

```
confusion_matrix_image.png
sample-file-to-write
some_path/ac998dee8787477891c604928edb335f/artifacts/test.txt
some_tracking_uri/0/meta.yaml
test_artifacts_root/faee23a36ef2[45](https://github.com/mlflow/mlflow/actions/runs/5256005072/jobs/9496685013?pr=8717#step:10:47)[46](https://github.com/mlflow/mlflow/actions/runs/5256005072/jobs/9496685013?pr=8717#step:10:48)b38fa36990e6e9f2/artifacts/test.txt
```

https://github.com/mlflow/mlflow/actions/runs/5256005072/jobs/9496685013?pr=8717

Those files are annoying, might affects other tests, and should be cleaned up or created in a `tmp_path`.",example python leaf following annoying might,issue,negative,negative,negative,negative,negative,negative
1590149362,"@BenWilson2 

> Are we worried that an automated commit process will include them in a commit?

Thanks for the comment, can you elaborate?",worried commit process include commit thanks comment elaborate,issue,positive,positive,positive,positive,positive,positive
1590053558,Do these files get cached between CI runs? Are we worried that an automated commit process will include them in a commit?,get worried commit process include commit,issue,negative,neutral,neutral,neutral,neutral,neutral
1590034193,@BenWilson2 @dbczumar @harupy I'm a first time contributor - could I get an approval to run your workflow on this PR? Please and thank you!,first time contributor could get approval run please thank,issue,positive,positive,positive,positive,positive,positive
1589767064,I think that a test that validates your offline test will be sufficient to validate that we're not getting schema constraint exceptions with concurrent writes from subprocesses.,think test test sufficient validate getting schema constraint concurrent,issue,negative,neutral,neutral,neutral,neutral,neutral
1589749607,"Hi @demorozov-deloitte, I've just taken your repro code and attempted to produce the error, but I can't seem to cause any issues. 

Please verify that this is the exact order of events that you've done:

1. Start Mlflow server locally

```shell
mlflow server --default-artifact-root file:///Users/.../tmp/demo --backend-store-uri file:///Users/.../tmp/backend
```

2. Define the tracking uri and run an autologging session with sklearn (your code):
```python
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
import mlflow
import numpy as np


URI = ""http://127.0.0.1:5000""
mlflow.set_tracking_uri(URI)
mlflow.sklearn.autolog()

mlflow.set_experiment(""lin-alg-1"")
params = {""fit_intercept"": True, ""positive"":True}

X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])
y = np.dot(X, np.array([1, 2])) + 3

model = LinearRegression(**params)
model.fit(X, y)

X_test = np.array([[2, 5], [1, 1]])
y_test = np.dot(X_test, np.array([1, 2])) + 3
y_pred = model.predict(X_test)

mse = mean_squared_error(y_test, y_pred)
mlflow.log_params(params)
mlflow.log_metrics({""mse"": mean_squared_error(y_test, y_pred)})
```

3. Execute the cell in Jupyter 100 times.

```python
client.get_run(run_id=""a769512859704c49a6dd122cde8b42d2"").info
```
```shell
<RunInfo: artifact_uri='file:///Users/.../tmp/demo/642378397189917133/a769512859704c49a6dd122cde8b42d2/artifacts', end_time=None, experiment_id='642378397189917133', lifecycle_stage='active', run_id='a769512859704c49a6dd122cde8b42d2', run_name='unique-fawn-809', run_uuid='a769512859704c49a6dd122cde8b42d2', start_time=1686675993091, status='RUNNING', user_id='...'>
```

That being said, all of this is writing to the exact same run_id. I'm sure that's not what you're intending to do. It's recommended to create a run context so that the active run is terminated each time you've finished logging to it. 

For example: 

```python
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
import mlflow
import numpy as np

URI = ""http://127.0.0.1:5000""
mlflow.set_tracking_uri(URI)
mlflow.sklearn.autolog()

mlflow.set_experiment(""lin-alg-2"")

with mlflow.start_run():
    params = {""fit_intercept"": True, ""positive"":True}

    X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])
    y = np.dot(X, np.array([1, 2])) + 3

    model = LinearRegression(**params)
    model.fit(X, y)

    X_test = np.array([[2, 5], [1, 1]])
    y_test = np.dot(X_test, np.array([1, 2])) + 3
    y_pred = model.predict(X_test)

    mse = mean_squared_error(y_test, y_pred)
    mlflow.log_metric(""mse"", mse)
```
After executing that cell 21 times, I get no connection errors. 
```python 
experiment = client.get_experiment_by_name(""lin-alg-2"")
runs = client.search_runs(experiment_ids=[experiment.experiment_id])
runs[-1].data.params
```
```shell
{'positive': 'True',
 'copy_X': 'True',
 'fit_intercept': 'True',
 'n_jobs': 'None'}
```
```python
runs[-1].data.metrics
```
```shell
{'training_score': 1.0,
 'training_root_mean_squared_error': 0.0,
 'training_r2_score': 1.0,
 'mse': 0.0,
 'training_mean_absolute_error': 0.0,
 'training_mean_squared_error': 0.0,
 'mean_squared_error_X_test': 0.0}
```


I haven't seen an issue raised. Can you try restarting your computer to ensure that this isn't a port allocation issue or that there are zombie processes running on your system that are causing the requests library to struggle to attain a thread to use for the client-to-server communication? 

",hi taken code produce error ca seem cause please verify exact order done start server locally shell server file file define run session code python import import import import true positive true model execute cell time python shell said writing exact sure intending create run context active run time finished logging example python import import import import true positive true model cell time get connection python experiment shell python shell seen issue raised try computer ensure port allocation issue zombie running system causing library struggle attain thread use communication,issue,positive,positive,positive,positive,positive,positive
1589557191,"We have the same use case described by the OP. Basically we want to insert a model into a custom microservice, but cannot depend on the Model Registry when the microservice starts (not even once) because it is an operational endpoint (not informational/analytical) , so it is not possible to fetch the model from the Model Registry when starting the microservice. However, it is be fine to read from the Model Registry and get a tar.gz from within the Dockerfile, at *container creation time*, in the `ADD` command, as mentioned by the OP.

So yes, this would definitely be a nice feature.",use case basically want insert model custom depend model registry even operational possible fetch model model registry starting however fine read model registry get within container creation time add command yes would definitely nice feature,issue,positive,positive,positive,positive,positive,positive
1589543124,"> What those tests may end up looking like is entirely up to how you formulate them to meet the requirement of ensuring consistent current behavior

Current behavior is inconsistent because of the probabilistic nature of this situation. Running multiple processes is not disallowed. However, it produces errors, which should not happen theoretically. 
What I wanted to introduce is to give a choice. If someone wants to run concurrent processes and set tags, then unfortunately it is not entirely possible to determine which tag will be set as the last one. This is already better than what is currently available. 
However, If the nondeterministic outcome was to be changed, then an entirely different solution needs to be developed, maybe some queue or other type of handling tags setting. 

> and enabling a fix to the use case that you're attempting to solve with the change.

Yeah, this just fixes the unwanted behavior of getting a duplicate key error, when you should just be overwriting the tag. If someone decides to run multiple processes at once then the drawbacks should be considered, however one should not be disallowed to do so.

I will try to come up with some tests, but I would be truly grateful if we could agree on what should be the desired path to take here.

",may end looking like entirely formulate meet requirement consistent current behavior current behavior inconsistent probabilistic nature situation running multiple however happen theoretically introduce give choice someone run concurrent set unfortunately entirely possible determine tag set last one already better currently available however outcome entirely different solution need maybe queue type handling setting fix use case solve change yeah unwanted behavior getting duplicate key error tag someone run multiple considered however one try come would truly grateful could agree desired path take,issue,positive,positive,neutral,neutral,positive,positive
1589515760,"Yep, acknowledged. We have the default experiment as a 'catch all' safe fallback location so that runs are not 'lost to the ether' or are written to randomly generated experiments if an experiment is not specified. 
We don't have a clear roadmap plan for solving this dilemma, unfortunately. 
As for the gc errors that you're getting, the PR from @PenHsuanWang was merged yesterday and will be part of the next minor release: #8498 so that you won't be suffering through those errors any longer. ",yep acknowledged default experiment safe fallback location ether written randomly experiment clear plan dilemma unfortunately getting yesterday part next minor release wo suffering longer,issue,negative,negative,neutral,neutral,negative,negative
1589499451,"I don't think that you're going to get the behavior out of trying to run just 2 concurrent writes of a single tag. You'll need to simulate the behavior that you're trying to enable with the change in your PR to validate that it behaves as expected, that there aren't any regressions with current behavior, and that there is some semblance of deterministic behavior. 
What those tests may end up looking like is entirely up to how you formulate them to meet the requirement of ensuring consistent current behavior and enabling a fix to the use case that you're attempting to solve with the change. 
We just like to be careful with core logic changes to how the tracking service behaves :) ",think going get behavior trying run concurrent single tag need simulate behavior trying enable change validate current behavior semblance deterministic behavior may end looking like entirely formulate meet requirement consistent current behavior fix use case solve change like careful core logic service,issue,positive,positive,neutral,neutral,positive,positive
1588703982,"Hi @BenWilson2, excuse me if this might be obvious. However, I'd like to make sure I understand correctly. 

> a) disparate tags to the same run

In this case, we want to try setting 2 different tags with 2 different keys using concurrent writes.
>b) conflicting tags to the same run

In this case, we want to try setting 2 different tags with the same key using concurrent writes.

In test case A we should get 2 tags with 2 keys, and in test case B we should get one of the 2 as the “final” one, do I understand correctly?

 If that is true, then I am uncertain if creating an automatic test is really possible, as I believe making 2 processes write at the exact same time is not so easily reproducible. This is why the manual test looks like it does, it needs many iterations to finally land that one time at the same time. That is also why the _set_tags() method is ALMOST thread safe, as there is still some very low probability of 3 failed operations one after another.

If you run the old set_tag() method 2 times with the same key, but different values, then it just gets overwritten. If that logic should be kept then if 2 concurrent processes try to do it we should expect one of them to be the final one, however we cannot tell which one.",hi excuse might obvious however like make sure understand correctly disparate run case want try setting different different concurrent conflicting run case want try setting different key concurrent test case get test case get one final one understand correctly true uncertain automatic test really possible believe making write exact time easily reproducible manual test like need many finally land one time time also method almost thread safe still low probability one another run old method time key different logic kept concurrent try expect one final one however tell one,issue,positive,positive,positive,positive,positive,positive
1588543598,"@BenWilson2 Thanks for the reply. I have actually used the import tool before and it is quite handy, but I don't believe it solves the problem.  
I regularly use `gc` from the mlflow cli. If there are runs in the default experiment (with nonexistent S3 bucket as an artifact store) I dont think I can permanently delete them. The command will end with boto3 error message `botocore.errorfactory.NoSuchBucket: An error occurred (NoSuchBucket) when calling the ListObjects operation: The specified bucket does not exist`. I can export all of these runs from default experiment and import them somewhere else, but it seems like an extra step (and with extra tool). I can go back to manually deleting artifacts from S3 and metadata from backend database, which I would rather avoid, but it is my only option at the moment.  
The whole problem could be probably restated even as follows - _delete runs/experiments from mlflow that had their S3 artifact storage deleted_. This is not problem for regular runs/experiments, since I can export them and import them and change the artifact storage, however the default experiment and its runs will just always be there.",thanks reply actually used import tool quite handy believe problem regularly use default experiment nonexistent bucket artifact store dont think permanently delete command end error message error calling operation bucket exist export default experiment import somewhere else like extra step extra tool go back manually would rather avoid option moment whole problem could probably even artifact storage problem regular since export import change artifact storage however default experiment always,issue,negative,positive,positive,positive,positive,positive
1588288911,Can you try this with MLflow 1.30.x and see if this issue still presents itself? Thank you!,try see issue still thank,issue,negative,neutral,neutral,neutral,neutral,neutral
1588261931,Thank you for reporting. We'll be sure to provide a fix for this.,thank sure provide fix,issue,positive,positive,positive,positive,positive,positive
1588260249,"There is an import/export tool that is here: https://github.com/mlflow/mlflow-export-import that is probably what you're looking for. We don't have any plans to enable core functionality within MLflow to migrate runs from one experiment to another. 
Let us know if this works for you :) Thanks for using MLflow!",tool probably looking enable core functionality within migrate one experiment another let u know work thanks,issue,negative,positive,positive,positive,positive,positive
1588245934,"Hi @szczesniak-piotr could you add a test that validates this using concurrent writes from separate processes that are attempting to set:
a) disparate tags to the same run
b) conflicting tags to the same run
and ensure that the behavior is as expected?",hi could add test concurrent separate set disparate run conflicting run ensure behavior,issue,negative,neutral,neutral,neutral,neutral,neutral
1587937412,"> Now that 2.4.1 is released, can I merge this in and update pyfunc in a follow-up PR? @dbczumar

Instead of `**kwargs`, can we introduce a parameter called `parameters` of type `dict` to `predict()`? This way, if we ever need to add other keyword arguments to `mlflow.pyfunc.predict()`, they won't conflict with these parameters.

Otherwise, I think we're almost ready once the Databricks Inference team approves the design.

cc also @BenWilson2 ",merge update instead introduce parameter type predict way ever need add wo conflict otherwise think almost ready inference team design also,issue,negative,positive,positive,positive,positive,positive
1587890115,"That's good news! I will do further research and if I find anything, I'll let you know.",good news research find anything let know,issue,negative,positive,positive,positive,positive,positive
1587879613,"The 2.4.1 release included #8648  as a fix for the reported LFI vulnerability. Are there outstanding issues that this branch's changes don't address? (If so, please detail them to us in the maintainers address)",release included fix vulnerability outstanding branch address please detail u address,issue,positive,positive,positive,positive,positive,positive
1587652031,"Same issue here:
- Clicking on the un-expanded parent in MLFlow tracking UI does not select its children (we need to first expand all parent runs by clicking on '+', then when selecting the parent the children are also selected). But this requires expanding all parents until one sees all the children nodes to select all the parent + children.

![Screenshot 2023-06-12 at 17 13 32](https://github.com/mlflow/mlflow/assets/22479356/e83343a8-5c6b-4999-92e5-f3cf7894c4ac)

![Screenshot 2023-06-12 at 17 13 41](https://github.com/mlflow/mlflow/assets/22479356/dd6a2bf8-7650-42b7-9874-a138f06c2327)

",issue parent select need first expand parent parent also selected expanding one select parent,issue,negative,positive,positive,positive,positive,positive
1587563755,@rohanicad can you try with the latest MLflow release? Some changes have been made to artifact serialization that may affect your error. ,try latest release made artifact serialization may affect error,issue,negative,positive,positive,positive,positive,positive
1587226654,"@dmatrix bump on this - any openness to this (I'm happy to implement if so)? Alternative as a user I'd also be fine with going directly to the aritfact repository - but as per for example https://github.com/mlflow/mlflow/blob/312f5f9f46f4ca4da6e0bf594bb7c23bbec4dbd2/mlflow/store/artifact/local_artifact_repo.py#LL114 it seems `delete_artifacts` is designed specifically to delete directories, not individual files. Would be open to changing this to support individual files too",bump openness happy implement alternative user also fine going directly repository per example designed specifically delete individual would open support individual,issue,positive,positive,positive,positive,positive,positive
1586637161,"@gabrielfu Thanks for the comment, we could add a CLI **if there is a request** :) Starting without a CLI is probably ok.",thanks comment could add request starting without probably,issue,negative,positive,neutral,neutral,positive,positive
1586621858,"Will we also add a CLI command to manage the credentials? So that users don't need to create / edit the file themselves. E.g., like the aws cli `aws configure`.",also add command manage need create edit file like configure,issue,positive,neutral,neutral,neutral,neutral,neutral
1586616441,Rebased on master to include recent updates from master.,master include recent master,issue,negative,neutral,neutral,neutral,neutral,neutral
1586602528,Let's rebase this branch on master periodically to minimize conflicts. ,let rebase branch master periodically minimize,issue,negative,neutral,neutral,neutral,neutral,neutral
1586561269,The version pinning issue is a separate issue. Merging this PR.,version pinning issue separate issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1586559185,"@harupy  
I manually updated the `requirements.txt` with `mlflow==2.4.1`  and then tried to serve it after removing the old venv so it will build a new one. 

Now it works fine, so that really is the fix
![image](https://github.com/mlflow/mlflow/assets/18140070/a99a3360-c7f2-439a-bafb-902d732614e1)
",manually tried serve removing old build new one work fine really fix image,issue,negative,positive,positive,positive,positive,positive
1586552647,"@harupy  I just tested it with Pandas. 

if you do `pip install pandas==1.5` it will install `pandas==1.5.0` and not the latest `pandas==1.5.3`. 

So this looks like a bug in mlflow I think.

The change in this PR is super safe and cannot break anything. 
I think we really need to merge it",tested pip install install latest like bug think change super safe break anything think really need merge,issue,positive,positive,positive,positive,positive,positive
1586548694,"Maybe it's a bug/feature in pip?  Maybe specific to some pip version?
I would have also expected it to install 2.4.1, but it does not do that for some reason",maybe pip maybe specific pip version would also install reason,issue,negative,neutral,neutral,neutral,neutral,neutral
1586546388,"@harupy  Mlflow version pinning is generated by  [_generate_mlflow_version_pinning()](https://github.com/mlflow/mlflow/blob/a6915464e615640bede9fcc20e4d2221ef0d15ab/mlflow/utils/environment.py#L457)  which does not log the `micro` aka `patch` version of mlflow.

it just logs 2.4, but not 2.4.1 ",version pinning log micro aka patch version,issue,negative,neutral,neutral,neutral,neutral,neutral
1586544994,"@harupy  the requirements.txt even shows mlflow==2.4 you can see pip resolves that to mlflow 2.4.0 and not to mlflow 2.4.1

![image](https://github.com/mlflow/mlflow/assets/18140070/d40edb00-4b5e-4147-96bf-62b6cca4bcbe)

![image](https://github.com/mlflow/mlflow/assets/18140070/315f803f-7759-466d-a36a-abbe7e67d2d4)
",even see pip image image,issue,negative,neutral,neutral,neutral,neutral,neutral
1586540595,"@harupy  
I just ran a completely fresh colab noteobok. 

1. Before running serve command
`! pip list  | grep flow`  gives 
`mlflow                        2.4.1` 


2. After exporting a model I try serve 
`! mlflow models serve -m my_mlflow_model --port 5001` 
returns : 

```bash
2023/06/12 03:54:08 INFO mlflow.models.flavor_backend_registry: Selected backend for flavor 'python_function'
2023/06/12 03:54:08 INFO mlflow.utils.virtualenv: Installing python 3.10.12 if it does not exist
Downloading Python-3.10.12.tar.xz...
-> https://www.python.org/ftp/python/3.10.12/Python-3.10.12.tar.xz
Installing Python-3.10.12...
Installed Python-3.10.12 to /root/.pyenv/versions/3.10.12
2023/06/12 03:59:25 INFO mlflow.utils.virtualenv: Creating a new environment in /root/.mlflow/envs/mlflow-de25317bfd3a5ca1670a4a4d068c3b3e722a361b with /root/.pyenv/versions/3.10.12/bin/python
created virtual environment CPython3.10.12.final.0-64 in 1905ms
  creator CPython3Posix(dest=/root/.mlflow/envs/mlflow-de25317bfd3a5ca1670a4a4d068c3b3e722a361b, clear=False, no_vcs_ignore=False, global=False)
  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/root/.local/share/virtualenv)
    added seed packages: pip==23.1.2, setuptools==67.7.2, wheel==0.40.0
  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator
2023/06/12 03:59:28 INFO mlflow.utils.virtualenv: Installing dependencies
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 446.0/446.0 kB 19.6 MB/s eta 0:00:00
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 18.1/18.1 MB 41.6 MB/s eta 0:00:00
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 84.4/84.4 kB 8.6 MB/s eta 0:00:00
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.1/12.1 MB 52.8 MB/s eta 0:00:00
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 96.6/96.6 kB 10.1 MB/s eta 0:00:00
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 682.2/682.2 kB 16.2 MB/s eta 0:00:00
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 304.5/304.5 kB 28.3 MB/s eta 0:00:00
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 502.3/502.3 kB 43.6 MB/s eta 0:00:00
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.6/62.6 kB 6.2 MB/s eta 0:00:00
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 48.9/48.9 kB 5.9 MB/s eta 0:00:00
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 41.2/41.2 kB 4.2 MB/s eta 0:00:00
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 96.9/96.9 kB 10.6 MB/s eta 0:00:00
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 17.3/17.3 MB 20.2 MB/s eta 0:00:00
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 34.4/34.4 MB 13.6 MB/s eta 0:00:00
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.7/2.7 MB 55.0 MB/s eta 0:00:00
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.6/9.6 MB 61.4 MB/s eta 0:00:00
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 38.9/38.9 MB 12.7 MB/s eta 0:00:00
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 93.9/93.9 kB 11.6 MB/s eta 0:00:00
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.6/11.6 MB 97.2 MB/s eta 0:00:00
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 133.1/133.1 kB 16.2 MB/s eta 0:00:00
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.1/3.1 MB 83.2 MB/s eta 0:00:00
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 798.7/798.7 kB 55.3 MB/s eta 0:00:00
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 247.7/247.7 kB 25.7 MB/s eta 0:00:00
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.7/151.7 kB 17.2 MB/s eta 0:00:00
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 143.1/143.1 kB 13.7 MB/s eta 0:00:00
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.6/56.6 kB 6.5 MB/s eta 0:00:00
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 242.5/242.5 kB 23.8 MB/s eta 0:00:00
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 300.3/300.3 kB 29.4 MB/s eta 0:00:00
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 63.8 MB/s eta 0:00:00
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 59.7 MB/s eta 0:00:00
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.4/3.4 MB 62.3 MB/s eta 0:00:00
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 98.3/98.3 kB 11.1 MB/s eta 0:00:00
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 199.3/199.3 kB 11.2 MB/s eta 0:00:00
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.5/61.5 kB 4.2 MB/s eta 0:00:00
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 157.0/157.0 kB 16.3 MB/s eta 0:00:00
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 298.0/298.0 kB 19.8 MB/s eta 0:00:00
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 613.7/613.7 kB 34.2 MB/s eta 0:00:00
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 385.8/385.8 kB 26.1 MB/s eta 0:00:00
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 37.3 MB/s eta 0:00:00
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 117.4/117.4 kB 13.2 MB/s eta 0:00:00
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 59.0/59.0 kB 6.3 MB/s eta 0:00:00
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100.8/100.8 kB 11.2 MB/s eta 0:00:00
2023/06/12 04:01:12 INFO mlflow.utils.environment: === Running command '['bash', '-c', 'source /root/.mlflow/envs/mlflow-de25317bfd3a5ca1670a4a4d068c3b3e722a361b/bin/activate && python -c """"']'
2023/06/12 04:01:13 INFO mlflow.utils.environment: === Running command '['bash', '-c', 'source /root/.mlflow/envs/mlflow-de25317bfd3a5ca1670a4a4d068c3b3e722a361b/bin/activate && exec gunicorn --timeout=60 -b 127.0.0.1:5001 -w 1 ${GUNICORN_CMD_ARGS} -- mlflow.pyfunc.scoring_server.wsgi:app']'
[2023-06-12 04:01:13 +0000] [19269] [INFO] Starting gunicorn 20.1.0
[2023-06-12 04:01:13 +0000] [19269] [INFO] Listening at: http://127.0.0.1:5001/ (19269)
[2023-06-12 04:01:13 +0000] [19269] [INFO] Using worker: sync
[2023-06-12 04:01:13 +0000] [19272] [INFO] Booting worker with pid: 19272
[2023-06-12 04:01:15 +0000] [19272] [ERROR] Exception in worker process
Traceback (most recent call last):
  File ""/root/.mlflow/envs/mlflow-de25317bfd3a5ca1670a4a4d068c3b3e722a361b/lib/python3.10/site-packages/gunicorn/arbiter.py"", line 589, in spawn_worker
    worker.init_process()
  File ""/root/.mlflow/envs/mlflow-de25317bfd3a5ca1670a4a4d068c3b3e722a361b/lib/python3.10/site-packages/gunicorn/workers/base.py"", line 134, in init_process
    self.load_wsgi()
  File ""/root/.mlflow/envs/mlflow-de25317bfd3a5ca1670a4a4d068c3b3e722a361b/lib/python3.10/site-packages/gunicorn/workers/base.py"", line 146, in load_wsgi
    self.wsgi = self.app.wsgi()
  File ""/root/.mlflow/envs/mlflow-de25317bfd3a5ca1670a4a4d068c3b3e722a361b/lib/python3.10/site-packages/gunicorn/app/base.py"", line 67, in wsgi
    self.callable = self.load()
  File ""/root/.mlflow/envs/mlflow-de25317bfd3a5ca1670a4a4d068c3b3e722a361b/lib/python3.10/site-packages/gunicorn/app/wsgiapp.py"", line 58, in load
    return self.load_wsgiapp()
  File ""/root/.mlflow/envs/mlflow-de25317bfd3a5ca1670a4a4d068c3b3e722a361b/lib/python3.10/site-packages/gunicorn/app/wsgiapp.py"", line 48, in load_wsgiapp
    return util.import_app(self.app_uri)
  File ""/root/.mlflow/envs/mlflow-de25317bfd3a5ca1670a4a4d068c3b3e722a361b/lib/python3.10/site-packages/gunicorn/util.py"", line 359, in import_app
    mod = importlib.import_module(module)
  File ""/root/.pyenv/versions/3.10.12/lib/python3.10/importlib/__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 1050, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 1027, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 1006, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 688, in _load_unlocked
  File ""<frozen importlib._bootstrap_external>"", line 883, in exec_module
  File ""<frozen importlib._bootstrap>"", line 241, in _call_with_frames_removed
  File ""/root/.mlflow/envs/mlflow-de25317bfd3a5ca1670a4a4d068c3b3e722a361b/lib/python3.10/site-packages/mlflow/pyfunc/scoring_server/wsgi.py"", line 6, in <module>
    app = scoring_server.init(load_model(os.environ[scoring_server._SERVER_MODEL_PATH]))
  File ""/root/.mlflow/envs/mlflow-de25317bfd3a5ca1670a4a4d068c3b3e722a361b/lib/python3.10/site-packages/mlflow/pyfunc/__init__.py"", line 597, in load_model
    model_impl = importlib.import_module(conf[MAIN])._load_pyfunc(data_path)
  File ""/root/.pyenv/versions/3.10.12/lib/python3.10/importlib/__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 1050, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 1027, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 1004, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'mlflow.johnsnowlabs'
[2023-06-12 04:01:15 +0000] [19272] [INFO] Worker exiting (pid: 19272)
[2023-06-12 04:01:16 +0000] [19269] [INFO] Shutting down: Master
[2023-06-12 04:01:16 +0000] [19269] [INFO] Reason: Worker failed to boot.
Traceback (most recent call last):
  File ""/usr/local/bin/mlflow"", line 8, in <module>
    sys.exit(cli())
  File ""/usr/local/lib/python3.10/dist-packages/click/core.py"", line 1130, in __call__
    return self.main(*args, **kwargs)
  File ""/usr/local/lib/python3.10/dist-packages/click/core.py"", line 1055, in main
    rv = self.invoke(ctx)
  File ""/usr/local/lib/python3.10/dist-packages/click/core.py"", line 1657, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File ""/usr/local/lib/python3.10/dist-packages/click/core.py"", line 1657, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File ""/usr/local/lib/python3.10/dist-packages/click/core.py"", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File ""/usr/local/lib/python3.10/dist-packages/click/core.py"", line 760, in invoke
    return __callback(*args, **kwargs)
  File ""/usr/local/lib/python3.10/dist-packages/mlflow/models/cli.py"", line 105, in serve
    return get_flavor_backend(
  File ""/usr/local/lib/python3.10/dist-packages/mlflow/pyfunc/backend.py"", line 229, in serve
    return self.prepare_env(local_path).execute(
  File ""/usr/local/lib/python3.10/dist-packages/mlflow/utils/environment.py"", line 614, in execute
    return _exec_cmd(
  File ""/usr/local/lib/python3.10/dist-packages/mlflow/utils/process.py"", line 117, in _exec_cmd
    raise ShellCommandException.from_completed_process(comp_process)
mlflow.utils.process.ShellCommandException: Non-zero exit code: 3
Command: ['bash', '-c', 'source /root/.mlflow/envs/mlflow-de25317bfd3a5ca1670a4a4d068c3b3e722a361b/bin/activate && exec gunicorn --timeout=60 -b 127.0.0.1:5001 -w 1 ${GUNICORN_CMD_ARGS} -- mlflow.pyfunc.scoring_server.wsgi:app']

```


3. Now I check the Venv that was created via mlflow 2.4.1
`! source /root/.mlflow/envs/mlflow-de25317bfd3a5ca1670a4a4d068c3b3e722a361b/bin/activate && python -m pip list | grep flow`

it shows mlflow 2.4.0


You can see this logged in here https://colab.research.google.com/drive/1NpPnpcTK1Tm0mzAy6H6hPBn73pIWd6RL?usp=sharing",ran completely fresh running serve command pip list flow model try serve serve port bash selected flavor python exist new environment virtual environment creator seeder added seed eta eta eta eta eta eta eta eta eta eta eta eta eta eta eta eta eta eta eta eta eta eta eta eta eta eta eta eta eta eta eta eta eta eta eta eta eta eta eta eta eta eta running command python running command starting listening worker sync booting worker error exception worker process recent call last file line file line file line file line file line load return file line return file line module file line return name level package level file frozen line file frozen line file frozen line file frozen line file frozen line file frozen line file line module file line main file line return name level package level file frozen line file frozen line file frozen line module worker shutting master reason worker boot recent call last file line module file line return file line main file line invoke return file line invoke return file line invoke return file line invoke return file line serve return file line serve return file line execute return file line raise exit code command check via source python pip list flow see logged,issue,negative,positive,neutral,neutral,positive,positive
1586538083,"@harupy  I just tested it again, it's still broken  reporting more in  a second",tested still broken second,issue,negative,negative,negative,negative,negative,negative
1586527473,Can you remove that env and serve the model again? This should work.,remove serve model work,issue,negative,neutral,neutral,neutral,neutral,neutral
1586527039,"You can also see this problem in this notebook. 
Its running mlflow 2.4.1 but the venv runs mlflow 2.4.0 because of the bug I mentioned

https://colab.research.google.com/drive/1NpPnpcTK1Tm0mzAy6H6hPBn73pIWd6RL?usp=sharing
![image](https://github.com/mlflow/mlflow/assets/18140070/19f8b53c-b65c-4b1d-9fb2-ce259a0f9422)
",also see problem notebook running bug image,issue,negative,neutral,neutral,neutral,neutral,neutral
1586525824,"@harupy  No, the bug was introduced with MLflow 2.4.1, we need another release or at  least an RC.

the serve comand is broken, requirements.txt has `mlflow==2.4` in it's requirements which causes the venv to install mlflow 2.4.0 and give `module not found mlflow.johnsnowlabs`  since that version does not have the flavor


It more described and fixed in https://github.com/mlflow/mlflow/pull/8687",bug need another release least serve broken install give module found since version flavor fixed,issue,negative,negative,negative,negative,negative,negative
1586524715,"> Please checkout this, right now the flavor is broken until we merge this and make a new mlflow release I think


We released MLflow 2.4.1. This should be no longer an issue, right?",please right flavor broken merge make new release think longer issue right,issue,negative,positive,neutral,neutral,positive,positive
1586517722,"@harupy  sounds good then let's merge this, I will make a follow-up PR for the notebooks.

It's a bit tricky to make the notebooks right now anyways since we broke the flavor in the latest release :/ 

Please checkout this, right now the flavor is broken until we merge this and make a new mlflow release I think 
https://github.com/mlflow/mlflow/pull/8687",good let merge make bit tricky make right anyways since broke flavor latest release please right flavor broken merge make new release think,issue,negative,positive,positive,positive,positive,positive
1586494518,"@C-K-Loan Please let us know the docs and API reference look ok. Once confirmed, we can cherry-picks the updates into MLflow 2.4.1's documentation :)",please let u know reference look confirmed documentation,issue,negative,positive,positive,positive,positive,positive
1586123352,"added entry to `models.rst`

only things left is  add notebooks for databrricks + colab


Will add until monday
btw please check this out https://github.com/mlflow/mlflow/pull/8687 ",added entry left add add please check,issue,negative,neutral,neutral,neutral,neutral,neutral
1585774768,"You need to use a proxied artifact storage access as described under scenario 5 here:
https://mlflow.org/docs/latest/tracking.html
To do so use --artifacts-destination, but not --default-artifact-root key",need use artifact storage access scenario use key,issue,negative,neutral,neutral,neutral,neutral,neutral
1585771751,"> 

Adding link to the related document ""Adding inference configuration in MLflow pyfunc flavor""
https://docs.google.com/document/d/1sLR6SCby0hLRLSHonPbnzLpS-7_J4Clk/edit#",link related document inference configuration flavor,issue,negative,neutral,neutral,neutral,neutral,neutral
1585509413,"Hey @harupy  I am working on this right now, I will send a WIP pr today, it covers the pages you already edited and a bit more. 
You can maybe close this PR",hey working right send today already bit maybe close,issue,negative,positive,positive,positive,positive,positive
1585347626,"Passed manual QA on dolly-7b and a mocked version of falcon-40b (same file sizes, just garbage file content)",manual version file size garbage file content,issue,negative,neutral,neutral,neutral,neutral,neutral
1584999210,"Looking at https://github.com/mlflow/mlflow/blob/master/mlflow/transformers.py#L139, I see that it was looking for `tensorflow` since `accelerate` was not in the environment (https://github.com/mlflow/mlflow/blob/master/mlflow/transformers.py#LL113C30-L113C30) . `accelerate` should be optional, right? Why is this required?",looking see looking since accelerate environment accelerate optional right,issue,negative,positive,positive,positive,positive,positive
1584827150,"```dockerfile
FROM python:3.8

RUN pip install mlflow==1.30.0 mlflow-skinny
RUN python -c ""import mlflow; print(mlflow.__version__)""
```

can also reproduce the issue.",python run pip install run python import print also reproduce issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1584806505,"I found:

```dockerfile
FROM python:3.8

RUN pip install mlflow==1.30.0 mlflow-skinny==2.4.0
RUN python -c ""import mlflow; print(mlflow.__version__)""
```

can reproduce the issue.",found python run pip install run python import print reproduce issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1584792593,"I have the same issue, not in Databricks but in Azure ML cluster. It uses our custom a docker image with all libraries pre-installed. Among them I have:

`mlflow==1.30.0`

Now when I try to run any python script that has:

`import mlflow `

I am getting the same exception.

I think it caused by some ""under the hood"" dependency changes of mlflow package that happened between 5th and 6th of June.

On 5th mlflow installed mlflow-skinny==2.3.2 and this version works fine.
But on 6th mlflow installed mlflow-skinny==2.4.0 and that version is broken. What exactly is broken there I am not sure.

Forcing mlflow-skinny==2.3.2 installation by explicitly specifying it in requriements.txt solves the issue, although its a temporary, ugly hack.

This is the worst type of braking dependency - something that is justifiable to hate in python ecosystem! 
",issue azure cluster custom docker image among try run python script import getting exception think hood dependency package th th june th version work fine th version broken exactly broken sure forcing installation explicitly issue although temporary ugly hack worst type dependency something justifiable hate python ecosystem,issue,negative,negative,negative,negative,negative,negative
1584432825,"@dbczumar @BenWilson2 Feel free to merge this once CI finishes, or push commits if it fails.",feel free merge push,issue,positive,positive,positive,positive,positive,positive
1583717854,try testing with session caching disabled.,try testing session disabled,issue,negative,negative,negative,negative,negative,negative
1583616746,"Hi, I saw that the CI workflow has passed. Is there anything else I can do to complete the PR?",hi saw anything else complete,issue,negative,positive,neutral,neutral,positive,positive
1583613597,Hi @fabiogomez11c thank you for letting us know. We'll be adjusting these files to use our own hosted copies of the data shortly. ,hi thank u know use data shortly,issue,negative,neutral,neutral,neutral,neutral,neutral
1583610062,Thank you for providing this notification. We are actively working on a fix for this! ,thank providing notification actively working fix,issue,positive,negative,negative,negative,negative,negative
1583456331,@harupy I incorporated almost all of the research and investigation from your evaluation PR. Awesome stuff! Thank you so much for collaborating and making the implementation much simpler :) ,incorporated almost research investigation evaluation awesome stuff thank much making implementation much simpler,issue,positive,positive,positive,positive,positive,positive
1583444241,Note: This is a blocker for 2.4.1 patch release,note blocker patch release,issue,negative,neutral,neutral,neutral,neutral,neutral
1583058256,"I'd like to port GitLab's issue triager https://gitlab.com/gitlab-org/ml-ops/tanuki-stan/-/blob/master/.gitlab-ci.yml to MLflow. Training is quite expensive and requires node with GPU, but inference probably doesn't need such dependencies.

Ideally it should look like this.
```yaml
name: tanuki-stan

entry_points:
  train:
    python_env: notebooks/requirements.tensorflow-gpu.txt
    parameters:
      # public|private
      data: string
    command: ""cd notebooks; jupyter  --to script train_groups.ipynb; python classify_groups.py {data}""
  classify:
    python_env: scripts/requirements.txt
    parameters:
      issue: uri
      # yes|no
      comment: no
    command: ""cd scripts; python3 classify_groups.py {issue} {comment}""
```
",like port issue training quite expensive node inference probably need ideally look like name train data string command script python data issue comment command python issue comment,issue,positive,positive,positive,positive,positive,positive
1583043464,Why only conda/docker? Is it already possible to use different `requirements.txt` for each entrypoint?,already possible use different,issue,negative,neutral,neutral,neutral,neutral,neutral
1581825485,@xiaoyu-work @jacwalte Please let us know if you know how to reproduce this issue :),please let u know know reproduce issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1581774167,"@labradovy Thanks for reporting this issue! It looks like mlflow 1.22's `mlflow/data` directory is overwritten by mlflow 2.4's `mlflow/data` directory. Would you mind telling us the following?

1. How you install MLflow
2. Databricks runtime version
",thanks issue like directory directory would mind telling u following install version,issue,positive,positive,neutral,neutral,positive,positive
1581601154,"@hmoon-drizly Thanks for reporting the error, how can we reproduce the error?",thanks error reproduce error,issue,negative,positive,positive,positive,positive,positive
1581191473,"yes, but that uvicorn `reload` feature was mentioned by the maintainers in the docs as something that is only used in development for developer productivity. https://fastapi.tiangolo.com/zh/deployment/manually/#run-the-server-program this is why I followed the guidance on doing a server restart for web servers that are actively handling prod traffic.
I really wish that it was a stable interface (there are many mentions of how this has blown up for people in production and where the uvicorn server crashed) because it would make this implementation VERY simple",yes reload feature something used development developer productivity guidance server restart web actively handling prod traffic really wish stable interface many blown people production server would make implementation simple,issue,positive,positive,positive,positive,positive,positive
1580854410,@C-K-Loan our pleasure :) Let us know what you're thinking of (and when you'd be ready to provide) for a guide (`models.rst`) and a usage example for a follow-on PR and we'll help with getting all of that setup and put in the right places in the repo :) ,pleasure let u know thinking ready provide guide usage example help getting setup put right,issue,positive,positive,positive,positive,positive,positive
1580768019,@JulianJvn Thanks for reporting the issue. I was able to make a repro.,thanks issue able make,issue,negative,positive,positive,positive,positive,positive
1580126227,"Hi! I have the same error and I don't know how to solve it, can someone help? I would appreciate it.

I have a notebook inside my experiments folder. When I place the terminal path into that folder I run `mlflow ui --backend-store-uri sqlite:///mlflow.db --port 5001` (this creates inside the experiments folder the `mlflow.db` file). Then in the notebook I have the code mlflow.set_tracking_uri(""sqlite:///mlflow.db"") and I can create a new experiment and store the logs and metrics of each run and I can see them inside the UI without problems. However when I try to access (next day or later) again the metrics saved through the UI by running `mlflow ui --backend-store-uri sqlite:///mlflow.db --port 5001` I'm getting the error:
```
raise MlflowException(
mlflow.exceptions.MlflowException: Detected out-of-date database schema (found version 3500859a5d39, but expected 97727af70f4d). Take a backup of your database, then run 'mlflow db upgrade <database_uri>' to migrate your database to the latest schema. NOTE: schema migration may result in database downtime - please consult your database's documentation for more detail.
```
And when I try to run `mlflow db upgrade sqlite:///mlflow.db` as it suggests I get the error of this issue:
```
raise util.CommandError(resolution) from re
alembic.util.exc.CommandError: Can't locate revision identified by '3500859a5d39'
```",hi error know solve someone help would appreciate notebook inside folder place terminal path folder run port inside folder file notebook code create new experiment store metric run see inside without however try access next day later metric saved running port getting error raise schema found version ad take backup run upgrade migrate latest schema note schema migration may result please consult documentation detail try run upgrade get error issue raise resolution ca locate revision,issue,positive,positive,positive,positive,positive,positive
1579784533,"```
$ curl 'http://localhost:5000/api/2.0/mlflow/experiments/get-by-name?experiment_name=xxxx'

{""error_code"": ""RESOURCE_DOES_NOT_EXIST"", ""message"": ""Could not find experiment with name 'xxxx'""}%
```",curl message could find experiment name,issue,negative,neutral,neutral,neutral,neutral,neutral
1579779838,"curl is fine ,

```
$ curl 'http://localhost:5000/api/2.0/mlflow/experiments/search?max_results=1'
{
  ""experiments"": [
    {
      ""experiment_id"": ""785865090587208438"",
      ""name"": ""gz_spread_week"",
      ""artifact_location"": ""mlflow-artifacts:/785865090587208438"",
      ""lifecycle_stage"": ""active"",
      ""last_update_time"": 1686042752792,
      ""creation_time"": 1686042752792
    }
  ],
  ""next_page_token"": ""eyJvZmZzZXQiOiAxfQ==""
}%
```",curl fine curl name active,issue,positive,positive,positive,positive,positive,positive
1579716680,"@harupy and @BenWilson2  Awesome thank you for all the help and reviews, I learned a lot from you guys!
I am sure there will be some follow-up issues and PR's :) 
",awesome thank help learned lot sure,issue,positive,positive,positive,positive,positive,positive
1579665602,"@C-K-Loan Thanks for all the hard work, merged the PR! Feel free to open issues if you find any.",thanks hard work feel free open find,issue,positive,positive,neutral,neutral,positive,positive
1579632792,"Need a mechanism (statically written file on the server FS that declares the subprocess pid, host, and port that has been started) to store state to support update commands.",need mechanism statically written file server host port store state support update,issue,negative,neutral,neutral,neutral,neutral,neutral
1579471103,"+1 - luckily, we just got out of python 3.7, but we were limited to 1.30.1 and it appeared like suddenly internal classes have just vanished.

For those wondering - you are able to upgrade to the latest v2.4.0 which seems to be working as expected",luckily got python limited like suddenly internal class wondering able upgrade latest working,issue,positive,positive,positive,positive,positive,positive
1579081479,"Previous CI failed with test `tests/tracking/test_model_registry.py::test_update_model_version_flow[file]` due to the flask server do not up within 20 seconds. Sync with the latest master, please approve the CI workflow. Many Thanks.",previous test file due flask server within sync latest master please approve many thanks,issue,positive,positive,positive,positive,positive,positive
1578991915,"@eromoe Can you try running the following command?

```
curl 'http://localhost:5000/api/2.0/mlflow/experiments/search?max_results=1'
```",try running following command curl,issue,negative,neutral,neutral,neutral,neutral,neutral
1578919057,"@harupy @WeichenXu123 @dbczumar @BenWilson2 @serena-ruan 

Any recommendations on this issue or the PR https://github.com/mlflow/mlflow/pull/8585? 

I think it's a pretty straight forward change but I have only been looking at the codebase for a couple days. 


",issue think pretty straight forward change looking couple day,issue,positive,positive,positive,positive,positive,positive
1578610441,Sync from the master after #8620 . Extending the timeout duration. Need the approval to run the CI workflow again. Thanks :),sync master extending duration need approval run thanks,issue,positive,positive,positive,positive,positive,positive
1578365131,"@harupy  here is the PR https://github.com/C-K-Loan/mlflow/pull/2 
It's from the fork and target's this pr.

I added 1 commit so we have a diff and can trigger PR, otherwise it's not possible. ",fork target added commit trigger otherwise possible,issue,negative,neutral,neutral,neutral,neutral,neutral
1578273926,"> @ka1mar Thanks for the update! Can we resolve conflicts?

@harupy, done",thanks update resolve done,issue,positive,positive,positive,positive,positive,positive
1578260677,Glad it's fixed! Can we close this issue?,glad fixed close issue,issue,negative,positive,positive,positive,positive,positive
1578255067,"I found that change `localhost` to `127.0.0.1` fix the error .

But the host mapping is good:
```
$ ping localhost
PING localhost (127.0.0.1): 56 data bytes
64 bytes from 127.0.0.1: icmp_seq=0 ttl=64 time=0.056 ms
64 bytes from 127.0.0.1: icmp_seq=1 ttl=64 time=0.065 ms
64 bytes from 127.0.0.1: icmp_seq=2 ttl=64 time=0.091 ms
```",found change fix error host good ping ping data,issue,negative,positive,positive,positive,positive,positive
1577938729,"@ka1mar Thanks for the comment! If we had more parameters like `run_id`, I'd use what @gabrielfu suggested. For now, the parameter that requires special handling is just `run_id`.",thanks comment like use parameter special handling,issue,positive,positive,positive,positive,positive,positive
1577927244,"- What is your tracking URI?
- Can you try running `python -c ""import mlflow; mlflow.get_experiment_by_name('xxxx'))` instead of `mlflow server`?",try running python import instead server,issue,negative,neutral,neutral,neutral,neutral,neutral
1577918446,How do I help you to dig the error on my machine?,help dig error machine,issue,negative,neutral,neutral,neutral,neutral,neutral
1577896905,@C-K-Loan Can you file a PR in your fork against this PR's branch to run tests? I will merge the PR once all the tests pass.,file fork branch run merge pas,issue,negative,neutral,neutral,neutral,neutral,neutral
1577864982,The command looks fine. I can't reproduce the error.,command fine ca reproduce error,issue,negative,positive,positive,positive,positive,positive
1577856074,"> Instead of increasing the timeout time, could we split the job to run against different folders tests in parallel?

We could if we had more github action runners. We currently only have 20 (free plan). Splitting a job is not free because we must install dependencies to run tests. If we have one job, we can install them once, but if we have two, we need to install them twice. This diff can be amplified by the number of developers we have.

",instead increasing time could split job run different parallel could action currently free plan splitting job free must install run one job install two need install twice number,issue,positive,positive,positive,positive,positive,positive
1577843033,"Instead of increasing the timeout time, could we split the job to run against different folders tests in parallel?",instead increasing time could split job run different parallel,issue,negative,neutral,neutral,neutral,neutral,neutral
1577840701,@eromoe What is the command you used to run the tracking server?,command used run server,issue,negative,neutral,neutral,neutral,neutral,neutral
1577832211,"Not exists, it just a check and safe on windows , but error on mac 

```python
experiment_exists = mlflow.get_experiment_by_name(experiment_name) 

if not experiment_exists: 
    experiment_id = mlflow.create_experiment(experiment_name)
    print(""Experiment created."")
else: 
    experiment_id = experiment_exists.experiment_id
    print(""Experiment already exists."")
```",check safe error mac python print experiment else print experiment already,issue,negative,positive,positive,positive,positive,positive
1577802092,"@jinzhang21 I'm sorry for taking so long to respond.

> What's the longest prompts you've used?

Regarding logged parameters, what interests us most are prompt _templates_ (e.g., `Please summarize the following text: {text_to_summarize}`.) The average template length has been increasing together with the limit put on the input length of Large Language Models. Although 1000-2000 character-long templates are common, seeing much longer templates is not unusual anymore. The longest I have seen In a professional context was **~18,000** character-long.

It might be interesting to note that OpenAI has a version of gpt-4 that supports prompts up to 32,000 token-long (~124,000 characters.) Furthermore, the next generation of open-source/proprietary models might have little-to-no limitation on prompt length ([[1]](https://arxiv.org/pdf/2305.13048), [[2]](https://arxiv.org/abs/2305.19466).) Of course, prompt _templates_ will typically remain much shorter than the observed prompts, but we should expect their average size to keep increasing over time nonetheless.

I don't remember what the storage backend used by MLflow is, but I guess the simplest would be to store strings in a format that enforces no limitation on length?",sorry taking long respond used regarding logged u prompt please summarize following text average template length increasing together limit put input length large language although common seeing much longer unusual seen professional context might interesting note version furthermore next generation might limitation prompt length course prompt typically remain much shorter expect average size keep increasing time nonetheless remember storage used guess would store format limitation length,issue,negative,positive,neutral,neutral,positive,positive
1577787434,We can comment out `test_model_deployment` and `test_sagemaker_docker_model_scoring_with_default_conda_env`. Feel free to comment out more tests.,comment feel free comment,issue,positive,positive,positive,positive,positive,positive
1577783196,"Hi @harupy @WeichenXu123 @BenWilson2 , The `MLflow tests/python` job was canceled after 90 minutes. Can I rerun this job only in this case? I saw some workflows in the master take around 70~90 minutes to complete the `tests/python` job, while others may exceed 90 minutes and get canceled. I suspect that the duration of running the `tests/python` job is influenced by other concurrent jobs running..",hi job rerun job case saw master take around complete job may exceed get suspect duration running job concurrent running,issue,negative,positive,neutral,neutral,positive,positive
1577740439,"Nice looks the first few  tests are running like expected, `test_model_deployment` and `test_sagemaker_docker_model_scoring_with_default_conda_env`  should fail right now. 
https://github.com/C-K-Loan/mlflow/actions/runs/5183066332/jobs/9340537492


But for some reason we get exit code 143, investigating.. maybe OOM? But the model is pretty small mh..  maybe some github runner limitation?
![image](https://github.com/mlflow/mlflow/assets/18140070/11311ee1-4ff8-4095-95ee-da1e80f15bb3)
",nice first running like fail right reason get exit code investigating maybe model pretty small maybe runner limitation image,issue,negative,positive,positive,positive,positive,positive
1577718681,"thank you @harupy I enabled cross-version tests and could trigger the corresponding job manually here  https://github.com/C-K-Loan/mlflow/actions/runs/5183066332/jobs/9340537492 

I will also try to enable `scheduled` event type",thank could trigger corresponding job manually also try enable event type,issue,negative,neutral,neutral,neutral,neutral,neutral
1577645232,"@BenWilson2 @C-K-Loan 

> But for some reason Cross version tests is not being executed on my fork. If it would run there we should have the correct results.

<img width=""1339"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/17039389/5f7ee76b-aaf3-4911-985e-b0346756ebbf"">

Looks like it's disabled because it's a scheduled job. I think you can edit `cross-version-tests.yml` and remove the `scheduled` event type, or enable it from GitHub UI.",reason cross version executed fork would run correct image like disabled job think edit remove event type enable,issue,negative,negative,neutral,neutral,negative,negative
1577588171,"Makes sense! The cross version tests have a workflow dispatch trigger that I'm going to try to trigger from your fork. I'm not sure if the hosted runner will correctly resolve everything, but it's worth a shot :) ",sense cross version dispatch trigger going try trigger fork sure runner correctly resolve everything worth shot,issue,positive,positive,positive,positive,positive,positive
1577565792,+1 this would be really helpful. Any update on this?,would really helpful update,issue,negative,positive,positive,positive,positive,positive
1577537161,"@BenWilson2 in the logs it also looks like the secrets are only present in my fork
On the ml-flow pr
https://github.com/mlflow/mlflow/actions/runs/5179631210/jobs/9334383093?pr=8556
![image](https://github.com/mlflow/mlflow/assets/18140070/ed08015b-f489-4c27-b9dd-5d6bb3630950)

on the pr from my fork
https://github.com/C-K-Loan/mlflow/actions/runs/5179631045/jobs/9332764845?pr=1
![image](https://github.com/mlflow/mlflow/assets/18140070/7e7aa75a-d63d-4fc1-a811-88f220ca9eab)
",also like present fork image fork image,issue,negative,neutral,neutral,neutral,neutral,neutral
1577523677,"@BenWilson2  I think it was properly set, it also seemed like it was properly used in some test runs. I  just reset them just to be safe though. 
![image](https://github.com/mlflow/mlflow/assets/18140070/ff5df5dc-62a7-4a5a-aa23-f4eb22c19053)


It will only be present from runs triggered on this PR on my fork https://github.com/C-K-Loan/mlflow/pull/1 

It seems like the `Cross version tests` flow in this PR is failing since it does not have the secrets here, they are just in the fork.

But for some reason `Cross version tests` is not being executed on my fork. If it would run there we should have the correct results.


",think properly set also like properly used test reset safe though image present triggered fork like cross version flow failing since fork reason cross version executed fork would run correct,issue,positive,positive,neutral,neutral,positive,positive
1577408515,"Seems like the environment variable is not set. 
`loaded_license = json.loads(os.environ[_JOHNSNOWLABS_ENV_JSON_LICENSE_KEY])` returns an empty string.",like environment variable set empty string,issue,negative,negative,neutral,neutral,negative,negative
1576998099,The Python test job was canceled after 90 minutes. Can we extend the timeout duration? Or can we separate out the testing module that is the most time-consuming? ,python test job extend duration separate testing module,issue,negative,neutral,neutral,neutral,neutral,neutral
1576858698,"> https://runbot.staging.cloud.databricks.com/build/MlflowOssBuildDocs/run/17680231

The bash script passes, just the version is not fetched correctly. This PR fixes the previous error.",bash script version fetched correctly previous error,issue,negative,negative,negative,negative,negative,negative
1576686811,"@harupy The issue is related to this `pip` issue:  https://github.com/pypa/pip/issues/8761

As discussed in https://github.com/cctbx/cctbx_project/pull/797 and https://pip.pypa.io/en/stable/user_guide/#using-pip-from-your-program, it might be better to avoid importing pip by doing something like this:

```
import pkg_resources  # part of setuptools
version = pkg_resources.get_distribution(""pip"").version
```",issue related pip issue might better avoid pip something like import part version pip,issue,negative,positive,positive,positive,positive,positive
1576677688,"> @ka1mar Thanks for the PR! Can we check `run_uuid` as well if `run_id` is passed as follows?
> 
> ```python
> def _get_request_param(param: str):
>     ...
>     if param not in args and not optional:
>         # Special handling for run_id
>         if param == ""run_id"":
>             return _get_request_param(""run_uuid"")
>         raise ...
>     return args.get(param, default)
> ```

@harupy, thanks for the review!
Yes, we can, but are you sure we need? I guess it will make the code (especially `_get_request_param` calls with `run_id` param and `optional=False`) a little confusing. And the previous suggestion from @gabrielfu was not to hardcode `run_id` handling logic to `_get_request_param` function.",thanks check well python param param optional special handling param return raise return param default thanks review yes sure need guess make code especially param little previous suggestion handling logic function,issue,positive,positive,positive,positive,positive,positive
1576602513," After further investigation I noticed that I can also reproduce the warning by importing `setuptools` and then `pip`.

My `setuptools` version is 67.8.0",investigation also reproduce warning pip version,issue,negative,neutral,neutral,neutral,neutral,neutral
1576381849,"Hi @harupy , I was confused by the recipe test failures and had no idea how to fix them. However, that has been resolved after #8598 . I have merged the master into my branch. Could you please assist me in verifying and running the CI action again?  Thanks.",hi confused recipe test idea fix however resolved master branch could please assist running action thanks,issue,positive,negative,neutral,neutral,negative,negative
1575917840,"@ka1mar Thanks for the PR! Can we check `run_uuid` as well if `run_id` is passed as follows?

```python
def _get_request_param(param: str):
    ...
    if param not in args and not optional:
        # Special handling for run_id
        if param == ""run_id"":
            return _get_request_param(""run_uuid"")
        raise ...
    return args.get(param, default)
```",thanks check well python param param optional special handling param return raise return param default,issue,positive,positive,positive,positive,positive,positive
1575903769,regarding 2: Sure we can also just manually bump the version,regarding sure also manually bump version,issue,negative,positive,positive,positive,positive,positive
1575903372,"1. Got it, let's use pyspark 3.3 for now.
2. Can we update the version once a newer one is published?",got let use update version one,issue,negative,neutral,neutral,neutral,neutral,neutral
1575896288,"@harupy  thank you for the commits
1) I just realized the current build of johnsnowlabs library is only compatible up to pyspark 3.3.0.     
pyspark 3.4.0 will be suppported on the next release in ~ 1 week.  Could you consider this in the CI and maybe use pyspark 3.3.0? I can also make an RC build which would be compatible with pyspark 3.4.0 but that would overcomplicate things for now I think


2) Can we always install the latest johnsnowlabs instead of fixing it to 4.4.6 for ci? ",thank current build library compatible next release week could consider maybe use also make build would compatible would think always install latest instead fixing,issue,negative,positive,positive,positive,positive,positive
1575637480,"> @tahesse i use Scenario 5, it's work well, but after i enable authen via nginx, basic authen, i can not log artifact from client, only metric, param are work. How to fix it?
> 
> [Scenario 5: MLflow Tracking Server enabled with proxied artifact storage access](https://www.mlflow.org/docs/latest/tracking.html#id36)

What method do you use to store artifacts?",use scenario work well enable via basic log artifact client metric param work fix scenario server artifact storage access method use store,issue,negative,neutral,neutral,neutral,neutral,neutral
1575466100,"I managed to get this working, but i got 

```
Failed to load HostKeys from
/home/acer/.ssh/known_hosts.  You will need to explicitly load HostKeys (cnopts.hostkeys.load(filename)) or disableHostKey checking (
cnopts.hostkeys = None).
  warnings.warn(wmsg, UserWarning)
Traceback (most recent call last):
  File ""/home/shared/mlflow/examples/quickstart/mlflow_tracking.py"", line 27, in <module>
    log_artifacts(""outputs"")
  File ""/home/acer/.pyenv/versions/training_env/lib/python3.9/site-packages/mlflow/tracking/fluent.py"", line 818, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File ""/home/acer/.pyenv/versions/training_env/lib/python3.9/site-packages/mlflow/tracking/client.py"", line 1074, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File ""/home/acer/.pyenv/versions/training_env/lib/python3.9/site-packages/mlflow/tracking/_tracking_service/client.py"", line 448, i
n log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File ""/home/acer/.pyenv/versions/training_env/lib/python3.9/site-packages/mlflow/tracking/_tracking_service/client.py"", line 416, i
n _get_artifact_repo
    artifact_repo = get_artifact_repository(artifact_uri)
  File ""/home/acer/.pyenv/versions/training_env/lib/python3.9/site-packages/mlflow/store/artifact/artifact_repository_registry.py"", l
ine 106, in get_artifact_repository
    return _artifact_repository_registry.get_artifact_repository(artifact_uri)
  File ""/home/acer/.pyenv/versions/training_env/lib/python3.9/site-packages/mlflow/store/artifact/artifact_repository_registry.py"", l
ine 72, in get_artifact_repository
    return repository(artifact_uri)
  File ""/home/acer/.pyenv/versions/training_env/lib/python3.9/site-packages/mlflow/store/artifact/sftp_artifact_repo.py"", line 82, in
 __init__
    connections = [pysftp.Connection(**self.config) for _ in range(self.max_workers)]
  File ""/home/acer/.pyenv/versions/training_env/lib/python3.9/site-packages/mlflow/store/artifact/sftp_artifact_repo.py"", line 82, in
 <listcomp>
    connections = [pysftp.Connection(**self.config) for _ in range(self.max_workers)]
  File ""/home/acer/.pyenv/versions/training_env/lib/python3.9/site-packages/pysftp/__init__.py"", line 132, in __init__
    self._tconnect['hostkey'] = self._cnopts.get_hostkey(host)
  File ""/home/acer/.pyenv/versions/training_env/lib/python3.9/site-packages/pysftp/__init__.py"", line 71, in get_hostkey
    raise SSHException(""No hostkey for host %s found."" % host)

```",get working got load need explicitly load none recent call last file line module file line file line file line file line file return file return repository file line range file line range file line host file line raise host found host,issue,negative,neutral,neutral,neutral,neutral,neutral
1575428833,"@dbczumar 

I also hit this issue with sftp server,

```
mlflow server --host 1.1.1.1 --backend-store-uri mysql://acer:test@1.1.1.1:3306/mlflow_artifacts  --default-artifact-root sftp://acer:test@11.1.1.1:2222/home/acer/upload
```

I can access the ftp server with filezilla, so  i think the sftp server setup is okay.

Here are my test script to reprodcue the problem

```
  import os
  from random import random, randint

  import mlflow
  from mlflow import log_metric, log_param, log_artifacts

  if __name__ == ""__main__"":
      print(""Running mlflow_tracking.py"")

      mlflow.set_tracking_uri(""http://10.36.172.141:5000"")
      mlflow.set_experiment(""my-experiment"")


      log_param(""param1"", randint(0, 100))

      log_metric(""foo"", random())
      log_metric(""foo"", random() + 1)
      log_metric(""foo"", random() + 2)

      if not os.path.exists(""outputs""):
          os.makedirs(""outputs"")
      with open(""outputs/test.txt"", ""w"") as f:
          f.write(""hello world!"")

      log_artifacts(""outputs"")
```

Here are the error messges

```
  File ""/home/shared/mlflow/examples/quickstart/mlflow_tracking.py"", line 25, in <module>
    log_artifacts(""outputs"")
  File ""/home/acer/.pyenv/versions/training_env/lib/python3.9/site-packages/mlflow/tracking/fluent.py"", line 818, in log_artifacts
    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)
  File ""/home/acer/.pyenv/versions/training_env/lib/python3.9/site-packages/mlflow/tracking/client.py"", line 1074, in log_artifacts
    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)
  File ""/home/acer/.pyenv/versions/training_env/lib/python3.9/site-packages/mlflow/tracking/_tracking_service/client.py"", line 448, in log_artifacts
    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)
  File ""/home/acer/.pyenv/versions/training_env/lib/python3.9/site-packages/mlflow/store/artifact/ftp_artifact_repo.py"", line 95, in log_artifacts
    self.log_artifact(os.path.join(root, f), upload_path)
  File ""/home/acer/.pyenv/versions/training_env/lib/python3.9/site-packages/mlflow/store/artifact/ftp_artifact_repo.py"", line 78, in log_artifact
    ftp.storbinary(""STOR "" + os.path.basename(local_file), f)
  File ""/home/acer/.pyenv/versions/3.9.16/lib/python3.9/ftplib.py"", line 498, in storbinary
    with self.transfercmd(cmd, rest) as conn:
  File ""/home/acer/.pyenv/versions/3.9.16/lib/python3.9/ftplib.py"", line 393, in transfercmd
    return self.ntransfercmd(cmd, rest)[0]
  File ""/home/acer/.pyenv/versions/3.9.16/lib/python3.9/ftplib.py"", line 354, in ntransfercmd
    conn = socket.create_connection((host, port), self.timeout,
  File ""/home/acer/.pyenv/versions/3.9.16/lib/python3.9/socket.py"", line 844, in create_connection
    raise err
  File ""/home/acer/.pyenv/versions/3.9.16/lib/python3.9/socket.py"", line 832, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

```",also hit issue server server host test test access server think server setup test script problem import o random import random import import print running param foo random foo random foo random open hello world error file line module file line file line file line file line root file line file line rest conn file line return rest file line conn host port file line raise err file line sa connection,issue,negative,negative,negative,negative,negative,negative
1573838669,"This PR is filed against https://github.com/mlflow/mlflow/tree/investigate-windows. The latest commit on this branch is https://github.com/mlflow/mlflow/commit/fb983d262e122b2c0dafaf0fe569a5c8a9485423. The `recipe-windows` ran successfully.


What does this imply?

https://github.com/mlflow/mlflow/commit/3a58f74aeec78a0d9c21cdf62e44e89e5017ca68 (the commit that added `datasets`) looks suspicious.


<img width=""762"" alt=""Screen Shot 2023-06-02 at 23 38 25"" src=""https://github.com/mlflow/mlflow/assets/17039389/c8da57b2-7c03-4029-ac8d-628269aae07c"">

On the commit before the dataset commit, we see the green check mark.


",latest commit branch ran successfully imply commit added suspicious screen shot commit commit see green check mark,issue,positive,positive,positive,positive,positive,positive
1573589878,"@harupy 

I tried uploading some files directly through boto3 into my S3 bucket and I am able to do so by specifying the region explicitly while creating the boto3 resource and/or client object.",tried directly bucket able region explicitly resource client object,issue,negative,positive,positive,positive,positive,positive
1573573607,I would like to add support for this feature as well for the reason mentioned by @myaseen-oraclase. I work with generative models and this would make evolution tracking easier. This request may be linked to https://github.com/mlflow/mlflow/issues/3843 as well although I feel more strongly about this particular one,would like add support feature well reason work generative would make evolution easier request may linked well although feel strongly particular one,issue,positive,positive,positive,positive,positive,positive
1573457076,"@nlgranger thanks for opening this issue. I needed something like this in MLFlow for my project and found this issue.

@harupy I'd like to add my support for this feature / enhancement as well. In addition to the confusion matrix example already discussed, I think this feature will also be very useful in a large variety of generative AI tasks where it is invaluable to be able to see the ""evolution"" of an image etc. over iterations.",thanks opening issue something like project found issue like add support feature enhancement well addition confusion matrix example already think feature also useful large variety generative ai invaluable able see evolution image,issue,positive,positive,positive,positive,positive,positive
1573080209,"@C-K-Loan 

> I am working on setting up the CI on my fork with this

Thanks!",working setting fork thanks,issue,negative,positive,positive,positive,positive,positive
1573077097,"I updated `mlflow.johnsnowlabs` to only expect 1 environment varriable `JOHNSNOWLABS_LICENSE_JSON` which is the raw json string and can be set like this
```python
os.environ['JOHNSNOWLABS_LICENSE_JSON'] = \
'{""AWS_ACCESS_KEY_ID"":""..."", ""AWS_SECRET_ACCESS_KEY"":""..."", ""SPARK_NLP_LICENSE"":""..."", ""SECRET"":""...""}'
```


Regarding the CI: 

One problem with this approach is the following: 
the `SECRET` variable must be updated every 2 weeks because we are creating a new `SECRET`  for every release.

For this purpose, I will set the `JSL_ACCESS_KEY` Secret variable in github which will be checked for during test execution. With it, this snippet will setup the licensed libs on the fly

```python
def setup_env():
    if 'JSL_ACCESS_KEY' in os.environ:
        # via access_token
        from johnsnowlabs.py_models.jsl_secrets import JslSecrets
        # Download License & Install Licensed Libraries
        nlp.install(access_token=os.environ['JSL_ACCESS_KEY'])
        # Write json secret to env
        secrets = JslSecrets.from_jsl_home()
        os.environ[mlflow.johnsnowlabs._JOHNSNOWLABS_JSON_VARS] = json.dumps(
            {
                'SECRET': secrets.HC_SECRET,
                'AWS_ACCESS_KEY_ID': secrets.AWS_ACCESS_KEY_ID,
                'AWS_SECRET_ACCESS_KEY': secrets.AWS_SECRET_ACCESS_KEY,
                'SPARK_NLP_LICENSE': secrets.HC_LICENSE,
            }

        )
    # mlflow.johnsnowlabs._JOHNSNOWLABS_JSON_VARS needs to be present now either from CI or from JSL_ACCESS_KEY
    mlflow.johnsnowlabs._set_env_vars()
    nlp.install()
```

I am working on setting up the CI on my fork with this 
",expect environment raw string set like python secret regarding one problem approach following secret variable must every new secret every release purpose set secret variable checked test execution snippet setup licensed fly python via import license install licensed write secret need present either working setting fork,issue,negative,negative,negative,negative,negative,negative
1573026782,Spacy + Torch failures are now passing. whew.,spacy torch passing whew,issue,negative,neutral,neutral,neutral,neutral,neutral
1573024670,"This PR fixes the artifact example suite failure. If we can get those core python tests (and, by extension, that skinny test) to pass, we should be good! :D ",artifact example suite failure get core python extension skinny test pas good,issue,negative,positive,positive,positive,positive,positive
1573006148,Manual Examples run from this branch: https://github.com/mlflow/mlflow/actions/runs/5150908907/jobs/9275574444 via dispatch trigger,manual run branch via dispatch trigger,issue,negative,neutral,neutral,neutral,neutral,neutral
1572995912,"@BenWilson2 @harupy @serena-ruan This change is definitely the right direction for supporting inference-time configurations. Before releasing this change, it would be great to have the following:

- Support for viewing which configs can be set via the MLflow Model Signature
- Support for passing inference configs to model serving: databricks, mlflow OSS flask, mlflow OSS mlserver
- Solution for users to define which configs they want to expose when deploying their models

cc @santiagxf ",change definitely right direction supporting change would great following support set via model signature support passing inference model serving flask solution define want expose,issue,positive,positive,positive,positive,positive,positive
1572977814,"> This is great functionality to have! Would it be possible to also support `kwargs` with `mlflow.pyfunc.spark_udf`? One could pass in the keyword args at UDF creation time, then the created UDF would pass them into the scoring server / predict function.

This sounds reasonable, we'll support it in follow up PRs :)",great functionality would possible also support one could pas creation time would pas scoring server predict function reasonable support follow,issue,positive,positive,positive,positive,positive,positive
1572497626,"This is great functionality to have! Would it be possible to also support `kwargs` with `mlflow.pyfunc.spark_udf`? One could pass in the keyword args at UDF creation time, then the created UDF would pass them into the scoring server / predict function.",great functionality would possible also support one could pas creation time would pas scoring server predict function,issue,positive,positive,positive,positive,positive,positive
1571949088,Looking for this feature to be implemented as open source as well.  ,looking feature open source well,issue,negative,neutral,neutral,neutral,neutral,neutral
1571816707,"Hi @WeichenXu123 , I have merged the latest master commit into my branch. The workflows require approval to run.

I am confused by the failure testing `Example` and the `recipes-windows` these days. It seems that occurs from the test environment setup.
e.g. Running Pytorch/MNIST MLProject example will cause following error. It is coming from `setuptools` when building virtual environment.
```text
File ""/home/runner/.mlflow/envs/mlflow-c671fa24ea66f8db7c1137e54f0f9cf067740341/lib/python3.8/site-packages/mlflow/utils/environment.py"", line 79, in current
    build_dependencies=cls.get_current_build_dependencies(),
  File ""/home/runner/.mlflow/envs/mlflow-c671fa24ea66f8db7c1137e54f0f9cf067740341/lib/python3.8/site-packages/mlflow/utils/environment.py"", line 94, in get_current_build_dependencies
    version = _PythonEnv._get_package_version(package)
  File ""/home/runner/.mlflow/envs/mlflow-c671fa24ea66f8db7c1137e54f0f9cf067740341/lib/python3.8/site-packages/mlflow/utils/environment.py"", line 86, in _get_package_version
    return __import__(package_name).__version__
  File ""/home/runner/.mlflow/envs/mlflow-c671fa24ea66f8db7c1137e54f0f9cf067740341/lib/python3.8/site-packages/setuptools/__init__.py"", line 7, in <module>
    import _distutils_hack.override  # noqa: F401
  File ""/home/runner/.mlflow/envs/mlflow-c671fa24ea66f8db7c1137e54f0f9cf067740341/lib/python3.8/site-packages/_distutils_hack/override.py"", line 1, in <module>
    __import__('_distutils_hack').do_override()
  File ""/home/runner/.mlflow/envs/mlflow-c671fa24ea66f8db7c1137e54f0f9cf067740341/lib/python3.8/site-packages/_distutils_hack/__init__.py"", line 77, in do_override
    ensure_local_distutils()
  File ""/home/runner/.mlflow/envs/mlflow-c671fa24ea66f8db7c1137e54f0f9cf067740341/lib/python3.8/site-packages/_distutils_hack/__init__.py"", line 64, in ensure_local_distutils
    assert '_distutils' in core.__file__, core.__file__
AssertionError: /home/runner/.pyenv/versions/3.8.16/lib/python3.8/distutils/core.py
```
I have used the `dev/dev-env-setup.sh -d ./mlflow-dev-env/ -f` to set up my local environment and these errors are still there.

And another failed test `recipe-windows`, did not occur when I tested it locally..
```text
tests/recipes/test_transform_step.py::test_transform_empty_step - ModuleNotFoundError: No module named 'steps.transform'
```
Do you have any ideas to solve these issues?
Thanks ~",hi latest master commit branch require approval run confused failure testing example day test environment setup running example cause following error coming building virtual environment text file line current file line version package file line return file line module import file line module file line file line assert used set local environment still another test occur tested locally text module solve thanks,issue,negative,negative,neutral,neutral,negative,negative
1571748693,"I think this feature would be awesome and more intuitive for deleting experiments IMHO. Because when clicking delete icon on the UI, the experiment disappears but neither its artifacts nor its metadata aren't deleted. I think it is confusing for end user.",think feature would awesome intuitive delete icon experiment neither think end user,issue,positive,positive,positive,positive,positive,positive
1571672830,could you merge mlflow master code and then check result of CI ? thanks ! ,could merge master code check result thanks,issue,negative,positive,positive,positive,positive,positive
1571608761,"Thank you so much, that was exactly the issue.",thank much exactly issue,issue,negative,positive,positive,positive,positive,positive
1571600129,Feel free to re-open the issue if it doesn't work.,feel free issue work,issue,positive,positive,positive,positive,positive,positive
1571598160,"@ynusinovich It looks like you forgot to call `mlflow.set_tracking(MLFLOW_TRACKING_URI)`. Because the tracking URI is not set, `mlflow` attempt to fetch the model from the local file system and fails to find it. Setting the tracking URI should fix the issue.",like forgot call set attempt fetch model local file system find setting fix issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1571244071,a better approach might be to build a partially applied func in pyfunc.log_model closed over a context it builds there and sends into this util..,better approach might build partially applied closed context,issue,negative,positive,positive,positive,positive,positive
1571236926,"You can add `[skip ci]` to a commit message to skip workflow runs:

https://docs.github.com/en/actions/managing-workflow-runs/skipping-workflow-runs",add skip commit message skip,issue,negative,neutral,neutral,neutral,neutral,neutral
1571230360,I'll reopen it after testing :) Don't want to trigger the workflow tests,reopen testing want trigger,issue,negative,neutral,neutral,neutral,neutral,neutral
1571196696,Rerequesting a review @dbczumar because I added in new protobuf definitions and wanted another pair of eyes on the way im serializing the protobuf message for the HTTP header.,review added new another pair way message header,issue,negative,positive,positive,positive,positive,positive
1571173025,"@C-K-Loan Can you register required credentials as secrets in **your fork** and see if it works? Once it's set up, I can push a commit to edit github actions config files to run tests.",register fork see work set push commit edit run,issue,negative,neutral,neutral,neutral,neutral,neutral
1571102959,"Can we collapse the **kwargs and the input data into a single table-friendly entry to work around this until we have a deeper discussion with inference team? We might have to provide guidance to users that if they set a model signature, they will have to include all possible overrides that they want to support and we'll have to nullify the column entries so that schema enforcement doesn't fail. ",collapse input data single entry work around discussion inference team might provide guidance set model signature include possible want support nullify column schema enforcement fail,issue,negative,negative,negative,negative,negative,negative
1571099220,"> MLServer is the Seldon implementation for MLflow input types: https://github.com/SeldonIO/MLServer
> We should coerce the input to conform to the structure that this package expects (represented as a DataFrame input that has been cast to the structure required (it supports the input JSON structure from `split`, `records` or `inputs` for orientation conversion from a `pd.DataFrame.split(orient=""<x>"")`


This is the change I made to mlflow.pyfunc.scoring_server.__init__.py function
<img width=""618"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/82044803/c11bb41d-e663-4de1-bbdb-0200799ac312"">

So in order to pass those additional kwargs when you call '/invocations' I updated the logic to this:
```
data, inference_config = _split_data_and_inference_config(json_str)
data = infer_and_parse_data(data, input_schema)
```

But looks like mlserver_mlflow was copying from the exact logic here 
<img width=""573"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/82044803/95f5bed5-86dc-4fb2-bd26-0cb2bdc3397a"">
So once I change this part's logic then mlserver_mlflow doesn't work.

Now that even if I change the code in mlserver_mlflow to be consistent with us, they're not released yet so tests would fail. I feel like we should expose this part to a function and let mlserver_mlflow just call us, then in the future any changes be made here won't break. WDYT?",implementation input coerce input conform structure package input cast structure input structure split orientation conversion change made function image order pas additional call logic data data data like exact logic image change part logic work even change code consistent u yet would fail feel like expose part function let call u future made wo break,issue,negative,neutral,neutral,neutral,neutral,neutral
1570919303,"@BenWilson2 I added a note in model.rst, but some tests (while all were passing before) are failing for some reason. My last [commit](https://github.com/mlflow/mlflow/pull/8567/commits/3f5e7c2a0d723337782e2644c80c2900a7ea916c) only changes the doc and one comment, so the new failing tests are quite confusing for me. Do you know what might go wrong?

Edit: The tests are also passing in my local env, so i'm making empty commit to trigger another run.",added note passing failing reason last commit doc one comment new failing quite know might go wrong edit also passing local making empty commit trigger another run,issue,negative,negative,neutral,neutral,negative,negative
1570424544,"Hello, any news about OpenAPI spec definition for mlflow? Is this Pr planned to be merged?",hello news spec definition,issue,negative,neutral,neutral,neutral,neutral,neutral
1570397842,"MLServer is the Seldon implementation for MLflow input types: https://github.com/SeldonIO/MLServer 
We should coerce the input to conform to the structure that this package expects (represented as a DataFrame input that has been cast to the structure required (it supports the input JSON structure from `split`, `records` or `inputs` for orientation conversion from a `pd.DataFrame.split(orient=""<x>"")`",implementation input coerce input conform structure package input cast structure input structure split orientation conversion,issue,negative,neutral,neutral,neutral,neutral,neutral
1570361053,"Question: mlserver_mlflow uses this function from mlflow.pyfunc.scoring_server, which I updated in order to support kwargs in serving. How can I update the logics in mlserver_mlflow as well? It looks like an independent package installed",question function order support serving update well like independent package,issue,positive,neutral,neutral,neutral,neutral,neutral
1570355907,"> Does the same thing happen on Jupyter notebook?

I'm testing on Databricks notebook though.",thing happen notebook testing notebook though,issue,negative,neutral,neutral,neutral,neutral,neutral
1569832806,"> @serena-ruan Can you take a screen recording and attach it in the PR description?

Yes, I'm still testing, the behavior of tqdm is quite strange, sometimes it doesn't make it to 100% and even when it does, and I added the config `leave=False` which is supposed to remove the progress bar after complete, but it doesn't work well. Once I make sure it works I'll update the PR description.",take screen recording attach description yes still testing behavior quite strange sometimes make even added supposed remove progress bar complete work well make sure work update description,issue,positive,positive,positive,positive,positive,positive
1569768996,@serena-ruan Can you take a screen recording and attach it in the PR description?,take screen recording attach description,issue,negative,neutral,neutral,neutral,neutral,neutral
1569591442,"Sorry @harupy , I realized the client and test cases are incomplete, so I pushed a few new commits here",sorry client test incomplete new,issue,negative,negative,negative,negative,negative,negative
1569485448,"@BenWilson2  and @harupy  everything should be addressed in the latest commit please let me know if there is anything else, thank you a lot for the rigorous review! ",everything latest commit please let know anything else thank lot rigorous review,issue,positive,positive,positive,positive,positive,positive
1569468905,"Btw, tests were triggered (several non-audio also failing)",triggered several also failing,issue,negative,neutral,neutral,neutral,neutral,neutral
1569317493,@PenHsuanWang Thanks for reporting this issue. Can you run the example again once the PR above is merged (will be soon)?,thanks issue run example soon,issue,negative,positive,positive,positive,positive,positive
1569011375,"Ok I figured out the issue. The Pala Alto Firewall was seeing this as threat ID 40015 (Brute Force Accept). Disabling this threat ID fixes the issue.

I would recommend decreasing this back down to ~10-12 connections OR making the `_NUM_MAX_THREADS` configurable. ",figured issue alto seeing threat id brute force accept threat id issue would recommend decreasing back making,issue,negative,neutral,neutral,neutral,neutral,neutral
1568851848,"@harupy yes I have tried that. The solution was mentioned in #2401, but it doesnt seem to work for my case ",yes tried solution doesnt seem work case,issue,positive,neutral,neutral,neutral,neutral,neutral
1568724922,"Can we make sure that we're validating that this works with model serving by creating a test (or modifying an existing test that uses the pyfunc serving and scoring test fixture)? 
Similar to this test: https://github.com/mlflow/mlflow/blob/616858977d3964933839141967e13124491acd0d/tests/transformers/test_transformers_model_export.py#L1758-L1811 where we're supplying overrides with the inference payload",make sure work model serving test test serving scoring test fixture similar test inference,issue,negative,positive,positive,positive,positive,positive
1568552784,Can one of the examples be updated to show this functionality? https://github.com/mlflow/mlflow/blob/master/examples/transformers/simple.py is probably a great candidate :) ,one show functionality probably great candidate,issue,positive,positive,positive,positive,positive,positive
1568209122,"We use DagsHub for multi-tenancy, since it creates a separate MLflow sever with each repository, and this also includes authentication and access controls. 
See:
https://dagshub.com/docs/integration_guide/mlflow_tracking/index.html",use since separate sever repository also authentication access see,issue,negative,neutral,neutral,neutral,neutral,neutral
1567797962,"@fedetask Adding a sliding bar (like the Points sliding bar) is one option:

<img width=""704"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/17039389/ab7068a0-908e-45be-92ed-e2d981fb80bb"">
",sliding bar like sliding bar one option image,issue,negative,neutral,neutral,neutral,neutral,neutral
1567769157,Could you record a demo video and attach it to the PR description ? :),could record video attach description,issue,negative,neutral,neutral,neutral,neutral,neutral
1567703272,I will close this ticket since no new updates.,close ticket since new,issue,negative,positive,positive,positive,positive,positive
1567638939,"@piseabhijeet  Do we have any progress in this issue?
I am willing to engage on this enhancement.",progress issue willing engage enhancement,issue,positive,positive,positive,positive,positive,positive
1567623499,"Not yet. I've listed some proposals like [this](https://github.com/ciela/mlflow/commit/2ceecd894c9f3ad220f953d9f15334e877426282) that could merge directly, but I haven't gotten any response from MLflow maintainers.
Maybe I should submit as a pull-request?",yet listed like could merge directly gotten response maybe submit,issue,negative,positive,neutral,neutral,positive,positive
1567610186,"I'd like to help with contributions on this. 

Since mlflow relies on Flask, would [something like this](https://flask.palletsprojects.com/en/2.3.x/deploying/proxy_fix/) need to be conditionally applied?

```python
from werkzeug.middleware.proxy_fix import ProxyFix

app.wsgi_app = ProxyFix(
    app.wsgi_app, x_for=1, x_proto=1, x_host=1, x_prefix=1
)
```",like help since flask would something like need conditionally applied python import,issue,positive,neutral,neutral,neutral,neutral,neutral
1567597344,"Hello, are PRs for this being accepted? I would like to help contribute if so",hello accepted would like help contribute,issue,positive,neutral,neutral,neutral,neutral,neutral
1567591927,"@nicolasang333 How do you set `GOOGLE_APPLICATION_CREDENTIALS`? Do you set it by `export GOOGLE_APPLICATION_CREDENTIALS=...`. If not, can you try that?",set set export try,issue,negative,neutral,neutral,neutral,neutral,neutral
1567590143,"@nicolasang333 Can you log an artifact?

```python
import mlflow

# Set GCS as an arifact storage?

with mlflow.start_run():
    mlflow.log_artifact(...)
```",log artifact python import set storage,issue,negative,neutral,neutral,neutral,neutral,neutral
1567330331,"Ive tested my credentials and my credentials worked fine if I use it on the jupyter notebook, BUT does not work on ML Flow Projects or Recipes.

I'm running the code locally but extracting data from Google Cloud Storage",tested worked fine use notebook work flow running code locally data cloud storage,issue,negative,positive,positive,positive,positive,positive
1566612773,Thanks @harupy  I was not sure if it was re-triggering. Sorry for the previous  Pr's its now fixed,thanks sure sorry previous fixed,issue,positive,positive,neutral,neutral,positive,positive
1566600238,@C-K-Loan Opening a new PR doesn't fix the DCO check.,opening new fix check,issue,negative,positive,positive,positive,positive,positive
1566590787,"> @gabrielfu LGTM! Can you fix the lint errors?

Great! Just fixed it!",fix lint great fixed,issue,positive,positive,positive,positive,positive,positive
1566516204,@serena-ruan Can you update the PR description to add a table describing how large the performance gain is?,update description add table large performance gain,issue,positive,positive,positive,positive,positive,positive
1566417604,"@baky0905 Thanks for reporting this. The code looks incorrect, but I'm wondering why tests are passing.",thanks code incorrect wondering passing,issue,negative,positive,positive,positive,positive,positive
1564855458,"Don't use MLFlow unless you want to get yourself locked out in the future. IMHO this issue (and all nesting involved with it) defeats the whole purpose. If I want to maintain the complete lifecycle, I want it to be persistent and EASILY accessible across multiple releases regardless of used versions, at the end of the day it is nothing else but metadata management via stored `yaml` (how difficult can it be?). This issue is equivalent to building an Eiffel without proper foundation: you know it is going to topple, it is just a matter of time.

Based on that, the way I see it, MLFlow it is a tool for impromptu tracking during experimentation phase, assuming no versions are in motions, and as such it does not qualify for full lifecycle because such issues discredit it because it will cause future issues (saying it form experience).

Point I am trying to make, tools such as MLFlow should be an add-on features that should work as a fluent sidecar regardless of underlying processes/versions, meaning sidecar should be version agnostic as much as possible. Instead, MLFlow is build as if it was the foundation of the lifecycle that forces you do build everything else around it. IMHO: bad design.

If anybody disagrees, this issue has been opened end of 2021, and we are mid 2023 and it is still present including release of MLFlow 2.0 🙄 ",use unless want get locked future issue involved whole purpose want maintain complete want persistent easily accessible across multiple regardless used end day nothing else management via difficult issue equivalent building without proper foundation know going topple matter time based way see tool impromptu experimentation phase assuming qualify full discredit cause future saying form experience point trying make work fluent sidecar regardless underlying meaning sidecar version agnostic much possible instead build foundation build everything else around bad design anybody issue end mid still present release,issue,negative,negative,neutral,neutral,negative,negative
1564836177,@harupy any thoughts on this change impacting SFTP connections and a possible way to get around it? https://github.com/mlflow/mlflow/blob/v2.3.2/mlflow/store/artifact/artifact_repo.py#L16,change possible way get around,issue,negative,neutral,neutral,neutral,neutral,neutral
1564576197,"I also just built a fresh image from the latest code on master branch using

> pip install git+https://github.com/mlflow/mlflow.git@maste

This picked up sha [a31fbe0](https://github.com/mlflow/mlflow/commit/a31fbe04ba62f9e4d45b920e13f4abb2893fb971)

> $ mlflow --version
> mlflow, version 2.3.3.dev0

With a Postgres backend, I can confirm the error returned is incorrect.

```json
{
    ""ErrorCode"": ""BAD_REQUEST"",
    ""Message"": ""(psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \""experiments_name_key\""\nDETAIL:  Key (name)=(default-project-72428692-8556-488a-ba97-0feb0796a898) already exists.\n\n[SQL: INSERT INTO experiments (name, artifact_location, lifecycle_stage, creation_time, last_update_time) VALUES (%(name)s, %(artifact_location)s, %(lifecycle_stage)s, %(creation_time)s, %(last_update_time)s) RETURNING experiments.experiment_id]\n[parameters: {'name': 'default-project-72428692-8556-488a-ba97-0feb0796a898', 'artifact_location': 'mlflow-artifacts:/mlflow', 'lifecycle_stage': 'active', 'creation_time': 1685114933068, 'last_update_time': 1685114933068}]\n(Background on this error at: https://sqlalche.me/e/20/gkpj)""
}
```",also built fresh image latest code master branch pip install picked sha version version dev confirm error returned incorrect message duplicate key value unique constraint key name already insert name name background error,issue,negative,positive,positive,positive,positive,positive
1564532561,"@WeichenXu123 sorry for the late response. I was just able to test this against a 2.3.2 mlflow instance.

I can confirm that this bug is still  present unfortunately.  I think that the issue should be reopened -- unless you were talking about building an as of yet unreleased version off of the head of the branch?",sorry late response able test instance confirm bug still present unfortunately think issue unless talking building yet unreleased version head branch,issue,negative,negative,negative,negative,negative,negative
1564258148,"@mlflow-automation  this issue is not fixed yet, i am still getting the same error, this could be avoided by using 1.30.0 version, but this is not the optimal due to the Vulnerabilities with 1.30.0",issue fixed yet still getting error could version optimal due,issue,negative,negative,neutral,neutral,negative,negative
1563678107,Checking in here to see if I can help move this along as our organization has a vested interest in consuming an official MLFlow helm-chart.,see help move along organization interest consuming official,issue,positive,neutral,neutral,neutral,neutral,neutral
1563638539,"@rishavmandal771 Looks like `kwargs` already contains `map_location`. You can pop it out by `kwargs.pop(""map_location"", None)`.",like already pop none,issue,negative,neutral,neutral,neutral,neutral,neutral
1563596489,@dbczumar Did you ever determine whether this was due a timeout issue due to limited network bandwidth for the t2.medium instances as you speculated above? ,ever determine whether due issue due limited network,issue,negative,negative,negative,negative,negative,negative
1562971283,"> Didn't https://github.com/mlflow/mlflow/pull/8352/files#r1203403706 work?

Sorry didn't see that comment. I know it's a bit weird to put those functions in download_cloud_file_chunk, should we just put them in a new file like 'request_utils.py'? Cuz all those functions don't import mlflow, then importing that single file won't trigger importing mlflow at all.",work sorry see comment know bit weird put put new file like import single file wo trigger,issue,negative,negative,negative,negative,negative,negative
1562910276,"When running this code, now i am getting the following error-

```
23-05-25 11:38:37,037 E [66] azmlinfsrv - Encountered Exception Traceback (most recent call last):
  File ""/azureml-envs/azureml_9a3b1e0a66d72d612aebc12b4a285f72/lib/python3.9/site-packages/azureml_inference_server_http/server/user_script.py"", line 117, in invoke_init
    self._user_init()
  File ""/var/azureml-app/dependencies/score.py"", line 31, in init
    model = mlflow.pyfunc.load_model(model_path)
  File ""/azureml-envs/azureml_9a3b1e0a66d72d612aebc12b4a285f72/lib/python3.9/site-packages/mlflow/pyfunc/__init__.py"", line 735, in load_model
    model_impl = importlib.import_module(conf[MAIN])._load_pyfunc(data_path)
  File ""/azureml-envs/azureml_9a3b1e0a66d72d612aebc12b4a285f72/lib/python3.9/site-packages/mlflow/pytorch/__init__.py"", line 735, in _load_pyfunc
    return _PyTorchWrapper(_load_model(path, **kwargs))
  File ""/azureml-envs/azureml_9a3b1e0a66d72d612aebc12b4a285f72/lib/python3.9/site-packages/mlflow/pytorch/__init__.py"", line 643, in _load_model
    return torch.load(model_path, **kwargs)
  File ""/var/azureml-app/dependencies/score.py"", line 21, in load
    return torch.load(*args, **kwargs, map_location=torch.device(""cpu""))
  File ""/var/azureml-app/dependencies/score.py"", line 21, in load
    return torch.load(*args, **kwargs, map_location=torch.device(""cpu""))
TypeError: entry_module.load() got multiple values for keyword argument 'map_location'

The above exception was the direct cause of the following exception:

```",running code getting following exception recent call last file line file line model file line main file line return path file line return file line load return file line load return got multiple argument exception direct cause following exception,issue,negative,positive,neutral,neutral,positive,positive
1562860387,"I have this same problem but only when running code remotely on Databricks.

Locally works fine i.e. running `mlflow.projects.run` having `MLFLOW_TRACKING_URI=""""` and `backend=""local""`.

But remote is broken, i.e. running `mlflow.projects.run` having `MLFLOW_TRACKING_URI=""databricks""` and `backend=""databricks""`.

Very difficult to debug... :(",problem running code remotely locally work fine running local remote broken running difficult,issue,negative,negative,neutral,neutral,negative,negative
1562730971,"Thanks for your tip.

As per my understanding, you meant this right
```
original = torch.load

def load(*args, **kwargs):
    return torch.load(*args, **kwargs, map_location=torch.device(""cpu""))


def init():
    global model
    # ""model"" is the path of the mlflow artifacts when the model was registered. For automl
    # models, this is generally ""mlflow-model"".

    with mock.patch(""torch.load"", load):
        model_path = os.path.join(os.getenv(""AZUREML_MODEL_DIR""), ""use-case1-model"")
        model = mlflow.pyfunc.load_model(model_path)
        
    logging.info(""Init complete"")
```

Also, is there a possibility to fix this issue, by let's say adding this parameter into the pyfunc.torch_load function or something?",thanks tip per understanding meant right original load return global model model path model registered generally load model complete also possibility fix issue let say parameter function something,issue,positive,positive,positive,positive,positive,positive
1562670343,"This is obviously a hack, not a fix, but you can do:

```python
from unittest import mock
import torch


original = torch.load


def load(*args, **kwargs):
    return torch.load(*args, **kwargs, map_location=torch.device(""cpu""))


with mock.patch(""torch.load"", load):
    # Load the model here
    ...

```",obviously hack fix python import mock import torch original load return load load model,issue,negative,positive,positive,positive,positive,positive
1562657456,"So, can you suggest an alternative to fix this issue",suggest alternative fix issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1562655754,"@rishavmandal771 Unfortunately, mlflow currently doesn't provide a way to specify `map_location` when loading a torch model.",unfortunately currently provide way specify loading torch model,issue,negative,neutral,neutral,neutral,neutral,neutral
1562431495,"> Thanks for reporting this issue! Though I would suggest not hardcoding this logic inside `_get_request_param()`. How about something like this?
> 
> ```python
> def _get_request_param(param: str, optional: bool = False, default = None):
>     ...
>     if param not in args and not optional:
>         raise ...
>     return args.get(param, default)
> 
> 
> def _get_permission_from_run_id():
>     ...
>     run_id = _get_request_param(""run_id"", optional=True) or _get_request_param(""run_uuid"")
> ```

Thanks, I corrected.",thanks issue though would suggest logic inside something like python param optional bool false default none param optional raise return param default thanks corrected,issue,positive,negative,neutral,neutral,negative,negative
1562325437,"@rgaudenzi-fub 
It works for me. thank you.
Almost examples on web save artifact at local direcotry. This is not my case.
I want to know that scenario 5 on server-side and client-side specific settings.
Thank you. Thank you.",work thank almost web save artifact local case want know scenario specific thank thank,issue,positive,neutral,neutral,neutral,neutral,neutral
1562158798,"Thanks for reporting this issue! Though I would suggest not hardcoding this logic inside `_get_request_param()`. How about something like this?

```python
def _get_request_param(param: str, optional: bool = False, default = None):
    ...
    if param not in args and not optional:
        raise ...
    return args.get(param, default)


def _get_permission_from_run_id():
    ...
    run_id = _get_request_param(""run_id"", optional=True) or _get_request_param(""run_uuid"")
```",thanks issue though would suggest logic inside something like python param optional bool false default none param optional raise return param default,issue,positive,negative,negative,negative,negative,negative
1561328520,Thanks for your reply. I could make it work with run_name_prefix. Then I will close this FR. ,thanks reply could make work close,issue,negative,positive,positive,positive,positive,positive
1561094350,"@santiagxf  I am only reporting when world_rank==0
I get this error also in another code for training using DistributedDataParallel. My Azure cluster has 4 nodes each node with 4 K80 GPUs. Please let me know if you may need further logs or information. I now switched to 
```
mlflow==2.3.2
azureml-mlflow==1.50.0
```
and still same problem. Dump of mlflow.doctor() below.

Example snippets of code are here:
```
local_rank = os.environ[""LOCAL_RANK""]
self_is_main_node = False 

logger = logging.getLogger(__name__)


print(""opt.checkpoints = {}"".format(opt.checkpoints))
# save the hyper parameters passed


distributed_backend = opt.distributed_backend
if distributed_backend == ""nccl"":
    world_size = int(os.environ[""WORLD_SIZE""])
    world_rank = int(os.environ['RANK'])
    local_rank = int(os.environ[""LOCAL_RANK""])
    multinode_available = world_size > 1
    self_is_main_node = world_rank == 0
    print(""world size is: "", world_size)
    print(""global rank is {} and local_rank is {}"".format(world_rank, local_rank))
else:
    raise NotImplementedError(
        f""distributed_backend={distributed_backend} is not implemented yet.""
    )
    

mlflow.doctor()
mlflow.autolog()

logged_params = {
    ""instance_per_node"": world_size,
    ""cuda_available"": torch.cuda.is_available(),
    ""distributed"": multinode_available,
    ""distributed_backend"": distributed_backend,
    # data loading params
    ""batch_size"": batch_size,
    ""num_epochs"": opt.num_epochs,
    ""num_workers"": opt.num_workers,
    ""cpu_count"": os.cpu_count(),
    ""prefetch_factor"": opt.prefetch_factor,
    ""persistent_workers"": opt.persistent_workers,
    ""pin_memory"": opt.pin_memory,
    ""non_blocking"": opt.non_blocking,
    # ""multiprocessing_sharing_strategy"": opt.multiprocessing_sharing_strategy,
    # training params
    ""model_arch"": opt.model_arch,
    ""model_arch_pretrained"": opt.model_arch_pretrained,
    ""optimizer.learning_rate"": opt.learning_rate,
    # profiling params
    ""enable_profiling"": opt.enable_profiling,
}

if torch.cuda.is_available():
    # add some gpu properties
    logged_params[""cuda_device_count""] = torch.cuda.device_count()
    cuda_device_properties = torch.cuda.get_device_properties(device)
    logged_params[""cuda_device_name""] = cuda_device_properties.name
    logged_params[""cuda_device_major""] = cuda_device_properties.major
    logged_params[""cuda_device_minor""] = cuda_device_properties.minor
    logged_params[
        ""cuda_device_memory""
    ] = cuda_device_properties.total_memory
    logged_params[
        ""cuda_device_processor_count""
    ] = cuda_device_properties.multi_processor_count
    
    

tags = {""team"": team_name,
        ""dataset"": dataset_name, 
        ""model"": model_name}

exp_name = exp_name

if self_is_main_node:
    mlflow.set_tags(tags)
    mlflow.log_params(logged_params)
        if train:
            if batch_idx % opt.loginterval == 0:
                print('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.15f}'.format(
                    epoch, batch_idx * len(data), len(loader.dataset),
                    100. * batch_idx / len(loader), loss.data.item()))   
                print(""epoch is: {} and train loss is {}"".format(epoch, loss))
                if self_is_main_node:
                    mlflow.log_metric(""train_loss"", loss.data.item())
        else:
            if batch_idx % opt.loginterval == 0:
                print('Test Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.15f}'.format(
                    epoch, batch_idx * len(data), len(loader.dataset),
                    100. * batch_idx / len(loader), loss.data.item()))
                print(""epoch is: {} and test loss is {}"".format(epoch, loss))
                if self_is_main_node:
                    mlflow.log_metric(""test_loss"", loss.data.item())


if self_is_main_node:
    print(mlflow.active_run().info.run_uuid)
    if mlflow.active_run():
        mlflow.end_run()
```






```
CPython
3.8.10
uname_result(system='Linux', node='3a742b5dcfec4b4b8658b52b96a0c2d3000000', release='5.15.0-1029-azure', version='#36~20.04.1-Ubuntu SMP Tue Dec 6 17:00:26 UTC 2022', machine='x86_64', processor='x86_64')
System information: Linux #36~20.04.1-Ubuntu SMP Tue Dec 6 17:00:26 UTC 2022
Python version: 3.8.10
MLflow version: 2.3.2
MLflow module location: /usr/local/lib/python3.8/dist-packages/mlflow/__init__.py
Tracking URI: URI
Registry URI: URI
MLflow environment variables:
  MLFLOW_DISABLE_ENV_MANAGER_CONDA_WARNING: True
  MLFLOW_EXPERIMENT_ID: 021dec90-c7d3-4233-813e-799d15e43f9a
  MLFLOW_EXPERIMENT_NAME: my_exp_name
  MLFLOW_RUN_ID: 63f59200-0c4f-43f2-84ea-3cb136c4f7bc
  MLFLOW_TRACKING_TOKEN: token
  MLFLOW_TRACKING_URI: URI
MLflow dependencies:
  Flask: 2.3.2
  Jinja2: 3.1.2
  alembic: 1.11.1
  click: 8.1.3
  cloudpickle: 2.2.0
  databricks-cli: 0.17.7
  docker: 6.1.2
  entrypoints: 0.4
  gitpython: 3.1.31
  gunicorn: 20.1.0
  importlib-metadata: 5.1.0
  markdown: 3.4.1
  matplotlib: 3.7.0
  numpy: 1.24.2
  packaging: 22.0
  pandas: 1.5.2
  protobuf: 3.20.1
  pyarrow: 9.0.0
  pytz: 2022.6
  pyyaml: 6.0
  querystring-parser: 1.2.4
  requests: 2.28.1
  scikit-learn: 0.24.2
  scipy: 1.10.1
  sqlalchemy: 2.0.15
  sqlparse: 0.4.4
2023/05/23 20:57:24 WARNING mlflow.tracking.fluent: Exception raised while enabling autologging for sklearn: No module named 'sklearn.utils.testing'
INFO:__main__:os.getpid() is 39 and initializing process group with {'MASTER_ADDR': '10.0.0.4', 'MASTER_PORT': '6105', 'LOCAL_RANK': '0', 'RANK': '0', 'WORLD_SIZE': '16'}
INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 0
INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:39 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:39 [0] NCCL INFO Bootstrap : Using eth0:10.0.0.4<0>
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:39 [0] NCCL INFO NET/Plugin: Failed to find ncclNetPlugin_v6 symbol.
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:39 [0] NCCL INFO NET/Plugin: Loaded net plugin NCCL RDMA Plugin (v5)
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:39 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:39 [0] NCCL INFO NET/Plugin: Loaded coll plugin SHARP (v5)
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:39 [0] NCCL INFO cudaDriverVersion 11040
NCCL version 2.15.5+cuda11.8
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO P2P plugin IBext
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO NET/IB : No device found.
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO NET/Socket : Using [0]eth0:10.0.0.4<0>
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO Using network Socket
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO Topology detection : could not read /sys/devices/LNXSYSTM:00/LNXSYBUS:00/PNP0A03:00/device:07/VMBUS:01/47505500-0001-0000-3130-444531303244/pci0001:00/0001:00:00.0/../max_link_speed, ignoring
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO Topology detection : could not read /sys/devices/LNXSYSTM:00/LNXSYBUS:00/PNP0A03:00/device:07/VMBUS:01/47505500-0001-0000-3130-444531303244/pci0001:00/0001:00:00.0/../max_link_width, ignoring
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO Topology detection : could not read /sys/devices/LNXSYSTM:00/LNXSYBUS:00/PNP0A03:00/device:07/VMBUS:01/47505500-0002-0000-3130-444531303244/pci0002:00/0002:00:00.0/../max_link_speed, ignoring
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO Topology detection : could not read /sys/devices/LNXSYSTM:00/LNXSYBUS:00/PNP0A03:00/device:07/VMBUS:01/47505500-0002-0000-3130-444531303244/pci0002:00/0002:00:00.0/../max_link_width, ignoring
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO Topology detection : could not read /sys/devices/LNXSYSTM:00/LNXSYBUS:00/PNP0A03:00/device:07/VMBUS:01/47505500-0003-0000-3130-444531303244/pci0003:00/0003:00:00.0/../max_link_speed, ignoring
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO Topology detection : could not read /sys/devices/LNXSYSTM:00/LNXSYBUS:00/PNP0A03:00/device:07/VMBUS:01/47505500-0003-0000-3130-444531303244/pci0003:00/0003:00:00.0/../max_link_width, ignoring
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO Topology detection : could not read /sys/devices/LNXSYSTM:00/LNXSYBUS:00/PNP0A03:00/device:07/VMBUS:01/47505500-0004-0000-3130-444531303244/pci0004:00/0004:00:00.0/../max_link_speed, ignoring
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO Topology detection : could not read /sys/devices/LNXSYSTM:00/LNXSYBUS:00/PNP0A03:00/device:07/VMBUS:01/47505500-0004-0000-3130-444531303244/pci0004:00/0004:00:00.0/../max_link_width, ignoring
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO Topology detection: network path /sys/devices/LNXSYSTM:00/LNXSYBUS:00/PNP0A03:00/device:07/VMBUS:01/000d3a03-f30f-000d-3a03-f30f000d3a03 is not a PCI device (vmbus). Attaching to first CPU
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO KV Convert to int : could not find value of '' in dictionary, falling back to 60
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO KV Convert to int : could not find value of '' in dictionary, falling back to 60
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO KV Convert to int : could not find value of '' in dictionary, falling back to 60
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO KV Convert to int : could not find value of '' in dictionary, falling back to 60
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO === System : maxBw 5.0 totalBw 12.0 ===
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO CPU/0 (1/1/1)
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO + PCI[5000.0] - NIC/0
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO                 + NET[5.0] - NET/0 (0/0/5.000000)
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO + PCI[12.0] - GPU/100000 (0)
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO + PCI[12.0] - GPU/200000 (1)
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO + PCI[12.0] - GPU/300000 (2)
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO + PCI[12.0] - GPU/400000 (3)
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO ==========================================
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO GPU/100000 :GPU/100000 (0/5000.000000/LOC) GPU/200000 (2/12.000000/PHB) GPU/300000 (2/12.000000/PHB) GPU/400000 (2/12.000000/PHB) CPU/0 (1/12.000000/PHB) NET/0 (3/5.000000/PHB)
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO GPU/200000 :GPU/100000 (2/12.000000/PHB) GPU/200000 (0/5000.000000/LOC) GPU/300000 (2/12.000000/PHB) GPU/400000 (2/12.000000/PHB) CPU/0 (1/12.000000/PHB) NET/0 (3/5.000000/PHB)
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO GPU/300000 :GPU/100000 (2/12.000000/PHB) GPU/200000 (2/12.000000/PHB) GPU/300000 (0/5000.000000/LOC) GPU/400000 (2/12.000000/PHB) CPU/0 (1/12.000000/PHB) NET/0 (3/5.000000/PHB)
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO GPU/400000 :GPU/100000 (2/12.000000/PHB) GPU/200000 (2/12.000000/PHB) GPU/300000 (2/12.000000/PHB) GPU/400000 (0/5000.000000/LOC) CPU/0 (1/12.000000/PHB) NET/0 (3/5.000000/PHB)
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO NET/0 :GPU/100000 (3/5.000000/PHB) GPU/200000 (3/5.000000/PHB) GPU/300000 (3/5.000000/PHB) GPU/400000 (3/5.000000/PHB) CPU/0 (2/5.000000/PHB) NET/0 (0/5000.000000/LOC)
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO Setting affinity for GPU 0 to 0fff
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO Pattern 4, crossNic 0, nChannels 1, bw 5.000000/5.000000, type PHB/PHB, sameChannels 1
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO  0 : NET/0 GPU/0 GPU/1 GPU/2 GPU/3 NET/0
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO Pattern 1, crossNic 0, nChannels 1, bw 6.000000/5.000000, type PHB/PHB, sameChannels 1
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO  0 : NET/0 GPU/0 GPU/1 GPU/2 GPU/3 NET/0
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO Pattern 3, crossNic 0, nChannels 0, bw 0.000000/0.000000, type NVL/PIX, sameChannels 1
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO Tree 0 : -1 -> 0 -> 1/8/-1
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO Tree 1 : 4 -> 0 -> 1/-1/-1
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO Channel 00/02 :    0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO Channel 01/02 :    0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO Ring 00 : 15 -> 0 -> 1
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO Ring 01 : 15 -> 0 -> 1
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO Trees [0] 1/8/-1->0->-1 [1] 1/-1/-1->0->4
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO Channel 00/0 : 15[400000] -> 0[100000] [receive] via NET/Socket/0
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO Channel 01/0 : 15[400000] -> 0[100000] [receive] via NET/Socket/0
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO Channel 00 : 0[100000] -> 1[200000] via SHM/direct/direct
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO Channel 01 : 0[100000] -> 1[200000] via SHM/direct/direct
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO Connected all rings
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO Channel 01/0 : 0[100000] -> 4[100000] [send] via NET/Socket/0
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO Channel 00/0 : 8[100000] -> 0[100000] [receive] via NET/Socket/0
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO Channel 00/0 : 0[100000] -> 8[100000] [send] via NET/Socket/0
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO Channel 01/0 : 4[100000] -> 0[100000] [receive] via NET/Socket/0
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NINFO:azureml.mlflow._internal.utils:Parsing tracking uri /mlflow/v1.0/subscriptions/ID/resourceGroups/group-name/providers/Microsoft.MachineLearningServices/workspaces/workspace-name
INFO:azureml.mlflow._internal.utils:Tracking uri /mlflow/v1.0/subscriptions/ID/resourceGroups/group-name/providers/Microsoft.MachineLearningServices/workspaces/workspace-name has sub id ID, resource group group-name, and workspace workspace-name
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication.TokenRefresherDaemon:Starting daemon and triggering first instance
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1819084.45985 seconds
INFO:azureml.mlflow._common._cloud.cloud:Fetching cloud metadata from known urls
DEBUG:azureml.mlflow._common._cloud.cloud:Start : Loading cloud metatdata from url https://management.azure.com/metadata/endpoints?api-version=2019-05-01
DEBUG:azureml.mlflow._common._cloud.cloud:Start : Loading cloud metatdata from the url specified by https://management.azure.com/metadata/endpoints?api-version=2019-05-01
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): management.azure.com:443
DEBUG:urllib3.connectionpool:https://management.azure.com:443 ""GET /metadata/endpoints?api-version=2019-05-01 HTTP/1.1"" 200 913
DEBUG:azureml.mlflow._common._cloud.cloud:Active directory endpoint loaded from AzureCloud metadata is https://login.microsoftonline.com/
DEBUG:azureml.mlflow._common._cloud.cloud:Active directory endpoint for cloud AzureCloud set to https://login.microsoftonline.com
DEBUG:azureml.mlflow._common._cloud.cloud:Active directory endpoint loaded from AzureCloud metadata is https://login.microsoftonline.com
DEBUG:azureml.mlflow._common._cloud.cloud:Active directory endpoint for cloud AzureCloud set to https://login.microsoftonline.com
DEBUG:azureml.mlflow._common._cloud.cloud:Active directory endpoint loaded from AzureChinaCloud metadata is https://login.chinacloudapi.cn
DEBUG:azureml.mlflow._common._cloud.cloud:Active directory endpoint for cloud AzureChinaCloud set to https://login.chinacloudapi.cn
DEBUG:azureml.mlflow._common._cloud.cloud:Active directory endpoint loaded from AzureCloud metadata is https://login.microsoftonline.com
DEBUG:azureml.mlflow._common._cloud.cloud:Active directory endpoint for cloud AzureCloud set to https://login.microsoftonline.com
DEBUG:azureml.mlflow._common._cloud.cloud:Active directory endpoint loaded from AzureChinaCloud metadata is https://login.chinacloudapi.cn
DEBUG:azureml.mlflow._common._cloud.cloud:Active directory endpoint for cloud AzureChinaCloud set to https://login.chinacloudapi.cn
DEBUG:azureml.mlflow._common._cloud.cloud:Active directory endpoint loaded from AzureUSGovernment metadata is https://login.microsoftonline.us
DEBUG:azureml.mlflow._common._cloud.cloud:Active directory endpoint for cloud AzureUSGovernment set to https://login.microsoftonline.us
DEBUG:azureml.mlflow._common._cloud.cloud:Active directory endpoint loaded from AzureCloud metadata is https://login.microsoftonline.com
DEBUG:azureml.mlflow._common._cloud.cloud:Active directory endpoint for cloud AzureCloud set to https://login.microsoftonline.com
DEBUG:azureml.mlflow._common._cloud.cloud:Active directory endpoint loaded from AzureChinaCloud metadata is https://login.chinacloudapi.cn
DEBUG:azureml.mlflow._common._cloud.cloud:Active directory endpoint for cloud AzureChinaCloud set to https://login.chinacloudapi.cn
DEBUG:azureml.mlflow._common._cloud.cloud:Active directory endpoint loaded from AzureUSGovernment metadata is https://login.microsoftonline.us
DEBUG:azureml.mlflow._common._cloud.cloud:Active directory endpoint for cloud AzureUSGovernment set to https://login.microsoftonline.us
DEBUG:azureml.mlflow._common._cloud.cloud:Finish : Loading cloud metatdata from the url specified by https://management.azure.com/metadata/endpoints?api-version=2019-05-01
DEBUG:azureml.mlflow._common._cloud.cloud:Finish : Loading cloud metatdata
INFO:azureml.mlflow._common._cloud.cloud:Cloud was fetched from known metadataurls
INFO:azureml.mlflow._common._cloud.cloud:Cloud metadata not found so falling back to AzureCloud as default
DEBUG:azureml.mlflow._internal.service_context_loader:Created a new service context from mlflow env vars: <azureml.mlflow._internal.utils.ServiceContext object at 0x14f9a2116eb0>
DEBUG:azureml.mlflow._store.tracking.store:Initializing the AzureMLRestStore
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): eastus2.api.azureml.ms:443
DEBUG:urllib3.connectionpool:https://eastus2.api.azureml.ms:443 ""GET /mlflow/v2.0/subscriptions/ID/resourceGroups/group-nam/providers/Microsoft.MachineLearningServices/workspaces/workspace-name/api/2.0/mlflow/runs/get?run_uuid=63f59200-0c4f-43f2-84ea-3cb136c4f7bc&run_id=63f59200-0c4f-43f2-84ea-3cb136c4f7bc HTTP/1.1"" 200 None
DEBUG:azureml.mlflow._store.tracking.store:Status update was skipped for remote run 63f59200-0c4f-43f2-84ea-3cb136c4f7bc

Downloading: ""https://download.pytorch.org/models/vgg19-dcbb9e9d.pth"" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth
training script path:  /mnt/azureml/cr/j/7646e7ce32bc45a5b78f8aaeb1e1f90c/exe/wd
start: 20:57:24.712810
object of interest is: cracker
manual seed set to 8978
opt.checkpoints = /mnt/azureml/cr/j/7646e7ce32bc45a5b78f8aaeb1e1f90c/cap/data-capability/wd/checkpoints
world size is:  16
global rank is 0 and local_rank is 0
is_distributed is True and batch_size is 16
os.getpid() is 39 and initializing process group with {'MASTER_ADDR': '10.0.0.4', 'MASTER_PORT': '6105', 'LOCAL_RANK': '0', 'RANK': '0', 'WORLD_SIZE': '16'}
device is cuda:0
load data
train data size:  246000
training data len:  246000
batch size is:  16
training data: 961 batches
load models
torch.cuda.device_count():  4
type opt.gpuids: <class 'list'>
gpuids are: [0, 1, 2, 3]
Training network pretrained on imagenet.

  0%|          | 0.00/548M [00:00<?, ?B/s]
  1%|          | 4.26M/548M [00:00<00:12, 44.6MB/s]
  2%|▏         | 8.52M/548M [00:00<00:14, 38.7MB/s]
  2%|▏         | 13.2M/548M [00:00<00:13, 42.8MB/s]
  3%|▎         | 17.8M/548M [00:00<00:12, 44.9MB/s]
  4%|▍         | 22.5M/548M [00:00<00:11, 46.4MB/s]
  5%|▌         | 27.9M/548M [00:00<00:11, 49.4MB/s]
  6%|▌         | 33.4M/548M [00:00<00:10, 52.1MB/s]
  7%|▋         | 39.1M/548M [00:00<00:09, 54.8MB/s]
  8%|▊         | 44.4M/548M [00:00<00:09, 54.2MB/s]
  9%|▉         | 49.6M/548M [00:01<00:10, 52.2MB/s]
 10%|▉         | 54.6M/548M [00:01<00:11, 47.0MB/s]
 11%|█         | 59.2M/548M [00:01<00:11, 42.7MB/s]
 12%|█▏        | 63.4M/548M [00:01<00:15, 33.7MB/s]
 12%|█▏        | 66.9M/548M [00:01<00:18, 27.3MB/s]
 13%|█▎        | 69.9M/548M [00:01<00:22, 22.6MB/s]
 13%|█▎        | 72.4M/548M [00:02<00:25, 19.2MB/s]
 14%|█▎        | 74.5M/548M [00:02<00:28, 17.6MB/s]
 14%|█▍        | 76.3M/548M [00:02<00:30, 16.4MB/s]
 14%|█▍        | 78.0M/548M [00:02<00:30, 15.9MB/s]
 15%|█▍        | 79.6M/548M [00:02<00:30, 16.1MB/s]
 15%|█▍        | 81.3M/548M [00:02<00:29, 16.7MB/s]
 15%|█▌        | 83.4M/548M [00:02<00:27, 17.9MB/s]
 16%|█▌        | 85.8M/548M [00:03<00:24, 19.6MB/s]
 16%|█▌        | 88.1M/548M [00:03<00:22, 21.1MB/s]
 17%|█▋        | 90.8M/548M [00:03<00:20, 23.0MB/s]
 17%|█▋        | 93.7M/548M [00:03<00:18, 25.1MB/s]
 18%|█▊        | 96.8M/548M [00:03<00:17, 27.1MB/s]
 18%|█▊        | 100M/548M [00:03<00:15, 29.6MB/s]
 19%|█▉        | 104M/548M [00:03<00:14, 31.3MB/s]
 19%|█▉        | 107M/548M [00:03<00:17, 26.9MB/s]
 20%|██        | 110M/548M [00:03<00:15, 29.1MB/s]
 21%|██        | 114M/548M [00:03<00:13, 32.7MB/s]
 22%|██▏       | 119M/548M [00:04<00:12, 36.9MB/s]
 22%|██▏       | 123M/548M [00:04<00:11, 40.3MB/s]
 23%|██▎       | 128M/548M [00:04<00:10, 42.8MB/s]
 24%|██▍       | 133M/548M [00:04<00:09, 44.5MB/s]
 25%|██▍       | 137M/548M [00:04<00:10, 41.8MB/s]
 26%|██▌       | 141M/548M [00:04<00:10, 40.4MB/s]
 26%|██▋       | 145M/548M [00:04<00:10, 40.3MB/s]
 27%|██▋       | 149M/548M [00:04<00:10, 41.1MB/s]
 28%|██▊       | 153M/548M [00:04<00:10, 38.5MB/s]
 29%|██▊       | 157M/548M [00:05<00:10, 37.7MB/s]
 29%|██▉       | 160M/548M [00:05<00:10, 37.4MB/s]
 30%|██▉       | 164M/548M [00:05<00:11, 35.9MB/s]
 31%|███       | 167M/548M [00:05<00:12, 32.0MB/s]
 31%|███       | 171M/548M [00:05<00:13, 29.5MB/s]
 32%|███▏      | 173M/548M [00:05<00:13, 28.2MB/s]
 32%|███▏      | 176M/548M [00:05<00:13, 28.6MB/s]
 33%|███▎      | 179M/548M [00:05<00:13, 29.2MB/s]
 33%|███▎      | 182M/548M [00:05<00:12, 30.6MB/s]
 34%|███▍      | 186M/548M [00:06<00:11, 32.3MB/s]
 35%|███▍      | 190M/548M [00:06<00:11, 33.6MB/s]
 35%|███▌      | 193M/548M [00:06<00:10, 34.6MB/s]
 36%|███▌      | 197M/548M [00:06<00:10, 36.1MB/s]
 37%|███▋      | 201M/548M [00:06<00:09, 36.8MB/s]
 37%|███▋      | 204M/548M [00:06<00:10, 35.9MB/s]
 38%|███▊      | 208M/548M [00:06<00:09, 36.1MB/s]
 39%|███▊      | 211M/548M [00:06<00:09, 36.4MB/s]
 39%|███▉      | 215M/548M [00:06<00:09, 36.5MB/s]
 40%|███▉      | 218M/548M [00:06<00:09, 37.1MB/s]
 41%|████      | 223M/548M [00:07<00:08, 39.8MB/s]
 41%|████▏     | 227M/548M [00:07<00:07, 42.4MB/s]
 42%|████▏     | 232M/548M [00:07<00:07, 44.2MB/s]
 43%|████▎     | 237M/548M [00:07<00:07, 45.7MB/s]
 44%|████▍     | 242M/548M [00:07<00:06, 46.7MB/s]
 45%|████▌     | 247M/548M [00:07<00:06, 49.6MB/s]
 46%|████▌     | 252M/548M [00:07<00:06, 50.1MB/s]
 47%|████▋     | 257M/548M [00:07<00:06, 46.0MB/s]
 48%|████▊     | 261M/548M [00:07<00:06, 46.1MB/s]
 48%|████▊     | 266M/548M [00:08<00:06, 46.8MB/s]
 49%|████▉     | 270M/548M [00:08<00:06, 46.6MB/s]
 50%|█████     | 275M/548M [00:08<00:06, 43.2MB/s]
 51%|█████     | 279M/548M [00:08<00:06, 41.2MB/s]
 52%|█████▏    | 283M/548M [00:08<00:06, 40.2MB/s]
 52%|█████▏    | 287M/548M [00:08<00:06, 41.1MB/s]
 53%|█████▎    | 291M/548M [00:08<00:06, 42.0MB/s]
 54%|█████▍    | 295M/548M [00:08<00:06, 39.1MB/s]
 55%|█████▍    | 299M/548M [00:08<00:07, 33.7MB/s]
 55%|█████▌    | 302M/548M [00:09<00:08, 32.2MB/s]
 56%|█████▌    | 306M/548M [00:09<00:08, 31.8MB/s]
 56%|█████▋    | 309M/548M [00:09<00:07, 32.3MB/s]
 57%|█████▋    | 312M/548M [00:09<00:07, 33.5MB/s]
 58%|█████▊    | 316M/548M [00:09<00:07, 33.5MB/s]
 58%|█████▊    | 319M/548M [00:09<00:08, 29.3MB/s]
 59%|█████▊    | 322M/548M [00:09<00:07, 29.7MB/s]
 59%|█████▉    | 325M/548M [00:09<00:07, 30.7MB/s]
 60%|█████▉    | 329M/548M [00:09<00:07, 32.4MB/s]
 61%|██████    | 332M/548M [00:10<00:06, 33.6MB/s]
 61%|██████▏   | 336M/548M [00:10<00:06, 34.6MB/s]
 62%|██████▏   | 339M/548M [00:10<00:06, 35.8MB/s]
 63%|██████▎   | 344M/548M [00:10<00:05, 38.9MB/s]
 63%|██████▎   | 348M/548M [00:10<00:05, 39.6MB/s]
 64%|██████▍   | 352M/548M [00:10<00:05, 38.7MB/s]
 65%|██████▍   | 355M/548M [00:10<00:05, 38.2MB/s]
 66%|██████▌   | 359M/548M [00:10<00:05, 37.8MB/s]
 66%|██████▌   | 363M/548M [00:10<00:05, 37.7MB/s]
 67%|██████▋   | 367M/548M [00:10<00:04, 39.1MB/s]
 68%|██████▊   | 370M/548M [00:11<00:04, 38.1MB/s]
 68%|██████▊   | 374M/548M [00:11<00:04, 37.2MB/s]
 69%|██████▉   | 378M/548M [00:11<00:04, 37.2MB/s]
 70%|██████▉   | 381M/548M [00:11<00:04, 36.6MB/s]
 70%|███████   | 385M/548M [00:11<00:05, 33.6MB/s]
 71%|███████   | 388M/548M [00:11<00:05, 32.8MB/s]
 71%|███████▏  | 391M/548M [00:11<00:04, 33.5MB/s]
 72%|███████▏  | 395M/548M [00:11<00:04, 34.5MB/s]
 73%|███████▎  | 398M/548M [00:11<00:04, 35.2MB/s]
 73%|███████▎  | 402M/548M [00:12<00:04, 35.6MB/s]
 74%|███████▍  | 406M/548M [00:12<00:04, 36.3MB/s]
 75%|███████▍  | 409M/548M [00:12<00:04, 35.0MB/s]
 75%|███████▌  | 412M/548M [00:12<00:04, 35.0MB/s]
 76%|███████▌  | 416M/548M [00:12<00:03, 35.5MB/s]
 77%|███████▋  | 419M/548M [00:12<00:03, 35.8MB/s]
 77%|███████▋  | 423M/548M [00:12<00:03, 36.2MB/s]
 78%|███████▊  | 427M/548M [00:12<00:03, 37.3MB/s]
 79%|███████▊  | 431M/548M [00:12<00:03, 38.2MB/s]
 79%|███████▉  | 434M/548M [00:12<00:03, 37.0MB/s]DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1819054.465984 seconds

 80%|███████▉  | 438M/548M [00:13<00:03, 36.9MB/s]
 81%|████████  | 441M/548M [00:13<00:03, 35.1MB/s]
 81%|████████  | 445M/548M [00:13<00:03, 32.1MB/s]
 82%|████████▏ | 448M/548M [00:13<00:03, 28.9MB/s]
 82%|████████▏ | 451M/548M [00:13<00:03, 27.6MB/s]
 83%|████████▎ | 453M/548M [00:13<00:03, 27.4MB/s]
 83%|████████▎ | 456M/548M [00:13<00:03, 28.2MB/s]
 84%|████████▍ | 459M/548M [00:13<00:03, 29.1MB/s]
 84%|████████▍ | 463M/548M [00:14<00:02, 31.0MB/s]
 85%|████████▌ | 466M/548M [00:14<00:02, 32.6MB/s]
 86%|████████▌ | 470M/548M [00:14<00:02, 33.9MB/s]
 86%|████████▋ | 473M/548M [00:14<00:02, 34.8MB/s]
 87%|████████▋ | 477M/548M [00:14<00:01, 37.4MB/s]
 88%|████████▊ | 482M/548M [00:14<00:01, 40.7MB/s]
 89%|████████▊ | 486M/548M [00:14<00:01, 41.5MB/s]
 89%|████████▉ | 490M/548M [00:14<00:01, 34.5MB/s]
 90%|█████████ | 494M/548M [00:14<00:01, 29.1MB/s]
 91%|█████████ | 497M/548M [00:15<00:01, 27.7MB/s]
 91%|█████████ | 500M/548M [00:15<00:01, 27.1MB/s]
 92%|█████████▏| 502M/548M [00:15<00:01, 27.7MB/s]
 92%|█████████▏| 505M/548M [00:15<00:01, 28.6MB/s]
 93%|█████████▎| 509M/548M [00:15<00:01, 30.2MB/s]
 93%|█████████▎| 512M/548M [00:15<00:01, 32.1MB/s]
 94%|█████████▍| 516M/548M [00:15<00:01, 33.4MB/s]
 95%|█████████▍| 519M/548M [00:15<00:00, 34.5MB/s]
 95%|█████████▌| 523M/548M [00:15<00:00, 36.3MB/s]
 96%|█████████▋| 528M/548M [00:16<00:00, 39.7MB/s]
 97%|█████████▋| 532M/548M [00:16<00:00, 42.1MB/s]
 98%|█████████▊| 537M/548M [00:16<00:00, 42.5MB/s]
 99%|█████████▊| 541M/548M [00:16<00:00, 40.5MB/s]
 99%|█████████▉| 545M/548M [00:16<00:00, 39.3MB/s]
100%|██████████| 548M/548M [00:16<00:00, 34.8MB/s]
CCL INFO Connected all trees
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO NCCL_P2P_PXN_LEVEL set by environment to 0.
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:295 [0] NCCL INFO comm 0xa8975a0 rank 0 nranks 16 cudaDev 0 busId 100000 - Init COMPLETE
DEBUG:urllib3.connectionpool:https://eastus2.api.azureml.ms:443 ""POST /mlflow/v2.0/subscriptions/ID/resourceGroups/group-name/providers/Microsoft.MachineLearningServices/workspaces/workspace-name/api/2.0/mlflow/runs/log-metric HTTP/1.1"" 200 3
INFO:torch.nn.parallel.distributed:Reducer buckets have been rebuilt in this iteration.
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1819024.465007 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1818994.464612 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1818964.464085 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1818934.463633 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1818904.463188 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1818874.462657 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1818844.462206 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1818814.461749 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1818784.461 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1818754.460659 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1818724.46022 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1818694.459747 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1818664.459287 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1818634.458804 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1818604.458403 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1818574.457824 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1818544.457338 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1818514.456933 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1818484.456612 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1818454.456319 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1818424.456012 seconds
DEBUG:urllib3.util.retry:Incremented Retry for (url='/mlflow/v2.0/subscriptions/ID/resourceGroups/group-name/providers/Microsoft.MachineLearningServices/workspaces/workspace-name/api/2.0/mlflow/runs/log-metric'): Retry(total=4, connect=5, read=4, redirect=5, status=5)

DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1818394.455404 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1818364.454947 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1818334.454452 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1818304.454 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1818274.453534 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1818244.452846 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1818214.452398 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1818184.452029 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1818154.451633 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1818124.4512 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1818094.450751 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1818064.450306 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1818034.45002 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1818004.449531 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1817974.448973 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1817944.448577 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1817914.448138 seconds
DEBUG:urllib3.connectionpool:Resetting dropped connection: eastus2.api.azureml.ms
DEBUG:urllib3.connectionpool:https://eastus2.api.azureml.ms:443 ""POST /mlflow/v2.0/subscriptions/ID/resourceGroups/group-name/providers/Microsoft.MachineLearningServices/workspaces/workspace-name/api/2.0/mlflow/runs/log-metric HTTP/1.1"" 200 3
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1817884.447645 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1817854.446722 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1817824.446541 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1817794.446262 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1817764.445742 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1817734.445204 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1817704.44487 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1817674.444383 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1817644.443978 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1817614.44349 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1817584.442992 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1817554.44267 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1817524.442161 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1817494.441805 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1817464.44135 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1817434.440902 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1817404.440467 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1817374.440039 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1817344.43973 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1817314.439418 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1817284.439091 seconds


DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1817254.438576 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1817224.438157 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1817194.437633 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1817164.437279 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1817134.436685 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1817104.436322 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1817074.43583 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1817044.435438 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1817014.434976 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1816984.434547 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1816954.434273 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1816924.433759 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1816894.433344 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1816864.432835 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1816834.432637 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1816804.432003 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1816774.431427 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1816744.431215 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1816714.430857 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1816684.430536 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1816654.430204 seconds

DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1816624.42968 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1816594.429247 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1816564.428776 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1816534.428247 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1816504.427924 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1816474.427461 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1816444.42716 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1816414.426688 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1816384.426333 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1816354.425869 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1816324.425507 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1816294.425051 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1816264.424576 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1816234.424152 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1816204.423682 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1816174.423252 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1816144.42277 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1816114.422464 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1816084.422128 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1816054.421795 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1816024.42148 seconds

DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1815994.420954 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1815964.420474 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1815934.420039 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1815904.419586 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1815874.419196 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1815844.418742 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1815814.418306 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1815784.417866 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1815754.417415 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1815724.416996 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1815694.416506 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1815664.416144 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1815634.415684 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1815604.415033 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1815574.414747 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1815544.414102 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1815514.413227 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1815484.41307 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1815454.412745 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1815424.412451 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1815394.412119 seconds

DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1815364.411595 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1815334.411291 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1815304.410832 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1815274.410285 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1815244.409836 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1815214.409547 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1815184.409022 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1815154.408582 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1815124.407989 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1815094.407668 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1815064.407207 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1815034.406729 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1815004.406143 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1814974.405871 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1814944.4054 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1814914.404958 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1814884.40464 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1814854.404178 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1814824.403825 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1814794.403492 seconds
DEBUG:azureml.mlflow._common._authentication.azureml_token_authentication:Time to expire 1814764.403157 seconds

Train Epoch: 1 [0/246000 (0%)] Loss: 0.000000000000000
epoch is: 1 and train loss is 0.0
Train Epoch: 1 [1600/246000 (10%)] Loss: 0.000000000000000
epoch is: 1 and train loss is 0.0
Train Epoch: 1 [3200/246000 (21%)] Loss: 0.000000000000000
epoch is: 1 and train loss is 0.0
Train Epoch: 1 [4800/246000 (31%)] Loss: 0.000000000000000
epoch is: 1 and train loss is 0.0
Train Epoch: 1 [6400/246000 (42%)] Loss: 0.000000000000000
epoch is: 1 and train loss is 0.0
Train Epoch: 1 [8000/246000 (52%)] Loss: 0.000000000000000
epoch is: 1 and train loss is 0.0
Train Epoch: 1 [9600/246000 (62%)] Loss: 0.000000000000000
epoch is: 1 and train loss is 0.0
Train Epoch: 1 [11200/246000 (73%)] Loss: 0.000000000000000
epoch is: 1 and train loss is 0.0
Train Epoch: 1 [12800/246000 (83%)] Loss: 0.000000000000000
epoch is: 1 and train loss is 0.0
Train Epoch: 1 [14400/246000 (94%)] Loss: 0.000000000000000
epoch is: 1 and train loss is 0.0
Train Epoch: 2 [0/246000 (0%)] Loss: 0.000000000000000
epoch is: 2 and train loss is 0.0
Train Epoch: 2 [1600/246000 (10%)] Loss: 0.000000000000000
epoch is: 2 and train loss is 0.0
Train Epoch: 2 [3200/246000 (21%)] Loss: 0.000000000000000
epoch is: 2 and train loss is 0.0
Train Epoch: 2 [4800/246000 (31%)] Loss: 0.000000000000000
epoch is: 2 and train loss is 0.0
Train Epoch: 2 [6400/246000 (42%)] Loss: 0.000000000000000
epoch is: 2 and train loss is 0.0
Train Epoch: 2 [8000/246000 (52%)] Loss: 0.000000000000000
epoch is: 2 and train loss is 0.0
Train Epoch: 2 [9600/246000 (62%)] Loss: 0.000000000000000
epoch is: 2 and train loss is 0.0
Train Epoch: 2 [11200/246000 (73%)] Loss: 0.000000000000000
epoch is: 2 and train loss is 0.0
Train Epoch: 2 [12800/246000 (83%)] Loss: 0.000000000000000
epoch is: 2 and train loss is 0.0
Train Epoch: 2 [14400/246000 (94%)] Loss: 0.000000000000000
epoch is: 2 and train loss is 0.0
Train Epoch: 3 [0/246000 (0%)] Loss: 0.000000000000000
epoch is: 3 and train loss is 0.0
Train Epoch: 3 [1600/246000 (10%)] Loss: 0.000000000000000
epoch is: 3 and train loss is 0.0
Train Epoch: 3 [3200/246000 (21%)] Loss: 0.000000000000000
epoch is: 3 and train loss is 0.0
Train Epoch: 3 [4800/246000 (31%)] Loss: 0.000000000000000
epoch is: 3 and train loss is 0.0
Train Epoch: 3 [6400/246000 (42%)] Loss: 0.000000000000000
epoch is: 3 and train loss is 0.0
Train Epoch: 3 [8000/246000 (52%)] Loss: 0.000000000000000
epoch is: 3 and train loss is 0.0
Train Epoch: 3 [9600/246000 (62%)] Loss: 0.000000000000000
epoch is: 3 and train loss is 0.0
Train Epoch: 3 [11200/246000 (73%)] Loss: 0.000000000000000
epoch is: 3 and train loss is 0.0
Train Epoch: 3 [12800/246000 (83%)] Loss: 0.000000000000000
epoch is: 3 and train loss is 0.0
Train Epoch: 3 [14400/246000 (94%)] Loss: 0.000000000000000
epoch is: 3 and train loss is 0.0
Train Epoch: 4 [0/246000 (0%)] Loss: 0.000000000000000
epoch is: 4 and train loss is 0.0
Train Epoch: 4 [1600/246000 (10%)] Loss: 0.000000000000000
epoch is: 4 and train loss is 0.0
Train Epoch: 4 [3200/246000 (21%)] Loss: 0.000000000000000
epoch is: 4 and train loss is 0.0
Train Epoch: 4 [4800/246000 (31%)] Loss: 0.000000000000000
epoch is: 4 and train loss is 0.0
Train Epoch: 4 [6400/246000 (42%)] Loss: 0.000000000000000
epoch is: 4 and train loss is 0.0
Train Epoch: 4 [8000/246000 (52%)] Loss: 0.000000000000000
epoch is: 4 and train loss is 0.0
Train Epoch: 4 [9600/246000 (62%)] Loss: 0.000000000000000
epoch is: 4 and train loss is 0.0
Train Epoch: 4 [11200/246000 (73%)] Loss: 0.000000000000000
epoch is: 4 and train loss is 0.0
Train Epoch: 4 [12800/246000 (83%)] Loss: 0.000000000000000
epoch is: 4 and train loss is 0.0
Train Epoch: 4 [14400/246000 (94%)] Loss: 0.000000000000000
epoch is: 4 and train loss is 0.0
Train Epoch: 5 [0/246000 (0%)] Loss: 0.000000000000000
epoch is: 5 and train loss is 0.0
Train Epoch: 5 [1600/246000 (10%)] Loss: 0.000000000000000
epoch is: 5 and train loss is 0.0
Train Epoch: 5 [3200/246000 (21%)] Loss: 0.000000000000000
epoch is: 5 and train loss is 0.0
Train Epoch: 5 [4800/246000 (31%)] Loss: 0.000000000000000
epoch is: 5 and train loss is 0.0
Train Epoch: 5 [6400/246000 (42%)] Loss: 0.000000000000000
epoch is: 5 and train loss is 0.0
Train Epoch: 5 [8000/246000 (52%)] Loss: 0.000000000000000
epoch is: 5 and train loss is 0.0
Train Epoch: 5 [9600/246000 (62%)] Loss: 0.000000000000000
epoch is: 5 and train loss is 0.0
Train Epoch: 5 [11200/246000 (73%)] Loss: 0.000000000000000
epoch is: 5 and train loss is 0.0
Train Epoch: 5 [12800/246000 (83%)] Loss: 0.000000000000000
epoch is: 5 and train loss is 0.0
Train Epoch: 5 [14400/246000 (94%)] Loss: 0.000000000000000
epoch is: 5 and train loss is 0.0
end: 05:19:29.147170
63f59200-0c4f-43f2-84ea-3cb136c4f7bc
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:302 [0] NCCL INFO [Service thread] Connection closed by localRank -1

3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:302 [0] proxy.cc:1111 NCCL WARN [Service thread] Unknown command 66326 from localRank -1


3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:302 [0] proxy.cc:1111 NCCL WARN [Service thread] Unknown command 66326 from localRank -1


3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:302 [0] proxy.cc:1111 NCCL WARN [Service thread] Unknown command 16843542 from localRank -1


3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:302 [0] proxy.cc:1111 NCCL WARN [Service thread] Unknown command 16843542 from localRank -1


3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:302 [0] proxy.cc:1111 NCCL WARN [Service thread] Unknown command 66326 from localRank -1


3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:302 [0] proxy.cc:1111 NCCL WARN [Service thread] Unknown command 16843542 from localRank -1


3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:302 [0] proxy.cc:1111 NCCL WARN [Service thread] Unknown command 66326 from localRank -1


3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:302 [0] proxy.cc:1111 NCCL WARN [Service thread] Unknown command 16843542 from localRank -1


3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:302 [0] proxy.cc:1111 NCCL WARN [Service thread] Unknown command 790 from localRank -1


3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:302 [0] proxy.cc:1111 NCCL WARN [Service thread] Unknown command 790 from localRank -1


3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:302 [0] proxy.cc:1111 NCCL WARN [Service thread] Unknown command 16843542 from localRank -1


3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:302 [0] proxy.cc:1111 NCCL WARN [Service thread] Unknown command 16843542 from localRank -1

3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:302 [0] NCCL INFO [Service thread] Connection closed by localRank 0
3a742b5dcfec4b4b8658b52b96a0c2d3000000:39:39 [0] NCCL INFO comm 0xa8975a0 rank 0 nranks 16 cudaDev 0 busId 100000 - Abort COMPLETE

```


Here's all the properties:
```
{
    ""runId"": ""63f59200-0c4f-43f2-84ea-3cb136c4f7bc"",
    ""runUuid"": ""7646e7ce-32bc-45a5-b78f-8aaeb1e1f90c"",
    ""parentRunUuid"": ""e9db720e-c082-4ec5-a737-78bda3bfb6e1"",
    ""rootRunUuid"": ""e9db720e-c082-4ec5-a737-78bda3bfb6e1"",
    ""target"": ""mona-gpu-cluster"",
    ""status"": ""Completed"",
    ""parentRunId"": ""modest_crayon_zq9vlm41hg"",
    ""dataContainerId"": ""dcid.63f59200-0c4f-43f2-84ea-3cb136c4f7bc"",
    ""createdTimeUtc"": ""2023-05-23T20:15:36.333113+00:00"",
    ""startTimeUtc"": ""2023-05-23T20:51:01.806Z"",
    ""endTimeUtc"": ""2023-05-24T05:22:20.576Z"",
    ""error"": null,
    ""warnings"": null,
    ""tags"": {
        ""azureml.nodeid"": ""238161b6"",
        ""azureml.pipeline"": ""modest_crayon_zq9vlm41hg"",
        ""_aml_system_ComputeTargetStatus"": ""{\""AllocationState\"":\""steady\"",\""PreparingNodeCount\"":0,\""RunningNodeCount\"":0,\""CurrentNodeCount\"":0}"",
        ""team"": ""ARD"",
        ""dataset"": ""FAT120K"",
        ""model"": ""pose""
    },
    ""properties"": {
        ""mlflow.source.git.repoURL"": ""https://ToyotaMaterialHandling@dev.azure.com/ToyotaMaterialHandling/PROJ_NAME/_git/PROJ_NAME,
        ""mlflow.source.git.commit"": ""a7b5a44768551e8e5a963f64efd78b777aac66a6"",
        ""azureml.git.dirty"": ""True"",
        ""azureml.DevPlatv2"": ""true"",
        ""azureml.DatasetAccessMode"": ""Asset"",
        ""ContentSnapshotId"": ""63a23d89-18a8-4f9d-b490-0ae7692aa08a"",
        ""StepType"": ""PythonScriptStep"",
        ""ComputeTargetType"": ""AmlCompute"",
        ""azureml.moduleid"": ""3db667cc-4a97-480a-8f7a-ee84b7f85004"",
        ""azureml.moduleName"": ""azureml_anonymous"",
        ""azureml.moduleVersion"": ""1"",
        ""azureml.runsource"": ""azureml.StepRun"",
        ""azureml.nodeid"": ""238161b6"",
        ""azureml.pipelinerunid"": ""modest_crayon_zq9vlm41hg"",
        ""azureml.pipeline"": ""modest_crayon_zq9vlm41hg"",
        ""azureml.pipelineComponent"": ""masterescloud"",
        ""_azureml.ComputeTargetType"": ""amlctrain"",
        ""ProcessInfoFile"": ""azureml-logs/process_info.json"",
        ""ProcessStatusFile"": ""azureml-logs/process_status.json""
    },
    ""parameters"": {
        ""instance_per_node"": ""16"",
        ""cuda_available"": ""True"",
        ""distributed"": ""True"",
        ""distributed_backend"": ""nccl"",
        ""batch_size"": ""16"",
        ""num_epochs"": ""5"",
        ""num_workers"": ""5"",
        ""cpu_count"": ""24"",
        ""prefetch_factor"": ""4"",
        ""persistent_workers"": ""1"",
        ""pin_memory"": ""1"",
        ""non_blocking"": ""0"",
        ""model_arch"": ""vgg16"",
        ""model_arch_pretrained"": ""1"",
        ""optimizer.learning_rate"": ""0.0001"",
        ""enable_profiling"": ""0"",
        ""cuda_device_count"": ""4"",
        ""cuda_device_name"": ""Tesla K80"",
        ""cuda_device_major"": ""3"",
        ""cuda_device_minor"": ""7"",
        ""cuda_device_memory"": ""11997020160"",
        ""cuda_device_processor_count"": ""13""
    },
    ""services"": {},
    ""inputDatasets"": [],
    ""outputDatasets"": [],
    ""runDefinition"": {
        ""script"": null,
        ""command"": ""python3 train.py --data $AZUREML_DATAREFERENCE_train_data --batch_size $AZUREML_PARAMETER_batch_size --num_workers $AZUREML_PARAMETER_num_workers --prefetch_factor $AZUREML_PARAMETER_prefetch_factor --persistent_workers $AZUREML_PARAMETER_persistent_workers --pin_memory $AZUREML_PARAMETER_pin_memory --non_blocking $AZUREML_PARAMETER_non_blocking --model_arch $AZUREML_PARAMETER_model_arch --model_arch_pretrained $AZUREML_PARAMETER_model_arch_pretrained --num_epochs $AZUREML_PARAMETER_num_epochs --learning_rate $AZUREML_PARAMETER_learning_rate --checkpoints DatasetOutputConfig:checkpoints --register_model_as $AZUREML_PARAMETER_register_model_as --enable_profiling $AZUREML_PARAMETER_enable_profiling"",
        ""useAbsolutePath"": false,
        ""arguments"": [],
        ""sourceDirectoryDataStore"": null,
        ""framework"": ""PyTorch"",
        ""communicator"": ""Nccl"",
        ""target"": ""mona-gpu-cluster"",
        ""dataReferences"": {},
        ""data"": {},
        ""inputAssets"": {
            ""train_data"": {
                ""asset"": {
                    ""assetId"": URI,
                    ""type"": ""UriFolder""
                },
                ""mechanism"": ""Download"",
                ""environmentVariableName"": ""AZURE_ML_INPUT_train_data"",
                ""pathOnCompute"": null,
                ""overwrite"": true,
                ""options"": {
                    ""IsEvalMode"": ""False"",
                    ""ReadWrite"": ""False"",
                    ""ForceFolder"": ""False""
                }
            }
        },
        ""outputData"": {
            ""checkpoints"": {
                ""outputLocation"": {
                    ""dataset"": null,
                    ""dataPath"": null,
                    ""uri"": {
                        ""path"": ""azureml://datastores/mydatastore/paths/azureml/${{name}}/checkpoints/"",
                        ""isFile"": false
                    },
                    ""type"": ""UriFolder""
                },
                ""mechanism"": ""Upload"",
                ""additionalOptions"": {
                    ""pathOnCompute"": null,
                    ""registrationOptions"": {
                        ""name"": null,
                        ""description"": null,
                        ""tags"": null,
                        ""datasetRegistrationOptions"": null
                    },
                    ""uploadOptions"": null,
                    ""mountOptions"": null
                },
                ""environmentVariableName"": ""AZURE_ML_OUTPUT_checkpoints""
            }
        },
        ""datacaches"": [],
        ""jobName"": null,
        ""maxRunDurationSeconds"": null,
        ""nodeCount"": 4,
        ""instanceTypes"": [],
        ""priority"": null,
        ""credentialPassthrough"": false,
        ""identity"": null,
        ""environment"": {
            ""name"": ""nvidia_pytorch"",
            ""version"": ""113"",
            ""assetId"": URI,
            ""autoRebuild"": false,
            ""python"": {
                ""interpreterPath"": null,
                ""userManagedDependencies"": true,
                ""condaDependencies"": null,
                ""baseCondaEnvironment"": null
            },
            ""environmentVariables"": {},
            ""docker"": {
                ""baseImage"": null,
                ""platform"": {
                    ""os"": ""Linux"",
                    ""architecture"": ""amd64""
                },
                ""baseDockerfile"": null,
                ""buildContext"": {
                    ""locationType"": ""storageAccount"",
                    ""location"": LOCATION
                    ""dockerfilePath"": ""Dockerfile""
                },
                ""baseImageRegistry"": null
            },
            ""spark"": {
                ""repositories"": [],
                ""packages"": [],
                ""precachePackages"": true
            },
            ""inferencingStackVersion"": null
        },
        ""history"": {
            ""outputCollection"": true,
            ""directoriesToWatch"": [
                ""logs""
            ],
            ""enableMLflowTracking"": false
        },
        ""spark"": {
            ""configuration"": {}
        },
        ""parallelTask"": {
            ""maxRetriesPerWorker"": 0,
            ""workerCountPerNode"": 1,
            ""terminalExitCodes"": null,
            ""configuration"": {}
        },
        ""amlCompute"": {
            ""name"": null,
            ""vmSize"": null,
            ""retainCluster"": false,
            ""clusterMaxNodeCount"": 1
        },
        ""aiSuperComputer"": {
            ""instanceType"": ""D2"",
            ""imageVersion"": ""pytorch-1.7.0"",
            ""location"": null,
            ""aiSuperComputerStorageData"": null,
            ""interactive"": false,
            ""scalePolicy"": null,
            ""virtualClusterArmId"": null,
            ""tensorboardLogDirectory"": null,
            ""sshPublicKey"": null,
            ""sshPublicKeys"": null,
            ""enableAzmlInt"": true,
            ""priority"": ""Medium"",
            ""slaTier"": ""Standard"",
            ""userAlias"": null
        },
        ""kubernetesCompute"": {
            ""instanceType"": null
        },
        ""tensorflow"": {
            ""workerCount"": 0,
            ""parameterServerCount"": 0
        },
        ""mpi"": {
            ""processCountPerNode"": 1
        },
        ""pyTorch"": {
            ""communicationBackend"": ""Nccl"",
            ""processCount"": 16
        },
        ""hdi"": {
            ""yarnDeployMode"": ""None""
        },
        ""containerInstance"": {
            ""region"": null,
            ""cpuCores"": 2,
            ""memoryGb"": 3.5
        },
        ""exposedPorts"": null,
        ""docker"": {
            ""useDocker"": true,
            ""sharedVolumes"": true,
            ""shmSize"": ""2g"",
            ""arguments"": []
        },
        ""cmk8sCompute"": {
            ""configuration"": {}
        },
        ""globalJobDispatcher"": {
            ""myResourceOnly"": false,
            ""lowPriorityVMTolerant"": true
        },
        ""commandReturnCodeConfig"": {
            ""returnCode"": ""Zero"",
            ""successfulReturnCodes"": []
        },
        ""environmentVariables"": {
            ""NCCL_DEBUG"": ""INFO"",
            ""NCCL_IB_DISABLE"": ""1"",
            ""NCCL_SOCKET_IFNAME"": ""eth0"",
            ""NCCL_P2P_PXN_LEVEL"": ""0"",
            ""CUDA_DEVICE_ORDER"": ""PCI_BUS_ID"",
            ""TORCH_DISTRIBUTED_DEBUG"": ""DETAIL"",
            ""AZUREML_PARAMETER_Node_Count"": ""4"",
            ""AZUREML_PARAMETER_batch_size"": ""256"",
            ""AZUREML_PARAMETER_num_workers"": ""5"",
            ""AZUREML_PARAMETER_prefetch_factor"": ""4"",
            ""AZUREML_PARAMETER_persistent_workers"": ""True"",
            ""AZUREML_PARAMETER_pin_memory"": ""True"",
            ""AZUREML_PARAMETER_non_blocking"": ""False"",
            ""AZUREML_PARAMETER_manualseed"": ""42"",
            ""AZUREML_PARAMETER_model_arch"": ""vgg16"",
            ""AZUREML_PARAMETER_model_arch_pretrained"": ""True"",
            ""AZUREML_PARAMETER_num_epochs"": ""5"",
            ""AZUREML_PARAMETER_learning_rate"": ""0.0001"",
            ""AZUREML_PARAMETER_momentum"": ""0.9"",
            ""AZUREML_PARAMETER_register_model_as"": MODEL_NAME,
            ""AZUREML_PARAMETER_enable_profiling"": ""False"",
            ""AZUREML_PARAMETER_multiprocessing_sharing_strategy"": """"
        },
        ""applicationEndpoints"": {},
        ""parameters"": [],
        ""dataBricks"": {
            ""workers"": 0,
            ""minimumWorkerCount"": 0,
            ""maxMumWorkerCount"": 0,
            ""sparkVersion"": ""4.0.x-scala2.11"",
            ""nodeTypeId"": ""Standard_D3_v2"",
            ""sparkConf"": {},
            ""sparkEnvVars"": {},
            ""instancePoolId"": null,
            ""timeoutSeconds"": 0,
            ""jarLibraries"": [],
            ""eggLibraries"": [],
            ""whlLibraries"": [],
            ""pypiLibraries"": [],
            ""rCranLibraries"": [],
            ""mavenLibraries"": [],
            ""linkedADBWorkspaceMetadata"": null,
            ""databrickResourceId"": null,
            ""autoScale"": false
        },
        ""componentConfiguration"": {
            ""componentIdentifier"": IDENTIFIER
        }
    },
    ""logFiles"": {
        ""azureml-logs/20_image_build_log.txt"": URL,
        ""logs/azureml/executionlogs.txt"": URL,
        ""logs/azureml/stderrlogs.txt"": URL,
        ""logs/azureml/stdoutlogs.txt"": URL
    },
    ""jobCost"": {
        ""chargedCpuCoreSeconds"": 2945088,
        ""chargedCpuMemoryMegabyteSeconds"": null,
        ""chargedGpuSeconds"": null,
        ""chargedNodeUtilizationSeconds"": 3067877.05425
    },
    ""revision"": 17,
    ""runTypeV2"": {
        ""orchestrator"": ""Execution"",
        ""traits"": [
            ""azureml.StepRun"",
            ""scriptRun"",
            ""remote"",
            ""AlmostCommonRuntime"",
            ""OsType:Linux"",
            ""CommonRuntime"",
            ""mlflow""
        ],
        ""attribution"": ""Aether"",
        ""computeType"": ""AmlcTrain""
    },
    ""settings"": {},
    ""computeRequest"": {
        ""nodeCount"": 4,
        ""gpuCount"": 0
    },
    ""compute"": {
        ""target"": ""mona-gpu-cluster"",
        ""targetType"": ""amlcompute"",
        ""vmSize"": null,
        ""instanceType"": null,
        ""instanceCount"": 4,
        ""gpuCount"": 0,
        ""priority"": null,
        ""region"": null,
        ""armId"": null,
        ""properties"": null
    },
    ""createdBy"": {
        ""userObjectId"": ""2d5cd057-35c3-4f5c-ad3e-d9d376e8d926"",
        ""userPuId"": null,
        ""userIdp"": ""https://sts.windows.net/c954f2eb-f231-49c3-a14a-2dd6682a00f1/"",
        ""userAltSecId"": null,
        ""userIss"": ""https://sts.windows.net/c954f2eb-f231-49c3-a14a-2dd6682a00f1/"",
        ""userTenantId"": ""c954f2eb-f231-49c3-a14a-2dd6682a00f1"",
        ""userName"": ""21ecc095-b175-4cd1-ae47-3b0a3d917756"",
        ""upn"": null
    },
    ""computeDuration"": ""08:31:18.7705425"",
    ""effectiveStartTimeUtc"": null,
    ""runNumber"": 1684872936,
    ""rootRunId"": ""modest_crayon_zq9vlm41hg"",
    ""userId"": ""2d5cd057-35c3-4f5c-ad3e-d9d376e8d926"",
    ""statusRevision"": 6,
    ""currentComputeTime"": null,
    ""lastStartTimeUtc"": null,
    ""lastModifiedBy"": {
        ""userObjectId"": ""2d5cd057-35c3-4f5c-ad3e-d9d376e8d926"",
        ""userPuId"": null,
        ""userIdp"": ""https://sts.windows.net/c954f2eb-f231-49c3-a14a-2dd6682a00f1/"",
        ""userAltSecId"": null,
        ""userIss"": ""azureml"",
        ""userTenantId"": ""c954f2eb-f231-49c3-a14a-2dd6682a00f1"",
        ""userName"": ""21ecc095-b175-4cd1-ae47-3b0a3d917756"",
        ""upn"": null
    },
    ""lastModifiedUtc"": ""2023-05-23T20:57:28.998715+00:00"",
    ""duration"": ""08:31:18.7705425"",
    ""inputs"": {
        ""train_data"": {
            ""assetId"": URI
            ""type"": ""UriFolder""
        }
    },
    ""outputs"": {
        ""checkpoints"": {
            ""assetId"": URI,
            ""type"": ""UriFolder""
        }
    },
    ""currentAttemptId"": 1
}
```",get error also another code training azure cluster node please let know may need information switched still problem dump example code false logger print save hyper print world size print global rank else raise yet distributed data loading training add device team model train print epoch epoch data loader print epoch train loss epoch loss else print epoch epoch data loader print epoch test loss epoch loss print azure tue system information tue python version version module location registry environment true token flask jinja alembic click docker markdown warning exception raised module process group added key store rank rank barrier key set environment bootstrap find symbol loaded net find symbol loaded coll sharp version path set environment device found set environment set environment network socket topology detection could read topology detection could read topology detection could read topology detection could read topology detection could read topology detection could read topology detection could read topology detection could read topology detection network path device first convert could find value dictionary falling back convert could find value dictionary falling back convert could find value dictionary falling back convert could find value dictionary falling back system net setting affinity pattern type pattern type pattern type tree tree channel channel ring ring channel receive via channel receive via channel via channel via connected channel send via channel receive via channel send via channel receive via sub id id resource group starting daemon first instance time expire fetching cloud known start loading cloud start loading cloud starting new connection get active directory loaded active directory cloud set active directory loaded active directory cloud set active directory loaded active directory cloud set active directory loaded active directory cloud set active directory loaded active directory cloud set active directory loaded active directory cloud set active directory loaded active directory cloud set active directory loaded active directory cloud set active directory loaded active directory cloud set finish loading cloud finish loading cloud cloud fetched known cloud found falling back default new service context object starting new connection get none status update remote run training script path start object interest cracker manual seed set world size global rank true process group device load data train data size training data batch size training data load type class training network time expire connected coll per peer set environment rank complete post reducer rebuilt iteration time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire retry retry time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire connection post time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire time expire train epoch loss epoch train loss train epoch loss epoch train loss train epoch loss epoch train loss train epoch loss epoch train loss train epoch loss epoch train loss train epoch loss epoch train loss train epoch loss epoch train loss train epoch loss epoch train loss train epoch loss epoch train loss train epoch loss epoch train loss train epoch loss epoch train loss train epoch loss epoch train loss train epoch loss epoch train loss train epoch loss epoch train loss train epoch loss epoch train loss train epoch loss epoch train loss train epoch loss epoch train loss train epoch loss epoch train loss train epoch loss epoch train loss train epoch loss epoch train loss train epoch loss epoch train loss train epoch loss epoch train loss train epoch loss epoch train loss train epoch loss epoch train loss train epoch loss epoch train loss train epoch loss epoch train loss train epoch loss epoch train loss train epoch loss epoch train loss train epoch loss epoch train loss train epoch loss epoch train loss train epoch loss epoch train loss train epoch loss epoch train loss train epoch loss epoch train loss train epoch loss epoch train loss train epoch loss epoch train loss train epoch loss epoch train loss train epoch loss epoch train loss train epoch loss epoch train loss train epoch loss epoch train loss train epoch loss epoch train loss train epoch loss epoch train loss train epoch loss epoch train loss train epoch loss epoch train loss train epoch loss epoch train loss train epoch loss epoch train loss train epoch loss epoch train loss train epoch loss epoch train loss train epoch loss epoch train loss train epoch loss epoch train loss train epoch loss epoch train loss end service thread connection closed warn service thread unknown command warn service thread unknown command warn service thread unknown command warn service thread unknown command warn service thread unknown command warn service thread unknown command warn service thread unknown command warn service thread unknown command warn service thread unknown command warn service thread unknown command warn service thread unknown command warn service thread unknown command service thread connection closed rank abort complete target status error null null team model pose true true asset true distributed true script null command python data false null framework communicator target data asset type mechanism null overwrite true false false false null null path name false type mechanism null name null description null null null null null null null priority null false identity null environment name version false python null true null null docker null platform o architecture null location location null spark true null history true false spark configuration null configuration name null null false location null null interactive false null null null null null true priority medium standard null null none region null null docker true true configuration false true zero detail true true false true false null null null false identifier null null revision orchestrator execution remote attribution compute target null null priority null region null null null null null null null null null null null null duration type type,issue,negative,negative,neutral,neutral,negative,negative
1560966118,Why has #8514 been merged? I enabled auto-merge. Cross-version tests are optional checks (we can't mark them as required because they run optionally when relevant files are changed). So it was merged.,optional ca mark run optionally relevant,issue,negative,positive,positive,positive,positive,positive
1560960296,@liangz1 Feel free to merge if all the CI checks are green :),feel free merge green,issue,positive,positive,neutral,neutral,positive,positive
1560797687,"@okoben's solution works, but it feels very much that an explicit extra argument is needed for `mlflow gc` in addition to the `--backend-store-uri` one",solution work much explicit extra argument addition one,issue,negative,positive,neutral,neutral,positive,positive
1560701478,"PR is ready:
https://github.com/mlflow/mlflow/pull/8508

Note that `atexit` hook does not work, see explanation: https://github.com/mlflow/mlflow/pull/8508#issuecomment-1560426471

So that with my fix, you still need to add `spark.stop()` at the end of main thread to ensure spark callback server shut down properly.

@florent-brosse ",ready note hook work see explanation fix still need add end main thread ensure spark server shut properly,issue,positive,positive,positive,positive,positive,positive
1560673410,"Yes, the experiments are accessible, thanks for the responsiveness.",yes accessible thanks responsiveness,issue,positive,positive,positive,positive,positive,positive
1560665591,@ka1mar Thanks for reporting this ! Exciting to see your fixing PR!,thanks exciting see fixing,issue,positive,positive,positive,positive,positive,positive
1560661429,"Hi @monajalal could you set logging level to DEBUG to and paste the ""full stack trace"" of the root cause exception ? Thank you!",hi could set logging level paste full stack trace root cause exception thank,issue,negative,positive,positive,positive,positive,positive
1560634607,"@ChekrounMohammed @ot-babs @WeichenXu123 
Thanks for reporting, the issue has been fixed a while ago. Can you confirm the experiments are accessible in Databricks Community Cloud?",thanks issue fixed ago confirm accessible community cloud,issue,negative,positive,positive,positive,positive,positive
1560546112,"Hello! Great work on this tool! 
In Table View, the metrics that are displayed are the ones from the last epoch. Would be nice to have the minimum / maximum achieved for that model instead of the last metric obtained.",hello great work tool table view metric displayed last epoch would nice minimum maximum model instead last metric,issue,positive,positive,positive,positive,positive,positive
1560426471,"I just tested atexit hook but I found it does not work,
because atexit hook is called only after all non-daemon background threads exit,
but the spark callback server will generate some non-daemon background threads which blocks triggering atexit hook when main thread exits,
so that I removed atexit hook code,
user can add `sparkSession.stop()` at the end of main thread code to make the python process exit properly.",tested hook found work hook background exit spark server generate background hook main thread removed hook code user add end main thread code make python process exit properly,issue,negative,positive,positive,positive,positive,positive
1560360502,"> @serena-ruan Shall we run a pressure tests ? i.e. run test with many threads (e.g. > 500 threads) for a long time to confirm there is no new concurrency issue and verify that the file content is always correct (you can verify the sha256sum of the downloaded file).

Yes that's a good idea! Will do!",shall run pressure run test many long time confirm new concurrency issue verify file content always correct verify file yes good idea,issue,positive,positive,positive,positive,positive,positive
1560358440,@serena-ruan Shall we run a pressure tests ? i.e. run test with many threads (e.g. > 500 threads) for a long time to confirm there is no new concurrency issue and verify that the file content is always correct (you can verify the sha256sum of the downloaded file). ,shall run pressure run test many long time confirm new concurrency issue verify file content always correct verify file,issue,negative,positive,positive,positive,positive,positive
1560310550,"> Had the same, setting MLFLOW_TRACKING_URI environmental variable on server side (in my case MLFLOW_TRACKING_URI=mysql+pymysql://${MYSQL_USER}:${MYSQL_PASSWORD}@db:3306/${MYSQL_DATABASE}) solved the problem.

Thanks @ka1mar, it is solved.",setting environmental variable server side case problem thanks,issue,negative,positive,positive,positive,positive,positive
1560250610,"> > It decreases time to download a 1GB file from 18.x seconds to 1.x seconds 😄
> 
> Faster than I expected! Does the downloaded file has the same contents as the original file? The notebook I shared just downloads a file and doesn't check its contents.

That's a good point! I checked they're the same.",time file faster file content original file notebook file check content good point checked,issue,positive,positive,positive,positive,positive,positive
1560017614,"> I got it. Another workaround is you can create sub-directory under the s3 bucket and configure different MLflow server to use different s3 sub-directory as the root artifact storage path, e.g.
> 
> s3://bucket_name/folder1 s3://bucket_name/folder2
> 
> What do you think ?

This works well. Thanks!",got another create bucket configure different server use different root artifact storage path think work well thanks,issue,positive,positive,neutral,neutral,positive,positive
1559998239,"Had the same, setting MLFLOW_TRACKING_URI environmental variable on server side (in my case MLFLOW_TRACKING_URI=mysql+pymysql://${MYSQL_USER}:${MYSQL_PASSWORD}@db:3306/${MYSQL_DATABASE}) solved the problem.",setting environmental variable server side case problem,issue,negative,neutral,neutral,neutral,neutral,neutral
1559331704,This is a fantastic idea. @PenHsuanWang could you add a brief description to the docs (https://www.mlflow.org/docs/latest/cli.html#mlflow-gc) (set here: https://github.com/mlflow/mlflow/blob/7796af26c2d3f9910c91c5c96145afbb226be6b9/mlflow/cli.py#L464 in pydoc) to let users know about this change in behavior and how they can 'clean up' uri locations that have been passed over due to path resolution issues?,fantastic idea could add brief description set let know change behavior due path resolution,issue,positive,positive,neutral,neutral,positive,positive
1559080006,"Got it , we hardcode the options here:
https://github.com/mlflow/mlflow/blob/b61e3ce24219e402aac05ec37d09a00dff5b09c4/mlflow/server/js/src/experiment-tracking/components/runs-compare/config/RunsCompareConfigureContourChart.tsx#L144

How large number do you want to use ? We can increase it :)


On the other way, you can select any number of runs and then click ""compare"" button, then in the comparing run page, you can click `Contour Plot`, there you can see more than 20 points if you have more than 20 runs being compared.

@xtfocus ",got large number want use increase way select number click compare button run page click contour plot see,issue,negative,positive,positive,positive,positive,positive
1559063053,"> Btw do you know why does it happen? In the CallbackServerParameters `daemonize=True` should prevent this, right?

This should be spark code bug. @@HyukjinKwon know more details. To support existing spark versions, we have to add handling code in mlflow side.",know happen prevent right spark code bug know support spark add handling code side,issue,positive,positive,positive,positive,positive,positive
1559028404,"Btw do you know why does it happen? In the CallbackServerParameters `daemonize=True` should prevent this, right?",know happen prevent right,issue,negative,positive,positive,positive,positive,positive
1559020396,"Hi Weichen, 

I like your solution because I tried to disable the autolog and it did nothing.
Sure fill a PR that's your solution and you'll be faster than me.
Thanks again.

Florent",hi like solution tried disable nothing sure fill solution faster thanks florent,issue,positive,positive,positive,positive,positive,positive
1559005378,"Getting the same problem, and i'm running version 12.2 LTS (includes Apache Spark 3.3.2, Scala 2.12)
",getting problem running version apache spark scala,issue,negative,neutral,neutral,neutral,neutral,neutral
1559000636,"I suggest to update mlflow code like:

* When `mlflow.spark.autolog(disable=True)` is called, trigger  `spark.sparkContext._gateway.shutdown_callback_server()`
* ~~We register a `sys.atexit` hook, in the hook,  in the atexit hook, checking whether `mlflow.spark` autologging is ON, if it is ON we should call `mlflow.spark.autolog(disable=True)` to disable it (so that the spark callback server is shut down properly)~~
* We hook `sparkSession.stop` method and shut down the spark callback server when `sparkSession.stop` is called.


I can file a PR for this, if you are not familiar with related code :)",suggest update code like trigger register hook hook hook whether call disable spark server shut properly hook method shut spark server file familiar related code,issue,positive,positive,positive,positive,positive,positive
1558966648,"I think we can call `spark.sparkContext._gateway.shutdown_callback_server()`, this is a better way.",think call better way,issue,negative,positive,positive,positive,positive,positive
1558960153,"I can reproduce your issue. I tested on spark 3.3 and spark 3.4, both of them have the issue.",reproduce issue tested spark spark issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1558842163,I do not encounter the issue anymore with MLflow version 2.3.2 and scikit-learn version 1.2.2,encounter issue version version,issue,negative,neutral,neutral,neutral,neutral,neutral
1558833165,"I've tried with a new venv : pyspark 3.4.0 and mlflow 2.3.2
With spark.stop() the spark UI is no more available but the script never finishes. Some threads are still running.
![Capture d’écran 2023-05-23 à 10 44 14](https://github.com/mlflow/mlflow/assets/33132524/f3fc5594-306d-4fcd-8a38-bf3d63af52b9)
",tried new spark available script never still running capture,issue,negative,positive,positive,positive,positive,positive
1558819941,"> It decreases time to download a 1GB file from 18.x seconds to 1.x seconds 😄

Faster than I expected! Does the downloaded file has the same contents as the original file? The notebook I shared just downloads a file and doesn't check its contents.",time file faster file content original file notebook file check content,issue,negative,positive,positive,positive,positive,positive
1558800461,"You only need to call `mlflow.pytorch.autolog()` in main thread once.

It supports pytorch DDP training.

See https://github.com/mlflow/mlflow/blob/b61e3ce24219e402aac05ec37d09a00dff5b09c4/tests/pytorch/test_pytorch_autolog.py#L348",need call main thread training see,issue,negative,positive,positive,positive,positive,positive
1558753698,"I discussed with Mlflow dev team members, we recommand to use ""run_name_prefix"" in your case:
See https://github.com/mlflow/mlflow/pull/7763/files

i.e., adds an ""experiment"" section in recipe profile yaml file, and inside ""experiment"" section, adds a ""run_name_prefix"" config.",dev team recommand use case see experiment section recipe profile file inside experiment section,issue,negative,neutral,neutral,neutral,neutral,neutral
1558751219,"Emm, I cannot reproduce your issue, what's your pyspark version ?

CC @HyukjinKwon

In `mlflow.spark.autolog`, we register a callback server on py4j gateway:
https://github.com/mlflow/mlflow/blob/b61e3ce24219e402aac05ec37d09a00dff5b09c4/mlflow/_spark_autologging.py#L100

any reason that might cause the issue ?

@florent-brosse 

Did you try to add `spark.stop()` at the end of the script and see whether the python process can exit ?
",reproduce issue version register server gateway reason might cause issue try add end script see whether python process exit,issue,negative,neutral,neutral,neutral,neutral,neutral
1558709970,"Hi @johny-c , have you found a nice way of logging nested dictionaries parameters ? Have you thought of a UI element to ""browse"" such parameters (e.g. wrapping/unwrapping a tree of parameters...) ?

Since this is still not managed, I am thinking of using a dictionary ""flattening"" option (e.g. [this SO question](https://stackoverflow.com/questions/6027558/flatten-nested-dictionaries-compressing-keys)), that converts nested keys into flat ""level1__level2"" keys, that stay grouped together in the UI by alphabetical ordering.

```python
param = {""level1"": {""level2-key1"": ""value1"", ""level2-key2"": ""value2""}}
mlflow.log_params(flatten(param, separator='__'))
```

![image](https://github.com/mlflow/mlflow/assets/10188846/ea755c6e-ed87-411b-9fe0-5870192684c8)
",hi found nice way logging thought element browse tree since still thinking dictionary flattening option question flat stay grouped together alphabetical python param level value value flatten param image,issue,positive,positive,positive,positive,positive,positive
1558701108,"I think this approach addresses the issue https://github.com/mlflow/mlflow/issues/8435#issuecomment-1549441363

I will close this ticket, but you can reopen it if you have new issues related to this ticket.",think approach issue close ticket reopen new related ticket,issue,negative,positive,neutral,neutral,positive,positive
1558696280,"Benchmarking:
Comparing existing download with multi-part download. 
File size: 1GB
Run 10 times

Direct download:
<img width=""431"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/82044803/b07d4ff3-9770-49ac-91f5-a238b04725a0"">

Multi-part download:
<img width=""454"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/82044803/7b5cb6a0-2357-4aa2-b109-c07d8a10d664"">

It decreases time to download a 1GB file from 18.x seconds to 1.x seconds 😄 ",file size run time direct image image time file,issue,negative,positive,neutral,neutral,positive,positive
1558617431,"> Thanks @gabrielfu I've added it as: `extraArgs: appName: basic-auth` in https://artifacthub.io/packages/helm/community-charts/mlflow But getting: `2023/05/23 06:25:08 INFO mlflow.store.db.utils: Creating initial MLflow database tables... 2023/05/23 06:25:08 INFO mlflow.store.db.utils: Updating database tables INFO [alembic.runtime.migration] Context impl SQLiteImpl. INFO [alembic.runtime.migration] Will assume non-transactional DDL. INFO [alembic.runtime.migration] Running upgrade -> 451aebb31d03, add metric step INFO [alembic.runtime.migration] Running upgrade 451aebb31d03 -> 90e64c465722, migrate user column to tags INFO [alembic.runtime.migration] Running upgrade 90e64c465722 -> 181f10493468, allow nulls for metric values INFO [alembic.runtime.migration] Running upgrade 181f10493468 -> df50e92ffc5e, Add Experiment Tags Table INFO [alembic.runtime.migration] Running upgrade df50e92ffc5e -> 7ac759974ad8, Update run tags with larger limit INFO [alembic.runtime.migration] Running upgrade 7ac759974ad8 -> 89d4b8295536, create latest metrics table INFO [89d4b8295536_create_latest_metrics_table_py] Migration complete! INFO [alembic.runtime.migration] Running upgrade 89d4b8295536 -> 2b4d017a5e9b, add model registry tables to db INFO [2b4d017a5e9b_add_model_registry_tables_to_db_py] Adding registered_models and model_versions tables to database. INFO [2b4d017a5e9b_add_model_registry_tables_to_db_py] Migration complete! INFO [alembic.runtime.migration] Running upgrade 2b4d017a5e9b -> cfd24bdc0731, Update run status constraint with killed INFO [alembic.runtime.migration] Running upgrade cfd24bdc0731 -> 0a8213491aaa, drop_duplicate_killed_constraint INFO [alembic.runtime.migration] Running upgrade 0a8213491aaa -> 728d730b5ebd, add registered model tags table INFO [alembic.runtime.migration] Running upgrade 728d730b5ebd -> 27a6a02d2cf1, add model version tags table INFO [alembic.runtime.migration] Running upgrade 27a6a02d2cf1 -> 84291f40a231, add run_link to model_version INFO [alembic.runtime.migration] Running upgrade 84291f40a231 -> a8c4a736bde6, allow nulls for run_id INFO [alembic.runtime.migration] Running upgrade a8c4a736bde6 -> 39d1c3be5f05, add_is_nan_constraint_for_metrics_tables_if_necessary INFO [alembic.runtime.migration] Running upgrade 39d1c3be5f05 -> c48cb773bb87, reset_default_value_for_is_nan_in_metrics_table_for_mysql INFO [alembic.runtime.migration] Running upgrade c48cb773bb87 -> bd07f7e963c5, create index on run_uuid INFO [alembic.runtime.migration] Running upgrade bd07f7e963c5 -> 0c779009ac13, add deleted_time field to runs table INFO [alembic.runtime.migration] Running upgrade 0c779009ac13 -> cc1f77228345, change param value length to 500 INFO [alembic.runtime.migration] Running upgrade cc1f77228345 -> 97727af70f4d, Add creation_time and last_update_time to experiments table INFO [alembic.runtime.migration] Running upgrade 97727af70f4d -> 3500859a5d39, Add Model Aliases table INFO [alembic.runtime.migration] Context impl SQLiteImpl. INFO [alembic.runtime.migration] Will assume non-transactional DDL. [2023-05-23 06:25:08 +0000] [14] [INFO] Starting gunicorn 20.1.0 [2023-05-23 06:25:08 +0000] [14] [INFO] Listening at: http://0.0.0.0:5000 (14) [2023-05-23 06:25:08 +0000] [14] [INFO] Using worker: sync [2023-05-23 06:25:08 +0000] [15] [INFO] Booting worker with pid: 15 [2023-05-23 06:25:08 +0000] [16] [INFO] Booting worker with pid: 16 [2023-05-23 06:25:09 +0000] [17] [INFO] Booting worker with pid: 17 [2023-05-23 06:25:09 +0000] [18] [INFO] Booting worker with pid: 18 [2023-05-23 06:25:11 +0000] [15] [ERROR] Exception in worker process Traceback (most recent call last): File “/usr/local/lib/python3.10/site-packages/gunicorn/arbiter.py”, line 589, in spawn_worker worker.init_process() File “/usr/local/lib/python3.10/site-packages/gunicorn/workers/base.py”, line 134, in init_process self.load_wsgi() File “/usr/local/lib/python3.10/site-packages/gunicorn/workers/base.py”, line 146, in load_wsgi self.wsgi = self.app.wsgi() File “/usr/local/lib/python3.10/site-packages/gunicorn/app/base.py”, line 67, in wsgi self.callable = self.load() File “/usr/local/lib/python3.10/site-packages/gunicorn/app/wsgiapp.py”, line 58, in load return self.load_wsgiapp() File “/usr/local/lib/python3.10/site-packages/gunicorn/app/wsgiapp.py”, line 48, in load_wsgiapp return util.import_app(self.app_uri) File “/usr/local/lib/python3.10/site-packages/gunicorn/util.py”, line 359, in import_app mod = importlib.import_module(module) File “/usr/local/lib/python3.10/importlib/**init**.py”, line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level) File ““, line 1050, in _gcd_import File ““, line 1027, in _find_and_load File ““, line 1006, in _find_and_load_unlocked File ““, line 688, in _load_unlocked File ““, line 883, in exec_module File ““, line 241, in _call_with_frames_removed File “/usr/local/lib/python3.10/site-packages/mlflow/server/auth/**init**.py”, line 97, in auth_config = read_auth_config(auth_config_path) File “/usr/local/lib/python3.10/site-packages/mlflow/server/auth/config.py”, line 16, in read_auth_config default_permission=config[“mlflow”][“default_permission”], File “/usr/local/lib/python3.10/configparser.py”, line 965, in **getitem** raise KeyError(key) KeyError: ‘mlflow’ [2023-05-23 06:25:11 +0000] [15] [INFO] Worker exiting (pid: 15) [2023-05-23 06:25:12 +0000] [16] [ERROR] Exception in worker process Traceback (most recent call last): File “/usr/local/lib/python3.10/site-packages/gunicorn/arbiter.py”, line 589, in spawn_worker worker.init_process() File “/usr/local/lib/python3.10/site-packages/gunicorn/workers/base.py”, line 134, in init_process self.load_wsgi() File “/usr/local/lib/python3.10/site-packages/gunicorn/workers/base.py”, line 146, in load_wsgi self.wsgi = self.app.wsgi() File “/usr/local/lib/python3.10/site-packages/gunicorn/app/base.py”, line 67, in wsgi self.callable = self.load() File “/usr/local/lib/python3.10/site-packages/gunicorn/app/wsgiapp.py”, line 58, in load return self.load_wsgiapp() File “/usr/local/lib/python3.10/site-packages/gunicorn/app/wsgiapp.py”, line 48, in load_wsgiapp return util.import_app(self.app_uri) File “/usr/local/lib/python3.10/site-packages/gunicorn/util.py”, line 359, in import_app mod = importlib.import_module(module) File “/usr/local/lib/python3.10/importlib/**init**.py”, line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level) File ““, line 1050, in _gcd_import File ““, line 1027, in _find_and_load File ““, line 1006, in _find_and_load_unlocked File ““, line 688, in _load_unlocked File ““, line 883, in exec_module File ““, line 241, in _call_with_frames_removed File “/usr/local/lib/python3.10/site-packages/mlflow/server/auth/**init**.py”, line 97, in auth_config = read_auth_config(auth_config_path) File “/usr/local/lib/python3.10/site-packages/mlflow/server/auth/config.py”, line 16, in read_auth_config default_permission=config[“mlflow”][“default_permission”], File “/usr/local/lib/python3.10/configparser.py”, line 965, in **getitem** raise KeyError(key) KeyError: ‘mlflow’ [2023-05-23 06:25:12 +0000] [16] [INFO] Worker exiting (pid: 16) [2023-05-23 06:25:12 +0000] [18] [ERROR] Exception in worker process Traceback (most recent call last): File “/usr/local/lib/python3.10/site-packages/gunicorn/arbiter.py”, line 589, in spawn_worker worker.init_process() File “/usr/local/lib/python3.10/site-packages/gunicorn/workers/base.py”, line 134, in init_process self.load_wsgi() File “/usr/local/lib/python3.10/site-packages/gunicorn/workers/base.py”, line 146, in load_wsgi self.wsgi = self.app.wsgi() File “/usr/local/lib/python3.10/site-packages/gunicorn/app/base.py”, line 67, in wsgi self.callable = self.load() File “/usr/local/lib/python3.10/site-packages/gunicorn/app/wsgiapp.py”, line 58, in load return self.load_wsgiapp() File “/usr/local/lib/python3.10/site-packages/gunicorn/app/wsgiapp.py”, line 48, in load_wsgiapp return util.import_app(self.app_uri) File “/usr/local/lib/python3.10/site-packages/gunicorn/util.py”, line 359, in import_app mod = importlib.import_module(module) File “/usr/local/lib/python3.10/importlib/**init**.py”, line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level) File ““, line 1050, in _gcd_import File ““, line 1027, in _find_and_load File ““, line 1006, in _find_and_load_unlocked File ““, line 688, in _load_unlocked File ““, line 883, in exec_module File ““, line 241, in _call_with_frames_removed File “/usr/local/lib/python3.10/site-packages/mlflow/server/auth/**init**.py”, line 97, in auth_config = read_auth_config(auth_config_path) File “/usr/local/lib/python3.10/site-packages/mlflow/server/auth/config.py”, line 16, in read_auth_config default_permission=config[“mlflow”][“default_permission”], File “/usr/local/lib/python3.10/configparser.py”, line 965, in **getitem** raise KeyError(key) KeyError: ‘mlflow’ [2023-05-23 06:25:12 +0000] [18] [INFO] Worker exiting (pid: 18) [2023-05-23 06:25:12 +0000] [17] [ERROR] Exception in worker process Traceback (most recent call last): File “/usr/local/lib/python3.10/site-packages/gunicorn/arbiter.py”, line 589, in spawn_worker worker.init_process() File “/usr/local/lib/python3.10/site-packages/gunicorn/workers/base.py”, line 134, in init_process self.load_wsgi() File “/usr/local/lib/python3.10/site-packages/gunicorn/workers/base.py”, line 146, in load_wsgi self.wsgi = self.app.wsgi() File “/usr/local/lib/python3.10/site-packages/gunicorn/app/base.py”, line 67, in wsgi self.callable = self.load() File “/usr/local/lib/python3.10/site-packages/gunicorn/app/wsgiapp.py”, line 58, in load return self.load_wsgiapp() File “/usr/local/lib/python3.10/site-packages/gunicorn/app/wsgiapp.py”, line 48, in load_wsgiapp return util.import_app(self.app_uri) File “/usr/local/lib/python3.10/site-packages/gunicorn/util.py”, line 359, in import_app mod = importlib.import_module(module) File “/usr/local/lib/python3.10/importlib/**init**.py”, line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level) File ““, line 1050, in _gcd_import File ““, line 1027, in _find_and_load File ““, line 1006, in _find_and_load_unlocked File ““, line 688, in _load_unlocked File ““, line 883, in exec_module File ““, line 241, in _call_with_frames_removed File “/usr/local/lib/python3.10/site-packages/mlflow/server/auth/**init**.py”, line 97, in auth_config = read_auth_config(auth_config_path) File “/usr/local/lib/python3.10/site-packages/mlflow/server/auth/config.py”, line 16, in read_auth_config default_permission=config[“mlflow”][“default_permission”], File “/usr/local/lib/python3.10/configparser.py”, line 965, in **getitem** raise KeyError(key) KeyError: ‘mlflow’ [2023-05-23 06:25:12 +0000] [17] [INFO] Worker exiting (pid: 17) Traceback (most recent call last): File “/usr/local/lib/python3.10/site-packages/gunicorn/arbiter.py”, line 209, in run self.sleep() File “/usr/local/lib/python3.10/site-packages/gunicorn/arbiter.py”, line 357, in sleep ready = select.select([self.PIPE[0]], [], [], 1.0) File “/usr/local/lib/python3.10/site-packages/gunicorn/arbiter.py”, line 242, in handle_chld self.reap_workers() File “/usr/local/lib/python3.10/site-packages/gunicorn/arbiter.py”, line 525, in reap_workers raise HaltServer(reason, self.WORKER_BOOT_ERROR) gunicorn.errors.HaltServer: <HaltServer ‘Worker failed to boot.’ 3>
> 
> During handling of the above exception, another exception occurred:
> 
> Traceback (most recent call last): File “/usr/local/bin/gunicorn”, line 8, in sys.exit(run()) File “/usr/local/lib/python3.10/site-packages/gunicorn/app/wsgiapp.py”, line 67, in run WSGIApplication(“%(prog)s [OPTIONS] [APP_MODULE]“).run() File “/usr/local/lib/python3.10/site-packages/gunicorn/app/base.py”, line 231, in run [2023-05-23 06:25:13 +0000] [14] [WARNING] Worker with pid 18 was terminated due to signal 15 super().run() File “/usr/local/lib/python3.10/site-packages/gunicorn/app/base.py”, line 72, in run Arbiter(self).run() File “/usr/local/lib/python3.10/site-packages/gunicorn/arbiter.py”, line 229, in run self.halt(reason=inst.reason, exit_status=inst.exit_status) File “/usr/local/lib/python3.10/site-packages/gunicorn/arbiter.py”, line 342, in halt self.stop() File “/usr/local/lib/python3.10/site-packages/gunicorn/arbiter.py”, line 393, in stop time.sleep(0.1) File “/usr/local/lib/python3.10/site-packages/gunicorn/arbiter.py”, line 242, in handle_chld self.reap_workers() File “/usr/local/lib/python3.10/site-packages/gunicorn/arbiter.py”, line 525, in reap_workers raise HaltServer(reason, self.WORKER_BOOT_ERROR) gunicorn.errors.HaltServer: <HaltServer ‘Worker failed to boot.’ 3> Running the mlflow server failed. Please see the logs above for details. Stream closed EOF for localns/mlflow-poc-upgrde-74cf56484-tb5h8 (mlflow)`

Hi @rima317 , i have also acknowledged this bug. This will be addressed in #8497 , thanks",thanks added getting initial table table context assume running upgrade add metric step running upgrade migrate user column running upgrade allow metric running upgrade add experiment table running upgrade update run limit running upgrade create latest metric table migration complete running upgrade add model registry table table migration complete running upgrade update run status constraint running upgrade running upgrade add registered model table running upgrade add model version table running upgrade fa add running upgrade fa allow running upgrade running upgrade running upgrade create index running upgrade add field table running upgrade change param value length running upgrade add table running upgrade ad add model table context assume starting listening worker sync booting worker booting worker booting worker booting worker error exception worker process recent call last file line file line file line file line file line load return file line return file line module file line return name level package level file line file line file line file line file line file line file line file line file line raise key worker error exception worker process recent call last file line file line file line file line file line load return file line return file line module file line return name level package level file line file line file line file line file line file line file line file line file line raise key worker error exception worker process recent call last file line file line file line file line file line load return file line return file line module file line return name level package level file line file line file line file line file line file line file line file line file line raise key worker error exception worker process recent call last file line file line file line file line file line load return file line return file line module file line return name level package level file line file line file line file line file line file line file line file line file line raise key worker recent call last file line run file line sleep ready file line file line raise reason worker handling exception another exception recent call last file line run file line run prog file line run warning worker due signal super file line run arbiter self file line run file line halt file line stop file line file line raise reason worker running server please see stream closed hi rima also acknowledged bug thanks,issue,positive,positive,neutral,neutral,positive,positive
1558613175,"Thanks @gabrielfu 
I've added it as:
`extraArgs:
  appName: basic-auth`
in https://artifacthub.io/packages/helm/community-charts/mlflow
But getting:
`2023/05/23 06:25:08 INFO mlflow.store.db.utils: Creating initial MLflow database tables...
2023/05/23 06:25:08 INFO mlflow.store.db.utils: Updating database tables
INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade  -> 451aebb31d03, add metric step
INFO  [alembic.runtime.migration] Running upgrade 451aebb31d03 -> 90e64c465722, migrate user column to tags
INFO  [alembic.runtime.migration] Running upgrade 90e64c465722 -> 181f10493468, allow nulls for metric values
INFO  [alembic.runtime.migration] Running upgrade 181f10493468 -> df50e92ffc5e, Add Experiment Tags Table
INFO  [alembic.runtime.migration] Running upgrade df50e92ffc5e -> 7ac759974ad8, Update run tags with larger limit
INFO  [alembic.runtime.migration] Running upgrade 7ac759974ad8 -> 89d4b8295536, create latest metrics table
INFO  [89d4b8295536_create_latest_metrics_table_py] Migration complete!
INFO  [alembic.runtime.migration] Running upgrade 89d4b8295536 -> 2b4d017a5e9b, add model registry tables to db
INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Adding registered_models and model_versions tables to database.
INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Migration complete!
INFO  [alembic.runtime.migration] Running upgrade 2b4d017a5e9b -> cfd24bdc0731, Update run status constraint with killed
INFO  [alembic.runtime.migration] Running upgrade cfd24bdc0731 -> 0a8213491aaa, drop_duplicate_killed_constraint
INFO  [alembic.runtime.migration] Running upgrade 0a8213491aaa -> 728d730b5ebd, add registered model tags table
INFO  [alembic.runtime.migration] Running upgrade 728d730b5ebd -> 27a6a02d2cf1, add model version tags table
INFO  [alembic.runtime.migration] Running upgrade 27a6a02d2cf1 -> 84291f40a231, add run_link to model_version
INFO  [alembic.runtime.migration] Running upgrade 84291f40a231 -> a8c4a736bde6, allow nulls for run_id
INFO  [alembic.runtime.migration] Running upgrade a8c4a736bde6 -> 39d1c3be5f05, add_is_nan_constraint_for_metrics_tables_if_necessary
INFO  [alembic.runtime.migration] Running upgrade 39d1c3be5f05 -> c48cb773bb87, reset_default_value_for_is_nan_in_metrics_table_for_mysql
INFO  [alembic.runtime.migration] Running upgrade c48cb773bb87 -> bd07f7e963c5, create index on run_uuid
INFO  [alembic.runtime.migration] Running upgrade bd07f7e963c5 -> 0c779009ac13, add deleted_time field to runs table
INFO  [alembic.runtime.migration] Running upgrade 0c779009ac13 -> cc1f77228345, change param value length to 500
INFO  [alembic.runtime.migration] Running upgrade cc1f77228345 -> 97727af70f4d, Add creation_time and last_update_time to experiments table
INFO  [alembic.runtime.migration] Running upgrade 97727af70f4d -> 3500859a5d39, Add Model Aliases table
INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
[2023-05-23 06:25:08 +0000] [14] [INFO] Starting gunicorn 20.1.0
[2023-05-23 06:25:08 +0000] [14] [INFO] Listening at: http://0.0.0.0:5000 (14)
[2023-05-23 06:25:08 +0000] [14] [INFO] Using worker: sync
[2023-05-23 06:25:08 +0000] [15] [INFO] Booting worker with pid: 15
[2023-05-23 06:25:08 +0000] [16] [INFO] Booting worker with pid: 16
[2023-05-23 06:25:09 +0000] [17] [INFO] Booting worker with pid: 17
[2023-05-23 06:25:09 +0000] [18] [INFO] Booting worker with pid: 18
[2023-05-23 06:25:11 +0000] [15] [ERROR] Exception in worker process
Traceback (most recent call last):
  File “/usr/local/lib/python3.10/site-packages/gunicorn/arbiter.py”, line 589, in spawn_worker
    worker.init_process()
  File “/usr/local/lib/python3.10/site-packages/gunicorn/workers/base.py”, line 134, in init_process
    self.load_wsgi()
  File “/usr/local/lib/python3.10/site-packages/gunicorn/workers/base.py”, line 146, in load_wsgi
    self.wsgi = self.app.wsgi()
  File “/usr/local/lib/python3.10/site-packages/gunicorn/app/base.py”, line 67, in wsgi
    self.callable = self.load()
  File “/usr/local/lib/python3.10/site-packages/gunicorn/app/wsgiapp.py”, line 58, in load
    return self.load_wsgiapp()
  File “/usr/local/lib/python3.10/site-packages/gunicorn/app/wsgiapp.py”, line 48, in load_wsgiapp
    return util.import_app(self.app_uri)
  File “/usr/local/lib/python3.10/site-packages/gunicorn/util.py”, line 359, in import_app
    mod = importlib.import_module(module)
  File “/usr/local/lib/python3.10/importlib/__init__.py”, line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File “<frozen importlib._bootstrap>“, line 1050, in _gcd_import
  File “<frozen importlib._bootstrap>“, line 1027, in _find_and_load
  File “<frozen importlib._bootstrap>“, line 1006, in _find_and_load_unlocked
  File “<frozen importlib._bootstrap>“, line 688, in _load_unlocked
  File “<frozen importlib._bootstrap_external>“, line 883, in exec_module
  File “<frozen importlib._bootstrap>“, line 241, in _call_with_frames_removed
  File “/usr/local/lib/python3.10/site-packages/mlflow/server/auth/__init__.py”, line 97, in <module>
    auth_config = read_auth_config(auth_config_path)
  File “/usr/local/lib/python3.10/site-packages/mlflow/server/auth/config.py”, line 16, in read_auth_config
    default_permission=config[“mlflow”][“default_permission”],
  File “/usr/local/lib/python3.10/configparser.py”, line 965, in __getitem__
    raise KeyError(key)
KeyError: ‘mlflow’
[2023-05-23 06:25:11 +0000] [15] [INFO] Worker exiting (pid: 15)
[2023-05-23 06:25:12 +0000] [16] [ERROR] Exception in worker process
Traceback (most recent call last):
  File “/usr/local/lib/python3.10/site-packages/gunicorn/arbiter.py”, line 589, in spawn_worker
    worker.init_process()
  File “/usr/local/lib/python3.10/site-packages/gunicorn/workers/base.py”, line 134, in init_process
    self.load_wsgi()
  File “/usr/local/lib/python3.10/site-packages/gunicorn/workers/base.py”, line 146, in load_wsgi
    self.wsgi = self.app.wsgi()
  File “/usr/local/lib/python3.10/site-packages/gunicorn/app/base.py”, line 67, in wsgi
    self.callable = self.load()
  File “/usr/local/lib/python3.10/site-packages/gunicorn/app/wsgiapp.py”, line 58, in load
    return self.load_wsgiapp()
  File “/usr/local/lib/python3.10/site-packages/gunicorn/app/wsgiapp.py”, line 48, in load_wsgiapp
    return util.import_app(self.app_uri)
  File “/usr/local/lib/python3.10/site-packages/gunicorn/util.py”, line 359, in import_app
    mod = importlib.import_module(module)
  File “/usr/local/lib/python3.10/importlib/__init__.py”, line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File “<frozen importlib._bootstrap>“, line 1050, in _gcd_import
  File “<frozen importlib._bootstrap>“, line 1027, in _find_and_load
  File “<frozen importlib._bootstrap>“, line 1006, in _find_and_load_unlocked
  File “<frozen importlib._bootstrap>“, line 688, in _load_unlocked
  File “<frozen importlib._bootstrap_external>“, line 883, in exec_module
  File “<frozen importlib._bootstrap>“, line 241, in _call_with_frames_removed
  File “/usr/local/lib/python3.10/site-packages/mlflow/server/auth/__init__.py”, line 97, in <module>
    auth_config = read_auth_config(auth_config_path)
  File “/usr/local/lib/python3.10/site-packages/mlflow/server/auth/config.py”, line 16, in read_auth_config
    default_permission=config[“mlflow”][“default_permission”],
  File “/usr/local/lib/python3.10/configparser.py”, line 965, in __getitem__
    raise KeyError(key)
KeyError: ‘mlflow’
[2023-05-23 06:25:12 +0000] [16] [INFO] Worker exiting (pid: 16)
[2023-05-23 06:25:12 +0000] [18] [ERROR] Exception in worker process
Traceback (most recent call last):
  File “/usr/local/lib/python3.10/site-packages/gunicorn/arbiter.py”, line 589, in spawn_worker
    worker.init_process()
  File “/usr/local/lib/python3.10/site-packages/gunicorn/workers/base.py”, line 134, in init_process
    self.load_wsgi()
  File “/usr/local/lib/python3.10/site-packages/gunicorn/workers/base.py”, line 146, in load_wsgi
    self.wsgi = self.app.wsgi()
  File “/usr/local/lib/python3.10/site-packages/gunicorn/app/base.py”, line 67, in wsgi
    self.callable = self.load()
  File “/usr/local/lib/python3.10/site-packages/gunicorn/app/wsgiapp.py”, line 58, in load
    return self.load_wsgiapp()
  File “/usr/local/lib/python3.10/site-packages/gunicorn/app/wsgiapp.py”, line 48, in load_wsgiapp
    return util.import_app(self.app_uri)
  File “/usr/local/lib/python3.10/site-packages/gunicorn/util.py”, line 359, in import_app
    mod = importlib.import_module(module)
  File “/usr/local/lib/python3.10/importlib/__init__.py”, line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File “<frozen importlib._bootstrap>“, line 1050, in _gcd_import
  File “<frozen importlib._bootstrap>“, line 1027, in _find_and_load
  File “<frozen importlib._bootstrap>“, line 1006, in _find_and_load_unlocked
  File “<frozen importlib._bootstrap>“, line 688, in _load_unlocked
  File “<frozen importlib._bootstrap_external>“, line 883, in exec_module
  File “<frozen importlib._bootstrap>“, line 241, in _call_with_frames_removed
  File “/usr/local/lib/python3.10/site-packages/mlflow/server/auth/__init__.py”, line 97, in <module>
    auth_config = read_auth_config(auth_config_path)
  File “/usr/local/lib/python3.10/site-packages/mlflow/server/auth/config.py”, line 16, in read_auth_config
    default_permission=config[“mlflow”][“default_permission”],
  File “/usr/local/lib/python3.10/configparser.py”, line 965, in __getitem__
    raise KeyError(key)
KeyError: ‘mlflow’
[2023-05-23 06:25:12 +0000] [18] [INFO] Worker exiting (pid: 18)
[2023-05-23 06:25:12 +0000] [17] [ERROR] Exception in worker process
Traceback (most recent call last):
  File “/usr/local/lib/python3.10/site-packages/gunicorn/arbiter.py”, line 589, in spawn_worker
    worker.init_process()
  File “/usr/local/lib/python3.10/site-packages/gunicorn/workers/base.py”, line 134, in init_process
    self.load_wsgi()
  File “/usr/local/lib/python3.10/site-packages/gunicorn/workers/base.py”, line 146, in load_wsgi
    self.wsgi = self.app.wsgi()
  File “/usr/local/lib/python3.10/site-packages/gunicorn/app/base.py”, line 67, in wsgi
    self.callable = self.load()
  File “/usr/local/lib/python3.10/site-packages/gunicorn/app/wsgiapp.py”, line 58, in load
    return self.load_wsgiapp()
  File “/usr/local/lib/python3.10/site-packages/gunicorn/app/wsgiapp.py”, line 48, in load_wsgiapp
    return util.import_app(self.app_uri)
  File “/usr/local/lib/python3.10/site-packages/gunicorn/util.py”, line 359, in import_app
    mod = importlib.import_module(module)
  File “/usr/local/lib/python3.10/importlib/__init__.py”, line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File “<frozen importlib._bootstrap>“, line 1050, in _gcd_import
  File “<frozen importlib._bootstrap>“, line 1027, in _find_and_load
  File “<frozen importlib._bootstrap>“, line 1006, in _find_and_load_unlocked
  File “<frozen importlib._bootstrap>“, line 688, in _load_unlocked
  File “<frozen importlib._bootstrap_external>“, line 883, in exec_module
  File “<frozen importlib._bootstrap>“, line 241, in _call_with_frames_removed
  File “/usr/local/lib/python3.10/site-packages/mlflow/server/auth/__init__.py”, line 97, in <module>
    auth_config = read_auth_config(auth_config_path)
  File “/usr/local/lib/python3.10/site-packages/mlflow/server/auth/config.py”, line 16, in read_auth_config
    default_permission=config[“mlflow”][“default_permission”],
  File “/usr/local/lib/python3.10/configparser.py”, line 965, in __getitem__
    raise KeyError(key)
KeyError: ‘mlflow’
[2023-05-23 06:25:12 +0000] [17] [INFO] Worker exiting (pid: 17)
Traceback (most recent call last):
  File “/usr/local/lib/python3.10/site-packages/gunicorn/arbiter.py”, line 209, in run
    self.sleep()
  File “/usr/local/lib/python3.10/site-packages/gunicorn/arbiter.py”, line 357, in sleep
    ready = select.select([self.PIPE[0]], [], [], 1.0)
  File “/usr/local/lib/python3.10/site-packages/gunicorn/arbiter.py”, line 242, in handle_chld
    self.reap_workers()
  File “/usr/local/lib/python3.10/site-packages/gunicorn/arbiter.py”, line 525, in reap_workers
    raise HaltServer(reason, self.WORKER_BOOT_ERROR)
gunicorn.errors.HaltServer: <HaltServer ‘Worker failed to boot.’ 3>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File “/usr/local/bin/gunicorn”, line 8, in <module>
    sys.exit(run())
  File “/usr/local/lib/python3.10/site-packages/gunicorn/app/wsgiapp.py”, line 67, in run
    WSGIApplication(“%(prog)s [OPTIONS] [APP_MODULE]“).run()
  File “/usr/local/lib/python3.10/site-packages/gunicorn/app/base.py”, line 231, in run
[2023-05-23 06:25:13 +0000] [14] [WARNING] Worker with pid 18 was terminated due to signal 15
    super().run()
  File “/usr/local/lib/python3.10/site-packages/gunicorn/app/base.py”, line 72, in run
    Arbiter(self).run()
  File “/usr/local/lib/python3.10/site-packages/gunicorn/arbiter.py”, line 229, in run
    self.halt(reason=inst.reason, exit_status=inst.exit_status)
  File “/usr/local/lib/python3.10/site-packages/gunicorn/arbiter.py”, line 342, in halt
    self.stop()
  File “/usr/local/lib/python3.10/site-packages/gunicorn/arbiter.py”, line 393, in stop
    time.sleep(0.1)
  File “/usr/local/lib/python3.10/site-packages/gunicorn/arbiter.py”, line 242, in handle_chld
    self.reap_workers()
  File “/usr/local/lib/python3.10/site-packages/gunicorn/arbiter.py”, line 525, in reap_workers
    raise HaltServer(reason, self.WORKER_BOOT_ERROR)
gunicorn.errors.HaltServer: <HaltServer ‘Worker failed to boot.’ 3>
Running the mlflow server failed. Please see the logs above for details.
Stream closed EOF for localns/mlflow-poc-upgrde-74cf56484-tb5h8 (mlflow)`",thanks added getting initial table table context assume running upgrade add metric step running upgrade migrate user column running upgrade allow metric running upgrade add experiment table running upgrade update run limit running upgrade create latest metric table migration complete running upgrade add model registry table table migration complete running upgrade update run status constraint running upgrade running upgrade add registered model table running upgrade add model version table running upgrade fa add running upgrade fa allow running upgrade running upgrade running upgrade create index running upgrade add field table running upgrade change param value length running upgrade add table running upgrade ad add model table context assume starting listening worker sync booting worker booting worker booting worker booting worker error exception worker process recent call last file line file line file line file line file line load return file line return file line module file line return name level package level file frozen line file frozen line file frozen line file frozen line file frozen line file frozen line file line module file line file line raise key worker error exception worker process recent call last file line file line file line file line file line load return file line return file line module file line return name level package level file frozen line file frozen line file frozen line file frozen line file frozen line file frozen line file line module file line file line raise key worker error exception worker process recent call last file line file line file line file line file line load return file line return file line module file line return name level package level file frozen line file frozen line file frozen line file frozen line file frozen line file frozen line file line module file line file line raise key worker error exception worker process recent call last file line file line file line file line file line load return file line return file line module file line return name level package level file frozen line file frozen line file frozen line file frozen line file frozen line file frozen line file line module file line file line raise key worker recent call last file line run file line sleep ready file line file line raise reason worker handling exception another exception recent call last file line module run file line run prog file line run warning worker due signal super file line run arbiter self file line run file line halt file line stop file line file line raise reason worker running server please see stream closed,issue,positive,positive,neutral,neutral,positive,positive
1558492751,"> @gabrielfu This is great! What should be done in order to enable the login page when using this helm chart: https://artifacthub.io/packages/helm/community-charts/mlflow ?

Hi @rima317 , I think you'll need to add the flag `--app-name=basic-auth` to the CMD here 
https://github.com/burakince/mlflow/blob/main/Dockerfile

Then once you launched the tracking server, there'll be a login prompt when you visit any page on the browser (except signup). To signup, go to `https://<host>/signup`",great done order enable login page helm chart hi rima think need add flag server login prompt visit page browser except go,issue,positive,positive,positive,positive,positive,positive
1558363380,"> In Table View, the metrics that are displayed are the ones from the last epoch. Would be nice to have the minimum / maximum achieved for that model instead of the last metric obtained.

Or even the number from a custom step?",table view metric displayed last epoch would nice minimum maximum model instead last metric even number custom step,issue,negative,positive,positive,positive,positive,positive
1558287870,"@ChekrounMohammed 

Thanks for reporting this !

Could you also provide your Databricks runtime version and databricks cluster config ? ",thanks could also provide version cluster,issue,negative,positive,positive,positive,positive,positive
1558284780,"To avoid mlflow database migration issue, we decided to not change the experiment id format stored in mlflow database. We recommend this approach https://github.com/mlflow/mlflow/issues/8457#issuecomment-1553846708
But if you still have issue, feel free to reopen the ticket.",avoid migration issue decided change experiment id format recommend approach still issue feel free reopen ticket,issue,positive,positive,positive,positive,positive,positive
1558275413,"(1)

We have some limitation values defined here:
https://github.com/mlflow/mlflow/blob/a5b61dbe967633e8f5f97f3bd11002d42c1fc9cc/mlflow/utils/validation.py#L47

For safety / performance reason we don't want to make the default value to be too large. You can increase these values if your own cases require larger value.

(2)

> PerformanceWarning: DataFrame is highly fragmented

Such warning is caused by the dataframe with too many columns, currently we haven't optimized code for dataframes with many columns, for such case, I recommend to use the approach https://github.com/mlflow/mlflow/issues/7946#issuecomment-1556851817",limitation defined safety performance reason want make default value large increase require value highly fragmented warning many currently code many case recommend use approach,issue,positive,positive,positive,positive,positive,positive
1557521134,"@WeichenXu123 Thank you for your comment! But I think the main issue may be the storage of the entire model information, including input examples and signatures, in tags. This is because the size limit for tag values is fixed, while input examples and signatures can significantly increase in size depending on the training data.

I believe the problem could be resolved by saving input examples and signatures through a different method and separating the storage of other model information in mlflow.log-model.history. This is because, apart from input examples and signatures, most of the model information has relatively fixed lengths.

I haven't been able to investigate if the input examples and signatures stored in mlflow.log-model.history are being used anywhere. If MLflow requires those information, alternative approaches will need to be considered.",thank comment think main issue may storage entire model information input size limit tag fixed input significantly increase size depending training data believe problem could resolved saving input different method separating storage model information apart input model information relatively fixed able investigate input used anywhere information alternative need considered,issue,negative,positive,positive,positive,positive,positive
1557162700,"@gabrielfu This is great! What should be done in order to enable the login page when using this helm chart: 
https://artifacthub.io/packages/helm/community-charts/mlflow ?",great done order enable login page helm chart,issue,positive,positive,positive,positive,positive,positive
1556955451,Hey @meg-dialexa . I am facing the exact issue that you are facing. Have you found any solution. If yes can you share the solution.,hey facing exact issue facing found solution yes share solution,issue,positive,positive,positive,positive,positive,positive
1556888221,"In my opinion, it could be passed in as an argument of the class Recipe, and can be set in the recipe config file (recipe.yaml). This way, one could easily define a template for the run_name, based on input parameters, that are set via profile config. e.g. estimator name and primary metric names are defined in the profile as {ESTIMATOR_NAME} and {PRIMARY_METRIC} variables. Then, the run_name could be set in the recipe config as: {{ESTIMATOR_NAME}}_{{PRIMARY_METRIC}}.",opinion could argument class recipe set recipe file way one could easily define template based input set via profile estimator name primary metric defined profile could set recipe,issue,negative,positive,positive,positive,positive,positive
1556859905,"@Abonia1 

Sorry my previous comment is wrong, I updated my comment, https://github.com/hwchase17/langchain/issues/4401#issuecomment-1553831613
you need to install `typing-extensions>=4.2.0` to address the issue.



> For info: As mentionned [here](https://community.databricks.com/s/question/0D53f00001oo9ZXCAY/community-edition-restexception-permissiondenied-model-registry-is-not-enabled-for-organization-2183541758974102), there are certain limitations with the community edition and we do not have this feature there. To use this we need to go with the commercial version of Databricks.

Yes this is an limitation


",sorry previous comment wrong comment need install address issue certain community edition feature use need go commercial version yes limitation,issue,negative,negative,negative,negative,negative,negative
1556854208,"I will close this ticket since no updates, if you have new issues feel free to reopen it.",close ticket since new feel free reopen,issue,positive,positive,positive,positive,positive,positive
1556851817,"emm, in such case, I think we should use numpy array as model input, i.e., the training / inference dataset is a numpy array, the array size is (num_of_samples, num_of_features)",case think use array model input training inference array array size,issue,negative,neutral,neutral,neutral,neutral,neutral
1556807674,The feature make sense . Shall we add the name in recipe profile config file or add it as an argument of `class Recipe` constructor ?,feature make sense shall add name recipe profile file add argument class recipe constructor,issue,negative,neutral,neutral,neutral,neutral,neutral
1556589637,"@VishnuMurthyChakka @WeichenXu123 

> length 28273, which exceeded length limit of 5000

I encountered the same error as well. This error means that the value of the system tag 'mlflow.log-model.history' exceeded 5000, and as a result, it couldn't be registered in the database. 5000 is the maximum limit for tag values.
When dealing with table data with a large number of columns, saving input examples and signatures can easily exceed the 5000 limit. Is it possible to save input examples and signatures in a location that doesn't have such strict limitations, rather than storing them in 'mlflow.log-model.history'?

If 'mlflow.log-model.history' is not present, it causes an issue in MLflow 2.2.2 where the model information is not displayed in the 'Models' section of the Experiment's UI. This is because starting from MLflow 2, a logic was introduced to retrieve and display model version information only for runs that have 'mlflow.log-model.history' present",length length limit error well error value system tag result could registered maximum limit tag dealing table data large number saving input easily exceed limit possible save input location strict rather present issue model information displayed section experiment starting logic retrieve display model version information present,issue,positive,positive,positive,positive,positive,positive
1556481598,"> You can share your code of logging params / metrics and I can help check.

My interface looks a bit different from yours
![image](https://github.com/mlflow/mlflow/assets/34581986/1670be14-7f59-46f1-a42d-9322cf11ed34)
",share code logging metric help check interface bit different image,issue,positive,neutral,neutral,neutral,neutral,neutral
1555881191,"@BenWilson2 @adekunleoajayi 
is this Feature request still in WIP? have we made any decision on implementing this? 
I am interested in contributing and  would love to take up this effort  :)",feature request still made decision interested would love take effort,issue,positive,positive,positive,positive,positive,positive
1555874773,@dbczumar is this issue resolved? are there any more ENV variables to migrate? I see this issue was reopened ,issue resolved migrate see issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1555452966,I think it's related. Can you move `from packaging.version import Version` above `from flask import __version__ as flask_version`?,think related move import version flask import,issue,negative,neutral,neutral,neutral,neutral,neutral
1555400395,"@BenWilson2 

> Do we want to add some notes in the docs about this new behavior or will that be part of the larger Evaluate support for LLMs in general in subsequent PRs?

I'll update the docs in subsequent PRs :)",want add new behavior part evaluate support general subsequent update subsequent,issue,negative,positive,neutral,neutral,positive,positive
1555180244,"Hi @vijethmoudgalya , absolutely. Feel free to file a PR :)",hi absolutely feel free file,issue,positive,positive,positive,positive,positive,positive
1555179666,"The lint failure is unrelated to my change but I could change it if we want, please let me know.",lint failure unrelated change could change want please let know,issue,negative,negative,negative,negative,negative,negative
1555079948,"@WeichenXu123 Even I  have tried 

`%pip install langchain typing_extensions==4.1.0`

I got this error as we don'thave access to model in community version of databricks:
<img width=""1172"" alt=""Capture d’écran 2023-05-19 à 20 35 45"" src=""https://github.com/mlflow/mlflow/assets/22887323/5022bd63-e78f-43f6-b3b3-1b787980f100"">


For info: As mentionned [here](https://community.databricks.com/s/question/0D53f00001oo9ZXCAY/community-edition-restexception-permissiondenied-model-registry-is-not-enabled-for-organization-2183541758974102), there are certain limitations with the community edition and we do not have this feature there. To use this we need to go with the commercial version of Databricks.

So consider we can't use the feature of mlfow+langchain in community version of databricks. Thanks for all the help.",even tried pip install got error access model community version capture certain community edition feature use need go commercial version consider ca use feature community version thanks help,issue,positive,positive,positive,positive,positive,positive
1555053021,"@monajalal what I meant is that if you are running with distributed training, you code is effectively running on multiple processes. However, when reporting metrics, you typically need to do that in a single one. Usually the controller. The controller is the process with RANK=0. Are you using Azure Machine Learning clusters or something else?",meant running distributed training code effectively running multiple however metric typically need single one usually controller controller process azure machine learning something else,issue,negative,positive,neutral,neutral,positive,positive
1555012443,"Hey @dbczumar , as i still see that the doc is still not fixed , can you assign it to me?",hey still see doc still fixed assign,issue,negative,positive,neutral,neutral,positive,positive
1554776108,"We're not out of the woods yet.

I tried using the standard batch inference usage of the model having installed the MLFlow 2.3.3..dev0 using this code:

```
import mlflow
logged_model = 'runs:/beca191e59f54a2e9777186774058e96/model'

# Load model as a PyFuncModel.
loaded_model = mlflow.pyfunc.load_model(logged_model)

# Predict on a Pandas DataFrame.
import pandas as pd
loaded_model.predict(df.toPandas())
```

This was the error:

```
2023/05/19 16:05:18 WARNING mlflow.pyfunc: Detected one or more mismatches between the model's dependencies and the current Python environment:
 - numpy (current: 1.21.5, required: numpy==1.24.3)
To fix the mismatches, call `mlflow.pyfunc.get_model_dependencies(model_uri)` to fetch the model's environment and install dependencies using the resulting environment file.
2023/05/19 16:05:19 WARNING mlflow.langchain.api_request_parallel_processor: Request #0 failed with AttributeError(""'str' object has no attribute 'page_content'"")
2023/05/19 16:05:19 WARNING mlflow.langchain.api_request_parallel_processor: Request #1 failed with AttributeError(""'str' object has no attribute 'page_content'"")
2023/05/19 16:05:19 WARNING mlflow.langchain.api_request_parallel_processor: Request #2 failed with AttributeError(""'str' object has no attribute 'page_content'"")
2023/05/19 16:05:19 WARNING mlflow.langchain.api_request_parallel_processor: Request #3 failed with AttributeError(""'str' object has no attribute 'page_content'"")
2023/05/19 16:05:19 WARNING mlflow.langchain.api_request_parallel_processor: Request #4 failed with AttributeError(""'str' object has no attribute 'page_content'"")


> Entering new StuffDocumentsChain chain...


> Entering new StuffDocumentsChain chain...


> Entering new StuffDocumentsChain chain...


> Entering new StuffDocumentsChain chain...


> Entering new StuffDocumentsChain chain...
MlflowException: 5 tasks failed. See logs for details.
---------------------------------------------------------------------------
MlflowException                           Traceback (most recent call last)
File <command-3944480421186138>:9
      7 # Predict on a Pandas DataFrame.
      8 import pandas as pd
----> 9 loaded_model.predict(df.toPandas())

File /local_disk0/.ephemeral_nfs/envs/pythonEnv-266e36af-e081-49ac-a9b9-36047b4ff7a4/lib/python3.10/site-packages/mlflow/pyfunc/__init__.py:427, in PyFuncModel.predict(self, data)
    424         if _MLFLOW_OPENAI_TESTING.get():
    425             raise
--> 427 return self._predict_fn(data)

File /local_disk0/.ephemeral_nfs/envs/pythonEnv-266e36af-e081-49ac-a9b9-36047b4ff7a4/lib/python3.10/site-packages/mlflow/langchain/__init__.py:444, in _LangChainModelWrapper.predict(self, data)
    440 else:
    441     raise mlflow.MlflowException.invalid_parameter_value(
    442         ""Input must be a pandas DataFrame or a list of strings or a list of dictionaries"",
    443     )
--> 444 return process_api_requests(lc_model=self.lc_model, requests=messages)```",yet tried standard batch inference usage model dev code import load model predict import error warning one model current python environment current fix call fetch model environment install resulting environment file warning request object attribute warning request object attribute warning request object attribute warning request object attribute warning request object attribute entering new chain entering new chain entering new chain entering new chain entering new chain see recent call last file predict import file self data raise return data file self data else raise input must list list return,issue,negative,positive,neutral,neutral,positive,positive
1554653914,"![image](https://github.com/mlflow/mlflow/assets/124541637/bd5c6bf8-c682-4544-acb7-7c58816b453f)

The type of my model tested is **langchain.chains.combine_documents.stuff.StuffDocumentsChain**

Code used to deploy:

```def publish_model_to_mlflow(llm_model):

  with mlflow.start_run() as run:
      # Save model to MLFlow
      # Note that this only saves the langchain pipeline (we could also add the ChatBot with a custom Model Wrapper class)
      # See https://mlflow.org/docs/latest/models.html#custom-python-models for an example
      # The vector database lives outside of your model
      mlflow.langchain.log_model(llm_model, artifact_path=""model"")
      model_registered = mlflow.register_model(f""runs:/{run.info.run_id}/model"", ""gardening-dolly-7b-bot"")

  # Move the model in production
  client = mlflow.tracking.MlflowClient()
  print(""registering model version ""+model_registered.version+"" as production model"")
  client.transition_model_version_stage(""gardening-dolly-7b-bot"", model_registered.version, stage = ""Production"", archive_existing_versions=True)

publish_model_to_mlflow(qa_chain)
```
  
Resulting message after fixing promotion code:

```2023/05/19 14:13:33 WARNING mlflow: MLflow does not guarantee support for Chains outside of the subclasses of LLMChain, found StuffDocumentsChain
Registered model 'gardening-dolly-7b-bot' already exists. Creating a new version of this model...
2023/05/19 14:13:37 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: gardening-dolly-7b-bot, version 3
Created version '3' of model 'gardening-dolly-7b-bot'.
registering model version 3 as production model```",image type model tested code used deploy run save model note pipeline could also add custom model wrapper class see example vector outside model model move model production client print model version production model stage production resulting message fixing promotion code warning guarantee support outside found registered model already new version model waiting model version finish creation model name version version model model version production model,issue,positive,positive,neutral,neutral,positive,positive
1554599281,"> @WeichenXu123 Thanks for linking the issue. @minkin-koantek If you don't mind sharing the code to reproduce this issue #8460, I can also help take a look. Thanks!

The setup is based on a Databricks Dolly script from dbdemos.  If I am unsuccessful in getting the model to register I will isolate it so you can try it",thanks linking issue mind code reproduce issue also help take look thanks setup based dolly script unsuccessful getting model register isolate try,issue,positive,positive,positive,positive,positive,positive
1554399589,@shimizust We've uploaded the missing source distributions for mlflow-skinny :) We found a bug in our internal pipeline to release a new version and fixed it. Thanks for catching this!,missing source found bug internal pipeline release new version fixed thanks catching,issue,negative,positive,positive,positive,positive,positive
1554200370,Can we make linter capture such error ?,make linter capture error,issue,negative,neutral,neutral,neutral,neutral,neutral
1554078551,"@WeichenXu123 Thanks for linking the issue.
@minkin-koantek If you don't mind sharing the code to reproduce this issue https://github.com/mlflow/mlflow/issues/8460, I can also help take a look. Thanks!",thanks linking issue mind code reproduce issue also help take look thanks,issue,positive,positive,positive,positive,positive,positive
1553937257,"@WeichenXu123  @santiagxf  I didn't mean that I don't know how to get the run id. I meant in my case I used `mlflow.get_run(""dummy"")` method and the error happens, so the run id here is ""dummy"" and I'm not sure if this is helpful for dev to look up for logs. ",mean know get run id meant case used dummy method error run id dummy sure helpful dev look,issue,negative,positive,neutral,neutral,positive,positive
1553890075,"@minkin-koantek could you help test ?

You can install this branch of the PR via:

```
pip install git+https://github.com/liangz1/mlflow.git@support-more-chains
```",could help test install branch via pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
1553882179,"@leqiao-1 Could you fix the lint errors https://github.com/mlflow/mlflow/actions/runs/5011618497/jobs/8987189752?pr=8433

Once you fix them, I will merge the PR.",could fix lint fix merge,issue,negative,neutral,neutral,neutral,neutral,neutral
1553861223,"@liangz1 

Could you also manually test this for dolly ? https://github.com/mlflow/mlflow/issues/8460

(We don't need to add dolly tests in CI)",could also manually test dolly need add dolly,issue,negative,neutral,neutral,neutral,neutral,neutral
1553853750,"I'll get back to you mid next week on it, but likely yes",get back mid next week likely yes,issue,negative,neutral,neutral,neutral,neutral,neutral
1553848287,Thanks for reporting this ! Would you file a PR to fix it ? :),thanks would file fix,issue,negative,positive,positive,positive,positive,positive
1553846708,"I got it. Another workaround is you can create sub-directory under the s3 bucket and configure different MLflow server to use different s3 sub-directory as the root artifact storage path, e.g.

s3://bucket_name/folder1
s3://bucket_name/folder2

What do you think ?",got another create bucket configure different server use different root artifact storage path think,issue,negative,neutral,neutral,neutral,neutral,neutral
1553430780,@0mza987 shouldn't you getting the run information in the driver process (RANK=0)?,getting run information driver process,issue,negative,neutral,neutral,neutral,neutral,neutral
1553271358,"![scenario_4](https://github.com/mlflow/mlflow/assets/8956612/8125c544-14b8-48e2-a527-5ca866ac076c)

I am using this design of mlflow tracking (image from mlflow docs). I containerized both mlflow tracking server and PostgreSQL. Everytime I redeployed the tracking server and PostgreSQL, the new experiments are given experiment_id starting from 1, 2, 3, incrementally, since PostgreSQL is a fresh start. But I was reusing the same S3 bucket. Therefore the old experiments are polluted with new experiments in S3 bucket because they have same experiment id. If experiment id is  unique number, then the problem will be solved.",design image server server new given starting since fresh start bucket therefore old polluted new bucket experiment id experiment id unique number problem,issue,negative,positive,positive,positive,positive,positive
1553055730,"In Table View, the metrics that are displayed are the ones from the last epoch. Would be nice to have the minimum / maximum achieved for that model instead of the last metric obtained.",table view metric displayed last epoch would nice minimum maximum model instead last metric,issue,negative,positive,positive,positive,positive,positive
1553007934,"@0mza987 

Do you mean the ""runID"" of mlflow run ?

if yes, we can get run id by:

```
with mlflow.start_run() as run:
  print(run.info.run_id)
```

or if you are sure there's an active run currently, you can get active run id by

```
mlflow.active_run().info.run_id
```

But if you mean other component's ""run id"", then it is out of mlflow scope",mean run yes get run id run print sure active run currently get active run id mean component run id scope,issue,positive,negative,neutral,neutral,negative,negative
1552961786,"@WeichenXu123  @monajalal I posted a thread in internal teams channel and linked this thread there too. Their dev replied this:
> ""please let us know workspace/runId details with an UTC timestamp so that we can look at the specific logs on the service side.""

In my case I just used ""get_run(""dummy"")"" so there is no specific run id, maybe you can provide the asked info I could pass it to them.",posted thread internal channel linked thread dev please let u know look specific service side case used dummy specific run id maybe provide could pas,issue,negative,neutral,neutral,neutral,neutral,neutral
1552951098,Got it. Let me check. I think we need to address the langchain issue on databricks,got let check think need address issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1552737025,"Agreed with @harupy , i.e., we can do:

```
if Version(flask.__version__) >= Version(""2.0""):
  # Flask version is greater or equal to than 2.0
  return send_from_directory(STATIC_DIR, path, max_age=2419200)
else:
   # Flask version is less than 2.0
  return send_from_directory(STATIC_DIR, path, cache_timeout=2419200)
```",agreed version version flask version greater equal return path else flask version le return path,issue,positive,positive,positive,positive,positive,positive
1552688715,"Awesome, thanks!

On Thu, 18 May, 2023, 12:50 pm Dean P, ***@***.***> wrote:

> Hey @nikshingadiya <https://github.com/nikshingadiya>, @harupy
> <https://github.com/harupy> – Dean from DagsHub here, I tested the
> notebook @harupy <https://github.com/harupy> provided with dagshub.init()
> and it successfully logged a model to my MLflow server.
>
> Adding the example notebook that works:
> https://colab.research.google.com/drive/1D8p_C9AtYhUeGM8A3xFXxEyVMxAqA52q?usp=sharing
>
> Hopefully this is useful for other people that find this thread.
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/mlflow/mlflow/issues/8275#issuecomment-1552622955>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ALFNHJZ3364YRF5SZUWX4E3XGXETNANCNFSM6AAAAAAXD5WRPY>
> .
> You are receiving this because you were mentioned.Message ID:
> ***@***.***>
>
",awesome thanks may dean wrote hey dean tested notebook provided successfully logged model server example notebook work hopefully useful people find thread reply directly view id,issue,positive,positive,positive,positive,positive,positive
1552622955,"Hey @nikshingadiya, @harupy – Dean from DagsHub here, I tested the notebook @harupy provided with `dagshub.init()` and it successfully logged a model to my MLflow server.

Adding the example notebook that works: https://colab.research.google.com/drive/1D8p_C9AtYhUeGM8A3xFXxEyVMxAqA52q?usp=sharing

Hopefully, this is useful for other people that find this thread. It means you can use both methods for authentication",hey dean tested notebook provided successfully logged model server example notebook work hopefully useful people find thread use authentication,issue,positive,positive,positive,positive,positive,positive
1552499018,"@kevingreer We can check the flask version and use `cache_timeout` if it's < 2.0, otherwise `max_age`. I believe this is safer than catching `TypeError`.",check flask version use otherwise believe catching,issue,negative,positive,positive,positive,positive,positive
1552351575,"Also echoing this. A version 0 with just a static histogram would be already extremely useful. 

To be sure, this is what I'm looking for (from tensorboard):
![image](https://github.com/mlflow/mlflow/assets/48225584/2bee2549-e76a-431d-bd34-b137975604d0)
",also version static histogram would already extremely useful sure looking image,issue,positive,positive,positive,positive,positive,positive
1552345350,"It is legitimate that different backend uses different format experiment ID.
Just curious, what is the issue you are facing that is caused by the different ID format between filestore / sql-store backends ?

Changing sql-store backend experiment ID format is doable, but my concern is that it might cause backward-compatiblity issue, i.e. if we upgrade mlflow and new version mlflow might not work on existing mlflow database, we need to deal with such change carefully.",legitimate different different format experiment id curious issue facing different id format experiment id format doable concern might cause issue upgrade new version might work need deal change carefully,issue,negative,negative,neutral,neutral,negative,negative
1552313449,"> Hi @gabrielfu, can we work on the following follow-up tasks next?
> 
> 1. Add a client to manage permissions (prototype: [[Prototype] Add permission client harupy/mlflow#65](https://github.com/harupy/mlflow/pull/65))
> 2. Add a small doc (`docs/source/auth.rst`) for the basic auth feature.

Hi @harupy, of course! I will start implementing right away. I think there's still one part missing though: `after_request` for search experiment & models",hi work following next add client manage prototype prototype add permission client add small doc basic feature hi course start right away think still one part missing though search experiment,issue,negative,negative,neutral,neutral,negative,negative
1552288425,"@benjaminbluhm Could you merge the PR with mlflow/master ? Some CIs failed , we need to rerun it.",could merge need rerun,issue,negative,neutral,neutral,neutral,neutral,neutral
1551657867,"The new chart view is indeed looking really good! Excited for this. I'm already using this in a few collaborative projects on DagsHub. I discovered that due to the way the state of the chart view is saved to local storage in the browser, I can't share the chart view that I created with my collaborators. Each one sees what they configured, which is a shame since I think this feature could be much more powerful if it's shareable.

The way to reproduce this is to configure some custom charts in the chart view, then send it to someone else, when they view the MLflow UI, they will not see any configured charts.

Hope this is useful feedback! Thanks for the awesome feature.",new chart view indeed looking really good excited already collaborative discovered due way state chart view saved local storage browser ca share chart view one shame since think feature could much powerful shareable way reproduce configure custom chart view send someone else view see hope useful feedback thanks awesome feature,issue,positive,positive,positive,positive,positive,positive
1551643959,"I installed mlflow==2.3.2 and then pip installed azureml-mlflow, it installed 1.50.0 version, so that's a way to figure but providing users with a compatibility matrix would be useful.
```
mlflow==2.3.2
azureml-mlflow==1.50.0
```",pip version way figure providing compatibility matrix would useful,issue,negative,positive,positive,positive,positive,positive
1551437247,"Hi @gabrielfu, can we work on the following follow-up tasks next?

1. Add a client to manage permissions (prototype: https://github.com/harupy/mlflow/pull/65)
2. Add a small doc (`docs/source/auth.rst`) for the basic auth feature.",hi work following next add client manage prototype add small doc basic feature,issue,negative,negative,neutral,neutral,negative,negative
1551413908,"@harupy  I do not have this problem when I have one node, multi-GPU in Azure, however, I do have the problem if I have multi-node, multi-gpu in each node in Azure. Could you please suggest a fix?

Here's my `requirements.txt`:
```
 # for local testing (cpu)
torchvision==0.12.0
torch==1.11.0
transformers==4.18.0

# for metrics reporting/plotting
mlflow==1.25.1
azureml-mlflow==1.41.0
matplotlib==3.5.2
tqdm==4.64.0
psutil==5.9.0

# for unit testing
pytest==7.1.2

```

and here's my `Dockerfile`:
```
# check release notes https://docs.nvidia.com/deeplearning/frameworks/pytorch-release-notes/index.html
FROM nvcr.io/nvidia/pytorch:22.04-py3

##############################################################################
# NCCL TESTS
##############################################################################
ENV NCCL_TESTS_TAG=v2.11.0

# NOTE: adding gencodes to support K80, M60, V100, A100
RUN mkdir /tmp/nccltests && \
    cd /tmp/nccltests && \
    git clone -b ${NCCL_TESTS_TAG} https://github.com/NVIDIA/nccl-tests.git && \
    cd nccl-tests && \
    make \
    MPI=1 MPI_HOME=/opt/hpcx/ompi \
    NVCC_GENCODE=""-gencode=arch=compute_35,code=sm_35 -gencode=arch=compute_50,code=sm_50 -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_80,code=sm_80"" \
    CUDA_HOME=/usr/local/cuda && \
    cp ./build/* /usr/local/bin && \
    rm -rf /tmp/nccltests

# Install dependencies missing in this container
# NOTE: container already has matplotlib==3.5.1 tqdm==4.62.0
COPY requirements.txt ./
RUN pip install -r requirements.txt


# add ndv4-topo.xml
RUN mkdir /opt/microsoft/
ADD ./ndv4-topo.xml /opt/microsoft

# to use on A100, enable env var below in your job
# ENV NCCL_TOPO_FILE=""/opt/microsoft/ndv4-topo.xml""

# adjusts the level of info from NCCL tests
ENV NCCL_DEBUG=""INFO""
ENV NCCL_DEBUG_SUBSYS=""GRAPH,INIT,ENV""

# Relaxed Ordering can greatly help the performance of Infiniband networks in virtualized environments.
ENV NCCL_IB_PCI_RELAXED_ORDERING=""1""
ENV CUDA_DEVICE_ORDER=""PCI_BUS_ID""
ENV NCCL_SOCKET_IFNAME=""eth0""
# ENV NCCL_SOCKET_IFNAME='lo'
ENV NCCL_IB_DISABLE=""1""

```

Here's the non-problematic situation:

```
fec33820a43e42eaa326fabda0a0a7b3000001:37:37 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0
fec33820a43e42eaa326fabda0a0a7b3000001:37:37 [0] NCCL INFO Bootstrap : Using eth0:10.0.0.5<0>
fec33820a43e42eaa326fabda0a0a7b3000001:37:37 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
fec33820a43e42eaa326fabda0a0a7b3000001:37:37 [0] NCCL INFO P2P plugin IBext
fec33820a43e42eaa326fabda0a0a7b3000001:37:37 [0] NCCL INFO NCCL_IB_PCI_RELAXED_ORDERING set by environment to 1.
fec33820a43e42eaa326fabda0a0a7b3000001:37:37 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0
fec33820a43e42eaa326fabda0a0a7b3000001:37:37 [0] NCCL INFO NET/IB : No device found.
fec33820a43e42eaa326fabda0a0a7b3000001:37:37 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
fec33820a43e42eaa326fabda0a0a7b3000001:37:37 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0
fec33820a43e42eaa326fabda0a0a7b3000001:37:37 [0] NCCL INFO NET/Socket : Using [0]eth0:10.0.0.5<0>
fec33820a43e42eaa326fabda0a0a7b3000001:37:37 [0] NCCL INFO Using network Socket
NCCL version 2.10.3+cuda10.2
fec33820a43e42eaa326fabda0a0a7b3000001:37:208 [0] NCCL INFO Topology detection : could not read /sys/devices/LNXSYSTM:00/LNXSYBUS:00/PNP0A03:00/device:07/VMBUS:01/47505500-0001-0000-3130-444531303244/pci0001:00/0001:00:00.0/../max_link_speed, ignoring
fec33820a43e42eaa326fabda0a0a7b3000001:37:208 [0] NCCL INFO Topology detection : could not read /sys/devices/LNXSYSTM:00/LNXSYBUS:00/PNP0A03:00/device:07/VMBUS:01/47505500-0001-0000-3130-444531303244/pci0001:00/0001:00:00.0/../max_link_width, ignoring
fec33820a43e42eaa326fabda0a0a7b3000001:37:208 [0] NCCL INFO Topology detection : could not read /sys/devices/LNXSYSTM:00/LNXSYBUS:00/PNP0A03:00/device:07/VMBUS:01/47505500-0002-0000-3130-444531303244/pci0002:00/0002:00:00.0/../max_link_speed, ignoring
fec33820a43e42eaa326fabda0a0a7b3000001:37:208 [0] NCCL INFO Topology detection : could not read /sys/devices/LNXSYSTM:00/LNXSYBUS:00/PNP0A03:00/device:07/VMBUS:01/47505500-0002-0000-3130-444531303244/pci0002:00/0002:00:00.0/../max_link_width, ignoring
fec33820a43e42eaa326fabda0a0a7b3000001:37:208 [0] NCCL INFO Topology detection : could not read /sys/devices/LNXSYSTM:00/LNXSYBUS:00/PNP0A03:00/device:07/VMBUS:01/47505500-0003-0000-3130-444531303244/pci0003:00/0003:00:00.0/../max_link_speed, ignoring
fec33820a43e42eaa326fabda0a0a7b3000001:37:208 [0] NCCL INFO Topology detection : could not read /sys/devices/LNXSYSTM:00/LNXSYBUS:00/PNP0A03:00/device:07/VMBUS:01/47505500-0003-0000-3130-444531303244/pci0003:00/0003:00:00.0/../max_link_width, ignoring
fec33820a43e42eaa326fabda0a0a7b3000001:37:208 [0] NCCL INFO Topology detection : could not read /sys/devices/LNXSYSTM:00/LNXSYBUS:00/PNP0A03:00/device:07/VMBUS:01/47505500-0004-0000-3130-444531303244/pci0004:00/0004:00:00.0/../max_link_speed, ignoring
fec33820a43e42eaa326fabda0a0a7b3000001:37:208 [0] NCCL INFO Topology detection : could not read /sys/devices/LNXSYSTM:00/LNXSYBUS:00/PNP0A03:00/device:07/VMBUS:01/47505500-0004-0000-3130-444531303244/pci0004:00/0004:00:00.0/../max_link_width, ignoring
fec33820a43e42eaa326fabda0a0a7b3000001:37:208 [0] NCCL INFO Topology detection: network path /sys/devices/LNXSYSTM:00/LNXSYBUS:00/PNP0A03:00/device:07/VMBUS:01/6045bdbd-f1de-6045-bdbd-f1de6045bdbd is not a PCI device (vmbus). Attaching to first CPU
fec33820a43e42eaa326fabda0a0a7b3000001:37:208 [0] NCCL INFO KV Convert to int : could not find value of '' in dictionary, falling back to 60
fec33820a43e42eaa326fabda0a0a7b3000001:37:208 [0] NCCL INFO KV Convert to int : could not find value of '' in dictionary, falling back to 60
fec33820a43e42eaa326fabda0a0a7b3000001:37:208 [0] NCCL INFO KV Convert to int : could not find value of '' in dictionary, falling back to 60
fec33820a43e42eaa326fabda0a0a7b3000001:37:208 [0] NCCL INFO KV Convert to int : could not find value of '' in dictionary, falling back to 60
fec33820a43e42eaa326fabda0a0a7b3000001:37:208 [0] NCCL INFO Attribute coll of node net not found
fec33820a43e42eaa326fabda0a0a7b3000001:37:208 [0] NCCL INFO === System : maxWidth 12.0 totalWidth 12.0 ===
fec33820a43e42eaa326fabda0a0a7b3000001:37:208 [0] NCCL INFO CPU/0 (1/1/1)
fec33820a43e42eaa326fabda0a0a7b3000001:37:208 [0] NCCL INFO + PCI[5000.0] - NIC/0
fec33820a43e42eaa326fabda0a0a7b3000001:37:208 [0] NCCL INFO + PCI[12.0] - GPU/100000 (0)
fec33820a43e42eaa326fabda0a0a7b3000001:37:208 [0] NCCL INFO + PCI[12.0] - GPU/200000 (1)
fec33820a43e42eaa326fabda0a0a7b3000001:37:208 [0] NCCL INFO + PCI[12.0] - GPU/300000 (2)
fec33820a43e42eaa326fabda0a0a7b3000001:37:208 [0] NCCL INFO + PCI[12.0] - GPU/400000 (3)
fec33820a43e42eaa326fabda0a0a7b3000001:37:208 [0] NCCL INFO ==========================================
fec33820a43e42eaa326fabda0a0a7b3000001:37:208 [0] NCCL INFO GPU/100000 :GPU/100000 (0/5000.000000/LOC) GPU/200000 (2/12.000000/PHB) GPU/300000 (2/12.000000/PHB) GPU/400000 (2/12.000000/PHB) CPU/0 (1/12.000000/PHB) 
fec33820a43e42eaa326fabda0a0a7b3000001:37:208 [0] NCCL INFO GPU/200000 :GPU/100000 (2/12.000000/PHB) GPU/200000 (0/5000.000000/LOC) GPU/300000 (2/12.000000/PHB) GPU/400000 (2/12.000000/PHB) CPU/0 (1/12.000000/PHB) 
fec33820a43e42eaa326fabda0a0a7b3000001:37:208 [0] NCCL INFO GPU/300000 :GPU/100000 (2/12.000000/PHB) GPU/200000 (2/12.000000/PHB) GPU/300000 (0/5000.000000/LOC) GPU/400000 (2/12.000000/PHB) CPU/0 (1/12.000000/PHB) 
fec33820a43e42eaa326fabda0a0a7b3000001:37:208 [0] NCCL INFO GPU/400000 :GPU/100000 (2/12.000000/PHB) GPU/200000 (2/12.000000/PHB) GPU/300000 (2/12.000000/PHB) GPU/400000 (0/5000.000000/LOC) CPU/0 (1/12.000000/PHB) 
fec33820a43e42eaa326fabda0a0a7b3000001:37:208 [0] NCCL INFO Pattern 4, crossNic 0, nChannels 1, speed 10.000000/10.000000, type PHB/PIX, sameChannels 1
fec33820a43e42eaa326fabda0a0a7b3000001:37:208 [0] NCCL INFO  0 : GPU/0 GPU/1 GPU/2 GPU/3
fec33820a43e42eaa326fabda0a0a7b3000001:37:208 [0] NCCL INFO Pattern 1, crossNic 0, nChannels 1, speed 10.000000/10.000000, type PHB/PIX, sameChannels 1
fec33820a43e42eaa326fabda0a0a7b3000001:37:208 [0] NCCL INFO  0 : GPU/0 GPU/1 GPU/2 GPU/3
fec33820a43e42eaa326fabda0a0a7b3000001:37:208 [0] NCCL INFO Pattern 3, crossNic 0, nChannels 1, speed 10.000000/10.000000, type PHB/PIX, sameChannels 1
fec33820a43e42eaa326fabda0a0a7b3000001:37:208 [0] NCCL INFO  0 : GPU/0 GPU/1 GPU/2 GPU/3
fec33820a43e42eaa326fabda0a0a7b3000001:37:208 [0] NCCL INFO Tree 0 : -1 -> 0 -> 1/-1/-1
fec33820a43e42eaa326fabda0a0a7b3000001:37:208 [0] NCCL INFO Tree 1 : -1 -> 0 -> 1/-1/-1
fec33820a43e42eaa326fabda0a0a7b3000001:37:208 [0] NCCL INFO Channel 00/02 :    0   1   2   3
fec33820a43e42eaa326fabda0a0a7b3000001:37:208 [0] NCCL INFO Channel 01/02 :    0   1   2   3
fec33820a43e42eaa326fabda0a0a7b3000001:37:208 [0] NCCL INFO Ring 00 : 3 -> 0 -> 1
fec33820a43e42eaa326fabda0a0a7b3000001:37:208 [0] NCCL INFO Ring 01 : 3 -> 0 -> 1
fec33820a43e42eaa326fabda0a0a7b3000001:37:208 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
fec33820a43e42eaa326fabda0a0a7b3000001:37:208 [0] NCCL INFO Setting affinity for GPU 0 to 0fff
fec33820a43e42eaa326fabda0a0a7b3000001:37:208 [0] NCCL INFO Channel 00 : 0[100000] -> 1[200000] via direct shared memory
fec33820a43e42eaa326fabda0a0a7b3000001:37:208 [0] NCCL INFO Channel 01 : 0[100000] -> 1[200000] via direct shared memory
fec33820a43e42eaa326fabda0a0a7b3000001:37:208 [0] NCCL INFO Connected all rings
fec33820a43e42eaa326fabda0a0a7b3000001:37:208 [0] NCCL INFO Connected all trees
fec33820a43e42eaa326fabda0a0a7b3000001:37:208 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
fec33820a43e42eaa326fabda0a0a7b3000001:37:208 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
fec33820a43e42eaa326fabda0a0a7b3000001:37:208 [0] NCCL INFO comm 0x153eb0001240 rank 0 nranks 4 cudaDev 0 busId 100000 - Init COMPLETE
fec33820a43e42eaa326fabda0a0a7b3000001:37:37 [0] NCCL INFO Launch mode Parallel
MLflow version: 1.25.1
Tracking URI: azureml:URI
Artifact URI: azureml:URI
World size: 4
local rank is 0 and world rank is 0
Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data_0/cifar-10-python.tar.gz

  0%|          | 0/170498071 [00:00<?, ?it/s]
  0%|          | 544768/170498071 [00:00<00:31, 5369680.61it/s]
  2%|▏         | 2880512/170498071 [00:00<00:10, 15844914.53it/s]
  3%|▎         | 5056512/170498071 [00:00<00:09, 17856230.77it/s]
  4%|▍         | 7335936/170498071 [00:00<00:08, 19729892.43it/s]
  6%|▌         | 9648128/170498071 [00:00<00:07, 20931046.37it/s]
  7%|▋         | 11968512/170498071 [00:00<00:07, 21630963.81it/s]
  8%|▊         | 14247936/170498071 [00:00<00:07, 22005088.89it/s]
 10%|▉         | 16520192/170498071 [00:00<00:06, 22113817.44it/s]
 11%|█         | 18784256/170498071 [00:00<00:06, 22276545.60it/s]
 12%|█▏        | 21054464/170498071 [00:01<00:06, 22407118.86it/s]
 14%|█▎        | 23296000/170498071 [00:01<00:06, 22188998.50it/s]
 15%|█▍        | 25516032/170498071 [00:01<00:06, 21661435.98it/s]
 16%|█▌        | 27685888/170498071 [00:01<00:06, 21140440.07it/s]
 17%|█▋        | 29804544/170498071 [00:01<00:06, 20593556.49it/s]
 19%|█▊        | 31868928/170498071 [00:01<00:06, 20156557.50it/s]
 20%|█▉        | 33888256/170498071 [00:01<00:06, 19745679.59it/s]
 21%|██        | 35865600/170498071 [00:01<00:06, 19687404.90it/s]
 22%|██▏       | 37836800/170498071 [00:01<00:06, 19460052.10it/s]
 23%|██▎       | 39784448/170498071 [00:01<00:06, 19222178.56it/s]
 24%|██▍       | 41707520/170498071 [00:02<00:06, 19104469.22it/s]
 26%|██▌       | 43624448/170498071 [00:02<00:06, 19072615.77it/s]
 27%|██▋       | 45544448/170498071 [00:02<00:06, 19046030.11it/s]
 28%|██▊       | 47472640/170498071 [00:02<00:06, 18993926.03it/s]
 29%|██▉       | 49392640/170498071 [00:02<00:06, 18941301.65it/s]
 30%|███       | 51333120/170498071 [00:02<00:06, 19078166.70it/s]
 31%|███       | 53265408/170498071 [00:02<00:06, 19150688.08it/s]
 32%|███▏      | 55181312/170498071 [00:02<00:06, 19015663.83it/s]
 33%|███▎      | 57083904/170498071 [00:02<00:05, 18921455.92it/s]
 35%|███▍      | 59008000/170498071 [00:02<00:05, 18876725.57it/s]
 36%|███▌      | 60896256/170498071 [00:03<00:05, 18868879.10it/s]
 37%|███▋      | 62840832/170498071 [00:03<00:05, 19039215.17it/s]
 38%|███▊      | 64745472/170498071 [00:03<00:05, 18795086.88it/s]
 39%|███▉      | 66632704/170498071 [00:03<00:05, 18810168.86it/s]
 40%|████      | 68552704/170498071 [00:03<00:05, 18886629.32it/s]
 41%|████▏     | 70480896/170498071 [00:03<00:05, 18926663.49it/s]
 42%|████▏     | 72408064/170498071 [00:03<00:05, 19017268.26it/s]
 44%|████▎     | 74384384/170498071 [00:03<00:05, 19154625.24it/s]
 45%|████▍     | 76312576/170498071 [00:03<00:04, 19185430.64it/s]
 46%|████▌     | 78232576/170498071 [00:03<00:04, 19044355.19it/s]
 47%|████▋     | 80138240/170498071 [00:04<00:04, 19032394.16it/s]
 48%|████▊     | 82072576/170498071 [00:04<00:04, 19032762.39it/s]
 49%|████▉     | 84000768/170498071 [00:04<00:04, 18993284.35it/s]
 50%|█████     | 85984256/170498071 [00:04<00:04, 19194041.36it/s]
 52%|█████▏    | 87968768/170498071 [00:04<00:04, 19295312.99it/s]
 53%|█████▎    | 89960448/170498071 [00:04<00:04, 19394267.99it/s]
 54%|█████▍    | 91943936/170498071 [00:04<00:04, 19474106.16it/s]
 55%|█████▌    | 94000128/170498071 [00:04<00:03, 19731032.65it/s]
 56%|█████▋    | 96304128/170498071 [00:04<00:03, 20653426.52it/s]
 58%|█████▊    | 98657280/170498071 [00:05<00:03, 21509811.57it/s]
 59%|█████▉    | 100984832/170498071 [00:05<00:03, 21949022.30it/s]
 61%|██████    | 103304192/170498071 [00:05<00:03, 22318196.75it/s]
 62%|██████▏   | 105656320/170498071 [00:05<00:02, 22563801.79it/s]
 63%|██████▎   | 107984896/170498071 [00:05<00:02, 22772587.92it/s]
 65%|██████▍   | 110336000/170498071 [00:05<00:02, 22893636.05it/s]
 66%|██████▋   | 113224704/170498071 [00:05<00:02, 24611655.12it/s]
 68%|██████▊   | 116120576/170498071 [00:05<00:02, 25873352.76it/s]
 70%|██████▉   | 118992896/170498071 [00:05<00:01, 26672004.11it/s]
 71%|███████▏  | 121872384/170498071 [00:05<00:01, 27269632.47it/s]
 73%|███████▎  | 124768256/170498071 [00:06<00:01, 27738624.97it/s]
 75%|███████▍  | 127640576/170498071 [00:06<00:01, 27994351.27it/s]
 77%|███████▋  | 130528256/170498071 [00:06<00:01, 28237881.13it/s]
 78%|███████▊  | 133408768/170498071 [00:06<00:01, 28395251.23it/s]
 80%|███████▉  | 136296448/170498071 [00:06<00:01, 28490006.83it/s]
 82%|████████▏ | 139175936/170498071 [00:06<00:01, 28557051.70it/s]
 83%|████████▎ | 142064640/170498071 [00:06<00:00, 28576616.43it/s]
 85%|████████▌ | 144948224/170498071 [00:06<00:00, 28653993.24it/s]
 87%|████████▋ | 147896320/170498071 [00:06<00:00, 28869425.59it/s]
 88%|████████▊ | 150784000/170498071 [00:06<00:00, 28754943.51it/s]
 91%|█████████ | 155528192/170498071 [00:07<00:00, 34291822.22it/s]
 95%|█████████▍| 161680384/170498071 [00:07<00:00, 42359886.52it/s]
 98%|█████████▊| 167552000/170498071 [00:07<00:00, 47246998.05it/s]
170499072it [00:07, 23447255.93it/s]                               Extracting ./data_0/cifar-10-python.tar.gz to ./data_0
Files already downloaded and verified

[Epoch 1] loss: 469.946
[Epoch 2] loss: 331.277
[Epoch 3] loss: 288.598
[Epoch 4] loss: 271.003
[Epoch 5] loss: 253.672
[Epoch 6] loss: 238.890
[Epoch 7] loss: 228.931
[Epoch 8] loss: 218.206
[Epoch 9] loss: 220.511
[Epoch 10] loss: 199.832
[Epoch 11] loss: 186.101
[Epoch 12] loss: 188.461
[Epoch 13] loss: 179.636
```

Here's the full log of my problem when I switch to multi-node multi-GPU (here, 4 nodes each with 4 GPUs, 16 GPUs total):
https://github.com/microsoft/MLOpsPython/issues/416
https://github.com/mlflow/mlflow/issues/8444",problem one node azure however problem node azure could please suggest fix local testing metric unit testing check release note support run git clone make install missing container note container already copy run pip install add run add use enable job level graph relaxed greatly help performance situation set environment bootstrap path set environment set environment device found set environment set environment network socket version topology detection could read topology detection could read topology detection could read topology detection could read topology detection could read topology detection could read topology detection could read topology detection could read topology detection network path device first convert could find value dictionary falling back convert could find value dictionary falling back convert could find value dictionary falling back convert could find value dictionary falling back attribute coll node net found system pattern speed type pattern speed type pattern speed type tree tree channel channel ring ring setting affinity channel via direct memory channel via direct memory connected connected coll per peer rank complete launch mode parallel version artifact world size local rank world rank already epoch loss epoch loss epoch loss epoch loss epoch loss epoch loss epoch loss epoch loss epoch loss epoch loss epoch loss epoch loss epoch loss full log problem switch total,issue,negative,negative,neutral,neutral,negative,negative
1551390275,"@0mza987 given you work at Microsoft, would you please be able to tag Microsoft Azure mlflow team on either of the issues I have created? This one or the one linked to here? Thanks for your comment.

@WeichenXu123  It happens when I use an Azure GPU cluster with 4 nodes (4 instances) each node with 4 GPU (called process in Azure MLOps Pipeline Templates). I am using Azure MLOps Pipeline Template for submitting the job and I start the job from the Devops pipeline.",given work would please able tag azure team either one one linked thanks comment use azure cluster node process azure pipeline azure pipeline template job start job pipeline,issue,positive,positive,positive,positive,positive,positive
1551351643,"But with recent version I can't import Langchain in databricks. I have reported the issue and its still open [here](https://github.com/hwchase17/langchain/issues/4401) .

As old version is supported by databricks now,  there is any work around to make mlflow work with `langchain==0.0.125` ?

Any help would be appreciated. ",recent version ca import issue still open old version work around make work help would,issue,negative,positive,neutral,neutral,positive,positive
1551174165,You can share your code of logging params / metrics and I can help check.,share code logging metric help check,issue,positive,neutral,neutral,neutral,neutral,neutral
1551172965,"I use mlflow 2.3.2 to draw a plot with more than 20 points:

<img width=""1613"" alt=""image"" src=""https://github.com/mlflow/mlflow/assets/19235986/e2b52b60-66f1-4750-99c7-ee3e35a914c7"">
",use draw plot image,issue,negative,neutral,neutral,neutral,neutral,neutral
1551053991,"Got it. I guess it might be azure product network issue, would you ask Azure support team ? :)",got guess might azure product network issue would ask azure support team,issue,negative,neutral,neutral,neutral,neutral,neutral
1551031086,"@LukasBa1 

I cannot reproduce your reported bug,

I tested your code on Windows with mlflow 1.30.1 and mlflow 2.3.2, they both work fine.

For each version mlflow, I tested your code with MLflow sql-store backend and filestore backend. They all work fine. 
",reproduce bug tested code work fine version tested code work fine,issue,negative,positive,positive,positive,positive,positive
1551023419,"We are having the exact same error here. Our scenario is this:

```python
p = multiprocessing.Process(
    target=execute_request_multiprocessing_impl,  # use mlflow.get_run() inside
    args=(xxxx),
)

p.start()
mlflow.get_run(xx)
p.join()
```

Apparently `mlflow.get_run()` in `execute_request_multiprocessing_impl` works fine but the `mlflow.get_run()` after `p.start()` gets the `Timeout` error:

`WARNING:urllib3.connectionpool:Retrying (Retry(total=4, connect=5, read=4, redirect=5, status=5)) after connection broken by 'ReadTimeoutError(""HTTPSConnectionPool(host='eastus2euap.api.azureml.ms', port=443): Read timed out. (read timeout=120)"")': /mlflow/v2.0/subscriptions/xx/resourceGroups/xxx/providers/Microsoft.MachineLearningServices/workspaces/xxx/api/2.0/mlflow/runs/get?run_uuid=dummy&run_id=dummy`


In our case, the check run operation failed and the process get stucked. And it happens occasionally, like 10% chance to meet the error.
",exact error scenario python use inside apparently work fine error warning retry connection broken read timed read case check run operation process get occasionally like chance meet error,issue,negative,positive,neutral,neutral,positive,positive
1550806160,Merged master to reflect https://github.com/mlflow/mlflow/pull/8446. The R check should pass now.,master reflect check pas,issue,negative,neutral,neutral,neutral,neutral,neutral
1550534717,Question: Do you plan to use SSH to control arbitrary hostname machine in your proposed feature ?,question plan use control arbitrary machine feature,issue,negative,negative,neutral,neutral,negative,negative
1550519035,Could you update PR description to attach an example code that shows the case your PR supports ?,could update description attach example code case,issue,negative,neutral,neutral,neutral,neutral,neutral
1550513114,"@monajalal 

Could you help check
 - Is the metric logged successfully or not ?
 - Does the error always happen or it happens occasionally ?",could help check metric logged successfully error always happen occasionally,issue,negative,positive,positive,positive,positive,positive
1550236179,"Sanity check, it’s the same error still. @harupy
We've upgraded to the official mlflow image and switch to a postgres server. I don't there's a connectivity issue, as we can do literally any other operation without issue.

There's also a similar issue here: https://github.com/mlflow/mlflow/issues/3840 that is almost the same exact problem.

Source line is here:
`const runUuids = JSON.parse(searchValues['?runs']);
`
https://github.com/mlflow/mlflow/blob/v2.1.1/mlflow/server/js/src/experiment-tracking/components/CompareRunPage.js#L57

I tried more debugging on my end.
added a breakpoint and we get an parsing error as soon as we select any run, before even clicking on compare:

```
OTS parsing error: invalid sfntVersion: 1008821359
Failed to decode downloaded font: https://kubeflow.[host]/static-files/static/media/fontawesome-webfont.1e59d2330b4c6deb84b3.ttf
```
This usually occurs trying to load fonts, but getting HTML content instead.
This may or may not be related, not sure.

Finally when comparing three experiments, I was able to find the values it tries to parse during a comparison.
`search: ""?runs=%5B%25222aff5917ac904c1b92f6242892bf89eb%2522,%252289914c6a0a7140568299ed4d0d53dd51%2522%5D&experiments=%5B%25222%2522%5D"" `
It seems like '%' makes this an invalid json.",sanity check error still official image switch server connectivity issue literally operation without issue also similar issue almost exact problem source line tried end added get error soon select run even compare error invalid decode font usually trying load getting content instead may may related sure finally three able find parse comparison search like invalid,issue,negative,positive,positive,positive,positive,positive
1549945625,"I have recently run into a similar issue.  I get the `connect() failed (111: Connection refused) while connecting to upstream` error when trying to replace an existing endpoint right before that replacement fails.  Is it possible that the destination port is getting closed due to something (related to the delay perhaps?) in the endpoint replacement process? I also have issues creating new endpoints when trying to deploy to ml.t2.medium instances where the container seems to get hung up as  it gets to the step of installing pip dependencies.  The last message in the Cloudwatch logs, in these cases is: `Executing transactions: ..working.. done`.  If it was working properly, it should move on to `Installing pip dependencies:` but it just seems to hang there and eventually fails.  A larger instance seems to work, in some cases, but and it takes+30 minutes to create these endpoints.  To make things more confusing, I was previously able to deploy the same model using the same image on the ml.t2.medium.  This led me to wonder if it could have something to do with the fact that the Docker image always grabs the latest version of Miniconda.  It tried images that specifically used older versions but that didn't seem to solve the problem. I also tried using some older images and that worked for one model but not another.  Everything was fine until recently.  
",recently run similar issue get connect connection upstream error trying replace right replacement possible destination port getting closed due something related delay perhaps replacement process also new trying deploy container get hung step pip last message working done working properly move pip eventually instance work create make previously able deploy model image led wonder could something fact docker image always latest version tried specifically used older seem solve problem also tried older worked one model another everything fine recently,issue,negative,positive,positive,positive,positive,positive
1549891271,"@BenWilson2 Do you still need help with this? I can work on the following items:

- A full example of setting up a tracking server with nginx and basic http authentication with .htaccess (using env vars MLFLOW_TRACKING_USERNAME and MLFLOW_TRACKING_PASSWORD) 
- End to end tracking server configuration for MLflow Tracking Server used exclusively as proxied access host for artifact storage access [scenario 6](https://mlflow.org/docs/latest/tracking.html#scenario-6-mlflow-tracking-server-used-exclusively-as-proxied-access-host-for-artifact-storage-access)

",still need help work following full example setting server basic authentication end end server configuration server used exclusively access host artifact storage access scenario,issue,negative,positive,positive,positive,positive,positive
1549854329,"@ankit-db Hello, is there a known fix for this issue I have the same problem with both local and client mlflow using same version (2.2.2) ? ",hello known fix issue problem local client version,issue,negative,neutral,neutral,neutral,neutral,neutral
1549743613,"I have tried to reproduce this issue in my local machine with mlflow==2.3.2 and I see also that model is logged with .bst extension. I didn't suppose thah, but it could be environment problem of Jupyter Notebook in Kubeflow with image: jupyter-scipy:v1.6.0-rc.2 
Thanks for help. ",tried reproduce issue local machine see also model logged extension suppose could environment problem notebook image thanks help,issue,negative,positive,neutral,neutral,positive,positive
1549702507,"Hi @szymonbcoding

Unfortunately, I cannot reproduce your issue using mlflow==2.3.2

I first tried your reproducing code in PR description, it logs model as file ""model.xgb"" (xgb is the default model_format)

then I called `mlflow.xgboost.autolog(model_format='bst')`,

then rerun your xgboost training code, then the model is logged as file ""model.bst"".


Could you double check your mlflow version ?",hi unfortunately reproduce issue first tried code description model file default rerun training code model logged file could double check version,issue,negative,negative,neutral,neutral,negative,negative
1549441363,"I think a workaround could be, setting environment variable instead of params in this case,
on windows, you can set environment variable by command like:

```
set xyz=aa bb cc
```
(xyz is the environment variable name and the content after `=` is the environment variable value)",think could setting environment variable instead case set environment variable command like set environment variable name content environment variable value,issue,positive,neutral,neutral,neutral,neutral,neutral
1549417958,"Thanks for reporting this !

But we cannot easily splitting the command to multiple components, the reason is:

* (1) on UNIX-like system, (e.g., linux/macos) , because we need to use `bash -c XXX`, we have to pass `[""bach"", ""-c"", some_command]` to `Popen`, the `some_command` must be one string containing the whole command (the command string can also be multiple commands connected with `&&` e.g. `'command1 && command2'`),  otherwise it does not work.


* (2) For windows, seemingly we can split the `some_command` into a list of strings, but, if doing this, we need to change code in a lot of places, because the command here contains the part ""conda activate xxx"", we already generate a whole string for the activating command.
",thanks easily splitting command multiple reason system need use bash pas bach must one string whole command command string also multiple connected command otherwise work seemingly split list need change code lot command part activate already generate whole string command,issue,positive,positive,positive,positive,positive,positive
1549310942,Good proposal! Exciting to see your PR :),good proposal exciting see,issue,positive,positive,positive,positive,positive,positive
1549290492,"Thanks for reporting this, I will take a look soon.",thanks take look soon,issue,negative,positive,positive,positive,positive,positive
1548811962,"it was complaining about the hadoop executable missing but I also did not install pyarrow, I will try this out !",executable missing also install try,issue,negative,negative,negative,negative,negative,negative
1548797677,"I thin you are using an out-of-date langchain package , the latest version is 0.0.170 now. And I tested in 0.0.170 version we don't have the issue.",thin package latest version tested version issue,issue,negative,positive,neutral,neutral,positive,positive
1548787215,"> Yeah in the end I modified the Dockerfile to add pymsql as a client, the only i'm still having trouble with is the hadoop client for hdfs artifcats destination 🤔 if you have any idea ?

We use pyarrow hdfs client, what issue did you hit ? You should confirm first that pyarrow is correctly installed.",yeah end add client still trouble client destination idea use client issue hit confirm first correctly,issue,negative,positive,neutral,neutral,positive,positive
1547977841,"For local storage users, you can move folder from a xp to an other, don't forget to update metadata if necessary.",local storage move folder forget update necessary,issue,negative,neutral,neutral,neutral,neutral,neutral
1547899899,"Hello @WeichenXu123 ,thanks for taking a lead on this topic.
As  I got  the error with latest version of `langchain` I  have repoted the issue [here](https://github.com/hwchase17/langchain/issues/4401) and  using ` langchain==0.0.125`.

Complete code :

```
from langchain import PromptTemplate, HuggingFaceHub, LLMChain
from langchain.llms import HuggingFacePipeline
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, AutoModelForSeq2SeqLM


import torch
import mlflow

tokenizer = AutoTokenizer.from_pretrained(""google/flan-t5-small"")

model = AutoModelForSeq2SeqLM.from_pretrained(""google/flan-t5-small"")
pipe = pipeline(
    ""text2text-generation"",
    model=model, 
    tokenizer=tokenizer, 
    max_length=100
)

local_llm = HuggingFacePipeline(pipeline=pipe)
template = """"""Translate everything you see after this into French:{input}""""""
prompt = PromptTemplate(template=template, input_variables=[""input""])

llm_chain = LLMChain(prompt=prompt, 
                     llm=local_llm
                     )
question = ""What is the capital of England?""
print(llm_chain.run(question))

mlflow.langchain.log_model(
    lc_model=llm_chain,
    artifact_path=""model"",
    registered_model_name=""flan-t5""
)
```

",hello thanks taking lead topic got error latest version issue complete code import import import pipeline import torch import model pipe pipeline template translate everything see input prompt input question capital print question model,issue,negative,positive,positive,positive,positive,positive
1547885844,@dbczumar Maybe you can have a look at this as there seems to be another person (see above) who (likely) saw the same unexpected behavior. Thanks. ,maybe look another person see likely saw unexpected behavior thanks,issue,negative,positive,positive,positive,positive,positive
1547766883,"Yeah in the end I modified the Dockerfile to add pymsql as a client, the only i'm still having trouble with is the hadoop client for hdfs artifcats destination 🤔 if you have any idea ?",yeah end add client still trouble client destination idea,issue,negative,negative,negative,negative,negative,negative
1547444561,"@space192 I think we want to make the docker image small so we don't install all possible dependencies. You can use ""sqlite"" database instead of mysql in docker container, or you can manually install mysql + pymysql which should be simple. :)",space think want make docker image small install possible use instead docker container manually install simple,issue,negative,negative,neutral,neutral,negative,negative
1547437555,"I tested this with mlflow master version (you can install it via `pip install git+https://github.com/mlflow/mlflow`), it shows ""RESOURCE_ALREADY_EXISTS"" error, the full error stack from my testing code is:

```
/Users/weichen.xu/opt/miniconda3/envs/py38/bin/python3.8 /Users/weichen.xu/work/mlflow-debug/t00.py
Traceback (most recent call last):
  File ""/Users/weichen.xu/work/mlflow-debug/t00.py"", line 6, in <module>
    mlflow.create_experiment(""foo"")
  File ""/Users/weichen.xu/work/mlflow/mlflow/tracking/fluent.py"", line 1222, in create_experiment
    return MlflowClient().create_experiment(name, artifact_location, tags)
  File ""/Users/weichen.xu/work/mlflow/mlflow/tracking/client.py"", line 511, in create_experiment
    return self._tracking_client.create_experiment(name, artifact_location, tags)
  File ""/Users/weichen.xu/work/mlflow/mlflow/tracking/_tracking_service/client.py"", line 234, in create_experiment
    return self.store.create_experiment(
  File ""/Users/weichen.xu/work/mlflow/mlflow/store/tracking/rest_store.py"", line 95, in create_experiment
    response_proto = self._call_endpoint(CreateExperiment, req_body)
  File ""/Users/weichen.xu/work/mlflow/mlflow/store/tracking/rest_store.py"", line 56, in _call_endpoint
    return call_endpoint(self.get_host_creds(), endpoint, method, json_body, response_proto)
  File ""/Users/weichen.xu/work/mlflow/mlflow/utils/rest_utils.py"", line 303, in call_endpoint
    response = verify_rest_response(response, endpoint)
  File ""/Users/weichen.xu/work/mlflow/mlflow/utils/rest_utils.py"", line 227, in verify_rest_response
    raise RestException(json.loads(response.text))
mlflow.exceptions.RestException: RESOURCE_ALREADY_EXISTS: Experiment(name=foo) already exists. Error: (raised as a result of Query-invoked autoflush; consider using a session.no_autoflush block if this flush is occurring prematurely)
(sqlite3.IntegrityError) UNIQUE constraint failed: experiments.name
[SQL: INSERT INTO experiments (name, artifact_location, lifecycle_stage, creation_time, last_update_time) VALUES (?, ?, ?, ?, ?)]
[parameters: ('foo', '', 'active', 1684140167220, 1684140167220)]
(Background on this error at: https://sqlalche.me/e/14/gkpj)
```

Could you also  test against the latest dev mlflow version ? ",tested master version install via pip install error full error stack testing code recent call last file line module foo file line return name file line return name file line return file line file line return method file line response response file line raise experiment already error raised result consider block flush prematurely unique constraint insert name background error could also test latest dev version,issue,negative,positive,positive,positive,positive,positive
1547172638,"I assigned the task to you, feel free to file PR , I will review it. :)",assigned task feel free file review,issue,positive,positive,positive,positive,positive,positive
1547137813,"yes, we can only save session options when user provides this info and load model with session option if this config is saved in mlflow model. ",yes save session user load model session option saved model,issue,positive,neutral,neutral,neutral,neutral,neutral
1547120309,"> I think it is a solution. But is there any concern to save the options in MLmodel if user provides this info when saving models ? In this way, users don't need to set environemnt variables when they load the models, and it would be easier to share the mdoels.

if user provides this info when saving models, I think we can save them as model config. This sounds good.",think solution concern save user saving way need set load would easier share user saving think save model good,issue,positive,positive,positive,positive,positive,positive
1547094903,"I think it is a solution. But is there any concern to save the options in MLmodel if user provides this info when saving models ? In this way, users don't need to set environemnt variables when they load the models, and it would be easier to share the mdoels.",think solution concern save user saving way need set load would easier share,issue,positive,neutral,neutral,neutral,neutral,neutral
1546602993,"Hi @BenWilson2, just wanted to mention that if you think any of these custom flavors are worth turning into a built-in flavor, I would be happy to work on a PR - just in case :-) ",hi mention think custom worth turning flavor would happy work case,issue,positive,positive,positive,positive,positive,positive
1545551616,"My idea is we can allow user to define environment variable like:
`MLFLOW_ONNX_SESSION_OPTION.{KEY}`

and in code https://github.com/mlflow/mlflow/blob/79598e722f6772dde22a53ddef7f12157491de74/mlflow/onnx.py#L265
we can read the environment variables to get these option values and pass them to onnxruntime.InferenceSession constructor.

But type conversion might be a bit troublesome.",idea allow user define environment variable like key code read environment get option pas constructor type conversion might bit troublesome,issue,negative,neutral,neutral,neutral,neutral,neutral
1545514991,I don't quite understand how to control the session config with environment variable when loading onnx model with mlflow.pyfunc.load.,quite understand control session environment variable loading model,issue,negative,neutral,neutral,neutral,neutral,neutral
1545509042,"Q:

I guess a common case might be,

user loads an ONNX model at different environments, and for different environments, user want to config different session config. Shall we consider this case ?

If so , I feel like setting environment variable to control the session config might be a better choice when running model inference .",guess common case might user model different different user want different session shall consider case feel like setting environment variable control session might better choice running model inference,issue,positive,positive,neutral,neutral,positive,positive
1545495252,Hi @Abonia1 Could you provide your `langchain` package version and the complete reproducing code ? Thank you!,hi could provide package version complete code thank,issue,negative,positive,neutral,neutral,positive,positive
1545032043,"> @BenWilson2 Is this PR also a blocker for 2.3.2?

Tentatively yes. A lot of people have been asking for this",also blocker tentatively yes lot people,issue,negative,neutral,neutral,neutral,neutral,neutral
1544991793,This was identified as an issue in Azure ML notebooks and not related with MLflow SDK not the integration with Azure ML. @AdamLouly can we close this issue?,issue azure related integration azure close issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1544948245,"@jordan-melendez 

Synced with @dbczumar , now we agree your proposal ""I feel that it would be straightforward to allow an environment variable or CLI argument override it if necessary."" is better, by default the schema is None and it does not introduce breaking change.",agree proposal feel would straightforward allow environment variable argument override necessary better default schema none introduce breaking change,issue,positive,positive,positive,positive,positive,positive
1544944440,"@WeichenXu123 Thanks for reply. 
Yes I want to save session option when saving model, just like the provider info. 
Even though they are not bound to model, both session option and provider info are directly used when loading onnx model with pyfunc.load, and the loaded model is used directly for inference. 
So user should be able to configure the inference session.",thanks reply yes want save session option saving model like provider even though bound model session option provider directly used loading model loaded model used directly inference user able configure inference session,issue,positive,positive,positive,positive,positive,positive
1544054911,"> I feel that it would be straightforward to allow an environment variable or CLI argument override it if necessary.

My concern is this might cause trouble when we do [mlflow database upgrading ](https://github.com/mlflow/mlflow/blob/master/mlflow/store/db_migrations/README.md) we have to specify the old db schema name and new schema name when doing db migration, we'd better simplify the issue by fixing the schema name.",feel would straightforward allow environment variable argument override necessary concern might cause trouble specify old schema name new schema name migration better simplify issue fixing schema name,issue,negative,positive,positive,positive,positive,positive
1544045699,"1. Having a default of `mlflow` seems reasonable (though we may want to consider backwards compatibility here). However, I feel that it would be straightforward to allow an environment variable or CLI argument override it if necessary. Although not a deal breaker, it could be nice in my case to have different teams keep their tracking / model results in distinct parts of the database.
2. It appears that SQLAlchemy permits this functionality in multiple database types, see [this](https://docs.sqlalchemy.org/en/14/core/metadata.html#specifying-the-schema-name)
> Regardless of which kind of database is in use, SQLAlchemy uses the phrase “schema” to refer to the qualifying identifier within the general syntax of `“<qualifier>.<tablename>”`.",default reasonable though may want consider backwards compatibility however feel would straightforward allow environment variable argument override necessary although deal breaker could nice case different keep model distinct functionality multiple see regardless kind use phrase schema refer identifier within general syntax qualifier,issue,positive,positive,positive,positive,positive,positive
1544028905,"@BenWilson2 Unfortunately, I am not able to open source my companies code without permission.",unfortunately able open source code without permission,issue,negative,positive,positive,positive,positive,positive
1543904524,"> Thanks! Could you file a PR to fix the doc ? I think it is doc error.

Sure. Thanks for reply.",thanks could file fix doc think doc error sure thanks reply,issue,positive,positive,positive,positive,positive,positive
1543806298,Make sense! Appreciate your contribution!,make sense appreciate contribution,issue,negative,neutral,neutral,neutral,neutral,neutral
1543804141,Question: Would you want save the session option values when saving model ? These configs looks like some runtime config e.g. `intra_op_num_threads` that is not bound to the model,question would want save session option saving model like bound model,issue,positive,neutral,neutral,neutral,neutral,neutral
1543796968,Thanks! Could you file a PR to fix the doc ? I think it is doc error.,thanks could file fix doc think doc error,issue,negative,positive,positive,positive,positive,positive
1543790628,"Good proposal! But I have 2 questions:

* can we fix the schema name to be `mlflow` ? i.e. all tables becomes `mlflow.*`, this way is simpler.
* can it support all other kinds of databases that mlflow already supports (mysql, sqlite, etc ?) Currently we uses `SQLAlchemy` to control database, if `SQLAlchemy` supports it well it is fine.",good proposal fix schema name table becomes way simpler support already currently control well fine,issue,positive,positive,positive,positive,positive,positive
1543740264,"@jinzhang21 I think tensorboard implements this quite well (add_image command), maybe that UX is helpful?",think quite well command maybe helpful,issue,positive,neutral,neutral,neutral,neutral,neutral
1543733235,"@jinzhang21 
Any updates on this feature? Are there any concrete plans to make this happen?

",feature concrete make happen,issue,negative,positive,positive,positive,positive,positive
1543510234,Does 2.0.1? I see that it was merged into 2.0.0 as well. Can you please confirm?,see well please confirm,issue,positive,neutral,neutral,neutral,neutral,neutral
1543038536,"Hi @dbczumar I'm able to replicate this bug and would be happy to work on this if you would like to assign the issue to me, cheers!",hi able replicate bug would happy work would like assign issue,issue,positive,positive,positive,positive,positive,positive
1542846352,Hi @lobrien could you revert that merge and rebase from your fork's updated main branch? There are some issues with the merge above. Thanks!,hi could revert merge rebase fork main branch merge thanks,issue,negative,positive,positive,positive,positive,positive
1541062885,"@dbczumar 

As a user, it is not expected behavior. if the user does not provide each artifact with a different name, the system uses the last steps and does not raise any warning. Users think that all is well, but it's not. At a bare minimum, an error should be popped. 

This can be a big implication for automation where machine may be packaging the artifacts. ",user behavior user provide artifact different name system last raise warning think well bare minimum error big implication machine may,issue,negative,positive,neutral,neutral,positive,positive
1541034311,"Could you elaborate on what you're trying to see? Or maybe open up a new issue with the specific feature ask?
",could elaborate trying see maybe open new issue specific feature ask,issue,negative,positive,positive,positive,positive,positive
1541020314,"Hi @DhavalRepo18 , the behavior you're encountering is expected. We recommend using the `artifact_path` parameter to specify different destinations for each model artifact, e.g. `artifact_path=""model/step1""`, `artifact_path=""model/step2""`, etc. Thank you for using MLflow!",hi behavior recommend parameter specify different model artifact thank,issue,positive,neutral,neutral,neutral,neutral,neutral
1541018542,"Hi @DhavalRepo18 , thank you for identifying this issue in our documentation. We would be thrilled about a contribution for this fix. Thank you in advance for your pull request, and please let me know if you have any questions :)",hi thank issue documentation would contribution fix thank advance pull request please let know,issue,positive,neutral,neutral,neutral,neutral,neutral
1541012852,"Hi @peak-jiteshahuja, which database are you using for storage (e.g. MySQL, Postgres), and which version are you using? If possible, can you share a full stacktrace?",hi storage version possible share full,issue,negative,positive,positive,positive,positive,positive
1541010632,"Hi @sebastianfastert , thank you for pointing out this outdated piece of documentation. We would be thrilled if you could contribute a fix. Thank you in advance for your contribution, and please let me know if you have any questions :)",hi thank pointing outdated piece documentation would could contribute fix thank advance contribution please let know,issue,positive,negative,negative,negative,negative,negative
1540772780,"> Actually, given that Jerry found & fixed an issue in a docstrings code example in #8401, I'm assuming we don't have tests (e.g. [doctests](https://docs.python.org/3/library/doctest.html)) for the docstring examples 😅

We don't currently have testing of docstring examples, no. Definitely something to think about!",actually given jerry found fixed issue code example assuming currently testing definitely something think,issue,negative,positive,neutral,neutral,positive,positive
1540759824,"Actually, given that Jerry found & fixed an issue in a docstrings code example in https://github.com/mlflow/mlflow/pull/8401, I'm assuming we don't have tests (e.g. [doctests](https://docs.python.org/3/library/doctest.html)) for the docstring examples 😅 ",actually given jerry found fixed issue code example assuming,issue,negative,positive,neutral,neutral,positive,positive
1540468782,"Do you have an example that works properly that you'd be willing to contribute and are interested in updating documentation guidelines for this use case? If so, please feel free to file a PR and we can discuss there :) ",example work properly willing contribute interested documentation use case please feel free file discus,issue,positive,positive,positive,positive,positive,positive
1540158991,"One thing to think about for the future: If we want to simplify the component-level task allocation, the accelerate library automates handling device management based on detection of local environment configuration for inference. (It can assign tasks to multiple GPUs, a single GPU, or a CPU autonomously while also handling memory allocation and caching of pipeline components). If that is something that we'd like to entertain for inference, we'll want to ignore the `device` parameter at pipeline instantiation. 
This is just a note for future reference :) ",one thing think future want simplify task allocation accelerate library handling device management based detection local environment configuration inference assign multiple single autonomously also handling memory allocation pipeline something like entertain inference want ignore device parameter pipeline note future reference,issue,negative,positive,neutral,neutral,positive,positive
1540024894,"@BenWilson2 I think it is pretty much https://github.com/mlflow/mlflow/issues/4245 except that our pretrained model is wrapped with PytorchLightning module like in https://github.com/NielsRogge/Transformers-Tutorials/blob/master/Donut/CORD/Fine_tune_Donut_on_a_custom_dataset_(CORD)_with_PyTorch_Lightning.ipynb

Do you think it makes sense to open a new issue for it? I feel like there is just a best practice section missing in the docs for it. The `mlflow.pytorch.autolog()` was of no help because the `{Train,Val}Dataloader` seem to be pickled with the Lightning module and the they wrap the huggingface `datasets` and the caching makes it impossible to load it on a different filesystem.",think pretty much except model wrapped module like think sense open new issue feel like best practice section missing help train seem lightning module wrap impossible load different,issue,positive,positive,neutral,neutral,positive,positive
1540011776,@tahesse what is the nature of the issue that you're experiencing? Would you like to file an issue so that we can have a place to discuss and you can share example code?,nature issue would like file issue place discus share example code,issue,positive,neutral,neutral,neutral,neutral,neutral
1539999133,"Quick question: we're currently trying to log a pytorch lightning module with transformers in it (logging transformer model and processor via callback).

We are currently stuck loading these models with our lightning module wrapper - are there any best practices from the mlflow team?

I cannot find anything in the docs.",quick question currently trying log lightning module logging transformer model processor via currently stuck loading lightning module wrapper best team find anything,issue,negative,positive,positive,positive,positive,positive
1538599072,"Sorry again for breaking this! If there's anything LightGBM-related you all need some help with, please `@` me any time.",sorry breaking anything need help please time,issue,positive,negative,negative,negative,negative,negative
1538344523,"> @gabrielfu Sorry for the late reply! I was on vacation last week :) Thanks for the update!

No worries! :) ",sorry late reply vacation last week thanks update,issue,negative,negative,negative,negative,negative,negative
1538208696,Thanks for the PR @gabrielfu. I would really appreciate if this got merged. Is there anything I can do to help?,thanks would really appreciate got anything help,issue,positive,positive,positive,positive,positive,positive
1537928136,"Increase the default timeout value by setting the timeout database option:

""OPTIONS"": {
    # ...
    ""timeout"": 20,
    # ...
}",increase default value setting option,issue,positive,neutral,neutral,neutral,neutral,neutral
1537536651,"See 1091d71 for a suggestion. I could create a PR, if it's helpful.
",see suggestion could create helpful,issue,positive,neutral,neutral,neutral,neutral,neutral
1537432618,I am a beginner and willing to contribute if someone can specify the task and steps.,beginner willing contribute someone specify task,issue,negative,positive,positive,positive,positive,positive
1537193986,"Hi everyone, I have recently faced the same issue while starting `mlflow ui` from my local docker container.

I was following official mlflow tutorials, from [this](https://mlflow.org/docs/latest/quickstart.html). The code is following:
```
import mlflow
from sklearn.model_selection import train_test_split
from sklearn.datasets import load_diabetes
from sklearn.ensemble import RandomForestRegressor

mlflow.autolog()

db = load_diabetes()
X_train, X_test, y_train, y_test = train_test_split(db.data, db.target)
rf = RandomForestRegressor(n_estimators=100, max_depth=6, max_features=3)
rf.fit(X_train, y_train)
predictions = rf.predict(X_test)
```
Which outputs this traceback:
```
(base) root@85d11d68ad08:/workspace/cv_dev/MLOps# python test1.py 
2023/05/06 18:04:31 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.
2023/05/06 18:04:31 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'e116db062f054f0c9584041c92426f81', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow
2023/05/06 18:04:31 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during sklearn autologging: The configured tracking uri scheme: 'file' is invalid for use with the proxy mlflow-artifact scheme. The allowed tracking schemes are: {'https', 'http'}
```

**IMPORTANT,** when I repeat this scenario with running `mlflow ui` from standard terminal (not a docker container), everything works fine. ",hi everyone recently faced issue starting local docker container following official code following import import import import base root python successfully run id track performance metric model lineage information current warning unexpected error scheme invalid use proxy scheme important repeat scenario running standard terminal docker container everything work fine,issue,negative,positive,neutral,neutral,positive,positive
1537109836,"**+1**

Many metrics of mine are just pointless when only 3 digits after the decimal separator are displayed",many metric mine pointless decimal separator displayed,issue,negative,positive,positive,positive,positive,positive
1536908045,"> Can we also update our e2e test to cover this new behavior?

Yes! For sure!",also update test cover new behavior yes sure,issue,positive,positive,positive,positive,positive,positive
1536640473,So the base image I get from `mlflow sagemaker build-and-push-container` I can rebuild with Docker to support other architectures? Graviton is ARM and won't work with images that use x86.,base image get rebuild docker support arm wo work use,issue,negative,negative,negative,negative,negative,negative
1536582737,"> > > I am also facing the same problem. I run my experiments on a remote HPC server. I cannot visualize the results on the HPC server (no x window, no HTTP access).
> > > I have to download the mlruns folder to my local machine to visualize the results. However, the artifacts are stored in the absolute path and I cannot access them using mlflow UI.
> > > The capability to use a relative path instead of an absolute path would be very important.
> > 
> > 
> > Until this issue is fixed you can use [mlf-core's fix-artifact-paths](https://mlf-core.readthedocs.io/en/latest/fix_artifact_paths.html).
> 
> It seems that this library is a little outdated, and I wasn't able to get it to solve the problem. So I wrote a standalone script to fix artifact paths - sharing [here](https://gist.github.com/alam-shahul/08a92fd6c33a5584491af4c3ac515e61) in case anyone finds it useful.

I have tried various other approaches, from manipulating the path in Python after starting an mlflow run, to a system variable in the meta.yaml file for the absolute (first) part and batch files to fix the path or symbolic links. The best solution at the moment is the source code provided by @alam-shahul, wrapped in a batch file (if you like). 

I wasted a lot of time to find another workaround, but nothing worked.
For research purpose, where you can't share in one network and potentialy have to submit your code and data to someone else or for an exam, so you have to make a copy to another (unknown) system it would be way easier if there could be an easy build in way to use relativ paths. It would help to convince/enable more students to use the tool, too.
",also facing problem run remote server visualize server window access folder local machine visualize however absolute path access capability use relative path instead absolute path would important issue fixed use library little outdated able get solve problem wrote script fix artifact case anyone useful tried various path python starting run system variable file absolute first part batch fix path symbolic link best solution moment source code provided wrapped batch file like wasted lot time find another nothing worked research purpose ca share one network submit code data someone else exam make copy another unknown system would way easier could easy build way use would help use tool,issue,positive,positive,positive,positive,positive,positive
1536521778,@singankit do we have anything we can do immediately or will we need to go through the whole process of enabling network traces etc?,anything immediately need go whole process network,issue,negative,positive,positive,positive,positive,positive
1535997980,@dbczumar looks like those are fixed with alembic>=1.10.4 and sqlalchemy>=2.0.12. I wasn't able to replicate that issues with the same existing code. ,like fixed alembic able replicate code,issue,negative,positive,positive,positive,positive,positive
1535891782,This would be really useful for us as well. We work around this by using nested runs and limiting the number of experiments but that's not ideal. ,would really useful u well work around limiting number ideal,issue,positive,positive,positive,positive,positive,positive
1535541889,"Hi @roylleh, thank you for your feature request. You can use Graviton instance types (https://aws.amazon.com/about-aws/whats-new/2022/10/amazon-sagemaker-adds-new-graviton-based-instances-model-deployment/) by including an `""instance_type""` entry in your `config` dictionary when calling `get_deploy_client(""sagemaker"").create_deployment()`.

Please let me know if you need additional functionality in `mlflow sagemaker build-and-push-container` for this use case.",hi thank feature request use instance entry dictionary calling please let know need additional functionality use case,issue,positive,neutral,neutral,neutral,neutral,neutral
1535539482,@pradipneupane Got it - thank you! Our CI runs database migrations nightly with the latest versions of sqlalchemy and alembic. It looks like the most recent run with sqlalchemy==2.0.12 and alembic==1.10.4 is succeeding: https://github.com/mlflow/mlflow/actions/runs/4885156162/jobs/8718851278. Can you try again with the latest versions of each of these libraries?,got thank nightly latest alembic like recent run succeeding try latest,issue,positive,positive,positive,positive,positive,positive
1535523310,"> @BenWilson2 instead of pinning numpy in our tests, can we fix all of the incompatibilities that make them fail? Users will run into these incompatibilities when using these features with the latest numpy versions, right?

The gluon and shap issues are internal failures to those packages that are still using the deprecated numpy data types within their logic. The pins for onnx and mleap are for older versions only; the latest releases of them have fixes in place for numpy's 1.24.x changes. 
The two test failures that we have control over are for the numpy array creation from mixed length lists and the tensorflow array equivalency assertion that are adjusted in this PR. ",instead pinning fix make fail run latest right shap internal still data within logic older latest place two test control array creation mixed length array equivalency assertion,issue,negative,positive,positive,positive,positive,positive
1535437521,Thanks @dbczumar ! Glad to hear it's being worked on.,thanks glad hear worked,issue,positive,positive,positive,positive,positive,positive
1534458550,"I second this! 
I'm doing research in the field and often am in the situation where i do the training in one environment but end up doing the analysis somewhere else in a different environment in a different network with no way to run a mlflow server accessible from all locations (also due to the artefacts being quite large it is not feasible to run a AWS server as mlflow server externally)
For my next experiments i'll try running the code on an external drive and mounting the drive on the same mounting point on both devices.
Unfortunately for my past experiments it's too late though.
I really hope at some point there's the option to easily update the path, or to optionally change to relative paths. That would make things so much easier!

Edit:
I fixed the problem now using the fallowing SQL Query:
```SQL
UPDATE tablename SET columnname = replace( columnname, '/old/location/mlruns/', '/new/location/mlruns/' ) WHERE columnname LIKE '/old/location/mlruns/%'
```
You have to change the path in two tables:
1. Table: runs, column: artifact_uri
2. Table: experiments, column: artifact_location

If you get the alembic version error you have to use the same python version as used on the original machine where the db was created.

Probably there are other workarounds as well, but that worked for me!",second research field often situation training one environment end analysis somewhere else different environment different network way run server accessible also due quite large feasible run server server externally next try running code external drive mounting drive mounting point unfortunately past late though really hope point option easily update path optionally change relative would make much easier edit fixed problem query update set replace like change path two table table column table column get alembic version error use python version used original machine probably well worked,issue,positive,positive,neutral,neutral,positive,positive
1534300427,"Hi @harupy I'm just back from being away so looking at this again, couple questions:

1. For the Python search_runs I have `run_info_only` after the `pageToken` just to support backwards compatibility of positional arguments. But it looks a bit odd not to have `pageToken` be the last argument. Not sure which wins in importance? I (accidentally) made the Java do things more naturally with `runInfoOnly` first, but based on this answer can adjust Java to be consistent.

2. Could you rekick off the full test suite for the last commit please

Thank you :) ",hi back away looking couple python support backwards compatibility positional bit odd last argument sure importance accidentally made naturally first based answer adjust consistent could rekick full test suite last commit please thank,issue,positive,positive,positive,positive,positive,positive
1534286746,"I'm using this right now for some study purposes on my laptop and tower PC, sync via git and need relative paths too. Any update on the status?",right study tower sync via git need relative update status,issue,negative,positive,positive,positive,positive,positive
1533897373,"Hi @shimizust, thank you for notifying us of this gap. We're working to get source distributions published for future mlflow-skinny releases. Thank you for using MLflow!",hi thank u gap working get source future thank,issue,positive,neutral,neutral,neutral,neutral,neutral
1533896131,"Hi @sumitgpl , this appears to be a nodejs issue and not an MLflow issue. The workaround in https://stackoverflow.com/questions/69692842/ for nodejs v18 seems to help. Thank you for using MLflow!",hi issue issue help thank,issue,positive,neutral,neutral,neutral,neutral,neutral
1533895019,"Hi @asolimando, boto3 is deliberately excluded from the MLflow Server Docker image in order to keep dependencies minimal. Thank you for using MLflow!",hi deliberately server docker image order keep minimal thank,issue,negative,negative,neutral,neutral,negative,negative
1533893264,"Hi @balbarka, thank you for your proposal. This makes a lot of sense to me, and I think it would be a valuable addition for the community. Would you be interested in prototyping this extension for the MLflow Recipes regression template? https://github.com/mlflow/recipes-regression-template.",hi thank proposal lot sense think would valuable addition community would interested extension regression template,issue,positive,positive,positive,positive,positive,positive
1533521432,"I came across the same issue but when comparing runs. I can't quite identity what data fields on the run are causing the issue. None have any spaces but some have periods in them? Could that be the issue?

![Screen Shot 2023-05-02 at 2 13 36 PM](https://user-images.githubusercontent.com/19543576/236012099-2b9b1bb4-e808-44bc-9c23-de7ff06e50ec.png)
",came across issue ca quite identity data run causing issue none could issue screen shot,issue,negative,neutral,neutral,neutral,neutral,neutral
1532767730,"Hi @dbczumar, I would love to take on this issue, if that's okay with you guys?",hi would love take issue,issue,positive,positive,positive,positive,positive,positive
1532708881,"Hi @dbczumar @harupy, incase @arunkumarkota isn't available right now, I would be very happy to pick up the work. Could you update me with your current thoughts on this PR?",hi incase available right would happy pick work could update current,issue,positive,positive,positive,positive,positive,positive
1532104023,"> > @arpitjasa-db @vladimirk-db Can we clarify the motivation for this PR? Is it just to help users avoid typos in secret scopes? If this is being done for security purposes, it won't help since users can just modify the client code.
> 
> @dbczumar yeah besides typos, it will also make sure users know that they need the right permissions on the provided secret scope. While this is a soft-enforcement (you're right it can be removed), we do have other checks in place so that if the user does try do anything with this model in Databricks and they don't have the proper ACLs in place, they wouldn't be able to. But yeah more along the side of nice-to-have rather than need-to-have

Got it. I think it may be best to make this a warning :)",clarify motivation help avoid secret done security wo help since modify client code yeah besides also make sure know need right provided secret scope right removed place user try anything model proper place would able yeah along side rather got think may best make warning,issue,positive,positive,positive,positive,positive,positive
1532093038,"> @arpitjasa-db @vladimirk-db Can we clarify the motivation for this PR? Is it just to help users avoid typos in secret scopes? If this is being done for security purposes, it won't help since users can just modify the client code.

@dbczumar yeah besides typos, it will also make sure users know that they need the right permissions on the provided secret scope. While this is a soft-enforcement (you're right it can be removed), we do have other checks in place so that if the user does try do anything with this model in Databricks and they don't have the proper ACLs in place, they wouldn't be able to. But yeah more along the side of nice-to-have rather than need-to-have",clarify motivation help avoid secret done security wo help since modify client code yeah besides also make sure know need right provided secret scope right removed place user try anything model proper place would able yeah along side rather,issue,positive,positive,positive,positive,positive,positive
1530933972,"> Can we add this script as `examples/auth.py` for quick manual testing?

added!",add script quick manual testing added,issue,negative,positive,positive,positive,positive,positive
1530837948,Lint failures are unrelated and will be fixed in a separate PR. Merging :),lint unrelated fixed separate,issue,negative,positive,neutral,neutral,positive,positive
1528823677,Hello @harupy I would like to contribute to this issue. Can you assign this issue to me? And can you tell me the filename where you implemented the sphinx-copybutton .,hello would like contribute issue assign issue tell,issue,negative,neutral,neutral,neutral,neutral,neutral
1528214623,"I have more info. It appears that `IN` syntax does not work for `run_id`. Pinning runs is a red herring.

If I enter this filter string for the run list, it works:
```
attributes.run_id = 'd8c60187b6684a3795f2aec8563c482f'
```

If I enter this filter string, I get the same error:
```
attributes.run_id IN ('d8c60187b6684a3795f2aec8563c482f')
```

It's interesting, because this is literally almost identical to one of the example filter strings in the pop-up help. See screenshot.

<img width=""1113"" alt=""image"" src=""https://user-images.githubusercontent.com/1678585/235270199-788047b4-9441-4586-abf8-06636f8c620a.png"">
",syntax work pinning red herring enter filter string run list work enter filter string get error interesting literally almost identical one example filter help see image,issue,negative,positive,positive,positive,positive,positive
1528114210,"Also am not entirely sure what the linter is mad about. I tried following the docs in `CONTRIBUTING.md` saying to run `./dev/lint.sh`, but that file doesn't exist",also entirely sure linter mad tried following saying run file exist,issue,negative,negative,neutral,neutral,negative,negative
1528035303,"Guys just copy the MLproject file from any github repo (for reference: https://github.com/mlflow/mlflow/tree/master/examples) and change as per your configurations.
Make sure that MLproject does not follow any extension, its should just be a file.",copy file reference change per make sure follow extension file,issue,negative,positive,positive,positive,positive,positive
1527007638,"> Do we see a significant change in the speedup factor after doing this? + have we done checksum comparisons?

It's still quite fast (2GB in ~ 6-7 seconds, 10GB in ~ 24 seconds on a cheap Databricks test cluster) after some additional changes: https://github.com/mlflow/mlflow/pull/8352. This needs serious testing though, including checksums, ensuring nothing hangs, retry logic for 401s / 403s (this was broken before).

I'm closing this in favor of https://github.com/mlflow/mlflow/pull/8352.",see significant change factor done still quite fast cheap test cluster additional need serious testing though nothing retry logic broken favor,issue,positive,positive,neutral,neutral,positive,positive
1526412854,Is there a way to autoconnect a full tb url for the experiment run as e.g. we cannot log images with this API.,way full experiment run log,issue,negative,positive,positive,positive,positive,positive
1526380674,"Hey @bhack we were mostly adding tbX for pytorch autologging but after the pivot to bare tb in pytorch, @temporaer added it to the pytorch flavor. is there some other scenario you're interested in?",hey mostly pivot bare added flavor scenario interested,issue,negative,positive,positive,positive,positive,positive
1526159683,"@harupy looks like the ONNX flavor violates the signature of the predict method, [since it returns a dictionary in the pyfunc implementation](https://github.com/mlflow/mlflow/blob/92aa6c9575c0134e4445d289f1de3f32f73a511a/mlflow/onnx.py#L357). It's not in the list of supported types: 


[mlflow/models/utils.py:L40](https://github.com/mlflow/mlflow/blob/92aa6c9575c0134e4445d289f1de3f32f73a511a/mlflow/models/utils.py#L34) `PyFuncOutput = Union[pd.DataFrame, pd.Series, np.ndarray, list, str]`

Should this be adjusted or the ONNX flavor to return one of the supported types?",like flavor signature predict method since dictionary implementation list union list flavor return one,issue,negative,neutral,neutral,neutral,neutral,neutral
1525301782,"Can we add this script as `examples/auth.py` for quick manual testing?

```python
import os
import mlflow


class User:
    MLFLOW_TRACKING_USERNAME = ""MLFLOW_TRACKING_USERNAME""
    MLFLOW_TRACKING_PASSWORD = ""MLFLOW_TRACKING_PASSWORD""

    def __init__(self, username, password) -> None:
        self.username = username
        self.password = password
        self.env = {}

    def _record_env_var(self, key):
        if key := os.getenv(key):
            self.env[key] = key

    def _restore_env_var(self, key):
        if value := self.env.get(key):
            os.environ[key] = value
        else:
            del os.environ[key]

    def __enter__(self):
        self._record_env_var(User.MLFLOW_TRACKING_USERNAME)
        self._record_env_var(User.MLFLOW_TRACKING_PASSWORD)
        os.environ[User.MLFLOW_TRACKING_USERNAME] = self.username
        os.environ[User.MLFLOW_TRACKING_PASSWORD] = self.password
        return self

    def __exit__(self, *_exc):
        self._restore_env_var(User.MLFLOW_TRACKING_USERNAME)
        self._restore_env_var(User.MLFLOW_TRACKING_PASSWORD)
        self.env.clear()


mlflow.set_tracking_uri(""http://localhost:5000"")
A = User(""user_a"", ""password_a"")
B = User(""user_b"", ""password_b"")

with A:
    mlflow.set_experiment(""experiment_a"")
    with mlflow.start_run():
        mlflow.log_metric(""a"", 1)

with B:
    print(mlflow.get_experiment_by_name(""experiment_a"").tags)  # allowed
    with mlflow.start_run():  # not allowed
        mlflow.log_metric(""b"", 2)

```",add script quick manual testing python import o import class user self password none password self key key key key key self key value key key value else key self return self self user user print,issue,positive,positive,neutral,neutral,positive,positive
1525260904,@harupy Thanks. I am in the process of getting this done. Can I contribute to this in any way? I've a team of developer and testers as well. ,thanks process getting done contribute way team developer well,issue,positive,positive,positive,positive,positive,positive
1524903291,"> @SaravananSathyanandhaQC Thanks for the reply! Is there a reason that you're using a filestore?

Client restriction unfortunately, they don't allow central databases and servers. Instead users have their own machines where they run their Python scripts/models, and the machines have access to a common NFS. So the NFS is the Mlflow backing store because it's the only thing that all machines have shared access to.",thanks reply reason client restriction unfortunately allow central instead run python access common backing store thing access,issue,negative,negative,negative,negative,negative,negative
1524164785,"I have created a pull request from a non-master branch according to ""We recommend pull requests be filed from a non-master branch on a repository fork (e.g. <username>:fix-xxx). "" #8335 ",pull request branch according recommend pull branch repository fork,issue,negative,neutral,neutral,neutral,neutral,neutral
1523797618,"> Overall looks good. Just missing `input_tag`. Also, we have changed the `get_run` and `search_runs` APIs. Do we want to indicate that somewhere too?

Great catch! Added to `get_run()` in fluent and client. Search runs doesn't call out specifics about returned run content, so left that as-is for now.",overall good missing also want indicate somewhere great catch added fluent client search call returned run content left,issue,positive,positive,positive,positive,positive,positive
1523768368,"Hi @Ewande, yes it was done as part of this PR: https://github.com/mlflow/mlflow/pull/8322",hi yes done part,issue,negative,neutral,neutral,neutral,neutral,neutral
1523666280,"> @gabrielfu  Can I push a commit to add some CSS to the sign-up form?

Of course, please do",push commit add form course please,issue,positive,neutral,neutral,neutral,neutral,neutral
1523646515,@gabrielfu  Can I push a commit to add some CSS to the sign-up form?,push commit add form,issue,negative,neutral,neutral,neutral,neutral,neutral
1523408347,"@dbczumar The use case is that we use the Mlflow backend store for running and logging all our models, however we have a separate UI where, amongst other things, we allow users to view the the runs. We have ~100 experiments, with ~30 runs per experiment. The user can search and select the relevant experiment, see runs, and on selecting them we then show some info about the run and some outputs (domain specific UI using the logged outputs from the run).

So the motivation came from 2 areas (I realised a second one yesterday) where we call `search_runs`, which at the moment is being quite slow, affecting the user experience:

1. When they look through the list of experiments we want to show the number of runs in each experiment as a little icon beside. It's a bit of a nice to have that helps them quickly see the count, but it's frustrating (and somewhat surprising) that to collect the number of runs for every single experiment is taking 45 seconds.

2. When they select an experiment we show a list of runs with the info. However this call is slow because it's loading all the metrics, tags and params, even though we're not showing any of this extra info. Again it's mainly about the user response time being faster, and having pages load in 2 seconds instead of 15 seconds.

We're running our own Mlflow pointing to a filestore. It's NFS backed filesystem, which contributes to the slowness of loading lots of files, but it's maybe a 2x slow down compared to a standard file system.",use case use store running logging however separate amongst allow view per experiment user search select relevant experiment see show run domain specific logged run motivation came second one yesterday call moment quite slow affecting user experience look list want show number experiment little icon beside bit nice quickly see count somewhat surprising collect number every single experiment taking select experiment show list however call slow loading metric even though showing extra mainly user response time faster load instead running pointing backed loading lot maybe slow standard file system,issue,positive,positive,neutral,neutral,positive,positive
1523396098,"Is this a network connection issue? It's strange that the tracking server and api work just fine, but doing a compare in the UI triggers this. Like it clearly can communicate with the database, since it's logging experiments to it as well as s3. 

EDIT:  No, this is definitely a UI bug, I'm not even getting 502 errors anymore. The only error I'm getting now is:

`SyntaxError: Unexpected token '%', ""[%222e479c8""... is not valid JSON
    at JSON.parse (<anonymous>)
    at Function.mapToProps (CompareRunPage.tsx:59:25)
    at r (wrapMapToProps.js:41:46)
    at h (selectorFactory.js:38:57)
    at selectorFactory.js:64:32
    at connectAdvanced.js:327:16
    at Object.Na [as useMemo] (react-dom.production.min.js:168:377)
    at t.useMemo (react.production.min.js:23:113)
    at g (connectAdvanced.js:312:30)
    at sa (react-dom.production.min.js:157:137)`

and it only happens on comparison.

Worth noting I've upgraded to 2.3.0 before seeing the 502 errors disappear.",network connection issue strange server work fine compare like clearly communicate since logging well edit definitely bug even getting error getting unexpected token valid anonymous sa comparison worth seeing disappear,issue,positive,positive,positive,positive,positive,positive
1523321110,Maybe something is wrong with Ubuntu instances that Lambda Cloud provides. Can you reproduce this issue using Docker?,maybe something wrong lambda cloud reproduce issue docker,issue,negative,negative,negative,negative,negative,negative
1523276271,"Seems to me it might be related just to virtualenv. On the setup that reproduces the issue, with no `pyenv` installed, I already get this: in spite of the fact that the pip installation I am running contains a `_vendor/six.py`, the virtualenv I  made with `virtualenv` doesn't contain it. 

```
ubuntu@192-9-133-158:~$ which python
/usr/bin/python
ubuntu@192-9-133-158:~$ which pip
/home/ubuntu/.local/bin/pip
ubuntu@192-9-133-158:~$ which virtualenv
/usr/bin/virtualenv
ubuntu@192-9-133-158:~$ python --version
Python 3.8.10
ubuntu@192-9-133-158:~$ pip --version
pip 22.3 from /home/ubuntu/.local/lib/python3.8/site-packages/pip (python 3.8)
ubuntu@192-9-133-158:~$ ll /home/ubuntu/.local/lib/python3.8/site-packages/pip/_vendor/six.py 
-rw-rw-r-- 1 ubuntu ubuntu 34549 Oct 26 22:37 /home/ubuntu/.local/lib/python3.8/site-packages/pip/_vendor/six.py
ubuntu@192-9-133-158:~$ 
ubuntu@192-9-133-158:~$ virtualenv --python /usr/bin/python ~/enva
created virtual environment CPython3.8.10.final.0-64 in 166ms
  creator CPython3Posix(dest=/home/ubuntu/enva, clear=False, global=False)
  seeder FromAppData(download=False, pip=latest, setuptools=latest, wheel=latest, pkg_resources=latest, via=copy, app_data_dir=/home/ubuntu/.local/share/virtualenv/seed-app-data/v1.0.1.debian.1)
  activators BashActivator,CShellActivator,FishActivator,PowerShellActivator,PythonActivator,XonshActivator
ubuntu@192-9-133-158:~$ . ~/enva/bin/activate
(enva) ubuntu@192-9-133-158:~$ which pip
/home/ubuntu/enva/bin/pip
(enva) ubuntu@192-9-133-158:~$ which python
/home/ubuntu/enva/bin/python
(enva) ubuntu@192-9-133-158:~$ pip --version
pip 20.0.2 from /home/ubuntu/enva/lib/python3.8/site-packages/pip (python 3.8)
(enva) ubuntu@192-9-133-158:~$ ll /home/ubuntu/enva/lib/python3.8/site-packages/pip/_vendor
total 20
drwxrwxr-x 3 ubuntu ubuntu 4096 Apr 26 11:04 ./
drwxrwxr-x 5 ubuntu ubuntu 4096 Apr 26 11:04 ../
-rw-rw-r-- 1 ubuntu ubuntu 4975 Apr 26 11:02 __init__.py
drwxrwxr-x 2 ubuntu ubuntu 4096 Apr 26 11:04 __pycache__/
```

The line 
`seeder FromAppData(download=False, pip=latest, setuptools=latest, wheel=latest, pkg_resources=latest, via=copy, app_data_dir=/home/ubuntu/.local/share/virtualenv/seed-app-data/v1.0.1.debian.1)` 
references an `app_data_dir` that didn't exist, and `virtualenv` has created itself.

On the PC where mlflow works correctly I get this instead
```
⮕ virtualenv --python /usr/bin/python3 ~/enva
created virtual environment CPython3.10.6.final.0-64 in 69ms
  creator CPython3Posix(dest=/home/fanta/enva, clear=False, no_vcs_ignore=False, global=False)
  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/home/fanta/.local/share/virtualenv)
    added seed packages: pip==22.0.2, setuptools==59.6.0, wheel==0.37.1
  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator
```",might related setup issue already get spite fact pip installation running made contain python pip python version python pip version pip python python virtual environment creator seeder pip python pip version pip python total line seeder exist work correctly get instead python virtual environment creator seeder added seed,issue,negative,neutral,neutral,neutral,neutral,neutral
1523206015,"> LGTM! Can you resolve conflicts?

Done, can you please check again @harupy?",resolve done please check,issue,positive,neutral,neutral,neutral,neutral,neutral
1523192526,"Hello team, nice registry for the tracking...",hello team nice registry,issue,negative,positive,positive,positive,positive,positive
1523184535,"@maciejskorski I filed #8331 to fix this issue. Would you mind testing this PR?

```
pip install git+https://github.com/mlflow/mlflow.git@refs/pull/8331/merge
```

To ensure a new session is created in each process, I added a dummy argument to `_get_request_session` for invalidating the cache.",fix issue would mind testing pip install ensure new session process added dummy argument cache,issue,negative,positive,positive,positive,positive,positive
1523114404,"Fantastic, it works - thanks a lot @harupy  ",fantastic work thanks lot,issue,positive,positive,positive,positive,positive,positive
1523098853,"@harupy Thanks for quick feedback!

Indeed this works when using `load_model`. But then another problem arises when I try to predict on the loaded model `loaded_pyfunc.predict(X.numpy())`, it throws an error `AttributeError: predict`

I suppose this is because the native onnx flavor does not have a predict method, but I need to load the onnx model in its `pyfunc `flavor to serve it to an endpoit.",thanks quick feedback indeed work another problem try predict loaded model error predict suppose native flavor predict method need load model flavor serve,issue,negative,positive,positive,positive,positive,positive
1523081080,This looks like a pyenv issue. Can you file an issue in https://github.com/pyenv/pyenv?,like issue file issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1523078971,"> Maybe reinstalling pyenv might help.

I have done it multiple times, also today. Every time I have started a new compute instance in a cloud (Lambda Cloud), and then reinstalled pyenv and mlflow.",maybe might help done multiple time also today every time new compute instance cloud lambda cloud,issue,negative,positive,neutral,neutral,positive,positive
1523078123,@benjaminbluhm Can you try replacing `_load_pyfunc` with `load_model`? This made the script run successfully on my side. ,try made script run successfully side,issue,negative,positive,positive,positive,positive,positive
1523073010,There is no six. I'm not sure why six is missing.,six sure six missing,issue,negative,positive,positive,positive,positive,positive
1523069930,"> What is the output of `ls /home/ubuntu/.pyenv/versions/3.10.7/share/python-wheels`?

That directory doesn't exist. This is the content of the parent directory
```
$ ls -laF /home/ubuntu/.pyenv/versions/3.10.7/share
total 12
drwxr-xr-x 3 ubuntu ubuntu 4096 Apr 26 05:01 ./
drwxr-xr-x 7 ubuntu ubuntu 4096 Apr 26 05:02 ../
drwxr-xr-x 3 ubuntu ubuntu 4096 Apr 26 05:01 man/
```",output directory exist content parent directory total,issue,negative,neutral,neutral,neutral,neutral,neutral
1523059244,"> What does your `_vendor/__init__.py` look like?

This is `pip/_vendor/__init__.py`
```
pip._vendor is for vendoring dependencies of pip to prevent needing pip to
depend on something external.

Files inside of pip._vendor should be considered immutable and should only be
updated to versions from upstream.
""""""
from __future__ import absolute_import

import glob
import os.path
import sys

# Downstream redistributors which have debundled our dependencies should also
# patch this value to be true. This will trigger the additional patching
# to cause things like ""six"" to be available as pip.
DEBUNDLED = True

# By default, look in this directory for a bunch of .whl files which we will
# add to the beginning of sys.path before attempting to import anything. This
# is done to support downstream re-distributors like Debian and Fedora who
# wish to create their own Wheels for our dependencies to aid in debundling.
prefix = getattr(sys, ""base_prefix"", sys.prefix)
if prefix.startswith('/usr/lib/pypy'):
    prefix = '/usr'
WHEEL_DIR = os.path.abspath(os.path.join(prefix, 'share', 'python-wheels'))


# Define a small helper function to alias our vendored modules to the real ones
# if the vendored ones do not exist. This idea of this was taken from
# https://github.com/kennethreitz/requests/pull/2567.
def vendored(modulename):
    vendored_name = ""{0}.{1}"".format(__name__, modulename)

    try:
        __import__(modulename, globals(), locals(), level=0)
    except ImportError as e:
        # We can just silently allow import failures to pass here. If we
        # got to this point it means that ``import pip._vendor.whatever``
        # failed and so did ``import whatever``. Since we're importing this
        # upfront in an attempt to alias imports, not erroring here will
        # just mean we get a regular import error whenever pip *actually*
        # tries to import one of these modules to use it, which actually
        # gives us a better error message than we would have otherwise
        # gotten.
        print(f""WHEEL_DIR is {print(os.environ.get('WHEEL_DIR', None))}"")
        print(e)
    else:
        sys.modules[vendored_name] = sys.modules[modulename]
        base, head = vendored_name.rsplit(""."", 1)
        setattr(sys.modules[base], head, sys.modules[modulename])


# If we're operating in a debundled setup, then we want to go ahead and trigger
# the aliasing of our vendored libraries as well as looking for wheels to add
# to our sys.path. This will cause all of this code to be a no-op typically
# however downstream redistributors can enable it in a consistent way across
# all platforms.
if DEBUNDLED:
    # Actually look inside of WHEEL_DIR to find .whl files and add them to the
    # front of our sys.path.
    sys.path[:] = glob.glob(os.path.join(WHEEL_DIR, ""*.whl"")) + sys.path

    # Actually alias all of our vendored dependencies.
    vendored(""appdirs"")
    vendored(""cachecontrol"")
    vendored(""colorama"")
    vendored(""contextlib2"")
    vendored(""distlib"")
    vendored(""distro"")
    vendored(""html5lib"")
    vendored(""six"")
    vendored(""six.moves"")
    vendored(""six.moves.urllib"")
    vendored(""six.moves.urllib.parse"")
    vendored(""packaging"")
    vendored(""packaging.version"")
    vendored(""packaging.specifiers"")
    vendored(""pep517"")
    vendored(""pkg_resources"")
    vendored(""progress"")
    vendored(""retrying"")
    vendored(""requests"")
    vendored(""requests.exceptions"")
    vendored(""requests.packages"")
    vendored(""requests.packages.urllib3"")
    vendored(""requests.packages.urllib3._collections"")
    vendored(""requests.packages.urllib3.connection"")
    vendored(""requests.packages.urllib3.connectionpool"")
    vendored(""requests.packages.urllib3.contrib"")
    vendored(""requests.packages.urllib3.contrib.ntlmpool"")
    vendored(""requests.packages.urllib3.contrib.pyopenssl"")
    vendored(""requests.packages.urllib3.exceptions"")
    vendored(""requests.packages.urllib3.fields"")
    vendored(""requests.packages.urllib3.filepost"")
    vendored(""requests.packages.urllib3.packages"")
    try:
        vendored(""requests.packages.urllib3.packages.ordered_dict"")
        vendored(""requests.packages.urllib3.packages.six"")
    except ImportError:
        # Debian already unbundles these from requests.
        pass
    vendored(""requests.packages.urllib3.packages.ssl_match_hostname"")
    vendored(""requests.packages.urllib3.packages.ssl_match_hostname.""
             ""_implementation"")
    vendored(""requests.packages.urllib3.poolmanager"")
    vendored(""requests.packages.urllib3.request"")
    vendored(""requests.packages.urllib3.response"")
    vendored(""requests.packages.urllib3.util"")
    vendored(""requests.packages.urllib3.util.connection"")
    vendored(""requests.packages.urllib3.util.request"")
    vendored(""requests.packages.urllib3.util.response"")
    vendored(""requests.packages.urllib3.util.retry"")
    vendored(""requests.packages.urllib3.util.ssl_"")
    vendored(""requests.packages.urllib3.util.timeout"")
    vendored(""requests.packages.urllib3.util.url"")
    vendored(""toml"")
    vendored(""toml.encoder"")
    vendored(""toml.decoder"")
    vendored(""urllib3"")
```",look like pip prevent needing pip depend something external inside considered immutable import import import import downstream also patch value true trigger additional cause like six available pip true default look directory bunch add beginning import anything done support downstream like wish create aid prefix prefix prefix define small helper function alias real exist idea taken try except silently allow import pas got point import import whatever since attempt alias mean get regular import error whenever pip actually import one use actually u better error message would otherwise gotten print print none print else base head base head operating setup want go ahead trigger well looking add cause code typically however downstream enable consistent way across actually look inside find add front actually alias six pep progress try except already pas,issue,positive,negative,neutral,neutral,negative,negative
1523044654,"> Can you print the value of `WHEEL_DIR`?

The env. variable `WHEEL_DIR` is not set, neither in the shell nor in `__init_.py` (I had it printed right after `print(e)`).
",print value variable set neither shell printed right print,issue,negative,positive,positive,positive,positive,positive
1523036613,"@harupy I will try to explain it from the perspectives of a user (data scientist) and the platform team (admin):

1. The ""Artifacts"" section appears to be malfunctioning to the UI user. In [Scenario 4](https://mlflow.org/docs/latest/tracking.html#scenario-4-mlflow-with-remote-tracking-server-backend-and-artifact-stores), the user will se a GIF spinning forever and no artifact.
2. The server logs will contain an error stack for each visit to the details page of a run (<mlflow-server-url>/experiments/0/runs/<run_id>). As a platform team we currently have to ignore these errors, with at potential risk of not detecting other more critical errors.",try explain user data scientist platform team section user scenario user se gif spinning forever artifact server contain error stack visit page run platform team currently ignore potential risk critical,issue,negative,neutral,neutral,neutral,neutral,neutral
1523033589,"> Can you modify `_vendor/__init__.py` to see why it failed to import six? You can insert `print` in the `vendored` function.

I have modified file `/home/ubuntu/my_virtualenv/lib/python3.10/site-packages/pip/_vendor/__init__.py` , this is the output
```
$ pip --version
No module named 'appdirs'
No module named 'cachecontrol'
No module named 'colorama'
No module named 'contextlib2'
No module named 'distlib'
No module named 'distro'
No module named 'html5lib'
No module named 'six'
No module named 'six'
No module named 'six'
No module named 'six'
No module named 'packaging'
No module named 'packaging'
No module named 'packaging'
No module named 'pep517'
No module named 'progress'
No module named 'retrying'
No module named 'requests'
No module named 'requests'
No module named 'requests'
No module named 'requests'
No module named 'requests'
No module named 'requests'
No module named 'requests'
No module named 'requests'
No module named 'requests'
No module named 'requests'
No module named 'requests'
No module named 'requests'
No module named 'requests'
No module named 'requests'
No module named 'requests'
No module named 'requests'
No module named 'requests'
No module named 'requests'
No module named 'requests'
No module named 'requests'
No module named 'requests'
No module named 'requests'
No module named 'requests'
No module named 'requests'
No module named 'requests'
No module named 'requests'
No module named 'requests'
No module named 'requests'
No module named 'requests'
No module named 'toml'
No module named 'toml'
No module named 'toml'
No module named 'urllib3'
Traceback (most recent call last):
  File ""/home/ubuntu/my_virtualenv/bin/pip"", line 5, in <module>
    from pip._internal.cli.main import main
  File ""/home/ubuntu/my_virtualenv/lib/python3.10/site-packages/pip/_internal/cli/main.py"", line 10, in <module>
    from pip._internal.cli.autocompletion import autocomplete
  File ""/home/ubuntu/my_virtualenv/lib/python3.10/site-packages/pip/_internal/cli/autocompletion.py"", line 9, in <module>
    from pip._internal.cli.main_parser import create_main_parser
  File ""/home/ubuntu/my_virtualenv/lib/python3.10/site-packages/pip/_internal/cli/main_parser.py"", line 7, in <module>
    from pip._internal.cli import cmdoptions
  File ""/home/ubuntu/my_virtualenv/lib/python3.10/site-packages/pip/_internal/cli/cmdoptions.py"", line 24, in <module>
    from pip._internal.exceptions import CommandError
  File ""/home/ubuntu/my_virtualenv/lib/python3.10/site-packages/pip/_internal/exceptions.py"", line 10, in <module>
    from pip._vendor.six import iteritems
ModuleNotFoundError: No module named 'pip._vendor.six'
$
```",modify see import six insert print function file output pip version module module module module module module module module module module module module module module module module module module module module module module module module module module module module module module module module module module module module module module module module module module module module module module module module module module recent call last file line module import main file line module import file line module import file line module import file line module import file line module import module,issue,negative,positive,neutral,neutral,positive,positive
1523015247,"Can you modify `_vendor/__init__.py` to see why it failed to import six? You can insert `print` in the `vendored` function.

```python
def vendored(modulename):
    vendored_name = ""{0}.{1}"".format(__name__, modulename)

    try:
        __import__(modulename, globals(), locals(), level=0)
    except ImportError as e:
        # We can just silently allow import failures to pass here. If we
        # got to this point it means that ``import pip._vendor.whatever``
        # failed and so did ``import whatever``. Since we're importing this
        # upfront in an attempt to alias imports, not erroring here will
        # just mean we get a regular import error whenever pip *actually*
        # tries to import one of these modules to use it, which actually
        # gives us a better error message than we would have otherwise
        # gotten.
        print(e)
    else:
        sys.modules[vendored_name] = sys.modules[modulename]
        base, head = vendored_name.rsplit(""."", 1)
        setattr(sys.modules[base], head, sys.modules[modulename])
```",modify see import six insert print function python try except silently allow import pas got point import import whatever since attempt alias mean get regular import error whenever pip actually import one use actually u better error message would otherwise gotten print else base head base head,issue,negative,negative,negative,negative,negative,negative
1523011354,"> /usr/share/python-wheels

Yes
```
$ ll /usr/share/python-wheels
total 2260
drwxr-xr-x   2 root root  12288 Apr 26 04:47 ./
drwxr-xr-x 177 root root   4096 Apr 26 04:50 ../
-rw-r--r--   1 root root  28023 Feb 28 09:41 CacheControl-0.12.6-py2.py3-none-any.whl
-rw-r--r--   1 root root  18776 Feb 28 09:41 appdirs-1.4.3-py2.py3-none-any.whl
-rw-r--r--   1 root root 164552 Feb 28 09:41 certifi-2019.11.28-py2.py3-none-any.whl
-rw-r--r--   1 root root 141487 Feb 28 09:41 chardet-3.0.4-py2.py3-none-any.whl
-rw-r--r--   1 root root  25094 Feb 28 09:41 colorama-0.4.3-py2.py3-none-any.whl
-rw-r--r--   1 root root  17188 Feb 28 09:41 contextlib2-0.6.0-py2.py3-none-any.whl
-rw-r--r--   1 root root 152027 Feb 28 09:41 distlib-0.3.0-py2.py3-none-any.whl
-rw-r--r--   1 root root  23898 Feb 28 09:41 distro-1.4.0-py2.py3-none-any.whl
-rw-r--r--   1 root root 120020 Feb 28 09:41 html5lib-1.0.1-py2.py3-none-any.whl
-rw-r--r--   1 root root  66836 Feb 28 09:41 idna-2.8-py2.py3-none-any.whl
-rw-r--r--   1 root root  24287 Feb 28 09:41 ipaddr-2.2.0-py2.py3-none-any.whl
-rw-r--r--   1 root root  21972 Feb 28 09:41 lockfile-0.12.2-py2.py3-none-any.whl
-rw-r--r--   1 root root  92927 Feb 28 09:41 msgpack-0.6.2-py2.py3-none-any.whl
-rw-r--r--   1 root root  42242 Feb 28 09:41 packaging-20.3-py2.py3-none-any.whl
-rw-r--r--   1 root root  26686 Feb 28 09:41 pep517-0.8.2-py2.py3-none-any.whl
-rw-r--r--   1 root root 262440 Feb 28 09:41 pip-20.0.2-py2.py3-none-any.whl
-rw-r--r--   1 root root 127312 Feb 28 09:41 pkg_resources-0.0.0-py2.py3-none-any.whl
-rw-r--r--   1 root root  17547 Feb 28 09:41 progress-1.5-py2.py3-none-any.whl
-rw-r--r--   1 root root  77093 Feb 28 09:41 pyparsing-2.4.6-py2.py3-none-any.whl
-rw-r--r--   1 root root  67470 Feb 28 09:41 requests-2.22.0-py2.py3-none-any.whl
-rw-r--r--   1 root root  16358 Feb 28 09:41 retrying-1.3.3-py2.py3-none-any.whl
-rw-r--r--   1 root root 477455 Feb 28 09:41 setuptools-44.0.0-py2.py3-none-any.whl
-rw-r--r--   1 root root  20256 Feb 28 09:41 six-1.14.0-py2.py3-none-any.whl
-rw-r--r--   1 root root  24106 Feb 28 09:41 toml-0.10.0-py2.py3-none-any.whl
-rw-r--r--   1 root root 127068 Feb 28 09:41 urllib3-1.25.8-py2.py3-none-any.whl
-rw-r--r--   1 root root  20484 Feb 28 09:41 webencodings-0.5.1-py2.py3-none-any.whl
-rw-r--r--   1 root root  35613 Feb 28 09:41 wheel-0.34.2-py2.py3-none-any.whl
```",yes total root root root root root root root root root root root root root root root root root root root root root root root root root root root root root root root root root root root root root root root root root root root root root root root root root root root root root root root root root root,issue,negative,neutral,neutral,neutral,neutral,neutral
1522970061,"> Can you run `python -c 'import six'`?

From within the virtualenv I have just created, I cannot import `six`:
```
$ python -c 'import six'
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
ModuleNotFoundError: No module named 'six'
$ 
```
",run python six within import six python recent call last file string line module module,issue,negative,neutral,neutral,neutral,neutral,neutral
1522963143,"> 

Yes.
```
$ virtualenv --version
virtualenv 20.0.17 from /usr/lib/python3/dist-packages/virtualenv/__init__.py
$ virtualenv --python /home/ubuntu/.pyenv/versions/3.10.7/bin/python /home/ubuntu/my_virtualenv
created virtual environment CPython3.10.7.final.0-64 in 89ms
  creator CPython3Posix(dest=/home/ubuntu/my_virtualenv, clear=False, global=False)
  seeder FromAppData(download=False, pip=latest, setuptools=latest, wheel=latest, pkg_resources=latest, via=copy, app_data_dir=/home/ubuntu/.local/share/virtualenv/seed-app-data/v1.0.1.debian.1)
  activators BashActivator,CShellActivator,FishActivator,PowerShellActivator,PythonActivator,XonshActivator
$ source /home/ubuntu/my_virtualenv/bin/activate
$ pip --version
Traceback (most recent call last):
  File ""/home/ubuntu/my_virtualenv/bin/pip"", line 5, in <module>
    from pip._internal.cli.main import main
  File ""/home/ubuntu/my_virtualenv/lib/python3.10/site-packages/pip/_internal/cli/main.py"", line 10, in <module>
    from pip._internal.cli.autocompletion import autocomplete
  File ""/home/ubuntu/my_virtualenv/lib/python3.10/site-packages/pip/_internal/cli/autocompletion.py"", line 9, in <module>
    from pip._internal.cli.main_parser import create_main_parser
  File ""/home/ubuntu/my_virtualenv/lib/python3.10/site-packages/pip/_internal/cli/main_parser.py"", line 7, in <module>
    from pip._internal.cli import cmdoptions
  File ""/home/ubuntu/my_virtualenv/lib/python3.10/site-packages/pip/_internal/cli/cmdoptions.py"", line 24, in <module>
    from pip._internal.exceptions import CommandError
  File ""/home/ubuntu/my_virtualenv/lib/python3.10/site-packages/pip/_internal/exceptions.py"", line 10, in <module>
    from pip._vendor.six import iteritems
ModuleNotFoundError: No module named 'pip._vendor.six'
$ 
```
",yes version python virtual environment creator seeder source pip version recent call last file line module import main file line module import file line module import file line module import file line module import file line module import module,issue,negative,positive,neutral,neutral,positive,positive
1522893764,@dmatrix is there any update on this. I need this feature in my use-case and I am happy to contribute as well if possible.,update need feature happy contribute well possible,issue,positive,positive,positive,positive,positive,positive
1522886568,@fantauzzi Can you reproduce the error by directly running `virtualenv` to create an environment and running `pip install` in it?,reproduce error directly running create environment running pip install,issue,negative,positive,neutral,neutral,positive,positive
1522839555,"> /home/ubuntu/.local/share/virtualenv

I was typing in this issue at the same time as you and noticed later you had updated it. So now I have removed that directory, removed `/home/ubuntu/.mlflow/envs/mlflow*`, run `mlflow run .` again, and got the usual error. Also, `mlflow run .` has recreated the directory I had just removed, with this content:
```
$ ll /home/ubuntu/.local/share/virtualenv
total 16
drwxrwxr-x 4 ubuntu ubuntu 4096 Apr 26 06:05 ./
drwxrwxr-x 7 ubuntu ubuntu 4096 Apr 26 06:05 ../
drwxrwxr-x 3 ubuntu ubuntu 4096 Apr 26 06:05 py_info/
drwxrwxr-x 3 ubuntu ubuntu 4096 Apr 26 06:05 seed-app-data/
```",issue time later removed directory removed run run got usual error also run directory removed content total,issue,negative,negative,neutral,neutral,negative,negative
1522823766,"Because I reproduce the error in a cloud setup with Ubuntu 20.04, but don't reproduce it on my PC with Ubuntu 22.04, I have compared the output of `mlflow run .` between the two, and spotted an interesting difference. I copy and paste here the relevant output and then outline the difference.

Here on the setup that reproduces the error:
```
$ mlflow run .
2023/04/26 05:07:31 INFO mlflow.utils.virtualenv: Installing python 3.8.16 if it does not exist
Downloading Python-3.8.16.tar.xz...
-> https://www.python.org/ftp/python/3.8.16/Python-3.8.16.tar.xz
Installing Python-3.8.16...
Installed Python-3.8.16 to /home/ubuntu/.pyenv/versions/3.8.16
2023/04/26 05:08:12 INFO mlflow.utils.virtualenv: Creating a new environment in /home/ubuntu/.mlflow/envs/mlflow-dc1faba5c996e345dd1cc40210944f3b69389fb6 with /home/ubuntu/.pyenv/versions/3.8.16/bin/python
created virtual environment CPython3.8.16.final.0-64 in 213ms
  creator CPython3Posix(dest=/home/ubuntu/.mlflow/envs/mlflow-dc1faba5c996e345dd1cc40210944f3b69389fb6, clear=False, global=False)
  seeder FromAppData(download=False, pip=latest, setuptools=latest, wheel=latest, pkg_resources=latest, via=copy, app_data_dir=/home/ubuntu/.local/share/virtualenv/seed-app-data/v1.0.1.debian.1)
  activators BashActivator,CShellActivator,FishActivator,PowerShellActivator,PythonActivator,XonshActivator
2023/04/26 05:08:13 INFO mlflow.utils.virtualenv: Installing dependencies
Traceback (most recent call last):
[...]
```

Here on the setup that doesn't reproduce the error, and the example code completes correctly
```
-> https://www.python.org/ftp/python/3.8.16/Python-3.8.16.tar.xz
Installing Python-3.8.16...
Installed Python-3.8.16 to /home/fanta/.pyenv/versions/3.8.16
2023/04/26 07:29:26 INFO mlflow.utils.virtualenv: Creating a new environment in /home/fanta/.mlflow/envs/mlflow-dc1faba5c996e345dd1cc40210944f3b69389fb6 with /home/fanta/.pyenv/versions/3.8.16/bin/python
created virtual environment CPython3.8.16.final.0-64 in 189ms
  creator CPython3Posix(dest=/home/fanta/.mlflow/envs/mlflow-dc1faba5c996e345dd1cc40210944f3b69389fb6, clear=False, no_vcs_ignore=False, global=False)
  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/home/fanta/.local/share/virtualenv)
    added seed packages: pip==22.3.1, setuptools==65.6.3, wheel==0.38.4
  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator
2023/04/26 07:29:26 INFO mlflow.utils.virtualenv: Installing dependencies
[...]
```
I believe the relevant difference is in the `seeder FromAppData(` part, which in the working setup contains `pip=bundle, setuptools=bundle, wheel=bundle` while in the faulty setup contains `pip=latest, setuptools=latest, wheel=latest`

MLFlow seems to be using a bundled pip on one system, and a different (non bundled) pip on another system.",reproduce error cloud setup reproduce output run two spotted interesting difference copy paste relevant output outline difference setup error run python exist new environment virtual environment creator seeder recent call last setup reproduce error example code correctly new environment virtual environment creator seeder added seed believe relevant difference seeder part working setup faulty setup pip one system different non pip another system,issue,negative,positive,positive,positive,positive,positive
1522817053,"@fantauzzi I ran `mlflow run .` and got the following:

```
> mlflow run .
2023/04/26 14:39:36 INFO mlflow.utils.virtualenv: Installing python 3.8.16 if it does not exist
2023/04/26 14:39:36 INFO mlflow.utils.virtualenv: Creating a new environment in /home/haru/.mlflow/envs/mlflow-0c30c75c1190ace1070fa325506dbb84f690a784 with /home/haru/.pyenv/versions/3.8.16/bin/python
created virtual environment CPython3.8.16.final.0-64 in 205ms
  creator CPython3Posix(dest=/home/haru/.mlflow/envs/mlflow-0c30c75c1190ace1070fa325506dbb84f690a784, clear=False, no_vcs_ignore=False, global=False)
  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/home/haru/.local/share/virtualenv)
  ^ 👆 is different
    added seed packages: pip==23.0.1, setuptools==67.6.1, wheel==0.40.0
```

",ran run got following run python exist new environment virtual environment creator seeder different added seed,issue,negative,positive,neutral,neutral,positive,positive
1522800503,"> @fantauzzi Feel free to open this issue if re-creating the virtual vironment with the bundled pip doesn't work.

I don't think I am allowed, as a collaborator closed it.",feel free open issue virtual pip work think collaborator closed,issue,positive,positive,positive,positive,positive,positive
1522796877,"> @fantauzzi Can you remove `home/ubuntu/.mlflow/envs/mlflow-dc1faba5c996e345dd1cc40210944f3b69389fb6` and run `mlflow run .` again?
> 
> > The system-wide pip in /usr/local/bin/pip didn't seem to be bundled with a six module
> 
> Maybe virtualenv picked up this unbundled pip and hit the error?

After removing that and running `mlflow run .` again, I get the same error again. In fact, to reproduce the error, I must remove the half-backed virtualenv from `home/ubuntu/.mlflow/envs` before running `mlflow run .` again.

If instead I run `mlflow run .` again with the half-backed virtualenv still there, mlflow tries to use it and fails with a different error message (`ModuleNotFoundError: No module named 'pmdarima'`). Here an example, scroll down to see the second attempt to run `mlflow run .`:
```
(python3.10.7) ubuntu@192-9-242-164:~/mlflow/examples/diviner$ mlflow run .
2023/04/26 05:07:31 INFO mlflow.utils.virtualenv: Installing python 3.8.16 if it does not exist
Downloading Python-3.8.16.tar.xz...
-> https://www.python.org/ftp/python/3.8.16/Python-3.8.16.tar.xz
Installing Python-3.8.16...
Installed Python-3.8.16 to /home/ubuntu/.pyenv/versions/3.8.16
2023/04/26 05:08:12 INFO mlflow.utils.virtualenv: Creating a new environment in /home/ubuntu/.mlflow/envs/mlflow-dc1faba5c996e345dd1cc40210944f3b69389fb6 with /home/ubuntu/.pyenv/versions/3.8.16/bin/python
created virtual environment CPython3.8.16.final.0-64 in 213ms
  creator CPython3Posix(dest=/home/ubuntu/.mlflow/envs/mlflow-dc1faba5c996e345dd1cc40210944f3b69389fb6, clear=False, global=False)
  seeder FromAppData(download=False, pip=latest, setuptools=latest, wheel=latest, pkg_resources=latest, via=copy, app_data_dir=/home/ubuntu/.local/share/virtualenv/seed-app-data/v1.0.1.debian.1)
  activators BashActivator,CShellActivator,FishActivator,PowerShellActivator,PythonActivator,XonshActivator
2023/04/26 05:08:13 INFO mlflow.utils.virtualenv: Installing dependencies
Traceback (most recent call last):
  File ""/home/ubuntu/.pyenv/versions/3.8.16/lib/python3.8/runpy.py"", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File ""/home/ubuntu/.pyenv/versions/3.8.16/lib/python3.8/runpy.py"", line 87, in _run_code
    exec(code, run_globals)
  File ""/home/ubuntu/.mlflow/envs/mlflow-dc1faba5c996e345dd1cc40210944f3b69389fb6/lib/python3.8/site-packages/pip/__main__.py"", line 16, in <module>
    from pip._internal.cli.main import main as _main  # isort:skip # noqa
  File ""/home/ubuntu/.mlflow/envs/mlflow-dc1faba5c996e345dd1cc40210944f3b69389fb6/lib/python3.8/site-packages/pip/_internal/cli/main.py"", line 10, in <module>
    from pip._internal.cli.autocompletion import autocomplete
  File ""/home/ubuntu/.mlflow/envs/mlflow-dc1faba5c996e345dd1cc40210944f3b69389fb6/lib/python3.8/site-packages/pip/_internal/cli/autocompletion.py"", line 9, in <module>
    from pip._internal.cli.main_parser import create_main_parser
  File ""/home/ubuntu/.mlflow/envs/mlflow-dc1faba5c996e345dd1cc40210944f3b69389fb6/lib/python3.8/site-packages/pip/_internal/cli/main_parser.py"", line 7, in <module>
    from pip._internal.cli import cmdoptions
  File ""/home/ubuntu/.mlflow/envs/mlflow-dc1faba5c996e345dd1cc40210944f3b69389fb6/lib/python3.8/site-packages/pip/_internal/cli/cmdoptions.py"", line 24, in <module>
    from pip._internal.exceptions import CommandError
  File ""/home/ubuntu/.mlflow/envs/mlflow-dc1faba5c996e345dd1cc40210944f3b69389fb6/lib/python3.8/site-packages/pip/_internal/exceptions.py"", line 10, in <module>
    from pip._vendor.six import iteritems
ModuleNotFoundError: No module named 'pip._vendor.six'
Traceback (most recent call last):
  File ""/home/ubuntu/.pyenv/versions/python3.10.7/bin/mlflow"", line 8, in <module>
    sys.exit(cli())
  File ""/home/ubuntu/.pyenv/versions/3.10.7/envs/python3.10.7/lib/python3.10/site-packages/click/core.py"", line 1130, in __call__
    return self.main(*args, **kwargs)
  File ""/home/ubuntu/.pyenv/versions/3.10.7/envs/python3.10.7/lib/python3.10/site-packages/click/core.py"", line 1055, in main
    rv = self.invoke(ctx)
  File ""/home/ubuntu/.pyenv/versions/3.10.7/envs/python3.10.7/lib/python3.10/site-packages/click/core.py"", line 1657, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File ""/home/ubuntu/.pyenv/versions/3.10.7/envs/python3.10.7/lib/python3.10/site-packages/click/core.py"", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File ""/home/ubuntu/.pyenv/versions/3.10.7/envs/python3.10.7/lib/python3.10/site-packages/click/core.py"", line 760, in invoke
    return __callback(*args, **kwargs)
  File ""/home/ubuntu/.pyenv/versions/3.10.7/envs/python3.10.7/lib/python3.10/site-packages/mlflow/cli.py"", line 202, in run
    projects.run(
  File ""/home/ubuntu/.pyenv/versions/3.10.7/envs/python3.10.7/lib/python3.10/site-packages/mlflow/projects/__init__.py"", line 338, in run
    submitted_run_obj = _run(
  File ""/home/ubuntu/.pyenv/versions/3.10.7/envs/python3.10.7/lib/python3.10/site-packages/mlflow/projects/__init__.py"", line 105, in _run
    submitted_run = backend.run(
  File ""/home/ubuntu/.pyenv/versions/3.10.7/envs/python3.10.7/lib/python3.10/site-packages/mlflow/projects/backend/local.py"", line 167, in run
    activate_cmd = _create_virtualenv(
  File ""/home/ubuntu/.pyenv/versions/3.10.7/envs/python3.10.7/lib/python3.10/site-packages/mlflow/utils/virtualenv.py"", line 269, in _create_virtualenv
    _exec_cmd(cmd, capture_output=capture_output, cwd=tmp_model_dir, extra_env=extra_env)
  File ""/home/ubuntu/.pyenv/versions/3.10.7/envs/python3.10.7/lib/python3.10/site-packages/mlflow/utils/process.py"", line 117, in _exec_cmd
    raise ShellCommandException.from_completed_process(comp_process)
mlflow.utils.process.ShellCommandException: Non-zero exit code: 1
Command: ['bash', '-c', 'source /home/ubuntu/.mlflow/envs/mlflow-dc1faba5c996e345dd1cc40210944f3b69389fb6/bin/activate && python -m pip install --quiet -r requirements.1ff80735675c49ec986a3849caf7600f.txt']
(python3.10.7) ubuntu@192-9-242-164:~/mlflow/examples/diviner$ mlflow run .
2023/04/26 05:09:52 INFO mlflow.utils.virtualenv: Installing python 3.8.16 if it does not exist
2023/04/26 05:09:52 INFO mlflow.utils.virtualenv: Environment /home/ubuntu/.mlflow/envs/mlflow-dc1faba5c996e345dd1cc40210944f3b69389fb6 already exists
2023/04/26 05:09:52 INFO mlflow.projects.utils: === Created directory /tmp/tmpg3aq2q9y for downloading remote URIs passed to arguments of type 'path' ===
2023/04/26 05:09:52 INFO mlflow.projects.backend.local: === Running command 'source /home/ubuntu/.mlflow/envs/mlflow-dc1faba5c996e345dd1cc40210944f3b69389fb6/bin/activate && python train.py' in run with ID '17ad76248b7b4f699d2b67762e9c1cb1' === 
Traceback (most recent call last):
  File ""train.py"", line 2, in <module>
    from pmdarima import datasets
ModuleNotFoundError: No module named 'pmdarima'
2023/04/26 05:09:52 ERROR mlflow.cli: === Run (ID '17ad76248b7b4f699d2b67762e9c1cb1') failed ===
(python3.10.7) ubuntu@192-9-242-164:~/mlflow/examples/diviner$ 
```



",remove run run pip seem six module maybe picked unbundled pip hit error removing running run get error fact reproduce error must remove running run instead run run still use different error message module example scroll see second attempt run run python run python exist new environment virtual environment creator seeder recent call last file line return code none file line code file line module import main skip file line module import file line module import file line module import file line module import file line module import module recent call last file line module file line return file line main file line invoke return file line invoke return file line invoke return file line run file line run file line file line run file line file line raise exit code command python pip install quiet python run python exist environment already directory remote type running command python run id recent call last file line module import module error run id python,issue,negative,positive,neutral,neutral,positive,positive
1522769736,"> This is really neat! One thing I'm curious about is why this approach is better than a function like `dataset.get_source()`, which we can define on `DatasetInput`, `DatasetEntity`, and `Dataset`. I feel that experience may be more natural.

As discussed offline, I think there might be a bit of ambiguity around `dataset.source` (string) vs `dataset.get_source()` (DatasetSource). For now, are you okay with introducing `mlflow.data.get_source()` as `experimental` (I added the annotation), and we can follow up later with a different experience if needed?",really neat one thing curious approach better function like define feel experience may natural think might bit ambiguity around string experimental added annotation follow later different experience,issue,positive,positive,positive,positive,positive,positive
1522632679,@chris-ds-dk Could you tell us why you want to hide artifacts on MLflow UI?,could tell u want hide,issue,negative,neutral,neutral,neutral,neutral,neutral
1522631455,@fantauzzi Feel free to open this issue if re-creating the virtual vironment with the bundled pip doesn't work.,feel free open issue virtual pip work,issue,positive,positive,positive,positive,positive,positive
1522630732,"@maciejskorski 

> one thing that still puzzles me is that the issue seems to occur somewhat randomly

We observed the same. It was flaky :)",one thing still issue occur somewhat randomly flaky,issue,negative,negative,negative,negative,negative,negative
1522626904,"@stephanrb3 Thanks for reporting this issue. I wasn't able to reproduce  it:

https://user-images.githubusercontent.com/17039389/234437584-1c778141-48e4-4c37-a5b1-a2219cd72728.mov

I don't think this is an MLflow's issue, but an issue in your K8s cluster. Not sure why navigating to the compare page triggers the issue though.
",thanks issue able reproduce think issue issue cluster sure compare page issue though,issue,positive,positive,positive,positive,positive,positive
1522609859,"As many here have suggested, having relative paths enables us to access artifacts locally on different machine environments, e.g., dev and training. This is also important when writing integration tests for applications that require access to the local artifacts. Big thanks to the MLFlow team for the great work! ",many relative u access locally different machine dev training also important writing integration require access local big thanks team great work,issue,positive,positive,positive,positive,positive,positive
1522597890,"btw the `autoformat` label does nothing :) No idea who created it, but `@mlflow-automation autoformat` is the only way trigger auto formatting.",label nothing idea way trigger auto,issue,negative,neutral,neutral,neutral,neutral,neutral
1522002624,@foster sorry for the delay! Thank you for the reminder :) ,foster sorry delay thank reminder,issue,negative,negative,negative,negative,negative,negative
1521813447,"Hey @BenWilson2, gentle bump on this. Thanks!",hey gentle bump thanks,issue,positive,positive,positive,positive,positive,positive
1521165451,"@harupy many thanks for root-causing it! Indeed, without multiprocessing, my use-case is stable. yet, one thing that still puzzles me is that the issue seems to occur somewhat randomly",many thanks indeed without stable yet one thing still issue occur somewhat randomly,issue,negative,positive,neutral,neutral,positive,positive
1521037093,"@r-remus I don't think this is an MLflow's issue, but a PyCharm's issue. A similar issue is reported in https://youtrack.jetbrains.com/issue/PY-4213 (which implies a call to certain functions can break the debugger in PyCharm)

I don't use PyCharm but is it possible to debug the debugger? That might help identify what breaks the debugger

---

I tested the attached code on VSCode and the breakpoint works fine.",think issue issue similar issue call certain break use possible might help identify tested attached code work fine,issue,positive,positive,positive,positive,positive,positive
1521028182,"@fantauzzi Can you remove `home/ubuntu/.mlflow/envs/mlflow-dc1faba5c996e345dd1cc40210944f3b69389fb6` and run `mlflow run .` again?


> The system-wide pip in /usr/local/bin/pip didn't seem to be bundled with a six module

Maybe virtualenv picked up this unbundled pip and hit the error?",remove run run pip seem six module maybe picked unbundled pip hit error,issue,negative,neutral,neutral,neutral,neutral,neutral
1521015973,"@Ewande Thanks for the PR!

> I see this is probably already being covered by https://github.com/mlflow/mlflow/pull/8311 but please confirm.

Correc,t #8311 will fix this issue :)

",thanks see probably already covered please confirm fix issue,issue,positive,positive,positive,positive,positive,positive
1520992442,"Hi @SaravananSathyanandhaQC , thank you for filing this feature request and the companion pull request. If possible, can you provide a little more context for the use case? In particular, I'm wondering what the use case is for reading the run count within a certain SLA.

Finally, are you running MLflow on Databricks, or are you hosting your own MLflow tracking server and database? (This may also help us align on a solution).",hi thank filing feature request companion pull request possible provide little context use case particular wondering use case reading run count within certain sla finally running hosting server may also help u align solution,issue,positive,positive,neutral,neutral,positive,positive
1520990758,I see this is probably already being covered by https://github.com/mlflow/mlflow/pull/8311 but please confirm.,see probably already covered please confirm,issue,negative,neutral,neutral,neutral,neutral,neutral
1520779296,Thanks @prithvikannan . Test failures are all from the current `datasets` branch head. They will be fixed by https://github.com/mlflow/mlflow/pull/8300. Merging :),thanks test current branch head fixed,issue,negative,positive,positive,positive,positive,positive
1520646001,"@BenWilson2 

I tried using my credentials with boto3 to upload a file to minio which worked fine (this means that the tokens are correct). I am not sure how to upload a file via boto3 externally to mlflow. Could you please tell me how to do so?

Here is the code I use to upload a file using boto3 to minio:
```python
 s3 = boto3.resource(
    's3',
    endpoint_url='http://localhost:9000',
    aws_access_key_id='adminuser',
    aws_secret_access_key='adminuser',
    aws_session_token=None,
    config=boto3.session.Config(signature_version='s3v4'),
    verify=False
 )
 
 for bucket in s3.buckets.all():
    print(bucket.name)
 
 s3.Bucket('bucket').upload_file(Filename='test.txt', Key='test.txt')
```",tried file worked fine correct sure file via externally could please tell code use file python bucket print,issue,positive,positive,positive,positive,positive,positive
1520450517,"@harupy thanks for your support on this PR! I'm nearly there, 1 question and 2 comments:

1. For the Python `search_runs` I have `run_info_only` after the `pageToken` just to support backwards compatibility of positional arguments. But it looks a bit odd not to have `pageToken` be the last argument. Not sure which wins in importance? I (accidentally) made the Java do things more naturally with `runInfoOnly` first, but based on this answer can adjust Java to be consistent.

2. Just fighting setting up my R environment locally, so that's a todo still to test properly.

3. Fixed the Python/Java tests from the last run.",thanks support nearly question python support backwards compatibility positional bit odd last argument sure importance accidentally made naturally first based answer adjust consistent fighting setting environment locally still test properly fixed last run,issue,positive,positive,positive,positive,positive,positive
1520229753,"I have been working on the hypothesis that the `pip` module used by `mlflow run .` doesn't come bundled with a `six` module. That is the root cause of the `No module named 'pip._vendor.six` error also in the StackOverflow posts you linked.

So far I am not able to tell which `pip` module `mlflow run .` uses to make its own virtualenv.

The `pip` I have under `~/.local` seems to be bundled with a `six` module, as its `_vendor` contains a `six.py`
The system-wide `pip` in `/usr/local/bin/pip` didn't seem to be bundled with a `six` module, as its `_vendor` was almost empty and with no `six.py`, so I have re-installed it, and now it does have a populated `_vendor` also with a `six.py`.

The error with `mlflow run .` persists.",working hypothesis pip module used run come six module root cause module error also linked far able tell pip module run make pip six module pip seem six module almost empty also error run,issue,negative,positive,positive,positive,positive,positive
1520207666,"> Can you run:
> 
> ```
> home/ubuntu/.mlflow/envs/mlflow-dc1faba5c996e345dd1cc40210944f3b69389fb6/lib/python3.8/site-packages/pip/_vendor/__init__.py
> ```
> 
> and check the contents of `__init__.py`?

I have run `__init__.py` in `_vendor` and got no output
```
$ python __init__.py 
$ 
```
This is the content of the file now:
```
""""""
pip._vendor is for vendoring dependencies of pip to prevent needing pip to
depend on something external.

Files inside of pip._vendor should be considered immutable and should only be
updated to versions from upstream.
""""""
from __future__ import absolute_import

import glob
import os.path
import sys

# Downstream redistributors which have debundled our dependencies should also
# patch this value to be true. This will trigger the additional patching
# to cause things like ""six"" to be available as pip.
DEBUNDLED = True

# By default, look in this directory for a bunch of .whl files which we will
# add to the beginning of sys.path before attempting to import anything. This
# is done to support downstream re-distributors like Debian and Fedora who
# wish to create their own Wheels for our dependencies to aid in debundling.
prefix = getattr(sys, ""base_prefix"", sys.prefix)
if prefix.startswith('/usr/lib/pypy'):
    prefix = '/usr'
WHEEL_DIR = os.path.abspath(os.path.join(prefix, 'share', 'python-wheels'))


# Define a small helper function to alias our vendored modules to the real ones
# if the vendored ones do not exist. This idea of this was taken from
# https://github.com/kennethreitz/requests/pull/2567.
def vendored(modulename):
    vendored_name = ""{0}.{1}"".format(__name__, modulename)

    try:
        __import__(modulename, globals(), locals(), level=0)
    except ImportError:
        # We can just silently allow import failures to pass here. If we
        # got to this point it means that ``import pip._vendor.whatever``
        # failed and so did ``import whatever``. Since we're importing this
        # upfront in an attempt to alias imports, not erroring here will
        # just mean we get a regular import error whenever pip *actually*
        # tries to import one of these modules to use it, which actually
        # gives us a better error message than we would have otherwise
        # gotten.
        pass
    else:
        sys.modules[vendored_name] = sys.modules[modulename]
        base, head = vendored_name.rsplit(""."", 1)
        setattr(sys.modules[base], head, sys.modules[modulename])


# If we're operating in a debundled setup, then we want to go ahead and trigger
# the aliasing of our vendored libraries as well as looking for wheels to add
# to our sys.path. This will cause all of this code to be a no-op typically
# however downstream redistributors can enable it in a consistent way across
# all platforms.
if DEBUNDLED:
    # Actually look inside of WHEEL_DIR to find .whl files and add them to the
    # front of our sys.path.
    sys.path[:] = glob.glob(os.path.join(WHEEL_DIR, ""*.whl"")) + sys.path

    # Actually alias all of our vendored dependencies.
    vendored(""appdirs"")
    vendored(""cachecontrol"")
    vendored(""colorama"")
    vendored(""contextlib2"")
    vendored(""distlib"")
    vendored(""distro"")
    vendored(""html5lib"")
    vendored(""six"")
    vendored(""six.moves"")
    vendored(""six.moves.urllib"")
    vendored(""six.moves.urllib.parse"")
    vendored(""packaging"")
    vendored(""packaging.version"")
    vendored(""packaging.specifiers"")
    vendored(""pep517"")
    vendored(""pkg_resources"")
    vendored(""progress"")
    vendored(""retrying"")
    vendored(""requests"")
    vendored(""requests.exceptions"")
    vendored(""requests.packages"")
    vendored(""requests.packages.urllib3"")
    vendored(""requests.packages.urllib3._collections"")
    vendored(""requests.packages.urllib3.connection"")
    vendored(""requests.packages.urllib3.connectionpool"")
    vendored(""requests.packages.urllib3.contrib"")
    vendored(""requests.packages.urllib3.contrib.ntlmpool"")
    vendored(""requests.packages.urllib3.contrib.pyopenssl"")
    vendored(""requests.packages.urllib3.exceptions"")
    vendored(""requests.packages.urllib3.fields"")
    vendored(""requests.packages.urllib3.filepost"")
    vendored(""requests.packages.urllib3.packages"")
    try:
        vendored(""requests.packages.urllib3.packages.ordered_dict"")
        vendored(""requests.packages.urllib3.packages.six"")
    except ImportError:
        # Debian already unbundles these from requests.
        pass
    vendored(""requests.packages.urllib3.packages.ssl_match_hostname"")
    vendored(""requests.packages.urllib3.packages.ssl_match_hostname.""
             ""_implementation"")
    vendored(""requests.packages.urllib3.poolmanager"")
    vendored(""requests.packages.urllib3.request"")
    vendored(""requests.packages.urllib3.response"")
    vendored(""requests.packages.urllib3.util"")
    vendored(""requests.packages.urllib3.util.connection"")
    vendored(""requests.packages.urllib3.util.request"")
    vendored(""requests.packages.urllib3.util.response"")
    vendored(""requests.packages.urllib3.util.retry"")
    vendored(""requests.packages.urllib3.util.ssl_"")
    vendored(""requests.packages.urllib3.util.timeout"")
    vendored(""requests.packages.urllib3.util.url"")
    vendored(""toml"")
    vendored(""toml.encoder"")
    vendored(""toml.decoder"")
    vendored(""urllib3"")
```
",run check content run got output python content file pip prevent needing pip depend something external inside considered immutable import import import import downstream also patch value true trigger additional cause like six available pip true default look directory bunch add beginning import anything done support downstream like wish create aid prefix prefix prefix define small helper function alias real exist idea taken try except silently allow import pas got point import import whatever since attempt alias mean get regular import error whenever pip actually import one use actually u better error message would otherwise gotten pas else base head base head operating setup want go ahead trigger well looking add cause code typically however downstream enable consistent way across actually look inside find add front actually alias six pep progress try except already pas,issue,positive,negative,neutral,neutral,negative,negative
1520199086,"> why is the vendor directory almost empty?

I don't know. 

The `pip` installation I have in `~/.local/lib/python3.8/site-packages/pip` contains a number of files in its `_vendor`, including `six.py`.

But I noticed the system-wide `/usr/lib/python3/dist-packages/pip` has an almost empty `_vendor`, with no `six.py`. I have therefore reinstalled the system-wide `pip`, based on the instructions at one of the links you posted, with
```
curl -sS  https://bootstrap.pypa.io/pip/3.6/get-pip.py | sudo pypy3
```
Now also the system-wide `pip` has a crowded `_vendor` directory, containing `six.py`.

Unfortunately the error with `mlflow run .` persists.

Where does `mlflow run .` take its `pip` from? Looks to me like it doesn't use neither the system-wide nor the one I have in `~/.local`. 
",vendor directory almost empty know pip installation number almost empty therefore pip based one link posted curl also pip crowded directory unfortunately error run run take pip like use neither one,issue,negative,negative,negative,negative,negative,negative
1520039410,"@harupy Appreciate your support, thank you. I have modified `score.py` to make it work. How do I get the modified `score.py` file into the mlflow model artefact that is currently registered in my Azure Machine Learning model registry? 
The way I fixed it in the local inference server deployment was by encoding the numpy array resulting from the `session.run()`call (see scoring file below) using `json.dumps(result, cls=NumpyEncoder)`.

Also, this seems like a workaround. Please, is it possible to modify the default score.py file in a way that it does not output a numpy array that cannot be serialised into a .json object required for the API response? Having a manual amended scoring file defeats the automation purpose of using MLFlow.

FYI, there is a similar issue with the other frameworks (e.g. pyfunc.log_model).


```
import os
import json
import logging
import json
import time
import sys
import os
import numpy as np    # we're going to use numpy to process input and output data
import onnxruntime    # to inference ONNX models, we use the ONNX Runtime
import json


class NumpyEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        return json.JSONEncoder.default(self, obj)

def init():
    global session
    
    model = os.path.join(os.getcwd(), 'model/model_natasha-copy.onnx')
    session = onnxruntime.InferenceSession(model)

# def preprocess(input_data_json):
#     # convert the JSON data into the tensor input
#     with open(input_data_json, 'r') as j:            
#         contents = json.loads(j.read())
#     #return np.array(json.loads(input_data_json)[""inputs""]).astype('float32')
#     return np.array(contents[""inputs""]).astype('float32')

# def postprocess(result):
#     # We use argmax to pick the highest confidence label
#     return int(np.argmax(np.array(result), axis=0))

def run(input_data_json):
    input_data = np.array(json.loads(input_data_json)[""inputs""]).astype('float32')
    try:
        start = time.time()   # start timer
        #input_data = preprocess(input_data_json)
        print(""###SHAPE#####"", input_data.shape)
        print(""####"", input_data.dtype)
        input_name = session.get_inputs()[0].name  # get the id of the first input of the model   
        print(""input_name"", input_name)
        result = session.run([], {input_name: input_data})
        # ENCODE FOR MODEL OUTPUT
        json_result = json.dumps(result, cls=NumpyEncoder)
        end = time.time()     # stop timer
        return {""result"": json_result,
                ""time"": end - start}
    except Exception as e:
        result = str(e)
        return {""error""}#: result}
```",appreciate support thank make work get file model artefact currently registered azure machine learning model registry way fixed local inference server deployment array resulting call see scoring file result also like please possible modify default file way output array object response manual scoring file purpose similar issue import o import import logging import import time import import o import going use process input output data import inference use import class default self return return self global session model session model convert data tensor input open content return return content result use pick highest confidence label return result run try start start timer print shape print get id first input model print result encode model output result end stop timer return result time end start except exception result return error result,issue,positive,positive,neutral,neutral,positive,positive
1519904664,"Hi @BenWilson2 
I will try using boto3 externally to MLflow now and see whether this issue still arises.
",hi try externally see whether issue still,issue,negative,neutral,neutral,neutral,neutral,neutral
1519741240,"**alert box**:

upon successful signup: will redirect to home after clicking OK
![image](https://user-images.githubusercontent.com/22888849/233958700-80a1024e-4734-45dc-8f7c-d579776fbafd.png)


upon unsuccessful signup: will redirect to signup after clicking OK
![image](https://user-images.githubusercontent.com/22888849/233958874-3dec6206-cd75-4da6-9f28-98223dd5892c.png)
",alert box upon successful redirect home image upon unsuccessful redirect image,issue,positive,positive,positive,positive,positive,positive
1519582953,"ML FLow initialises all loggers by using a `from_dict` method, which clears all other loggers. This has to be changed - the clearing of loggers happens in `logging` library.",flow method clearing logging library,issue,negative,neutral,neutral,neutral,neutral,neutral
1519540836,"@SaravananSathyanandhaQC 

> I have one behavioural nuance in my current draft implementation, which is that with the SQL store a filter on a tag will work even with run_info_only=True, because it can do the filter within the query, it just doesn't return the value. Whereas for a file backing store the tags aren't loaded so any filter will assume there's no tags and fail. Probably not ideal, open to thoughts on how best to handle this

Not ideal, but sounds ok to me as long as this behavior is documented.",one nuance current draft implementation store filter tag work even filter within query return value whereas file backing store loaded filter assume fail probably ideal open best handle ideal long behavior,issue,positive,positive,positive,positive,positive,positive
1519477817,why is the vendor directory almost empty?,vendor directory almost empty,issue,negative,negative,neutral,neutral,negative,negative
1519436310,"
> @fantauzzi Does `/home/ubuntu/.mlflow/envs/mlflow-dc1faba5c996e345dd1cc40210944f3b69389fb6/lib/python3.8/site-packages/pip/_vendor/six.py` exist?

I had checked that, and it didn't. I don't have that set-up anymore, so I have reproduced the issue in a new set-up, and this is the content of the relevant directory in the new set-up after running `mlflow run .` and getting the error:
```
$ ll /home/ubuntu/.mlflow/envs/mlflow-dc1faba5c996e345dd1cc40210944f3b69389fb6/lib/python3.8/site-packages/pip/_vendor/
total 20
drwxrwxr-x 3 ubuntu ubuntu 4096 Apr 24 06:00 ./
drwxrwxr-x 5 ubuntu ubuntu 4096 Apr 24 06:00 ../
-rw-rw-r-- 1 ubuntu ubuntu 4975 Apr 24 06:00 __init__.py
drwxrwxr-x 2 ubuntu ubuntu 4096 Apr 24 06:00 __pycache__/
```
It looks like the creation of the virtualenv got interrupted by the error, and therefore didn't complete. If I try to activate it from shell, I get this:
```
$ pyenv activate mlflow-dc1faba5c996e345dd1cc40210944f3b69389fb6
pyenv-virtualenv: version `mlflow-dc1faba5c996e345dd1cc40210944f3b69389fb6' is not a virtualenv
```
Also, it is not listed as a virtualenv:
```
$ pyenv virtualenvs 
$ 
```",exist checked issue new content relevant directory new running run getting error total like creation got interrupted error therefore complete try activate shell get activate version also listed,issue,negative,positive,positive,positive,positive,positive
1519426224,"> @gabrielfu Left some initial comments, thanks for the PR! Great work :)

Thanks! :) ",left initial thanks great work thanks,issue,positive,positive,positive,positive,positive,positive
1519344809,@julcsii The suggestion makes sense to me! Looking forward to your PR :),suggestion sense looking forward,issue,negative,neutral,neutral,neutral,neutral,neutral
1519338630,"@gabrielfu Left some initial comments, thanks for the PR! Great work :)",left initial thanks great work,issue,positive,positive,positive,positive,positive,positive
1519279401,"https://github.com/pypa/pipenv/issues/4804 reports the same issue, might be worth a look",issue might worth look,issue,negative,positive,positive,positive,positive,positive
1518695418,"Very excited to see this, this issue (slow loading) is the main reason Im forced to use wandb instead of mlflow tracking.  

My models use a *lot* of metrics on a lot of predictions.  That does not seem to affect wandb , mlflow tracking quickly becomes unusably slow.",excited see issue slow loading main reason forced use instead use lot metric lot seem affect quickly becomes unusably slow,issue,negative,negative,neutral,neutral,negative,negative
1518330393,"@ericvincent18 you most certainly may :) Keep in mind that the statsmodels example will be split into 2 parts (for the two separate ""families of APIs"" in statsmodels. I'd recommend doing one on some form of traditional regression statistical model and another on a timeseries model. That way we can demonstrate the two different paradigms in play within that library. Feel free to choose any base model types within those families (a statistical model and a timeseries model) that tickle your fancy. ",certainly may keep mind example split two separate recommend one form traditional regression statistical model another model way demonstrate two different play within library feel free choose base model within statistical model model tickle fancy,issue,positive,negative,neutral,neutral,negative,negative
1518296290,"> LGTM! Great stuff @sunishsheth2009 ! Is there going to be a followup PR to update the flavor description capabilities in models.rst?

+1 @sunishsheth2009 we should make sure to update docs and API docstrings for this :)",great stuff going update flavor description make sure update,issue,positive,positive,positive,positive,positive,positive
1517830090,"Hi @harupy, I am a beginner. 
Are there any tasks I can work upon in this issue? ",hi beginner work upon issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1517218687,Wanted to add a +1 to request this feature. It would be a game changer!,add request feature would game changer,issue,negative,negative,negative,negative,negative,negative
1517137359,"Adding: convert to `collapse_whitespace`, additional NB notes that make it clear when these are being used (why and what their defaults are), docstring for the method, and updating the docs.",convert additional make clear used method,issue,negative,positive,positive,positive,positive,positive
1517060470,"@jlmeunier Thanks! I'll close this issue, but let me know if the issue still persists in the latest version of MLflow :)",thanks close issue let know issue still latest version,issue,negative,positive,positive,positive,positive,positive
1517040796,Makes sense. Removing `/models/documentClassifier` or using a unique temporary directory in each run might change the result.,sense removing unique temporary directory run might change result,issue,negative,positive,positive,positive,positive,positive
1516852159,"I still get 2 warnings on the build, but they relate to references from the docstrings. In particular, I tried to chase down the warning ""mlflow/mlflow/sklearn/__init__.py:docstring of mlflow.sklearn.autolog:130:"" by looking at the docstring for autolog, but I didn't find any :ref: references. So hopefully those aren't blocking warnings. 
 ",still get build relate particular tried chase warning looking find ref hopefully blocking,issue,negative,positive,positive,positive,positive,positive
1516716120,"Yes, that could make sense. We are loading the models into the docker image, so I could imagine if I rerun the pipeline without code changes, it will cache the models.",yes could make sense loading docker image could imagine rerun pipeline without code cache,issue,negative,neutral,neutral,neutral,neutral,neutral
1516600431,Hi @tueboesen the current pytorch implementation in MLflow supports `torch.jit.script` or `torch.jit.trace` to be passed to the `pytorch_model` argument in `save_model()` and `log_model()`. Have you given this a try?,hi current implementation argument given try,issue,negative,neutral,neutral,neutral,neutral,neutral
1516508032,"Thanks for the information. I think there are two scenarios where we hit the return statement (that triggers the error) in the following code:

1. The file is downloaded serially.
2. The file is already in `download_path` and its size is larger than `downloaded_size`. For example, if you make a download twice with the same destination, the first download doesn't hit the return statement, but the second one does because the file is already there. Hope this makes sense.


https://github.com/mlflow/mlflow/blob/24e7c0701ca31bc0925a6647c97dffdee9ef938b/mlflow/utils/file_utils.py#L632-L641

If the download became faster (= the model is downloaded by chunks), the first scenario is probably not the case. The second scenario might be because you seem to set `dst_path` when calling `mlflow.artifacts.download_artifacts`.",thanks information think two hit return statement error following code file serially file already size example make twice destination first hit return statement second one file already hope sense faster model first scenario probably case second scenario might seem set calling,issue,negative,positive,positive,positive,positive,positive
1516497517,"We are downloading the same models each time - 1 big model and 20+ smaller
models, but it seems to always throw the error at the big model.

tor. 20. apr. 2023 16.54 skrev Harutaka Kawamura ***@***.***>:

> I'm not sure why 2.3.0 is flaky. I think it should constantly fail (unless
> you download different models in each attempt).
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/mlflow/mlflow/issues/8288#issuecomment-1516476234>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/A5YY6NOGKP3CN233Z5XTUULXCFE37ANCNFSM6AAAAAAXFOXZMA>
> .
> You are receiving this because you were mentioned.Message ID:
> ***@***.***>
>
",time big model smaller always throw error big model tor sure flaky think constantly fail unless different attempt reply directly view id,issue,negative,positive,neutral,neutral,positive,positive
1516476234,I'm not sure why 2.3.0 is flaky. I think it should constantly fail (unless you download different models in each attempt).,sure flaky think constantly fail unless different attempt,issue,negative,neutral,neutral,neutral,neutral,neutral
1516459095,"Nope, it seems to be stable using the PR version. At least it worked fine 4 out of 4 times :)

It might be relevant to say that the error mentioned in this bug appeared when building my docker container in Azure DevOps pipelines. When running the container locally, I have for a long time received a time out error once in a while, but this doesn't seem to be the case more.",nope stable version least worked fine time might relevant say error bug building docker container azure running container locally long time received time error seem case,issue,negative,positive,positive,positive,positive,positive
1516449123,Hi @pakesson-truesec the fix for the reported vulnerability has just merged into master.,hi fix vulnerability master,issue,negative,neutral,neutral,neutral,neutral,neutral
1516405994,"Yes, it has been randomly failing and succeeding since using 2.3.0.
I have just tried again, and it succeeded .",yes randomly failing succeeding since tried,issue,negative,negative,negative,negative,negative,negative
1516385207,"Glad to hear that!

> However, it also succeeded 3/15 times using 2.3.0.

So it randomly succeeds/fails? Does ""3/15 times"" mean 3 successful downloads out of 15 attempts?",glad hear however also time randomly time mean successful,issue,positive,positive,positive,positive,positive,positive
1516381085,"Thanks, Harupy!
I have just tested it, and it worked - and it loaded the models much faster than usual :)
However, it also succeeded 3/15 times using 2.3.0.",thanks tested worked loaded much faster usual however also time,issue,negative,positive,neutral,neutral,positive,positive
1516359789,"> The exception is being thrown from pytorch. We simply rely on their serialization utilities to store model artifacts. What sort of additional information did you need to save that is incompatible with the native pytorch save functionality?

I see. It is a highly customized model and I'm not sure exactly what is incompatible. Normally I would save the state_dict, which is the recommended way in pytorch from what I understand, but I can understand why you would do it this way.
I believe a method that enables the user to log the model converted to torchscript or jit compilated might be able to fix this issue, but I don't know enough about that. ",exception thrown simply rely serialization store model sort additional information need save incompatible native save functionality see highly model sure exactly incompatible normally would save way understand understand would way believe method user log model converted might able fix issue know enough,issue,positive,positive,positive,positive,positive,positive
1516341843,"@TobiasRD95 Thanks for the reply! Got it, would you mind testing [the PR](https://github.com/mlflow/mlflow/pull/8289) by using the command above?",thanks reply got would mind testing command,issue,negative,positive,positive,positive,positive,positive
1516331450,"Hi

We are using Databricks on Azure

tor. 20. apr. 2023 15.18 skrev Harutaka Kawamura ***@***.***>:

> @TobiasRD95 <https://github.com/TobiasRD95> Thanks for trying out MLflow
> 2.3.0. In this version, we made a few updates to upload/download large
> files faster. I think the error occurs here:
>
>
> https://github.com/mlflow/mlflow/blob/251428cb7ffb0977f78655a24563be7ea75d8a5f/mlflow/store/artifact/databricks_artifact_repo.py#L438
>
> Are you using Databricks on Google Cloud?
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/mlflow/mlflow/issues/8288#issuecomment-1516314549>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/A5YY6NL74HDEONJOEYURVNTXCEZSJANCNFSM6AAAAAAXFOXZMA>
> .
> You are receiving this because you were mentioned.Message ID:
> ***@***.***>
>
",hi azure tor thanks trying version made large faster think error cloud reply directly view id,issue,negative,positive,positive,positive,positive,positive
1516330758,"Filed https://github.com/mlflow/mlflow/pull/8289. The following command installs mlflow from this PR:

```
%pip install git+https://github.com/mlflow/mlflow.git@refs/pull/8289/merge
```",following command pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
1516314549,"@TobiasRD95 Thanks for trying out MLflow 2.3.0. In this version, we made several updates to upload/download large files faster. I think the error occurs here:

https://github.com/mlflow/mlflow/blob/251428cb7ffb0977f78655a24563be7ea75d8a5f/mlflow/store/artifact/databricks_artifact_repo.py#L438

`failed_downloads` being `None` means we reach here:

https://github.com/mlflow/mlflow/blob/24e7c0701ca31bc0925a6647c97dffdee9ef938b/mlflow/utils/file_utils.py#L632-L641


I'll file a PR. We'll make a patch release next week. Are you using Databricks on Google Cloud?",thanks trying version made several large faster think error none reach file make patch release next week cloud,issue,negative,positive,positive,positive,positive,positive
1516282577,"> @chris-ds-dk `--no-serve-artifacts` basically means disabling the endpoints for proxy artifact operations and doesn't disable the endpoints that UI uses to display artifacts, so it doesn't mean ""Do not show artifacts on UI"".

Thank you for the clarification. Does that mean I should create a feature request for the UI component on an option to ""Disable showing artifacts in the UI""? I assume it should include a flag to the mlflow server cli",basically proxy artifact disable display mean show thank clarification mean create feature request component option disable showing assume include flag server,issue,positive,negative,negative,negative,negative,negative
1516270575,"Hi @BenWilson2 

I have sent a PR regarding the error handling of InvalidURL. Please take a look :)

Thanks, ",hi sent regarding error handling please take look thanks,issue,negative,positive,positive,positive,positive,positive
1516106958,"> @SaravananSathyanandhaQC Thanks for the PR! Can you create a script that compares the performance between with-flag and without-flag, and attach the code in the PR description?

Yep added! This minimal example perf test shows a 5x improvement.

On real data I tried calling `_list_run_infos` directly and was seeing a 10x improvement. Not 100% sure if that discrepancy is because I was avoiding creating `RunData` objects and the filtering/sorting, or because the real data is sat on an NFS, or because my real data was just bigger due to more params/tags/artifacts. Maybe a bit of everything",thanks create script performance attach code description yep added minimal example test improvement real data tried calling directly seeing improvement sure discrepancy real data sat real data bigger due maybe bit everything,issue,positive,positive,positive,positive,positive,positive
1516072920,"@SaravananSathyanandhaQC Thanks for the PR! Can you create a script that compares the performance between with-flag and without-flag, and attach the code in the PR description?",thanks create script performance attach code description,issue,positive,positive,positive,positive,positive,positive
1516047698,"@harupy Thanks! Just got a draft going here https://github.com/mlflow/mlflow/pull/8287

Comments so far
- Is making the Java/R clients equivalent to Python a requirement? I'm guessing so - I can give Java a go, don't know R though unfortunately
- I have one behavioural nuance in my current draft implementation, which is that with the SQL store a filter on a tag will work even with `run_info_only=True`, because it can do the filter within the query, it just doesn't return the value. Whereas for a file backing store the tags aren't loaded so any filter will assume there's no tags and fail. Probably not ideal, open to thoughts on how best to handle this",thanks got draft going far making equivalent python requirement guessing give go know though unfortunately one nuance current draft implementation store filter tag work even filter within query return value whereas file backing store loaded filter assume fail probably ideal open best handle,issue,positive,positive,positive,positive,positive,positive
1515901002,"my version is 1.29.0

Yes the URL you showed is promising for my case!

I'll update my server and come back to you. Thanks for the help!

..but I see that ""This release contains several important breaking changes from the 1.x API""... So let's see when I can do the upgrade. Thanks a lot anyway!",version yes promising case update server come back thanks help see release several important breaking let see upgrade thanks lot anyway,issue,positive,positive,positive,positive,positive,positive
1515881288,"Relevant code:

https://github.com/mlflow/mlflow/blob/24e7c0701ca31bc0925a6647c97dffdee9ef938b/mlflow/utils/rest_utils.py#L42-L44


We currently don't provide an option to disable session caching.",relevant code currently provide option disable session,issue,negative,positive,positive,positive,positive,positive
1515847182,@jlmeunier What is your MLflow version? The latest version of MLflow no longer has `categorizedUncheckedKeys`.,version latest version longer,issue,negative,positive,positive,positive,positive,positive
1515818471,"Sorry, I shared part of the long link, but it did not went thru. Here again below!

Maybe another solution would consist in omitting the ""uncheckedKeys"" in the URL. Somehow doing the reverse of what is done currently where MLFlow shows everything that is not omitted. Showing only what is mentioned in the link cannot be so large since it corresponds to what a user wants to look at.
And then maybe adding a boolean parameter that tells that non-mentioned key must be omitted?

An excerpt of the long parameter value, which represents most of the 32k (347 metrics):
`categorizedUncheckedKeys[metrics]=alpha,bleu,bsz,chrf,chrfpp,full_loss,gate_loss,gnorm,gpu_0_mem,gpu_0_use,gpu_1_mem,gpu_1_use,gpu_2_mem,gpu_2_use,gpu_3_mem,gpu_3_use,kl_loss,langid,len_ratio,lines,load_wall,loss,loss_scale,lps,lr,max_mem,nll_loss,ppl,spbleu,src_oov,tgt_oov,tokens,total_wall,ups,valid-it.cs-da%2Fbleu,valid-it.cs-da%2Fbsz,valid-it.cs-da%2Fchrf,valid-it.cs-da%2Fchrfpp,valid-it.cs-da%2Flen_ratio,valid-it.cs-da%2Flines,valid-it.cs-da%2Floss,valid-it.cs-da%2Flps,valid-it.cs-da%2Fnll_loss,valid-it.cs-da%2Fppl,valid-it.cs-da%2Fspbleu,valid-it.cs-da%2Fups,valid-it.cs-da%2Fwall,valid-it.cs-da%2Fwpb,valid-it.cs-da%2Fwps,valid-it.cs-de%2Fbleu,valid-it.cs-de%2Fbsz,valid-it.cs-de%2Fchrf,valid-it.cs-de%2Fchrfpp,valid-it.cs-de%2Flen_ratio,valid-it.cs-de%2Flines,valid-it.cs-de%2Floss,valid-it.cs-de%2Flps,valid-it.cs-de%2Fnll_loss,valid-it.cs-de%2Fppl,valid-it.cs-de%2Fspbleu,valid-it.cs-de%2Fups,valid-it.cs-de%2Fwall,valid-it.cs-de%2Fwpb,valid-it.cs-de%2Fwps,valid-it.cs-en%2Fbleu,valid-it.cs-en%2Fbsz,valid-it.cs-en%2Fchrf,valid-it.cs-en%2Fchrfpp,valid-it.cs-en%2Flen_ratio,valid-it.cs-en%2Flines,valid-it.cs-en%2Floss,valid-it.cs-en%2Flps,valid-it.cs-en%2Fnll_loss,valid-it.cs-en%2Fppl,valid-it.cs-en%2Fspbleu,valid-it.cs-en%2Fups,valid-it.cs-en%2Fwall,valid-it.cs-en%2Fwpb,valid-it.cs-en%2Fwps,valid-it.cs-fr%2Fbleu,valid-it.cs-fr%2Fbsz,valid-it.cs-fr%2Fchrf`",sorry part long link went maybe another solution would consist somehow reverse done currently everything showing link large since user look maybe parameter key must excerpt long parameter value metric metric loss floss floss floss,issue,negative,negative,neutral,neutral,negative,negative
1515764205,@maciejskorski We encountered the same issue in https://github.com/mlflow/mlflow/pull/8116 and found reusing a cached `requests.Session` was the cause. See https://stackoverflow.com/questions/3724900/python-ssl-problem-with-multiprocessing.,issue found cause see,issue,negative,neutral,neutral,neutral,neutral,neutral
1515757715,"> @maciejskorski Are you saying that the code like beflow results in creating multiple unfinished runs due to connection retries?
> 
> ```python
> with mlflow.start_run():
>     ...
> ```

Yup that's what I am saying. 

The usage is pretty standard as you said, except that I am tunnelling and multiprocessing. 
```
experiment_id = mlflow.create_experiment(experiment_name)

def do_job(cfg):
    with mlflow.start_run(experiment_id=experiment_id):
      mlflow.log_param('file',cfg.inputfile)
      # ... do stuff

with mp.Pool(4) as p:
  p.map(do_job, all_cfgs)
  
WARNING:urllib3.connectionpool:Retrying (Retry(total=4, connect=5, read=5, redirect=5, status=5)) after connection broken by 'SSLError(SSLError(1, '[SSL: SSLV3_ALERT_BAD_RECORD_MAC] sslv3 alert bad record mac (_ssl.c:2633)'))': /api/2.0/mlflow/runs/log-parameter
WARNING:urllib3.connectionpool:Retrying (Retry(total=4, connect=5, read=5, redirect=5, status=5)) after connection broken by 'SSLError(SSLError(1, '[SSL: DECRYPTION_FAILED_OR_BAD_RECORD_MAC] decryption failed or bad record mac (_ssl.c:2633)'))': /api/2.0/mlflow/runs/create
```
I typically end up with one ghost round more than the length of the task list.

If nothing comes to mind right away, I can try a bit harder and make a fully reproducible example in Google Colab

",saying code like multiple unfinished due connection python saying usage pretty standard said except stuff warning retry connection broken alert bad record mac warning retry connection broken bad record mac typically end one ghost round length task list nothing come mind right away try bit harder make fully reproducible example,issue,negative,negative,negative,negative,negative,negative
1515708967,"Want to echo this feature request. This is the one feature I truly wish mlflow had!

Thanks for all your hard work :)",want echo feature request one feature truly wish thanks hard work,issue,positive,negative,neutral,neutral,negative,negative
1515697638,"I really love Mlflow it's a very user-friendly platform, and the way you support me I feel good Thanks to all mlflow community.",really love platform way support feel good thanks community,issue,positive,positive,positive,positive,positive,positive
1515623037,"Hi @pakesson-truesec thank you for bringing this to our attention. Once #8281 is merged to master, could you perform a validation on your end to let us know if there are any additional creative ways that you can find that our changes didn't cover? 
Thank you for helping to make the project more secure! It is greatly appreciated by both the maintainers and our users. ",hi thank attention master could perform validation end let u know additional creative way find cover thank helping make project secure greatly,issue,positive,positive,positive,positive,positive,positive
1515586343,@SaravananSathyanandhaQC Thanks for the FR! The motivation makes sense. I'm leaning towards on adding a flag (e.g. `run_info_only`) because it's easier to implement. We used to have `list_run_infos` but removed it in MLflow 2.0 because we have `search_runs`.,thanks motivation sense leaning towards flag easier implement used removed,issue,positive,positive,positive,positive,positive,positive
1515539354,"@nikshingadiya Feel free to reopen the issue if it's not a dagshub's issue, but an MLflow's issue :)",feel free reopen issue issue issue,issue,positive,positive,positive,positive,positive,positive
1515508473,@foreveronehundred You can see the error contains `Messagey of Parameters can not modify its value after it is set'`. A parameter value can't be changed.,see error modify value set parameter value ca,issue,negative,neutral,neutral,neutral,neutral,neutral
1514971259,@ericvincent18 we'd be thrilled to have you work on the H2o example! Let us know when your PR is ready.,work ho example let u know ready,issue,negative,positive,positive,positive,positive,positive
1514970447,"@krishnakalyan3 @dipanjank I think a simplified example in line with what you're suggesting is ideal. We don't need to implement a custom CNN from scratch as an example, but a fairly simple integration within a training loop would be great for the TF flavor. ",think simplified example line suggesting ideal need implement custom scratch example fairly simple integration within training loop would great flavor,issue,positive,positive,positive,positive,positive,positive
1514866623,"@amesar Is there anything we need to fix in **the OSS MLflow documentation?** If no, I'll close this. You can file an internal ticket to track this.",anything need fix documentation close file internal ticket track,issue,negative,neutral,neutral,neutral,neutral,neutral
1514860668,So the selectedColumns parameter is very long? Curious which parameter has many characeters in the URL.,parameter long curious parameter many,issue,negative,positive,positive,positive,positive,positive
1514818278,"Actually, the selectedColumns is precisely what I want to share with others. (once I've carefully selected the columns of interest for a particular goal).
Thanks @harupy for the interest.",actually precisely want share carefully selected interest particular goal thanks interest,issue,positive,positive,positive,positive,positive,positive
1514731386,@jianyuan I think the `selectedColumns` query parameter becomes very long if you have many parameters/metrics. Would the option (e.g. checkbox) to exclude it from the URL help?,think query parameter becomes long many would option exclude help,issue,negative,positive,positive,positive,positive,positive
1514728302,"@chris-ds-dk `--no-serve-artifacts` basically means disabling the endpoints for proxy artifact operations and doesn't disable the endpoints that UI uses to display artifacts, so it doesn't mean ""Do not show artifacts on UI"".",basically proxy artifact disable display mean show,issue,negative,negative,negative,negative,negative,negative
1514688863,"can you share with me above code via google notebook

On Wed, Apr 19, 2023 at 6:25 PM Nikhil Shingadiya <
***@***.***> wrote:

> So issue comes from dagshub side thanks for guidence
>
> On Wed, 19 Apr, 2023, 6:21 pm Harutaka Kawamura, ***@***.***>
> wrote:
>
>> Ran your notebook without dagshub. The model was logged:
>>
>> [image: image]
>> <https://user-images.githubusercontent.com/17039389/233079863-d6601dc1-1c11-4cf0-9de3-903bb26de627.png>
>>
>> —
>> Reply to this email directly, view it on GitHub
>> <https://github.com/mlflow/mlflow/issues/8275#issuecomment-1514680905>,
>> or unsubscribe
>> <https://github.com/notifications/unsubscribe-auth/ALFNHJ3DCWMMGZE5WBMDWFDXB7NTPANCNFSM6AAAAAAXD5WRPY>
>> .
>> You are receiving this because you were mentioned.Message ID:
>> ***@***.***>
>>
>
",share code via notebook wed wrote issue come side thanks wed wrote ran notebook without model logged image image reply directly view id,issue,positive,positive,positive,positive,positive,positive
1514687005,"So issue comes from dagshub side thanks for guidence

On Wed, 19 Apr, 2023, 6:21 pm Harutaka Kawamura, ***@***.***>
wrote:

> Ran your notebook without dagshub. The model was logged:
>
> [image: image]
> <https://user-images.githubusercontent.com/17039389/233079863-d6601dc1-1c11-4cf0-9de3-903bb26de627.png>
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/mlflow/mlflow/issues/8275#issuecomment-1514680905>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ALFNHJ3DCWMMGZE5WBMDWFDXB7NTPANCNFSM6AAAAAAXD5WRPY>
> .
> You are receiving this because you were mentioned.Message ID:
> ***@***.***>
>
",issue come side thanks wed wrote ran notebook without model logged image image reply directly view id,issue,negative,positive,positive,positive,positive,positive
1514684267,"Hi @harupy, I have updated as per your comments. Can you review the changes made?",hi per review made,issue,negative,neutral,neutral,neutral,neutral,neutral
1514680905,"Ran your notebook without `dagshub`. The model was logged:

<img width=""1006"" alt=""image"" src=""https://user-images.githubusercontent.com/17039389/233079863-d6601dc1-1c11-4cf0-9de3-903bb26de627.png"">
",ran notebook without model logged image,issue,negative,neutral,neutral,neutral,neutral,neutral
1514641536,"Here is the link:  google colab notebook link
<https://colab.research.google.com/drive/1N5unt8ALPHlJeHuXdxxv2t4v-UsD18v_?usp=sharing>
In the artifact folder, i didn't find any TensorFlow model
Note: Run notebook to till this cell ""model.fit(train_images, train_labels,
epochs=2)"" and you will get those similar logs which I already defined in
github issue

On Wed, Apr 19, 2023 at 5:29 PM Nikhil Shingadiya <
***@***.***> wrote:

> I will send you another code which will create this same issue thanks for
> supporting us
>
> On Wed, 19 Apr, 2023, 5:20 pm Harutaka Kawamura, ***@***.***>
> wrote:
>
>> we can't share all the codes with github it's our personal project sry for
>>
>> You don't have to share your code. What we need is code that can
>> reproduce the issue. If you don't have it, please create it.
>>
>> —
>> Reply to this email directly, view it on GitHub
>> <https://github.com/mlflow/mlflow/issues/8275#issuecomment-1514595120>,
>> or unsubscribe
>> <https://github.com/notifications/unsubscribe-auth/ALFNHJ364VAT24LSVVDIVY3XB7GSHANCNFSM6AAAAAAXD5WRPY>
>> .
>> You are receiving this because you were mentioned.Message ID:
>> ***@***.***>
>>
>
",link notebook link artifact folder find model note run notebook till cell get similar already defined issue wed wrote send another code create issue thanks supporting u wed wrote ca share personal project share code need code reproduce issue please create reply directly view id,issue,positive,positive,positive,positive,positive,positive
1514606339,"I will send you another code which will create this same issue thanks for
supporting us

On Wed, 19 Apr, 2023, 5:20 pm Harutaka Kawamura, ***@***.***>
wrote:

> we can't share all the codes with github it's our personal project sry for
>
> You don't have to share your code. What we need is code that can reproduce
> the issue. If you don't have it, please create it.
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/mlflow/mlflow/issues/8275#issuecomment-1514595120>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ALFNHJ364VAT24LSVVDIVY3XB7GSHANCNFSM6AAAAAAXD5WRPY>
> .
> You are receiving this because you were mentioned.Message ID:
> ***@***.***>
>
",send another code create issue thanks supporting u wed wrote ca share personal project share code need code reproduce issue please create reply directly view id,issue,positive,positive,positive,positive,positive,positive
1514595120,"> we can't share all the codes with github it's our personal project  sry for


You don't have to share your code. What we need is code that can reproduce the issue. If you don't have it, please create it, otherwise we can't reproduce the issue.",ca share personal project share code need code reproduce issue please create otherwise ca reproduce issue,issue,positive,neutral,neutral,neutral,neutral,neutral
1514591606,"we can't share all the codes with github it's our personal project  sry for
the inconvenience.

On Wed, 19 Apr, 2023, 5:11 pm Harutaka Kawamura, ***@***.***>
wrote:

> mlflow.keras.autolog()dagshub.init(""Eye_disease_MLflow"", ""bhuvnesh.shukla"", mlflow=True)# New runmlflow.start_run(run_name=""Aptos_Resnet_5"")# Run idrun_id = mlflow.active_run().info.run_idhistory = model.fit(x=x_train, y=y_train, batch_size=16, epochs=20, verbose = 1, validation_data = (x_val, y_val), validation_batch_size = 16, callbacks = callback)
>
> is not runnable. Can you:
>
>    - add all the required import statements
>    - add undefined variables
>    - make sure it can be executed by copy & pasting
>
> ?
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/mlflow/mlflow/issues/8275#issuecomment-1514584453>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ALFNHJYA7Y4LMPCBGKCN7HTXB7FO7ANCNFSM6AAAAAAXD5WRPY>
> .
> You are receiving this because you were mentioned.Message ID:
> ***@***.***>
>
",ca share personal project inconvenience wed wrote new run verbose runnable add import add undefined make sure executed copy pasting reply directly view id,issue,negative,positive,positive,positive,positive,positive
1514584453,"Your issue reproducer:

```python
mlflow.keras.autolog()
dagshub.init(""Eye_disease_MLflow"", ""bhuvnesh.shukla"", mlflow=True)
# New run
mlflow.start_run(run_name=""Aptos_Resnet_5"")
# Run id
run_id = mlflow.active_run().info.run_id
history = model.fit(x=x_train, y=y_train, batch_size=16, epochs=20, verbose = 1, validation_data = (x_val, y_val), validation_batch_size = 16, callbacks = callback)
```

is not runnable. Can you:

- add all the required import statements
- add undefined variables
- remove `dagshub` unless it's required to reproduce the issue.
- make sure it can be executed by `echo <code> > a.py && python a.py`

?",issue reproducer python new run run id history verbose runnable add import add undefined remove unless reproduce issue make sure executed echo code python,issue,negative,positive,positive,positive,positive,positive
1514579168,@nikshingadiya You can set the `MLFLOW_AUTOLOGGING_TESTING` environment variable to see what went wrong.,set environment variable see went wrong,issue,negative,negative,negative,negative,negative,negative
1514554792,"> Perhaps `tensorflow` example is not required as its already covered in #6781?. Maybe we can just add a note that with Tensorflow v2, Keras has tighter integration with tensorflow. @BenWilson2 what do you think?

I wanted to ask this as well. IMHO the only thing the ""keras"" example doesn't cover is the scenario where an mlflow user has hand-written a low-level training loop and wants to record some params / metric on every iteration, e.g. 

```python

@tf.function
def train_step(x, y, step):
    with tf.GradientTape() as tape:
        y_hat = tf.matmul(w, x)
        loss_value = loss_fn(y, y_hat)
    grads = tape.gradient(loss_value, model.trainable_weights)
    optimizer.apply_gradients(zip(grads, model.trainable_weights))
    mlflow.log_metric(key=""loss"", value=loss_value, step=step) .
    return loss_value
```

Do we see this as a valuable addition?
",perhaps example already covered maybe add note integration think ask well thing example cover scenario user training loop record metric every iteration python step tape zip loss return see valuable addition,issue,negative,neutral,neutral,neutral,neutral,neutral
1514541694,"@maciejskorski Are you saying that the code like beflow results in creating multiple unfinished runs due to connection retries?

```python
with mlflow.start_run():
    ...
```
",saying code like multiple unfinished due connection python,issue,negative,negative,neutral,neutral,negative,negative
1514369937,"Perhaps `tensorflow` example is not required as its already covered in https://github.com/mlflow/mlflow/pull/6781?. Maybe we can just add a note that with Tensorflow v2, Keras has tighter integration with tensorflow.
@BenWilson2 what do you think?",perhaps example already covered maybe add note integration think,issue,negative,neutral,neutral,neutral,neutral,neutral
1514214302,@jhaneyrf Thanks for filing this issue! I filed #8271 to improve the doc for `experiment_name`.,thanks filing issue improve doc,issue,positive,positive,positive,positive,positive,positive
1514197900,"Hi @dbczumar I'd be happy to contribute here, could I pick up h2o example? ",hi happy contribute could pick ho example,issue,positive,positive,positive,positive,positive,positive
1514174884,"`pipdeptree` found `triton` and `torch` depend on each other:

```
> pip install torch==2.0.0
> pipdeptree --packages torch
Warning!!! Possibly conflicting dependencies found:
* fastai==2.7.10
 - torch [required: >=1.7,<1.14, installed: 2.0.0]
* langchain==0.0.141
 - SQLAlchemy [required: >=1,<2, installed: 2.0.9]
* mleap==0.21.0
 - scikit-learn [required: >=0.22.0,<0.23.0, installed: 1.1.1]
* mlflow==2.2.2
 - pytz [required: <2023, installed: 2023.3]
* numba==0.56.4
 - numpy [required: >=1.18,<1.24, installed: 1.24.2]
* onnx==1.12.0
 - protobuf [required: >=3.12.2,<=3.20.1, installed: 4.22.3]
* spacy==3.4.2
 - typer [required: >=0.3.0,<0.5.0, installed: 0.7.0]
* Sphinx==3.5.4
 - docutils [required: >=0.12,<0.17, installed: 0.19]
* tensorflow==2.12.0
 - numpy [required: >=1.22,<1.24, installed: 1.24.2]
* torchvision==0.14.0
 - torch [required: ==1.13.0, installed: 2.0.0]
------------------------------------------------------------------------
Warning!! Cyclic dependencies found:
* triton => torch => triton
* torch => triton => torch
------------------------------------------------------------------------
```",found triton torch depend pip install torch warning possibly conflicting found torch typer torch warning cyclic found triton torch triton torch triton torch,issue,negative,neutral,neutral,neutral,neutral,neutral
1513252266,Thanks @BenWilson2. I fixed the long lines that Checkstyle didn't like. Do you mind queueing the tests again? Thanks!,thanks fixed long like mind thanks,issue,positive,positive,positive,positive,positive,positive
1512697381,@benjaminbluhm Thanks for reporting this issue. It looks like we should avoid parsing file paths. I'll file a PR.,thanks issue like avoid file file,issue,negative,positive,positive,positive,positive,positive
1512399890,Thanks for another great contribution @jmahlik 🎉 ,thanks another great contribution,issue,positive,positive,positive,positive,positive,positive
1511962908,"## Related Issues/PRs

None that I could see. I searched **quickstart** in issues and none seem relevant to this text. 

## What changes are proposed in this pull request?

Rewrite of the MLFlow quickstart for focus, terseness, and SEO. 

## How is this patch tested?

- [ ] Existing unit/integration tests
- [ ] New unit/integration tests
- [X] Manual tests (describe details, including test results, below)

Local builds and review. Tech review from engineers, editorial peer-review from Carolyn G.

## Does this PR change the documentation?

- [ ] No. You can skip the rest of this section.
- [X] Yes. Make sure the changed pages / sections render correctly in the documentation preview.

## Release Notes

### Is this a user-facing change?

- [ ] No. You can skip the rest of this section.
- [X] Yes. Give a description of this change to be included in the release notes for MLflow users.

New quickstart focused on time-to-live for Python data scientists.

### What component(s), interfaces, languages, and integrations does this PR affect?

Components

- [ ] `area/artifacts`: Artifact stores and artifact logging
- [ ] `area/build`: Build and test infrastructure for MLflow
- [X] `area/docs`: MLflow documentation pages
- [ ] `area/examples`: Example code
- [ ] `area/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry
- [ ] `area/models`: MLmodel format, model serialization/deserialization, flavors
- [ ] `area/recipes`: Recipes, Recipe APIs, Recipe configs, Recipe Templates
- [ ] `area/projects`: MLproject format, project running backends
- [ ] `area/scoring`: MLflow Model server, model deployment tools, Spark UDFs
- [ ] `area/server-infra`: MLflow Tracking server backend
- [ ] `area/tracking`: Tracking Service, tracking client APIs, autologging

Interface

- [ ] `area/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server
- [ ] `area/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models
- [ ] `area/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry
- [ ] `area/windows`: Windows support

Language

- [ ] `language/r`: R APIs and clients
- [ ] `language/java`: Java APIs and clients
- [ ] `language/new`: Proposals for new client languages

Integrations

- [ ] `integrations/azure`: Azure and Azure ML integrations
- [ ] `integrations/sagemaker`: SageMaker integrations
- [X] `integrations/databricks`: Databricks integrations

(Has an H2 on using MLFlow tracking with a Databricks workspace)

<!--
Insert an empty named anchor here to allow jumping to this section with a fragment URL
(e.g. https://github.com/mlflow/mlflow/pull/123#user-content-release-note-category).
Note that GitHub prefixes anchor names in markdown with ""user-content-"".
-->

<a name=""release-note-category""></a>

### How should the PR be classified in the release notes? Choose one:

- [ ] `rn/breaking-change` - The PR will be mentioned in the ""Breaking Changes"" section
- [ ] `rn/none` - No description will be included. The PR will be mentioned only by the PR number in the ""Small Bugfixes and Documentation Updates"" section
- [ ] `rn/feature` - A new user-facing feature worth mentioning in the release notes
- [ ] `rn/bug-fix` - A user-facing bug fix worth mentioning in the release notes
- [X] `rn/documentation` - A user-facing documentation change worth mentioning in the release notes",related none could see none seem relevant text pull request rewrite focus terseness patch tested new manual describe test local review tech review editorial change documentation skip rest section yes make sure render correctly documentation preview release change skip rest section yes give description change included release new python data component affect artifact artifact logging build test infrastructure documentation example code model registry service fluent client model registry format model recipe recipe recipe format project running model server model deployment spark server service client interface user experience plotting dev server docker use across use service model registry support language new client azure azure insert empty anchor allow section fragment note anchor markdown classified release choose one breaking section description included number small documentation section new feature worth release bug fix worth release documentation change worth release,issue,positive,positive,positive,positive,positive,positive
1511954090,"My understanding is that `MLflow.set_tracking_uri` is stateful, and therefore you cannot log to multiple backends simultaneously. You can, however, rapidly change the tracking uri. So you might have something like: 

    class MultiTracker:
      def __init__(self, uris):
        self.uris = uris

      def log_metric(self, key, value):
        for uri in self.uris:
            mlflow.set_tracking_uri(uri)
            mlflow.log_metric(key, value)

Or, if you're okay with monkey-patching, something like:

    from functools import wraps
    
    tracking_uris = [... uris ...]
    
    def multi_uri_wrapper(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            for uri in tracking_uris:
                mlflow.set_tracking_uri(uri)
                func(*args, **kwargs)
        return wrapper
    
    mlflow.log_metric = multi_uri_wrapper(mlflow.log_metric)
    mlflow.log_params = multi_uri_wrapper(MLflow.log_params)
    ... etc ... ",understanding stateful therefore log multiple simultaneously however rapidly change might something like class self self key value key value something like import wrapper return wrapper,issue,positive,neutral,neutral,neutral,neutral,neutral
1511841074,@jmahlik those test failures were due to the release of PySpark3.4 and a recent breaking release of mlserver. They've been fixed in master. :) ,test due release recent breaking release fixed master,issue,negative,negative,neutral,neutral,negative,negative
1511513730,"Hi @natasha-savic-msft, I'm reading https://learn.microsoft.com/en-us/azure/machine-learning/how-to-inference-server-http?view=azureml-api-2. I'm not familiar with `azureml_inference_server_http`, but is it possible to create `score.py` as described [here](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-inference-server-http?view=azureml-api-2#end-to-end-example) to convert a numpy array to a list?",hi reading familiar possible create convert array list,issue,negative,positive,positive,positive,positive,positive
1511468762,@PsionTheory I directly invited you to the channel. Did you receive an email from Slack?,directly channel receive slack,issue,negative,positive,neutral,neutral,positive,positive
1511466102,"same thing happens with other corporate emails as well

> ---------- Original Message ----------
> From: Neil Barnett ***@***.***>
> To: mlflow/mlflow ***@***.***>
> Date: 04/17/2023 10:20 AM EDT
> Subject: Re: [mlflow/mlflow] Can't Join MLFlow Slack Channel 2023 Edition [BUG] (Issue #8239)
>  
>  
>  
> Here's the issue thats not resolved. Seems MLFlow is expecting me to already be joined, when im applying to join the group, and thusly won't let me join the group.
>  
> I Put in my email to join group 
>  
>  
>  
>  
>  
> This is the loop thats happening 
>  
>  
>  
> 
> > II On 04/17/2023 4:51 AM EDT Harutaka Kawamura ***@***.***> wrote:
> >  
> >  
> > 
> >  
> > 
> > @PsionTheory https://github.com/PsionTheory Sorry for the inconvenience, #8244 https://github.com/mlflow/mlflow/pull/8244 should be able to fix the issue.
> > 
> > —
> > Reply to this email directly, view it on GitHub https://github.com/mlflow/mlflow/issues/8239#issuecomment-1510951420, or unsubscribe https://github.com/notifications/unsubscribe-auth/AA4VELS3LMXDRVTCXMH2MTDXBUAABANCNFSM6AAAAAAXAINUVA.
> > You are receiving this because you were mentioned.Message ID: ***@***.***>
> > 
> 
",thing corporate well original message date subject ca join slack channel edition bug issue issue thats resolved already join group thusly wo let join group put join group loop thats happening wrote sorry inconvenience able fix issue reply directly view id,issue,positive,positive,neutral,neutral,positive,positive
1511456446," 
Here's the issue thats not resolved. Seems MLFlow is expecting me to already be joined, when im applying to join the group, and thusly won't let me join the group.
 
I Put in my email to join group 
 
 
 
 
 
This is the loop thats happening 
 
 
 

> II On 04/17/2023 4:51 AM EDT Harutaka Kawamura ***@***.***> wrote:
>  
>  
> 
>  
> 
> @PsionTheory https://github.com/PsionTheory Sorry for the inconvenience, #8244 https://github.com/mlflow/mlflow/pull/8244 should be able to fix the issue.
> 
> —
> Reply to this email directly, view it on GitHub https://github.com/mlflow/mlflow/issues/8239#issuecomment-1510951420, or unsubscribe https://github.com/notifications/unsubscribe-auth/AA4VELS3LMXDRVTCXMH2MTDXBUAABANCNFSM6AAAAAAXAINUVA.
> You are receiving this because you were mentioned.Message ID: ***@***.***>
> 
",issue thats resolved already join group thusly wo let join group put join group loop thats happening wrote sorry inconvenience able fix issue reply directly view id,issue,positive,positive,neutral,neutral,positive,positive
1511407823,By following your instruction mlflow 2.2.2 was installed on the airflow server and model registering now works. Thanks !!!,following instruction server model work thanks,issue,negative,positive,neutral,neutral,positive,positive
1511242999,"@clementlefevre The reason the run wasn't found is because the run was created in the local file system, not in the database. `mlflow run` creates a run before running the entrypoint, and then runs the entrypoint. As `MLFLOW_TRACKING_URI` is not set, it creates a run in the local file system, and store its ID to `MLFLOW_RUN_ID`, and then runs the entrypoint.

```
export MLFLOW_TRACKING_URI=sqlite:///mlruns/mlflow.db
mlflow run . -P alpha=0.5
```

should work.",reason run found run local file system run run running set run local file system store id export run work,issue,negative,neutral,neutral,neutral,neutral,neutral
1511200524,"@stealthBanana I think the root cause is a version mismatch between the client and server. The client (airflow) uses MLflow < 2.0, but the server uses MLflow >= 2.0. We removed the `/api/2.0/preview/...` routes in MLflow 2.0. Can you replace `apache/airflow
` with `apache/airflow:latest-python3.8`?",think root cause version mismatch client server client server removed replace,issue,negative,neutral,neutral,neutral,neutral,neutral
1510951420,"@PsionTheory Sorry for the inconvenience, #8244 should be able to fix the issue.",sorry inconvenience able fix issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1510924570,"Looking at my own data it seems this migration would have to amend columns in a few tables:

- runs.artifact_uri
- experiments.artifact_location
- model_versions.source",looking data migration would amend table,issue,negative,neutral,neutral,neutral,neutral,neutral
1509407047,"@WeichenXu123 Great suggestion: I added the env variable. Can you PTAL! I would like to merge this before the mlflow cut on monday.
@sueann 
Following testing was done manually:
1. Create a dev wheel using this PR.
2. Uploaded to a cluster.
3. Tried downloading wheels of a simple sklearn model -> **Successful**.
4. Created a model with requirements that are known to fail (horovod, pyspark, etc).
5. Tried downloading the wheels for the new model using default behaviour.
6. The downloading fails as expected.
7. Used the following steps to set env var
`import os
os.environ[""MLFLOW_WHEELED_MODEL_PIP_DOWNLOAD_OPTIONS""] = ""--prefer-binary""`
9. Tried downloading again -> **Successful**
I can share the model notebook if needed.",great suggestion added variable would like merge cut following testing done manually create dev wheel cluster tried simple model successful model known fail tried new model default behaviour used following set import o tried successful share model notebook,issue,positive,positive,positive,positive,positive,positive
1509007903,Looks like some possibly flakey tests failing for 404's on installing pyspark and mlleap serialization.,like possibly failing serialization,issue,negative,neutral,neutral,neutral,neutral,neutral
1508247244,"> Interesting. yarn install modifies yarn.lock on Windows, but doesn't on Linux

@harupy `YARN_ENABLE_IMMUTABLE_INSTALLS` env might be disabled but using syntax working in shell env only, hence the warning on Windows 🤔. Which change caused it to pass on Windows again?",interesting yarn install might disabled syntax working shell hence warning change pas,issue,negative,positive,neutral,neutral,positive,positive
1508010499,@prithvikannan Applied the `only-latest` label to avoid triggering too many jobs.,applied label avoid many,issue,negative,positive,positive,positive,positive,positive
1507582869,@jinzhang21 finished adding all of the parsing tests (and fixed 2 small edge case parsing bugs). Good to go (provided we're passing with this commit),finished fixed small edge case good go provided passing commit,issue,positive,positive,positive,positive,positive,positive
1507230322,"@Rahul-Shedge 

I am not with the organization I used to work with anymore and I cannot check it, but what I remember is that we just used another format and it worked.",organization used work check remember used another format worked,issue,negative,neutral,neutral,neutral,neutral,neutral
1506987894,"> Could you fix the DCO check?

Should be fixed!",could fix check fixed,issue,negative,positive,neutral,neutral,positive,positive
1506952604,"> @gabrielfu Thanks for the update! I'm not sure why CircleCI jobs have been failing. Can you logout, and log back in on CircleCI as suggested here?
> 
> https://support.circleci.com/hc/en-us/articles/12504745606171-Why-am-I-seeing-the-Could-not-find-a-usable-config-yml-you-may-have-revoked-the-CircleCI-OAuth-app-message?utm_source=google&utm_medium=sem&utm_campaign=sem-google-dg--japac-en-dsa-tROAS-auth-brand&utm_term=g_-_c__dsa_&utm_content=&gclid=CjwKCAjw0N6hBhAUEiwAXab-TQGjLkXy9mvV42d83epe7VbRubjzgXMGOkzrZqptwMIH4QS47ZCpyRoCdPkQAvD_BwE

Thanks :) i just pushed new commits, looks like they're running now ",thanks update sure failing log back thanks new like running,issue,positive,positive,positive,positive,positive,positive
1506933145,"@gabrielfu Thanks for the update! I'm not sure why CircleCI jobs have been failing. Can you logout, and log back in on CircleCI as suggested here?

https://support.circleci.com/hc/en-us/articles/12504745606171-Why-am-I-seeing-the-Could-not-find-a-usable-config-yml-you-may-have-revoked-the-CircleCI-OAuth-app-message?utm_source=google&utm_medium=sem&utm_campaign=sem-google-dg--japac-en-dsa-tROAS-auth-brand&utm_term=g_-_c__dsa_&utm_content=&gclid=CjwKCAjw0N6hBhAUEiwAXab-TQGjLkXy9mvV42d83epe7VbRubjzgXMGOkzrZqptwMIH4QS47ZCpyRoCdPkQAvD_BwE",thanks update sure failing log back,issue,negative,positive,positive,positive,positive,positive
1506884019,"@BenWilson2  Sorry I am not an professional programmer, so have little knowledge on how to write code or unit tests to verify it. I can only report it by this way to see if other users also met this issue.",sorry professional programmer little knowledge write code unit verify report way see also met issue,issue,negative,negative,negative,negative,negative,negative
1506839385,"@Khawaja261 I think https://github.com/mlflow/mlflow/issues/8176#issuecomment-1498324665 should address your issue. But if you still find issues after adopting my suggestion, feel free to reopen this ticket :)",think address issue still find suggestion feel free reopen ticket,issue,positive,positive,positive,positive,positive,positive
1506804559,@gabrielfu can you rebase on master? That should fix the test failures.,rebase master fix test,issue,negative,neutral,neutral,neutral,neutral,neutral
1506406800,"> @sunishsheth2009 any objections to having a card not populated so that we don't have to have shap as a hard dependency?

I think this makes sense. Maybe we should add it here in that case: https://github.com/mlflow/recipes-examples/blob/main/requirements.txt ",card shap hard dependency think sense maybe add case,issue,negative,negative,negative,negative,negative,negative
1506221530,Hi @foster thanks for the contribution! Sorry for the delay on initiating CI for this PR :) Please ping me directly on this PR if you have another commit that you'd like tested!,hi foster thanks contribution sorry delay please ping directly another commit like tested,issue,positive,negative,neutral,neutral,negative,negative
1506115095,"@amesar I took a look at swagger, that would definitely be nice, though I haven't looked in deep enough to see how it could be implemented on the lower level. Would the best way to currently tackle this issue be to update the `service.proto` and `rest-api.rst` files ? Let me know what you think",took look swagger would definitely nice though deep enough see could lower level would best way currently tackle issue update let know think,issue,positive,positive,positive,positive,positive,positive
1506112510,"The exception is being thrown from pytorch. We simply rely on their serialization utilities to store model artifacts. 
What sort of additional information did you need to save that is incompatible with the native pytorch save functionality?",exception thrown simply rely serialization store model sort additional information need save incompatible native save functionality,issue,positive,neutral,neutral,neutral,neutral,neutral
1506110631,"I think this is a great idea. Please ping when your PR is ready (and make sure that the user gets alerted to the fact that there were invalid paths that need manual cleanup, while not aborting the gc operation)",think great idea please ping ready make sure user fact invalid need manual cleanup operation,issue,positive,positive,positive,positive,positive,positive
1506109060,@sunishsheth2009 any objections to having a card not populated so that we don't have to have shap as a hard dependency?,card shap hard dependency,issue,negative,negative,negative,negative,negative,negative
1505869303,"Additional work needs to be done in order to have this state change tracked, but I did want to get something into the webpage so that at least there is some way to resize the pane, even if it isn't stored in the local state. I just realized that I had  said ""yes"" for willingness to contribute, which I am, but I'm also not really a React developer so the full implementation might be a bit out of my wheelhouse. But if someone can help give me some pointers I'd be happy to keep contributing here.",additional work need done order state change tracked want get something least way resize pane even local state said yes willingness contribute also really react developer full implementation might bit wheelhouse someone help give happy keep,issue,positive,positive,positive,positive,positive,positive
1505726313,"@harupy added a test, could you take another look?",added test could take another look,issue,negative,neutral,neutral,neutral,neutral,neutral
1505677573,"There is a workaround if one is **not** using evaluators or recipies where shap/numba is imported. The rc of numba is unstable, especially on windows, importing shap fails. So, would not recommend this if you are using shap in any way beyond testing the numba rc.

`python -m pip install mlflow 'numba>=0.57.0rc1'`

https://github.com/numba/numba/issues/8841",one unstable especially shap would recommend shap way beyond testing python pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
1505611030,"> @jmahlik 🤔 we should make sure that the solution to this issue will be both well working and intuitive to use. We will try to engage a UX designer and get some guidelines on how to solve this properly, then get back to this thread with some ideas

That would be awesome. #8180 is not a good solution IMO, more an example of pitfalls.",make sure solution issue well working intuitive use try engage designer get solve properly get back thread would awesome good solution example,issue,positive,positive,positive,positive,positive,positive
1505560828,"Interesting! Please let us know what you come up with (whether this is a behavior that is exclusive to sqlite or not) by validating the behavior with the FileStore backend when implementing unit tests as well. The current test suites for mlflow gc don't seem to have all of the nuanced coverage that your validation is showing. If you could update them with validation of this exact behavior (with logging multiple experiments, multiple runs per experiment) to ensure that the gc operation is handling each edge case, that would be great! 
Ping us when your PR is ready and we'll be sure to get it reviewed quickly. Thank you!",interesting please let u know come whether behavior exclusive behavior unit well current test seem coverage validation showing could update validation exact behavior logging multiple multiple per experiment ensure operation handling edge case would great ping u ready sure get quickly thank,issue,positive,positive,positive,positive,positive,positive
1505551522,"It does :) We might want to think about the maximum size allowable so that the right pane, when resized, doesn't become unusable. Looking forward to your contribution! Thanks again :) ",might want think maximum size allowable right pane become unusable looking forward contribution thanks,issue,negative,positive,positive,positive,positive,positive
1505484738,"I can confirm that the warning no longer appears with the latest version. 

It was probably fixed in https://github.com/mlflow/mlflow/pull/5286, which was released in version 1.25.0.",confirm warning longer latest version probably fixed version,issue,negative,positive,positive,positive,positive,positive
1505396692,"@jmahlik 
🤔 we should make sure that the solution to this issue will be both well working and intuitive to use. We will try to engage a UX designer and get some guidelines on how to solve this properly, then get back to this thread with some ideas",make sure solution issue well working intuitive use try engage designer get solve properly get back thread,issue,positive,positive,positive,positive,positive,positive
1505204581,"Hi @BenWilson2, thanks for the quick reply! Yes, I was thinking a simple option where if you hover over the line that separates the sidebar from the display, it would have the ability to let you drag it to expand or reduce the width, and would save your selection into the browser cache so that it would remember the state when you reload the app. 
So that would turn the mouse icon into something like: 
![image](https://user-images.githubusercontent.com/33383515/231458768-d5046586-264a-4b37-bf95-fa46cd019c49.png)

And the draggable interface would be the part highlighted yellow in this picture.
![Screenshot 2023-04-12 at 8 32 14 AM](https://user-images.githubusercontent.com/33383515/231459597-5b83919b-e581-4641-a905-3b0692b4aabd.png)

Does that sound like a reasonable approach?

",hi thanks quick reply yes thinking simple option hover line separate display would ability let drag expand reduce width would save selection browser cache would remember state reload would turn mouse icon something like image interface would part yellow picture sound like reasonable approach,issue,positive,positive,positive,positive,positive,positive
1504822466,"I'm running the following code in devbox to test this PR:

```python
import tempfile
import urllib

import torch
from PIL import Image
from torchvision import transforms

import mlflow


def log_and_load_large_model():
    """"""
    Log a large model to MLflow and load it back, and ensure that the loaded model is the same as the
    original model by comparing the output of the model on a sample input.
    """"""
    model = torch.hub.load(""pytorch/vision:v0.10.0"", ""resnet152"", pretrained=True)
    model.eval()

    with tempfile.TemporaryDirectory() as tmpdir:
        url = ""https://github.com/pytorch/hub/raw/master/images/dog.jpg""
        filepath = f""{tmpdir}/dog.jpg""
        try:
            urllib.URLopener().retrieve(url, filepath)
        except:
            urllib.request.urlretrieve(url, filepath)

        input_image = Image.open(filepath)

    preprocess = transforms.Compose(
        [
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ]
    )
    input_tensor = preprocess(input_image)
    input_batch = input_tensor.unsqueeze(0)  # create a mini-batch as expected by the model

    with torch.no_grad():
        output = model(input_batch)

    with mlflow.start_run():
        print(""Logging model"")
        info = mlflow.pytorch.log_model(model, ""model"", pip_requirements=[""torch""])
        print(""Loading model"")
        loaded_model = mlflow.pytorch.load_model(info.model_uri)

    output_loaded = loaded_model(input_batch)
    print(""Comparing output"")
    assert torch.equal(output, output_loaded)


def main():
    mlflow.set_tracking_uri(""databricks"")
    mlflow.set_experiment(""/Users/harutaka.kawamura@databricks.com/test"")
    # Need some attempts to reproduce the issue
    for i in range(10):
        log_and_load_large_model()


if __name__ == ""__main__"":
    main()
```

This script _**sometimes**_ fails with the following error:

```python
concurrent.futures.process._RemoteTraceback:
""""""
Traceback (most recent call last):
  File ""/home/harutakakawamura/miniconda3/lib/python3.10/site-packages/urllib3/response.py"", line 444, in _error_catcher
    yield
  File ""/home/harutakakawamura/miniconda3/lib/python3.10/site-packages/urllib3/response.py"", line 567, in read
    data = self._fp_read(amt) if not fp_closed else b""""
  File ""/home/harutakakawamura/miniconda3/lib/python3.10/site-packages/urllib3/response.py"", line 533, in _fp_read
    return self._fp.read(amt) if amt is not None else self._fp.read()
  File ""/home/harutakakawamura/miniconda3/lib/python3.10/http/client.py"", line 465, in read
    s = self.fp.read(amt)
  File ""/home/harutakakawamura/miniconda3/lib/python3.10/socket.py"", line 705, in readinto
    return self._sock.recv_into(b)
  File ""/home/harutakakawamura/miniconda3/lib/python3.10/ssl.py"", line 1274, in recv_into
    return self.read(nbytes, buffer)
  File ""/home/harutakakawamura/miniconda3/lib/python3.10/ssl.py"", line 1130, in read
    return self._sslobj.read(len, buffer)
ssl.SSLError: [SSL: DECRYPTION_FAILED_OR_BAD_RECORD_MAC] decryption failed or bad record mac (_ssl.c:2548)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/harutakakawamura/miniconda3/lib/python3.10/site-packages/requests/models.py"", line 816, in generate
    yield from self.raw.stream(chunk_size, decode_content=True)
  File ""/home/harutakakawamura/miniconda3/lib/python3.10/site-packages/urllib3/response.py"", line 628, in stream
    data = self.read(amt=amt, decode_content=decode_content)
  File ""/home/harutakakawamura/miniconda3/lib/python3.10/site-packages/urllib3/response.py"", line 566, in read
    with self._error_catcher():
  File ""/home/harutakakawamura/miniconda3/lib/python3.10/contextlib.py"", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File ""/home/harutakakawamura/miniconda3/lib/python3.10/site-packages/urllib3/response.py"", line 455, in _error_catcher
    raise SSLError(e)
urllib3.exceptions.SSLError: [SSL: DECRYPTION_FAILED_OR_BAD_RECORD_MAC] decryption failed or bad record mac (_ssl.c:2548)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/harutakakawamura/miniconda3/lib/python3.10/concurrent/futures/process.py"", line 246, in _process_worker
    r = call_item.fn(*call_item.args, **call_item.kwargs)
  File ""/home/harutakakawamura/oss-mlflow/mlflow/utils/file_utils.py"", line 602, in download_chunk
    with cloud_storage_http_request(
  File ""/home/harutakakawamura/oss-mlflow/mlflow/utils/rest_utils.py"", line 326, in cloud_storage_http_request
    return _get_http_response_with_retries(
  File ""/home/harutakakawamura/oss-mlflow/mlflow/utils/rest_utils.py"", line 97, in _get_http_response_with_retries
    return session.request(method, url, **kwargs)
  File ""/home/harutakakawamura/miniconda3/lib/python3.10/site-packages/requests/sessions.py"", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File ""/home/harutakakawamura/miniconda3/lib/python3.10/site-packages/requests/sessions.py"", line 745, in send
    r.content
  File ""/home/harutakakawamura/miniconda3/lib/python3.10/site-packages/requests/models.py"", line 899, in content
    self._content = b"""".join(self.iter_content(CONTENT_CHUNK_SIZE)) or b""""
  File ""/home/harutakakawamura/miniconda3/lib/python3.10/site-packages/requests/models.py"", line 824, in generate
    raise RequestsSSLError(e)
requests.exceptions.SSLError: [SSL: DECRYPTION_FAILED_OR_BAD_RECORD_MAC] decryption failed or bad record mac (_ssl.c:2548)
""""""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""/home/harutakakawamura/oss-mlflow/b.py"", line 62, in <module>
    main()
  File ""/home/harutakakawamura/oss-mlflow/b.py"", line 58, in main
    log_and_load_large_model()
  File ""/home/harutakakawamura/oss-mlflow/b.py"", line 47, in log_and_load_large_model
    loaded_model = mlflow.pytorch.load_model(info.model_uri)
  File ""/home/harutakakawamura/oss-mlflow/mlflow/pytorch/__init__.py"", line 743, in load_model
    local_model_path = _download_artifact_from_uri(artifact_uri=model_uri, output_path=dst_path)
  File ""/home/harutakakawamura/oss-mlflow/mlflow/tracking/artifact_utils.py"", line 100, in _download_artifact_from_uri
    return get_artifact_repository(artifact_uri=root_uri).download_artifacts(
  File ""/home/harutakakawamura/oss-mlflow/mlflow/store/artifact/runs_artifact_repo.py"", line 125, in download_artifacts
    return self.repo.download_artifacts(artifact_path, dst_path)
  File ""/home/harutakakawamura/oss-mlflow/mlflow/store/artifact/artifact_repo.py"", line 260, in download_artifacts
    inflight_download.download_future.result()
  File ""/home/harutakakawamura/miniconda3/lib/python3.10/concurrent/futures/_base.py"", line 458, in result
    return self.__get_result()
  File ""/home/harutakakawamura/miniconda3/lib/python3.10/concurrent/futures/_base.py"", line 403, in __get_result
    raise self._exception
  File ""/home/harutakakawamura/miniconda3/lib/python3.10/concurrent/futures/thread.py"", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
  File ""/home/harutakakawamura/oss-mlflow/mlflow/store/artifact/databricks_artifact_repo.py"", line 767, in _download_file
    self._parallelized_download_from_cloud(
  File ""/home/harutakakawamura/oss-mlflow/mlflow/store/artifact/databricks_artifact_repo.py"", line 426, in _parallelized_download_from_cloud
    failed_downloads = parallelized_download_file_using_http_uri(
  File ""/home/harutakakawamura/oss-mlflow/mlflow/utils/file_utils.py"", line 662, in parallelized_download_file_using_http_uri
    fut.result()
  File ""/home/harutakakawamura/miniconda3/lib/python3.10/concurrent/futures/_base.py"", line 451, in result
    return self.__get_result()
  File ""/home/harutakakawamura/miniconda3/lib/python3.10/concurrent/futures/_base.py"", line 403, in __get_result
    raise self._exception
requests.exceptions.SSLError: [SSL: DECRYPTION_FAILED_OR_BAD_RECORD_MAC] decryption failed or bad record mac (_ssl.c:2548)
```

(To get this error, I added `raise` in a few `except` blocks)

Investigating whether this is relevant to this PR.",running following code test python import import import torch import image import import log large model load back ensure loaded model original model output model sample model try except create model output model print logging model model model torch print loading model print output assert output main need reproduce issue range main script sometimes following error python recent call last file line yield file line read data amt else file line return amt amt none else file line read amt file line return file line return buffer file line read return buffer bad record mac handling exception another exception recent call last file line generate yield file line stream data file line read file line value file line raise bad record mac handling exception another exception recent call last file line file line file line return file line return method file line request resp prep file line send file line content file line generate raise bad record mac exception direct cause following exception recent call last file line module main file line main file line file line file line return file line return file line file line result return file line raise file line run result file line file line file line file line result return file line raise bad record mac get error added raise except investigating whether relevant,issue,negative,negative,neutral,neutral,negative,negative
1504816659,"Suggested change:

* Switch to new API in this line: https://github.com/mlflow/mlflow/blob/master/mlflow/store/artifact/hdfs_artifact_repo.py#L188
* Require at least `2.0.0` pyarrow version in the setup.py",change switch new line require least version,issue,negative,negative,neutral,neutral,negative,negative
1504375013,"The option that you're specifying is inclusive. When you specify a specific run_id (or run_id's) to the `mlflow gc` command, it will append those specified arg values to the existing logic. 
What you're seeing is mlflow gc doing it's job of cleaning up all run_id's that have been marked for deletion (as well as the one that you specified, provided that it is in a marked for deletion state). If you have hundreds (or thousands) of runs marked for deletion, you'll have to wait for the gc operation to finish to see all of the marked runs to be deleted. 

It is working as intended. ",option inclusive specify specific command append logic seeing job cleaning marked deletion well one provided marked deletion state marked deletion wait operation finish see marked working intended,issue,negative,positive,neutral,neutral,positive,positive
1504336154,Can you make sure that your tokens are valid and correct? Can you use them precisely via boto3 externally to MLflow and validate that you have PUT access to minio?,make sure valid correct use precisely via externally validate put access,issue,positive,positive,positive,positive,positive,positive
1504334189,Could you share some ideas on how you would like to resize the pane? We'd love to discuss it with you!,could share would like resize pane love discus,issue,positive,positive,positive,positive,positive,positive
1504295191,Hi @Jingnan-Jia an interesting idea! We'll discuss it internally. Thank you for the feature request!,hi interesting idea discus internally thank feature request,issue,positive,positive,positive,positive,positive,positive
1504110915,"@harupy @ichbinjakes 
Anyway I can help move this along? Looks like it's simply blocked by an easy merge conflict.  I have this PR open https://github.com/ichbinjakes/mlflow/pull/2",anyway help move along like simply blocked easy merge conflict open,issue,positive,positive,positive,positive,positive,positive
1503036604,"Very helpful! 
I think it makes sense to open up a new issue to handle this, because else this conversation will probably get lost in this current topic (on a already merged branch).

I'll try to find some time to make a first setup for this issue, but I am currently very short on spare time..",helpful think sense open new issue handle else conversation probably get lost current topic already branch try find time make first setup issue currently short spare time,issue,negative,positive,neutral,neutral,positive,positive
1503007290,"Hi @BenWilson2, Sure ""Pyenv + VirutalEnv"" and other supported environments (conda, docker, local) work fine as expected. 

The problem is that MLflow does not support the specification of multiple environment fields in the MLproject file. 

This means if you create a pipeline that uses an MLproject alongside multiple environment fields that support this project.   To run this pipeline on any of the env (with the current configuration with MLproject), you have to manually define **only this preferred environment field option in the MLproject file.**

See these examples

**1 - Current Situation**

1.1 - Mlproject file with **one** specified environment field

```bash
name: my-mlflow-mlproject-file

conda_env: my_conda_env.yaml

# python_env: my_python_env.yaml

# docker_env:
#   image: my_docker_image

entry_points:
  main:
    parameters:
      param_1: {type: float, default: 0.5}
      param_2: {type: float, default: 0.1}
    command: ""python train.py --param_1 {param_1} --param_2 {param_2}""
```

1.2 - Run the project
```bash
mlflow run .
```


**2 - Proposed Feature** 

2.1 - Mlproject file with **multiple** specified environment fields

```bash
name: my-mlflow-mlproject-file

conda_env: my_conda_env.yaml

python_env: my_python_env.yaml

docker_env:
   image: my_docker_image

entry_points:
  main:
    parameters:
      param_1: {type: float, default: 0.5}
      param_2: {type: float, default: 0.1}
    command: ""python train.py --param_1 {param_1} --param_2 {param_2}""
```

2.2 - Run the project with any of the env managers.
```bash
mlflow run . --env-manager conda 
```
or

```bash
mlflow run . --env-manager docker 
```",hi sure docker local work fine problem support specification multiple environment file create pipeline alongside multiple environment support project run pipeline current configuration manually define preferred environment field option file see current situation file one environment field bash name image main type float default type float default command python run project bash run feature file multiple environment bash name image main type float default type float default command python run project bash run bash run docker,issue,positive,positive,positive,positive,positive,positive
1502996277,@dbczumar do you have ETA for this? I can try working on that if you can provide guidance,eta try working provide guidance,issue,negative,neutral,neutral,neutral,neutral,neutral
1502985146,"@BenWilson2 
Still broken, this bug makes it impossible to work with MLFlow v1. Is there an alternative way to get to those docs?",still broken bug impossible work alternative way get,issue,negative,negative,negative,negative,negative,negative
1502525203,@cgeller I will close this ticket because I think for now https://github.com/mlflow/mlflow/issues/8132#issuecomment-1495745670 is the best solution and it works. If you have any better idea feel free to reopen the ticket. :),close ticket think best solution work better idea feel free reopen ticket,issue,positive,positive,positive,positive,positive,positive
1502519524,Hi @tamis-laan thank you for bringing this to our attention. We're going to investigate. ,hi thank attention going investigate,issue,negative,neutral,neutral,neutral,neutral,neutral
1502500711,"Hi @adekunleoajayi thank you for filing this FR. 
The general intention of using Pyenv + VirutalEnv is to make the environment reproducible in any location (any hardware, any OS). Does this not meet your needs?",hi thank filing general intention make environment reproducible location hardware o meet need,issue,negative,positive,neutral,neutral,positive,positive
1502494987,We're working on it! #8181 (and the first part is already part of master :)) We sincerely hope that you get some great use from the flavor at the next release! ,working first part already part master sincerely hope get great use flavor next release,issue,positive,positive,positive,positive,positive,positive
1502486294,"![Screen Shot 2023-04-10 at 7 58 28 PM](https://user-images.githubusercontent.com/39283302/231021497-a5790341-2715-4e25-98c0-b7d183e09ce1.png)
Waaaay zoomed out view. This is what you want, right @jerrylian-db ?",screen shot view want right,issue,negative,positive,positive,positive,positive,positive
1502155895,Landed on installing shap for the tests vs. removing it entirely and checking the for error logs. That seems to make more sense.,landed shap removing entirely error make sense,issue,negative,neutral,neutral,neutral,neutral,neutral
1502092786,I'll fix up the failing tests. Would it be worth adding a ci test against python 3.11 at all?,fix failing would worth test python,issue,negative,positive,positive,positive,positive,positive
1502052186,"@foster Thank you for the contribution! Could you fix the following issue(s)?

#### &#x26a0; DCO check

The DCO check failed. Please sign off your commit(s) by following the instructions [here](https://github.com/mlflow/mlflow/runs/12637790479). See https://github.com/mlflow/mlflow/blob/master/CONTRIBUTING.md#sign-your-work for more details.",foster thank contribution could fix following issue check check please sign commit following see,issue,positive,neutral,neutral,neutral,neutral,neutral
1501466209,"I'm also facing the same problem.
As for the case of only ```import mlflow```, it can solve easily with local import. 

However, if a custom model is defined and used, the local import method cannot be used.
```python3
from mlflow.pyfunc import PythonModel, PythonModelContext

# local import cannot available...
class MyInferenceModelV1(PythonModel):
    def __init__(self, *args, **kwargs):
        ...
```
Is there any solution?
",also facing problem case import solve easily local import however custom model defined used local import method used python import local import available class self solution,issue,negative,positive,neutral,neutral,positive,positive
1500941831,"I'm really interested in this one, it would be pretty helpful.
I'm willing also to help and collaborate, is there any progress with this? any help needed?",really interested one would pretty helpful willing also help collaborate progress help,issue,positive,positive,positive,positive,positive,positive
1500242807,"I am pretty much sure I do it correctly though
<img width=""1295"" alt=""image"" src=""https://user-images.githubusercontent.com/19648595/230608104-a3b2d0ae-21a1-4fe0-a599-fe5c4bf00f5d.png"">
<img width=""1346"" alt=""image"" src=""https://user-images.githubusercontent.com/19648595/230608218-11d00514-9372-410e-a4a3-01b4cb0f167d.png"">


",pretty much sure correctly though image image,issue,positive,positive,positive,positive,positive,positive
1500237314,"Are you providing an exact match to the names that you're searching for (it doesn't do a partial match)? As for the error message in the top right, this is a UI bug that we'll be fixing. ",providing exact match searching partial match error message top right bug fixing,issue,negative,positive,positive,positive,positive,positive
1499822319,Hey I'm having the exactly same problem. And I'm having this even though I'm running `mlflow ui` on the jupyter notebook kernel. How did you solve your problem ?,hey exactly problem even though running notebook kernel solve problem,issue,negative,positive,positive,positive,positive,positive
1499684178,"Can you check your syntax in your query?

![Screen Shot 2023-04-06 at 6 07 46 PM](https://user-images.githubusercontent.com/39283302/230502806-3225b7ff-3957-4fe5-80f9-c91b4c55ab18.png)
![Screen Shot 2023-04-06 at 6 08 02 PM](https://user-images.githubusercontent.com/39283302/230502816-0afff6c2-d144-456a-bffa-54c3c5fb526f.png)
",check syntax query screen shot screen shot,issue,negative,neutral,neutral,neutral,neutral,neutral
1499652930,"Ah yes, that makes sense! I am not a maintainer of mlflow, so might make sense to open another issue to assess whether the maintainers are comfortable with the change; I'd be surprised if they weren't. The change isn't particularly ""hard"", but unfortunately there's multiple places to touch...

In case you or someone else wants to implement it, I think what effectively what needs to happen:

- Add the `predict_fn` argument to [pyfunc.log_model](https://github.com/mlflow/mlflow/blob/master/mlflow/pyfunc/__init__.py#L1492)
- Pass `predict_fn` [through to `Model.log`](https://github.com/mlflow/mlflow/blob/master/mlflow/pyfunc/__init__.py#L1615)

From here, `Model.log` will eventually call back into `pyfunc.save_model`and you'll want to thread the `predict_fn` arg down:

- Add `predict_fn` to [pyfunc.save_model](https://github.com/mlflow/mlflow/blob/master/mlflow/pyfunc/__init__.py#L1312); pay attention to the kwargs here, the maintainers may have particular opinions about how to represent new args (e.g. might want you to just parse out of kwargs instead of making explicit arg?)
- Thread `predict_fn` through the [two](https://github.com/mlflow/mlflow/blob/master/mlflow/pyfunc/__init__.py#L1468) [paths](https://github.com/mlflow/mlflow/blob/master/mlflow/pyfunc/__init__.py#L1479) to save the model, all the way through to the calls to `pyfunc.add_to_model` ... [for example here](https://github.com/mlflow/mlflow/blob/93ee3525205ab217db7261552d3190d4bf02f371/mlflow/pyfunc/model.py#L203)

Hope that's helpful!",ah yes sense maintainer might make sense open another issue ass whether comfortable change change particularly hard unfortunately multiple touch case someone else implement think effectively need happen add argument pas eventually call back want thread add pay attention may particular represent new might want parse instead making explicit thread two save model way example hope helpful,issue,positive,positive,positive,positive,positive,positive
1499492524,"Yes you're right. 
Basically our usecase is as follows:

We've created a custom class:


```
class CustomModelWrapper(mlflow.pyfunc.PythonModel):
    """""" Wrapper class to store arbitrary model to mlflow""""""""
    def __init__ (self, model):
        self.model = model
        
    def predict(self, context, model_input: ArrayLike) -> ArrayLike:
    """""" predict class labels  with the trained model""""""
        self.model.predict(model_input)
        
    def predict_proba(self, context, model_input:ArrayLike) -> ArrayLike:
    """""" predict class probabilities with the trained model""""""
      self.model.predict_proba(model_input)
```

We (after some HyperOpt GridSearch) store the model  to MLflow (which is an SKlearn pipeline object with an estimator as its final step) with:
```
best_model_pipeline = .... # performs some hyperparameter search optimalisation
model = CustomModelWrapper(best_model_pipeline)
mlflow.pyfunc.log_model('model_name', python_model=model, conda_env=... signature=...)
```

Loading the model is done via:
```
...
model_uri = f""models:/{model_name}/{version}""
model = mlflow.pyfunc.load_model(model_uri=model_uri, dst_path=dst_path)
````


So yes, our current work-around is to overwrite the `.predict()` method of the `CustomModelWrapper` to return `self.model.predict_proba(model_input)`, but I think it would be nicer if we can still have our custom class, which will then have both support for a `.predict()` and `.predict_proba()` method, and then have our MLflow Model specification determine which of the predict- methods we will use by default, after loading up our model. 
",yes right basically custom class class wrapper class store arbitrary model self model model predict self context predict class trained model self context predict class trained model store model pipeline object estimator final step search model loading model done via version model yes current overwrite method return think would still custom class support method model specification determine use default loading model,issue,positive,positive,neutral,neutral,positive,positive
1499463994,"Hi folks, the 2.2.1 release notes have been updated to reference the GitHub Security Advisories, which refer to the CVEs and provide additional context. The `mlflow-users` group and Slack channel were contacted as soon as the security advisories were disclosed.

MLflow 1.30.1 was released yesterday, which patches these security vulnerabilities for the 1.30 series: https://pypi.org/project/mlflow/1.30.1/.

Thank you for using MLflow!",hi release reference security refer provide additional context group slack channel soon security disclosed yesterday security series thank,issue,positive,neutral,neutral,neutral,neutral,neutral
1499459489,"MLflow has issued GitHub Security Advisories: 
- https://github.com/mlflow/mlflow/security/advisories/GHSA-xg73-94fp-g449 (critical severity)
- https://github.com/mlflow/mlflow/security/advisories/GHSA-wp72-7hj9-5265 (moderate severity)

_Disclaimer: I'm not an MLflow maintainer._",security critical severity moderate severity,issue,negative,neutral,neutral,neutral,neutral,neutral
1499331566,"Could someone please update the release notes to include mention of the CVEs? I don't know if / where announcements are sent out for this project, but a 10 is typically justification for broad disclosure and an urge to upgrade immediately.",could someone please update release include mention know sent project typically justification broad disclosure urge upgrade immediately,issue,negative,negative,neutral,neutral,negative,negative
1499182651,"Hey @RooieRakkert , thanks for the question.

When I put together this PR, it appears I neglected to provide a straight-forward path for your use case. I think we would similarly need to add `predict_fn` as an argument to `mlflow.pyfunc.log_model`. It is available when you call `mlflow.pyfunc.add_to_model`. So I think this would need to be added to `mlflow.pyfunc.log_model`

I'd be a bit curious to learn a little more about your use case though. In the case that you are using the direct form of `mlflow.pyfunc.log_model`, I would think you have a custom class, where you control which method is ""predict"" and perhaps have less of a problem, so I may be missing something.

Could you share a little more detail about the object you are trying to log?",hey thanks question put together provide path use case think would similarly need add argument available call think would need added bit curious learn little use case though case direct form would think custom class control method predict perhaps le problem may missing something could share little detail object trying log,issue,negative,positive,neutral,neutral,positive,positive
1499093907,"I've stumbled upon this thread after facing issues using the predict_proba of a model, loaded from MLflow.

I've noticed that the  source code for `load_model` [here](https://mlflow.org/docs/latest/_modules/mlflow/pyfunc.html#load_model) tries to find a `predict_fn` within its `conf` (which I assume is the model metadata configuration for the specified FLAVOR_NAME). It will return a `PyFuncModel` object, which indeed can [take a](https://www.mlflow.org/docs/latest/python_api/mlflow.pyfunc.html#mlflow.pyfunc.PyFuncModel) `predict_fn` kwarg.

However, I did not find any documentation on where I can actually **_set_** the `predict_fn` _during the storage of the model to MLflow_. Neither the `mlflow.pyfunc.log_model()` or `mlflow.pyfunc.save_model()` has any argument that seems to hold this configuration. The only reference to this additional kwarg can be found [here](https://www.mlflow.org/docs/latest/python_api/mlflow.sklearn.html#mlflow.sklearn.log_model), in the `mlflow.sklearn.log_model()`. Here, we can pass it to the `pyfunc_predict_fn` arg.

However, we are not logging a sklearn model, thus we're using the `mlflow.pyfunc.log_model()` functionality to log our model to mlflow. I would assume this kwarg to also be present there, but it is not. 

So my question comes down to; how do I store a custom model to MLflow, whilst also passing the appropriate `predict_fn`, in such a way that after loading of the stored model it will be using this custom `predict_fn` by default?
",upon thread facing model loaded source code find within assume model configuration return object indeed take however find documentation actually storage model neither argument hold configuration reference additional found pas however logging model thus functionality log model would assume also present question come store custom model whilst also passing appropriate way loading model custom default,issue,negative,positive,positive,positive,positive,positive
1498423063,"Hi Weichen,

Just to clarify. I won't be able to create any PR for this anytime soon.
It was more like I was asking if you have such feature.

Regards,
Jacob

On Thu, 6 Apr 2023, 12:32 pm WeichenXu, ***@***.***> wrote:

> Thanks for reporting this FR ! It is a very meaningful feature, Exciting
> to see your PR !
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/mlflow/mlflow/issues/8175#issuecomment-1498407399>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AC33V5Q7IEJBWBNHN3ZU2XDW7YTNJANCNFSM6AAAAAAWTWOETY>
> .
> You are receiving this because you authored the thread.Message ID:
> ***@***.***>
>
",hi clarify wo able create soon like feature wrote thanks meaningful feature exciting see reply directly view id,issue,positive,positive,positive,positive,positive,positive
1498407399,"Thanks for reporting this FR ! It is a very meaningful feature, Exciting to see your PR !",thanks meaningful feature exciting see,issue,positive,positive,positive,positive,positive,positive
1498324665,"@Khawaja261 

I think your command has an issue:

If we use `--serve-artifacts`, we should set `--artifacts-destination` option correspondingly, if we use `--no-serve-artifacts`, then we should set `--default-artifact-root`, could you try it ? Thank you.
",think command issue use set option correspondingly use set could try thank,issue,negative,neutral,neutral,neutral,neutral,neutral
1498309505,"Hi @Khawaja261 ,

The string format looks problematic: `mlflow server --port 4000 --host 0.0.0.0 --backend-store-uri ""://:@:/"" --default-artifact-root ""hdfs://<>host:<>port/<>path/"" --serve-artifacts`, could you fix it ? Thank you. ",hi string format problematic server port host host could fix thank,issue,negative,neutral,neutral,neutral,neutral,neutral
1498298646,"We need to convert TensorSpec to spark schema, i.e., we need to flatten the tensor to one dimension array",need convert spark schema need flatten tensor one dimension array,issue,negative,neutral,neutral,neutral,neutral,neutral
1497934542,"One little wrinkle is that currently `TensorSpec` doesn't produce valid spark schemas. I think this can be made to work with a multi-dimensional spark array (of floats, doubles, etc.) - depending on the dimensionality of the `TensorSpec`. ",one little wrinkle currently produce valid spark think made work spark array depending dimensionality,issue,negative,negative,neutral,neutral,negative,negative
1497817343,@sunishsheth2009 an example PR in #8180 if you want to take a look.,example want take look,issue,negative,neutral,neutral,neutral,neutral,neutral
1497656870,@jcuquemelle Thanks for the contribution! The DCO check failed. Please sign off your commits by following the instructions here: https://github.com/mlflow/mlflow/runs/12542307820. See https://github.com/mlflow/mlflow/blob/master/CONTRIBUTING.rst#sign-your-work for more details.,thanks contribution check please sign following see,issue,positive,positive,neutral,neutral,positive,positive
1496936650,"Since we're committed to protobuf, I guess the REST->Python stub generation for docs isn't going to fly. But this would be nice: https://swagger.io/tools/swagger-codegen/
",since guess python stub generation going fly would nice,issue,negative,positive,positive,positive,positive,positive
1496934881,"I don't think its a backend issue. The issues are not specific to backends, just general user-facing doc for the contract. Granted its not easy, since I assume we're grabbing the Python doc from docstrings. How to sync with the REST API then? Maybe Open API (Swagger) could help since I believe it can generate language-specific stubs. I would assume the original REST doc would also be transferred into the Python stubs. Just thinking aloud.
",think issue specific general doc contract easy since assume python doc sync rest maybe open swagger could help since believe generate would assume original rest doc would also transferred python thinking aloud,issue,positive,positive,positive,positive,positive,positive
1496846091,"Current result_type default value is ""double"", we should change the default value to be ""auto inferred"", and check if there's model output schema, we can generate correct return type, otherwise we use default ""double"" type. Feel free to file a PR and I will review it. Thank you!",current default value double change default value auto check model output schema generate correct return type otherwise use default double type feel free file review thank,issue,positive,positive,neutral,neutral,positive,positive
1496841633,Make sense! I think this is doable. Let me check details and get back to you.,make sense think doable let check get back,issue,negative,neutral,neutral,neutral,neutral,neutral
1496807024,"Then could you provide following info ?
* Inference dataset sample
* Model signature ( you can get it via `loaded_model.signature.to_dict()` )",could provide following inference sample model signature get via,issue,negative,neutral,neutral,neutral,neutral,neutral
1496710122,"> I think we can create 2 PRs for #8060 and #8059
> 
> I feel PR for #8060 might need more discussion but it does not need to block the other PR.

hey @WeichenXu123, alright sure. let me do that.

pls ignore this PR for now, i realised that there are more areas that needs to change for #8060 if not tests will fail. open for discussion if #8060 should proceed or not!",think create feel might need discussion need block hey alright sure let ignore need change fail open discussion proceed,issue,negative,neutral,neutral,neutral,neutral,neutral
1496616431,"Any progress on this front? I am using [this](https://pypi.org/project/dynaflow/) package, but it is not compatible with mlflow v2.0+.  It would be convenient if mlflow was compatible with K/V stores. ",progress front package compatible would convenient compatible,issue,negative,neutral,neutral,neutral,neutral,neutral
1495988699,@wolfier  I would really love to see this fixed. Can I help you somehow? I've been trying workarounds but nothing works. ,would really love see fixed help somehow trying nothing work,issue,positive,positive,positive,positive,positive,positive
1495917009,"I think we can create 2 PRs for https://github.com/mlflow/mlflow/issues/8060 and  https://github.com/mlflow/mlflow/issues/8059

I feel PR for https://github.com/mlflow/mlflow/issues/8060 might need more discussion but it does not need to block the other PR.",think create feel might need discussion need block,issue,negative,neutral,neutral,neutral,neutral,neutral
1495842067,"I have written the code after deploying the model by MLFlow. If I give you the code still it won't work because model is not available.
data I have passed given below

`newtext = [""visit www.bet365.com for a free trial""]`

",written code model give code still wo work model available data given visit free trial,issue,positive,positive,positive,positive,positive,positive
1495745670,"@cgeller 

> ""Sync one experiment run (including all of its metrics/artifacts/params/tags) to another MLflow server""

For this solution we hit an issue: Current rest API cannot support create experiment run with specified `run_id`, (and supporting this is not agreed by mlflow core team members), so if we want to exactly sync one run to remote server, we have to directly insert data into remote server database (which is hacky and risky)

So for now, the best solution should be:

Using Mlflow client API, construct MlflowClient with the remote server tracking URI,
then create a new run with `client.create_run()`, then within the run call `client.log_artifacts()` to upload locally logged model artifacts to remote server, and then call client.register_model() (or you can register the model on remote server web UI)",sync one experiment run another server solution hit issue current rest support create experiment run supporting agreed core team want exactly sync one run remote server directly insert data remote server hacky risky best solution client construct remote server create new run within run call locally logged model remote server call register model remote server web,issue,positive,positive,positive,positive,positive,positive
1495736453,"Hi @DevDaring 
Could you create a python script that can reproduce the error? Please make sure that just running the script is runnable via `python <script_name>.py`

Thank you!",hi could create python script reproduce error please make sure running script runnable via python thank,issue,positive,positive,positive,positive,positive,positive
1495700241,"I have raised a more precise and new issue: https://github.com/mlflow/mlflow/issues/8168
Closing this one. ",raised precise new issue one,issue,negative,positive,positive,positive,positive,positive
1495435157,"@WeichenXu123 @amesar I'm willing to work on this issue. If the short term solution/consensus is to update the docs to be consistent/synced on both sides (Python API, REST API), I can tackle this (although I do agree with @amesar that entering the docs in two places is error prone). Let me know !",willing work issue short term update side python rest tackle although agree entering two error prone let know,issue,negative,positive,positive,positive,positive,positive
1495435151,"> LGTM (assuming we won't release pyspark 3.3.3)!

Or assuming that 3.3.3 fixes pandas compatibility :D",assuming wo release assuming compatibility,issue,negative,neutral,neutral,neutral,neutral,neutral
1495365714,@harupy @WeichenXu123 Serving tests were still failing because the spark conda env doesn't pin pandas for old PySpark versions. I've updated the PR to fix that. Can you take another look?,serving still failing spark pin old fix take another look,issue,negative,positive,neutral,neutral,positive,positive
1495335536,"@amesar 

> If you have logged more than one model artifact in a run, the ""Source Run"" field of the Model Version UI page always links to the last model artifact in the Run UI page.

The ""Source Run"" field just links to the run. The run page makes it look like it links to the last model artifact.

<img width=""1045"" alt=""Screen Shot 2023-04-04 at 13 33 23"" src=""https://user-images.githubusercontent.com/17039389/229689087-a2434abd-a1f4-4246-a0fa-c78fbad175f8.png"">

Never mind, @WeichenXu123 already found this.
",logged one model artifact run source run field model version page always link last model artifact run page source run field link run run page look like link last model artifact screen shot never mind already found,issue,negative,neutral,neutral,neutral,neutral,neutral
1495205794,"I synced with our techlead, we’re investigating this, please stay tuned for future updates :)  CC @dbczumar ",investigating please stay tuned future,issue,negative,neutral,neutral,neutral,neutral,neutral
1495136477,@harupy Sure I will add unit test. Manually tests already passed.,sure add unit test manually already,issue,negative,positive,positive,positive,positive,positive
1494698111,@WeichenXu123 this is absolutely not the same as the histogram feature in WandB or Tensorboard which both can be used to plot very large weight/grad tensors as hist plots,absolutely histogram feature used plot large hist,issue,negative,positive,positive,positive,positive,positive
1494332967,"@ketangangal 

- What is your browser?
- Does the console tab in the browser devtools show anything?
- What does the HTML of the button look like?

<img width=""737"" alt=""image"" src=""https://user-images.githubusercontent.com/17039389/229525373-54b6942c-e26d-4ea4-a53a-ccf40a4faea3.png"">
",browser console tab browser show anything button look like image,issue,negative,neutral,neutral,neutral,neutral,neutral
1494308950,I fully agree with you. Such functionality would be clear and fulfil all our use case demands.,fully agree functionality would clear use case,issue,positive,positive,positive,positive,positive,positive
1494265792,"> Do you see a way to automatically call a custom method when registering a method via the UI?

I prefer to add an UI button like: ""Sync one experiment run (including all of its metrics/artifacts/params/tags) to another MLflow server"", this way makes the functionality more clear. Then in another MLflow server you can register the model via UI.",see way automatically call custom method method via prefer add button like sync one experiment run another server way functionality clear another server register model via,issue,positive,positive,positive,positive,positive,positive
1494255851,"Thanks a lot, this would be amazing.

Do you see a way to automatically call a custom method when registering a method via the UI?",thanks lot would amazing see way automatically call custom method method via,issue,positive,positive,positive,positive,positive,positive
1494247985,"Got it. 

> Instead, the developer could upload the desired experiment run to the central-server

I think I can provide a utility method to do this. If an experiment Run is logged locally, we can upload its metrics / params/ tags/ artifacts to specified central server.
Let me discuss it with my teammates.


> without logging/training the model again.

We can avoid training twice, using above paragraph solution. But avoiding logging twice is an overkill request I think, logging locally does not bring too much overhead.

> I'm thinking of a solution where the Experiments tab manages all local experiment runs, and the Models tab manages all remote, registered models. This would include an artifact upload during the registering process, instead ""just"" linking to an already existing experiment run.

This is a much bigger feature request, we need more discussion before doing it. :)


",got instead developer could desired experiment run think provide utility method experiment run logged locally metric central server let discus without model avoid training twice paragraph solution logging twice request think logging locally bring much overhead thinking solution tab local experiment tab remote registered would include artifact process instead linking already experiment run much bigger feature request need discussion,issue,positive,positive,neutral,neutral,positive,positive
1494232094,"Not sure I understand this correctly, but I think you can use metric ""step"" to simulate the time axix.

e.g., the following simple code:

```
with mlflow.start_run() as run:
    for i in range(100):
        mlflow.log_metric(""aa"", i / 100, i)
```
It logs 100 times ""aa"" metric with step 0, 1, ... until 100,
and then you can view the plot of aa metric from mlflow UI like:

<img width=""1557"" alt=""image"" src=""https://user-images.githubusercontent.com/19235986/229508818-0e2e7ee0-6004-48ad-91ba-62ba94d1c6ca.png"">
",sure understand correctly think use metric step simulate time following simple code run range aa time aa metric step view plot aa metric like image,issue,positive,positive,positive,positive,positive,positive
1494225062,This issue is not fixed. Still present with latest mlflow + latest airflow,issue fixed still present latest latest,issue,negative,positive,positive,positive,positive,positive
1493961625,"The model version source https://github.com/mlflow/mlflow/blob/8622d73aa75423c839f02fbe21d0a66673ef5d3d/mlflow/server/js/src/model-registry/components/ModelVersionView.js#L320 is a link like:

`http://localhost:3000/#/experiments/0/runs/94bf8e51c0b545aabeff2c9ce4e3c8c8`

Such link page always highlight the latest model in a run.",model version source link like link page always highlight latest model run,issue,positive,positive,positive,positive,positive,positive
1493916819,"Hi @jcuquemelle, we sent you an email. Could you check your email box?",hi sent could check box,issue,negative,neutral,neutral,neutral,neutral,neutral
1493872591,"Thanks again for your very comprehensive explanation. 

I tried your solution. Using the `register_model` method requires a mlflow `run_id` which has to exist on the mlflow server (in this case the `central-server`). This means that a user has to log the model again when deciding to upload a ""verified, final"" experiment. I think a user wants to ""upload"" an already existing model to the registry, if somehow possible, without logging/training the model again.

Instead, the developer could upload the desired experiment run to the `central-server` and then call the `register_model` method.  However, using the mlflow UI for the ""uploading"" task would be more user-friendly. 

I'm thinking of a solution where the `Experiments` tab manages all local experiment runs, and the `Models` tab manages all remote, registered models. This would include an artefact upload during the registering process, instead ""just"" linking to an already existing experiment run.

Maybe there is another solution for this really common problem?",thanks comprehensive explanation tried solution method exist server case user log model final experiment think user already model registry somehow possible without model instead developer could desired experiment run call method however task would thinking solution tab local experiment tab remote registered would include artefact process instead linking already experiment run maybe another solution really common problem,issue,positive,negative,neutral,neutral,negative,negative
1493685412,"> Since the Python API depends upon the REST API

I think it is not so simple, basically, we have 3 kinds of backends:

- file store
- database store
- remote MLflow server backend

Only for the case ""remote MLflow server backend"", the python client will invoke rest APIs.",since python upon rest think simple basically file store store remote server case remote server python client invoke rest,issue,negative,negative,neutral,neutral,negative,negative
1493680175,"Thanks for reporting this, let me check them and get back to you.",thanks let check get back,issue,negative,positive,neutral,neutral,positive,positive
1493602923,"~hey mlflow, i tried pushing my changes to my branch but run into this error~

~is there something i need to do before i can commit anything? thanks!~",tried pushing branch run something need commit anything thanks,issue,positive,positive,positive,positive,positive,positive
1493512623,"@rileyhun, How did you resolve this? I'm experiencing the same issue, specifically ""Booting worker with pid: {##}"".",resolve issue specifically booting worker,issue,negative,neutral,neutral,neutral,neutral,neutral
1493316045,"@cgeller 

I consider your use case again, we have a simpler solution for this case:

1. launch a central MLflow server (command like: `mlflow server  --serve-artifacts`) that is accessible by all developer workstation. Supposing the tracking URI for this server is: `http://central-server-ip:5000`
2. For each workstation user, by default, they will create experiment and log artifacts locally, but, if an user needs to register a model to the central MLflow server, he can write code like:

```
from mlflow.tracking._tracking_service.utils import _use_tracking_uri

with _use_tracking_uri('http://central-server-ip:5000'):
  with mlflow.start_run() as run:
    run_id = run.info.run_id
    mlflow.sklearn.log_model(sklearn_model, artifact_path)  # log model to the central server
    mlflow.register_model(f""runs:/{run_id}/{artifact_path}"", registered_model_name)  # register the just logged model to central server
```

But note the `_use_tracking_uri` is a developer API. @dbczumar Can we make it to be a public API so that it makes user easier in this case ?

Another option is you can use MLflow client API. Like:

```
from mlflow.tracking.client import MlflowClient
client = MlflowClient(tracking_uri='http://central-server-ip:5000')
client.log_artifacts(...) # log model artifacts
client.create_registered_model(...)
client.client.create_model_version(...)
```
But this way we cannot use the API of `mlflow.<flavor>.log_model` to log model, which makes the solution inconvenient.",consider use case simpler solution case launch central server command like server accessible developer supposing server user default create experiment log locally user need register model central server write code like import run log model central server register logged model central server note developer make public user easier case another option use client like import client log model way use flavor log model solution inconvenient,issue,positive,negative,neutral,neutral,negative,negative
1492907228,"I think such a function and storing the whole model artifacts when registering a model would be a great feature for all of us. I`m not familiar with the current mlflow implementation, so it's hard to evaluate the feasibility.",think function whole model model would great feature u familiar current implementation hard evaluate feasibility,issue,positive,positive,positive,positive,positive,positive
1492771786,"A script to reproduce the error and verify the fix works properly:

```python
import requests


def augmented_raise_for_status(response):
    try:
        response.raise_for_status()
    except requests.HTTPError as e:
        if response.text:
            raise requests.HTTPError(f""{e}. Response text: {response.text}"")
        else:
            raise e


def fixed_augmented_raise_for_status(response):
    try:
        response.raise_for_status()
    except requests.HTTPError as e:
        if response.text:
            raise requests.HTTPError(
                f""{e}. Response text: {response.text}"", response=response, request=response.request
            )
        else:
            raise e


resp = requests.get(
    ""https://api.github.com/repos/mlflow/mlflow/commits"",
    headers={
        ""Accept"": ""application/vnd.github+json"",
        ""Authorization"": ""Bearer bad-token"",  # <--- bad token, this request should fail with 401
        ""X-GitHub-Api-Version"": ""2022-11-28"",
    },
)

try:
    augmented_raise_for_status(resp)
except requests.HTTPError as e:
    print(e.request)  # None
    print(e.response)  # None

try:
    fixed_augmented_raise_for_status(resp)
except requests.HTTPError as e:
    print(e.request)  # <PreparedRequest [GET]>
    print(e.response)  # <Response [401]>
```",script reproduce error verify fix work properly python import response try except raise response text else raise response try except raise response text else raise resp accept authorization bearer bad token request fail try resp except print none print none try resp except print get print response,issue,negative,negative,negative,negative,negative,negative
1492070678,"@harupy Thank you for the information. I have noticed the same issue. In the above-explained solution, I used the
``/get-artifact`` endpoint. This endpoint is used in the UI to download the artifacts. The endpoint in the _download_file method utilises the ``/api/2.0/mlflow-artifacts/artifacts/...`` endpoint which does not return the ``Content-Length``(as you stated). To solve this problem I have now changed the request to the ``/get-artifact`` endpoint. We still call the http_request function but now just to a different endpoint. I have tested it in the docker container and now all files are downloaded correctly. The fork on which I have implemented the solution is under this URL: [fix_incomplete_download_of_large_artifacts](https://github.com/TobiasRothlin/mlflow/tree/fix_incomplete_download_of_large_artifacts). I have not made a PR at this point since to call the ``/get-artifact`` endpoint I have to reparse the ``endpoint`` and ``self.artifact_uri`` variables which is not the cleanest solution and would like to know if there would be a better way.",thank information issue solution used used method return stated solve problem request still call function different tested docker container correctly fork solution made point since call solution would like know would better way,issue,positive,positive,positive,positive,positive,positive
1492015553,"I think for this use case, we need to add a new option like ""--registry-model-artifact-server"" for Mlflow server CLI.",think use case need add new option like server,issue,negative,positive,positive,positive,positive,positive
1491669375,"@cgeller No, unfortunately :) Artifacts are saved in server's file system (usually the mlrun directory) or cloud storage like s3.",unfortunately saved server file system usually directory cloud storage like,issue,negative,negative,negative,negative,negative,negative
1491658637,"Okay, thanks! So normally also the model artifacts are stored within the sqlite database? So if I transfer the database to a complete new workstation, I should also be able to access the registered models, including the artifacts? This behavior would be desired and also perfectly suitable to our usecase. Thanks for checking!",thanks normally also model within transfer complete new also able access registered behavior would desired also perfectly suitable thanks,issue,positive,positive,positive,positive,positive,positive
1491646513,"Got it . this is an issue, the registry server does not store the model artifacts in this case. Let me check it.",got issue registry server store model case let check,issue,negative,neutral,neutral,neutral,neutral,neutral
1491563034,"Thanks, again! Yes .. but then, in the registry sqlite database only a reference to a source run/experiment is stored. The actual artifacts from the source run/experiment are not included in the database (and therefore on my remote machine), which are required to download and distribute the model. That's my actual problem ..

![Screenshot 2023-03-31 105813](https://user-images.githubusercontent.com/88664444/229075482-adf2b9ed-2dca-4df2-a4ba-fd275f801230.png)
To the source run `link` in a registered model would be empty.
",thanks yes registry reference source actual source included therefore remote machine distribute model actual problem source run link registered model would empty,issue,negative,neutral,neutral,neutral,neutral,neutral
1491545142,"Thanks to the people spending time to answer this thread.

At the time of writing I can confirm that the MLFlow model registry does not work for mounted storage on Databricks in Azure Cloud. Only the default DBFS works with the MLFlow model registry. 

For legislative reasons we cannot use the default DBFS that is hosted on a Microsoft managed ressource group (using public IPs).

This is a dealbreaker that I would have like to have known much earlier. 

There are 2 problems:

1: The MLFLow model registry is incompatible with mounted storage on Azure Cloud
2: This is not clearly described in the documentation.


Speaking in euphemisms, both problems are a big source of frustration.",thanks people spending time answer thread time writing confirm model registry work mounted storage azure cloud default work model registry legislative use default group public would like known much model registry incompatible mounted storage azure cloud clearly documentation speaking big source frustration,issue,positive,positive,neutral,neutral,positive,positive
1491517449,"@cgeller 
> the sqlite database is hosted locally and ""only""

No. You can setup a database on a remote server

> Or are all artifacts of experiments also included in the sqlite database when registering a model?

No. artifacts of experiments are still stored in `backend-store-uri` server (i.e. local server in your case). `registry-store-uri` is for server that only stores registered mode info.
",locally setup remote server also included model still server local server case server registered mode,issue,negative,negative,neutral,neutral,negative,negative
1491486601,"
<!-- documentation preview -->

### Documentation preview will be available [here](https://output.circle-artifacts.com/output/job/5ebadf6c-397a-4e35-b93f-18af21206188/artifacts/0/docs/build/html/index.html).

<details>
<summary>Notes</summary>

- Ignore this comment if this PR does not change the documentation.
- It takes a few minutes for the preview to be available.
- The preview is updated on every commit to this PR.
- Job URL: https://circleci.com/gh/mlflow/mlflow/45225
- Updated at: 2023-04-05 09:06:07.203318

</details>
",documentation preview documentation preview available summary ignore comment change documentation preview available preview every commit job,issue,negative,positive,positive,positive,positive,positive
1491430165,"Thanks a lot for your answer, @WeichenXu123. For my understanding, the sqlite database is hosted locally and ""only"" refers to objects from the backend store-uri? Is this correct? 

Or are all artifacts of experiments also included in the sqlite database when registering a model? So the database can also work `standalone`. Then one can maybe find a way to host a sqlite database on a remote server. Does anybody have already some experiments with that? ",thanks lot answer understanding locally correct also included model also work one maybe find way host remote server anybody already,issue,negative,positive,neutral,neutral,positive,positive
1491392447,"@BenWilson2 Thanks, Ben! I merged the PR (assuming just bumping the versions normally doesn't break anything)",thanks ben assuming bumping normally break anything,issue,negative,positive,positive,positive,positive,positive
1491152548,"Can we set spark config spark.executorEnv.[EnvironmentVariableName] as a workround ?
e.g. if we set spark.executorEnv.ABC  to be value XYZ,
then in spark UDF we can read environment variable ""ABC"" with value ""XYZ""",set spark set value spark read environment variable value,issue,positive,neutral,neutral,neutral,neutral,neutral
1491128994,"@cgeller 

I think you can specify `--registry-store-uri` option for tracking server, acceptable URIs are SQLAlchemy-compatible database connection strings (e.g. 'sqlite:///path/to/file.db'), if `--registry-store-uri`  is not specified, it will use `--backend-store-uri` . :)
",think specify option server acceptable connection use,issue,negative,neutral,neutral,neutral,neutral,neutral
1491010316,"> FYI - I tinkered with this a little bit today and couldn't get any useful output from gnostic (more specifically `protoc-gen-openapi`. I've noticed a couple of things:
> 
> * Syntax is `proto2` which might have issues. I did also try porting over to `proto3` but couldn't get that working correctly either.
> * At the very least, running the tool requires the `.proto` files to have something like `option go_package = ""./"";`. I got all the import tests to pass, but running `protoc model_registry.proto service.proto -I=. --openapi_out=.` produce a stub `openapi.yml` without anything in it. Some discussion at https://stackoverflow.com/questions/70586511/protoc-gen-go-unable-to-determine-go-import-path-for-simple-proto (and a few other ideas in https://stackoverflow.com/questions/61666805/correct-format-of-protoc-go-package)
> 
> Gave up for now, but would love to see some real Swagger produced as well

Thanks @ddl-ebrown , this is super helpful!",little bit today could get useful output gnostic specifically couple syntax proto might also try proto could get working correctly either least running tool something like option got import pas running produce stub without anything discussion gave would love see real swagger produced well thanks super helpful,issue,positive,positive,positive,positive,positive,positive
1491009186,"FYI - I tinkered with this a little bit today and couldn't get any useful output from gnostic (more specifically `protoc-gen-openapi`. I've noticed a couple of things:

* Syntax is `proto2` which might have issues. I did also try porting over to `proto3` but couldn't get that working correctly either.
* At the very least, running the tool requires the `.proto` files to have something like `option go_package = ""./"";`. I got all the import tests to pass, but running `protoc model_registry.proto service.proto -I=. --openapi_out=.` produce a stub `openapi.yml` without anything in it. Some discussion at https://stackoverflow.com/questions/70586511/protoc-gen-go-unable-to-determine-go-import-path-for-simple-proto (and a few other ideas in https://stackoverflow.com/questions/61666805/correct-format-of-protoc-go-package)


Gave up for now, but would love to see some real Swagger produced as well",little bit today could get useful output gnostic specifically couple syntax proto might also try proto could get working correctly either least running tool something like option got import pas running produce stub without anything discussion gave would love see real swagger produced well,issue,positive,positive,positive,positive,positive,positive
1490895097,"I'm going to close this PR since I am not sure about if I can amend the commit message, `--force` it up to my fork, and then have it flow over here without breaking stuff. I'll just reopen with a new, signed commit.",going close since sure amend commit message force fork flow without breaking stuff reopen new commit,issue,positive,positive,positive,positive,positive,positive
1490684309,"Hello, I am running across the same issue where my volume defined in mlflow is not picking up when using a Kubernetes Backend but works just fine when we run it normally with docker.  @somasays were you able to fix this issue after all these years?",hello running across issue volume defined work fine run normally docker able fix issue,issue,negative,positive,positive,positive,positive,positive
1490453694,"> @benjaminbluhm An absolutely fantastic job on that tutorial! Great work! I left a few _very minor_ nits. We'll get this merged once those are adjusted.

My pleaseure @BenWilson2, and thanks for the great guidance on this PR!",absolutely fantastic job tutorial great work left get thanks great guidance,issue,positive,positive,positive,positive,positive,positive
1490312178,"```
Error: The version '3.7.12' with architecture 'x64' was not found for Ubuntu 22.04.
```
I guess we have to use py 3.7.13...
From https://raw.githubusercontent.com/actions/python-versions/main/versions-manifest.json -> 

  {
    ""version"": ""3.7.13"",
    ""stable"": true,
    ""release_url"": ""https://github.com/actions/python-versions/releases/tag/3.7.13-2268493565"",
    ""files"": [
      {
        ""filename"": ""python-3.7.13-darwin-x64.tar.gz"",
        ""arch"": ""x64"",
        ""platform"": ""darwin"",
        ""download_url"": ""https://github.com/actions/python-versions/releases/download/3.7.13-2268493565/python-3.7.13-darwin-x64.tar.gz""
      },
      {
        ""filename"": ""python-3.7.13-linux-18.04-x64.tar.gz"",
        ""arch"": ""x64"",
        ""platform"": ""linux"",
        ""platform_version"": ""18.04"",
        ""download_url"": ""https://github.com/actions/python-versions/releases/download/3.7.13-2268493565/python-3.7.13-linux-18.04-x64.tar.gz""
      },
      {
        ""filename"": ""python-3.7.13-linux-20.04-x64.tar.gz"",
        ""arch"": ""x64"",
        ""platform"": ""linux"",
        ""platform_version"": ""20.04"",
        ""download_url"": ""https://github.com/actions/python-versions/releases/download/3.7.13-2268493565/python-3.7.13-linux-20.04-x64.tar.gz""
      },
      **_{
        ""filename"": ""python-3.7.13-linux-22.04-x64.tar.gz"",
        ""arch"": ""x64"",
        ""platform"": ""linux"",
        ""platform_version"": ""22.04"",
        ""download_url"": ""https://github.com/actions/python-versions/releases/download/3.7.13-2268493565/python-3.7.13-linux-22.04-x64.tar.gz""
      }_**
    ]
  },
  {
    ""version"": ""3.7.12"",
    ""stable"": true,
    ""release_url"": ""https://github.com/actions/python-versions/releases/tag/3.7.12-116024"",
    ""files"": [
      {
        ""filename"": ""python-3.7.12-darwin-x64.tar.gz"",
        ""arch"": ""x64"",
        ""platform"": ""darwin"",
        ""download_url"": ""https://github.com/actions/python-versions/releases/download/3.7.12-116024/python-3.7.12-darwin-x64.tar.gz""
      },
      {
        ""filename"": ""python-3.7.12-linux-18.04-x64.tar.gz"",
        ""arch"": ""x64"",
        ""platform"": ""linux"",
        ""platform_version"": ""18.04"",
        ""download_url"": ""https://github.com/actions/python-versions/releases/download/3.7.12-116024/python-3.7.12-linux-18.04-x64.tar.gz""
      },
      {
        ""filename"": ""python-3.7.12-linux-20.04-x64.tar.gz"",
        ""arch"": ""x64"",
        ""platform"": ""linux"",
        ""platform_version"": ""20.04"",
        ""download_url"": ""https://github.com/actions/python-versions/releases/download/3.7.12-116024/python-3.7.12-linux-20.04-x64.tar.gz""
      }
    ]
  },
",error version architecture found guess use version stable true arch platform arch platform arch platform arch platform version stable true arch platform arch platform arch platform,issue,positive,positive,positive,positive,positive,positive
1490283621,"@benjaminbluhm An absolutely fantastic job on that tutorial! Great work! 
I left a few _very minor_ nits. We'll get this merged once those are adjusted. ",absolutely fantastic job tutorial great work left get,issue,positive,positive,positive,positive,positive,positive
1490142221,"Hi @BenWilson2 

I added the docs part, just let me know if certain aspects deserve more elaboration",hi added part let know certain deserve elaboration,issue,negative,positive,positive,positive,positive,positive
1489470731,Hi @harupy Please find an email from  rahul@projectdiscovery.io to mlflow-oss-maintainers@googlegroups.com. since the title might reveal the vulnerability name beforehand. Maybe check the spam folder too just in case.,hi please find since title might reveal vulnerability name beforehand maybe check folder case,issue,negative,neutral,neutral,neutral,neutral,neutral
1489466085,"Hi @iamnoooob, thanks for reporting this! I could not find the email. Did you really send it?",hi thanks could find really send,issue,negative,positive,positive,positive,positive,positive
1489448689,Will the fixes get back ported to the 1.3 series? ,get back ported series,issue,negative,neutral,neutral,neutral,neutral,neutral
1489196395,"Same problem with 

```bash
databricks-connect==9.1.34
databricks-connect==9.1.33
databricks-connect==9.1.30
```

When running 

```python

from pyspark.ml.clustering import KMeans

kmeans = self.KMeans().setK(3).setSeed(1)
kmeans.fit(self.data)
```

## Error

```bash
Traceback (most recent call last):
  File ""src/services/src/main.py"", line 49, in <module>
    k_means_estimator.fit()
  File ""/home/daniel/Downloads/lh-maz-pop/src/services/src/pop/clustering.py"", line 25, in fit
    self.model = kmeans.fit(self.data)
  File ""/home/daniel/Downloads/lh-maz-pop/venv/lib/python3.8/site-packages/pyspark/ml/base.py"", line 161, in fit
    return self._fit(dataset)
  File ""/home/daniel/Downloads/lh-maz-pop/venv/lib/python3.8/site-packages/pyspark/ml/wrapper.py"", line 339, in _fit
    java_model = self._fit_java(dataset)
  File ""/home/daniel/Downloads/lh-maz-pop/venv/lib/python3.8/site-packages/pyspark/ml/wrapper.py"", line 336, in _fit_java
    return self._java_obj.fit(dataset._jdf)
  File ""/home/daniel/Downloads/lh-maz-pop/venv/lib/python3.8/site-packages/py4j/java_gateway.py"", line 1304, in __call__
    return_value = get_return_value(
  File ""/home/daniel/Downloads/lh-maz-pop/venv/lib/python3.8/site-packages/pyspark/sql/utils.py"", line 117, in deco
    return f(*a, **kw)
  File ""/home/daniel/Downloads/lh-maz-pop/venv/lib/python3.8/site-packages/py4j/protocol.py"", line 326, in get_return_value
    raise Py4JJavaError(
py4j.protocol.Py4JJavaError: An error occurred while calling o63.fit.
: java.io.StreamCorruptedException: invalid type code: 0B
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1700)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2431)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2355)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2213)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1669)
	at java.io.ObjectInputStream.readArray(ObjectInputStream.java:2119)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1657)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2431)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2355)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2213)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1669)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:503)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:461)
	at org.apache.spark.sql.util.ProtoSerializer.$anonfun$deserializeObject$1(ProtoSerializer.scala:6631)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.sql.util.ProtoSerializer.deserializeObject(ProtoSerializer.scala:6616)
	at com.databricks.service.SparkServiceRPCHandler.execute0(SparkServiceRPCHandler.scala:728)
	at com.databricks.service.SparkServiceRPCHandler.$anonfun$executeRPC0$1(SparkServiceRPCHandler.scala:477)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.service.SparkServiceRPCHandler.executeRPC0(SparkServiceRPCHandler.scala:372)
	at com.databricks.service.SparkServiceRPCHandler$$anon$2.call(SparkServiceRPCHandler.scala:323)
	at com.databricks.service.SparkServiceRPCHandler$$anon$2.call(SparkServiceRPCHandler.scala:309)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at com.databricks.service.SparkServiceRPCHandler.$anonfun$executeRPC$1(SparkServiceRPCHandler.scala:359)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.service.SparkServiceRPCHandler.executeRPC(SparkServiceRPCHandler.scala:336)
	at com.databricks.service.SparkServiceRPCServlet.doPost(SparkServiceRPCServer.scala:167)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:790)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:550)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:383)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:882)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1036)
	at java.lang.Thread.run(Thread.java:750)

```

This works in a notebook in databricks",problem bash running python import error bash recent call last file line module file line fit file line fit return file line file line return file line file line return file line raise error calling invalid type code anon anon handle work notebook,issue,negative,positive,positive,positive,positive,positive
1488227164,"@harupy I think the issue **""mlflow.utils.process.ShellCommandException: Non-zero exit code: 1""** is due to MLFLOW trying to create a conda environment for the test case by installing tensorflow==2.3.0. As we already know, this is not possible on M1 and hence the test fails. 

@harupy Do you know of any potential workaround for this?

<img width=""1536"" alt=""Screenshot 2023-03-29 at 10 58 55"" src=""https://user-images.githubusercontent.com/12529807/228485398-1875ba93-e6c8-4d8c-bcf6-c308b9200441.png"">
",think issue exit code due trying create environment test case already know possible hence test know potential,issue,negative,negative,neutral,neutral,negative,negative
1488135695,@ry3s Thanks for catching this issue! It looks like we never use `kubernetes` with k8s backend.,thanks catching issue like never use,issue,positive,positive,positive,positive,positive,positive
1488055291,"A quick benchmark for uploading a 1GB file in devbox:

- PR: 13.7 sec!
- master: 220.1 sec",quick file sec master sec,issue,negative,positive,neutral,neutral,positive,positive
1487988610,"Hi @dbczumar, @harupy 

Sorry for the beginner question, do u know where the code that needs enhancement is for this FR?
",hi sorry beginner question know code need enhancement,issue,negative,negative,negative,negative,negative,negative
1487909801,The PR title needs to be updated to be consistent with PR content.,title need consistent content,issue,negative,positive,positive,positive,positive,positive
1487795329,"@adekunleoajayi Closing as this is not an MLflow issue, but I'm happy to help, please feel free to leave comments :)",issue happy help please feel free leave,issue,positive,positive,positive,positive,positive,positive
1487730619,@sam2881 Feel free to reopen the issue once you have the traceback.,sam feel free reopen issue,issue,positive,positive,positive,positive,positive,positive
1487081986,"@harupy thank you for your prompt reply.

Indeed with older versions of the tensorflow-macos and tensorflow-metal, most of the tests are successful. 

New conda.yml

```yml
name: mlflow-dev-env-v2
channels:
    - apple
    - conda-forge
    - defaults
dependencies:
    - python=3.8.13
    - pip>=19.0
    - tensorflow-deps=2.9.0
    - pip:
        - tensorflow-macos==2.9.0
        - tensorflow-metal==0.5.0
```

There are however some failures with this exception 

**""mlflow.utils.process.ShellCommandException: Non-zero exit code: 1""**

<img width=""1521"" alt=""Screenshot 2023-03-28 at 16 57 41"" src=""https://user-images.githubusercontent.com/12529807/228281783-3103bbc6-5c5c-41ae-a6c4-c08ca5858ba7.png"">
",thank prompt reply indeed older successful new name apple pip pip however exception exit code,issue,positive,positive,positive,positive,positive,positive
1487053781,"@sam2881 Please provide the traceback. It's impossible to investigate the issue with just `
mlflow models serve --model-uri models:/<>r/Production -p 1234`.",sam please provide impossible investigate issue serve,issue,negative,negative,negative,negative,negative,negative
1486879614,The error message looks similar to the one reported in https://developer.apple.com/forums/thread/722873,error message similar one,issue,negative,neutral,neutral,neutral,neutral,neutral
1486842538,@BenWilson2  how would the [Scenario 3: MLflow on localhost with Tracking Server](https://mlflow.org/docs/latest/tracking.html#id34) be different from an existing [example on artifact store](https://github.com/mlflow/mlflow/tree/master/examples/mlflow_artifacts)? Seems to me they're pretty much the same.,would scenario server different example artifact store pretty much,issue,negative,positive,positive,positive,positive,positive
1486817722,"Got it. As I suggested, you can check the network tab in the browser devtools.

This package seems very old. It might not be compatible with the latest version.",got check network tab browser package old might compatible latest version,issue,negative,positive,positive,positive,positive,positive
1486800145,"MLFlow support JFrog artifactory using this package: https://pypi.org/project/mlflow-jfrog-artifactory/

I was able to push and pull artifacts from JFrog artifactory through MLFLOW. The only problem I see is that artifact section in MLFLOW UI keeps loading.",support package able push pull problem see artifact section loading,issue,negative,positive,positive,positive,positive,positive
1486625539,@Coder-Vishali MLflow doesn't support using JFrog as an artifact repository. You can check the network or console tab in the devtools on your browser to see what went wrong.,support artifact repository check network console tab browser see went wrong,issue,negative,negative,negative,negative,negative,negative
1486273608,"> @WeichenXu123 What's the cause? Which commmit/PR caused this issue?

I haven't checked it. But I think we should always use `import keras; keras.__version__` to get keras version since TF 2.6 because since TF 2.6 tf.keras uses the separate keras pacakge as backend.",cause issue checked think always use import get version since since separate,issue,negative,neutral,neutral,neutral,neutral,neutral
1486092343,@TobiasRothlin We found responses from the tracking server don't contain the `Content-Length` header. Can you add it in your PR?,found server contain header add,issue,negative,neutral,neutral,neutral,neutral,neutral
1485839713,What is the solution for AutoGluon? I'm okay with disabling the metrics in mlflow but none of the suggestions above for imports worked for me.,solution metric none worked,issue,negative,neutral,neutral,neutral,neutral,neutral
1485229426,"@TobiasRothlin Thanks for reporting the issue. I found a couple related issues:

- https://github.com/psf/requests/issues/4956
- https://stackoverflow.com/questions/69919912/requests-iter-content-thinks-file-is-complete-but-its-not


It looks like this issue is not fixed yet in `requests`. Looking forward to your PR :)",thanks issue found couple related like issue fixed yet looking forward,issue,positive,positive,positive,positive,positive,positive
1485183685,"> Is there a way to add a backend-store-uri after running multiple experiments while keeping all of them?

Unfortunately, MLflow doesn't support loading experiments from backend-store-uris ",way add running multiple keeping unfortunately support loading,issue,negative,negative,negative,negative,negative,negative
1485181063,"@rlaroanf 

```
mlflow server -h 0.0.0.0 --default-artifact-root s3://xxxx
```

logs experiments in the local file system.

```
mlflow server -h 0.0.0.0 --default-artifact-root --backend-store-uri sqlite:///mlflow.db
```

logs experiments in a database.",server local file system server,issue,negative,neutral,neutral,neutral,neutral,neutral
1485100047,"@harupy Thanks for the fix, my organisation still uses mlflow 1.29 as we didn't evaluate the cost of handling the breaking changes  between 1.30 and 2.0.1 for our clients, and the 1.30 has a bug that was only solved in 2.0.1:
`[Tracking] Set the MLflow Run name correctly when specified as part of the tags argument to mlflow.start_run() (#7228, @Cokral)`

We need to get this patch though, can you consider backporting it on the 1.29 version, along with https://github.com/mlflow/mlflow/pull/7965/files  ?

I can do the PR but I'd like to be sure you agree to republish a 1.29.1 version with the fix",thanks fix still evaluate cost handling breaking bug set run name correctly part argument need get patch though consider version along like sure agree republish version fix,issue,positive,positive,positive,positive,positive,positive
1484810286,"For reference, I addressed my issue by adding these lines in my main module:

```python
import cloudpickle
import train

if __name__ == '__main__':
    cloudpickle.register_pickle_by_value(train)
```

This allows my `train.Model` to be loaded correctly when I run `ìnference.py`.",reference issue main module python import import train train loaded correctly run,issue,negative,positive,positive,positive,positive,positive
1484326671,@laerciop The DCO check is not fixed yet. Can you fix it?,check fixed yet fix,issue,negative,positive,neutral,neutral,positive,positive
1483830903,"After doing some extensive testing with retraining Tokenizers / retraining Models, modifying Model structures, and attempting to use a Tokenizer from the hub that hasn't been retrained and configured properly with structural embedding changes to a retrained model...

- Removing the ability to pass only a Model instance. This is dangerous. 
- Simplifying (removing) all of the pipeline required component inference logic. If the user wants to retrain, they need to pass all required elements in a dict OR pass a Pipeline.
- Add a simple validation check for the passed in dict (must have a model and can't have any keys not in the pipeline API list)

This approach will make supporting Trainer types in the future very trivial to implement (out of scope for now). It also simplifies the user use case of using model components in a serving context if they need to do pre-modeling activities (tokenization, encoding, etc) in a different container than the model is running in (common use case for high-volume inference at larger scales). ",extensive testing model use hub properly structural model removing ability pas model instance dangerous removing pipeline component inference logic user retrain need pas pas pipeline add simple validation check must model ca pipeline list approach make supporting trainer future trivial implement scope also user use case model serving context need different container model running common use case inference scale,issue,negative,negative,neutral,neutral,negative,negative
1483413327,"> Can you explain a bit more here? Basically are we just talking about the experiment list on the left side where it only requires the name so only fetch the name, and let the right side fetch everything else? Or am I missing something? I think the right side is already configured to fetch just 1 experiment it requires as far as I remember.

When not pulling all experiments right away, it was causing a bunch of issues if an experiment wasn't in the store but a user navigates to it. Maybe I'll give a go around at: 
* Disconnecting the list from the store entirely
* Removing the initial fetch for all experiments

And see what the issues that might cause. Then we could talk through them?

> Also I like the paginated approach to just fetch the name of the experiment. Shouldn't be as bad to store 1M(which is super unlikely that a user creates 1M experiments) experiment names in the redux store.

I like this idea. Is there an api that returns only experiment names? Or maybe parse the full json and only retain the name?
",explain bit basically talking experiment list left side name fetch name let right side fetch everything else missing something think right side already fetch experiment far remember right away causing bunch experiment store user maybe give go around list store entirely removing initial fetch see might cause could talk also like approach fetch name experiment bad store super unlikely user experiment redux store like idea experiment maybe parse full retain name,issue,negative,positive,neutral,neutral,positive,positive
1483285971,"CVEs have been published:
- https://nvd.nist.gov/vuln/detail/CVE-2023-1177 (critical severity; score 10)
- https://nvd.nist.gov/vuln/detail/CVE-2023-1176 (medium severity; score 5.3)

Dan has published blog post detailing the issue at:
https://protectai.com/blog/hacking-ai-system-takeover-exploit-in-mlflow

MLflow v2.2.2 has patched these vulnerabilities.",critical severity score medium severity score dan post issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1482977400,"I just solve the problem. 
The problem was antivirus software that has own firewall independent of the windows firewall.
That is the reason why I can't connected to mlflow-server even if I open the `windows firewall` port.

Thanks for response to my issue. @harupy ",solve problem problem antivirus independent reason ca connected even open port thanks response issue,issue,negative,positive,neutral,neutral,positive,positive
1482906646,@tahesse How would one change their REST API version on either the client or server? I have been unable to find info on how to do that thus far in this case. Any help would be appreciated,would one change rest version either client server unable find thus far case help would,issue,negative,negative,negative,negative,negative,negative
1482861023,"Yes @robsonpeixoto. I had done the benchmark. The performance was much better in terms of latency and throughput.

So, when I started on the task, a single inference GBM model serving was taking around 8ms-10ms. Then I looked into the inference process and did following optimisations.

Default implementation uses pandas Dataframe as standard request format for MLFlow model, but creating a Dataframe usually takes around 4ms-5ms. So, I had replaced it with Pydantic raw-json request handler. 

Removing dataframe request format brought down the latency to 3.5ms-5ms.

Then, I replaced the Flask app with FastAPI and it brought the latency to 1.5ms-3ms. 

So, I scaled this change across 50+ models running on Zomato production systems and brought down the infra costs by atleast 50%. Some of the models were running with over a million RPM.",yes done performance much better latency throughput task single inference model serving taking around inference process following default implementation standard request format model usually around request handler removing request format brought latency flask brought latency scaled change across running production brought infra running million,issue,positive,positive,neutral,neutral,positive,positive
1482776875,"Glad we indentified the root cause, thanks for using mlflow!",glad root cause thanks,issue,positive,positive,positive,positive,positive,positive
1482757618,"I get it now, thank you for the answer! I'm going to have to review the way I use mlflow as I have a multitude of trainers which can be invoked from my `main.py`, and I need to be able to modify the class definitions.",get thank answer going review way use multitude need able modify class,issue,negative,positive,positive,positive,positive,positive
1482754920,@dbczumar I have raised a [PR](https://github.com/mlflow/mlflow/pull/8099) that would potentialy resolve this issue. I was wondering if you could take a look and provide some feedback. Thanks,raised would resolve issue wondering could take look provide feedback thanks,issue,positive,positive,positive,positive,positive,positive
1482659735,"https://github.com/cloudpipe/cloudpickle says:

> Among other things, cloudpickle supports pickling for lambda functions along with functions and classes defined interactively in the __main__ module (for instance in a script, a shell or a Jupyter notebook).

For the new train.py in https://github.com/mlflow/mlflow/issues/8078#issuecomment-1482647412, cloudpickle pickles the `Model` class, hence the expected behavior.
",among lambda along class defined module instance script shell notebook new model class hence behavior,issue,negative,positive,positive,positive,positive,positive
1482647412,"If I make the following changes and execute the procedure from [this comment](https://github.com/mlflow/mlflow/issues/8078#issuecomment-1481614451), I get the expected behavior.

`MLproject`: run `train.py` instead of `main.py`
```
name: mlflow_debug

conda_env: conda.yaml

entry_points:
  main:
    command: ""python train.py""
```

`train.py`: add a python entry point
```python
import mlflow


class Model(mlflow.pyfunc.PythonModel):

    def predict(self, context, model_input):
        return 'good'


class Trainer:

    def __init__(self):
        mlflow.pyfunc.log_model(
            'model',
            python_model=Model(),
            registered_model_name='registered_model'
        )


if __name__ == '__main__':
    Trainer()
```",make following execute procedure comment get behavior run instead name main command python add python entry point python import class model predict self context return class trainer self trainer,issue,negative,positive,neutral,neutral,positive,positive
1482645938,"I wanted to be part of the contribution but you committed yourself :), waiting for this to be merged and to contribute more ",part contribution waiting contribute,issue,negative,neutral,neutral,neutral,neutral,neutral
1482636072,">  I'm expecting this class to be pickled

The class is not pickled.

```python
# a.py

import pickle


class Foo:
    def foo(self):
        return ""foo""


foo = Foo()
with open(""foo.pkl"", ""wb"") as f:
    pickle.dump(foo, f)
```

```python
# b.py

import pickle


class Foo:
    def foo(self):
        return ""bar""


f = ""foo.pkl""
with open(f, ""rb"") as f:
    foo = pickle.load(f)
    print(foo.foo())
```

```bash
> python a.py
> python b.py
bar
```
",class class python import pickle class foo foo self return foo foo foo open foo python import pickle class foo foo self return bar open foo print bash python python bar,issue,negative,neutral,neutral,neutral,neutral,neutral
1482625378,"I greatly appreciate your help, and I'm sorry for the confusion.
From what I understand, when I use `log_model` to register version 1 of my model (which `return 'good'` in it's `predict` method), I'm expecting this class to be pickled so that I can load it later and it will output `good`.
Then if I change the logic of my class by changing `return 'good'` to `return 'bad'`, and use `log_model` to register this model as version 2, I'm expecting this class to be pickled so that I can load it later and it will output `bad`.
However, if I want to load version 1 of my model, the one which outputs `good`, I thought I could ask for version 1 with `model = mlflow.pyfunc.load_model(model_uri=f""models:/registered_model/1"")`, and it would load the pickled class which outputs `good`. When I do that, I get the output of version 2: `bad`.
Am I making sense?",greatly appreciate help sorry confusion understand use register version model return predict method class load later output good change logic class return return use register model version class load later output bad however want load version model one good thought could ask version model would load class good get output version bad making sense,issue,positive,positive,positive,positive,positive,positive
1482602882,"I'm confused. In https://github.com/mlflow/mlflow/issues/8078#issuecomment-1481614451, you said `I would expect to get good printed in my terminal, but I actually get bad` (= output changed).",confused said would expect get good printed terminal actually get bad output,issue,negative,negative,neutral,neutral,negative,negative
1482594769,"> I don't think this is a bug. If you changed the class definition, the output would also change.

I change `'good'` to `'bad'` in `predict`, so the class definition changes, so the output should change, but it doesn't.",think bug class definition output would also change change predict class definition output change,issue,negative,neutral,neutral,neutral,neutral,neutral
1482576486,"> I first observed this issue in production when a Staging model (call it B) behaved strangely similar to the previous Staging model (call it A).

When you observed this, did you change the class definition of your model?",first issue production staging model call strangely similar previous staging model call change class definition model,issue,negative,positive,neutral,neutral,positive,positive
1482575933,"I don't think this is a bug. If you changed the class definition, the output would also change.",think bug class definition output would also change,issue,negative,neutral,neutral,neutral,neutral,neutral
1482571529,"Is it appropriate to classify this as a bug, or am I utilizing the library incorrectly?",appropriate bug library incorrectly,issue,negative,positive,positive,positive,positive,positive
1482563089,"I think I got it. It's because you changed the class. pickle loads the first model **with the changed class**, hence `""bad""` is returned.",think got class pickle first model class hence bad returned,issue,negative,negative,negative,negative,negative,negative
1482553545,"Strange indeed, were you able to reproduce?
I first observed this issue in production when a Staging model (call it B) behaved strangely similar to the previous Staging model (call it A).
To verify my intuition about mlflow serving model A, I registered a new model (call it C) by replacing my model prediction in `predict` with `return 'Hello World!'`, I put it in Staging, and when I ran my inference file, I still got my previous prediction from model A.",strange indeed able reproduce first issue production staging model call strangely similar previous staging model call verify intuition serving model registered new model call model prediction predict return world put staging ran inference file still got previous prediction model,issue,negative,positive,neutral,neutral,positive,positive
1482544572,Strange. Wondering why `Change line 7 of train.py from return 'good' to return 'bad'` gives a different result.,strange wondering change line return return different result,issue,negative,negative,neutral,neutral,negative,negative
1482520470,"I also observed that creating two different model classes fixes the issue.
These other modifications also fix the issue:
- Add a `if __name__ == '__main__:` in `train.py` and run the mlflow on `train.py` directly
- Replace `bad` and `good` by an argument

This might be a pickling issue.",also two different model class issue also fix issue add run directly replace bad good argument might issue,issue,negative,positive,neutral,neutral,positive,positive
1482511003,"@harupy thank you for helping on this issue 🙂
Unfortunately this command shows the second model registered as v2:
> <ModelVersion: creation_timestamp=1679650362566, current_stage='None', description='', last_updated_timestamp=1679650362566, name='registered_model', run_id='500d1af0a7b14269a8ee62cc081a1f19', run_link='', source='mlflow-artifacts:/9/500d1af0a7b14269a8ee62cc081a1f19/artifacts/model', status='READY', status_message='', tags={}, user_id='', version='2'>
<ModelVersion: creation_timestamp=1679650352391, current_stage='None', description='', last_updated_timestamp=1679650352391, name='registered_model', run_id='ad68b3e539d94eec96834035465f0b39', run_link='', source='mlflow-artifacts:/9/ad68b3e539d94eec96834035465f0b39/artifacts/model', status='READY', status_message='', tags={}, user_id='', version='1'>",thank helping issue unfortunately command second model registered,issue,negative,negative,negative,negative,negative,negative
1482479439,@thomas-schillaci Can you try running `mlflow.MlflowClient().search_model_versions()` after logging the second model and check the output? You can also check model versions on MLflow UI. Maybe the second model is registered as v1.,try running logging second model check output also check model maybe second model registered,issue,negative,neutral,neutral,neutral,neutral,neutral
1482478895,"@thomas-schillaci Thanks for the reproducer. I wasn't able to reproduce the issue.

```python
import mlflow
import numpy as np
import tempfile
import subprocess
import os
import signal
import time


class Model1(mlflow.pyfunc.PythonModel):
    def predict(self, context, model_input):
        return ""good""


class Model2(mlflow.pyfunc.PythonModel):
    def predict(self, context, model_input):
        return ""bad""


with tempfile.TemporaryDirectory() as tmpdir:
    with subprocess.Popen(
        [
            ""mlflow"",
            ""server"",
            ""--port"",
            ""5000"",
            ""--backend-store-uri"",
            f""sqlite:///{tmpdir}/mlflow.db"",
        ],
        preexec_fn=os.setsid,
    ) as proc:
        print(""Waiting for server to be up and running..."")
        time.sleep(3)

        mlflow.set_tracking_uri(""http://localhost:5000"")

        with mlflow.start_run() as run:
            mlflow.pyfunc.log_model(
                ""model"", python_model=Model1(), registered_model_name=""registered_model""
            )

        with mlflow.start_run() as run:
            mlflow.pyfunc.log_model(
                ""model"", python_model=Model2(), registered_model_name=""registered_model""
            )

        print(mlflow.MlflowClient().search_model_versions())

        model = mlflow.pyfunc.load_model(model_uri=f""models:/registered_model/1"")
        print(model.predict(np.array([])))

        os.killpg(os.getpgid(proc.pid), signal.SIGTERM)
```

I ran this code and got `good`.",thanks reproducer able reproduce issue python import import import import import o import signal import time class model predict self context return good class model predict self context return bad server port print waiting server running run model run model print model print ran code got good,issue,positive,positive,positive,positive,positive,positive
1482330588,"@tpanza Thanks for the good suggestion. I have exposed those values in the quickstart helm chart, but left them commented. Leaving them commented means we won't need to keep track of image versions in the values files. I tried installation with them uncommented (as empty values) but helm expanded them to empty strings in the generated k8s manifests and threw an error.

@harupy, @justmike1 - thanks for the feedback.

",thanks good suggestion exposed helm chart left leaving wo need keep track image tried installation uncommented empty helm expanded empty threw error thanks feedback,issue,negative,positive,positive,positive,positive,positive
1482101523,@thingumajig Glad increasing the timeout helped! Can we close this issue?,thingumajig glad increasing close issue,issue,negative,positive,positive,positive,positive,positive
1482073153,"@harupy Yes, the timeout for model-registry server as in my previous comment helped me. I run model serve and model registry on different physical servers, I had to apply a timeout on the right physical server :) Thanks",yes server previous comment run model serve model registry different physical apply right physical server thanks,issue,positive,positive,neutral,neutral,positive,positive
1482056665,"@jaume-ferrarons Makes sense, would you be interested in creating a PR to fix this issue?",sense would interested fix issue,issue,negative,positive,positive,positive,positive,positive
1481930581,"@harupy I restarted my mlflow model-registry server with an extended timeout for gunicorn:
`GUNICORN_CMD_ARGS=""--timeout 600"" mlflow server  -h 0.0.0.0 -p 5000 `
That seems to have helped. I'll fix the next batch of bugs and see if that's true.",server extended server fix next batch see true,issue,negative,positive,positive,positive,positive,positive
1481893930,"@harupy I checked on the scikit-learn model, it works.
Any other recommendations? Maybe the timeout should be increased on the server side (model registry side)?

Client-side working code for scikit-learn model:
```
import mlflow.pyfunc
import mlflow

import os
os.environ[""MLFLOW_HTTP_REQUEST_TIMEOUT""] = ""600""

TRACKING_URI='http://192.168.10.38:5000'
mlflow.set_tracking_uri(TRACKING_URI)

model_name = ""ElasticnetWineModel""
stage = ""Production""

model = mlflow.sklearn.load_model(model_uri=f""models:/{model_name}/{stage}"")

model.predict([[7.4, 0.70, 0.00, 1.9, 0.076, 11.0, 34.0, 0.9978, 3.51, 0.56, 9.4]])
```
",checked model work maybe server side model registry side working code model import import import o stage production model stage,issue,negative,neutral,neutral,neutral,neutral,neutral
1481644512,"Yes I want but I couldn't find the documentation I mentioned in the repo (only in the website urls I shared).

Can anyone help me with this guidance?",yes want could find documentation anyone help guidance,issue,positive,neutral,neutral,neutral,neutral,neutral
1481614451,"@harupy I tried to recreate an example as small as possible.

1. Start a tracking server: in a terminal execute `mlflow server -h 0.0.0.0 -p 5002 --backend-store-uri sqlite:///mlflow.db`
2. Create a folder (and cd to it), and create these files:

`conda.yaml`
```yaml
name: mlflow_debug
channels:
  - defaults
dependencies:
  - python=3.9
  - pip
  - pip:
    - mlflow==2.2.2
```

`inference.py`
```python
import mlflow
import numpy as np

model = mlflow.pyfunc.load_model(model_uri=f""models:/registered_model/1"")
print(model.predict(np.array([])))
```

`main.py`
```python
from train import Trainer

if __name__ == '__main__':
    Trainer()
```

`MLproject`
```
name: mlflow_debug

conda_env: conda.yaml

entry_points:
  main:
    command: ""python main.py""
```

`train.py`
```python
import mlflow


class Model(mlflow.pyfunc.PythonModel):

    def predict(self, context, model_input):
        return 'good'


class Trainer:

    def __init__(self):
        mlflow.pyfunc.log_model(
            'model',
            python_model=Model(),
            registered_model_name='registered_model'
        )
```

3. Execute `export MLFLOW_TRACKING_URI=""http://0.0.0.0:5002""`
4. Execute `mlflow run . --experiment-name debug_experiment`
5. Change line 7 of `train.py` from `return 'good'` to `return 'bad'`
6. Execute `mlflow run . --experiment-name debug_experiment`
7. Execute `python inference.py` -> I would expect to get `good` printed in my terminal, but I actually get `bad`",tried recreate example small possible start server terminal execute server create folder create name pip pip python import import model print python train import trainer trainer name main command python python import class model predict self context return class trainer self execute export execute run change line return return execute run execute python would expect get good printed terminal actually get bad,issue,negative,negative,neutral,neutral,negative,negative
1481326864,"FYI

This is how we deploy our MLflow extension, for Privacy-Preserving ML, on Kubernetes:

https://github.com/inaccel/heflow/tree/master/charts/heflow

For sure, there are similarities with your chart and we might consider using it (as a dependency) in the future. I thought you might be interested.",deploy extension sure chart might consider dependency future thought might interested,issue,positive,positive,positive,positive,positive,positive
1481215065,"From reading the Keras documentation, [fit method](https://keras.io/api/models/model_training_apis/), I deduce that yes, the output of the Sequence is **always** a batched `input` for the model. The input x is an _array (or array-like), or a list of arrays (in case the model has multiple inputs)_, no other option is mentioned.

Also it states that the input can be _keras.utils.Sequence returning (inputs, targets) or (inputs, targets, sample_weights)_.

From the [Sequence class](https://keras.io/api/utils/python_utils/#sequence-class), it states: _The method \_\_getitem\_\_ should return a complete batch._.

When connecting points, Sequence has to return a complete batch, in which the inputs should  _array (or array-like), or a list of arrays (in case the model has multiple inputs)_. Then, for a single input models the batch size is the 1st dimension and multi-input the 2nd.",reading documentation fit method deduce yes output sequence always input model input list case model multiple option also input sequence class method return complete sequence return complete batch list case model multiple single input batch size st dimension,issue,positive,positive,neutral,neutral,positive,positive
1481197753,"> cc @sunishsheth2009 can you file a ticket to track moving SHAP to an extra (like it was before) and gate recipes functionality based on whether or not shap is installed (if not installed, MLflow Recipes won't log model explanations).

@dbczumar is there work internally for this? I am happy to start a PR but don't want to duplicate anything.",file ticket track moving shap extra like gate functionality based whether shap wo log model work internally happy start want duplicate anything,issue,positive,positive,positive,positive,positive,positive
1481097728,"> Thanks for the update, let's see what happens.

Thanks for the suggestion @harupy . I added both and tested it in cpu and gpu. Until `pytorch_lightning` support is removed from `lightning` , we are good. At some point, we might need to move into `lightning`. Which may involve almost the rewrite of entire library. We can use MlflowLogger at that time and change the library. Can you please review and let me know your comments. ",thanks update let see thanks suggestion added tested support removed lightning good point might need move lightning may involve almost rewrite entire library use time change library please review let know,issue,positive,positive,positive,positive,positive,positive
1481093206,@laerciop feel free to file a PR if you want :),feel free file want,issue,positive,positive,positive,positive,positive,positive
1481064364,"Alright :)
Thanks again and please tell me if I can help in any form.",alright thanks please tell help form,issue,positive,positive,positive,positive,positive,positive
1481047605,"Thanks for the update, let's see what happens.",thanks update let see,issue,negative,positive,positive,positive,positive,positive
1481012526,"> Hi @jaume-ferrarons, when the model has more than one input, does the 2nd dimension **_always_** corresponds to the batch size?

Hi @harupy , I think so but I'm not sure at 100%. ",hi model one input dimension batch size hi think sure,issue,negative,positive,positive,positive,positive,positive
1481006799,"Hi @jaume-ferrarons, when the model has more than one input, does the 2nd dimension **_always_** correspond to the batch size?",hi model one input dimension correspond batch size,issue,negative,neutral,neutral,neutral,neutral,neutral
1480999638,@laerciop Looks like we forgot to update the documentation.,like forgot update documentation,issue,negative,neutral,neutral,neutral,neutral,neutral
1480971568,"Thanks @harupy ! It worked :)

So, as far I understand this should be reflected in the documentation, which describes the functioning of the method in the same way both in v1.30.0 and v.2.2.2:

 - The following text was extracted from the documentation from the current version (https://mlflow.org/docs/latest/projects.html) and describe the behaviour of the run method using a docker image - exactly the behaviour I was expecting, no caveats:

> _""When you run an MLflow project that specifies a Docker image, MLflow adds a new Docker layer that copies the project’s contents into the /mlflow/projects/code directory. This step produces a new image. MLflow then runs the new image and invokes the project entrypoint in the resulting container.""_

- And this one from the version which works in a slightly different way from the current (https://mlflow.org/docs/1.3.0/projects.html) tells exactly the same:

> _""When you run an MLflow project that specifies a Docker image, MLflow adds a new Docker layer that copies the project’s contents into the /mlflow/projects/code directory. This step produces a new image. MLflow then runs the new image and invokes the project entrypoint in the resulting container.""_

Does that make sense to you?


",thanks worked far understand reflected documentation method way following text extracted documentation current version describe behaviour run method docker image exactly behaviour run project docker image new docker layer project content directory step new image new image project resulting container one version work slightly different way current exactly run project docker image new docker layer project content directory step new image new image project resulting container make sense,issue,negative,positive,positive,positive,positive,positive
1480958775,"Great job, @shubh0508 :heart: 
Did you do any benchmark? The performance was better? And latency?",great job heart performance better latency,issue,positive,positive,positive,positive,positive,positive
1480847466,"> I haven't tested the case where we patch both of it. Can you please explain a bit more on the context.

Sure. If patching both Trainer is fine, we can simplify the code as I suggested.

```python
    try:
        import pytorch_lightning as pl
    except ImportError:
        pass
    else:
        from mlflow.pytorch._lightning_autolog import patched_fit

        safe_patch(FLAVOR_NAME, pl.Trainer, ""fit"", patched_fit, manage_run=True)

    try:
        import lightning as L
    except ImportError:
        pass
    else:
        from mlflow.pytorch._lightning_autolog import patched_fit

        safe_patch(FLAVOR_NAME, L.Trainer, ""fit"", patched_fit, manage_run=True)
```

Just because `lightning` can be imported doesn't mean the user uses `lightning`. The user might use `pytorch_lightning` even when `lightning` is available.",tested case patch please explain bit context sure trainer fine simplify code python try import except pas else import fit try import lightning except pas else import fit lightning mean user lightning user might use even lightning available,issue,positive,positive,positive,positive,positive,positive
1480838839,"> @shrinath-suresh What happens if we patch both `L.Trainer` and `pl.Trainer`?

I haven't tested the case where we patch both of it. Can you please explain a bit more on the context. 

As of now, the logic is to patch `L.Trainer` for lightning package and `pl.Trainer` for the ptl<=1.9.4. If we patch both, ptl<=1.9.4 will not have `L.Trainer` and fail.",patch tested case patch please explain bit context logic patch lightning package patch fail,issue,negative,negative,negative,negative,negative,negative
1480704414,"Thanks, opening an issue in the flask repository might help.",thanks opening issue flask repository might help,issue,positive,positive,positive,positive,positive,positive
1480687184,"> > Message: 'Could not install packages due to an OSError: [Errno 28] No space left on device\n'
> 
> Where did you see this error? Can you share the URL?
> 
> > For running autolog test, pytorch_lightning or lightning is mandatory right ?
> 
> No, it's not mandatory. See #7627 for more details.

I was getting the Space error in this [run](https://github.com/mlflow/mlflow/actions/runs/4488931479/jobs/7894121505) -  . But in the latest run i am not seeing it.

Thanks for the reference. Cross functional tests (for pytorch flavor) failed  due to the import error.. i fixed it supporting all three options (lightning, pytorch lightning <=1.9.4 and pytorch flavor)

```
    # For lightning>=2.0.0 flavor
    try:
        import lightning as L
    except ImportError:
        # for pytorch-lightning <= 1.9.4 flavor
        try:
            import pytorch_lightning as pl
        except ImportError:
            # For PyTorch flavor
            pass
        else:
            from mlflow.pytorch._lightning_autolog import patched_fit

            safe_patch(FLAVOR_NAME, pl.Trainer, ""fit"", patched_fit, manage_run=True)
    else:
        from mlflow.pytorch._lightning_autolog import patched_fit

        safe_patch(FLAVOR_NAME, L.Trainer, ""fit"", patched_fit, manage_run=True)
```

",message install due space left see error share running test lightning mandatory right mandatory see getting space error run latest run seeing thanks reference cross functional flavor due import error fixed supporting three lightning lightning flavor lightning flavor try import lightning except flavor try import except flavor pas else import fit else import fit,issue,positive,positive,positive,positive,positive,positive
1480662515,@ahlag Fantastic! Thanks so much! I wrote up a more detailed list of requirements here: https://github.com/mlflow/mlflow/issues/7870. Please let me know if you have questions; @harupy and I are happy to help. Thank you in advance for your contribution!,fantastic thanks much wrote detailed list please let know happy help thank advance contribution,issue,positive,positive,positive,positive,positive,positive
1480606511,@ahlag Is this something you would be interested in working on?,something would interested working,issue,negative,positive,positive,positive,positive,positive
1480594208,"@harupy  it's not easy, it was an experiment with fine tuning hugging face model, respectively it was custom mlflow.pyfunc.PythonModel and artifacts. I need to actually come up with a new little model of some sort, I can't do it quickly. ",easy experiment fine tuning hugging face model respectively custom need actually come new little model sort ca quickly,issue,positive,positive,positive,positive,positive,positive
1480590954,Can you create a smaller model and try the same thing?,create smaller model try thing,issue,negative,neutral,neutral,neutral,neutral,neutral
1480589473,"@harupy tried it this way: 
```
import mlflow.pyfunc
import mlflow

import os
os.environ[""MLFLOW_HTTP_REQUEST_TIMEOUT""] = ""600""

TRACKING_URI='http://192.168.x.x:5000'
mlflow.set_tracking_uri(TRACKING_URI)

model_name = ""xxxxxxx""
stage = ""Production""

model = mlflow.pyfunc.load_model(model_uri=f""models:/{model_name}/{stage}"")

model.predict('xxxxxx')

```
same error. I also tried it this way:
```

#!/bin/bash
# Set environment variable for the tracking URL where the Model Registry resides
export MLFLOW_TRACKING_URI=http://192.168.x.x:5000
export MLFLOW_HTTP_REQUEST_TIMEOUT=600 

# Serve the production model from the model registry
mlflow models serve -m ""models:/classifier-ruRoberta-large/Production""

```
same error
",tried way import import import o stage production model stage error also tried way set environment variable model registry export export serve production model model registry serve error,issue,negative,neutral,neutral,neutral,neutral,neutral
1480585202,"Setting the `MLFLOW_HTTP_REQUEST_TIMEOUT` environment variable might help.

```bash
export MLFLOW_HTTP_REQUEST_TIMEOUT=600  # 10 minutes
```

Can you try this?",setting environment variable might help bash export try,issue,negative,neutral,neutral,neutral,neutral,neutral
1480584295,"@harupy This is now the usual size of models, I would even say closer to small ;)",usual size would even say closer small,issue,negative,negative,negative,negative,negative,negative
1480579872,"@harupy I'm not loading a file, I'm loading the model as a whole. I need to rework the processing pipeline to shrink the model... I can't make it that fast yet, sorry.",loading file loading model whole need rework pipeline shrink model ca make fast yet sorry,issue,negative,negative,neutral,neutral,negative,negative
1480577503,@thingumajig This might be because the file is very large. Can you download a small file without any issues?,thingumajig might file large small file without,issue,negative,negative,neutral,neutral,negative,negative
1480574186,@jmahlik Invited you in the community slack. We can discuss there if you want.,community slack discus want,issue,negative,neutral,neutral,neutral,neutral,neutral
1480570670,"> Message: 'Could not install packages due to an OSError: [Errno 28] No space left on device\n'

Where did you see this error? Can you share the URL?

> For running autolog test, pytorch_lightning or lightning is mandatory right ?

No, it's not mandatory. See https://github.com/mlflow/mlflow/pull/7627 for more details.",message install due space left see error share running test lightning mandatory right mandatory see,issue,negative,positive,neutral,neutral,positive,positive
1480437238,"@seungtaek94 Can you create this minimal application and send a request from your remote server?

https://flask.palletsprojects.com/en/0.12.x/quickstart/#a-minimal-application

```python
from flask import Flask
app = Flask(__name__)

@app.route('/')
def hello_world():
    return 'Hello, World!'
```

If this doesn't work, I think something is wrong with your firewall settings.",create minimal application send request remote server python flask import flask flask return world work think something wrong,issue,negative,negative,negative,negative,negative,negative
1480434586,"I just tried. But It doesn't work.

`mlflow server --host=0.0.0.0 --backend-store-uri file://C:/Users/<my>/<path>/mlflow_server/mlruns -p 5000`",tried work server file path,issue,negative,neutral,neutral,neutral,neutral,neutral
1480414977,"I'm not, unfortunately, although I believe it can be a great addition to
mlflow
ᐧ

On Wed, 22 Mar 2023 at 17:12, mlflow-automation ***@***.***>
wrote:

> @dvirginz <https://github.com/dvirginz> Any updates here? If you're
> working on a PR, please link it to this issue.
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/mlflow/mlflow/issues/7983#issuecomment-1480412324>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AHM4A7ZWJVPRYT5AU6HCCATW5OIPJANCNFSM6AAAAAAVSB3ZGY>
> .
> You are receiving this because you were mentioned.Message ID:
> ***@***.***>
>
",unfortunately although believe great addition wed mar wrote working please link issue reply directly view id,issue,positive,positive,positive,positive,positive,positive
1480413747,"Thank you for response :) @harupy 

If I turn on the windows firewalls. There is no response after call `mlflow.set_experiment(""test_159"")`.
![image](https://user-images.githubusercontent.com/56434476/227066548-b61ea649-e7bb-4a4e-8414-785ced1520d9.png)

But if I turn off the windows firewalls It works.
![image](https://user-images.githubusercontent.com/56434476/227066629-6f57929a-6e7c-4b6f-bef2-ec8582defaa6.png)

Even I add the inbound and outbound rules for port 5000.
",thank response turn response call image turn work image even add inbound outbound port,issue,negative,neutral,neutral,neutral,neutral,neutral
1480412583,Thanks @thomasbell1985 ! Merging :). We'll make a new release some time in April. Thank you for your contribution!,thanks make new release time thank contribution,issue,positive,positive,positive,positive,positive,positive
1480402964,"Hi @seungtaek94,

> it doesn't work in the opposite case.

Can you elaborate on this? What error did you get?",hi work opposite case elaborate error get,issue,negative,positive,positive,positive,positive,positive
1480390070,"Hi @laerciop, can you try the following command?

```
mlflow run --build-image .
           ^^^^^^^^^^^^^ add this
```",hi try following command run add,issue,negative,neutral,neutral,neutral,neutral,neutral
1480389223,@thomas-schillaci Thank for reporting the issue! Can you create a python script that can reproduce the error (please make sure just running the script can reproduce the error)?,thank issue create python script reproduce error please make sure running script reproduce error,issue,negative,positive,positive,positive,positive,positive
1480195559,"May I suggest that these charts have the registries parameterized and optional setting of a `pullSecret`? This would support corporate users who do not have direct access to public registries and must go through an Artifactory proxy server requiring authentication.

For each `image`, have the `registry`, `repository`, and `tag` broken out as separate fields, so that the registry can be set/overridden. ",may suggest optional setting would support corporate direct access public must go proxy server authentication image registry repository tag broken separate registry,issue,negative,negative,neutral,neutral,negative,negative
1480131369,"@harupy Observing the following error message in CI - `Message: 'Could not install packages due to an OSError: [Errno 28] No space left on device\n'` ... Some of the test cases are failing during the package installation.

And the cross version tests are failing.. When i check the failure logs.. it has failed in `import pytorch_lightning as pl` . And in the master branch autolog code, the import is in try except block with `pass` in except - [code link](https://github.com/mlflow/mlflow/blob/1aa5434e6643de9b5d2ce78b095d42900bcde1ca/mlflow/pytorch/__init__.py#L1089)

For running autolog test, `pytorch_lightning` or `lightning` is mandatory right ? ",observing following error message message install due space left test failing package installation cross version failing check failure import master branch code import try except block pas except code link running test lightning mandatory right,issue,negative,negative,neutral,neutral,negative,negative
1480006455,@harupy Can we ask the Databricks ML Training team to take a look and approve before merging this?,ask training team take look approve,issue,negative,neutral,neutral,neutral,neutral,neutral
1479716454,Fixed the failing tests. Ready for another CI run.,fixed failing ready another run,issue,negative,positive,positive,positive,positive,positive
1479285049,"Hey @harupy, I fixed those items you highlighted, I have also fixed the failing CI",hey fixed also fixed failing,issue,negative,positive,neutral,neutral,positive,positive
1479158072,"> @shrinath-suresh thanks for the PR, ping me when it's ready for review!

sure @harupy . We are working on the GPU tests. Will let you know once the PR is ready for review",thanks ping ready review sure working let know ready review,issue,positive,positive,positive,positive,positive,positive
1478909243,"Rt now, we have switched to using Azure Blob client to download the model.
You can close this tkt. Will re-open if needed.

Thanks,
Anirban

On Wed, Mar 22, 2023 at 4:47 AM Harutaka Kawamura ***@***.***>
wrote:

> @anirbankonar123 <https://github.com/anirbankonar123> Did increasing the
> timeout help?
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/mlflow/mlflow/issues/8044#issuecomment-1478716780>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ADIW7N2VVE7RFKNRHYLMIQTW5IZI5ANCNFSM6AAAAAAV4YBXLU>
> .
> You are receiving this because you were mentioned.Message ID:
> ***@***.***>
>
",switched azure blob client model close thanks wed mar wrote increasing help reply directly view id,issue,positive,positive,positive,positive,positive,positive
1478770925,"@benelot glad to here that. it's amazing how MLflow is in 2.2 and still doesn't have an ""add graph button"".  I hope they can release the new MLflow version soon.",glad amazing still add graph button hope release new version soon,issue,positive,positive,positive,positive,positive,positive
1478726835,"@shrinath-suresh thanks for the PR, ping me when it's ready for review!",thanks ping ready review,issue,positive,positive,positive,positive,positive,positive
1478651368,Also bumping on this. Would love this feature to be added.,also bumping would love feature added,issue,positive,positive,positive,positive,positive,positive
1478320893,"Was doing a pre-review and I think I still need to add a unit test to `test_rest_utils` to verify the `extra_headers` behavior. Once that's in and everything's passing I'll flip this out of draft state.

Update: this is ready for review. ",think still need add unit test verify behavior everything passing flip draft state update ready review,issue,negative,positive,positive,positive,positive,positive
1478253696,"> Is there any update on this issue? We are currently monkey patching our MLflow Docker image to get the icons back.

@ruial  Could you post or link a reference to the monkey patch you're applying to fix this issue? It could be something very similar to what we need. Thanks in advance.",update issue currently monkey docker image get back could post link reference monkey patch fix issue could something similar need thanks advance,issue,negative,positive,neutral,neutral,positive,positive
1477851992,"For this next block of failing tests, I'd try: 
1. ON DELETE CASCADE (as you mentioned to me - it's a good thing to try and it SHOULD fix it) 
2. If that isn't working, the manual approach will be to handle reverse dependency operations within the DAG of foreign keys (delete the tail ref, then work back to get to the upstream definition) ",next block failing try delete cascade good thing try fix working manual approach handle reverse dependency within dag foreign delete tail ref work back get upstream definition,issue,negative,positive,positive,positive,positive,positive
1477650533,Done. But could only find one place in the source with that link. Even though it is there twice in the documentation ¯\_(ツ)_/¯,done could find one place source link even though twice documentation,issue,negative,neutral,neutral,neutral,neutral,neutral
1477408769,"
Failed to find a documentation preview for 68c357a2bc7e8ee5f1ff433df5b5b8d44bb8fa5c.

<details>
<summary>More info</summary>

- If the `ci/circleci: build_doc` job status is successful, you can see the preview with the following steps:
  1. Click `Details`.
  2. Click `Artifacts`.
  3. Click `docs/build/html/index.html`.
- This comment was created by https://github.com/mlflow/mlflow/actions/runs/4476720416.

</details>
",find documentation preview summary job status successful see preview following click click click comment,issue,positive,positive,positive,positive,positive,positive
1477033067,"> Details

Thanks @prithvikannan ! https://github.com/mlflow/mlflow/actions/runs/4472538093/jobs/7858821871?pr=8042 test failure is unrelated. Merging :D",thanks test failure unrelated,issue,negative,negative,neutral,neutral,negative,negative
1476673236,"I still think this would be a valuable addition, but really since mlflow can't handle a lot of models and a lot of concurrency, it isn't equipped to be one monolithic deployment that handles multiple teams. We've found at my work that it is appropriate to have one mlflow instance per team or per project for a few reasons. One, after too many models and versions are stored, the ui becomes sluggish. Also, most users ignore naming conventions and this leads to clutter, so they don't want to share an instance with others they don't know. The lack of one more nested level of organization for ""project-teams"" means separate instances fulfills this function.

Auth and instance (container) management is still useful though. Auth can be done with a simple nginx wrapper like some examples you can find out there, with shared credentials (service account), or with something like AD if you find an nginx example to integrate with sso/ad. The approach we would suggest is embedding the mlflow container in something else that handles both auth and spinning up/down of instances to manage resources if they go idle for a long time. Think jhub or kubeflow.

Before any of this, I think a higher priority though might be to refactor the flask app part of mlflow to be a fastapi app, so it can leverage the faster and more efficient (newer) ASGI (Asynchronous Server Gateway Inteface) instead of the older WSGI used by flask. It's possible this could be improved/changed while keeping flask, which might minimize the need for refactoring. https://flask.palletsprojects.com/en/2.2.x/deploying/asgi/

I'm not sure which of these approaches is best, but ASGI would probably help performance with lots of concurrent api calls (necessary with multiple teams). Not sure what can be done about the sluggish UI in cases with lots of content. That's probably a separate issue.

The fastapi approach would also allow inclusion of auth in the same framework, without an extra nginx wrapper if that's desirable.

Just some thoughts.",still think would valuable addition really since ca handle lot lot concurrency one monolithic deployment multiple found work appropriate one instance per team per project one many becomes sluggish also ignore naming clutter want share instance know lack one level organization separate function instance container management still useful though done simple wrapper like find service account something like ad find example integrate approach would suggest container something else spinning manage go idle long time think think higher priority though might flask part leverage faster efficient asynchronous server gateway instead older used flask possible could keeping flask might minimize need sure best would probably help performance lot concurrent necessary multiple sure done sluggish lot content probably separate issue approach would also allow inclusion framework without extra wrapper desirable,issue,positive,positive,positive,positive,positive,positive
1476465970,"+1

I'd like to do a simple `pip install mlflow` without dealing with complex C/C++ dependencies.",like simple pip install without dealing complex,issue,negative,negative,negative,negative,negative,negative
1476354368,"yes, it has to be the same number of rows (and index value to be concatenated).",yes number index value,issue,positive,neutral,neutral,neutral,neutral,neutral
1476245315,"If so, probably not an mlflow's issue. Can you repost an issue in the spark repository?",probably issue repost issue spark repository,issue,negative,neutral,neutral,neutral,neutral,neutral
1476154531,"We have a fix committed on our end. It will start rolling out tomorrow, 3/21, and be available globally 3/28.",fix end start rolling tomorrow available globally,issue,negative,positive,positive,positive,positive,positive
1476089851,"OOps, I ticked the wrong box ; but it's okay I guess I can do that ; ",ticked wrong box guess,issue,negative,negative,negative,negative,negative,negative
1476071284,"@Judekeyser `Union[DataType, str]` sounds good to me, looking forward to your PR!",union good looking forward,issue,negative,positive,positive,positive,positive,positive
1476005427,"Okay thanks, I will try this out and get back to you. ",thanks try get back,issue,negative,positive,neutral,neutral,positive,positive
1475999025,"You can create a custom evaluator with the following steps:

1. Create a python package like: https://github.com/mlflow/mlflow/tree/7f75f54860c7baefcaf3fbde330e5fbbb144d696/tests/resources/mlflow-test-plugin

https://github.com/mlflow/mlflow/blob/7f75f54860c7baefcaf3fbde330e5fbbb144d696/tests/resources/mlflow-test-plugin/setup.py#L33 is the key

2. Define your evaluator:

https://github.com/mlflow/mlflow/blob/7f75f54860c7baefcaf3fbde330e5fbbb144d696/tests/resources/mlflow-test-plugin/mlflow_test_plugin/dummy_evaluator.py#L27

3. Install the package

4. Set the name of your evaluator when calling `mlflow.evaluate`. MLflow should automatically pick up your evaluator:

https://github.com/mlflow/mlflow/blob/451845695d97f03839d3869a6e1f06eb0e5f4416/tests/models/test_evaluation.py#L406",create custom following create python package like key define install package set name calling automatically pick,issue,positive,neutral,neutral,neutral,neutral,neutral
1475991712,"Thanks for the prompt reply!

I might be missing some context here. I have not tried creating a custom plugin, but how can I pass this back to mlflow.evaluate? Or do you suggest that I create custom plugin and then change the source? ",thanks prompt reply might missing context tried custom pas back suggest create custom change source,issue,negative,neutral,neutral,neutral,neutral,neutral
1475986644,"Good catch, pushed a commit to update the SFTP artifact repo",good catch commit update artifact,issue,positive,positive,positive,positive,positive,positive
1475985207,"Perfect, I was about to answer with the same conclusion.

Will the fix also occur for SFTP ?",perfect answer conclusion fix also occur,issue,positive,positive,positive,positive,positive,positive
1475961182,"> 

I confess I haven't checked the FTP specification to know whether or not the string was ill-formed.

Couldn't find a location in the FTP specification where the format is clearly stated. Online resources usually don't make the trailing `/` explicit so I thought it would be okay to drop it too here.


",confess checked specification know whether string could find location specification format clearly stated usually make trailing explicit thought would drop,issue,negative,negative,neutral,neutral,negative,negative
1475952322,"Inserting `/` after `ftp://admin:123@localhost:21` as shown below:

```
      mlflow server \
        --backend-store-uri sqlite:///data.db \
        --artifacts-destination ftp://admin:123@localhost:21/ \
                                                            👆 this
        --serve-artifacts \
        --host 127.0.0.1 \
        --port 3000
```

fixed the issue. Investigting why now.",shown server host port fixed issue,issue,negative,positive,neutral,neutral,positive,positive
1475934974,"minimum reproducer:

```python
import tempfile
import mlflow
from pathlib import Path

mlflow.set_tracking_uri(""http://localhost:3000"")


with tempfile.TemporaryDirectory() as tmpdir:
    t = Path(tmpdir)

    t.joinpath(""a.txt"").write_text(""a"")
    t.joinpath(""subdir"").mkdir()
    t.joinpath(""subdir"", ""b.txt"").write_text(""b"")
    t.joinpath(""subdir"", ""c.txt"").write_text(""c"")

    with mlflow.start_run():
        mlflow.log_artifacts(tmpdir)

```",minimum reproducer python import import import path path,issue,negative,neutral,neutral,neutral,neutral,neutral
1475887560,"I am afraid no, I do not know docker-compose and I don't have it installed. I put all the commands I do in the original message, maybe doing the compose from there would be quite straightforward if you have it? ",afraid know put original message maybe compose would quite straightforward,issue,negative,positive,neutral,neutral,positive,positive
1475884671,@Judekeyser Got it. Can you creaet a docker compose file that can reproduce the issue?,got docker compose file reproduce issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1475878746,"> > I get my test successful, and the idk/model.json file exists at the correct place (in my case, it was idk/model.json/model.json because of the artifact_path :D but okay, log_artifact seems to work!
> 
> What about `log_artifacts`?

Yes, that one does not work neither. Same error, ""cannot change dir"":

```
log_artifacts(
  local_dir=my_directory_path_containing_stuffs,
  artifact_path=""idk""
)
```",get test successful file correct place case work yes one work neither error change,issue,positive,positive,positive,positive,positive,positive
1475857060,"@harupy 
> Would you be interested in create a PR?

Thank you for your suggestion. I'd like that.",would interested create thank suggestion like,issue,positive,positive,positive,positive,positive,positive
1475822686,"@shumingpeh Thanks for the FR, is it possible to create a custom evaluator that can handle 2D inputs using the pluging mechanism?

Example:
https://github.com/mlflow/mlflow/blob/master/tests/resources/mlflow-test-plugin/mlflow_test_plugin/dummy_evaluator.py",thanks possible create custom handle mechanism example,issue,positive,positive,neutral,neutral,positive,positive
1475821184,"@yukimori Thanks for reporting the issue. Let's remove that line. Would you be interested in create a PR?
",thanks issue let remove line would interested create,issue,positive,positive,positive,positive,positive,positive
1475801568,"> I get my test successful, and the idk/model.json file exists at the correct place (in my case, it was idk/model.json/model.json because of the artifact_path :D but okay, log_artifact seems to work!

What about `log_artifacts`?",get test successful file correct place case work,issue,positive,positive,positive,positive,positive,positive
1475747487,"no worries. i will give the actual snippet of the overall, and proposed changes. but let me know if its clear (if not i will give more details).

example of how our `eval_df` looks like
```python
pd.DataFrame({
    ""prediction"": list(np.array([[0.05,0.9,0.05], [0.05,0.9,0.05]])),
    ""target"": np.array([1,1])
})
```

_**current overall**_
so this is how we are doing the `top_10_accuracy` for the overall dataset
```python
def top_n_accuracy(eval_df, builtin_metrics) -> Dict:

    cumsum_array = np.array([0] * 10, dtype=float)
    correct_predictions = []

    for i, row in enumerate(eval_df.values):
        sorted_array = row[0].argsort()[-10:][::-1]

        try:
            is_present_position = np.where(sorted_array == row[1])[0][0]
            position_of_prediction = np.concatenate(
                (
                    np.array([0] * (is_present_position)),
                    np.array([1] * (10 - is_present_position)),
                )
            )
        except Exception:
            position_of_prediction = np.array([0] * 10, dtype=float)
            is_present_position = -1

        cumsum_array += position_of_prediction
        correct_predictions.append(is_present_position)

    top_n_accuracy_result = pd.DataFrame(
        cumsum_array / eval_df.shape[0], columns=[""accuracy_at_10""]
    ).assign(nth_value=[(i + 1) for i in range(10)])[[""nth_value"", ""accuracy_at_10""]]

    return {""top_n_accuracy_result"": top_n_accuracy_result.accuracy_at_10.max()}
```

**_proposed changes_** 
and assuming that we have additional context to the `eval_df`. we can concat with the `eval_df` and evaluate on a more granular level.
```python
def top_n_accuracy(
    eval_df, builtin_metrics, additional_df=None, additional_array=None
) ->  Dict:

    cumsum_array = np.array([0] * 10, dtype=float)
    correct_predictions = []

    ...
    ...
    
    aggregation_df = (
        pd.concat([eval_df, additional_df], axis=1)
        .pipe(lambda x:x.assign(is_correct = correct_predictions))
        .groupby(['parent_cat_col'])
        .agg({...})
        ...
    )
    
    dict_metrics = {f""{row['parent_cat_col']}_top_10_accuracy"": row['is_correct_agg'] for row in aggregation_df.iterrows()}
    dict_metrics['top_n_accuracy_result'] = top_n_accuracy_result.accuracy_at_10.max()
    
    return dict_metrics
```",give actual snippet overall let know clear give example like python prediction list target current overall overall python row enumerate row try row except exception range return assuming additional context evaluate granular level python lambda row row row return,issue,positive,positive,neutral,neutral,positive,positive
1475742184,"In the `pyfunc.log_model`, I went up to a call that looks like:
```
mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
```
from `model.py`. In that call, `local_path` is the temporary name of the model, while `mlflow_model.artifact_path` is my parameter `""idk""` I provided. Beyond that point, as you say, I guess no other break point trigger because of the proxy thing.",went call like call temporary name model parameter provided beyond point say guess break point trigger proxy thing,issue,negative,neutral,neutral,neutral,neutral,neutral
1475736476,"Okay but still, I think the bug location is not well posed, because when I do
```
log_artifact(
  local_path=my_json_file,
  artifact_path=""idk/model.json""
)
```
I get my test successful, and the `idk/model.json` file exists at the correct place (in my case, it was `idk/model.json/model.json` because of the `artifact_path` :D but okay, `log_artifact` seems to work!

However, for a reason I don't know about, `log_model` does not work the same.
",still think bug location well get test successful file correct place case work however reason know work,issue,positive,positive,positive,positive,positive,positive
1475728072,"@shumingpeh Thanks for the FR, with the proposed changes, how would evaluation code would look like? Could you give us an example?",thanks would evaluation code would look like could give u example,issue,positive,positive,positive,positive,positive,positive
1475722770,"> no breakpoint trigger from the file you refer to, neither in log_artifact nor in log_artifacts.

When artifact proxy is enabled, the client just sends HTTP requests to the tracking server, doesn't run `FTPArtifactRepository.log_artifact` or `log_artifacts`.",trigger file refer neither artifact proxy client server run,issue,negative,neutral,neutral,neutral,neutral,neutral
1475703960,"> https://github.com/mlflow/mlflow/blob/7f75f54860c7baefcaf3fbde330e5fbbb144d696/mlflow/store/artifact/ftp_artifact_repo.py#L72-L78
> 
> * Line 77 is the failed line
> * Line 75 should create `artifact_dir`, but `ftplib.error_perm: 550 Can't change directory to 2/efb7e67ea019498abb3aee831db54172/artifacts/idk: No such file or directory` sounds like it doesn't.

I hardly doubt the bug (only) happens here, because no break point gets triggered on my side. My breakpoint in `pyfunc.log_model` triggers until there is indeed a call to a `log_artifacts` (plural) from a mlflow client). But **no breakpoint** trigger from the file you refer to, neither in `log_artifact` nor in `log_artifacts`.",line line line create ca change directory file directory like hardly doubt bug break point triggered side indeed call plural client trigger file refer neither,issue,negative,negative,negative,negative,negative,negative
1475678856,"Hi @harupy , sorry for my mistake, the file that is created is indeed:
```
mlflow-artifacts:/2/efb7e67ea019498abb3aee831db54172/artifacts/idk/python_env.yaml
```
The file exists correctly, and then the issue occurs. If I refer to the stacktrace, it feels like there is a missing prefix / or something, and it looks like it tries to change directory to a folder that is wrongly located (because it does exist and there is a file in there)",hi sorry mistake file indeed file correctly issue refer like missing prefix something like change directory folder wrongly exist file,issue,negative,negative,negative,negative,negative,negative
1475655096,"@harupy your right, I am using python 3.7.7 and mlflow-1.28.0. Will have a try and update later, thanks👍",right python try update later thanks,issue,negative,positive,positive,positive,positive,positive
1475654357,"> @Zhangjiawei-Beinloft btw why do you need to run `yarn build`?

Because I‘m fixing the problem that mlflow UI not working in iframe. 
[mlflow UI not working in iframe[BUG]--cross origin issue](https://github.com/mlflow/mlflow/issues/3583#issue-727989150)",need run yarn build fixing problem working working bug cross origin issue,issue,negative,negative,neutral,neutral,negative,negative
1475649918,It looks like you're using python 3.7 and mlflow < 2.0. Can you update python to 3.8 and install mlflow >= 2.0?,like python update python install,issue,negative,neutral,neutral,neutral,neutral,neutral
1475649809,"> @Zhangjiawei-Beinloft
> 
> > why can't I use windows
> 
> Line 74 in `craco.config.js` may not match on Windows:
> 
> <img alt=""image"" width=""748"" src=""https://user-images.githubusercontent.com/17039389/226077493-7a5f059e-d572-49de-885c-a080ae848456.png"">
> 
> If line 74 matches nothing, that would leave `cssRuleFixed` `false`, then cause the error.
> 
> > what should I use?
> 
> Linux or Mac should work. If you don't have them, https://github.com/features/codespacess should help.

it worked！Thanks！",ca use line may match image line nothing would leave false cause error use mac work help,issue,negative,negative,negative,negative,negative,negative
1475640425,"thank you for your help, I got a problem here, 
![Screen Shot 2023-03-20 at 13 14 29](https://user-images.githubusercontent.com/51428350/226252522-73e10e65-727f-41ee-a93d-b4933aef51fd.png)

the codes are as below:
![Screen Shot 2023-03-20 at 13 17 57](https://user-images.githubusercontent.com/51428350/226252971-e724fe9a-c561-4f8d-a659-07b27c64a6e3.png)

",thank help got problem screen shot screen shot,issue,negative,neutral,neutral,neutral,neutral,neutral
1475605254,"I have a similar problem, but the same stacktrace from .../artifact/... . I did:

` $ mlflow gc --backend-store-uri=sqlite:///mlflow.db `

and I get the following error:

```
# mlflow gc --older-than=1h  --backend-store-uri=sqlite:///mlflow.db 
2023/03/20 04:19:31 INFO mlflow.store.db.utils: Creating initial MLflow database tables...
2023/03/20 04:19:31 INFO mlflow.store.db.utils: Updating database tables
INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
Run with ID b27d67938f88468a8430407955b9ebaa has been permanently deleted.
Run with ID 02bd3de0e9a348a1ae7938a7851891ac has been permanently deleted.
Run with ID cc5565e682f14fc89c52291891ccf95b has been permanently deleted.
Run with ID 732d05c7b13b4c08a9bc8715bcd75e58 has been permanently deleted.
Traceback (most recent call last):
  File ""/usr/local/bin/mlflow"", line 8, in <module>
    sys.exit(cli())
  File ""/usr/local/lib/python3.9/site-packages/click/core.py"", line 1130, in __call__
    return self.main(*args, **kwargs)
  File ""/usr/local/lib/python3.9/site-packages/click/core.py"", line 1055, in main
    rv = self.invoke(ctx)
  File ""/usr/local/lib/python3.9/site-packages/click/core.py"", line 1657, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File ""/usr/local/lib/python3.9/site-packages/click/core.py"", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File ""/usr/local/lib/python3.9/site-packages/click/core.py"", line 760, in invoke
    return __callback(*args, **kwargs)
  File ""/usr/local/lib/python3.9/site-packages/mlflow/cli.py"", line 573, in gc
    artifact_repo = get_artifact_repository(run.info.artifact_uri)
  File ""/usr/local/lib/python3.9/site-packages/mlflow/store/artifact/artifact_repository_registry.py"", line 106, in get_artifact_repository
    return _artifact_repository_registry.get_artifact_repository(artifact_uri)
  File ""/usr/local/lib/python3.9/site-packages/mlflow/store/artifact/artifact_repository_registry.py"", line 72, in get_artifact_repository
    return repository(artifact_uri)
  File ""/usr/local/lib/python3.9/site-packages/mlflow/store/artifact/mlflow_artifacts_repo.py"", line 45, in __init__
    super().__init__(self.resolve_uri(artifact_uri, get_tracking_uri()))
  File ""/usr/local/lib/python3.9/site-packages/mlflow/store/artifact/mlflow_artifacts_repo.py"", line 59, in resolve_uri
    _validate_uri_scheme(track_parse.scheme)
  File ""/usr/local/lib/python3.9/site-packages/mlflow/store/artifact/mlflow_artifacts_repo.py"", line 35, in _validate_uri_scheme
    raise MlflowException(
mlflow.exceptions.MlflowException: The configured tracking uri scheme: 'file' is invalid for use with the proxy mlflow-artifact scheme. The allowed tracking schemes are: {'http', 'https'}

```",similar problem get following error initial table table context assume context assume run id permanently run id permanently run id permanently run id permanently recent call last file line module file line return file line main file line invoke return file line invoke return file line invoke return file line file line return file line return repository file line super file line file line raise scheme invalid use proxy scheme,issue,negative,positive,neutral,neutral,positive,positive
1475532968,@Zhangjiawei-Beinloft btw why do you need to run `yarn build`?,need run yarn build,issue,negative,negative,neutral,neutral,negative,negative
1475532570,Freel free to reopne the issue if the code above doesn't work.,free issue code work,issue,positive,positive,positive,positive,positive,positive
1475527211,"Hi @652994331, the following code logs metrics and a model using `log_metrics` and `log_model`:

```python
with mlflow.start_run():
    metrics = compute_metrics(model, ...)
    mlflow.log_metrics(metrics)
    mlflow.tensorflow.log_model(model)
```",hi following code metric model python metric model metric model,issue,negative,neutral,neutral,neutral,neutral,neutral
1475469317,"https://github.com/mlflow/mlflow/blob/7f75f54860c7baefcaf3fbde330e5fbbb144d696/mlflow/store/artifact/ftp_artifact_repo.py#L72-L78

- Line 77 is the failed line
- Line 75 should create `artifact_dir`, but `ftplib.error_perm: 550 Can't change directory to 2/efb7e67ea019498abb3aee831db54172/artifacts/idk: No such file or directory` sounds like it doesn't.",line line line create ca change directory file directory like,issue,positive,neutral,neutral,neutral,neutral,neutral
1475468020,"@ichbinjakes thanks for the PR, can you fix the DCO check failure?",thanks fix check failure,issue,negative,negative,neutral,neutral,negative,negative
1475456316,"Hi @Judekeyser, can you reproduce the same error with `mlflow.log_artifact` or `mlflow.log_artifacts?`

```python
with mlflow.start_run():
    mlflow.log_artifact(__file__, ""idk"")
    # or mlflow.log_artifacts(...)
```",hi reproduce error python,issue,negative,neutral,neutral,neutral,neutral,neutral
1475360171,"@dbczumar Unfortunately the above solution isn't sufficient when using assumed role for calling the tracking server with `MLFLOW_TRACKING_AWS_SIG4 = True`, suggested solution is to allow passing session here: https://github.com/mlflow/mlflow/blob/master/mlflow/utils/rest_utils.py#L157",unfortunately solution sufficient assumed role calling server true solution allow passing session,issue,positive,negative,neutral,neutral,negative,negative
1475345794,"Hey @jmahlik thank you for the suggestions. 

> Each component is responsible for fetching any experiments it needs on the fly

Can you explain a bit more here? Basically are we just talking about the experiment list on the left side where it only requires the name so only fetch the name, and let the right side fetch everything else? Or am I missing something? 
I think the right side is already configured to fetch just 1 experiment it requires as far as I remember. 

Also I like the paginated approach to just fetch the name of the experiment. Shouldn't be as bad to store 1M(which is super unlikely that a user creates 1M experiments) experiment names in the redux store. ",hey thank component responsible fetching need fly explain bit basically talking experiment list left side name fetch name let right side fetch everything else missing something think right side already fetch experiment far remember also like approach fetch name experiment bad store super unlikely user experiment redux store,issue,positive,positive,neutral,neutral,positive,positive
1475237585,"I've been passing the logger explicitly as follows:
`logger = MLFlowLogger(run_id=net.run_id, log_model=True)` and so far it works. Still need to try with pytorch 2 and lightning 2.
(I'm not using autolog)",passing logger explicitly logger far work still need try lightning,issue,negative,positive,neutral,neutral,positive,positive
1475166405,"Hey @dbczumar I have put in a draft merge request: https://github.com/mlflow/mlflow/pull/8056. @Maelstro If you are available to test the helm chart with azure and gcp storage, that would be great. I have only tested it with MinIO. It took me a while to figure out how best structure the helm chart to manage the complexity of different artifact storage providers. Happy to take feedback.

The helm chart only supports AWS/MinIO, Azure and GCP for artifact storage. If anyone wants to contribute  other providers let me know (or we could do it through separate MRs)

Some other loose ends, and whether they need to be solved in the PR is:
- Running the helm unit tests with CI
- Packaging helm chart and pushing them to a repo with CI
- Building the docker image with the artifact provider libraries and pushing it to a repo with CI",hey put draft merge request available test helm chart azure storage would great tested took figure best structure helm chart manage complexity different artifact storage happy take feedback helm chart azure artifact storage anyone contribute let know could separate loose whether need running helm unit helm chart pushing building docker image artifact provider pushing,issue,positive,positive,positive,positive,positive,positive
1474576381,@meg-dialexa Can this model be loaded fine without using MLflow?,model loaded fine without,issue,negative,positive,positive,positive,positive,positive
1474566512,"No, mlflow currently doesn't. We need to update the pytorch autologging code.",currently need update code,issue,negative,neutral,neutral,neutral,neutral,neutral
1474552754,"> @Zhangjiawei-Beinloft I wasn't able to reproduce the issue. This might be because you're using windows.

why can't I use windows and what should I use?",able reproduce issue might ca use use,issue,negative,positive,positive,positive,positive,positive
1474528878,Looks like you'll have to override these methods in `mlflow/store/_unity_catalog/registry/rest_store.py` (even with a placeholder of raising a NotImplementedError for the time being),like override even raising time,issue,negative,neutral,neutral,neutral,neutral,neutral
1474418017,Being able to stream logs in real time is useful because in those cases where the instance you are running your training fails on Out of Memory you cannot handle that exception. For example weights and biases does that automatically.,able stream real time useful instance running training memory handle exception example automatically,issue,negative,positive,positive,positive,positive,positive
1474211687,"@amie-roten Probably even more helpful to display the spectrogram in most cases. I've been thinking about adding this so maybe I will. No updates from the maintainers, though.",probably even helpful display spectrogram thinking maybe though,issue,negative,neutral,neutral,neutral,neutral,neutral
1474143073,"> @gbrener hey, are you still working on this? let me know if you need any help

Hey @rafaelvp-db , I'm not working on this any longer. Feel free to pick it up!",hey still working let know need help hey working longer feel free pick,issue,positive,positive,positive,positive,positive,positive
1474036567,"Unfortunately I switched to S3 instead of FTP using MINIO.

Anyway, thank you for your support and work on mlflow.",unfortunately switched instead anyway thank support work,issue,negative,negative,negative,negative,negative,negative
1473897703,"Sure. I would probably name it Keras/Tensorflow instead.

I can make a PR but like I said I can't even find the source for the docs right now.",sure would probably name instead make like said ca even find source right,issue,positive,positive,positive,positive,positive,positive
1473480163,@Zhangjiawei-Beinloft I wasn't able to reproduce the issue. This might be because you're using windows.,able reproduce issue might,issue,negative,positive,positive,positive,positive,positive
1473329135,"when i running `yarn build` in the `mlflow/mlflow/server/js` folder , it report an error like: 
```
craco:  *** Cannot find ESLint plugin (ESLintWebpackPlugin). ***
C:\Users\zhangjiawei16\Desktop\MLflow\mlflow-branch-2.1\mlflow\server\js\craco.config.js:87
    throw new Error('Failed to fix CSS paths!');
```
Has anyone encountered this problem and how can I solve it?",running yarn build folder report error like find throw new error fix anyone problem solve,issue,negative,positive,neutral,neutral,positive,positive
1473233493,"@jmahlik Thanks for the reply! Can you comment on the doc?

> a user need to implement custom auth to get the user name in the before_request but then that may block them from using the built in after_request

Could you elaborate on this?",thanks reply comment doc user need implement custom get user name may block built could elaborate,issue,negative,positive,positive,positive,positive,positive
1473066650,"Its 450 MB.

On Fri, Mar 17, 2023, 05:11 Harutaka Kawamura ***@***.***>
wrote:

> @anirbankonar123 <https://github.com/anirbankonar123> I'm also curious
> how large your model is.
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/mlflow/mlflow/issues/8044#issuecomment-1472901201>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ADIW7N2Q64KGD5HXYSYV7SDW4OQLJANCNFSM6AAAAAAV4YBXLU>
> .
> You are receiving this because you were mentioned.Message ID:
> ***@***.***>
>
",mar wrote also curious large model reply directly view id,issue,negative,positive,neutral,neutral,positive,positive
1473066426,"I'm investigating why the confusiont matrix image is logged twice in the same run. I guess autologging logs it first and the default evaluator logs it again, then hits the error.",investigating matrix image logged twice run guess first default error,issue,negative,positive,positive,positive,positive,positive
1473064975,"One workaround is to create a new experiment without specifying the artifact location. If it's unspecifed, it's automatically set to a path under `dbfs:/databricks/` and file overwrite should work.",one create new experiment without artifact location automatically set path file overwrite work,issue,negative,positive,positive,positive,positive,positive
1473009685,"@dmcguire81 Thanks for reportin the issue. I was able to reproduce the issue with the following code:

```python
import mlflow

# Before running this script, create an experiment with artifact_location=dbfs:/path/to/location

mlflow.set_tracking_uri(""databricks"")
mlflow.set_experiment(""/path/to/experiment"")

with mlflow.start_run():
    mlflow.log_artifact(__file__)
    mlflow.log_artifact(__file__)
```

We're investigating the cause now.",thanks issue able reproduce issue following code python import running script create experiment investigating cause,issue,positive,positive,positive,positive,positive,positive
1472901201,"@anirbankonar123 I'm also curious how large your model is. If it's large, can you try increase the timeout for gunicorn?

```
mlflow server ... --gunicorn-opts=""--timeout 60""
```",also curious large model large try increase server,issue,positive,positive,positive,positive,positive,positive
1472893470,"@grofte Understood, can we replace the broken link with https://github.com/mlflow/mlflow/blob/master/examples/keras/train.py?

Would you be interested in filing a PR to fix this?",understood replace broken link would interested filing fix,issue,negative,negative,neutral,neutral,negative,negative
1472890826,"@AdamStelmaszczyk Understood, thanks for the explanation! I thought just logging the same parameter twice can reproduce the issue, but concurrent write is needed to reproduce. I was able to reproduce the issue using the attached code.",understood thanks explanation thought logging parameter twice reproduce issue concurrent write reproduce able reproduce issue attached code,issue,negative,positive,positive,positive,positive,positive
1472797941,"Hey @dbczumar great, happy to help. I have a solution mostly there but I've hit one snag. Could you give me advice on how to handle this circular import problem in my draft PR? https://github.com/mlflow/mlflow/pull/8048#discussion_r1139391853",hey great happy help solution mostly hit one snag could give advice handle circular import problem draft,issue,positive,positive,positive,positive,positive,positive
1472771435,"I'd love this feature to be added as well, any status updates?

It would be nice to display the spectrogram too, but that may be more difficult/time-consuming.",love feature added well status would nice display spectrogram may,issue,positive,positive,positive,positive,positive,positive
1472718292,"Sounds highly beneficial.  I'd for sure be interested in at least providing feedback after giving it a read over. Potentially working on some smaller PR's toward the end goal. 

Is there a good place to comment on the proposal? I have some initial thoughts on how it might play with other plugins, ex. a user need to implement custom auth to get the user name in the `before_request` but then that may block them from using the built in `after_request` . Wondered if enriching the request with the user info might be an alternate route. ",highly beneficial sure interested least providing feedback giving read potentially working smaller toward end goal good place comment proposal initial might play ex user need implement custom get user name may block built enriching request user might alternate route,issue,positive,positive,positive,positive,positive,positive
1472336151,"@jvschoen I am facing the same issue as you, I am on databricks as well.
How did you manage to fix it? I am getting 
`NameError: name '_mlflow_conda_env' is not defined`",facing issue well manage fix getting name defined,issue,negative,neutral,neutral,neutral,neutral,neutral
1471822338,"Hi @harupy 

The docs link to https://github.com/mlflow/mlflow/tree/master/examples/tensorflow which is a 404. But that's a page controlled by MLflow so you can either stop pointing to it or add something there.

The first place the MLflow docs link to that page are https://mlflow.org/docs/latest/tracking.html#keras (specifically in the text ""See example usages with [Keras](https://github.com/mlflow/mlflow/tree/master/examples/keras) and [TensorFlow](https://github.com/mlflow/mlflow/tree/master/examples/tensorflow)."" and ""As an example, try running the [MLflow TensorFlow examples](https://github.com/mlflow/mlflow/tree/master/examples/tensorflow)."")

The second place is https://mlflow.org/docs/latest/python_api/mlflow.tensorflow.html#mlflow.tensorflow.autolog (specifically in ""As an example, try running the [TensorFlow examples](https://github.com/mlflow/mlflow/tree/master/examples/tensorflow)."")

And there may be more places of course. I don't know where to search the docs source.",hi link page either stop pointing add something first place link page specifically text see example example try running second place specifically example try running may course know search source,issue,negative,positive,positive,positive,positive,positive
1471817769,"Could we also add a flavor for AutoGluon (multimodal) while we are at it?
Since in that case we need to store a larger breadth of prepocessing elements, it could be a nice litmus test for whether the currently considered approach will work.

Im currently relying on the kedro-mlflow definition of a pipeline, and storing everything as such as a pyfunc. This also allows one to store entire pipelines as well (alhough it is more opinionated).

anyway,[ there is already an issue open at Autogluon](https://github.com/autogluon/autogluon/issues/1404)",could also add flavor multimodal since case need store breadth could nice litmus test whether currently considered approach work currently definition pipeline everything also one store entire well opinionated anyway already issue open,issue,positive,positive,positive,positive,positive,positive
1471812255,"Unfortunately, I don't know how to test this with 100% repeatability to have an automatic test. One needs at least 2 threads performing DB inserts in exactly same time, so it's probabilistic. That's why I wrote client.py which shows the bug (exception thrown) let's say ~80% of time. So with manual testing it's fine, one can try several times client.py - but it doesn't seem suitable for an automatic test.",unfortunately know test repeatability automatic test one need least exactly time probabilistic wrote bug exception thrown let say time manual testing fine one try several time seem suitable automatic test,issue,negative,positive,neutral,neutral,positive,positive
1471727297,@grofte Thanks for catching the issue. Which page contains 404 links?,thanks catching issue page link,issue,negative,positive,positive,positive,positive,positive
1471711029,"Strange. If something goes wrong, stacktrace should be printed out. Have you tried the solution in https://stackoverflow.com/a/66874741?",strange something go wrong printed tried solution,issue,negative,negative,negative,negative,negative,negative
1471553508,"We see this exception : ""HTTPConnectionPool(host='mlflow.mlflow.svc.cluster.local', port=5000): Read timed out. (read timeout=10)""

In MLFlow server logs we only see : [2023-03-16 05:26:34 +0000] [14] [DEBUG] Ignoring EPIPE",see exception read timed read server see,issue,negative,neutral,neutral,neutral,neutral,neutral
1471488275,"We found the following line is failing intermittently for some projects:
client = MlflowClient()
local_path = client.download_artifacts(RUN_ID, ""model/model_final.pth"", local_dir)
--though the RUN_ID value is corr and there are artifacts for this RUN_ID.

downloading artifacts for RUN ID:93143830d0304237b3e73ecc1bf7a228
created client
HTTPConnectionPool(host='mlflow.mlflow.svc.cluster.local', port=5000): Read timed out. (read timeout=10)",found following line failing intermittently client though value run id client read timed read,issue,negative,neutral,neutral,neutral,neutral,neutral
1471404904,"We are not using nginx, but using gunicorn, checking this.

Thanks for the information.

On Thu, Mar 16, 2023 at 11:44 AM Harutaka Kawamura ***@***.***>
wrote:

> @anirbankonar123 <https://github.com/anirbankonar123> The same issue is
> reported in
> https://stackoverflow.com/questions/55768090/gunicorn-nginx-ignoring-epipe.
> Are you using nginx?
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/mlflow/mlflow/issues/8044#issuecomment-1471381128>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ADIW7N7YT32OU6MPP5QQ743W4KVTLANCNFSM6AAAAAAV4YBXLU>
> .
> You are receiving this because you were mentioned.Message ID:
> ***@***.***>
>
",thanks information mar wrote issue reply directly view id,issue,negative,positive,positive,positive,positive,positive
1471357627,"> LGTM. What is the process for making sure those tests post-merge?

Great question! I'll kick off the corresponding GitHub action manually after merge to make sure it passes",process making sure great question kick corresponding action manually merge make sure,issue,positive,positive,positive,positive,positive,positive
1471135289,"Hi @kabartay, did you get a chance to work on the catboost integration?",hi get chance work integration,issue,negative,neutral,neutral,neutral,neutral,neutral
1470769425,"@WeichenXu123 currently, the framework value is heavily nested in the tags and are also in different locations within the dictionary keys.

In order to do this for different frameworks I had to use the following code.
```
d = mlflow.get_run(run_id=run_id).to_dictionary()['data']['tags']['mlflow.log-model.history']
d = json.loads(d)[0]
d = list(d['flavors'].keys())

    for element in d: 
        if element in ['xgboost', 'tensorflow', 'sklearn']:
            print(element)
```
If something like `mlflow.get_run().framework` could be implemented it would be great.",currently framework value heavily also different within dictionary order different use following code list element element print element something like could would great,issue,positive,positive,positive,positive,positive,positive
1470516810,"@WeichenXu123 If possible it would be nice to get this automatically. In the use case we need, we don't have control on how the users send models to MLFlow in terms of tagging or other properties, but we need to know the model type in order to create a serving container using the correct framework",possible would nice get automatically use case need control send need know model type order create serving container correct framework,issue,positive,positive,positive,positive,positive,positive
1470504565,"> 

Thanks for the approval @dbczumar. Just curious what would be the next steps for getting this one merged, and will a new version be created for installation? ",thanks approval curious would next getting one new version installation,issue,positive,positive,neutral,neutral,positive,positive
1470275391,"@harupy just tried out your branch, and it works! Thank you so much for fixing this 🙌 ",tried branch work thank much fixing,issue,negative,positive,positive,positive,positive,positive
1470154161,"@BenWilson2 @dbczumar @harupy @WeichenXu123 

Open questions:
1. What should be covered by tests as a bare minimum (aside from newly added helper functions)?
2. Can the temp `nginx_conf` file eventually be left undeleted?
3. `mleap` (or `org.mlflow.sagemaker.ScoringServer` to be precise). `ScoringServer` runs the `Jetty` server internally. It is not clear to me how to pass `0.0.0.0` host address in a simple manner w/o refactoring the internals of `ScoringServer` 🤔

It would be nice to have any suggestions here. Thank you in advance!",open covered bare minimum aside newly added helper temp file eventually left undeleted precise jetty server internally clear pas host address simple manner internals would nice thank advance,issue,positive,positive,positive,positive,positive,positive
1470125385,It's looking great @benjaminbluhm :) Looking forward to the docs updates so we can get this fantastic example merged! ,looking great looking forward get fantastic example,issue,positive,positive,positive,positive,positive,positive
1470109459,"I have a similar issue: I set the tracking URI directly from the tracking_uri parameter of MLFlowLogger to ""http://localhost:5050/"". I also set the log_model parameter to True.

However, when the training is complete, I receive the following error:
`mlflow.exceptions.MlflowException: The configured tracking uri scheme: 'file' is invalid for use with the proxy mlflow-artifact scheme. The allowed tracking schemes are: {'http', 'https'}`

I checked the tracking_uri value of MLFlow, but it seems that it switched back to the default value. Does this mean that we also need to set the tracking URI manually with native MLFlow, or can we still rely on the logger?",similar issue set directly parameter also set parameter true however training complete receive following error scheme invalid use proxy scheme checked value switched back default value mean also need set manually native still rely logger,issue,positive,positive,neutral,neutral,positive,positive
1469016349,"Hi @arunkumarkota, just gently pinging on this. Let me know if there are any updates :D",hi gently let know,issue,negative,positive,positive,positive,positive,positive
1469015427,"@WillEngler Thank you for filing this issue. The use case and proposal make perfect sense to me, and we'd be excited to review a pull request with this functionality. Please let me know if you have any questions, and we look forward to your contribution. Thanks in advance!",thank filing issue use case proposal make perfect sense excited review pull request functionality please let know look forward contribution thanks advance,issue,positive,positive,positive,positive,positive,positive
1469013952,"Hi @M4nouel , thank you for raising this issue and for using MLflow. The problem and proposed fix make perfect sense. We would be very excited to review a pull request for this change. Please let me know if you have any questions, and thank you in advance for your contribution!",hi thank raising issue problem fix make perfect sense would excited review pull request change please let know thank advance contribution,issue,positive,positive,positive,positive,positive,positive
1468814702,"> @BenWilson2 @benjaminbluhm any updates here?

Hi @dbczumar @BenWilson2, will start working on the step-by-step walk through as part of the documentation from next week onwards. Will push an update once I have a first draft ready to get your feedback ",hi start working walk part documentation next week onwards push update first draft ready get feedback,issue,negative,positive,positive,positive,positive,positive
1468684688,"If you ask I can give more details about the steps involved in the reproduction and the results I get.
If I may, I have written a quick fix that will take into account `MLSERVER_INFER_WORKERS` variable environment if it is set (see https://mlserver.readthedocs.io/en/latest/reference/settings.html), or set `nworker` to `cpu_count` otherwise.

We can test the fix like this:
- build MLFlow locally: `python setup.py sdist bdist_wheel`
- create this Dockerfile in `dist` directory, where `mlserver_model_x:latest` is the image packaged with the old mlflow as in the issue description.
```
FROM mlserver_model_x:latest

COPY mlflow-2.2.3.dev0-py3-none-any.whl /tmp/
RUN pip uninstall -y mlflow && pip install /tmp/mlflow-2.2.3.dev0-py3-none-any.whl
```
- run `docker build . -t mlserver_model_x_fix:latest` in `dist` directory to produce `mlserver_model_x_fix:latest` image which will use mlflow-2.2.3.dev0
- run `docker run --rm -it -p 8080:8080 -p 8082:8082 -e MLSERVER_INFER_WORKERS=2 mlserver_model_x_fix:latest`

**output**:
```
➜  dist git:(master) docker run --rm -it -p 8080:8080 -p 8082:8082 -e MLSERVER_INFER_WORKERS=2 mlserver_model_x_fix:latest
2023-03-14 19:05:15,568 [mlserver.parallel] DEBUG - Starting response processing loop...
2023-03-14 19:05:15,569 [mlserver.rest] INFO - HTTP server running on http://0.0.0.0:8080
INFO:     Started server process [39]
INFO:     Waiting for application startup.
2023-03-14 19:05:15,604 [mlserver.metrics] INFO - Metrics server running on http://0.0.0.0:8082
2023-03-14 19:05:15,604 [mlserver.metrics] INFO - Prometheus scraping endpoint can be accessed on http://0.0.0.0:8082/metrics
INFO:     Started server process [39]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
2023-03-14 19:05:15,605 [mlserver.grpc] INFO - gRPC server running on http://0.0.0.0:8081
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8080 (Press CTRL+C to quit)
INFO:     Uvicorn running on http://0.0.0.0:8082 (Press CTRL+C to quit)
[2023-03-14 19:05:26,472] DEBUG /opt/ml/model/code/config.py:31 - LOG_LEVEL setted to DEBUG
[2023-03-14 19:05:26,472] DEBUG /opt/ml/model/code/config.py:31 - LOG_LEVEL setted to DEBUG
[2023-03-14 19:05:28,600] DEBUG /root/.mlflow/envs/mlflow-666d50f4cf285be857a595662c5bd79567ab6141/lib/python3.9/site-packages/tensorflow/python/distribute/cluster_resolver/tpu/tpu_cluster_resolver.py:32 - Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.
[2023-03-14 19:05:28,600] DEBUG /root/.mlflow/envs/mlflow-666d50f4cf285be857a595662c5bd79567ab6141/lib/python3.9/site-packages/tensorflow/python/distribute/cluster_resolver/tpu/tpu_cluster_resolver.py:32 - Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.
INFO:     172.17.0.1:48656 - ""GET /health HTTP/1.1"" 404 Not Found
2023-03-14 19:05:41,971 [mlserver] INFO - Loaded model 'mlflow-model' succesfully.
[2023-03-14 19:05:41,971] INFO /root/.mlflow/envs/mlflow-666d50f4cf285be857a595662c5bd79567ab6141/lib/python3.9/site-packages/mlserver/registry.py:160 - Loaded model 'mlflow-model' succesfully.
2023-03-14 19:05:42,137 [mlserver] INFO - Loaded model 'mlflow-model' succesfully.
[2023-03-14 19:05:42,137] INFO /root/.mlflow/envs/mlflow-666d50f4cf285be857a595662c5bd79567ab6141/lib/python3.9/site-packages/mlserver/registry.py:160 - Loaded model 'mlflow-model' succesfully.
2023-03-14 19:05:42,173 [mlserver] INFO - Loaded model 'mlflow-model' succesfully.
INFO:     172.17.0.1:39708 - ""GET /health HTTP/1.1"" 200 OK
```
we can see that only 2 workers are created.",ask give involved reproduction get may written quick fix take account variable environment set see set otherwise test fix like build locally python create directory latest image old issue description latest copy run pip pip install run docker build latest directory produce latest image use dev run docker run latest output git master docker run latest starting response loop server running server process waiting application metric server running scraping server process waiting application application complete server running application complete running press quit running press quit falling back client install cloud client directly pip install falling back client install cloud client directly pip install get found loaded model loaded model loaded model loaded model loaded model get see,issue,negative,positive,positive,positive,positive,positive
1468318652,"Hi all, We're planning to start work on this flavor starting today. 
We'll be leaning heavily into supporting PIpeline abstractions as a first class citizen (for pyfunc, spark_udf use cases) but also supporting the logging of Trainers, individual model components (logging a model, a tokenizer, and a feature extractor separately), and maintaining metadata logging to ensure that loading of any of these components from a saved state will create the appropriate object from the correct subclass. 
We should have this flavor officially supported and part of MLflow by the time that the next minor release is out! 
Thank you all for your continued interest in this and we'll be sure to have something useful for you to streamline your use of the fantastic transformers package!",hi start work flavor starting today leaning heavily supporting pipeline first class citizen use also supporting logging individual model logging model feature extractor separately logging ensure loading saved state create appropriate object correct subclass flavor officially part time next minor release thank continued interest sure something useful streamline use fantastic package,issue,positive,positive,positive,positive,positive,positive
1468308787,"> @hugocool maybe this helps? https://github.com/telekom/transformer-tools/blob/main/transformer_tools/mlflow_transformers_flavor.py

That is really nice, although it does not support mlflow v > 2. (I get an error with respect to mlflow.pyfunc.utils)
So ill have a look at the implementation in this PR, and the package you mentioned, merge them, see whether they work for my purposes, and ill report back.
",maybe really nice although support get error respect ill look implementation package merge see whether work ill report back,issue,negative,negative,neutral,neutral,negative,negative
1468298460,"Sorry, first time here. I have set the release notes category to none; I don't believe I have access to rerun failing validation. Let me know if I missed something.",sorry first time set release category none believe access rerun failing validation let know something,issue,negative,negative,negative,negative,negative,negative
1468287644,"Hi all, [this document](https://docs.google.com/document/d/1VpYM8MBOrY71tYr3C80xwJi_xWa94u4hSIKVjYuTJc0) proposes an opt-in authentication/authorization mechanism using Flask's before_request and after_request hooks. The proposed mechanism:

- protects MLflow resources (experiments, runs, etc.) and UI using Basic authentication.
- allows users to share their resouces with others.
- supports user management.

We'd appreciate any feedback on the proposal!

cc @jmahlik would you be interested in working on implementing the proposal with us (asking because you worked on #7757)?

cc @dbczumar",hi document mechanism flask mechanism basic authentication share user management appreciate feedback proposal would interested working proposal u worked,issue,positive,positive,positive,positive,positive,positive
1468180936,"@BenWilson2 @dbczumar @harupy @WeichenXu123 
We have tested the latest version 2.2.1.

Large files are getting uploaded(tested up to logging 3GB files ). But at the end of execution its throws error 504 at client

```
MLflow version: 2.2.1
Tracking URI: https://mlflow-rare23.internal.cloud/
experiment_id 3
System information: Linux #1 SMP Wed Dec 14 16:00:01 EST 2022
Python version: 3.10.8
MLflow version: 2.2.1
MLflow module location: /home/<userid>/.conda/envs/mlflow_env/lib/python3.10/site-packages/mlflow/__init__.py
Tracking URI: https://mlflow-rare23.internal.cloud/
Registry URI: https://mlflow-rare23.internal.cloud/
Active experiment ID: 3
Active run ID: 0ddf506217ca487c9a6493de3939c992
Active run artifact URI: mlflow-artifacts:/3/0ddf506217ca487c9a6493de3939c992/artifacts
MLflow environment variables:
  MLFLOW_ARTIFACT_UPLOAD_DOWNLOAD_TIMEOUT: 1200
  MLFLOW_TRACKING_INSECURE_TLS: True
MLflow dependencies:
  Flask: 2.2.2
  Jinja2: 3.1.2
  alembic: 1.9.1
  click: 8.1.3
  cloudpickle: 2.2.1
  databricks-cli: 0.17.4
  docker: 6.0.0
  entrypoints: 0.4
  gitpython: 3.1.30
  gunicorn: 20.1.0
  importlib-metadata: 4.11.4
  markdown: 3.4.1
  matplotlib: 3.6.3
  numpy: 1.23.5
  packaging: 22.0
  pandas: 1.5.3
  protobuf: 4.21.12
  pyarrow: 10.0.1
  pytz: 2022.7.1
  pyyaml: 6.0
  querystring-parser: 1.2.4
  requests: 2.28.2
  scikit-learn: 1.2.1
  scipy: 1.10.0
  shap: 0.41.0
  sqlalchemy: 1.4.46
  sqlparse: 0.4.3
write output





Traceback (most recent call last):
  File ""/home/<userid>/.conda/envs/mlflow_env/lib/python3.10/site-packages/requests/adapters.py"", line 489, in send
    resp = conn.urlopen(
  File ""/home/<userid>/.conda/envs/mlflow_env/lib/python3.10/site-packages/urllib3/connectionpool.py"", line 878, in urlopen
    return self.urlopen(
  File ""/home/<userid>/.conda/envs/mlflow_env/lib/python3.10/site-packages/urllib3/connectionpool.py"", line 878, in urlopen
    return self.urlopen(
  File ""/home/<userid>/.conda/envs/mlflow_env/lib/python3.10/site-packages/urllib3/connectionpool.py"", line 878, in urlopen
    return self.urlopen(
  [Previous line repeated 2 more times]
  File ""/home/<userid>/.conda/envs/mlflow_env/lib/python3.10/site-packages/urllib3/connectionpool.py"", line 868, in urlopen
    retries = retries.increment(method, url, response=response, _pool=self)
  File ""/home/<userid>/.conda/envs/mlflow_env/lib/python3.10/site-packages/urllib3/util/retry.py"", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='mlflow-rare23.internal.cloud', port=443): Max retries exceeded with url: /api/2.0/mlflow-artifacts/artifacts/3/0ddf506217ca487c9a6493de3939c992/artifacts/largefile (Caused by ResponseError('too many 504 error responses'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/<userid>/.conda/envs/mlflow_env/lib/python3.10/site-packages/mlflow/utils/rest_utils.py"", line 167, in http_request
    return _get_http_response_with_retries(
  File ""/home/<userid>/.conda/envs/mlflow_env/lib/python3.10/site-packages/mlflow/utils/rest_utils.py"", line 98, in _get_http_response_with_retries
    return session.request(method, url, **kwargs)
  File ""/home/<userid>/.conda/envs/mlflow_env/lib/python3.10/site-packages/requests/sessions.py"", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File ""/home/<userid>/.conda/envs/mlflow_env/lib/python3.10/site-packages/requests/sessions.py"", line 701, in send
    r = adapter.send(request, **kwargs)
  File ""/home/<userid>/.conda/envs/mlflow_env/lib/python3.10/site-packages/requests/adapters.py"", line 556, in send
    raise RetryError(e, request=request)
requests.exceptions.RetryError: HTTPSConnectionPool(host='mlflow-rare23.internal.cloud', port=443): Max retries exceeded with url: /api/2.0/mlflow-artifacts/artifacts/3/0ddf506217ca487c9a6493de3939c992/artifacts/largefile (Caused by ResponseError('too many 504 error responses'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/<userid>/mlflow-testing/run.py"", line 98, in <module>
    mlflow.log_artifact(""largefile"")
  File ""/home/<userid>/.conda/envs/mlflow_env/lib/python3.10/site-packages/mlflow/tracking/fluent.py"", line 783, in log_artifact
    MlflowClient().log_artifact(run_id, local_path, artifact_path)
  File ""/home/<userid>/.conda/envs/mlflow_env/lib/python3.10/site-packages/mlflow/tracking/client.py"", line 1023, in log_artifact
    self._tracking_client.log_artifact(run_id, local_path, artifact_path)
  File ""/home/<userid>/.conda/envs/mlflow_env/lib/python3.10/site-packages/mlflow/tracking/_tracking_service/client.py"", line 439, in log_artifact
    artifact_repo.log_artifact(local_path, artifact_path)
  File ""/home/<userid>/.conda/envs/mlflow_env/lib/python3.10/site-packages/mlflow/store/artifact/http_artifact_repo.py"", line 25, in log_artifact
    resp = http_request(self._host_creds, endpoint, ""PUT"", data=f)
  File ""/home/<userid>/.conda/envs/mlflow_env/lib/python3.10/site-packages/mlflow/utils/rest_utils.py"", line 185, in http_request
    raise MlflowException(f""API request to {url} failed with exception {e}"")
mlflow.exceptions.MlflowException: API request to https://mlflow-rare23.internal.cloud/api/2.0/mlflow-artifacts/artifacts/3/0ddf506217ca487c9a6493de3939c992/artifacts/largefile failed with exception HTTPSConnectionPool(host='mlflow-rare23.internal.cloud', port=443): Max retries exceeded with url: /api/2.0/mlflow-artifacts/artifacts/3/0ddf506217ca487c9a6493de3939c992/artifacts/largefile (Caused by ResponseError('too many 504 error responses'))

```",tested latest version large getting tested logging end execution error client version system information wed python version version module location registry active experiment id active run id active run artifact environment true flask jinja alembic click docker markdown shap write output recent call last file line send resp file line return file line return file line return previous line repeated time file line method file line increment raise error cause many error handling exception another exception recent call last file line return file line return method file line request resp prep file line send request file line send raise many error handling exception another exception recent call last file line module file line file line file line file line resp put file line raise request exception request exception many error,issue,negative,positive,positive,positive,positive,positive
1467742149,Awesome work! @dbczumar Will this fix also be patched to the `1.x` version? We're still using `1.x` internally :),awesome work fix also version still internally,issue,positive,positive,positive,positive,positive,positive
1467265797,"Thanks @dbczumar , I am glad you confirmed this because I had already removed it earlier today :)
and thank you for building MLFlow! Please feel free to close the ticket now. I apologise if filing it as a bug might have caused you any grief.",thanks glad confirmed already removed today thank building please feel free close ticket filing bug might grief,issue,positive,positive,positive,positive,positive,positive
1467110035,"> Hi @marioga , sorry to hear about the REST API stability difficulties you're encountering with MLflow v2. Unfortunately, we haven't seen these issues reported by other users as of yet. By chance, are you running a proxy layer between the client and the Kubernetes-hosted MLflow service?

Hi @dbczumar , we expose our MLflow service (as well as many other services) using an Ambassador API Gateway. Our setup is roughly similar to what's described here: https://www.digitalocean.com/community/tutorials/how-to-create-an-api-gateway-using-ambassador-on-digitalocean-kubernetes",hi sorry hear rest stability unfortunately seen yet chance running proxy layer client service hi expose service well many ambassador gateway setup roughly similar,issue,negative,negative,negative,negative,negative,negative
1467075430,"Thanks @jmahlik!

@sunishsheth2009 Can you advise here? Option 1 sounds quite appealing :)",thanks advise option quite appealing,issue,negative,positive,positive,positive,positive,positive
1467069467,"Thank you, @sauerburger. For now, we do not plan to implement name-based experiment hiding. We do recommend using experiment tags or experiment naming conventions of your choosing, along with the https://mlflow.org/docs/latest/python_api/mlflow.client.html#mlflow.client.MlflowClient.rename_experiment API, to keep track of which experiments are relevant and which can be deleted later on.

Thank you so much for using MLflow!",thank plan implement experiment recommend experiment experiment naming choosing along keep track relevant later thank much,issue,positive,positive,positive,positive,positive,positive
1467065853,"Thanks @smartlymo! The Java dependencies are included in the MLflow model server to support serving Spark models with MLeap. There is no other purpose for the JDK, and you can remove it if you don't need to serve Spark models with MLeap.

We'll get this information documented.

I absolutely agree that the ability to specify customer dockerfiles would be very useful. We will consider this for future prioritization.

Thank you for using MLflow!",thanks included model server support serving spark purpose remove need serve spark get information absolutely agree ability specify customer would useful consider future thank,issue,positive,positive,positive,positive,positive,positive
1467060478,@beasteers Thank you for creating this feature request. I agree that this is a useful capability. We will certainly consider it for future prioritization.,thank feature request agree useful capability certainly consider future,issue,positive,positive,positive,positive,positive,positive
1467059046,"Thanks @sunishsheth2009 .

@darenr Would you be willing to try upgrading [showdown](https://www.npmjs.com/package/showdown) to see if the latest version works with the MLflow UI and, if so, file an upgrade PR? We would really appreciate your contribution :D",thanks would willing try showdown see latest version work file upgrade would really appreciate contribution,issue,positive,positive,positive,positive,positive,positive
1467057250,"Hi @davideCremona , thank you for filing this issue. To isolate the problem, can you check whether the following script runs successfully?:

```
from ftplib import FTP

import posixpath
import urllib.parse

from urllib.parse import unquote

artifact_uri = ""ftp://<mlflow_ftp_user>:<mlflow_ftp_psw>@10.11.12.2/home/mlflow""
parsed = urllib.parse.urlparse(artifact_uri)
config = {
            ""host"": parsed.hostname,
            ""port"": 21 if parsed.port is None else parsed.port,
            ""username"": parsed.username,
            ""password"": parsed.password,
}
ftp = FTP()
ftp.connect(self.config[""host""], self.config[""port""])
ftp.login(self.config[""username""], self.config[""password""])
ftp.cwd(""/home/mlflow"")
```",hi thank filing issue isolate problem check whether following script successfully import import import import unquote host port none else password host port password,issue,negative,positive,positive,positive,positive,positive
1467047326,"Hi @marioga , sorry to hear about the REST API stability difficulties you're encountering with MLflow v2. Unfortunately, we haven't seen these issues reported by other users as of yet. By chance, are you running a proxy layer between the client and the Kubernetes-hosted MLflow service?",hi sorry hear rest stability unfortunately seen yet chance running proxy layer client service,issue,negative,negative,negative,negative,negative,negative
1466995091,"Awesome! Thanks @sunishsheth2009 , @n3011 . I'll merge once tests pass :)",awesome thanks merge pas,issue,positive,positive,positive,positive,positive,positive
1466482703,"is there any movement on this issue?
Could I contribute in any way? Id like to log transformer models to MLFlow, so id love to use this flavor.",movement issue could contribute way id like log transformer id love use flavor,issue,positive,positive,positive,positive,positive,positive
1466225562,"Hi, actually we didn't file a databricks ticket in the end. We ended up executing the parts of the code that require loading such  models from notebooks and/or jobs instead of using databricks-connect. Perhaps you can also try executing it via the new [databricks extension for VS code ](https://docs.databricks.com/dev-tools/vscode-ext.html) and see if it's fixed there? ",hi actually file ticket end ended code require loading instead perhaps also try via new extension code see fixed,issue,negative,positive,neutral,neutral,positive,positive
1465884861,"> The only thing I can think of that might cause cache issues is if the hashes don't update when the source does. 

Yeah, I think that we can leave the responsibility of correctly recalculating hashes to CRA.
I think it's ok to open a PR with the discussed changes (caching assets, leaving `no-cache` on index.html) - let us know if you're willing to do so 🙂 ",thing think might cause cache update source yeah think leave responsibility correctly think open asset leaving let u know willing,issue,positive,positive,positive,positive,positive,positive
1465723742,"> I'm not able to use deprecated annotation for the higher_is_better property method because it throws exception ""AttributeError: 'property' object has no attribute 'module'""

I guess you tried:

```python
@deprecated(...)
@property
def f(...):
    ...
```

Swapping `property` and `deprecated` should work.


```python
@property
@deprecated(...)
def f(...):
    ...
```
",able use annotation property method exception object attribute guess tried python property swapping property work python property,issue,negative,positive,positive,positive,positive,positive
1465547529,"@cchan-lm Thanks for reporting the issue! We're planning to make a patch release this week. Would you mind testing our release candidate using the following command?

```bash
# Install mlflow from https://github.com/mlflow/mlflow/commits/branch-2.2
pip install git+https://github.com/mlflow/mlflow.git@branch-2.2
```

https://github.com/mlflow/mlflow/pull/7993 is a patch for this issue.",thanks issue make patch release week would mind testing release candidate following command bash install pip install patch issue,issue,negative,positive,neutral,neutral,positive,positive
1465284218,cc: @harupy @dbczumar - @niklasdiehm I think we'd be happy to help out if you give it a try!,think happy help give try,issue,positive,positive,positive,positive,positive,positive
1465264021,"I'm willing to contribute to this feature request, but I never contributed to this project before, so I will probably need some help.",willing contribute feature request never project probably need help,issue,negative,positive,positive,positive,positive,positive
1464878285,"@dbczumar, @BenWilson2, @harupy, or @WeichenXu123 I would like to contribute to the design.Please advise.Is there a current design which can be referred to.",would like contribute current design,issue,negative,neutral,neutral,neutral,neutral,neutral
1464463685,"@WeichenXu123 FYI I closed the original pull request, because I forgot to signoff on the commits and was stuck in rebase hell, so I created a new PR which I updated above, but [here it is also ](https://github.com/mlflow/mlflow/pull/8009)",closed original pull request forgot stuck rebase hell new also,issue,negative,positive,positive,positive,positive,positive
1464331207,"I believe this is an issue with mysql `5.6`. If anyone is still having this issue, I made [this fork](https://github.com/NarekA/mlflow) which resolves it. If you deploy the fork once, it will create your database and then you can deploy the current version.",believe issue anyone still issue made fork deploy fork create deploy current version,issue,negative,neutral,neutral,neutral,neutral,neutral
1464328748,"If anyone is still having this issue, I made [this fork](https://github.com/NarekA/mlflow) which resolves it. If you deploy the fork once, it will create your database and then you can deploy the current version.",anyone still issue made fork deploy fork create deploy current version,issue,negative,neutral,neutral,neutral,neutral,neutral
1464051927,"Hey y'all, thanks for the work on this so far! Is there any update on this or an existing PR / other issue regarding adding the Run ID to the column selector? I still think that this would be an extremely useful feature for identifying and cross-referencing runs. ",hey thanks work far update issue regarding run id column selector still think would extremely useful feature,issue,positive,positive,positive,positive,positive,positive
1463942492,"Hello,

Could someone please tell me why this `__MlflowPLCallback` isn't actually used when using a `pytorch_lightning.Trainer` with a 
`pytorch_lightning.loggers.MLFlowLogger`? I had a hard time understanding that `__MlflowPLCallback` is **not** integrated into `pytorch_lightning`. 

Lightning code [here](https://github.com/Lightning-AI/lightning/blob/95831286b390fd90337bd97e2f624c67f5fba818/src/lightning/pytorch/trainer/connectors/checkpoint_connector.py#L402) and [here](https://github.com/Lightning-AI/lightning/blob/7c80fe6990dfa8c8ce77e74f425239123cfdd50b/src/lightning/pytorch/loggers/mlflow.py#L363) causes checkpoints to be uploaded as state dicts instead of whole `LightningModule`s, therefore it is not possible to use `torch.load()` directly on such checkpoints (not saying I would need this feature, just that it was what I expected `mlflow` to do as it does do it in `mlflow.pytorch.load_model()`)

Thanks in advance ;)",hello could someone please tell actually used hard time understanding lightning code state instead whole therefore possible use directly saying would need feature thanks advance,issue,positive,positive,neutral,neutral,positive,positive
1463476459,"@CarlaFernandez Did you solve your problem ?  Can we have the link to follow databricks ES ticket ?
I have the same problem with runtime 10.4, only with pyspark model. sklearn model are corectly loaded",solve problem link follow e ticket problem model model loaded,issue,negative,neutral,neutral,neutral,neutral,neutral
1463393638,"@WeichenXu123 ,

Thanks for response. Please find the full traceback log for this warning.

2023/03/10 07:34:20 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed, possibly due older server version. The model artifacts have been logged successfully under s3://rml-model-artifacts/users/csvishnumurthy/3/bf8257f63fc84f6c870e0674d4dea615/artifacts. In addition to exporting model artifacts, MLflow clients 1.7.0 and above attempt to record model metadata to the tracking store. If logging to a mlflow server via REST, consider upgrading the server version to MLflow 1.7.0 or above. Set logging level to DEBUG via `logging.getLogger(""mlflow"").setLevel(logging.DEBUG)` to see the full traceback.
2023/03/10 07:34:20 DEBUG mlflow.models.model: 
Traceback (most recent call last):
  File ""/miniconda/lib/python3.10/site-packages/mlflow/models/model.py"", line 489, in log
    mlflow.tracking.fluent._record_logged_model(mlflow_model)
  File ""/miniconda/lib/python3.10/site-packages/mlflow/tracking/fluent.py"", line 985, in _record_logged_model
    MlflowClient()._record_logged_model(run_id, mlflow_model)
  File ""/miniconda/lib/python3.10/site-packages/mlflow/tracking/client.py"", line 1370, in _record_logged_model
    self._tracking_client._record_logged_model(run_id, mlflow_model)
  File ""/miniconda/lib/python3.10/site-packages/mlflow/tracking/_tracking_service/client.py"", line 404, in _record_logged_model
    self.store.record_logged_model(run_id, mlflow_model)
  File ""/miniconda/lib/python3.10/site-packages/mlflow/store/tracking/rest_store.py"", line 325, in record_logged_model
    self._call_endpoint(LogModel, req_body)
  File ""/miniconda/lib/python3.10/site-packages/mlflow/store/tracking/rest_store.py"", line 56, in _call_endpoint
    return call_endpoint(self.get_host_creds(), endpoint, method, json_body, response_proto)
  File ""/miniconda/lib/python3.10/site-packages/mlflow/utils/rest_utils.py"", line 281, in call_endpoint
    response = verify_rest_response(response, endpoint)
  File ""/miniconda/lib/python3.10/site-packages/mlflow/utils/rest_utils.py"", line 207, in verify_rest_response
    raise RestException(json.loads(response.text))
mlflow.exceptions.RestException: INVALID_PARAMETER_VALUE: Tag value '[{""run_id"": ""bf8257f63fc84f6c870e0674d4dea615"", ""artifact_path"": ""model"", ""utc_time_created"": ""2023-03-10 07:34:20.350545"", ""flavors"": {""python_function"": {""model_path"": ""model.pkl"", ""predict_fn"": ""predict"", ""loader_module"": ""mlflow.sklearn"", ""python' had length 28273, which exceeded length limit of 5000",thanks response please find full log warning warning logging model server possibly due older server version model logged successfully addition model attempt record model store logging server via rest consider server version set logging level via see full recent call last file line log file line file line file line file line file line return method file line response response file line raise tag value model predict python length length limit,issue,positive,positive,positive,positive,positive,positive
1463387007,"Hi @WeichenXu123 ,

Thanks for response. I have analyzed and found that dataframe serilization does not take much time but model prediction takes time when the model signature is present.  During model invocation, model input data is being validated against the model signature and the data type enforcement is applied. The following is the reason for higher latency during this process.

- In the method _enforce_col_schema (Line no 444 in https://github.com/mlflow/mlflow/blob/master/mlflow/models/utils.py), a empty data frame is crated and data type enforcement (_enforce_mlflow_datatype) is performed on every column. The output of this function is inserted as new column in the new data frame. Hence, it is taking time (warning message indicates that)

The following is the example code to prove the above reason.

Create a dataframe with 600 columns:
``
dfx, dfy = make_classification(n_samples=100, n_features=600)
dfx = pd.DataFrame(dfx)
print(dfx.shape)
ncols = dfx.shape[1]
col_pre = 'col'
col_name = list()
for i in np.arange(0,ncols):
    col_name.append(col_pre + str(i))
dfx.columns = col_name
`

- Example Code1 (Copy each column to new dataframe)

```
%%time
new_pf_input = pd.DataFrame()
for column in dfx.columns.values:
    new_pf_input[column] = dfx[column]
```
The above code takes approximately 175ms

- Example Code2 (Copy the entire dataframe and update each column)

`
%%time
new_pf_input = dfx.copy(deep=True)
for column in dfx.columns.values:
    new_pf_input[column] = dfx[column]
`
The above code takes around 86ms

### Solution:
I propose the following changes in two methods
1) Copy the entire input dataframe to new dataframe
2) Perform data type enforcement 
3) If there is change of data type, then only copy the updated column

**enforce_col_schema:**
def _enforce_col_schema(pf_input, input_schema):
    """"""Enforce the input columns conform to the model's column-based signature.""""""
    if input_schema.has_input_names():
        input_names = input_schema.input_names()
    else:
        input_names = pf_input.columns[: len(input_schema.inputs)]
    input_types = input_schema.input_types()
    
#    new_pf_input = pd.DataFrame()
    new_pf_input = pf_input.copy(deep=True)
    for i, x in enumerate(input_names):
#        new_pf_input[x] = enforce_mlflow_datatype(x, pf_input[x], input_types[i])
        change, values = enforce_mlflow_datatype_2(x, pf_input[x], input_types[i])
        if change == True:
            new_pf_input[x] = values
        
        return new_pf_input

**_enforce_mlflow_datatype**
def enforce_mlflow_datatype_2(name, values: pd.Series, t: DataType):
    """"""
    Enforce the input column type matches the declared in model input schema.
    The following type conversions are allowed:
    1. object -> string
    2. int -> long (upcast)
    3. float -> double (upcast)
    4. int -> double (safe conversion)
    5. np.datetime64[x] -> datetime (any precision)
    6. object -> datetime
    NB: pandas does not have native decimal data type, when user train and infer
    model from pyspark dataframe that contains decimal type, the schema will be
    treated as float64.
    7. decimal -> double
    Any other type mismatch will raise error.
    """"""
    if values.dtype == object and t not in (DataType.binary, DataType.string):
        values = values.infer_objects()

    if t == DataType.string and values.dtype == object:
        # NB: the object can contain any type and we currently cannot cast to pandas Strings
        # due to how None is cast
        change = False
        return (change, values)
#        return values

    # NB: Comparison of pandas and numpy data type fails when numpy data type is on the left hand
    # side of the comparison operator. It works, however, if pandas type is on the left hand side.
    # That is because pandas is aware of numpy.
    if t.to_pandas() == values.dtype or t.to_numpy() == values.dtype:
        # The types are already compatible => conversion is not necessary.
        change = False
        return (change, values)
#        return values

    if t == DataType.binary and values.dtype.kind == t.binary.to_numpy().kind:
        # NB: bytes in numpy have variable itemsize depending on the length of the longest
        # element in the array (column). Since MLflow binary type is length agnostic, we ignore
        # itemsize when matching binary columns.
        change = False
        return (change, values)
#        return values

    if t == DataType.datetime and values.dtype.kind == t.to_numpy().kind:
        # NB: datetime values have variable precision denoted by brackets, e.g. datetime64[ns]
        # denotes nanosecond precision. Since MLflow datetime type is precision agnostic, we
        # ignore precision when matching datetime columns.
        change = True
        values = values.astype(np.dtype(""datetime64[ns]""))
        return (change, values)
#        return values.astype(np.dtype(""datetime64[ns]""))

    if t == DataType.datetime and values.dtype == object:
        # NB: Pyspark date columns get converted to object when converted to a pandas
        # DataFrame. To respect the original typing, we convert the column to datetime.
        try:
            return values.astype(np.dtype(""datetime64[ns]""), errors=""raise"")
        except ValueError as e:
            raise MlflowException(
                ""Failed to convert column {} from type {} to {}."".format(name, values.dtype, t)
            ) from e
    if t == DataType.double and values.dtype == decimal.Decimal:
        # NB: Pyspark Decimal column get converted to decimal.Decimal when converted to pandas
        # DataFrame. In order to support decimal data training from spark data frame, we add this
        # conversion even we might lose the precision.
        try:
            return pd.to_numeric(values, errors=""raise"")
        except ValueError:
            raise MlflowException(
                ""Failed to convert column {} from type {} to {}."".format(name, values.dtype, t)
            )

    numpy_type = t.to_numpy()
    if values.dtype.kind == numpy_type.kind:
        is_upcast = values.dtype.itemsize <= numpy_type.itemsize
    elif values.dtype.kind == ""u"" and numpy_type.kind == ""i"":
        is_upcast = values.dtype.itemsize < numpy_type.itemsize
    elif values.dtype.kind in (""i"", ""u"") and numpy_type == np.float64:
        # allow (u)int => double conversion
        is_upcast = values.dtype.itemsize <= 6
    else:
        is_upcast = False

    if is_upcast:
        change = True
        values = values.astype(numpy_type, errors=""raise"")
        return (change, values)
#        return values.astype(numpy_type, errors=""raise"")
    else:
        # NB: conversion between incompatible types (e.g. floats -> ints or
        # double -> float) are not allowed. While supported by pandas and numpy,
        # these conversions alter the values significantly.
        def all_ints(xs):
            return all(pd.isnull(x) or int(x) == x for x in xs)

        hint = """"
        if (
            values.dtype == np.float64
            and numpy_type.kind in (""i"", ""u"")
            and values.hasnans
            and all_ints(values)
        ):
            hint = (
                "" Hint: the type mismatch is likely caused by missing values. ""
                ""Integer columns in python can not represent missing values and are therefore ""
                ""encoded as floats. The best way to avoid this problem is to infer the model ""
                ""schema based on a realistic data sample (training dataset) that includes missing ""
                ""values. Alternatively, you can declare integer columns as doubles (float64) ""
                ""whenever these columns may have missing values. See `Handling Integers With ""
                ""Missing Values <https://www.mlflow.org/docs/latest/models.html#""
                ""handling-integers-with-missing-values>`_ for more details.""
            )

        raise MlflowException(
            ""Incompatible input types for column {}. ""
            ""Can not safely convert {} to {}.{}"".format(name, values.dtype, numpy_type, hint)
        )

I have tested the above changes locally in my system. The latency for invocation reduced from 180ms to 15ms.

Please review my proposal and let me know if you need any other details from me. Thanks",hi thanks response found take much time model prediction time model signature present model invocation model input data model signature data type enforcement applied following reason higher latency process method line empty data frame data type enforcement every column output function inserted new column new data frame hence taking time warning message following example code prove reason create print list example code copy column new time column column column code approximately example code copy entire update column time column column column code around solution propose following two copy entire input new perform data type enforcement change data type copy column enforce input conform model signature else enumerate change change true return name enforce input column type declared model input schema following type object string long upcast float double upcast double safe conversion precision object native decimal data type user train infer model decimal type schema float decimal double type mismatch raise object object object contain type currently cast due none cast change false return change return comparison data type data type left hand side comparison operator work however type left hand side aware already compatible conversion necessary change false return change return variable depending length element array column since binary type length agnostic ignore matching binary change false return change return variable precision precision since type precision agnostic ignore precision matching change true return change return object date get converted object converted respect original convert column try return raise except raise convert column type name decimal column get converted converted order support decimal data training spark data frame add conversion even might lose precision try return raise except raise convert column type name allow double conversion else false change true raise return change return raise else conversion incompatible double float alter significantly return hint hint hint type mismatch likely missing integer python represent missing therefore best way avoid problem infer model schema based realistic data sample training missing alternatively declare integer float whenever may missing see handling missing raise incompatible input column safely convert name hint tested locally system latency invocation reduced please review proposal let know need thanks,issue,positive,positive,neutral,neutral,positive,positive
1463189629,"Facing same issue with MLFlow: https://mlflow.org/docs/latest/python_api/mlflow.shap.html#mlflow.shap.log_explainer .

I cannot automate the shap explainer pipeline with MLFlow :(",facing issue shap explainer pipeline,issue,negative,neutral,neutral,neutral,neutral,neutral
1462748363,"To provide a specific error handling message that is much more user friendly, we'd likely want to create a decorator for the main cli entrypoint that catches this Exception and throws with a new message. Thoughts on this, @harupy ?",provide specific error handling message much user friendly likely want create decorator main exception new message,issue,negative,positive,positive,positive,positive,positive
1462669888,"I had the same issue today, because I got a wrong token.

I'm using only the MLFlow 2.1.1 cli from the terminal, connecting to a remote tracking server from Databricks.

Any command with the CLI fails with this stack:
```
    return self.store.search_experiments(
  File ""/Users/luis/extra_code/mlops/mlserver-trial/venv/lib/python3.9/site-packages/mlflow/store/tracking/rest_store.py"", line 75, in search_experiments
    response_proto = self._call_endpoint(SearchExperiments, req_body)
  File ""/Users/luis/extra_code/mlops/mlserver-trial/venv/lib/python3.9/site-packages/mlflow/store/tracking/rest_store.py"", line 56, in _call_endpoint
    return call_endpoint(self.get_host_creds(), endpoint, method, json_body, response_proto)
  File ""/Users/luis/extra_code/mlops/mlserver-trial/venv/lib/python3.9/site-packages/mlflow/utils/rest_utils.py"", line 283, in call_endpoint
    response = verify_rest_response(response, endpoint)
  File ""/Users/luis/extra_code/mlops/mlserver-trial/venv/lib/python3.9/site-packages/mlflow/utils/rest_utils.py"", line 207, in verify_rest_response
    raise RestException(json.loads(response.text))
  File ""/Users/luis/extra_code/mlops/mlserver-trial/venv/lib/python3.9/site-packages/mlflow/exceptions.py"", line 103, in __init__
    super().__init__(message, error_code=ErrorCode.Value(error_code))
  File ""/Users/luis/extra_code/mlops/mlserver-trial/venv/lib/python3.9/site-packages/google/protobuf/internal/enum_type_wrapper.py"", line 82, in Value
    raise ValueError('Enum {} has no value defined for name {!r}'.format(
ValueError: Enum ErrorCode has no value defined for name '403'
```

adding debug I see the server response has status 403 and body:
```json
{""error_code"":""403"",""message"":""Invalid access token.""}
```

The path to error is then:
https://github.com/mlflow/mlflow/blob/ffe005c58dd45e4f200bfb5a77aa5273a57ca39d/mlflow/utils/rest_utils.py#L205-L208

as the response can be parsed a RestException is raised:
https://github.com/mlflow/mlflow/blob/ffe005c58dd45e4f200bfb5a77aa5273a57ca39d/mlflow/exceptions.py#L93-L103

That error code dictionary comes from:
https://github.com/mlflow/mlflow/blob/ffe005c58dd45e4f200bfb5a77aa5273a57ca39d/mlflow/protos/databricks_pb2.py#L20-L33

That seems to respond to other API codes, that are not http status.

Fixing this will allow cli users to have a better experience, by being able to visualize the error, could be invalid token or any other non 200 status code.

I can work on it but I don't know how those error codes will fit together with standard http status codes.

Any thougths @BenWilson2 @harupy ?
",issue today got wrong token terminal remote server command stack return file line file line return method file line response response file line raise file line super message file line value raise value defined name value defined name see server response status body message invalid access token path error response raised error code dictionary come respond status fixing allow better experience able visualize error could invalid token non status code work know error fit together standard status,issue,positive,positive,positive,positive,positive,positive
1462548311,"Good catch on the `index.html` @hubertzub-db. 

Seems like the above should shave a solid few seconds off the page load for a real use case (k8's deployment behind nginx and a load balancer). I'd imagine other mlflow deployments in the wild are somewhat similarly configured.

Quick pic of the network tab below. All the green would be time saved for both the client and server. 

![image](https://user-images.githubusercontent.com/38999128/224111180-5817385a-0c13-482c-8aa5-a3541fa514b8.png)

The only thing I can think of that might cause cache issues is if the hashes don't update when the source does. The way create react app is configured does hash based on source (see details), so doesn't seem to be a concern.


<details>

Make a small change and rebuild. Results in different hashes for `main.js`.

```patch
diff --git a/mlflow/server/js/src/experiment-tracking/components/HomePage.js b/mlflow/server/js/src/experiment-tracking/components/HomePage.js
index 89b4ad4f1..e59ae017b 100644
--- a/mlflow/server/js/src/experiment-tracking/components/HomePage.js
+++ b/mlflow/server/js/src/experiment-tracking/components/HomePage.js
@@ -32,6 +32,9 @@ export class HomePageImpl extends Component {
   }

   render() {
+    const hello = {}
+    console.log(hello);
+
     const homeView = (
       <HomeView
         history={this.props.history}
```

```diff
*** asset-manifest-pre.json     2023-03-09 12:03:21.098424300 -0600
--- ./build/asset-manifest.json 2023-03-09 12:06:39.005817500 -0600
***************
*** 1,7 ****
  {
    ""files"": {
      ""main.css"": ""/static-files/static/css/main.cf5f55dc.css"",
!     ""main.js"": ""/static-files/static/js/main.7eabccff.js"",
      ""static/js/113.ade46c2e.chunk.js"": ""/static-files/static/js/113.ade46c2e.chunk.js"",
      ""static/js/49.7e6414e5.chunk.js"": ""/static-files/static/js/49.7e6414e5.chunk.js"",
      ""static/js/243.8158ea45.chunk.js"": ""/static-files/static/js/243.8158ea45.chunk.js"",
--- 1,7 ----
  {
    ""files"": {
      ""main.css"": ""/static-files/static/css/main.cf5f55dc.css"",
!     ""main.js"": ""/static-files/static/js/main.ad4f2ebb.js"",
      ""static/js/113.ade46c2e.chunk.js"": ""/static-files/static/js/113.ade46c2e.chunk.js"",
      ""static/js/49.7e6414e5.chunk.js"": ""/static-files/static/js/49.7e6414e5.chunk.js"",
      ""static/js/243.8158ea45.chunk.js"": ""/static-files/static/js/243.8158ea45.chunk.js"",
***************
*** 46,52 ****
      ""static/media/job.svg"": ""/static-files/static/media/job.6a7e5f3695068e7fa63e60ffcc34641c.svg"",
      ""static/media/chart-line.svg"": ""/static-files/static/media/chart-line.0adaa2036bb4eb5956db6d0c7e925a3d.svg"",
      ""main.cf5f55dc.css.map"": ""/static-files/static/css/main.cf5f55dc.css.map"",
!     ""main.7eabccff.js.map"": ""/static-files/static/js/main.7eabccff.js.map"",
      ""113.ade46c2e.chunk.js.map"": ""/static-files/static/js/113.ade46c2e.chunk.js.map"",
      ""49.7e6414e5.chunk.js.map"": ""/static-files/static/js/49.7e6414e5.chunk.js.map"",
      ""243.8158ea45.chunk.js.map"": ""/static-files/static/js/243.8158ea45.chunk.js.map"",
--- 46,52 ----
      ""static/media/job.svg"": ""/static-files/static/media/job.6a7e5f3695068e7fa63e60ffcc34641c.svg"",
      ""static/media/chart-line.svg"": ""/static-files/static/media/chart-line.0adaa2036bb4eb5956db6d0c7e925a3d.svg"",
      ""main.cf5f55dc.css.map"": ""/static-files/static/css/main.cf5f55dc.css.map"",
!     ""main.ad4f2ebb.js.map"": ""/static-files/static/js/main.ad4f2ebb.js.map"",
      ""113.ade46c2e.chunk.js.map"": ""/static-files/static/js/113.ade46c2e.chunk.js.map"",
      ""49.7e6414e5.chunk.js.map"": ""/static-files/static/js/49.7e6414e5.chunk.js.map"",
      ""243.8158ea45.chunk.js.map"": ""/static-files/static/js/243.8158ea45.chunk.js.map"",
***************
*** 67,72 ****
    },
    ""entrypoints"": [
      ""static/css/main.cf5f55dc.css"",
!     ""static/js/main.7eabccff.js""
    ]
  }
\ No newline at end of file
--- 67,72 ----
    },
    ""entrypoints"": [
      ""static/css/main.cf5f55dc.css"",
!     ""static/js/main.ad4f2ebb.js""
    ]
  }
```

</details>",good catch like shave solid page load real use case deployment behind load balancer imagine wild somewhat similarly quick pic network tab green would time saved client server image thing think might cause cache update source way create react hash based source see seem concern make small change rebuild different patch git index export class component render hello hello end file,issue,positive,positive,neutral,neutral,positive,positive
1462326040,"@harupy Sure, technically, this would work. However, I prefer to have a ""paper trail"" to investigate in case something breaks unexpectedly and the tests don't/didn't detect it.

More generally, I think there are other scenarios where a user might want to create a hidden experiment.",sure technically would work however prefer paper trail investigate case something unexpectedly detect generally think user might want create hidden experiment,issue,positive,positive,neutral,neutral,positive,positive
1461807718,"For anyone looking, here is my workaround:
```bash
pip install mlflow-skinny
pip install --no-deps mlflow
```
`mlflow-skinny` will install the bare dependencies while `--no-deps mlflow` will just pull in the pre-built JS.

This is more convenient for me rather than building from source, which requires a copy of the repo.",anyone looking bash pip install pip install install bare pull convenient rather building source copy,issue,negative,positive,neutral,neutral,positive,positive
1461577967,"If we don't hear from @smurching nor @dbczumar , what about enabling `max_age` for hashed assets? i.e. this part

```patch
 @app.route(_add_static_prefix(""/static-files/<path:path>""))
 def serve_static_file(path):
-    return send_from_directory(STATIC_DIR, path)
+    return send_from_directory(STATIC_DIR, path, max_age=2419200)

```
",hear asset part patch path path path return path return path,issue,negative,neutral,neutral,neutral,neutral,neutral
1461407498,"@arpitjasa-db 

This worked, but not sure if this is really correct:

```diff
diff --git a/mlflow/store/db_migrations/versions/29599da4828d_add_model_aliases_table.py b/mlflow/store/db_migrations/versions/29599da4828d_add_model_aliases_table.py
index f81ed23d9..ce9fd7879 100644
--- a/mlflow/store/db_migrations/versions/29599da4828d_add_model_aliases_table.py
+++ b/mlflow/store/db_migrations/versions/29599da4828d_add_model_aliases_table.py
@@ -20,16 +20,10 @@ depends_on = None
 def upgrade():
     op.create_table(
         SqlRegisteredModelAlias.__tablename__,
-        sa.Column(
-            ""name"",
-            sa.String(length=256),
-            sa.ForeignKey(""registered_models.name"", onupdate=""cascade""),
-            primary_key=True,
-            nullable=False,
-        ),
-        sa.Column(""alias"", sa.String(length=250), primary_key=True, nullable=False),
-        sa.Column(""version"", sa.Integer(), primary_key=True, nullable=False),
-        sa.PrimaryKeyConstraint(""name"", ""alias"", name=""registered_model_alias_pk""),
+        sa.Column(""name"", sa.String(length=256), nullable=False),
+        sa.Column(""alias"", sa.String(length=250), nullable=False),
+        sa.Column(""version"", sa.Integer(), nullable=False),
+        sa.PrimaryKeyConstraint(""name"", ""version"", ""alias"", name=""registered_model_alias_pk""),
         sa.ForeignKeyConstraint(
             (""name"", ""version""),
             (""model_versions.name"", ""model_versions.version""),
diff --git a/mlflow/store/model_registry/dbmodels/models.py b/mlflow/store/model_registry/dbmodels/models.py
index fc32b2f9d..163721281 100644
--- a/mlflow/store/model_registry/dbmodels/models.py
+++ b/mlflow/store/model_registry/dbmodels/models.py
@@ -174,14 +174,10 @@ class SqlModelVersionTag(Base):
 
 class SqlRegisteredModelAlias(Base):
     __tablename__ = ""registered_model_aliases""
-    name = Column(String(256), ForeignKey(""registered_models.name"", onupdate=""cascade""))
-    alias = Column(String(256), nullable=False)
+    name = Column(String(256), nullable=False)
     version = Column(Integer, nullable=False)
+    alias = Column(String(256), nullable=False)
 
-    # linked entities
-    registered_model = relationship(
-        ""SqlRegisteredModel"", backref=backref(""registered_model_aliases"", cascade=""all"")
-    )
     model_version = relationship(
         ""SqlModelVersion"",
         foreign_keys=[name, version],
@@ -189,7 +185,7 @@ class SqlRegisteredModelAlias(Base):
     )
 
     __table_args__ = (
-        PrimaryKeyConstraint(""name"", ""alias"", name=""registered_model_alias_pk""),
+        PrimaryKeyConstraint(""name"", ""alias"", ""version"", name=""registered_model_alias_pk""),
         ForeignKeyConstraint(
             (""name"", ""version""),
             (""model_versions.name"", ""model_versions.version""),
```",worked sure really correct git index none upgrade name cascade alias version name alias name alias version name version alias name version git index class base class base name column string cascade alias column string name column string version column integer alias column string linked relationship relationship name version class base name alias name alias version name version,issue,negative,negative,negative,negative,negative,negative
1461162867,"That is possible. We are on version `1.9.1` of [showdown](https://www.npmjs.com/package/showdown) and there is a newer version: 2.1.0. Maybe upgrading to the newer version would solve that. But since it is a major version upgrade, we need to figure out the upgrading path and see if there are any breaking changes. 
",possible version showdown version maybe version would solve since major version upgrade need figure path see breaking,issue,negative,positive,neutral,neutral,positive,positive
1461144747,"that's embarassing! I appreciate you letting me know.

I'd tried using 

```python
 def foo() -> str:
   return ""bar""
```

to see if color syntax highlighting works (as above) in an experiment description and didn't see the highlighting. I'd also tried an svg path which also didn't seem to work (to embed an image without an external source)

```html
<svg height=""210"" width=""400"">
  <path d=""M150 0 L75 200 L225 200 Z"" />
</svg>


the main one was to embedd yaml with color syntax highlighting",appreciate know tried python foo return bar see color syntax work experiment description see also tried path also seem work embed image without external source path main one color syntax,issue,negative,positive,neutral,neutral,positive,positive
1461132169,"@darenr as @sunishsheth2009 pointed out, MLflow already appears to use GitHub markdown: https://github.com/mlflow/mlflow/blob/a54ca23bb4fbd4fdcd7f895c84969cedc4b2f523/mlflow/server/js/src/common/utils/MarkdownUtils.js#L6. Are there missing features?",pointed already use markdown missing,issue,negative,negative,negative,negative,negative,negative
1461097465,"@sauerburger Thank you!

For Q1:
> Q1: Indeed, it is a breaking change if there are experiments that start with a dot. In my view, the only reason to have experiments starting with a dot, is to expect them to be hidden. However, I see, that this is clearly subjective.

What do you think @dbczumar ?
What about showing a tip bar on the dashboard saying ""experiments starting with dot are hidden, if you want to view them, type . in the search box"" if there's some experiments starting with dot existing.",thank indeed breaking change start dot view reason starting dot expect hidden however see clearly subjective think showing tip bar dashboard saying starting dot hidden want view type search box starting dot,issue,positive,negative,neutral,neutral,negative,negative
1460990815,"I am discovering the new version, the chart view looks very promising :).

Moreover, I think a useful MLFlow UI defines two separate fundamental tools:

(1) - An experiment tracking (logging) tool, such as the table view.

(2) - An experiment results analysis tool such as the _Chart view_.


In order, to make accurate results analysis through (2), the user should be able to observe what marginally differs between runs, that's why the show diff switch is extremely useful both for tracking and analysis:

First, It allows the user to ensure the experiments are the same except for a small subset of hyperparameters.

Second, It allows to identify which parameters impact the metrics.


So please, take into account my comment on the readability of the Show only diff table.

Example from something like MLFlow 1.18:

![image](https://user-images.githubusercontent.com/41160498/223868411-822ae5c3-46f3-4e14-a2ae-ef13a5afa6b2.png)

",new version chart view promising moreover think useful two separate fundamental experiment logging tool table view experiment analysis tool order make accurate analysis user able observe marginally show switch extremely useful analysis first user ensure except small subset second identify impact metric please take account comment readability show table example something like image,issue,positive,positive,positive,positive,positive,positive
1460909046,@ReHoss Thank you for your feedback. Have you tried the new chart view on the experiment page? Our goal is for the chart view to be a replacement for this run comparison view.,thank feedback tried new chart view experiment page goal chart view replacement run comparison view,issue,negative,positive,positive,positive,positive,positive
1460903690,"Hi thanks for the nice job!

In the _Compare runs_ tab, it would be much more readable to transpose the tables in order to:

1 - Be able to see all runs at once without scrolling horizontally
2 - Be consistent with the standard _Table view_


At least to provide an option to transpose all tables.
In practice when dealing with 50+ runs, the MLFlow 1.28 Only show diff switch was very efficient. Think as we want to identify the run where a parameter marginally differs in order to extract information.

As a researcher It is extremely useful to be able to see the marginal differences in parameters w.r.t. to all runs at once. Moreover the introduction of inter-experiments analysis is really useful.

Note all the blank spaces left in the table by 1-digit parameters values below:

![image](https://user-images.githubusercontent.com/41160498/223853803-579b9c9c-bb21-4183-951b-c99f3736e9d3.png)



Thank you for your consideration,




",hi thanks nice job tab would much readable transpose table order able see without horizontally consistent standard least provide option transpose table practice dealing show switch efficient think want identify run parameter marginally order extract information researcher extremely useful able see marginal moreover introduction analysis really useful note blank left table image thank consideration,issue,positive,positive,positive,positive,positive,positive
1460814688,"oh nice to hear on (2) @dbczumar ! I guess i had to download the model to tweak the conda.yaml manually for (1) so I didn't correctly observe behavior there. What exactly are the relative path implications for your example? ""./mymodel"" relative to the root model?
```
like this?
/newmodel
    MLmodel
    mymodel/
        MLmodel
```

RE (1) if I'm understanding correctly, it would then

1. first eagerly fetch the models specified in artifacts=()
1. union all requirements from every set from individual artifacts entries + new ones introduced at log_model() time?
2.1. would this preserve relative ordering in the pip section to allow --extra-index-url semantics?
1. This sounds like it is ripe for footguns (but with much better user experience), so maybe we can optionally run conda --dry-run at log time to make sure the union even resolves?",oh nice hear guess model tweak manually correctly observe behavior exactly relative path example relative root model like understanding correctly would first eagerly fetch union every set individual new time would preserve relative pip section allow semantics like ripe much better user experience maybe optionally run log time make sure union even,issue,positive,positive,positive,positive,positive,positive
1460746337,+1 to this - current search syntax is extremely limiting right now,current search syntax extremely limiting right,issue,negative,positive,neutral,neutral,positive,positive
1460571248,"Hi @charlietsai , MLflow skinny does not include javascript assets in order to minimize the package size. You can build the UI manually via https://github.com/mlflow/mlflow/blob/master/CONTRIBUTING.md#javascript-and-ui. Thank you for using MLflow!",hi skinny include asset order minimize package size build manually via thank,issue,positive,neutral,neutral,neutral,neutral,neutral
1460086493,"Would you paste some example snapshot to show the difference between them ?
And how much performance difference between them ?
And what's the major gramma differences between them ?",would paste example snapshot show difference much performance difference major,issue,negative,positive,positive,positive,positive,positive
1459966516,"@WeichenXu123 thanks for your feedback.

- Q1: Indeed, it is a breaking change if there are experiments that start with a dot. In my view, the only reason to have experiments starting with a dot, is to expect them to be hidden. However, I see, that this is clearly subjective.
- Q2: The easiest way to see these experiments again is to enter any string into the search field. If a user is interested in *all* hidden experiments, I'd suggest entering a dot (`.`) into the search box. All hidden experiments will match the query and will be visible.",thanks feedback indeed breaking change start dot view reason starting dot expect hidden however see clearly subjective easiest way see enter string search field user interested hidden suggest entering dot search box hidden match query visible,issue,positive,positive,neutral,neutral,positive,positive
1459942942,"* Q1: One concern is, this looks like a breaking change, some user might have experiment name starting with dot, after upgrading they become invisible.

* Q2: What can user do if they want to view these experiment on web UI ?",one concern like breaking change user might experiment name starting dot become invisible user want view experiment web,issue,negative,neutral,neutral,neutral,neutral,neutral
1459936005,"> > > Btw, this should not be a bug, but just an improvement on error message ?
> > 
> > 
> > The bug is that mlflow does not show any experiments in the list, because of one bad experiment. My fix is regarding finding the bad experiment, but a more comprehensive fix can be considered.
> 
> Got it, do you want to file PR for a complete fix ?

Sorry this is out of my scope in mlflow system",bug improvement error message bug show list one bad experiment fix regarding finding bad experiment comprehensive fix considered got want file complete fix sorry scope system,issue,negative,negative,negative,negative,negative,negative
1459612792,"> Thanks. One thing I wasn't sure how to do was update the documentation, I guess there maybe some automations for that?

You can edit `*.rst` files in `mlflow/docs` directory and run `cd docs; make clean rsthtml` to build docs locally.
The doc website we will update it when mlflow releasing new version.",thanks one thing sure update documentation guess maybe edit directory run make clean build locally doc update new version,issue,positive,positive,positive,positive,positive,positive
1459422294,"Glad that resolved the problem. Thanks for using MLflow, @levscaut !",glad resolved problem thanks,issue,positive,positive,positive,positive,positive,positive
1459420293,"> Since this is a breaking change, can we expect a quick release of 2.2.2 ? Sorry if I appear pushy, but it's been back to back breaking change releases for us and I need to plan accordingly.

@labradovy Apologies for the breaking change. This was unintentional. We're working on a fix PR (cc @harupy ) and expect to have a patch release out by early next week at the latest.",since breaking change expect quick release sorry appear back back breaking change u need plan accordingly breaking change unintentional working fix expect patch release early next week latest,issue,negative,positive,neutral,neutral,positive,positive
1459286224,"Thanks a lot @WeichenXu123 @dbczumar . Perfectly solved my problem. Before this I tried setting the mlflow.parentId tag of autologging runs to achieve nested child run, but clearly wrapping them with start_run is more elegant.",thanks lot perfectly problem tried setting tag achieve child run clearly wrapping elegant,issue,positive,positive,positive,positive,positive,positive
1459128127,"I think the following will work:

```
import mlflow
import hyperopt
import time
import sklearn

def _sklearn_tune(config):
    X, y = sklearn.datasets.load_diabetes(return_X_y=True, as_frame=True)
    train_x, test_x, train_y, test_y = sklearn.model_selection.train_test_split(X, y, test_size=0.25)
    rf = sklearn.ensemble.RandomForestRegressor(**config)
    rf.fit(train_x, train_y)
    pred = rf.predict(test_x)
    r2 = sklearn.metrics.r2_score(test_y, pred)
    return {""r2"": r2}

def hyperopt_obj(params):
    with mlflow.start_run(nested=True):
        n_estimators = int(params[""n_estimators""])
        min_samples_leaf = int(params[""min_samples_leaf""])
        conf = {""n_estimators"": n_estimators, ""min_samples_leaf"": min_samples_leaf}
        r2 = _sklearn_tune(conf)[""r2""]
        return {""loss"": -r2, ""status"": hyperopt.STATUS_OK}

params = {
    ""n_estimators"": hyperopt.hp.uniformint(""n_estimators"", 100, 200),
    ""min_samples_leaf"": hyperopt.hp.uniformint(""min_samples_leaf"", 1, 10),
}

mlflow.autolog()
mlflow.set_experiment(""autolog_hyperopt"")
mlflow.set_tag(""mlflow.runName"", f""trials_{int(time.time())}"")

with mlflow.start_run():
    best_params = hyperopt.fmin(hyperopt_obj,
                                params,
                                algo=hyperopt.tpe.suggest,
                                max_evals=3,
                                )

autolog_run = mlflow.last_active_run()
print(autolog_run.info)
mlflow.end_run()
```",think following work import import import time import return return loss status print,issue,negative,neutral,neutral,neutral,neutral,neutral
1459121299,"I think the best follow-up is to update the docs for https://mlflow.org/docs/latest/python_api/mlflow.client.html#mlflow.client.MlflowClient.search_model_versions to remove the string ""defaults to searching for all model versions"" and instead say that different backends have different filter string requirements.

We can't require name in OSS without creating a breaking change. We also don't want to stop requiring name on Databricks   at this time. Each backend can decide its own filter string semantics.

@amesar Are you willing to contribute this docs fix?",think best update remove string searching model instead say different different filter string ca require name without breaking change also want stop name time decide filter string semantics willing contribute fix,issue,positive,positive,positive,positive,positive,positive
1459109943,"Hi @dvirginz, thank you for your feature request. The motivation and use cases are clear to me. As @WeichenXu123 pointed out, there are definitely some important design questions to answer before we implement the feature. We have noted the feature on our backlog for future prioritization. Thank you for using MLflow!",hi thank feature request motivation use clear pointed definitely important design answer implement feature noted feature backlog future thank,issue,positive,positive,positive,positive,positive,positive
1458366099,"Thanks. One thing I wasn't sure how to do was update the documentation, I guess there maybe some automations for that?
",thanks one thing sure update documentation guess maybe,issue,positive,positive,positive,positive,positive,positive
1458363147,"Since this is a breaking change, can we expect a quick release of 2.2.2 ? Sorry if I appear pushy, but it's been back to back breaking change releases for us and I need to plan accordingly.",since breaking change expect quick release sorry appear back back breaking change u need plan accordingly,issue,negative,negative,neutral,neutral,negative,negative
1458224344,"Thank you for the clear explanation!
Yes, for a newcomer like me, just reading the code doesn't tell me much about test settings. It should be helpful for more readable code. I appreciate your effort. Thank you!",thank clear explanation yes newcomer like reading code tell much test helpful readable code appreciate effort thank,issue,positive,positive,positive,positive,positive,positive
1458220879,@WeichenXu123 yeah just wanted to make sure the tests pass but some build checks failed.,yeah make sure pas build,issue,positive,positive,positive,positive,positive,positive
1458130574,"> Can the autologger automatically start child runs under the parent run created by the user? (like nested=True) This is what I want to achieve.


Yes. You can try:


```

def hyperopt_obj(params):
    with mlflow.start_run(nested=True):  # set nested=True to make it a child run.
        n_estimators = int(params[""n_estimators""])
        min_samples_leaf = int(params[""min_samples_leaf""])
        conf = {""n_estimators"": n_estimators, ""min_samples_leaf"": min_samples_leaf}
        r2 = _sklearn_tune(conf)[""r2""]
        return {""loss"": -r2, ""status"": hyperopt.STATUS_OK}


with mlflow.start_run() as run:  # parent run
    best_params = hyperopt.fmin(hyperopt_obj,
                                params,
                                algo=hyperopt.tpe.suggest,
                                max_evals=3,
                                )

```


But the approach it has a limitation that we cannot run `hyperopt_obj` routine concurrently. Can we support nested run executed in parallel.?",automatically start child parent run user like want achieve yes try set make child run return loss status run parent run approach limitation run routine concurrently support run executed parallel,issue,positive,neutral,neutral,neutral,neutral,neutral
1458102981,"It may also be confusing since negative variable names are present here. As a best practice, we should avoid using such variable names",may also since negative variable present best practice avoid variable,issue,negative,positive,positive,positive,positive,positive
1458087966,"I filed a fixing PR, you can test it by instaliing:

```
pip install git+https://github.com/WeichenXu123/mlflow.git@fix-is_local_uri-windows
```
",fixing test pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
1458067298,"Hey @UponTheSky !

You are correct. The default behavior is `disable_nginx = False` which leads to running an `nginx` server as a proxy. On the other hand, the intended behavior in docstring examples and tests is to disable `nginx` (`disable_nginx = True`; why else would you assign `""1""` and not `""0""` in that case? Or just avoid passing the env var at all to eventually get `nginx` enabled?). So my point is to change `""1""` to `""true""`; otherwise, the intention might be misleading for the newcomers or people who look through the codebase. Moreover, the tests _may_ operate a bit differently (that also needs to be verified).

 Hope, it's become clearer for you now.",hey correct default behavior false running server proxy hand intended behavior disable true else would assign case avoid passing eventually get point change true otherwise intention might misleading people look moreover operate bit differently also need hope become clearer,issue,positive,positive,neutral,neutral,positive,positive
1458065201,"Good idea!
But I have a couple of questions:

* If multiple users runs mlflow training tasks concurrently, the logged usage data is affected by other user's workloads. This prevent us to analyze the logged resources usage chart. How to distinguish the usage that is used by the logged mlflow training routine or used by other unrelated workloads ?

* We might have multiple GPU devices on machine, shall we log all GPU usages or the GPUs used only by the logged training routine ? How to know which GPU cores it uses ?

* Besides logging the resources usage data, we should also log the hardware device information, the reason is, e.g. the same usage percentage on different type CPU still indicates different amount of workloads.",good idea couple multiple training concurrently logged usage data affected user prevent u analyze logged usage chart distinguish usage used logged training routine used unrelated might multiple machine shall log used logged training routine know besides logging usage data also log hardware device information reason usage percentage different type still different amount,issue,negative,positive,positive,positive,positive,positive
1458041773,"It is caused by this line: https://github.com/mlflow/mlflow/blob/ffe005c58dd45e4f200bfb5a77aa5273a57ca39d/mlflow/utils/uri.py#L33

On windows, path like `\\<WINDOWS_SERVER>\Mlruns\..`, `urlparse('\\<WINDOWS_SERVER>\Mlruns\..')` will get hostname of `None` and get a scheme of '', then it causes the `is_local_uri` function returns True",line path like get none get scheme function true,issue,positive,positive,positive,positive,positive,positive
1458037163,"Thank you for this issue.

Can I ask a question?

You mentioned as 

> A positive value of the DISABLE_NGINX environment variable is expected to be equal to ""true""  

However,  the link you mentioned has the comment line saying 

```py
# option to disable manually nginx. The default behavior is to enable nginx.
```

https://github.com/mlflow/mlflow/blob/ffe005c58dd45e4f200bfb5a77aa5273a57ca39d/mlflow/models/container/__init__.py#L149

So from the code, any other text value than `true` or its variants(like `True` or `TRUE`), will give `disable_nginx` the value `False`, which is the default value that the comments above intends to have. I wonder if I am missing some points from your explanation. ",thank issue ask question positive value environment variable equal true however link comment line saying option disable manually default behavior enable code text value true like true true give value false default value wonder missing explanation,issue,positive,positive,positive,positive,positive,positive
1457953500,@MANOJ21K Feel free to reopen the issue if it still persists.,feel free reopen issue still,issue,positive,positive,positive,positive,positive,positive
1457916357,"Ran the following commands to confirm:

```
> pip install alembic==1.10.1  
...

> rmrf mlflow.db
> python -c ""import mlflow; mlflow.set_tracking_uri('sqlite:///mlflow.db'); mlflow.start_run()""
2023/03/07 19:20:45 INFO mlflow.store.db.utils: Creating initial MLflow database tables...
2023/03/07 19:20:45 INFO mlflow.store.db.utils: Updating database tables
INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade  -> 451aebb31d03, add metric step
INFO  [alembic.runtime.migration] Running upgrade 451aebb31d03 -> 90e64c465722, migrate user column to tags
INFO  [alembic.runtime.migration] Running upgrade 90e64c465722 -> 181f10493468, allow nulls for metric values
INFO  [alembic.runtime.migration] Running upgrade 181f10493468 -> df50e92ffc5e, Add Experiment Tags Table
INFO  [alembic.runtime.migration] Running upgrade df50e92ffc5e -> 7ac759974ad8, Update run tags with larger limit
INFO  [alembic.runtime.migration] Running upgrade 7ac759974ad8 -> 89d4b8295536, create latest metrics table
INFO  [89d4b8295536_create_latest_metrics_table_py] Migration complete!
INFO  [alembic.runtime.migration] Running upgrade 89d4b8295536 -> 2b4d017a5e9b, add model registry tables to db
INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Adding registered_models and model_versions tables to database.
INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Migration complete!
INFO  [alembic.runtime.migration] Running upgrade 2b4d017a5e9b -> cfd24bdc0731, Update run status constraint with killed
INFO  [alembic.runtime.migration] Running upgrade cfd24bdc0731 -> 0a8213491aaa, drop_duplicate_killed_constraint
INFO  [alembic.runtime.migration] Running upgrade 0a8213491aaa -> 728d730b5ebd, add registered model tags table
INFO  [alembic.runtime.migration] Running upgrade 728d730b5ebd -> 27a6a02d2cf1, add model version tags table
INFO  [alembic.runtime.migration] Running upgrade 27a6a02d2cf1 -> 84291f40a231, add run_link to model_version
INFO  [alembic.runtime.migration] Running upgrade 84291f40a231 -> a8c4a736bde6, allow nulls for run_id
INFO  [alembic.runtime.migration] Running upgrade a8c4a736bde6 -> 39d1c3be5f05, add_is_nan_constraint_for_metrics_tables_if_necessary
INFO  [alembic.runtime.migration] Running upgrade 39d1c3be5f05 -> c48cb773bb87, reset_default_value_for_is_nan_in_metrics_table_for_mysql
INFO  [alembic.runtime.migration] Running upgrade c48cb773bb87 -> bd07f7e963c5, create index on run_uuid
INFO  [alembic.runtime.migration] Running upgrade bd07f7e963c5 -> 0c779009ac13, add deleted_time field to runs table
INFO  [alembic.runtime.migration] Running upgrade 0c779009ac13 -> cc1f77228345, change param value length to 500
INFO  [alembic.runtime.migration] Running upgrade cc1f77228345 -> 97727af70f4d, Add creation_time and last_update_time to experiments table
INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
```",ran following confirm pip install python import initial table table context assume running upgrade add metric step running upgrade migrate user column running upgrade allow metric running upgrade add experiment table running upgrade update run limit running upgrade create latest metric table migration complete running upgrade add model registry table table migration complete running upgrade update run status constraint running upgrade running upgrade add registered model table running upgrade add model version table running upgrade fa add running upgrade fa allow running upgrade running upgrade running upgrade create index running upgrade add field table running upgrade change param value length running upgrade add table context assume,issue,positive,positive,positive,positive,positive,positive
1457884222,"I suggest to make OSS to the same behavior with databricks, i.e. adding similar restriction ""Specify at least one of model name, run ID, or source in search filter."", @dbczumar WDYT ? The restriction prevents returning too many version results.",suggest make behavior similar restriction specify least one model name run id source search filter restriction many version,issue,negative,positive,neutral,neutral,positive,positive
1457871082,"@ntakouris 

Would you like to help testing this fix ? https://github.com/mlflow/mlflow/pull/7985

You need to rerun the mlflow/store/db_migrations/versions/cfd24bdc0731_update_run_status_constraint_with_killed.py step migration. 

",would like help testing fix need rerun step migration,issue,positive,neutral,neutral,neutral,neutral,neutral
1457822472,@AndersonReyes Thanks for your contribution! Is the PR ready for review ?,thanks contribution ready review,issue,positive,positive,positive,positive,positive,positive
1457819485,"What about adding a environment variable to control this ?

By default we use `--only-binary=:all:` option, but we can allow user to set other options, like:

```
        pip_wheel_options = os.environ.get(""MLFLOW_MODEL_PIP_WHEEL_OPTIONS"", ""--only-binary=:all:"")
        download_command = (
            f""{sys.executable} -m pip wheel {pip_wheel_options} --wheel-dir={dst_path} -r""
            f""{pip_requirements_path} --no-cache-dir""
        )
```",environment variable control default use option allow user set like pip wheel,issue,positive,neutral,neutral,neutral,neutral,neutral
1457704559,"Can the autologger automatically start child runs under the parent run created by the user? (like nested=True) This is what I want to achieve.
",automatically start child parent run user like want achieve,issue,negative,neutral,neutral,neutral,neutral,neutral
1457562338,"Hi @akshaya-a , sorry for the delay.

Regarding (1), I think `extra_pip_requirements` is intended to append additional requirements to the model's base environment. The issue appears to be that the base environment for a wrapped model isn't correctly inferred. We can definitely adjust requirements inference logic for `mlflow.pyfunc.log_model()` to look at the requirements files of any artifacts that are added to the model.

Regarding (2), fortunately, eager artifact resolution during `mlflow.pyfunc.log_model()` is already included. If you pass `artifacts={""mymodel"": ""models:/mymodel/1""}`, the model will be downloaded to the local filesystem and packaged with the model automatically.

Let me know what your thoughts are re: (1) and on the current behavior in (2).",hi sorry delay regarding think intended append additional model base environment issue base environment wrapped model correctly definitely adjust inference logic look added model regarding fortunately eager artifact resolution already included pas model local model automatically let know current behavior,issue,negative,negative,negative,negative,negative,negative
1457457840,"I agree, we should surely cache the assets rather than busting them every single time. if its the same hash since same assets are served, we can return the result from the cache. 
not sure if there were any reasons not to cache it. I can't think of any reason that it would break anything. 
cc @smurching and @dbczumar if you know any legacy reasons. ",agree surely cache asset rather every single time hash since asset return result cache sure cache ca think reason would break anything know legacy,issue,positive,positive,positive,positive,positive,positive
1457294956,"Unfortunately, we can't make this change at this time due to limitations from partner integrations on the size of GET request query strings. cc @akshaya-a.",unfortunately ca make change time due partner size get request query,issue,negative,negative,negative,negative,negative,negative
1457294061,Thank you! I will take a look soon.,thank take look soon,issue,negative,neutral,neutral,neutral,neutral,neutral
1457292696,This proposal makes sense. @dbczumar Shall we modify them from POST to GET ? Will this cause breaking change ?,proposal sense shall modify post get cause breaking change,issue,negative,neutral,neutral,neutral,neutral,neutral
1457275535,"> > Btw, this should not be a bug, but just an improvement on error message ?
> 
> The bug is that mlflow does not show any experiments in the list, because of one bad experiment. My fix is regarding finding the bad experiment, but a more comprehensive fix can be considered.

Got it, do you want to file PR for a complete fix ?",bug improvement error message bug show list one bad experiment fix regarding finding bad experiment comprehensive fix considered got want file complete fix,issue,negative,negative,negative,negative,negative,negative
1456723650,"This change broke most of my models, where is the documentation about this? I use a network drive to save the artifacts.",change broke documentation use network drive save,issue,negative,neutral,neutral,neutral,neutral,neutral
1456306723,I have created a [PR](https://github.com/mlflow/mlflow/pull/8009) that I believe should address this issue. Any guidance on getting this one merged would be appreciated. We have some deployment code that will require this fix.  ,believe address issue guidance getting one would deployment code require fix,issue,negative,neutral,neutral,neutral,neutral,neutral
1455763174,Thanks for the reply. I think it needs to be re-phrased as it's a little bit misleading. Adding more context as the things you mentioned can give more clarity.,thanks reply think need little bit misleading context give clarity,issue,negative,positive,neutral,neutral,positive,positive
1455753879,"> Btw, this should not be a bug, but just an improvement on error message ?

The bug is that mlflow does not show any experiments in the list, because of one bad experiment. 
My fix is regarding finding the bad experiment, but a more comprehensive fix can be considered.",bug improvement error message bug show list one bad experiment fix regarding finding bad experiment comprehensive fix considered,issue,negative,negative,negative,negative,negative,negative
1455690795,"> This should be a bug, let me check.

I've found the cause for this issue. Just don't manually start any run will solve this issue. Manually start run will lead the autologger to record everything into the manually started run. 
In the bad case code above, just remove line `mlflow.set_tag(""mlflow.runName"", f""trials_{int(time.time())}"")` and `with mlflow.start_run(nested=True):` will be fine.",bug let check found cause issue manually start run solve issue manually start run lead record everything manually run bad case code remove line fine,issue,negative,negative,negative,negative,negative,negative
1455640812,"> This should be a bug, let me check.

Thanks so much for your attention. Besides sklearn models, I also encountered this issue when autologging spark.ml models.",bug let check thanks much attention besides also issue,issue,negative,positive,positive,positive,positive,positive
1455619053,"@midhun1998  Hey, thanks for chiming in. Actually boto3 client is already used to upload the model to S3 and link it with SageMaker Model entity.

It's just packing everything ML Flow registry has, while some SageMaker implementations expect only 1 single file in the archive - the model binary. So this option would allow us to pack only that single file, and not the rest.",hey thanks actually client already used model link model entity everything flow registry expect single file archive model binary option would allow u pack single file rest,issue,positive,positive,neutral,neutral,positive,positive
1455300674,"@VishnuMurthyChakka 

Could you run `logging.getLogger(""mlflow"").setLevel(logging.DEBUG)` before you running above reproducing code ? and rerun your code and then provide the full traceback log for debugging ?

Thank you!",could run running code rerun code provide full log thank,issue,negative,positive,positive,positive,positive,positive
1455288588,"I think we need some test, the latency mainly comes from:

* input dataframe serialization (before sending to server) / deserialization (in server side, before prediction)
* Model prediction.

@VishnuMurthyChakka Could you test the above 2 steps locally (without using rest server) to see whether they also consume nearly the same time ?",think need test latency mainly come input serialization sending server server side prediction model prediction could test locally without rest server see whether also consume nearly time,issue,negative,positive,neutral,neutral,positive,positive
1455284443,"@pvardanis 

> ""We do not recommend using this format because it is not guaranteed to preserve column ordering."" Does this refer to the pandas_df.to_dict() command? To my knowledge since Python 3.6 dictionaries are ordered, therefore this command should preserve column ordering.

It refers to `pandas_df.to_dict(""records"")`.
although since Python 3.6 dictionaries are ordered, but user might use lower python version to send http request to mlflow server, so it is still unsafe.

> fine for vector rows, loses ordering for JSON records

""Vector rows"" is unclear, does it mean a row field that is an array ?
""loses ordering for JSON records"" is the same issue with above one.",recommend format preserve column refer command knowledge since python ordered therefore command preserve column although since python ordered user might use lower python version send request server still unsafe fine vector vector unclear mean row field array issue one,issue,negative,positive,neutral,neutral,positive,positive
1455279205,"Btw, this should not be a bug, but just an improvement on error message ?",bug improvement error message,issue,negative,neutral,neutral,neutral,neutral,neutral
1455277386,"@rangit3 

According to https://github.com/mlflow/mlflow/pull/7961/checks?check_run_id=11772235743

maybe this is the reason:
> Commit sha: [7ee0ef5](https://github.com/mlflow/mlflow/pull/7961/commits/7ee0ef5e5be3e27236529669377d49f286281f47), Author: Ran, Committer: Ran; Expected ""Ran [rangit3@github.com](mailto:rangit3@github.com)"", but got ""Ran Levy [rangit3@github.com](mailto:rangit3@github.com)"".",according maybe reason commit sha author ran committer ran ran got ran levy,issue,negative,neutral,neutral,neutral,neutral,neutral
1455064581,"The PR is blocked because of DCO.
https://github.com/mlflow/mlflow/commit/7ee0ef5e5be3e27236529669377d49f286281f47

However, I signed my commit as requested. What is the issue?",blocked however commit issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1455039598,"Hi,

This is the issue:
https://github.com/unit8co/darts/issues/1618

BR,
Sotiris

On Fri, 24 Feb 2023 at 4:47 PM, ET ***@***.***> wrote:

> Well, it could't be bad to ask there if they have planned anything or have
> some recommendations. If you do so, please let me know so i can monitor
> that issue.
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/mlflow/mlflow/issues/5689#issuecomment-1443788022>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AKXVR24S5M4EF5B4A75WW5DWZDCZXANCNFSM5TKBYRJA>
> .
> You are receiving this because you were mentioned.Message ID:
> ***@***.***>
>
",hi issue wrote well bad ask anything please let know monitor issue reply directly view id,issue,negative,negative,negative,negative,negative,negative
1455009937,"Hi @BenWilson2 ,

I'm willing to pick up this issue too. But before I pick up here is a gist of my understanding: Sagemaker SDK doesn't have a native method that supports uploading the model.tar.gz file so we could leverage the boto3 client to upload to S3 and link it back to the same URL-based implementation that we currently have. Let me know if what I think is correct. If not, Please correct me. 

Thanks! 🙂 ",hi willing pick issue pick gist understanding native method file could leverage client link back implementation currently let know think correct please correct thanks,issue,positive,positive,positive,positive,positive,positive
1454800200,"Hi @BenWilson2 ,

Sorry I was busy past few days and only got to take a look at the workflow today. I see that we are already setting up buildx and QEMU before building and pushing the image in [push_images.yaml](https://github.com/mlflow/mlflow/blob/master/.github/workflows/push-images.yml). We could add the platform options as shown below and that should build the image for arm64 platform too. 
```
      - name: Build and Push Base Image
        uses: docker/build-push-action@v3
        with:
          context: docker
          push: true
          platform: linux/amd64,linux/arm64
          tags: ${{ steps.meta.outputs.tags }}
          build-args: |
            VERSION=${{ steps.meta.outputs.version }}
```

Let me know if we really need to add another stage for arm64 or if the above suggestion to the existing stage will do.
Also, Is any other change required anywhere else. Sorry, I'm just new to code base and still filling up my ga in understanding so. 😃 ",hi sorry busy past day got take look today see already setting building pushing image could add platform shown build image arm platform name build push base image context docker push true platform let know really need add another stage arm suggestion stage also change anywhere else sorry new code base still filling ga understanding,issue,negative,negative,negative,negative,negative,negative
1454374891,"https://user-images.githubusercontent.com/17039389/222875072-0299bee4-d359-4280-a21f-0a143db71165.mov

We could add a user registration form like this **by modifying the front end**. I found Basic authorization header is removed when the browser is closed (= you need to type username and password every time you reopen the browser). So I tried JWT authentication (the token is stored in the browser's local storage to keep the user signed in).

",could add user registration form like front end found basic authorization header removed browser closed need type password every time reopen browser tried authentication token browser local storage keep user,issue,negative,negative,neutral,neutral,negative,negative
1453874686,Thanks @DanMcInerney for finding these vulnerabilities along with contributors at @protectai for testing/verification. Appreciate the MLflow maintainers for a very prompt response.,thanks finding along appreciate prompt response,issue,positive,positive,positive,positive,positive,positive
1453195008,"You can also adding tag for specific model version, via the API `MlflowClient.set_model_version_tag`
Does this satisfy your demand ?",also tag specific model version via satisfy demand,issue,negative,neutral,neutral,neutral,neutral,neutral
1452861529,"[
<img width=""1502"" alt=""스크린샷 2023-03-03 오전 11 20 23"" src=""https://user-images.githubusercontent.com/38372691/222615697-ac95573b-dc54-4cf0-bb57-cf9e86870022.png"">
](url)

In my case, hypertext link works well in Source, Git Commit.
(Also, it works [mlflow sample](https://github.com/mlflow/mlflow/tree/master/examples/sklearn_elasticnet_wine) in github too)",case link work well source git commit also work sample,issue,positive,neutral,neutral,neutral,neutral,neutral
1452825587,I wasn't sure if you wanted to actually throw in the Spinnaker pipeline for this. I can update the utility script instead :) ,sure actually throw spinnaker pipeline update utility script instead,issue,negative,positive,positive,positive,positive,positive
1452751068,"Our application code pins version 2.2.0 of mlflow. Now, calling `search_model_versions` with the default arguments is rejected by the server, with message: `RestException: INVALID_PARAMETER_VALUE: Invalid max results 200000, should be between 0 and 10000`. Presumably this is because the databricks-hosted tracking servers were updated to 2.2.1.

Did we miss a deprecation warning? I didn't expect this function to break in a point update.",application code version calling default server message invalid presumably miss deprecation warning expect function break point update,issue,negative,neutral,neutral,neutral,neutral,neutral
1452741337,"This relates to https://github.com/mlflow/mlflow/actions/runs/4314312216/jobs/7527176422, right? I think we can just make the following change:

```diff
diff --git a/dev/update_requirements.py b/dev/update_requirements.py
index d04febf93..6b8265ac7 100644
--- a/dev/update_requirements.py
+++ b/dev/update_requirements.py
@@ -62,7 +62,6 @@ def main():
         pip_release = req_info[""pip_release""]
         max_major_version = req_info[""max_major_version""]
         latest_major_version = get_latest_major_version(pip_release)
-        assert latest_major_version >= max_major_version
         if latest_major_version > max_major_version:
             requirements[key][""max_major_version""] = latest_major_version
             print(f""Updated {key}.max_major_version to {latest_major_version}"")
```

in case we manually update requirements.",right think make following change git index bac main assert key print key case manually update,issue,negative,positive,neutral,neutral,positive,positive
1452739938,"> running the update_requirements.py script do not provide contextual information in the assertion check. This allows for local testing.

If so, can we fix `update_requirements.py`?",running script provide contextual information assertion check local testing fix,issue,negative,neutral,neutral,neutral,neutral,neutral
1452729745,"In both snippets in description, if the environment variable is not set, `MlflowHostCreds.server_cert_path` is set to None. In turn this would have set request's `verify` to None (behaves like False); this rather would definitely need to default to True to preserve behavior. The idea is that if variable is unset, it behaves exactly the same (will need to hardcode `requests`'s `verify`'s default value to pass explicitely, could be done by simply changing `MlflowHostCreds.server_cert_path`'s default); if it is set, we enforce validation against that cert instead.

If trying to validate Azure Blob Store with local CA cert (or invalid path) set in `MLFLOW_TRACKING_SERVER_CERT_PATH` environment variable, it will prevent connection (`CERTIFICATE_VERIFY_FAILED`). This will induce a risk that it will break setups already defining this to invalid CA certificate, but as such I'm not sure how much undesirable it is in itself.",description environment variable set set none turn would set request verify none like false rather would definitely need default true preserve behavior idea variable unset exactly need verify default value pas could done simply default set enforce validation instead trying validate azure blob store local ca invalid path set environment variable prevent connection induce risk break already invalid ca certificate sure much undesirable,issue,positive,positive,positive,positive,positive,positive
1452665738,"As of MLflow 2.2.1  this is a major breaking change that breaks all previous code that calls MlflowClient.create_model_version() on a local tracking server.

It has broken all the tests in https://github.com/mlflow/mlflow-export-import/tree/master/tests.
For example: https://github.com/mlflow/mlflow-export-import/blob/master/tests/open_source/test_models.py#L114

How do I then create a model version on a local (test) tracking server?",major breaking change previous code local server broken example create model version local test server,issue,negative,negative,negative,negative,negative,negative
1452620232,"Hi @shrinath-suresh , 

Yes, you're right. I needed to add the `devices` flag, no `gpus`. Thanks!",hi yes right add flag thanks,issue,positive,positive,positive,positive,positive,positive
1452429087,Hi @rangit3 sounds like a good idea! Let us know when your PR is ready,hi like good idea let u know ready,issue,positive,positive,positive,positive,positive,positive
1451725392,"I ran this command to test MLflow 2.2.0 UI:

```
docker run --rm -w /mlflow -v $(pwd)/mlruns:/mlflow/mlruns -p 5000:5000 python:3.8 bash -c 'pip install mlflow==2.2 && mlflow server --host 0.0.0.0 --gunicorn-opts ""--log-level debug""'
```

but wasn't able to reproduce the issue.",ran command test docker run python bash install server host able reproduce issue,issue,negative,positive,positive,positive,positive,positive
1451722063,"> Opening mlflow through anaconda prompt in local

Can you provide more details? Can you provide code that can generate data that can reproduce the issue?",opening anaconda prompt local provide provide code generate data reproduce issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1451695053,@MANOJ21K Thanks for reporting the issue. Can you open DevTools on your browser and check the console?,thanks issue open browser check console,issue,negative,positive,neutral,neutral,positive,positive
1451429097,"Thanks @jmahlik for filling in the issue! Thoughts:
- Actually, we might want to retain `no-cache` but only for the index.html. It's the only file that does not include a hash in the filename, but its contents contain potentially changing references to other assets. This way we should still be safe from a whole class of stale cache problems. Ofc this means additional latency for fetching this particular file - but on the other hand, it's a pretty small one.
- Still, I'm not sure if there wasn't any deliberate decision in the past to use caching configured in this way. @sunishsheth2009 @harupy do you know something about it, or do you have an idea of who can we ask about it?",thanks filling issue actually might want retain file include hash content contain potentially asset way still safe whole class stale cache additional latency fetching particular file hand pretty small one still sure deliberate decision past use way know something idea ask,issue,positive,positive,neutral,neutral,positive,positive
1451118886,@BenWilson2 I rebased on master to reflect https://github.com/mlflow/mlflow/pulls?q=is%3Apr+is%3Aclosed. Let's see what happens.,master reflect let see,issue,negative,neutral,neutral,neutral,neutral,neutral
1451074228,does the artifact server on windows still need a longer amount of time to become responsive? It was using the default of 60 seconds before from `tests/tracking/test_mlflow_artifacts.py::41`,artifact server still need longer amount time become responsive default,issue,negative,neutral,neutral,neutral,neutral,neutral
1451054880,@harupy @sunishsheth2009 @hubertzub-db would the three of you mind taking a look at the proposal here and weigh in? Thank you!,would three mind taking look proposal weigh thank,issue,negative,neutral,neutral,neutral,neutral,neutral
1449928326,"On master branch, tests that launch a tracking server in a subprocess, have been failing.

https://github.com/mlflow/mlflow/actions/runs/4301397579/jobs/7498577376

<img width=""1445"" alt=""image"" src=""https://user-images.githubusercontent.com/17039389/222125007-a526e399-8dc6-412c-b60d-c6aff94c8e6f.png"">

It's unclear what's happening because the job got timed out. Each test takes 1 minute to fail. This indicates that a server fails to start.

---

Found the root cause. Filed #7918 ",master branch launch server failing image unclear happening job got timed test minute fail server start found root cause,issue,negative,negative,negative,negative,negative,negative
1449789406,"@benlansdell I tested the MNIST example in multiple gpus and only one run is getting logged. 

Can you please cross check if you are using `devices` as the parameter to specify number of gpus ?

If you use `gpus` it may create multiple runs. Sooner it is going to get deprecated.

```
$ python mnist_autolog_example.py --max_epochs 5 --gpus 3 --strategy ddp
/opt/conda/envs/pytorch/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:474: LightningDeprecationWarning: Setting Trainer(gpus=3) is deprecated in v1.7 and will be removed in v2.0. Please use Trainer(accelerator='gpu', devices=3) instead.
```

Instead run it as 

```
$ python mnist_autolog_example.py --max_epochs 5 --devices 3 --strategy ddp
```

It logs only one run. Attaching screenshot for reference

![multigputest](https://user-images.githubusercontent.com/63862647/222110452-16ae21be-67fa-4d77-9b75-4bdf11179071.png)
",tested example multiple one run getting logged please cross check parameter specify number use may create multiple sooner going get python strategy setting trainer removed please use trainer instead instead run python strategy one run reference,issue,positive,neutral,neutral,neutral,neutral,neutral
1449695185,"You have a typo in your import. Try:
```from mlflow.recipes import Recipe```",typo import try import recipe,issue,negative,neutral,neutral,neutral,neutral,neutral
1449678609,@BenWilson2 I have MLflow 2.1.1 and still can not import `receipes` module. Is `Receipe` officially available?,still import module officially available,issue,negative,positive,positive,positive,positive,positive
1449529513,"@jmahlik sure, feel free to extract next features/discussion points from https://github.com/mlflow/mlflow/pull/7174",sure feel free extract next,issue,positive,positive,positive,positive,positive,positive
1449243467,"I'm afraid I don't follow. If you have MLflow specify ""conda"" or ""local"" but you have the project configured to run in Docker, then it will use a conda environment or the local environment within the docker container's isolated process encapsulation. 
If you want to run the model within the local system environment, you can just log the model to the tracking server, use the native flavor or pyfunc flavor implementation to load the model from the tracking server's artifact registered location and use the model. 
With your 2nd statement above, the expedient thing to do is to build your 'external container' such that the registered model artifact is loaded into that container that contains the rest of your code and infrastructure. 
If that's not appealing to you, you'll have to look into secure ways of running DinD (Docker in Docker). There are plenty of advanced guides on the internet to help you get started. Here's one: https://hub.docker.com/_/docker Here's another: https://blog.nestybox.com/2019/09/14/dind.html 
Keep in mind that you'll have to run with elevated privileges in order to get it working. You might want to consider sibling containers as that is a far safer bet. 
However, none of this is officially supported by MLflow and we don't provide guidance on how to tackle these advanced use cases of Docker. Best of luck!",afraid follow specify local project run docker use environment local environment within docker container isolated process encapsulation want run model within local system environment log model server use native flavor flavor implementation load model server artifact registered location use model statement expedient thing build container registered model artifact loaded container rest code infrastructure appealing look secure way running docker docker plenty advanced help get one another keep mind run elevated order get working might want consider sibling far bet however none officially provide guidance tackle advanced use docker best luck,issue,positive,positive,positive,positive,positive,positive
1449089660,"@BenWilson2 When specifying conda as the project environment is this not instead of the docker environment? So that mlflow creates a new conda env (not inside a container per se) and runs it inside that conda env?

In the same way, I want to run it in its current system environment so not have it create a docker container. As explained above I have another package that creates a container and I want mlflow to then simply run in that container's local (not create a docker env, conda env or anything else).",project environment instead docker environment new inside container per se inside way want run current system environment create docker container another package container want simply run container local create docker anything else,issue,positive,positive,neutral,neutral,positive,positive
1449070464,"Sounds like a good idea @martlaf . 
So the plan is to use the env config value if set (for use in testing), else, use the default host creds value? 
Have you validated what the behavior is if this cert key is present when acquiring auth access to Azure Blob Store? Does it ignore it?
Either way, we'll be looking forward to your PR!",like good idea plan use value set use testing else use default host value behavior key present access azure blob store ignore either way looking forward,issue,positive,positive,positive,positive,positive,positive
1448901995,Failures due to MLflow version lower bound pinning are expected because MLflow 2.2 has yet to be released,due version lower bound pinning yet,issue,negative,negative,negative,negative,negative,negative
1447342880,Thanks for the filing @akshaya-a! We'll take a look and offer some responses after we've had some time to discuss.,thanks filing take look offer time discus,issue,negative,positive,positive,positive,positive,positive
1447341319,"Hi @mehran66 TIFF files, while incredibly detailed, are remarkably large. As such, they're not supported on most modern browsers that people would be using Mlflow UI on. 
Based on my search of browser documentation, I can see that TIFF is supported only in:
- Internet Explorer (permanently end-of-life as of June 15th, 2022)
- Edge
- Safari
- A few niche browsers that don't have much market share.


TIFF is not supported in: Chrome or Firefox without installing a plugin. 

I'm not sure if it's advisable for us to enable support for something that will be completely broken for users unless they choose to install a plugin to their browsers. Based on this: https://gs.statcounter.com/browser-market-share I think that the vast majority of our users would run into this problem if they tried to log such an image expecting it to display correctly.",hi tiff incredibly detailed remarkably large modern people would based search browser documentation see tiff explorer permanently june th edge safari niche much market share tiff chrome without sure advisable u enable support something completely broken unless choose install based think vast majority would run problem tried log image display correctly,issue,negative,positive,positive,positive,positive,positive
1447322131,@morelen17 sounds like a great idea! Let us know when you have your initial PR filed and we'll be available to answer questions within that. Looking forward to it!,like great idea let u know initial available answer within looking forward,issue,positive,positive,positive,positive,positive,positive
1446538832,@midhun1998 it definitely is open to anyone who wishes to contribute. After checking the implementation of the 'native ARM runner' https://github.com/marketplace/actions/arm-runner it also uses emulation to execute the builds. I wouldn't worry about the slow down as this will be an isolated test suite that runs just a few key critical tests for validating builds on Apple Silicon (M1 / M2 / Mx). I think it's safe for you to go with whichever approach is simpler to implement. Feel free to submit a PR that tags this FR when you're ready! ,definitely open anyone contribute implementation arm runner also emulation execute would worry slow isolated test suite key critical apple silicon think safe go whichever approach simpler implement feel free submit ready,issue,positive,positive,positive,positive,positive,positive
1446506205,"Rebased, should take care of the conflicts and (hopefully) the failing installs.",take care hopefully failing,issue,negative,neutral,neutral,neutral,neutral,neutral
1446401163,"> @jmahlik this is fantastic, works great! LGTM given the fact that the one comment about scrollbar is addressed (you can just accept GH code suggestion). 

Accepted. I can open another issue to discuss how to handle fetching experiments in smaller batches? As we found out in https://github.com/mlflow/mlflow/pull/7174 it will be more involved. Probably worth some up front discussion.
",fantastic work great given fact one comment accept code suggestion accepted open another issue discus handle fetching smaller found involved probably worth front discussion,issue,positive,positive,positive,positive,positive,positive
1446008063,"I tried this with 
```
import mlflow

dictionary = {""k"": ""https://www.google.com/""}

with mlflow.start_run():
    # Log a dictionary as a JSON file under the run's root artifact directory
    mlflow.log_dict(dictionary, ""data.json"")

    # Log a dictionary as a YAML file in a subdirectory of the run's root artifact directory
    mlflow.log_dict(dictionary, ""dir/data.yml"")

    # If the file extension doesn't exist or match any of ["".json"", "".yaml"", "".yml""],
    # JSON format is used.
    mlflow.log_dict(dictionary, ""data"")
    mlflow.log_dict(dictionary, ""data.txt"")
    mlflow.log_dict(dictionary, ""data.html"")

    mlflow.set_tag(""url"",""https://www.google.com/"")
```

the tag is not clickable. What happened?",tried import dictionary log dictionary file run root artifact directory dictionary log dictionary file run root artifact directory dictionary file extension exist match format used dictionary data dictionary dictionary tag,issue,negative,neutral,neutral,neutral,neutral,neutral
1445644798,@viditjain99 Thanks! Let's complete `tests/store/tracking/test_file_store.py` first.,thanks let complete first,issue,negative,positive,positive,positive,positive,positive
1445641589,I can have a go at `tests/store/tracking/test_file_store.py` and `tests/store/tracking/test_sqlalchemy_store.py`. This should complete the migration to pytest according to the above [list](https://github.com/mlflow/mlflow/issues/7201#issuecomment-1396215250).,go complete migration according list,issue,negative,positive,neutral,neutral,positive,positive
1445429984,"Hi @BenWilson2 ,

Is the issue open to any new contributors? I see this issue might require us an ARM runner to build the image natively but we could also use Buildkit with buildx from [docker ](https://docs.docker.com/build/building/multi-platform/#building-multi-platform-images)to create multiplatform images on amd64 but one downside being it might be slow as it uses QEMU emulation. There are couple of other strategies like using an arm64 native runner as builder instance.  ",hi issue open new see issue might require u arm runner build image natively could also use docker create one downside might slow emulation couple like arm native runner builder instance,issue,negative,negative,neutral,neutral,negative,negative
1444380276,"> Would changing `prevState.checkedKeys` to `props.activeExperimentIds` in lines 123 and 126 in `ExperimentListView.js` fix this? A quick test round shows me that it should do the trick, however I'd like to confirm this with you since you've probably have the best insight in this mechanism at the moment :) let's just confirm this one, hopefully it's the last issue 🙏

Seems to have resolved the history issues. I've been trying to write tests that include mounting the component with history and updating the props but it's quite hard. Haven't found a good solution in the last couple days. Wish I could include them but it doesn't seem feasible at this time.

Side note: Rebased to the new UI and it seems to play nicely with it.

",would fix quick test round trick however like confirm since probably best insight mechanism moment let confirm one hopefully last issue resolved history trying write include mounting component history prop quite hard found good solution last couple day wish could include seem feasible time side note new play nicely,issue,positive,positive,positive,positive,positive,positive
1443841179,Thank you for the screenshot and confirming the correct rendering! ,thank confirming correct rendering,issue,negative,neutral,neutral,neutral,neutral,neutral
1443838620,"Sounds good! I can see how an unbounded call could result in some strange behavior depending on what backend you're using with extreme counts of runs present in the runs table. The return result SHOULD just give a continuation token, though. 
Can you share any information about the tracking server that you're using (DB type, version, approx number of runs recorded, etc...)?",good see unbounded call could result strange behavior depending extreme present table return result give continuation token though share information server type version number,issue,positive,positive,positive,positive,positive,positive
1443788022,"Well, it could't be bad to ask there if they have planned anything or have some recommendations. If you do so, please let me know so i can monitor that issue.",well bad ask anything please let know monitor issue,issue,negative,negative,negative,negative,negative,negative
1443427768,"Hi,

Not really. Do you suggest that I create an issue there?

Best,
Sotiris

On Fri, 24 Feb 2023 at 10:26 AM, ET ***@***.***> wrote:

> Hi Sotoris
>
> I missed that also and it would be a nice feature! did you reach out
> already to the guys at U8darts for help? I was looking there if there is
> already an issue about mlflow but coulden't find one..
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/mlflow/mlflow/issues/5689#issuecomment-1443112515>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AKXVR2ZFIY2LCWWCTA2B52DWZBWDFANCNFSM5TKBYRJA>
> .
> You are receiving this because you were mentioned.Message ID:
> ***@***.***>
>
",hi really suggest create issue best wrote hi also would nice feature reach already help looking already issue find one reply directly view id,issue,positive,positive,positive,positive,positive,positive
1443112515,"Hi Sotoris

I missed that also and it would be a nice feature! did you reach out already to the guys at U8darts for help? I was looking there if there is already an issue about mlflow but coulden't find one..",hi also would nice feature reach already help looking already issue find one,issue,positive,positive,positive,positive,positive,positive
1443071064,"Hi @BenWilson2 , what eventually worked for me was to limit the number of runs:

runs = mlflow.search_runs(experiment_names=[name_here], max_results=5000)

So maybe there was some problematic run or the issue was with handling too many runs.

I updated urllib and requests first thing after the error occurred :)
Updating the mlflow server version is less straightforward since I't shared and is out of my control, sadly",hi eventually worked limit number maybe problematic run issue handling many first thing error server version le straightforward since control sadly,issue,negative,positive,positive,positive,positive,positive
1442771879,"> Hey @gabrielfu could you check to see if you have any issues in your fork related to the circleci config file? Since the Java API has been changed, we just need to make sure that the Java Docs will render properly in order to merge.

Hi, not sure what's happening with circleci, but I can see the docs locally:
![image](https://user-images.githubusercontent.com/22888849/221087828-a39728e0-489b-4f2a-83f5-cf2e42e983be.png)
![image](https://user-images.githubusercontent.com/22888849/221087973-7ed3a7f5-d3ce-4740-90e8-2fc569326450.png)
![image](https://user-images.githubusercontent.com/22888849/221088002-645a9012-3256-4cc3-896d-3212eda41d07.png)

",hey could check see fork related file since need make sure render properly order merge hi sure happening see locally image image image,issue,positive,positive,positive,positive,positive,positive
1442680137,"Hey @gabrielfu could you check to see if you have any issues in your fork related to the circleci config file? Since the Java API has been changed, we just need to make sure that the Java Docs will render properly in order to merge.",hey could check see fork related file since need make sure render properly order merge,issue,negative,positive,positive,positive,positive,positive
1442636961,"I'm wondering if any changes were made since the Jul 17, 2020? It would be nice to have such config option that would allow users to make a decision what they do want to allow to open in iframe. Or maybe add some option to open HTML artifacts directly in browser but not in the iFrame. ",wondering made since would nice option would allow make decision want allow open maybe add option open directly browser,issue,positive,positive,positive,positive,positive,positive
1442458427,"> LGTM once https://github.com/mlflow/mlflow/pull/7864/files#r1113688664 is addressed (or address it in a follow-up PR)

@harupy Done! :). Filed a follow-up ticket internally to track reenabling.",address done ticket internally track,issue,negative,neutral,neutral,neutral,neutral,neutral
1442311894,"I ended up just disabling the mysteriously-failing test for now, given that it's failing due to mocking behavior that we plan to remove in the next week or so anyways",ended test given failing due behavior plan remove next week anyways,issue,negative,negative,neutral,neutral,negative,negative
1442122852,"Thanks @harupy ! The remaining test failure is a bit mysterious, seems it doesn't occur if only the tests in the new suite are executed (e.g. see [this job run](https://github.com/mlflow/mlflow/actions/runs/4250075030/jobs/7390829672)), but does occur when all the tests are run together (see [this job run](https://github.com/mlflow/mlflow/actions/runs/4249369628/jobs/7389460748)). I'll take a look today",thanks test failure bit mysterious occur new suite executed see job run occur run together see job run take look today,issue,negative,positive,neutral,neutral,positive,positive
1442007103,Hi @mskoenz thank you for the feature request. We'll take a look at a potential solution.,hi thank feature request take look potential solution,issue,positive,neutral,neutral,neutral,neutral,neutral
1441834580,"Current workaround is to build the mlflow image myself, as it is only three lines.
(I use a multi-stage build process as build-essential are needed for the shap install)",current build image three use build process shap install,issue,negative,neutral,neutral,neutral,neutral,neutral
1441818266,"This might also be a feature request, but as installing mlflow directly on an M1 Mac works without any issue, I labeled it as a bug. Feel free to re-categorize.

",might also feature request directly mac work without issue bug feel free,issue,positive,positive,positive,positive,positive,positive
1441174655,"> Weird, the tests seem to pass for me locally but fail in CI - I wonder why, maybe I have a different pytest etc version locally - will double check

Have you tried mocking `get_databricks_host_creds`?",weird seem pas locally fail wonder maybe different version locally double check tried,issue,negative,negative,negative,negative,negative,negative
1441105577,"Weird, the tests seem to pass for me locally but fail in CI - I wonder why, maybe I have a different pytest etc version locally - will double check",weird seem pas locally fail wonder maybe different version locally double check,issue,negative,negative,negative,negative,negative,negative
1441090839,I'll migrate `test_model_version.py` as well. Can I also have a try at `tests/store/model_registry/test_sqlalchemy_store.py` after I am done?,migrate well also try done,issue,negative,neutral,neutral,neutral,neutral,neutral
1440982224,"Guidance on accessing bind points can be found here: https://docs.docker.com/storage/ 
Closing this issue.",guidance bind found issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1440846973,"@dbczumar I can implement this on my own if we can agree on an approach. I use MLflow quite often, so I'd be more than happy to contribute.",implement agree approach use quite often happy contribute,issue,positive,positive,positive,positive,positive,positive
1440561417,Thank you for the report. We're likely going to address this the next time that we need to perform a database migration update in a future release. Thanks again!,thank report likely going address next time need perform migration update future release thanks,issue,positive,positive,neutral,neutral,positive,positive
1440535253,"> Looks like lint is timing out on install.

Maybe we could try running lint again? Or I could rebase it again.",like lint timing install maybe could try running lint could rebase,issue,negative,neutral,neutral,neutral,neutral,neutral
1440145335,"hey @jmahlik! again, thanks for the update 🙌 
I still can see a (super-edge case) scenario related to navigation/checking, however it's probably easily fixable. PTAL:

https://user-images.githubusercontent.com/104438646/220653767-65916b29-e575-4dd3-9f42-f32d98681140.mov


After checking then navigating back and then checking something else, the previous check state is restored.

Would changing `prevState.checkedKeys` to `props.activeExperimentIds` in lines 123 and 126 in `ExperimentListView.js` fix this? A quick test round shows me that it should do the trick, however I'd like to confirm this with you since you've probably have the best insight in this mechanism at the moment :) 
let's just confirm this one, hopefully it's the last issue 🙏 ",hey thanks update still see case scenario related however probably easily fixable back something else previous check state would fix quick test round trick however like confirm since probably best insight mechanism moment let confirm one hopefully last issue,issue,positive,positive,positive,positive,positive,positive
1440120374,"Hello @BenWilson2

Thanks for your answer. 

To be honest, it is not a big problem for us, since we can simply lowercase the metrics. I just wanted to report the bug, since it took me a while to find the root cause of the error in our code, and I thought it would be interesting for you to know. :)",hello thanks answer honest big problem u since simply metric report bug since took find root cause error code thought would interesting know,issue,positive,positive,positive,positive,positive,positive
1439529792,Are there any updates on that matter? I would highly appreciate this feature.,matter would highly appreciate feature,issue,negative,positive,positive,positive,positive,positive
1439405009,"I think the following change should work:

```diff
diff --git a/mlflow/recipes/cards/pandas_renderer.py b/mlflow/recipes/cards/pandas_renderer.py
index 68f961bb9..dbd67bb4e 100644
--- a/mlflow/recipes/cards/pandas_renderer.py
+++ b/mlflow/recipes/cards/pandas_renderer.py
@@ -5,6 +5,7 @@ import base64
 import numpy as np
 import pandas as pd
 import sys
+from packaging.version import Version
 
 from typing import Union, Iterable, Tuple
 from mlflow.protos import facet_feature_statistics_pb2
@@ -116,9 +117,12 @@ def convert_to_dataset_feature_statistics(
             if converter:
                 date_time_converted = converter(current_column_value)
                 current_column_value = pd.DataFrame(date_time_converted)[0]
-                pandas_describe_key = current_column_value.describe(
-                    datetime_is_numeric=True, include=""all""
+                kwargs = (
+                    {}
+                    if Version(pd.__version__) > Version(""1.5"")
+                    else {""datetime_is_numeric"": True}
                 )
+                pandas_describe_key = current_column_value.describe(include=""all"", **kwargs)
                 quantiles[key] = current_column_value.quantile(quantiles_to_get)
 
             default_value = 0
```",think following change work git index import base import import import import version import union iterable import converter converter version version else true key,issue,negative,negative,negative,negative,negative,negative
1439374310,"@WeichenXu123 

> Do we have a backlog ticket for addressing pickling issue when using ddp_spawn strategy ?

We don't. I think this is a pytorch-lightning's issue. https://github.com/Lightning-AI/lightning/issues/11398 reports a similar issue. I'm investigating how we can reproduce the issue.",backlog ticket issue strategy think issue similar issue investigating reproduce issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1439371106,Do we have a backlog ticket for addressing pickling issue when using ddp_spawn strategy ?,backlog ticket issue strategy,issue,negative,neutral,neutral,neutral,neutral,neutral
1439324744,"Hi @gusghrlrl101 sounds like a great idea! Feel free to modify the existing regex matching patterns to simplify the existing implementation wherein we don't do explicit guarded checking of the set(github.com, gitlab.com, bitbucket.com) so that any valid git handler will integrate with the UI. Let us know when you have the PR ready! Thanks!",hi like great idea feel free modify matching simplify implementation wherein explicit guarded set valid git handler integrate let u know ready thanks,issue,positive,positive,positive,positive,positive,positive
1439323810,"An alternative that you might want to think about:
Open access to your local file system from within your docker container so that you can access the model directly from this opened port and shared file system path. ",alternative might want think open access local file system within docker container access model directly port file system path,issue,negative,positive,neutral,neutral,positive,positive
1439322847,"After some discussion amongst the maintainers, we feel like the effort to fix this for MSSQL will involve a great deal of potentially backwards incompatible changes. While we know this is a bug, the effort and risk in correcting it is pretty substantial (extensive database migration for all users who utilize MSSQL). 
Is there any particular reason why you need to modify the casing on your metrics? Can renaming them function as a workaround for you?",discussion amongst feel like effort fix involve great deal potentially backwards incompatible know bug effort risk correcting pretty substantial extensive migration utilize particular reason need modify casing metric function,issue,positive,positive,positive,positive,positive,positive
1439268176,Hey @saryazdi I sent an invite link to your email listed in Github. Sorry for the annoyance.,hey sent invite link listed sorry annoyance,issue,negative,negative,negative,negative,negative,negative
1439264868,"Hi @prestrepoh thanks for reporting this. The root cause is the default collation properties on the primary key index for the metric history table. In MSSQL, collation is set by default as ""CI"" (case insensitive), while the proper primary key restriction we should be using for this DB is ""CS"" (case sensitive). We'll take a look at what this would require.",hi thanks root cause default collation primary key index metric history table collation set default case insensitive proper primary key restriction case sensitive take look would require,issue,negative,positive,positive,positive,positive,positive
1439243085,"The local environment manager would be the local instance within the container's run context (as opposed to using conda or virtualenv from within the docker container). If you're looking to execute a model saved within a container context, from your local environment, can't you just point directly to the `some_script.py` to execute a test from the local OS? ",local environment manager would local instance within container run context opposed within docker container looking execute model saved within container context local environment ca point directly execute test local o,issue,negative,positive,neutral,neutral,positive,positive
1439236856,This error is raising due to the special characters (the ValueError raised is a red herring). Can you follow the guide here: https://pip.pypa.io/en/stable/topics/authentication/#percent-encoding-special-characters to do percent-encoding of your password to properly escape these reserved characters for urlencoding with urllib?,error raising due special raised red herring follow guide password properly escape reserved,issue,negative,positive,neutral,neutral,positive,positive
1439234267,This sounds like a great idea and an awesome feature. @adamwrobel-ext-gd :) Looking forward to your PR!,like great idea awesome feature looking forward,issue,positive,positive,positive,positive,positive,positive
1439112032,"> Nit: is it possible to align the eye icons in the table view?
> 
> <img alt=""image"" width=""739"" src=""https://user-images.githubusercontent.com/17039389/220013811-f1374d2d-137f-41ed-a3df-bbf3fa89c2b9.png"">

I applied @hubertzub-db 's fix for this by merging https://github.com/dbczumar/mlflow/pull/64/files. Looks much better:

<img width=""2135"" alt=""Screen Shot 2023-02-21 at 1 24 17 PM"" src=""https://user-images.githubusercontent.com/39497902/220461747-b60f6b39-d8b0-4456-91b2-045dbfae20ea.png"">

Thanks @hubertzub-db !",nit possible align eye table view image applied fix much better screen shot thanks,issue,positive,positive,positive,positive,positive,positive
1439040968,I still have this issue. Running version 2.1.1. Multi-GPU training results in multiple logs being created for the same run.,still issue running version training multiple run,issue,negative,neutral,neutral,neutral,neutral,neutral
1438990030,Everything should be addressed now. Had to resort to filtering the experiments prop on each render so the list items stay up to date when re-naming or deleting. The list itself seems to perform just fine on 5000 experiments. I'm not sure how to test this. Had tried a shallow mount but that won't render the items. A normal mount doesn't let us change the props to update the experiments. Maybe it's ok to assume the props will flow through correctly?,everything resort filtering prop render list stay date list perform fine sure test tried shallow mount wo render normal mount let u change prop update maybe assume prop flow correctly,issue,negative,positive,positive,positive,positive,positive
1438940567,"> > Hi @AndersonReyes , your approach from [#6075 (comment)](https://github.com/mlflow/mlflow/issues/6075#issuecomment-1399551648) sounds great to me. Is this still something you're able to contribute?
> 
> Hey sorry I've been unresponsive, (got a little weird with recent layoffs at work) but I need to do the RFC writeup so the changes are documented

Hope all is well! Sounds great :). Thank you for looking into this!",hi approach comment great still something able contribute hey sorry unresponsive got little weird recent work need hope well great thank looking,issue,positive,positive,positive,positive,positive,positive
1438934709,"> Hi @AndersonReyes , your approach from [#6075 (comment)](https://github.com/mlflow/mlflow/issues/6075#issuecomment-1399551648) sounds great to me. Is this still something you're able to contribute?

Hey sorry I've been unresponsive, (got a little weird with recent layoffs at work) but I need to do the RFC writeup so the changes are documented ",hi approach comment great still something able contribute hey sorry unresponsive got little weird recent work need,issue,positive,positive,neutral,neutral,positive,positive
1438656839,"> Issue verified fixed! Thanks to both @xinglong700000 and @labradovy for reporting this issue and @bali0019 for the great set of PRs that fixed it! :D
> 
> @labradovy we aim for approximately monthly releases (give or take a few weeks) and we're gearing up for another release soon. No firm exact date as of yet, but it's coming soon!

Hi, just wanted to ask about the new release, it's been 2 months since the last one. Do you guys have an approximate for 2.1.2?",issue fixed thanks issue bali great set fixed aim approximately monthly give take gearing another release soon firm exact date yet coming soon hi ask new release since last one approximate,issue,positive,positive,neutral,neutral,positive,positive
1438303805,"> this is a design decision as well - only the run name column (with visibility controls to the left) is supposed to be visible in the chart mode.

@hubertzub-db Got it!",design decision well run name column visibility left supposed visible chart mode got,issue,negative,neutral,neutral,neutral,neutral,neutral
1438193729,"Can i try adding this feature?

- Will implement the methods at this file. Python API is `PagedList`, so this will also return a Page
    - `public ModelVersionsPage searchModelVersions()`
    - `public ModelVersionsPage searchModelVersions(String searchFilter)`
https://github.com/mlflow/mlflow/blob/75e39dcff8aae5c1859d8c364f3eae8537c9076a/mlflow/java/client/src/main/java/org/mlflow/tracking/MlflowClient.java

- Will add the test at the end of this file, to be together with other ModelVersion related tests:
https://github.com/mlflow/mlflow/blob/75e39dcff8aae5c1859d8c364f3eae8537c9076a/mlflow/java/client/src/test/java/org/mlflow/tracking/ModelRegistryMlflowClientTest.java",try feature implement file python also return page public public string add test end file together related,issue,negative,neutral,neutral,neutral,neutral,neutral
1438177831,"> > Is there a specific chart you're referring to? By design, bar and line charts are supposed to display metric info only

> What I meant was:

@harupy this is a design decision as well - only the run name column (with visibility controls to the left) is supposed to be visible in the chart mode.",specific chart design bar line supposed display metric meant design decision well run name column visibility left supposed visible chart mode,issue,negative,neutral,neutral,neutral,neutral,neutral
1438029391,"Hi @dbczumar  thank you for your answer! I will let you know once it is ready!
The JupyterLab extension is very simple and it is part of a larger sample I am creating to showcase integrations with AWS native services for authentication purposes for the MLflow UI, while the plugins are for the Python SDK as far as I understand.

Some of the changes included in this sample already made the mlflow upstream ( :yeah: https://github.com/mlflow/mlflow/issues/7019 ) but I am also experimenting with authentication from the MLflow UI and integration with Amazon Cognito using Amplify React components for authentication. I havent opened any pull request as it is a proof-of-concept and I am not really a frontend dev 🙈 
Would you be interested in knowing more about this?",hi thank answer let know ready extension simple part sample showcase native authentication python far understand included sample already made upstream yeah also authentication integration amplify react authentication havent pull request really dev would interested knowing,issue,positive,positive,positive,positive,positive,positive
1437849332,"> @harupy Should I update this newly added 'mlflow/store/_unity_catalog/registry/rest_store.py' to follow the same function pattern of search_model_versions? The proto definition doesn't include order_by in it as for now.

The failing lint test is for this newly added `mlflow/store/_unity_catalog/registry/rest_store.py`, should we fix it or ignore pylint here?",update newly added follow function pattern proto definition include failing lint test newly added fix ignore,issue,negative,positive,positive,positive,positive,positive
1437807882,"hi @dbczumar @befelix , i could help on this


- considering tracking store is not public facing, I would change `update_run_info()` to take additional argument `start_time`, e.g., https://github.com/mlflow/mlflow/blob/a9a7f6d04058c41c4de7f20335eba7bd1447489f/mlflow/store/tracking/file_store.py#L564
- add `start_time=get_current_time_millis()` argument at
https://github.com/mlflow/mlflow/blob/a9a7f6d04058c41c4de7f20335eba7bd1447489f/mlflow/tracking/fluent.py#L307-L309
- for any other places that call `update_run_info()`, update the signatures accordingly",hi could help considering store public facing would change take additional argument add argument call update accordingly,issue,negative,neutral,neutral,neutral,neutral,neutral
1437769884,Agreed. https://github.com/Lightning-AI/lightning/issues/11398 seems related. I'll try to reproduce the issue and report it in the pytorch-lightning repository.,agreed related try reproduce issue report repository,issue,negative,neutral,neutral,neutral,neutral,neutral
1437753839,"Looks like the official doc recommends us to use ddp instead of ddp_spawn

https://pytorch-lightning.readthedocs.io/en/stable/accelerators/gpu_intermediate.html#distributed-data-parallel-spawn

It would be nice if we can totally address the issue raised when we set it to ddp.",like official doc u use instead would nice totally address issue raised set,issue,positive,positive,positive,positive,positive,positive
1437583057,"> > Another regression. Rename experiment doesn't update the list after renaming. Even after calling `this.list.forceUpdateGrid`. It should since the props/state change.
> 
> There's also a regression when deleting an experiment. The list never updates until it is re-filtered. Seems like it could have to do with using `this.state.filteredExperiments` instead of `this.props.Experiments`. Going to try making the list item a separate component.

This appears to fix the list items not updating. Seems ok to do unless you think there might be an issue indexing into the props like this. 

```patch
diff --git a/mlflow/server/js/src/experiment-tracking/components/ExperimentListView.js b/mlflow/server/js/src/experiment-tracking/components/ExperimentListView.js
index 02c194e8a..9e1f40e94 100644
--- a/mlflow/server/js/src/experiment-tracking/components/ExperimentListView.js
+++ b/mlflow/server/js/src/experiment-tracking/components/ExperimentListView.js
@@ -152,7 +152,7 @@ export class ExperimentListView extends Component {
   );

   renderListItem = ({ index, key, style, isScrolling }) => {
-    const item = this.state.filteredExperiments[index];
+    const item = this.props.experiments[index];
     const { activeExperimentIds } = this.props;
     const isActive = activeExperimentIds.includes(item.experiment_id);
     const dataTestId = isActive ? 'active-experiment-list-item' : 'experiment-list-item';

```",another regression rename experiment update list even calling since change also regression experiment list never like could instead going try making list item separate component fix list unless think might issue indexing prop like patch git index export class component index key style item index item index,issue,negative,neutral,neutral,neutral,neutral,neutral
1437566722,"> Another regression. Rename experiment doesn't update the list after renaming. Even after calling `this.list.forceUpdateGrid`. It should since the props/state change.

There's also a regression when deleting an experiment. The list never updates until it is re-filtered. Seems like it could have to do with using `this.state.filteredExperiments` instead of `this.props.Experiments`. Going to try making the list item a separate component.",another regression rename experiment update list even calling since change also regression experiment list never like could instead going try making list item separate component,issue,negative,neutral,neutral,neutral,neutral,neutral
1437353576,"There are major improvements to the MLflow Experiments UI, including a configurable chart view providing visual model performance insights, a revamped parallel coordinates experience for tuning, and a streamlined table view with enhancements for search and filtering in the upcoming MLFlow version:
https://www.databricks.com/blog/2023/02/17/accelerate-your-model-development-new-mlflow-experiments-ui.html",major chart view providing visual model performance parallel experience tuning streamlined table view search filtering upcoming version,issue,negative,positive,neutral,neutral,positive,positive
1437153239,@harupy Should I update this newly added 'mlflow/store/_unity_catalog/registry/rest_store.py' to follow the same function pattern of search_model_versions? The proto definition doesn't include order_by in it as for now.,update newly added follow function pattern proto definition include,issue,negative,positive,positive,positive,positive,positive
1436994431,Can I get some feedback on the code before I move on to the documentation part? Would be useful for me to avoid any double work,get feedback code move documentation part would useful avoid double work,issue,negative,positive,positive,positive,positive,positive
1436909651,"> Is there a specific chart you're referring to? By design, bar and line charts are supposed to display metric info only 

What I meant was:

<img width=""820"" alt=""image"" src=""https://user-images.githubusercontent.com/17039389/220104953-4f3c9459-397e-4f0b-aabe-8548c6d57dab.png"">
",specific chart design bar line supposed display metric meant image,issue,negative,neutral,neutral,neutral,neutral,neutral
1436794971,"> Is there a way to show parameter columns in the chart view?

Is there a specific chart you're referring to? By design, bar and line charts are supposed to display metric info only 🤔 ",way show parameter chart view specific chart design bar line supposed display metric,issue,negative,neutral,neutral,neutral,neutral,neutral
1436479688,"Is it possible to pin the hover info?

https://user-images.githubusercontent.com/17039389/220040966-5ae9e1b4-c4f8-4f2b-87fa-c2274020e422.mov

---

I see, clicking a bar pins the hover info.

",possible pin hover see bar hover,issue,negative,neutral,neutral,neutral,neutral,neutral
1436363702,Is there a way to show parameter columns in the chart view?,way show parameter chart view,issue,negative,neutral,neutral,neutral,neutral,neutral
1436334730,"Nit: is it possible to align the eye icons in the table view?

<img width=""739"" alt=""image"" src=""https://user-images.githubusercontent.com/17039389/220013811-f1374d2d-137f-41ed-a3df-bbf3fa89c2b9.png"">
",nit possible align eye table view image,issue,negative,neutral,neutral,neutral,neutral,neutral
1436221971,@viditjain99 Thanks! I think `tests/entities/model_registry/test_registered_model.py` is good as a starter. What do you think?,thanks think good starter think,issue,positive,positive,positive,positive,positive,positive
1435912955,"Hey @Maelstro, if you could help test on GCP and Azure that would be great :smiley:. First let me get the base charts together, just tidying them up, hopefully they will be done by next weekend.

If you or someone else want to make a helm chart for deploying models from a tracking server, feel free to have a go at that. (If you look at my fork there are instructions in `CONTRIBUTING.md` for setting up a local development cluster).",hey could help test azure would great first let get base together hopefully done next weekend someone else want make helm chart server feel free go look fork setting local development cluster,issue,positive,positive,positive,positive,positive,positive
1435791739,Hi @harupy! I would like to contribute to this issue. But I am a beginner so I would like to start by working on the `model_registry` tests.,hi would like contribute issue beginner would like start working,issue,positive,neutral,neutral,neutral,neutral,neutral
1434812216,"> @jmahlik just a heads up - do you plan to investigate mentioned regressions / do you need any help with this? I want to encourage you to finish this effort, I think that virtualizing this list is a valuable feature :)

Did fix the bug, will push it on Monday. I got really stuck on the renaming not updating. It is extremely hard to write a unit test for.",plan investigate need help want encourage finish effort think list valuable feature fix bug push got really stuck extremely hard write unit test,issue,positive,negative,neutral,neutral,negative,negative
1434570821,"Hi, have you tried to use backslash `\` before each special character?
And also I think the error was raised because of invalid IP, not an invalid password (?)",hi tried use special character also think error raised invalid invalid password,issue,negative,positive,positive,positive,positive,positive
1434542644,Any update about this bug? I am facing the same problem.,update bug facing problem,issue,negative,neutral,neutral,neutral,neutral,neutral
1434327332,"@jmahlik just a heads up - do you plan to investigate mentioned regressions / do you need any help with this? I want to encourage you to finish this effort, I think that virtualizing this list is a valuable feature :) ",plan investigate need help want encourage finish effort think list valuable feature,issue,positive,neutral,neutral,neutral,neutral,neutral
1434298894,"Hello,

I was having this issue too. This is one workaround that works in my case.

Save model:

1. Create a PersistentVolumeClaim (PVC) & mount it to Spark drivers/executors
2. Use mlflow.spark.log_model() with 'dfs_tmpdir' parameter set to a shared PVC directory.

Load model:
Use spark.PipelineModel.load(""s3 model path"") to load model directly from S3


I still cannot load the model with mlflow.spark.load_model().
It will result in the following error even when using PVC 'dfs_tmpdir':
""file:/tmp/tmpxgdze85x/sparkml/metadata/part-00000 does not exist\n""",hello issue one work case save model create mount spark use parameter set directory load model use model path load model directly still load model result following error even file,issue,positive,positive,neutral,neutral,positive,positive
1433964130,"Hi @adamwrobel-ext-gd, this sounds like a great idea. Feel free to file a PR and let me know if you have any questions. Thank you in advance for your contribution!",hi like great idea feel free file let know thank advance contribution,issue,positive,positive,positive,positive,positive,positive
1433963368,"Hi @pdifranc , feel free to use the above logo from https://github.com/mlflow/mlflow/issues/7840#issuecomment-1431474965 in your project. We're very excited about the extension and would love to document it on our website once it's available. Would you be interested in contributing docs for it in https://mlflow.org/docs/latest/plugins.html?",hi feel free use project excited extension would love document available would interested,issue,positive,positive,positive,positive,positive,positive
1433600833,"Mermaid upgraded and some breaking changes for us:
![image](https://user-images.githubusercontent.com/5621432/219466737-c8d1bf54-bc98-45b4-86d4-9f0858821d46.png)


We currently use internals of mermaid to override styles and few other things. So we need a version that doesn't break. 
Yes that means we need to upgrade manually but it would be better than breaking things. Thoughts? 


Btw we do the same for ace editor as well currently.
```
""ace"": ""https://cdnjs.cloudflare.com/ajax/libs/ace/1.5.1/"",
""python"": ""https://cdnjs.cloudflare.com/ajax/libs/ace/1.5.1/mode-python.min"",
""yaml"": ""https://cdnjs.cloudflare.com/ajax/libs/ace/1.5.1/mode-yaml.min"",
""idle_fingers"": ""https://cdnjs.cloudflare.com/ajax/libs/ace/1.5.1/theme-idle_fingers.min"",
```

We rely on version `1.5.1`",mermaid breaking u image currently use internals mermaid override need version break yes need upgrade manually would better breaking ace editor well currently ace python rely version,issue,positive,positive,positive,positive,positive,positive
1433071883,"@dbczumar Thanks for the reply! 

I have just come up with a demo to implement the needed function. 

```python
import sys
from io import TextIOWrapper


class DuplicateStream:
    def __init__(self, io, dp_io):
        self.io = io 
        self.dp_io = dp_io
    def flush(self):
        self.io.flush()
        self.dp_io.flush()
    def write(self, buffer):
        self.io.write(buffer)
        self.dp_io.write(buffer)
    def close(self):
        self.dp_io.close()
        return self.io

class RedirectedFileIOWrapper:
    def __init__(self, sourceIO, newIO):
        assert hasattr(sourceIO, 'write')
        assert hasattr(newIO, 'write')
        self.sourceIO = sourceIO
        self.newIO = newIO

    def write(self, __s: str) -> int:
        self.sourceIO.write(__s)
        self.newIO.write(__s)

    def flush(self):
        self.sourceIO.flush()
        self.newIO.flush()

    def close(self):
        self.newIO.close()
        return self.sourceIO

with open('first_run_stdout.log', 'w') as f1:
    print('this should be in stdout, but not in any log')
    sys.stdout = DuplicateStream(sys.stdout, f1)
    print('this should be in stdout and f1')
    with open('second_run_stdout.log', 'w') as f2:
        print('this should be in stdout and f1')
        sys.stdout = DuplicateStream(sys.stdout, f2)
        print('this should be in stdout and f1, f2')
        sys.stdout = sys.stdout.close()
    print('this should be in stdout and f1')
    sys.stdout = sys.stdout.close()

```

The `stdout/stderr` could perform almost the same if all needed attributes in `TextIOWrapper` are implemented. 

Users could use any kind of print/logger in any package to send a string to stdout/stderr, so the only possible way is to configure the `sys.stdout` and `sys.stderr`?? 

This is crazy and dirty but practical, as users seldomly configure the `sys.stdout` and `sys.stderr` directly. So do anyone have any suggestions?",thanks reply come implement function python import io import class self io io flush self write self buffer buffer buffer close self return class self assert assert write self flush self close self return open print log print open print print print could perform almost could use kind package send string possible way configure crazy dirty practical seldomly configure directly anyone,issue,negative,negative,neutral,neutral,negative,negative
1432370170,"For those facing this same issue, I resolved it by updating the `experiment_id` PK column in the `experiments` table to an auto-incrementing identity columns. 

See: https://dba.stackexchange.com/questions/78732/change-existing-column-in-pg-to-auto-incremental-primary-key

Similar to OP, I had my pgsql tables created manually after migrating from sqlite3. ",facing issue resolved column table identity see similar table manually,issue,negative,neutral,neutral,neutral,neutral,neutral
1432340918,"> > @mpicard The error looks similar to [numba/llvmlite#621](https://github.com/numba/llvmlite/issues/621), which is not an MLflow's issue.
> 
> Got the same error reported here using poetry. However it seems to be related to llvmlite 0.34. Don'k know why mlflow requires llvmlite 0.34 because if i do
> 
> Successful install
> 
> ```shell
> >>>poetry add numba
> >>>poetry add mlflow 
> ```
> 
> Unsucessful install
> 
> ```shell
> >>>poetry add mlflow
> .....
>   • Installing llvmlite (0.34.0): Failed
> ....
> ```
> 
> The question is therefore - why is MLflow dependent on llvmlite (0.34.0). Or at least interpeted so by poetry.
> 
> Currenlty sitting on M1 Mac as well.



The question is why it requires llvmlite (0.34.0), not llvmlite in general. Wonky that the workaround is to manually install numba, then install mlflow. Seems like a dependency issue with mlflow, and not an external issue.",error similar issue got error poetry however related know successful install shell poetry add poetry add install shell poetry add question therefore dependent least poetry sitting mac well question general wonky manually install install like dependency issue external issue,issue,negative,positive,neutral,neutral,positive,positive
1431913003,"This is an essential feature to me. The current workflow of manually building docker images, then storing in local docker registry, then knowing the image name in the MLproject file is awful.  What's the hold up? Can I contribute to getting this merge request resolved?",essential feature current manually building docker local docker registry knowing image name file awful hold contribute getting merge request resolved,issue,negative,negative,negative,negative,negative,negative
1430594807,"Hi @AndersonReyes , your approach from https://github.com/mlflow/mlflow/issues/6075#issuecomment-1399551648 sounds great to me. Is this still something you're able to contribute?",hi approach great still something able contribute,issue,positive,positive,positive,positive,positive,positive
1430594238,"Got it. Thanks @amylizzle . In that case, I'll go ahead and close this issue for now. Thank you for using MLflow!",got thanks case go ahead close issue thank,issue,positive,positive,positive,positive,positive,positive
1430593763,"Hi @befelix , I agree that this would be a useful feature. The current behavior is counterintuitive. I've added the `help wanted` label here.",hi agree would useful feature current behavior added help label,issue,positive,positive,positive,positive,positive,positive
1430488376,"Hi @Maelstro , we would definitely welcome your contribution here. @ichbinjakes please let @Maelstro know how best to help :)",hi would definitely welcome contribution please let know best help,issue,positive,positive,positive,positive,positive,positive
1430483550,"Hi, I'm also willing to contribute to this - I did some work on deploying MLFlow using Helm Charts, with cloud storage (S3/MinIO, GCP and Azure), I'm eager to help with this issue. 👋🏻 ",hi also willing contribute work helm cloud storage azure eager help issue,issue,positive,positive,positive,positive,positive,positive
1430193424,"@dbczumar PR for this issue is ready to review. The PR scope is wider than anticipated, it address similar issues in experiments, models, models tag section screens.",issue ready review scope address similar tag section,issue,negative,positive,neutral,neutral,positive,positive
1430092154,Looks like lint is timing out on install.,like lint timing install,issue,negative,neutral,neutral,neutral,neutral,neutral
1429915396,"> @jmahlik Thanks for the updates! Could you rebase on master? I think that should fix the timeout issue.

rebased",thanks could rebase master think fix issue,issue,negative,positive,positive,positive,positive,positive
1429693472,"Hi all,  hi @dbczumar .

still getting this in mlflow 2.1.1 (Python 3.9.15, Windows 11 Pro, mlflow Version: 2.1.1.). 

Is this still a known issue? The solution suggested is not clear to me from the discussions above. Any ideas?

The command : 
`mlflow run https://github.com/mlflow/mlflow-example.git -P alpha=5.0`

gives the following  error. 

ERROR
--------
```(env_explore) >mlflow run https://github.com/mlflow/mlflow-example.git -P alpha=5.0
Traceback (most recent call last):
  File ""C:\Users\m\miniconda3\envs\env_explore\lib\runpy.py"", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File ""C:\Users\m\miniconda3\envs\env_explore\lib\runpy.py"", line 87, in _run_code
    exec(code, run_globals)
  File ""C:\Users\m\miniconda3\envs\env_explore\Scripts\mlflow.exe\__main__.py"", line 7, in <module>
  File ""C:\Users\m\miniconda3\envs\env_explore\lib\site-packages\click\core.py"", line 1130, in __call__
    return self.main(*args, **kwargs)
  File ""C:\Users\m\miniconda3\envs\env_explore\lib\site-packages\click\core.py"", line 1055, in main
    rv = self.invoke(ctx)
  File ""C:\Users\m\miniconda3\envs\env_explore\lib\site-packages\click\core.py"", line 1657, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File ""C:\Users\m\miniconda3\envs\env_explore\lib\site-packages\click\core.py"", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File ""C:\Users\m\miniconda3\envs\env_explore\lib\site-packages\click\core.py"", line 760, in invoke
    return __callback(*args, **kwargs)
  File ""C:\Users\m\miniconda3\envs\env_explore\lib\site-packages\mlflow\cli.py"", line 201, in run
    projects.run(
  File ""C:\Users\m\miniconda3\envs\env_explore\lib\site-packages\mlflow\projects\__init__.py"", line 329, in run
    submitted_run_obj = _run(
  File ""C:\Users\m\miniconda3\envs\env_explore\lib\site-packages\mlflow\projects\__init__.py"", line 102, in _run
    submitted_run = backend.run(
  File ""C:\Users\m\miniconda3\envs\env_explore\lib\site-packages\mlflow\projects\backend\local.py"", line 77, in run
    work_dir = fetch_and_validate_project(project_uri, version, entry_point, params)
  File ""C:\Users\m\miniconda3\envs\env_explore\lib\site-packages\mlflow\projects\utils.py"", line 137, in fetch_and_validate_project
    work_dir = _fetch_project(uri=uri, version=version)
  File ""C:\Users\m\miniconda3\envs\env_explore\lib\site-packages\mlflow\projects\utils.py"", line 152, in _fetch_project
    use_temp_dst_dir = _is_zip_uri(parsed_uri) or not _is_local_uri(parsed_uri)     
  File ""C:\Users\m\miniconda3\envs\env_explore\lib\site-packages\mlflow\projects\utils.py"", line 109, in _is_local_uri
    resolved_uri = pathlib.Path(_parse_file_uri(uri)).resolve()
  File ""C:\Users\m\miniconda3\envs\env_explore\lib\pathlib.py"", line 1215, in resolve
    s = self._flavour.resolve(self, strict=strict)
  File ""C:\Users\m\miniconda3\envs\env_explore\lib\pathlib.py"", line 215, in resolve
    s = self._ext_to_normal(_getfinalpathname(s))
OSError: [WinError 123] The filename, directory name, or volume label syntax is incorrect: 'https:\\github.com\\mlflow\\mlflow-example.git```",hi hi still getting python pro version still known issue solution clear command run following error error run recent call last file line return code none file line code file line module file line return file line main file line invoke return file line invoke return file line invoke return file line run file line run file line file line run version file line file line file line file line resolve self file line resolve directory name volume label syntax incorrect,issue,positive,positive,neutral,neutral,positive,positive
1429688676,"Thanks @dbczumar for the swift response and your work on MLflow! 

I guess we misunderstand each other. Thus, I attached some screenshots to make the observed and expected behavior clearer. 

Starting point:
![No Filter](https://user-images.githubusercontent.com/8392548/218740057-e8d7850d-7a5c-48ce-b654-ce7f092affa2.PNG)

When I filter for a tag that exists on a child and not on the parent, I would expect that the child is shown here, so that the filter omits parents without that tag but still shows childs that have that tag. Instead neither the parent nor the childs are shown (only pinned stay):
![Filtered (Only Pinned Remain)](https://user-images.githubusercontent.com/8392548/218740919-60f8f63d-2d90-45af-9faa-a20156510668.PNG)


Showing you the child and the behavior when I manually expanded the parent to show the child. You can see the tag here. 
![No Filter Opened](https://user-images.githubusercontent.com/8392548/218740534-009f72eb-80f8-4e3d-adf9-c883184a9d80.PNG)

When I filter now, the child gets shown.
![Filtered (Pinned And Open Childs Remain)](https://user-images.githubusercontent.com/8392548/218741666-0c880be5-d8fc-4f00-9745-b3918e63fc8c.PNG)

So for filtering on children in 2.0.1 to work (as I expect it to work) I would need to expand all parents manually to show the childs before filtering. 

Hope this helps. :-) ",thanks swift response work guess misunderstand thus attached make behavior clearer starting point filter filter tag child parent would expect child shown filter without tag still tag instead neither parent shown pinned stay pinned remain showing child behavior manually expanded parent show child see tag filter filter child shown pinned open remain filtering work expect work would need expand manually show filtering hope,issue,positive,positive,neutral,neutral,positive,positive
1429404657,"> I investigated the cause. By running `docker run --rm python:3.8 bash -c ""pip install tensorflow==2.3.0 pipdeptree && pipdeptree --reverse --packages protobuf""`, you can get:
> 
> ```
> protobuf==4.21.12
>   - tensorboard==2.12.0 [requires: protobuf>=3.19.6]
>     - tensorflow==2.3.0 [requires: tensorboard>=2.3.0,<3]
>   - tensorflow==2.3.0 [requires: protobuf>=3.9.2]
> ```
> 
> This means `tensorflow` and `tensorboard` require `protobuf`.
> 
> The latest version of `tensorboard` was released on Feb 10 so it looks suspicious because this issue started happening 3 or 4 days ago: https://pypi.org/project/tensorboard/2.12.0
> 
> This file determines `tensorboard`'s dependencies: https://github.com/tensorflow/tensorboard/blob/master/tensorboard/pip_package/requirements.txt
> 
> I'm checking the commit history of this file: https://github.com/tensorflow/tensorboard/commits/master/tensorboard/pip_package/requirements.txt
> 
> Found [tensorflow/tensorboard@78f97c2](https://github.com/tensorflow/tensorboard/commit/78f97c28273f3909a69c0b9f36ffcc2d0130ca48) changed `protobuf >= 3.9.2, < 4` to `protobuf >= 3.9.16`.

Great investigation!",cause running docker run python bash pip install reverse get require latest version suspicious issue happening day ago file commit history file found great investigation,issue,positive,positive,positive,positive,positive,positive
1429322135,"Hi @bryanwhiting, upon closer inspection it appears that the following code is the source of the issue:

```
# experiment_id = mlflow.create_experiment(
#     ""client2"",
#     artifact_location=Path.cwd().joinpath(""mlruns"").as_uri(),
#     tags={""target"": ""revenue"", ""priority"": ""P1""},
# )
# exp = mlflow.set_experiment(""client2"")
```

The `client2` experiment is being created with the `mlruns` directory as the artifact location. As a result, artifacts are logged in run ID subdirectories of `mlruns`. Creating a new experiment and omitting `artifact_location` as follows should resolve the issue:

```
experiment_id = mlflow.create_experiment(
    ""client3"",
    tags={""target"": ""revenue"", ""priority"": ""P1""},
)
exp = mlflow.set_experiment(""client3"")
```

Thank you for using MLflow!",hi upon closer inspection following code source issue client target revenue priority client client experiment directory artifact location result logged run id new experiment resolve issue client target revenue priority client thank,issue,positive,positive,neutral,neutral,positive,positive
1429317684,"Hi @yossibiton , thank you for clarifying. I think this is a bug in `mlflow ui`. Because `mlflow ui` shares the same code with `mlflow server`, it uses a default artifact location of the form `mlflow-artifacts:/` for newly-created experiments. Instead, it should use the local filesystem.

For now, you can circumvent the problem by specifying `artifact_location` and passing in a local filesystem path. I've reopened this issue, and we'll get it addressed in the next release.",hi thank think bug code server default artifact location form instead use local circumvent problem passing local path issue get next release,issue,negative,neutral,neutral,neutral,neutral,neutral
1429305014,"> I guess conda-forge might upload some new version package that affect the version resolution.

`tests/tensorflow/mlflow-128-tf-23-env.yaml` doesn't contain conda dependencies. `conda-forge` is unrelated.",guess might new version package affect version resolution contain unrelated,issue,negative,positive,positive,positive,positive,positive
1429292192,"I investigated the cause. By running `docker run --rm python:3.8 bash -c ""pip install tensorflow==2.3.0 pipdeptree && pipdeptree --reverse --packages protobuf""`, you can get:

```
protobuf==4.21.12
  - tensorboard==2.12.0 [requires: protobuf>=3.19.6]
    - tensorflow==2.3.0 [requires: tensorboard>=2.3.0,<3]
  - tensorflow==2.3.0 [requires: protobuf>=3.9.2]
```

This means `tensorflow` and `tensorboard` require `protobuf`.

---

The latest version of `tensorboard` was released on Feb 10 so it looks suspicious because this issue started happening 3 or 4 days ago: https://pypi.org/project/tensorboard/2.12.0

---

This file determines `tensorboard`'s dependencies:
https://github.com/tensorflow/tensorboard/blob/master/tensorboard/pip_package/requirements.txt

---

I'm checking the commit history of this file:
https://github.com/tensorflow/tensorboard/commits/master/tensorboard/pip_package/requirements.txt

---

Found https://github.com/tensorflow/tensorboard/commit/78f97c28273f3909a69c0b9f36ffcc2d0130ca48 changed `protobuf >= 3.9.2, < 4` to `protobuf >= 3.9.16`.",cause running docker run python bash pip install reverse get require latest version suspicious issue happening day ago file commit history file found,issue,negative,positive,positive,positive,positive,positive
1429269360,"Thank you for your response !
However, I'm still not able to solve the issue. I'm not using mlflow server, just storing the files locally on local path (/efs/mlflow) as you can see in my code example.

In order to create the experiments I did this : 
```
cd /efs/mlflow
mlflow ui
```
   
And then in the UI I created a new experiment : 
![image](https://user-images.githubusercontent.com/6518016/218670827-3a1ea767-7951-4c08-9c12-91f4d873fc21.png)

Can you explain please what did I do wrong ?
Do I have to set ""Artifact Location"" ?",thank response however still able solve issue server locally local path see code example order create new experiment image explain please wrong set artifact location,issue,positive,positive,neutral,neutral,positive,positive
1429229801,"We can confirm that,

now we run `conda env create -f tests/tensorflow/mlflow-128-tf-23-env.yaml`, we will create an environment with `protobuf==4.21.12`, and we know that protobuf 4.21 version is not compatible with Tensorflow model saving.

For several days ago, it should install older version of protobuf when running the same command, I guess conda-forge might upload some new version package that affect the version resolution.",confirm run create create environment know version compatible model saving several day ago install older version running command guess might new version package affect version resolution,issue,negative,positive,positive,positive,positive,positive
1429097203,"Removing `/opt/hostedtoolcache` frees up about 9GB disk space:

```
+ df -h
Filesystem      Size  Used Avail Use% Mounted on
/dev/root        84G   51G   33G  61% /
tmpfs           3.4G  172K  3.4G   1% /dev/shm
tmpfs           1.4G  1.1M  1.4G   1% /run
tmpfs           5.0M     0  5.0M   0% /run/lock
/dev/sdb15      105M  5.3M  100M   5% /boot/efi
/dev/sda1        14G  4.1G  9.0G  31% /mnt
tmpfs           695M   [12](https://github.com/mlflow/mlflow/actions/runs/4169937735/jobs/7218418083#step:3:13)K  695M   1% /run/user/1001
+ rm -rf /opt/hostedtoolcache

+ df -h
Filesystem      Size  Used Avail Use% Mounted on
/dev/root        84G   42G   42G  51% /
tmpfs           3.4G  172K  3.4G   1% /dev/shm
tmpfs           1.4G  1.1M  1.4G   1% /run
tmpfs           5.0M     0  5.0M   0% /run/lock
/dev/sdb15      105M  5.3M  100M   5% /boot/efi
/dev/sda1        [14](https://github.com/mlflow/mlflow/actions/runs/4169937735/jobs/7218418083#step:3:15)G  4.1G  9.0G  31% /mnt
tmpfs           695M   12K  695M   1% /run/user/1001
```

We have 33GB disk space by default. I thin that should be enough.",removing disk space size used avail use mounted size used avail use mounted disk space default thin enough,issue,negative,negative,negative,negative,negative,negative
1428953843,Multiple plots at the same time sounds great. It's a shame that this feature can't be implemented yet though. Thanks for clarifying.,multiple time great shame feature ca yet though thanks,issue,positive,positive,positive,positive,positive,positive
1428873186,"@CaptainTrojan Got it - we'll be introducing a revamped experience for this shortly; you will be able to see multiple metric plots side by side and visualize them across time or epoch. We hope this will ease the burden of model selection. In the future, I completely agree that tracking the min / max / mean of each metric automatically would be very helpful. This will require some substantial changes to our REST API and as such isn't easily prioritized, but we've seen similar requests and will be mindful of them going forward. Thank you for using MLflow!",got experience shortly able see multiple metric side side visualize across time epoch hope ease burden model selection future completely agree min mean metric automatically would helpful require substantial rest easily seen similar mindful going forward thank,issue,positive,positive,positive,positive,positive,positive
1428871063,"Hi @Syntax3rror404 , we don't yet support deepspeed in MLflow Recipes, but we will certainly work to introduce this in the future.",hi yet support certainly work introduce future,issue,positive,positive,positive,positive,positive,positive
1428870407,"Thanks @Crazybean-lwb , we would welcome an implementation of this FR. @ridhimag11 would you be able to advise on where this functionality should be exposed in the MLflow UI?",thanks would welcome implementation would able advise functionality exposed,issue,positive,positive,positive,positive,positive,positive
1428868329,"Hi @PannenetsF, your request makes a lot of sense. I think we could achieve this by piping the contents of stderr and stdout to a file while a run is being executed (e.g. within a `with mlflow.start_run()` block or between `mlflow.start_run()` and `mlflow.end_run()` commands). We could then log this file as an artifact to the run. We should also take care to handle nested runs properly (i.e. when creating a nested run, a new file should be created for the scope of the nested run).

We would certainly welcome your contribution of this feature, and let me know if you have any questions.",hi request lot sense think could achieve piping content file run executed within block could log file artifact run also take care handle properly run new file scope run would certainly welcome contribution feature let know,issue,positive,positive,positive,positive,positive,positive
1428865369,"Hi @aaparikh, thank you for raising this issue. The problem appears to be that your PyTorch model is attached as an attribute of your `ModelDetectorWrapper` custom pyfunc model. MLflow uses cloudpickle to serialize this custom model class, which means that it's also trying to serialize your PyTorch model with cloudpickle.

To fix the issue, we recommend using the `artifacts` argument of `mlflow.pyfunc.log_model()` to specify the path to your serialized PyTorch model and then defining a `load_context()` method in your `ModelDetectorWrapper` to automatically load the serialized model when `mlflow.pyfunc.load_model()` is called. For reference, here's a similar example from the MLflow docs: https://mlflow.org/docs/latest/models.html#example-saving-an-xgboost-model-in-mlflow-format.

Thank you for using MLflow!",hi thank raising issue problem model attached attribute custom model serialize custom model class also trying serialize model fix issue recommend argument specify path model method automatically load model reference similar example thank,issue,negative,neutral,neutral,neutral,neutral,neutral
1428861421,"Hi @yossibiton, thank you for raising this issue. The problem appears to be that your MLflow experiment with name `object_detection` was created using an HTTP request to `mlflow server` or was created by manually specifying an `mlflow-artifacts://` URI as the `artifact_location`. In order to log artifacts to this experiment, you'll need to run your `mlflow server` and set the MLflow Tracking URI to communicate with the MLflow server, e.g. something like `mlflow.set_tracking_uri(""http://127.0.0.1:5000"")`.

Thank you for using MLflow!",hi thank raising issue problem experiment name request server manually order log experiment need run server set communicate server something like thank,issue,positive,neutral,neutral,neutral,neutral,neutral
1428856760,"Thanks @bryanwhiting ! A couple small questions:

1. What is your tracking URI?
2. From what directory are you running the `Code to reproduce issue`?",thanks couple small directory running code reproduce issue,issue,negative,negative,neutral,neutral,negative,negative
1428849309,"Hi @ddejaco, this behavior is intended because we assume that the metrics correspond to the model that was logged by calling the sklearn `fit()` method. Thank you for using MLflow!",hi behavior intended assume metric correspond model logged calling fit method thank,issue,positive,positive,positive,positive,positive,positive
1428810317,"Hi!

Not really progressing as I did not receive any feedback. Is there any
chance that we proceed with that?

Best regards,
Sotiris


On Mon, 13 Feb 2023 at 11:25 PM, fpollet-altanova ***@***.***>
wrote:

> Hi! How is this project going?
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/mlflow/mlflow/issues/5689#issuecomment-1428708570>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AKXVR22TPTZKZEXBCCE3KA3WXKRDLANCNFSM5TKBYRJA>
> .
> You are receiving this because you were mentioned.Message ID:
> ***@***.***>
>
",hi really receive feedback chance proceed best mon wrote hi project going reply directly view id,issue,positive,positive,positive,positive,positive,positive
1428329871,@serena-ruan the tasks were cancelled due to a timeout from pip resolution tree logic. Could you merge master branch into your PR (that should fix it :) )?,due pip resolution tree logic could merge master branch fix,issue,negative,negative,negative,negative,negative,negative
1427992024,Cheers. It seems the builds seem to be timing out on installing the deps for the 4 cancelled steps. It appears that a few other PRs also have this issue. Let me know if anything needs changing.,seem timing also issue let know anything need,issue,negative,neutral,neutral,neutral,neutral,neutral
1427509647,@BenWilson2 @harupy Could you help me rerun the cancelled tasks? And if it passes I'm waiting for approval :D,could help rerun waiting approval,issue,positive,neutral,neutral,neutral,neutral,neutral
1427119074,"I tried running this and got this error

`S3UploadFailedError: Failed to upload foo.txt to mlflow-artifacts-remote-010123/1/fda81f37e5b74023b798dc09dfc79f9b/artifacts/foo.txt: An error occurred (405) when calling the PutObject operation: Method Not Allowed`

Please assist",tried running got error error calling operation method please assist,issue,negative,neutral,neutral,neutral,neutral,neutral
1427069376,"If you are using python3.7 and you have mlflow version 1.27.* and you have this error, you need to update the mlflow to 1.30.* to resolve this error.
python3.7 -m pip install mlflow -U
It worked for me, it might work for you.",python version error need update resolve error python pip install worked might work,issue,negative,neutral,neutral,neutral,neutral,neutral
1427068621,"If you are using python3.7 and you have mlflow version 1.27.* and you have this error, you need to update the mlflow to 1.30.* to resolve this error.
`python3.7 -m pip install mlflow -U`
It worked for me",python version error need update resolve error python pip install worked,issue,negative,neutral,neutral,neutral,neutral,neutral
1426890782,"Note, this error happens if exp_id is a string or an int:
```
with mlflow.start_run(experiment_id=584226892336041065, run_name=""2023-02-rev"") as run:
```

Also, this doesn't happen with the default exp_id. But it happens if I pass in an experiment_id into `start_run()` or if i use the `mlflow.set_experiment(exp_name)`.",note error string rev run also happen default pas use,issue,negative,neutral,neutral,neutral,neutral,neutral
1426587279,"Hi @JoaoAreias , I tried it on Windows 11 with the identical script that you provided. and it works just fine. 
I create a brand new conda environment and then install mlflow as @dbczumar mentioned by running `pip install git+https://github.com/mlflow/mlflow@master` inside that environment. I then installed plotly/kaleido as needed by your script. Details:

Environment:
```
alembic==1.9.3
certifi @ file:///C:/b/abs_85o_6fm0se/croot/certifi_1671487778835/work/certifi
charset-normalizer==3.0.1
click==8.1.3
cloudpickle==2.2.1
colorama==0.4.6
contourpy==1.0.7
cycler==0.11.0
databricks-cli==0.17.4
docker==6.0.1
entrypoints==0.4
Flask==2.2.2
fonttools==4.38.0
gitdb==4.0.10
GitPython==3.1.30
greenlet==2.0.2
idna==3.4
importlib-metadata==5.2.0
importlib-resources==5.10.2
itsdangerous==2.1.2
Jinja2==3.1.2
joblib==1.2.0
kaleido @ file:///C:/Users/bali0/Downloads/kaleido-0.1.0.post1-py2.py3-none-win_amd64.whl
kiwisolver==1.4.4
llvmlite==0.39.1
Mako==1.2.4
Markdown==3.4.1
MarkupSafe==2.1.2
matplotlib==3.6.3
mlflow @ git+https://github.com/mlflow/mlflow@43b1ec7476ce2cb40a88d534ca77604f3e02ba01
numba==0.56.4
numpy==1.23.5
oauthlib==3.2.2
packaging==22.0
pandas==1.5.3
Pillow==9.4.0
plotly==5.13.0
protobuf==4.21.12
pyarrow==10.0.1
PyJWT==2.6.0
pyparsing==3.0.9
python-dateutil==2.8.2
pytz==2022.7.1
pywin32==305
PyYAML==6.0
querystring-parser==1.2.4
requests==2.28.2
scikit-learn==1.2.1
scipy==1.10.0
shap==0.41.0
six==1.16.0
slicer==0.0.7
smmap==5.0.0
SQLAlchemy==2.0.3
sqlparse==0.4.3
tabulate==0.9.0
tenacity==8.2.1
threadpoolctl==3.1.0
tqdm==4.64.1
typing_extensions==4.4.0
urllib3==1.26.14
waitress==2.1.2
websocket-client==1.5.1
Werkzeug==2.2.2
wincertstore==0.2
zipp==3.13.0
```





Artifact correctly logged:


![Screenshot_20230210_100041](https://user-images.githubusercontent.com/18537688/218235707-015bda4f-dd82-4b6e-9762-5473f67a80a5.png)




`mlruns` folder correctly resolved:


![Screenshot_20230210_100109](https://user-images.githubusercontent.com/18537688/218235735-23a45062-f7fc-4d5e-85f5-4fde2dc0983a.png)


script:
```
import mlflow

from pathlib import Path
from datetime import datetime
from hashlib import sha256

import plotly.express as px
import plotly.graph_objects as go
import plotly.figure_factory as ff
import plotly

_now = datetime.now()
EXPERIMENT_NAME = f""FOOBAR-{_now.strftime('%y-%m-%d_%H:%M')}-{sha256(str(_now).encode()).hexdigest()[:6]}""

Path(""mlruns"").mkdir(parents=True, exist_ok=True)
mlflow.set_tracking_uri(""file:mlruns"")


client = mlflow.MlflowClient()
experiment_id = client.create_experiment(
    f""STAR-17472_{EXPERIMENT_NAME}"",
    tags={
        ""phase"": ""foobar"",
        ""author"": ""joao.pedro.a.moraes"",
    }
)
experiment = client.get_experiment(experiment_id)

fig = go.Figure()
fig.add_trace(go.Bar(
    x=[""foo"", ""bar""],
    y=[20, 80],
    textposition='auto',
    name=""foo-bar"",
    showlegend=False,
))

# Add figure to experiment
with mlflow.start_run(
        experiment_id=experiment_id,
        run_name=""foo-bar"",
        description=""lorem ipsum dolor sit amet, consectetur adipiscing elit.""
    ) as run:

    mlflow.log_figure(fig, ""foo.png"")


fig.show()
```

OS: 
![Screenshot_20230210_100642](https://user-images.githubusercontent.com/18537688/218235902-3d731e99-f230-4ce0-8581-9be8b746b02f.png)

",hi tried identical script provided work fine create brand new environment install running pip install inside environment script environment file file artifact correctly logged folder correctly resolved script import import path import import sha import import go import import sha path file client phase author experiment fig foo bar add figure experiment dolor sit run fig o,issue,positive,positive,positive,positive,positive,positive
1426481498,"Hi @paprocki-r , we are in the process of releasing a fix for this bug. If you're a multitenant customer, the fix should have already been applied to your workspace about 24 hours ago. If you're a single tenant customer, the fix will be applied next week. As an alternative, you can use shift + click to select multiple runs for comparison. Thank you for using MLflow!",hi process fix bug customer fix already applied ago single tenant customer fix applied next week alternative use shift click select multiple comparison thank,issue,negative,negative,neutral,neutral,negative,negative
1426479711,"Hi @bjoerm , when submitting search queries in the UI, the run nesting hierarchy is not shown. Rest assured, all of the runs that match the specified criteria are shown correctly, including child runs and their parents. The hierarchy just isn't displayed. Thank you for using MLflow!",hi search run hierarchy shown rest assured match criterion shown correctly child hierarchy displayed thank,issue,positive,neutral,neutral,neutral,neutral,neutral
1426468858,I believe I have made the suggested changes. One thing that should be added is that with `mlflow.onnx.load_model` the onnx model checker 2GB models need to be passed in the model path instead of the model object as suggested in https://github.com/onnx/onnx/blob/main/docs/ExternalData.md#large-models-2gb . I will switch the onnx model loader to check the path instead of the object once all the tests have finished running. Models that are smaller than 2GB/do not need the external data saving can still be checked using the model path alone.,believe made one thing added model checker need model path instead model object switch model loader check path instead object finished running smaller need external data saving still checked model path alone,issue,negative,neutral,neutral,neutral,neutral,neutral
1426218783,"> You need to set the `mlflow.use`r tag as follows:
> 
> `mlflow.set_tag(""mlflow.user"", ""NAME"")`

I am trying this on a MLFlow Tracking server that we have running v2.0.1 and am getting a 500 server error. I get the same error when going directly through the REST API. Anyone know what might be happening?

I can create a new tag

`mlflow.set_tag('User', 'NAME')`

but am unable to modify the mlflow.user tag.",need set tag name trying server running getting server error get error going directly rest anyone know might happening create new tag unable modify tag,issue,negative,negative,neutral,neutral,negative,negative
1425988504,"so I did a little poking at this and I think it might actually be a tensorflow/keras issue, not an MLFlow one. `model.save()` just fails with the unable to serialise error.",little poking think might actually issue one unable error,issue,negative,negative,negative,negative,negative,negative
1425752849,"Hi, I tried installing from the latest `master` and the same issue is happening",hi tried latest master issue happening,issue,negative,positive,positive,positive,positive,positive
1425214672,"My issue here was that I installed the `mlflow-skinny` pip dependency, instead of `mlflow`. ",issue pip dependency instead,issue,negative,neutral,neutral,neutral,neutral,neutral
1425183652,"It looks like for [AWS or GCP based stores the method of transferring data is using a REST api](https://github.com/mlflow/mlflow/blob/8ba9c3dbf1dffa73c70a2d5f40689a8e72df8210/mlflow/store/artifact/databricks_artifact_repo.py#L346) using a PUT operation.
The [AWS documentation for uploading objects](https://docs.aws.amazon.com/AmazonS3/latest/userguide/upload-objects.html) says that with a single PUT operation, we can upload only up to 5GB.  
Converting this to boto3 based multipart upload would be extremely helpful.
",like based method transferring data rest put operation documentation single put operation converting based would extremely helpful,issue,positive,negative,neutral,neutral,negative,negative
1425091944,"> Update: I think I've managed to solve 1.7.0 cross version test locally. It appears the `save_as_external_data` parameter was introduced in ONNX 1.9.0 and greater, and so I have an if else version check for ONNX for this locally. I haven't quite managed to figure out why the 1.8.1 version test isn't working. When I run the new test it appears I get into out of memory errors and the pytest process gets killed without a stack trace. Here is an excerpt of my syslogs:
> 
> ```
> Feb  9 18:19:28 albert kernel: [ 1078.308111] oom-kill:constraint=CONSTRAINT_NONE,nodemask=(null),cpuset=user.slice,mems_allowed=0,global_oom,task_memcg=/user.slice/user-1000.slice/user@1000.service/app.slice/app-gnome-code-92219.scope,task=pytest,pid=98896,uid=1000
> Feb  9 18:19:28 albert kernel: [ 1078.308189] Out of memory: Killed process 98896 (pytest) total-vm:41067268kB, anon-rss:29123520kB, file-rss:0kB, shmem-rss:0kB, UID:1000 pgtables:59472kB oom_score_adj:0
> Feb  9 18:19:28 albert kernel: [ 1078.315377] pytest: page allocation failure: order:0, mode:0x1100cca(GFP_HIGHUSER_MOVABLE), nodemask=(null),cpuset=user.slice,mems_allowed=0
> ```
> 
> I will push up both fixes once I have figured out this particular issue. I believe the test fixture exporting with `torch.onnx` is fine, but not the `onnx.save_model` call. Reducing the size of the model below the 2GB limit seems to work. If anyone has ideas if it's some memory leak or whatever I'd be keen to know.

I've seen some other users report OOMs when exporting models as ONNX. If possible, can we adjust the test case to instead verify that the external data functionality from ONNX is being used, instead of verifying that a 2GB model can be saved? This will help avoid potential OOM flakiness.",update think solve cross version test locally parameter greater else version check locally quite figure version test working run new test get memory process without stack trace excerpt kernel null kernel memory process kernel page allocation failure order mode null push figured particular issue believe test fixture fine call reducing size model limit work anyone memory leak whatever keen know seen report possible adjust test case instead verify external data functionality used instead model saved help avoid potential flakiness,issue,positive,positive,neutral,neutral,positive,positive
1424845192,"Update: I think I've managed to solve 1.7.0 cross version test locally. It appears the `save_as_external_data` parameter was introduced in ONNX 1.9.0 and greater, and so I have an if else version check for ONNX for this locally. I haven't quite managed to figure out why the 1.8.1 version test isn't working. When I run the new test it appears I get into out of memory errors and the pytest process gets killed without a stack trace. Here is an excerpt of my syslogs:

```
Feb  9 18:19:28 albert kernel: [ 1078.308111] oom-kill:constraint=CONSTRAINT_NONE,nodemask=(null),cpuset=user.slice,mems_allowed=0,global_oom,task_memcg=/user.slice/user-1000.slice/user@1000.service/app.slice/app-gnome-code-92219.scope,task=pytest,pid=98896,uid=1000
Feb  9 18:19:28 albert kernel: [ 1078.308189] Out of memory: Killed process 98896 (pytest) total-vm:41067268kB, anon-rss:29123520kB, file-rss:0kB, shmem-rss:0kB, UID:1000 pgtables:59472kB oom_score_adj:0
Feb  9 18:19:28 albert kernel: [ 1078.315377] pytest: page allocation failure: order:0, mode:0x1100cca(GFP_HIGHUSER_MOVABLE), nodemask=(null),cpuset=user.slice,mems_allowed=0

```

I will push up both fixes once I have figured out this particular issue. I believe the test fixture exporting with `torch.onnx` is fine, but not the `onnx.save_model` call. Reducing the size of the model below the 2GB limit seems to work. If anyone has ideas if it's some memory leak or whatever I'd be keen to know. ",update think solve cross version test locally parameter greater else version check locally quite figure version test working run new test get memory process without stack trace excerpt kernel null kernel memory process kernel page allocation failure order mode null push figured particular issue believe test fixture fine call reducing size model limit work anyone memory leak whatever keen know,issue,negative,positive,positive,positive,positive,positive
1424590309,Yeah that's fine! I'll fit this in when my other workload is a bit lower,yeah fine fit bit lower,issue,positive,positive,positive,positive,positive,positive
1424517756,Another regression. Rename experiment doesn't update the list after renaming. Even after calling `this.list.forceUpdateGrid`. It should since the props/state change.,another regression rename experiment update list even calling since change,issue,negative,neutral,neutral,neutral,neutral,neutral
1424055189,"Sure can: 
```
TypeError                                 Traceback (most recent call last)
Cell In[7], line 115
    107 plot_update_callback = keras.callbacks.LambdaCallback(
    108     on_batch_end=lambda batch, logs:  update_image_outputs() if batch % 250 == 0 else None
    109 )
    111 with strategy.scope():
    112     #train_dataset = tf.data.Dataset.from_tensor_slices((train_data)).repeat(epochs).batch(batch_size).with_options(options)
    113     #val_dataset = tf.data.Dataset.from_tensor_slices((val_data)).batch(batch_size).with_options(options)
    114     # Model fitting using data generator
--> 115     train_hist = model.fit(KDG, validation_data = VDG, batch_size=batch_size, epochs=epochs, steps_per_epoch=int(nPulses/batch_size), callbacks=[plot_update_callback,lr_sched], workers=32, use_multiprocessing=True)

File ~/.local/lib/python3.9/site-packages/mlflow/utils/autologging_utils/safety.py:553, in safe_patch.<locals>.safe_patch_function(*args, **kwargs)
    543 try_log_autologging_event(
    544     AutologgingEventLogger.get_logger().log_patch_function_start,
    545     session,
   (...)
    549     kwargs,
    550 )
    552 if patch_is_class:
--> 553     patch_function.call(call_original, *args, **kwargs)
    554 else:
    555     patch_function(call_original, *args, **kwargs)

File ~/.local/lib/python3.9/site-packages/mlflow/utils/autologging_utils/safety.py:170, in PatchFunction.call(cls, original, *args, **kwargs)
    168 @classmethod
    169 def call(cls, original, *args, **kwargs):
--> 170     return cls().__call__(original, *args, **kwargs)

File ~/.local/lib/python3.9/site-packages/mlflow/utils/autologging_utils/safety.py:181, in PatchFunction.__call__(self, original, *args, **kwargs)
    177     self._on_exception(e)
    178 finally:
    179     # Regardless of what happens during the `_on_exception` callback, reraise
    180     # the original implementation exception once the callback completes
--> 181     raise e

File ~/.local/lib/python3.9/site-packages/mlflow/utils/autologging_utils/safety.py:174, in PatchFunction.__call__(self, original, *args, **kwargs)
    172 def __call__(self, original, *args, **kwargs):
    173     try:
--> 174         return self._patch_implementation(original, *args, **kwargs)
    175     except (Exception, KeyboardInterrupt) as e:
    176         try:

File ~/.local/lib/python3.9/site-packages/mlflow/utils/autologging_utils/safety.py:232, in with_managed_run.<locals>.PatchWithManagedRun._patch_implementation(self, original, *args, **kwargs)
    229 if not mlflow.active_run():
    230     self.managed_run = create_managed_run()
--> 232 result = super()._patch_implementation(original, *args, **kwargs)
    234 if self.managed_run:
    235     mlflow.end_run(RunStatus.to_string(RunStatus.FINISHED))

File ~/.local/lib/python3.9/site-packages/mlflow/tensorflow/__init__.py:1229, in autolog.<locals>.FitPatch._patch_implementation(self, original, inst, *args, **kwargs)
   1226 history = original(inst, *args, **kwargs)
   1228 if log_models:
-> 1229     _log_keras_model(history, args)
   1231 _log_early_stop_callback_metrics(
   1232     callback=early_stop_callback,
   1233     history=history,
   1234     metrics_logger=metrics_logger,
   1235 )
   1237 _flush_queue()

File ~/.local/lib/python3.9/site-packages/mlflow/tensorflow/__init__.py:1144, in autolog.<locals>._log_keras_model(history, args)
   1134     return keras_input_example_slice
   1136 input_example, signature = resolve_input_example_and_signature(
   1137     _get_tf_keras_input_example_slice,
   1138     _infer_model_signature,
   (...)
   1141     _logger,
   1142 )
-> 1144 log_model(
   1145     model=history.model,
   1146     artifact_path=""model"",
   1147     input_example=input_example,
   1148     signature=signature,
   1149     registered_model_name=get_autologging_config(
   1150         FLAVOR_NAME, ""registered_model_name"", None
   1151     ),
   1152     saved_model_kwargs=saved_model_kwargs,
   1153     keras_model_kwargs=keras_model_kwargs,
   1154 )

File ~/.local/lib/python3.9/site-packages/mlflow/tensorflow/__init__.py:220, in log_model(model, artifact_path, custom_objects, conda_env, code_paths, signature, input_example, registered_model_name, await_registration_for, pip_requirements, extra_pip_requirements, saved_model_kwargs, keras_model_kwargs, metadata)
    124 @format_docstring(LOG_MODEL_PARAM_DOCS.format(package_name=FLAVOR_NAME))
    125 def log_model(
    126     model,
   (...)
    139     metadata=None,
    140 ):
    141     """"""
    142     Log a TF2 core model (inheriting tf.Module) or a Keras model in MLflow Model format.
    143 
   (...)
    217              metadata of the logged model.
    218     """"""
--> 220     return Model.log(
    221         artifact_path=artifact_path,
    222         flavor=mlflow.tensorflow,
    223         model=model,
    224         conda_env=conda_env,
    225         code_paths=code_paths,
    226         custom_objects=custom_objects,
    227         registered_model_name=registered_model_name,
    228         signature=signature,
    229         input_example=input_example,
    230         await_registration_for=await_registration_for,
    231         pip_requirements=pip_requirements,
    232         extra_pip_requirements=extra_pip_requirements,
    233         saved_model_kwargs=saved_model_kwargs,
    234         keras_model_kwargs=keras_model_kwargs,
    235         metadata=metadata,
    236     )

File ~/.local/lib/python3.9/site-packages/mlflow/models/model.py:486, in Model.log(cls, artifact_path, flavor, registered_model_name, await_registration_for, metadata, **kwargs)
    484 run_id = mlflow.tracking.fluent._get_or_start_run().info.run_id
    485 mlflow_model = cls(artifact_path=artifact_path, run_id=run_id, metadata=metadata)
--> 486 flavor.save_model(path=local_path, mlflow_model=mlflow_model, **kwargs)
    487 mlflow.tracking.fluent.log_artifacts(local_path, mlflow_model.artifact_path)
    488 try:

File ~/.local/lib/python3.9/site-packages/mlflow/tensorflow/__init__.py:433, in save_model(model, path, conda_env, code_paths, mlflow_model, custom_objects, signature, input_example, pip_requirements, extra_pip_requirements, saved_model_kwargs, keras_model_kwargs, metadata)
    431         shutil.copyfile(src=f.name, dst=model_path)
    432 else:
--> 433     model.save(model_path, **keras_model_kwargs)
    435 pyfunc_options = {
    436     ""data"": data_subpath,
    437 }
    438 flavor_options = {
    439     **pyfunc_options,
    440     ""model_type"": _MODEL_TYPE_KERAS,
    441     ""keras_version"": keras_module.__version__,
    442     ""save_format"": save_format,
    443 }

File /opt/tljh/user/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70, in filter_traceback.<locals>.error_handler(*args, **kwargs)
     67     filtered_tb = _process_traceback_frames(e.__traceback__)
     68     # To get the full stack trace, call:
     69     # `tf.debugging.disable_traceback_filtering()`
---> 70     raise e.with_traceback(filtered_tb) from None
     71 finally:
     72     del filtered_tb

File /opt/tljh/user/lib/python3.9/json/encoder.py:199, in JSONEncoder.encode(self, o)
    195         return encode_basestring(o)
    196 # This doesn't pass the iterator directly to ''.join() because the
    197 # exceptions aren't as detailed.  The list call should be roughly
    198 # equivalent to the PySequence_Fast that ''.join() would do.
--> 199 chunks = self.iterencode(o, _one_shot=True)
    200 if not isinstance(chunks, (list, tuple)):
    201     chunks = list(chunks)

File /opt/tljh/user/lib/python3.9/json/encoder.py:257, in JSONEncoder.iterencode(self, o, _one_shot)
    252 else:
    253     _iterencode = _make_iterencode(
    254         markers, self.default, _encoder, self.indent, floatstr,
    255         self.key_separator, self.item_separator, self.sort_keys,
    256         self.skipkeys, _one_shot)
--> 257 return _iterencode(o, 0)

TypeError: Unable to serialize 1j to JSON. Unrecognized type <class 'complex'>.
```

As for fixing it myself, I'd be willing to give it a crack if there's no speedy resolution likely, but I'm pretty busy as is.",sure recent call last cell line batch batch else none model fitting data generator file session else file original call original return original file self original finally regardless reraise original implementation exception raise file self original self original try return original except exception try file self original result super original file self original history original history file history return signature model none file model signature model log core model model model format logged return file flavor try file model path signature else data file get full stack trace call raise none finally file self return pas directly detailed list call roughly equivalent would list list file self else return unable serialize unrecognized type class fixing willing give crack speedy resolution likely pretty busy,issue,positive,positive,positive,positive,positive,positive
1423489523,"@dbczumar Very little. Yes, it is possible to find the best performing model that way, as the table in the compare/metric view shows you min and max values of said metric for each run in the selection, but you cannot compare using multiple metrics and all those scatter plot / parallel coordinate plot visualizations, which I was looking forward to using, are useless for me, because, well, _last tracked value_ is not representative. Not to mention that the overview metric columns are not representative as well.",little yes possible find best model way table view min said metric run selection compare multiple metric scatter plot parallel plot looking forward useless well tracked representative mention overview metric representative well,issue,positive,positive,neutral,neutral,positive,positive
1423427750,"Thanks for the PR, @dogeplusplus. Looks great in general; our CI for older versions seems to indicate that there's some incompatibility with ONNX 1.8.1 and 1.7.0:

```
tests/onnx/test_onnx_model_export.py::test_model_save_load FAILED        [  3%]
tests/onnx/test_onnx_model_export.py::test_model_save_load_2gb 
Error: Process completed with exit code 143.
```

Please let me know if you'd like assistance debugging this.",thanks great general older indicate incompatibility error process exit code please let know like assistance,issue,positive,positive,positive,positive,positive,positive
1423241298,"@monajalal, the general Azure guidance is to log into the [Azure Machine Learning studio](https://ml.azure.com/) and find your AzureML workspace, navigate to the Jobs tab, and find your experiment there. Do you have access to this workspace view?

Adding @santiagxf a) in case he has a better option b) so that he can track this ask in case we want to build a more direct solution",general azure guidance log azure machine learning studio find navigate tab find experiment access view case better option track ask case want build direct solution,issue,positive,positive,positive,positive,positive,positive
1423240766,"Hi @Nika-St I did some digging into similar issues that users have posted regarding this in the `requests` repo and looked into what this error actually is. 
From what I've gleaned and the fact that I can't reproduce this with different tracking server configuration types, it leads me to believe that the comms error is either:
a) an issue in your tracking server. 
b) an issue with your local install of `urrlib` and `requests` versions having some degreee of incompatibility with each other.

Can you try:
1. Install the latest versions of `urllib` and `requests`?
2. Upgrade your MLflow server version",hi digging similar posted regarding error actually fact ca reproduce different server configuration believe error either issue server issue local install incompatibility try install latest upgrade server version,issue,negative,positive,neutral,neutral,positive,positive
1423138139,Hi @wamartin-aml can you provide guidance regarding how to view the Azure UI for an MLflow Experiment?,hi provide guidance regarding view azure experiment,issue,negative,neutral,neutral,neutral,neutral,neutral
1423136660,"Hi @hugolytics , thank you for filing this issue. At this time, parameter and metric names cannot contain commas. We recommend replacing commas with a supported character, such as an underscore, prior to logging. Thank you for using MLflow!",hi thank filing issue time parameter metric contain recommend character underscore prior logging thank,issue,positive,neutral,neutral,neutral,neutral,neutral
1423133809,"Hi @subramaniam02 , thank you for raising this issue! We'd be very excited to review a PR that addresses it. Please let me know if you have any questions. Thank you in advance for your contribution!",hi thank raising issue excited review please let know thank advance contribution,issue,positive,positive,positive,positive,positive,positive
1423132285,"Hi @dogeplusplus , thank you for raising this feature request. We'd be very excited to review a PR with your proposed extension. Please let me know if you have any questions, and we look forward to your contribution!",hi thank raising feature request excited review extension please let know look forward contribution,issue,positive,positive,positive,positive,positive,positive
1423130045,"Hi @amylizzle , thank you for raising this issue. If possible, can you set the environment variable `MLFLOW_AUTOLOGGING_TESTING=true` and provide the full stacktrace of the issue?

In any case, we would very much appreciate a fix for this issue. If you have a solution in mind, feel free to file a PR; we're happy to provide guidance and reviews. Thank you in advance!",hi thank raising issue possible set environment variable provide full issue case would much appreciate fix issue solution mind feel free file happy provide guidance thank advance,issue,positive,positive,positive,positive,positive,positive
1423126457,"Hi @JoaoAreias , can you try installing MLflow from the latest `master` branch via `pip install git+https://github.com/mlflow/mlflow@master` and then run your workflow again? @bali0019 recently made some fixes here in https://github.com/mlflow/mlflow/pull/7670 and https://github.com/mlflow/mlflow/pull/7750.

If the problem persists, feel free to reopen this issue.",hi try latest master branch via pip install run bali recently made problem feel free reopen issue,issue,negative,positive,positive,positive,positive,positive
1423122756,"Thank you, @subramaniam02! @aaparikh Since the issue appears to be resolved, I'm going to go ahead and close it. Please feel free to reopen this if the problem persists.",thank since issue resolved going go ahead close please feel free reopen problem,issue,positive,positive,positive,positive,positive,positive
1423120884,"Hi @fzyzcjy , we recommend deleting and cleaning up runs that you no longer need via the `mlflow gc` command (https://mlflow.org/docs/latest/cli.html#mlflow-gc). Additionally, you may see better scalability over time by using MySQL, Postgres, or SQLServer. Thank you for using MLflow!",hi recommend cleaning longer need via command additionally may see better time thank,issue,positive,positive,positive,positive,positive,positive
1423118783,@CaptainTrojan Does having the ability to plot the train / val loss curves for multiple runs on the same axis help? We'll be improving this view and embedding it directly on the experiment page shortly.,ability plot train loss multiple axis help improving view directly experiment page shortly,issue,positive,positive,neutral,neutral,positive,positive
1423093860,"I made the [following forked version](https://github.com/NarekA/mlflow/commit/8b6eba8da8acefd4867af190c48ace54171eb02b) to work around this issue. I run the server for the first time with that forked version and it initializes the DB with all the `VARCHAR(255)` fields as `VARCHAR(250)`. After that, I am able to run the current latest release and no longer need the fork.

Start with an empty database and run:
```bash
pip3 install \
    'mlflow @ git+https://github.com/NarekA/mlflow.git@8b6eba8da8acefd4867af190c48ace54171eb02b#mlflow[extras,mlflow-dbstore]'

# Ctrl-c to kill this process once the db is initialzed
mlflow server --backend-store-uri=mysql://[...]

pip3 install --force-reinstall mlflow==2.1.1

mlflow server --backend-store-uri=mysql://[...]
```
",made following forked version work around issue run server first time forked version able run current latest release longer need fork start empty run bash pip install kill process server pip install server,issue,negative,positive,positive,positive,positive,positive
1422829022,"@idlefella yes, you can delete this PR. I think that once the PR for #7566 is merged, you should contribute a plugin version of what you're working on as an example for the docs (along with the full plugin example code in an instructional format) to serve as a really awesome example of how to override the behavior of the inference server. LMK what you think!",yes delete think contribute version working example along full example code instructional format serve really awesome example override behavior inference server think,issue,positive,positive,positive,positive,positive,positive
1422500179,"Hi @BenWilson2 

Yes that sounds good if we can solve that with a plugin. So I will delete this PR, ok?",hi yes good solve delete,issue,positive,positive,positive,positive,positive,positive
1421604685,"`mlflow.set_tracking_uri(""http://localhost:5000"")` should be done before any mlflow operation.
```
import mlflow
import torch
import cv2



#This line of code, when included is causing an error
#-----------------------------------------------------
mlflow.set_tracking_uri(""http://localhost:5000"")
#-----------------------------------------------------

#helper function to get experiment id
def get_experiment_id(name):
    exp = mlflow.get_experiment_by_name(name)
    if exp is None:
      exp_id = mlflow.create_experiment(name)
      return exp_id
    return exp.experiment_id

#Implementing mlflow
model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)
exp_id = get_experiment_id(""yolov5"")
model_name = ""YoloModel""

with mlflow.start_run(run_name=""PARENT_RUN"",experiment_id=exp_id) as parent_run:
    res = model.train(data=""coco128.yaml"", epochs=1, imgsz=640)
    mlflow.pytorch.log_model(
       model, 
       ""model"",
       registered_model_name=model_name
       )
    mlflow.end_run()

model = mlflow.pytorch.load_model(
    model_uri=f""models:/{model_name}/latest""
)

image_path = 'https://ultralytics.com/images/bus.jpg'
img=cv2.imread(image_path)
results=model(img)
results.show()
```",done operation import import torch import line code included causing error helper function get experiment id name name none name return return model model model model,issue,negative,neutral,neutral,neutral,neutral,neutral
1421604161,I'll be adding integration testing support for the spark version of diviner's MLflow integration within the Diviner repo once this is merged into Master.,integration testing support spark version diviner integration within diviner master,issue,positive,neutral,neutral,neutral,neutral,neutral
1421482973,"> @dipanjank Sounds great! Thank you for all of the contributions! 👍

It's great to be able to contribute to such a popular project :)",great thank great able contribute popular project,issue,positive,positive,positive,positive,positive,positive
1421431963,"Hello everyone, is there an update on this request?",hello everyone update request,issue,negative,neutral,neutral,neutral,neutral,neutral
1420694976,"@BenWilson2 @dbczumar @harupy @WeichenXu123 please let me know the status, also please suggest a alternative for communication so that i can reach out to you all (either mail, or some slack channel or something else) as i have some other use-case specific queries which i believe needed to be catered.",please let know status also please suggest alternative communication reach either mail slack channel something else specific believe,issue,positive,neutral,neutral,neutral,neutral,neutral
1420519330,"@Nika-St  

>  I also need to track dozens of parameters and metrics but only compare a few within a set of runs

I face the same needs. I recommend you to downgrade to MLFlow 1.17 then as I did.",also need track metric compare within set face need recommend downgrade,issue,negative,neutral,neutral,neutral,neutral,neutral
1420424831,"Hey, thanks for the suggestion.
I did change the uri but another error appeared that says
`mlflow.exceptions.RestException: RESOURCE_DOES_NOT_EXIST: No Experiment with id=433051632486373249 exists`

Following is the traceback that occured.
```shell
Traceback (most recent call last):
  File ""/Users/{some_path}/Mlflow yolo implementation/final_file.py"", line 20, in <module>
    with mlflow.start_run(run_name=""PARENT_RUN"",experiment_id=exp_id) as parent_run:
  File ""/Users/atharvaparikh/miniconda3/envs/torch/lib/python3.9/site-packages/mlflow/tracking/fluent.py"", line 349, in start_run
    active_run_obj = client.create_run(
  File ""/Users/atharvaparikh/miniconda3/envs/torch/lib/python3.9/site-packages/mlflow/tracking/client.py"", line 270, in create_run
    return self._tracking_client.create_run(experiment_id, start_time, tags, run_name)
  File ""/Users/atharvaparikh/miniconda3/envs/torch/lib/python3.9/site-packages/mlflow/tracking/_tracking_service/client.py"", line 131, in create_run
    return self.store.create_run(
  File ""/Users/atharvaparikh/miniconda3/envs/torch/lib/python3.9/site-packages/mlflow/store/tracking/rest_store.py"", line 175, in create_run
    response_proto = self._call_endpoint(CreateRun, req_body)
  File ""/Users/atharvaparikh/miniconda3/envs/torch/lib/python3.9/site-packages/mlflow/store/tracking/rest_store.py"", line 56, in _call_endpoint
    return call_endpoint(self.get_host_creds(), endpoint, method, json_body, response_proto)
  File ""/Users/atharvaparikh/miniconda3/envs/torch/lib/python3.9/site-packages/mlflow/utils/rest_utils.py"", line 281, in call_endpoint
    response = verify_rest_response(response, endpoint)
  File ""/Users/atharvaparikh/miniconda3/envs/torch/lib/python3.9/site-packages/mlflow/utils/rest_utils.py"", line 207, in verify_rest_response
    raise RestException(json.loads(response.text))
mlflow.exceptions.RestException: RESOURCE_DOES_NOT_EXIST: No Experiment with id=433051632486373249 exists
```",hey thanks suggestion change another error experiment following shell recent call last file line module file line file line return file line return file line file line return method file line response response file line raise experiment,issue,negative,positive,neutral,neutral,positive,positive
1420289621,"@aaparikh Based on the details provided, Tracking server is running on port number `5555`.  mlflow.set_tracking_uri is using port number `5000`  change it to `5555`.
",based provided server running port number port number change,issue,negative,neutral,neutral,neutral,neutral,neutral
1420148103,"While the mlflow client seems to be getting the `--default-artifact-root` setting from the tracking server, maybe it SHOULD also get the values of `MLFLOW_S3_ENDPOINT_URL` and `MLFLOW_S3_IGNORE_TLS` from the server IF they're set on the server side? it will make the remote server setup easier by consolidating the environment variables",client getting setting server maybe also get server set server side make remote server setup easier environment,issue,negative,negative,neutral,neutral,negative,negative
1420144616,I have a keen interest in this feature as well. Can it be added? I'm open to helping out ,keen interest feature well added open helping,issue,positive,neutral,neutral,neutral,neutral,neutral
1420143944,"The error looks irrelevant, but I don't have access to rerun the workflow :(",error irrelevant access rerun,issue,negative,negative,negative,negative,negative,negative
1420055173,"Hi,

I was facing the same probleming. Our scenario was using spark operator on AKS, but in our case was a missing a config for hadoop. 
Have fixed it setting param **dst_path** when use ***mlflow.spark.load.model*** pointing to a mount that is shared between the driver and executors
   * :param dfs_tmpdir: Temporary directory path on Distributed (Hadoop) File System (DFS) or local
                       filesystem if running in local mode. The model is written in this
                       destination and then copied into the model's artifact directory. This is
                       necessary as Spark ML models read from and write to DFS if running on a
                       cluster. If this operation completes successfully, all temporary files
                       created on the DFS are removed. Defaults to ``/tmp/mlflow``.*
for example:

```mlflow.spark.load_model(model_uri, dst_path=""/mnt/"")```

So, when we use spark file will be downloaded in a shared mount point between executors, if use default it will be saved in driver.

hope this can help.",hi facing scenario spark operator case missing fixed setting param use pointing mount driver param temporary directory path distributed file system local running local mode model written destination copied model artifact directory necessary spark read write running cluster operation successfully temporary removed example use spark file mount point use default saved driver hope help,issue,positive,positive,positive,positive,positive,positive
1419575333,@harupy My questions are not landing!  Sorry.  Is there a way we could chat live for 5-10 minutes so I can articulate clearly?,landing sorry way could chat live articulate clearly,issue,negative,negative,neutral,neutral,negative,negative
1419260568,"Hi @dbczumar, as per our discussion, this is the sample usage of synapseml together with mlflow autologging! Thanks for your review :D",hi per discussion sample usage together thanks review,issue,negative,positive,positive,positive,positive,positive
1419056086,"> ```python
> mlflow.shap.log_explanation(model.predict, X)
> ```

Hi @BenWilson2, I am following your example, until the last command which gives me error similar to what @kuromt mentioned above :

Model is missing inputs [HERE is a list of input varialbe names]. Note that there were extra inputs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]

Any tips what should I change to fix the issue here?",python hi following example last command error similar model missing list input note extra change fix issue,issue,negative,negative,neutral,neutral,negative,negative
1419018902,I've also asked the question on Stack Overflow but no one seems to find the answer (https://stackoverflow.com/questions/75297454/mlflow-experiment-tracking-no-such-file-or-directory),also question stack overflow one find answer,issue,negative,neutral,neutral,neutral,neutral,neutral
1419017689,"> ```python
> mlflow.shap.log_explainer(explainer_original, ""test_explainer"")
> ```

When I log the explainer in the following code` mlflow.shap.log_explainer(explainer_original, ""test_explainer"")`
It replies: ""Unable to serialize underlying model using MLflow, will use SHAP serialization"", do I need to change my code regarding this mlflow.pyfunc.PyFuncModel?",python log explainer following code unable serialize underlying model use shap serialization need change code regarding,issue,negative,negative,negative,negative,negative,negative
1418773470,"I meet the same issue. Get Loading Artifacts Failed
Unable to list artifacts stored under <code>{artifactUri}</code> for the current run. Please contact your tracking server administrator to notify them of this error, which can happen when the tracking server lacks permission to list artifacts under the current run's root artifact directory.",meet issue get loading unable list code current run please contact server administrator notify error happen server permission list current run root artifact directory,issue,negative,negative,negative,negative,negative,negative
1418658832,"@harupy I am interested to work on this FR. I have tried something, attached some screenshots. Idea is based on having two columns, one relative and other absolute (not visible by default). Users will have the option to choose absolute date from `Columns` dropdown and optionally hide relative date column.

![Screenshot 2023-02-05 at 11 57 12 PM](https://user-images.githubusercontent.com/1637727/216916140-b0d57df4-081e-4503-aa74-cace41f2abfa.png)

![Screenshot 2023-02-05 at 11 57 20 PM](https://user-images.githubusercontent.com/1637727/216916003-d5f0bb47-331e-4908-ac41-13b503e55030.png)

Thanks !",interested work tried something attached idea based two one relative absolute visible default option choose absolute date optionally hide relative date column thanks,issue,positive,positive,positive,positive,positive,positive
1416780493,"Hi @dbczumar, sounds good! Will raise a draft PR in the coming weeks when I have a first version of the custom flavor code ready to get some preliminary feedback",hi good raise draft coming first version custom flavor code ready get preliminary feedback,issue,positive,positive,positive,positive,positive,positive
1416720230,"Oh wow, thank you for the super fast fix @dbczumar ",oh wow thank super fast fix,issue,positive,positive,positive,positive,positive,positive
1416565661,Added a ticket to next sprint :) ,added ticket next sprint,issue,negative,neutral,neutral,neutral,neutral,neutral
1416565224,"@ceevee830 You can download https://files.pythonhosted.org/packages/82/21/554d28051202125013f64d5e74df5504a57ae8263d73e6fc6f75db6113db/mlflow-2.1.1.tar.gz and see what's in `mlflow/server/js/build`. I don't think the contents in this directory are SDK.
",see think content directory,issue,negative,neutral,neutral,neutral,neutral,neutral
1416542053,"
When I run the suite `tests/lightgbm/test_lightgbm_autolog.py` I get 3 expected test failures with the change introduced with that PR. 
`test_lgb_autolog_sklearn`
`test_lgb_autolog_with_sklearn_outputs_do_not_reflect_training_dataset_mutations`
`test_sklearn_api_autolog_registering_model`

Cross version testing caught it last night. Filed follow-up ticket.

",run suite get test change cross version testing caught last night ticket,issue,negative,neutral,neutral,neutral,neutral,neutral
1416530510,"> LGTM! Do we need to test various options of running a Python script with `-oo` and `-ooo` to validate optimize settings throughout MLflow? (maybe a follow-on PR later?)

Yeah, probably a good follow-on :)",need test various running python script validate optimize throughout maybe later yeah probably good,issue,positive,positive,positive,positive,positive,positive
1416473670,"Manually triggered examples with CI enablement dispatch trigger: https://github.com/BenWilson2/mlflow/actions/runs/4088026383/jobs/7049229965
",manually triggered enablement dispatch trigger,issue,negative,neutral,neutral,neutral,neutral,neutral
1416339621,@befelix Thank you for filing this issue. Can you try out the branch at https://github.com/mlflow/mlflow/pull/7791 and let me know if this resolves the issue?,thank filing issue try branch let know issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1416264341,"@harupy Issue was marked closed yesterday after your reply for some reason, @'ing you in hopes you can reply to my followup.",issue marked closed yesterday reply reason reply,issue,negative,neutral,neutral,neutral,neutral,neutral
1416262486,"_> It's not SDK._
But the letters SDK embedded in the name of the folder in the repo: mlflow/server/js/src/experiment-tracking/sdk

_> We build UI assets (HTML, JS, etc.) from it_
That's exactly what we're looking for.  Can customers reuse that code for that purpose?
",name folder build asset exactly looking reuse code purpose,issue,negative,positive,positive,positive,positive,positive
1416005871,Any updates? @dmatrix's idea of introducing server-side plugins to be able to act upon e.g. model state transitions sounds fantastic. Being able to trigger deployments based on model state transitions is the missing piece in my MLOps puzzle :) ,idea able act upon model state fantastic able trigger based model state missing piece puzzle,issue,negative,positive,positive,positive,positive,positive
1415653863,@harupy  can you please review again? I applied all your review comments?,please review applied review,issue,negative,neutral,neutral,neutral,neutral,neutral
1415464195,"> > mlflow_set_tracking_uri(""postgresql://<db_username>:<db_password>@<db_host>:<db_port>/<db_name>"")
> 
> Hello @yash-ghelani-dsw `Tracking URI` is your mlflow server uri, similar like `http://localhost:5000`. You can set `tracking uri` like `mlflow_set_tracking_uri(""http://<mlflow server ip>:<mlflow server port>"")`.

hi @QipengZhou , Thank you it works now..",hello server similar like set like server server port hi thank work,issue,positive,neutral,neutral,neutral,neutral,neutral
1415272669,"> mlflow_set_tracking_uri(""postgresql://<db_username>:<db_password>@<db_host>:<db_port>/<db_name>"")

Hello @yash-ghelani-dsw `Tracking URI` is your mlflow server uri, similar like `http://localhost:5000`. You can set `tracking uri` like `mlflow_set_tracking_uri(""http://<mlflow server ip>:<mlflow server port>"")`.
",hello server similar like set like server server port,issue,positive,neutral,neutral,neutral,neutral,neutral
1415023514,"@ceevee830 It's not SDK. It's the source code of MLflow UI. We build UI assets (HTML, JS, etc.) from it and bundle it to the python package.",source code build asset bundle python package,issue,negative,neutral,neutral,neutral,neutral,neutral
1414589221,"@ceevee830 

> Is there a way to re-use MLflow's charting library?

Can you elaborate on this? MLflow uses Plotly for plots on UI. I think you can use it.
",way charting library elaborate think use,issue,negative,positive,positive,positive,positive,positive
1414273135,Hopefully the tests should be good to go now. Having a heck of a time running tests on a windows work machine :/. Will debug on my personal if it fails again.,hopefully good go heck time running work machine personal,issue,positive,positive,positive,positive,positive,positive
1413869208,Looks like installing a custom app that returns 403's only messes with the tests quite a bit... At least we know it works. Will fix that up.,like custom quite bit least know work fix,issue,negative,negative,negative,negative,negative,negative
1413304832,Noticed that this feature was added in a recent release (but was not yet available on the tracking server I was trying to match versions with). Closing.,feature added recent release yet available server trying match,issue,negative,positive,positive,positive,positive,positive
1413294577,"Hi @ReHoss For me, the workaround is to use mlflow only for logging but writing my own scripts for analysis and comparison. I also need to track dozens of parameters and metrics but only compare a few within a set of runs, so mlflow doesn't work for me: selecting columns every time I reopen the page or start a new run or load more runs takes too much time. I do hope that the ""Only show differences"" is returned at some point though - and is applied to all columns, including parameters",hi use logging writing analysis comparison also need track metric compare within set work every time reopen page start new run load much time hope show returned point though applied,issue,negative,positive,positive,positive,positive,positive
1412835909,Has any thought been given to implementing an equivalent for the R client?  I see no way to easily modify outgoing requests in https://github.com/mlflow/mlflow/blob/master/mlflow/R/mlflow/R/tracking-rest.R#L34,thought given equivalent client see way easily modify outgoing,issue,positive,positive,positive,positive,positive,positive
1412545837,"@harupy thanks so much for taking a look! Open to any alternative solutions too.
We did look into [checkpoint](https://github.com/dominodatalab/domino-research/tree/main/checkpoint#quick-start) for a bit but the project is a bit stale. It touched on the problem by adding an approval step to the model transition workflow but what we really want is to restrict model transitioning to only a CI service account. ",thanks much taking look open alternative look bit project bit stale touched problem approval step model transition really want restrict model service account,issue,negative,positive,neutral,neutral,positive,positive
1412320773,"Hi any news about this bug. With typing-extensions > 4 I have the same problem.
Thanks",hi news bug problem thanks,issue,negative,positive,positive,positive,positive,positive
1411826027,"@jsnb-devoted Thanks for the FR!

> In the absence of any RBAC we don't have any mechanism to prevent a user from going in to the UI and calling any model they want ""production"".

Correct. Currently, MLflow doesn't provide a way to turn off transitioning model stages on UI (the only workaround is to fork this repo and modify the UI source code).

```diff
diff --git a/mlflow/server/js/src/model-registry/components/ModelVersionView.js b/mlflow/server/js/src/model-registry/components/ModelVersionView.js
index cab8f6774..4145ebe81 100644
--- a/mlflow/server/js/src/model-registry/components/ModelVersionView.js
+++ b/mlflow/server/js/src/model-registry/components/ModelVersionView.js
@@ -258,7 +258,7 @@ export class ModelVersionViewImpl extends React.Component {
     const defaultOrder = [
       this.renderRegisteredTimestampDescription(modelVersion.creation_timestamp),
       this.renderCreatorDescription(modelVersion.user_id),
-      this.renderStageDropdown(modelVersion),
+      // this.renderStageDropdown(modelVersion),
       this.renderLastModifiedDescription(modelVersion.last_updated_timestamp),
       this.renderSourceRunDescription(),
     ];
```

We're going to discuss this in the team and get back to you.",thanks absence mechanism prevent user going calling model want production correct currently provide way turn model fork modify source code git index export class going discus team get back,issue,positive,positive,neutral,neutral,positive,positive
1411762297,"I'm using a windows machine and I have ""make"" installed that helped me run the ""r.ingest"" step but I'm seeing this error at ""r.split"" step, can someone please help?",machine make run step seeing error step someone please help,issue,negative,neutral,neutral,neutral,neutral,neutral
1411669762,"> @ddejaco I think the difference comes from `average`. MLflow uses `weighted` by default:
> 
> https://github.com/mlflow/mlflow/blob/9eeeff414d119c7df72b10da3dda8daf000d85ea/mlflow/sklearn/utils.py#L215
> 
> You can use `mlflow.sklearn.autolog(..., pos_label=1)` for binary classification.

Thank you @harupy for your comment. I see now that by setting **pos_label = 1** the metrics are correct.

I think it is very misleading that the metrics autologged with default arguments are not the same as the sklearn.metrics calculated with default arguments. (the default arguments of e.g. sklearn.metrics.recall_score are **pos_label = 1** and **average = ""binary""**)
 Shouldn't the default calculation be the same? (I changed the title accordingly)


 ",think difference come average weighted default use binary classification thank comment see setting metric correct think misleading metric default calculated default default average binary default calculation title accordingly,issue,negative,negative,negative,negative,negative,negative
1411557686,"> @Crazybean-lwb Thanks for the FR! Can you elaborate on how to handle different git services. Let's we say have two users, one uses GitHub, the other one uses GitLab. How do we handle this? Maybe we could consider adding an option to specify a git service for the `mlflow server` command and allow UI to fetch that information to construct a link.

Good question.
I think we can simplify this problem. Since we can use git diff only when tracking script file was under git repo.
We only need to get git.repoURL in `tags`.
eg:
```
        {
          ""key"": ""mlflow.source.git.repoURL"",
          ""value"": ""https://gitlab.stonewise.cn/liuweibin/try-mlflow.git""
        },
```
no need to check git service. Only two runs in same repo can construct a link.",thanks elaborate handle different git let say two one one handle maybe could consider option specify git service server command allow fetch information construct link good question think simplify problem since use git script file git need get key value need check git service two construct link,issue,positive,positive,positive,positive,positive,positive
1411526915,"> You can ref [how-runs-and-artifacts-are-recorded](https://mlflow.org/docs/latest/tracking.html#how-runs-and-artifacts-are-recorded), if you wand store metadata in DB, you need start a tracking server, instead of just using R Language.

hello @QipengZhou , I am colleague of @Jaidatt, I had a look on the above link you provided. Currently we are trying to replicate scenario 4 refering to same link. 

>mlflow server --backend-store-uri postgresql+psycopg2://username:password@IP:port/DBname

The above command is working to read the artifacts and backend store details from given location. But the problem is when we are trying to set the tracking URI during the creation of experiment (using R API), it shows schema not valid error. Below are the more specific details:

Command use to set the tracking URI (using R API) is
>mlflow_set_tracking_uri(""postgresql://<db_username>:<db_password>@<db_host>:<db_port>/<db_name>"")

Later on we are trying to the create the experiment ((using R API)) with following command:
>mlflow_create_experiment(name = ""test"", artifact_location = ""s3://<bucket_name>/<folder_name>"" )

Then it shows following error:
>Error in new_mlflow_client.default(tracking_uri): Unsupported scheme: 'postgresql'
>Traceback:
>1. mlflow_create_experiment(name = ""test05"", artifact_location = ""s3://mlflow/test-mlflow"")
>2. resolve_client(client)
>3. mlflow_client()
>4. new_mlflow_client(tracking_uri)
>5. new_mlflow_client.default(tracking_uri)
>6. stop(paste(""Unsupported scheme: '"", tracking_uri$scheme, ""'"", . sep = """"))
",ref wand store need start server instead language hello colleague look link provided currently trying replicate scenario link server password command working read store given location problem trying set creation experiment schema valid error specific command use set later trying create experiment following command name test following error error unsupported scheme name test client stop paste unsupported scheme scheme,issue,negative,neutral,neutral,neutral,neutral,neutral
1411451415,"> @ann-lab52 Can you try running this? `artifact_path` must be relative.
> 
> ```
> mlflow.pytorch.log_model(self.model, artifact_path=""model"", registered_model_name=""OurModel"")
> ```

I'm sorry for the late reply. Unfortunately, our MLFlow server was terminated lately, therefore I can't reproduce it anymore. 

I will close this issue then.  If anyone have the same issue, please feel free to reopen it. Thanks",try running must relative model sorry late reply unfortunately server lately therefore ca reproduce close issue anyone issue please feel free reopen thanks,issue,positive,negative,negative,negative,negative,negative
1411247876,"@Crazybean-lwb Thanks for the FR! Can you elaborate on how to handle different git services. Let's we say have two users, one uses GitHub, the other one uses GitLab. How do we handle this? Maybe we could consider adding an option to specify a git service for the `mlflow server` command and allow UI to fetch that information to construct a link.",thanks elaborate handle different git let say two one one handle maybe could consider option specify git service server command allow fetch information construct link,issue,positive,positive,positive,positive,positive,positive
1411113603,"I am currently trying to focus on https://github.com/mlflow/mlflow/issues/6077, so I think you can go ahead with your PR.",currently trying focus think go ahead,issue,negative,neutral,neutral,neutral,neutral,neutral
1411096778,"Got it. I can work on a fast follow up PR if need be. @kamalesh0406, let me know :) ",got work fast follow need let know,issue,negative,positive,positive,positive,positive,positive
1411081047,@dbczumar the FR was posted by @sunishsheth2009 ; @kamalesh0406 just picked it up to get familiar with contributing to the repo :) ,posted picked get familiar,issue,negative,positive,positive,positive,positive,positive
1411079198,@mengxr That makes sense to me. @kamalesh0406 does the prefix approach satisfy your use case(s)?,sense prefix approach satisfy use case,issue,negative,neutral,neutral,neutral,neutral,neutral
1411075471,It would be nice to keep run names unique to help model comparison. Shall we make this param the run name prefix instead of the full run name?,would nice keep run unique help model comparison shall make param run name prefix instead full run name,issue,positive,positive,positive,positive,positive,positive
1410872339,"@dbczumar I'm still available to coordinate and contribute to this. Happy for this issue to be assigned to me
",still available contribute happy issue assigned,issue,positive,positive,positive,positive,positive,positive
1410611026,"@JaynouOliver The desired example here is something that shows a ""soup to nuts"" configuration of a full stack for a typical MLflow tracking server deployment. 

This means:
- Set up a SQL server that is supported by MLflow (MySQL is most widely used) in a Docker container 
- Start the Docker container and validate that the MySQL server running within it can accept queries
- Configure minio in another Docker container (with script) to serve as the artifact store
- Setup the Mlflow tracking server to use the MySQL instance as the tracking server 
- Setup an additional MLflow tracking server in --artifacts-only mode to handle passthrough to the minio instance for artifact storage
- A simple ML model script that will use the configured tracking server to log 2 experiments, each with 5-20 runs each (including nested child runs) and provide instructions on how to open up the UI to see the experiments. Then, load the experiments from the saved locations in the artifact store and perform inference in batch mode.

Hope that provides a bit more clarity on the ask here :) ",desired example something soup configuration full stack typical server deployment set server widely used docker container start docker container validate server running within accept configure another docker container script serve artifact store setup server use instance server setup additional server mode handle instance artifact storage simple model script use server log child provide open see load saved artifact store perform inference batch mode hope bit clarity ask,issue,positive,positive,neutral,neutral,positive,positive
1410590853,"Issue verified fixed! Thanks to both @xinglong700000 and @labradovy for reporting this issue and @bali0019 for the great set of PRs that fixed it! :D 

@labradovy we aim for approximately monthly releases (give or take a few weeks) and we're gearing up for another release soon. No firm exact date as of yet, but it's coming soon! ",issue fixed thanks issue bali great set fixed aim approximately monthly give take gearing another release soon firm exact date yet coming soon,issue,positive,positive,positive,positive,positive,positive
1410531020,"@bali0019 I saw the PR merged and I tried this nightly build `mlflow-2.1.2.dev0-0.b4a14ffce67fdaca-py3-none-any.whl`

It looks like is **working correctly** now, thank you for the support.

When do you think 2.1.2 will be released?",bali saw tried nightly build like working correctly thank support think,issue,positive,neutral,neutral,neutral,neutral,neutral
1410179968,"@ddejaco I think the difference comes from `average`. MLflow uses `weighted` by default:

https://github.com/mlflow/mlflow/blob/9eeeff414d119c7df72b10da3dda8daf000d85ea/mlflow/sklearn/utils.py#L215

You can use `mlflow.sklearn.autolog(..., pos_label=1)` for binary classification.",think difference come average weighted default use binary classification,issue,negative,negative,negative,negative,negative,negative
1409986202,"You can ref [how-runs-and-artifacts-are-recorded](https://mlflow.org/docs/latest/tracking.html#how-runs-and-artifacts-are-recorded), if you wand store metadata in DB, you need start a tracking server, instead of just using R Language.",ref wand store need start server instead language,issue,negative,neutral,neutral,neutral,neutral,neutral
1409885040,"Hi @ichbinjakes @BenGalewsky apologies for the delay here. The requirements outlined by @ichbinjakes look great, and I think that https://github.com/ncsa/charts/tree/main/charts/mlflow covers a lot of the groundwork. 

@ichbinjakes @BenGalewsky Would you still be interested in coordinating to extend the helm chart's capabilities and contribute it to MLflow, perhaps with help from @skbly7 if they're still interested as well?",hi delay outlined look great think lot groundwork would still interested extend helm chart contribute perhaps help still interested well,issue,positive,positive,positive,positive,positive,positive
1409879181,"Hi @AdityaThakur1 @shaikmoeed @phatlast96 apologies for the delay here. It would be super helpful to integrate a utility into MLflow that can generate OpenAPI specs for the MLflow Tracking and Model Registry APIs from proto. For example, https://github.com/google/gnostic would be a very useful tool for this. We could add a script for this generation in https://github.com/mlflow/mlflow/tree/master/dev, which is where proto generation scripts (https://github.com/mlflow/mlflow/blob/master/dev/generate-protos.sh) live.",hi delay would super helpful integrate utility generate spec model registry proto example would useful tool could add script generation proto generation live,issue,positive,positive,positive,positive,positive,positive
1409874260,"@BenWilson2 Can you provide some additional context on expectations here?

@JaynouOliver Of course! Thank you in advance for your contribution. Please let me know if you have any questions.",provide additional context course thank advance contribution please let know,issue,positive,neutral,neutral,neutral,neutral,neutral
1409797471,@harupy Can you please assign this task to me? I would be using pep 8 for this task,please assign task would pep task,issue,negative,neutral,neutral,neutral,neutral,neutral
1409606033,"Hi @benjaminbluhm, apologies for the delay. That plan sounds great!  ",hi delay plan great,issue,negative,positive,positive,positive,positive,positive
1408945558,"I agree the diff is quite giant, will break it down. Didn't realize how inter-dependent all the components are on having access to all the experiments locally but kept finding more scenarios where things break without all the experiments.",agree quite giant break realize access locally kept finding break without,issue,negative,neutral,neutral,neutral,neutral,neutral
1408813362,Thank you. I think the failing tests are unrelated to my changes.,thank think failing unrelated,issue,negative,neutral,neutral,neutral,neutral,neutral
1408503054,"This error is not specific to macOS. I have the same issue on Debian GNU/Linux and Python  3.9.1.
I've had success though with installing numba first though using the following in `pyproject.toml`
```
numba = "">0.56""
mlflow = ""^2.1.1""
```
which turned out in `poetry.lock` as 
```
name = ""mlflow""
version = ""2.1.1""

name = ""numba""
version = ""0.56.4""
```
Note: `numba==0.56.0 ` did not work for me due to a conflict with (as far as I remember) numpy.

",error specific issue python success though first though following turned name version name version note work due conflict far remember,issue,negative,positive,neutral,neutral,positive,positive
1408310870,"@jmahlik 
Ok, once again apologies for the delay. We're putting much effort into new features at the moment and the time around holidays+new year was pretty hectic :) 

I can see that in the meanwhile, you've introduced new changes to `HomePage` and `ExperimentView` components as well. 🤔 Despite the changes are probably well-thought, I'm afraid we're slightly deviating from the guidelines for keeping changes and PRs possible small, atomic, reversible and focused on a single change. The diff overall has grown to bulky ~1000 LoCs and it would be risky to consider merging it all at once. 

AFAIR I think this lengthy effort started with an attempt of improving UX/responsiveness in scenarios where a user had a lot of experiments, having virtualized list as a viable approach. Therefore I propose to break down this changeset into smaller chunks that will subsequently introduce one feature by one:
1. Let's start with putting `react-virtualized`'s `List`, `AutoSizer` etc. into the experiment list view, but with no changes to data fetching/filtering. It should improve the UX a lot already since virtualized rows will be **way** more performant than rendering all of them at once. This should result in ~300-400 LoC changeset while improving much.
2. Next, it'd be great to add pagination/querying by name and if necessary, all changes to actions and reducers.
3. At this step, evaluate if there is anything else to be changes and if necessary, propose next PRs.

I think that step 1. is discussed thoroughly already in this PR so if you manage to isolate these changes I think it will be good to go very quickly.

LMK what you think!",delay much effort new moment time around year pretty hectic see meanwhile new well despite probably afraid slightly keeping possible small atomic reversible single change overall grown bulky would risky consider think lengthy effort attempt improving user lot list viable approach therefore propose break smaller subsequently introduce one feature one let start list experiment list view data improve lot already since way performant rendering result improving much next great add name necessary step evaluate anything else necessary propose next think step thoroughly already manage isolate think good go quickly think,issue,positive,positive,neutral,neutral,positive,positive
1408154431,"@dongshengzhangmthreads PLEASE DON'T DO THIS. If you want to practice creating a PR, you can use your repositories.",please want practice use,issue,negative,neutral,neutral,neutral,neutral,neutral
1408081639,"QipengZhou thank you for your reply,
I want to store experiement metadata in Postgresql using R language (not using Python language).
ex:
>library(mlflow)
>mlflow_set_tracking_uri("""")
>mlflow_create_experiment("""")
![image](https://user-images.githubusercontent.com/92085242/215406352-d1a5e748-8949-4154-a3b9-bb19aed02776.png)

I want to set tracking uri in Postgres Sql so whenever experiment is created it will store metadata in DB using R Language.",thank reply want store language python language ex library image want set whenever experiment store language,issue,negative,neutral,neutral,neutral,neutral,neutral
1407344418,"got the solution during the weekends. 

I have typed ```export MLFLOW_TRACKING_URI=""xxx.xxx.xxx.xxx:5000""``` in terminal before 
which was not an accessible port from outside.
I changed the ```export MLFLOW_TRACKING_URI = ""xxx.xxx.xxx.xxx:remote_accessible_port""``` 
and ```mlflow.set_tracking_uri()``` as same one.


registry URI was somewhere else(i don't exactly know, but itk it's something different from artifact storage)
If anyone knows difference between registry URI and artifact_storage_URI, please let me know.
Thanks.
",got solution export terminal accessible port outside export one registry somewhere else exactly know something different artifact storage anyone difference registry please let know thanks,issue,positive,positive,positive,positive,positive,positive
1407330337,"This tracking uri refers to `mlflow server uri`, not `db dsn`. You need to specify db dsn when starting mlflow server, like `mlflow ui --backend-store-uri postgresql+psycopg2://username:password@IP:port/DBname`.",server need specify starting server like password,issue,negative,neutral,neutral,neutral,neutral,neutral
1406925034,"Hi @idlefella we discussed it internally and would like to avoid the header-embedded approach in MLflow due to the aforementioned 'usability concerns'. If it can be done completely through the use of plugins and a PR is filed that:
a) enables plugin support for server-level configurations that can support defining a bespoke serialization protocol (or whatever else you'd like to add to the serving layer). This would be a modification of the cli to have a configuration app module function as a pluggable configuration loader. 
b) explains the functionality with an example (this use case for pickling and passing an octet-stream would be ideal) and applicable documentation updates that explain this cool new feature :) 

Let me know what you think!",hi internally would like avoid approach due done completely use support support bespoke serialization protocol whatever else like add serving layer would modification configuration module function pluggable configuration loader functionality example use case passing would ideal applicable documentation explain cool new feature let know think,issue,positive,positive,positive,positive,positive,positive
1406731883,"I ran into the same issue, and unfortunately the `numba` dependencies and my `pandas` dependencies clash. This is what happens when I try to fix it to use `numba=0.56.0`.
```
Because numba (0.56.0) depends on numpy (>=1.18,<1.23)
 and pandas (1.5.3) depends on numpy (>=1.23.2), numba (0.56.0) is incompatible with pandas (1.5.3).
And because no versions of pandas match >1.5.3,<2.0.0, numba (0.56.0) is incompatible with pandas (>=1.5.3,<2.0.0).
So, because <env> depends on both pandas (^1.5.3) and numba (0.56), version solving failed.
```

EDIT: I was able to resolve the package install errors using `Python v3.10.9` and `numba==0.56.4` and `mlflow=2.1.1`. I'm using poetry with macos M1 chip and `pyenv` for python management.",ran issue unfortunately clash try fix use incompatible match incompatible version edit able resolve package install python poetry chip python management,issue,negative,neutral,neutral,neutral,neutral,neutral
1406714449,"@labradovy thank you for getting back to me. I am looking into this and will update you soon (most likely, going to be a PR fix for this). ",thank getting back looking update soon likely going fix,issue,negative,neutral,neutral,neutral,neutral,neutral
1406663690,"@bali0019 Thanks for the quick reply.
I just ran the code with the nightly build `mlflow-2.1.2.dev0-0.102faef8d-py2.py3-none-any.whl` and added the file:// to the URI as well. It didn't work.

The operation that triggers the exception is:
```
model = mlflow.pyfunc.load_model(
    f""models:/{tags.model_name}/{tags.model_stage}""
)
```

Like you said I don't see the code handling a separate netloc, I see netloc populated but discarted.

Edit: it was the wrong nightly build (still didn't work)",bali thanks quick reply ran code nightly build added file well work operation exception model like said see code handling separate see edit wrong nightly build still work,issue,positive,positive,neutral,neutral,positive,positive
1406485198,are there news about having one model tagged with two stages? This is a feature that I also need since I have a similar setup to what is mentioned by @mackinleysmith  and @krlng ,news one model tagged two feature also need since similar setup,issue,negative,neutral,neutral,neutral,neutral,neutral
1406438953,"> @hubertzub-db just a quick ping if you get a chance to take a look.

@jmahlik sorry about the delay, I'll get back to this one ASAP",quick ping get chance take look sorry delay get back one,issue,negative,negative,neutral,neutral,negative,negative
1406361575,"Hi @BenWilson2 

Thanks for your prompt response. I concur that utilizing pickled data from Python has certain drawbacks. I'm not particularly fond of that approach either, but it would currently address our issue.

The main concern I with to address is to make it transparent for the developer whether the model runs in the same Python process or is called remotely. Essentially, I would like the following lines of code to have the same behavior and be interchangeable:

```python
logged_model = 'mlflow-artifacts:/xxxxx/MySimpleModel'

loaded_model = mlflow.sklearn.load_model(logged_model)
# loaded_model = proxy_interface_to_model_over_rest(logged_model)

predictions = loaded_model.predict(df)
print(type(predictions))
print(predictions)
```

Currently, it is not possible to write such a `proxy_interface_to_model_over_rest` method, as the result cannot be transformed back, and the developer would have to modify their code depending on the implementation used.

I also read https://github.com/mlflow/mlflow/issues/7566 and I think that such a plugin interface or similar would make sense here. Another option I see is adding a HTTP response header indicating the actual type, but I assume that exposing any Python-specific information in the HTTP interface to consumers is not desired?

Please let me know.

Best idlefella",hi thanks prompt response concur data python certain particularly approach either would currently address issue main concern address make transparent developer whether model python process remotely essentially would like following code behavior interchangeable python print type print currently possible write method result back developer would modify code depending implementation used also read think interface similar would make sense another option see response header actual type assume information interface desired please let know best,issue,positive,positive,positive,positive,positive,positive
1406127182,"> ```diff
> diff --git a/tests/examples/test_examples.py b/tests/examples/test_examples.py
> index 9eb146c82..71deae0d2 100644
> --- a/tests/examples/test_examples.py
> +++ b/tests/examples/test_examples.py
> @@ -89,6 +89,7 @@ def clean_up_mlflow_virtual_environments():
>      ],
>  )
>  def test_mlflow_run_example(directory, params, tmp_path):
> +    mlflow.set_tracking_uri(tmp_path.joinpath(""mlruns"").as_uri())
>      example_dir = Path(EXAMPLES_DIR, directory)
>      tmp_example_dir = tmp_path.joinpath(example_dir)
>      shutil.copytree(example_dir, tmp_example_dir)
> ```
> 
> Inserting `mlflow.set_tracking_uri(tmp_dir)` to avoid using a cached tracking store worked.

Great idea! Changed the PR :)",git index directory path directory avoid store worked great idea,issue,negative,positive,positive,positive,positive,positive
1406124256,"```diff
diff --git a/tests/examples/test_examples.py b/tests/examples/test_examples.py
index 9eb146c82..71deae0d2 100644
--- a/tests/examples/test_examples.py
+++ b/tests/examples/test_examples.py
@@ -89,6 +89,7 @@ def clean_up_mlflow_virtual_environments():
     ],
 )
 def test_mlflow_run_example(directory, params, tmp_path):
+    mlflow.set_tracking_uri(tmp_path.joinpath(""mlruns"").as_uri())
     example_dir = Path(EXAMPLES_DIR, directory)
     tmp_example_dir = tmp_path.joinpath(example_dir)
     shutil.copytree(example_dir, tmp_example_dir)
```

Inserting `mlflow.set_tracking_uri(tmp_dir)` to avoid using a cached tracking store worked.",git index directory path directory avoid store worked,issue,negative,neutral,neutral,neutral,neutral,neutral
1406042970,"@BenWilson2 can you review this PR? Also, when I try to rerun the recipe with the same run name, we create a run with the same run name instead of adding a suffix like `1` after the name. Is this fine? I am attaching a screenshot of the runs to give you an idea of what I mean.

<img width=""945"" alt=""Screen Shot 2023-01-26 at 9 35 14 PM"" src=""https://user-images.githubusercontent.com/29024165/215016775-d13d2624-c3b2-4677-9bcd-1b37f5eb462c.png"">



",review also try rerun recipe run name create run run name instead suffix like name fine give idea mean screen shot,issue,positive,positive,neutral,neutral,positive,positive
1405953854,"@labradovy We [merged a fix](https://github.com/mlflow/mlflow/pull/7670) for a related issue to master. Can you please retry using the `master` branch? When you do that, please ensure you set `--default-artifact-root` to a `file://` URI, for example: doing it this way `file:///server_name_a/Mlruns/DEV` (if this doesn't work: `file://server_name_a/Mlruns/DEV`), that will just force the path to contain netloc (servername here) to work with `pathlib`, I just don't see that logic handling in the related mlflow code to parse netloc as servername for UNC path. We may have to put a fix on this based on your run against the master branch. If you can report back on whether that works, that will be great. Based on your feedback, we can open an issue to address this if it still persists in the master branch. 
Also, just curious, what is your operation that triggers that exception? It seems like you are either logging or downloading artifacts. 

@xinglong700000 Can you kindly elaborate more on it? perhaps some pseudo code/steps would be great.",fix related issue master please retry master branch please ensure set file example way file work file force path contain work see logic handling related code parse path may put fix based run master branch report back whether work great based feedback open issue address still master branch also curious operation exception like either logging kindly elaborate perhaps pseudo would great,issue,positive,positive,positive,positive,positive,positive
1405896707,"> > By the way, the tracking server version is 1.23.1, but my mlflow client is 2.0.1. Would it cause any problem?
> 
> @xinglong700000 Have you resolved this problem? This version mismatch is most likely the cause for the error you are experiencing.

I just found that some of the registered model has no such error. Means I can load them with their model name and version only. However, if I try to load the old registered models, it still has 404 not found error. I think maybe the artifact paths has some mismatch.",way server version client would cause problem resolved problem version mismatch likely cause error found registered model error load model name version however try load old registered still found error think maybe artifact mismatch,issue,negative,positive,neutral,neutral,positive,positive
1405808013,"> The plugin interface approach looks great! I think it will keep the mllfow implementation simple and clean as well as simplifying the UX for the submitted app configuration as well. Looking forward to your PR! :D

Have it ready, just waiting on approval to sign the DCO",interface approach great think keep implementation simple clean well configuration well looking forward ready waiting approval sign,issue,positive,positive,positive,positive,positive,positive
1405792340,"I am having a similar issue:

My server is running on Windows.

We were on 1.22.1 running fine and just upgraded to 2.1.1 ( ran mlflow db upgrade) when the issue started.

The main difference is that I am using a network drive as --default-artifact-root.

This is how I initialize the server:
`mlflow server --backend-store-uri mssql+pymssql://{{DATABASE_SERVER}}/{{MLFLOW_DATABASE}} --default-artifact-root \\{{DATABASE_SERVER}}\Mlruns\DEV`

When urllib parses my path the server name is not included in the path in this line of code at `mlflow.utils.file_utils.py`:
![image](https://user-images.githubusercontent.com/123701472/214969987-bc55ca93-8f06-4c75-95c7-5b8ee1484a28.png)

![image](https://user-images.githubusercontent.com/123701472/214970322-60077dfd-1df1-4a05-b846-5f0f63079398.png)

So I end up with:
```
OSError: No such file or directory: '\Mlruns\DEV\3\d875a513a0dc4f42b642df7026d6bd7b\artifacts\my_model_pth.pth\MLmodel'

Process finished with exit code 0
```",similar issue server running running fine ran upgrade issue main difference network drive initialize server server path server name included path line code image image end file directory process finished exit code,issue,negative,positive,positive,positive,positive,positive
1405691471,"Thanks @wamartin-aml ! Since duration is derived from start time & end time, I think it might be nice to avoid putting that derived information in the REST API.

What are your thoughts about supporting duration in search as a derived attribute, e.g. SearchRuns with filter `attributes.duration > 1000` and surfacing it on the `RunInfo` entity in the MLflow Python / R / Java clients?

We'll also need to think about resolution. Currently, start & end time are measured in milliseconds. Should users apply millisecond resolution for duration filtering? This seems reasonable, but just confirming.",thanks since duration derived start time end time think might nice avoid derived information rest supporting duration search derived attribute filter surfacing entity python also need think resolution currently start end time measured apply millisecond resolution duration filtering reasonable confirming,issue,positive,positive,positive,positive,positive,positive
1405620538,"The problematic function `_load_version_file_as_dict` has been refactored in the master branch as per #7577 and, as such, has different behavior. Could you attempt to build from master to see if the new changes work for you? ",problematic function master branch per different behavior could attempt build master see new work,issue,negative,positive,neutral,neutral,positive,positive
1405591911,"Hi @idlefella there are a few concerns that we have with this approach. 
1. This would require that the consumers of anything produced with the pickled data, in order to deserialize the payload, would need to a) have the exact same version of Python installed as the inference server and b) have the exact same pickle protocol and version installed. This is going to be quite a stretch in the real-world and will just induce frustration in consumers of the inference data. 
2. This limits consumers of the inference payload to those running a Python process. It's a bit restrictive. 

Instead of embedding this within MLflow as you have done in your PR, perhaps a plugin approach will be a better way to go. 
We can expose a plugin app configuration to the `mlflow models serve` cli as an optional argument that can be used to enable this (or any other mime type that someone might need). The plugin would be reusable as a standalone application that is entirely customizable for any particular use case that someone might have for configuring the specific needs of the returned inference data types for a particular project (as opposed to having to set restrictive configurations on the MLflow server configuration side which will end up being rather complex to maintain as more mime types are added). 

Please have a look at the discussion here: #7566 for a similar design discussion that leverages a plugin approach that would effectively be portable here as well. 

Let us know what you think!",hi approach would require anything produced data order would need exact version python inference server exact pickle protocol version going quite stretch induce frustration inference data inference running python process bit restrictive instead within done perhaps approach better way go expose configuration serve optional argument used enable mime type someone might need would application entirely particular use case someone might specific need returned inference data particular project opposed set restrictive server configuration side end rather complex maintain mime added please look discussion similar design discussion approach would effectively portable well let u know think,issue,negative,positive,positive,positive,positive,positive
1405059170,The plugin interface approach looks great! I think it will keep the mllfow implementation simple and clean as well as simplifying the UX for the submitted app configuration as well. Looking forward to your PR! :D ,interface approach great think keep implementation simple clean well configuration well looking forward,issue,positive,positive,positive,positive,positive,positive
1404572754,"sorry if it was rude for somebody else to come and ask for a closed issue.
If opening new issue is right and link this page, feel free to tell me. I will follow your suggestion.

I am experiencing same error on same **mlflow version 1.25.1**
tried downgrading to **pysftp=0.2.8** but it gives paramiko error like below:

```paramiko.ssh_exception.SSHException: Unable to connect to xx.xx.xxx.xx: [Errno 110] Connection timed out```

the only possible cause for me is that **I am trying to connect to mlflow server on the same device.**
(which means mlflow server~ command and mlflow.log_model() was ran on same device, different cmd windows)

```mlflow server --backend-store-uri postgresql://mlflow_user:mlflow@localhost/mlflow_remote --default-artifact-root sftp://sftpuser:password@49.50.164.14/mlruns -p 2247 --host 0.0.0.0```

can it cause a problem? 

and can you please give me a bit detailed explaination about 'IT WORKS WITH PYSFTP==0.2.8'

with pysftp==0.2.8, i tried your test code above and it gave me error like this:
```
    raise SSHException(
paramiko.ssh_exception.SSHException: Error reading SSH protocol banner
```

please feel free to tell me any lack of info or anything else.
thanks in advance.",sorry rude somebody else come ask closed issue opening new issue right link page feel free tell follow suggestion error version tried error like unable connect connection timed possible cause trying connect server device command ran device different server password host cause problem please give bit detailed work tried test code gave error like raise error reading protocol banner please feel free tell lack anything else thanks advance,issue,negative,positive,neutral,neutral,positive,positive
1404534742,"Thoughts on implementing via a plugin entrypoint? Thought I'd throw together an example before getting too far down the road.

* Seems simple
* Allows sharing of plugins between users
* Falls in line with the other plugin styles
* Keeps it clean by requiring a plugin interface with an entrypoint.
* Allows complete control over the config like @lucascott was mentioning a need for. There could be multiple things a user needs to do. Adding them via another interface seems overly complex.

Some some pseudo code. (possibly almost all of the code)

```python
# Default app name is mlflow.server.app
app_name = ""{}:app"".format(__name__)

# A user can have one app plugin installed
apps = [entrypoint.name for entrypoint in entrypoints.get_group_all(""mlflow.app"")]

if len(apps) > 1:
    raise MlflowException(""There can only be one app, multiple detected. {}"".format(apps))

if len(apps) == 1:
    app_name = apps[0]

# Change the commands to reference app_name

def _build_waitress_command(waitress_opts, host, port):
    opts = shlex.split(waitress_opts) if waitress_opts else []
    return (
        [""waitress-serve""]
        + opts
        + [""--host=%s"" % host, ""--port=%s"" % port, ""--ident=mlflow"", app_name]
    )


def _build_gunicorn_command(gunicorn_opts, host, port, workers):
    bind_address = f""{host}:{port}""
    opts = shlex.split(gunicorn_opts) if gunicorn_opts else []
    return [""gunicorn""] + opts + [""-b"", bind_address, ""-w"", ""%s"" % workers, app_name]
```

And an example plugin would look something like this

entrypoint: `mlflow.app = my_plugin:app`

```python
import logging

# This would be all that plugin author is required to import
from mlflow.server import app

# Could do custom logging on either the app or logging itself
# but you'll possibly have to clear the handlers or there will be duplicate output
logging.basicConfig(level=logging.INFO)
root_logger = logging.getLogger(""root"")
mlflow_logger = logging.getLogger(""mlflow"")

for handler in root_logger.handlers:
    root_logger.removeHandler(handler)

for handler in mlflow_logger.handlers:
    root_logger.removeHandler(handler)

# Change the format or implement json logging etc
f = logging.Formatter(""%(asctime)s - %(name)s - %(levelname)s - %(message)s"")
st = logging.StreamHandler()
st.setFormatter(f)
root_logger.addHandler(st)


# Now configure the app to meet your needs
@app.before_request
def before_req_hook():
    # Implement jwt auth here
    return ""This works!""
```",via thought throw together example getting far road simple line clean interface complete control like need could multiple user need via another interface overly complex pseudo code possibly almost code python default name user one raise one multiple change reference host port else return host port host port host port else return example would look something like python import logging would author import import could custom logging either logging possibly clear duplicate output root handler handler handler handler change format implement logging name message st st configure meet need implement return work,issue,positive,positive,neutral,neutral,positive,positive
1404506445,"Interesting. It works in the following case:

```python
# tests/test_foo.py

import pytest
import numpy as np

@pytest.mark.parametrize(""np_obj"", [np.float(0.0), np.array([0.0])])
def test_foo(np_obj):
    assert True
```

```
> pytest tests/test_foo.py
============================================== test session starts ==============================================
platform darwin -- Python 3.8.13, pytest-7.2.0, pluggy-1.0.0 -- /Users/harutakakawamura/.pyenv/versions/miniconda3-4.7.12/envs/mlflow-dev-env/bin/python3.8
cachedir: .pytest_cache
rootdir: /Users/harutakakawamura/Desktop/repositories/mlflow, configfile: pytest.ini
plugins: cov-4.0.0
collected 0 items / 1 error                                                                                     

==================================================== ERRORS =====================================================
______________________________________ ERROR collecting tests/test_foo.py _______________________________________
tests/test_foo.py:4: in <module>
    @pytest.mark.parametrize(""np_obj"", [np.float(0.0), np.array([0.0])])
        __builtins__ = <builtins>
        __cached__ = '/Users/harutakakawamura/Desktop/repositories/mlflow/tests/__pycache__/test_foo.cpython-38.pyc'
        __doc__    = None
        __file__   = '/Users/harutakakawamura/Desktop/repositories/mlflow/tests/test_foo.py'
        __loader__ = <_pytest.assertion.rewrite.AssertionRewritingHook object at 0x7f92902caa60>
        __name__   = 'tests.test_foo'
        __package__ = 'tests'
        __spec__   = ModuleSpec(name='tests.test_foo', loader=<_pytest.assertion.rewrite.AssertionRewritingHook object at 0x7f92902caa60>, origin='/Users/harutakakawamura/Desktop/repositories/mlflow/tests/test_foo.py')
        __warningregistry__ = {'version': 38}
        np         = <module 'numpy' from '/Users/harutakakawamura/.pyenv/versions/miniconda3-4.7.12/envs/mlflow-dev-env/lib/python3.8/site-packages/numpy/__init__.py'>
        pytest     = <module 'pytest' from '/Users/harutakakawamura/.pyenv/versions/miniconda3-4.7.12/envs/mlflow-dev-env/lib/python3.8/site-packages/pytest/__init__.py'>
../../../.pyenv/versions/miniconda3-4.7.12/envs/mlflow-dev-env/lib/python3.8/site-packages/numpy/__init__.py:295: in __getattr__
    warnings.warn(msg, DeprecationWarning, stacklevel=2)
E   DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
E   Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
        attr       = 'float'
        msg        = '`np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this ...recated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations'
        val        = <class 'float'>
```",interesting work following case python import import assert true test session platform python collected error error module none object object module module alias float silence warning use float modify behavior safe specifically scalar type use guidance alias float silence warning use float guidance class,issue,negative,positive,positive,positive,positive,positive
1404499140,"This line should turn warnings for deprecated aliases into errors: 
https://github.com/mlflow/mlflow/blob/f9d999e049f4a05e36df0ac6921e588d9f3e693a/pytest.ini#L6

but it doesn't seem to work.",line turn seem work,issue,negative,neutral,neutral,neutral,neutral,neutral
1404413663,@jmahlik Please feel free to submit a draft PR where we can discuss your plans for implementation (And see a mockup of your proposed design). Looking forward to it!,please feel free submit draft discus implementation see design looking forward,issue,positive,positive,positive,positive,positive,positive
1404384235,"Hi @ikrizanic , unfortunately, all of the MlflowClient APIs are, by design, matched to the REST API. We have no plans to implement this functionality as parsing the return from `search_model_versions()` is fairly trivial and we don't want to add unnecessary APIs to the client or to the REST APIs. 
Let us know if you have a desire to work on one of the outstanding roadmap items, though! Cheers!",hi unfortunately design rest implement functionality return fairly trivial want add unnecessary client rest let u know desire work one outstanding though,issue,positive,positive,neutral,neutral,positive,positive
1404377968,"Your UI is showing 1.26.1.dev0 (see the top of your screenshots, upper left). That's a build from the master branch from last summer. Can you make sure that you install MLflow from pip if you're doing local development and try again? 
In local mode, the default experiment will need to be created first for anything to register in the UI, so please give it a few seconds after creating a valid experiment and run that is placed in the 'tracking server' (your hard drive) before seeing if anything appears in the UI. 
I recommend going through the Getting Started guide on how to start up a local MLflow instance and not one that is based on a repo fork. Feel free to reopen if you get stuck (or ask in the Discussions section for help on how to get started with MLflow :) ) ",showing dev see top upper left build master branch last summer make sure install pip local development try local mode default experiment need first anything register please give valid experiment run server hard drive seeing anything recommend going getting guide start local instance one based fork feel free reopen get stuck ask section help get,issue,positive,positive,positive,positive,positive,positive
1404374282,@BenWilson2 Let me know if you have additional feedback here,let know additional feedback,issue,negative,neutral,neutral,neutral,neutral,neutral
1404230127,I'd be happy to work on this if there's interest. Currently manually running gunicorn to get the desired behavior. But that could break down if something were to change with mlflow.,happy work interest currently manually running get desired behavior could break something change,issue,positive,positive,positive,positive,positive,positive
1404189592,@hubertzub-db just a quick ping if you get a chance to take a look.,quick ping get chance take look,issue,negative,positive,positive,positive,positive,positive
1404158791,"Thanks for your help! My client version is 2.1.1 and does not create a remote service, it is all running locally. I tried all the cases locally and the interface does not show a single experimental data. I don't quite understand what you mean by the server version, is it the mlflow package?@ BenWilson2",thanks help client version create remote service running locally tried locally interface show single experimental data quite understand mean server version package,issue,positive,negative,neutral,neutral,negative,negative
1403828928,"@dbczumar here's [the doc](https://docs.google.com/document/d/1OFTMIb4c42XjENjhyPlX5tC22-6o_fguElX7NbowdAs/edit?usp=sharing) you requested, please feel free to ask for clarifications/expansions if anything is missing! ",doc please feel free ask anything missing,issue,positive,positive,neutral,neutral,positive,positive
1403306895,"This is not only a MAC problem, it happens on Ubuntu 22.10 as well. What is weird is that this is happening on mlflow versions which were previously installed correctly.

Some usecases might depend on lower numba versions, so I suggest - if/when shap will be used - to lock numba version to the lowest possible which doesn't crash. I'm ready to find the lowest numba version which works fine if this is the acceptable solution.",mac problem well weird happening previously correctly might depend lower suggest shap used lock version possible crash ready find version work fine acceptable solution,issue,negative,negative,neutral,neutral,negative,negative
1403269763,@BenWilson2 @dbczumar I will pick up the Spacy Example next - it doesn't seem to be assigned to someone atm.,pick spacy example next seem assigned someone,issue,negative,neutral,neutral,neutral,neutral,neutral
1403237654,"> `poetry add numba==0.56` fixes the issue for me on Python3.10.9. MLFlow doesn't seem to have a fixed `numba` requirement and `llvmlite = "">=0.39.0dev0,<0.40""` of `numba v0.56` installs fine.

Yes. Works for me as well. Would be great if this was documented somewhere until fixed.",poetry add issue python seem fixed requirement dev fine yes work well would great somewhere fixed,issue,positive,positive,positive,positive,positive,positive
1403234334,"@harupy I'm not comfortable closing this issue without discussing - should MLflow really depend on shap if it crashes installation on M1 Macs. Should there be a mention on the suggested workaround somewhere in the documentation.

Please consider",comfortable issue without really depend shap installation mention somewhere documentation please consider,issue,positive,positive,positive,positive,positive,positive
1402690965,"Yes, I replaced all these arguments with \<XXX\> in the ticket just to remove all personal info but forgot to escape angle brackets. I pass valid params in the actual code of course :)",yes ticket remove personal forgot escape angle pas valid actual code course,issue,positive,neutral,neutral,neutral,neutral,neutral
1402603582,"Oh, funny: I inserted <XXX> (Xes in angle brackets) instead of all names, but apparently that's reserved ",oh funny inserted angle instead apparently reserved,issue,negative,positive,positive,positive,positive,positive
1402563337,"Out of curiosity, in your repro code, how are you able to set an experiment without providing either a name or an id?",curiosity code able set experiment without providing either name id,issue,negative,positive,positive,positive,positive,positive
1402531472,"It's a permanent assignment. Once you volunteer, you're obliga- kidding. I'll fix it for you and we'll take a look at the bug! Thanks again for reporting! :) ",permanent assignment volunteer fix take look bug thanks,issue,negative,positive,positive,positive,positive,positive
1402518554,"@BenWilson2 Oops, the ""Yes. I can contribute a fix for this bug independently."" option was selected by mistake. Should I recreate it or is it ok?",yes contribute fix bug independently option selected mistake recreate,issue,negative,neutral,neutral,neutral,neutral,neutral
1402507479,Thanks for the bug report @Nika-St feel free to let us know what you find and if you need any help diagnosing (and ping us with the PR fix when it's ready!) Thank you!,thanks bug report feel free let u know find need help ping u fix ready thank,issue,positive,positive,positive,positive,positive,positive
1402499792,"This fork of numpy isn't directly supported by MLflow. Since you're using a non-standard build here, it is recommended to declare the pip requirements directly as you mentioned to avoid this warning and fallback to a package that you didn't intend to be used for inference. ",fork directly since build declare pip directly avoid warning fallback package intend used inference,issue,negative,positive,neutral,neutral,positive,positive
1402492591,@marQca What is your environment setup? Version of MLflow that you're trying to use?,environment setup version trying use,issue,negative,neutral,neutral,neutral,neutral,neutral
1402463597,"> > > I am also facing the same problem. I run my experiments on a remote HPC server. I cannot visualize the results on the HPC server (no x window, no HTTP access).
> > > I have to download the mlruns folder to my local machine to visualize the results. However, the artifacts are stored in the absolute path and I cannot access them using mlflow UI.
> > > The capability to use a relative path instead of an absolute path would be very important.
> > 
> > 
> > Until this issue is fixed you can use [mlf-core's fix-artifact-paths](https://mlf-core.readthedocs.io/en/latest/fix_artifact_paths.html).
> 
> It seems that this library is a little outdated, and I wasn't able to get it to solve the problem. So I wrote a standalone script to fix artifact paths - sharing [here](https://gist.github.com/alam-shahul/08a92fd6c33a5584491af4c3ac515e61) in case anyone finds it useful.

Feel free to create a PR with the fix!",also facing problem run remote server visualize server window access folder local machine visualize however absolute path access capability use relative path instead absolute path would important issue fixed use library little outdated able get solve problem wrote script fix artifact case anyone useful feel free create fix,issue,positive,positive,positive,positive,positive,positive
